{
  "metadata": {
    "title": "Pragmatic Unit Testing In CSharp with NUnit 2nd Edition",
    "author": "Unknown Author",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 220,
    "conversion_date": "2025-12-25T18:16:08.252633",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Pragmatic Unit Testing In CSharp with NUnit 2nd Edition.pdf",
    "extraction_method": "PyMuPDF_fallback (Unstructured failed)"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 2-10)",
      "start_page": 2,
      "end_page": 10,
      "detection_method": "topic_boundary",
      "content": "Pragmatic Unit Testing\nin C# with NUnit, Second Edition\nAndy Hunt\nDave Thomas\nwith Matt Hargett\nThe Pragmatic Bookshelf\nRaleigh, North Carolina\nDallas, Texas\n\n\nBookshelf\nPragmatic\nMany of the designations used by manufacturers and sellers to distinguish\ntheir products are claimed as trademarks. Where those designations appear\nin this book, and The Pragmatic Programmers, LLC was aware of a trademark\nclaim, the designations have been printed in initial capital letters or in all\ncapitals. The Pragmatic Starter Kit, The Pragmatic Programmer, Pragmatic\nProgramming, Pragmatic Bookshelf and the linking “g” device are trademarks\nof The Pragmatic Programmers, LLC.\nEvery precaution was taken in the preparation of this book. However, the\npublisher assumes no responsibility for errors or omissions, or for damages\nthat may result from the use of information (including program listings) con-\ntained herein.\nOur Pragmatic courses, workshops and other products can help you and your\nteam create better software and have more fun. For more information, as well\nas the latest Pragmatic titles, please visit us at:\nhttp://www.pragmaticprogrammer.com\nCopyright c⃝2007 The Pragmatic Programmers, LLC. All rights reserved. No\npart of this publication may be reproduced, stored in a retrieval system, or\ntransmitted, in any form, or by any means, electronic, mechanical, photo-\ncopying, recording, or otherwise, without the prior consent of the publisher.\nPrinted in the United States of America.\nISBN-10: 0-9776166-7-3\nISBN-13: 978-0-9776166-7-4\n\n\nContents\nAbout the Starter Kit\nix\nPreface\nxi\n1\nIntroduction\n1\n1.1\nCoding With Conﬁdence . . . . . . . . . . . . . .\n2\n1.2\nWhat is Unit Testing? . . . . . . . . . . . . . . .\n3\n1.3\nWhy Should I Bother with Unit Testing?\n. . . .\n4\n1.4\nWhat Do I Want to Accomplish? . . . . . . . . .\n5\n1.5\nHow Do I Do Unit Testing? . . . . . . . . . . . .\n7\n1.6\nExcuses For Not Testing . . . . . . . . . . . . . .\n8\n1.7\nRoadmap\n. . . . . . . . . . . . . . . . . . . . . .\n15\n2\nYour First Unit Tests\n16\n2.1\nPlanning Tests\n. . . . . . . . . . . . . . . . . . .\n17\n2.2\nTesting a Simple Method\n. . . . . . . . . . . . .\n18\n2.3\nRunning Tests with NUnit\n. . . . . . . . . . . .\n20\n2.4\nRunning the Example . . . . . . . . . . . . . . .\n27\n2.5\nMore Tests . . . . . . . . . . . . . . . . . . . . . .\n31\n3\nWriting Tests in NUnit\n32\n3.1\nStructuring Unit Tests . . . . . . . . . . . . . . .\n32\n3.2\nClassic Asserts . . . . . . . . . . . . . . . . . . .\n34\n3.3\nConstraint-based Asserts . . . . . . . . . . . . .\n37\n3.4\nNUnit Framework\n. . . . . . . . . . . . . . . . .\n41\n3.5\nNUnit Test Selection . . . . . . . . . . . . . . . .\n43\n3.6\nMore NUnit Asserts\n. . . . . . . . . . . . . . . .\n51\n3.7\nNUnit Custom Asserts . . . . . . . . . . . . . . .\n53\n3.8\nNUnit and Exceptions . . . . . . . . . . . . . . .\n54\n3.9\nTemporarily Ignoring Tests . . . . . . . . . . . .\n57\n\n\nCONTENTS\nvi\n4\nWhat to Test: The Right-BICEP\n60\n4.1\nAre the Results Right? . . . . . . . . . . . . . . .\n61\n4.2\nBoundary Conditions\n. . . . . . . . . . . . . . .\n64\n4.3\nCheck Inverse Relationships . . . . . . . . . . .\n66\n4.4\nCross-check Using Other Means . . . . . . . . .\n67\n4.5\nForce Error Conditions\n. . . . . . . . . . . . . .\n68\n4.6\nPerformance Characteristics . . . . . . . . . . .\n69\n5\nCORRECT Boundary Conditions\n71\n5.1\nConformance . . . . . . . . . . . . . . . . . . . .\n72\n5.2\nOrdering . . . . . . . . . . . . . . . . . . . . . . .\n74\n5.3\nRange\n. . . . . . . . . . . . . . . . . . . . . . . .\n75\n5.4\nReference\n. . . . . . . . . . . . . . . . . . . . . .\n79\n5.5\nExistence\n. . . . . . . . . . . . . . . . . . . . . .\n81\n5.6\nCardinality\n. . . . . . . . . . . . . . . . . . . . .\n82\n5.7\nTime . . . . . . . . . . . . . . . . . . . . . . . . .\n84\n5.8\nTry It Yourself . . . . . . . . . . . . . . . . . . . .\n86\n6\nUsing Mock Objects\n90\n6.1\nStubs . . . . . . . . . . . . . . . . . . . . . . . . .\n92\n6.2\nFakes . . . . . . . . . . . . . . . . . . . . . . . . .\n94\n6.3\nMock Objects . . . . . . . . . . . . . . . . . . . . 100\n6.4\nWhen Not To Mock . . . . . . . . . . . . . . . . . 112\n7\nProperties of Good Tests\n117\n7.1\nAutomatic . . . . . . . . . . . . . . . . . . . . . . 118\n7.2\nThorough\n. . . . . . . . . . . . . . . . . . . . . . 119\n7.3\nRepeatable\n. . . . . . . . . . . . . . . . . . . . . 122\n7.4\nIndependent . . . . . . . . . . . . . . . . . . . . . 122\n7.5\nProfessional . . . . . . . . . . . . . . . . . . . . . 123\n7.6\nTesting the Tests . . . . . . . . . . . . . . . . . . 125\n8\nTesting on a Project\n129\n8.1\nWhere to Put Test Code . . . . . . . . . . . . . . 129\n8.2\nWhere to Put NUnit\n. . . . . . . . . . . . . . . . 132\n8.3\nTest Courtesy . . . . . . . . . . . . . . . . . . . . 132\n8.4\nTest Frequency . . . . . . . . . . . . . . . . . . . 135\n8.5\nTests and Legacy Code\n. . . . . . . . . . . . . . 136\n8.6\nTests and Code Reviews . . . . . . . . . . . . . . 139\n\n\nCONTENTS\nvii\n9\nDesign Issues\n143\n9.1\nDesigning for Testability . . . . . . . . . . . . . . 143\n9.2\nRefactoring for Testing . . . . . . . . . . . . . . . 146\n9.3\nTesting the Class Invariant . . . . . . . . . . . . 159\n9.4\nTest-Driven Design . . . . . . . . . . . . . . . . . 161\n9.5\nTesting Invalid Parameters . . . . . . . . . . . . 163\n10 GUI Testing\n165\n10.1 Unit testing WinForms\n. . . . . . . . . . . . . . 165\n10.2 Unit testing beyond Windows Forms\n. . . . . . 169\n10.3 Web UIs . . . . . . . . . . . . . . . . . . . . . . . 171\n10.4 Command Line UIs . . . . . . . . . . . . . . . . . 175\n10.5 GUI Testing Gotchas . . . . . . . . . . . . . . . . 177\nA\nExtending NUnit\n180\nA.1\nWriting NUnit Extensions . . . . . . . . . . . . . 180\nA.2\nUsing NUnit Core Addins . . . . . . . . . . . . . 182\nB\nGotchas\n183\nB.1\nAs Long As The Code Works\n. . . . . . . . . . . 183\nB.2\n“Smoke” Tests\n. . . . . . . . . . . . . . . . . . . 183\nB.3\n“Works On My Machine” . . . . . . . . . . . . . . 184\nB.4\nFloating-Point Problems . . . . . . . . . . . . . . 184\nB.5\nTests Take Too Long . . . . . . . . . . . . . . . . 185\nB.6\nTests Keep Breaking . . . . . . . . . . . . . . . . 186\nB.7\nTests Fail on Some Machines . . . . . . . . . . . 186\nB.8\nTests Pass in One Test Runner, Not the Other . 187\nB.9\nThread state issues\n. . . . . . . . . . . . . . . . 187\nB.10 C# 2.0-speciﬁc Issues . . . . . . . . . . . . . . . 188\nC\nResources\n190\nC.1\nOn The Web . . . . . . . . . . . . . . . . . . . . . 190\nC.2\nBibliography\n. . . . . . . . . . . . . . . . . . . . 192\nD\nSummary: Pragmatic Unit Testing\n194\nE\nAnswers to Exercises\n195\n\n\nBETA BOOK\nviii\nBeta\nBook\nAgile publishing for agile developers\nThe book you’re reading is still under development. As part of\nour industry-leading Beta Book program, we’re releasing this\ncopy well before we normally would. That way you’ll be able\nto get this content a couple of months before it’s available in\nﬁnished form, and we’ll get feedback to make the book even\nbetter. The idea is that everyone wins!\nBe warned. The book has not had a full technical edit, so it\nwill contain errors. It has not been copyedited, so it will be\nfull of typos. And there’s been no effort spent doing layout, so\nyou’ll ﬁnd bad page breaks, over-long lines (with black boxes\nat the end of line), incorrect hyphenations, and all the other\nugly things that you wouldn’t expect to see in a ﬁnished book.\nWe can’t be held liable if you use this book to try to create a\nspiffy application and you somehow end up with a strangely\nshaped farm implement instead.\nDespite all this, we think\nyou’ll enjoy it!\nThroughout this process you’ll be able to download updated\nPDFs from http://books.pragprog.com/titles/utc2/reorder.\nWhen the book is ﬁnally ready, you’ll get the ﬁnal version (and\nsubsequent updates) from the same address. In the mean-\ntime, we’d appreciate you sending us your feedback on this\nbook at http://books.pragprog.com/titles/utc2/errata.\nThank you for taking part in our Beta Book program.\nAndy Hunt\n\n\nAbout the Starter Kit\nOur ﬁrst book, The Pragmatic Programmer: From Journeyman\nto Master, is a widely-acclaimed overview of practical topics\nin modern software development. Since it was ﬁrst published\nin 1999, many people have asked us about follow-on books,\nor sequels. Towards that end, we started our own publishing\ncompany, the Pragmatic Bookshelf. By now we’ve got dozens\nof titles in print and in development, major awards, and many\nﬁve star reviews.\nBut the very books we published are still some of the most im-\nportant ones. Before embarking on any sequels to The Prag-\nmatic Programmer, we thought we’d go back and offer a pre-\nquel of sorts.\nOver the years, we’ve found that many of our pragmatic read-\ners who are just starting out need a helping hand to get their\ndevelopment infrastructure in place, so they can begin form-\ning good habits early. Many of our more advanced pragmatic\nreaders understand these topics thoroughly, but need help\nconvincing and educating the rest of their team or organiza-\ntion. We think we’ve got something that can help.\nThe Pragmatic Starter Kit is a three-volume set that covers\nthe essential basics for modern software development. These\nvolumes include the practices, tools, and philosophies that\nyou need to get a team up and running and super-productive.\nArmed with this knowledge, you and your team can adopt\ngood habits easily and enjoy the safety and comfort of a well-\nestablished “safety net” for your project.\nVolume I, Pragmatic Version Control, describes how to use ver-\nsion control as the cornerstone of a project. A project with-\n\n\nABOUT THE STARTER KIT\nx\nout version control is like a word processor without an UNDO\nbutton: the more text you enter, the more expensive a mis-\ntake will be. Pragmatic Version Control shows you how to use\nversion control systems effectively, with all the beneﬁts and\nsafety but without crippling bureaucracy or lengthy, tedious\nprocedures.\nThis volume, Pragmatic Unit Testing, is the second volume in\nthe series. Unit testing is an essential technique as it provides\nreal-world, real-time feedback for developers as we write code.\nMany developers misunderstand unit testing, and don’t real-\nize that it makes our jobs as developers easier. This volume\nis available in two different language versions: in Java with\nJUnit, and in C# with NUnit.\nVolume III, Pragmatic Automation, covers the essential prac-\ntices and technologies needed to automate your code’s build,\ntest, and release procedures. Few projects suffer from having\ntoo much time on their hands, so Pragmatic Automation will\nshow you how to get the computer to do more of the mun-\ndane tasks by itself, freeing you to concentrate on the more\ninteresting—and difﬁcult—challenges.\nThese books are created in the same approachable style as\nour ﬁrst book, and address speciﬁc needs and problems that\nyou face in the trenches every day. But these aren’t dummy-\nlevel books that only give you part of the picture; they’ll give\nyou enough understanding that you’ll be able to invent your\nown solutions to the novel problems you face that we haven’t\naddressed speciﬁcally.\nFor up-to-date information on these and other books, as well\nas related pragmatic resources for developers and managers,\nplease visit us on the web at:\nhttp://www.pragmaticprogrammer.com\nThanks, and remember to make it fun!\n\n\nPreface\nWelcome to the world of developer-centric unit testing!\nWe\nhope you ﬁnd this book to be a valuable resource for yourself\nand your project team. You can tell us how it helped you—\nor let us know how we can improve—by visiting the Pragmatic\nUnit Testing page on our web site1 and clicking on “Feedback.”\nFeedback like that is what makes books great. It’s also what\nmakes people and projects great. Pragmatic programming is\nall about using real-world feedback to ﬁne tune and adjust\nyour approach.\nWhich brings us to unit testing. As we’ll see, unit testing is\nimportant to you as a programmer because it provides the\nfeedback you need. Without unit testing, you may as well be\nwriting programs on a yellow legal pad and hoping for the best\nwhen they’re run.\nThat’s not very pragmatic.\nThis book can help. It is aimed primarily at the C# program-\nmer who has some experience writing and designing code, but\nwho does not have much experience with unit testing.\nBut while the examples are in C#, using the NUnit framework,\nthe concepts remain the same whether you are writing in C++,\nFortran, Ruby, Smalltalk, or VisualBasic. Testing frameworks\nsimilar to NUnit exist for over 60 different languages; these\nvarious frameworks can be downloaded for free.2\n1http://www.pragmaticprogrammer.com/titles/utc2\n2http://www.xprogramming.com/software.htm\n",
      "page_number": 2
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 11-18)",
      "start_page": 11,
      "end_page": 18,
      "detection_method": "topic_boundary",
      "content": "PREFACE\nxii\nFor the more advanced programmer, who has done unit test-\ning before, we hope there will be a couple of nice surprises for\nyou here. Skim over the basics of using NUnit and concen-\ntrate on how to think about tests, how testing affects design,\nand how to handle certain team-wide issues you may be hav-\ning.\nAnd remember that this book is just the beginning. It may be\nyour ﬁrst book on unit testing, but we hope it won’t be your\nlast.\nWhere To Find The Code\nThroughout the book you’ll ﬁnd examples of C# code; some\nof these are complete programs while others are fragments of\nprograms. If you want to run any of the example code or look\nat the complete source (instead of just the printed fragment),\nlook in the margin: the ﬁlename of each code fragment in the\nbook is printed in the margin next to the code fragment itself.\nSome code fragments evolve with the discussion, so you may\nﬁnd the same source code ﬁle (with the same name) in the\nmain directory as well as in subdirectories that contain later\nversions (rev1, rev2, and so on).\nAll of the code in this book is available via the Pragmatic Unit\nTesting page on our web site.\nTypographic Conventions\nitalic font\nIndicates terms that are being deﬁned, or\nborrowed from another language.\ncomputer font\nIndicates method names, ﬁle and class\nnames, and various other literal strings.\nx xx xx xx;\nIndicates unimportant portions of source\ncode that are deliberately omitted.\nThe “curves ahead” sign warns that this\nmaterial is more advanced, and can safely\nbe skipped on your ﬁrst reading.\n\n\nPREFACE\nxiii\n“Joe the Developer,” our cartoon friend,\nasks a related question that you may ﬁnd\nuseful.\nSTOP\nA break in the text where you should stop\nand think about what’s been asked, or try\nan experiment live on a computer before\ncontinuing.\nLanguage-speciﬁc Versions\nAs of this printing, Pragmatic Unit Testing is available in two\nprogramming language-speciﬁc versions:\n• in Java with JUnit\n• in C# with NUnit\nAcknowledgments from the First Edition\nWe’d especially like to thank the following Practitioners for\ntheir valuable input, suggestions, and stories: Mitch Amiano,\nNascif Abousalh-Neto, Andrew C. Oliver, Jared Richardson,\nand Bobby Woolf.\nThanks also to our reviewers who took the time and energy\nto point out our errors, omissions, and occasionally-twisted\nwriting:\nGareth Hayter, Dominique Plante, Charlie Poole,\nMaik Schmidt, and David Starnes.\n\n\nPREFACE\nxiv\nMatt’s Acknowledgments\nI would like to ﬁrst thank my amazing husband, Geoff, for\nall his patience while writing the book and contributing to\nvarious open source projects to ﬁx issues discovered along\nthe way. Second, gratitude to all the people who have been\ngreat pairs to program with and illuminated so much: Bryan\nSiepert, Strick, Mike Muldoon, Edward Hieatt, Aaron Peck-\nham, Luis Miras, Rob Myers, Li Moore, Marcel Prasetya, An-\nthony Lineberry, Mike Seery, Todd Nagengast, Richard Blay-\nlock, Andre Fonseca, Keith Dreibelbis, Katya Androchina, and\nCullen Bryan. Last, I’d like to thank my mom for pair pro-\ngramming with me as a boy, helping to typing in very long\nBASIC programs from various magazines of the day.\nAcknowledgments from the Second Edition\nThanks to all of you for your hard work and support. A special\nthank you goes to Matt Hargett for his contributions to this\nedition.\nThanks to our early reviewers, Cory Foy, Wes Reisz, and\nFrédérick Ros.\nAnd since this is a beta book, watch for more acknowledge-\nments in this space.\nAndy Hunt\nJuly, 2007\npragprog@pragmaticprogrammer.com\n\n\nChapter 1\nIntroduction\nThere are lots of different kinds of testing that can and should\nbe performed on a software project. Some of this testing re-\nquires extensive involvement from the end users; other forms\nmay require teams of dedicated Quality Assurance personnel\nor other expensive resources.\nBut that’s not what we’re going to talk about here.\nInstead, we’re talking about unit testing: an essential, if often\nmisunderstood, part of project and personal success.\nUnit\ntesting is a relatively inexpensive, easy way to produce better\ncode, faster.\n”Unit testing” is the practice of using small bits of code to\nexercise the code you’ve written. In this book, we’ll be using\nthe NUnit testing framework to help manage and run these\nlittle bits of code.\nMany organizations have grand intentions when it comes to\ntesting, but tend to test only toward the end of a project, when\nthe mounting schedule pressures cause testing to be curtailed\nor eliminated entirely.\nMany programmers feel that testing is just a nuisance: an\nunwanted bother that merely distracts from the real business\nat hand—cutting code.\nEveryone agrees that more testing is needed, in the same way\nthat everyone agrees you should eat your broccoli, stop smok-\n\n\nCODING WITH CONFIDENCE\n2\ning, get plenty of rest, and exercise regularly. That doesn’t\nmean that any of us actually do these things, however.\nBut unit testing can be much more than these—while you\nmight consider it to be in the broccoli family, we’re here to tell\nyou that it’s more like an awesome sauce that makes every-\nthing taste better. Unit testing isn’t designed to achieve some\ncorporate quality initiative; it’s not a tool for the end-users,\nor managers, or team leads. Unit testing is done by program-\nmers, for programmers. It’s here for our beneﬁt alone, to make\nour lives easier.\nPut simply, unit testing alone can mean the difference be-\ntween your success and your failure. Consider the following\nshort story.\n1.1\nCoding With Conﬁdence\nOnce upon a time—maybe it was last Tuesday—there were\ntwo developers, Pat and Dale.\nThey were both up against\nthe same deadline, which was rapidly approaching. Pat was\npumping out code pretty fast; developing class after class and\nmethod after method, stopping every so often to make sure\nthat the code would compile.\nPat kept up this pace right until the night before the deadline,\nwhen it would be time to demonstrate all this code. Pat ran\nthe top-level program, but didn’t get any output at all. Noth-\ning. Time to step through using the debugger. Hmm. That\ncan’t be right, thought Pat. There’s no way that this variable\ncould be zero by now. So Pat stepped back through the code,\ntrying to track down the history of this elusive problem.\nIt was getting late now. That bug was found and ﬁxed, but Pat\nfound several more during the process. And still, there was\nno output at all. Pat couldn’t understand why. It just didn’t\nmake any sense.\nDale, meanwhile, wasn’t churning out code nearly as fast.\nDale would write a new routine and a short test to go along\nwith it. Nothing fancy, just a simple test to see if the routine\njust written actually did what it was supposed to do. It took a\nlittle longer to think of the test, and write it, but Dale refused\n\n\nWHAT IS UNIT TESTING?\n3\nto move on until the new routine could prove itself. Only then\nwould Dale move up and write the next routine that called it,\nand so on.\nDale rarely used the debugger, if ever, and was somewhat puz-\nzled at the picture of Pat, head in hands, muttering various\nevil-sounding curses at the computer with wide, bloodshot\neyes staring at all those debugger windows.\nThe deadline came and went, and Pat didn’t make it. Dale’s\ncode was integrated1 and ran almost perfectly.\nOne little\nglitch came up, but it was pretty easy to see where the prob-\nlem was. Dale ﬁxed it in just a few minutes.\nNow comes the punch line: Dale and Pat are the same age,\nand have roughly the same coding skills and mental prowess.\nThe only difference is that Dale believes very strongly in unit\ntesting, and tests every newly-crafted method before relying\non it or using it from other code.\nPat does not. Pat “knows” that the code should work as writ-\nten, and doesn’t bother to try it until most of the code has\nbeen completed. But by then it’s too late, and it becomes very\nhard to try to locate the source of bugs, or even determine\nwhat’s working and what’s not.\n1.2\nWhat is Unit Testing?\nA unit test is a piece of code written by a developer that ex-\nercises a very small, speciﬁc area of functionality in the code\nbeing tested.\nUsually a unit test exercises some particular\nmethod in a particular context. For example, you might add\na large value to a sorted list, then conﬁrm that this value ap-\npears at the end of the list. Or you might delete a pattern of\ncharacters from a string and then conﬁrm that they are gone.\nUnit tests are performed to prove that a piece of code does\nwhat the developer thinks it should do.\nThe question remains open as to whether that’s the right thing\nto do according to the customer or end-user: that’s what ac-\nceptance testing is for. We’re not really concerned with formal\n1Because Dale had been integrating all along via the unit tests.\n\n\nWHY SHOULD I BOTHER WITH UNIT TESTING?\n4\nvalidation and veriﬁcation or correctness just yet. We’re re-\nally not even interested in performance testing at this point.\nAll we want to do is prove that code does what we intended,2\nand so we want to test very small, very isolated pieces of func-\ntionality. By building up conﬁdence that the individual pieces\nwork as expected, we can then proceed to assemble and test\nworking systems.\nAfter all, if we aren’t sure the code is doing what we think,\nthen any other forms of testing may just be a waste of time.\nYou still need other forms of testing, and perhaps much more\nformal testing depending on your environment. But testing,\nas with charity, begins at home.\n1.3\nWhy Should I Bother with Unit Testing?\nUnit testing will make your life easier.3\nPlease say that with us, out loud. Unit testing will make your\nlife easier. That’s why we’re here.\nIt will make your designs better and drastically reduce the\namount of time you spend debugging. We like to write code,\nand time wasted on debugging is time spent not writing code.\nIn our tale above, Pat got into trouble by assuming that lower-\nlevel code worked, and then went on to use that in higher-level\ncode, which was in turn used by more code, and so on. With-\nout legitimate conﬁdence in any of the code, Pat was building\na “house of cards” of assumptions—one little nudge at the\nbottom and the whole thing falls down.\nWhen basic, low-level code isn’t reliable, the requisite ﬁxes\ndon’t stay at the low level. You ﬁx the low level problem, but\nthat impacts code at higher levels, which then need ﬁxing,\nand so on. Fixes begin to ripple throughout the code, getting\nlarger and more complicated as they go. The house of cards\nfalls down, taking the project with it.\n2You also need to ensure that you’re intending the right thing, see [SH06].\n3It could also make you wildest dreams come true, but only if you Vote\nfor Pedro.\n\n\nWHAT DO I WANT TO ACCOMPLISH?\n5\nPat keeps saying things like “that’s impossible” or “I don’t un-\nderstand how that could happen.” If you ﬁnd yourself think-\ning these sorts of thoughts, then that’s usually a good indica-\ntion that you don’t have enough conﬁdence in your code—you\ndon’t know for sure what’s working and what’s not.\nIn order to gain the kind of code conﬁdence that Dale has,\nyou’ll need to ask the code itself what it is doing, and check\nthat the result is what you expect it to be. Dale’s conﬁdence\ndoesn’t come from the fact he knows the code forward and\nbackward at all times; it comes from the fact that he has a\nsafety net of tests that verify things work the way he thought\nthey should.\nThat simple idea describes the heart of unit testing: the single\nmost effective technique to better coding.\n1.4\nWhat Do I Want to Accomplish?\nIt’s easy to get carried away with unit testing because the con-\nﬁdence it instills makes coding so much fun, but at the end\nof the day we still need to produce production code for cus-\ntomers and end-users, so let’s be clear about our goals for\nunit testing. First and foremost, you want to do this to make\nyour life—and the lives of your teammates—easier.\nAnd of course, executable documentation has the beneﬁt of\nbeing self-veriﬁably correct without much effort beyond writ-\ning it the ﬁrst time. Unlike written documentation, it won’t\ndrift away from the code (unless, of course, you stop running\nthe tests or let them continuously fail).\nDoes It Do What I Want?\nFundamentally, you want to answer the question: “Is the code\nfulﬁlling my intent?” The code might well be doing the wrong\nthing as far as the requirements are concerned, but that’s a\nseparate exercise. You want the code to prove to you that it’s\ndoing exactly what you think it should.\n",
      "page_number": 11
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 19-26)",
      "start_page": 19,
      "end_page": 26,
      "detection_method": "topic_boundary",
      "content": "WHAT DO I WANT TO ACCOMPLISH?\n6\nDoes It Do What I Want All of the Time?\nMany developers who claim they do testing only ever write one\ntest. That’s the test that goes right down the middle, taking\nthe one, well-known, “happy path” through the code where\neverything goes perfectly.\nBut of course, life is rarely that cooperative, and things don’t\nalways go perfectly:\nexceptions get thrown, disks get full,\nnetwork lines drop, buffers overﬂow, and—heaven forbid—we\nwrite bugs. That’s the “engineering” part of software develop-\nment. Civil engineers must consider the load on bridges, the\neffects of high winds, of earthquakes, ﬂoods, and so on. Elec-\ntrical engineers plan on frequency drift, voltage spikes, noise,\neven problems with parts availability.\nYou don’t test a bridge by driving a single car over it right\ndown the middle lane on a clear, calm day. That’s not sufﬁ-\ncient, and the fact you succeeded is just a coincidence.4 Be-\nyond ensuring that the code does what you want, you need\nto ensure that the code does what you want all of the time,\neven when the winds are high, the parameters are suspect,\nthe disk is full, and the network is sluggish.\nCan I Depend On It?\nCode that you can’t depend on is not particularly useful.\nWorse, code that you think you can depend on (but turns out\nto have bugs) can cost you a lot of time to track down and\ndebug. There are very few projects that can afford to waste\ntime, so you want to avoid that “one step forward two steps\nback” approach at all costs, and stick to moving forward.\nNo one writes perfect code, and that’s okay—as long as you\nknow where the problems exist. Many of the most spectacu-\nlar software failures that strand broken spacecraft on distant\nplanets or blow them up in mid-ﬂight could have been avoided\nsimply by knowing the limitations of the software.\nFor in-\nstance, the Arianne 5 rocket software re-used a library from\nan older rocket that simply couldn’t handle the larger num-\n4See Programming by Coincidence in [HT00].\n\n\nHOW DO I DO UNIT TESTING?\n7\nbers of the higher-ﬂying new rocket.5 It exploded 40 seconds\ninto ﬂight, taking $500 million dollars with it into oblivion.\nWe want to be able to depend on the code we write, and know\nfor certain both its strengths and its limitations.\nFor example, suppose you’ve written a routine to reverse a\nlist of numbers. As part of testing, you give it an empty list—\nand the code blows up. The requirements don’t say you have\nto accept an empty list, so maybe you simply document that\nfact in the comment block for the method and throw an ex-\nception if the routine is called with an empty list. Now you\nknow the limitations of code right away, instead of ﬁnding out\nthe hard way (often somewhere inconvenient, such as in the\nupper atmosphere).\nDoes It Document My Intent?\nOne nice side-effect of unit testing is that it helps you commu-\nnicate the code’s intended use. In effect, a unit test behaves as\nexecutable documentation, showing how you expect the code\nto behave under the various conditions you’ve considered.\nCurrent and future team members can look at the tests for\nexamples of how to use your code. If someone comes across\na test case that you haven’t considered, they’ll be alerted\nquickly to that fact.\nAnd of course, executable documentation has the beneﬁt of\nbeing correct.\nUnlike written documentation, it won’t drift\naway from the code (unless, of course, you stop running the\ntests and making sure they pass).\n1.5\nHow Do I Do Unit Testing?\nUnit testing is basically an easy practice to adopt, but there\nare some guidelines and common steps that you can follow to\nmake it easier and more effective.\n5For aviation geeks: The numeric overﬂow was due to a much larger “hor-\nizontal bias” due to a different trajectory that increased the horizontal velocity\nof the rocket.\n\n\nEXCUSES FOR NOT TESTING\n8\nThe ﬁrst step is to decide how to test the method in question—\nbefore writing the code itself. With at least a rough idea of\nhow to proceed, you can then write the test code itself, either\nbefore or concurrently with the implementation code. If you’re\nwriting unit tests for existing code, that’s ﬁne too, but you may\nﬁnd you need to refactor it more often than with new code in\norder to make things testable.\nNext, you run the test itself, and probably all the other tests\nin that part of the system, or even the entire system’s tests if\nthat can be done relatively quickly. It’s important that all the\ntests pass, not just the new one. This kind of basic regression\ntesting helps you avoid any collateral damage as well as any\nimmediate, local bugs.\nEvery test needs to determine whether it passed or not—it\ndoesn’t count if you or some other hapless human has to read\nthrough a pile of output and decide whether the code worked\nor not. If you can eyeball it, you can use a code assertion to\ntest it.\nYou want to get into the habit of looking at the test results\nand telling at a glance whether it all worked. We’ll talk more\nabout that when we go over the speciﬁcs of using unit testing\nframeworks.\n1.6\nExcuses For Not Testing\nDespite our rational and impassioned pleas, some developers\nwill still nod their heads and agree with the need for unit test-\ning, but will steadfastly assure us that they couldn’t possibly\ndo this sort of testing for one of a variety of reasons. Here are\nsome of the most popular excuses we’ve heard, along with our\nrebuttals.\nIt takes too much time to write the tests\nThis is the num-\nber one complaint voiced by most newcomers to unit testing.\nIt’s untrue, of course, but to see why we need to take a closer\nlook at where you spend your time when developing code.\nMany people view testing of any sort as something that hap-\npens toward the end of a project. And yes, if you wait to begin\n\n\nEXCUSES FOR NOT TESTING\n9\nJoe Asks. . .\nWhat’s collateral damage?\nCollateral damage is what happens when a new fea-\nture or a bug ﬁx in one part of the system causes a\nbug (damage) to another, possibly unrelated part of\nthe system. It’s an insidious problem that, if allowed to\ncontinue, can quickly render the entire system broken\nbeyond anyone’s ability to easily ﬁx.\nWe sometime call this the “Whac-a-Mole” effect. In\nthe carnival game of Whac-a-Mole, the player must\nstrike the mechanical mole heads that pop up on the\nplaying ﬁeld. But they don’t keep their heads up for\nlong; as soon as you move to strike one mole, it re-\ntreats and another mole pops up on the opposite side\nof the ﬁeld. The moles pop up and down fast enough\nthat it can be very frustrating to try to connect with\none and score. As a result, players generally ﬂail help-\nlessly at the ﬁeld as the moles continue to pop up\nwhere you least expect them.\nWidespread collateral damage to a code base can\nhave a similar effect. The root of the problem is usu-\nally some kind of inappropriate coupling, coming in\nforms such as global state via static variables or false\nsingletons, circular object or class dependencies, etc.\nEliminate them early on to avoid implicit dependen-\ncies on this abhorrent practice in other parts of the\ncode.\n\n\nEXCUSES FOR NOT TESTING\n10\nunit testing until then it will deﬁnitely longer than it would\notherwise. In fact, you may not ﬁnish the job until the heat\ndeath of the universe itself.\nAt least it will feel that way: it’s like trying to clear a cou-\nple of acres of land with a lawn mower. If you start early on\nwhen there’s just a ﬁeld of grasses, the job is easy. If you wait\nuntil later, when the ﬁeld contains thick, gnarled trees and\ndense, tangled undergrowth, then the job becomes impossi-\nbly difﬁcult by hand—you need bulldozers and lots of heavy\nequipment.\nInstead of waiting until the end, it’s far cheaper in the long\nrun to adopt the “pay-as-you-go” model. By writing individual\ntests with the code itself as you go along, there’s no crunch\nat the end, and you experience fewer overall bugs as you are\ngenerally always working with tested code. By taking a little\nextra time all the time, you minimize the risk of needing a\nhuge amount of time at the end.\nYou see, the trade-off is not “test now” versus “test later.” It’s\nlinear work now versus exponential work and complexity try-\ning to ﬁx and rework at the end: not only is the job larger\nand more complex, but now you have to re-learn the code you\nwrote some weeks or months ago.\nAll that extra work kills\nyour productivity, as shown in Figure 1.1 on the following\npage. These productivity losses can easily doom a project or\ndeveloper to being perpetually 90% done.\nNotice that testing isn’t free.\nIn the pay-as-you-go model,\nthe effort is not zero; it will cost you some amount of effort\n(and time and money). But look at the frightening direction\nthe right-hand curve takes over time—straight down.\nYour\nproductivity might even become negative. These productivity\nlosses can easily doom a project.\nSo if you think you don’t have time to write tests in addition to\nthe code you’re already writing, consider the following ques-\ntions:\n1. How much time do you spend debugging code that you\nor others have written?\n2. How much time do you spend reworking code that you\n\n\nEXCUSES FOR NOT TESTING\n11\nProductivity ¡\nProductivity ¡\nTime ¡\nTime ¡\nPAY-AS-YOU-GO\nSINGLE TEST PHASE\nFigure 1.1: Comparison of Paying-as-you-go vs. Having a Sin-\ngle Testing Phase\nthought was working, but turned out to have major, crip-\npling bugs?\n3. How much time do you spend isolating a reported bug to\nits source?\nFor most people who work without unit tests, these numbers\nadd up fast, and will continue to add up even faster over the\nlife of the project.\nProper unit testing can dramatically re-\nduces these times, which frees up enough time so that you’ll\nhave the opportunity to write all of the unit tests you want—\nand maybe even some free time to spare.\nIt takes too long to run the tests\nIt shouldn’t. Most unit\ntests should execute in the blink of an eye, so you should be\nable to run hundreds, even thousands of them in a matter\nof a few seconds. But sometimes that won’t be possible, and\nyou may end up with certain tests that simply take too long\nto conveniently run all of the time.\nIn that case, you’ll want to separate out the longer-running\ntests from the short ones. NUnit has functionality that han-\ndles this nicely, which we’ll talk about more later. Only run\nthe long tests in the automated build, or manually at the be-\nginning of the day while catching up on email, and run the\n\n\nEXCUSES FOR NOT TESTING\n12\nshorter tests constantly at every signiﬁcant change or before\nevery commit to your source repository.\nMy legacy code is impossible to test\nMany people offer\nthe excuse that they can’t possibly do unit testing because\nthe existing, legacy code base is such a tangled mess that it’s\nimpossible to get into the middle of it and create an individual\ntest. To test even a small part of the system might mean you\nhave to drag the entire system along for the ride, and making\nany changes is a fragile, risky business.6\nThe problem isn’t with unit testing, of course, the problem is\nwith the poorly written legacy code. You’ll have to refactor—\nincrementally re-design and adapt—the legacy code to untan-\ngle the mess. Note that this doesn’t really qualify as making\nchanges just for the sake of testing. The real power of unit\ntests is the design feedback that, when acted upon appropri-\nately, will lead to better object-oriented designs.\nCoding in a culture of fear because you are paralyzed by\nlegacy code is not productive; it’s bad for the project, bad for\nthe programmers, and ultimately bad for business. Introduc-\ning unit testing helps break that paralysis.\nIt’s not my job to test my code\nNow here’s an interesting\nexcuse. Pray tell, what is your job, exactly? Presumably your\njob, at least in part, is to create working, maintainable code.\nIf you are throwing code over the wall to some testing group\nwithout any assurance that it’s working, then you’re not do-\ning your job. It’s not polite to expect others to clean up our\nown messes, and in extreme cases submitting large volumes\nof buggy code can become a “career limiting” move.\nOn the other hand, if the testers or QA group ﬁnd it very\ndifﬁcult to ﬁnd fault with your code, your reputation will grow\nrapidly—along with your job security!\nI don’t really know how the code is supposed to behave so\nI can’t test it\nIf you truly don’t know how the code is sup-\n6See [Fea04] for details on working effectively with legacy code.\n\n\nEXCUSES FOR NOT TESTING\n13\nposed to behave, then maybe this isn’t the time to be writing\nit.7 Maybe a prototype would be more appropriate as a ﬁrst\nstep to help clarify the requirements.\nIf you don’t know what the code is supposed to do, then how\nwill you know that it does it?\nBut it compiles!\nOkay, no one really comes out with this as\nan excuse, at least not out loud. But it’s easy to get lulled\ninto thinking that a successful compile is somehow a mark of\napproval, that you’ve passed some threshold of goodness.\nBut the compiler’s blessing is a pretty shallow compliment. It\ncan verify that your syntax is correct, but it can’t ﬁgure out\nwhat your code should do. For example, the C# compiler can\neasily determine that this line is wrong:\nstatuc void Main() {\nIt’s just a simple typo, and should be static, not statuc.\nThat’s the easy part.\nBut now suppose you’ve written the\nfollowing:\npublic void Addit(Object anObject) {\nList myList = new List();\nmyList.Add(anObject);\nmyList.Add(anObject);\n// more code...\n}\nMain.cs\nDid you really mean to add the same object to the same list\ntwice? Maybe, maybe not. The compiler can’t tell the differ-\nence, only you know what you’ve intended the code to do.8\nI’m being paid to write code, not to write tests\nBy that\nsame logic, you’re not being paid to spend all day in the de-\nbugger, either. Presumably you are being paid to write work-\ning code, and unit tests are merely a tool toward that end, in\nthe same fashion as an editor, an IDE, or the compiler.\n7See [HT00] or [SH06] for more on learning requirements.\n8Automated testing tools that generate their own tests based on your ex-\nisting code fall into this same trap—they can only use what you wrote, not\nwhat you meant.\n",
      "page_number": 19
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 27-34)",
      "start_page": 27,
      "end_page": 34,
      "detection_method": "topic_boundary",
      "content": "EXCUSES FOR NOT TESTING\n14\nI feel guilty about putting testers and QA staff out of work\nNot to worry, you won’t. Remember we’re only talking about\nunit testing, here. It’s the barest-bones, lowest-level testing\nthat’s designed for us, the programmers.\nThere’s plenty of\nother work to be done in the way of functional testing, accep-\ntance testing, performance and environmental testing, valida-\ntion and veriﬁcation, formal analysis, and so on.\nMy company won’t let me run unit tests on the live sys-\ntem\nWhoa! We’re talking about developer unit-testing here.\nWhile you might be able to run those same tests in other con-\ntexts (on the live, production system, for instance) they are no\nlonger unit tests. Run your unit tests on your machine, using\nyour own database, or using a mock object (see Chapter 6).\nIf the QA department or other testing staff want to run these\ntests in a production or staging environment, you might be\nable to coordinate the technical details with them so they can,\nbut realize that they are no longer unit tests in that context.\nYeah, we unit test already\nUnit testing is one of the prac-\ntices that is typically marked by effusive and consistent en-\nthusiasm. If the team isn’t enthusiastic, maybe they aren’t\ndoing it right. See if you recognize any of the warning signs\nbelow.\n• Unit tests are in fact integration tests, requiring lots of\nsetup and test code, taking a long time to run, and ac-\ncessing resources such as databases and services on the\nnetwork.\n• Unit tests are scarce and test only one path, don’t test\nfor exceptional conditions (no disk space, etc.), or don’t\nreally express what the code is supposed to do.\n• Unit tests are not maintained:\ntests are ignored (or\ndeleted) forever if they start failing, or no new unit tests\nare added, even when bugs are encountered that illus-\ntrate holes in the coverage of the unit tests.\nIf you ﬁnd any of these symptoms, then your team is not unit\ntesting effectively or optimally. Have everyone read up on unit\n\n\nROADMAP\n15\ntesting again, go to some training, or try pair programming to\nget a fresh perspective.\n1.7\nRoadmap\nChapter 2, Your First Unit Tests, contains an overview of test\nwriting. From there we’ll take a look at the speciﬁcs of Writing\nTests in NUnit in Chapter 3. We’ll then spend a few chapters\non how you come up with what things need testing, and how\nto test them.\nNext we’ll look at the important properties of good tests in\nChapter 7, followed by what you need to do to use testing\neffectively in your project in Chapter 8.\nThis chapter also\ndiscusses how to handle existing projects with legacy code.\nWe’ll then talk about how testing can inﬂuence your applica-\ntion’s design (for the better) in Chapter 9, Design Issues. We\nthen wrap up with an overview of GUI testing in 10.\nThe appendices contain additional useful information: a look\nat common unit testing problems, extending NUnit itself, a\nnote on installing NUnit, and a list of resources including the\nbibliography. We ﬁnish off with a summary card containing\nhighlights of the book’s tips and suggestions.\nSo sit back, relax, and welcome to the world of better coding.\n\n\nChapter 2\nYour First Unit Tests\nAs we said in the introduction, a unit test is just a piece of\ncode. It’s a piece of code you write that happens to exercise\nanother piece of code, and determines whether the other piece\nof code is behaving as expected or not.\nHow do you do that, exactly?\nTo check if code is behaving as you expect, you use an as-\nsertion, a simple method call that veriﬁes that something is\ntrue. For instance, the method IsTrue checks that the given\nboolean condition is true, and fails the current test if it is not.\nIt might be implemented like the following.\npublic void IsTrue(bool condition)\n{\nif (!condition)\n{\nthrow new ArgumentException(\"Assertion failed\");\n}\n}\nAssertTrue.cs\nYou could use this assert to check all sorts of things, including\nwhether numbers are equal to each other:\nint a = 2;\nxx xxx xx x xxx x;\nx x x xx xxx xxxx x;\nIsTrue(a == 2);\nxxxx xx xx xxx xx;\nIf for some reason a does not equal 2 when the method IsTrue\nis called, then the program will throw an exception.\n\n\nPLANNING TESTS\n17\nSince we check for equality a lot, it might be easier to have an\nassert just for numbers. To check that two integers are equal,\nfor instance, we could write a method that takes two integer\nparameters:\npublic void AreEqual(int a, int b)\n{\nIsTrue(a == b);\n}\nAssertTrue.cs\nArmed with just these two asserts, we can start writing some\ntests. We’ll look at more asserts and describe the details of\nhow you use asserts in unit test code in the next chapter. But\nﬁrst, let’s consider what tests might be needed before we write\nany code at all.\n2.1\nPlanning Tests\nWe’ll start with a simple example, a single, static method de-\nsigned to ﬁnd the largest number in a list of numbers:\nstatic int Largest(int[] list);\nIn other words, given an array of numbers such as [7, 8,\n9], this method should return 9.\nThat’s a reasonable ﬁrst\ntest. What other tests can you think of, off the top of your\nhead? Take a minute and write down as many tests as you\ncan think of for this simple method before you continue read-\ning.\nSTOP\nThink about this for a moment before reading on. . .\nHow many tests did you come up with?\nIt shouldn’t matter what order the given list is in, so right off\nthe bat you’ve got the following test ideas (which we’ve written\nas “what you pass in” ¡ “what you expect”).\n• [7, 8, 9] ¡ 9\n• [8, 9, 7] ¡ 9\n• [9, 7, 8] ¡ 9\nWhat happens if there are duplicate largest numbers?\n\n\nTESTING A SIMPLE METHOD\n18\n• [7, 9, 8, 9] ¡ 9\nSince these are int types, not objects, you probably don’t care\nwhich 9 is returned, as long as one of them is.\nWhat if there’s only one number?\n• [1] ¡ 1\nAnd what happens with negative numbers:\n• [-9, -8, -7] ¡ -7\nIt might look odd, but indeed -7 is larger than -9. Glad we\nstraightened that out now, rather than in the debugger or in\nproduction code where it might not be so obvious.\nThis isn’t a comprehensive list by any means, but it’s good\nenough to get started with. To help make all this discussion\nmore concrete, we’ll write a “largest” method and test it using\nthese unit tests we just described. Here’s the code for our ﬁrst\nimplementation:\nLine 1\nusing System;\n-\n-\npublic class Cmp\n-\n{\n5\npublic static int Largest(int[] list)\n-\n{\n-\nint index, max=Int32.MaxValue;\n-\nfor (index = 0; index < list.Length-1; index++)\n-\n{\n10\nif (list[index] > max)\n-\n{\n-\nmax = list[index];\n-\n}\n-\n}\n15\nreturn max;\n-\n}\n-\n-\n}\nLargest.cs\nNow that we’ve got some ideas for tests, we’ll look at writing\nthese tests in C#, using the NUnit framework.\n2.2\nTesting a Simple Method\nNormally you want to make the ﬁrst test you write incredi-\nbly simple, because there is much to be tested the ﬁrst time\nbesides the code itself: all of that messy business of class\n\n\nTESTING A SIMPLE METHOD\n19\nnames, assembly references, and making sure it compiles.\nYou want to get all of that taken care of and out of the way with\nthe very ﬁrst, simplest test; you won’t have to worry about it\nanymore after that, and you won’t have to debug complex in-\ntegration issues at the same time you’re debugging a complex\ntest!\nFirst, let’s just test the simple case of passing in a small array\nwith a couple of unique numbers. Here’s the complete source\ncode for the test class.\nWe’ll explain all about test classes\nin the next chapter; for now, just concentrate on the assert\nstatements:\nusing System;\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\n[TestFixture]\npublic class LargestTest\n{\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\n}\n}\nLargestTest.cs\nC# note: the odd-looking syntax to create an anonymous ar-\nray is just for your authors’ beneﬁt, as we are lazy and do not\nlike to type. If you prefer, the test could be written this way\ninstead (although the previous syntax is idiomatic):\n[Test]\npublic void LargestOf3Alt()\n{\nint[] arr = new int[3];\narr[0] = 8;\narr[1] = 9;\narr[2] = 7;\nAssert.That(Cmp.Largest(arr), Is.EqualTo(9));\n}\nLargestTest.cs\nThat’s all it takes, and you have your ﬁrst test.\nWe want to run this simple test and make sure it passes; to\ndo that, we need to take a quick look at running tests using\nNUnit.\n\n\nRUNNING TESTS WITH NUNIT\n20\n2.3\nRunning Tests with NUnit\nNUnit is a freely available,1 open source product that pro-\nvides a testing framework and test runners. It’s available as\nC# source code that you can compile and install yourself, and\nas a ZIP ﬁle of the binaries. The binaries in the ZIP will run\non Microsoft .NET on Windows, and possibly other .NET im-\nplementations on Linux/UNIX or MacOS X. There is also an\nMSI package available, but we recommend just using the ZIP\nﬁle for the least amount of hassle.\nLinux and MacOS users may want to look at Mono, an open-\nsource implementation of the ECMA standards upon which\nC# and .NET are based. While mono ships with its own ver-\nsion of NUnit, we recommend referencing your own copy of\nNUnit, downloaded separately.\nThis will insulate you from\nchanges to the version of NUnit distributed by the mono team.\nWe discuss more of these project-oriented details in Chapter\n8.\nNext, you need to compile the code we’ve shown.\nIf you’re\nusing Visual Studio or SharpDevelop, create a new project for\nthis sample code of type Class Library. Type our “production”\ncode into a ﬁle named Largest.cs, and our new test code into\na ﬁle named LargestTest.cs. If you’d rather not type these\nprograms in from scratch, you’ll be pleased to know that all of\nthe source code for this book is available from our website.2)\nNotice that the test code uses NUnit.Framework; you’ll need\nto add a reference to nunit.framework.dll in order to com-\npile this code. In Visual Studio or SharpDevelop, expand the\nproject’s node in the Solution Explorer, bring up the con-\ntext menu on the References folder, then select “Add Refer-\nence. . . ”. Once there, browse to the nunit.framework.dll\nfrom the NUnit install directory. Press the SELECT button to\nadd the dll to the component list as shown in Figure 2.1. Press\nOK, and now your project will be able to use the functionality\nof the NUnit framework.\nGo ahead and build the project as you normally would (In\n1http://www.nunit.org\n2http://www.pragmaticprogrammer.com/titles/utc2\n\n\nRUNNING TESTS WITH NUNIT\n21\nJoe Asks. . .\nWhat’s the deal with Open Source?\nWhat is open source, exactly? Open source refers to\nsoftware where the source code is made freely avail-\nable. Typically this means that you can obtain the\nproduct for free, and that you are also free to modify\nit, add to it, give it to your friends, and so on.\nIs it safe to use? For the most part, open source prod-\nucts are safer to use than their commercial, closed-\nsource counterparts, because they are open to ex-\namination by thousands of other interested develop-\ners. Malicious programs, spyware, viruses, and other\nsimilar problems are rare to non-existent in the open\nsource community.\nIs it legal? Absolutely. Just as you are free to write a\nsong or a book and give it away (or sell it), you are\nfree to write code and give it away (or sell it). There\nare a variety of open source licenses that clarify the\nfreedoms involved. Before you distribute any software\nthat includes open source components, you should\ncarefully check the particular license agreements in-\nvolved.\nCan I contribute? We certainly hope so! The strength\nof open source comes from people all over the world:\nPeople just like you, who know how to program and\nhave a need for some particular feature. Would you\nlike to add a feature to NUnit?\nYou can!\nYou can\nedit the source code to the library or one of the test\nrunners and change it, and use those changes your-\nself. You can e-mail your changes to the maintainers\nof the product, and they may even incorporate your\nchanges into the next release. You can also submit\nchanges using patch tracker on sourceforge.net;\nthat way, even if your change is not included in an\nofﬁcial release, other users can take advantage of it.\n",
      "page_number": 27
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 35-44)",
      "start_page": 35,
      "end_page": 44,
      "detection_method": "topic_boundary",
      "content": "RUNNING TESTS WITH NUNIT\n22\nFigure 2.1: Adding NUnit Assembly Reference\nVisual Studio, CTRL-SHIFT-B works well). Using Mono, you’d\ninvoke the compiler using something such as:\ngmcs -debug -t:library -r:System -r:lib/nunit.framework.dll \\\n-out:Largest.dll Largest.cs LargestTest.cs\n(The reference to nunit.framework.dll will of course be the\nlocation where you copied the NUnit distribution.)\nNow you’ve got an assembly. But it’s just a library. How can\nwe run it?\nTest Runners to the rescue! A test runner knows to look for\nthe [TestFixture] attribute of a class, and for the [Test]\nmethods within it. The runner will run the tests, accumulate\nsome statistics on which tests passed and failed, and report\nthe results back to you. In this book, we focus on test runners\nthat are easily accessible and freely available.\nThere are four main ways to use a test runner:\n1. NUnit GUI (all platforms)\n2. NUnit command line (all platforms)\n\n\nRUNNING TESTS WITH NUNIT\n23\nFigure 2.2: NUnit Loaded and Ready\n3. TestDriven.NET (Windows-only)\n4. SharpDevelop 2.1 runner (Windows-only)\n5. MonoDevelop 0.13 runner (all platforms)\nNUnit GUI\nThe NUnit GUI can be started a number of ways: if you un-\nzipped the binaries on Windows, you can just point Windows\nExplorer at the directory and double-click on nunit.exe. If\nyou unzipped the binaries on MacOS or Linux, you can run\nNUnit GUI via the mono runtime executable (using mono -\ndebug nunit.exe). If you used the Windows installer, you\ncan use the shortcuts on your Windows desktop and in the\nPrograms menu of the Start Menu to start the NUnit GUI.\nWhen the GUI comes up, you’ve got a couple of choices. You\ncan create a new NUnit project as shown in Figure ?? on\npage ??; navigate to your source directory and create the\nNUnit project ﬁle.\nThen under the “Project” menu, add as-\nsemblies or Visual Studio projects to your NUnit project.3\n3Visual Studio support can be enabled using a preference located under\nTools/Options.\n\n\nRUNNING TESTS WITH NUNIT\n24\nAlternatively, you can just Open an assembly (a .dll or .exe\nﬁle) directly. In Figure 2.2 on the preceding page, we’ve loaded\nour tests directly from the dll. It’s ready to be tested by press-\ning the “Run” button.\nWhen you run a selected test, the GUI will display a large,\ncolored, status bar. If all the tests pass, the bar is a happy\nshade of bright green. If any test fails, the bar becomes an\nangry red. If the bar is a cautionary yellow, that means some\ntests were skipped (more on that later).\nNUnit Command Line\nNUnit can also be run from the command line, which comes in\nvery handy when automating the project build and test. You’ll\nneed to add the NUnit bin directory to your path (that is, the\ndirectory path to wherever you installed the NUnit application,\nplus “\\bin”).\nFor the current shell, you can set your path variable at the\ncommand line, as in the following example on Windows.\nC:\\> set \"PATH=%PATH%;C:\\Program Files\\Nunit V2.4\\bin\"\nFor more permanent use, go to Control Panel/System/Advan-\nced/Environment Variable and add NUnit’s bin directory to\nthe Path variable (see Figure 2.3 on the next page).\nTo run from the command line, type the command nunit-\nconsole followed by an NUnit project ﬁle or an assembly lo-\ncation. You’ll see output something like that shown in Fig-\nure 2.4 on page 26.\nTestDriven.NET (Visual Studio add-in)\nThere are several add-ins that integrate NUnit with Visual\nStudio. The TestDriven.NET4 add-in adds the ability to run\nor debug any test just by right-clicking on the source code and\nselecting “Run Test(s)”; the output from the tests are reported\nin Visual Studio’s output pane, just like compiler warnings or\n4Such as http://www.testdriven.net/\n\n\nRUNNING TESTS WITH NUNIT\n25\nFigure 2.3: Adding to the Windows System Path\nerrors. You can use this output to quickly browse to failed as-\nsertion locations, which is quite handy. Other similar projects\nadd visual reporting of tests and other features.\nSharpDevelop\nSharpDevelop 2.1 (and above), an open-source IDE writ-\nten in C#, includes an Eclipse-style integrated test runner.\nFailed tests come up like compiler errors, allowing for double-\nclicking on an item and going to the assertion that failed. It\nalso allows for measuring the code coverage of unit tests (us-\ning NCover5) with source code highlighting that can be en-\n5http://NCover.org\n\n\nRUNNING TESTS WITH NUNIT\n26\nFigure 2.4: NUnit Command Line Usage\nFigure 2.5: SharpDevelop’s Integrated Unit Testing\n\n\nRUNNING THE EXAMPLE\n27\nabled and disabled.\nA sample screenshot is shown in Fig-\nure 2.5 on the previous page. See SharpDevelop’s web page\nfor more details (http://sharpdevelop.net).\nMonoDevelop\nMonoDevelop 0.13 and above, which is based on SharpDe-\nvelop 0.9, also includes an integrated test runner. While not\nas advanced as SharpDevelop itself, it’s a welcome improve-\nment over a ﬂat text editor on platforms where other tools\ndon’t run. For more information, see MonoDevelop’s web page\n(http://monodevelop.com).\n2.4\nRunning the Example\nYou should be ready to run this ﬁrst test now.\nSTOP\nTry running this example before reading on. . .\nHaving just run that code, you probably saw an error similar\nto the following:\nFailures:\n1) LargestTest.LargestOf3 :\nexpected:<9>\nbut was:<2147483647>\nat LargestTest.LargestOf3() in c:\\largesttests.cs:line 13\nWhoops! That didn’t go as expected. Why did it return such\na huge number instead of our 9? Where could that very large\nnumber have come from? It almost looks like the largest num-\nber. . .\noh, it’s a small typo: max=Int32.MaxValue on line 7\nshould have been max=0.\nWe want to initialize max so that\nany other number instantly becomes the next max. Let’s ﬁx\nthe code, recompile, and run the test again to make sure that\nit works.\nNext we’ll look at what happens when the largest number ap-\npears in different places in the list—ﬁrst or last, and some-\nwhere in the middle. Bugs most often show up at the “edges.”\nIn this case, edges occur when the largest number is at the\nstart or end of the array that we pass in. We can lump all\n\n\nRUNNING THE EXAMPLE\n28\nthree of these asserts together in one test, but let’s add the\nassert statements one at a time. Notice that just as in pro-\nduction (non-test) code, you have to exercise care, taste, and\nrestraint when deciding how much code to add to one method,\nand when to break that up into multiple methods. Since this\nmethod is testing variations on a single theme (physical place-\nment of the largest value), let’s put them together in a single\nmethod.\nWe already have the case with the largest in the middle:\nusing System;\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\n[TestFixture]\npublic class LargestTest\n{\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\n}\n}\nLargestTest.cs\nNow try it with the 9 as the ﬁrst value (we’ll just add an addi-\ntional assertion to the existing LargestOf3() method):\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {9,8,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\n}\nLargestTest.cs\nWe’re on a roll. One more, just for the sake of completeness,\nand we can move on to more interesting tests:\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {9,8,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {7,8,9}), Is.EqualTo(9));\n}\nLargestTest.cs\nSTOP\nTry running this example before reading on. . .\nFailures:\n1) LargestTest.LargestOf3 :\n\n\nRUNNING THE EXAMPLE\n29\nexpected:<9>\nbut was:<8>\nat LargestTest.LargestOf3() in c:\\LargestTest.cs:line 14\nWhy did the test get an 8 as the largest number? It’s almost\nas if the code ignored the last entry in the list. Sure enough,\nanother simple typo: the for loop is terminating too early.\nThis is an example of the infamous “off-by-one” error. Our\ncode has:\nfor (index = 0; index < list.Length-1; index++) {\nBut it should be one of:\nfor (index = 0; index <= list.Length-1; index++) {\nfor (index = 0; index < list.Length; index++) {\nThe second expression is idiomatic in languages descended\nfrom C (including Java and C#), but as you can see, it’s\nprone to off-by-one errors.\nMake the changes and run the\ntests again, but consider that this sort of bug is telling you\nsomething: it would be better to use an iterator (using the C#\nforeach statement) here instead. That way you could avoid\nthis kind of off-by-one error in the future.\nLet’s check for duplicate largest values; type this in and run\nit (we’ll only show the newly added methods from here on):\n[Test]\npublic void Dups() {\nAssert.That(Cmp.Largest(new int[] {9,7,9,8}), Is.EqualTo(9));\n}\nLargestTest.cs\nSo far, so good. Now the test for just a single integer:\n[Test]\npublic void One() {\nAssert.That(Cmp.Largest(new int[] {1}), Is.EqualTo(1));\n}\nLargestTest.cs\nHey, it worked! You’re on a roll now, surely all the bugs we\nplanted in this example have been exorcised by now. Just one\nmore check with negative values:\n[Test]\npublic void Negative() {\nint[] negatives = new int[] {-9, -8, -7};\nAssert.That(Cmp.Largest(negatives), Is.EqualTo(-7));\n}\nLargestTest.cs\n\n\nRUNNING THE EXAMPLE\n30\nSTOP\nTry running this example before reading on. . .\nFailures:\n1) LargestTest.Negative :\nexpected:<-7>\nbut was:<0>\nat LargestTest.Negative() in c:\\LargestTest.cs:line 4\nWhoops! Where did zero come from?\nLooks like choosing 0 to initialize max was a bad idea; what we\nreally wanted was MinValue, so as to be less than all negative\nnumbers as well:\nmax = Int32.MinValue\nMake that change and try it again—all of the existing tests\nshould continue to pass, and now this one will as well.\nUnfortunately, the initial speciﬁcation for the method “largest”\nis incomplete, as it doesn’t say what should happen if the\narray is empty. Let’s say that it’s an error, and add some code\nat the top of the method that will throw a runtime-exception\nif the list length is zero:\npublic static int Largest(int[] list) {\nint index, max=Int32.MinValue;\nif (list.Length == 0) {\nthrow new ArgumentException(\"largest: Empty list\");\n}\n// ...\nLargest.cs\nNotice that just by thinking of the tests, we’ve already realized\nwe need a design change. That’s not at all unusual, and in\nfact is something we want to capitalize on. So for the last test,\nwe need to check that an exception is thrown when passing in\nan empty array. We’ll talk about testing exceptions in depth\non page 54, but for now just trust us:\n[Test]\n[ExpectedException(typeof(ArgumentException))]\npublic void Empty()\n{\nCmp.Largest(new int[] {});\n}\nLargestTest.cs\n\n\nMORE TESTS\n31\nFinally, a reminder: all code—test or production—should be\nclear and simple. Test code especially must be easy to under-\nstand, even at the expense of performance or verbosity.\n2.5\nMore Tests\nWe started with a very simple method and came up with a\ncouple of interesting tests that actually found some bugs.\nNote that we didn’t go overboard and blindly try every pos-\nsible number combination; we picked the interesting cases\nthat might expose problems. But are these all the tests you\ncan think of for this method?\nWhat other tests might be appropriate?\nSince we’ll need to think up tests all of the time, maybe we\nneed a way to think about code that will help us to come up\nwith good tests regularly and reliably. We’ll talk about that\nafter the next chapter, but ﬁrst, let’s take a more in-depth\nlook at using NUnit.\n",
      "page_number": 35
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 45-55)",
      "start_page": 45,
      "end_page": 55,
      "detection_method": "topic_boundary",
      "content": "Chapter 3\nWriting Tests in NUnit\nWe’ve looked at writing tests somewhat informally in the last\nchapter, but now it’s time to take a deeper look at the differ-\nence between test code and production code, all the various\nforms of NUnit’s assertions, the structure and composition of\nNUnit tests, and so on.\n3.1\nStructuring Unit Tests\nSuppose we have a method named CreateAccount;\nthe\nmethod encapsulates behaviour, and it’s behaviour that we\nwant to test. Your ﬁrst test method might be named some-\nthing like CreateSimpleAccount.\nThe method Create-\nSimpleAccount will call CreateAccount with the necessary\nparameters and verify that CreateAccount works as adver-\ntised. You can, of course, have many test methods that ex-\nercise CreateAccount (not all accounts are simple, after all).\nTests should be organized around behaviours, not necessarily\nindividual methods.\nThe relationship between these two pieces of code is shown in\nFigure 3.1 on the next page.\nThe test code is for our internal use only; customers or end-\nusers will generally never see it or use it.\nThe production\ncode—that is, the code that will eventually be shipped to a\ncustomer and put into production—must not know anything\nabout the test code. Production code will be thrust out into\n\n\nSTRUCTURING UNIT TESTS\n33\nCreateSimpleAccount()\nCreateDefaultAccount()\nCreateDupAccount()\nAccountTest.cs\n(Internal Only)\nCreateAccount()\nAccount.cs\n(Delivered)\nFigure 3.1: Test Code and Production Code\nthe cold world all alone, without the test code. This typically\nmeans that test code is placed under a different project, in its\nown assembly.\nTest code follows a standard formula:\n• Set up all conditions needed for testing (create any re-\nquired objects, allocate any needed resources, etc.)\n• Call the method to be tested\n• Verify that the tested functionality worked as expected\n• Clean up after itself1\nYou write test code and compile it in the normal fashion, as\nyou would any other bit of source code in your project.\nIt\nmight happen to use some additional libraries, but otherwise\nthere’s no magic—it’s just code.\nWhen it’s time to execute the code, remember that you never\nactually run the production code directly; at least, not the way\na user would. Instead, you run the test code, which in turn\nexercises the production code under very carefully controlled\nconditions.\nNow, although we could write all our tests from the ground\nup, that’s not terribly efﬁcient. For the rest of this book we’ll\nassume that you’re using the NUnit framework. More specif-\nically, we’ll be showing the speciﬁc method calls and classes\nfor NUnit 2.4, using C#, in our examples. Earlier or later ver-\n1This doesn’t mean nulling out ﬁelds or using GC.Collect(). If you ﬁnd\nyourself doing either, you may have a race condition due to a misbehaving\nFinalizer. These issues are almost never limited to test code.\n\n\nCLASSIC ASSERTS\n34\nsions may have slight differences from the details presented\nhere, but the general concepts are the same across all ver-\nsions, and indeed for any testing framework in any language\nor environment.\n3.2\nClassic Asserts\nAs we’ve seen, there are some helper methods that assist us\nin determining whether a method under test is performing\ncorrectly or not. Generically, we call all these helper meth-\nods assertions. They let us assert that some condition is true;\nthat two bits of data are equal, or not, and so on. NUnit 2.4\nintroduced a new constraint-style of assertions while still sup-\nporting the classic-style of assertions that more closely match\nother XUnit frameworks. We’ll start off by covering some basic\nclassic-style assertions before diving into the constraint-style\nassertions.\nAll of the following methods will report failures (that’s when\nthe assertion is false) or errors (that’s when we get an un-\nexpected exception), and report these through the NUnit test\nrunner. For the text version of the test runner, that means the\ndetails of the failure will be printed to the console. The GUI\nversions of the test runner will show a red bar and support-\ning details to indicate a failure. You can also output the test\nresults to an XML ﬁle.\nWhen a failure or error occurs, execution of the current test\nmethod is aborted. Other tests within the same test ﬁxture\nwill still be run.\nAsserts are the fundamental building block for unit tests; the\nNUnit library provides a number of different forms of assert\nas static methods in the Assert class.\nAreEqual\nAssert.AreEqual(expected, actual [, string message])\nThis is the most-often used form of assert. expected is a value\nyou hope to see (typically hard-coded), and actual is a value\nactually produced by the code under test. message is an op-\ntional message that will be reported in the event of a failure.\n\n\nCLASSIC ASSERTS\n35\nYou can omit the message argument and simply provide the\nexpected and actual values. We recommend omitting the mes-\nsage string for reporting unless you really need to; better that\nthe name of the test method itself expresses your intent, you\nuse the appropriate Assert method, or you split the test into\ntwo methods to keep it focused. We’ll show examples of all of\nthese practices in a bit.\nAny kind of object may be tested for equality; the appropri-\nate equals method will be used for the comparison.2 In par-\nticular, you can compare the contents of strings using this\nmethod. Different method signatures are also provided for all\nthe native types (int, decimal, etc.) and Object. Strings and\nCollections also have their own classic-style asserter classes\nwith extra methods, StringAssert and CollectionAssert,\nwhich we’ll get into a bit later.\nComputers cannot represent all ﬂoating-point numbers ex-\nactly, and will usually be off a little bit. Because of this, if you\nare using an assert to compare ﬂoating point numbers (ﬂoats\nor doubles in C#), you need to specify one additional piece of\ninformation, the tolerance.\nThis speciﬁes just how close to\n“equals” you need the result to be.\nAssert.AreEqual(expected,\nactual,\ntolerance [, string message])\nFor business applications, 4 or 5 decimal places is probably\nenough. For scientiﬁc apps, you may need greater precision.\nAs an example, the following assert will check that the actual\nresult is equal to 3.33, but only look at the ﬁrst two decimal\nplaces:\nAssert.AreEqual(3.33, 10.0/3.0, 0.01);\nLess / Greater\nAssert.Less(x, y)\nAssert.Greater(x,y)\n2Remember that the default Equals() inherited from System.Object\nonly checks to see if the object references themselves are the same—it checks\nfor identity, rather than equality. For value types (structs, enums, etc.) the\nﬁelds are veriﬁed to be equal [Ric06].\n\n\nCLASSIC ASSERTS\n36\nAsserts that x < y (or x > y) for numeric types, or any type\nthat is IComparable.\nGreaterOrEqual / LessOrEqual\nAssert.GreaterOrEqual(x, y)\nAssert.LessOrEqual(x,y)\nAsserts that x >= y (or x <= y) for numeric types, or any type\nthat is IComparable.\nIsNull / IsNotNull\nAssert.IsNull(object [, string message])\nAssert.IsNotNull(object [, string message])\nAsserts that the given object is null (or not null), failing oth-\nerwise. The message is optional.\nAreSame\nAssert.AreSame(expected, actual [, string message])\nAsserts that expected and actual refer to the same object, and\nfails the test if they do not. The message is optional.\nIsTrue\nAssert.IsTrue(bool condition [, string message])\nAsserts that the given boolean condition is true, otherwise the\ntest fails. The message is optional.\nIf you ﬁnd test code that is littered with the following:\nAssert.IsTrue(true);\nthen you should be concerned.\nUnless that construct is\nused to verify some sort of branching or exception logic, it’s\nprobably a bad idea.\nIn particular, what you really don’t\nwant to see is a whole page of “test” code with a single As-\nsert.IsTrue(true) at the very end (i.e., “the code made it\nto the very end without blowing up therefore it must work”).\nThat’s not testing, that’s wishful thinking.\nIn addition to testing for true, you can also test for false:\n\n\nCONSTRAINT-BASED ASSERTS\n37\nAssert.IsFalse(bool condition [, string message])\nAsserts that the given boolean condition is false, otherwise the\ntest fails. The message is optional.\nNeither IsTrue nor IsFalse give you any additional in-\nformation\nwhen\nthe\ntest\nfails;\nthis\nmeans\nyou\nmight\nhave to use the debugger or Console.WriteLine() state-\nments\nto\ndiagnose\na\nunit\ntest\nfailure.\nThat’s\nnot\nvery efﬁcient.\nThere might be\na better assertion you\ncould use, such as StringAssert.Contains() or Collec-\ntionAssert.DoesNotContain()—we’ll take a look at these\nmore interesting assertions in just a moment. A more precise\nassertion like those will give you more precise information on\nfailure so you can concentrate on ﬁxing the code rather than\ntrying to ﬁgure out what went wrong.\nFail\nAssert.Fail([string message])\nFails the test immediately, with the optional message. This\nmight be used to mark sections of code that should not be\nreached, but isn’t really used much in practice.\n3.3\nConstraint-based Asserts\nNUnit 2.4 introduced a new style of assertions that are a little\nless procedural and allow for a more object-oriented underly-\ning implementation. NUnit has a history of innovating on the\nclassic XUnit design, which other frameworks then incorpo-\nrate later. In this case the NUnit team decided to mimic an-\nother innovative framework called NMock2,3 which we’ll dis-\ncuss later in Chapter 6.\nThis new assertion style can seem a little odd at ﬁrst, but we\nsuggest giving it a chance before falling back on the “classic”\nassertion methods.\nAfter all, the classic assertion methods\njust delegate to the constraint-style assertion methods behind\nthe covers. Let’s look at a couple of assertions as they would\nbe written in the new style.\n3NMock2, in turn, was mimicking jMock.\n\n\nCONSTRAINT-BASED ASSERTS\n38\nJoe Asks. . .\nWhat was wrong with the old syntax?\nWell, nothing was particularly wrong with the classic\nsyntax, per se. In fact, there are no plans to remove or\ndeprecate the classic syntax. The classic-style assert\nmethods delegate to the new methods, so there’s no\nduplication. Here’s a quick history lesson that may il-\nluminate the progression.a In the beginning, test ﬁx-\nture classes had to derive from a class called Test-\nCase. Deriving from TestCase both told the test run-\nner which classes contained test methods and pro-\nvided assertion methods, amongst other things.\nIn those days, we would call assertEquals() and\nother assertions, which were inherited from Test-\nCase, from our test methods. The TestCase class was\nalso reponsible for providing a virtual setUp() and\ntearDown() method.\nClearly, the TestCase class\nwas a bit overloaded as far as its reponsibilities.\nFirst, NUnit used attributes to mark test ﬁxture classes,\nas previously discussed.\nThen, NUnit extracted the\ngrowing list of assertion methods into the family of As-\nsert classes. This effectively eliminated the TestCase\nclass altogether. Several other XUnit frameworks have\npicked up these ideas in their recent versions.\nThis\nbrings us up to NUnit 2.2.\nWhile developing NUnit 2.4, the NUnit team realised\nthat the Assert classes had a few too many repon-\nsibilities.\nThe Assert classes had to make sure the\nactual value matched the expected value, whatever\nthat meant for the given assertion method. On top of\nthis, the Assert class needed to format the text to be\noutput by the test runner when the assertion failed.\nThese responsibilities were broken up, with the Con-\nstraint objects (returned by syntax helpers such as\nIs.EqualTo()) bearing the responsibility of making\nsure the actual value met the context-speciﬁc con-\nstraint of the expected value. Because they are en-\ncapsulated in separate objects, multiple constraints\ncan be combined and applied to a single value.\nThat leaves the text formatting when an assertion fails,\nwhich falls to the TextMessageWriter object that\nNUnit uses internally.\nsoon\nGive the constraint style assertions a spin you\n\n\nCONSTRAINT-BASED ASSERTS\n39\nIs.EqualTo\nAssert.That(actual, Is.EqualTo(expected))\nThis\nis\nequivalant\nto\nthe\nAssert.AreEqual()\nclassic\nassertion\nmethod\nwe\ndiscussed\nin\nthe\nlast\nsection.\nThe\nIs.EqualTo()\nmethod\nis\na\nsyntax\nhelper\nin\nthe\nNUnit.Framework.SyntaxHelpers namespace. It’s a static\nmethod that just returns an EqualConstraint object. The\nfollowing code is equivalant, but may not read as smoothly to\nsome folks.\nAssert.That(actual, new EqualConstraint(expected))\nTo specify a tolerance for ﬂoating point numbers like we did\npreviously, we can use a neat feature of the new syntax called\nconstraint modiﬁers. There are several that we’ll look at, but\nhere is one called Within() that is equivalant to our same\nexample that used the classic-style in the previous section.\nAssert.That(10.0/3.0, Is.EqualTo(3.33).Within(0.01f));\nIs.Not.EqualTo\nAssert.That(actual, Is.Not.EqualTo(expected))\nThis is an example of one of the fun things that the\nconstraint-based syntax allows for and is equivalant to the\nAssert.AreNotEqual() classic assertion that was discussed\npreviously.\nThe usage of Not in this context isn’t exactly a\nseparate method, as in the other examples. By applying Not,\nit wraps the EqualConstraint in a NotConstraint object.\nThe following code is equivalant.\nAssert.That(actual, new NotConstraint(new EqualConstraint(expected)));\nWe can apply Not to any Is or Has syntax helper. As such, you\ncould also wrap the NotConstraint object around any other\nConstraint object. Given the verbosity that entails, though,\nwe’re probably better off using the syntax helper approach.\nIs.AtMost\nAssert.That(actual, Is.AtMost(expected))\nThis\nconstraint-style\nassert\nis\nequivalant\nto\nthe\nAssert.LessOrEqual()\nclassic\nassertion\nmethod.\n\n\nCONSTRAINT-BASED ASSERTS\n40\nIs.AtMost() is just an alias for Is.LessThenOrEqualTo(),\nwhich returns a LessThanOrEqualConstraint object.\nIs.Null\nAssert.That(expected, Is.Null);\nAsserts that expected is null, and fails the test if it is not. To\nassert the opposite, we have two choices of constraint-style\nsyntax.\nAssert.That(expected, Is.Not.Null);\nAssert.That(expected, !Is.Null);\nEither of these ways will wrap the constraint in a NotCon-\ntraint object under the covers. Either style can be applied\nto any of the constraints. Neat, huh?\nIs.Empty\nAssert.That(expected, Is.Empty);\nAsserts that expected is an empty collection or string, and\nfails the test if it is not.\nIs.AtLeast\nAssert.That(actual, Is.AtLeast(expected));\nThis is equivalant to Is.GreaterThanOrEqualTo(), which\nasserts that actual >= expected (or expected <= actual) for\nnumeric types, or any type that is IComparable.\nIs.InstanceOfType\nAssert.That(actual, Is.InstanceOfType(expected));\nAsserts that actual is of type expected, or a derivation of that\ntype.\nHas.Length\nAssert.That(actual, Has.Length(expected));\n\n\nNUNIT FRAMEWORK\n41\nAsserts that actual has a Length property that returns the\nexpected value. Note that it can be any object with a property\nnamed “Length”, not just a string or Collection. We could\nalso just assert the length using Is.EqualTo(), but this may\nbe easier to read for some.\nIn the rest of the examples, we’ll be using this new constraint-\nstyle of assertions. If you’re more comfortable with the classic-\nstyle, feel free to substitute those into the appropriate places\ninstead.\nUsing Asserts\nWe usually have multiple asserts in a given test method, as\nwe prove various aspects and relationships of the method(s)\nunder test.\nWhen an assert fails, that test method will be\naborted—the remaining assertions in that method will not be\nexecuted this time. But that shouldn’t be of any concern; we\nhave to ﬁx the failing test before we can proceed anyway. And\nwe ﬁx the next failing test. And the next. And so on.\nYou should normally expect that all tests pass all of the time.\nIn practice, that means that when we introduce a bug, only\none or two tests fail. Isolating the problem is usually pretty\neasy in that environment.\nUnder no circumstances should we continue to add features\nwhen there are failing tests! Fix any test as soon as it fails,\nand keep all tests passing all of the time.\nTo maintain that discipline, we’ll need an easy way to run all\nthe tests—or to run groups of tests, particular subsystems,\nand so on.\n3.4\nNUnit Framework\nSo far, we’ve just looked at the assert methods themselves.\nBut you can’t just stick assert methods into a source ﬁle and\nexpect it to work; you need a little bit more of a framework\nthan that. Fortunately, it’s not too much more.\nHere is a very simple piece of test code that illustrates the\nminimum framework we need to get started.\n\n\nNUNIT FRAMEWORK\n42\nLine 1\nusing System;\n-\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\n5\n[TestFixture]\n-\npublic class LargestTest\n-\n{\n-\n[Test]\n-\npublic void LargestOf3Alt()\n10\n{\n-\nint[] arr = new int[3];\n-\narr[0] = 8;\n-\narr[1] = 9;\n-\narr[2] = 7;\n15\nAssert.That(Cmp.Largest(arr), Is.EqualTo(9));\n-\n}\n-\n}\nLargestTest.cs\nThis code is pretty straightforward, but let’s take a look at\neach part in turn.\nFirst, the using statement on line ?? brings in the neces-\nsary NUnit classes. Remember we’ll need to tell the compiler\nyou’re referencing nunit.framework.dll, otherwise the us-\ning statement won’t be able to ﬁnd the NUnit.Framework\nnamespace.\nNext, we have the class deﬁnition itself on line ??: each class\nthat contains tests must be annotated with a [TestFixture]\nattribute as shown. The class must be declared public (so\nthat the test runners will run it; by default, classes are in-\nternal), and it must have a public, no-parameter, construc-\ntor (the default implicit constructor is all we need—adding a\nconstructor to a TestFixture is generally not necessary).\nFinally, the test class contains individual methods annotated\nwith [Test] attributes.\nIn the example, we’ve got one test\nmethod named LargestOf3 on line ??. Any public, param-\neterless method speciﬁed with a [Test] attribute will be run\nautomatically by NUnit.\nWe can include helper methods to\nsupport clean code in our tests as well, we just don’t mark\nthem as tests.\nIn the previous example, we showed a single test, using a\nsingle assert, in a single test method. Of course, inside a test\nmethod, you can place any number of asserts:\nusing System;\n",
      "page_number": 45
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 56-64)",
      "start_page": 56,
      "end_page": 64,
      "detection_method": "topic_boundary",
      "content": "NUNIT TEST SELECTION\n43\nJoe Asks. . .\nWhat’s a Fixture?\nFrom the c2.com wiki:a\nIn electronics testing, a ﬁxture is an environment in\nwhich you can test a component. Once the circuit\nboard or component is mounted in the text ﬁxture, it is\nprovided with the power and whatever else is needed\nto drive the behaviour to be tested.\nA ﬁxture in the context of unit testing is more about\nthe scenario we’re testing than the actual class we’re\ntesting. Testing a single class across multiple ﬁxtures is\nvery common.\nahttp://c2.com/cgi/wiki?TestFixture\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\n[TestFixture]\npublic class LargestTest\n{\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {9,8,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {7,8,9}), Is.EqualTo(9));\n}\nLargestTest.cs\nHere we have three calls to Assert.That inside a single test\nmethod.\n3.5\nNUnit Test Selection\nAs we’ve seen so far, a ﬁxture (that is, a class marked with\nthe [TestFixture] attribute) contains test methods; each\nmethod contains one or more assertions.\nMultiple test ﬁx-\ntures can be included into a source code ﬁle or a compiled\nassembly.\nYou will normally run all of the tests within an assembly just\n\n\nNUNIT TEST SELECTION\n44\nOrganizing ﬁxtures\nFollowing good object-oriented design, a class should\nbe focused on one responsibility. This applies to test\nﬁxtures as well—they’re just classes, after all. As such,\nput tests into a ﬁxture that describes the speciﬁc sce-\nnario they are being tested in.\nIf there aren’t multiple scenarios, then just name the\nﬁxture class after the class being tested. You can al-\nways extract more focused ﬁxtures from a general ﬁx-\nture once the general ﬁxture starts getting too fat.\nHaving a ﬁxture class focused on a speciﬁc sce-\nnario, with a name that documents that scenario,\nhelps avoid duplicating the scenario description in\nthe name of several test methods.\nTo keep things readable in the test runner output, put\nthe ﬁxture classes under a namespace that includes\nthe name of the class that the ﬁxtures are testing, like\nso:\nnamespace ZeroBay.Test.ShoppingCartTest\n{\n[TestFixture]\npublic class NoDataFixture\n{\n[Test]\npublic void OverallRateIsZero() {...}\n}\n}\nby specifying the assembly to the test runner. You can also\nchoose to run individual test ﬁxtures within an assembly us-\ning either the NUnit command line or GUI.\nFrom the GUI, you can select an individual test, a single test\nﬁxture, or the entire assembly by selecting it and clicking the\nrun button, and all the appropriate tests will be run.\nFrom the command line, you can specify the assembly and a\nparticular test ﬁxture as follows:\nc:\\> nunit-console\nassemblyname.dll\n/fixture:ClassName\nGiven this ﬂexibility, you may want to think a bit about how to\n\n\nNUNIT TEST SELECTION\n45\norganize test methods into individual assemblies and ﬁxtures\nto make testing easier.\nFor instance, you may want to run all the database-related\ntests at once, or all of the tests that Fred wrote (Fred is still\non probation from the last project, and you want to keep an\neye on him).\nFortunately, NUnit has a mechanism you can use to catego-\nrize and classify individual test methods and ﬁxtures.\nCategories\nNUnit provides an easy way to mark and run individual tests\nand ﬁxtures by using categories. A category is just a name\nthat you deﬁne. You can associate different test methods with\none or more categories, and then select which categories you\nwant to exclude (or include) when running the tests.\nSuppose among your tests you’ve got a method to ﬁnd the\nshortest route that our traveling salesman, Bob, can take to\nvisit the top n cities in his territory. The funny thing about\nthe Traveling Salesman algorithm is that for a small number\nof cities it works just ﬁne, but it’s an exponential algorithm.\nThat means that a few hundred cities might take 20,000 years\nto run, for example. Even 50 cities takes a few hours, so you\nprobably don’t want to to include that test by default.\nYou can use NUnit categories to help sort out your usual tests\nthat you can run constantly versus long-running tests that\nyou’d rather only run during the automated build. Categories\nare generally used for exclusion rather than inclusion.\nA category is speciﬁed as an attribute. You provide a string\nto identify the category when you declare the method. Then\nwhen you run the tests, you can specify which categories you\nwant to run (you can specify more than one).\nFor instance, suppose you’ve got a few methods that only take\na few seconds to run, but one method that takes a long time to\nrun. You can annotate them using the category names “Short”\nand “Long” (you might also consider making a category “Fred”\nif you still want to keep an eye on him.)\nLine 1\nusing NUnit.Framework;\n\n\nNUNIT TEST SELECTION\n46\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\n-\n[TestFixture]\n5\npublic class ShortestPathTest\n-\n{\n-\nTSP tsp;\n-\n-\n[SetUp]\n10\npublic void SetUp()\n-\n{\n-\ntsp = new TSP();\n-\n}\n-\n15\n[Test]\n-\n[Category(\"Short\")]\n-\npublic void Use5Cities()\n-\n{\n-\nAssert.That(tsp.ShortestPath(5), Is.AtMost(140));\n20\n}\n-\n-\n// This one takes a while...\n-\n[Test]\n-\n[Category(\"Long\")]\n25\n[Category(\"Fred\")]\n-\npublic void Use50Cities()\n-\n{\n-\nAssert.That(tsp.ShortestPath(50), Is.AtMost(2300));\n-\n}\n30\n}\nShortestPathTest.cs\nNotice that you can specify multiple attributes (in this case,\nTest and Category) on two separate lines as shown around\nline 26, or combined into one line.\nNow if you choose to run just “Short” methods, the two meth-\nods Use2Cities and Use10Cities will be selected to run.\nIf you choose “Long” methods, only Use50Cities will be se-\nlected. You can also select both categories to run all three of\nthese methods.\nIn the GUI, you select which categories of tests to include and\nwhich to exclude on the tab as shown in Figure 3.2 on the\nfollowing page.\nJust select each category you’re interested\nand press the ADD button.\nOn a real project, of course, you wouldn’t bother to mark a\nbunch of tests as “short.” They should all be short, except for\nthe ones speciﬁcally marked as “Long.”\nFrom the command line, you can specify individual categories\nto include as well. Just add the following parameter to the\n\n\nNUNIT TEST SELECTION\n47\nFigure 3.2: NUnit Category Selection\ncommand line:\n/include=category1;category2;...\nNote that multiple category names are separated by a semi-\ncolon (“;”).\nYou can also choose to exclude the listed categories so all\nother tests except those in the named categories run. There’s\na check box in the GUI for this; the command line option is,\noddly enough, /exclude.\nBut this isn’t quite enough: it turns out that some categories\nof tests should be run when no categories are selected, while\nothers should run only when explicitly selected.\nTo support this, you can specify the Explicit attribute:\n[Explicit(\"SpecialEquipmentNeeded\")]\nThis syntax automatically excludes the category from a run\nthat doesn’t specify any categories. By default, your run will\ninclude tests without categories and tests with non-explicit\ncategories. However, if even one category is speciﬁed in the\n\n\nNUNIT TEST SELECTION\n48\nGUI or the command line, then only that single category will\nbe run.\nThere’s a danger here, of course—these tests aren’t running\nall the time. They probably aren’t being run in the automated\nbuild system, either. This might lull you into a false sense of\nsecurity, so beware.\nIn addition to marking individual test methods as belonging to\na category, you can also mark entire ﬁxtures. For instance, if\nwe wanted to ﬂag our entire test ﬁxture as long-running (with-\nout having to mark each and every test method), we could do\nso.\nLine 1\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\n-\n[TestFixture]\n5\n[Category(\"Long\")]\n-\npublic class ShortestPathTest-Revised\n-\n{\n-\nTSP tsp;\n-\n10\n[Test]\n-\npublic void Use50Cities()\n-\n{\n-\ntsp = new TSP(); // load with default cities\n-\nAssert.That(tsp.ShortestPath(50), Is.AtMost(2300));\n15\n}\n-\n-\n[Test]\n-\npublic void Use100Cities()\n-\n{\n20\ntsp = new TSP(); // load with default cities\n-\nAssert.That(tsp.ShortestPath(100), Is.AtMost(4675));\n-\n}\n-\n-\n[Test]\n25\npublic void Use150Cities()\n-\n{\n-\ntsp = new TSP(); // load with default cities\n-\nAssert.That(tsp.ShortestPath(150), Is.AtMost(5357));\n-\n}\n30\n}\nShortestPathTest-Revised.cs\nNow you can quickly exclude the whole ﬁxture using a cate-\ngory name.\nOf course, not all tests need categories, and you may have\nentire projects where there are no categories at all. But it’s\nnice to know they are there if you do need them.\n\n\nNUNIT TEST SELECTION\n49\nPer-method Setup and Teardown\nEach test should run independently of every other test; this\nallows you to run any individual test at any time, in any order.\nTo accomplish this feat, you may need to reset some parts of\nthe testing environment in between tests, or clean up after\na test has run. NUnit lets you specify two methods to set up\nand then tear down the environment per test using attributes:\n[SetUp]\npublic void PerTestSetup() {\n...\n}\n[TearDown]\npublic void PerTestTeardown() {\n...\n}\nIn this example, the method PerTestSetup() is called before\neach one of the [Test] methods is executed, and the method\nPerTestTeardown() is called after each test method is exe-\ncuted, even if the test method throws an exception. This is\nwhy we mentioned that constructors in test ﬁxtures gener-\nally aren’t necessary.\nConstructors wouldn’t work the way\nyou wanted them to anyway, since NUnit doesn’t necessarily\nrecreate the TestFixture class each time it runs a test; it\ndiscovers and runs these methods using reﬂection.\nFor example, suppose you needed some sort of database con-\nnection object for each test. Rather than duplicating code in\neach test method that connects to and disconnects from the\ndatabase, you could simply use setup and teardown methods.\n[TestFixture]\npublic class DBTest\n{\nprivate Connection dbConn;\n[SetUp]\npublic void PerTestSetup()\n{\ndbConn = new Connection(\"oracle\", 1521, user, pw);\ndbConn.Connect();\n}\n[TearDown]\npublic void PerTestTeardown()\n{\ndbConn.Disconnect();\ndbConn.Dispose();\n}\n\n\nNUNIT TEST SELECTION\n50\n1. PerFixtureSetup()\n2.\nPerTestSetup()\n3.\ntest method 1\n4.\nPerTestTeardown()\n5.\nPerTestSetup()\n6.\ntest method 2\n7.\nPerTestTeardown()\n8. PerFixtureTeardown()\nPer-ﬁxture setup\nruns before any\ntests in a\nﬁxture, and\nteardown runs\nafter the last\ntest in a ﬁxture.\nPer-test setup\nruns before\neach test\nmethod, and\nteardown runs\nafter each\nmethod.\nFigure 3.3: Execution Order of Setup Code\n[Test]\npublic void AccountAccess()\n{\n// Uses dbConn\nxxx xxx xxxxxx xxx xxxxxxxxx;\nxx xxx xxx xxxx x xx xxxx;\n}\n[Test]\npublic void EmployeeAccess()\n{\n// Uses dbConn\nxxx xxx xxxxxx xxx xxxxxxxxx;\nxxxx x x xx xxx xx xxxx;\n}\n}\nDBTest.cs\nIn this example, the method PerTestSetup() will be called\nbefore TestAccountAccess(). After TestAccountAccess()\nhas ﬁnished, PerTestTearDown() will be called. PerTest-\nSetup() will be called again, followed by TestEmployee-\nAccess() and then PerTestTeardown() again.\nPer-ﬁxture Setup and Teardown\nNormally per-method setup is all you need, but in some cir-\ncumstances you may need to set something up or clean up af-\nter the entire test class has run; for that, you need per-ﬁxture\nsetup and teardown (the difference between per-test and per-\nﬁxture execution order is shown in Figure 3.3 on the previous\n\n\nMORE NUNIT ASSERTS\n51\npage). All you need to do is annotate your setup methods with\nthe following attributes:\n[TestFixtureSetUp]\npublic void PerFixtureSetup() {\n...\n}\n[TestFixtureTearDown]\npublic void PerFixtureTeardown() {\n...\n}\nNote that you can use both per-ﬁxture and per-test methods\nin the same class. While setup and teardown methods gener-\nally come in pairs, they don’t have to. Very often, a ﬁxture will\nhave a setup, but no teardown. A teardown without a setup,\nwhile rare, is also not unheard of. We can also deﬁne set-up\nmethods across inheritance boundaries, in both base classes\nand derived classes. They will work together as if they were\nall deﬁned in the same class.\n3.6\nMore NUnit Asserts\nIn addition to the basic asserts we’ve seen, NUnit provides\nadditional asserts to aid in testing collections and ﬁles.\nIf\nyou prefer the classic-style assertion methods, check out the\nStringAssert and CollectionAssert classes as well as the\nNUnit documentation.\nList.Contains\nAssert.That(actualCollection,\nList.Contains(expectedValue))\nAssert.That({5, 3, 2}, List.Contains(2))\nTests that the expected value is contained within actualCol-\nlection.\nIs.SubsetOf\nAssert.That(actualCollection,\nIs.SubsetOf(expectedCollection))\nAssert.That(new byte[] {5, 3, 2},\nIs.SubsetOf(new byte[] {1, 2, 3, 4, 5}))\n",
      "page_number": 56
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 65-73)",
      "start_page": 65,
      "end_page": 73,
      "detection_method": "topic_boundary",
      "content": "MORE NUNIT ASSERTS\n52\nTests that the elements of actualCollection are contained\nwithin expectedCollection, regardless of order.\nText.StartsWith\nAssert.That(actual,\nText.StartsWith(expected))\nAssert.That(\"header:data.\",\nText.StartsWith(\"header:\"))\nTests that the expected string is at the beginning of actual.\nThis is case sensitive by default; to ignore case sensitivity, we\nneed to add the IgnoreCase constraint modiﬁer.\nAssert.That(\"header:data.\",\nText.StartsWith(\"HeadeR\").IgnoreCase)\nText.Matches\nAssert.That(actual, Text.Matches(expected))\nAssert.That(\"header:data.\",\nText.Matches(\"$header^\\.\"))\nTests that the expected regular expression string matches\nactual.\nHere we’re making sure the actual string starts\nwith “header”,\nand ends with a period character.\nWe\ncould also have used a combination of Text.StartsWith,\nText.EndsWith, or Text.Contains constraints.\nFileAssert.AreEqual / AreNotEqual\nFileAssert.AreEqual(FileInfo expected,\nFileInfo actual)\nFileAssert.AreEqual(String pathToExpected,\nString pathToActual)\nTest whether two ﬁles are the same, byte for byte. Note that\nif we do the work of opening a Stream (ﬁle-based, or not), we\ncan use the EqualsConstraint instead, like so:\nStream expectedStream = File.OpenRead(\"expected.bin\");\nStream actualStream = File.OpenRead(\"actual.bin\");\nAssert.That(\nactualStream,\nIs.EqualTo(expectedStream)\n);\n\n\nNUNIT CUSTOM ASSERTS\n53\n3.7\nNUnit Custom Asserts\nThe standard asserts that NUnit provides are usually sufﬁ-\ncient for most testing. However, you may run into a situation\nwhere it would be handy to have your own, customized as-\nserts. Perhaps you’ve got a special data type, or a common\nsequence of actions that is done in multiple tests.\nThe worst thing you can do is slavishly copy the same se-\nquence of test code over and over again. “Copy and paste” of\ncommon code in the tests can be a fatal disease.\nInstead, tests should be written to the same high standards\nas regular code, which means honoring good coding practices\nsuch as the DRY principle,4 loose coupling, orthogonality, and\nso on. Factor out common bits of test harness into real meth-\nods, and use those methods in your test cases.\nThis is real code, and needs to be well-written, and well-\nfactored so you can reuse it and keep it up to date easily as\nthe system grows and evolves.\nDon’t be afraid to write your own assertion-style methods. For\ninstance, suppose you are testing a ﬁnancial application and\nvirtually all of the tests use a data type called Money.\nusing System;\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\npublic class MoneyAssert\n{\n// Assert that the amount of money is an even\n// number of dollars (no cents)\npublic static void AssertNoCents(Money amount,\nString message)\n{\nAssert.That(\nDecimal.Truncate(amount.AsDecimal()),\nIs.EqualTo(amount.AsDecimal()),\nmessage);\n}\n// Assert that the amount of money is an even\n// number of dollars (no cents)\npublic static void AssertNoCents(Money amount)\n4DRY stands for “Don’t Repeat Yourself.” It’s a fundamental technique\nthat demands that every piece of knowledge in a system must have a single,\nunambiguous, and authoritative representation [HT00].\n\n\nNUNIT AND EXCEPTIONS\n54\n{\nAssertNoCents(amount, String.Empty);\n}\n}\nMoneyAssert.cs\nNote that we provide both forms of assert: one that takes\na string and one that does not.\nNote also that we didn’t\nduplicate any code in doing so; we merely forward the call on.\nNow any other test classes in the project that need to test\nMoney can use our own custom assertion method. If multiple\ntest ﬁxture classes needed to use our custom assertions or\nother support methods, we could also extract a common base\nﬁxture class they would then derive from.\nWe’ll talk more\nabout that later in Chapter 8.\nusing NUnit.Framework;\n[TestFixture]\npublic class SomethingTest\n{\n[Test]\npublic void CountDeMonet()\n{\nMoney m = new Money(42.00);\nm.Add(2);\nMoneyAssert.AssertNoCents(m);\n}\n}\nSomethingTest.cs\nFor more examples, take a look at the NUnit source code itself\n(perhaps the StringAssert code). That’s part of the beauty\nof open source—you can go see the code for yourself, and see\nhow the magic is done.\n3.8\nNUnit and Exceptions\nWe might be interested in two different kinds of exceptions:\n1. Expected exceptions resulting from a test\n2. Unexpected exceptions from something that’s gone hor-\nribly wrong\nContrary to what you might think, exceptions are really good\nthings—they tell us that something is wrong. Sometimes in a\ntest, we want the method under test to throw an exception.\nConsider a method named ImportList(). It’s supposed to\n\n\nNUNIT AND EXCEPTIONS\n55\nthrow an ArgumentException if passed a null list. We must\ntest for that explicitly.\nGuarding against bad data is good defensive programming. If\na null parameter is passed in and not used immediately, the\neventual NullReferenceException becomes a time bomb of\nsorts.\nIt will go off at an unexpected moment, in some far\naway corner of the code. You then get the unenviable task of\ntracking down where in the system the bad data came from\noriginally. But by failing quickly, you’ll ﬁnd the root of the\nproblem quickly, and much more easily.\nSome people just\nlike pain, but we don’t, so we prefer to decrease our time spent\ndebugging by employing this practice.\nWith what we’ve learned so far, we can construct the following\ntest to ensure that the exception is thrown as expected.\n[Test]\npublic void NullList()\n{\ntry\n{\nWhitePages.ImportList(null);\nAssert.Fail(\"ArgumentNullException should have been thrown\");\n}\ncatch (ArgumentNullException)\n{\n}\n}\nThis test will fail if any exception other than Argument-\nNullException is thrown, or if no exception is thrown at\nall.\nIf no exception is thrown, the Assert.Fail() method\nis called, which fails the test. If an exception other than Ar-\ngumentNullException is thrown, it won’t be caught by the\ncatch deﬁned, which fails the test. This works, but it’s not\nexactly aesthetically pleasing.\nMore practically speaking, this style of test just doesn’t ex-\npress our intentions very well, and doesn’t scale well to more\ncomplicated cases. The NUnit user community and authors\nagreed, so for expected exceptions, NUnit now provides the\n[ExpectedException] attribute:\n[TestFixture]\npublic class ImportListTests\n{\n\n\nNUNIT AND EXCEPTIONS\n56\n[Test]\n[ExpectedException(typeof(ArgumentNullException))]\npublic void NullList() {\nWhitePages.ImportList(null);\n// Shouldn’t get to here\n}\n}\nExceptionTest.cs\nThis test method is now expected to throw an exception (from\nthe call to ImportList()). If it doesn’t, the test will fail. If the\nexact exception speciﬁed ﬁres as expected, the test passes. If\na different exception is thrown (even a super-class of the one\nspeciﬁed), the test fails. It might be tempting to just expect\nthe base Exception type, but you’re skirting around the fact\nthe tests are telling you your design needs some work.\nYou want to be as speciﬁc with exceptions in this context as\nyou would be in a catch() statement. Otherwise, you’ll get\ntests that pass when a totally different exception is thrown,\nand you might not know about it until the system starts mal-\nfunctioning in the hands of end-users.\nTwo salient details worth noting: Once the expected exception\nﬁres, any remaining code in the test method will be skipped. If\nthe SetUp method throws an exception before a test method’s\ncode executes, the test will always be reported as failing even\nthough the actual test code didn’t run.\nFurthermore, even\nif SetUp throws, TearDown method will still be run (if one is\ndeclared).\nIn general, you should test a method for every expected excep-\ntion, and make sure that the method throws it when it should.\nThat covers us for expected exceptions, but what about unex-\npected exceptions?\nNUnit will take care of those for you. For instance, suppose\nyou are reading a ﬁle of test data. Rather than catching the\npossible I/O exceptions yourself, just let them propagate out\nto the test framework.\n[Test]\npublic void TestData1() {\nStreamReader sr = new StreamReader(\"data.txt\");\nxxx xxx xxxxxx xxxxx xxxx;\n}\n\n\nTEMPORARILY IGNORING TESTS\n57\nEven better, NUnit will report the entire stack trace right down\nto the bug itself, not just to some failed assert, which helps\nwhen trying to ﬁgure out why a test failed. If you have enabled\ndebugging information during compilation of your assembly\nunder test, it will also give the exact source code line numbers\nin the stack trace.\nWhen compiling under mono’s C# compiler (gmcs) or Microsoft\n.NET’s C# compiler (csc), add -debug+ to the command line.\nIf you’re not working at the command line, this can be accom-\nplished by changing the Project settings in whatever IDE you\nhappen to be using. When running under mono, you’ll need to\nuse the -debug option to the mono runtime executable (mono\n-debug) for it to actually use that generated debug informa-\ntion.5\n3.9\nTemporarily Ignoring Tests\nNormally, you want all tests to pass all of the time. But sup-\npose you’ve thought up a bunch of tests ﬁrst, written them,\nand are now working your way through implementing the\ncode required to pass the tests.\nWhat about all those new\ntests that would fail now?\nYou can go ahead and write these tests, but you don’t want the\ntesting framework to run these tests just yet. NUnit provides\nthe [Ignore] attribute:\n[Test]\n[Ignore(\"Out of time.\nWill Continue Monday. --AH\")]\npublic void Something()\n{\nxxx xxx xxxxxx xxxxx xxxx;\n}\nExceptionTest.cs\nNUnit will report that this method was skipped (and show a\nyellow bar in the GUI version), so that you won’t forget about\nit later.\nIn other testing frameworks and languages, you’d have to ei-\nther name the method differently or comment it out. When\nusing JUnit in Java, for instance, methods whose names start\n5Microsoft .NET doesn’t require this; hopefully mono will remove this re-\nquirement in a future release.\n\n\nTEMPORARILY IGNORING TESTS\n58\nwith “test” (as in testSomething) will be run as tests; you\nhave to name the method something else until you’re ready\nto tackle it.\nIn any language, the code still has to compile\ncleanly; if it’s not ready for that yet, then you should com-\nment out the offending parts.\nIt’s a good idea to to put a meaningful message, and perhaps\neven your initials, into the ignore so that the team knows why\nthis test isn’t running. Are you still working on it? Do you\nneed something from someone else in order to ﬁnish? Can\nsomeone else ﬁnish it up for you (in a geographically diverse\nteam, perhaps)?\nDon’t just Ignore it and forget about it;\nthat’s a Broken Window.6\nYou want to avoid at all costs the habit of ignoring failing test\nresults. You don’t see green until they all work: just the ab-\nsence of a red bar (or error messages) does not mean success.\nIgnoring Platform-dependent Tests\nThere is one small exception to that rule; what to do when cer-\ntain tests have to be ignored because of the platform on which\nyou are running? This scenario isn’t uncommon and can oc-\ncur if you’re writing a cross-platform application (whether it\nbe for .NET 2.0 and mono, or speciﬁcally for .NET 1.1), some\nof your tests may only run (or pass) on a speciﬁc platform.\nThis was a problem NUnit itself faced, so they introduced the\nPlatform attribute, which is used like this:\n[Test]\n[Platform(Exclude = \"Mono\")]\npublic void RemoveOnEmpty() {\nxxx xx xxx xxxxx xx xx xxx;\n}\n[Test, Platform(Exclude = \"Net-1.0,Win95\")]\npublic void EmptyStatusBar() {\nxxx xx xxx xxxxx xx xx xxx;\n}\nAs you can see, Linux-speciﬁc tests that don’t work on Solaris,\nMacOS, or certain Windows or .NET versions can be marked\n6See [HT00].\n\n\nTEMPORARILY IGNORING TESTS\n59\nas such. 7 When using the Platform attribute, you will still\nget a green bar in the GUI (not yellow) even in the prescense\nof tests ignored via this attribute. Other than that, it operates\nsimilarly to the Ignore attribute.\nThe point again is that you want to avoid any situation where\nyou begin to ignore failing tests out of habit. Platform en-\nsures that the proper tests are run only in the proper envi-\nronment.\nNow that you’ve got a good idea of how to write tests, it’s time\nto take a closer look at ﬁguring out what to test.\n7A comprehensive list of the platforms can be found in the NUnit docu-\nmentation on http://nunit.org.\n\n\nChapter 4\nWhat to Test:\nThe Right-BICEP\nNow that you know how to test, we need to spend some chap-\nters looking at what to test; or more precisely, the kinds of\nthings that might need testing.\nIt can be hard to look at a method or a class and try to come\nup with all the ways it might fail and to anticipate all the bugs\nthat might be lurking in there. With enough experience, you\nstart to get a feel for those things that are “likely to break,”\nand can effectively concentrate on testing in those areas ﬁrst.\nBut without a lot of experience, it can be hard and frustrating\ntrying to discover possible failure modes. End-users are quite\nadept at ﬁnding our bugs, but that’s both embarrassing and\ndamaging to our careers! What we need are some guidelines,\nsome reminders of areas that might be important to test.\nLet’s take a look at six speciﬁc areas to test that will help\nstrengthen your testing skills, using your RIGHT-BICEP:\n• Right — Are the results right?\n• B — Are all the boundary conditions CORRECT?\n• I — Can you check inverse relationships?\n• C — Can you cross-check results using other means?\n• E — Can you force error conditions to happen?\n",
      "page_number": 65
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 74-81)",
      "start_page": 74,
      "end_page": 81,
      "detection_method": "topic_boundary",
      "content": "ARE THE RESULTS RIGHT?\n61\n• P — Are performance characteristics within bounds?\n4.1\nAre the Results Right?\nThe ﬁrst and most obvious area to test is simply to see if the\nRight\nBICEP\nexpected results are right—to validate the results.\nIt’s a good starting point. We’ve seen simple data validation\nalready: the tests in Chapter 2 that verify that a method re-\nturns the largest number from a list.\nThese are usually the “easy” tests, and many of these sorts of\nvalidations may even be speciﬁed in the requirements. If they\naren’t, you’ll probably need to ask someone. You need to be\nable to answer the key question:\nIf the code ran correctly, how would I know?\nIf you cannot answer this question satisfactorily, then writing\nthe code—or the test—may be a complete waste of time. “But\nwait,” you may say, “that doesn’t sound very agile! What if\nthe requirements are vague or incomplete? Does that mean\nwe can’t write code until all the requirements are ﬁrm?”\nNo, not at all. If the requirements are truly not yet known,\nor complete, you can always invent some as a stake in the\nground.\nThey may not be correct from the user’s point of\nview, but you now know what you think the code should do,\nand so you can answer the question.\nOf course, you’ll then arrange for feedback with users to\nﬁne-tune your assumptions. The deﬁnition of “correct” may\nchange over the lifetime of the code in question, but at any\npoint, you should be able to prove (using automated tests)\nthat the code is doing what you think it ought.\nUsing Data Files\nFor sets of tests with large amounts of test data, you might\nwant to consider putting the test values and/or results in a\nseparate data ﬁle that the unit test reads in. This doesn’t need\nto be a very complicated exercise—and you don’t even need to\n\n\nARE THE RESULTS RIGHT?\n62\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\nusing System;\nusing System.IO;\nusing System.Collections.Generic;\n[TestFixture]\npublic class LargestDataFileTests\n{\nprivate int[] getNumberList(string line)\n{\nstring[] tokens = line.Split(null);\nList<int> numberList = new List<int>();\nfor (int i=1; i < tokens.Length; i++)\n{\nnumberList.Add(Int32.Parse(tokens[i]));\n}\nreturn numberList.ToArray();\n}\nprivate int getLargestNumber(string line)\n{\nstring[] tokens = line.Split(null);\nstring val = tokens[0];\nint expected = Int32.Parse(val);\nreturn expected;\n}\nprivate bool hasComment(string line)\n{\nreturn line.StartsWith(\"#\");\n}\n// Run all the tests in testdata.txt (does not test\n// exception case). We’ll get an error if any of the\n// file I/O goes wrong.\n[Test]\npublic void FromFile()\n{\nstring line;\n// most IDEs output the test bi-\nnary in bin/[Debug,Release]\nStreamReader reader =\nnew StreamReader(\"../../testdata.txt\");\nwhile ((line = reader.ReadLine()) != null)\n{\nif (hasComment(line))\n{\ncontinue;\n}\nint[] numberListForLine = getNumberList(line);\nint expectedLargestNumber = getLargestNumber(line);\nint actualLargestNumber = Cmp.Largest(numberListForLine));\nAssert.That(expectedLargestNumber, Is.EqualTo(actualLargestNumber));\n}\n}\n\n\nARE THE RESULTS RIGHT?\n63\nuse XML.1 Figure 4.1 on the preceding page is a version of\nTestLargest that reads in all of the tests from a data ﬁle.\nThe data ﬁle has a very simple format; each line contains a\nset of numbers. The ﬁrst number is the expected answer, the\nnumbers on the rest of the line are the arguments with which\nto test. We’ll allow a pound-sign (#) for comments, so that you\ncan put meaningful descriptions and notes in the test ﬁle.\nThe test ﬁle can then be as simple as:\n#\n# Simple tests:\n#\n9 7 8 9\n9 9 8 7\n9 9 8 9\n#\n# Negative number tests:\n#\n-7 -7 -8 -9\n-7 -8 -7 -8\n-7 -9 -7 -8\n#\n# Mixture:\n#\n7 -9 -7 -8 7 6 4\n9 -1 0 9 -7 4\n#\n# Boundary conditions:\n#\n1 1\n0 0\n2147483647 2147483647\n-2147483648 -2147483648\ntestdata.txt\nIn this example we’re only running one particular test (using\none assert), but you could extend that to run as many differ-\nent tests on the same data as practical.\nFor just a handful of tests (as in this example), the separate\ndata ﬁle approach is probably not worth the effort or the per-\nformance overhead of the ﬁle I/O. In cases where you can’t\njustify an external ﬁle, C#’s string literals paired with a Tex-\ntReader can provide the same beneﬁts described above with-\nout the less palatable aspects:\nstring oneCommentWithTwoSets = @\"\n1This is clearly a joke. XML is mandatory on all projects today, isn’t it?\n\n\nBOUNDARY CONDITIONS\n64\n# comment line\n9 7 8 9\n-9 9 8 7\n\"\nBut say this was a more advanced application, with tens or\neven hundreds of test cases in this form. Then the ﬁle ap-\nproach becomes a very compelling choice.\nBe aware that test data, whether it’s in a ﬁle or in the test\ncode itself, might well be incorrect. In fact, experience sug-\ngests that test data is more likely to be incorrect than the\ncode you’re testing, especially if the data was hand-calculated\nor obtained from a system we’re replacing (where new fea-\ntures may deliberately cause new results).\nWhen test data\nsays you’re wrong, double- and triple-check that the test data\nis right before attacking the code. Ask a co-worker to take a\nlook, or just take a break (away from the keyboard); some-\ntimes it’s difﬁcult to see the woods through the trees.\nSomething else to think about: the code as presented in this\nexample does not test any exception cases. How might you\nimplement that? Also notice that we wrote a non-test “helper”\nmethod to parse the numbers from the data ﬁle.\nIt’s per-\nfectly okay—even encouraged—to create support methods and\nclasses as needed. We might even extract these support meth-\nods into a TestFileParser class if we wanted to share this\ncode across different ﬁxtures, or just to unclutter the test\nclass itself.\nDo whatever makes it easiest for you to prove that the method\nis right.\n4.2\nBoundary Conditions\nIn the previous “largest number” example, we discovered sev-\nRight\nB ICEP\neral boundary conditions: when the largest value was at the\nend of the array, when the array contained a negative number,\nan empty array, and so on.\nIdentifying boundary conditions is one of the most valuable\nparts of unit testing, because this is where most bugs gener-\nally live—at the edges. These nether-regions of untested code\n\n\nBOUNDARY CONDITIONS\n65\nare where almost all exploitable security vulnerabilities come\nfrom.\nSome conditions you might want to think about:\n• Totally bogus or inconsistent input values, such as a ﬁle\nname of \"!*W:X\\&Gi/w∼>g/h#WQ@\".\n• Badly formatted data that is missing delimeters or ter-\nminators, such as an e-mail address without a top-level\ndomain (\"fred@foobar.\").2\n• Empty or missing values (such as 0, 0.0, an empty string,\nan empty array, or null), or missing in a sequence (such\nas a missing TCP packet).\n• Values far in excess of reasonable expectations, such as\na person’s age of 10,000 years or a password string with\n10,000 characters in it.\n• Duplicates in lists that shouldn’t have duplicates.\n• Ordered lists that aren’t, and vice-versa. Try handing a\npre-sorted list to a sort algorithm, for instance—or even\na reverse-sorted list.\n• Things that arrive out of order, or happen out of expected\norder, such as trying to print a document before logging\nin, or getting fragmented IP packets out of order, for in-\nstance.\nAn easy way to think of possible boundary conditions is to\nremember the acronym CORRECT. For each of these items,\nconsider whether or not similar conditions may exist in your\nmethod that you want to test, and what might happen if these\nconditions were violated:\n• Conformance — Does the value conform to an expected\nformat?\n• Ordering — Is the set of values ordered or unordered as\nappropriate?\n2A popular mail service suffered from an exploitable bug like this involving\na missing ’>’ in SMTP headers.\n\n\nCHECK INVERSE RELATIONSHIPS\n66\n• Range — Is the value within reasonable minimum and\nmaximum values?\n• Reference — Does the code reference anything external\nthat isn’t under direct control of the code itself?\n• Existence — Does the value exist (e.g., is non-null, non-\nzero, present in a set, etc.)?\n• Cardinality — Are there exactly enough values?\n• Time (absolute and relative) — Is everything happening\nin order? At the right time? In time?\nBecause boundary conditions are such an important area to\ntest, we’ll examine these in detail in the next chapter (which\nmakes Right-BICEP a nested acronym).\n4.3\nCheck Inverse Relationships\nRight B I CEP\nSome methods can be checked by applying their logical in-\nverse. For instance, you might check a method that calcu-\nlates a square root by squaring the result, and testing that it\nis tolerably close to the original number:\n[Test]\npublic void SquareRootUsingInverse() {\ndouble x = MyMath.SquareRoot(4.0);\nAssert.That(4.0, Is.EqualTo(x*x).Within(0.0001));\n}\nRootsTest.cs\nYou might check that some data was successfully inserted\ninto a database, then search for it, and then delete it. You\nmight transfer money into an account, then transfer the same\namount out of the account. Any of these operations apply an\n“inverse” to see if you get back to an original state.\nBut be cautious when you’ve written both the original routine\nand it’s inverse, as some bugs might be masked by a com-\nmon error in both routines. Where possible, use a different\nsource for the inverse test. In the square root example, we’re\njust using regular multiplication to test our method. For the\ndatabase search, we’ll probably use a vendor-provided delete\nroutine to test our insertion.\n\n\nCROSS-CHECK USING OTHER MEANS\n67\n4.4\nCross-check Using Other Means\nYou might also be able to cross-check results of your method\nRight BI C EP\nusing different means.\nUsually there is more than one way to calculate some quan-\ntity; we might pick one algorithm over the others because it\nperforms better, or has other desirable characteristics. That’s\nthe one we’ll use in production, but we can use one of the\nother versions to cross-check our results in the test system.\nThis technique is especially helpful when there’s a proven,\nknown way of accomplishing the task that happens to be too\nslow or too inﬂexible to use in production code.\nWe can use that somewhat lesser version to our advantage\nto check that our new super-spiffy version is producing the\nsame results:3\n[Test]\npublic void SquareRootUsingStd() {\ndouble number = 3880900.0;\ndouble root1 = MyMath.SquareRoot(number);\ndouble root2 = Math.Sqrt(number);\nAssert.That(root2, Is.EqualTo(root1).Within(0.0001));\n}\nRootsTest.cs\nAnother way of looking at this issue is to use different pieces\nof data from the class itself to make sure they all “add up,” or\nreconcile. That counts as a cross-check as well.\nFor instance,\nsuppose you were working on a library’s\ndatabase system (that is, a brick-and-mortar library that\nlends out real books). In this system, the number of copies\nof a particular book should always balance. That is, the num-\nber of copies that are checked out plus the number of copies\nsitting on the shelves should always equal the total number\nof copies in the collection. These are separate pieces of data,\nand may even be reported by objects of different classes, but\nthey still have to agree, and so can be used to cross-check one\nanother.\n3Some spreadsheet engines (as found in Microsoft ExcelTM, etc.) employ\nsimilar techniques to check that the models and methods chosen to solve\na particular problem are appropriate, and that the answers from different\napplicable methods agree with each other.\n\n\nFORCE ERROR CONDITIONS\n68\nAs with the inverse checks above, make sure you aren’t simply\nexercising the same underlying code in two different ways—\nthe point of cross-checking is to explicitly use different code\nto verify the same result.\n4.5\nForce Error Conditions\nIn the real world, errors happen. Disks ﬁll up, network lines\nRight BIC E P\ndrop, e-mail goes into a black hole, and programs crash. You\nshould be able to test that your code handles all of these real-\nworld problems by forcing errors to occur.\nThat’s easy enough to do with invalid parameters and the like,\nbut to simulate speciﬁc network errors—without unplugging\nany cables—takes some special techniques. We’ll discuss one\nway to do this using Mock Objects in Chapter 6 on page 90.\nBut before we get there, consider what kinds of errors or other\nenvironmental constraints you might introduce to test your\nmethod? Make a short list before reading further.\nSTOP\nThink about this for a moment before reading on. . .\nHere are a few environmental things we’ve thought of.\n• Running out of memory\n• Running out of disk space\n• Issues with wall-clock time\n• Network availability and errors\n• Insufﬁcient File or Path permissions\n• System load\n• Limited color palette\n• Very high or very low video resolution\nThese are just general categories, for each of them there may\nbe more subtle issues worth testing. For instance, you might\ntest that the code can handle the case when the network itself\ngoes down, but what about if the network is up and the DNS\n",
      "page_number": 74
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 82-89)",
      "start_page": 82,
      "end_page": 89,
      "detection_method": "topic_boundary",
      "content": "PERFORMANCE CHARACTERISTICS\n69\nserver is down? Or the network is up, but slowed to a timeout-\ninducing crawl due to a denial of service attack? These things\nhappen, and if our code needs to handle these sort of errors,\nthen we need to test for them. If our code isn’t supposed to\nhandle these sorts of errors, we should still write a test that\nvalidates that behaviour using the ExpectedException we\npreviously discussed.\n4.6\nPerformance Characteristics\nOne area that might prove beneﬁcial to examine is perfor-\nRight BICE P\nmance characteristics—not performance itself, but trends as\ninput sizes grow, as problems become more complex, and so\non.\nWhat we’d like to achieve is a quick regression test of per-\nformance characteristics. All too often, we might release one\nversion of the system that works okay, but somehow by the\nnext release it has become dead-dog slow.\nWe don’t know\nwhy, or what change was made, or when, or who did it, or\nanything. And the end users are screaming bloody murder.\nTo avoid that awkward scenario, you might consider some\nrough tests just to make sure that the performance curve re-\nmains stable. For instance, suppose we’ve written a ﬁlter that\nidentiﬁes web sites that we wish to block (using our new prod-\nuct to view naughty pictures might get us in all sorts of legal\ntrouble, after all.)\nThe code works ﬁne with a few dozen sample sites, but will it\nwork as well with 10,000? 100,000? Let’s write a unit test to\nﬁnd out.\nLine 1\n[TestFixture]\n-\npublic class FilterTest\n-\n{\n-\nTimer timer;\nString naughty_url = \"http://www.xxxxxxxxx.com\";\n5\nURLFilter filter;\n-\n-\n[SetUp]\n-\npublic void Initialize()\n-\n{\n10\ntimer = new Timer();\n-\n}\n-\n-\n[Test]\n\n\nPERFORMANCE CHARACTERISTICS\n70\n-\npublic void SmallList()\n15\n{\n-\nfilter = new URLFilter(SMALL_LIST);\n-\ntimer.Start();\n-\nfilter.Check(naughty_url);\n-\ntimer.End();\n20\nAssert.That(timer.ElapsedTime, Is.LessThan(1.0));\n-\n}\n-\n}\n-\n[Test]\n-\n[Category(\"Long\")]\n25\npublic void HugeList()\n-\n{\n-\nfilter = new URLFilter(HUGE_LIST);\n-\ntimer.Start();\n-\nfilter.Check(naughty_url);\n30\ntimer.End();\n-\nAssert.That(timer.ElapsedTime, Is.LessThan(10.0));\n-\n}\n-\n}\nFilterTest.cs\nThis gives us some assurance that we’re still meeting perfor-\nmance targets. But because this one test takes 6–7 seconds to\nrun, we may not want to run it every time. As long as we run\nit in our automated build at least every couple of days, we’ll\nquickly be alerted to any problems we may introduce, while\nthere is still time to ﬁx them.\n\n\nChapter 5\nCORRECT\nBoundary Conditions\nAs we said in the last chapter, boundary conditions are such\na vibrant source of bugs that we need a whole chapter to talk\nabout them. Many bugs in code occur around boundary con-\nditions, that is, under conditions where the code’s behavior\nmay be different from the normal, day-to-day routine.\nFor instance, suppose we have a function that takes two inte-\ngers:\npublic int Calculate(int a, int b) {\nreturn a / (a+b);\n}\nRootsTest.cs\nMost of the time, this code will return a number just as we\nexpect. But if the sum of a and b happens to equal zero, we\nwill get a DivideByZeroException instead of a return value.\nThat is a boundary condition—at the edge of normal expecta-\ntions. It’s a place where things might suddenly go wrong, or\nat least behave differently from what we wanted.\nTo help us think of tests for boundary conditions, we’ll use\nthe acronym CORRECT:\n• Conformance—Does the value conform to an expected\nformat?\n\n\nCONFORMANCE\n72\n• Ordering—Is the set of values ordered or unordered as\nappropriate?\n• Range—Is the value within reasonable minimum and\nmaximum values?\n• Reference—Does the code reference anything external\nthat isn’t under direct control of the code itself?\n• Existence—Does the value exist (e.g., is non-null, non-\nzero, present in a set, etc.)?\n• Cardinality—Are there exactly enough values?\n• Time (absolute and relative)—Is everything happening in\norder? At the right time? In time?\nLet’s look at each one of these in turn. Remember that for\neach of these areas, you want to consider data that is passed\nin as arguments to your method as well as internal data that\nyou maintain inside your method and class.\nThe underlying question that we want to answer fully is:\nWhat else can go wrong?\nOnce you think of something that could go wrong, write a test\nfor it. Once that test passes, again ask yourself, “what else\ncan go wrong?” and write another test, and so on.\nThere’s always something else that could go wrong, and these\nare some of the more productive areas to consider.\n5.1\nConformance\nMany times you expect or produce data that must conform to\nC ORRECT\nsome speciﬁc format. An e-mail address, for instance, isn’t\njust a simple string. You expect that it must be of the form:\nname@somewhere.com\nWith the possibility of extra dotted parts:\nfirstname.lastname@subdomain.somewhere.com\nAnd even oddballs like this one:\nfirstname.lastname%somewhere@subdomain.somewhere.com\n\n\nCONFORMANCE\n73\nSuppose you are writing a method that will extract the user’s\nname from their e-mail address. You’ll expect that the user’s\nname is the portion before the “@” sign. What will your code\ndo if there is no “@” sign? Will it work? Throw an exception?\nWhat about multiple “@” signs or a string of only @” signs? Is\nthis a boundary condition you need to consider?1\nValidating formatted string data such as e-mail addresses,\nphone numbers, account numbers, or ﬁle names is usually\nstraightforward, but be aware of internationalization issues:\nnot only could there be issues with the format (many coun-\ntries don’t have states or provinces), but issues with character\nencoding as well.2 Will you be getting unicode data, and if so,\nwill you be able to handle it?\nThen there’s more complex, structured data to consider. Sup-\npose you are reading report data that contains a header record\nlinked to a number of data records, and ﬁnally to a trailer\nrecord. How many conditions might we have to test?\n• What if there’s no header, just data and a trailer?\n• What if there’s no data, just a header and trailer?\n• What if there’s no trailer, just a header and data?\n• What if there’s just a trailer?\n• What if there’s just a header?\n• What if there’s just data?\nJust as with the simpler e-mail address example, you have\nto consider what will happen if the data does not conform to\nthe structure you think it should. This directly applies to any\ncode that parses ﬁle formats or network protocols, avenues\nby which attacks will come either on purpose or unwittingly.\nIt’s best to code defensively and verify the defenses with unit\ntests,3 since an attacker will probably end up testing them for\nyou eventually whether we want them to or not.\n1E-mail addresses are actually very complicated.\nA close reading of\nRFC822 may surprise you.\n2Input validation should always be done on model objects, sometimes in\naddition to the UI validation.\n3A fun way to think about this is, “How would I attack this function?”\n\n\nORDERING\n74\nAnd of course, if you are creating data (not just validating\nit) such as an e-mail address (possibly building it up from\ndifferent sources) or the structured data above, you want to\ntest your result to make sure it conforms as well.\n5.2\nOrdering\nAnother area to consider is the order of data, or the position\nC O RRECT\nof one piece of data within a larger collection. For instance,\nin the Largest() example in the previous chapter, one bug\nmanifested itself depending on whether the largest number\nyou were searching for was at the beginning or end of the list.\nThat’s one aspect of ordering.\nAny kind of search routine\nshould be tested for conditions where the search target is ﬁrst\nor last, as many common bugs can be found that way.\nFor another aspect of ordering, suppose you are writing a\nmethod that is passed a collection containing a restaurant\norder. You would probably expect that the appetizers will ap-\npear ﬁrst in the order, followed by the salad (and that all-\nimportant dressing choice), then the entree and ﬁnally a deca-\ndent dessert involving lots of chocolate.\nWhat happens to your code if the dessert is ﬁrst, and the\nentree is last?\nIf there’s a chance that sort of thing can happen, and if it’s the\nresponsibility of your method to deal with it if it does, then you\nneed to test for this condition and address the problem. Now,\nit may be that this is not something your method needs to\nworry about. Perhaps this needs to be addressed at the user\ninput level (see “Testing Invalid Parameters” later on, and the\nchapter on GUI testing on page 165. Bear in mind that busi-\nness logic does not belong in the GUI itself–ever. User inter-\nface components (graphical or otherwise) should only contain\ncode for the UI, not for anything else.\nIf you’re writing a sort routine, what might happen if the set of\ndata is already ordered? Or worse yet, sorted in precisely re-\nverse order? Ask yourself if that could cause trouble—if these\nare conditions that might be worth testing, too. Then test it\nanyway, you may be surprised to ﬁnd it makes a difference.\n\n\nRANGE\n75\nIf you are supposed to maintain something in order, verify that\nit is. For example, if your method is part of the GUI that is\nsending the dinner order back to the kitchen, you should have\na test that veriﬁes that the items are in the correct serving\norder:\n[Test]\npublic void KitchenOrder()\n{\nOrder order = new Order();\nFoodItem dessert = new Dessert(\"Chocolate Decadence\");\nFoodItem entree = new Entree(\"Beef Oscar\");\nFoodItem salad\n= new Salad(\"Parmesan Peppercorn\");\n// Add out of order\norder.AddFoodItem(dessert);\norder.AddFoodItem(entree);\norder.AddFoodItem(salad);\n// But should come out in serving order\nIEnumerator itr = order.GetEnumerator();\nAssert.That(salad, Is.EqualTo(itr.Current));\nitr.MoveNext();\nAssert.That(entree, Is.EqualTo(itr.Current));\nitr.MoveNext();\nAssert.That(dessert, Is.EqualTo(itr.Current));\nitr.MoveNext();\n// No more left\nAssert.That(itr.MoveNext(), Is.False);\n}\nKitchenTest.cs\nOf course, from a human factors standpoint, you’d need to\nmodify the code so that it’s ﬂexible enough to allow people to\neat their ice cream ﬁrst, if so desired. In which case, you’d\nneed to add a test to prove that your four-year old nephew’s\nice cream comes with everyone else’s salads, but Grandma’s\nice cream comes at the end with your cappuccino.\n5.3\nRange\nRange is a convenient catch-all word for the situation where a\nCO R RECT\nvariable’s type allows it to take on a wider range of values than\nyou need—or want. For instance, a person’s age is typically\nrepresented as an integer, but no one has ever lived to be\n200,000 years old, even though that’s a perfectly valid integer\nvalue. Similarly, there are only 360 degrees in a circle, even\nthough degrees are commonly stored in an integer.\n\n\nRANGE\n76\nIn good object oriented design, you do not use a built-in value\ntype (e.g., an int or Int32) to store a bounded-integer value\nsuch as an age, or a compass heading.\nusing System;\n//\n// Compass bearing\n//\npublic class Bearing {\nprotected int bearing; // 0..359\n//\n// Initialize a bearing to a value from 0..359\n//\npublic Bearing(int num_degrees) {\nif (num_degrees < 0 || num_degrees > 359) {\nthrow new ArgumentException(\"Bad bearing\");\n}\nbearing = num_degrees;\n}\n//\n// Return the angle between our bearing and another.\n// May be negative.\n//\npublic int AngleBetween(Bearing anOther) {\nreturn bearing - anOther.bearing;\n}\n}\nBearing.cs\nNotice that the angle returned is just an int—a plain old num-\nber, as we are not placing any range restrictions on the result\n(it may be negative, etc.)\nBy encapsulating the concept of a bearing within a class,\nyou’ve now got one place in the system that can ﬁlter out bad\ndata. You cannot create a Bearing object with out of range\nvalues. Thus, the rest of the system can use Bearing objects\nand be assured that they contain only reasonable values.4\nOther ranges may not be as straightforward. For instance,\nsuppose you have a class that maintains two sets of x, y co-\nordinates. These are just integers, with arbitrary values, but\nthe constraint on the range is such that the two points must\ndescribe a rectangle with no side greater than 100 units. That\nis, the allowed range of values for both x, y pairs is interdepen-\n4For types like these, a struct might be preferred if you have a deep\nenough knowledge of the CLR to care.[Ric06]\n",
      "page_number": 82
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 90-97)",
      "start_page": 90,
      "end_page": 97,
      "detection_method": "topic_boundary",
      "content": "RANGE\n77\ndent. You’ll want a range test for any method that can affect a\ncoordinate to ensure that the resulting range of the x, y pairs\nremains legitimate. For more information on this topic, see\n“invariants” in the Design Issues chapter on page 143.\nSince you will likely call this from a number of different tests,\nit probably makes sense to make a new assert method:\npublic const int MAX_DIST = 100;\nstatic public void AssertPairInRange(Point one,\nPoint two,\nString message)\n{\nAssert.That(\nMath.Abs(one.X - two.X),\nIs.AtMost(MAX_DIST),\nmessage\n);\nAssert.That(\nMath.Abs(one.Y - two.Y),\nIs.AtMost(MAX_DIST),\nmessage\n);\n}\nPairTest.cs\nBut the most common ranges you’ll want to test probably de-\npend on physical data structure issues, not application do-\nmain constraints. Take a simple example like a stack class\nthat implements a stack of Strings using an array:\npublic class MyStack\n{\npublic MyStack()\n{\nelements = new string[100];\nnextIndex = 0;\n}\npublic String Pop()\n{\nreturn elements[--nextIndex];\n}\n// Delete n items from the elements en-masse\npublic void Delete(int n)\n{\nnextIndex -= n;\n}\npublic void Push(string element)\n{\nelements[nextIndex++] = element;\n}\npublic String Top()\n\n\nRANGE\n78\n{\nreturn elements[nextIndex-1];\n}\nprivate int nextIndex;\nprivate string[] elements;\n}\nMyStack.cs\nThere are some potential bugs lurking here, as there are no\nchecks at all for either an empty stack or a stack overﬂow.\nHowever we manipulate the index variable nextIndex, one\nthing is supposed to be always true: (next_index >= 0 &&\nnext_index < stack.Length). We’d like to check to make\nsure this expression is true.\nBoth nextIndex and stack are private variables; you don’t\nwant to have to expose those just for the sake of testing. There\nare several ways around this problem; for now we’ll just make\na special method in MyStack named CheckInvariant():\npublic void CheckInvariant()\n{\nif (!(nextIndex >= 0 &&\nnextIndex\n< elements.Length))\n{\nthrow new InvariantException(\n\"nextIndex out of range: \"\n+\nnextIndex +\n\" for elements length \" + elements.Length);\n}\n}\nMyStack.cs\nNow a test method can call CheckInvariant() to ensure that\nnothing has gone awry inside the guts of the stack class, with-\nout having direct access to those same guts.5\nusing NUnit.Framework;\n[TestFixture]\npublic class MyStackTest\n{\n[Test]\npublic void Empty()\n{\nMyStack stack = new MyStack();\nstack.CheckInvariant();\nstack.Push(\"sample\");\nstack.CheckInvariant();\n// Popping last element ok\n5You’d normally use an InvalidOperationException, but in this case\nwe want to reinforce the invariant concept by using a custom exception.\n\n\nREFERENCE\n79\nAssert.That(\nstack.Pop(),\nIs.EqualTo(\"sample\")\n);\nstack.CheckInvariant();\n// Delete from empty stack\nstack.Delete(1);\nstack.CheckInvariant();\n}\n}\nMyStackTest.cs\nWhen you run this test, you’ll quickly see that we need to add\nsome range checking!\nTestCase ’MyStackTest.Empty’ failed: InvariantException\nnextIndex out of range: -1 for stack length 100\nmystack.cs(34,0): at MyStack.CheckInvariant()\nmystacktest.cs(20,0): at MyStackTest.Empty()\nIt’s much easier to ﬁnd and ﬁx this sort of error here in a sim-\nple testing environment instead of buried in a real application.\nAlmost any indexing concept (whether it’s a genuine integer\nindex or not) should be extensively tested.\nHere are a few\nideas to get you started:\n• Start and End index have the same value\n• First is greater than Last\n• Index is negative\n• Index is greater than allowed\n• Count doesn’t match actual number of items\n• . . .\n5.4\nReference\nWhat things does your method reference that are outside the\nCOR R ECT\nscope of the method itself? Any external dependencies? What\nstate does the class have to be in?\nWhat other conditions\nmust exist in order for the method to work?\nFor example, a method in a web application to display a cus-\ntomer’s account history might require that the customer is\nﬁrst logged on. The method Pop() for a stack requires a non-\n\n\nREFERENCE\n80\nempty stack. Shifting the transmission in your car to Park\nfrom Drive requires that the car is stopped.\nIf you have to make assumptions about the state of the class\nand the state of other objects or the global application, then\nyou need to test your code to make sure that it is well-behaved\nif those conditions are not met.\nFor example, the code for\nthe microprocessor-controlled transmission might have unit\ntests that check for that particular condition: the state of the\ntransmission (whether it can shift into Park or not) depends\non the state of the car (is it in motion or stopped).\n[Test]\npublic void JamItIntoPark()\n{\ntransmission.Shift(DRIVE);\ncar.AccelerateTo(35);\nAssert.That(\ntransmission.CurrentGear,\nIs.EqualTo(DRIVE)\n);\n// should silently ignore\ntransmission.Shift(PARK);\nAssert.That(\ntransmission.CurrentGear,\nIs.EqualTo(DRIVE)\n);\ncar.AccelerateTo(0); // i.e., stop\ncar.BrakeToStop();\n// should work now\ntransmission.Shift(PARK);\nAssert.That(\ntransmission.CurrentGear,\nIs.EqualTo(PARK)\n);\n}\nThe preconditions for a given method specify what state the\nworld must be in for this method to run. In this case, the pre-\ncondition for putting the transmission in park is that the car’s\nengine (a separate component elsewhere in the application’s\nworld) must be at a stop. That’s a documented requirement\nfor the method, so we want to make sure that the method\nwill behave gracefully (in this particular case, just ignore the\nrequest silently) in case the precondition is not met.\nAt the end of the method, postconditions are those things that\nyou guarantee your method will make happen. Direct results\n\n\nEXISTENCE\n81\nreturned by the method are one obvious thing to check, but if\nthe method has any side-effects then you need to check those\nas well. In this case, applying the brakes has the side effect\nof stopping the car.\nSome languages even have built-in support for preconditions\nand postconditions; interested readers might want to read\nabout the original Eiffel in Object-Oriented Software Construc-\ntion [Mey97], or take a look at nContract,6 which can add\nsimilar capabilities to C#.7\n5.5\nExistence\nA large number of potential bugs can be discovered by asking\nCORR E CT\nthe key question “does some given thing exist?”.\nFor any value you are passed in or maintain, ask yourself\nwhat would happen to the method if the value didn’t exist—if\nit were null, or blank, or zero, or an empty string, or an empty\ncollection.\nMany C# library methods will throw an exception of some sort\nwhen faced with non-existent data. The problem is that it’s\nhard to debug a generic runtime exception thrown from the\ndepths of some library. But a speciﬁc exception that reports\n“Age isn’t set” makes tracking down the problem much easier.\nMost methods will blow up if expected data is not available,\nand that’s probably not what you want them to do. So you\ntest for the condition—see what happens if you get a null in-\nstead of a CustomerRecord because some search failed. See\nwhat happens if the ﬁle doesn’t exist, or if the network is un-\navailable.\nAh, yes: things in the environment can wink out of existence\nas well—networks, ﬁles’ URLs, license keys, users, printers,\npermissions that had been ﬁne last time you checked—you\nname it. All of these things may not exist when you expect\n6http://puzzleware.net/nContract/nContract.html\n7There\nare\nother\nefforts\nfor\nother\nlanguages\nas\nwell,\nsuch\nas\nhttp://dbc.rubyforge.org for C and http://icontract2.org for Java.\n\n\nCARDINALITY\n82\nthem to, so be sure to test with plenty of nulls, zeros, empty\nstrings and other nihilist trappings.\nMake sure your method can stand up to everything which,\nfunnily enough, includes nothing.\n5.6\nCardinality\nCardinality has nothing to do with either highly-placed reli-\nCORRE C T\ngious ﬁgures or small red birds, but instead with counting.\nComputer programmers (your humble authors included) are\nreally bad at counting, especially past 10 when the ﬁngers\ncan no longer assist us. For instance, answer the following\nquestion quickly, off the top of your head, without beneﬁt of\nﬁngers, paper, or UML:\nIf you’ve got 12 feet of lawn that you want to fence,\nand each section of fencing is 3 feet wide, how many\nfence posts do you need?\nIf you’re like most of us, you probably answered “4” without\nthinking too hard about it. Pity is, that’s wrong—you need ﬁve\nfence posts as shown in Figure 5.1 on page 84. This model,\nand the subsequent common errors, come up so often that\nthey are graced with the name “fence post errors.”\nIt’s one of many ways you can end up being “off by one;” an\noccasionally fatal condition that afﬂicts all programmers from\ntime to time. So you need to think about ways to test how\nwell your method counts, and check to see just how many of\na thing you may have.\nIt’s a related problem to Existence, but now you want to make\nsure you have exactly as many as you need, or that you’ve\nmade exactly as many as needed. In most cases, the count of\nsome set of values is only interesting in these three cases:\n1. Zero\n2. One\n3. More than one\nIt’s called the “0–1–n Rule,” and it’s based on the premise that\nif you can handle more than one of something, you can prob-\nably handle 10, 20, or 1,000 just as easily. Most of the time\n\n\nCARDINALITY\n83\nthat’s true, so many of our tests for cardinality are concerned\nwith whether we have 2 or more of something. Of course there\nare situations where an exact count makes a difference—10\nmight be important to you, or 260.\n(Why 260?\nThat’s the\ndeﬁned value for MAX_PATH in windows.h, and so turns out\nto be a good boundary condition for ﬁnding string truncation\nand buffer overﬂow issues in underlying native code.)\nSuppose you are maintaining a list of the Top-Ten food items\nordered in a pancake house. Every time an order is taken, you\nhave to adjust the top-ten list. You also provide the current\ntop-ten list as a real-time data feed to the pancake boss’s PDA.\nWhat sort of things might you want to test for?\n• Can you produce a report when there aren’t yet ten items\nin the list?\n• Can you produce a report when there are no items on\nthe list?\n• Can you produce a report when there is only one item on\nthe list?\n• Can you add an item when there aren’t yet ten items in\nthe list (but more than one)?\n• Can you add an item when there is only one item on the\nlist?\n• Can you add an item when there are already ten items\non the list?\n• What if there aren’t ten items on the menu?\n• What if there are no items on the menu?\nHaving gone through all that, the boss now changes his mind\nand wants a top-twenty list instead.\nWhat do you have to\nchange?\nThe correct answer is “one line,” something like the following:\npublic MaxEntries {\nget { return 20; }\n}\nNow, when the boss gets overwhelmed and pleads with you to\nchange this to be a top-ﬁve report (his PDA is pretty small, af-\n\n\nTIME\n84\n12 feet\r\n3 feet\r\n3 feet\r\n3 feet\r\n3 feet\r\n1\r\n5\r\n4\r\n3\r\n2\r\nFigure 5.1: A Set of Fence posts\nter all), you can go back and change this one number. The test\nshould automatically follow suit, because it uses the same\nproperty.\nSo in the end, the tests concentrate on boundary conditions\nof 0, 1, and n, where n can—and will—change as the business\ndemands.\n5.7\nTime\nThe last boundary condition in the CORRECT acronym is\nCORREC T\nTime.\nThere are several aspects to time you need to keep\nin mind:\n• Relative time (ordering in time)\n• Absolute time (elapsed and wall clock)\n• Concurrency issues\nSome interfaces are inherently stateful; you expect that Lo-\ngin() will be called before Logout(), that PrepareState-\nment() is called before ExecuteStatement(), Connect() be-\nfore Read() which is before Close(), and so on.\n",
      "page_number": 90
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 98-105)",
      "start_page": 98,
      "end_page": 105,
      "detection_method": "topic_boundary",
      "content": "TIME\n85\nWhat happens if those methods are called out of order? Maybe\nyou should try calling methods out of the expected order. Try\nskipping the ﬁrst, last and middle of a sequence to ﬁnd these\nkind of temporal dependencies.\nJust as order of data may\nhave mattered to you in the earlier examples (as we described\nin “Ordering” on page 74), now it’s the order of the calling\nsequence of methods.\nRelative time might also include issues of timeouts in the\ncode: how long your method is willing to wait for some ephem-\neral resource to become available.\nAs we’ll discuss shortly,\nyou’ll want to exercise possible error conditions in your code,\nincluding things such as timeouts.\nMaybe you’ve got con-\nditions that aren’t guarded by timeouts—can you think of a\nsituation where the code might get “stuck” waiting forever for\nsomething that might not happen?\nThis leads us to issues of elapsed time. What if something you\nare waiting for takes “too much” time? What if your method\ntakes too much time to return to the caller?\nThen there’s the actual wall clock time to consider. Most of\nthe time, this makes no difference whatsoever to code. But\nevery now and then, time of day will matter, perhaps in subtle\nways. Here’s a quick statement, is it true or false: every day\nof the year is 24 hours long?8\nThe answer is “it depends.”\nIn UTC (Universal Coordinated\nTime, the modern version of Greenwich Mean Time, or GMT),\nthe answer is yes. In areas of the world that do not observe\nDaylight Savings Time (DST), the answer is yes. In most of\nthe U.S. (which does observe DST), the answer is no. In April,\nyou’ll have a day with 23 hours (spring forward) and in Oc-\ntober you’ll have a day with 25 (fall back). This means that\narithmetic won’t always work as you expect; 1:45AM plus 30\nminutes might equal 1:15, for instance.\nBut you’ve tested any time-sensitive code on those boundary\ndays, right? For locations that honor DST and for those that\ndo not?\n8Ignoring leap seconds for now, we’re just talking about whole hours.\n\n\nTRY IT YOURSELF\n86\nOh, and don’t assume that any underlying library handles\nthese issues correctly on your behalf. Unfortunately, when it\ncomes to time, there’s a lot of broken code out there. And leap\nseconds do make a difference.\nFinally, one of the most insidious problems brought about\nby time occurs in the context of concurrency and synchro-\nnized access issues.\nIt would take an entire book to cover\ndesigning, implementing, and debugging multi-threaded, con-\ncurrent programs, so we won’t take the time now to go into de-\ntails, except to point out that most code you write in most lan-\nguages today will be run in a multi-threaded, multi-processor\nenvironment (see the section in on page 187 for an interesting\n“Gotcha” in C#).\nSo ask yourself, what will happen if multiple threads use this\nsame object at the same time? Are there global or instance-\nlevel data or methods that need to be synchronized?\nHow\nabout external access to ﬁles or hardware? Be sure to add\nthe lock keyword to any property or method that needs it,\nand try ﬁring off multiple threads as part of your test.\n5.8\nTry It Yourself\nNow that we’ve covered the Right-BICEP and CORRECT way\nto come up with tests, it’s your turn to try.\nFor each of the following examples and scenarios, write down\nas many possible unit tests as you can think of.\nExercises\n1.\nA simple stack class.\nPush String objects onto the stack,\nAnswer\non 196\nand Pop them off according to normal stack semantics. This\nclass provides the following methods:\nusing System;\npublic interface StackExercise {\n/// <summary>\n/// Return and remove the most recent item from\n/// the top of the\nstack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n\n\nTRY IT YOURSELF\n87\n/// </exception>\nString Pop();\n/// <summary>\n/// Add an item to the top of the stack.\n/// </summary>\n/// <param name=\"item\">A String to push\n/// on the stack</param>\nvoid Push(String item);\n/// <summary>\n/// Return but do not remove the most recent\n/// item from the top of the stack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n/// </exception>\nString Top();\n/// <summary>\n/// Returns true if the stack is empty.\n/// </summary>\nbool IsEmpty();\n}\nStackExercise.cs\nHere are some hints to get you started: what is likely to break?\nHow should the stack behave when it is ﬁrst initialized? After\nit’s been used for a while? Does it really do what it claims to\ndo?\n2.\nA shopping cart. This class lets you add, delete, and count\nAnswer\non 197\nthe items in a shopping cart.\nWhat sort of boundary conditions might come up? Are there\nany implicit restrictions on what you can delete? Are there any\ninteresting issues if the cart is empty?\npublic interface ShoppingCart {\n/// <summary>\n/// Add this many of this item to the\n/// shopping cart.\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\nvoid AddItems(Item anItem, int quantity);\n/// <summary>\n/// Delete this many of this item from the\n/// shopping cart\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\n/// <exception cref=\"NoSuchItemException\">\n/// </exception>\nvoid DeleteItems(Item anItem, int quantity);\n\n\nTRY IT YOURSELF\n88\n/// <summary>\n/// Count of all items in the cart\n/// (that is, all items x qty each)\n/// </summary>\nint ItemCount { get; }\n/// Return iterator of all items\nIEnumerable GetEnumerator();\n}\nShoppingCart.cs\n3.\nA fax scheduler. This code will send faxes from a speciﬁed ﬁle\nAnswer\non 198\nname to a U.S. phone number. There is a validation require-\nment; a U.S. phone number with area code must be of the form\nxnn-nnn-nnnn, where x must be a digit in the range [2..9] and\nn can be [0..9]. The following blocks are reserved and are not\ncurrently valid area codes: x11, x9n, 37n, 96n.\nThe method’s signature is:\n///\n/// Send the named file as a fax to the\n/// given phone number.\n/// <exception cref=\"MissingOrBadFileException\">\n/// </exception>\n/// <exception cref=\"PhoneFormatException\">\n/// </exception>\n/// <exception cref=\"PhoneAreaCodeException\">\n/// </exception>\npublic bool SendFax(String phone, String filename)\nGiven these requirements, what tests for boundary conditions\ncan you think of?\n4.\nAn automatic sewing machine that does embroidery. The\nAnswer\non 199\nclass that controls it takes a few basic commands.\nThe co-\nordinates (0,0) represent the lower-left corner of the machine.\nx and y increase as you move toward the upper-right corner,\nwhose coordinates are x = TableSize.Width - 1 and y = Ta-\nbleSize.Height - 1.\nCoordinates are speciﬁed in fractions of centimeters.\npublic void MoveTo(double x, double y);\npublic void SewTo(double x, double y);\npublic void SetWorkpieceSize(double width,\ndouble height);\npublic Size WorkpieceSize { get; }\npublic Size TableSize { get; }\nThere are some real-world constraints that might be interest-\ning: you can’t sew thin air, of course, and you can’t sew a\nworkpiece bigger than the machine.\n\n\nTRY IT YOURSELF\n89\nGiven these requirements, what boundary conditions can you\nthink of?\n5.\nAudio/Video Editing Transport. A class that provides meth-\nAnswer\non 200\nods to control a VCR or tape deck.\nThere’s the notion of a\n“current position” that lies somewhere between the beginning\nof tape (BOT) and the end of tape (EOT).\nYou can ask for the current position and move from there to\nanother given position. Fast-forward moves from current posi-\ntion toward EOT by some amount. Rewind moves from current\nposition toward BOT by some amount.\nWhen tapes are ﬁrst loaded, they are positioned at BOT auto-\nmatically.\nusing System;\npublic interface AVTransport {\n/// Move the current position ahead by this many\n/// seconds. Fast-forwarding past end-of-tape\n/// leaves the position at end-of-tape\nvoid FastForward(double seconds);\n/// Move the current position backwards by this\n/// many seconds. Rewinding past zero leaves\n/// the position at zero\nvoid Rewind(double seconds);\n/// Return current time position in seconds\ndouble CurrentTimePosition();\n/// Mark the current time position with label\nvoid MarkTimePosition(String name);\n/// Change the current position to the one\n/// associated with the marked name\nvoid GotoMark(String name);\n}\nAVTransport.cs\n6.\nAudio/Video Editing Transport, Release 2.0. As above, but\nAnswer\non 201\nnow you can position in seconds, minutes, or frames (there are\nexactly 30 frames per second in this example), and you can\nmove relative to the beginning or the end.\n\n\nChapter 6\nUsing Mock Objects\nThe objective of unit testing is to exercise just one behav-\nior at a time, but what happens when the method contain-\ning that behavior depends on other things—hard-to-control\nthings such as the network, or a database, or even special-\nized hardware?\nWhat if our code depends on other parts of the system—maybe\neven many other parts of the system? If you’re not careful,\nyou might ﬁnd yourself writing tests that end up (directly or\nindirectly) initializing nearly every system component just to\ngive the tests enough context in which to run. Not only is this\ntime consuming, it also introduces a ridiculous amount of\ncoupling into the testing process: someone goes and changes\nan interface or a database table, and suddenly the setup code\nfor our poor little unit test dies mysteriously. With this kind of\ncoupling, sometimes simply adding a new test can cause other\ntests to fail. Even the best-intentioned developers will become\ndiscouraged after this happens a few times, and eventually\nmay abandon all testing.\nBut there are techniques we can\nuse to help.\nIn movie and television production, crews will often use stand-\nins or doubles for the real actors.\nIn particular, while the\ncrews are setting up the lights and camera angles, they’ll\nuse lighting doubles: inexpensive, unimportant people who\nare about the same height and complexion as the expensive,\nimportant actors lounging safely in their luxurious trailers.\n\n\nCHAPTER 6. USING MOCK OBJECTS\n91\nThe crew then tests their setup with the lighting doubles,\nmeasuring the distance from the camera to the stand-in’s\nnose, adjusting the lighting until there are no unwanted shad-\nows, and so on, while the obedient stand-in just stands there\nand doesn’t whine or complain about “lacking motivation” for\ntheir character in this scene.\nSo what we’re going to do in unit testing is similar to the use\nof lighting doubles in the movies: we’ll use a cheap stand-in\nthat is kind of close to the real thing, at least superﬁcially, but\nthat will be easier to work with for our nefarious unit testing\npurposes.\nFortunately, there’s a testing pattern that can help: mock ob-\njects.\nA mock object is simply a testing replacement for a\nreal-world object. There are a number of situations that come\nup where mock objects can help us. Tim Mackinnon [MFC01]\noffers the following list:\n• The real object has nondeterministic behavior (it pro-\nduces unpredictable results, like a stock-market quote\nfeed.)\n• The real object is difﬁcult to set up, like requiring a cer-\ntain ﬁle system, database, or network environment.\n• The real object has behavior that is hard to trigger (for\nexample, a network error).\n• The real object is slow.\n• The real object has (or is) a user interface.\n• The test needs to ask the real object about how it was\nused (for example, a test might need to conﬁrm that a\ncallback function was actually called).\n• The real object does not yet exist (a common problem\nwhen interfacing with other teams or new hardware sys-\ntems).\nUsing mock objects, we can get around all of these problems.\nThe three key steps to using mock objects for testing are:\n1. Use an interface to describe the relevant methods on the\nobject\n\n\nSTUBS\n92\n2. Implement the interface for production code\n3. Implement the interface in a mock object for testing\nThe code under test only ever refers to the object by its inter-\nface or base class, so it can remain blissfully ignorant as to\nwhether it is using the real object or the mock. Sometimes\nthere’s a simpler solution to getting on with our testing, so\nlet’s explore that ﬁrst.\n6.1\nStubs\nWhat we need to do is stub out, or fake, all those uncoop-\nerative parts of the real world and replace them with more\ncomplicit allies—our own version of “lighting doubles.” For ex-\nample, stubs allow us to fake our interaction with a database\nor the ﬁlesystem.\nIn many cases, stubs just implement an interface and return\ndummy values for the methods in said interface.1\nIn even\nsimpler cases, all the implemented methods in the stub just\nthrow a NotImplementedException.2\nA common scenario is when there is a class that encapsulates\ndatabase access, but we don’t want to actually conﬁgure and\npopulate a database to run simple tests.\npublic class MySqlCustomerRepository\n{\npublic string FindBy(long id)\n{\nxxxx xx xxxxx\n}\n}\nFirst, we extract an interface for the methods we need to stub\nand apply that interface to the class we want to mock:\npublic interface CustomerRepository\n{\nstring FindBy(long id);\n}\n1Note that while you can also derive from an abstract class, interfaces are\npreferred.[?]\n2Most IDEs will ﬁll in this exception for you when told to automatically\nimplement the methods for an interface.\n",
      "page_number": 98
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 106-113)",
      "start_page": 106,
      "end_page": 113,
      "detection_method": "topic_boundary",
      "content": "STUBS\n93\npublic class MySqlCustomerRepository : CustomerRepository\n{\npublic string FindBy(long id)\n{\nxxxx xx xxxxx\n}\n}\nThen we can return the dummy value that we think will evoke\nthe behaviour we want from the ProductAdoptionService.\npublic class StubCustomerRepository : CustomerRepository\n{\npublic string FindBy(long id)\n{\nreturn string.Empty;\n}\n}\nWe put the code for this stub class in the same ﬁle as the test\nﬁxture class that will be using it, until we need to move it to a\nmore general area where other test ﬁxture classes can access\nit. Then we plug in the stub to our unit test like so:\nnamespace WebCRM.Test.ProductAdoptionTest\n{\n[TestFixture]\npublic class NoDataFixture\n{\n[Test]\npublic void OverallRateIsZero()\n{\nStubCustomerRepository customerRepository =\nnew StubCustomerRepository();\nProductAdoptionService service =\nnew ProductAdoptionService(customerRepository);\nAssert.That(service.GetPercentage(), Is.EqualTo(0));\n}\n}\n}\nIf we’re lucky, our test might now pass and we didn’t have\nto touch a database. In fact, this test could have been writ-\nten before there was ever a schema design, database vendor\ndebate, or anything else. By programming to interfaces, we\nwere able to plug in what we needed without depending on\npoliticking or other non-coding activities that can slow down\na project. Note that we not only get to verify the code being\ntested produces the results that we want, but we also get to\n\n\nFAKES\n94\nverify that it interacts with the stubbed class in the way we\nexpect. More on that later.\n6.2\nFakes\nSometimes we need to do more than return dummy values to\nget at the code we’re trying to test. What if we have ﬁles on\nthe ﬁlesystem that conform to a certain format and we want\nto test that we’re parsing them correctly?\npublic class DumpFileParser\n{\nFileStream stream;\npublic DumpFileParser(string fileName)\n{\nstream = File.Open(fileName);\n}\nxxxx xxx xxxx\n}\nThe code above requires a real ﬁle on the ﬁle system in order\nto be tested. This can put an unnecessary ﬁlesystem layout\nburden on the person running the tests, and the disk I/O\nwill slow down the tests.3 What can we do in a situation like\nthis to make it easier to test?\nThe class actually discards\nthe supplied ﬁlename after the constructor and just operates\non the resulting stream.\nWe’ll look at a suboptimal way of\nmaking it more testable, then a more optimal way. It’s good\nto understand what the evils in the world are so that we don’t\naccidentally end up evoking any of them.\nWhat if we used #define to tell the code when we were test-\ning, then it wouldn’t use the ﬁlesystem.\npublic class DumpFileParser\n{\nFileStream stream;\npublic DumpFileParser(string fileName)\n{\n#if TESTING\nstream = new MemoryStream();\n#else\nstream = File.Open(fileName);\n#endif\n3This doesn’t seem like a big deal, but little slowdowns like this add up\nquickly.\n\n\nFAKES\n95\n}\nxxxx xxx xxxx\n}\nMemoryStream is a nifty class in the .NET class library that\nallows us to make, as you may have guessed, an in-memory\nstream. Now we have a real Stream-derived object that the\nclass can interact with, and it doesn’t touch the ﬁlesystem.\nBefore we get too far ahead of ourselves, though, we have to\nrealise that an empty stream has limitations. First, an empty\nstream doesn’t really help us if we need to read data from\nthat stream. Many of the tests we write will probably want to\nsupply different data via the stream to make sure the parser\nbehaves correctly.\nWe could ﬁgure out various ways to get\nsome test data into place in this scenario, but this approach\nworks around the fact that the code wants the stream to be\nparameterized; our attempt to test this code has illuminated\nthis. Third, #if statements strewn throughout the code for\ntesting purposes are difﬁcult to maintain. And, in our opinion,\nthey’re ugly as well.\nIt might also be tempting to just add an empty constructor to\neliminate the need for any of this deep thinking. While this\nwould “work” in a very narrow sense, there’s a good reason\nthere wasn’t an empty constructor in the ﬁrst place: without\nthe Stream being created, the object isn’t in a valid state. In\nthis case, invalid state means a probable NullReferenceEx-\nception whenever we try to do anything with the object. Ob-\njects being in a valid state after construction is a core object-\noriented design principle, and ignoring it is not the right thing\nto do in this case. Tests can help drive improvements to the\ncode’s design, but this particular example isn’t one of them.\nNow that we’ve discussed what won’t work, what will work?\nWhat if we shifted the responsibility of actually getting the\nFileStream to the clients and passed in a FileStream in-\nstead?\nDoing this transformation would resolve the design\nfeedback we’re getting from testing this in the ﬁrst place.\npublic class DumpFileParser\n{\nStream stream;\npublic DumpFileParser(Stream dumpStream)\n{\n\n\nFAKES\n96\nthis.stream = dumpStream;\n}\nxxxx xxx xxxx\n}\nThis isn’t bad at all. Now the consumers of the class, includ-\ning the tests, could perform the File.Open() and pass in a\nFileStream. It may seem like we’re just moving the problem\naround, but we needed to do that to get to the next step. The\nnext step is to make our code a little more shy; speciﬁcally,\nto make it more liberal in what it will accept. In this case, we\naren’t using any methods speciﬁc to FileStream, so we can\nactually accept the base class, Stream, instead.\nWhat does that get us? Well, in our tests we can now use the\nspiffy MemoryStream class, like so:\n[TestFixture]\npublic class DumpFileParserTest\n{\nprivate StreamWriter writer;\nprivate DumpFileParser parser;\nprivate MemoryStream stream;\n[SetUp]\npublic void SetUp()\n{\nstream = new MemoryStream();\nwriter = new StreamWriter(stream);\n}\n[Test]\npublic void EmptyLine()\n{\nwriter.WriteLine(string.Empty);\nparser = new Parser(stream);\nAssert.That(xxxx, xxxx);\n}\n}\nPresto! An instant pseudo-text-ﬁle that you can also use to\nwrite binary data. Since this operates in-memory, you won’t\nincur the performance penalty of disk I/O.4 Now we can do the\ntesting we need, quickly and conveniently. A nice side effect\nis that our code is shyer, yielding a more ﬂexible design that\nis easier to reuse. One could say that changing the parameter\nto a Stream was a change strictly for the sake of testing and\n4Note that this technique works just as well with Sockets and other\nstream-based I/O as well.\n\n\nFAKES\n97\nthat observation would be somewhat correct. The other side\nof the story is that by not programming against a concrete\nimplementation, the code now has a more ﬂexible design. We\nwere led to this by refactoring a very little bit to make things\neasier to test. This kind of design feedback is the real magic\nof unit testing, but this is only one simple example.\nFaking collaberators\nThe DumpFileParser class we were just working on does some\npretty complicated collation of the data in the stream. If an-\nother class depends on DumpFileParser, we don’t want to\nmake the entire fake stream necessary for it to produce the\ndata we’re trying to test our other class against. Besides the\nfact that it would be really tedious, it adds a whole new di-\nmension of coupling and maintenance to the test code.\nIf\nwe used a real DumpFileParser while testing a collaberat-\ning class, we’re increasing the work we have to do if Dump-\nFileParser changes or gets removed.\nThat doesn’t sound very pragmatic, so how do we decou-\nple DumpFileParser from the tests of a class that requires\na DumpFileParser? It’s actually very similar to our initial ex-\nample – we need to abstract things up a level, then we can\nsupply a variation on DumpFileParser that returns whatever\ndummy values we need for the purpose of testing the other\nobject. This is known in some circles as creating a fake, and\nin other circles as a static mock. Let’s look at some code.\npublic class Analyzer\n{\nprivate DumpFileParser parser;\nprivate List<string> reportItems;\npublic Analyzer(DumpFileParser parser)\n{\nthis.parser = parser;\n}\npublic bool ExpectationsMet\n{\nget\n{\nreturn parser.ReportItems.Count == reportItems.Count;\n}\n}\npublic byte[] GetNextInstruction()\n\n\nFAKES\n98\n{\nxxxxxxxxx\n}\n}\nIf we wanted to test the ExpectationsMet property, the Re-\nportItems property on parser will need to be under our con-\ntrol so we can make it return what we want. One way would\nbe to make the ReportItems property on DumpFileParser\nvirtual. We could then subclass and override it for our test-\ning purposes, and pass an instance of said subclass into the\nconstructor for Analyzer. While that would work, there’s a\nbetter way that yields a more ﬂexible, and interface-oriented,\ndesign: extract an interface called Parsable that contains,\nfor the time being, a declaration for the ReportItems property\ngetter.\npublic interface Parsable\n{\nList<string> ReportItems\n{\nget;\n}\n}\nThen, we can make DumpFileParser implement the Parsable\ninterface.\nNext, we change the Analyzer constructor’s pa-\nrameter from DumpFileParser to Parsable. Last, we change\nthe parser ﬁeld in Analyzer from DumpFileParser concrete\nclass to be the Parsable interface that DumpFileParser now\nimplements.\nWhen we try to compile, the compiler might\ntell us that we’re using some methods not deﬁned on the\nParsable interface. We’ll need to add those methods to the\ninterface as well.\npublic DumpFileParser : Parsable\n{\nxxxxxxx\n}\npublic class Analyzer\n{\nprivate Parsable parser;\nprivate List<string> reportItems;\npublic Analyzer(Parsable parser)\n{\nthis.parser = parser;\n}\nxxxxxxxx\n}\n\n\nFAKES\n99\nNone of the existing consumers of Analyzer have to change,\nand yet, we have just made Analyzer easier to test and reuse.\nIf in the future we wanted to add the ability to parse another\nﬁle format, Analyzer itself wouldn’t have to change to acco-\nmodate the extra functionality—only the consumers would by\npassing in a new class that implements the Parsable inter-\nface.\nThis is a good example of the advantage of interface-based\ndesign, but the point worth mentioning again is that we ar-\nrived at this better design by refactoring toward testability.\nBesides being more testable and reusable, it also means that\nwe don’t need to wait for another set of programmers to ﬁn-\nish implementing the concrete class that our class might be\ncollaborating with. We can fully unit test our class by faking\nthe collaberator’s interface, which generally makes integrat-\ning with the concrete classes developed by others (or even our\nfuture selves) signiﬁcantly less painful.5\nFakes are great, especially when they’re simple, but it’s also\neasy to outgrow them; like when we need to do more than re-\nturn a single value, for instance. At some point, we want to re-\nturn values in a certain order each time a method is called. To\naccomplish this with a fake, we would need to track a Stack\nof return values for a given method.\npublic FakeParser : Parsable\n{\nprivate Stack<byte[]> bytesToReturn;\npublic Stack<byte[]> BytesToReturn\n{\nget { return bytesToReturn; }\nset { bytesToReturn = value; }\n}\npublic Boolean ExpectationsMet\n{\nget { return false; }\n}\npublic Byte[] GetNextInstruction()\n{\nreturn BytesToReturn.Pop();\n}\n}\n5In many cases, the usually pandemonious step of integration just works.\n\n\nMOCK OBJECTS\n100\nWhile this would work and is a clever way to make a pro-\ngrammable fake, we risk repeating ourselves because we\nwould end up doing this for most methods on our fake. It also\ngets a little more hairy when we have to make them throw spe-\nciﬁc exceptions at certain points to test failure modes. Surely,\nthere must be a better way.6\n6.3\nMock Objects\nIn the old days, just having the ability to call subroutines was\na great advance.\nThen libraries of code became popular—\neverything had to be library. Nowadays, libraries aren’t good\nenough. You’ve got to have a framework to be taken seriously.\nIn the case of .NET, there are several alternative mock ob-\nject frameworks to choose from (a good list can be found\nat http://www.mockobjects.com). NUnit includes its own\nbuilt-in framework that the NUnit team uses to test NUnit\nitself. NUnit’s mock framework doesn’t provide all of the fea-\ntures of some other frameworks, so we’ll look at a few other\nframeworks as well. But before we do, it’s worth noting that\nbecause we’re in .NET’s CLR environment, this same frame-\nwork can be used to mock objects for any code written in\nany language compliant with the Common Language Speciﬁ-\ncation.\nNUnit Mocks\nWhen you think about it, there’s really not too much to a mock\nobject: it’s simply an object that implements a particular in-\nterface, returns values we want it to return, and checks that it\nwas used in a certain way. As a result, the basic frameworks\nfor creating mock objects are also simple.\nIn the previous section, we saw what we would have to\ngo through to have our fake be somewhat programmable\nand return multiple values for a given method call.\nHere\nis how we would do this using NUnit’s mock framework.\n6Never call us Shirley.\n",
      "page_number": 106
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 114-121)",
      "start_page": 114,
      "end_page": 121,
      "detection_method": "topic_boundary",
      "content": "MOCK OBJECTS\n101\nNote that to compile this code, we’ll have to add a refer-\nence to the nunit.mocks.dll assembly in addition to the\nnunit.framework.dll reference.\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\nusing NUnit.Mocks;\n[TestFixture]\npublic class AnalyzerTest\n{\nAnalyzer analyzer;\nParsable parser;\n[Test]\npublic void NoBytes()\n{\nDynamicMock controller =\nnew DynamicMock(typeof(Parsable));\nparser = controller.MockInstance as Parsable;\nanalyzer = new Analyzer(parser);\ncontroller.ExpectAndReturn(\n\"GetNextInstruction\",// method name\nnew byte[] {},\n// return value\nnull\n// expected arguments\n);\ncontroller.ExpectAndReturn(\n\"get_ExpectedReportItems\",\nnew List<string>(),\nnull\n);\nanalyzer.Run();\ncontroller.Verify(); // fails the test if expecta-\ntions are unmet\nAssert.That(analyzer.ReportItems, Is.Empty);\n}\n}\nMock object frameworks make it very easy to set multi-\nple method call expectations, with or without accompany-\ning dummy values that should be returned, with or without\nthrowing exceptions, etc. In the code above, we ﬁrst instan-\ntiate a DynamicMock object, passing the Parsable interface’s\ntype into the constructor. We can only create a DynamicMock\nfor interfaces or classes that derive from MarshalByRefOb-\nject. We highly recommend extracting interfaces whenever\npossible, not only for the reasons previously discussed in this\nchapter, but also because of the complex implications of using\nMarshalByRefObject.[Ric06]\n\n\nMOCK OBJECTS\n102\nThere’ll be times when we need to test something that uses an\nexisting interface and there are no pre-written mock objects\nlying around. Often, we can just jump right on in and create\na new mock object. But what if the interface that we’re mock-\ning is enormous, with dozens of methods and accessors? That\ncould mean a lot of work producing a mock object that imple-\nments the interface. This is particularly galling if we only need\none or two methods from the interface to run our tests, and\nwe can’t refactor to break up the interface for some reason.\nThis is where dynamic mock objects come in.\nThey let us\ncreate an object that responds as if it implemented a full in-\nterface, but in reality it is totally generic. You only need to tell\nthis object how to respond to the method calls that our code\nuses. This can represent a considerable saving in time. It’ll\nalso give you less code to maintain in the future.\nThe dynamic mock packages operate by creating proxy objects\nin the underlying implementation. These are objects that are\ndesigned to stand in for their real-world counterparts. In the\ndynamic mock object context, this means that we can use\na proxy in place of a real object in our tests.\nHowever, we\nstill need to be able to control this generated proxy object—we\nneed to be able to tell it how to respond. This is where the\ncontroller comes in.\nThe controller is in charge of a dynamic mock object. You use\nthe controller to create an instance of the mock and to tell the\nmock what to do. Sometimes the controller is told directly,\nlike in NUnit’s mocks, sometimes indirectly as in the NMock2\nframework, which we’ll discuss later in the chapter.\nOnce the mock is created, we pass it in to the real object that\nwe are testing the interaction with. If our interaction testing\nwasn’t constrained to the Run() method, we would program\nthe mock before we passed it into the constructor for Ana-\nlyzer. Since we’re focusing on testing the interaction after\nRun() is called, we start programming it with our expecta-\ntions right before the call to run, since this expresses our\nintentions clearly. To put it another way, we don’t want to\nprogram all the expectations for our mock in a big clump that\nis difﬁcult to read and understand.\nIn the code above, the\nexpectations we set are:\n\n\nMOCK OBJECTS\n103\n1. The method name\n2. The value, if any, that will be returned when the mocked\nmethod is called\n3. The speciﬁc arguments, if any, we expect the mocked\nmethod to be called with.\nAfter creating the mock, we tell it to expect a call to Get-\nNextInstruction(), and to return an empty byte array.\nThe ﬁnal null parameter indicates that there are no speciﬁc\nmethod argument expectations. In this case, the method in\nquestion doesn’t have any parameters, but we can also sup-\nply null when we just don’t care. In our experience, checking\nspeciﬁc arguments supplied to the mocked method is usually\nnot necessary because that level of detail usually isn’t neces-\nsary to express the intention of the interaction we’re testing.\nNext, we tell the mock to expect a call to the getter for the Ex-\npectedReportItems property. Note that we had to prepend\n“get_” to the property name.7 In the context of this applica-\ntion, a parser having no bytes also means it should also not\nhave any expected report items.\nWe then get our mock object via the MockInstance property.\nBecause NUnit’s mock framework doesn’t take advantage of\ngenerics, we have to cast it—hence the use of the as operator.\nAt that point, we can treat that instance like the real object\nas long as we use it only in the way we programmed it. One\nway to think about it is the framework provides a kind of API-\nlevel record-and-playback mechanism. If we didn’t “record”\nthe method calls, the mock can’t play them back.\nBy default, the DynamicMock operates fairly loosely. Just by\ntelling the mock to expect the method call once, it will happily\ndo whatever we told it to do even if the method is called mul-\ntiple times. It also doesn’t care about the order in which the\nexpected methods are called by default. While we sometimes\ndon’t care about that level of detail, and that makes this de-\nfault behaviour quite nice, it’s a good idea to be vigilant when\npractical.\n7For more details on the inner workings of properties, see [Ric06].\n\n\nMOCK OBJECTS\n104\nWhen we want that vigilance, we can set the Strict property\non the mock to true. One of the things the strict ﬂag does\nis that the mock will fail the test immediately if something\nhappens that the mock wasn’t expecting. If we’re not using\nstrict mode, then we need to ask the mock to Verify() that\nall the expectations were met. The Verify method acts as a\nkind of assertion. If anything we expected didn’t happen, the\nveriﬁcation will fail. Since the veriﬁcation generally happens\nat the end of the test, it can sometimes be difﬁcult to track\ndown where things went wrong.\nThis is another reason to\nprefer the strict mode on the mock, if practical.\nNote that the ExpectAndReturn methods take the method\nname as a string parameter. This introduces a gotcha where\nif you rename the method in the code, but not in the mock\nexpectation, the mock will throw an exception. Other frame-\nworks, which we’ll discuss later in this chapter, improve upon\nthis limitation.\nSome of the other expectations we can set using NUnit’s Dy-\nnamicMock include:\n• ExpectNoCall(string methodName), which will cause\nveriﬁcation to fail if the method supplied is called. If the\nmock is in strict mode, the test will fail immediately if\nspeciﬁed method is called.\n• ExpectAndThrow(string methodName, Exception\nexception, params object[] args), which operates\nthe same as ExpectAndReturn, except the exception\nspeciﬁed is thrown.\nThis is great for making sure\nyour exception handling interaction between classes is\nrock-solid, and stays that way.\n• SetReturnValue(string methodName, object re-\nturnValue),\nwhich\nwill\nalways\nreturn\nthe\nvalue\nspeciﬁed no matter how many times the method in\nquestion is called. We generally don’t recommend using\nthis, as it can cover up the very interaction feedback\nthat mocks are so good at giving us.\nFor more information check out NUnit’s documentation or\njust explore a bit with a method-completing code editor.\n\n\nMOCK OBJECTS\n105\nNMock2 Framework\nNMock2,8 which is based on jMock for Java,9 inspired NUnit’s\nnew style of constraint-based assertions. It is meant to pro-\nvide a more concise and easily readable syntax in contrast to\nother mock frameworks. Since we use unit tests as documen-\ntation for our code, it’s important that the conﬁguration of our\nmocks be easy to read and understand. In that vein, NMock’s\nsyntax reads from left to right, albeit with a syntax that might\nlook a bit strange at ﬁrst.\nusing NUnit.Framework;\nusing NMock2;\n[TestFixture]\npublic class AnalyzerTest\n{\nAnalyzer analyzer;\nParsable parser;\nMockery mockery;\n[Test]\npublic void NoBytes()\n{\nmockery = new Mockery();\nparser = mocks.NewMock<Parsable>();\nanalyzer = new Analyzer(parser);\nExpect.Once.On(parser)\n.Method(\"GetNextInstruction\")\n.Will(Return.Value(new byte[] {}));\nExpect.Once.On(parser)\n.GetProperty(\"ExpectedReportItems\")\n.Will(Return.Value(new List<string>()));\nanalyzer.Run();\nmockery.VerifyAllExpectationsHaveBeenMet();\nAssert.That(\nanalyzer.ReportItems,\nnew EmptyConstraint()\n);\n}\n}\nThis code is equivelant to the code from the previous subsec-\ntion that was written using NUnit’s mocks. First, we create a\nMockery object. Mockery acts as a factory for mock objects,10\nvia the NewMock<T>() generic method. Because it is a generic\n8http://nmock.org\n9http://jmock.org\n10Mocks + Factory = Mockery, get it?\n\n\nMOCK OBJECTS\n106\nmethod, whatever type we parameterize it with is the type it\nwill return. This allows us to avoid the casting we had to do\nin NUnit’s mocks.11 Note that the use of a generic method is\na C# 2.0 feature, so NMock2 can’t be used on a project that\nstrictly uses an earlier C# version. The Mockery object also\nkeeps track of the expectations we are setting.\nWe then set up the expectations. Remember, we only program\nthe mock with the minimal number of expectations we need\nto test the interaction triggered by the speciﬁc method. We\nwant this to read like a conversation between the mock and\nthe real object, from A to B and back again. We expect that,\nonly once, the parser’s GetNextInstruction method will be\ncalled, and it will return an empty byte array.\nUnder the\ncovers, the expectations are communicated to the Mockery\nobject, which created the Parser mock in the ﬁrst place.\nTo our subjective eyes, NMock2 reads a bit more easily than\nother frameworks. It allows us to focus on only the aspects\nthat we care about.\nOn the other hand, NUnit’s mocks re-\nquire us to always provide the arguments we are expecting;\nwe have to supply null to tell it we don’t have any argu-\nment expectations.\nIn NMock2, we only add the argument\nconstraint matcher if we actually need it by adding .With(x)\nto the chain. This extra ﬂexibility seems small, but it adds up\nto test code that is easier to maintain.\nOne major caveat to note is that we can no longer use NUnit’s\nAssertionHelpers namespace, which gave us Is and Has,\namongst other nice things, because NMock2 also deﬁnes\nclasses with those names. We’re not using them in this ex-\nample, because they relate to argument matching. Because of\nthis conﬂict, we’re using new EmptyConstraint() instead of\nthe usual Is.Empty. We could also substitute in the classic-\nstyle assertion, CollectionAssert.IsEmpty().\nHopefully\nthis namespace issue will be resolved in future versions so\nwe can use the advantages of both.\n11The NUnit 2.4 team purposefully restrained themselves to only using C#\n1.1 features so it could be more widely used.\n\n\nMOCK OBJECTS\n107\nJoe Asks. . .\nHow do I mock singletons?\nWith\ndesign\npatterns\nbecoming\npopular,\nmany\nprojects have various patterns implemented as part\nof their design. One of the most commonly misunder-\nstood patterns is the Singleton. Unfortunately, it is usu-\nally mis-implemented in such a way that introduces\nglobal state, which in turn introduces a large amount\nof temporal coupling, hidden dependencies, and ex-\ntremely difﬁcult debugging. Many times, a singleton\nisn’t even necessary, but it can be a tempting way to\ncheat through actually improving the design.\nIn the next section, we show how to test around a us-\nage of DateTime.Now, which is a static global, just\nlike a singleton class can be. The key is to extract an\ninterface for the methods actually used by the con-\nsumers of the singleton class, and then extract a pa-\nrameter from the class or method that accepts the\ninterface for the singleton. From that point, you can\ncreate a mock from the extracted interface and pass\nin the mock via the parameter.\nEven if you aren’t unit testing, this is the standard set of\nrefactorings for loosening the hangman’s knot of sin-\ngletons that many projects get themselves into. Once\nyou see the real dependencies you have with the vis-\nibility of the extracted parameters, you’ll have the in-\nformation for genuinely improving our design instead\nof working around it. When applying this design feed-\nback, you may ﬁnd that the singleton is simply no\nlonger necessary.\n\n\nMOCK OBJECTS\n108\nRhinoMock\nThere’s a third option in the world of mock frameworks\nthat some of our reviewers asked us to mention, Rhi-\nnoMock.a RhinoMock primarily distinguishes itself by\nnot relying upon strings to specify the method that ex-\npectations will be set on. It is this simple feature that\nmakes it work more easily with code completion and\nrefactoring capabilities in modern IDEs.\nEach framework has advantages and disadvan-\ntages, which one you end up applying on your\nproject is a matter of preference and practicality. We\ndo encourage you to try a couple before settling,\nthough.\nahttp://www.ayende.com/projects/rhino-mocks.aspx\nDotNetMock Framework\nSome objects are difﬁcult to set up mocks for, regardless of\nthe framework, due to the complexity and girth of their inter-\nfaces. ASP.NET and ADO.NET objects can be fairly difﬁcult,\nin particular. In these cases, a library of static mocks that\nare engineered speciﬁcally for common unit testing scenarios\ncan come in handy.\nTo meet this need, the DotNetMock12\nframework is actually three things in one:\n1. It’s a framework (not surprisingly), allowing us to create\nmock objects in a structured way.\n2. It contains a (small) set of predeﬁned mock objects that\nwe can use out of the box to test our application.\n3. Finally, it comes with a technology, dynamic mocks, that\nlet’s us construct mock objects without all that messy\ncoding.\nWe recommend using one of the aforementioned mock object\nframeworks for standard mock program-activities, and Dot-\nNetMock for when you need to mock one of the messier frame-\n12http://dotnetmock.sourceforge.net\n",
      "page_number": 114
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 122-130)",
      "start_page": 122,
      "end_page": 130,
      "detection_method": "topic_boundary",
      "content": "MOCK OBJECTS\n109\nwork classes. As such, we’re only going to cover the library of\nmocks that DotNetMock comes with.\nSupplied Mock Objects\nOne of the nice things about using a standardized frame-\nwork for testing is that we can start to build a library of\nstandard mock objects and reuse these across projects.\nIn\nfact, in the open source world, you might even ﬁnd that other\nfolks have mocked up the interfaces that you need and made\nthem freely available. The DotNetMock package comes with\na (small) number of these off-the-shelf mock object packages,\navailable in DotNetMock.Framework. While DotNetMock’s li-\nbrary of predeﬁned mocks hasn’t been updated for .NET 2.0\nat the time of this writing, it’s still very useful if you’re using\n.NET 1.1 APIs. Here we’ll look at one of these, Data, which\nimplements many of the interfaces in .NET’s System.Data.\nLet’s start by implementing more of our access controller. Af-\nter verifying that a password has been supplied, we’ll now go\nto a database table and verify that a row exists giving this\nuser, identiﬁed with the given password, access to our re-\nsource.\nusing System;\nusing System.Data;\nusing System.Data.SqlClient;\npublic class AccessController1 {\nprivate ILogger\nlogger;\nprivate String\nresource;\nprivate IDbConnection conn;\npublic static readonly String CHECK_SQL =\n\"select count(*) from access where \" +\n\"user=@user and password=@password \" +\n\"and resource=@resource\";\npublic AccessController1(String resource,\nILogger logger,\nIDbConnection conn) {\nthis.logger\n= logger;\nthis.resource = resource;\nthis.conn\n= conn;\nlogger.SetName(\"AccessControl\");\n}\npublic bool CanAccess(String user, String password) {\nlogger.Log(\"Checking access for \" + user +\n\" to \" + resource);\n\n\nMOCK OBJECTS\n110\nif (password == null || password.Length == 0) {\nlogger.Log(\"Missing password. Access denied\");\nreturn false;\n}\nIDbCommand cmd = conn.CreateCommand();\ncmd.CommandText = CHECK_SQL;\ncmd.Parameters.Add(\nnew SqlParameter(\"@user\",\nuser));\ncmd.Parameters.Add(\nnew SqlParameter(\"@password\", password));\ncmd.Parameters.Add(\nnew SqlParameter(\"@resource\", resource));\nIDataReader rdr = cmd.ExecuteReader();\nint rows = 0;\nif (rdr.Read())\nrows = rdr.GetInt32(0);\ncmd.Dispose();\nif (rows == 1) {\nlogger.Log(\"Access granted\");\nreturn true;\n}\nelse {\nlogger.Log(\"Access denied\");\nreturn false;\n}\n}\n}\nAccessController1.cs\nThe test code for this is somewhat more complicated than the\nprevious cases, mostly because we want to knit together all\nthe various objects used to access the database (the connec-\ntion, the command, various parameters, and the reader that\nreturns the result). We also want to set up a reasonable set of\nexpectations to ensure that the underlying code is calling the\ndatabase layer correctly.\nLine 1\nusing DotNetMock.Framework.Data;\n-\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\nusing System;\n5\n-\n[TestFixture]\n-\npublic class AnotherAccessControllerTest\n-\n{\n-\n[Test]\n10\npublic void ValidUser()\n-\n{\n-\nMockLogger3 logger = new MockLogger3();\n-\nlogger.ExpectedName = \"AccessControl\";\n\n\nMOCK OBJECTS\n111\n-\nlogger.AddExpectedMsg(\n15\n\"Checking access for dave to secrets\");\n-\nlogger.AddExpectedMsg(\"Access granted\");\n-\n-\n// set up the mock database\n-\nMockDbConnection conn = new MockDbConnection();\n20\nMockCommand cmd = new MockCommand();\n-\nMockDataReader rdr = new MockDataReader();\n-\n-\nconn.SetExpectedCommand(cmd);\n-\ncmd.SetExpectedCommandText(\n25\nAccessController1.CHECK_SQL);\n-\ncmd.SetExpectedExecuteCalls(1);\n-\ncmd.SetExpectedParameter(\n-\nnew MockDataParameter(\"@user\",\n\"dave\"));\n-\ncmd.SetExpectedParameter(\n30\nnew MockDataParameter(\"@password\", \"shhh\"));\n-\ncmd.SetExpectedParameter(\n-\nnew MockDataParameter(\"@resource\", \"secrets\"));\n-\n-\ncmd.SetExpectedReader(rdr);\n35\nobject [,] rows = new object[1,1];\n-\nrows[0, 0] = 1;\n-\nrdr.SetRows(rows);\n-\n-\nAccessController1 access =\n40\nnew AccessController1(\"secrets\", logger, conn);\n-\n-\nAssert.That(\n-\naccess.CanAccess(\"dave\", \"shhh\"),\n-\nIs.True\n45\n);\n-\nlogger.Verify();\n-\nconn.Verify();\n-\ncmd.Verify();\n-\n}\n50\n}\nAccessControllerTest1.cs\nOn line 1 we bring in the DotNetMock framework’s Data com-\nponents. In the body of the test method, we start by creating\nand setting up a mock logger as before. At line 19 we cre-\nate three mock database objects: the connection, a command\n(used to issue SQL queries into the database), and a reader\n(used to return the results of a query).\nWe now need to associate these three objects together. Line 23\ntells the connection object that when it is asked to generate a\ncommand object it should return our mock command object,\ncmd. We then set up that command object’s expectations: the\nSQL it should receive, the number of times it will be executed,\nand the parameters it should expect to receive.\nLine 34 starts the stanza that sets up the reader object. It\n\n\nWHEN NOT TO MOCK\n112\nIt isn’t all perfect\nObservant readers may be wondering why our new\nAccessController class went to the trouble of using a\nReader object to get the count back from executing\nthe query. Why didn’t we just use the ExecuteScalar\nmethod of the command object to return the count\ndirectly?\nUnfortunately, the mock object implementation of\nIDbCommand isn’t quite complete (at least at the time\nof writing). Although ExecuteScalar is implemented,\nit always returns a null value.\nThis means that we\ncouldn’t use it in our tests.\nis ﬁrst associated with the command (so that when the mock\ncommand is executed it will return this reader object).\nWe\nthen set up its result set, a two dimensional array of objects,\ncontaining the rows returned by the query and the columns\nin each row. In our case, the result set contains just a single\nrow containing a single column, the count, but we still need\nto wrap it in the two-dimensional array.\nFinally, on line 39, we create our access controller and check\nto see if “dave” can access the resource “secrets” by using the\npassword “shhh.”\nBecause these values correspond to the\nvalues we set up for the query, the access controller will be\nable to use our mock database objects, which will return a\ncount of “1” and the access will be accepted. At the end of the\ntest, we then verify that the logger, connection, and command\nmock objects were used correctly by our method under test.\n6.4\nWhen Not To Mock\nMock objects are an appealing technology, but because they\ninvolve writing code, they represent a deﬁnite cost to a project.\nWhenever you ﬁnd yourself thinking that you want to write\na mock object to help with testing, stop and consider alter-\nnatives for a couple of seconds.\nIn particular, ask yourself\nthe simple question: “Do I need to write a mock object at\n\n\nWHEN NOT TO MOCK\n113\nall?” Sometimes we can eliminate the need for a mock object\nthrough some simple refactoring.\nAs a (somewhat contrived) example, let’s imagine that we’re\nwriting code that downloads ﬁles to a handheld device over a\nrelatively slow wire. Because of some hardware restrictions,\nafter we’ve sent a block of data, we have to wait a while before\ntrying to talk with the device again. The length of time we have\nto wait depends on the amount of data sent—the hardware\nguys gave us a table of values to use.\nWe might start off by writing a routine that waits a length of\ntime dependent on the size of data sent:\npublic void WaitForData(int dataSize)\n{\nint timeToWait;\nif (dataSize < 100)\n{\ntimeToWait = 50;\n}\nelse if (dataSize < 250)\n{\ntimeToWait = 100;\n}\nelse\n{\ntimeToWait = 200;\n}\nThread.Sleep(timeToWait);\n}\nExample.cs\nNow we want to test this method, but there’s a problem. The\nonly way to see if it works is to check to see if it sleeps for\nthe right amount of time for various values of the dataSize\nparameters.\nThat’s not an easy test to write: we’d have to\nbuild in a fudge factor, because the time we measure for the\nwait won’t be exact. We might even have to set up some kind\nof watchdog thread to ensure that the sleep doesn’t go on too\nlong. There’s also the elapsed time to consider. If running our\ntests causes Thread.Sleep to be called multiple times, our\nunit tests will take longer to complete—which won’t increase\nour popularity amongst co-workers.\nAfter reading this chapter, your ﬁrst thought might be to solve\nthese problems using a mock object.\nIf we replace Thread\nwith some kind of mock object, we can verify that its Sleep()\n\n\nWHEN NOT TO MOCK\n114\nmethod was called with the expected values.\nClass Thread\nis not an interface, and even if it were, it has a boatload of\nproperties and members.\nThis is the time to reﬂect: could we redesign our code slightly\nto make it easier to test? Of course we can!\npublic int HowLongToWait(int dataSize)\n{\nint timeToWait;\nif (dataSize < 100)\n{\ntimeToWait = 50;\n}\nelse if (dataSize < 250)\n{\ntimeToWait = 100;\n}\nelse\n{\ntimeToWait = 200;\n}\nreturn timeToWait;\n}\npublic void WaitForData(int dataSize)\n{\nThread.Sleep(HowLongToWait(dataSize));\n}\nExample.cs\nIn this code we’ve split the waiting into two methods. One cal-\nculates the number of milliseconds to wait based on the data’s\nsize, and the other calls it to get the parameter to pass the\nThread.Sleep(). If we assume that the framework Sleep()\nmethod works, then there’s probably no need to test this sec-\nond method: we can eyeball it and see it does what it says\nit should. That leaves us with the simple task of testing the\nmethod that calculates the time to wait.\n[Test]\nvoid WaitTimes()\n{\nWaiter w = new Waiter();\nAssert.That(w.HowLongToWait(0), Is.EqualTo(50));\nAssert.That(w.HowLongToWait(99), Is.EqualTo(50));\nAssert.That(w.HowLongToWait(100), Is.EqualTo(100));\nAssert.That(w.HowLongToWait(249), Is.EqualTo(100));\nAssert.That(w.HowLongToWait(250), Is.EqualTo(200));\nAssert.That(w.HowLongToWait(251), Is.EqualTo(200));\n}\nExample.cs\nA simple refactoring has led us to a better design and elimi-\n\n\nWHEN NOT TO MOCK\n115\nnated a whole lot of pain associated with coding up the tests.\nTesting for time\nHere’s another, real-world example that shows how a simple\nrefactoring makes for both an easier test and a better, more\ndecoupled design. This is the code to be tested; note the de-\npendency on the current system time.\npublic static string DaysFromNow(DateTime last)\n{\nTimeSpan span = DateTime.Now - last;\nswitch (span.Days)\n{\ncase 0:\nreturn \"Today\";\ncase 1:\nreturn \"Yesterday\";\ndefault:\nreturn span.Days + \" days ago\";\n}\n}\nOn this particular project, one senior engineer spent a lot\nof time trying to invent a good way to fake out or change\nDateTime.Now.\nBut then an intern from Portugal who\nlearned C# via a few test-driven development books saw\nthe code and made the obvious suggestion of extracting a\nparameter[FBB+99].\nIt took some time for the senior engi-\nneer to recover from a bad case of “bruised ego,” but everyone\nagreed it was for the best.\nThe code was refactored to look like the following.\npublic static\nstring DaysFromNow(DateTime current, DateTime last)\n{\nTimeSpan span = current - last;\nswitch (span.Days)\n{\ncase 0:\nreturn \"Today\";\ncase 1:\nreturn \"Yesterday\";\ndefault:\nreturn span.Days + \" days ago\";\n}\n}\n\n\nWHEN NOT TO MOCK\n116\nNotice there is no dependency on the current date or time\nanywhere in the code; it is passed in from the caller. Now we\ncan use a very simple test to drive this code.\n[Test]\npublic void Yesterday()\n{\nDateTime date = new DateTime(2007, 9, 27);\nDateTime dateMinusOneDay = new DateTime(2007, 9, 26);\nAssert.That(\nDaysFromNow(date, dateMinusOneDay),\nIs.EqualTo(\"Yesterday\")\n);\n}\nSometimes you can’t change your existing interfaces to accept\nthe parameterized singleton, or just want to do things in a\nmore incremental fashion so we don’t have to upheave the\nentire codebase. In that case, add a new interface that adds\nthe parameterized singleton, then have the original interface\ndelegate to the new one.\npublic static\nstring DaysFromNow(DateTime last)\n{\nreturn DaysFromNow(DateTime.Now, last);\n}\nWe will want to eventually get rid of this delegation, when\npractical, of course.\nAnd that’s all there is to mock objects: fake out parts of the\nreal world so we can concentrate on testing our own code,\nwhich generally has a nice side-effect of improving our design.\nSome people might perceive that testing with fakes and mocks\nmakes the testing less “real,” but as you can see through the\nexamples, we can actually test interactions that would be difﬁ-\ncult and slow to reproduce accurately in the real world. Also,\nremember that it’s called unit testing for a reason; we don’t\ndrag the whole system along for the ride because we want to\ntest one behavior of a single class.\n\n\nChapter 7\nProperties of\nGood Tests\nUnit tests are very powerful magic, and if used badly can\ncause an enormous amount of damage to a project by wast-\ning your time. If unit tests aren’t written and implemented\nproperly, you can easily waste so much time maintaining and\ndebugging the tests themselves that the production code—and\nthe whole project—suffers.\nWe can’t let that happen; remember, the whole reason you’re\ndoing unit testing in the ﬁrst place is to make your life easier!\nFortunately, there are only a few simple guidelines that you\nneed to follow to keep trouble from brewing on your project.\nGood tests have the following properties, which makes them\nA-TRIP:\n• Automatic\n• Thorough\n• Repeatable\n• Independent\n• Professional\nLet’s look at what each of these properties means to us.\n",
      "page_number": 122
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 131-140)",
      "start_page": 131,
      "end_page": 140,
      "detection_method": "topic_boundary",
      "content": "AUTOMATIC\n118\n7.1\nAutomatic\nUnit tests need to be run automatically. We mean “automat-\nA -TRIP\nically” in at least two ways: invoking the tests and checking\nthe results.\nAutomatic Invocation\nIt must be really easy for you to invoke one or more unit tests,\nas you will be doing it all day long, day in and day out. So it\nreally can’t be any more complicated than pressing one button\nin the IDE or typing in one command at the prompt in order\nto run the tests you want. Some IDEs can even be set up to\nrun the unit tests continually in the background.\nIt’s important to maintain this environment: don’t introduce\na test that breaks the automatic model by requiring manual\nsteps. Whatever resources the test requires (database, net-\nwork connections, etc.), make these an automatic part of the\ntest itself. Mock objects, as described in Chapter 6, can help\ninsulate you from changes in the real environment if needed.\nBut you’re not the only one running tests. Somewhere a ma-\nchine should be running all of the unit tests for all checked-in\ncode continuously. This automatic, unattended check acts as\na “back stop”; a safety mechanism to ensure that whatever\nis checked in hasn’t broken any tests, anywhere. In an ideal\nworld, this wouldn’t be necessary as you could count on every\nindividual developer to run all the necessary tests themselves.\nBut this isn’t an ideal world. Maybe an individual didn’t run\nsome necessary test in a remote corner of the project. Perhaps\nthey have some code on their own machine that makes it all\nwork—but they haven’t checked that code in, so even though\nthe tests work on their own machine, those same tests fail\neverywhere else.\nYou may want to investigate systems such as Cruise Con-\ntrol1 and other open source products that manage continuous\nbuilding and testing.\n1http://ccnet.thoughtworks.com\n\n\nTHOROUGH\n119\nAutomatic Checking\nFinally, by “automatic” we mean that the test must determine\nfor itself whether it passed or failed. Having a person (you or\nsome other hapless victim) read through the test output and\ndetermine whether the code is working or not is a recipe for\nproject failure. Also, in the interests of speed, note that any\ntest that spews tons of console I/O (via Console.WriteLine,\nlog4net or something similar) will slow down the unit tests—\nsometimes dramatically. We want unit tests to be silent, self-\ncontained, and fast.\nIt’s an important feature of consistent regression to have the\ntests check the results for themselves. We humans aren’t very\ngood at those repetitive tasks.\nWe’ll make mistakes in the\nchecking, and waste time investigating a bug that may not ex-\nist, or not catch a new bug that will go on to cause additional\ndamage. The computer will not make these inconsistent mis-\ntakes; a properly written unit test will check the same thing\nevery time it’s run with perfect consistency. Besides we’ve got\nmore important things to do—remember the project?\nThis idea of having the tests run by themselves and check\nthemselves is critical, because it means that you don’t have to\nthink about it—it just happens as part of the project. Testing\ncan then fulﬁll its role as a major component of our project’s\nsafety net. (Version control and automation are the other two\nmajor components of the “safety net.”) Tests are there to catch\nyou when you fall, but they’re not in your way.\nYou’ll need all of your concentration as you cross today’s high-\nwire.\n7.2\nThorough\nGood unit tests are thorough; they test everything that’s likely\nA- T RIP\nto break. But just how thorough?\nAt one extreme, you can aim to test every line of code, ev-\nery possible branch the code might take, every exception it\nthrows, and so on.\nAt the other extreme, you test just the\nmost likely candidates—boundary conditions, missing and\n\n\nTHOROUGH\n120\nmalformed data, and so on. It’s a question of judgment, based\non the needs of your project.\nIf you want to aim for more complete coverage, then you may\nwant to invest in code coverage tools to help.\nFor instance\nNCover, at http://ncover.org.2 NCover produces XML ﬁles\nthat describe the coverage, there are a couple of tools to visu-\nalize and explore that coverage data:\n• NCoverExplorer3, which is part of the TestDriven.NET\nextension to Visual Studio.NET.\n• CruiseControl.NET comes with a very nice XSL ﬁle for\ntransforming the NCover XML into some really cool-\nlooking HTML.\n• SharpDevelop 2.1 (and above) has NCover integration\nthat will allow you to browse a tree-view of classes and\nmethods. It also has as an option to highlight lines of\ncode in the IDE that were not covered by the unit tests.\nThese tools can help you determine how much of the code\nunder test is actually being exercised, as well as help you\npinpoint what’s not being exercised so you can focus your\ntesting efforts.\nIt’s important to realize that bugs are not evenly distributed\nthroughout the source code.\nInstead, they tend to clump\ntogether in problematic areas (for an interesting story along\nthese lines, see the sidebar on the next page).\nThis phenomenon leads to the well-known battle cry of “don’t\npatch it, rewrite it.” Often, it can be cheaper and less painful\nto throw out a piece of code you’ve written that has a clump\nof bugs and rewrite it from scratch. There’s nothing that can\nimprove code quite like a good old-fashioned disk crash.\nBut because it’s usually more fun to write new code rather\nthan refactor existing code, be careful with wholesale re-\nwriting—especially if it’s someone else’s code.\nRather than\nthrow it out, ﬁrst try to refactor someone else’s code to make\n2As of this writing, NCover does not work with Mono due to the way it\nhooks into Microsoft-speciﬁc portions of the CLR.\n3http://kiwidude.com/blog\n\n\nTHOROUGH\n121\nReported Bugs vs. Unit Test Coverage\nWe had a client recently that didn’t quite believe in\nthe power of unit tests. A few members of the team\nwere very good and disciplined at writing unit tests for\ntheir own modules, many were somewhat sporadic\nabout it, and a few refused to be bothered with unit\ntests at all.\nAs part of the hourly build process, we whipped up\na simple Ruby script that performed a quick-and-dirty\nanalysis of test coverage: it tallied up the ratio of test\ncode asserts to production code methods for each\nmodule. Well-tested methods may have 3, 4, or more\nasserts each; untested methods will have none at all.\nThis analysis ran with every build and produced a bar-\ngraph, ranking the most-tested modules at the top\nand the untested modules at the bottom.\nAfter a few weeks of gathering ﬁgures, we showed\nthe bargraph to the project manager, without initial\nexplanation. He was very surprised to see all of the\n“problem modules” lumped together at the bottom—\nhe thought we had somehow produced this graph\nbased on bug reports from QA and customer sup-\nport. Indeed, the modules at the top of the graph\n(well tested) were nearly unknown to him; very few, if\nany, problems had ever been reported against them.\nBut the clump of modules at the bottom (that had\nno unit tests) were very well known to him, the sup-\nport managers, and the local drugstore which had\nresorted to stocking extra-large supplies of antacid.\nThe results were very nearly linear:\nthe more unit-\ntested the code, the fewer problems.\nit more unit-testable. Then if that’s not working, you can go\nahead and succumb to the sweet siren song of coding from\nscratch.\nEither way, it will be safer to do: you’ll have a set of unit tests\nthat can conﬁrm the new code works as it should.\n\n\nREPEATABLE\n122\n7.3\nRepeatable\nJust as every test should be independent from every other\nA-T R IP\ntest, they must be independent of the environment as well.\nThe goal remains that every test should be able to run over\nand over again, in any order, and produce the same results.\nThis means that tests cannot rely on anything in the exter-\nnal environment that isn’t under your direct control.\nThat\nincludes obvious external entities such as databases, sys-\ntem time, network conditions, but also perhaps less obvi-\nous dependents such as global variables.\nAny global state\n(in false singletons or otherwise) really isn’t under your direct\ncontrol—it only seems like it.\nSomething, somewhere, when you least expect it, will alter\nthat state and you’ll end spending a lot a quality time in the\ndebugger trying to discover how you got into that state. That’s\nthe kind of frustration you just don’t need.\nUse mock objects as necessary to isolate the item under test\nand keep it independent from the environment.\nIf you are\nforced to use some element from the real world (a database,\nperhaps), make sure that you won’t get interference from any\nother developer. Each developer needs their own “sandbox”\nto play in, whether that’s their own database instance within\nOracle, or their own webserver on some non-standard port.\nWithout repeatability, you might be in for some surprises at\nthe worst possible moments. What’s worse, these sort of sur-\nprises are usually bogus—it’s not really a bug, it’s just a prob-\nlem with the test. You can’t afford to waste time chasing down\nphantom problems.\nEach test should produce the same results every time. If it\ndoesn’t, then that should tell you that there’s a real bug in\nthe code.\n7.4\nIndependent\nTests need to be kept neat and tidy, which means keeping\nA-TR I P\nthem tightly focused, and independent from the environment\nand each other (remember, other developers may be running\nthese same tests at the same time).\n\n\nPROFESSIONAL\n123\nWhen writing tests, make sure that you are only testing one\nthing at a time.\nNow that doesn’t mean you should use only one assert in a\ntest, but that a test method should test only what the name\nimplies—the same as regular methods in production code. If\nthat means stitching a few methods together to accomplish\nthe test, then so be it. Sometimes an entire test method might\nonly test one small aspect of a complex piece of functionality—\nyou may need multiple test methods to exercise the function-\nality thoroughly.\nAt any rate, you want to achieve a traceable correspondence\nbetween potential bugs and test code. In other words, when\na test fails, it should be obvious where in the code the under-\nlying bug exists without looking at the test code itself. The\nname of the test should tell us all we need to know. Other-\nwise, we’ve got to go hunting for it, and that will just waste\nour time.\nIndependent also means that no test relies on any other test;\nwe should be able to run any individual test at any time, and\nin any order. We really don’t want to have to rely on any other\ntest having run ﬁrst, especially since the ordering will vary\nbetween the different test runners.\nWe’ve shown mechanisms to help you do this: the per-test\nsetup and teardown methods and the per-ﬁxture setup and\nteardown methods. Use these methods to ensure that every\ntest gets a fresh start—and doesn’t impact any test that might\nrun next.\nRemember, you aren’t guaranteed that NUnit tests will run in\nany particular order, and as you start combining tests in ever-\nincreasing numbers, you really can’t afford to carry ordering\ndependencies along with you.\nJohn Donne may have been right about people, but not about\nunit tests: every test should be an island.\n7.5\nProfessional\nThe code you write for a unit test is real; some may argue\nA-TRI P\nit’s even more real than the code you ship to customers. This\n\n\nPROFESSIONAL\n124\nmeans that it must be written and maintained to the same\nprofessional standards as your production code. All the usual\nrules of good design—maintaining encapsulation, honoring\nthe DRY principle, lowering coupling, etc.—must be followed\nin test code just as in production code.\nIt’s easy to fall into the trap of writing very linear test code;\nthat is, code that just plods along doing the same thing over\nand over again, using the same lines of code over and over\nagain, with nary a function or object in sight. That’s a bad\nthing. Test code must be written in the same manner as real\ncode. That means you need to pull out common, repeated bits\nof code and put that functionality in a method instead, so it\ncan be called from several different places.\nYou may ﬁnd you accumulate several related test methods\nthat should be encapsulated in a class.\nDon’t ﬁght it!\nGo\nahead and create a new class, even if it’s only ever used for\ntesting. That’s not only okay, it’s encouraged: test code is real\ncode. In some cases, you may even need to create a larger\nframework, or create a data-driven testing facility (remember\nthe simple ﬁle reader for TestLargest on page 62?).\nDon’t waste time testing aspects that won’t help you. Remem-\nber, you don’t want to create tests just for the sake of creating\ntests. Test code must be thorough in that it must test every-\nthing interesting about a behavior that might break. If it’s not\nlikely to contain a bug, don’t bother testing it. That means\nthat usually you shouldn’t waste time testing things like sim-\nple property accessors:\npublic Money Balance\n{\nget { return balance; }\n}\nFrankly, there’s just not much here to go wrong that the com-\npiler can’t catch.4\nTesting methods such as these is just a\nwaste of time. However, if the property is doing some work\nalong the way, then suddenly it becomes interesting—and we\nwill want to test it:\npublic Money Balance\n4Unless, of course, the IL compiler, JIT compiler, or CLR itself has a bug.\n\n\nTESTING THE TESTS\n125\n{\nget\n{\nreturn posted.GetBalance() -\nunposted.GetDebits() +\nunposted.GetCredits();\n}\n}\nThat’s probably worth testing.\nFinally, expect that, in the end, there will be at least as much\ntest code written as there will be production code. Yup, you\nread that right.\nIf you’ve got 20,000 lines of code in your\nproject, then it would be reasonable to expect that there would\nbe about 20,000 lines or more of unit test code to exercise it.\nThat’s a lot of test code, which is partly why it needs to be\nkept neat and tidy, well designed and well-factored, just as\nprofessional as the production code.\n7.6\nTesting the Tests\nThere is one major conceptual weakness in our plans so far.\nTesting code to make sure it works is a great idea, but you\nhave to write code to perform the tests. What happens when\nthere are bugs in our test code? Does that mean you have to\nwrite test code to test the tests that test the code??? Where\nwill it all end?\nFortunately, you don’t need to go to that extreme. There are\ntwo things you can do to help ensure that the test code is\ncorrect:\n• Improve tests when ﬁxing bugs\n• Prove tests by introducing bugs\nHow to Fix a Bug\nThe steps you take when ﬁxing a bug are very important to\nunit testing. Many times, an existing test will expose a bug in\nthe code, and you can then simply ﬁx the code and watch the\nvigilant test pass.\n\n\nTESTING THE TESTS\n126\nWhen a bug is found “in the wild” and reported back, that\nmeans there’s a hole in the safety net—a missing test. This\nis an opportunity to close the hole, and make sure that this\nparticular bug never escapes into the wild again. All it takes\nis four simple steps:\n1. Identify the bug, or bugs, that caused the errant be-\nhaviour.\n2. Write a test that fails, for each individual bug, to prove\nthe bug exists.5\n3. Fix the code such that the test now passes.\n4. Verify that all tests still pass (i.e., you didn’t break any-\nthing else as a result of the ﬁx).\nThis simple mechanism of applying real-world feedback to\nhelp improve the tests is very effective. Over time, you can\nexpect that your test coverage will steadily increase, and the\nnumber of bugs that escape into the wild from existing code\nwill decrease.\nOf course, as you write new code, you’ll undoubtedly intro-\nduce new bugs, and new classes of bugs, that aren’t being\ncaught by the tests. But when ﬁxing any bug, ask yourself\nthe key question:\nCould this same kind of problem happen any-\nwhere else?\nThen it doesn’t matter whether you’re ﬁxing a bug in an older\nfeature or a new feature; either way, apply what you’ve just\nlearned to the whole project. Encode your new-found knowl-\nedge in all the unit tests that are appropriate, and you’ve done\nmore than just ﬁx one bug. You’ve caught a whole class of\nbugs, and potentially found an opportunity to refactor simi-\nlar code into one place for easier testing, maintenance, and\nenhancement.\n5Sometimes a bit of refactoring may need to happen so that tests can be\nwritten more easily.\n\n\nTESTING THE TESTS\n127\n[Test]\npublic void Add()\n{\n// Create a new account object\nAccount acct = new Account();\n// Populate with our test person\nacct.SetPerson(TEST_PERSON_1);\n// Add it to the database\nDatabaseHandler.Add(acct);\n// Should find it\nAssert.IsTrue(DatabaseHandler.Search(TEST_PERSON_1);\n}\nFigure 7.1: Test Adding a Person to a Database\nSpring the Trap\nIf you’re not sure that a test is written correctly, the easiest\nthing to do is to “spring the trap”: cause the production code\nto exhibit the very bug you’re trying to detect, and verify that\nthe test fails as expected.\nFor instance, suppose you’ve got a test method that adds a\ncustomer account to the database and then tries to ﬁnd it,\nsomething like the code in Figure 7.1. Perhaps you’re not cer-\ntain that the “ﬁnding” part is really working or not—it might\nbe reporting success even if the record wasn’t added correctly.\nSo maybe you’ll go into the Add() method for Database-\nHandler and short-circuit it: just return instead of actually\nadding the record to the database. Now you should see the\nassertion fail, because the record has not been added.\nBut wait, you may cry, what about a leftover record from a\nprevious test run? Won’t that be in the database? No, it won’t,\nfor several reasons:\n• You may not really be testing against a live database.\nThe code exercised by the above test case lies between\nthe add method shown and the actual low-level database\ncalls.\nThose database calls may well be handled by a\nmock object, whose data is not held persistently in be-\ntween runs.\n",
      "page_number": 131
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 141-148)",
      "start_page": 141,
      "end_page": 148,
      "detection_method": "topic_boundary",
      "content": "TESTING THE TESTS\n128\n• Tests are independent. All tests can be run in any or-\nder, and do not depend on each other, so even if a real\ndatabase is part of this test, the setup and tear-down\nmust ensure that you get a “clean sandbox” to play in.\nThe attempt above to spring the trap can help prove that\nthis is true.\nNow the Extreme Programming folks claim that their disci-\nplined practice of test-ﬁrst development avoids the problem\nof poor tests that don’t fail when they should.\nIn test-ﬁrst\ndevelopment, you only ever write code to ﬁx a failing test. As\nsoon as the test passes, then you know that the code you just\nadded ﬁxed it. This puts you in the position where you always\nknow with absolute certainty that the code you introduced\nﬁxes the failing test that caused you to write the code in the\nﬁrst place.\nBut there’s many a slip ’twixt the cup and the lip, and while\ntest-ﬁrst development does improve the situation dramatical-\nly, there will still be opportunities to be misled by coinci-\ndences. The practice of pair programming further reduces the\nchance of these kinds of slip-ups, but you we may not always\nhave someone to pair with. For those occasions, you can sat-\nisfy any lingering doubts by deliberately “springing the trap”\nto make sure that all is as you expect.\nFinally, remember to write tests that are A-TRIP (Automatic,\nThorough, Repeatable, Independent, Professional); keep add-\ning to your unit tests as new bugs and types of bugs are dis-\ncovered; and check to make sure your tests really do ﬁnd the\nbugs they target.\nThen sit back and watch problems on your project disappear\nlike magic.\n\n\nChapter 8\nTesting on a Project\nUp to now we’ve talked about testing as an individual, solitary\nexercise.\nBut of course, in the real world you’ll likely have\nteammates to work with. You’ll all be unit testing together,\nand that brings up a couple of issues.\n8.1\nWhere to Put Test Code\nOn a small, one-person project, the location of test code and\nencapsulation of the production code may not be very impor-\ntant, but on larger projects it can become a critical issue.\nThere are several different ways of structuring your produc-\ntion and test code that we’ll look at here.\nIn general, you don’t want to break any encapsulation for the\nsake of testing (or as Mom used to say, “don’t expose your pri-\nvates!”). Most of the time, you should be able to test a class\nby exercising its public methods. If there is signiﬁcant func-\ntionality that is hidden behind private or protected access,\nthat might be a warning sign that there’s another class in\nthere struggling to get out. When push comes to shove, how-\never, it’s probably better to break encapsulation with working,\ntested code than it is to have good encapsulation of untested,\nnon-working code.\n\n\nWHERE TO PUT TEST CODE\n130\nSame directory\nSuppose you are writing a class named:\nPragProg.Wibble.Account\nwith a corresponding test in:\nPragProg.Wibble.AccountTest\nThe ﬁrst and easiest method of structuring test code is to sim-\nply include it right in the same project and assembly alongside\nthe production code.\nThis has the advantage that AccountTest can access inter-\nnal and protected internal member variables and meth-\nods of Account. But the disadvantage is that the test code\nis lying around, cluttering up the production code directory.\nThis may or may not be a problem depending on your method\nof creating a release to ship to customers.\nMost of the time, it’s enough of a problem that we prefer one\nof the other solutions. But for small projects, this might be\nsufﬁcient.\nSeparate Assemblies\nThe next option is to create your tests in a separate assembly\nfrom the production code.\nThis has the advantage of keeping a clean separation between\ncode that you ship and code for testing.\nThe disadvantage is that now the test code is in a different\nassembly; You won’t be able to access internal or protected\ninternal members unless your test code uses a subclass of\nthe production code that exposes the necessary members. For\ninstance, suppose the class you want to test looks like this:\nnamespace FacilitiesManagment {\npublic class Pool {\nprotected Date lastCleaned;\npublic void xxxx xx {\nxxx xxx xxxx;\n}...\n}\n}\n\n\nWHERE TO PUT TEST CODE\n131\nAcme.Pool\n#LastCleaned()\nAcme.Test.PoolForTesting\n+LastCleaned()\nprotected\nmethod in\nproduction\ncode\nPRODUCTION CODE\npublic in test\ncode\nTEST CODE\nFigure 8.1: Subclasses Expose Methods for Testing\nYou need to get at that non-public bit of data that tells you\nwhen the pool was last cleaned for testing, but there’s no ac-\ncessor for it. (If there were, the pool association would prob-\nably sue us; they don’t like to make that information public.)\nSo you make a subclass that exposes it just for testing.\nusing FacilitiesManagment;\nnamespace FacilitiesManagmentTesting {\npublic class PoolForTesting : Pool {\npublic Date LastCleaned {\nget { return lastCleaned; }\n}\n}\n}\nYou then use PoolForTesting in the test code instead of us-\ning Pool directly (see Figure 8.1). In fact, you could make this\nclass internal to the test assembly (to ensure that we don’t\nget sued).\nWhatever convention the team decides to adopt, make sure it\ndoes so consistently. You cannot have some of the tests in\nthe system set up one way, and other tests elsewhere set up\na different way. Pick a style that looks like it will work in your\nenvironment and stick with it for all of the system’s unit tests.\n\n\nWHERE TO PUT NUNIT\n132\n8.2\nWhere to Put NUnit\nOne issue that comes up on real projects is how to distribute\nNUnit itself.\nYou could have each individual developer install the latest ver-\nsion on their own workstations (as well as on the automated\nbuild machine). All the developers would have to install NUnit\ninto the same directory, and make sure to reference that spe-\nciﬁc nunit.framework.dll assembly as not some random\none in the GAC or elsewhere via a shortcut or symlink. This is\nall actually more difﬁcult than it sounds, especially with little\nbugs that Visual Studio has with assembly references thrown\nin for fun.\nInstead, you should distribute NUnit via your version control\nsystem.\nMany .NET and Java projects deﬁne both a src/\ndirectory and a lib/ directory. The src/ directory contains\nthe source code to the project, and the lib/ directory contains\npre-compiled components (usually third-party).\nIn this context, you’d have a lib/nunit/ directory that con-\ntains the NUnit binary distribution. Your projects and NAnt\nﬁles would reference the nunit.framework.dll in this direc-\ntory, and developers would run the nunit.exe GUI from this\ndirectory via a shortcut.\nNow keeping developers’ versions of NUnit synchronized is\neasy, as is deploying any upgrades or customizations. It keeps\nthe environment consistent, freeing up time that would other-\nwise be spent on ﬁguring out mismatched NUnit issues (which\nusually manifest themselves in odd ways). You may want to\ndiscourage developers from installing NUnit on their work-\nstation to reduce confusion. If they do, keep an eye out for\nchanges in the project or NAnt build ﬁles that reference NUnit\nassemblies other than those in the project’s lib/nunit/ di-\nrectory.\n8.3\nTest Courtesy\nThe biggest difference between testing by yourself and testing\nwith others lies in synchronizing working tests and code.\n\n\nTEST COURTESY\n133\nObfuscation and Packaging\nMatt tells the following story about packaging, obfus-\ncation, and manual maintenance:\n“Recently I worked on a project that used a code ob-\nfuscation program, which the team thought helped\nprotect their intellectual property.\nThey packaged\ntheir unit tests in the same assembly as their produc-\ntion code, but the unit tests were #if’d out in the Re-\nlease build. Any time a developer added a new test\nﬁle, they had to remember to add the #if or risk vio-\nlating the obfuscation policy. Or, did they?\nPutting the tests into the assembly was reducing the\neffective design feedback of their packaging (which\nhad major issues), so I proposed to extract the unit\ntests into a separate assembly so the design issues\ncould be made more obvious. They said this was im-\npossible because the unit tests were testing classes\nmarked ’internal’ and thus the tests had to be inside\nthe same assembly as the production code.\nI was curious why these classes had to be internal,\nand this turned up an amusing (albeit embarrassing)\nmisunderstanding: the team thought that in order\nfor the obfuscater to work properly, classes had to\nbe marked as internal. That is, they thought public\nclasses wouldn’t be obfuscated in name or in code.\nThis was a mistake, of course. This particular obfus-\ncater didn’t really care, and I was able to conﬁgure\nit to obfuscate everything just ﬁne. One of the neat\ntricks that came out of this was that this obfuscation\nproduct was able to take several assemblies that ref-\nerenced each other, combine them into one binary,\nand prune out unused methods and code.\nBecause the unit tests weren’t referenced directly in\nany of the application code, they were pruned out\nautomatically. The manual #if statements they kept\nusing could simply be removed. This also opened the\ndoor to making those internal classes public; the unit\ntests could then be extracted into a separate assem-\nbly, and design feedback could be obtained and\nacted upon appropriately.”\n\n\nTEST COURTESY\n134\nWhen working with other members of a team, you will be us-\ning some sort of version control system, such as SubVersion,\nCVS, or (for the more masochistic among us), Visual Source-\nSafe. (If you aren’t familiar with version control, or would like\nsome assistance in getting it set up and working correctly,\nplease see [TH03].)\nIn a team environment (and even in a personal environment)\nyou should make sure that when you check in code (or other-\nwise make it available to everyone) that it has complete unit\ntests, and that it passes all of them. In fact, every test in the\nwhole system should continue to pass with your new code.\nThe rule is very simple: As soon as anyone else can access\nyour code, all tests everywhere need to pass. Since you should\nnormally work in fairly close synchronization with the rest of\nthe team and the version control system, this boils down to\n“all tests pass all the time.”\nMany teams institute policies to help “remind” developers of\nthe consequences of breaking the build, or breaking the tests.\nThese policies might begin by listing potential infractions in-\nvolving code that you have checked in (or otherwise made\navailable to other developers):\n• Incomplete code (e.g., checking in only one class ﬁle but\nforgetting to check in other ﬁles it may depend upon).\n• Code that doesn’t compile.\n• Code that compiles, but breaks existing code such that\nexisting code no longer compiles.\n• Code without corresponding unit tests.\n• Code with failing unit tests.\n• Code that passes its own tests, but causes other tests\nelsewhere in the system to fail.\nIf found guilty of any of these heinous crimes, you may be sen-\ntenced to providing donuts for the entire team the next morn-\ning, or beer or soda, or frozen margaritas, or maybe you’ll have\nto nursemaid the build machine, or some other token, menial\ntask.\n\n\nTEST FREQUENCY\n135\nA little lighthearted law enforcement usually provides enough\nmotivation against careless accidents. But what happens if\nyou have to make an incompatible change to the code, or if\nyou make a change that does cause other tests to fail else-\nwhere in the system?\nThe precise answer depends on the methodology and process\nyou’re using on the project, but somehow you need to coordi-\nnate your changes with the folks who are responsible for the\nother pieces of code—which may well be you! The idea is to\nmake all of the necessary changes at once, so the rest of the\nteam sees a coherent picture (that actually works) instead of\na fragmented, non-functional “work in progress.” (For more\ninformation on how to use version control to set up experi-\nmental developer branches, see [TH03].)\nSometimes the real world is not so willing, and it might take a\nfew hours or even a few days to work out all of the incompati-\nble bits and pieces, during which time the build is broken. If it\ncan’t be helped, then make sure that it is well-communicated.\nMake sure everyone knows that the build will be broken for\nthe requisite amount of time so that everyone can plan around\nit as needed. If you’re not involved, maybe it would be a good\ntime to take your car in for an oil change or slip off to the\nbeach for a day or two. If you are involved, get it done quickly\nso everyone else can come back from the beach and get to\nwork!\n8.4\nTest Frequency\nHow often should you run unit tests?\nIt depends on what\nyou’re doing, and your personal habits, but here are some\ngeneral guidelines that we ﬁnd helpful. You want to perform\nenough testing to make sure you’re catching everything you\nneed to catch, but not so much testing that it interferes with\nproducing production code.\nWrite a new method\nCompile and run local unit tests.\nFix a bug\nWrite and run tests that demonstrate bug; ﬁx the bug\nand re-run unit tests.\n",
      "page_number": 141
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 149-156)",
      "start_page": 149,
      "end_page": 156,
      "detection_method": "topic_boundary",
      "content": "TESTS AND LEGACY CODE\n136\nAny successful compile\nRun local unit tests.\nEach check-in to version control\nRun all module or system unit tests.\nContinuously\nA dedicated machine should be running a full build and\ntest, from scratch, automatically throughout the day (ei-\nther periodically or on check-in to version control).\nNote that for larger projects, you might not be able to compile\nand test the whole system in under a few hours. You may only\nbe able to run a full build and test overnight. For even larger\nprojects, it may have to be every couple of days—and that’s a\nshame, because the longer the time between automatic builds\nthe longer the “feedback gap” between creation of a problem\nand its identiﬁcation.\nThe reason to have a more-or-less continuous build is so that\nit can identify any problems quickly. You don’t want to have to\nwait for another developer to stumble upon a build problem if\nyou can help it. Having a build machine act as a constant de-\nveloper increases the odds that it will ﬁnd a problem, instead\nof a real developer.\nWhen the build machine does ﬁnd a problem, then the whole\nteam can be alerted to the fact that it’s not safe to get any new\ncode just yet, and can continue working with what they have.\nThat’s better than getting stuck in a situation where you’ve\ngotten fresh code that doesn’t work.\nFor more information on setting up automatic build and test-\ning systems, nightly and continuous builds, and automation\nin general please see [Cla04].\n8.5\nTests and Legacy Code\nSo far, we’ve talked about performing unit tests in the context\nof new code. But we haven’t said what to do if your project\nhas a lot of code already—code that doesn’t have unit tests.\nIt all depends on what kind of state that code is in. If it’s rea-\nsonably well-factored and modular, such that you can get at\n\n\nTESTS AND LEGACY CODE\n137\nall of the individual pieces you need to, then you can add unit\ntests fairly easily. If, on the other hand, it’s just a “big ball of\nmud” all tangled together, then it might be close to impossi-\nble to test without substantial rewriting. Most older projects\naren’t perfectly factored, but are usually modular enough that\nyou can add unit tests.\nFor new code that you write, you’ll obviously write unit tests\nas well. This may mean that you’ll have to expose or break out\nparts of the existing system, or create mock objects in order\nto test your new functionality.\nFor existing code, you might choose to methodically add unit\ntests for everything that is testable. But that’s not very prag-\nmatic. It’s better to add tests for the most broken stuff ﬁrst,\nto realize a better return on investment of effort.\nThe most important aspect of unit tests in this environment\nis to prevent back-sliding: to avoid the death-spiral where\nmaintenance ﬁxes and enhancements cause bugs in existing\nfeatures. We use NUnit unit tests as regression tests during\nnormal new code development (to make sure new code doesn’t\nbreak anything that had been working), but regression testing\nis even more important when dealing with legacy code.\nAnd it doesn’t have to cover the entire legacy code base, just\nthe painful parts.\nConsider the following true story from a\npragmatic developer (the team in question happened to be us-\ning Java and JUnit for this particular project, but they could\njust as easily have been using C#, Cobol, C++, Ruby, or any\nother programming language):\nRegression Tests Save the Day\n“Tibbert Enterprises1 ships multiple applications,\nall of which are based on a common Lower Level\nLibrary that is used to access the object database.\nOne day I overheard some application develop-\ners talking about a persistent problem they were\nhaving. In the product’s Lower Level interface, you\ncan look up objects using the object name, which\n1Not their real name.\n\n\nTESTS AND LEGACY CODE\n138\nincludes a path to the object. Since the application\nhas several layers between it and the Lower Level\ncode, and the Lower Level code has several more\nlayers to reach the object database, it takes a while\nto isolate a problem when the application breaks.\nAnd the application broke.\nAfter half the ap-\nplication team spent an entire day tracking down\nthe bug, they discovered the bug was in the Lower\nLevel code that accessed the database. If you had\na space in the name, the application died a violent,\nmessy death. After isolating the Lower Level code\nrelated to the database access, they presented the\nbug to the owner of the code, along with a ﬁx. He\nthanked them, incorporated their ﬁx, and commit-\nted the ﬁxed code into the repository.\nBut the next day, the application died.\nOnce\nagain, a team of application developers tracked it\ndown. It took only a half-a-day this time (as they\nrecognized the code paths by now), and the bug\nwas in the same place. This time, it was a space\nin the path to the object that was failing, instead of\na space in the name itself. Apparently, while inte-\ngrating the ﬁx, the developer had introduced a new\nbug.\nOnce again, they tracked it down and pre-\nsented him with a ﬁx. It’s Day Three, and the ap-\nplication is failing again! Apparently the developer\nin question re-introduced the original bug.\nThe application manager and I sat down and\nﬁgured out that the equivalent of nearly two man-\nmonths of effort had been spent on this one issue\nover the course of one week by his team alone (and\nthis likely affected other teams throughout the com-\npany).\nWe then developed JUnit tests that tested\nthe Lower Level API calls that the application prod-\nuct was using, and added tests for database access\nusing spaces in both the object name and in the\npath. We put the product under the control of our\ncontinuous-build-and-test program (using Cruise-\nControl) so that the unit tests were run automat-\nically every time code got committed back to the\nrepository.\n\n\nTESTS AND CODE REVIEWS\n139\nSure enough, the following week, the test failed\non two successive days, at the hands of the original\ndeveloper. He actually came to my ofﬁce, shook my\nhand, and thanked me when he got the automatic\nnotiﬁcation that the tests had failed.\nYou see, without the JUnit test, the bad code\nmade it out to the entire company during the night-\nly builds. But with our continuous build and test,\nhe (and his manager and tester) saw the failure at\nonce, and he was able to ﬁx it immediately before\nanyone else in the company used the code. In fact,\nthis test has failed half a dozen times since then.\nBut it gets caught, so its not a big deal anymore.\nThe product is now stable because of these tests.\nWe now have a rule that any issue that pops\nup twice must have a JUnit test by the end of the\nweek.”\nIn this story, Tibbert Enterprises aren’t using unit testing to\nprove things work so much as they are using it to inoculate\nagainst known issues. As they slowly catch up, they’ll even-\ntually expand to cover the entire product with unit tests, not\njust the most broken parts.\nWhen you come into a shop with no automated tests of any\nkind, this seems to be a very effective approach. Remember,\nthe only way to eat an elephant is one bite at a time.\n8.6\nTests and Code Reviews\nTeams that enjoy success often hold code reviews. This can\nbe an informal affair where a senior person just gives a quick\nlook at the code. Or perhaps two people are working on the\ncode together, using Extreme Programming’s “Pair Program-\nming” practice. Or maybe it’s a very formal affair with check-\nlists and a small committee.\nHowever you perform code reviews (and we suggest that you\ndo), make the test code an integral part of the review process.\nSince test code is held up to the same high standards as pro-\nduction code, it should be reviewed as well.\n\n\nTESTS AND CODE REVIEWS\n140\nIn fact, it can sometimes be helpful to expand on the idea of\n“test-ﬁrst design” to include both writing and reviewing test\ncode before writing production code. That is, code and review\nin this order:\n1. Write test cases and/or test code.\n2. Review test cases and/or test code.\n3. Revise test cases and/or test code per review.\n4. Write production code that passes the tests.\n5. Review production and test code.\n6. Revise test and production code per review.\nReviews of the test code are incredibly useful. Not only are\nreviews more effective than testing at ﬁnding bugs in the ﬁrst\nplace, but by having everyone involved in reviews you can\nimprove team communication. People on the team get to see\nhow others do testing, see what the team’s conventions are,\nand help keep everyone honest.\nYou can use the checklists on page 194 of this book to help\nidentify possible test cases in reviews. But don’t go overboard\ntesting things that aren’t likely to break, or repeat essentially\nsimilar tests over and over just for the sake of testing.\nFinally, you may want to keep track of common problems\nthat come up again and again. These might be areas where\nmore training might be needed, or perhaps something else\nthat should be added to your standard review checklist.\nFor example, at a client’s site several years ago, we discovered\nthat many of the developers misunderstood exception han-\ndling. The code base was full of fragments similar to the fol-\nlowing:\ntry\n{\nDatabaseConnection dbc = new DatabaseConnection();\nInsertNewRecord(dbc, record);\ndbc.Close();\n}\ncatch (Exception) {}\nThat is to say, they simply ignored any exceptions that might\nhave occurred.\nNot only did this result in random miss-\n\n\nTESTS AND CODE REVIEWS\n141\nDelusional Exception Handling\nMatt adds this story:\nI was working on a project where the company’s CTO\nlittered the code with empty catch-all statements.\nWhen running a run-time analysis tool, I noticed that\nseveral dozen exceptions were being thrown and\nhandled. Upon further inspection, I saw a piece of\ncode that would almost always fail because it was—\nwait for it—dividing by a value that was zero most of\nthe time.\nThe team found this apalling, so we spent a day\ncleaning up all the empty catch-all statements. The\nCTO was upset because the product was now more\nvisibly unstable. He demanded the team put the bad\nexception handling back in. The team refused—the\nbugs and broken functionality were always present,\nthe difference was we could see how bad it was.\ning records, but the system leaked database connections as\nwell—any error that came up would cause the Close to be\nskipped.\nWe added this to the list of known, typical problems to be\nchecked during reviews. As code was reviewed, any of these\ninfamous catch statements that were discovered were ﬁrst\nidentiﬁed, then proper unit tests were put in place to force\nvarious error conditions (the “E” in RIGHT-BICEP), and the\ncode was ﬁxed to either propagate or handle the exception.\nSystem stability increased tremendously as a result of this\nsimple process. For reference, the minimal ﬁx is to close (or\ndispose) resources in a finally clause. That way, they’ll be\ncleaned up when control ﬂow leaves the try block—whether\nan exception is thrown or not.\ntry\n{\nDatabaseConnection dbc = new DatabaseConnection();\nInsertNewRecord(dbc, record);\n}\nfinally\n{\n\n\nTESTS AND CODE REVIEWS\n142\ndbc.Close()\n}\n\n\nChapter 9\nDesign Issues\nSo far we have discussed unit testing as it helps you to un-\nderstand and verify the functional, operational characteristics\nof your code. But unit testing offers several opportunities to\nimprove the design and architecture of your code as well.\nIn this chapter, we’ll take a look at the following design-level\nissues:\n• Better separation of concerns by designing for testability\n• Clarifying design by deﬁning class invariants\n• Improving interfaces with test-driven design\n• Establishing and localizing validation responsibilities\n9.1\nDesigning for Testability\n“Separation of Concerns” is probably the single most impor-\ntant concept in software design and implementation. It’s the\ncatch-all phrase that encompasses encapsulation, orthogo-\nnality, coupling, and all those other computer science terms\nthat boil down to “write shy code” [HT00].\nYou can keep your code well-factored (i.e., “shy”) and easier to\nmaintain by explicitly designing code to be testable. For ex-\nample, suppose you are writing a method that will sleep until\nthe top of the next hour. You’ve got a bunch of calculations\nand then a Sleep():\n",
      "page_number": 149
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 157-164)",
      "start_page": 157,
      "end_page": 164,
      "detection_method": "topic_boundary",
      "content": "DESIGNING FOR TESTABILITY\n144\npublic void SleepUntilNextHour() {\nint howlong;\nxx xxxx x xxxx xx xx xxx;\n// Calculate how long to wait...\nx x xx xxx xxx x x xx;\nxx xxxx x xxxx xx xx xxx;\nThread.Sleep(howlong);\nreturn;\n}\nHow will you test that? Wait around for an hour? Set a timer,\ncall the method, wait for the method to return, check the\ntimer, handle the cases when the method doesn’t get called\nwhen it should—this is starting to get pretty messy. We saw\nsomething similar back in Chapter 6, but this issue is impor-\ntant enough to revisit. Once again, we’ll refactor the method\nin order to make testing easier.\nInstead of combining the calculation of how many millisec-\nonds to sleep with the Sleep() method itself, split them up:\npublic void SleepUntilNextHour() {\nint howlong = MilliSecondsToNextHour(DateTime.Now);\nThread.Sleep(howlong);\nreturn;\n}\nWhat’s likely to break? The system’s Sleep call? Or our code\nthat calculates the amount of time to wait? It’s probably a fair\nbet to say that .NET’s Thread.Sleep() works as advertised\n(even if it doesn’t, our rule is to always suspect our own code\nﬁrst, see the tip Select Isn’t Broken in [HT00]). So for now, you\nonly need to test that the number of milliseconds is calculated\ncorrectly, and what might have been a hairy test with timers\nand all sorts of logic (not to mention an hour’s wait) can be\nexpressed very simply as:\nAssert.AreEqual(10000, MilliSecondsToNextHour(DATE_1));\nIf we’re conﬁdent that MilliSecondsToNextHour() works to\nour satisfaction, then the odds are that SleepUntilNext-\nHour() will be reliable as well—if it is not, then at least we\nknow that the problem must be related to the sleep itself, and\nnot to the numerical calculation. You might even be able to\nreuse the MilliSecondsToNextHour() method in some other\ncontext.\n\n\nREFACTORING FOR TESTING\n145\nFigure 9.1: Recipes GUI Screen\nThis is what we mean when we claim that you can improve\nthe design of code by making it easier to test. By changing\ncode so that you can get in there and test it, you’ll end up\nwith a cleaner design that’s easier to extend and maintain as\nwell as test.\nBut instead of boring you with examples and techniques, all\nyou really need to do is remember this one fundamental ques-\ntion when writing code:\nHow am I going to test this?\nIf the answer is not obvious, or if it looks like the test would be\nugly or hard to write, then take that as a warning signal. Your\ndesign probably needs to be modiﬁed; change things around\nuntil the code is easy to test, and your design will end up\nbeing far better for the effort.\n\n\nREFACTORING FOR TESTING\n146\nRecipes\nname\ningredients\nLoad()\nSave()\nShowGUI()\nFigure 9.2: Original Recipes Static Class Diagram\n9.2\nRefactoring for Testing\nLet’s look at a real-life example.\nHere are excerpts from a\nnovice’s ﬁrst attempt at a recipe management system.\nThe\nGUI, shown in Figure 9.1 on the preceding page, is pretty\nstraightforward.\nThere’s only one class, with GUI behavior\nand ﬁle I/O intermixed.\nIt reads and writes individual recipes to ﬁles, using a line-\noriented format, somewhat like an INI or properties ﬁle:\nNAME=Cheeseburger\nINGREDIENTS=3\n1/4 lb ground sirloin\n3 slices Vermont cheddar cheese\n2 slices maple-cured bacon\ncheeseburger.txt\nAnd here’s the code, in its entirety. As is, this is pretty hard to\ntest. You’ve got to run the whole program and operate the GUI\nto get at any part of it. All of the ﬁle I/O and search routines\naccess the widgets directly, and so are tightly coupled to the\nGUI code (see, for instance, lines 138, 150, 157, and 166). In\nfact, the UML diagram for this class, shown in Figure 9.2, is\nkind of embarrassing—it’s just one big class! Unfortunately,\nthis kind of code is commonplace in many .NET projects be-\ncause Visual Studio’s designer-generated code gently coerces\nprogrammers to add logic directly into the Form or Control\nclass. The forms designers for WinForms and ASP.NET are\ngreat tools—just be aware of these sinful temptations.\nLine 1\nusing System;\n-\nusing System.Drawing;\n\n\nREFACTORING FOR TESTING\n147\n-\nusing System.Collections;\n-\nusing System.ComponentModel;\n5\nusing System.Windows.Forms;\n-\nusing System.Data;\n-\nusing System.IO;\n-\n-\npublic class Recipes : Form {\n10\nprivate Button exitButton = new Button();\n-\nprivate StatusBar statusBar = new StatusBar();\n-\nprivate GroupBox groupBox1 = new GroupBox();\n-\nprivate TextBox titleText = new TextBox();\n-\nprivate Button searchButton = new Button();\n15\nprivate ListBox searchList = new ListBox();\n-\nprivate GroupBox groupBox2 = new GroupBox();\n-\nprivate ListBox ingredientsList = new ListBox();\n-\nprivate Button removeButton = new Button();\n-\nprivate TextBox ingredientsText = new TextBox();\n20\nprivate Button saveButton = new Button();\n-\nprivate Button addButton = new Button();\n-\n-\npublic Recipes() {\n-\nInitializeComponent();\n25\n}\n-\n-\nprivate void InitializeComponent() {\n-\nexitButton.Location =\n-\nnew System.Drawing.Point(120, 232);\n30\nexitButton.Size = new System.Drawing.Size(48, 24);\n-\nexitButton.Text = \"Exit\";\n-\nexitButton.Click +=\n-\nnew System.EventHandler(exitButton_Click);\n-\n35\nstatusBar.Location = new System.Drawing.Point(0, 261);\n-\nstatusBar.Size = new System.Drawing.Size(400, 16);\n-\n-\ngroupBox1.Controls.Add(searchList);\n-\ngroupBox1.Controls.Add(searchButton);\n40\ngroupBox1.Controls.Add(titleText);\n-\ngroupBox1.Location = new System.Drawing.Point(8, 8);\n-\ngroupBox1.Size = new System.Drawing.Size(176, 216);\n-\ngroupBox1.TabStop = false;\n-\ngroupBox1.Text = \"Recipes\";\n45\n-\nsearchList.Location = new System.Drawing.Point(16, 56);\n-\nsearchList.Size = new System.Drawing.Size(144, 147);\n-\nsearchList.SelectedIndexChanged +=\n-\nnew System.EventHandler(\n50\nsearchList_SelectedIndexChanged);\n-\n-\nsearchButton.Location = new System.Drawing.Point(112, 24);\n-\nsearchButton.Size = new System.Drawing.Size(48, 24);\n-\nsearchButton.Text = \"Search\";\n55\nsearchButton.Click +=\n-\nnew System.EventHandler(searchButton_Click);\n-\n-\ntitleText.Location = new System.Drawing.Point(16, 24);\n\n\nREFACTORING FOR TESTING\n148\n-\ntitleText.Size = new System.Drawing.Size(88, 20);\n60\n-\ngroupBox2.Controls.Add(addButton);\n-\ngroupBox2.Controls.Add(ingredientsText);\n-\ngroupBox2.Controls.Add(removeButton);\n-\ngroupBox2.Controls.Add(ingredientsList);\n65\ngroupBox2.Location = new System.Drawing.Point(200, 8);\n-\ngroupBox2.Size = new System.Drawing.Size(192, 248);\n-\ngroupBox2.TabStop = false;\n-\ngroupBox2.Text = \"Ingredients\";\n-\n70\naddButton.Location = new System.Drawing.Point(136, 176);\n-\naddButton.Size = new System.Drawing.Size(48, 23);\n-\naddButton.Text = \"Add\";\n-\naddButton.Click +=\n-\nnew System.EventHandler(addButton_Click);\n75\n-\ningredientsText.Location = new System.Drawing.Point(16, 176);\n-\ningredientsText.Size = new System.Drawing.Size(112, 20);\n-\n-\nremoveButton.Enabled = false;\n80\nremoveButton.Location = new System.Drawing.Point(16, 208);\n-\nremoveButton.Size = new System.Drawing.Size(168, 32);\n-\nremoveButton.Text = \"Remove\";\n-\nremoveButton.Click +=\n-\nnew System.EventHandler(removeButton_Click);\n85\n-\ningredientsList.Location = new System.Drawing.Point(16, 24);\n-\ningredientsList.Size = new System.Drawing.Size(160, 134);\n-\ningredientsList.SelectedIndexChanged +=\n-\nnew System.EventHandler(\n90\ningredientsList_SelectedIndexChanged);\n-\n-\nsaveButton.Enabled = false;\n-\nsaveButton.Location = new System.Drawing.Point(40, 232);\n-\nsaveButton.Size = new System.Drawing.Size(48, 24);\n95\nsaveButton.Text = \"Save\";\n-\nsaveButton.Click +=\n-\nnew System.EventHandler(saveButton_Click);\n-\n-\nAutoScaleBaseSize = new System.Drawing.Size(5, 13);\n100\nClientSize = new System.Drawing.Size(400, 277);\n-\nControls.Add(saveButton);\n-\nControls.Add(groupBox2);\n-\nControls.Add(groupBox1);\n-\nControls.Add(statusBar);\n105\nControls.Add(exitButton);\n-\ngroupBox1.ResumeLayout(false);\n-\ngroupBox2.ResumeLayout(false);\n-\nResumeLayout(false);\n-\n}\n110\n-\n[STAThread]\n-\nstatic void Main() {\n-\nDirectory.SetCurrentDirectory(@\"..\\..\\recipes\\\");\n\n\nREFACTORING FOR TESTING\n149\n-\nApplication.Run(new Recipes());\n115\n}\n-\n-\nprivate void exitButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nApplication.Exit();\n120\n}\n-\n-\nprivate void searchButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nString toMatch = \"*\" + titleText.Text + \"*\";\n125\n-\ntry {\n-\nstring [] matchingFiles = Directory.GetFiles(@\".\", toMatch);\n-\nsearchList.DataSource = matchingFiles;\n-\n}\n130\ncatch (Exception error) {\n-\nstatusBar.Text = error.Message;\n-\n}\n-\n}\n-\n135\nprivate void\n-\nsearchList_SelectedIndexChanged(object sender,\n-\nSystem.EventArgs e) {\n-\nstring file = (string)searchList.SelectedItem;\n-\nstring line;\n140\nchar [] delim = new char[] { ’=’ };\n-\n-\nstatusBar.Text = file;\n-\n-\nusing (StreamReader reader =\n145\nnew StreamReader(file)) {\n-\nwhile ((line = reader.ReadLine()) != null) {\n-\nstring [] parts = line.Split(delim, 2);\n-\nswitch (parts[0]) {\n-\ncase \"NAME\":\n150\ntitleText.Text = parts[1];\n-\nbreak;\n-\ncase \"INGREDIENTS\":\n-\ntry {\n-\nint count = Int32.Parse(parts[1]);\n155\ningredientsList.Items.Clear();\n-\nfor (int i = 0; i < count; i++)\n-\ningredientsList.Items.Add(reader.ReadLine());\n-\n}\n-\ncatch (Exception error) {\n160\nstatusBar.Text = \"Bad ingredient count: \" +\n-\nerror.Message;\n-\nreturn;\n-\n}\n-\nbreak;\n165\ndefault:\n-\nstatusBar.Text = \"Invalid recipe line: \" + line;\n-\nreturn;\n-\n}\n-\n}\n\n\nREFACTORING FOR TESTING\n150\n170\n}\n-\nsaveButton.Enabled = false;\n-\n}\n-\n-\nprivate void removeButton_Click(object sender,\n175\nSystem.EventArgs e) {\n-\nint index = ingredientsList.SelectedIndex;\n-\nif (index >= 0) {\n-\nstatusBar.Text = \"Removed \" +\n-\ningredientsList.SelectedItem;\n180\ningredientsList.Items.RemoveAt(index);\n-\nsaveButton.Enabled = true;\n-\n}\n-\n}\n-\n185\nprivate void addButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nstring newIngredient = ingredientsText.Text;\n-\nif (newIngredient.Length > 0) {\n-\ningredientsList.Items.Add(newIngredient);\n190\nsaveButton.Enabled = true;\n-\n}\n-\n}\n-\n-\nprivate void\n195\ningredientsList_SelectedIndexChanged(object sender,\n-\nSystem.EventArgs e) {\n-\nint index = ingredientsList.SelectedIndex;\n-\nif (index < 0)\n-\nremoveButton.Enabled = false;\n200\nelse {\n-\nremoveButton.Text = \"Remove \" +\n-\ningredientsList.SelectedItem;\n-\nremoveButton.Enabled = true;\n-\n}\n205\n}\n-\n-\nprivate void saveButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nstring fileName = titleText.Text + \".txt\";\n210\nICollection items = ingredientsList.Items;\n-\nusing (StreamWriter file =\n-\nnew StreamWriter(fileName, false)) {\n-\nfile.WriteLine(\"NAME={0}\", titleText.Text);\n-\nfile.WriteLine(\"INGREDIENTS={0}\", items.Count);\n215\nforeach (string line in items) {\n-\nfile.WriteLine(line);\n-\n}\n-\n}\n-\nstatusBar.Text = \"Saved \" + fileName;\n220\n}\n-\n}\nRecipes.cs\nWe clearly need to improve this code. Let’s begin by making a\nseparate object to hold a recipe, so that we can construct test\n\n\nREFACTORING FOR TESTING\n151\nrecipe data easily and toss it back and forth to the screen,\ndisk, network, or wherever. This is just a simple data holder,\nwith accessors for the data members.\nLine 1\nusing System;\n-\nusing System.Collections.Generic;\n-\nusing System.Collections.ObjectModel;\n-\n5\npublic class Recipe\n-\n{\n-\nprotected string name;\n-\nprotected List<string> ingredients;\n-\n10\npublic Recipe()\n-\n{\n-\nname = string.Empty;\n-\ningredients = new List<string>();\n-\n}\n15\n-\npublic Recipe(Recipe another)\n-\n{\n-\nname = another.name;\n-\ningredients = new List<string>(another.ingredients);\n20\n}\n-\n-\npublic string Name\n-\n{\n-\nget { return name; }\n25\nset { name = value; }\n-\n}\n-\n-\npublic ReadOnlyCollection<string> Ingredients\n-\n{\n30\nget\n-\n{\n-\nreturn\n-\nnew ReadOnlyCollection<string>(ingredients);\n-\n}\n35\n}\n-\n-\npublic void AddIngredient(string ingredient)\n-\n{\n-\ningredients.Add(ingredient);\n40\n}\n-\n}\nRecipe.cs\nNext, we need to pull the code out from the original Recipes\nclass to save and load a ﬁle to disk.\nTo help separate ﬁle I/O from any other kind of I/O, we’ll per-\nform the ﬁle I/O in a helper class that uses Recipe. We want\nto take out all of the GUI widget references from the original\nsource code, and use instance member variables instead.\nLine 1\npublic class RecipeFile\n",
      "page_number": 157
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 165-172)",
      "start_page": 165,
      "end_page": 172,
      "detection_method": "topic_boundary",
      "content": "REFACTORING FOR TESTING\n152\n-\n{\n-\npublic Recipe Load(Stream savedRecipe)\n-\n{\n5\nRecipe recipe = new Recipe();\n-\nstring line;\n-\nchar[] delim = new char[] { ’=’ };\n-\n-\nusing (StreamReader reader = new StreamReader(savedRecipe))\n10\n{\n-\nwhile ((line = reader.ReadLine()) != null)\n-\n{\n-\nstring[] parts = line.Split(delim, 2);\n-\n15\nswitch (parts[0]) {\n-\ncase \"TITLE\":\n-\n{\n-\nrecipe.Name = parts[1];\n-\nbreak;\n20\n}\n-\ncase \"INGREDIENTS\":\n-\n{\n-\ntry\n-\n{\n25\nint count = Int32.Parse(parts[1]);\n-\nfor (int i = 0; i < count; i++)\n-\nrecipe.AddIngredient(reader.ReadLine());\n-\n}\n-\ncatch (Exception error)\n30\n{\n-\nthrow new RecipeFormatException(\n-\n\"Bad ingredient count: \" + error.Message);\n-\n}\n-\nbreak;\n35\n}\n-\n}\n-\n}\n-\n}\n-\n40\nreturn recipe;\n-\n}\n-\n-\npublic void Save(Stream savedRecipe, Recipe recipe)\n-\n{\n45\nusing (StreamWriter file =\n-\nnew StreamWriter(savedRecipe))\n-\n{\n-\nfile.WriteLine(\"NAME={0}\", recipe.Name);\n-\nfile.WriteLine(\n50\n\"INGREDIENTS={0}\",\n-\nrecipe.Ingredients.Count\n-\n);\n-\n-\nforeach (string line in recipe.Ingredients)\n55\n{\n-\nfile.WriteLine(line);\n-\n}\n\n\nREFACTORING FOR TESTING\n153\n-\n}\n-\n}\n60\n}\nRecipeFile.cs\nNow we’re in a position where we can write a genuine test case\nthat will test reading and writing to disk, without using any\nGUI code.\nLine 1\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\nusing System;\n-\nusing System.Collections.Generic;\n5\nusing System.IO;\n-\n-\n[TestFixture]\n-\npublic class RecipeTest\n-\n{\n10\nconst string CHEESEBURGER =\n-\n\"Cheeseburger\";\n-\nconst string SIRLOIN =\n-\n\"1/4 lb ground sirloin\";\n-\nconst string CHEESE =\n15\n\"3 slices Vermont cheddar cheese\";\n-\nconst string BACON =\n-\n\"2 slices maple-cured bacon\";\n-\nconst string RECIPE_FILE_NAME =\n-\n\"recipe.save\";\n20\n-\n[TearDown]\n-\npublic void TearDown()\n-\n{\n-\nif (File.Exists(RECIPE_FILE_NAME))\n25\n{\n-\nFile.Delete(RECIPE_FILE_NAME);\n-\n}\n-\n}\n-\n30\n[Test]\n-\npublic void SaveAndRestore()\n-\n{\n-\nRecipe recipe = new Recipe();\n-\nrecipe.Name = CHEESEBURGER;\n35\nrecipe.AddIngredient(SIRLOIN);\n-\nrecipe.AddIngredient(CHEESE);\n-\nrecipe.AddIngredient(BACON);\n-\n-\nStream recipeStream;\n40\nRecipeFile filer;\n-\nusing (recipeStream =\n-\nFile.OpenWrite(RECIPE_FILE_NAME))\n-\n{\n-\nfiler = new RecipeFile();\n45\nfiler.Save(recipeStream, recipe);\n-\n}\n\n\nREFACTORING FOR TESTING\n154\n-\n-\n// Now get it back\n-\nusing (recipeStream =\n50\nFile.OpenRead(RECIPE_FILE_NAME))\n-\n{\n-\nfiler = new RecipeFile();\n-\nrecipe = filer.Load(recipeStream);\n-\n}\n55\n-\nAssert.That(recipe.Ingredients.Count, Is.EqualTo(3));\n-\n-\nAssert.That(\n-\nrecipe.Name,\n60\nIs.EqualTo(CHEESEBURGER)\n-\n);\n-\n-\nAssert.That(\n-\nrecipe.Ingredients[0],\n65\nIs.EqualTo(SIRLOIN)\n-\n);\n-\n-\nAssert.That(\n-\nrecipe.Ingredients[1],\n70\nIs.EqualTo(CHEESE)\n-\n);\n-\n-\nAssert.That(\n-\nrecipe.Ingredients[2],\n75\nIs.EqualTo(BACON)\n-\n);\n-\n}\n-\n}\nRecipeTest.cs\nAt line 11 we’ll declare some constant strings for testing. Then\nwe make a new, empty object and populate it with the test\ndata beginning at line 34. We could just pass literal strings di-\nrectly into the object instead, and not bother with const data\nmembers, but since we’ll need to check the results against\nthese strings, it makes sense to put them in common con-\nstants that we can reference from both spots.\nWith a Recipe data object now fully populated, we’ll call the\nSave() method to write the recipe to disk at line 45. Now we\ncan make a brand-new Recipe object, and ask the helper to\nload it from that same ﬁle at line 53.\nWith the restored object in hand, we can now proceed to run\na whole bunch of asserts to make sure that the test data we\nset in the rec object has been restored in the rec2 object.\nFinally, at line 26 we play the part of a good neighbor and\ndelete the temporary ﬁle we used for the test. Note that we\n\n\nREFACTORING FOR TESTING\n155\nuse a finally clause to ensure that the ﬁle gets deleted, even\nif one of our assertions fails.\nNow we can run the unit test in the usual fashion to make\nsure that the code is reading and writing to disk okay.\nSTOP\nTry running this example before reading on. . .\nFailures:\n1) RecipeTest.SaveAndRestore :\nExpected string length 12 but was 0.\nStrings differ at index 0.\nExpected: \"Cheeseburger\"\nBut was:\n<string.Empty>\n-----------^\nat RecipeTest.SaveAndRestore() in RecipeTest.cs:58\nWhoops! Seems that wasn’t working as well as we thought—\nwe’re not getting the name line of the recipe back. When we\nsave the ﬁle out in RecipeFile.cs, the code is using the key\nstring \"NAME\" to identify the ﬁeld, but when we read it back\nin (line 19 of Load()), it’s trying to use the string \"TITLE\".\nThat’s just not going to work. We can easily change that to\nread \"NAME\", to match the key used for the save, but stop\nand ask yourself the critical question:\nCould this happen anywhere else in the code?\nUsing strings as keys is a ﬁne idea, but it does open the door\nto introduce errors due to misspellings or inconsistent naming\nas we’ve seen here. So perhaps this failing test is trying to tell\nyou something more—perhaps you should refactor the code\nand pull out those literal strings into constants.\nThe class\nthen looks like this:\nLine 1\npublic class RecipeFile\n-\n{\n-\nconst string NAME_TOKEN = \"NAME\";\n-\nconst string INGREDIENTS_TOKEN = \"INGREDIENTS\";\n5\n-\npublic Recipe Load(Stream savedRecipe)\n-\n{\n-\nRecipe recipe = new Recipe();\n-\nstring line;\n10\nchar[] delim = new char[] { ’=’ };\n-\n-\nusing (StreamReader reader = new StreamReader(savedRecipe))\n-\n{\n\n\nREFACTORING FOR TESTING\n156\n-\nwhile ((line = reader.ReadLine()) != null)\n15\n{\n-\nstring[] parts = line.Split(delim, 2);\n-\n-\nswitch (parts[0]) {\n-\ncase NAME_TOKEN:\n20\n{\n-\nrecipe.Name = parts[1];\n-\nbreak;\n-\n}\n-\ncase INGREDIENTS_TOKEN:\n25\n{\n-\ntry\n-\n{\n-\nint count = Int32.Parse(parts[1]);\n-\nfor (int i = 0; i < count; i++)\n30\nrecipe.AddIngredient(reader.ReadLine());\n-\n}\n-\ncatch (Exception error)\n-\n{\n-\nthrow new RecipeFormatException(\n35\n\"Bad ingredient count: \" + error.Message);\n-\n}\n-\nbreak;\n-\n}\n-\n}\n40\n}\n-\n}\n-\n-\nreturn recipe;\n-\n}\n45\n-\npublic void Save(Stream savedRecipe, Recipe recipe)\n-\n{\n-\nusing (StreamWriter file =\n-\nnew StreamWriter(savedRecipe))\n50\n{\n-\nfile.WriteLine(\n-\n\"{0}={1}\",\n-\nNAME_TOKEN,\n-\nrecipe.Name\n55\n);\n-\n-\nfile.WriteLine(\n-\n\"{0}={1}\",\n-\nINGREDIENTS_TOKEN,\n60\nrecipe.Ingredients.Count\n-\n);\n-\n-\nforeach (string line in recipe.Ingredients)\n-\n{\n65\nfile.WriteLine(line);\n-\n}\n-\n}\n-\n}\n\n\nREFACTORING FOR TESTING\n157\n-\n}\nRecipeFile.cs\n\n\nREFACTORING FOR TESTING\n158\nRecipe\nname\ningredients\nRecipeGUI\nShowGUI()\nRecipeFile\nLoad()\nSave()\nFigure 9.3: Refactored Recipes Static Class Diagram\nWe’ve improved the original program a lot with these simple\nchanges. In order to test the ﬁle I/O, we:\n• Made Recipe a ﬁrst-class object\n• Moved ﬁle I/O routines out of the GUI and into Recipe-\nFile to narrow the class’ responsibility.\n• Pulled literals into constants to avoid bugs from typos\nand reduce duplication.\nFinally, now that we have unit tests that provide the basic ca-\npabilities of a Recipe, we need to re-integrate the new Recipe\nclass into the GUI itself and tend to the ﬁle I/O. We’d like to\nend up with something like Figure 9.3.\nNow RecipeGUI holds an object of type Recipe, and uses\nthe helper class RecipeFile to read and write recipes to\ndisk.\nWhen the user presses the save button, the GUI will\nset values from the widgets in the Recipe object and call\nRecipeFile.Save(). When a new recipe is loaded in, the GUI\nwill get the proper values from the Recipe object returned\nfrom RecipeFile.Load().\nTesting a GUI can be very hard, but usually because the code\n\n\nTESTING THE CLASS INVARIANT\n159\nis written in such a way as to make it difﬁcult.\nThis kind\nof code isn’t uncommon, either—this is what happens when\nyou use the WinForms designer to generate code and then\njust integrate logic directly into the generated method’s code.\nIt can be tempting to use something like NUnitForms to test\nthis kind of logic, but if we went that route our tests would\nend up long and complicated.\nBy separating the pure GUI-related code from the actual logic\nof the application, you can easily add and test business fea-\ntures without having to worry about how you’re going to weave\nit into the GUI code.\nThe main GUI class RecipeGUI (formerly known as Recipes)\nshould now contain nothing but GUI-oriented code: widgets,\ncallbacks, and so on. Thus, all of the “business logic” and ﬁle\nI/O can be in non-GUI, fully testable classes.\nAnd we’ve got a clean design as an added bonus.\n9.3\nTesting the Class Invariant\nAnother way to improve the design of a class is by deﬁning\nand verifying the “class invariant.”1\nA class invariant is an assertion, or some set of assertions,\nabout objects of a class. For an object to be valid, all of these\nassertions must be true. They cannot vary.\nFor instance, a class that implements a sorted list may have\nthe invariant that its contents are in sorted order. That means\nthat no matter what else happens, no matter what methods\nare called, the list must always be in sorted order—at least as\nviewed from outside the object. Within a method, of course,\nthe invariant may be momentarily violated as the class per-\nforms whatever housekeeping is necessary. But by the time\nthe method returns, or the object is otherwise available for\nuse (as in a multi-threaded environment), the invariant must\nhold true or else it indicates a bug.\n1For more information on pre-conditions, post-conditions and invariants,\nsee [Mey97].\n",
      "page_number": 165
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 173-182)",
      "start_page": 173,
      "end_page": 182,
      "detection_method": "topic_boundary",
      "content": "TESTING THE CLASS INVARIANT\n160\nThat means it’s something you could check for as part of every\nunit test for this class.\nThe invariant is generally an artifact of implementation: inter-\nnal counters, the fact that certain member variables are pop-\nulated, and so on. The invariant is not the place to check for\nuser input validation or anything of that sort. When writing\ntests, you want to test just your one thing, but at the same\ntime you want to make sure the overall state of the class is\nconsistent—you want to make sure you have not inﬂicted any\ncollateral damage.\nHere are some possible areas where class invariants might\napply.\nStructural\nThe most common invariants are structural in nature. That\nis, they refer to structural properties of data. For instance, in\nan order-entry system you might have invariants such as:\n• Every line item must belong to an order\n• Every order must have one or more line items\nWhen working with arrays of data, you’ll typically maintain\na member variable that acts as an index into the array. The\ninvariants on that index would include:\n• index must be >= 0\n• index must be < array length\nYou want to check the invariant if any of these conditions\nare likely to break. Suppose you are performing some sort of\ncalculation on the index into an array; you’d want to check the\ninvariant throughout your unit tests to make sure the class\nis never in an inconsistent state. We showed this in the stack\nclass example on page 77.\nStructural errors will usually cause the program to throw an\nexception and/or terminate abruptly. For that matter, so will\nfailing the invariant check. The difference is that when the\ninvariant is violated, you know about it right away—right at\nthe scene of the crime. You’ll probably also know exactly what\ncondition was violated. Without the invariant, the failure may\n\n\nTEST-DRIVEN DESIGN\n161\noccur far from the original bug, and backtracking to the cause\nmight take you anywhere from a few minutes to a few days.\nMore importantly, checking the invariant makes sure that you\naren’t passing the tests based just on luck. It may be that\nthere’s a bug that the tests aren’t catching that will blow up\nunder real conditions.\nThe invariant might help you catch\nthat early, even if an explicit test does not.\nMathematical\nOther constraints are more mathematical in nature. Instead\nof verifying the physical nature of data structures, you may\nneed to consider the logical model. For example:\n• Debits and credits on a bank account match the balance.\n• Amounts measured in different units match after con-\nversion (an especially popular issue with spacecraft).\nThis starts to sound a lot like the boundary conditions we\ndiscussed earlier, and in a way they are.\nThe difference is\nthat an invariant must always be true for the entire visible\nstate of a class. It’s not just a ﬂeeting condition; it’s always\ntrue.\nData Consistency\nOften times an object may present the same data in different\nways—a list of items in a shopping cart, the total amount of\nthe sale, and the total number of items in the cart are closely\nrelated. From a list of items with details, you can derive the\nother two ﬁgures. It must be an invariant that these ﬁgures\nare consistent. If not, then there’s a bug.\n9.4\nTest-Driven Design\nTest-driven development is a valuable technique where you\nalways write the tests themselves before writing the methods\nthat they test [wCA04]. As a nice side beneﬁt of this style of\nworking, you can enjoy “test-driven design” and signiﬁcantly\nimprove the design of your interfaces.\n\n\nTEST-DRIVEN DESIGN\n162\nYou’ll get better interfaces (or API’s) because you are “eating\nyour own dog food,” as the saying goes—you are able to apply\nfeedback to improve the design.\nThat is, by writing the tests ﬁrst, you have now placed yourself\nin the role of a user of your code, instead of the implementor of\nyour code. From this perspective, you can usually get a much\nbetter sense of how an interface will really be used, and might\nsee opportunities to improve its design.\nFor example, suppose you’re writing a routine that does some\nspecial formatting for printed pages.\nThere are a bunch of\ndimensions that need to be speciﬁed, so you code up the ﬁrst\nversion like this:\nAddCropMarks(PSStream str, double paper_width,\ndouble paper_height,\ndouble body_width,\ndouble body_height);\nThen as you start to write the tests (based on real-world data)\nyou notice that a pattern emerges from the test code:\npublic Process() {\nxxx xx xxxxx xxx xx x xx xxx xxx xxxx xx xx;\nx xx x xxx xxxx xx xxx xx xxxxx xxxx;\nAddCropMarks(str, 8.5, 11.0, 6.0, 8.5);\nxx xxx x xxx xxx xx x xxx xxx xxx xxx xx xxx;\nx xxx xxx xxxx x xxx xxx\nxxx xxxx xx xxx xx;\nAddCropMarks(str, 8.5, 11.0, 6.0, 8.5);\nxx xx xxxx xx xx xxx xxx\nxxx xxxx xx xx xx xx;\nx xx xx x xxxx xxx x xxxx xx xx xx xxx xxx xx;\nAddCropMarks(str, 8.5, 11.0, 6.0, 8.5);\nxxx xx xxxxxxx xxx\nxxx xxxxx\nx xxx xxxx xx xxxxxx;\nxx\nx xxx xxxx xxxx xxx\nxxxx xxxx xx x x xx xx;\nAddCropMarks(str, 5.0, 7.0, 4.0, 5.5);\nxx xxx xxx xx x xxx xxx\nxxx xxxx xx xx xx xxx xx;\nxxx xx xxxxx xxx xx xxx x xxx xxxx xx xx xx xxx;\nAddCropMarks(str, 5.0, 7.0, 4.0, 5.5);\nxx xx xxxxx xx x xx xxx xxx xxxx xx xx;\nx xxx\nx xxx xxxx xx xx xxx xxxx xx;\n}\nAs it turns out, there are only a handful of common paper\nsizes in use, but you still need to allow for odd-ball sizes as\nnecessary.\nSo the ﬁrst thing to do—just to make the tests\neasier, of course—is to factor out the size speciﬁcation into a\nseparate object.\nPaperSpec standardPaper1 = new PaperSpec(8.5, 11.0,\n6.0, 8.5);\nPaperSpec standardPaper2 = new PaperSpec(5.0, 7.0,\n\n\nTESTING INVALID PARAMETERS\n163\n4.0, 5.5);\nxxx xx xxxxxxx xxx\nxxx xxxxx\nx xxx xxxx xx xxxxxx;\nxx\nx xxx xxxx xxxx xxx\nxxxx xxxx xx x x xx xx;\nAddCropMarks(str, standardPaper1);\nAddCropMarks(str, standardPaper1);\nxx xxx xxx xx x xxx xxx\nxxx xxxx xx xx xx xxx xx;\nxxx xx xxxxx xxx xx xxx x xxx xxxx xx xx xx xxx;\nAddCropMarks(str, standardPaper2);\nNow the tests are much cleaner and easier to follow, and the\napplication code that uses this will be cleaner as well.\nSince these standard paper sizes don’t vary, we can make\na factory class that will encapsulate the creation of all the\nstandard paper sizes.\npublic class StandardPaperFactory {\npublic static PaperSpec LetterInstance;\npublic static PaperSpec A4Instance;\npublic static PaperSpec LegalInstance;\nxxxxxx xxxxxx xxxxxxxxx xxxxxxxxxxx;\nxxxxxx xxxxxx xxxxxxxxx xxxxxxxxxxx;\n}\nBy making the tests cleaner and easier to write, you will make\nthe real code cleaner and easier to write as well.\nTry it\nExercises\n7.\nDesign an interest calculator that calculates the amount of in-\nAnswer\non 201\nterest based on the number of working days in-between two\ndates. Use test-ﬁrst design, and take it one step at a time.\n9.5\nTesting Invalid Parameters\nOne question that comes up when folks ﬁrst start testing is:\n“Do I have to test whether my class validates it parameters?”\nThe answer, in best consultant fashion, is “it depends. . . .”\nIs your class supposed to validate its parameters? If so, then\nyes, you need to test that this functionality is correct. But\nthere’s a larger question here: Who’s responsible for validat-\ning input data?\nIn many systems, the answer is mixed, or haphazard at best.\nYou can’t really trust that any other part of the system has\n\n\nTESTING INVALID PARAMETERS\n164\nchecked the input data, so you have to check it yourself—or at\nleast, that aspect of the input data that particularly concerns\nyou. In effect, the data ends up being checked by everyone\nand no one. Besides being a grotesque violation of the DRY\nprinciple [HT00], it wastes a lot of time and energy—and we\ntypically don’t have that much extra to waste.\nIn a well-designed system, you establish up-front the parts of\nthe system that need to perform validation, and localize those\nto a small and well-known part of the system.\nSo the ﬁrst question you should ask about a system is, “who\nis supposed to check the validity of input data?”\nGenerally we ﬁnd the easiest rule to adopt is the “keep the\nbarbarians out at the gate” approach.\nCheck input at the\nboundaries of the system, and you won’t have to duplicate\nthose tests inside the system. Internal components can trust\nthat if the data has made it this far into the system, then it\nmust be okay.\nIt’s sort of like a hospital operating room or industrial “clean\nroom” approach. You undergo elaborate cleaning rituals be-\nfore you—or any tools or materials—can enter the room, but\nonce there you are assured of a sterile ﬁeld. If the ﬁeld be-\ncomes contaminated, it’s a major catastrophe; you have to\nre-sterilize the whole environment.\nAny part of the software system that is outward-facing (a UI,\nor interface to another system) needs to be robust, and not\nallow any incorrect or unvalidated data through. What deﬁnes\n“correct” or valid data should be part of speciﬁcation you’re\ntesting against.\nWhat does any of this have to do with unit testing?\nIt makes a difference with regard to what you need to test\nagainst. As we mentioned earlier, if it isn’t your code’s respon-\nsibility to check for input data problems, then don’t waste\ntime checking for it. If it is your responsibility, then you need\nto be extra vigilant—because now the rest of the system is\npotentially relying on you, and you alone.\nBut that’s okay. You’ve got unit tests.\n\n\nChapter 10\nGUI Testing\nNow that we’ve separated out the logic from our UI code, what\nis there left to test in the GUI? And how is this a “unit test”\nwhen the GUI is involved?\n10.1\nUnit testing WinForms\nWe’re going to see how this works in the real world using\nthe NUnitForms framework, which is an extension of NUnit\n(http://nunitforms.sourceforge.net). Alas, NUnitForms\nuses Win32 native calls to work its magic and therefore\ndoesn’t currently work under Mono.\nBecause NUnitForms\nitself depends upon NUnit, we may ﬁnd that the version of\nAndy’s Rant on GUI Testing\n“Some people are convinced that they must com-\npare bitmaps to do GUI testing. Well, that is simply\nthe most antiquated, 1970’s bit of thinking I can imag-\nine. For crying out loud, I wrote a GUI tester based on\nX11 back in 1992 or so that was object-oriented (i.e., it\nworked with the ’OK’ button object on a form, place-\nment was irrelevant), scriptable, could do live record\nand playback and then later editing of the event, test\ncomposition, etc. And that was some 15 years ago.”\n\n\nUNIT TESTING WINFORMS\n166\nnunit.framework.dll we are referencing during compilation of\nour code isn’t the same version as the one NUnitForms was\nbuilt against.\n(The compiler will actually warn us of this.)\nDon’t panic, we’ll talk more about this later in the chapter.\nLet’s get started. There’s no magic here; remember that unit\ntests are just code, and controls (forms included) are just ob-\njects.\nFor instance, we can create and use additional con-\nstructors, and not just be stuck with the default empty con-\nstructor. If a Form requires a Recipe object to display, for\nexample, then the Form should have a constructor that takes\na Recipe parameter.\nNow we’ve got a ﬁrst easy unit test that doesn’t require\nNUnitForms—pass null in for the parameter and expect an\nArgumentNullException:\n[TestFixture]\npublic class RecipeViewFormTests\n{\n[Test]\n[ExpectedException(typeof(ArgumentNullException))]\npublic void NullRecipe()\n{\nnew RecipeViewForm(null);\n}\n}\nWhat\ncan\nwe\ntest\nthat’s\nactually\nGUI-related?\nThe\nRecipeViewForm has two buttons: Save and Cancel.\nYou\nwant to make sure that the Save button calls the Save()\nmethod on the Recipe object that is passed to it. (We’re only\nconcerned with the GUI functionality of the Save button—the\nlogic behind the Recipe.Save() method is tested elsewhere.)\nWe’ll use mock objects to make our lives easier.\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\nusing NUnit.Extensions.Forms;\nusing RecipeViewer;\nusing System;\nnamespace RecipeViewer.Tests\n{\npublic class FakeRecipe : Recipe\n{\nUInt32 saveCalled = 0;\npublic UInt32 SaveCalled\n{\n\n\nUNIT TESTING WINFORMS\n167\nget { return saveCalled; }\n}\npublic override Save()\n{\nsaveCalled++;\n}\n}\n[TestFixture]\npublic class RecipeViewFormTests\n{\n[Test]\npublic void Save()\n{\nFakeRecipe recipe = new FakeRecipe();\nRecipeViewForm recipeView =\nnew RecipeViewForm(recipe as Recipe);\nrecipeView.Show();\nButtonTester saveButton = new ButtonTester(\"Save\");\nsaveButton.Click();\nAssert.That(recipe.SaveCalled, Is.EqualTo(1));\n}\n}\n}\nFirst, we create a fake object for Recipe which tracks the\nnumber of calls to the Save() method. Then, we make a new\nRecipeViewControl and give it our FakeRecipe object, add\nthe control to a form, and ﬁnally call the Show() method on\nthe form. When we run the test, the form with the control will\npop up quickly (don’t blink or you’ll miss it).\nNext, we create a ButtonTester for the Save button. Note\nthat the ButtonTester isn’t based on the contents of the But-\nton’s Text property, but rather the Name property. Make sure\nyou give these sane names and not use the default ones gen-\nerated by the designer.\nWe then call the Click() method on the ButtonTester, and\nask the fake Recipe how many times Save() was called. We\nwant to assert that it was called only once.\nPretty cool, huh? By faking the model, we kept the unit test\nvery focused, even though it was testing the GUI. We could\nalso use one of the mock object frameworks discussed in\nChapter 6.\nHere’s another example we want to make sure works: press-\ning the Cancel button doesn’t save the recipe.\n\n\nUNIT TESTING WINFORMS\n168\n[Test]\npublic void Cancel()\n{\nFakeRecipe recipe = new FakeRecipe();\nRecipeViewControl recipeView =\nnew RecipeViewControl(recipe as Recipe);\nForm form = new Form();\nform.Add(recipeView);\nform.Show();\nButtonTester cancelButton = new ButtonTester(\"Cancel\");\ncancelButton.Click();\nAssert.That(recipe.SaveCalled, Is.EqualTo(0));\n}\nWe introduced a little duplication here with the previous test,\nso it’s time to refactor a bit.\nFirst, extract recipe and\nrecipeView to be class-level ﬁelds; then extract the intial-\nization of those ﬁelds into SetUp() so they’re fresh for each\ntest method. We’ve eliminated duplicate code, so we’re ready\nto proceed.\nMocking the User\nNUnitForms can also simulate a user changing ﬁelds in the\nGUI via the keyboard, and all other kinds of things, relatively\neasily.\nThere’s only one major exception and that’s modal\ndialogs.\n[TestFixture]\npublic class LoginModalDialogTest : NUnitFormTest\n{\nconst string PASSWORD_FAILURE = \"Password Failure\";\n[Test]\npublic void PasswordFailureClickOK()\n{\nExpectModal(PASSWORD_FAILURE, \"PasswordFailureOkHan-\ndler\");\nMessageBox.Show(\"Try again?\", PASSWORD_FAILURE);\n}\npublic void MessageBoxOkHandler()\n{\nMessageBoxTester messageBox =\nnew MessageBoxTester(PASSWORD_FAILURE);\nAssert.That(\nmessageBox.Title,\nIs.EqualTo(PASSWORD_FAILURE)\n);\nmessageBox.ClickOk();\n\n\nUNIT TESTING BEYOND WINDOWS FORMS\n169\n}\n}\nModal dialogs are interesting because they suspend the pro-\ngram until they’re dismissed. Thankfully, NUnitForms has a\nway to deal with that, using the ExpectModal method in the\nNUnitFormTest class.\nTo use it (or any other NUnitForms\nmethods), we derive our ﬁxture from NUnitFormTest and call\nExpectModal, passing the name of the caption (aka title) of\nthe modal dialog. When a modal dialog is displayed that has\nthe speciﬁed caption, the handler method is called. So in our\nhandler method, we do our button clicks, assertions, and so\non, and then dismiss the dialog as a user would. Then our\ntests continue on their merry way.\n10.2\nUnit testing beyond Windows Forms\nWhat if we’re using a UI library that isn’t Windows Forms?\nThis isn’t unthinkable, and it certainly isn’t untestable either.\nThere are some nuances, but many of the concepts presented\nthus far apply equally. We just won’t have a nice framework\nlike NUnitForms to help us along.\nFor other common GUI toolkits, like Qt# and Gtk#, there is\nsome variance in the ease of testing. Qt# is a .NET binding\nto the open source C++ native library, Qt. Qt 4.1 and above\nhas a built-in unit testing framework called QTestLib. Gtk# is\nalso a wrapper (in essence), but neither the wrapper nor the\nnative library has a unit testing framework associated with it\nas of the time of this writing.\nWhat about custom GUIs, like ones that are 3D?1 That turns\nout to be easier in some cases, because we have more control\nover the design and can make it easy to test.\nMost 3D applications use a scene graph, which is a tree of\nnodes where the nodes in the tree represent things to be\ndrawn in 3D space. The nodes know their X, Y, and Z (depth)\ncoordinates, and their length along those planes.\nA visitor\nclass visits each node in the scene graph and is responsible\n1For\ninstance,\na\nC#\nwrapper\naround\nOpenGL,\nlike\nTao:\nhttp://www.taoframework.com\n",
      "page_number": 173
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 183-190)",
      "start_page": 183,
      "end_page": 190,
      "detection_method": "topic_boundary",
      "content": "UNIT TESTING BEYOND WINDOWS FORMS\n170\nTesting code that runs on the GPU\nThanks to Ryan Dy, a programmer on some of Matt’s\nfavorite XBox games, for this real-world detail:\nSometimes there are transformations that aren’t done\non the CPU, they’re done on the GPU via shader pro-\ngrams. In that case, we need to expose the shader\nvariables to our test code running on the CPU so we\ncan make assertions. To accomplish that, we would\nwrite a shader program that would expose the val-\nues we need to assert against in our test.\nThis is a\ncommon method for debugging shader code, and\nit also allows us to make sure our shader perform simi-\nlarly across different hardware implementations in an\nautomated fashion.\nfor things like rendering the node in the 3D space or passing\nmessages such as mouse clicks or keyboard interactions.\nIt’s relatively straightforward to see where testing could be\nintroduced in this common 3D scenario. First, we may want\nto test the nodes themselves, but they are usually data-only—\nall the behaviour generally goes into the visitor2 objects that\napply transformations to the data contained in the nodes.\nNext, we could test the scene graph collection and make sure\nit is self-balancing based upon Z-order (or whatever other\nproperties we expect).\nLast, the visitor classes themselves\ncan be unit tested if they are well-encapsulated and loosely\ncoupled with the rest of the design.\nThis is a lot of talk to be sure; how can you actually code up\na test that makes sure that our layout algorithm ﬁts all the\nnodes onto the rendered screen? We might sketch out a test\nthat looks like this:\nMissing: [Code to be written]\nWhat’s this magical method referenced? It’s sometimes easier\n2Fun fact: Scene graphs are one of the few places that the Visitor design\npattern is commonly applied.\n\n\nWEB UIS\n171\nto write the test as you’d like it to read, then work backward\nand ﬁll in the missing pieces.\nNow that we have the test as we’d like it to read, here’s the\ncode for the aforementioned magical method:\nMissing: [Code to be written]\n10.3\nWeb UIs\nAn entire book could be written about testing web-based UIs.\nWe’ll touch on it brieﬂy here because many people are un-\nder the impression this is not possible or requires expen-\nsive commercial tools.\nFirst, many “Web 2.0” applications\nhave a great deal of their functionality in JavaScript (aka EC-\nMAScript). Unlike the dark ages of JavaScript, it is now an\nopen ECMA standard with frameworks available that make\nobject-orientation and unit testing a snap. In many modern\napplications, much of the important end-user functionality is\non the client-side in JavaScript. The server-side code mostly\naccepts AJAX requests that either retrieve or store data in the\ndatabase with some data validation and logging.\nAs such, unit testing the JavaScript is the ﬁrst step.\nWe\nrecommend JsUnit,3 which provides a framework and a test-\nrunner that can run within most modern browsers. You can\nassert that your JavaScript code is having the correct effect\non speciﬁc DOM elements, such as adding or removing styles,\nchild nodes, or whatever. This allows us to ﬁnd and test for\nbugs that would normally have to be done manually with vi-\nsual inspection.\nWe also recommend using a framework like Prototype or\nJQuery that provide various syntactic and functional helpers\nthat make JavaScript a little easier to code and test. There\nare all sorts of nifty AJAX libraries and frameworks out there,\nbut we should make sure that they don’t hinder our ability to\nunit test functionality. See the JsUnit web site for examples—\nmany of the concepts from this book can be applied equally\nbetween C#, JavaScript, and other languages.\n3http://www.jsunit.net\n\n\nWEB UIS\n172\nTo test web applications beyond JavaScript and our server-\nside objects, there is a free, open source tool called Sele-\nnium.4\nWith Selenium, you can write code that drives any\nof the mainstream browsers on the operating system of your\nchoice. It works by running a server that launches a browser,\nwhich accepts commands via a socket and translates those\ncommands into browser clicks and keyboard input.\nThis means we can write NUnit tests that look like this:\n[Test]\npublic void AnchoviesNotAvailableInMontana()\n{\nISelenium selenium =\nnew DefaultSelenium(\n\"localhost\", 4444, \"firefox2\",\n\"http://localhost:56789/OrderPizza.aspx\"\n);\nselenium.Select(INGREDIENT_DROPDOWN_ID, \"anchovies\");\nselenium.Type(STATE_TEXT_ID, \"montana\");\nselenium.Click(\"submit\");\nselenium.WaitForCondition(\n\"selenium.isTextPresent(’Not Available’)\"\n);\n}\nWe instantiate a new selenium controller, which starts the\nselenium server. This in turn starts the browser. We tell the\nselenium controller to select \"anchovies\" from a list control.\nNote that the location and style of that control don’t really\nmatter—we’re just working off the HTML IDs.\nBecause we\nhave stored the HTML IDs into a variable, we only have to\nchange them in one place should the HTML ID in the user\ninterface change. Then, we tell selenium to type ’montana’ in\nthe input control. Next, we tell selenium to click a button with\nthe HTML ID of ’submit’. Last, we wait for the validator (or\nwhatever else) text to appear. If the condition isn’t met by the\ndefault timeout,5 the test will fail. One interesting side note\nis that selenium.isTextPresent is a snippet of JavaScript\nthat will tell Selenium what to do on the browser-side.\nSelenium tests are like any other tests; you tend to do the\nsame things over and over. Being the pragmatic programmers\nthat we are, we don’t stand for duplication.\nWhen we see\n4http://www.openqa.org/selenium/index.html\n560 seconds in Selenium 0.9\n\n\nWEB UIS\n173\nJoe Asks. . .\nAren’t Selenium tests more like system tests?\nYes, Selenium tests aren’t really unit tests, even though\nwe are driving the browser in NUnit. ASP.NET doesn’t\nhave a good way to isolate the various handlers for\ntesting as of the time of this writing.a As such we have\na multi-lateral approach to get much of the same\nbeneﬁt. The ASP.NET pages and controls should be a\nvery thin layer on top of other, more easily testable,\nobjects—just like for WinForms or any other widget li-\nbrary. Selenium then helps us test the interaction be-\ntween the web controls and those underlying model\nobjects. It is slower, mainly due to the overhead of\nstarting and running a real browser, but it is deﬁnitely\nbetter than manual web UI testing. When using a sys-\ntem testing tool like Selenium, make sure to exclude\nit from your code coverage measurements. Your unit\ntests alone should provide high levels of code cov-\nerage; measuring the coverage of system-level tests\nobscures that data.\naWebWork and Rails do, which are Java- and Ruby-based re-\nspectively.\nit, we refactor by extracting methods, extracting a class, and\nperforming other refactorings. A very common pattern with\nSelenium is to wrap the Selenium instance and delegate to\nit. By doing this, you can have assertion and helper methods\ntied to a project-speciﬁc Selenium object that can be shared.\nnamespace PizzaWeb.Test.UI\n{\npublic class MySelenium\n{\nprotected ISelenium selenium;\npublic MySelenium(string host,\nint port,\nstring[] browsers,\nstring url)\n{\nselenium =\nnew DefaultSelenium(host, port, browsers, url);\n}\n\n\nWEB UIS\n174\npublic Stop()\n{\nselenium.Stop();\n}\npublic void waitForText(string expectedText)\n{\nselenium.WaitForCondition(\n\"selenium.isTextPresent(’\" + expectedText + \"’)\"\n);\n}\n}\n}\nSomething else that often gets repeated is the creation of\nthe selenium instance and the closing of the browser.\nAn-\nother common pattern is to have a base class that selenium-\noriented ﬁxtures derive from.\nnamespace PizzaWeb.Test.UI\n{\npublic abstract class MySeleniumFixture\n{\nstatic final uint SELENIUM_SERVER_PORT = 56789;\nprotected MySelenium selenium;\n[TestFixtureSetUp]\npublic void StartBrowser()\n{\nselenium = new MySelenium(\n\"localhost\", SELENIUM_SERVER_PORT,\n\"firefox2\", getInitialUrl()\n);\n}\n[TestFixtureTearDown]\npublic void StopBrowser()\n{\nselenium.Stop();\n}\nprotected abstract string getInitialUrl();\n}\n[TestFixture]\npublic class OrderPizzaTest : MySeleniumFixture\n{\nstatic final string INGREDIENT_DROPDOWN_ID = \"ingredi-\nents\";\nstatic final string STATE_TEXT_ID = \"state\";\nstring getInitialUrl()\n{\nreturn \"http://localhost:7890/OrderPizza.aspx\";\n}\n[Test]\n\n\nCOMMAND LINE UIS\n175\npublic void AnchoviesNotAvailableInMontana()\n{\nselenium.Select(\nINGREDIENT_DROPDOWN_ID,\n\"anchovies\"\n);\nselenium.Type(STATE_TEXT_ID, \"montana\");\nselenium.Click(\"submit\");\nselenium.waitForText(\"Not Available\");\n}\n}\n}\nWhen making the selenium instance, only one thing gener-\nally varies from test to test: the initial URL the browser loads.\nTo reuse the creation of the selenium instance, we extracted\nit into a method and then into a base class that the test ﬁx-\nture itself derives from. We marked that creation method with\nthe TestFixtureSetUp attribute so we don’t keep closing and\nopening the browser for every test. Your application may need\nto close the browser for each test, though, in which case we\nshould use SetUp and TearDown instead. The base class de-\nﬁnes the abstract method called getInitialUrl() which the\nderived class must implement. When we add a new test ﬁx-\nture for a different web page, we’ll override that method and\nget the beneﬁts of reuse.\nIn our example we set the default browser to ’ﬁrefox2’. If you\nwant to test with Internet Explorer as well, you can make\nsure your tests pass under both browsers by adding “IE6” to\nthe third parameter of the DefaultSelenium constructor.\n10.4\nCommand Line UIs\nBefore we ﬁnish talking about GUI Testing, we can’t forget\nabout our old friend the command line. Once again, the ﬁrst\nstep is to make sure that our static Main() method is a thin\nlayer that mostly interacts with other, more easily testable,\nobjects. Often, argument parsing is done in a quick and dirty\nfashion right in the Main() method. What do you do if there is\na bug in the command line argument parsing, and you want\nto write a unit test that fails when the bug is present and\npasses when it is ﬁxed? Say you had code like this:\nprivate static void isTracing;\n\n\nCOMMAND LINE UIS\n176\npublic static void Main(string[] args)\n{\nif (args.Length < 1)\n{\nprintUsage();\nEnvironment.Exit(-1);\n}\nif (args[0] == \"--trace\")\n{\nisTracing = true;\n}\n}\nThere is a bug (or lack of feature, depending on your personal\noutlook) where the -trace command line option is only rec-\nognized when it is the ﬁrst argument. We want to unit test the\nchange, regardless, because text processing is one of those\nareas in our experience where bugs tend to creep back in as\nseemingly “safe” changes are made.\nOne way would be to\nwrite a test like this:\n[Test]\npublic void TraceAsSecondArgument()\n{\nTextUI.Main(new String[] {\"filename\", \"--tracing\"});\nAssert.That(Main.IsTracing, Is.True);\n}\nThis test wouldn’t compile as-is—we would have to add a\nstatic property called IsTracing to our class.\nIf you ﬁnd\nyourself thinking this doesn’t feel right, we would agree with\nyou. Like the other UI testing paradigms we’ve discussed, we\nwant Main() to be a thin layer that does a little coordina-\ntion between other objects. Adding a property makes it fatter\nrather than thinner.\nInstead, let’s ﬁrst extract a method which will help highlight\nsome better seams along which we can extract a class that we\ncan then unit test.\nprivate static bool hasTracing(string[] args)\n{\nreturn (args[0] == \"--trace\");\n}\nNow here’s something we can unit test more easily. Testing\nthe Main() class still feels a little weird, so let’s extract that\nstatic method into a class called Args. Once we do that, we\ncan write a test like this:\n\n\nGUI TESTING GOTCHAS\n177\n[Test]\npublic void TraceAsSecondArgument()\n{\nArgs args = new Args(new string[] {\"filename\", \"--\ntracing\"});\nAssert.That(args.IsTracing, Is.True);\n}\nThis example backs up Andy’s rant from the beginning of the\nchapter. Unit testing most GUI code is hard only because peo-\nple think it is, not because it is that technically challenging.\nOnce we just approach the problem as though it is solvable\nand apply those amazing programming skills we posess, it\nbecomes one of the more trivial issues we’ll deal with in our\nprofessional career.\n10.5\nGUI Testing Gotchas\nGUI testing is fairly straight-forward, save for a couple of\ngotchas that we’ll discuss in this section. Don’t be scared—\nknowing about these issues up front deﬂates their difﬁculty\nquite a bit.\nConﬂicting NUnit libraries\nIf NUnitForms was built against a speciﬁc version of NUnit\nand that differs from the version of the NUnit libraries you’re\nreferencing in your project, you’ll get a compiler warning\ntelling you as such. This usually doesn’t present a problem,\nbut if it does there’s an easy way to ﬁx it.\nDownload the NUnitForms source code, and replace it’s NUnit\nlibraries with the version of NUnit you’re using. Then build\nNUnitForms and store the custom build in your project’s lib/\ndirectory.\nThis seems like a big deal, but it’s a minor an-\nnoyance at worst. You’ll have to rebuild when there’s a new\nNUnitForms release that you must deploy, but that’s about it.\nAutomated build\nThere’s a simple “gotcha” here worth mentioning when using\nNUnitForms (or similar tools) in an automated build.\n",
      "page_number": 183
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 191-198)",
      "start_page": 191,
      "end_page": 198,
      "detection_method": "topic_boundary",
      "content": "GUI TESTING GOTCHAS\n178\nIf your automated build runs as a service, you will be unable\nto show any modal dialogs.\nAttempting to do so will result\nin an exception that basically says “don’t show modal dialogs\nin a service.” This is historical, and does make some sense.\nSince the service doesn’t have a desktop where someone could\ndismiss a modal dialog, the service would get stuck and the\nmachine would require a reboot. This happened enough times\nwith poorly written commercial applications that Microsoft\nnipped it in the bud by disallowing it altogether.\nThere is an easy workaround, and it’s only a little messy. Start\nyour automated build controller from a logged-in account, via\na batch ﬁle or shell script.\nThen set the build machine to\nauto-login on boot and run the batch ﬁle on start-up for that\nuser. It ends up practically the same as running the service,\nbut you won’t run into the aforementioned issue with modal\ndialogs.\nMultithreaded and Complex Controls\nNow, for a more advanced gotcha.\nIf you’re testing a Form that contains a control that is mul-\ntithreaded and does interesting things with the Win32 event\nloop (such as MSHTML, the Internet Explorer HTML render-\ning control), you may ﬁnd it doesn’t work correctly when you\ntry to unit test it. This is because the event loop doesn’t work\nthe same in this test runner as it does when running under\nregular Windows.\nYou\ncan\nwork\naround\nthis\nby\ncalling\nApplica-\ntion.DoEvents(), which will suspend your current thread\nand run the message pump thread until there are no pending\nWin32 events in the queue.\nIn the case of some unreasonably complex controls (e.g.,\nMSHTML), you may have to run Application.DoEvents()\na couple of times in order for you to be able to coerce them\ninto behaving as they would in the real world.\nYou can deﬁnitely unit test most GUIs, but it is a slippery\nslope that makes it easy to write only what ends up being\nsystem tests. Testing only at the system level can sometimes\n\n\nGUI TESTING GOTCHAS\n179\nseem much easier because you work around the need to refac-\ntor the code to make it more testable. Don’t fall into that trap.\nAs we’ve said a couple of times before, one of the biggest val-\nues of unit testing is in making your designs better. On top\nof that, many unit-level tests can usually run in the same\namount of time as a single system-level test. Don’t sell your-\nself, or your project, short by taking the easier way out. Be\nmindful of the balance between unit-level tests and system-\nlevel tests.\n\n\nAppendix A\nExtending NUnit\nA.1\nWriting NUnit Extensions\nIn the nunit.extensions framework, there is a Repeat at-\ntribute:\n[Test]\n[Repeat (10)]\npublic void IntermittentFailure() {\nxxx xxx xxxxxx xxxxx xxxx;\n}\nThe Repeat attribute will, (as you may have guessed already),\nrepeat the same test the speciﬁed number of times. If it fails\nany of those times, it won’t run the remaining times. This can\nbe useful for tests that are sensitive to timing or state issues\nand you want to make sure you’ve shaken everything out.\nExamining an Existing Attribute\nWe’re going to implement a new kind of attribute that test\nmethods can be decorated with.\nWe’ve seen attributes like [Test], [Category], and [Re-\npeat] previously. We’re going to implement a new attribute\nthat will let you specify a maximum amount of time a test can\ntake to run. If it doesn’t complete in the expected time, the\ntest will fail (the test will also fail if its assertions fail, just as\nin a regular test.)\n\n\nWRITING NUNIT EXTENSIONS\n181\nYou can extend NUnit by adding new attributes; let’s see how\nby exploring the source code to NUnit. Download the NUnit\nsource code1 (if you haven’t already) and uncompress it some-\nwhere convenient on your disk—we’ll wait.\nTo\nstart\nexploring,\nwe\nshould\nlook\nat\nsomething\nsim-\nilar\nto\nwhat\nwe’re\ntrying\nto\naccomplish.\nThe\n[Re-\npeat(x)] attribute shown above seems like a good place\nto start.\nThe source code for the Repeat attribute is in\nsrc/NUnitExtensions/framework/RepeatAttribute.cs.\nIf you take a look, all it contains is literally the deﬁnition\nfor the Repeat attribute. Something else must interpret the\nattribute, so let’s look for that.\nIf you grep the source for “RepeatAttribute”, it leads you to\nsrc/NUnitExtensions/core/RepeatedTestDecorator.cs.\nThe RepeatedTestDecorator provides a couple of static\nmethods; the important one of interest to us right now is the\nDecorate() method that takes a TestCase as a parameter\nand returns a TestCase. This follows the Decorator design\npattern. The RepeatedTestDecorator’s Decorate method for\na TestCase does a couple of things; we’ll hit the highlights.\nFirst, it ensures that the TestCase method has the RepeatAt-\ntribute associated with it. If the TestCase method does not\nhave an associated RepeatAttribute, it skips the decoration\nand just returns the TestCase as-is. If the TestCase method\ndoes have an associated RepeatAttribute, it gets the Count\nvalue out of the RepeatAttribute’s Count property. It then\nconstructs a new RepeatedTestCase with the original Test-\nCase and the Count property. So, if the [Test] was marked\nwith [Repeat(x)], it wraps the underlying TestCase object\nwith a RepeatedTestCase object.\nLet’s\ntake\na\nlook\nat\nthe\nRepeatedTestCase\nobject\nin\nsrc/NUnitExtensions/core/RepeatedTestCase.cs.\nIt’s\npretty obvious how this works: the Run() method runs the\noriginal, wrapped TestCase by Count number of times. Test-\nCaseResult is a collection parameter for the results of the\ntest runs.\n1http://sourceforge.net/projects/nunit\n\n\nUSING NUNIT CORE ADDINS\n182\nMissing: Review at the unit tests for these objects.\nMissing: Finish off this content\nCreating a New Attribute\nMissing: Finish off this content\nA.2\nUsing NUnit Core Addins\nMissing: Content for this section will be added in a later\nbeta.\n\n\nAppendix B\nGotchas\nHere are some popular “gotchas,” that is, issues, problems, or\nmisconceptions that have popped up over and over again to\ntrap the unwary.\nB.1\nAs Long As The Code Works\nSome folks seem to think that it’s okay to live with broken unit\ntests as long as the code itself works. Code without tests—\nor code with broken tests—is broken.\nYou just don’t know\nwhere, or when. In this case, you’ve really got the worst of\nboth worlds: all that effort writing tests in the ﬁrst place is\nwasted, and you still have no conﬁdence that the code is doing\nwhat it ought.\nNote that a test that has no assert statements or (mock object\nveriﬁcation) will count as “passed.” This is arguably a bug in\nNUnit, but at any rate a test without asserts still counts as\nbroken.\nIf the tests are broken, treat it just as if the code were broken.\nB.2\n“Smoke” Tests\nSome developers believe that a “smoke test” is good enough\nfor unit testing. That is, if a method makes it all the way to\nthe end without blowing up, then it passed.\n\n\n“WORKS ON MY MACHINE”\n184\nYou can readily identify this sort of a test: there are no asserts\nwithin the test itself, just one big Assert.IsTrue(true) at\nthe end. Maybe the slightly more adventurous will have mul-\ntiple Assert.IsTrue(true)’s throughout, but no more than\nthat. All they are testing is, “did it make it this far?”\nAnd that’s just not enough. Without validating any data or\nother behavior, all you’re doing is lulling yourself into a false\nsense of security—you might think the code is tested, but it is\nnot.\nWatch out for this style of testing, and correct it as soon as\npossible. Real testing checks results. Anything else is just\nwasting everyone’s time.\nB.3\n“Works On My Machine”\nAnother pathologic problem that turns up on some projects\nis that old excuse, “It’s not broken, it works on my machine.”\nThis points to a bug that has some correlation with the envi-\nronment. When this happens, ask yourself:\n• Is everything under version control?\n• Is the development environment consistent on the af-\nfected machines?\n• Is it a genuine bug that just happens to manifest itself\non another machine (because it’s faster, or has more or\nless memory, etc.)?\nEnd users, in particular, don’t like to hear that the code works\non your machine and not theirs.\nAll tests must pass on all machines; otherwise the code is\nbroken.\nB.4\nFloating-Point Problems\nQuite a few developers appear to have missed that one day in\nclass when they talked about ﬂoating-point numbers. It’s a\nfact of life that there are ﬂoating point numbers that can only\nbe approximately represented in computer hardware.\nThe\n\n\nTESTS TAKE TOO LONG\n185\ncomputer only has so many bits to work with, so something\nhas to give.\nThis means that 1.333 + 1.333 isn’t going to equal 2.666\nexactly. It will be close, but not exact. That’s why the NUnit\nﬂoating-point asserts require you to specify a tolerance along\nwith the desired values (see the discussion on page 35).\nBut still you need to be aware that “close enough” may be\ndeceptive at times. Your tests may be too lenient for the real\nworld’s requirements, for instance. Or you might puzzle at an\nerror message that says:\nFailures:\n1) TestXyz.TestMe :\nexpected:<1.00000000>\nbut was:<1.00000000>\nat TestXyz.TestMe() in TestXyz.cs:line 10\n“Gosh, they sure look equal to me!” But they aren’t—there\nmust be a difference that’s smaller than is being displayed by\nthe print method.\nAs a side note, you can get a similar problem when using\ndate and time types. Two dates might look equal as they are\nnormally displayed—but maybe the milliseconds aren’t equal.\nB.5\nTests Take Too Long\nUnit tests need to run fairly quickly. After all, you’ll be run-\nning them a lot. But suddenly you might notice that the tests\nare taking too long. It’s slowing you down as you write tests\nand code during the day.\nThat means it’s time to go through and look at your tests with\na fresh eye. Cull out individual tests that take longer than av-\nerage to run, and group them together using the [Category]\nattribute discussed on page 45.\nYou can run these optional, longer-running tests once a day\nwith the build, or when you check in, but not have to run\nthem every single time you change code.\nJust don’t move them so far out of the way that they never get\nrun.\n",
      "page_number": 191
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 199-206)",
      "start_page": 199,
      "end_page": 206,
      "detection_method": "topic_boundary",
      "content": "TESTS KEEP BREAKING\n186\nB.6\nTests Keep Breaking\nSome teams notice that the tests keep breaking over and over\nagain. Small changes to the code base suddenly break tests\nall over the place, and it takes a remarkable amount of effort\nto get everything working again.\nThis is usually a sign of excessive coupling. Test code might\nbe too tightly-coupled to external data, to other parts of the\nsystem, and so on. Remember that a singleton is really just\na global variable wearing pretty clothes—if other bits of code\ncan muck with its state, they will, and usually when you least\nexpect it.\nAs soon as you identify this as a problem, you need to ﬁx it.\nIsolate the necessary parts of the system to make the tests\nmore robust, using the same techniques you would use to\nminimize coupling in production code. See [HT00] for more\ndetails on orthogonality and coupling, or [FBB+99] for infor-\nmation on refactoring and design smells, and don’t forget to\nuse Mock Objects (Chapter 6) to decouple yourself from the\nreal world.\nB.7\nTests Fail on Some Machines\nHere’s a common nightmare scenario: all the tests run ﬁne—\non most machines. But on certain machines they fail consis-\ntently. Maybe on some machines they even fail intermittently.\nWhat on earth could be going on? What could be different on\nthese different machines?\nThe obvious answer is differences in the version of the oper-\nating system, libraries, the C# runtime engine, the database\ndriver; that sort of thing. Different versions of software have\ndifferent bugs, workarounds, and features, so it’s quite possi-\nble that machines conﬁgured differently might behave differ-\nently.\nBut what if the machines are conﬁgured with identical soft-\nware, and you still get different results?\nIt might be that one machine runs a little faster than the\nother, and the difference in timing reveals a race condition\n\n\nTESTS PASS IN ONE TEST RUNNER, NOT THE OTHER\n187\nor other problem with concurrency. The same thing can show\nup on single vs. multiple-processor machines.\nIt’s a real bug, it just happened not to have shown up before.\nTrack it down on the affected machine using the usual meth-\nods. Prove the bug exists on that machine as best you can,\nand verify that all tests pass on all machines when you are\ndone.\nB.8\nTests Pass in One Test Runner, Not the\nOther\nYou may ﬁnd a situation where all the tests pass for you us-\ning nunit-gui, the GUI test runner, but fail in the automated\nbuild, which uses nunit-console. This can be an indicator\nof hidden global state, circular object dependencies, or Fi-\nnalizer bugs.\nThat last one can be especially subtle.\nFor instance, there\nwas a case where the developer wrote their ﬁnalizer like it\nwas a C++ destructor—they were accessing the object’s ﬁelds.\nBut in the .NET environment, the ﬁelds may be garbage col-\nlected before the Finalizer is executed. The result? An in-\ntermittent NullReferenceException.\nIn this case, it only\nhappened in the nunit-console test runner when launched\nfrom nant via CruiseControl.NET, aligning the stars of the\ngarbage collection universe just so.\nBut once diagnosed, it\nalso explained seemingly random, unreproducible crashes in\nthe ﬁeld as well.1\nMore likely, nunit-console and other test runners can run\ntests in slightly different order, which may expose hidden de-\npendancies.\nB.9\nThread state issues\nSometimes we see strange InvalidOperationException,\nThreadStateException,\nor\nCOM-based\nexceptions\nget\nthrown when code runs under NUnit, but not in production.\n1For more on garbage collection “gotchas,” see [Sub05].\n\n\nC# 2.0-SPECIFIC ISSUES\n188\nThis can sometimes be related to the apartment-type being\nmulti-threaded when it should be single-threaded and nice\nversa. These are usually referred to by the acronyms MTA and\nSTA, respectively. This is deep .NET voodoo we don’t want to\nget stuck in, but there are a couple of NUnit commandline\noptions to try: -thread and -domain. See the NUnit docu-\nmentation for more more information on these options. If you\nhave a burning desire to learn more, a quick perusal through\nCLR via C#[Ric06] or a web search will give you more infor-\nmation.\nB.10\nC# 2.0-speciﬁc Issues\nSo far, we haven’t mentioned too many things speciﬁc to C#\n2.0, so how do you use NUnit on a project that uses C# 2.0?\nJust as you normally would, with a couple of minor excep-\ntions.\nFirst, you’ll need to use a version of NUnit that is compiled\nwith a C# 2.0 compiler. There are separate packages on the\nNUnit web site for .NET 1.1 and 2.0 versions. By the way, it’s\nperfectly safe and okay to use the .NET 2.0-compiled NUnit\non a C# 1.1 project; the developers will just have to have .NET\n2.0 or mono 1.1 or newer installed to run the tests.\nAnother notable thing to watch out for is the interaction of\nAssert.IsNull() and Assert.IsNotNull() with Nullable\ntypes.\nNullable types, a C# 2.0 feature, allows value types\nlike int, DateTime, enums, or structs to have a “null” value\nwhen it is not initialized. This feature was added so that the\nlanguage could map more closely to the way databases repre-\nsent data (for more information, see [Ric06]).\nIf you write a test like this:\n[Test]\npublic void NullableInt() {\nint? first;\nNullable<int> second;\nAssert.IsNull(first);\nAssert.IsNull(second);\n}\n\n\nC# 2.0-SPECIFIC ISSUES\n189\nIt will fail. The reason why is because the value isn’t liter-\nally null. The ﬁrst line and second lines of code are seman-\ntically identical; the question mark syntax is just some syn-\ntactic sugar to make it easier to consume in C#. Looking at\nthe second declaration, you can see it is a struct of type Nul-\nlable<T>. This will never be null.\nTo correctly test whether the Nullable type has a value or not,\ncheck it’s HasValue property:\nAssert.IsTrue(first.HasValue)\n\n\nAppendix C\nResources\nC.1\nOn The Web\nCruise Control .NET\n⇒http://ccnet.thoughtworks.com\nCruiseControl.NET is an automated Continuous Integration server\nfor .NET that integrates with NAnt, NUnit, NCover, and most major\nopen source and proprietary version control systems.\nDotGNU\n⇒http://dotgnu.org\nAn open source implementation of the ECMA standards upon which\nC# and .NET are based. Sports C# and .NET 1.1 support as well an\noptimizing JIT compiler as of this writing. Not as complete as mono,\nanother open source implementation.\nDotNetMock\n⇒http://sourceforge.net/projects/dotnetmock\nA repository for Mock Object information in the .NET environment,\nas well as testing in general.\nmono\n⇒http://mono-project.com\nAnother open source implementation of the ECMA standards upon\nwhich C# and .NET are based. Supports C# and .NET 2.0 as well as\nan optimizing JIT compiler.\nNCover\n⇒http://ncover.org\nA simple code coverage tool that runs from the command line and\noutputs an XML ﬁle with the code coverage statistics. Requires de-\n\n\nON THE WEB\n191\nbug information for monitored assemblies, and produces line-by-line\nvisit counts. Also includes a simple XSLT transform to make the out-\nput readable in a browser.\nNCoverExplorer\n⇒http://kiwidude.com/blog\nA WinForms GUI and commandline UI for summarizing and explor-\ning the XML ﬁles that NCover emits.\nAlso includes NAnt tasks,\nstylesheets and tasks for CruiseControl.NET. Allows for failure of a\nbuild if code coverage gathered during the build and test are below a\ncertain watermark.\nNMock\n⇒http://nmock.org\nNMock is a dynamic mock-object library for .NET.\nNUnit\n⇒http://nunit.org\nThis xUnit-based unit testing tool for Microsoft .NET is written en-\ntirely in C# and has been completely redesigned to take advantage\nof many .NET language features, including custom attributes and\nother reﬂection related capabilities. NUnit brings xUnit to all .NET\nlanguages.\nPragmatic Programming\n⇒http://www.pragmaticprogrammer.com\nHome page for Pragmatic Programming and your authors. Here you’ll\nﬁnd all of the source code examples from this book, additional re-\nsources, updated URLs and errata, and news on additional volumes\nin this series and other resources.\nSharpDevelop\n⇒http://www.sharpdevelop.net\nA fully-featured and stable open-source IDE for .NET development.\nHas tight integration with NAnt, NUnit, NCover, code analysis, and\nsource control.i\nTestDriven.NET\n⇒http://www.testdriven.net\nVisual-Studio integration for NUnit and NCover.\nxUnit\n⇒http://www.xprogramming.com/software.htm\nUnit testing frameworks for many, many different languages and en-\nvironments.\n\n\nBIBLIOGRAPHY\n192\nC.2\nBibliography\n[Cla04]\nMike Clark. Pragmatic Project Automation. How to\nBuild, Deploy, and Monitor Java Applications. The\nPragmatic Programmers, LLC, Raleigh, NC, and\nDallas, TX, 2004.\n[FBB+99]\nMartin Fowler, Kent Beck, John Brant, William\nOpdyke, and Don Roberts.\nRefactoring: Improv-\ning the Design of Existing Code.\nAddison Wesley\nLongman, Reading, MA, 1999.\n[Fea04]\nMichael Feathers. Working Effectively with Legacy\nCode. Prentice Hall, Englewood Cliffs, NJ, 2004.\n[HT00]\nAndrew Hunt and David Thomas. The Pragmatic\nProgrammer: From Journeyman to Master.\nAddi-\nson-Wesley, Reading, MA, 2000.\n[Mey97]\nBertrand Meyer.\nObject-Oriented Software Con-\nstruction. Prentice Hall, Englewood Cliffs, NJ, sec-\nond edition, 1997.\n[MFC01]\nTim Mackinnon, Steve Freeman, and Philip Craig.\nEndo-testing:\nUnit testing with mock objects.\nIn Giancarlo Succi and Michele Marchesi, edi-\ntors, Extreme Programming Examined, chapter 17,\npages 287–302. Addison Wesley Longman, Read-\ning, MA, 2001.\n[Ric06]\nJeffrey Richter. CLR via C. Microsoft Press, Red-\nmond, WA, second edition, 2006.\n[SH06]\nVenkat Subramaniam and Andy Hunt. Practices of\nan Agile Developer: Working in the Real World. The\nPragmatic Programmers, LLC, Raleigh, NC, and\nDallas, TX, 2006.\n[Sub05]\nVenkat Subramaniam. .NET Gotchas. O’Reilly &\nAssociates, Inc, Sebastopol, CA, 2005.\n[TH03]\nDavid Thomas and Andrew Hunt. Pragmatic Ver-\nsion Control Using CVS. The Pragmatic Program-\nmers, LLC, Raleigh, NC, and Dallas, TX, 2003.\n\n\nBIBLIOGRAPHY\n193\n[wCA04]\nKent Beck with Cynthia Andres. Extreme Program-\nming Explained: Embrace Change. Addison-Wes-\nley, Reading, MA, second edition, 2004.\n",
      "page_number": 199
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 207-214)",
      "start_page": 207,
      "end_page": 214,
      "detection_method": "topic_boundary",
      "content": "Pragmatic Unit Testing: Summary\nGeneral Principles:\n2 Test anything that might break\n2 Test everything that does break\n2 New code is guilty until proven innocent\n2 Write at least as much test code as\nproduction code\n2 Run local tests with each compile\n2 Run all tests before check-in to repository\nQuestions to Ask:\n2 If the code ran correctly, how\nwould I know?\n2 How am I going to test this?\n2 What else can go wrong?\n2 Could this same kind of problem\nhappen anywhere else?\nWhat to Test: Use Your RIGHT-BICEP\n2 Are the results right?\n2 Are all the boundary conditions CORRECT?\n2 Can you check inverse relationships?\n2 Can you cross-check results using other\nmeans?\n2 Can you force error conditions to happen?\n2 Are performance characteristics within\nbounds?\nGood tests are A TRIP\n2 Automatic\n2 Thorough\n2 Repeatable\n2 Independent\n2 Professional\nCORRECT Boundary Conditions\n2 Conformance — Does the value conform to an expected format?\n2 Ordering — Is the set of values ordered or unordered as appropriate?\n2 Range — Is the value within reasonable minimum and maximum values?\n2 Reference — Does the code reference anything external that isn’t under direct\ncontrol of the code itself?\n2 Existence — Does the value exist? (e.g., is non-null, non-zero, present in a set, etc.)\n2 Cardinality — Are there exactly enough values?\n2 Time (absolute and relative) — Is everything happening in order? At the right time?\nIn time?\nhttp://www.pragmaticprogrammer.com/titles/utc2\n\n\nAppendix E\nAnswers to Exercises\nExercise 1:\nfrom page 86\nA simple stack class. Push String objects onto the stack, and Pop\nthem off according to normal stack semantics. This class provides\nthe following methods:\nusing System;\npublic interface StackExercise {\n/// <summary>\n/// Return and remove the most recent item from\n/// the top of the\nstack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n/// </exception>\nString Pop();\n/// <summary>\n/// Add an item to the top of the stack.\n/// </summary>\n/// <param name=\"item\">A String to push\n/// on the stack</param>\nvoid Push(String item);\n/// <summary>\n/// Return but do not remove the most recent\n/// item from the top of the stack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n/// </exception>\nString Top();\n/// <summary>\n/// Returns true if the stack is empty.\n\n\nAPPENDIX E. ANSWERS TO EXERCISES\n196\n/// </summary>\nbool IsEmpty();\n}\nStackExercise.cs\nHere are some hints to get you started: what is likely to break? How\nshould the stack behave when it is ﬁrst initialized? After it’s been\nused for a while? Does it really do what it claims to do?\nAnswer 1:\n• For a brand-new stack, IsEmpty() should be true, Top() and\nPop() should throw exceptions.\n• Starting with an empty stack, call Push() to push a test string\nonto the stack. Verify that Top() returns that string several\ntimes in a row, and that IsEmpty() returns false.\n• Call Pop() to remove the test string, and verify that it is the\nsame string.1 IsEmpty() should now be true. Call Pop() again\nverify an exception is thrown.\n• Now do the same test again, but this time add multiple items to\nthe stack. Make sure you get the right ones back, in the right\norder (the most recent item added should be the one returned).\n• Push a null onto the stack and Pop it; conﬁrm you get a null\nback.\n• Ensure you can use the stack after it has thrown exceptions.\nExercise 2:\nfrom page 87\nA shopping cart. This class lets you add, delete, and count the items\nin a shopping cart.\nWhat sort of boundary conditions might come up? Are there any im-\nplicit restrictions on what you can delete? Are there any interesting\nissues if the cart is empty?\npublic interface ShoppingCart {\n/// <summary>\n/// Add this many of this item to the\n/// shopping cart.\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\nvoid AddItems(Item anItem, int quantity);\n/// <summary>\n1In this case, the Is.EqualTo() constraint isn’t good enough; you need\nIs.Same() to ensure it’s the same object.\n\n\nAPPENDIX E. ANSWERS TO EXERCISES\n197\n/// Delete this many of this item from the\n/// shopping cart\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\n/// <exception cref=\"NoSuchItemException\">\n/// </exception>\nvoid DeleteItems(Item anItem, int quantity);\n/// <summary>\n/// Count of all items in the cart\n/// (that is, all items x qty each)\n/// </summary>\nint ItemCount { get; }\n/// Return iterator of all items\nIEnumerable GetEnumerator();\n}\nShoppingCart.cs\nAnswer 2:\n• Call AddItems with quantity of 0 and ItemCount should re-\nmain the same.\n• Call DeleteItem with quantity of 0 and ItemCount should re-\nmain the same.\n• Call AddItems with a negative quantity and it should raise an\nexception.\n• Call DeleteItem with a negative quantity and it should raise\nan exception.\n• Call AddItems and the item count should increase, whether\nthe item exists already or not.\n• Call DeleteItem where the item doesn’t exist and it should\nraise an exception.\n• Call DeleteItem when there are no items in the cart and Item-\nCount should remain at 0.\n• Call DeleteItem where the quantity is larger than the number\nof those items in the cart and it should raise an exception.\n• Call GetEnumerator when there are no items in the cart and\nit should return an empty iterator (i.e., it’s a real IEnumerable\nobject (not null) that contains no items).\n• Call AddItem several times for a couple of items and verify that\ncontents of the cart match what was added (as reported via\nGetEnumerator() and ItemCount()).\nHint: you can combine several of these asserts into a single test. For\ninstance, you might start with an empty cart, add 3 of an item, then\ndelete one of them at a time.\n\n\nAPPENDIX E. ANSWERS TO EXERCISES\n198\nExercise 3:\nfrom page 88\nA fax scheduler. This code will send faxes from a speciﬁed ﬁle name\nto a U.S. phone number. There is a validation requirement; a U.S.\nphone number with area code must be of the form xnn-nnn-nnnn,\nwhere x must be a digit in the range [2..9] and n can be [0..9].\nThe following blocks are reserved and are not currently valid area\ncodes: x11, x9n, 37n, 96n.\nThe method’s signature is:\n///\n/// Send the named file as a fax to the\n/// given phone number.\n/// <exception cref=\"MissingOrBadFileException\">\n/// </exception>\n/// <exception cref=\"PhoneFormatException\">\n/// </exception>\n/// <exception cref=\"PhoneAreaCodeException\">\n/// </exception>\npublic bool SendFax(String phone, String filename)\nGiven these requirements, what tests for boundary conditions can\nyou think of?\nAnswer 3:\n• Phone numbers with an area code of 111, 211, up to 911, 290,\n291, etc, 999, 370-379, or 960-969 should throw a Phone-\nAreaCodeException.\n• A phone number with too many digits (in one of each set of\nnumber, area code, preﬁx, number) should throw a PhoneFor-\nmatException.\n• A phone number with not enough digits (in one of each set)\nshould throw a PhoneFormatException.\n• A phone number with illegal characters (spaces, letters, etc.)\nshould throw a PhoneFormatException.\n• A phone number that’s missing dashes should throw a Phone-\nFormatException.\n• A phone number with multiple dashes should throw a Phone-\nFormatException.\n• A null phone number should throw a PhoneFormatException.\n• A ﬁle that doesn’t exist should throw a MissingOrBadFile-\nException.\n• A null ﬁlename should also throw that exception.\n• An empty ﬁle should throw a MissingOrBadFileException.\n\n\nAPPENDIX E. ANSWERS TO EXERCISES\n199\n• A ﬁle that’s not in the correct format should throw a Missing-\nOrBadFileException.\nExercise 4:\nfrom page 88\nAn automatic sewing machine that does embroidery. The class\nthat controls it takes a few basic commands. The coordinates (0,0)\nrepresent the lower-left corner of the machine. x and y increase as\nyou move toward the upper-right corner, whose coordinates are x =\nTableSize.Width - 1 and y = TableSize.Height - 1.\nCoordinates are speciﬁed in fractions of centimeters.\npublic void MoveTo(double x, double y);\npublic void SewTo(double x, double y);\npublic void SetWorkpieceSize(double width,\ndouble height);\npublic Size WorkpieceSize { get; }\npublic Size TableSize { get; }\nThere are some real-world constraints that might be interesting: you\ncan’t sew thin air, of course, and you can’t sew a workpiece bigger\nthan the machine.\nGiven these requirements, what boundary conditions can you think\nof?\nAnswer 4:\n• Huge value for one or both coordinates\n• Huge value for workpiece size\n• Zero or negative value for one or both coordinates\n• Zero or negative value for workpiece size\n• Coordinates that move off the workpiece\n• Workpiece bigger than the table\nExercise 5:\nfrom page 89\nAudio/Video Editing Transport. A class that provides methods to\ncontrol a VCR or tape deck. There’s the notion of a “current position”\nthat lies somewhere between the beginning of tape (BOT) and the end\nof tape (EOT).\nYou can ask for the current position and move from there to another\ngiven position.\nFast-forward moves from current position toward\nEOT by some amount. Rewind moves from current position toward\nBOT by some amount.\n\n\nAPPENDIX E. ANSWERS TO EXERCISES\n200\nWhen tapes are ﬁrst loaded, they are positioned at BOT automati-\ncally.\nusing System;\npublic interface AVTransport {\n/// Move the current position ahead by this many\n/// seconds. Fast-forwarding past end-of-tape\n/// leaves the position at end-of-tape\nvoid FastForward(double seconds);\n/// Move the current position backwards by this\n/// many seconds. Rewinding past zero leaves\n/// the position at zero\nvoid Rewind(double seconds);\n/// Return current time position in seconds\ndouble CurrentTimePosition();\n/// Mark the current time position with label\nvoid MarkTimePosition(String name);\n/// Change the current position to the one\n/// associated with the marked name\nvoid GotoMark(String name);\n}\nAVTransport.cs\nAnswer 5:\n• Verify that the initial position is BOT.\n• Fast forward by some allowed amount (not past end of tape),\nthen rewind by same amount. Should be at initial location.\n• Rewind by some allowed amount (not before the beginning of\ntape), then fast forward by same amount. Should be at initial\nlocation.\n• Fast forward past end of tape, then rewind by same amount.\nShould be before the initial location by an appropriate amount\nto reﬂect the fact that you can’t advance the location past the\nend of tape.\n• Try the same thing in the other direction (rewind past begin-\nning of tape).\n• Mark various positions and return to them after moving the\ncurrent position around.\n• Mark a position and return to it without moving in between.\n\n\nAPPENDIX E. ANSWERS TO EXERCISES\n201\nExercise 6:\nfrom page 89\nAudio/Video Editing Transport, Release 2.0. As above, but now\nyou can position in seconds, minutes, or frames (there are exactly\n30 frames per second in this example), and you can move relative to\nthe beginning or the end.\nAnswer 6:\nCross-check results using different units: move in one\nunit and verify your position using another unit; move forward in\none unit and back in another, and so on.\nExercise 7:\nfrom page 163\nDesign an interest calculator that calculates the amount of interest\nbased on the number of working days in-between two dates.\nUse\ntest-ﬁrst design, and take it one step at a time.\nAnswer 7:\nHere’s a possible scenario of steps you might take.\nThere is no right answer; this exercise is simply to get you to think\nabout test-ﬁrst design.\n1. Begin by simply calculating the days between any two dates\nﬁrst. The tests might include:\n• Use the same value for ﬁrst date and last date.\n• Try the normal case where ﬁrst date < last date.\n• Try the error case where ﬁrst date > last date.\n• Try dates that span a year boundary (from October 1 2003\nto March 1, 2004 for instance).\n• Try dates more than a year apart (from October 1 2003 to\nDecember 1, 2006).\n2. Next, exclude weekends from the calculation, using the same\nsorts of tests.\n3. Now exclude public and/or corporate holidays. This raises a\npotentially interesting question: how do you specify holidays?\nYou had to face that issue when writing the tests; do you think\ndoing so improved your interface?\n4. Finally, perform the interest calculation itself. You might start\noff with tests such as:\n• Interest amount should never be negative (an invariant).\n• Interest when ﬁrst date equals last date should be 0.0.\n",
      "page_number": 207
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 215-220)",
      "start_page": 215,
      "end_page": 220,
      "detection_method": "topic_boundary",
      "content": "Index\nSymbols\n0–1–n rule, 82\nA\nA-TRIP, 117\nAccessors, 124\nActual, 34\nAddCropMarks(), 162\nADO (mock objects), 109\nAgile, 61\nAmount of test code, 125\nAnonymous array, 19\nArianne 5 rocket, 6\nAssert\ncustom, 77\ndeﬁnition, 34\nAssert class, 34\nAreEqual(), 34\nAssert.AreEqual(), 17\nAssert.AreSame(), 36\nAssert.Fail(), 37\nAssert.IsFalse(), 36\nAssert.IsNotNull(), 36\nAssert.IsNull(), 36\nAssert.IsTrue(), 16, 36, 184\nAssert.That(), 39\nAssumptions, 80\nAutomatic, 118\nAutomation, x\nB\nBad magic, 117\nBean, see Enterprise Java Beans\n(EJB)\nBearing.cs, 76\nBig ball of mud, 137\nBlank, 81\nBoolean conditions, 16, 36\nBoundary conditions, 64, 71\nBreaking the build/tests, 134\nBroccoli, 1\nBug\nsee also Debugging; Error\nBugs\nclumping, 120, 121\nelusive, 187\nﬁxing, 126\nidentifying likely, 60\nin sort routines, 74\nisolating, 11, 41\nlist position, 29, 74\nmemory, 184\nphantom, 122\nrewriting due to, 11\ntraceable to unit tests, 123\nBuild machine, 118\nBusiness logic, 84, 159\nC\nC#\nlibrary versions, 186\nCardinality, 82\nCareer limiting move, 12\n[Category], 45\ncheckInvariant(), 78\nClean room, 164\nCode examples\nﬁnding the source to, xii\nCoding\nsee also Coupled code;\nDecoupled code;\nMetadata; Source code\ncontrol system (SCCS)\nCollateral damage, 160\n\n\nCOMMENT\n203\nFROG\ndeﬁnition, 9\nComment\nsee also Documentation\nComponent-based systems, see\nModular system\nConcurrency, 84, 86, 187\nConﬁdence, 4\nConformance, 72\nContinuous build/integration,\n118, 136\nContract\nsee also Design by contract\n(DBC)\nCopy and paste, 53, 124\nCORRECT, 71\nCosts, 11\nCoupled code\nsee also Decoupled code\nCoupling, 90, 186\nCross-checking, 67\nCruiseControl, 118, 190\nCVS, 134\nD\nData\nsee also Metadata\nData structures, 77\nDaylight savings time, 85\nDebugging, 2, 10\nDecoupled code\nsee also Coupled code\nDelphi\nsee also Object Pascal\nDependencies, 79, 186\nDependency, reducing, see\nModular system;\nOrthogonality\nDeveloper sandbox, 122, 128\nDocumentation\nsee also Comment; Web\ndocumentation\nDon’t repeat yourself, see DRY\nprinciple\nDonne, John, 123\nDotGNU, 190\nDotNetMock, 108–116, 190\nDownloading source code, see\nExample code\nDRY principle, 124, 164\ndeﬁnition, 53n\nsee also Duplication\nDuck, rubber, see Rubber duck\nDynamic mock objects, 101\nE\nE-mail address format, 72\nElephant\nhow to eat, 139\nEncapsulation, 76, 129\nEngineering, 6\nEnvironmental constraints, 68\nEqualConstraint, 39\nEquality, 16\ndeceptive, 185\nError\nsee also Exception\nError conditions, 68\nException, 30, 34, 54, 56, 81,\n140\nExcuses, 8\nExercises\nA/V transport, 89, 199\nfax machine, 88, 198\ninterest calculator, 163\nsewing machine, 88, 199\nshopping cart, 87, 196\nstack, 86, 195\nExistence, 81\nExpected, 34\n[ExpectedException], 55, 57\nExpert, see Guru\nExternal dependencies, 79, 186\nExtreme Programming, 128, 139\nF\nFactory class, 163\nfakes, 94\nFeedback, xi, 126, 136, 162\nFence post errors, 82\nFileAssert.AreEqual(), 52\nFileAssert.AreNotEqual(), 52\nFiles, 94\nFilterRanges(), 69\nFinally, 155\nﬁxture\ndeﬁnition, 43\nFloating-point numbers, 35, 184\nFormal testing, 4\nFree Software Foundation, see\nGNU Project\nFrog, boiled, see Boiled frog\n\n\nGMT\n204\nORTHOGONALITY\nG\nGMT, 85\nGood neighbor, 154\n“Good-enough software”, see\nSoftware, quality\nH\nHas.Length(), 40\nHouse of cards, 4\nI\nIDE, 13, 118\nImproving tests, 126\nIndependence, see Orthogonality\nIndependent, 49, 122\nIndexing concepts, 79\nInput data validation, 163\nInspection, code, see Code\nreviews\nInvariant, 77, 78, 159\non an index, 160\nInverse relationships, 66\nIs.AtLeast(), 40\nIs.AtMost, 39\nIs.Empty, 40\nIs.EqualTo(), 39\nIs.InstanceOfType(), 40\nIs.Not.EqualTo, 39\nIs.Null, 40\nIs.SubsetOf(), 51\nJ\nJamItIntoPark(), 80\nJavaDoc, see Java\nK\nKaizen\nsee also Knowledge portfolio\nKitchenOrder(), 75\nL\nLanguage, programming\nsee also Mini-language\nLargest(), 17–30\nLargest.cs, 18\nLargestDataFileTests, 62\nLargestTest.cs,\nhyperpage41, 19 −−43\nLargestTest, 30\nLayered system, see Modular\nsystem\nLegacy code, 136, 137\nLibrarian, see Project librarian\nLighting doubles, 90\nList.Contains, 51\nLogging\nsee also Tracing\nLong-running tests, 185\nM\nMember variables, see Accessor\nfunctions\nMessage, 34\nMock objects, 14, 90–116, 118,\n186\ndeﬁnition, 91\ndynamic, 101\nsteps to using, 91\nMoneyAssert.cs, 53\nmono, 190\nMyStack.cs, 77–79\nMyStackTest(), 78\nN\nNCover, 120, 190\nNCoverExplorer, 191\nNMock, 191\nNMock2, 105–106\nNotConstraint, 39\nNull, 36, 81\nNumeric overﬂow, 7n\nNUnit, 191\nattributes, 45, 49, 55, 57\ncustom asserts, 53\nand exceptions, 54\nminimum framework, 41\norder of tests, 123\nselecting tests, 43\nnunit.mocks, 100–104\nO\nObject identity, 36\nOff-by-one errors, 29, 82\nOpen Source\ndeﬁnition, 21\nOrdering, 74, see Workﬂow\nOrthogonality\nsee also Modular system\n\n\nPAIR PROGRAMMING\n205\n[TE A RDO W N]\nP\nPair programming, 139\nParrots, killer, see Branding\nPay-as-you go model, 10\nPerformance, 69\nPhantom bugs, 122\nPostconditions\ndeﬁnition, 80\nPragmatic Automation, x\nPragmatic Programmers\nemail address, xiv\nwebsite, xin\nPragmatic Programming, 191\nPragmatic Starter Kit, ix\nPragmatic Version Control, ix,\n134\nPreconditions\ndeﬁnition, 80\nPrivate access, 129\nProduction code, 5, 124\ndeﬁnition, 32\nProduction system, 14\nProfessional, 123, 139\nProject\nsee also Automation;\nTeam, project\nProperties ﬁle, 146\nProtected access, 129\nPrototype, 13\nPublic access, 129\nR\nRange, 75\nRecipe.cs, 151\nRecipeFile.cs, 151\nRecipes.cs, 146–150\nRecipeTest.cs, 153\nRefactoring, 146, 186\nReference, 79\nRegression, 69\nRepeatable, 122\nRequirements, 7, 30, 61, 84, 185\nRestaurant order, 74\nResults\nanalyzing, 8, 118, 184\nRetrospectives, 139\nReturn on investment, 137\nReviews, 139\nRight, 61\nRIGHT-BICEP, 60\nS\nSample programs, see Example\ncode\nSandbox, 122, 128\nScientiﬁc applications, 35\nSelf-contained components, see\nOrthogonality; Cohesion\nSendFax(), 88, 198\nSeparation of concerns, 143\n[SetUp], 49\nSetup code\nexecution order, 50\nSharpDevelop, 191\nShell, command\nsee also Command shell\n“Shy” code, 143\nSide-effects, 81\nSingle testing phase, 11\nsleep, 144\nSleepUntilNextHour(), 143\nSmoke test, 183\nSoftware engineering, 6\nSort routines, 74\nSource code\ndocumentation, see\nComments\ndownloading, see Example\ncode\nreviews, see Code reviews\nSQL (mock objects), 109\nStand-ins, 90\nStandardPaperFactory, 163\nStarting a project\nsee also Requirement\nStream, 94\nString constants, 155\nStructured walkthroughs, see\nCode reviews\nStubs, 92\nstubs, 92\nSubVersion, 134\nSupplier, see Vendor\nSVN, 134\nSynchronized, 86\nSyntax vs. semantics, 13\nSystem.Data, 109\nT\nTeam communication, 140\nTeam environment, 134\n[TearDown], 49\n\n\nTEARDOWN CODE\n206\nZERO\nTeardown code\nexecution order, 50\n[Test], 42\nTest code\nand property accessors, 124\nbroken, 41, 183, 186\ncleanup, 155\ncompiling, 33\ncorrelate to bugs, 123\nand data ﬁles, 61\nenvironment, 184\nﬁrst test, 18\ninvoking, 118\nlinear, 124\nlocating, 129\nlong running, 185\nordering, 123\nvs. production code, 33, 125\nrequired actions, 33\nresults, 8\nreviewing, 140\nselecting, 43\ntesting, 125\nTest coverage analysis tools, 120,\n121\nTest data, 64\nTest setup\nper-ﬁxture, 51\nper-test, 49\nTest-driven design, 140, 161\nTestAdd(), 127\nTestDriven.NET, 191\n[TestFixture], 42\nTesting\nacceptance, 3, 14\nand design, architecture,\n30, 143\ncourtesy, 132\nenvironment, 184\nexcuses, 8\nformal, 4\nfrequency, 135\nfunctional, 14\nGUI, 158\nmetrics, 121\nperformance, 3, 14\nregression, 69, 137\nresponsibility, 164\nsee also Unit testing\nText.Matches(), 52\nText.StartsWith(), 52\nThorough, 119\nTime, 8, 11, 84, 185\nTimeouts, 85\nTolerance, 185\nTracing\nsee also Logging\nTraveling salesman algorithm, 45\nU\nUML, see Uniﬁed modeling\nlanguage (UML)\nUnit testing\ndeﬁnition, 3\nintentional sabotage, 127\npotential dangers, 117\nusing, 42\nUTC, 85\nV\nValidation, 61\nand veriﬁcation, 3, 14\nformatted data, 73\ninput data, 163\nuser input, 164\nVersion control, ix, 134\nW\nWalkthoughs, see Code reviews\nWall-clock time, 85\nWhac-a-Mole, 9\nWriting\nsee also Documentation\nX\nXML, 63\nxUnit, 191\nZ\nZero, 81\n",
      "page_number": 215
    }
  ],
  "pages": [
    {
      "page_number": 2,
      "content": "What readers are saying about\nPragmatic Unit Testing in C#. . .\n“As part of the Mono project, we routinely create and\nmaintain extensive unit tests for our class libraries. This\nbook is a fantastic introduction for those interested in\ncreating solid code.”\nMiguel de Icaza, Mono Project, Novell, Inc.\n“Andy and Dave have created an excellent, practical and (of\ncourse) very pragmatic guide to unit-testing, illustrated with\nplenty of examples using the latest version of NUnit.”\nCharlie Poole, NUnit framework developer\n“Anybody coding in .NET or, for that matter, any language,\nwould do well to have a copy of this book, not just on their\nbookshelf, but sitting open in front of their monitor. Unit\ntesting is an essential part of any programmer’s skill set, and\nAndy and Dave have written (yet another) essential book on\nthe topic.”\nJustin Gehtland, Founder, Relevance LLC\n“The Pragmatic Programmers have done it again with this\nhighly useful guide. Aimed directly at C# programmers using\nthe most popular unit-testing package for the language, it\ngoes beyond the basics to show what you should test and\nhow you should test it. Recommended for all .NET\ndevelopers.”\nMike Gunderloy,\nContributing Editor, ADT Magazine\n“Using the approaches described by Dave and Andy you can\nreduce greatly the number of defects you put into your code.\nThe result will be faster development of better programs. Try\nthese techniques—they will work for you!”\nRon Jeffries, www.XProgramming.com\n",
      "content_length": 1475,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 3,
      "content": "Pragmatic Unit Testing\nin C# with NUnit, Second Edition\nAndy Hunt\nDave Thomas\nwith Matt Hargett\nThe Pragmatic Bookshelf\nRaleigh, North Carolina\nDallas, Texas\n",
      "content_length": 158,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 4,
      "content": "Bookshelf\nPragmatic\nMany of the designations used by manufacturers and sellers to distinguish\ntheir products are claimed as trademarks. Where those designations appear\nin this book, and The Pragmatic Programmers, LLC was aware of a trademark\nclaim, the designations have been printed in initial capital letters or in all\ncapitals. The Pragmatic Starter Kit, The Pragmatic Programmer, Pragmatic\nProgramming, Pragmatic Bookshelf and the linking “g” device are trademarks\nof The Pragmatic Programmers, LLC.\nEvery precaution was taken in the preparation of this book. However, the\npublisher assumes no responsibility for errors or omissions, or for damages\nthat may result from the use of information (including program listings) con-\ntained herein.\nOur Pragmatic courses, workshops and other products can help you and your\nteam create better software and have more fun. For more information, as well\nas the latest Pragmatic titles, please visit us at:\nhttp://www.pragmaticprogrammer.com\nCopyright c⃝2007 The Pragmatic Programmers, LLC. All rights reserved. No\npart of this publication may be reproduced, stored in a retrieval system, or\ntransmitted, in any form, or by any means, electronic, mechanical, photo-\ncopying, recording, or otherwise, without the prior consent of the publisher.\nPrinted in the United States of America.\nISBN-10: 0-9776166-7-3\nISBN-13: 978-0-9776166-7-4\n",
      "content_length": 1377,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 5,
      "content": "Contents\nAbout the Starter Kit\nix\nPreface\nxi\n1\nIntroduction\n1\n1.1\nCoding With Conﬁdence . . . . . . . . . . . . . .\n2\n1.2\nWhat is Unit Testing? . . . . . . . . . . . . . . .\n3\n1.3\nWhy Should I Bother with Unit Testing?\n. . . .\n4\n1.4\nWhat Do I Want to Accomplish? . . . . . . . . .\n5\n1.5\nHow Do I Do Unit Testing? . . . . . . . . . . . .\n7\n1.6\nExcuses For Not Testing . . . . . . . . . . . . . .\n8\n1.7\nRoadmap\n. . . . . . . . . . . . . . . . . . . . . .\n15\n2\nYour First Unit Tests\n16\n2.1\nPlanning Tests\n. . . . . . . . . . . . . . . . . . .\n17\n2.2\nTesting a Simple Method\n. . . . . . . . . . . . .\n18\n2.3\nRunning Tests with NUnit\n. . . . . . . . . . . .\n20\n2.4\nRunning the Example . . . . . . . . . . . . . . .\n27\n2.5\nMore Tests . . . . . . . . . . . . . . . . . . . . . .\n31\n3\nWriting Tests in NUnit\n32\n3.1\nStructuring Unit Tests . . . . . . . . . . . . . . .\n32\n3.2\nClassic Asserts . . . . . . . . . . . . . . . . . . .\n34\n3.3\nConstraint-based Asserts . . . . . . . . . . . . .\n37\n3.4\nNUnit Framework\n. . . . . . . . . . . . . . . . .\n41\n3.5\nNUnit Test Selection . . . . . . . . . . . . . . . .\n43\n3.6\nMore NUnit Asserts\n. . . . . . . . . . . . . . . .\n51\n3.7\nNUnit Custom Asserts . . . . . . . . . . . . . . .\n53\n3.8\nNUnit and Exceptions . . . . . . . . . . . . . . .\n54\n3.9\nTemporarily Ignoring Tests . . . . . . . . . . . .\n57\n",
      "content_length": 1331,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 6,
      "content": "CONTENTS\nvi\n4\nWhat to Test: The Right-BICEP\n60\n4.1\nAre the Results Right? . . . . . . . . . . . . . . .\n61\n4.2\nBoundary Conditions\n. . . . . . . . . . . . . . .\n64\n4.3\nCheck Inverse Relationships . . . . . . . . . . .\n66\n4.4\nCross-check Using Other Means . . . . . . . . .\n67\n4.5\nForce Error Conditions\n. . . . . . . . . . . . . .\n68\n4.6\nPerformance Characteristics . . . . . . . . . . .\n69\n5\nCORRECT Boundary Conditions\n71\n5.1\nConformance . . . . . . . . . . . . . . . . . . . .\n72\n5.2\nOrdering . . . . . . . . . . . . . . . . . . . . . . .\n74\n5.3\nRange\n. . . . . . . . . . . . . . . . . . . . . . . .\n75\n5.4\nReference\n. . . . . . . . . . . . . . . . . . . . . .\n79\n5.5\nExistence\n. . . . . . . . . . . . . . . . . . . . . .\n81\n5.6\nCardinality\n. . . . . . . . . . . . . . . . . . . . .\n82\n5.7\nTime . . . . . . . . . . . . . . . . . . . . . . . . .\n84\n5.8\nTry It Yourself . . . . . . . . . . . . . . . . . . . .\n86\n6\nUsing Mock Objects\n90\n6.1\nStubs . . . . . . . . . . . . . . . . . . . . . . . . .\n92\n6.2\nFakes . . . . . . . . . . . . . . . . . . . . . . . . .\n94\n6.3\nMock Objects . . . . . . . . . . . . . . . . . . . . 100\n6.4\nWhen Not To Mock . . . . . . . . . . . . . . . . . 112\n7\nProperties of Good Tests\n117\n7.1\nAutomatic . . . . . . . . . . . . . . . . . . . . . . 118\n7.2\nThorough\n. . . . . . . . . . . . . . . . . . . . . . 119\n7.3\nRepeatable\n. . . . . . . . . . . . . . . . . . . . . 122\n7.4\nIndependent . . . . . . . . . . . . . . . . . . . . . 122\n7.5\nProfessional . . . . . . . . . . . . . . . . . . . . . 123\n7.6\nTesting the Tests . . . . . . . . . . . . . . . . . . 125\n8\nTesting on a Project\n129\n8.1\nWhere to Put Test Code . . . . . . . . . . . . . . 129\n8.2\nWhere to Put NUnit\n. . . . . . . . . . . . . . . . 132\n8.3\nTest Courtesy . . . . . . . . . . . . . . . . . . . . 132\n8.4\nTest Frequency . . . . . . . . . . . . . . . . . . . 135\n8.5\nTests and Legacy Code\n. . . . . . . . . . . . . . 136\n8.6\nTests and Code Reviews . . . . . . . . . . . . . . 139\n",
      "content_length": 1971,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 7,
      "content": "CONTENTS\nvii\n9\nDesign Issues\n143\n9.1\nDesigning for Testability . . . . . . . . . . . . . . 143\n9.2\nRefactoring for Testing . . . . . . . . . . . . . . . 146\n9.3\nTesting the Class Invariant . . . . . . . . . . . . 159\n9.4\nTest-Driven Design . . . . . . . . . . . . . . . . . 161\n9.5\nTesting Invalid Parameters . . . . . . . . . . . . 163\n10 GUI Testing\n165\n10.1 Unit testing WinForms\n. . . . . . . . . . . . . . 165\n10.2 Unit testing beyond Windows Forms\n. . . . . . 169\n10.3 Web UIs . . . . . . . . . . . . . . . . . . . . . . . 171\n10.4 Command Line UIs . . . . . . . . . . . . . . . . . 175\n10.5 GUI Testing Gotchas . . . . . . . . . . . . . . . . 177\nA\nExtending NUnit\n180\nA.1\nWriting NUnit Extensions . . . . . . . . . . . . . 180\nA.2\nUsing NUnit Core Addins . . . . . . . . . . . . . 182\nB\nGotchas\n183\nB.1\nAs Long As The Code Works\n. . . . . . . . . . . 183\nB.2\n“Smoke” Tests\n. . . . . . . . . . . . . . . . . . . 183\nB.3\n“Works On My Machine” . . . . . . . . . . . . . . 184\nB.4\nFloating-Point Problems . . . . . . . . . . . . . . 184\nB.5\nTests Take Too Long . . . . . . . . . . . . . . . . 185\nB.6\nTests Keep Breaking . . . . . . . . . . . . . . . . 186\nB.7\nTests Fail on Some Machines . . . . . . . . . . . 186\nB.8\nTests Pass in One Test Runner, Not the Other . 187\nB.9\nThread state issues\n. . . . . . . . . . . . . . . . 187\nB.10 C# 2.0-speciﬁc Issues . . . . . . . . . . . . . . . 188\nC\nResources\n190\nC.1\nOn The Web . . . . . . . . . . . . . . . . . . . . . 190\nC.2\nBibliography\n. . . . . . . . . . . . . . . . . . . . 192\nD\nSummary: Pragmatic Unit Testing\n194\nE\nAnswers to Exercises\n195\n",
      "content_length": 1598,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 8,
      "content": "BETA BOOK\nviii\nBeta\nBook\nAgile publishing for agile developers\nThe book you’re reading is still under development. As part of\nour industry-leading Beta Book program, we’re releasing this\ncopy well before we normally would. That way you’ll be able\nto get this content a couple of months before it’s available in\nﬁnished form, and we’ll get feedback to make the book even\nbetter. The idea is that everyone wins!\nBe warned. The book has not had a full technical edit, so it\nwill contain errors. It has not been copyedited, so it will be\nfull of typos. And there’s been no effort spent doing layout, so\nyou’ll ﬁnd bad page breaks, over-long lines (with black boxes\nat the end of line), incorrect hyphenations, and all the other\nugly things that you wouldn’t expect to see in a ﬁnished book.\nWe can’t be held liable if you use this book to try to create a\nspiffy application and you somehow end up with a strangely\nshaped farm implement instead.\nDespite all this, we think\nyou’ll enjoy it!\nThroughout this process you’ll be able to download updated\nPDFs from http://books.pragprog.com/titles/utc2/reorder.\nWhen the book is ﬁnally ready, you’ll get the ﬁnal version (and\nsubsequent updates) from the same address. In the mean-\ntime, we’d appreciate you sending us your feedback on this\nbook at http://books.pragprog.com/titles/utc2/errata.\nThank you for taking part in our Beta Book program.\nAndy Hunt\n",
      "content_length": 1396,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 9,
      "content": "About the Starter Kit\nOur ﬁrst book, The Pragmatic Programmer: From Journeyman\nto Master, is a widely-acclaimed overview of practical topics\nin modern software development. Since it was ﬁrst published\nin 1999, many people have asked us about follow-on books,\nor sequels. Towards that end, we started our own publishing\ncompany, the Pragmatic Bookshelf. By now we’ve got dozens\nof titles in print and in development, major awards, and many\nﬁve star reviews.\nBut the very books we published are still some of the most im-\nportant ones. Before embarking on any sequels to The Prag-\nmatic Programmer, we thought we’d go back and offer a pre-\nquel of sorts.\nOver the years, we’ve found that many of our pragmatic read-\ners who are just starting out need a helping hand to get their\ndevelopment infrastructure in place, so they can begin form-\ning good habits early. Many of our more advanced pragmatic\nreaders understand these topics thoroughly, but need help\nconvincing and educating the rest of their team or organiza-\ntion. We think we’ve got something that can help.\nThe Pragmatic Starter Kit is a three-volume set that covers\nthe essential basics for modern software development. These\nvolumes include the practices, tools, and philosophies that\nyou need to get a team up and running and super-productive.\nArmed with this knowledge, you and your team can adopt\ngood habits easily and enjoy the safety and comfort of a well-\nestablished “safety net” for your project.\nVolume I, Pragmatic Version Control, describes how to use ver-\nsion control as the cornerstone of a project. A project with-\n",
      "content_length": 1592,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 10,
      "content": "ABOUT THE STARTER KIT\nx\nout version control is like a word processor without an UNDO\nbutton: the more text you enter, the more expensive a mis-\ntake will be. Pragmatic Version Control shows you how to use\nversion control systems effectively, with all the beneﬁts and\nsafety but without crippling bureaucracy or lengthy, tedious\nprocedures.\nThis volume, Pragmatic Unit Testing, is the second volume in\nthe series. Unit testing is an essential technique as it provides\nreal-world, real-time feedback for developers as we write code.\nMany developers misunderstand unit testing, and don’t real-\nize that it makes our jobs as developers easier. This volume\nis available in two different language versions: in Java with\nJUnit, and in C# with NUnit.\nVolume III, Pragmatic Automation, covers the essential prac-\ntices and technologies needed to automate your code’s build,\ntest, and release procedures. Few projects suffer from having\ntoo much time on their hands, so Pragmatic Automation will\nshow you how to get the computer to do more of the mun-\ndane tasks by itself, freeing you to concentrate on the more\ninteresting—and difﬁcult—challenges.\nThese books are created in the same approachable style as\nour ﬁrst book, and address speciﬁc needs and problems that\nyou face in the trenches every day. But these aren’t dummy-\nlevel books that only give you part of the picture; they’ll give\nyou enough understanding that you’ll be able to invent your\nown solutions to the novel problems you face that we haven’t\naddressed speciﬁcally.\nFor up-to-date information on these and other books, as well\nas related pragmatic resources for developers and managers,\nplease visit us on the web at:\nhttp://www.pragmaticprogrammer.com\nThanks, and remember to make it fun!\n",
      "content_length": 1750,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 11,
      "content": "Preface\nWelcome to the world of developer-centric unit testing!\nWe\nhope you ﬁnd this book to be a valuable resource for yourself\nand your project team. You can tell us how it helped you—\nor let us know how we can improve—by visiting the Pragmatic\nUnit Testing page on our web site1 and clicking on “Feedback.”\nFeedback like that is what makes books great. It’s also what\nmakes people and projects great. Pragmatic programming is\nall about using real-world feedback to ﬁne tune and adjust\nyour approach.\nWhich brings us to unit testing. As we’ll see, unit testing is\nimportant to you as a programmer because it provides the\nfeedback you need. Without unit testing, you may as well be\nwriting programs on a yellow legal pad and hoping for the best\nwhen they’re run.\nThat’s not very pragmatic.\nThis book can help. It is aimed primarily at the C# program-\nmer who has some experience writing and designing code, but\nwho does not have much experience with unit testing.\nBut while the examples are in C#, using the NUnit framework,\nthe concepts remain the same whether you are writing in C++,\nFortran, Ruby, Smalltalk, or VisualBasic. Testing frameworks\nsimilar to NUnit exist for over 60 different languages; these\nvarious frameworks can be downloaded for free.2\n1http://www.pragmaticprogrammer.com/titles/utc2\n2http://www.xprogramming.com/software.htm\n",
      "content_length": 1348,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 12,
      "content": "PREFACE\nxii\nFor the more advanced programmer, who has done unit test-\ning before, we hope there will be a couple of nice surprises for\nyou here. Skim over the basics of using NUnit and concen-\ntrate on how to think about tests, how testing affects design,\nand how to handle certain team-wide issues you may be hav-\ning.\nAnd remember that this book is just the beginning. It may be\nyour ﬁrst book on unit testing, but we hope it won’t be your\nlast.\nWhere To Find The Code\nThroughout the book you’ll ﬁnd examples of C# code; some\nof these are complete programs while others are fragments of\nprograms. If you want to run any of the example code or look\nat the complete source (instead of just the printed fragment),\nlook in the margin: the ﬁlename of each code fragment in the\nbook is printed in the margin next to the code fragment itself.\nSome code fragments evolve with the discussion, so you may\nﬁnd the same source code ﬁle (with the same name) in the\nmain directory as well as in subdirectories that contain later\nversions (rev1, rev2, and so on).\nAll of the code in this book is available via the Pragmatic Unit\nTesting page on our web site.\nTypographic Conventions\nitalic font\nIndicates terms that are being deﬁned, or\nborrowed from another language.\ncomputer font\nIndicates method names, ﬁle and class\nnames, and various other literal strings.\nx xx xx xx;\nIndicates unimportant portions of source\ncode that are deliberately omitted.\nThe “curves ahead” sign warns that this\nmaterial is more advanced, and can safely\nbe skipped on your ﬁrst reading.\n",
      "content_length": 1554,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 13,
      "content": "PREFACE\nxiii\n“Joe the Developer,” our cartoon friend,\nasks a related question that you may ﬁnd\nuseful.\nSTOP\nA break in the text where you should stop\nand think about what’s been asked, or try\nan experiment live on a computer before\ncontinuing.\nLanguage-speciﬁc Versions\nAs of this printing, Pragmatic Unit Testing is available in two\nprogramming language-speciﬁc versions:\n• in Java with JUnit\n• in C# with NUnit\nAcknowledgments from the First Edition\nWe’d especially like to thank the following Practitioners for\ntheir valuable input, suggestions, and stories: Mitch Amiano,\nNascif Abousalh-Neto, Andrew C. Oliver, Jared Richardson,\nand Bobby Woolf.\nThanks also to our reviewers who took the time and energy\nto point out our errors, omissions, and occasionally-twisted\nwriting:\nGareth Hayter, Dominique Plante, Charlie Poole,\nMaik Schmidt, and David Starnes.\n",
      "content_length": 860,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 14,
      "content": "PREFACE\nxiv\nMatt’s Acknowledgments\nI would like to ﬁrst thank my amazing husband, Geoff, for\nall his patience while writing the book and contributing to\nvarious open source projects to ﬁx issues discovered along\nthe way. Second, gratitude to all the people who have been\ngreat pairs to program with and illuminated so much: Bryan\nSiepert, Strick, Mike Muldoon, Edward Hieatt, Aaron Peck-\nham, Luis Miras, Rob Myers, Li Moore, Marcel Prasetya, An-\nthony Lineberry, Mike Seery, Todd Nagengast, Richard Blay-\nlock, Andre Fonseca, Keith Dreibelbis, Katya Androchina, and\nCullen Bryan. Last, I’d like to thank my mom for pair pro-\ngramming with me as a boy, helping to typing in very long\nBASIC programs from various magazines of the day.\nAcknowledgments from the Second Edition\nThanks to all of you for your hard work and support. A special\nthank you goes to Matt Hargett for his contributions to this\nedition.\nThanks to our early reviewers, Cory Foy, Wes Reisz, and\nFrédérick Ros.\nAnd since this is a beta book, watch for more acknowledge-\nments in this space.\nAndy Hunt\nJuly, 2007\npragprog@pragmaticprogrammer.com\n",
      "content_length": 1112,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 15,
      "content": "Chapter 1\nIntroduction\nThere are lots of different kinds of testing that can and should\nbe performed on a software project. Some of this testing re-\nquires extensive involvement from the end users; other forms\nmay require teams of dedicated Quality Assurance personnel\nor other expensive resources.\nBut that’s not what we’re going to talk about here.\nInstead, we’re talking about unit testing: an essential, if often\nmisunderstood, part of project and personal success.\nUnit\ntesting is a relatively inexpensive, easy way to produce better\ncode, faster.\n”Unit testing” is the practice of using small bits of code to\nexercise the code you’ve written. In this book, we’ll be using\nthe NUnit testing framework to help manage and run these\nlittle bits of code.\nMany organizations have grand intentions when it comes to\ntesting, but tend to test only toward the end of a project, when\nthe mounting schedule pressures cause testing to be curtailed\nor eliminated entirely.\nMany programmers feel that testing is just a nuisance: an\nunwanted bother that merely distracts from the real business\nat hand—cutting code.\nEveryone agrees that more testing is needed, in the same way\nthat everyone agrees you should eat your broccoli, stop smok-\n",
      "content_length": 1229,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 16,
      "content": "CODING WITH CONFIDENCE\n2\ning, get plenty of rest, and exercise regularly. That doesn’t\nmean that any of us actually do these things, however.\nBut unit testing can be much more than these—while you\nmight consider it to be in the broccoli family, we’re here to tell\nyou that it’s more like an awesome sauce that makes every-\nthing taste better. Unit testing isn’t designed to achieve some\ncorporate quality initiative; it’s not a tool for the end-users,\nor managers, or team leads. Unit testing is done by program-\nmers, for programmers. It’s here for our beneﬁt alone, to make\nour lives easier.\nPut simply, unit testing alone can mean the difference be-\ntween your success and your failure. Consider the following\nshort story.\n1.1\nCoding With Conﬁdence\nOnce upon a time—maybe it was last Tuesday—there were\ntwo developers, Pat and Dale.\nThey were both up against\nthe same deadline, which was rapidly approaching. Pat was\npumping out code pretty fast; developing class after class and\nmethod after method, stopping every so often to make sure\nthat the code would compile.\nPat kept up this pace right until the night before the deadline,\nwhen it would be time to demonstrate all this code. Pat ran\nthe top-level program, but didn’t get any output at all. Noth-\ning. Time to step through using the debugger. Hmm. That\ncan’t be right, thought Pat. There’s no way that this variable\ncould be zero by now. So Pat stepped back through the code,\ntrying to track down the history of this elusive problem.\nIt was getting late now. That bug was found and ﬁxed, but Pat\nfound several more during the process. And still, there was\nno output at all. Pat couldn’t understand why. It just didn’t\nmake any sense.\nDale, meanwhile, wasn’t churning out code nearly as fast.\nDale would write a new routine and a short test to go along\nwith it. Nothing fancy, just a simple test to see if the routine\njust written actually did what it was supposed to do. It took a\nlittle longer to think of the test, and write it, but Dale refused\n",
      "content_length": 2009,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 17,
      "content": "WHAT IS UNIT TESTING?\n3\nto move on until the new routine could prove itself. Only then\nwould Dale move up and write the next routine that called it,\nand so on.\nDale rarely used the debugger, if ever, and was somewhat puz-\nzled at the picture of Pat, head in hands, muttering various\nevil-sounding curses at the computer with wide, bloodshot\neyes staring at all those debugger windows.\nThe deadline came and went, and Pat didn’t make it. Dale’s\ncode was integrated1 and ran almost perfectly.\nOne little\nglitch came up, but it was pretty easy to see where the prob-\nlem was. Dale ﬁxed it in just a few minutes.\nNow comes the punch line: Dale and Pat are the same age,\nand have roughly the same coding skills and mental prowess.\nThe only difference is that Dale believes very strongly in unit\ntesting, and tests every newly-crafted method before relying\non it or using it from other code.\nPat does not. Pat “knows” that the code should work as writ-\nten, and doesn’t bother to try it until most of the code has\nbeen completed. But by then it’s too late, and it becomes very\nhard to try to locate the source of bugs, or even determine\nwhat’s working and what’s not.\n1.2\nWhat is Unit Testing?\nA unit test is a piece of code written by a developer that ex-\nercises a very small, speciﬁc area of functionality in the code\nbeing tested.\nUsually a unit test exercises some particular\nmethod in a particular context. For example, you might add\na large value to a sorted list, then conﬁrm that this value ap-\npears at the end of the list. Or you might delete a pattern of\ncharacters from a string and then conﬁrm that they are gone.\nUnit tests are performed to prove that a piece of code does\nwhat the developer thinks it should do.\nThe question remains open as to whether that’s the right thing\nto do according to the customer or end-user: that’s what ac-\nceptance testing is for. We’re not really concerned with formal\n1Because Dale had been integrating all along via the unit tests.\n",
      "content_length": 1975,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 18,
      "content": "WHY SHOULD I BOTHER WITH UNIT TESTING?\n4\nvalidation and veriﬁcation or correctness just yet. We’re re-\nally not even interested in performance testing at this point.\nAll we want to do is prove that code does what we intended,2\nand so we want to test very small, very isolated pieces of func-\ntionality. By building up conﬁdence that the individual pieces\nwork as expected, we can then proceed to assemble and test\nworking systems.\nAfter all, if we aren’t sure the code is doing what we think,\nthen any other forms of testing may just be a waste of time.\nYou still need other forms of testing, and perhaps much more\nformal testing depending on your environment. But testing,\nas with charity, begins at home.\n1.3\nWhy Should I Bother with Unit Testing?\nUnit testing will make your life easier.3\nPlease say that with us, out loud. Unit testing will make your\nlife easier. That’s why we’re here.\nIt will make your designs better and drastically reduce the\namount of time you spend debugging. We like to write code,\nand time wasted on debugging is time spent not writing code.\nIn our tale above, Pat got into trouble by assuming that lower-\nlevel code worked, and then went on to use that in higher-level\ncode, which was in turn used by more code, and so on. With-\nout legitimate conﬁdence in any of the code, Pat was building\na “house of cards” of assumptions—one little nudge at the\nbottom and the whole thing falls down.\nWhen basic, low-level code isn’t reliable, the requisite ﬁxes\ndon’t stay at the low level. You ﬁx the low level problem, but\nthat impacts code at higher levels, which then need ﬁxing,\nand so on. Fixes begin to ripple throughout the code, getting\nlarger and more complicated as they go. The house of cards\nfalls down, taking the project with it.\n2You also need to ensure that you’re intending the right thing, see [SH06].\n3It could also make you wildest dreams come true, but only if you Vote\nfor Pedro.\n",
      "content_length": 1921,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 19,
      "content": "WHAT DO I WANT TO ACCOMPLISH?\n5\nPat keeps saying things like “that’s impossible” or “I don’t un-\nderstand how that could happen.” If you ﬁnd yourself think-\ning these sorts of thoughts, then that’s usually a good indica-\ntion that you don’t have enough conﬁdence in your code—you\ndon’t know for sure what’s working and what’s not.\nIn order to gain the kind of code conﬁdence that Dale has,\nyou’ll need to ask the code itself what it is doing, and check\nthat the result is what you expect it to be. Dale’s conﬁdence\ndoesn’t come from the fact he knows the code forward and\nbackward at all times; it comes from the fact that he has a\nsafety net of tests that verify things work the way he thought\nthey should.\nThat simple idea describes the heart of unit testing: the single\nmost effective technique to better coding.\n1.4\nWhat Do I Want to Accomplish?\nIt’s easy to get carried away with unit testing because the con-\nﬁdence it instills makes coding so much fun, but at the end\nof the day we still need to produce production code for cus-\ntomers and end-users, so let’s be clear about our goals for\nunit testing. First and foremost, you want to do this to make\nyour life—and the lives of your teammates—easier.\nAnd of course, executable documentation has the beneﬁt of\nbeing self-veriﬁably correct without much effort beyond writ-\ning it the ﬁrst time. Unlike written documentation, it won’t\ndrift away from the code (unless, of course, you stop running\nthe tests or let them continuously fail).\nDoes It Do What I Want?\nFundamentally, you want to answer the question: “Is the code\nfulﬁlling my intent?” The code might well be doing the wrong\nthing as far as the requirements are concerned, but that’s a\nseparate exercise. You want the code to prove to you that it’s\ndoing exactly what you think it should.\n",
      "content_length": 1803,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 20,
      "content": "WHAT DO I WANT TO ACCOMPLISH?\n6\nDoes It Do What I Want All of the Time?\nMany developers who claim they do testing only ever write one\ntest. That’s the test that goes right down the middle, taking\nthe one, well-known, “happy path” through the code where\neverything goes perfectly.\nBut of course, life is rarely that cooperative, and things don’t\nalways go perfectly:\nexceptions get thrown, disks get full,\nnetwork lines drop, buffers overﬂow, and—heaven forbid—we\nwrite bugs. That’s the “engineering” part of software develop-\nment. Civil engineers must consider the load on bridges, the\neffects of high winds, of earthquakes, ﬂoods, and so on. Elec-\ntrical engineers plan on frequency drift, voltage spikes, noise,\neven problems with parts availability.\nYou don’t test a bridge by driving a single car over it right\ndown the middle lane on a clear, calm day. That’s not sufﬁ-\ncient, and the fact you succeeded is just a coincidence.4 Be-\nyond ensuring that the code does what you want, you need\nto ensure that the code does what you want all of the time,\neven when the winds are high, the parameters are suspect,\nthe disk is full, and the network is sluggish.\nCan I Depend On It?\nCode that you can’t depend on is not particularly useful.\nWorse, code that you think you can depend on (but turns out\nto have bugs) can cost you a lot of time to track down and\ndebug. There are very few projects that can afford to waste\ntime, so you want to avoid that “one step forward two steps\nback” approach at all costs, and stick to moving forward.\nNo one writes perfect code, and that’s okay—as long as you\nknow where the problems exist. Many of the most spectacu-\nlar software failures that strand broken spacecraft on distant\nplanets or blow them up in mid-ﬂight could have been avoided\nsimply by knowing the limitations of the software.\nFor in-\nstance, the Arianne 5 rocket software re-used a library from\nan older rocket that simply couldn’t handle the larger num-\n4See Programming by Coincidence in [HT00].\n",
      "content_length": 1999,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 21,
      "content": "HOW DO I DO UNIT TESTING?\n7\nbers of the higher-ﬂying new rocket.5 It exploded 40 seconds\ninto ﬂight, taking $500 million dollars with it into oblivion.\nWe want to be able to depend on the code we write, and know\nfor certain both its strengths and its limitations.\nFor example, suppose you’ve written a routine to reverse a\nlist of numbers. As part of testing, you give it an empty list—\nand the code blows up. The requirements don’t say you have\nto accept an empty list, so maybe you simply document that\nfact in the comment block for the method and throw an ex-\nception if the routine is called with an empty list. Now you\nknow the limitations of code right away, instead of ﬁnding out\nthe hard way (often somewhere inconvenient, such as in the\nupper atmosphere).\nDoes It Document My Intent?\nOne nice side-effect of unit testing is that it helps you commu-\nnicate the code’s intended use. In effect, a unit test behaves as\nexecutable documentation, showing how you expect the code\nto behave under the various conditions you’ve considered.\nCurrent and future team members can look at the tests for\nexamples of how to use your code. If someone comes across\na test case that you haven’t considered, they’ll be alerted\nquickly to that fact.\nAnd of course, executable documentation has the beneﬁt of\nbeing correct.\nUnlike written documentation, it won’t drift\naway from the code (unless, of course, you stop running the\ntests and making sure they pass).\n1.5\nHow Do I Do Unit Testing?\nUnit testing is basically an easy practice to adopt, but there\nare some guidelines and common steps that you can follow to\nmake it easier and more effective.\n5For aviation geeks: The numeric overﬂow was due to a much larger “hor-\nizontal bias” due to a different trajectory that increased the horizontal velocity\nof the rocket.\n",
      "content_length": 1808,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 22,
      "content": "EXCUSES FOR NOT TESTING\n8\nThe ﬁrst step is to decide how to test the method in question—\nbefore writing the code itself. With at least a rough idea of\nhow to proceed, you can then write the test code itself, either\nbefore or concurrently with the implementation code. If you’re\nwriting unit tests for existing code, that’s ﬁne too, but you may\nﬁnd you need to refactor it more often than with new code in\norder to make things testable.\nNext, you run the test itself, and probably all the other tests\nin that part of the system, or even the entire system’s tests if\nthat can be done relatively quickly. It’s important that all the\ntests pass, not just the new one. This kind of basic regression\ntesting helps you avoid any collateral damage as well as any\nimmediate, local bugs.\nEvery test needs to determine whether it passed or not—it\ndoesn’t count if you or some other hapless human has to read\nthrough a pile of output and decide whether the code worked\nor not. If you can eyeball it, you can use a code assertion to\ntest it.\nYou want to get into the habit of looking at the test results\nand telling at a glance whether it all worked. We’ll talk more\nabout that when we go over the speciﬁcs of using unit testing\nframeworks.\n1.6\nExcuses For Not Testing\nDespite our rational and impassioned pleas, some developers\nwill still nod their heads and agree with the need for unit test-\ning, but will steadfastly assure us that they couldn’t possibly\ndo this sort of testing for one of a variety of reasons. Here are\nsome of the most popular excuses we’ve heard, along with our\nrebuttals.\nIt takes too much time to write the tests\nThis is the num-\nber one complaint voiced by most newcomers to unit testing.\nIt’s untrue, of course, but to see why we need to take a closer\nlook at where you spend your time when developing code.\nMany people view testing of any sort as something that hap-\npens toward the end of a project. And yes, if you wait to begin\n",
      "content_length": 1947,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 23,
      "content": "EXCUSES FOR NOT TESTING\n9\nJoe Asks. . .\nWhat’s collateral damage?\nCollateral damage is what happens when a new fea-\nture or a bug ﬁx in one part of the system causes a\nbug (damage) to another, possibly unrelated part of\nthe system. It’s an insidious problem that, if allowed to\ncontinue, can quickly render the entire system broken\nbeyond anyone’s ability to easily ﬁx.\nWe sometime call this the “Whac-a-Mole” effect. In\nthe carnival game of Whac-a-Mole, the player must\nstrike the mechanical mole heads that pop up on the\nplaying ﬁeld. But they don’t keep their heads up for\nlong; as soon as you move to strike one mole, it re-\ntreats and another mole pops up on the opposite side\nof the ﬁeld. The moles pop up and down fast enough\nthat it can be very frustrating to try to connect with\none and score. As a result, players generally ﬂail help-\nlessly at the ﬁeld as the moles continue to pop up\nwhere you least expect them.\nWidespread collateral damage to a code base can\nhave a similar effect. The root of the problem is usu-\nally some kind of inappropriate coupling, coming in\nforms such as global state via static variables or false\nsingletons, circular object or class dependencies, etc.\nEliminate them early on to avoid implicit dependen-\ncies on this abhorrent practice in other parts of the\ncode.\n",
      "content_length": 1305,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 24,
      "content": "EXCUSES FOR NOT TESTING\n10\nunit testing until then it will deﬁnitely longer than it would\notherwise. In fact, you may not ﬁnish the job until the heat\ndeath of the universe itself.\nAt least it will feel that way: it’s like trying to clear a cou-\nple of acres of land with a lawn mower. If you start early on\nwhen there’s just a ﬁeld of grasses, the job is easy. If you wait\nuntil later, when the ﬁeld contains thick, gnarled trees and\ndense, tangled undergrowth, then the job becomes impossi-\nbly difﬁcult by hand—you need bulldozers and lots of heavy\nequipment.\nInstead of waiting until the end, it’s far cheaper in the long\nrun to adopt the “pay-as-you-go” model. By writing individual\ntests with the code itself as you go along, there’s no crunch\nat the end, and you experience fewer overall bugs as you are\ngenerally always working with tested code. By taking a little\nextra time all the time, you minimize the risk of needing a\nhuge amount of time at the end.\nYou see, the trade-off is not “test now” versus “test later.” It’s\nlinear work now versus exponential work and complexity try-\ning to ﬁx and rework at the end: not only is the job larger\nand more complex, but now you have to re-learn the code you\nwrote some weeks or months ago.\nAll that extra work kills\nyour productivity, as shown in Figure 1.1 on the following\npage. These productivity losses can easily doom a project or\ndeveloper to being perpetually 90% done.\nNotice that testing isn’t free.\nIn the pay-as-you-go model,\nthe effort is not zero; it will cost you some amount of effort\n(and time and money). But look at the frightening direction\nthe right-hand curve takes over time—straight down.\nYour\nproductivity might even become negative. These productivity\nlosses can easily doom a project.\nSo if you think you don’t have time to write tests in addition to\nthe code you’re already writing, consider the following ques-\ntions:\n1. How much time do you spend debugging code that you\nor others have written?\n2. How much time do you spend reworking code that you\n",
      "content_length": 2032,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 25,
      "content": "EXCUSES FOR NOT TESTING\n11\nProductivity ¡\nProductivity ¡\nTime ¡\nTime ¡\nPAY-AS-YOU-GO\nSINGLE TEST PHASE\nFigure 1.1: Comparison of Paying-as-you-go vs. Having a Sin-\ngle Testing Phase\nthought was working, but turned out to have major, crip-\npling bugs?\n3. How much time do you spend isolating a reported bug to\nits source?\nFor most people who work without unit tests, these numbers\nadd up fast, and will continue to add up even faster over the\nlife of the project.\nProper unit testing can dramatically re-\nduces these times, which frees up enough time so that you’ll\nhave the opportunity to write all of the unit tests you want—\nand maybe even some free time to spare.\nIt takes too long to run the tests\nIt shouldn’t. Most unit\ntests should execute in the blink of an eye, so you should be\nable to run hundreds, even thousands of them in a matter\nof a few seconds. But sometimes that won’t be possible, and\nyou may end up with certain tests that simply take too long\nto conveniently run all of the time.\nIn that case, you’ll want to separate out the longer-running\ntests from the short ones. NUnit has functionality that han-\ndles this nicely, which we’ll talk about more later. Only run\nthe long tests in the automated build, or manually at the be-\nginning of the day while catching up on email, and run the\n",
      "content_length": 1307,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 26,
      "content": "EXCUSES FOR NOT TESTING\n12\nshorter tests constantly at every signiﬁcant change or before\nevery commit to your source repository.\nMy legacy code is impossible to test\nMany people offer\nthe excuse that they can’t possibly do unit testing because\nthe existing, legacy code base is such a tangled mess that it’s\nimpossible to get into the middle of it and create an individual\ntest. To test even a small part of the system might mean you\nhave to drag the entire system along for the ride, and making\nany changes is a fragile, risky business.6\nThe problem isn’t with unit testing, of course, the problem is\nwith the poorly written legacy code. You’ll have to refactor—\nincrementally re-design and adapt—the legacy code to untan-\ngle the mess. Note that this doesn’t really qualify as making\nchanges just for the sake of testing. The real power of unit\ntests is the design feedback that, when acted upon appropri-\nately, will lead to better object-oriented designs.\nCoding in a culture of fear because you are paralyzed by\nlegacy code is not productive; it’s bad for the project, bad for\nthe programmers, and ultimately bad for business. Introduc-\ning unit testing helps break that paralysis.\nIt’s not my job to test my code\nNow here’s an interesting\nexcuse. Pray tell, what is your job, exactly? Presumably your\njob, at least in part, is to create working, maintainable code.\nIf you are throwing code over the wall to some testing group\nwithout any assurance that it’s working, then you’re not do-\ning your job. It’s not polite to expect others to clean up our\nown messes, and in extreme cases submitting large volumes\nof buggy code can become a “career limiting” move.\nOn the other hand, if the testers or QA group ﬁnd it very\ndifﬁcult to ﬁnd fault with your code, your reputation will grow\nrapidly—along with your job security!\nI don’t really know how the code is supposed to behave so\nI can’t test it\nIf you truly don’t know how the code is sup-\n6See [Fea04] for details on working effectively with legacy code.\n",
      "content_length": 2010,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 27,
      "content": "EXCUSES FOR NOT TESTING\n13\nposed to behave, then maybe this isn’t the time to be writing\nit.7 Maybe a prototype would be more appropriate as a ﬁrst\nstep to help clarify the requirements.\nIf you don’t know what the code is supposed to do, then how\nwill you know that it does it?\nBut it compiles!\nOkay, no one really comes out with this as\nan excuse, at least not out loud. But it’s easy to get lulled\ninto thinking that a successful compile is somehow a mark of\napproval, that you’ve passed some threshold of goodness.\nBut the compiler’s blessing is a pretty shallow compliment. It\ncan verify that your syntax is correct, but it can’t ﬁgure out\nwhat your code should do. For example, the C# compiler can\neasily determine that this line is wrong:\nstatuc void Main() {\nIt’s just a simple typo, and should be static, not statuc.\nThat’s the easy part.\nBut now suppose you’ve written the\nfollowing:\npublic void Addit(Object anObject) {\nList myList = new List();\nmyList.Add(anObject);\nmyList.Add(anObject);\n// more code...\n}\nMain.cs\nDid you really mean to add the same object to the same list\ntwice? Maybe, maybe not. The compiler can’t tell the differ-\nence, only you know what you’ve intended the code to do.8\nI’m being paid to write code, not to write tests\nBy that\nsame logic, you’re not being paid to spend all day in the de-\nbugger, either. Presumably you are being paid to write work-\ning code, and unit tests are merely a tool toward that end, in\nthe same fashion as an editor, an IDE, or the compiler.\n7See [HT00] or [SH06] for more on learning requirements.\n8Automated testing tools that generate their own tests based on your ex-\nisting code fall into this same trap—they can only use what you wrote, not\nwhat you meant.\n",
      "content_length": 1725,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 28,
      "content": "EXCUSES FOR NOT TESTING\n14\nI feel guilty about putting testers and QA staff out of work\nNot to worry, you won’t. Remember we’re only talking about\nunit testing, here. It’s the barest-bones, lowest-level testing\nthat’s designed for us, the programmers.\nThere’s plenty of\nother work to be done in the way of functional testing, accep-\ntance testing, performance and environmental testing, valida-\ntion and veriﬁcation, formal analysis, and so on.\nMy company won’t let me run unit tests on the live sys-\ntem\nWhoa! We’re talking about developer unit-testing here.\nWhile you might be able to run those same tests in other con-\ntexts (on the live, production system, for instance) they are no\nlonger unit tests. Run your unit tests on your machine, using\nyour own database, or using a mock object (see Chapter 6).\nIf the QA department or other testing staff want to run these\ntests in a production or staging environment, you might be\nable to coordinate the technical details with them so they can,\nbut realize that they are no longer unit tests in that context.\nYeah, we unit test already\nUnit testing is one of the prac-\ntices that is typically marked by effusive and consistent en-\nthusiasm. If the team isn’t enthusiastic, maybe they aren’t\ndoing it right. See if you recognize any of the warning signs\nbelow.\n• Unit tests are in fact integration tests, requiring lots of\nsetup and test code, taking a long time to run, and ac-\ncessing resources such as databases and services on the\nnetwork.\n• Unit tests are scarce and test only one path, don’t test\nfor exceptional conditions (no disk space, etc.), or don’t\nreally express what the code is supposed to do.\n• Unit tests are not maintained:\ntests are ignored (or\ndeleted) forever if they start failing, or no new unit tests\nare added, even when bugs are encountered that illus-\ntrate holes in the coverage of the unit tests.\nIf you ﬁnd any of these symptoms, then your team is not unit\ntesting effectively or optimally. Have everyone read up on unit\n",
      "content_length": 1999,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 29,
      "content": "ROADMAP\n15\ntesting again, go to some training, or try pair programming to\nget a fresh perspective.\n1.7\nRoadmap\nChapter 2, Your First Unit Tests, contains an overview of test\nwriting. From there we’ll take a look at the speciﬁcs of Writing\nTests in NUnit in Chapter 3. We’ll then spend a few chapters\non how you come up with what things need testing, and how\nto test them.\nNext we’ll look at the important properties of good tests in\nChapter 7, followed by what you need to do to use testing\neffectively in your project in Chapter 8.\nThis chapter also\ndiscusses how to handle existing projects with legacy code.\nWe’ll then talk about how testing can inﬂuence your applica-\ntion’s design (for the better) in Chapter 9, Design Issues. We\nthen wrap up with an overview of GUI testing in 10.\nThe appendices contain additional useful information: a look\nat common unit testing problems, extending NUnit itself, a\nnote on installing NUnit, and a list of resources including the\nbibliography. We ﬁnish off with a summary card containing\nhighlights of the book’s tips and suggestions.\nSo sit back, relax, and welcome to the world of better coding.\n",
      "content_length": 1139,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 30,
      "content": "Chapter 2\nYour First Unit Tests\nAs we said in the introduction, a unit test is just a piece of\ncode. It’s a piece of code you write that happens to exercise\nanother piece of code, and determines whether the other piece\nof code is behaving as expected or not.\nHow do you do that, exactly?\nTo check if code is behaving as you expect, you use an as-\nsertion, a simple method call that veriﬁes that something is\ntrue. For instance, the method IsTrue checks that the given\nboolean condition is true, and fails the current test if it is not.\nIt might be implemented like the following.\npublic void IsTrue(bool condition)\n{\nif (!condition)\n{\nthrow new ArgumentException(\"Assertion failed\");\n}\n}\nAssertTrue.cs\nYou could use this assert to check all sorts of things, including\nwhether numbers are equal to each other:\nint a = 2;\nxx xxx xx x xxx x;\nx x x xx xxx xxxx x;\nIsTrue(a == 2);\nxxxx xx xx xxx xx;\nIf for some reason a does not equal 2 when the method IsTrue\nis called, then the program will throw an exception.\n",
      "content_length": 1009,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 31,
      "content": "PLANNING TESTS\n17\nSince we check for equality a lot, it might be easier to have an\nassert just for numbers. To check that two integers are equal,\nfor instance, we could write a method that takes two integer\nparameters:\npublic void AreEqual(int a, int b)\n{\nIsTrue(a == b);\n}\nAssertTrue.cs\nArmed with just these two asserts, we can start writing some\ntests. We’ll look at more asserts and describe the details of\nhow you use asserts in unit test code in the next chapter. But\nﬁrst, let’s consider what tests might be needed before we write\nany code at all.\n2.1\nPlanning Tests\nWe’ll start with a simple example, a single, static method de-\nsigned to ﬁnd the largest number in a list of numbers:\nstatic int Largest(int[] list);\nIn other words, given an array of numbers such as [7, 8,\n9], this method should return 9.\nThat’s a reasonable ﬁrst\ntest. What other tests can you think of, off the top of your\nhead? Take a minute and write down as many tests as you\ncan think of for this simple method before you continue read-\ning.\nSTOP\nThink about this for a moment before reading on. . .\nHow many tests did you come up with?\nIt shouldn’t matter what order the given list is in, so right off\nthe bat you’ve got the following test ideas (which we’ve written\nas “what you pass in” ¡ “what you expect”).\n• [7, 8, 9] ¡ 9\n• [8, 9, 7] ¡ 9\n• [9, 7, 8] ¡ 9\nWhat happens if there are duplicate largest numbers?\n",
      "content_length": 1394,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 32,
      "content": "TESTING A SIMPLE METHOD\n18\n• [7, 9, 8, 9] ¡ 9\nSince these are int types, not objects, you probably don’t care\nwhich 9 is returned, as long as one of them is.\nWhat if there’s only one number?\n• [1] ¡ 1\nAnd what happens with negative numbers:\n• [-9, -8, -7] ¡ -7\nIt might look odd, but indeed -7 is larger than -9. Glad we\nstraightened that out now, rather than in the debugger or in\nproduction code where it might not be so obvious.\nThis isn’t a comprehensive list by any means, but it’s good\nenough to get started with. To help make all this discussion\nmore concrete, we’ll write a “largest” method and test it using\nthese unit tests we just described. Here’s the code for our ﬁrst\nimplementation:\nLine 1\nusing System;\n-\n-\npublic class Cmp\n-\n{\n5\npublic static int Largest(int[] list)\n-\n{\n-\nint index, max=Int32.MaxValue;\n-\nfor (index = 0; index < list.Length-1; index++)\n-\n{\n10\nif (list[index] > max)\n-\n{\n-\nmax = list[index];\n-\n}\n-\n}\n15\nreturn max;\n-\n}\n-\n-\n}\nLargest.cs\nNow that we’ve got some ideas for tests, we’ll look at writing\nthese tests in C#, using the NUnit framework.\n2.2\nTesting a Simple Method\nNormally you want to make the ﬁrst test you write incredi-\nbly simple, because there is much to be tested the ﬁrst time\nbesides the code itself: all of that messy business of class\n",
      "content_length": 1288,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 33,
      "content": "TESTING A SIMPLE METHOD\n19\nnames, assembly references, and making sure it compiles.\nYou want to get all of that taken care of and out of the way with\nthe very ﬁrst, simplest test; you won’t have to worry about it\nanymore after that, and you won’t have to debug complex in-\ntegration issues at the same time you’re debugging a complex\ntest!\nFirst, let’s just test the simple case of passing in a small array\nwith a couple of unique numbers. Here’s the complete source\ncode for the test class.\nWe’ll explain all about test classes\nin the next chapter; for now, just concentrate on the assert\nstatements:\nusing System;\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\n[TestFixture]\npublic class LargestTest\n{\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\n}\n}\nLargestTest.cs\nC# note: the odd-looking syntax to create an anonymous ar-\nray is just for your authors’ beneﬁt, as we are lazy and do not\nlike to type. If you prefer, the test could be written this way\ninstead (although the previous syntax is idiomatic):\n[Test]\npublic void LargestOf3Alt()\n{\nint[] arr = new int[3];\narr[0] = 8;\narr[1] = 9;\narr[2] = 7;\nAssert.That(Cmp.Largest(arr), Is.EqualTo(9));\n}\nLargestTest.cs\nThat’s all it takes, and you have your ﬁrst test.\nWe want to run this simple test and make sure it passes; to\ndo that, we need to take a quick look at running tests using\nNUnit.\n",
      "content_length": 1408,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 34,
      "content": "RUNNING TESTS WITH NUNIT\n20\n2.3\nRunning Tests with NUnit\nNUnit is a freely available,1 open source product that pro-\nvides a testing framework and test runners. It’s available as\nC# source code that you can compile and install yourself, and\nas a ZIP ﬁle of the binaries. The binaries in the ZIP will run\non Microsoft .NET on Windows, and possibly other .NET im-\nplementations on Linux/UNIX or MacOS X. There is also an\nMSI package available, but we recommend just using the ZIP\nﬁle for the least amount of hassle.\nLinux and MacOS users may want to look at Mono, an open-\nsource implementation of the ECMA standards upon which\nC# and .NET are based. While mono ships with its own ver-\nsion of NUnit, we recommend referencing your own copy of\nNUnit, downloaded separately.\nThis will insulate you from\nchanges to the version of NUnit distributed by the mono team.\nWe discuss more of these project-oriented details in Chapter\n8.\nNext, you need to compile the code we’ve shown.\nIf you’re\nusing Visual Studio or SharpDevelop, create a new project for\nthis sample code of type Class Library. Type our “production”\ncode into a ﬁle named Largest.cs, and our new test code into\na ﬁle named LargestTest.cs. If you’d rather not type these\nprograms in from scratch, you’ll be pleased to know that all of\nthe source code for this book is available from our website.2)\nNotice that the test code uses NUnit.Framework; you’ll need\nto add a reference to nunit.framework.dll in order to com-\npile this code. In Visual Studio or SharpDevelop, expand the\nproject’s node in the Solution Explorer, bring up the con-\ntext menu on the References folder, then select “Add Refer-\nence. . . ”. Once there, browse to the nunit.framework.dll\nfrom the NUnit install directory. Press the SELECT button to\nadd the dll to the component list as shown in Figure 2.1. Press\nOK, and now your project will be able to use the functionality\nof the NUnit framework.\nGo ahead and build the project as you normally would (In\n1http://www.nunit.org\n2http://www.pragmaticprogrammer.com/titles/utc2\n",
      "content_length": 2051,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 35,
      "content": "RUNNING TESTS WITH NUNIT\n21\nJoe Asks. . .\nWhat’s the deal with Open Source?\nWhat is open source, exactly? Open source refers to\nsoftware where the source code is made freely avail-\nable. Typically this means that you can obtain the\nproduct for free, and that you are also free to modify\nit, add to it, give it to your friends, and so on.\nIs it safe to use? For the most part, open source prod-\nucts are safer to use than their commercial, closed-\nsource counterparts, because they are open to ex-\namination by thousands of other interested develop-\ners. Malicious programs, spyware, viruses, and other\nsimilar problems are rare to non-existent in the open\nsource community.\nIs it legal? Absolutely. Just as you are free to write a\nsong or a book and give it away (or sell it), you are\nfree to write code and give it away (or sell it). There\nare a variety of open source licenses that clarify the\nfreedoms involved. Before you distribute any software\nthat includes open source components, you should\ncarefully check the particular license agreements in-\nvolved.\nCan I contribute? We certainly hope so! The strength\nof open source comes from people all over the world:\nPeople just like you, who know how to program and\nhave a need for some particular feature. Would you\nlike to add a feature to NUnit?\nYou can!\nYou can\nedit the source code to the library or one of the test\nrunners and change it, and use those changes your-\nself. You can e-mail your changes to the maintainers\nof the product, and they may even incorporate your\nchanges into the next release. You can also submit\nchanges using patch tracker on sourceforge.net;\nthat way, even if your change is not included in an\nofﬁcial release, other users can take advantage of it.\n",
      "content_length": 1733,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 36,
      "content": "RUNNING TESTS WITH NUNIT\n22\nFigure 2.1: Adding NUnit Assembly Reference\nVisual Studio, CTRL-SHIFT-B works well). Using Mono, you’d\ninvoke the compiler using something such as:\ngmcs -debug -t:library -r:System -r:lib/nunit.framework.dll \\\n-out:Largest.dll Largest.cs LargestTest.cs\n(The reference to nunit.framework.dll will of course be the\nlocation where you copied the NUnit distribution.)\nNow you’ve got an assembly. But it’s just a library. How can\nwe run it?\nTest Runners to the rescue! A test runner knows to look for\nthe [TestFixture] attribute of a class, and for the [Test]\nmethods within it. The runner will run the tests, accumulate\nsome statistics on which tests passed and failed, and report\nthe results back to you. In this book, we focus on test runners\nthat are easily accessible and freely available.\nThere are four main ways to use a test runner:\n1. NUnit GUI (all platforms)\n2. NUnit command line (all platforms)\n",
      "content_length": 932,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 37,
      "content": "RUNNING TESTS WITH NUNIT\n23\nFigure 2.2: NUnit Loaded and Ready\n3. TestDriven.NET (Windows-only)\n4. SharpDevelop 2.1 runner (Windows-only)\n5. MonoDevelop 0.13 runner (all platforms)\nNUnit GUI\nThe NUnit GUI can be started a number of ways: if you un-\nzipped the binaries on Windows, you can just point Windows\nExplorer at the directory and double-click on nunit.exe. If\nyou unzipped the binaries on MacOS or Linux, you can run\nNUnit GUI via the mono runtime executable (using mono -\ndebug nunit.exe). If you used the Windows installer, you\ncan use the shortcuts on your Windows desktop and in the\nPrograms menu of the Start Menu to start the NUnit GUI.\nWhen the GUI comes up, you’ve got a couple of choices. You\ncan create a new NUnit project as shown in Figure ?? on\npage ??; navigate to your source directory and create the\nNUnit project ﬁle.\nThen under the “Project” menu, add as-\nsemblies or Visual Studio projects to your NUnit project.3\n3Visual Studio support can be enabled using a preference located under\nTools/Options.\n",
      "content_length": 1027,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 38,
      "content": "RUNNING TESTS WITH NUNIT\n24\nAlternatively, you can just Open an assembly (a .dll or .exe\nﬁle) directly. In Figure 2.2 on the preceding page, we’ve loaded\nour tests directly from the dll. It’s ready to be tested by press-\ning the “Run” button.\nWhen you run a selected test, the GUI will display a large,\ncolored, status bar. If all the tests pass, the bar is a happy\nshade of bright green. If any test fails, the bar becomes an\nangry red. If the bar is a cautionary yellow, that means some\ntests were skipped (more on that later).\nNUnit Command Line\nNUnit can also be run from the command line, which comes in\nvery handy when automating the project build and test. You’ll\nneed to add the NUnit bin directory to your path (that is, the\ndirectory path to wherever you installed the NUnit application,\nplus “\\bin”).\nFor the current shell, you can set your path variable at the\ncommand line, as in the following example on Windows.\nC:\\> set \"PATH=%PATH%;C:\\Program Files\\Nunit V2.4\\bin\"\nFor more permanent use, go to Control Panel/System/Advan-\nced/Environment Variable and add NUnit’s bin directory to\nthe Path variable (see Figure 2.3 on the next page).\nTo run from the command line, type the command nunit-\nconsole followed by an NUnit project ﬁle or an assembly lo-\ncation. You’ll see output something like that shown in Fig-\nure 2.4 on page 26.\nTestDriven.NET (Visual Studio add-in)\nThere are several add-ins that integrate NUnit with Visual\nStudio. The TestDriven.NET4 add-in adds the ability to run\nor debug any test just by right-clicking on the source code and\nselecting “Run Test(s)”; the output from the tests are reported\nin Visual Studio’s output pane, just like compiler warnings or\n4Such as http://www.testdriven.net/\n",
      "content_length": 1728,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 39,
      "content": "RUNNING TESTS WITH NUNIT\n25\nFigure 2.3: Adding to the Windows System Path\nerrors. You can use this output to quickly browse to failed as-\nsertion locations, which is quite handy. Other similar projects\nadd visual reporting of tests and other features.\nSharpDevelop\nSharpDevelop 2.1 (and above), an open-source IDE writ-\nten in C#, includes an Eclipse-style integrated test runner.\nFailed tests come up like compiler errors, allowing for double-\nclicking on an item and going to the assertion that failed. It\nalso allows for measuring the code coverage of unit tests (us-\ning NCover5) with source code highlighting that can be en-\n5http://NCover.org\n",
      "content_length": 649,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 40,
      "content": "RUNNING TESTS WITH NUNIT\n26\nFigure 2.4: NUnit Command Line Usage\nFigure 2.5: SharpDevelop’s Integrated Unit Testing\n",
      "content_length": 116,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 41,
      "content": "RUNNING THE EXAMPLE\n27\nabled and disabled.\nA sample screenshot is shown in Fig-\nure 2.5 on the previous page. See SharpDevelop’s web page\nfor more details (http://sharpdevelop.net).\nMonoDevelop\nMonoDevelop 0.13 and above, which is based on SharpDe-\nvelop 0.9, also includes an integrated test runner. While not\nas advanced as SharpDevelop itself, it’s a welcome improve-\nment over a ﬂat text editor on platforms where other tools\ndon’t run. For more information, see MonoDevelop’s web page\n(http://monodevelop.com).\n2.4\nRunning the Example\nYou should be ready to run this ﬁrst test now.\nSTOP\nTry running this example before reading on. . .\nHaving just run that code, you probably saw an error similar\nto the following:\nFailures:\n1) LargestTest.LargestOf3 :\nexpected:<9>\nbut was:<2147483647>\nat LargestTest.LargestOf3() in c:\\largesttests.cs:line 13\nWhoops! That didn’t go as expected. Why did it return such\na huge number instead of our 9? Where could that very large\nnumber have come from? It almost looks like the largest num-\nber. . .\noh, it’s a small typo: max=Int32.MaxValue on line 7\nshould have been max=0.\nWe want to initialize max so that\nany other number instantly becomes the next max. Let’s ﬁx\nthe code, recompile, and run the test again to make sure that\nit works.\nNext we’ll look at what happens when the largest number ap-\npears in different places in the list—ﬁrst or last, and some-\nwhere in the middle. Bugs most often show up at the “edges.”\nIn this case, edges occur when the largest number is at the\nstart or end of the array that we pass in. We can lump all\n",
      "content_length": 1580,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 42,
      "content": "RUNNING THE EXAMPLE\n28\nthree of these asserts together in one test, but let’s add the\nassert statements one at a time. Notice that just as in pro-\nduction (non-test) code, you have to exercise care, taste, and\nrestraint when deciding how much code to add to one method,\nand when to break that up into multiple methods. Since this\nmethod is testing variations on a single theme (physical place-\nment of the largest value), let’s put them together in a single\nmethod.\nWe already have the case with the largest in the middle:\nusing System;\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\n[TestFixture]\npublic class LargestTest\n{\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\n}\n}\nLargestTest.cs\nNow try it with the 9 as the ﬁrst value (we’ll just add an addi-\ntional assertion to the existing LargestOf3() method):\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {9,8,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\n}\nLargestTest.cs\nWe’re on a roll. One more, just for the sake of completeness,\nand we can move on to more interesting tests:\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {9,8,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {7,8,9}), Is.EqualTo(9));\n}\nLargestTest.cs\nSTOP\nTry running this example before reading on. . .\nFailures:\n1) LargestTest.LargestOf3 :\n",
      "content_length": 1472,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 43,
      "content": "RUNNING THE EXAMPLE\n29\nexpected:<9>\nbut was:<8>\nat LargestTest.LargestOf3() in c:\\LargestTest.cs:line 14\nWhy did the test get an 8 as the largest number? It’s almost\nas if the code ignored the last entry in the list. Sure enough,\nanother simple typo: the for loop is terminating too early.\nThis is an example of the infamous “off-by-one” error. Our\ncode has:\nfor (index = 0; index < list.Length-1; index++) {\nBut it should be one of:\nfor (index = 0; index <= list.Length-1; index++) {\nfor (index = 0; index < list.Length; index++) {\nThe second expression is idiomatic in languages descended\nfrom C (including Java and C#), but as you can see, it’s\nprone to off-by-one errors.\nMake the changes and run the\ntests again, but consider that this sort of bug is telling you\nsomething: it would be better to use an iterator (using the C#\nforeach statement) here instead. That way you could avoid\nthis kind of off-by-one error in the future.\nLet’s check for duplicate largest values; type this in and run\nit (we’ll only show the newly added methods from here on):\n[Test]\npublic void Dups() {\nAssert.That(Cmp.Largest(new int[] {9,7,9,8}), Is.EqualTo(9));\n}\nLargestTest.cs\nSo far, so good. Now the test for just a single integer:\n[Test]\npublic void One() {\nAssert.That(Cmp.Largest(new int[] {1}), Is.EqualTo(1));\n}\nLargestTest.cs\nHey, it worked! You’re on a roll now, surely all the bugs we\nplanted in this example have been exorcised by now. Just one\nmore check with negative values:\n[Test]\npublic void Negative() {\nint[] negatives = new int[] {-9, -8, -7};\nAssert.That(Cmp.Largest(negatives), Is.EqualTo(-7));\n}\nLargestTest.cs\n",
      "content_length": 1619,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 44,
      "content": "RUNNING THE EXAMPLE\n30\nSTOP\nTry running this example before reading on. . .\nFailures:\n1) LargestTest.Negative :\nexpected:<-7>\nbut was:<0>\nat LargestTest.Negative() in c:\\LargestTest.cs:line 4\nWhoops! Where did zero come from?\nLooks like choosing 0 to initialize max was a bad idea; what we\nreally wanted was MinValue, so as to be less than all negative\nnumbers as well:\nmax = Int32.MinValue\nMake that change and try it again—all of the existing tests\nshould continue to pass, and now this one will as well.\nUnfortunately, the initial speciﬁcation for the method “largest”\nis incomplete, as it doesn’t say what should happen if the\narray is empty. Let’s say that it’s an error, and add some code\nat the top of the method that will throw a runtime-exception\nif the list length is zero:\npublic static int Largest(int[] list) {\nint index, max=Int32.MinValue;\nif (list.Length == 0) {\nthrow new ArgumentException(\"largest: Empty list\");\n}\n// ...\nLargest.cs\nNotice that just by thinking of the tests, we’ve already realized\nwe need a design change. That’s not at all unusual, and in\nfact is something we want to capitalize on. So for the last test,\nwe need to check that an exception is thrown when passing in\nan empty array. We’ll talk about testing exceptions in depth\non page 54, but for now just trust us:\n[Test]\n[ExpectedException(typeof(ArgumentException))]\npublic void Empty()\n{\nCmp.Largest(new int[] {});\n}\nLargestTest.cs\n",
      "content_length": 1423,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 45,
      "content": "MORE TESTS\n31\nFinally, a reminder: all code—test or production—should be\nclear and simple. Test code especially must be easy to under-\nstand, even at the expense of performance or verbosity.\n2.5\nMore Tests\nWe started with a very simple method and came up with a\ncouple of interesting tests that actually found some bugs.\nNote that we didn’t go overboard and blindly try every pos-\nsible number combination; we picked the interesting cases\nthat might expose problems. But are these all the tests you\ncan think of for this method?\nWhat other tests might be appropriate?\nSince we’ll need to think up tests all of the time, maybe we\nneed a way to think about code that will help us to come up\nwith good tests regularly and reliably. We’ll talk about that\nafter the next chapter, but ﬁrst, let’s take a more in-depth\nlook at using NUnit.\n",
      "content_length": 833,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 46,
      "content": "Chapter 3\nWriting Tests in NUnit\nWe’ve looked at writing tests somewhat informally in the last\nchapter, but now it’s time to take a deeper look at the differ-\nence between test code and production code, all the various\nforms of NUnit’s assertions, the structure and composition of\nNUnit tests, and so on.\n3.1\nStructuring Unit Tests\nSuppose we have a method named CreateAccount;\nthe\nmethod encapsulates behaviour, and it’s behaviour that we\nwant to test. Your ﬁrst test method might be named some-\nthing like CreateSimpleAccount.\nThe method Create-\nSimpleAccount will call CreateAccount with the necessary\nparameters and verify that CreateAccount works as adver-\ntised. You can, of course, have many test methods that ex-\nercise CreateAccount (not all accounts are simple, after all).\nTests should be organized around behaviours, not necessarily\nindividual methods.\nThe relationship between these two pieces of code is shown in\nFigure 3.1 on the next page.\nThe test code is for our internal use only; customers or end-\nusers will generally never see it or use it.\nThe production\ncode—that is, the code that will eventually be shipped to a\ncustomer and put into production—must not know anything\nabout the test code. Production code will be thrust out into\n",
      "content_length": 1255,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 47,
      "content": "STRUCTURING UNIT TESTS\n33\nCreateSimpleAccount()\nCreateDefaultAccount()\nCreateDupAccount()\nAccountTest.cs\n(Internal Only)\nCreateAccount()\nAccount.cs\n(Delivered)\nFigure 3.1: Test Code and Production Code\nthe cold world all alone, without the test code. This typically\nmeans that test code is placed under a different project, in its\nown assembly.\nTest code follows a standard formula:\n• Set up all conditions needed for testing (create any re-\nquired objects, allocate any needed resources, etc.)\n• Call the method to be tested\n• Verify that the tested functionality worked as expected\n• Clean up after itself1\nYou write test code and compile it in the normal fashion, as\nyou would any other bit of source code in your project.\nIt\nmight happen to use some additional libraries, but otherwise\nthere’s no magic—it’s just code.\nWhen it’s time to execute the code, remember that you never\nactually run the production code directly; at least, not the way\na user would. Instead, you run the test code, which in turn\nexercises the production code under very carefully controlled\nconditions.\nNow, although we could write all our tests from the ground\nup, that’s not terribly efﬁcient. For the rest of this book we’ll\nassume that you’re using the NUnit framework. More specif-\nically, we’ll be showing the speciﬁc method calls and classes\nfor NUnit 2.4, using C#, in our examples. Earlier or later ver-\n1This doesn’t mean nulling out ﬁelds or using GC.Collect(). If you ﬁnd\nyourself doing either, you may have a race condition due to a misbehaving\nFinalizer. These issues are almost never limited to test code.\n",
      "content_length": 1600,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 48,
      "content": "CLASSIC ASSERTS\n34\nsions may have slight differences from the details presented\nhere, but the general concepts are the same across all ver-\nsions, and indeed for any testing framework in any language\nor environment.\n3.2\nClassic Asserts\nAs we’ve seen, there are some helper methods that assist us\nin determining whether a method under test is performing\ncorrectly or not. Generically, we call all these helper meth-\nods assertions. They let us assert that some condition is true;\nthat two bits of data are equal, or not, and so on. NUnit 2.4\nintroduced a new constraint-style of assertions while still sup-\nporting the classic-style of assertions that more closely match\nother XUnit frameworks. We’ll start off by covering some basic\nclassic-style assertions before diving into the constraint-style\nassertions.\nAll of the following methods will report failures (that’s when\nthe assertion is false) or errors (that’s when we get an un-\nexpected exception), and report these through the NUnit test\nrunner. For the text version of the test runner, that means the\ndetails of the failure will be printed to the console. The GUI\nversions of the test runner will show a red bar and support-\ning details to indicate a failure. You can also output the test\nresults to an XML ﬁle.\nWhen a failure or error occurs, execution of the current test\nmethod is aborted. Other tests within the same test ﬁxture\nwill still be run.\nAsserts are the fundamental building block for unit tests; the\nNUnit library provides a number of different forms of assert\nas static methods in the Assert class.\nAreEqual\nAssert.AreEqual(expected, actual [, string message])\nThis is the most-often used form of assert. expected is a value\nyou hope to see (typically hard-coded), and actual is a value\nactually produced by the code under test. message is an op-\ntional message that will be reported in the event of a failure.\n",
      "content_length": 1885,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 49,
      "content": "CLASSIC ASSERTS\n35\nYou can omit the message argument and simply provide the\nexpected and actual values. We recommend omitting the mes-\nsage string for reporting unless you really need to; better that\nthe name of the test method itself expresses your intent, you\nuse the appropriate Assert method, or you split the test into\ntwo methods to keep it focused. We’ll show examples of all of\nthese practices in a bit.\nAny kind of object may be tested for equality; the appropri-\nate equals method will be used for the comparison.2 In par-\nticular, you can compare the contents of strings using this\nmethod. Different method signatures are also provided for all\nthe native types (int, decimal, etc.) and Object. Strings and\nCollections also have their own classic-style asserter classes\nwith extra methods, StringAssert and CollectionAssert,\nwhich we’ll get into a bit later.\nComputers cannot represent all ﬂoating-point numbers ex-\nactly, and will usually be off a little bit. Because of this, if you\nare using an assert to compare ﬂoating point numbers (ﬂoats\nor doubles in C#), you need to specify one additional piece of\ninformation, the tolerance.\nThis speciﬁes just how close to\n“equals” you need the result to be.\nAssert.AreEqual(expected,\nactual,\ntolerance [, string message])\nFor business applications, 4 or 5 decimal places is probably\nenough. For scientiﬁc apps, you may need greater precision.\nAs an example, the following assert will check that the actual\nresult is equal to 3.33, but only look at the ﬁrst two decimal\nplaces:\nAssert.AreEqual(3.33, 10.0/3.0, 0.01);\nLess / Greater\nAssert.Less(x, y)\nAssert.Greater(x,y)\n2Remember that the default Equals() inherited from System.Object\nonly checks to see if the object references themselves are the same—it checks\nfor identity, rather than equality. For value types (structs, enums, etc.) the\nﬁelds are veriﬁed to be equal [Ric06].\n",
      "content_length": 1886,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 50,
      "content": "CLASSIC ASSERTS\n36\nAsserts that x < y (or x > y) for numeric types, or any type\nthat is IComparable.\nGreaterOrEqual / LessOrEqual\nAssert.GreaterOrEqual(x, y)\nAssert.LessOrEqual(x,y)\nAsserts that x >= y (or x <= y) for numeric types, or any type\nthat is IComparable.\nIsNull / IsNotNull\nAssert.IsNull(object [, string message])\nAssert.IsNotNull(object [, string message])\nAsserts that the given object is null (or not null), failing oth-\nerwise. The message is optional.\nAreSame\nAssert.AreSame(expected, actual [, string message])\nAsserts that expected and actual refer to the same object, and\nfails the test if they do not. The message is optional.\nIsTrue\nAssert.IsTrue(bool condition [, string message])\nAsserts that the given boolean condition is true, otherwise the\ntest fails. The message is optional.\nIf you ﬁnd test code that is littered with the following:\nAssert.IsTrue(true);\nthen you should be concerned.\nUnless that construct is\nused to verify some sort of branching or exception logic, it’s\nprobably a bad idea.\nIn particular, what you really don’t\nwant to see is a whole page of “test” code with a single As-\nsert.IsTrue(true) at the very end (i.e., “the code made it\nto the very end without blowing up therefore it must work”).\nThat’s not testing, that’s wishful thinking.\nIn addition to testing for true, you can also test for false:\n",
      "content_length": 1348,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 51,
      "content": "CONSTRAINT-BASED ASSERTS\n37\nAssert.IsFalse(bool condition [, string message])\nAsserts that the given boolean condition is false, otherwise the\ntest fails. The message is optional.\nNeither IsTrue nor IsFalse give you any additional in-\nformation\nwhen\nthe\ntest\nfails;\nthis\nmeans\nyou\nmight\nhave to use the debugger or Console.WriteLine() state-\nments\nto\ndiagnose\na\nunit\ntest\nfailure.\nThat’s\nnot\nvery efﬁcient.\nThere might be\na better assertion you\ncould use, such as StringAssert.Contains() or Collec-\ntionAssert.DoesNotContain()—we’ll take a look at these\nmore interesting assertions in just a moment. A more precise\nassertion like those will give you more precise information on\nfailure so you can concentrate on ﬁxing the code rather than\ntrying to ﬁgure out what went wrong.\nFail\nAssert.Fail([string message])\nFails the test immediately, with the optional message. This\nmight be used to mark sections of code that should not be\nreached, but isn’t really used much in practice.\n3.3\nConstraint-based Asserts\nNUnit 2.4 introduced a new style of assertions that are a little\nless procedural and allow for a more object-oriented underly-\ning implementation. NUnit has a history of innovating on the\nclassic XUnit design, which other frameworks then incorpo-\nrate later. In this case the NUnit team decided to mimic an-\nother innovative framework called NMock2,3 which we’ll dis-\ncuss later in Chapter 6.\nThis new assertion style can seem a little odd at ﬁrst, but we\nsuggest giving it a chance before falling back on the “classic”\nassertion methods.\nAfter all, the classic assertion methods\njust delegate to the constraint-style assertion methods behind\nthe covers. Let’s look at a couple of assertions as they would\nbe written in the new style.\n3NMock2, in turn, was mimicking jMock.\n",
      "content_length": 1781,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 52,
      "content": "CONSTRAINT-BASED ASSERTS\n38\nJoe Asks. . .\nWhat was wrong with the old syntax?\nWell, nothing was particularly wrong with the classic\nsyntax, per se. In fact, there are no plans to remove or\ndeprecate the classic syntax. The classic-style assert\nmethods delegate to the new methods, so there’s no\nduplication. Here’s a quick history lesson that may il-\nluminate the progression.a In the beginning, test ﬁx-\nture classes had to derive from a class called Test-\nCase. Deriving from TestCase both told the test run-\nner which classes contained test methods and pro-\nvided assertion methods, amongst other things.\nIn those days, we would call assertEquals() and\nother assertions, which were inherited from Test-\nCase, from our test methods. The TestCase class was\nalso reponsible for providing a virtual setUp() and\ntearDown() method.\nClearly, the TestCase class\nwas a bit overloaded as far as its reponsibilities.\nFirst, NUnit used attributes to mark test ﬁxture classes,\nas previously discussed.\nThen, NUnit extracted the\ngrowing list of assertion methods into the family of As-\nsert classes. This effectively eliminated the TestCase\nclass altogether. Several other XUnit frameworks have\npicked up these ideas in their recent versions.\nThis\nbrings us up to NUnit 2.2.\nWhile developing NUnit 2.4, the NUnit team realised\nthat the Assert classes had a few too many repon-\nsibilities.\nThe Assert classes had to make sure the\nactual value matched the expected value, whatever\nthat meant for the given assertion method. On top of\nthis, the Assert class needed to format the text to be\noutput by the test runner when the assertion failed.\nThese responsibilities were broken up, with the Con-\nstraint objects (returned by syntax helpers such as\nIs.EqualTo()) bearing the responsibility of making\nsure the actual value met the context-speciﬁc con-\nstraint of the expected value. Because they are en-\ncapsulated in separate objects, multiple constraints\ncan be combined and applied to a single value.\nThat leaves the text formatting when an assertion fails,\nwhich falls to the TextMessageWriter object that\nNUnit uses internally.\nsoon\nGive the constraint style assertions a spin you\n",
      "content_length": 2170,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 53,
      "content": "CONSTRAINT-BASED ASSERTS\n39\nIs.EqualTo\nAssert.That(actual, Is.EqualTo(expected))\nThis\nis\nequivalant\nto\nthe\nAssert.AreEqual()\nclassic\nassertion\nmethod\nwe\ndiscussed\nin\nthe\nlast\nsection.\nThe\nIs.EqualTo()\nmethod\nis\na\nsyntax\nhelper\nin\nthe\nNUnit.Framework.SyntaxHelpers namespace. It’s a static\nmethod that just returns an EqualConstraint object. The\nfollowing code is equivalant, but may not read as smoothly to\nsome folks.\nAssert.That(actual, new EqualConstraint(expected))\nTo specify a tolerance for ﬂoating point numbers like we did\npreviously, we can use a neat feature of the new syntax called\nconstraint modiﬁers. There are several that we’ll look at, but\nhere is one called Within() that is equivalant to our same\nexample that used the classic-style in the previous section.\nAssert.That(10.0/3.0, Is.EqualTo(3.33).Within(0.01f));\nIs.Not.EqualTo\nAssert.That(actual, Is.Not.EqualTo(expected))\nThis is an example of one of the fun things that the\nconstraint-based syntax allows for and is equivalant to the\nAssert.AreNotEqual() classic assertion that was discussed\npreviously.\nThe usage of Not in this context isn’t exactly a\nseparate method, as in the other examples. By applying Not,\nit wraps the EqualConstraint in a NotConstraint object.\nThe following code is equivalant.\nAssert.That(actual, new NotConstraint(new EqualConstraint(expected)));\nWe can apply Not to any Is or Has syntax helper. As such, you\ncould also wrap the NotConstraint object around any other\nConstraint object. Given the verbosity that entails, though,\nwe’re probably better off using the syntax helper approach.\nIs.AtMost\nAssert.That(actual, Is.AtMost(expected))\nThis\nconstraint-style\nassert\nis\nequivalant\nto\nthe\nAssert.LessOrEqual()\nclassic\nassertion\nmethod.\n",
      "content_length": 1735,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 54,
      "content": "CONSTRAINT-BASED ASSERTS\n40\nIs.AtMost() is just an alias for Is.LessThenOrEqualTo(),\nwhich returns a LessThanOrEqualConstraint object.\nIs.Null\nAssert.That(expected, Is.Null);\nAsserts that expected is null, and fails the test if it is not. To\nassert the opposite, we have two choices of constraint-style\nsyntax.\nAssert.That(expected, Is.Not.Null);\nAssert.That(expected, !Is.Null);\nEither of these ways will wrap the constraint in a NotCon-\ntraint object under the covers. Either style can be applied\nto any of the constraints. Neat, huh?\nIs.Empty\nAssert.That(expected, Is.Empty);\nAsserts that expected is an empty collection or string, and\nfails the test if it is not.\nIs.AtLeast\nAssert.That(actual, Is.AtLeast(expected));\nThis is equivalant to Is.GreaterThanOrEqualTo(), which\nasserts that actual >= expected (or expected <= actual) for\nnumeric types, or any type that is IComparable.\nIs.InstanceOfType\nAssert.That(actual, Is.InstanceOfType(expected));\nAsserts that actual is of type expected, or a derivation of that\ntype.\nHas.Length\nAssert.That(actual, Has.Length(expected));\n",
      "content_length": 1078,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 55,
      "content": "NUNIT FRAMEWORK\n41\nAsserts that actual has a Length property that returns the\nexpected value. Note that it can be any object with a property\nnamed “Length”, not just a string or Collection. We could\nalso just assert the length using Is.EqualTo(), but this may\nbe easier to read for some.\nIn the rest of the examples, we’ll be using this new constraint-\nstyle of assertions. If you’re more comfortable with the classic-\nstyle, feel free to substitute those into the appropriate places\ninstead.\nUsing Asserts\nWe usually have multiple asserts in a given test method, as\nwe prove various aspects and relationships of the method(s)\nunder test.\nWhen an assert fails, that test method will be\naborted—the remaining assertions in that method will not be\nexecuted this time. But that shouldn’t be of any concern; we\nhave to ﬁx the failing test before we can proceed anyway. And\nwe ﬁx the next failing test. And the next. And so on.\nYou should normally expect that all tests pass all of the time.\nIn practice, that means that when we introduce a bug, only\none or two tests fail. Isolating the problem is usually pretty\neasy in that environment.\nUnder no circumstances should we continue to add features\nwhen there are failing tests! Fix any test as soon as it fails,\nand keep all tests passing all of the time.\nTo maintain that discipline, we’ll need an easy way to run all\nthe tests—or to run groups of tests, particular subsystems,\nand so on.\n3.4\nNUnit Framework\nSo far, we’ve just looked at the assert methods themselves.\nBut you can’t just stick assert methods into a source ﬁle and\nexpect it to work; you need a little bit more of a framework\nthan that. Fortunately, it’s not too much more.\nHere is a very simple piece of test code that illustrates the\nminimum framework we need to get started.\n",
      "content_length": 1790,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 56,
      "content": "NUNIT FRAMEWORK\n42\nLine 1\nusing System;\n-\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\n5\n[TestFixture]\n-\npublic class LargestTest\n-\n{\n-\n[Test]\n-\npublic void LargestOf3Alt()\n10\n{\n-\nint[] arr = new int[3];\n-\narr[0] = 8;\n-\narr[1] = 9;\n-\narr[2] = 7;\n15\nAssert.That(Cmp.Largest(arr), Is.EqualTo(9));\n-\n}\n-\n}\nLargestTest.cs\nThis code is pretty straightforward, but let’s take a look at\neach part in turn.\nFirst, the using statement on line ?? brings in the neces-\nsary NUnit classes. Remember we’ll need to tell the compiler\nyou’re referencing nunit.framework.dll, otherwise the us-\ning statement won’t be able to ﬁnd the NUnit.Framework\nnamespace.\nNext, we have the class deﬁnition itself on line ??: each class\nthat contains tests must be annotated with a [TestFixture]\nattribute as shown. The class must be declared public (so\nthat the test runners will run it; by default, classes are in-\nternal), and it must have a public, no-parameter, construc-\ntor (the default implicit constructor is all we need—adding a\nconstructor to a TestFixture is generally not necessary).\nFinally, the test class contains individual methods annotated\nwith [Test] attributes.\nIn the example, we’ve got one test\nmethod named LargestOf3 on line ??. Any public, param-\neterless method speciﬁed with a [Test] attribute will be run\nautomatically by NUnit.\nWe can include helper methods to\nsupport clean code in our tests as well, we just don’t mark\nthem as tests.\nIn the previous example, we showed a single test, using a\nsingle assert, in a single test method. Of course, inside a test\nmethod, you can place any number of asserts:\nusing System;\n",
      "content_length": 1637,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 57,
      "content": "NUNIT TEST SELECTION\n43\nJoe Asks. . .\nWhat’s a Fixture?\nFrom the c2.com wiki:a\nIn electronics testing, a ﬁxture is an environment in\nwhich you can test a component. Once the circuit\nboard or component is mounted in the text ﬁxture, it is\nprovided with the power and whatever else is needed\nto drive the behaviour to be tested.\nA ﬁxture in the context of unit testing is more about\nthe scenario we’re testing than the actual class we’re\ntesting. Testing a single class across multiple ﬁxtures is\nvery common.\nahttp://c2.com/cgi/wiki?TestFixture\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\n[TestFixture]\npublic class LargestTest\n{\n[Test]\npublic void LargestOf3()\n{\nAssert.That(Cmp.Largest(new int[] {9,8,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {8,9,7}), Is.EqualTo(9));\nAssert.That(Cmp.Largest(new int[] {7,8,9}), Is.EqualTo(9));\n}\nLargestTest.cs\nHere we have three calls to Assert.That inside a single test\nmethod.\n3.5\nNUnit Test Selection\nAs we’ve seen so far, a ﬁxture (that is, a class marked with\nthe [TestFixture] attribute) contains test methods; each\nmethod contains one or more assertions.\nMultiple test ﬁx-\ntures can be included into a source code ﬁle or a compiled\nassembly.\nYou will normally run all of the tests within an assembly just\n",
      "content_length": 1278,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 58,
      "content": "NUNIT TEST SELECTION\n44\nOrganizing ﬁxtures\nFollowing good object-oriented design, a class should\nbe focused on one responsibility. This applies to test\nﬁxtures as well—they’re just classes, after all. As such,\nput tests into a ﬁxture that describes the speciﬁc sce-\nnario they are being tested in.\nIf there aren’t multiple scenarios, then just name the\nﬁxture class after the class being tested. You can al-\nways extract more focused ﬁxtures from a general ﬁx-\nture once the general ﬁxture starts getting too fat.\nHaving a ﬁxture class focused on a speciﬁc sce-\nnario, with a name that documents that scenario,\nhelps avoid duplicating the scenario description in\nthe name of several test methods.\nTo keep things readable in the test runner output, put\nthe ﬁxture classes under a namespace that includes\nthe name of the class that the ﬁxtures are testing, like\nso:\nnamespace ZeroBay.Test.ShoppingCartTest\n{\n[TestFixture]\npublic class NoDataFixture\n{\n[Test]\npublic void OverallRateIsZero() {...}\n}\n}\nby specifying the assembly to the test runner. You can also\nchoose to run individual test ﬁxtures within an assembly us-\ning either the NUnit command line or GUI.\nFrom the GUI, you can select an individual test, a single test\nﬁxture, or the entire assembly by selecting it and clicking the\nrun button, and all the appropriate tests will be run.\nFrom the command line, you can specify the assembly and a\nparticular test ﬁxture as follows:\nc:\\> nunit-console\nassemblyname.dll\n/fixture:ClassName\nGiven this ﬂexibility, you may want to think a bit about how to\n",
      "content_length": 1555,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 59,
      "content": "NUNIT TEST SELECTION\n45\norganize test methods into individual assemblies and ﬁxtures\nto make testing easier.\nFor instance, you may want to run all the database-related\ntests at once, or all of the tests that Fred wrote (Fred is still\non probation from the last project, and you want to keep an\neye on him).\nFortunately, NUnit has a mechanism you can use to catego-\nrize and classify individual test methods and ﬁxtures.\nCategories\nNUnit provides an easy way to mark and run individual tests\nand ﬁxtures by using categories. A category is just a name\nthat you deﬁne. You can associate different test methods with\none or more categories, and then select which categories you\nwant to exclude (or include) when running the tests.\nSuppose among your tests you’ve got a method to ﬁnd the\nshortest route that our traveling salesman, Bob, can take to\nvisit the top n cities in his territory. The funny thing about\nthe Traveling Salesman algorithm is that for a small number\nof cities it works just ﬁne, but it’s an exponential algorithm.\nThat means that a few hundred cities might take 20,000 years\nto run, for example. Even 50 cities takes a few hours, so you\nprobably don’t want to to include that test by default.\nYou can use NUnit categories to help sort out your usual tests\nthat you can run constantly versus long-running tests that\nyou’d rather only run during the automated build. Categories\nare generally used for exclusion rather than inclusion.\nA category is speciﬁed as an attribute. You provide a string\nto identify the category when you declare the method. Then\nwhen you run the tests, you can specify which categories you\nwant to run (you can specify more than one).\nFor instance, suppose you’ve got a few methods that only take\na few seconds to run, but one method that takes a long time to\nrun. You can annotate them using the category names “Short”\nand “Long” (you might also consider making a category “Fred”\nif you still want to keep an eye on him.)\nLine 1\nusing NUnit.Framework;\n",
      "content_length": 1992,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 60,
      "content": "NUNIT TEST SELECTION\n46\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\n-\n[TestFixture]\n5\npublic class ShortestPathTest\n-\n{\n-\nTSP tsp;\n-\n-\n[SetUp]\n10\npublic void SetUp()\n-\n{\n-\ntsp = new TSP();\n-\n}\n-\n15\n[Test]\n-\n[Category(\"Short\")]\n-\npublic void Use5Cities()\n-\n{\n-\nAssert.That(tsp.ShortestPath(5), Is.AtMost(140));\n20\n}\n-\n-\n// This one takes a while...\n-\n[Test]\n-\n[Category(\"Long\")]\n25\n[Category(\"Fred\")]\n-\npublic void Use50Cities()\n-\n{\n-\nAssert.That(tsp.ShortestPath(50), Is.AtMost(2300));\n-\n}\n30\n}\nShortestPathTest.cs\nNotice that you can specify multiple attributes (in this case,\nTest and Category) on two separate lines as shown around\nline 26, or combined into one line.\nNow if you choose to run just “Short” methods, the two meth-\nods Use2Cities and Use10Cities will be selected to run.\nIf you choose “Long” methods, only Use50Cities will be se-\nlected. You can also select both categories to run all three of\nthese methods.\nIn the GUI, you select which categories of tests to include and\nwhich to exclude on the tab as shown in Figure 3.2 on the\nfollowing page.\nJust select each category you’re interested\nand press the ADD button.\nOn a real project, of course, you wouldn’t bother to mark a\nbunch of tests as “short.” They should all be short, except for\nthe ones speciﬁcally marked as “Long.”\nFrom the command line, you can specify individual categories\nto include as well. Just add the following parameter to the\n",
      "content_length": 1415,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 61,
      "content": "NUNIT TEST SELECTION\n47\nFigure 3.2: NUnit Category Selection\ncommand line:\n/include=category1;category2;...\nNote that multiple category names are separated by a semi-\ncolon (“;”).\nYou can also choose to exclude the listed categories so all\nother tests except those in the named categories run. There’s\na check box in the GUI for this; the command line option is,\noddly enough, /exclude.\nBut this isn’t quite enough: it turns out that some categories\nof tests should be run when no categories are selected, while\nothers should run only when explicitly selected.\nTo support this, you can specify the Explicit attribute:\n[Explicit(\"SpecialEquipmentNeeded\")]\nThis syntax automatically excludes the category from a run\nthat doesn’t specify any categories. By default, your run will\ninclude tests without categories and tests with non-explicit\ncategories. However, if even one category is speciﬁed in the\n",
      "content_length": 899,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 62,
      "content": "NUNIT TEST SELECTION\n48\nGUI or the command line, then only that single category will\nbe run.\nThere’s a danger here, of course—these tests aren’t running\nall the time. They probably aren’t being run in the automated\nbuild system, either. This might lull you into a false sense of\nsecurity, so beware.\nIn addition to marking individual test methods as belonging to\na category, you can also mark entire ﬁxtures. For instance, if\nwe wanted to ﬂag our entire test ﬁxture as long-running (with-\nout having to mark each and every test method), we could do\nso.\nLine 1\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\n-\n[TestFixture]\n5\n[Category(\"Long\")]\n-\npublic class ShortestPathTest-Revised\n-\n{\n-\nTSP tsp;\n-\n10\n[Test]\n-\npublic void Use50Cities()\n-\n{\n-\ntsp = new TSP(); // load with default cities\n-\nAssert.That(tsp.ShortestPath(50), Is.AtMost(2300));\n15\n}\n-\n-\n[Test]\n-\npublic void Use100Cities()\n-\n{\n20\ntsp = new TSP(); // load with default cities\n-\nAssert.That(tsp.ShortestPath(100), Is.AtMost(4675));\n-\n}\n-\n-\n[Test]\n25\npublic void Use150Cities()\n-\n{\n-\ntsp = new TSP(); // load with default cities\n-\nAssert.That(tsp.ShortestPath(150), Is.AtMost(5357));\n-\n}\n30\n}\nShortestPathTest-Revised.cs\nNow you can quickly exclude the whole ﬁxture using a cate-\ngory name.\nOf course, not all tests need categories, and you may have\nentire projects where there are no categories at all. But it’s\nnice to know they are there if you do need them.\n",
      "content_length": 1442,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 63,
      "content": "NUNIT TEST SELECTION\n49\nPer-method Setup and Teardown\nEach test should run independently of every other test; this\nallows you to run any individual test at any time, in any order.\nTo accomplish this feat, you may need to reset some parts of\nthe testing environment in between tests, or clean up after\na test has run. NUnit lets you specify two methods to set up\nand then tear down the environment per test using attributes:\n[SetUp]\npublic void PerTestSetup() {\n...\n}\n[TearDown]\npublic void PerTestTeardown() {\n...\n}\nIn this example, the method PerTestSetup() is called before\neach one of the [Test] methods is executed, and the method\nPerTestTeardown() is called after each test method is exe-\ncuted, even if the test method throws an exception. This is\nwhy we mentioned that constructors in test ﬁxtures gener-\nally aren’t necessary.\nConstructors wouldn’t work the way\nyou wanted them to anyway, since NUnit doesn’t necessarily\nrecreate the TestFixture class each time it runs a test; it\ndiscovers and runs these methods using reﬂection.\nFor example, suppose you needed some sort of database con-\nnection object for each test. Rather than duplicating code in\neach test method that connects to and disconnects from the\ndatabase, you could simply use setup and teardown methods.\n[TestFixture]\npublic class DBTest\n{\nprivate Connection dbConn;\n[SetUp]\npublic void PerTestSetup()\n{\ndbConn = new Connection(\"oracle\", 1521, user, pw);\ndbConn.Connect();\n}\n[TearDown]\npublic void PerTestTeardown()\n{\ndbConn.Disconnect();\ndbConn.Dispose();\n}\n",
      "content_length": 1533,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 64,
      "content": "NUNIT TEST SELECTION\n50\n1. PerFixtureSetup()\n2.\nPerTestSetup()\n3.\ntest method 1\n4.\nPerTestTeardown()\n5.\nPerTestSetup()\n6.\ntest method 2\n7.\nPerTestTeardown()\n8. PerFixtureTeardown()\nPer-ﬁxture setup\nruns before any\ntests in a\nﬁxture, and\nteardown runs\nafter the last\ntest in a ﬁxture.\nPer-test setup\nruns before\neach test\nmethod, and\nteardown runs\nafter each\nmethod.\nFigure 3.3: Execution Order of Setup Code\n[Test]\npublic void AccountAccess()\n{\n// Uses dbConn\nxxx xxx xxxxxx xxx xxxxxxxxx;\nxx xxx xxx xxxx x xx xxxx;\n}\n[Test]\npublic void EmployeeAccess()\n{\n// Uses dbConn\nxxx xxx xxxxxx xxx xxxxxxxxx;\nxxxx x x xx xxx xx xxxx;\n}\n}\nDBTest.cs\nIn this example, the method PerTestSetup() will be called\nbefore TestAccountAccess(). After TestAccountAccess()\nhas ﬁnished, PerTestTearDown() will be called. PerTest-\nSetup() will be called again, followed by TestEmployee-\nAccess() and then PerTestTeardown() again.\nPer-ﬁxture Setup and Teardown\nNormally per-method setup is all you need, but in some cir-\ncumstances you may need to set something up or clean up af-\nter the entire test class has run; for that, you need per-ﬁxture\nsetup and teardown (the difference between per-test and per-\nﬁxture execution order is shown in Figure 3.3 on the previous\n",
      "content_length": 1246,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 65,
      "content": "MORE NUNIT ASSERTS\n51\npage). All you need to do is annotate your setup methods with\nthe following attributes:\n[TestFixtureSetUp]\npublic void PerFixtureSetup() {\n...\n}\n[TestFixtureTearDown]\npublic void PerFixtureTeardown() {\n...\n}\nNote that you can use both per-ﬁxture and per-test methods\nin the same class. While setup and teardown methods gener-\nally come in pairs, they don’t have to. Very often, a ﬁxture will\nhave a setup, but no teardown. A teardown without a setup,\nwhile rare, is also not unheard of. We can also deﬁne set-up\nmethods across inheritance boundaries, in both base classes\nand derived classes. They will work together as if they were\nall deﬁned in the same class.\n3.6\nMore NUnit Asserts\nIn addition to the basic asserts we’ve seen, NUnit provides\nadditional asserts to aid in testing collections and ﬁles.\nIf\nyou prefer the classic-style assertion methods, check out the\nStringAssert and CollectionAssert classes as well as the\nNUnit documentation.\nList.Contains\nAssert.That(actualCollection,\nList.Contains(expectedValue))\nAssert.That({5, 3, 2}, List.Contains(2))\nTests that the expected value is contained within actualCol-\nlection.\nIs.SubsetOf\nAssert.That(actualCollection,\nIs.SubsetOf(expectedCollection))\nAssert.That(new byte[] {5, 3, 2},\nIs.SubsetOf(new byte[] {1, 2, 3, 4, 5}))\n",
      "content_length": 1305,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 66,
      "content": "MORE NUNIT ASSERTS\n52\nTests that the elements of actualCollection are contained\nwithin expectedCollection, regardless of order.\nText.StartsWith\nAssert.That(actual,\nText.StartsWith(expected))\nAssert.That(\"header:data.\",\nText.StartsWith(\"header:\"))\nTests that the expected string is at the beginning of actual.\nThis is case sensitive by default; to ignore case sensitivity, we\nneed to add the IgnoreCase constraint modiﬁer.\nAssert.That(\"header:data.\",\nText.StartsWith(\"HeadeR\").IgnoreCase)\nText.Matches\nAssert.That(actual, Text.Matches(expected))\nAssert.That(\"header:data.\",\nText.Matches(\"$header^\\.\"))\nTests that the expected regular expression string matches\nactual.\nHere we’re making sure the actual string starts\nwith “header”,\nand ends with a period character.\nWe\ncould also have used a combination of Text.StartsWith,\nText.EndsWith, or Text.Contains constraints.\nFileAssert.AreEqual / AreNotEqual\nFileAssert.AreEqual(FileInfo expected,\nFileInfo actual)\nFileAssert.AreEqual(String pathToExpected,\nString pathToActual)\nTest whether two ﬁles are the same, byte for byte. Note that\nif we do the work of opening a Stream (ﬁle-based, or not), we\ncan use the EqualsConstraint instead, like so:\nStream expectedStream = File.OpenRead(\"expected.bin\");\nStream actualStream = File.OpenRead(\"actual.bin\");\nAssert.That(\nactualStream,\nIs.EqualTo(expectedStream)\n);\n",
      "content_length": 1354,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 67,
      "content": "NUNIT CUSTOM ASSERTS\n53\n3.7\nNUnit Custom Asserts\nThe standard asserts that NUnit provides are usually sufﬁ-\ncient for most testing. However, you may run into a situation\nwhere it would be handy to have your own, customized as-\nserts. Perhaps you’ve got a special data type, or a common\nsequence of actions that is done in multiple tests.\nThe worst thing you can do is slavishly copy the same se-\nquence of test code over and over again. “Copy and paste” of\ncommon code in the tests can be a fatal disease.\nInstead, tests should be written to the same high standards\nas regular code, which means honoring good coding practices\nsuch as the DRY principle,4 loose coupling, orthogonality, and\nso on. Factor out common bits of test harness into real meth-\nods, and use those methods in your test cases.\nThis is real code, and needs to be well-written, and well-\nfactored so you can reuse it and keep it up to date easily as\nthe system grows and evolves.\nDon’t be afraid to write your own assertion-style methods. For\ninstance, suppose you are testing a ﬁnancial application and\nvirtually all of the tests use a data type called Money.\nusing System;\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\npublic class MoneyAssert\n{\n// Assert that the amount of money is an even\n// number of dollars (no cents)\npublic static void AssertNoCents(Money amount,\nString message)\n{\nAssert.That(\nDecimal.Truncate(amount.AsDecimal()),\nIs.EqualTo(amount.AsDecimal()),\nmessage);\n}\n// Assert that the amount of money is an even\n// number of dollars (no cents)\npublic static void AssertNoCents(Money amount)\n4DRY stands for “Don’t Repeat Yourself.” It’s a fundamental technique\nthat demands that every piece of knowledge in a system must have a single,\nunambiguous, and authoritative representation [HT00].\n",
      "content_length": 1793,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 68,
      "content": "NUNIT AND EXCEPTIONS\n54\n{\nAssertNoCents(amount, String.Empty);\n}\n}\nMoneyAssert.cs\nNote that we provide both forms of assert: one that takes\na string and one that does not.\nNote also that we didn’t\nduplicate any code in doing so; we merely forward the call on.\nNow any other test classes in the project that need to test\nMoney can use our own custom assertion method. If multiple\ntest ﬁxture classes needed to use our custom assertions or\nother support methods, we could also extract a common base\nﬁxture class they would then derive from.\nWe’ll talk more\nabout that later in Chapter 8.\nusing NUnit.Framework;\n[TestFixture]\npublic class SomethingTest\n{\n[Test]\npublic void CountDeMonet()\n{\nMoney m = new Money(42.00);\nm.Add(2);\nMoneyAssert.AssertNoCents(m);\n}\n}\nSomethingTest.cs\nFor more examples, take a look at the NUnit source code itself\n(perhaps the StringAssert code). That’s part of the beauty\nof open source—you can go see the code for yourself, and see\nhow the magic is done.\n3.8\nNUnit and Exceptions\nWe might be interested in two different kinds of exceptions:\n1. Expected exceptions resulting from a test\n2. Unexpected exceptions from something that’s gone hor-\nribly wrong\nContrary to what you might think, exceptions are really good\nthings—they tell us that something is wrong. Sometimes in a\ntest, we want the method under test to throw an exception.\nConsider a method named ImportList(). It’s supposed to\n",
      "content_length": 1418,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 69,
      "content": "NUNIT AND EXCEPTIONS\n55\nthrow an ArgumentException if passed a null list. We must\ntest for that explicitly.\nGuarding against bad data is good defensive programming. If\na null parameter is passed in and not used immediately, the\neventual NullReferenceException becomes a time bomb of\nsorts.\nIt will go off at an unexpected moment, in some far\naway corner of the code. You then get the unenviable task of\ntracking down where in the system the bad data came from\noriginally. But by failing quickly, you’ll ﬁnd the root of the\nproblem quickly, and much more easily.\nSome people just\nlike pain, but we don’t, so we prefer to decrease our time spent\ndebugging by employing this practice.\nWith what we’ve learned so far, we can construct the following\ntest to ensure that the exception is thrown as expected.\n[Test]\npublic void NullList()\n{\ntry\n{\nWhitePages.ImportList(null);\nAssert.Fail(\"ArgumentNullException should have been thrown\");\n}\ncatch (ArgumentNullException)\n{\n}\n}\nThis test will fail if any exception other than Argument-\nNullException is thrown, or if no exception is thrown at\nall.\nIf no exception is thrown, the Assert.Fail() method\nis called, which fails the test. If an exception other than Ar-\ngumentNullException is thrown, it won’t be caught by the\ncatch deﬁned, which fails the test. This works, but it’s not\nexactly aesthetically pleasing.\nMore practically speaking, this style of test just doesn’t ex-\npress our intentions very well, and doesn’t scale well to more\ncomplicated cases. The NUnit user community and authors\nagreed, so for expected exceptions, NUnit now provides the\n[ExpectedException] attribute:\n[TestFixture]\npublic class ImportListTests\n{\n",
      "content_length": 1672,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 70,
      "content": "NUNIT AND EXCEPTIONS\n56\n[Test]\n[ExpectedException(typeof(ArgumentNullException))]\npublic void NullList() {\nWhitePages.ImportList(null);\n// Shouldn’t get to here\n}\n}\nExceptionTest.cs\nThis test method is now expected to throw an exception (from\nthe call to ImportList()). If it doesn’t, the test will fail. If the\nexact exception speciﬁed ﬁres as expected, the test passes. If\na different exception is thrown (even a super-class of the one\nspeciﬁed), the test fails. It might be tempting to just expect\nthe base Exception type, but you’re skirting around the fact\nthe tests are telling you your design needs some work.\nYou want to be as speciﬁc with exceptions in this context as\nyou would be in a catch() statement. Otherwise, you’ll get\ntests that pass when a totally different exception is thrown,\nand you might not know about it until the system starts mal-\nfunctioning in the hands of end-users.\nTwo salient details worth noting: Once the expected exception\nﬁres, any remaining code in the test method will be skipped. If\nthe SetUp method throws an exception before a test method’s\ncode executes, the test will always be reported as failing even\nthough the actual test code didn’t run.\nFurthermore, even\nif SetUp throws, TearDown method will still be run (if one is\ndeclared).\nIn general, you should test a method for every expected excep-\ntion, and make sure that the method throws it when it should.\nThat covers us for expected exceptions, but what about unex-\npected exceptions?\nNUnit will take care of those for you. For instance, suppose\nyou are reading a ﬁle of test data. Rather than catching the\npossible I/O exceptions yourself, just let them propagate out\nto the test framework.\n[Test]\npublic void TestData1() {\nStreamReader sr = new StreamReader(\"data.txt\");\nxxx xxx xxxxxx xxxxx xxxx;\n}\n",
      "content_length": 1802,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 71,
      "content": "TEMPORARILY IGNORING TESTS\n57\nEven better, NUnit will report the entire stack trace right down\nto the bug itself, not just to some failed assert, which helps\nwhen trying to ﬁgure out why a test failed. If you have enabled\ndebugging information during compilation of your assembly\nunder test, it will also give the exact source code line numbers\nin the stack trace.\nWhen compiling under mono’s C# compiler (gmcs) or Microsoft\n.NET’s C# compiler (csc), add -debug+ to the command line.\nIf you’re not working at the command line, this can be accom-\nplished by changing the Project settings in whatever IDE you\nhappen to be using. When running under mono, you’ll need to\nuse the -debug option to the mono runtime executable (mono\n-debug) for it to actually use that generated debug informa-\ntion.5\n3.9\nTemporarily Ignoring Tests\nNormally, you want all tests to pass all of the time. But sup-\npose you’ve thought up a bunch of tests ﬁrst, written them,\nand are now working your way through implementing the\ncode required to pass the tests.\nWhat about all those new\ntests that would fail now?\nYou can go ahead and write these tests, but you don’t want the\ntesting framework to run these tests just yet. NUnit provides\nthe [Ignore] attribute:\n[Test]\n[Ignore(\"Out of time.\nWill Continue Monday. --AH\")]\npublic void Something()\n{\nxxx xxx xxxxxx xxxxx xxxx;\n}\nExceptionTest.cs\nNUnit will report that this method was skipped (and show a\nyellow bar in the GUI version), so that you won’t forget about\nit later.\nIn other testing frameworks and languages, you’d have to ei-\nther name the method differently or comment it out. When\nusing JUnit in Java, for instance, methods whose names start\n5Microsoft .NET doesn’t require this; hopefully mono will remove this re-\nquirement in a future release.\n",
      "content_length": 1783,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 72,
      "content": "TEMPORARILY IGNORING TESTS\n58\nwith “test” (as in testSomething) will be run as tests; you\nhave to name the method something else until you’re ready\nto tackle it.\nIn any language, the code still has to compile\ncleanly; if it’s not ready for that yet, then you should com-\nment out the offending parts.\nIt’s a good idea to to put a meaningful message, and perhaps\neven your initials, into the ignore so that the team knows why\nthis test isn’t running. Are you still working on it? Do you\nneed something from someone else in order to ﬁnish? Can\nsomeone else ﬁnish it up for you (in a geographically diverse\nteam, perhaps)?\nDon’t just Ignore it and forget about it;\nthat’s a Broken Window.6\nYou want to avoid at all costs the habit of ignoring failing test\nresults. You don’t see green until they all work: just the ab-\nsence of a red bar (or error messages) does not mean success.\nIgnoring Platform-dependent Tests\nThere is one small exception to that rule; what to do when cer-\ntain tests have to be ignored because of the platform on which\nyou are running? This scenario isn’t uncommon and can oc-\ncur if you’re writing a cross-platform application (whether it\nbe for .NET 2.0 and mono, or speciﬁcally for .NET 1.1), some\nof your tests may only run (or pass) on a speciﬁc platform.\nThis was a problem NUnit itself faced, so they introduced the\nPlatform attribute, which is used like this:\n[Test]\n[Platform(Exclude = \"Mono\")]\npublic void RemoveOnEmpty() {\nxxx xx xxx xxxxx xx xx xxx;\n}\n[Test, Platform(Exclude = \"Net-1.0,Win95\")]\npublic void EmptyStatusBar() {\nxxx xx xxx xxxxx xx xx xxx;\n}\nAs you can see, Linux-speciﬁc tests that don’t work on Solaris,\nMacOS, or certain Windows or .NET versions can be marked\n6See [HT00].\n",
      "content_length": 1723,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 73,
      "content": "TEMPORARILY IGNORING TESTS\n59\nas such. 7 When using the Platform attribute, you will still\nget a green bar in the GUI (not yellow) even in the prescense\nof tests ignored via this attribute. Other than that, it operates\nsimilarly to the Ignore attribute.\nThe point again is that you want to avoid any situation where\nyou begin to ignore failing tests out of habit. Platform en-\nsures that the proper tests are run only in the proper envi-\nronment.\nNow that you’ve got a good idea of how to write tests, it’s time\nto take a closer look at ﬁguring out what to test.\n7A comprehensive list of the platforms can be found in the NUnit docu-\nmentation on http://nunit.org.\n",
      "content_length": 665,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 74,
      "content": "Chapter 4\nWhat to Test:\nThe Right-BICEP\nNow that you know how to test, we need to spend some chap-\nters looking at what to test; or more precisely, the kinds of\nthings that might need testing.\nIt can be hard to look at a method or a class and try to come\nup with all the ways it might fail and to anticipate all the bugs\nthat might be lurking in there. With enough experience, you\nstart to get a feel for those things that are “likely to break,”\nand can effectively concentrate on testing in those areas ﬁrst.\nBut without a lot of experience, it can be hard and frustrating\ntrying to discover possible failure modes. End-users are quite\nadept at ﬁnding our bugs, but that’s both embarrassing and\ndamaging to our careers! What we need are some guidelines,\nsome reminders of areas that might be important to test.\nLet’s take a look at six speciﬁc areas to test that will help\nstrengthen your testing skills, using your RIGHT-BICEP:\n• Right — Are the results right?\n• B — Are all the boundary conditions CORRECT?\n• I — Can you check inverse relationships?\n• C — Can you cross-check results using other means?\n• E — Can you force error conditions to happen?\n",
      "content_length": 1154,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 75,
      "content": "ARE THE RESULTS RIGHT?\n61\n• P — Are performance characteristics within bounds?\n4.1\nAre the Results Right?\nThe ﬁrst and most obvious area to test is simply to see if the\nRight\nBICEP\nexpected results are right—to validate the results.\nIt’s a good starting point. We’ve seen simple data validation\nalready: the tests in Chapter 2 that verify that a method re-\nturns the largest number from a list.\nThese are usually the “easy” tests, and many of these sorts of\nvalidations may even be speciﬁed in the requirements. If they\naren’t, you’ll probably need to ask someone. You need to be\nable to answer the key question:\nIf the code ran correctly, how would I know?\nIf you cannot answer this question satisfactorily, then writing\nthe code—or the test—may be a complete waste of time. “But\nwait,” you may say, “that doesn’t sound very agile! What if\nthe requirements are vague or incomplete? Does that mean\nwe can’t write code until all the requirements are ﬁrm?”\nNo, not at all. If the requirements are truly not yet known,\nor complete, you can always invent some as a stake in the\nground.\nThey may not be correct from the user’s point of\nview, but you now know what you think the code should do,\nand so you can answer the question.\nOf course, you’ll then arrange for feedback with users to\nﬁne-tune your assumptions. The deﬁnition of “correct” may\nchange over the lifetime of the code in question, but at any\npoint, you should be able to prove (using automated tests)\nthat the code is doing what you think it ought.\nUsing Data Files\nFor sets of tests with large amounts of test data, you might\nwant to consider putting the test values and/or results in a\nseparate data ﬁle that the unit test reads in. This doesn’t need\nto be a very complicated exercise—and you don’t even need to\n",
      "content_length": 1774,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 76,
      "content": "ARE THE RESULTS RIGHT?\n62\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\nusing System;\nusing System.IO;\nusing System.Collections.Generic;\n[TestFixture]\npublic class LargestDataFileTests\n{\nprivate int[] getNumberList(string line)\n{\nstring[] tokens = line.Split(null);\nList<int> numberList = new List<int>();\nfor (int i=1; i < tokens.Length; i++)\n{\nnumberList.Add(Int32.Parse(tokens[i]));\n}\nreturn numberList.ToArray();\n}\nprivate int getLargestNumber(string line)\n{\nstring[] tokens = line.Split(null);\nstring val = tokens[0];\nint expected = Int32.Parse(val);\nreturn expected;\n}\nprivate bool hasComment(string line)\n{\nreturn line.StartsWith(\"#\");\n}\n// Run all the tests in testdata.txt (does not test\n// exception case). We’ll get an error if any of the\n// file I/O goes wrong.\n[Test]\npublic void FromFile()\n{\nstring line;\n// most IDEs output the test bi-\nnary in bin/[Debug,Release]\nStreamReader reader =\nnew StreamReader(\"../../testdata.txt\");\nwhile ((line = reader.ReadLine()) != null)\n{\nif (hasComment(line))\n{\ncontinue;\n}\nint[] numberListForLine = getNumberList(line);\nint expectedLargestNumber = getLargestNumber(line);\nint actualLargestNumber = Cmp.Largest(numberListForLine));\nAssert.That(expectedLargestNumber, Is.EqualTo(actualLargestNumber));\n}\n}\n",
      "content_length": 1268,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 77,
      "content": "ARE THE RESULTS RIGHT?\n63\nuse XML.1 Figure 4.1 on the preceding page is a version of\nTestLargest that reads in all of the tests from a data ﬁle.\nThe data ﬁle has a very simple format; each line contains a\nset of numbers. The ﬁrst number is the expected answer, the\nnumbers on the rest of the line are the arguments with which\nto test. We’ll allow a pound-sign (#) for comments, so that you\ncan put meaningful descriptions and notes in the test ﬁle.\nThe test ﬁle can then be as simple as:\n#\n# Simple tests:\n#\n9 7 8 9\n9 9 8 7\n9 9 8 9\n#\n# Negative number tests:\n#\n-7 -7 -8 -9\n-7 -8 -7 -8\n-7 -9 -7 -8\n#\n# Mixture:\n#\n7 -9 -7 -8 7 6 4\n9 -1 0 9 -7 4\n#\n# Boundary conditions:\n#\n1 1\n0 0\n2147483647 2147483647\n-2147483648 -2147483648\ntestdata.txt\nIn this example we’re only running one particular test (using\none assert), but you could extend that to run as many differ-\nent tests on the same data as practical.\nFor just a handful of tests (as in this example), the separate\ndata ﬁle approach is probably not worth the effort or the per-\nformance overhead of the ﬁle I/O. In cases where you can’t\njustify an external ﬁle, C#’s string literals paired with a Tex-\ntReader can provide the same beneﬁts described above with-\nout the less palatable aspects:\nstring oneCommentWithTwoSets = @\"\n1This is clearly a joke. XML is mandatory on all projects today, isn’t it?\n",
      "content_length": 1352,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 78,
      "content": "BOUNDARY CONDITIONS\n64\n# comment line\n9 7 8 9\n-9 9 8 7\n\"\nBut say this was a more advanced application, with tens or\neven hundreds of test cases in this form. Then the ﬁle ap-\nproach becomes a very compelling choice.\nBe aware that test data, whether it’s in a ﬁle or in the test\ncode itself, might well be incorrect. In fact, experience sug-\ngests that test data is more likely to be incorrect than the\ncode you’re testing, especially if the data was hand-calculated\nor obtained from a system we’re replacing (where new fea-\ntures may deliberately cause new results).\nWhen test data\nsays you’re wrong, double- and triple-check that the test data\nis right before attacking the code. Ask a co-worker to take a\nlook, or just take a break (away from the keyboard); some-\ntimes it’s difﬁcult to see the woods through the trees.\nSomething else to think about: the code as presented in this\nexample does not test any exception cases. How might you\nimplement that? Also notice that we wrote a non-test “helper”\nmethod to parse the numbers from the data ﬁle.\nIt’s per-\nfectly okay—even encouraged—to create support methods and\nclasses as needed. We might even extract these support meth-\nods into a TestFileParser class if we wanted to share this\ncode across different ﬁxtures, or just to unclutter the test\nclass itself.\nDo whatever makes it easiest for you to prove that the method\nis right.\n4.2\nBoundary Conditions\nIn the previous “largest number” example, we discovered sev-\nRight\nB ICEP\neral boundary conditions: when the largest value was at the\nend of the array, when the array contained a negative number,\nan empty array, and so on.\nIdentifying boundary conditions is one of the most valuable\nparts of unit testing, because this is where most bugs gener-\nally live—at the edges. These nether-regions of untested code\n",
      "content_length": 1815,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 79,
      "content": "BOUNDARY CONDITIONS\n65\nare where almost all exploitable security vulnerabilities come\nfrom.\nSome conditions you might want to think about:\n• Totally bogus or inconsistent input values, such as a ﬁle\nname of \"!*W:X\\&Gi/w∼>g/h#WQ@\".\n• Badly formatted data that is missing delimeters or ter-\nminators, such as an e-mail address without a top-level\ndomain (\"fred@foobar.\").2\n• Empty or missing values (such as 0, 0.0, an empty string,\nan empty array, or null), or missing in a sequence (such\nas a missing TCP packet).\n• Values far in excess of reasonable expectations, such as\na person’s age of 10,000 years or a password string with\n10,000 characters in it.\n• Duplicates in lists that shouldn’t have duplicates.\n• Ordered lists that aren’t, and vice-versa. Try handing a\npre-sorted list to a sort algorithm, for instance—or even\na reverse-sorted list.\n• Things that arrive out of order, or happen out of expected\norder, such as trying to print a document before logging\nin, or getting fragmented IP packets out of order, for in-\nstance.\nAn easy way to think of possible boundary conditions is to\nremember the acronym CORRECT. For each of these items,\nconsider whether or not similar conditions may exist in your\nmethod that you want to test, and what might happen if these\nconditions were violated:\n• Conformance — Does the value conform to an expected\nformat?\n• Ordering — Is the set of values ordered or unordered as\nappropriate?\n2A popular mail service suffered from an exploitable bug like this involving\na missing ’>’ in SMTP headers.\n",
      "content_length": 1537,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 80,
      "content": "CHECK INVERSE RELATIONSHIPS\n66\n• Range — Is the value within reasonable minimum and\nmaximum values?\n• Reference — Does the code reference anything external\nthat isn’t under direct control of the code itself?\n• Existence — Does the value exist (e.g., is non-null, non-\nzero, present in a set, etc.)?\n• Cardinality — Are there exactly enough values?\n• Time (absolute and relative) — Is everything happening\nin order? At the right time? In time?\nBecause boundary conditions are such an important area to\ntest, we’ll examine these in detail in the next chapter (which\nmakes Right-BICEP a nested acronym).\n4.3\nCheck Inverse Relationships\nRight B I CEP\nSome methods can be checked by applying their logical in-\nverse. For instance, you might check a method that calcu-\nlates a square root by squaring the result, and testing that it\nis tolerably close to the original number:\n[Test]\npublic void SquareRootUsingInverse() {\ndouble x = MyMath.SquareRoot(4.0);\nAssert.That(4.0, Is.EqualTo(x*x).Within(0.0001));\n}\nRootsTest.cs\nYou might check that some data was successfully inserted\ninto a database, then search for it, and then delete it. You\nmight transfer money into an account, then transfer the same\namount out of the account. Any of these operations apply an\n“inverse” to see if you get back to an original state.\nBut be cautious when you’ve written both the original routine\nand it’s inverse, as some bugs might be masked by a com-\nmon error in both routines. Where possible, use a different\nsource for the inverse test. In the square root example, we’re\njust using regular multiplication to test our method. For the\ndatabase search, we’ll probably use a vendor-provided delete\nroutine to test our insertion.\n",
      "content_length": 1706,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 81,
      "content": "CROSS-CHECK USING OTHER MEANS\n67\n4.4\nCross-check Using Other Means\nYou might also be able to cross-check results of your method\nRight BI C EP\nusing different means.\nUsually there is more than one way to calculate some quan-\ntity; we might pick one algorithm over the others because it\nperforms better, or has other desirable characteristics. That’s\nthe one we’ll use in production, but we can use one of the\nother versions to cross-check our results in the test system.\nThis technique is especially helpful when there’s a proven,\nknown way of accomplishing the task that happens to be too\nslow or too inﬂexible to use in production code.\nWe can use that somewhat lesser version to our advantage\nto check that our new super-spiffy version is producing the\nsame results:3\n[Test]\npublic void SquareRootUsingStd() {\ndouble number = 3880900.0;\ndouble root1 = MyMath.SquareRoot(number);\ndouble root2 = Math.Sqrt(number);\nAssert.That(root2, Is.EqualTo(root1).Within(0.0001));\n}\nRootsTest.cs\nAnother way of looking at this issue is to use different pieces\nof data from the class itself to make sure they all “add up,” or\nreconcile. That counts as a cross-check as well.\nFor instance,\nsuppose you were working on a library’s\ndatabase system (that is, a brick-and-mortar library that\nlends out real books). In this system, the number of copies\nof a particular book should always balance. That is, the num-\nber of copies that are checked out plus the number of copies\nsitting on the shelves should always equal the total number\nof copies in the collection. These are separate pieces of data,\nand may even be reported by objects of different classes, but\nthey still have to agree, and so can be used to cross-check one\nanother.\n3Some spreadsheet engines (as found in Microsoft ExcelTM, etc.) employ\nsimilar techniques to check that the models and methods chosen to solve\na particular problem are appropriate, and that the answers from different\napplicable methods agree with each other.\n",
      "content_length": 1975,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 82,
      "content": "FORCE ERROR CONDITIONS\n68\nAs with the inverse checks above, make sure you aren’t simply\nexercising the same underlying code in two different ways—\nthe point of cross-checking is to explicitly use different code\nto verify the same result.\n4.5\nForce Error Conditions\nIn the real world, errors happen. Disks ﬁll up, network lines\nRight BIC E P\ndrop, e-mail goes into a black hole, and programs crash. You\nshould be able to test that your code handles all of these real-\nworld problems by forcing errors to occur.\nThat’s easy enough to do with invalid parameters and the like,\nbut to simulate speciﬁc network errors—without unplugging\nany cables—takes some special techniques. We’ll discuss one\nway to do this using Mock Objects in Chapter 6 on page 90.\nBut before we get there, consider what kinds of errors or other\nenvironmental constraints you might introduce to test your\nmethod? Make a short list before reading further.\nSTOP\nThink about this for a moment before reading on. . .\nHere are a few environmental things we’ve thought of.\n• Running out of memory\n• Running out of disk space\n• Issues with wall-clock time\n• Network availability and errors\n• Insufﬁcient File or Path permissions\n• System load\n• Limited color palette\n• Very high or very low video resolution\nThese are just general categories, for each of them there may\nbe more subtle issues worth testing. For instance, you might\ntest that the code can handle the case when the network itself\ngoes down, but what about if the network is up and the DNS\n",
      "content_length": 1514,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 83,
      "content": "PERFORMANCE CHARACTERISTICS\n69\nserver is down? Or the network is up, but slowed to a timeout-\ninducing crawl due to a denial of service attack? These things\nhappen, and if our code needs to handle these sort of errors,\nthen we need to test for them. If our code isn’t supposed to\nhandle these sorts of errors, we should still write a test that\nvalidates that behaviour using the ExpectedException we\npreviously discussed.\n4.6\nPerformance Characteristics\nOne area that might prove beneﬁcial to examine is perfor-\nRight BICE P\nmance characteristics—not performance itself, but trends as\ninput sizes grow, as problems become more complex, and so\non.\nWhat we’d like to achieve is a quick regression test of per-\nformance characteristics. All too often, we might release one\nversion of the system that works okay, but somehow by the\nnext release it has become dead-dog slow.\nWe don’t know\nwhy, or what change was made, or when, or who did it, or\nanything. And the end users are screaming bloody murder.\nTo avoid that awkward scenario, you might consider some\nrough tests just to make sure that the performance curve re-\nmains stable. For instance, suppose we’ve written a ﬁlter that\nidentiﬁes web sites that we wish to block (using our new prod-\nuct to view naughty pictures might get us in all sorts of legal\ntrouble, after all.)\nThe code works ﬁne with a few dozen sample sites, but will it\nwork as well with 10,000? 100,000? Let’s write a unit test to\nﬁnd out.\nLine 1\n[TestFixture]\n-\npublic class FilterTest\n-\n{\n-\nTimer timer;\nString naughty_url = \"http://www.xxxxxxxxx.com\";\n5\nURLFilter filter;\n-\n-\n[SetUp]\n-\npublic void Initialize()\n-\n{\n10\ntimer = new Timer();\n-\n}\n-\n-\n[Test]\n",
      "content_length": 1676,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 84,
      "content": "PERFORMANCE CHARACTERISTICS\n70\n-\npublic void SmallList()\n15\n{\n-\nfilter = new URLFilter(SMALL_LIST);\n-\ntimer.Start();\n-\nfilter.Check(naughty_url);\n-\ntimer.End();\n20\nAssert.That(timer.ElapsedTime, Is.LessThan(1.0));\n-\n}\n-\n}\n-\n[Test]\n-\n[Category(\"Long\")]\n25\npublic void HugeList()\n-\n{\n-\nfilter = new URLFilter(HUGE_LIST);\n-\ntimer.Start();\n-\nfilter.Check(naughty_url);\n30\ntimer.End();\n-\nAssert.That(timer.ElapsedTime, Is.LessThan(10.0));\n-\n}\n-\n}\nFilterTest.cs\nThis gives us some assurance that we’re still meeting perfor-\nmance targets. But because this one test takes 6–7 seconds to\nrun, we may not want to run it every time. As long as we run\nit in our automated build at least every couple of days, we’ll\nquickly be alerted to any problems we may introduce, while\nthere is still time to ﬁx them.\n",
      "content_length": 795,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 85,
      "content": "Chapter 5\nCORRECT\nBoundary Conditions\nAs we said in the last chapter, boundary conditions are such\na vibrant source of bugs that we need a whole chapter to talk\nabout them. Many bugs in code occur around boundary con-\nditions, that is, under conditions where the code’s behavior\nmay be different from the normal, day-to-day routine.\nFor instance, suppose we have a function that takes two inte-\ngers:\npublic int Calculate(int a, int b) {\nreturn a / (a+b);\n}\nRootsTest.cs\nMost of the time, this code will return a number just as we\nexpect. But if the sum of a and b happens to equal zero, we\nwill get a DivideByZeroException instead of a return value.\nThat is a boundary condition—at the edge of normal expecta-\ntions. It’s a place where things might suddenly go wrong, or\nat least behave differently from what we wanted.\nTo help us think of tests for boundary conditions, we’ll use\nthe acronym CORRECT:\n• Conformance—Does the value conform to an expected\nformat?\n",
      "content_length": 963,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 86,
      "content": "CONFORMANCE\n72\n• Ordering—Is the set of values ordered or unordered as\nappropriate?\n• Range—Is the value within reasonable minimum and\nmaximum values?\n• Reference—Does the code reference anything external\nthat isn’t under direct control of the code itself?\n• Existence—Does the value exist (e.g., is non-null, non-\nzero, present in a set, etc.)?\n• Cardinality—Are there exactly enough values?\n• Time (absolute and relative)—Is everything happening in\norder? At the right time? In time?\nLet’s look at each one of these in turn. Remember that for\neach of these areas, you want to consider data that is passed\nin as arguments to your method as well as internal data that\nyou maintain inside your method and class.\nThe underlying question that we want to answer fully is:\nWhat else can go wrong?\nOnce you think of something that could go wrong, write a test\nfor it. Once that test passes, again ask yourself, “what else\ncan go wrong?” and write another test, and so on.\nThere’s always something else that could go wrong, and these\nare some of the more productive areas to consider.\n5.1\nConformance\nMany times you expect or produce data that must conform to\nC ORRECT\nsome speciﬁc format. An e-mail address, for instance, isn’t\njust a simple string. You expect that it must be of the form:\nname@somewhere.com\nWith the possibility of extra dotted parts:\nfirstname.lastname@subdomain.somewhere.com\nAnd even oddballs like this one:\nfirstname.lastname%somewhere@subdomain.somewhere.com\n",
      "content_length": 1476,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 87,
      "content": "CONFORMANCE\n73\nSuppose you are writing a method that will extract the user’s\nname from their e-mail address. You’ll expect that the user’s\nname is the portion before the “@” sign. What will your code\ndo if there is no “@” sign? Will it work? Throw an exception?\nWhat about multiple “@” signs or a string of only @” signs? Is\nthis a boundary condition you need to consider?1\nValidating formatted string data such as e-mail addresses,\nphone numbers, account numbers, or ﬁle names is usually\nstraightforward, but be aware of internationalization issues:\nnot only could there be issues with the format (many coun-\ntries don’t have states or provinces), but issues with character\nencoding as well.2 Will you be getting unicode data, and if so,\nwill you be able to handle it?\nThen there’s more complex, structured data to consider. Sup-\npose you are reading report data that contains a header record\nlinked to a number of data records, and ﬁnally to a trailer\nrecord. How many conditions might we have to test?\n• What if there’s no header, just data and a trailer?\n• What if there’s no data, just a header and trailer?\n• What if there’s no trailer, just a header and data?\n• What if there’s just a trailer?\n• What if there’s just a header?\n• What if there’s just data?\nJust as with the simpler e-mail address example, you have\nto consider what will happen if the data does not conform to\nthe structure you think it should. This directly applies to any\ncode that parses ﬁle formats or network protocols, avenues\nby which attacks will come either on purpose or unwittingly.\nIt’s best to code defensively and verify the defenses with unit\ntests,3 since an attacker will probably end up testing them for\nyou eventually whether we want them to or not.\n1E-mail addresses are actually very complicated.\nA close reading of\nRFC822 may surprise you.\n2Input validation should always be done on model objects, sometimes in\naddition to the UI validation.\n3A fun way to think about this is, “How would I attack this function?”\n",
      "content_length": 2007,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 88,
      "content": "ORDERING\n74\nAnd of course, if you are creating data (not just validating\nit) such as an e-mail address (possibly building it up from\ndifferent sources) or the structured data above, you want to\ntest your result to make sure it conforms as well.\n5.2\nOrdering\nAnother area to consider is the order of data, or the position\nC O RRECT\nof one piece of data within a larger collection. For instance,\nin the Largest() example in the previous chapter, one bug\nmanifested itself depending on whether the largest number\nyou were searching for was at the beginning or end of the list.\nThat’s one aspect of ordering.\nAny kind of search routine\nshould be tested for conditions where the search target is ﬁrst\nor last, as many common bugs can be found that way.\nFor another aspect of ordering, suppose you are writing a\nmethod that is passed a collection containing a restaurant\norder. You would probably expect that the appetizers will ap-\npear ﬁrst in the order, followed by the salad (and that all-\nimportant dressing choice), then the entree and ﬁnally a deca-\ndent dessert involving lots of chocolate.\nWhat happens to your code if the dessert is ﬁrst, and the\nentree is last?\nIf there’s a chance that sort of thing can happen, and if it’s the\nresponsibility of your method to deal with it if it does, then you\nneed to test for this condition and address the problem. Now,\nit may be that this is not something your method needs to\nworry about. Perhaps this needs to be addressed at the user\ninput level (see “Testing Invalid Parameters” later on, and the\nchapter on GUI testing on page 165. Bear in mind that busi-\nness logic does not belong in the GUI itself–ever. User inter-\nface components (graphical or otherwise) should only contain\ncode for the UI, not for anything else.\nIf you’re writing a sort routine, what might happen if the set of\ndata is already ordered? Or worse yet, sorted in precisely re-\nverse order? Ask yourself if that could cause trouble—if these\nare conditions that might be worth testing, too. Then test it\nanyway, you may be surprised to ﬁnd it makes a difference.\n",
      "content_length": 2082,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 89,
      "content": "RANGE\n75\nIf you are supposed to maintain something in order, verify that\nit is. For example, if your method is part of the GUI that is\nsending the dinner order back to the kitchen, you should have\na test that veriﬁes that the items are in the correct serving\norder:\n[Test]\npublic void KitchenOrder()\n{\nOrder order = new Order();\nFoodItem dessert = new Dessert(\"Chocolate Decadence\");\nFoodItem entree = new Entree(\"Beef Oscar\");\nFoodItem salad\n= new Salad(\"Parmesan Peppercorn\");\n// Add out of order\norder.AddFoodItem(dessert);\norder.AddFoodItem(entree);\norder.AddFoodItem(salad);\n// But should come out in serving order\nIEnumerator itr = order.GetEnumerator();\nAssert.That(salad, Is.EqualTo(itr.Current));\nitr.MoveNext();\nAssert.That(entree, Is.EqualTo(itr.Current));\nitr.MoveNext();\nAssert.That(dessert, Is.EqualTo(itr.Current));\nitr.MoveNext();\n// No more left\nAssert.That(itr.MoveNext(), Is.False);\n}\nKitchenTest.cs\nOf course, from a human factors standpoint, you’d need to\nmodify the code so that it’s ﬂexible enough to allow people to\neat their ice cream ﬁrst, if so desired. In which case, you’d\nneed to add a test to prove that your four-year old nephew’s\nice cream comes with everyone else’s salads, but Grandma’s\nice cream comes at the end with your cappuccino.\n5.3\nRange\nRange is a convenient catch-all word for the situation where a\nCO R RECT\nvariable’s type allows it to take on a wider range of values than\nyou need—or want. For instance, a person’s age is typically\nrepresented as an integer, but no one has ever lived to be\n200,000 years old, even though that’s a perfectly valid integer\nvalue. Similarly, there are only 360 degrees in a circle, even\nthough degrees are commonly stored in an integer.\n",
      "content_length": 1716,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 90,
      "content": "RANGE\n76\nIn good object oriented design, you do not use a built-in value\ntype (e.g., an int or Int32) to store a bounded-integer value\nsuch as an age, or a compass heading.\nusing System;\n//\n// Compass bearing\n//\npublic class Bearing {\nprotected int bearing; // 0..359\n//\n// Initialize a bearing to a value from 0..359\n//\npublic Bearing(int num_degrees) {\nif (num_degrees < 0 || num_degrees > 359) {\nthrow new ArgumentException(\"Bad bearing\");\n}\nbearing = num_degrees;\n}\n//\n// Return the angle between our bearing and another.\n// May be negative.\n//\npublic int AngleBetween(Bearing anOther) {\nreturn bearing - anOther.bearing;\n}\n}\nBearing.cs\nNotice that the angle returned is just an int—a plain old num-\nber, as we are not placing any range restrictions on the result\n(it may be negative, etc.)\nBy encapsulating the concept of a bearing within a class,\nyou’ve now got one place in the system that can ﬁlter out bad\ndata. You cannot create a Bearing object with out of range\nvalues. Thus, the rest of the system can use Bearing objects\nand be assured that they contain only reasonable values.4\nOther ranges may not be as straightforward. For instance,\nsuppose you have a class that maintains two sets of x, y co-\nordinates. These are just integers, with arbitrary values, but\nthe constraint on the range is such that the two points must\ndescribe a rectangle with no side greater than 100 units. That\nis, the allowed range of values for both x, y pairs is interdepen-\n4For types like these, a struct might be preferred if you have a deep\nenough knowledge of the CLR to care.[Ric06]\n",
      "content_length": 1580,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 91,
      "content": "RANGE\n77\ndent. You’ll want a range test for any method that can affect a\ncoordinate to ensure that the resulting range of the x, y pairs\nremains legitimate. For more information on this topic, see\n“invariants” in the Design Issues chapter on page 143.\nSince you will likely call this from a number of different tests,\nit probably makes sense to make a new assert method:\npublic const int MAX_DIST = 100;\nstatic public void AssertPairInRange(Point one,\nPoint two,\nString message)\n{\nAssert.That(\nMath.Abs(one.X - two.X),\nIs.AtMost(MAX_DIST),\nmessage\n);\nAssert.That(\nMath.Abs(one.Y - two.Y),\nIs.AtMost(MAX_DIST),\nmessage\n);\n}\nPairTest.cs\nBut the most common ranges you’ll want to test probably de-\npend on physical data structure issues, not application do-\nmain constraints. Take a simple example like a stack class\nthat implements a stack of Strings using an array:\npublic class MyStack\n{\npublic MyStack()\n{\nelements = new string[100];\nnextIndex = 0;\n}\npublic String Pop()\n{\nreturn elements[--nextIndex];\n}\n// Delete n items from the elements en-masse\npublic void Delete(int n)\n{\nnextIndex -= n;\n}\npublic void Push(string element)\n{\nelements[nextIndex++] = element;\n}\npublic String Top()\n",
      "content_length": 1187,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 92,
      "content": "RANGE\n78\n{\nreturn elements[nextIndex-1];\n}\nprivate int nextIndex;\nprivate string[] elements;\n}\nMyStack.cs\nThere are some potential bugs lurking here, as there are no\nchecks at all for either an empty stack or a stack overﬂow.\nHowever we manipulate the index variable nextIndex, one\nthing is supposed to be always true: (next_index >= 0 &&\nnext_index < stack.Length). We’d like to check to make\nsure this expression is true.\nBoth nextIndex and stack are private variables; you don’t\nwant to have to expose those just for the sake of testing. There\nare several ways around this problem; for now we’ll just make\na special method in MyStack named CheckInvariant():\npublic void CheckInvariant()\n{\nif (!(nextIndex >= 0 &&\nnextIndex\n< elements.Length))\n{\nthrow new InvariantException(\n\"nextIndex out of range: \"\n+\nnextIndex +\n\" for elements length \" + elements.Length);\n}\n}\nMyStack.cs\nNow a test method can call CheckInvariant() to ensure that\nnothing has gone awry inside the guts of the stack class, with-\nout having direct access to those same guts.5\nusing NUnit.Framework;\n[TestFixture]\npublic class MyStackTest\n{\n[Test]\npublic void Empty()\n{\nMyStack stack = new MyStack();\nstack.CheckInvariant();\nstack.Push(\"sample\");\nstack.CheckInvariant();\n// Popping last element ok\n5You’d normally use an InvalidOperationException, but in this case\nwe want to reinforce the invariant concept by using a custom exception.\n",
      "content_length": 1407,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 93,
      "content": "REFERENCE\n79\nAssert.That(\nstack.Pop(),\nIs.EqualTo(\"sample\")\n);\nstack.CheckInvariant();\n// Delete from empty stack\nstack.Delete(1);\nstack.CheckInvariant();\n}\n}\nMyStackTest.cs\nWhen you run this test, you’ll quickly see that we need to add\nsome range checking!\nTestCase ’MyStackTest.Empty’ failed: InvariantException\nnextIndex out of range: -1 for stack length 100\nmystack.cs(34,0): at MyStack.CheckInvariant()\nmystacktest.cs(20,0): at MyStackTest.Empty()\nIt’s much easier to ﬁnd and ﬁx this sort of error here in a sim-\nple testing environment instead of buried in a real application.\nAlmost any indexing concept (whether it’s a genuine integer\nindex or not) should be extensively tested.\nHere are a few\nideas to get you started:\n• Start and End index have the same value\n• First is greater than Last\n• Index is negative\n• Index is greater than allowed\n• Count doesn’t match actual number of items\n• . . .\n5.4\nReference\nWhat things does your method reference that are outside the\nCOR R ECT\nscope of the method itself? Any external dependencies? What\nstate does the class have to be in?\nWhat other conditions\nmust exist in order for the method to work?\nFor example, a method in a web application to display a cus-\ntomer’s account history might require that the customer is\nﬁrst logged on. The method Pop() for a stack requires a non-\n",
      "content_length": 1331,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 94,
      "content": "REFERENCE\n80\nempty stack. Shifting the transmission in your car to Park\nfrom Drive requires that the car is stopped.\nIf you have to make assumptions about the state of the class\nand the state of other objects or the global application, then\nyou need to test your code to make sure that it is well-behaved\nif those conditions are not met.\nFor example, the code for\nthe microprocessor-controlled transmission might have unit\ntests that check for that particular condition: the state of the\ntransmission (whether it can shift into Park or not) depends\non the state of the car (is it in motion or stopped).\n[Test]\npublic void JamItIntoPark()\n{\ntransmission.Shift(DRIVE);\ncar.AccelerateTo(35);\nAssert.That(\ntransmission.CurrentGear,\nIs.EqualTo(DRIVE)\n);\n// should silently ignore\ntransmission.Shift(PARK);\nAssert.That(\ntransmission.CurrentGear,\nIs.EqualTo(DRIVE)\n);\ncar.AccelerateTo(0); // i.e., stop\ncar.BrakeToStop();\n// should work now\ntransmission.Shift(PARK);\nAssert.That(\ntransmission.CurrentGear,\nIs.EqualTo(PARK)\n);\n}\nThe preconditions for a given method specify what state the\nworld must be in for this method to run. In this case, the pre-\ncondition for putting the transmission in park is that the car’s\nengine (a separate component elsewhere in the application’s\nworld) must be at a stop. That’s a documented requirement\nfor the method, so we want to make sure that the method\nwill behave gracefully (in this particular case, just ignore the\nrequest silently) in case the precondition is not met.\nAt the end of the method, postconditions are those things that\nyou guarantee your method will make happen. Direct results\n",
      "content_length": 1626,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 95,
      "content": "EXISTENCE\n81\nreturned by the method are one obvious thing to check, but if\nthe method has any side-effects then you need to check those\nas well. In this case, applying the brakes has the side effect\nof stopping the car.\nSome languages even have built-in support for preconditions\nand postconditions; interested readers might want to read\nabout the original Eiffel in Object-Oriented Software Construc-\ntion [Mey97], or take a look at nContract,6 which can add\nsimilar capabilities to C#.7\n5.5\nExistence\nA large number of potential bugs can be discovered by asking\nCORR E CT\nthe key question “does some given thing exist?”.\nFor any value you are passed in or maintain, ask yourself\nwhat would happen to the method if the value didn’t exist—if\nit were null, or blank, or zero, or an empty string, or an empty\ncollection.\nMany C# library methods will throw an exception of some sort\nwhen faced with non-existent data. The problem is that it’s\nhard to debug a generic runtime exception thrown from the\ndepths of some library. But a speciﬁc exception that reports\n“Age isn’t set” makes tracking down the problem much easier.\nMost methods will blow up if expected data is not available,\nand that’s probably not what you want them to do. So you\ntest for the condition—see what happens if you get a null in-\nstead of a CustomerRecord because some search failed. See\nwhat happens if the ﬁle doesn’t exist, or if the network is un-\navailable.\nAh, yes: things in the environment can wink out of existence\nas well—networks, ﬁles’ URLs, license keys, users, printers,\npermissions that had been ﬁne last time you checked—you\nname it. All of these things may not exist when you expect\n6http://puzzleware.net/nContract/nContract.html\n7There\nare\nother\nefforts\nfor\nother\nlanguages\nas\nwell,\nsuch\nas\nhttp://dbc.rubyforge.org for C and http://icontract2.org for Java.\n",
      "content_length": 1847,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 96,
      "content": "CARDINALITY\n82\nthem to, so be sure to test with plenty of nulls, zeros, empty\nstrings and other nihilist trappings.\nMake sure your method can stand up to everything which,\nfunnily enough, includes nothing.\n5.6\nCardinality\nCardinality has nothing to do with either highly-placed reli-\nCORRE C T\ngious ﬁgures or small red birds, but instead with counting.\nComputer programmers (your humble authors included) are\nreally bad at counting, especially past 10 when the ﬁngers\ncan no longer assist us. For instance, answer the following\nquestion quickly, off the top of your head, without beneﬁt of\nﬁngers, paper, or UML:\nIf you’ve got 12 feet of lawn that you want to fence,\nand each section of fencing is 3 feet wide, how many\nfence posts do you need?\nIf you’re like most of us, you probably answered “4” without\nthinking too hard about it. Pity is, that’s wrong—you need ﬁve\nfence posts as shown in Figure 5.1 on page 84. This model,\nand the subsequent common errors, come up so often that\nthey are graced with the name “fence post errors.”\nIt’s one of many ways you can end up being “off by one;” an\noccasionally fatal condition that afﬂicts all programmers from\ntime to time. So you need to think about ways to test how\nwell your method counts, and check to see just how many of\na thing you may have.\nIt’s a related problem to Existence, but now you want to make\nsure you have exactly as many as you need, or that you’ve\nmade exactly as many as needed. In most cases, the count of\nsome set of values is only interesting in these three cases:\n1. Zero\n2. One\n3. More than one\nIt’s called the “0–1–n Rule,” and it’s based on the premise that\nif you can handle more than one of something, you can prob-\nably handle 10, 20, or 1,000 just as easily. Most of the time\n",
      "content_length": 1758,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 97,
      "content": "CARDINALITY\n83\nthat’s true, so many of our tests for cardinality are concerned\nwith whether we have 2 or more of something. Of course there\nare situations where an exact count makes a difference—10\nmight be important to you, or 260.\n(Why 260?\nThat’s the\ndeﬁned value for MAX_PATH in windows.h, and so turns out\nto be a good boundary condition for ﬁnding string truncation\nand buffer overﬂow issues in underlying native code.)\nSuppose you are maintaining a list of the Top-Ten food items\nordered in a pancake house. Every time an order is taken, you\nhave to adjust the top-ten list. You also provide the current\ntop-ten list as a real-time data feed to the pancake boss’s PDA.\nWhat sort of things might you want to test for?\n• Can you produce a report when there aren’t yet ten items\nin the list?\n• Can you produce a report when there are no items on\nthe list?\n• Can you produce a report when there is only one item on\nthe list?\n• Can you add an item when there aren’t yet ten items in\nthe list (but more than one)?\n• Can you add an item when there is only one item on the\nlist?\n• Can you add an item when there are already ten items\non the list?\n• What if there aren’t ten items on the menu?\n• What if there are no items on the menu?\nHaving gone through all that, the boss now changes his mind\nand wants a top-twenty list instead.\nWhat do you have to\nchange?\nThe correct answer is “one line,” something like the following:\npublic MaxEntries {\nget { return 20; }\n}\nNow, when the boss gets overwhelmed and pleads with you to\nchange this to be a top-ﬁve report (his PDA is pretty small, af-\n",
      "content_length": 1588,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 98,
      "content": "TIME\n84\n12 feet\r\n3 feet\r\n3 feet\r\n3 feet\r\n3 feet\r\n1\r\n5\r\n4\r\n3\r\n2\r\nFigure 5.1: A Set of Fence posts\nter all), you can go back and change this one number. The test\nshould automatically follow suit, because it uses the same\nproperty.\nSo in the end, the tests concentrate on boundary conditions\nof 0, 1, and n, where n can—and will—change as the business\ndemands.\n5.7\nTime\nThe last boundary condition in the CORRECT acronym is\nCORREC T\nTime.\nThere are several aspects to time you need to keep\nin mind:\n• Relative time (ordering in time)\n• Absolute time (elapsed and wall clock)\n• Concurrency issues\nSome interfaces are inherently stateful; you expect that Lo-\ngin() will be called before Logout(), that PrepareState-\nment() is called before ExecuteStatement(), Connect() be-\nfore Read() which is before Close(), and so on.\n",
      "content_length": 817,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 99,
      "content": "TIME\n85\nWhat happens if those methods are called out of order? Maybe\nyou should try calling methods out of the expected order. Try\nskipping the ﬁrst, last and middle of a sequence to ﬁnd these\nkind of temporal dependencies.\nJust as order of data may\nhave mattered to you in the earlier examples (as we described\nin “Ordering” on page 74), now it’s the order of the calling\nsequence of methods.\nRelative time might also include issues of timeouts in the\ncode: how long your method is willing to wait for some ephem-\neral resource to become available.\nAs we’ll discuss shortly,\nyou’ll want to exercise possible error conditions in your code,\nincluding things such as timeouts.\nMaybe you’ve got con-\nditions that aren’t guarded by timeouts—can you think of a\nsituation where the code might get “stuck” waiting forever for\nsomething that might not happen?\nThis leads us to issues of elapsed time. What if something you\nare waiting for takes “too much” time? What if your method\ntakes too much time to return to the caller?\nThen there’s the actual wall clock time to consider. Most of\nthe time, this makes no difference whatsoever to code. But\nevery now and then, time of day will matter, perhaps in subtle\nways. Here’s a quick statement, is it true or false: every day\nof the year is 24 hours long?8\nThe answer is “it depends.”\nIn UTC (Universal Coordinated\nTime, the modern version of Greenwich Mean Time, or GMT),\nthe answer is yes. In areas of the world that do not observe\nDaylight Savings Time (DST), the answer is yes. In most of\nthe U.S. (which does observe DST), the answer is no. In April,\nyou’ll have a day with 23 hours (spring forward) and in Oc-\ntober you’ll have a day with 25 (fall back). This means that\narithmetic won’t always work as you expect; 1:45AM plus 30\nminutes might equal 1:15, for instance.\nBut you’ve tested any time-sensitive code on those boundary\ndays, right? For locations that honor DST and for those that\ndo not?\n8Ignoring leap seconds for now, we’re just talking about whole hours.\n",
      "content_length": 2014,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 100,
      "content": "TRY IT YOURSELF\n86\nOh, and don’t assume that any underlying library handles\nthese issues correctly on your behalf. Unfortunately, when it\ncomes to time, there’s a lot of broken code out there. And leap\nseconds do make a difference.\nFinally, one of the most insidious problems brought about\nby time occurs in the context of concurrency and synchro-\nnized access issues.\nIt would take an entire book to cover\ndesigning, implementing, and debugging multi-threaded, con-\ncurrent programs, so we won’t take the time now to go into de-\ntails, except to point out that most code you write in most lan-\nguages today will be run in a multi-threaded, multi-processor\nenvironment (see the section in on page 187 for an interesting\n“Gotcha” in C#).\nSo ask yourself, what will happen if multiple threads use this\nsame object at the same time? Are there global or instance-\nlevel data or methods that need to be synchronized?\nHow\nabout external access to ﬁles or hardware? Be sure to add\nthe lock keyword to any property or method that needs it,\nand try ﬁring off multiple threads as part of your test.\n5.8\nTry It Yourself\nNow that we’ve covered the Right-BICEP and CORRECT way\nto come up with tests, it’s your turn to try.\nFor each of the following examples and scenarios, write down\nas many possible unit tests as you can think of.\nExercises\n1.\nA simple stack class.\nPush String objects onto the stack,\nAnswer\non 196\nand Pop them off according to normal stack semantics. This\nclass provides the following methods:\nusing System;\npublic interface StackExercise {\n/// <summary>\n/// Return and remove the most recent item from\n/// the top of the\nstack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n",
      "content_length": 1739,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 101,
      "content": "TRY IT YOURSELF\n87\n/// </exception>\nString Pop();\n/// <summary>\n/// Add an item to the top of the stack.\n/// </summary>\n/// <param name=\"item\">A String to push\n/// on the stack</param>\nvoid Push(String item);\n/// <summary>\n/// Return but do not remove the most recent\n/// item from the top of the stack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n/// </exception>\nString Top();\n/// <summary>\n/// Returns true if the stack is empty.\n/// </summary>\nbool IsEmpty();\n}\nStackExercise.cs\nHere are some hints to get you started: what is likely to break?\nHow should the stack behave when it is ﬁrst initialized? After\nit’s been used for a while? Does it really do what it claims to\ndo?\n2.\nA shopping cart. This class lets you add, delete, and count\nAnswer\non 197\nthe items in a shopping cart.\nWhat sort of boundary conditions might come up? Are there\nany implicit restrictions on what you can delete? Are there any\ninteresting issues if the cart is empty?\npublic interface ShoppingCart {\n/// <summary>\n/// Add this many of this item to the\n/// shopping cart.\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\nvoid AddItems(Item anItem, int quantity);\n/// <summary>\n/// Delete this many of this item from the\n/// shopping cart\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\n/// <exception cref=\"NoSuchItemException\">\n/// </exception>\nvoid DeleteItems(Item anItem, int quantity);\n",
      "content_length": 1498,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 102,
      "content": "TRY IT YOURSELF\n88\n/// <summary>\n/// Count of all items in the cart\n/// (that is, all items x qty each)\n/// </summary>\nint ItemCount { get; }\n/// Return iterator of all items\nIEnumerable GetEnumerator();\n}\nShoppingCart.cs\n3.\nA fax scheduler. This code will send faxes from a speciﬁed ﬁle\nAnswer\non 198\nname to a U.S. phone number. There is a validation require-\nment; a U.S. phone number with area code must be of the form\nxnn-nnn-nnnn, where x must be a digit in the range [2..9] and\nn can be [0..9]. The following blocks are reserved and are not\ncurrently valid area codes: x11, x9n, 37n, 96n.\nThe method’s signature is:\n///\n/// Send the named file as a fax to the\n/// given phone number.\n/// <exception cref=\"MissingOrBadFileException\">\n/// </exception>\n/// <exception cref=\"PhoneFormatException\">\n/// </exception>\n/// <exception cref=\"PhoneAreaCodeException\">\n/// </exception>\npublic bool SendFax(String phone, String filename)\nGiven these requirements, what tests for boundary conditions\ncan you think of?\n4.\nAn automatic sewing machine that does embroidery. The\nAnswer\non 199\nclass that controls it takes a few basic commands.\nThe co-\nordinates (0,0) represent the lower-left corner of the machine.\nx and y increase as you move toward the upper-right corner,\nwhose coordinates are x = TableSize.Width - 1 and y = Ta-\nbleSize.Height - 1.\nCoordinates are speciﬁed in fractions of centimeters.\npublic void MoveTo(double x, double y);\npublic void SewTo(double x, double y);\npublic void SetWorkpieceSize(double width,\ndouble height);\npublic Size WorkpieceSize { get; }\npublic Size TableSize { get; }\nThere are some real-world constraints that might be interest-\ning: you can’t sew thin air, of course, and you can’t sew a\nworkpiece bigger than the machine.\n",
      "content_length": 1758,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 103,
      "content": "TRY IT YOURSELF\n89\nGiven these requirements, what boundary conditions can you\nthink of?\n5.\nAudio/Video Editing Transport. A class that provides meth-\nAnswer\non 200\nods to control a VCR or tape deck.\nThere’s the notion of a\n“current position” that lies somewhere between the beginning\nof tape (BOT) and the end of tape (EOT).\nYou can ask for the current position and move from there to\nanother given position. Fast-forward moves from current posi-\ntion toward EOT by some amount. Rewind moves from current\nposition toward BOT by some amount.\nWhen tapes are ﬁrst loaded, they are positioned at BOT auto-\nmatically.\nusing System;\npublic interface AVTransport {\n/// Move the current position ahead by this many\n/// seconds. Fast-forwarding past end-of-tape\n/// leaves the position at end-of-tape\nvoid FastForward(double seconds);\n/// Move the current position backwards by this\n/// many seconds. Rewinding past zero leaves\n/// the position at zero\nvoid Rewind(double seconds);\n/// Return current time position in seconds\ndouble CurrentTimePosition();\n/// Mark the current time position with label\nvoid MarkTimePosition(String name);\n/// Change the current position to the one\n/// associated with the marked name\nvoid GotoMark(String name);\n}\nAVTransport.cs\n6.\nAudio/Video Editing Transport, Release 2.0. As above, but\nAnswer\non 201\nnow you can position in seconds, minutes, or frames (there are\nexactly 30 frames per second in this example), and you can\nmove relative to the beginning or the end.\n",
      "content_length": 1493,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 104,
      "content": "Chapter 6\nUsing Mock Objects\nThe objective of unit testing is to exercise just one behav-\nior at a time, but what happens when the method contain-\ning that behavior depends on other things—hard-to-control\nthings such as the network, or a database, or even special-\nized hardware?\nWhat if our code depends on other parts of the system—maybe\neven many other parts of the system? If you’re not careful,\nyou might ﬁnd yourself writing tests that end up (directly or\nindirectly) initializing nearly every system component just to\ngive the tests enough context in which to run. Not only is this\ntime consuming, it also introduces a ridiculous amount of\ncoupling into the testing process: someone goes and changes\nan interface or a database table, and suddenly the setup code\nfor our poor little unit test dies mysteriously. With this kind of\ncoupling, sometimes simply adding a new test can cause other\ntests to fail. Even the best-intentioned developers will become\ndiscouraged after this happens a few times, and eventually\nmay abandon all testing.\nBut there are techniques we can\nuse to help.\nIn movie and television production, crews will often use stand-\nins or doubles for the real actors.\nIn particular, while the\ncrews are setting up the lights and camera angles, they’ll\nuse lighting doubles: inexpensive, unimportant people who\nare about the same height and complexion as the expensive,\nimportant actors lounging safely in their luxurious trailers.\n",
      "content_length": 1453,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 105,
      "content": "CHAPTER 6. USING MOCK OBJECTS\n91\nThe crew then tests their setup with the lighting doubles,\nmeasuring the distance from the camera to the stand-in’s\nnose, adjusting the lighting until there are no unwanted shad-\nows, and so on, while the obedient stand-in just stands there\nand doesn’t whine or complain about “lacking motivation” for\ntheir character in this scene.\nSo what we’re going to do in unit testing is similar to the use\nof lighting doubles in the movies: we’ll use a cheap stand-in\nthat is kind of close to the real thing, at least superﬁcially, but\nthat will be easier to work with for our nefarious unit testing\npurposes.\nFortunately, there’s a testing pattern that can help: mock ob-\njects.\nA mock object is simply a testing replacement for a\nreal-world object. There are a number of situations that come\nup where mock objects can help us. Tim Mackinnon [MFC01]\noffers the following list:\n• The real object has nondeterministic behavior (it pro-\nduces unpredictable results, like a stock-market quote\nfeed.)\n• The real object is difﬁcult to set up, like requiring a cer-\ntain ﬁle system, database, or network environment.\n• The real object has behavior that is hard to trigger (for\nexample, a network error).\n• The real object is slow.\n• The real object has (or is) a user interface.\n• The test needs to ask the real object about how it was\nused (for example, a test might need to conﬁrm that a\ncallback function was actually called).\n• The real object does not yet exist (a common problem\nwhen interfacing with other teams or new hardware sys-\ntems).\nUsing mock objects, we can get around all of these problems.\nThe three key steps to using mock objects for testing are:\n1. Use an interface to describe the relevant methods on the\nobject\n",
      "content_length": 1752,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 106,
      "content": "STUBS\n92\n2. Implement the interface for production code\n3. Implement the interface in a mock object for testing\nThe code under test only ever refers to the object by its inter-\nface or base class, so it can remain blissfully ignorant as to\nwhether it is using the real object or the mock. Sometimes\nthere’s a simpler solution to getting on with our testing, so\nlet’s explore that ﬁrst.\n6.1\nStubs\nWhat we need to do is stub out, or fake, all those uncoop-\nerative parts of the real world and replace them with more\ncomplicit allies—our own version of “lighting doubles.” For ex-\nample, stubs allow us to fake our interaction with a database\nor the ﬁlesystem.\nIn many cases, stubs just implement an interface and return\ndummy values for the methods in said interface.1\nIn even\nsimpler cases, all the implemented methods in the stub just\nthrow a NotImplementedException.2\nA common scenario is when there is a class that encapsulates\ndatabase access, but we don’t want to actually conﬁgure and\npopulate a database to run simple tests.\npublic class MySqlCustomerRepository\n{\npublic string FindBy(long id)\n{\nxxxx xx xxxxx\n}\n}\nFirst, we extract an interface for the methods we need to stub\nand apply that interface to the class we want to mock:\npublic interface CustomerRepository\n{\nstring FindBy(long id);\n}\n1Note that while you can also derive from an abstract class, interfaces are\npreferred.[?]\n2Most IDEs will ﬁll in this exception for you when told to automatically\nimplement the methods for an interface.\n",
      "content_length": 1505,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 107,
      "content": "STUBS\n93\npublic class MySqlCustomerRepository : CustomerRepository\n{\npublic string FindBy(long id)\n{\nxxxx xx xxxxx\n}\n}\nThen we can return the dummy value that we think will evoke\nthe behaviour we want from the ProductAdoptionService.\npublic class StubCustomerRepository : CustomerRepository\n{\npublic string FindBy(long id)\n{\nreturn string.Empty;\n}\n}\nWe put the code for this stub class in the same ﬁle as the test\nﬁxture class that will be using it, until we need to move it to a\nmore general area where other test ﬁxture classes can access\nit. Then we plug in the stub to our unit test like so:\nnamespace WebCRM.Test.ProductAdoptionTest\n{\n[TestFixture]\npublic class NoDataFixture\n{\n[Test]\npublic void OverallRateIsZero()\n{\nStubCustomerRepository customerRepository =\nnew StubCustomerRepository();\nProductAdoptionService service =\nnew ProductAdoptionService(customerRepository);\nAssert.That(service.GetPercentage(), Is.EqualTo(0));\n}\n}\n}\nIf we’re lucky, our test might now pass and we didn’t have\nto touch a database. In fact, this test could have been writ-\nten before there was ever a schema design, database vendor\ndebate, or anything else. By programming to interfaces, we\nwere able to plug in what we needed without depending on\npoliticking or other non-coding activities that can slow down\na project. Note that we not only get to verify the code being\ntested produces the results that we want, but we also get to\n",
      "content_length": 1419,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 108,
      "content": "FAKES\n94\nverify that it interacts with the stubbed class in the way we\nexpect. More on that later.\n6.2\nFakes\nSometimes we need to do more than return dummy values to\nget at the code we’re trying to test. What if we have ﬁles on\nthe ﬁlesystem that conform to a certain format and we want\nto test that we’re parsing them correctly?\npublic class DumpFileParser\n{\nFileStream stream;\npublic DumpFileParser(string fileName)\n{\nstream = File.Open(fileName);\n}\nxxxx xxx xxxx\n}\nThe code above requires a real ﬁle on the ﬁle system in order\nto be tested. This can put an unnecessary ﬁlesystem layout\nburden on the person running the tests, and the disk I/O\nwill slow down the tests.3 What can we do in a situation like\nthis to make it easier to test?\nThe class actually discards\nthe supplied ﬁlename after the constructor and just operates\non the resulting stream.\nWe’ll look at a suboptimal way of\nmaking it more testable, then a more optimal way. It’s good\nto understand what the evils in the world are so that we don’t\naccidentally end up evoking any of them.\nWhat if we used #define to tell the code when we were test-\ning, then it wouldn’t use the ﬁlesystem.\npublic class DumpFileParser\n{\nFileStream stream;\npublic DumpFileParser(string fileName)\n{\n#if TESTING\nstream = new MemoryStream();\n#else\nstream = File.Open(fileName);\n#endif\n3This doesn’t seem like a big deal, but little slowdowns like this add up\nquickly.\n",
      "content_length": 1410,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 109,
      "content": "FAKES\n95\n}\nxxxx xxx xxxx\n}\nMemoryStream is a nifty class in the .NET class library that\nallows us to make, as you may have guessed, an in-memory\nstream. Now we have a real Stream-derived object that the\nclass can interact with, and it doesn’t touch the ﬁlesystem.\nBefore we get too far ahead of ourselves, though, we have to\nrealise that an empty stream has limitations. First, an empty\nstream doesn’t really help us if we need to read data from\nthat stream. Many of the tests we write will probably want to\nsupply different data via the stream to make sure the parser\nbehaves correctly.\nWe could ﬁgure out various ways to get\nsome test data into place in this scenario, but this approach\nworks around the fact that the code wants the stream to be\nparameterized; our attempt to test this code has illuminated\nthis. Third, #if statements strewn throughout the code for\ntesting purposes are difﬁcult to maintain. And, in our opinion,\nthey’re ugly as well.\nIt might also be tempting to just add an empty constructor to\neliminate the need for any of this deep thinking. While this\nwould “work” in a very narrow sense, there’s a good reason\nthere wasn’t an empty constructor in the ﬁrst place: without\nthe Stream being created, the object isn’t in a valid state. In\nthis case, invalid state means a probable NullReferenceEx-\nception whenever we try to do anything with the object. Ob-\njects being in a valid state after construction is a core object-\noriented design principle, and ignoring it is not the right thing\nto do in this case. Tests can help drive improvements to the\ncode’s design, but this particular example isn’t one of them.\nNow that we’ve discussed what won’t work, what will work?\nWhat if we shifted the responsibility of actually getting the\nFileStream to the clients and passed in a FileStream in-\nstead?\nDoing this transformation would resolve the design\nfeedback we’re getting from testing this in the ﬁrst place.\npublic class DumpFileParser\n{\nStream stream;\npublic DumpFileParser(Stream dumpStream)\n{\n",
      "content_length": 2018,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 110,
      "content": "FAKES\n96\nthis.stream = dumpStream;\n}\nxxxx xxx xxxx\n}\nThis isn’t bad at all. Now the consumers of the class, includ-\ning the tests, could perform the File.Open() and pass in a\nFileStream. It may seem like we’re just moving the problem\naround, but we needed to do that to get to the next step. The\nnext step is to make our code a little more shy; speciﬁcally,\nto make it more liberal in what it will accept. In this case, we\naren’t using any methods speciﬁc to FileStream, so we can\nactually accept the base class, Stream, instead.\nWhat does that get us? Well, in our tests we can now use the\nspiffy MemoryStream class, like so:\n[TestFixture]\npublic class DumpFileParserTest\n{\nprivate StreamWriter writer;\nprivate DumpFileParser parser;\nprivate MemoryStream stream;\n[SetUp]\npublic void SetUp()\n{\nstream = new MemoryStream();\nwriter = new StreamWriter(stream);\n}\n[Test]\npublic void EmptyLine()\n{\nwriter.WriteLine(string.Empty);\nparser = new Parser(stream);\nAssert.That(xxxx, xxxx);\n}\n}\nPresto! An instant pseudo-text-ﬁle that you can also use to\nwrite binary data. Since this operates in-memory, you won’t\nincur the performance penalty of disk I/O.4 Now we can do the\ntesting we need, quickly and conveniently. A nice side effect\nis that our code is shyer, yielding a more ﬂexible design that\nis easier to reuse. One could say that changing the parameter\nto a Stream was a change strictly for the sake of testing and\n4Note that this technique works just as well with Sockets and other\nstream-based I/O as well.\n",
      "content_length": 1508,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 111,
      "content": "FAKES\n97\nthat observation would be somewhat correct. The other side\nof the story is that by not programming against a concrete\nimplementation, the code now has a more ﬂexible design. We\nwere led to this by refactoring a very little bit to make things\neasier to test. This kind of design feedback is the real magic\nof unit testing, but this is only one simple example.\nFaking collaberators\nThe DumpFileParser class we were just working on does some\npretty complicated collation of the data in the stream. If an-\nother class depends on DumpFileParser, we don’t want to\nmake the entire fake stream necessary for it to produce the\ndata we’re trying to test our other class against. Besides the\nfact that it would be really tedious, it adds a whole new di-\nmension of coupling and maintenance to the test code.\nIf\nwe used a real DumpFileParser while testing a collaberat-\ning class, we’re increasing the work we have to do if Dump-\nFileParser changes or gets removed.\nThat doesn’t sound very pragmatic, so how do we decou-\nple DumpFileParser from the tests of a class that requires\na DumpFileParser? It’s actually very similar to our initial ex-\nample – we need to abstract things up a level, then we can\nsupply a variation on DumpFileParser that returns whatever\ndummy values we need for the purpose of testing the other\nobject. This is known in some circles as creating a fake, and\nin other circles as a static mock. Let’s look at some code.\npublic class Analyzer\n{\nprivate DumpFileParser parser;\nprivate List<string> reportItems;\npublic Analyzer(DumpFileParser parser)\n{\nthis.parser = parser;\n}\npublic bool ExpectationsMet\n{\nget\n{\nreturn parser.ReportItems.Count == reportItems.Count;\n}\n}\npublic byte[] GetNextInstruction()\n",
      "content_length": 1722,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 112,
      "content": "FAKES\n98\n{\nxxxxxxxxx\n}\n}\nIf we wanted to test the ExpectationsMet property, the Re-\nportItems property on parser will need to be under our con-\ntrol so we can make it return what we want. One way would\nbe to make the ReportItems property on DumpFileParser\nvirtual. We could then subclass and override it for our test-\ning purposes, and pass an instance of said subclass into the\nconstructor for Analyzer. While that would work, there’s a\nbetter way that yields a more ﬂexible, and interface-oriented,\ndesign: extract an interface called Parsable that contains,\nfor the time being, a declaration for the ReportItems property\ngetter.\npublic interface Parsable\n{\nList<string> ReportItems\n{\nget;\n}\n}\nThen, we can make DumpFileParser implement the Parsable\ninterface.\nNext, we change the Analyzer constructor’s pa-\nrameter from DumpFileParser to Parsable. Last, we change\nthe parser ﬁeld in Analyzer from DumpFileParser concrete\nclass to be the Parsable interface that DumpFileParser now\nimplements.\nWhen we try to compile, the compiler might\ntell us that we’re using some methods not deﬁned on the\nParsable interface. We’ll need to add those methods to the\ninterface as well.\npublic DumpFileParser : Parsable\n{\nxxxxxxx\n}\npublic class Analyzer\n{\nprivate Parsable parser;\nprivate List<string> reportItems;\npublic Analyzer(Parsable parser)\n{\nthis.parser = parser;\n}\nxxxxxxxx\n}\n",
      "content_length": 1370,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 113,
      "content": "FAKES\n99\nNone of the existing consumers of Analyzer have to change,\nand yet, we have just made Analyzer easier to test and reuse.\nIf in the future we wanted to add the ability to parse another\nﬁle format, Analyzer itself wouldn’t have to change to acco-\nmodate the extra functionality—only the consumers would by\npassing in a new class that implements the Parsable inter-\nface.\nThis is a good example of the advantage of interface-based\ndesign, but the point worth mentioning again is that we ar-\nrived at this better design by refactoring toward testability.\nBesides being more testable and reusable, it also means that\nwe don’t need to wait for another set of programmers to ﬁn-\nish implementing the concrete class that our class might be\ncollaborating with. We can fully unit test our class by faking\nthe collaberator’s interface, which generally makes integrat-\ning with the concrete classes developed by others (or even our\nfuture selves) signiﬁcantly less painful.5\nFakes are great, especially when they’re simple, but it’s also\neasy to outgrow them; like when we need to do more than re-\nturn a single value, for instance. At some point, we want to re-\nturn values in a certain order each time a method is called. To\naccomplish this with a fake, we would need to track a Stack\nof return values for a given method.\npublic FakeParser : Parsable\n{\nprivate Stack<byte[]> bytesToReturn;\npublic Stack<byte[]> BytesToReturn\n{\nget { return bytesToReturn; }\nset { bytesToReturn = value; }\n}\npublic Boolean ExpectationsMet\n{\nget { return false; }\n}\npublic Byte[] GetNextInstruction()\n{\nreturn BytesToReturn.Pop();\n}\n}\n5In many cases, the usually pandemonious step of integration just works.\n",
      "content_length": 1688,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 114,
      "content": "MOCK OBJECTS\n100\nWhile this would work and is a clever way to make a pro-\ngrammable fake, we risk repeating ourselves because we\nwould end up doing this for most methods on our fake. It also\ngets a little more hairy when we have to make them throw spe-\nciﬁc exceptions at certain points to test failure modes. Surely,\nthere must be a better way.6\n6.3\nMock Objects\nIn the old days, just having the ability to call subroutines was\na great advance.\nThen libraries of code became popular—\neverything had to be library. Nowadays, libraries aren’t good\nenough. You’ve got to have a framework to be taken seriously.\nIn the case of .NET, there are several alternative mock ob-\nject frameworks to choose from (a good list can be found\nat http://www.mockobjects.com). NUnit includes its own\nbuilt-in framework that the NUnit team uses to test NUnit\nitself. NUnit’s mock framework doesn’t provide all of the fea-\ntures of some other frameworks, so we’ll look at a few other\nframeworks as well. But before we do, it’s worth noting that\nbecause we’re in .NET’s CLR environment, this same frame-\nwork can be used to mock objects for any code written in\nany language compliant with the Common Language Speciﬁ-\ncation.\nNUnit Mocks\nWhen you think about it, there’s really not too much to a mock\nobject: it’s simply an object that implements a particular in-\nterface, returns values we want it to return, and checks that it\nwas used in a certain way. As a result, the basic frameworks\nfor creating mock objects are also simple.\nIn the previous section, we saw what we would have to\ngo through to have our fake be somewhat programmable\nand return multiple values for a given method call.\nHere\nis how we would do this using NUnit’s mock framework.\n6Never call us Shirley.\n",
      "content_length": 1752,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 115,
      "content": "MOCK OBJECTS\n101\nNote that to compile this code, we’ll have to add a refer-\nence to the nunit.mocks.dll assembly in addition to the\nnunit.framework.dll reference.\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\nusing NUnit.Mocks;\n[TestFixture]\npublic class AnalyzerTest\n{\nAnalyzer analyzer;\nParsable parser;\n[Test]\npublic void NoBytes()\n{\nDynamicMock controller =\nnew DynamicMock(typeof(Parsable));\nparser = controller.MockInstance as Parsable;\nanalyzer = new Analyzer(parser);\ncontroller.ExpectAndReturn(\n\"GetNextInstruction\",// method name\nnew byte[] {},\n// return value\nnull\n// expected arguments\n);\ncontroller.ExpectAndReturn(\n\"get_ExpectedReportItems\",\nnew List<string>(),\nnull\n);\nanalyzer.Run();\ncontroller.Verify(); // fails the test if expecta-\ntions are unmet\nAssert.That(analyzer.ReportItems, Is.Empty);\n}\n}\nMock object frameworks make it very easy to set multi-\nple method call expectations, with or without accompany-\ning dummy values that should be returned, with or without\nthrowing exceptions, etc. In the code above, we ﬁrst instan-\ntiate a DynamicMock object, passing the Parsable interface’s\ntype into the constructor. We can only create a DynamicMock\nfor interfaces or classes that derive from MarshalByRefOb-\nject. We highly recommend extracting interfaces whenever\npossible, not only for the reasons previously discussed in this\nchapter, but also because of the complex implications of using\nMarshalByRefObject.[Ric06]\n",
      "content_length": 1452,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 116,
      "content": "MOCK OBJECTS\n102\nThere’ll be times when we need to test something that uses an\nexisting interface and there are no pre-written mock objects\nlying around. Often, we can just jump right on in and create\na new mock object. But what if the interface that we’re mock-\ning is enormous, with dozens of methods and accessors? That\ncould mean a lot of work producing a mock object that imple-\nments the interface. This is particularly galling if we only need\none or two methods from the interface to run our tests, and\nwe can’t refactor to break up the interface for some reason.\nThis is where dynamic mock objects come in.\nThey let us\ncreate an object that responds as if it implemented a full in-\nterface, but in reality it is totally generic. You only need to tell\nthis object how to respond to the method calls that our code\nuses. This can represent a considerable saving in time. It’ll\nalso give you less code to maintain in the future.\nThe dynamic mock packages operate by creating proxy objects\nin the underlying implementation. These are objects that are\ndesigned to stand in for their real-world counterparts. In the\ndynamic mock object context, this means that we can use\na proxy in place of a real object in our tests.\nHowever, we\nstill need to be able to control this generated proxy object—we\nneed to be able to tell it how to respond. This is where the\ncontroller comes in.\nThe controller is in charge of a dynamic mock object. You use\nthe controller to create an instance of the mock and to tell the\nmock what to do. Sometimes the controller is told directly,\nlike in NUnit’s mocks, sometimes indirectly as in the NMock2\nframework, which we’ll discuss later in the chapter.\nOnce the mock is created, we pass it in to the real object that\nwe are testing the interaction with. If our interaction testing\nwasn’t constrained to the Run() method, we would program\nthe mock before we passed it into the constructor for Ana-\nlyzer. Since we’re focusing on testing the interaction after\nRun() is called, we start programming it with our expecta-\ntions right before the call to run, since this expresses our\nintentions clearly. To put it another way, we don’t want to\nprogram all the expectations for our mock in a big clump that\nis difﬁcult to read and understand.\nIn the code above, the\nexpectations we set are:\n",
      "content_length": 2311,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 117,
      "content": "MOCK OBJECTS\n103\n1. The method name\n2. The value, if any, that will be returned when the mocked\nmethod is called\n3. The speciﬁc arguments, if any, we expect the mocked\nmethod to be called with.\nAfter creating the mock, we tell it to expect a call to Get-\nNextInstruction(), and to return an empty byte array.\nThe ﬁnal null parameter indicates that there are no speciﬁc\nmethod argument expectations. In this case, the method in\nquestion doesn’t have any parameters, but we can also sup-\nply null when we just don’t care. In our experience, checking\nspeciﬁc arguments supplied to the mocked method is usually\nnot necessary because that level of detail usually isn’t neces-\nsary to express the intention of the interaction we’re testing.\nNext, we tell the mock to expect a call to the getter for the Ex-\npectedReportItems property. Note that we had to prepend\n“get_” to the property name.7 In the context of this applica-\ntion, a parser having no bytes also means it should also not\nhave any expected report items.\nWe then get our mock object via the MockInstance property.\nBecause NUnit’s mock framework doesn’t take advantage of\ngenerics, we have to cast it—hence the use of the as operator.\nAt that point, we can treat that instance like the real object\nas long as we use it only in the way we programmed it. One\nway to think about it is the framework provides a kind of API-\nlevel record-and-playback mechanism. If we didn’t “record”\nthe method calls, the mock can’t play them back.\nBy default, the DynamicMock operates fairly loosely. Just by\ntelling the mock to expect the method call once, it will happily\ndo whatever we told it to do even if the method is called mul-\ntiple times. It also doesn’t care about the order in which the\nexpected methods are called by default. While we sometimes\ndon’t care about that level of detail, and that makes this de-\nfault behaviour quite nice, it’s a good idea to be vigilant when\npractical.\n7For more details on the inner workings of properties, see [Ric06].\n",
      "content_length": 2002,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 118,
      "content": "MOCK OBJECTS\n104\nWhen we want that vigilance, we can set the Strict property\non the mock to true. One of the things the strict ﬂag does\nis that the mock will fail the test immediately if something\nhappens that the mock wasn’t expecting. If we’re not using\nstrict mode, then we need to ask the mock to Verify() that\nall the expectations were met. The Verify method acts as a\nkind of assertion. If anything we expected didn’t happen, the\nveriﬁcation will fail. Since the veriﬁcation generally happens\nat the end of the test, it can sometimes be difﬁcult to track\ndown where things went wrong.\nThis is another reason to\nprefer the strict mode on the mock, if practical.\nNote that the ExpectAndReturn methods take the method\nname as a string parameter. This introduces a gotcha where\nif you rename the method in the code, but not in the mock\nexpectation, the mock will throw an exception. Other frame-\nworks, which we’ll discuss later in this chapter, improve upon\nthis limitation.\nSome of the other expectations we can set using NUnit’s Dy-\nnamicMock include:\n• ExpectNoCall(string methodName), which will cause\nveriﬁcation to fail if the method supplied is called. If the\nmock is in strict mode, the test will fail immediately if\nspeciﬁed method is called.\n• ExpectAndThrow(string methodName, Exception\nexception, params object[] args), which operates\nthe same as ExpectAndReturn, except the exception\nspeciﬁed is thrown.\nThis is great for making sure\nyour exception handling interaction between classes is\nrock-solid, and stays that way.\n• SetReturnValue(string methodName, object re-\nturnValue),\nwhich\nwill\nalways\nreturn\nthe\nvalue\nspeciﬁed no matter how many times the method in\nquestion is called. We generally don’t recommend using\nthis, as it can cover up the very interaction feedback\nthat mocks are so good at giving us.\nFor more information check out NUnit’s documentation or\njust explore a bit with a method-completing code editor.\n",
      "content_length": 1939,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 119,
      "content": "MOCK OBJECTS\n105\nNMock2 Framework\nNMock2,8 which is based on jMock for Java,9 inspired NUnit’s\nnew style of constraint-based assertions. It is meant to pro-\nvide a more concise and easily readable syntax in contrast to\nother mock frameworks. Since we use unit tests as documen-\ntation for our code, it’s important that the conﬁguration of our\nmocks be easy to read and understand. In that vein, NMock’s\nsyntax reads from left to right, albeit with a syntax that might\nlook a bit strange at ﬁrst.\nusing NUnit.Framework;\nusing NMock2;\n[TestFixture]\npublic class AnalyzerTest\n{\nAnalyzer analyzer;\nParsable parser;\nMockery mockery;\n[Test]\npublic void NoBytes()\n{\nmockery = new Mockery();\nparser = mocks.NewMock<Parsable>();\nanalyzer = new Analyzer(parser);\nExpect.Once.On(parser)\n.Method(\"GetNextInstruction\")\n.Will(Return.Value(new byte[] {}));\nExpect.Once.On(parser)\n.GetProperty(\"ExpectedReportItems\")\n.Will(Return.Value(new List<string>()));\nanalyzer.Run();\nmockery.VerifyAllExpectationsHaveBeenMet();\nAssert.That(\nanalyzer.ReportItems,\nnew EmptyConstraint()\n);\n}\n}\nThis code is equivelant to the code from the previous subsec-\ntion that was written using NUnit’s mocks. First, we create a\nMockery object. Mockery acts as a factory for mock objects,10\nvia the NewMock<T>() generic method. Because it is a generic\n8http://nmock.org\n9http://jmock.org\n10Mocks + Factory = Mockery, get it?\n",
      "content_length": 1386,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 120,
      "content": "MOCK OBJECTS\n106\nmethod, whatever type we parameterize it with is the type it\nwill return. This allows us to avoid the casting we had to do\nin NUnit’s mocks.11 Note that the use of a generic method is\na C# 2.0 feature, so NMock2 can’t be used on a project that\nstrictly uses an earlier C# version. The Mockery object also\nkeeps track of the expectations we are setting.\nWe then set up the expectations. Remember, we only program\nthe mock with the minimal number of expectations we need\nto test the interaction triggered by the speciﬁc method. We\nwant this to read like a conversation between the mock and\nthe real object, from A to B and back again. We expect that,\nonly once, the parser’s GetNextInstruction method will be\ncalled, and it will return an empty byte array.\nUnder the\ncovers, the expectations are communicated to the Mockery\nobject, which created the Parser mock in the ﬁrst place.\nTo our subjective eyes, NMock2 reads a bit more easily than\nother frameworks. It allows us to focus on only the aspects\nthat we care about.\nOn the other hand, NUnit’s mocks re-\nquire us to always provide the arguments we are expecting;\nwe have to supply null to tell it we don’t have any argu-\nment expectations.\nIn NMock2, we only add the argument\nconstraint matcher if we actually need it by adding .With(x)\nto the chain. This extra ﬂexibility seems small, but it adds up\nto test code that is easier to maintain.\nOne major caveat to note is that we can no longer use NUnit’s\nAssertionHelpers namespace, which gave us Is and Has,\namongst other nice things, because NMock2 also deﬁnes\nclasses with those names. We’re not using them in this ex-\nample, because they relate to argument matching. Because of\nthis conﬂict, we’re using new EmptyConstraint() instead of\nthe usual Is.Empty. We could also substitute in the classic-\nstyle assertion, CollectionAssert.IsEmpty().\nHopefully\nthis namespace issue will be resolved in future versions so\nwe can use the advantages of both.\n11The NUnit 2.4 team purposefully restrained themselves to only using C#\n1.1 features so it could be more widely used.\n",
      "content_length": 2089,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 121,
      "content": "MOCK OBJECTS\n107\nJoe Asks. . .\nHow do I mock singletons?\nWith\ndesign\npatterns\nbecoming\npopular,\nmany\nprojects have various patterns implemented as part\nof their design. One of the most commonly misunder-\nstood patterns is the Singleton. Unfortunately, it is usu-\nally mis-implemented in such a way that introduces\nglobal state, which in turn introduces a large amount\nof temporal coupling, hidden dependencies, and ex-\ntremely difﬁcult debugging. Many times, a singleton\nisn’t even necessary, but it can be a tempting way to\ncheat through actually improving the design.\nIn the next section, we show how to test around a us-\nage of DateTime.Now, which is a static global, just\nlike a singleton class can be. The key is to extract an\ninterface for the methods actually used by the con-\nsumers of the singleton class, and then extract a pa-\nrameter from the class or method that accepts the\ninterface for the singleton. From that point, you can\ncreate a mock from the extracted interface and pass\nin the mock via the parameter.\nEven if you aren’t unit testing, this is the standard set of\nrefactorings for loosening the hangman’s knot of sin-\ngletons that many projects get themselves into. Once\nyou see the real dependencies you have with the vis-\nibility of the extracted parameters, you’ll have the in-\nformation for genuinely improving our design instead\nof working around it. When applying this design feed-\nback, you may ﬁnd that the singleton is simply no\nlonger necessary.\n",
      "content_length": 1478,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 122,
      "content": "MOCK OBJECTS\n108\nRhinoMock\nThere’s a third option in the world of mock frameworks\nthat some of our reviewers asked us to mention, Rhi-\nnoMock.a RhinoMock primarily distinguishes itself by\nnot relying upon strings to specify the method that ex-\npectations will be set on. It is this simple feature that\nmakes it work more easily with code completion and\nrefactoring capabilities in modern IDEs.\nEach framework has advantages and disadvan-\ntages, which one you end up applying on your\nproject is a matter of preference and practicality. We\ndo encourage you to try a couple before settling,\nthough.\nahttp://www.ayende.com/projects/rhino-mocks.aspx\nDotNetMock Framework\nSome objects are difﬁcult to set up mocks for, regardless of\nthe framework, due to the complexity and girth of their inter-\nfaces. ASP.NET and ADO.NET objects can be fairly difﬁcult,\nin particular. In these cases, a library of static mocks that\nare engineered speciﬁcally for common unit testing scenarios\ncan come in handy.\nTo meet this need, the DotNetMock12\nframework is actually three things in one:\n1. It’s a framework (not surprisingly), allowing us to create\nmock objects in a structured way.\n2. It contains a (small) set of predeﬁned mock objects that\nwe can use out of the box to test our application.\n3. Finally, it comes with a technology, dynamic mocks, that\nlet’s us construct mock objects without all that messy\ncoding.\nWe recommend using one of the aforementioned mock object\nframeworks for standard mock program-activities, and Dot-\nNetMock for when you need to mock one of the messier frame-\n12http://dotnetmock.sourceforge.net\n",
      "content_length": 1611,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 123,
      "content": "MOCK OBJECTS\n109\nwork classes. As such, we’re only going to cover the library of\nmocks that DotNetMock comes with.\nSupplied Mock Objects\nOne of the nice things about using a standardized frame-\nwork for testing is that we can start to build a library of\nstandard mock objects and reuse these across projects.\nIn\nfact, in the open source world, you might even ﬁnd that other\nfolks have mocked up the interfaces that you need and made\nthem freely available. The DotNetMock package comes with\na (small) number of these off-the-shelf mock object packages,\navailable in DotNetMock.Framework. While DotNetMock’s li-\nbrary of predeﬁned mocks hasn’t been updated for .NET 2.0\nat the time of this writing, it’s still very useful if you’re using\n.NET 1.1 APIs. Here we’ll look at one of these, Data, which\nimplements many of the interfaces in .NET’s System.Data.\nLet’s start by implementing more of our access controller. Af-\nter verifying that a password has been supplied, we’ll now go\nto a database table and verify that a row exists giving this\nuser, identiﬁed with the given password, access to our re-\nsource.\nusing System;\nusing System.Data;\nusing System.Data.SqlClient;\npublic class AccessController1 {\nprivate ILogger\nlogger;\nprivate String\nresource;\nprivate IDbConnection conn;\npublic static readonly String CHECK_SQL =\n\"select count(*) from access where \" +\n\"user=@user and password=@password \" +\n\"and resource=@resource\";\npublic AccessController1(String resource,\nILogger logger,\nIDbConnection conn) {\nthis.logger\n= logger;\nthis.resource = resource;\nthis.conn\n= conn;\nlogger.SetName(\"AccessControl\");\n}\npublic bool CanAccess(String user, String password) {\nlogger.Log(\"Checking access for \" + user +\n\" to \" + resource);\n",
      "content_length": 1722,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 124,
      "content": "MOCK OBJECTS\n110\nif (password == null || password.Length == 0) {\nlogger.Log(\"Missing password. Access denied\");\nreturn false;\n}\nIDbCommand cmd = conn.CreateCommand();\ncmd.CommandText = CHECK_SQL;\ncmd.Parameters.Add(\nnew SqlParameter(\"@user\",\nuser));\ncmd.Parameters.Add(\nnew SqlParameter(\"@password\", password));\ncmd.Parameters.Add(\nnew SqlParameter(\"@resource\", resource));\nIDataReader rdr = cmd.ExecuteReader();\nint rows = 0;\nif (rdr.Read())\nrows = rdr.GetInt32(0);\ncmd.Dispose();\nif (rows == 1) {\nlogger.Log(\"Access granted\");\nreturn true;\n}\nelse {\nlogger.Log(\"Access denied\");\nreturn false;\n}\n}\n}\nAccessController1.cs\nThe test code for this is somewhat more complicated than the\nprevious cases, mostly because we want to knit together all\nthe various objects used to access the database (the connec-\ntion, the command, various parameters, and the reader that\nreturns the result). We also want to set up a reasonable set of\nexpectations to ensure that the underlying code is calling the\ndatabase layer correctly.\nLine 1\nusing DotNetMock.Framework.Data;\n-\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\nusing System;\n5\n-\n[TestFixture]\n-\npublic class AnotherAccessControllerTest\n-\n{\n-\n[Test]\n10\npublic void ValidUser()\n-\n{\n-\nMockLogger3 logger = new MockLogger3();\n-\nlogger.ExpectedName = \"AccessControl\";\n",
      "content_length": 1323,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 125,
      "content": "MOCK OBJECTS\n111\n-\nlogger.AddExpectedMsg(\n15\n\"Checking access for dave to secrets\");\n-\nlogger.AddExpectedMsg(\"Access granted\");\n-\n-\n// set up the mock database\n-\nMockDbConnection conn = new MockDbConnection();\n20\nMockCommand cmd = new MockCommand();\n-\nMockDataReader rdr = new MockDataReader();\n-\n-\nconn.SetExpectedCommand(cmd);\n-\ncmd.SetExpectedCommandText(\n25\nAccessController1.CHECK_SQL);\n-\ncmd.SetExpectedExecuteCalls(1);\n-\ncmd.SetExpectedParameter(\n-\nnew MockDataParameter(\"@user\",\n\"dave\"));\n-\ncmd.SetExpectedParameter(\n30\nnew MockDataParameter(\"@password\", \"shhh\"));\n-\ncmd.SetExpectedParameter(\n-\nnew MockDataParameter(\"@resource\", \"secrets\"));\n-\n-\ncmd.SetExpectedReader(rdr);\n35\nobject [,] rows = new object[1,1];\n-\nrows[0, 0] = 1;\n-\nrdr.SetRows(rows);\n-\n-\nAccessController1 access =\n40\nnew AccessController1(\"secrets\", logger, conn);\n-\n-\nAssert.That(\n-\naccess.CanAccess(\"dave\", \"shhh\"),\n-\nIs.True\n45\n);\n-\nlogger.Verify();\n-\nconn.Verify();\n-\ncmd.Verify();\n-\n}\n50\n}\nAccessControllerTest1.cs\nOn line 1 we bring in the DotNetMock framework’s Data com-\nponents. In the body of the test method, we start by creating\nand setting up a mock logger as before. At line 19 we cre-\nate three mock database objects: the connection, a command\n(used to issue SQL queries into the database), and a reader\n(used to return the results of a query).\nWe now need to associate these three objects together. Line 23\ntells the connection object that when it is asked to generate a\ncommand object it should return our mock command object,\ncmd. We then set up that command object’s expectations: the\nSQL it should receive, the number of times it will be executed,\nand the parameters it should expect to receive.\nLine 34 starts the stanza that sets up the reader object. It\n",
      "content_length": 1754,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 126,
      "content": "WHEN NOT TO MOCK\n112\nIt isn’t all perfect\nObservant readers may be wondering why our new\nAccessController class went to the trouble of using a\nReader object to get the count back from executing\nthe query. Why didn’t we just use the ExecuteScalar\nmethod of the command object to return the count\ndirectly?\nUnfortunately, the mock object implementation of\nIDbCommand isn’t quite complete (at least at the time\nof writing). Although ExecuteScalar is implemented,\nit always returns a null value.\nThis means that we\ncouldn’t use it in our tests.\nis ﬁrst associated with the command (so that when the mock\ncommand is executed it will return this reader object).\nWe\nthen set up its result set, a two dimensional array of objects,\ncontaining the rows returned by the query and the columns\nin each row. In our case, the result set contains just a single\nrow containing a single column, the count, but we still need\nto wrap it in the two-dimensional array.\nFinally, on line 39, we create our access controller and check\nto see if “dave” can access the resource “secrets” by using the\npassword “shhh.”\nBecause these values correspond to the\nvalues we set up for the query, the access controller will be\nable to use our mock database objects, which will return a\ncount of “1” and the access will be accepted. At the end of the\ntest, we then verify that the logger, connection, and command\nmock objects were used correctly by our method under test.\n6.4\nWhen Not To Mock\nMock objects are an appealing technology, but because they\ninvolve writing code, they represent a deﬁnite cost to a project.\nWhenever you ﬁnd yourself thinking that you want to write\na mock object to help with testing, stop and consider alter-\nnatives for a couple of seconds.\nIn particular, ask yourself\nthe simple question: “Do I need to write a mock object at\n",
      "content_length": 1820,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 127,
      "content": "WHEN NOT TO MOCK\n113\nall?” Sometimes we can eliminate the need for a mock object\nthrough some simple refactoring.\nAs a (somewhat contrived) example, let’s imagine that we’re\nwriting code that downloads ﬁles to a handheld device over a\nrelatively slow wire. Because of some hardware restrictions,\nafter we’ve sent a block of data, we have to wait a while before\ntrying to talk with the device again. The length of time we have\nto wait depends on the amount of data sent—the hardware\nguys gave us a table of values to use.\nWe might start off by writing a routine that waits a length of\ntime dependent on the size of data sent:\npublic void WaitForData(int dataSize)\n{\nint timeToWait;\nif (dataSize < 100)\n{\ntimeToWait = 50;\n}\nelse if (dataSize < 250)\n{\ntimeToWait = 100;\n}\nelse\n{\ntimeToWait = 200;\n}\nThread.Sleep(timeToWait);\n}\nExample.cs\nNow we want to test this method, but there’s a problem. The\nonly way to see if it works is to check to see if it sleeps for\nthe right amount of time for various values of the dataSize\nparameters.\nThat’s not an easy test to write: we’d have to\nbuild in a fudge factor, because the time we measure for the\nwait won’t be exact. We might even have to set up some kind\nof watchdog thread to ensure that the sleep doesn’t go on too\nlong. There’s also the elapsed time to consider. If running our\ntests causes Thread.Sleep to be called multiple times, our\nunit tests will take longer to complete—which won’t increase\nour popularity amongst co-workers.\nAfter reading this chapter, your ﬁrst thought might be to solve\nthese problems using a mock object.\nIf we replace Thread\nwith some kind of mock object, we can verify that its Sleep()\n",
      "content_length": 1663,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 128,
      "content": "WHEN NOT TO MOCK\n114\nmethod was called with the expected values.\nClass Thread\nis not an interface, and even if it were, it has a boatload of\nproperties and members.\nThis is the time to reﬂect: could we redesign our code slightly\nto make it easier to test? Of course we can!\npublic int HowLongToWait(int dataSize)\n{\nint timeToWait;\nif (dataSize < 100)\n{\ntimeToWait = 50;\n}\nelse if (dataSize < 250)\n{\ntimeToWait = 100;\n}\nelse\n{\ntimeToWait = 200;\n}\nreturn timeToWait;\n}\npublic void WaitForData(int dataSize)\n{\nThread.Sleep(HowLongToWait(dataSize));\n}\nExample.cs\nIn this code we’ve split the waiting into two methods. One cal-\nculates the number of milliseconds to wait based on the data’s\nsize, and the other calls it to get the parameter to pass the\nThread.Sleep(). If we assume that the framework Sleep()\nmethod works, then there’s probably no need to test this sec-\nond method: we can eyeball it and see it does what it says\nit should. That leaves us with the simple task of testing the\nmethod that calculates the time to wait.\n[Test]\nvoid WaitTimes()\n{\nWaiter w = new Waiter();\nAssert.That(w.HowLongToWait(0), Is.EqualTo(50));\nAssert.That(w.HowLongToWait(99), Is.EqualTo(50));\nAssert.That(w.HowLongToWait(100), Is.EqualTo(100));\nAssert.That(w.HowLongToWait(249), Is.EqualTo(100));\nAssert.That(w.HowLongToWait(250), Is.EqualTo(200));\nAssert.That(w.HowLongToWait(251), Is.EqualTo(200));\n}\nExample.cs\nA simple refactoring has led us to a better design and elimi-\n",
      "content_length": 1461,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 129,
      "content": "WHEN NOT TO MOCK\n115\nnated a whole lot of pain associated with coding up the tests.\nTesting for time\nHere’s another, real-world example that shows how a simple\nrefactoring makes for both an easier test and a better, more\ndecoupled design. This is the code to be tested; note the de-\npendency on the current system time.\npublic static string DaysFromNow(DateTime last)\n{\nTimeSpan span = DateTime.Now - last;\nswitch (span.Days)\n{\ncase 0:\nreturn \"Today\";\ncase 1:\nreturn \"Yesterday\";\ndefault:\nreturn span.Days + \" days ago\";\n}\n}\nOn this particular project, one senior engineer spent a lot\nof time trying to invent a good way to fake out or change\nDateTime.Now.\nBut then an intern from Portugal who\nlearned C# via a few test-driven development books saw\nthe code and made the obvious suggestion of extracting a\nparameter[FBB+99].\nIt took some time for the senior engi-\nneer to recover from a bad case of “bruised ego,” but everyone\nagreed it was for the best.\nThe code was refactored to look like the following.\npublic static\nstring DaysFromNow(DateTime current, DateTime last)\n{\nTimeSpan span = current - last;\nswitch (span.Days)\n{\ncase 0:\nreturn \"Today\";\ncase 1:\nreturn \"Yesterday\";\ndefault:\nreturn span.Days + \" days ago\";\n}\n}\n",
      "content_length": 1225,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 130,
      "content": "WHEN NOT TO MOCK\n116\nNotice there is no dependency on the current date or time\nanywhere in the code; it is passed in from the caller. Now we\ncan use a very simple test to drive this code.\n[Test]\npublic void Yesterday()\n{\nDateTime date = new DateTime(2007, 9, 27);\nDateTime dateMinusOneDay = new DateTime(2007, 9, 26);\nAssert.That(\nDaysFromNow(date, dateMinusOneDay),\nIs.EqualTo(\"Yesterday\")\n);\n}\nSometimes you can’t change your existing interfaces to accept\nthe parameterized singleton, or just want to do things in a\nmore incremental fashion so we don’t have to upheave the\nentire codebase. In that case, add a new interface that adds\nthe parameterized singleton, then have the original interface\ndelegate to the new one.\npublic static\nstring DaysFromNow(DateTime last)\n{\nreturn DaysFromNow(DateTime.Now, last);\n}\nWe will want to eventually get rid of this delegation, when\npractical, of course.\nAnd that’s all there is to mock objects: fake out parts of the\nreal world so we can concentrate on testing our own code,\nwhich generally has a nice side-effect of improving our design.\nSome people might perceive that testing with fakes and mocks\nmakes the testing less “real,” but as you can see through the\nexamples, we can actually test interactions that would be difﬁ-\ncult and slow to reproduce accurately in the real world. Also,\nremember that it’s called unit testing for a reason; we don’t\ndrag the whole system along for the ride because we want to\ntest one behavior of a single class.\n",
      "content_length": 1491,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 131,
      "content": "Chapter 7\nProperties of\nGood Tests\nUnit tests are very powerful magic, and if used badly can\ncause an enormous amount of damage to a project by wast-\ning your time. If unit tests aren’t written and implemented\nproperly, you can easily waste so much time maintaining and\ndebugging the tests themselves that the production code—and\nthe whole project—suffers.\nWe can’t let that happen; remember, the whole reason you’re\ndoing unit testing in the ﬁrst place is to make your life easier!\nFortunately, there are only a few simple guidelines that you\nneed to follow to keep trouble from brewing on your project.\nGood tests have the following properties, which makes them\nA-TRIP:\n• Automatic\n• Thorough\n• Repeatable\n• Independent\n• Professional\nLet’s look at what each of these properties means to us.\n",
      "content_length": 794,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 132,
      "content": "AUTOMATIC\n118\n7.1\nAutomatic\nUnit tests need to be run automatically. We mean “automat-\nA -TRIP\nically” in at least two ways: invoking the tests and checking\nthe results.\nAutomatic Invocation\nIt must be really easy for you to invoke one or more unit tests,\nas you will be doing it all day long, day in and day out. So it\nreally can’t be any more complicated than pressing one button\nin the IDE or typing in one command at the prompt in order\nto run the tests you want. Some IDEs can even be set up to\nrun the unit tests continually in the background.\nIt’s important to maintain this environment: don’t introduce\na test that breaks the automatic model by requiring manual\nsteps. Whatever resources the test requires (database, net-\nwork connections, etc.), make these an automatic part of the\ntest itself. Mock objects, as described in Chapter 6, can help\ninsulate you from changes in the real environment if needed.\nBut you’re not the only one running tests. Somewhere a ma-\nchine should be running all of the unit tests for all checked-in\ncode continuously. This automatic, unattended check acts as\na “back stop”; a safety mechanism to ensure that whatever\nis checked in hasn’t broken any tests, anywhere. In an ideal\nworld, this wouldn’t be necessary as you could count on every\nindividual developer to run all the necessary tests themselves.\nBut this isn’t an ideal world. Maybe an individual didn’t run\nsome necessary test in a remote corner of the project. Perhaps\nthey have some code on their own machine that makes it all\nwork—but they haven’t checked that code in, so even though\nthe tests work on their own machine, those same tests fail\neverywhere else.\nYou may want to investigate systems such as Cruise Con-\ntrol1 and other open source products that manage continuous\nbuilding and testing.\n1http://ccnet.thoughtworks.com\n",
      "content_length": 1832,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 133,
      "content": "THOROUGH\n119\nAutomatic Checking\nFinally, by “automatic” we mean that the test must determine\nfor itself whether it passed or failed. Having a person (you or\nsome other hapless victim) read through the test output and\ndetermine whether the code is working or not is a recipe for\nproject failure. Also, in the interests of speed, note that any\ntest that spews tons of console I/O (via Console.WriteLine,\nlog4net or something similar) will slow down the unit tests—\nsometimes dramatically. We want unit tests to be silent, self-\ncontained, and fast.\nIt’s an important feature of consistent regression to have the\ntests check the results for themselves. We humans aren’t very\ngood at those repetitive tasks.\nWe’ll make mistakes in the\nchecking, and waste time investigating a bug that may not ex-\nist, or not catch a new bug that will go on to cause additional\ndamage. The computer will not make these inconsistent mis-\ntakes; a properly written unit test will check the same thing\nevery time it’s run with perfect consistency. Besides we’ve got\nmore important things to do—remember the project?\nThis idea of having the tests run by themselves and check\nthemselves is critical, because it means that you don’t have to\nthink about it—it just happens as part of the project. Testing\ncan then fulﬁll its role as a major component of our project’s\nsafety net. (Version control and automation are the other two\nmajor components of the “safety net.”) Tests are there to catch\nyou when you fall, but they’re not in your way.\nYou’ll need all of your concentration as you cross today’s high-\nwire.\n7.2\nThorough\nGood unit tests are thorough; they test everything that’s likely\nA- T RIP\nto break. But just how thorough?\nAt one extreme, you can aim to test every line of code, ev-\nery possible branch the code might take, every exception it\nthrows, and so on.\nAt the other extreme, you test just the\nmost likely candidates—boundary conditions, missing and\n",
      "content_length": 1940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 134,
      "content": "THOROUGH\n120\nmalformed data, and so on. It’s a question of judgment, based\non the needs of your project.\nIf you want to aim for more complete coverage, then you may\nwant to invest in code coverage tools to help.\nFor instance\nNCover, at http://ncover.org.2 NCover produces XML ﬁles\nthat describe the coverage, there are a couple of tools to visu-\nalize and explore that coverage data:\n• NCoverExplorer3, which is part of the TestDriven.NET\nextension to Visual Studio.NET.\n• CruiseControl.NET comes with a very nice XSL ﬁle for\ntransforming the NCover XML into some really cool-\nlooking HTML.\n• SharpDevelop 2.1 (and above) has NCover integration\nthat will allow you to browse a tree-view of classes and\nmethods. It also has as an option to highlight lines of\ncode in the IDE that were not covered by the unit tests.\nThese tools can help you determine how much of the code\nunder test is actually being exercised, as well as help you\npinpoint what’s not being exercised so you can focus your\ntesting efforts.\nIt’s important to realize that bugs are not evenly distributed\nthroughout the source code.\nInstead, they tend to clump\ntogether in problematic areas (for an interesting story along\nthese lines, see the sidebar on the next page).\nThis phenomenon leads to the well-known battle cry of “don’t\npatch it, rewrite it.” Often, it can be cheaper and less painful\nto throw out a piece of code you’ve written that has a clump\nof bugs and rewrite it from scratch. There’s nothing that can\nimprove code quite like a good old-fashioned disk crash.\nBut because it’s usually more fun to write new code rather\nthan refactor existing code, be careful with wholesale re-\nwriting—especially if it’s someone else’s code.\nRather than\nthrow it out, ﬁrst try to refactor someone else’s code to make\n2As of this writing, NCover does not work with Mono due to the way it\nhooks into Microsoft-speciﬁc portions of the CLR.\n3http://kiwidude.com/blog\n",
      "content_length": 1928,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 135,
      "content": "THOROUGH\n121\nReported Bugs vs. Unit Test Coverage\nWe had a client recently that didn’t quite believe in\nthe power of unit tests. A few members of the team\nwere very good and disciplined at writing unit tests for\ntheir own modules, many were somewhat sporadic\nabout it, and a few refused to be bothered with unit\ntests at all.\nAs part of the hourly build process, we whipped up\na simple Ruby script that performed a quick-and-dirty\nanalysis of test coverage: it tallied up the ratio of test\ncode asserts to production code methods for each\nmodule. Well-tested methods may have 3, 4, or more\nasserts each; untested methods will have none at all.\nThis analysis ran with every build and produced a bar-\ngraph, ranking the most-tested modules at the top\nand the untested modules at the bottom.\nAfter a few weeks of gathering ﬁgures, we showed\nthe bargraph to the project manager, without initial\nexplanation. He was very surprised to see all of the\n“problem modules” lumped together at the bottom—\nhe thought we had somehow produced this graph\nbased on bug reports from QA and customer sup-\nport. Indeed, the modules at the top of the graph\n(well tested) were nearly unknown to him; very few, if\nany, problems had ever been reported against them.\nBut the clump of modules at the bottom (that had\nno unit tests) were very well known to him, the sup-\nport managers, and the local drugstore which had\nresorted to stocking extra-large supplies of antacid.\nThe results were very nearly linear:\nthe more unit-\ntested the code, the fewer problems.\nit more unit-testable. Then if that’s not working, you can go\nahead and succumb to the sweet siren song of coding from\nscratch.\nEither way, it will be safer to do: you’ll have a set of unit tests\nthat can conﬁrm the new code works as it should.\n",
      "content_length": 1781,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 136,
      "content": "REPEATABLE\n122\n7.3\nRepeatable\nJust as every test should be independent from every other\nA-T R IP\ntest, they must be independent of the environment as well.\nThe goal remains that every test should be able to run over\nand over again, in any order, and produce the same results.\nThis means that tests cannot rely on anything in the exter-\nnal environment that isn’t under your direct control.\nThat\nincludes obvious external entities such as databases, sys-\ntem time, network conditions, but also perhaps less obvi-\nous dependents such as global variables.\nAny global state\n(in false singletons or otherwise) really isn’t under your direct\ncontrol—it only seems like it.\nSomething, somewhere, when you least expect it, will alter\nthat state and you’ll end spending a lot a quality time in the\ndebugger trying to discover how you got into that state. That’s\nthe kind of frustration you just don’t need.\nUse mock objects as necessary to isolate the item under test\nand keep it independent from the environment.\nIf you are\nforced to use some element from the real world (a database,\nperhaps), make sure that you won’t get interference from any\nother developer. Each developer needs their own “sandbox”\nto play in, whether that’s their own database instance within\nOracle, or their own webserver on some non-standard port.\nWithout repeatability, you might be in for some surprises at\nthe worst possible moments. What’s worse, these sort of sur-\nprises are usually bogus—it’s not really a bug, it’s just a prob-\nlem with the test. You can’t afford to waste time chasing down\nphantom problems.\nEach test should produce the same results every time. If it\ndoesn’t, then that should tell you that there’s a real bug in\nthe code.\n7.4\nIndependent\nTests need to be kept neat and tidy, which means keeping\nA-TR I P\nthem tightly focused, and independent from the environment\nand each other (remember, other developers may be running\nthese same tests at the same time).\n",
      "content_length": 1951,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 137,
      "content": "PROFESSIONAL\n123\nWhen writing tests, make sure that you are only testing one\nthing at a time.\nNow that doesn’t mean you should use only one assert in a\ntest, but that a test method should test only what the name\nimplies—the same as regular methods in production code. If\nthat means stitching a few methods together to accomplish\nthe test, then so be it. Sometimes an entire test method might\nonly test one small aspect of a complex piece of functionality—\nyou may need multiple test methods to exercise the function-\nality thoroughly.\nAt any rate, you want to achieve a traceable correspondence\nbetween potential bugs and test code. In other words, when\na test fails, it should be obvious where in the code the under-\nlying bug exists without looking at the test code itself. The\nname of the test should tell us all we need to know. Other-\nwise, we’ve got to go hunting for it, and that will just waste\nour time.\nIndependent also means that no test relies on any other test;\nwe should be able to run any individual test at any time, and\nin any order. We really don’t want to have to rely on any other\ntest having run ﬁrst, especially since the ordering will vary\nbetween the different test runners.\nWe’ve shown mechanisms to help you do this: the per-test\nsetup and teardown methods and the per-ﬁxture setup and\nteardown methods. Use these methods to ensure that every\ntest gets a fresh start—and doesn’t impact any test that might\nrun next.\nRemember, you aren’t guaranteed that NUnit tests will run in\nany particular order, and as you start combining tests in ever-\nincreasing numbers, you really can’t afford to carry ordering\ndependencies along with you.\nJohn Donne may have been right about people, but not about\nunit tests: every test should be an island.\n7.5\nProfessional\nThe code you write for a unit test is real; some may argue\nA-TRI P\nit’s even more real than the code you ship to customers. This\n",
      "content_length": 1907,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 138,
      "content": "PROFESSIONAL\n124\nmeans that it must be written and maintained to the same\nprofessional standards as your production code. All the usual\nrules of good design—maintaining encapsulation, honoring\nthe DRY principle, lowering coupling, etc.—must be followed\nin test code just as in production code.\nIt’s easy to fall into the trap of writing very linear test code;\nthat is, code that just plods along doing the same thing over\nand over again, using the same lines of code over and over\nagain, with nary a function or object in sight. That’s a bad\nthing. Test code must be written in the same manner as real\ncode. That means you need to pull out common, repeated bits\nof code and put that functionality in a method instead, so it\ncan be called from several different places.\nYou may ﬁnd you accumulate several related test methods\nthat should be encapsulated in a class.\nDon’t ﬁght it!\nGo\nahead and create a new class, even if it’s only ever used for\ntesting. That’s not only okay, it’s encouraged: test code is real\ncode. In some cases, you may even need to create a larger\nframework, or create a data-driven testing facility (remember\nthe simple ﬁle reader for TestLargest on page 62?).\nDon’t waste time testing aspects that won’t help you. Remem-\nber, you don’t want to create tests just for the sake of creating\ntests. Test code must be thorough in that it must test every-\nthing interesting about a behavior that might break. If it’s not\nlikely to contain a bug, don’t bother testing it. That means\nthat usually you shouldn’t waste time testing things like sim-\nple property accessors:\npublic Money Balance\n{\nget { return balance; }\n}\nFrankly, there’s just not much here to go wrong that the com-\npiler can’t catch.4\nTesting methods such as these is just a\nwaste of time. However, if the property is doing some work\nalong the way, then suddenly it becomes interesting—and we\nwill want to test it:\npublic Money Balance\n4Unless, of course, the IL compiler, JIT compiler, or CLR itself has a bug.\n",
      "content_length": 1993,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 139,
      "content": "TESTING THE TESTS\n125\n{\nget\n{\nreturn posted.GetBalance() -\nunposted.GetDebits() +\nunposted.GetCredits();\n}\n}\nThat’s probably worth testing.\nFinally, expect that, in the end, there will be at least as much\ntest code written as there will be production code. Yup, you\nread that right.\nIf you’ve got 20,000 lines of code in your\nproject, then it would be reasonable to expect that there would\nbe about 20,000 lines or more of unit test code to exercise it.\nThat’s a lot of test code, which is partly why it needs to be\nkept neat and tidy, well designed and well-factored, just as\nprofessional as the production code.\n7.6\nTesting the Tests\nThere is one major conceptual weakness in our plans so far.\nTesting code to make sure it works is a great idea, but you\nhave to write code to perform the tests. What happens when\nthere are bugs in our test code? Does that mean you have to\nwrite test code to test the tests that test the code??? Where\nwill it all end?\nFortunately, you don’t need to go to that extreme. There are\ntwo things you can do to help ensure that the test code is\ncorrect:\n• Improve tests when ﬁxing bugs\n• Prove tests by introducing bugs\nHow to Fix a Bug\nThe steps you take when ﬁxing a bug are very important to\nunit testing. Many times, an existing test will expose a bug in\nthe code, and you can then simply ﬁx the code and watch the\nvigilant test pass.\n",
      "content_length": 1368,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 140,
      "content": "TESTING THE TESTS\n126\nWhen a bug is found “in the wild” and reported back, that\nmeans there’s a hole in the safety net—a missing test. This\nis an opportunity to close the hole, and make sure that this\nparticular bug never escapes into the wild again. All it takes\nis four simple steps:\n1. Identify the bug, or bugs, that caused the errant be-\nhaviour.\n2. Write a test that fails, for each individual bug, to prove\nthe bug exists.5\n3. Fix the code such that the test now passes.\n4. Verify that all tests still pass (i.e., you didn’t break any-\nthing else as a result of the ﬁx).\nThis simple mechanism of applying real-world feedback to\nhelp improve the tests is very effective. Over time, you can\nexpect that your test coverage will steadily increase, and the\nnumber of bugs that escape into the wild from existing code\nwill decrease.\nOf course, as you write new code, you’ll undoubtedly intro-\nduce new bugs, and new classes of bugs, that aren’t being\ncaught by the tests. But when ﬁxing any bug, ask yourself\nthe key question:\nCould this same kind of problem happen any-\nwhere else?\nThen it doesn’t matter whether you’re ﬁxing a bug in an older\nfeature or a new feature; either way, apply what you’ve just\nlearned to the whole project. Encode your new-found knowl-\nedge in all the unit tests that are appropriate, and you’ve done\nmore than just ﬁx one bug. You’ve caught a whole class of\nbugs, and potentially found an opportunity to refactor simi-\nlar code into one place for easier testing, maintenance, and\nenhancement.\n5Sometimes a bit of refactoring may need to happen so that tests can be\nwritten more easily.\n",
      "content_length": 1617,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 141,
      "content": "TESTING THE TESTS\n127\n[Test]\npublic void Add()\n{\n// Create a new account object\nAccount acct = new Account();\n// Populate with our test person\nacct.SetPerson(TEST_PERSON_1);\n// Add it to the database\nDatabaseHandler.Add(acct);\n// Should find it\nAssert.IsTrue(DatabaseHandler.Search(TEST_PERSON_1);\n}\nFigure 7.1: Test Adding a Person to a Database\nSpring the Trap\nIf you’re not sure that a test is written correctly, the easiest\nthing to do is to “spring the trap”: cause the production code\nto exhibit the very bug you’re trying to detect, and verify that\nthe test fails as expected.\nFor instance, suppose you’ve got a test method that adds a\ncustomer account to the database and then tries to ﬁnd it,\nsomething like the code in Figure 7.1. Perhaps you’re not cer-\ntain that the “ﬁnding” part is really working or not—it might\nbe reporting success even if the record wasn’t added correctly.\nSo maybe you’ll go into the Add() method for Database-\nHandler and short-circuit it: just return instead of actually\nadding the record to the database. Now you should see the\nassertion fail, because the record has not been added.\nBut wait, you may cry, what about a leftover record from a\nprevious test run? Won’t that be in the database? No, it won’t,\nfor several reasons:\n• You may not really be testing against a live database.\nThe code exercised by the above test case lies between\nthe add method shown and the actual low-level database\ncalls.\nThose database calls may well be handled by a\nmock object, whose data is not held persistently in be-\ntween runs.\n",
      "content_length": 1553,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 142,
      "content": "TESTING THE TESTS\n128\n• Tests are independent. All tests can be run in any or-\nder, and do not depend on each other, so even if a real\ndatabase is part of this test, the setup and tear-down\nmust ensure that you get a “clean sandbox” to play in.\nThe attempt above to spring the trap can help prove that\nthis is true.\nNow the Extreme Programming folks claim that their disci-\nplined practice of test-ﬁrst development avoids the problem\nof poor tests that don’t fail when they should.\nIn test-ﬁrst\ndevelopment, you only ever write code to ﬁx a failing test. As\nsoon as the test passes, then you know that the code you just\nadded ﬁxed it. This puts you in the position where you always\nknow with absolute certainty that the code you introduced\nﬁxes the failing test that caused you to write the code in the\nﬁrst place.\nBut there’s many a slip ’twixt the cup and the lip, and while\ntest-ﬁrst development does improve the situation dramatical-\nly, there will still be opportunities to be misled by coinci-\ndences. The practice of pair programming further reduces the\nchance of these kinds of slip-ups, but you we may not always\nhave someone to pair with. For those occasions, you can sat-\nisfy any lingering doubts by deliberately “springing the trap”\nto make sure that all is as you expect.\nFinally, remember to write tests that are A-TRIP (Automatic,\nThorough, Repeatable, Independent, Professional); keep add-\ning to your unit tests as new bugs and types of bugs are dis-\ncovered; and check to make sure your tests really do ﬁnd the\nbugs they target.\nThen sit back and watch problems on your project disappear\nlike magic.\n",
      "content_length": 1619,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 143,
      "content": "Chapter 8\nTesting on a Project\nUp to now we’ve talked about testing as an individual, solitary\nexercise.\nBut of course, in the real world you’ll likely have\nteammates to work with. You’ll all be unit testing together,\nand that brings up a couple of issues.\n8.1\nWhere to Put Test Code\nOn a small, one-person project, the location of test code and\nencapsulation of the production code may not be very impor-\ntant, but on larger projects it can become a critical issue.\nThere are several different ways of structuring your produc-\ntion and test code that we’ll look at here.\nIn general, you don’t want to break any encapsulation for the\nsake of testing (or as Mom used to say, “don’t expose your pri-\nvates!”). Most of the time, you should be able to test a class\nby exercising its public methods. If there is signiﬁcant func-\ntionality that is hidden behind private or protected access,\nthat might be a warning sign that there’s another class in\nthere struggling to get out. When push comes to shove, how-\never, it’s probably better to break encapsulation with working,\ntested code than it is to have good encapsulation of untested,\nnon-working code.\n",
      "content_length": 1149,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 144,
      "content": "WHERE TO PUT TEST CODE\n130\nSame directory\nSuppose you are writing a class named:\nPragProg.Wibble.Account\nwith a corresponding test in:\nPragProg.Wibble.AccountTest\nThe ﬁrst and easiest method of structuring test code is to sim-\nply include it right in the same project and assembly alongside\nthe production code.\nThis has the advantage that AccountTest can access inter-\nnal and protected internal member variables and meth-\nods of Account. But the disadvantage is that the test code\nis lying around, cluttering up the production code directory.\nThis may or may not be a problem depending on your method\nof creating a release to ship to customers.\nMost of the time, it’s enough of a problem that we prefer one\nof the other solutions. But for small projects, this might be\nsufﬁcient.\nSeparate Assemblies\nThe next option is to create your tests in a separate assembly\nfrom the production code.\nThis has the advantage of keeping a clean separation between\ncode that you ship and code for testing.\nThe disadvantage is that now the test code is in a different\nassembly; You won’t be able to access internal or protected\ninternal members unless your test code uses a subclass of\nthe production code that exposes the necessary members. For\ninstance, suppose the class you want to test looks like this:\nnamespace FacilitiesManagment {\npublic class Pool {\nprotected Date lastCleaned;\npublic void xxxx xx {\nxxx xxx xxxx;\n}...\n}\n}\n",
      "content_length": 1419,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 145,
      "content": "WHERE TO PUT TEST CODE\n131\nAcme.Pool\n#LastCleaned()\nAcme.Test.PoolForTesting\n+LastCleaned()\nprotected\nmethod in\nproduction\ncode\nPRODUCTION CODE\npublic in test\ncode\nTEST CODE\nFigure 8.1: Subclasses Expose Methods for Testing\nYou need to get at that non-public bit of data that tells you\nwhen the pool was last cleaned for testing, but there’s no ac-\ncessor for it. (If there were, the pool association would prob-\nably sue us; they don’t like to make that information public.)\nSo you make a subclass that exposes it just for testing.\nusing FacilitiesManagment;\nnamespace FacilitiesManagmentTesting {\npublic class PoolForTesting : Pool {\npublic Date LastCleaned {\nget { return lastCleaned; }\n}\n}\n}\nYou then use PoolForTesting in the test code instead of us-\ning Pool directly (see Figure 8.1). In fact, you could make this\nclass internal to the test assembly (to ensure that we don’t\nget sued).\nWhatever convention the team decides to adopt, make sure it\ndoes so consistently. You cannot have some of the tests in\nthe system set up one way, and other tests elsewhere set up\na different way. Pick a style that looks like it will work in your\nenvironment and stick with it for all of the system’s unit tests.\n",
      "content_length": 1205,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 146,
      "content": "WHERE TO PUT NUNIT\n132\n8.2\nWhere to Put NUnit\nOne issue that comes up on real projects is how to distribute\nNUnit itself.\nYou could have each individual developer install the latest ver-\nsion on their own workstations (as well as on the automated\nbuild machine). All the developers would have to install NUnit\ninto the same directory, and make sure to reference that spe-\nciﬁc nunit.framework.dll assembly as not some random\none in the GAC or elsewhere via a shortcut or symlink. This is\nall actually more difﬁcult than it sounds, especially with little\nbugs that Visual Studio has with assembly references thrown\nin for fun.\nInstead, you should distribute NUnit via your version control\nsystem.\nMany .NET and Java projects deﬁne both a src/\ndirectory and a lib/ directory. The src/ directory contains\nthe source code to the project, and the lib/ directory contains\npre-compiled components (usually third-party).\nIn this context, you’d have a lib/nunit/ directory that con-\ntains the NUnit binary distribution. Your projects and NAnt\nﬁles would reference the nunit.framework.dll in this direc-\ntory, and developers would run the nunit.exe GUI from this\ndirectory via a shortcut.\nNow keeping developers’ versions of NUnit synchronized is\neasy, as is deploying any upgrades or customizations. It keeps\nthe environment consistent, freeing up time that would other-\nwise be spent on ﬁguring out mismatched NUnit issues (which\nusually manifest themselves in odd ways). You may want to\ndiscourage developers from installing NUnit on their work-\nstation to reduce confusion. If they do, keep an eye out for\nchanges in the project or NAnt build ﬁles that reference NUnit\nassemblies other than those in the project’s lib/nunit/ di-\nrectory.\n8.3\nTest Courtesy\nThe biggest difference between testing by yourself and testing\nwith others lies in synchronizing working tests and code.\n",
      "content_length": 1871,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 147,
      "content": "TEST COURTESY\n133\nObfuscation and Packaging\nMatt tells the following story about packaging, obfus-\ncation, and manual maintenance:\n“Recently I worked on a project that used a code ob-\nfuscation program, which the team thought helped\nprotect their intellectual property.\nThey packaged\ntheir unit tests in the same assembly as their produc-\ntion code, but the unit tests were #if’d out in the Re-\nlease build. Any time a developer added a new test\nﬁle, they had to remember to add the #if or risk vio-\nlating the obfuscation policy. Or, did they?\nPutting the tests into the assembly was reducing the\neffective design feedback of their packaging (which\nhad major issues), so I proposed to extract the unit\ntests into a separate assembly so the design issues\ncould be made more obvious. They said this was im-\npossible because the unit tests were testing classes\nmarked ’internal’ and thus the tests had to be inside\nthe same assembly as the production code.\nI was curious why these classes had to be internal,\nand this turned up an amusing (albeit embarrassing)\nmisunderstanding: the team thought that in order\nfor the obfuscater to work properly, classes had to\nbe marked as internal. That is, they thought public\nclasses wouldn’t be obfuscated in name or in code.\nThis was a mistake, of course. This particular obfus-\ncater didn’t really care, and I was able to conﬁgure\nit to obfuscate everything just ﬁne. One of the neat\ntricks that came out of this was that this obfuscation\nproduct was able to take several assemblies that ref-\nerenced each other, combine them into one binary,\nand prune out unused methods and code.\nBecause the unit tests weren’t referenced directly in\nany of the application code, they were pruned out\nautomatically. The manual #if statements they kept\nusing could simply be removed. This also opened the\ndoor to making those internal classes public; the unit\ntests could then be extracted into a separate assem-\nbly, and design feedback could be obtained and\nacted upon appropriately.”\n",
      "content_length": 2010,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 148,
      "content": "TEST COURTESY\n134\nWhen working with other members of a team, you will be us-\ning some sort of version control system, such as SubVersion,\nCVS, or (for the more masochistic among us), Visual Source-\nSafe. (If you aren’t familiar with version control, or would like\nsome assistance in getting it set up and working correctly,\nplease see [TH03].)\nIn a team environment (and even in a personal environment)\nyou should make sure that when you check in code (or other-\nwise make it available to everyone) that it has complete unit\ntests, and that it passes all of them. In fact, every test in the\nwhole system should continue to pass with your new code.\nThe rule is very simple: As soon as anyone else can access\nyour code, all tests everywhere need to pass. Since you should\nnormally work in fairly close synchronization with the rest of\nthe team and the version control system, this boils down to\n“all tests pass all the time.”\nMany teams institute policies to help “remind” developers of\nthe consequences of breaking the build, or breaking the tests.\nThese policies might begin by listing potential infractions in-\nvolving code that you have checked in (or otherwise made\navailable to other developers):\n• Incomplete code (e.g., checking in only one class ﬁle but\nforgetting to check in other ﬁles it may depend upon).\n• Code that doesn’t compile.\n• Code that compiles, but breaks existing code such that\nexisting code no longer compiles.\n• Code without corresponding unit tests.\n• Code with failing unit tests.\n• Code that passes its own tests, but causes other tests\nelsewhere in the system to fail.\nIf found guilty of any of these heinous crimes, you may be sen-\ntenced to providing donuts for the entire team the next morn-\ning, or beer or soda, or frozen margaritas, or maybe you’ll have\nto nursemaid the build machine, or some other token, menial\ntask.\n",
      "content_length": 1856,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 149,
      "content": "TEST FREQUENCY\n135\nA little lighthearted law enforcement usually provides enough\nmotivation against careless accidents. But what happens if\nyou have to make an incompatible change to the code, or if\nyou make a change that does cause other tests to fail else-\nwhere in the system?\nThe precise answer depends on the methodology and process\nyou’re using on the project, but somehow you need to coordi-\nnate your changes with the folks who are responsible for the\nother pieces of code—which may well be you! The idea is to\nmake all of the necessary changes at once, so the rest of the\nteam sees a coherent picture (that actually works) instead of\na fragmented, non-functional “work in progress.” (For more\ninformation on how to use version control to set up experi-\nmental developer branches, see [TH03].)\nSometimes the real world is not so willing, and it might take a\nfew hours or even a few days to work out all of the incompati-\nble bits and pieces, during which time the build is broken. If it\ncan’t be helped, then make sure that it is well-communicated.\nMake sure everyone knows that the build will be broken for\nthe requisite amount of time so that everyone can plan around\nit as needed. If you’re not involved, maybe it would be a good\ntime to take your car in for an oil change or slip off to the\nbeach for a day or two. If you are involved, get it done quickly\nso everyone else can come back from the beach and get to\nwork!\n8.4\nTest Frequency\nHow often should you run unit tests?\nIt depends on what\nyou’re doing, and your personal habits, but here are some\ngeneral guidelines that we ﬁnd helpful. You want to perform\nenough testing to make sure you’re catching everything you\nneed to catch, but not so much testing that it interferes with\nproducing production code.\nWrite a new method\nCompile and run local unit tests.\nFix a bug\nWrite and run tests that demonstrate bug; ﬁx the bug\nand re-run unit tests.\n",
      "content_length": 1912,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 150,
      "content": "TESTS AND LEGACY CODE\n136\nAny successful compile\nRun local unit tests.\nEach check-in to version control\nRun all module or system unit tests.\nContinuously\nA dedicated machine should be running a full build and\ntest, from scratch, automatically throughout the day (ei-\nther periodically or on check-in to version control).\nNote that for larger projects, you might not be able to compile\nand test the whole system in under a few hours. You may only\nbe able to run a full build and test overnight. For even larger\nprojects, it may have to be every couple of days—and that’s a\nshame, because the longer the time between automatic builds\nthe longer the “feedback gap” between creation of a problem\nand its identiﬁcation.\nThe reason to have a more-or-less continuous build is so that\nit can identify any problems quickly. You don’t want to have to\nwait for another developer to stumble upon a build problem if\nyou can help it. Having a build machine act as a constant de-\nveloper increases the odds that it will ﬁnd a problem, instead\nof a real developer.\nWhen the build machine does ﬁnd a problem, then the whole\nteam can be alerted to the fact that it’s not safe to get any new\ncode just yet, and can continue working with what they have.\nThat’s better than getting stuck in a situation where you’ve\ngotten fresh code that doesn’t work.\nFor more information on setting up automatic build and test-\ning systems, nightly and continuous builds, and automation\nin general please see [Cla04].\n8.5\nTests and Legacy Code\nSo far, we’ve talked about performing unit tests in the context\nof new code. But we haven’t said what to do if your project\nhas a lot of code already—code that doesn’t have unit tests.\nIt all depends on what kind of state that code is in. If it’s rea-\nsonably well-factored and modular, such that you can get at\n",
      "content_length": 1821,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 151,
      "content": "TESTS AND LEGACY CODE\n137\nall of the individual pieces you need to, then you can add unit\ntests fairly easily. If, on the other hand, it’s just a “big ball of\nmud” all tangled together, then it might be close to impossi-\nble to test without substantial rewriting. Most older projects\naren’t perfectly factored, but are usually modular enough that\nyou can add unit tests.\nFor new code that you write, you’ll obviously write unit tests\nas well. This may mean that you’ll have to expose or break out\nparts of the existing system, or create mock objects in order\nto test your new functionality.\nFor existing code, you might choose to methodically add unit\ntests for everything that is testable. But that’s not very prag-\nmatic. It’s better to add tests for the most broken stuff ﬁrst,\nto realize a better return on investment of effort.\nThe most important aspect of unit tests in this environment\nis to prevent back-sliding: to avoid the death-spiral where\nmaintenance ﬁxes and enhancements cause bugs in existing\nfeatures. We use NUnit unit tests as regression tests during\nnormal new code development (to make sure new code doesn’t\nbreak anything that had been working), but regression testing\nis even more important when dealing with legacy code.\nAnd it doesn’t have to cover the entire legacy code base, just\nthe painful parts.\nConsider the following true story from a\npragmatic developer (the team in question happened to be us-\ning Java and JUnit for this particular project, but they could\njust as easily have been using C#, Cobol, C++, Ruby, or any\nother programming language):\nRegression Tests Save the Day\n“Tibbert Enterprises1 ships multiple applications,\nall of which are based on a common Lower Level\nLibrary that is used to access the object database.\nOne day I overheard some application develop-\ners talking about a persistent problem they were\nhaving. In the product’s Lower Level interface, you\ncan look up objects using the object name, which\n1Not their real name.\n",
      "content_length": 1980,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 152,
      "content": "TESTS AND LEGACY CODE\n138\nincludes a path to the object. Since the application\nhas several layers between it and the Lower Level\ncode, and the Lower Level code has several more\nlayers to reach the object database, it takes a while\nto isolate a problem when the application breaks.\nAnd the application broke.\nAfter half the ap-\nplication team spent an entire day tracking down\nthe bug, they discovered the bug was in the Lower\nLevel code that accessed the database. If you had\na space in the name, the application died a violent,\nmessy death. After isolating the Lower Level code\nrelated to the database access, they presented the\nbug to the owner of the code, along with a ﬁx. He\nthanked them, incorporated their ﬁx, and commit-\nted the ﬁxed code into the repository.\nBut the next day, the application died.\nOnce\nagain, a team of application developers tracked it\ndown. It took only a half-a-day this time (as they\nrecognized the code paths by now), and the bug\nwas in the same place. This time, it was a space\nin the path to the object that was failing, instead of\na space in the name itself. Apparently, while inte-\ngrating the ﬁx, the developer had introduced a new\nbug.\nOnce again, they tracked it down and pre-\nsented him with a ﬁx. It’s Day Three, and the ap-\nplication is failing again! Apparently the developer\nin question re-introduced the original bug.\nThe application manager and I sat down and\nﬁgured out that the equivalent of nearly two man-\nmonths of effort had been spent on this one issue\nover the course of one week by his team alone (and\nthis likely affected other teams throughout the com-\npany).\nWe then developed JUnit tests that tested\nthe Lower Level API calls that the application prod-\nuct was using, and added tests for database access\nusing spaces in both the object name and in the\npath. We put the product under the control of our\ncontinuous-build-and-test program (using Cruise-\nControl) so that the unit tests were run automat-\nically every time code got committed back to the\nrepository.\n",
      "content_length": 2021,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 153,
      "content": "TESTS AND CODE REVIEWS\n139\nSure enough, the following week, the test failed\non two successive days, at the hands of the original\ndeveloper. He actually came to my ofﬁce, shook my\nhand, and thanked me when he got the automatic\nnotiﬁcation that the tests had failed.\nYou see, without the JUnit test, the bad code\nmade it out to the entire company during the night-\nly builds. But with our continuous build and test,\nhe (and his manager and tester) saw the failure at\nonce, and he was able to ﬁx it immediately before\nanyone else in the company used the code. In fact,\nthis test has failed half a dozen times since then.\nBut it gets caught, so its not a big deal anymore.\nThe product is now stable because of these tests.\nWe now have a rule that any issue that pops\nup twice must have a JUnit test by the end of the\nweek.”\nIn this story, Tibbert Enterprises aren’t using unit testing to\nprove things work so much as they are using it to inoculate\nagainst known issues. As they slowly catch up, they’ll even-\ntually expand to cover the entire product with unit tests, not\njust the most broken parts.\nWhen you come into a shop with no automated tests of any\nkind, this seems to be a very effective approach. Remember,\nthe only way to eat an elephant is one bite at a time.\n8.6\nTests and Code Reviews\nTeams that enjoy success often hold code reviews. This can\nbe an informal affair where a senior person just gives a quick\nlook at the code. Or perhaps two people are working on the\ncode together, using Extreme Programming’s “Pair Program-\nming” practice. Or maybe it’s a very formal affair with check-\nlists and a small committee.\nHowever you perform code reviews (and we suggest that you\ndo), make the test code an integral part of the review process.\nSince test code is held up to the same high standards as pro-\nduction code, it should be reviewed as well.\n",
      "content_length": 1855,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 154,
      "content": "TESTS AND CODE REVIEWS\n140\nIn fact, it can sometimes be helpful to expand on the idea of\n“test-ﬁrst design” to include both writing and reviewing test\ncode before writing production code. That is, code and review\nin this order:\n1. Write test cases and/or test code.\n2. Review test cases and/or test code.\n3. Revise test cases and/or test code per review.\n4. Write production code that passes the tests.\n5. Review production and test code.\n6. Revise test and production code per review.\nReviews of the test code are incredibly useful. Not only are\nreviews more effective than testing at ﬁnding bugs in the ﬁrst\nplace, but by having everyone involved in reviews you can\nimprove team communication. People on the team get to see\nhow others do testing, see what the team’s conventions are,\nand help keep everyone honest.\nYou can use the checklists on page 194 of this book to help\nidentify possible test cases in reviews. But don’t go overboard\ntesting things that aren’t likely to break, or repeat essentially\nsimilar tests over and over just for the sake of testing.\nFinally, you may want to keep track of common problems\nthat come up again and again. These might be areas where\nmore training might be needed, or perhaps something else\nthat should be added to your standard review checklist.\nFor example, at a client’s site several years ago, we discovered\nthat many of the developers misunderstood exception han-\ndling. The code base was full of fragments similar to the fol-\nlowing:\ntry\n{\nDatabaseConnection dbc = new DatabaseConnection();\nInsertNewRecord(dbc, record);\ndbc.Close();\n}\ncatch (Exception) {}\nThat is to say, they simply ignored any exceptions that might\nhave occurred.\nNot only did this result in random miss-\n",
      "content_length": 1724,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 155,
      "content": "TESTS AND CODE REVIEWS\n141\nDelusional Exception Handling\nMatt adds this story:\nI was working on a project where the company’s CTO\nlittered the code with empty catch-all statements.\nWhen running a run-time analysis tool, I noticed that\nseveral dozen exceptions were being thrown and\nhandled. Upon further inspection, I saw a piece of\ncode that would almost always fail because it was—\nwait for it—dividing by a value that was zero most of\nthe time.\nThe team found this apalling, so we spent a day\ncleaning up all the empty catch-all statements. The\nCTO was upset because the product was now more\nvisibly unstable. He demanded the team put the bad\nexception handling back in. The team refused—the\nbugs and broken functionality were always present,\nthe difference was we could see how bad it was.\ning records, but the system leaked database connections as\nwell—any error that came up would cause the Close to be\nskipped.\nWe added this to the list of known, typical problems to be\nchecked during reviews. As code was reviewed, any of these\ninfamous catch statements that were discovered were ﬁrst\nidentiﬁed, then proper unit tests were put in place to force\nvarious error conditions (the “E” in RIGHT-BICEP), and the\ncode was ﬁxed to either propagate or handle the exception.\nSystem stability increased tremendously as a result of this\nsimple process. For reference, the minimal ﬁx is to close (or\ndispose) resources in a finally clause. That way, they’ll be\ncleaned up when control ﬂow leaves the try block—whether\nan exception is thrown or not.\ntry\n{\nDatabaseConnection dbc = new DatabaseConnection();\nInsertNewRecord(dbc, record);\n}\nfinally\n{\n",
      "content_length": 1642,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 156,
      "content": "TESTS AND CODE REVIEWS\n142\ndbc.Close()\n}\n",
      "content_length": 41,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 157,
      "content": "Chapter 9\nDesign Issues\nSo far we have discussed unit testing as it helps you to un-\nderstand and verify the functional, operational characteristics\nof your code. But unit testing offers several opportunities to\nimprove the design and architecture of your code as well.\nIn this chapter, we’ll take a look at the following design-level\nissues:\n• Better separation of concerns by designing for testability\n• Clarifying design by deﬁning class invariants\n• Improving interfaces with test-driven design\n• Establishing and localizing validation responsibilities\n9.1\nDesigning for Testability\n“Separation of Concerns” is probably the single most impor-\ntant concept in software design and implementation. It’s the\ncatch-all phrase that encompasses encapsulation, orthogo-\nnality, coupling, and all those other computer science terms\nthat boil down to “write shy code” [HT00].\nYou can keep your code well-factored (i.e., “shy”) and easier to\nmaintain by explicitly designing code to be testable. For ex-\nample, suppose you are writing a method that will sleep until\nthe top of the next hour. You’ve got a bunch of calculations\nand then a Sleep():\n",
      "content_length": 1140,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 158,
      "content": "DESIGNING FOR TESTABILITY\n144\npublic void SleepUntilNextHour() {\nint howlong;\nxx xxxx x xxxx xx xx xxx;\n// Calculate how long to wait...\nx x xx xxx xxx x x xx;\nxx xxxx x xxxx xx xx xxx;\nThread.Sleep(howlong);\nreturn;\n}\nHow will you test that? Wait around for an hour? Set a timer,\ncall the method, wait for the method to return, check the\ntimer, handle the cases when the method doesn’t get called\nwhen it should—this is starting to get pretty messy. We saw\nsomething similar back in Chapter 6, but this issue is impor-\ntant enough to revisit. Once again, we’ll refactor the method\nin order to make testing easier.\nInstead of combining the calculation of how many millisec-\nonds to sleep with the Sleep() method itself, split them up:\npublic void SleepUntilNextHour() {\nint howlong = MilliSecondsToNextHour(DateTime.Now);\nThread.Sleep(howlong);\nreturn;\n}\nWhat’s likely to break? The system’s Sleep call? Or our code\nthat calculates the amount of time to wait? It’s probably a fair\nbet to say that .NET’s Thread.Sleep() works as advertised\n(even if it doesn’t, our rule is to always suspect our own code\nﬁrst, see the tip Select Isn’t Broken in [HT00]). So for now, you\nonly need to test that the number of milliseconds is calculated\ncorrectly, and what might have been a hairy test with timers\nand all sorts of logic (not to mention an hour’s wait) can be\nexpressed very simply as:\nAssert.AreEqual(10000, MilliSecondsToNextHour(DATE_1));\nIf we’re conﬁdent that MilliSecondsToNextHour() works to\nour satisfaction, then the odds are that SleepUntilNext-\nHour() will be reliable as well—if it is not, then at least we\nknow that the problem must be related to the sleep itself, and\nnot to the numerical calculation. You might even be able to\nreuse the MilliSecondsToNextHour() method in some other\ncontext.\n",
      "content_length": 1803,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 159,
      "content": "REFACTORING FOR TESTING\n145\nFigure 9.1: Recipes GUI Screen\nThis is what we mean when we claim that you can improve\nthe design of code by making it easier to test. By changing\ncode so that you can get in there and test it, you’ll end up\nwith a cleaner design that’s easier to extend and maintain as\nwell as test.\nBut instead of boring you with examples and techniques, all\nyou really need to do is remember this one fundamental ques-\ntion when writing code:\nHow am I going to test this?\nIf the answer is not obvious, or if it looks like the test would be\nugly or hard to write, then take that as a warning signal. Your\ndesign probably needs to be modiﬁed; change things around\nuntil the code is easy to test, and your design will end up\nbeing far better for the effort.\n",
      "content_length": 769,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 160,
      "content": "REFACTORING FOR TESTING\n146\nRecipes\nname\ningredients\nLoad()\nSave()\nShowGUI()\nFigure 9.2: Original Recipes Static Class Diagram\n9.2\nRefactoring for Testing\nLet’s look at a real-life example.\nHere are excerpts from a\nnovice’s ﬁrst attempt at a recipe management system.\nThe\nGUI, shown in Figure 9.1 on the preceding page, is pretty\nstraightforward.\nThere’s only one class, with GUI behavior\nand ﬁle I/O intermixed.\nIt reads and writes individual recipes to ﬁles, using a line-\noriented format, somewhat like an INI or properties ﬁle:\nNAME=Cheeseburger\nINGREDIENTS=3\n1/4 lb ground sirloin\n3 slices Vermont cheddar cheese\n2 slices maple-cured bacon\ncheeseburger.txt\nAnd here’s the code, in its entirety. As is, this is pretty hard to\ntest. You’ve got to run the whole program and operate the GUI\nto get at any part of it. All of the ﬁle I/O and search routines\naccess the widgets directly, and so are tightly coupled to the\nGUI code (see, for instance, lines 138, 150, 157, and 166). In\nfact, the UML diagram for this class, shown in Figure 9.2, is\nkind of embarrassing—it’s just one big class! Unfortunately,\nthis kind of code is commonplace in many .NET projects be-\ncause Visual Studio’s designer-generated code gently coerces\nprogrammers to add logic directly into the Form or Control\nclass. The forms designers for WinForms and ASP.NET are\ngreat tools—just be aware of these sinful temptations.\nLine 1\nusing System;\n-\nusing System.Drawing;\n",
      "content_length": 1441,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 161,
      "content": "REFACTORING FOR TESTING\n147\n-\nusing System.Collections;\n-\nusing System.ComponentModel;\n5\nusing System.Windows.Forms;\n-\nusing System.Data;\n-\nusing System.IO;\n-\n-\npublic class Recipes : Form {\n10\nprivate Button exitButton = new Button();\n-\nprivate StatusBar statusBar = new StatusBar();\n-\nprivate GroupBox groupBox1 = new GroupBox();\n-\nprivate TextBox titleText = new TextBox();\n-\nprivate Button searchButton = new Button();\n15\nprivate ListBox searchList = new ListBox();\n-\nprivate GroupBox groupBox2 = new GroupBox();\n-\nprivate ListBox ingredientsList = new ListBox();\n-\nprivate Button removeButton = new Button();\n-\nprivate TextBox ingredientsText = new TextBox();\n20\nprivate Button saveButton = new Button();\n-\nprivate Button addButton = new Button();\n-\n-\npublic Recipes() {\n-\nInitializeComponent();\n25\n}\n-\n-\nprivate void InitializeComponent() {\n-\nexitButton.Location =\n-\nnew System.Drawing.Point(120, 232);\n30\nexitButton.Size = new System.Drawing.Size(48, 24);\n-\nexitButton.Text = \"Exit\";\n-\nexitButton.Click +=\n-\nnew System.EventHandler(exitButton_Click);\n-\n35\nstatusBar.Location = new System.Drawing.Point(0, 261);\n-\nstatusBar.Size = new System.Drawing.Size(400, 16);\n-\n-\ngroupBox1.Controls.Add(searchList);\n-\ngroupBox1.Controls.Add(searchButton);\n40\ngroupBox1.Controls.Add(titleText);\n-\ngroupBox1.Location = new System.Drawing.Point(8, 8);\n-\ngroupBox1.Size = new System.Drawing.Size(176, 216);\n-\ngroupBox1.TabStop = false;\n-\ngroupBox1.Text = \"Recipes\";\n45\n-\nsearchList.Location = new System.Drawing.Point(16, 56);\n-\nsearchList.Size = new System.Drawing.Size(144, 147);\n-\nsearchList.SelectedIndexChanged +=\n-\nnew System.EventHandler(\n50\nsearchList_SelectedIndexChanged);\n-\n-\nsearchButton.Location = new System.Drawing.Point(112, 24);\n-\nsearchButton.Size = new System.Drawing.Size(48, 24);\n-\nsearchButton.Text = \"Search\";\n55\nsearchButton.Click +=\n-\nnew System.EventHandler(searchButton_Click);\n-\n-\ntitleText.Location = new System.Drawing.Point(16, 24);\n",
      "content_length": 1955,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 162,
      "content": "REFACTORING FOR TESTING\n148\n-\ntitleText.Size = new System.Drawing.Size(88, 20);\n60\n-\ngroupBox2.Controls.Add(addButton);\n-\ngroupBox2.Controls.Add(ingredientsText);\n-\ngroupBox2.Controls.Add(removeButton);\n-\ngroupBox2.Controls.Add(ingredientsList);\n65\ngroupBox2.Location = new System.Drawing.Point(200, 8);\n-\ngroupBox2.Size = new System.Drawing.Size(192, 248);\n-\ngroupBox2.TabStop = false;\n-\ngroupBox2.Text = \"Ingredients\";\n-\n70\naddButton.Location = new System.Drawing.Point(136, 176);\n-\naddButton.Size = new System.Drawing.Size(48, 23);\n-\naddButton.Text = \"Add\";\n-\naddButton.Click +=\n-\nnew System.EventHandler(addButton_Click);\n75\n-\ningredientsText.Location = new System.Drawing.Point(16, 176);\n-\ningredientsText.Size = new System.Drawing.Size(112, 20);\n-\n-\nremoveButton.Enabled = false;\n80\nremoveButton.Location = new System.Drawing.Point(16, 208);\n-\nremoveButton.Size = new System.Drawing.Size(168, 32);\n-\nremoveButton.Text = \"Remove\";\n-\nremoveButton.Click +=\n-\nnew System.EventHandler(removeButton_Click);\n85\n-\ningredientsList.Location = new System.Drawing.Point(16, 24);\n-\ningredientsList.Size = new System.Drawing.Size(160, 134);\n-\ningredientsList.SelectedIndexChanged +=\n-\nnew System.EventHandler(\n90\ningredientsList_SelectedIndexChanged);\n-\n-\nsaveButton.Enabled = false;\n-\nsaveButton.Location = new System.Drawing.Point(40, 232);\n-\nsaveButton.Size = new System.Drawing.Size(48, 24);\n95\nsaveButton.Text = \"Save\";\n-\nsaveButton.Click +=\n-\nnew System.EventHandler(saveButton_Click);\n-\n-\nAutoScaleBaseSize = new System.Drawing.Size(5, 13);\n100\nClientSize = new System.Drawing.Size(400, 277);\n-\nControls.Add(saveButton);\n-\nControls.Add(groupBox2);\n-\nControls.Add(groupBox1);\n-\nControls.Add(statusBar);\n105\nControls.Add(exitButton);\n-\ngroupBox1.ResumeLayout(false);\n-\ngroupBox2.ResumeLayout(false);\n-\nResumeLayout(false);\n-\n}\n110\n-\n[STAThread]\n-\nstatic void Main() {\n-\nDirectory.SetCurrentDirectory(@\"..\\..\\recipes\\\");\n",
      "content_length": 1917,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 163,
      "content": "REFACTORING FOR TESTING\n149\n-\nApplication.Run(new Recipes());\n115\n}\n-\n-\nprivate void exitButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nApplication.Exit();\n120\n}\n-\n-\nprivate void searchButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nString toMatch = \"*\" + titleText.Text + \"*\";\n125\n-\ntry {\n-\nstring [] matchingFiles = Directory.GetFiles(@\".\", toMatch);\n-\nsearchList.DataSource = matchingFiles;\n-\n}\n130\ncatch (Exception error) {\n-\nstatusBar.Text = error.Message;\n-\n}\n-\n}\n-\n135\nprivate void\n-\nsearchList_SelectedIndexChanged(object sender,\n-\nSystem.EventArgs e) {\n-\nstring file = (string)searchList.SelectedItem;\n-\nstring line;\n140\nchar [] delim = new char[] { ’=’ };\n-\n-\nstatusBar.Text = file;\n-\n-\nusing (StreamReader reader =\n145\nnew StreamReader(file)) {\n-\nwhile ((line = reader.ReadLine()) != null) {\n-\nstring [] parts = line.Split(delim, 2);\n-\nswitch (parts[0]) {\n-\ncase \"NAME\":\n150\ntitleText.Text = parts[1];\n-\nbreak;\n-\ncase \"INGREDIENTS\":\n-\ntry {\n-\nint count = Int32.Parse(parts[1]);\n155\ningredientsList.Items.Clear();\n-\nfor (int i = 0; i < count; i++)\n-\ningredientsList.Items.Add(reader.ReadLine());\n-\n}\n-\ncatch (Exception error) {\n160\nstatusBar.Text = \"Bad ingredient count: \" +\n-\nerror.Message;\n-\nreturn;\n-\n}\n-\nbreak;\n165\ndefault:\n-\nstatusBar.Text = \"Invalid recipe line: \" + line;\n-\nreturn;\n-\n}\n-\n}\n",
      "content_length": 1321,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 164,
      "content": "REFACTORING FOR TESTING\n150\n170\n}\n-\nsaveButton.Enabled = false;\n-\n}\n-\n-\nprivate void removeButton_Click(object sender,\n175\nSystem.EventArgs e) {\n-\nint index = ingredientsList.SelectedIndex;\n-\nif (index >= 0) {\n-\nstatusBar.Text = \"Removed \" +\n-\ningredientsList.SelectedItem;\n180\ningredientsList.Items.RemoveAt(index);\n-\nsaveButton.Enabled = true;\n-\n}\n-\n}\n-\n185\nprivate void addButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nstring newIngredient = ingredientsText.Text;\n-\nif (newIngredient.Length > 0) {\n-\ningredientsList.Items.Add(newIngredient);\n190\nsaveButton.Enabled = true;\n-\n}\n-\n}\n-\n-\nprivate void\n195\ningredientsList_SelectedIndexChanged(object sender,\n-\nSystem.EventArgs e) {\n-\nint index = ingredientsList.SelectedIndex;\n-\nif (index < 0)\n-\nremoveButton.Enabled = false;\n200\nelse {\n-\nremoveButton.Text = \"Remove \" +\n-\ningredientsList.SelectedItem;\n-\nremoveButton.Enabled = true;\n-\n}\n205\n}\n-\n-\nprivate void saveButton_Click(object sender,\n-\nSystem.EventArgs e) {\n-\nstring fileName = titleText.Text + \".txt\";\n210\nICollection items = ingredientsList.Items;\n-\nusing (StreamWriter file =\n-\nnew StreamWriter(fileName, false)) {\n-\nfile.WriteLine(\"NAME={0}\", titleText.Text);\n-\nfile.WriteLine(\"INGREDIENTS={0}\", items.Count);\n215\nforeach (string line in items) {\n-\nfile.WriteLine(line);\n-\n}\n-\n}\n-\nstatusBar.Text = \"Saved \" + fileName;\n220\n}\n-\n}\nRecipes.cs\nWe clearly need to improve this code. Let’s begin by making a\nseparate object to hold a recipe, so that we can construct test\n",
      "content_length": 1486,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 165,
      "content": "REFACTORING FOR TESTING\n151\nrecipe data easily and toss it back and forth to the screen,\ndisk, network, or wherever. This is just a simple data holder,\nwith accessors for the data members.\nLine 1\nusing System;\n-\nusing System.Collections.Generic;\n-\nusing System.Collections.ObjectModel;\n-\n5\npublic class Recipe\n-\n{\n-\nprotected string name;\n-\nprotected List<string> ingredients;\n-\n10\npublic Recipe()\n-\n{\n-\nname = string.Empty;\n-\ningredients = new List<string>();\n-\n}\n15\n-\npublic Recipe(Recipe another)\n-\n{\n-\nname = another.name;\n-\ningredients = new List<string>(another.ingredients);\n20\n}\n-\n-\npublic string Name\n-\n{\n-\nget { return name; }\n25\nset { name = value; }\n-\n}\n-\n-\npublic ReadOnlyCollection<string> Ingredients\n-\n{\n30\nget\n-\n{\n-\nreturn\n-\nnew ReadOnlyCollection<string>(ingredients);\n-\n}\n35\n}\n-\n-\npublic void AddIngredient(string ingredient)\n-\n{\n-\ningredients.Add(ingredient);\n40\n}\n-\n}\nRecipe.cs\nNext, we need to pull the code out from the original Recipes\nclass to save and load a ﬁle to disk.\nTo help separate ﬁle I/O from any other kind of I/O, we’ll per-\nform the ﬁle I/O in a helper class that uses Recipe. We want\nto take out all of the GUI widget references from the original\nsource code, and use instance member variables instead.\nLine 1\npublic class RecipeFile\n",
      "content_length": 1273,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 166,
      "content": "REFACTORING FOR TESTING\n152\n-\n{\n-\npublic Recipe Load(Stream savedRecipe)\n-\n{\n5\nRecipe recipe = new Recipe();\n-\nstring line;\n-\nchar[] delim = new char[] { ’=’ };\n-\n-\nusing (StreamReader reader = new StreamReader(savedRecipe))\n10\n{\n-\nwhile ((line = reader.ReadLine()) != null)\n-\n{\n-\nstring[] parts = line.Split(delim, 2);\n-\n15\nswitch (parts[0]) {\n-\ncase \"TITLE\":\n-\n{\n-\nrecipe.Name = parts[1];\n-\nbreak;\n20\n}\n-\ncase \"INGREDIENTS\":\n-\n{\n-\ntry\n-\n{\n25\nint count = Int32.Parse(parts[1]);\n-\nfor (int i = 0; i < count; i++)\n-\nrecipe.AddIngredient(reader.ReadLine());\n-\n}\n-\ncatch (Exception error)\n30\n{\n-\nthrow new RecipeFormatException(\n-\n\"Bad ingredient count: \" + error.Message);\n-\n}\n-\nbreak;\n35\n}\n-\n}\n-\n}\n-\n}\n-\n40\nreturn recipe;\n-\n}\n-\n-\npublic void Save(Stream savedRecipe, Recipe recipe)\n-\n{\n45\nusing (StreamWriter file =\n-\nnew StreamWriter(savedRecipe))\n-\n{\n-\nfile.WriteLine(\"NAME={0}\", recipe.Name);\n-\nfile.WriteLine(\n50\n\"INGREDIENTS={0}\",\n-\nrecipe.Ingredients.Count\n-\n);\n-\n-\nforeach (string line in recipe.Ingredients)\n55\n{\n-\nfile.WriteLine(line);\n-\n}\n",
      "content_length": 1048,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 167,
      "content": "REFACTORING FOR TESTING\n153\n-\n}\n-\n}\n60\n}\nRecipeFile.cs\nNow we’re in a position where we can write a genuine test case\nthat will test reading and writing to disk, without using any\nGUI code.\nLine 1\nusing NUnit.Framework;\n-\nusing NUnit.Framework.SyntaxHelpers;\n-\nusing System;\n-\nusing System.Collections.Generic;\n5\nusing System.IO;\n-\n-\n[TestFixture]\n-\npublic class RecipeTest\n-\n{\n10\nconst string CHEESEBURGER =\n-\n\"Cheeseburger\";\n-\nconst string SIRLOIN =\n-\n\"1/4 lb ground sirloin\";\n-\nconst string CHEESE =\n15\n\"3 slices Vermont cheddar cheese\";\n-\nconst string BACON =\n-\n\"2 slices maple-cured bacon\";\n-\nconst string RECIPE_FILE_NAME =\n-\n\"recipe.save\";\n20\n-\n[TearDown]\n-\npublic void TearDown()\n-\n{\n-\nif (File.Exists(RECIPE_FILE_NAME))\n25\n{\n-\nFile.Delete(RECIPE_FILE_NAME);\n-\n}\n-\n}\n-\n30\n[Test]\n-\npublic void SaveAndRestore()\n-\n{\n-\nRecipe recipe = new Recipe();\n-\nrecipe.Name = CHEESEBURGER;\n35\nrecipe.AddIngredient(SIRLOIN);\n-\nrecipe.AddIngredient(CHEESE);\n-\nrecipe.AddIngredient(BACON);\n-\n-\nStream recipeStream;\n40\nRecipeFile filer;\n-\nusing (recipeStream =\n-\nFile.OpenWrite(RECIPE_FILE_NAME))\n-\n{\n-\nfiler = new RecipeFile();\n45\nfiler.Save(recipeStream, recipe);\n-\n}\n",
      "content_length": 1160,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 168,
      "content": "REFACTORING FOR TESTING\n154\n-\n-\n// Now get it back\n-\nusing (recipeStream =\n50\nFile.OpenRead(RECIPE_FILE_NAME))\n-\n{\n-\nfiler = new RecipeFile();\n-\nrecipe = filer.Load(recipeStream);\n-\n}\n55\n-\nAssert.That(recipe.Ingredients.Count, Is.EqualTo(3));\n-\n-\nAssert.That(\n-\nrecipe.Name,\n60\nIs.EqualTo(CHEESEBURGER)\n-\n);\n-\n-\nAssert.That(\n-\nrecipe.Ingredients[0],\n65\nIs.EqualTo(SIRLOIN)\n-\n);\n-\n-\nAssert.That(\n-\nrecipe.Ingredients[1],\n70\nIs.EqualTo(CHEESE)\n-\n);\n-\n-\nAssert.That(\n-\nrecipe.Ingredients[2],\n75\nIs.EqualTo(BACON)\n-\n);\n-\n}\n-\n}\nRecipeTest.cs\nAt line 11 we’ll declare some constant strings for testing. Then\nwe make a new, empty object and populate it with the test\ndata beginning at line 34. We could just pass literal strings di-\nrectly into the object instead, and not bother with const data\nmembers, but since we’ll need to check the results against\nthese strings, it makes sense to put them in common con-\nstants that we can reference from both spots.\nWith a Recipe data object now fully populated, we’ll call the\nSave() method to write the recipe to disk at line 45. Now we\ncan make a brand-new Recipe object, and ask the helper to\nload it from that same ﬁle at line 53.\nWith the restored object in hand, we can now proceed to run\na whole bunch of asserts to make sure that the test data we\nset in the rec object has been restored in the rec2 object.\nFinally, at line 26 we play the part of a good neighbor and\ndelete the temporary ﬁle we used for the test. Note that we\n",
      "content_length": 1471,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 169,
      "content": "REFACTORING FOR TESTING\n155\nuse a finally clause to ensure that the ﬁle gets deleted, even\nif one of our assertions fails.\nNow we can run the unit test in the usual fashion to make\nsure that the code is reading and writing to disk okay.\nSTOP\nTry running this example before reading on. . .\nFailures:\n1) RecipeTest.SaveAndRestore :\nExpected string length 12 but was 0.\nStrings differ at index 0.\nExpected: \"Cheeseburger\"\nBut was:\n<string.Empty>\n-----------^\nat RecipeTest.SaveAndRestore() in RecipeTest.cs:58\nWhoops! Seems that wasn’t working as well as we thought—\nwe’re not getting the name line of the recipe back. When we\nsave the ﬁle out in RecipeFile.cs, the code is using the key\nstring \"NAME\" to identify the ﬁeld, but when we read it back\nin (line 19 of Load()), it’s trying to use the string \"TITLE\".\nThat’s just not going to work. We can easily change that to\nread \"NAME\", to match the key used for the save, but stop\nand ask yourself the critical question:\nCould this happen anywhere else in the code?\nUsing strings as keys is a ﬁne idea, but it does open the door\nto introduce errors due to misspellings or inconsistent naming\nas we’ve seen here. So perhaps this failing test is trying to tell\nyou something more—perhaps you should refactor the code\nand pull out those literal strings into constants.\nThe class\nthen looks like this:\nLine 1\npublic class RecipeFile\n-\n{\n-\nconst string NAME_TOKEN = \"NAME\";\n-\nconst string INGREDIENTS_TOKEN = \"INGREDIENTS\";\n5\n-\npublic Recipe Load(Stream savedRecipe)\n-\n{\n-\nRecipe recipe = new Recipe();\n-\nstring line;\n10\nchar[] delim = new char[] { ’=’ };\n-\n-\nusing (StreamReader reader = new StreamReader(savedRecipe))\n-\n{\n",
      "content_length": 1666,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 170,
      "content": "REFACTORING FOR TESTING\n156\n-\nwhile ((line = reader.ReadLine()) != null)\n15\n{\n-\nstring[] parts = line.Split(delim, 2);\n-\n-\nswitch (parts[0]) {\n-\ncase NAME_TOKEN:\n20\n{\n-\nrecipe.Name = parts[1];\n-\nbreak;\n-\n}\n-\ncase INGREDIENTS_TOKEN:\n25\n{\n-\ntry\n-\n{\n-\nint count = Int32.Parse(parts[1]);\n-\nfor (int i = 0; i < count; i++)\n30\nrecipe.AddIngredient(reader.ReadLine());\n-\n}\n-\ncatch (Exception error)\n-\n{\n-\nthrow new RecipeFormatException(\n35\n\"Bad ingredient count: \" + error.Message);\n-\n}\n-\nbreak;\n-\n}\n-\n}\n40\n}\n-\n}\n-\n-\nreturn recipe;\n-\n}\n45\n-\npublic void Save(Stream savedRecipe, Recipe recipe)\n-\n{\n-\nusing (StreamWriter file =\n-\nnew StreamWriter(savedRecipe))\n50\n{\n-\nfile.WriteLine(\n-\n\"{0}={1}\",\n-\nNAME_TOKEN,\n-\nrecipe.Name\n55\n);\n-\n-\nfile.WriteLine(\n-\n\"{0}={1}\",\n-\nINGREDIENTS_TOKEN,\n60\nrecipe.Ingredients.Count\n-\n);\n-\n-\nforeach (string line in recipe.Ingredients)\n-\n{\n65\nfile.WriteLine(line);\n-\n}\n-\n}\n-\n}\n",
      "content_length": 899,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 171,
      "content": "REFACTORING FOR TESTING\n157\n-\n}\nRecipeFile.cs\n",
      "content_length": 46,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 172,
      "content": "REFACTORING FOR TESTING\n158\nRecipe\nname\ningredients\nRecipeGUI\nShowGUI()\nRecipeFile\nLoad()\nSave()\nFigure 9.3: Refactored Recipes Static Class Diagram\nWe’ve improved the original program a lot with these simple\nchanges. In order to test the ﬁle I/O, we:\n• Made Recipe a ﬁrst-class object\n• Moved ﬁle I/O routines out of the GUI and into Recipe-\nFile to narrow the class’ responsibility.\n• Pulled literals into constants to avoid bugs from typos\nand reduce duplication.\nFinally, now that we have unit tests that provide the basic ca-\npabilities of a Recipe, we need to re-integrate the new Recipe\nclass into the GUI itself and tend to the ﬁle I/O. We’d like to\nend up with something like Figure 9.3.\nNow RecipeGUI holds an object of type Recipe, and uses\nthe helper class RecipeFile to read and write recipes to\ndisk.\nWhen the user presses the save button, the GUI will\nset values from the widgets in the Recipe object and call\nRecipeFile.Save(). When a new recipe is loaded in, the GUI\nwill get the proper values from the Recipe object returned\nfrom RecipeFile.Load().\nTesting a GUI can be very hard, but usually because the code\n",
      "content_length": 1128,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 173,
      "content": "TESTING THE CLASS INVARIANT\n159\nis written in such a way as to make it difﬁcult.\nThis kind\nof code isn’t uncommon, either—this is what happens when\nyou use the WinForms designer to generate code and then\njust integrate logic directly into the generated method’s code.\nIt can be tempting to use something like NUnitForms to test\nthis kind of logic, but if we went that route our tests would\nend up long and complicated.\nBy separating the pure GUI-related code from the actual logic\nof the application, you can easily add and test business fea-\ntures without having to worry about how you’re going to weave\nit into the GUI code.\nThe main GUI class RecipeGUI (formerly known as Recipes)\nshould now contain nothing but GUI-oriented code: widgets,\ncallbacks, and so on. Thus, all of the “business logic” and ﬁle\nI/O can be in non-GUI, fully testable classes.\nAnd we’ve got a clean design as an added bonus.\n9.3\nTesting the Class Invariant\nAnother way to improve the design of a class is by deﬁning\nand verifying the “class invariant.”1\nA class invariant is an assertion, or some set of assertions,\nabout objects of a class. For an object to be valid, all of these\nassertions must be true. They cannot vary.\nFor instance, a class that implements a sorted list may have\nthe invariant that its contents are in sorted order. That means\nthat no matter what else happens, no matter what methods\nare called, the list must always be in sorted order—at least as\nviewed from outside the object. Within a method, of course,\nthe invariant may be momentarily violated as the class per-\nforms whatever housekeeping is necessary. But by the time\nthe method returns, or the object is otherwise available for\nuse (as in a multi-threaded environment), the invariant must\nhold true or else it indicates a bug.\n1For more information on pre-conditions, post-conditions and invariants,\nsee [Mey97].\n",
      "content_length": 1872,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 174,
      "content": "TESTING THE CLASS INVARIANT\n160\nThat means it’s something you could check for as part of every\nunit test for this class.\nThe invariant is generally an artifact of implementation: inter-\nnal counters, the fact that certain member variables are pop-\nulated, and so on. The invariant is not the place to check for\nuser input validation or anything of that sort. When writing\ntests, you want to test just your one thing, but at the same\ntime you want to make sure the overall state of the class is\nconsistent—you want to make sure you have not inﬂicted any\ncollateral damage.\nHere are some possible areas where class invariants might\napply.\nStructural\nThe most common invariants are structural in nature. That\nis, they refer to structural properties of data. For instance, in\nan order-entry system you might have invariants such as:\n• Every line item must belong to an order\n• Every order must have one or more line items\nWhen working with arrays of data, you’ll typically maintain\na member variable that acts as an index into the array. The\ninvariants on that index would include:\n• index must be >= 0\n• index must be < array length\nYou want to check the invariant if any of these conditions\nare likely to break. Suppose you are performing some sort of\ncalculation on the index into an array; you’d want to check the\ninvariant throughout your unit tests to make sure the class\nis never in an inconsistent state. We showed this in the stack\nclass example on page 77.\nStructural errors will usually cause the program to throw an\nexception and/or terminate abruptly. For that matter, so will\nfailing the invariant check. The difference is that when the\ninvariant is violated, you know about it right away—right at\nthe scene of the crime. You’ll probably also know exactly what\ncondition was violated. Without the invariant, the failure may\n",
      "content_length": 1834,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 175,
      "content": "TEST-DRIVEN DESIGN\n161\noccur far from the original bug, and backtracking to the cause\nmight take you anywhere from a few minutes to a few days.\nMore importantly, checking the invariant makes sure that you\naren’t passing the tests based just on luck. It may be that\nthere’s a bug that the tests aren’t catching that will blow up\nunder real conditions.\nThe invariant might help you catch\nthat early, even if an explicit test does not.\nMathematical\nOther constraints are more mathematical in nature. Instead\nof verifying the physical nature of data structures, you may\nneed to consider the logical model. For example:\n• Debits and credits on a bank account match the balance.\n• Amounts measured in different units match after con-\nversion (an especially popular issue with spacecraft).\nThis starts to sound a lot like the boundary conditions we\ndiscussed earlier, and in a way they are.\nThe difference is\nthat an invariant must always be true for the entire visible\nstate of a class. It’s not just a ﬂeeting condition; it’s always\ntrue.\nData Consistency\nOften times an object may present the same data in different\nways—a list of items in a shopping cart, the total amount of\nthe sale, and the total number of items in the cart are closely\nrelated. From a list of items with details, you can derive the\nother two ﬁgures. It must be an invariant that these ﬁgures\nare consistent. If not, then there’s a bug.\n9.4\nTest-Driven Design\nTest-driven development is a valuable technique where you\nalways write the tests themselves before writing the methods\nthat they test [wCA04]. As a nice side beneﬁt of this style of\nworking, you can enjoy “test-driven design” and signiﬁcantly\nimprove the design of your interfaces.\n",
      "content_length": 1709,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 176,
      "content": "TEST-DRIVEN DESIGN\n162\nYou’ll get better interfaces (or API’s) because you are “eating\nyour own dog food,” as the saying goes—you are able to apply\nfeedback to improve the design.\nThat is, by writing the tests ﬁrst, you have now placed yourself\nin the role of a user of your code, instead of the implementor of\nyour code. From this perspective, you can usually get a much\nbetter sense of how an interface will really be used, and might\nsee opportunities to improve its design.\nFor example, suppose you’re writing a routine that does some\nspecial formatting for printed pages.\nThere are a bunch of\ndimensions that need to be speciﬁed, so you code up the ﬁrst\nversion like this:\nAddCropMarks(PSStream str, double paper_width,\ndouble paper_height,\ndouble body_width,\ndouble body_height);\nThen as you start to write the tests (based on real-world data)\nyou notice that a pattern emerges from the test code:\npublic Process() {\nxxx xx xxxxx xxx xx x xx xxx xxx xxxx xx xx;\nx xx x xxx xxxx xx xxx xx xxxxx xxxx;\nAddCropMarks(str, 8.5, 11.0, 6.0, 8.5);\nxx xxx x xxx xxx xx x xxx xxx xxx xxx xx xxx;\nx xxx xxx xxxx x xxx xxx\nxxx xxxx xx xxx xx;\nAddCropMarks(str, 8.5, 11.0, 6.0, 8.5);\nxx xx xxxx xx xx xxx xxx\nxxx xxxx xx xx xx xx;\nx xx xx x xxxx xxx x xxxx xx xx xx xxx xxx xx;\nAddCropMarks(str, 8.5, 11.0, 6.0, 8.5);\nxxx xx xxxxxxx xxx\nxxx xxxxx\nx xxx xxxx xx xxxxxx;\nxx\nx xxx xxxx xxxx xxx\nxxxx xxxx xx x x xx xx;\nAddCropMarks(str, 5.0, 7.0, 4.0, 5.5);\nxx xxx xxx xx x xxx xxx\nxxx xxxx xx xx xx xxx xx;\nxxx xx xxxxx xxx xx xxx x xxx xxxx xx xx xx xxx;\nAddCropMarks(str, 5.0, 7.0, 4.0, 5.5);\nxx xx xxxxx xx x xx xxx xxx xxxx xx xx;\nx xxx\nx xxx xxxx xx xx xxx xxxx xx;\n}\nAs it turns out, there are only a handful of common paper\nsizes in use, but you still need to allow for odd-ball sizes as\nnecessary.\nSo the ﬁrst thing to do—just to make the tests\neasier, of course—is to factor out the size speciﬁcation into a\nseparate object.\nPaperSpec standardPaper1 = new PaperSpec(8.5, 11.0,\n6.0, 8.5);\nPaperSpec standardPaper2 = new PaperSpec(5.0, 7.0,\n",
      "content_length": 2038,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 177,
      "content": "TESTING INVALID PARAMETERS\n163\n4.0, 5.5);\nxxx xx xxxxxxx xxx\nxxx xxxxx\nx xxx xxxx xx xxxxxx;\nxx\nx xxx xxxx xxxx xxx\nxxxx xxxx xx x x xx xx;\nAddCropMarks(str, standardPaper1);\nAddCropMarks(str, standardPaper1);\nxx xxx xxx xx x xxx xxx\nxxx xxxx xx xx xx xxx xx;\nxxx xx xxxxx xxx xx xxx x xxx xxxx xx xx xx xxx;\nAddCropMarks(str, standardPaper2);\nNow the tests are much cleaner and easier to follow, and the\napplication code that uses this will be cleaner as well.\nSince these standard paper sizes don’t vary, we can make\na factory class that will encapsulate the creation of all the\nstandard paper sizes.\npublic class StandardPaperFactory {\npublic static PaperSpec LetterInstance;\npublic static PaperSpec A4Instance;\npublic static PaperSpec LegalInstance;\nxxxxxx xxxxxx xxxxxxxxx xxxxxxxxxxx;\nxxxxxx xxxxxx xxxxxxxxx xxxxxxxxxxx;\n}\nBy making the tests cleaner and easier to write, you will make\nthe real code cleaner and easier to write as well.\nTry it\nExercises\n7.\nDesign an interest calculator that calculates the amount of in-\nAnswer\non 201\nterest based on the number of working days in-between two\ndates. Use test-ﬁrst design, and take it one step at a time.\n9.5\nTesting Invalid Parameters\nOne question that comes up when folks ﬁrst start testing is:\n“Do I have to test whether my class validates it parameters?”\nThe answer, in best consultant fashion, is “it depends. . . .”\nIs your class supposed to validate its parameters? If so, then\nyes, you need to test that this functionality is correct. But\nthere’s a larger question here: Who’s responsible for validat-\ning input data?\nIn many systems, the answer is mixed, or haphazard at best.\nYou can’t really trust that any other part of the system has\n",
      "content_length": 1703,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 178,
      "content": "TESTING INVALID PARAMETERS\n164\nchecked the input data, so you have to check it yourself—or at\nleast, that aspect of the input data that particularly concerns\nyou. In effect, the data ends up being checked by everyone\nand no one. Besides being a grotesque violation of the DRY\nprinciple [HT00], it wastes a lot of time and energy—and we\ntypically don’t have that much extra to waste.\nIn a well-designed system, you establish up-front the parts of\nthe system that need to perform validation, and localize those\nto a small and well-known part of the system.\nSo the ﬁrst question you should ask about a system is, “who\nis supposed to check the validity of input data?”\nGenerally we ﬁnd the easiest rule to adopt is the “keep the\nbarbarians out at the gate” approach.\nCheck input at the\nboundaries of the system, and you won’t have to duplicate\nthose tests inside the system. Internal components can trust\nthat if the data has made it this far into the system, then it\nmust be okay.\nIt’s sort of like a hospital operating room or industrial “clean\nroom” approach. You undergo elaborate cleaning rituals be-\nfore you—or any tools or materials—can enter the room, but\nonce there you are assured of a sterile ﬁeld. If the ﬁeld be-\ncomes contaminated, it’s a major catastrophe; you have to\nre-sterilize the whole environment.\nAny part of the software system that is outward-facing (a UI,\nor interface to another system) needs to be robust, and not\nallow any incorrect or unvalidated data through. What deﬁnes\n“correct” or valid data should be part of speciﬁcation you’re\ntesting against.\nWhat does any of this have to do with unit testing?\nIt makes a difference with regard to what you need to test\nagainst. As we mentioned earlier, if it isn’t your code’s respon-\nsibility to check for input data problems, then don’t waste\ntime checking for it. If it is your responsibility, then you need\nto be extra vigilant—because now the rest of the system is\npotentially relying on you, and you alone.\nBut that’s okay. You’ve got unit tests.\n",
      "content_length": 2024,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 179,
      "content": "Chapter 10\nGUI Testing\nNow that we’ve separated out the logic from our UI code, what\nis there left to test in the GUI? And how is this a “unit test”\nwhen the GUI is involved?\n10.1\nUnit testing WinForms\nWe’re going to see how this works in the real world using\nthe NUnitForms framework, which is an extension of NUnit\n(http://nunitforms.sourceforge.net). Alas, NUnitForms\nuses Win32 native calls to work its magic and therefore\ndoesn’t currently work under Mono.\nBecause NUnitForms\nitself depends upon NUnit, we may ﬁnd that the version of\nAndy’s Rant on GUI Testing\n“Some people are convinced that they must com-\npare bitmaps to do GUI testing. Well, that is simply\nthe most antiquated, 1970’s bit of thinking I can imag-\nine. For crying out loud, I wrote a GUI tester based on\nX11 back in 1992 or so that was object-oriented (i.e., it\nworked with the ’OK’ button object on a form, place-\nment was irrelevant), scriptable, could do live record\nand playback and then later editing of the event, test\ncomposition, etc. And that was some 15 years ago.”\n",
      "content_length": 1050,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 180,
      "content": "UNIT TESTING WINFORMS\n166\nnunit.framework.dll we are referencing during compilation of\nour code isn’t the same version as the one NUnitForms was\nbuilt against.\n(The compiler will actually warn us of this.)\nDon’t panic, we’ll talk more about this later in the chapter.\nLet’s get started. There’s no magic here; remember that unit\ntests are just code, and controls (forms included) are just ob-\njects.\nFor instance, we can create and use additional con-\nstructors, and not just be stuck with the default empty con-\nstructor. If a Form requires a Recipe object to display, for\nexample, then the Form should have a constructor that takes\na Recipe parameter.\nNow we’ve got a ﬁrst easy unit test that doesn’t require\nNUnitForms—pass null in for the parameter and expect an\nArgumentNullException:\n[TestFixture]\npublic class RecipeViewFormTests\n{\n[Test]\n[ExpectedException(typeof(ArgumentNullException))]\npublic void NullRecipe()\n{\nnew RecipeViewForm(null);\n}\n}\nWhat\ncan\nwe\ntest\nthat’s\nactually\nGUI-related?\nThe\nRecipeViewForm has two buttons: Save and Cancel.\nYou\nwant to make sure that the Save button calls the Save()\nmethod on the Recipe object that is passed to it. (We’re only\nconcerned with the GUI functionality of the Save button—the\nlogic behind the Recipe.Save() method is tested elsewhere.)\nWe’ll use mock objects to make our lives easier.\nusing NUnit.Framework;\nusing NUnit.Framework.SyntaxHelpers;\nusing NUnit.Extensions.Forms;\nusing RecipeViewer;\nusing System;\nnamespace RecipeViewer.Tests\n{\npublic class FakeRecipe : Recipe\n{\nUInt32 saveCalled = 0;\npublic UInt32 SaveCalled\n{\n",
      "content_length": 1584,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 181,
      "content": "UNIT TESTING WINFORMS\n167\nget { return saveCalled; }\n}\npublic override Save()\n{\nsaveCalled++;\n}\n}\n[TestFixture]\npublic class RecipeViewFormTests\n{\n[Test]\npublic void Save()\n{\nFakeRecipe recipe = new FakeRecipe();\nRecipeViewForm recipeView =\nnew RecipeViewForm(recipe as Recipe);\nrecipeView.Show();\nButtonTester saveButton = new ButtonTester(\"Save\");\nsaveButton.Click();\nAssert.That(recipe.SaveCalled, Is.EqualTo(1));\n}\n}\n}\nFirst, we create a fake object for Recipe which tracks the\nnumber of calls to the Save() method. Then, we make a new\nRecipeViewControl and give it our FakeRecipe object, add\nthe control to a form, and ﬁnally call the Show() method on\nthe form. When we run the test, the form with the control will\npop up quickly (don’t blink or you’ll miss it).\nNext, we create a ButtonTester for the Save button. Note\nthat the ButtonTester isn’t based on the contents of the But-\nton’s Text property, but rather the Name property. Make sure\nyou give these sane names and not use the default ones gen-\nerated by the designer.\nWe then call the Click() method on the ButtonTester, and\nask the fake Recipe how many times Save() was called. We\nwant to assert that it was called only once.\nPretty cool, huh? By faking the model, we kept the unit test\nvery focused, even though it was testing the GUI. We could\nalso use one of the mock object frameworks discussed in\nChapter 6.\nHere’s another example we want to make sure works: press-\ning the Cancel button doesn’t save the recipe.\n",
      "content_length": 1483,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 182,
      "content": "UNIT TESTING WINFORMS\n168\n[Test]\npublic void Cancel()\n{\nFakeRecipe recipe = new FakeRecipe();\nRecipeViewControl recipeView =\nnew RecipeViewControl(recipe as Recipe);\nForm form = new Form();\nform.Add(recipeView);\nform.Show();\nButtonTester cancelButton = new ButtonTester(\"Cancel\");\ncancelButton.Click();\nAssert.That(recipe.SaveCalled, Is.EqualTo(0));\n}\nWe introduced a little duplication here with the previous test,\nso it’s time to refactor a bit.\nFirst, extract recipe and\nrecipeView to be class-level ﬁelds; then extract the intial-\nization of those ﬁelds into SetUp() so they’re fresh for each\ntest method. We’ve eliminated duplicate code, so we’re ready\nto proceed.\nMocking the User\nNUnitForms can also simulate a user changing ﬁelds in the\nGUI via the keyboard, and all other kinds of things, relatively\neasily.\nThere’s only one major exception and that’s modal\ndialogs.\n[TestFixture]\npublic class LoginModalDialogTest : NUnitFormTest\n{\nconst string PASSWORD_FAILURE = \"Password Failure\";\n[Test]\npublic void PasswordFailureClickOK()\n{\nExpectModal(PASSWORD_FAILURE, \"PasswordFailureOkHan-\ndler\");\nMessageBox.Show(\"Try again?\", PASSWORD_FAILURE);\n}\npublic void MessageBoxOkHandler()\n{\nMessageBoxTester messageBox =\nnew MessageBoxTester(PASSWORD_FAILURE);\nAssert.That(\nmessageBox.Title,\nIs.EqualTo(PASSWORD_FAILURE)\n);\nmessageBox.ClickOk();\n",
      "content_length": 1343,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 183,
      "content": "UNIT TESTING BEYOND WINDOWS FORMS\n169\n}\n}\nModal dialogs are interesting because they suspend the pro-\ngram until they’re dismissed. Thankfully, NUnitForms has a\nway to deal with that, using the ExpectModal method in the\nNUnitFormTest class.\nTo use it (or any other NUnitForms\nmethods), we derive our ﬁxture from NUnitFormTest and call\nExpectModal, passing the name of the caption (aka title) of\nthe modal dialog. When a modal dialog is displayed that has\nthe speciﬁed caption, the handler method is called. So in our\nhandler method, we do our button clicks, assertions, and so\non, and then dismiss the dialog as a user would. Then our\ntests continue on their merry way.\n10.2\nUnit testing beyond Windows Forms\nWhat if we’re using a UI library that isn’t Windows Forms?\nThis isn’t unthinkable, and it certainly isn’t untestable either.\nThere are some nuances, but many of the concepts presented\nthus far apply equally. We just won’t have a nice framework\nlike NUnitForms to help us along.\nFor other common GUI toolkits, like Qt# and Gtk#, there is\nsome variance in the ease of testing. Qt# is a .NET binding\nto the open source C++ native library, Qt. Qt 4.1 and above\nhas a built-in unit testing framework called QTestLib. Gtk# is\nalso a wrapper (in essence), but neither the wrapper nor the\nnative library has a unit testing framework associated with it\nas of the time of this writing.\nWhat about custom GUIs, like ones that are 3D?1 That turns\nout to be easier in some cases, because we have more control\nover the design and can make it easy to test.\nMost 3D applications use a scene graph, which is a tree of\nnodes where the nodes in the tree represent things to be\ndrawn in 3D space. The nodes know their X, Y, and Z (depth)\ncoordinates, and their length along those planes.\nA visitor\nclass visits each node in the scene graph and is responsible\n1For\ninstance,\na\nC#\nwrapper\naround\nOpenGL,\nlike\nTao:\nhttp://www.taoframework.com\n",
      "content_length": 1929,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 184,
      "content": "UNIT TESTING BEYOND WINDOWS FORMS\n170\nTesting code that runs on the GPU\nThanks to Ryan Dy, a programmer on some of Matt’s\nfavorite XBox games, for this real-world detail:\nSometimes there are transformations that aren’t done\non the CPU, they’re done on the GPU via shader pro-\ngrams. In that case, we need to expose the shader\nvariables to our test code running on the CPU so we\ncan make assertions. To accomplish that, we would\nwrite a shader program that would expose the val-\nues we need to assert against in our test.\nThis is a\ncommon method for debugging shader code, and\nit also allows us to make sure our shader perform simi-\nlarly across different hardware implementations in an\nautomated fashion.\nfor things like rendering the node in the 3D space or passing\nmessages such as mouse clicks or keyboard interactions.\nIt’s relatively straightforward to see where testing could be\nintroduced in this common 3D scenario. First, we may want\nto test the nodes themselves, but they are usually data-only—\nall the behaviour generally goes into the visitor2 objects that\napply transformations to the data contained in the nodes.\nNext, we could test the scene graph collection and make sure\nit is self-balancing based upon Z-order (or whatever other\nproperties we expect).\nLast, the visitor classes themselves\ncan be unit tested if they are well-encapsulated and loosely\ncoupled with the rest of the design.\nThis is a lot of talk to be sure; how can you actually code up\na test that makes sure that our layout algorithm ﬁts all the\nnodes onto the rendered screen? We might sketch out a test\nthat looks like this:\nMissing: [Code to be written]\nWhat’s this magical method referenced? It’s sometimes easier\n2Fun fact: Scene graphs are one of the few places that the Visitor design\npattern is commonly applied.\n",
      "content_length": 1804,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 185,
      "content": "WEB UIS\n171\nto write the test as you’d like it to read, then work backward\nand ﬁll in the missing pieces.\nNow that we have the test as we’d like it to read, here’s the\ncode for the aforementioned magical method:\nMissing: [Code to be written]\n10.3\nWeb UIs\nAn entire book could be written about testing web-based UIs.\nWe’ll touch on it brieﬂy here because many people are un-\nder the impression this is not possible or requires expen-\nsive commercial tools.\nFirst, many “Web 2.0” applications\nhave a great deal of their functionality in JavaScript (aka EC-\nMAScript). Unlike the dark ages of JavaScript, it is now an\nopen ECMA standard with frameworks available that make\nobject-orientation and unit testing a snap. In many modern\napplications, much of the important end-user functionality is\non the client-side in JavaScript. The server-side code mostly\naccepts AJAX requests that either retrieve or store data in the\ndatabase with some data validation and logging.\nAs such, unit testing the JavaScript is the ﬁrst step.\nWe\nrecommend JsUnit,3 which provides a framework and a test-\nrunner that can run within most modern browsers. You can\nassert that your JavaScript code is having the correct effect\non speciﬁc DOM elements, such as adding or removing styles,\nchild nodes, or whatever. This allows us to ﬁnd and test for\nbugs that would normally have to be done manually with vi-\nsual inspection.\nWe also recommend using a framework like Prototype or\nJQuery that provide various syntactic and functional helpers\nthat make JavaScript a little easier to code and test. There\nare all sorts of nifty AJAX libraries and frameworks out there,\nbut we should make sure that they don’t hinder our ability to\nunit test functionality. See the JsUnit web site for examples—\nmany of the concepts from this book can be applied equally\nbetween C#, JavaScript, and other languages.\n3http://www.jsunit.net\n",
      "content_length": 1889,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 186,
      "content": "WEB UIS\n172\nTo test web applications beyond JavaScript and our server-\nside objects, there is a free, open source tool called Sele-\nnium.4\nWith Selenium, you can write code that drives any\nof the mainstream browsers on the operating system of your\nchoice. It works by running a server that launches a browser,\nwhich accepts commands via a socket and translates those\ncommands into browser clicks and keyboard input.\nThis means we can write NUnit tests that look like this:\n[Test]\npublic void AnchoviesNotAvailableInMontana()\n{\nISelenium selenium =\nnew DefaultSelenium(\n\"localhost\", 4444, \"firefox2\",\n\"http://localhost:56789/OrderPizza.aspx\"\n);\nselenium.Select(INGREDIENT_DROPDOWN_ID, \"anchovies\");\nselenium.Type(STATE_TEXT_ID, \"montana\");\nselenium.Click(\"submit\");\nselenium.WaitForCondition(\n\"selenium.isTextPresent(’Not Available’)\"\n);\n}\nWe instantiate a new selenium controller, which starts the\nselenium server. This in turn starts the browser. We tell the\nselenium controller to select \"anchovies\" from a list control.\nNote that the location and style of that control don’t really\nmatter—we’re just working off the HTML IDs.\nBecause we\nhave stored the HTML IDs into a variable, we only have to\nchange them in one place should the HTML ID in the user\ninterface change. Then, we tell selenium to type ’montana’ in\nthe input control. Next, we tell selenium to click a button with\nthe HTML ID of ’submit’. Last, we wait for the validator (or\nwhatever else) text to appear. If the condition isn’t met by the\ndefault timeout,5 the test will fail. One interesting side note\nis that selenium.isTextPresent is a snippet of JavaScript\nthat will tell Selenium what to do on the browser-side.\nSelenium tests are like any other tests; you tend to do the\nsame things over and over. Being the pragmatic programmers\nthat we are, we don’t stand for duplication.\nWhen we see\n4http://www.openqa.org/selenium/index.html\n560 seconds in Selenium 0.9\n",
      "content_length": 1932,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 187,
      "content": "WEB UIS\n173\nJoe Asks. . .\nAren’t Selenium tests more like system tests?\nYes, Selenium tests aren’t really unit tests, even though\nwe are driving the browser in NUnit. ASP.NET doesn’t\nhave a good way to isolate the various handlers for\ntesting as of the time of this writing.a As such we have\na multi-lateral approach to get much of the same\nbeneﬁt. The ASP.NET pages and controls should be a\nvery thin layer on top of other, more easily testable,\nobjects—just like for WinForms or any other widget li-\nbrary. Selenium then helps us test the interaction be-\ntween the web controls and those underlying model\nobjects. It is slower, mainly due to the overhead of\nstarting and running a real browser, but it is deﬁnitely\nbetter than manual web UI testing. When using a sys-\ntem testing tool like Selenium, make sure to exclude\nit from your code coverage measurements. Your unit\ntests alone should provide high levels of code cov-\nerage; measuring the coverage of system-level tests\nobscures that data.\naWebWork and Rails do, which are Java- and Ruby-based re-\nspectively.\nit, we refactor by extracting methods, extracting a class, and\nperforming other refactorings. A very common pattern with\nSelenium is to wrap the Selenium instance and delegate to\nit. By doing this, you can have assertion and helper methods\ntied to a project-speciﬁc Selenium object that can be shared.\nnamespace PizzaWeb.Test.UI\n{\npublic class MySelenium\n{\nprotected ISelenium selenium;\npublic MySelenium(string host,\nint port,\nstring[] browsers,\nstring url)\n{\nselenium =\nnew DefaultSelenium(host, port, browsers, url);\n}\n",
      "content_length": 1590,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 188,
      "content": "WEB UIS\n174\npublic Stop()\n{\nselenium.Stop();\n}\npublic void waitForText(string expectedText)\n{\nselenium.WaitForCondition(\n\"selenium.isTextPresent(’\" + expectedText + \"’)\"\n);\n}\n}\n}\nSomething else that often gets repeated is the creation of\nthe selenium instance and the closing of the browser.\nAn-\nother common pattern is to have a base class that selenium-\noriented ﬁxtures derive from.\nnamespace PizzaWeb.Test.UI\n{\npublic abstract class MySeleniumFixture\n{\nstatic final uint SELENIUM_SERVER_PORT = 56789;\nprotected MySelenium selenium;\n[TestFixtureSetUp]\npublic void StartBrowser()\n{\nselenium = new MySelenium(\n\"localhost\", SELENIUM_SERVER_PORT,\n\"firefox2\", getInitialUrl()\n);\n}\n[TestFixtureTearDown]\npublic void StopBrowser()\n{\nselenium.Stop();\n}\nprotected abstract string getInitialUrl();\n}\n[TestFixture]\npublic class OrderPizzaTest : MySeleniumFixture\n{\nstatic final string INGREDIENT_DROPDOWN_ID = \"ingredi-\nents\";\nstatic final string STATE_TEXT_ID = \"state\";\nstring getInitialUrl()\n{\nreturn \"http://localhost:7890/OrderPizza.aspx\";\n}\n[Test]\n",
      "content_length": 1046,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 189,
      "content": "COMMAND LINE UIS\n175\npublic void AnchoviesNotAvailableInMontana()\n{\nselenium.Select(\nINGREDIENT_DROPDOWN_ID,\n\"anchovies\"\n);\nselenium.Type(STATE_TEXT_ID, \"montana\");\nselenium.Click(\"submit\");\nselenium.waitForText(\"Not Available\");\n}\n}\n}\nWhen making the selenium instance, only one thing gener-\nally varies from test to test: the initial URL the browser loads.\nTo reuse the creation of the selenium instance, we extracted\nit into a method and then into a base class that the test ﬁx-\nture itself derives from. We marked that creation method with\nthe TestFixtureSetUp attribute so we don’t keep closing and\nopening the browser for every test. Your application may need\nto close the browser for each test, though, in which case we\nshould use SetUp and TearDown instead. The base class de-\nﬁnes the abstract method called getInitialUrl() which the\nderived class must implement. When we add a new test ﬁx-\nture for a different web page, we’ll override that method and\nget the beneﬁts of reuse.\nIn our example we set the default browser to ’ﬁrefox2’. If you\nwant to test with Internet Explorer as well, you can make\nsure your tests pass under both browsers by adding “IE6” to\nthe third parameter of the DefaultSelenium constructor.\n10.4\nCommand Line UIs\nBefore we ﬁnish talking about GUI Testing, we can’t forget\nabout our old friend the command line. Once again, the ﬁrst\nstep is to make sure that our static Main() method is a thin\nlayer that mostly interacts with other, more easily testable,\nobjects. Often, argument parsing is done in a quick and dirty\nfashion right in the Main() method. What do you do if there is\na bug in the command line argument parsing, and you want\nto write a unit test that fails when the bug is present and\npasses when it is ﬁxed? Say you had code like this:\nprivate static void isTracing;\n",
      "content_length": 1814,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 190,
      "content": "COMMAND LINE UIS\n176\npublic static void Main(string[] args)\n{\nif (args.Length < 1)\n{\nprintUsage();\nEnvironment.Exit(-1);\n}\nif (args[0] == \"--trace\")\n{\nisTracing = true;\n}\n}\nThere is a bug (or lack of feature, depending on your personal\noutlook) where the -trace command line option is only rec-\nognized when it is the ﬁrst argument. We want to unit test the\nchange, regardless, because text processing is one of those\nareas in our experience where bugs tend to creep back in as\nseemingly “safe” changes are made.\nOne way would be to\nwrite a test like this:\n[Test]\npublic void TraceAsSecondArgument()\n{\nTextUI.Main(new String[] {\"filename\", \"--tracing\"});\nAssert.That(Main.IsTracing, Is.True);\n}\nThis test wouldn’t compile as-is—we would have to add a\nstatic property called IsTracing to our class.\nIf you ﬁnd\nyourself thinking this doesn’t feel right, we would agree with\nyou. Like the other UI testing paradigms we’ve discussed, we\nwant Main() to be a thin layer that does a little coordina-\ntion between other objects. Adding a property makes it fatter\nrather than thinner.\nInstead, let’s ﬁrst extract a method which will help highlight\nsome better seams along which we can extract a class that we\ncan then unit test.\nprivate static bool hasTracing(string[] args)\n{\nreturn (args[0] == \"--trace\");\n}\nNow here’s something we can unit test more easily. Testing\nthe Main() class still feels a little weird, so let’s extract that\nstatic method into a class called Args. Once we do that, we\ncan write a test like this:\n",
      "content_length": 1515,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 191,
      "content": "GUI TESTING GOTCHAS\n177\n[Test]\npublic void TraceAsSecondArgument()\n{\nArgs args = new Args(new string[] {\"filename\", \"--\ntracing\"});\nAssert.That(args.IsTracing, Is.True);\n}\nThis example backs up Andy’s rant from the beginning of the\nchapter. Unit testing most GUI code is hard only because peo-\nple think it is, not because it is that technically challenging.\nOnce we just approach the problem as though it is solvable\nand apply those amazing programming skills we posess, it\nbecomes one of the more trivial issues we’ll deal with in our\nprofessional career.\n10.5\nGUI Testing Gotchas\nGUI testing is fairly straight-forward, save for a couple of\ngotchas that we’ll discuss in this section. Don’t be scared—\nknowing about these issues up front deﬂates their difﬁculty\nquite a bit.\nConﬂicting NUnit libraries\nIf NUnitForms was built against a speciﬁc version of NUnit\nand that differs from the version of the NUnit libraries you’re\nreferencing in your project, you’ll get a compiler warning\ntelling you as such. This usually doesn’t present a problem,\nbut if it does there’s an easy way to ﬁx it.\nDownload the NUnitForms source code, and replace it’s NUnit\nlibraries with the version of NUnit you’re using. Then build\nNUnitForms and store the custom build in your project’s lib/\ndirectory.\nThis seems like a big deal, but it’s a minor an-\nnoyance at worst. You’ll have to rebuild when there’s a new\nNUnitForms release that you must deploy, but that’s about it.\nAutomated build\nThere’s a simple “gotcha” here worth mentioning when using\nNUnitForms (or similar tools) in an automated build.\n",
      "content_length": 1585,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 192,
      "content": "GUI TESTING GOTCHAS\n178\nIf your automated build runs as a service, you will be unable\nto show any modal dialogs.\nAttempting to do so will result\nin an exception that basically says “don’t show modal dialogs\nin a service.” This is historical, and does make some sense.\nSince the service doesn’t have a desktop where someone could\ndismiss a modal dialog, the service would get stuck and the\nmachine would require a reboot. This happened enough times\nwith poorly written commercial applications that Microsoft\nnipped it in the bud by disallowing it altogether.\nThere is an easy workaround, and it’s only a little messy. Start\nyour automated build controller from a logged-in account, via\na batch ﬁle or shell script.\nThen set the build machine to\nauto-login on boot and run the batch ﬁle on start-up for that\nuser. It ends up practically the same as running the service,\nbut you won’t run into the aforementioned issue with modal\ndialogs.\nMultithreaded and Complex Controls\nNow, for a more advanced gotcha.\nIf you’re testing a Form that contains a control that is mul-\ntithreaded and does interesting things with the Win32 event\nloop (such as MSHTML, the Internet Explorer HTML render-\ning control), you may ﬁnd it doesn’t work correctly when you\ntry to unit test it. This is because the event loop doesn’t work\nthe same in this test runner as it does when running under\nregular Windows.\nYou\ncan\nwork\naround\nthis\nby\ncalling\nApplica-\ntion.DoEvents(), which will suspend your current thread\nand run the message pump thread until there are no pending\nWin32 events in the queue.\nIn the case of some unreasonably complex controls (e.g.,\nMSHTML), you may have to run Application.DoEvents()\na couple of times in order for you to be able to coerce them\ninto behaving as they would in the real world.\nYou can deﬁnitely unit test most GUIs, but it is a slippery\nslope that makes it easy to write only what ends up being\nsystem tests. Testing only at the system level can sometimes\n",
      "content_length": 1968,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 193,
      "content": "GUI TESTING GOTCHAS\n179\nseem much easier because you work around the need to refac-\ntor the code to make it more testable. Don’t fall into that trap.\nAs we’ve said a couple of times before, one of the biggest val-\nues of unit testing is in making your designs better. On top\nof that, many unit-level tests can usually run in the same\namount of time as a single system-level test. Don’t sell your-\nself, or your project, short by taking the easier way out. Be\nmindful of the balance between unit-level tests and system-\nlevel tests.\n",
      "content_length": 532,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 194,
      "content": "Appendix A\nExtending NUnit\nA.1\nWriting NUnit Extensions\nIn the nunit.extensions framework, there is a Repeat at-\ntribute:\n[Test]\n[Repeat (10)]\npublic void IntermittentFailure() {\nxxx xxx xxxxxx xxxxx xxxx;\n}\nThe Repeat attribute will, (as you may have guessed already),\nrepeat the same test the speciﬁed number of times. If it fails\nany of those times, it won’t run the remaining times. This can\nbe useful for tests that are sensitive to timing or state issues\nand you want to make sure you’ve shaken everything out.\nExamining an Existing Attribute\nWe’re going to implement a new kind of attribute that test\nmethods can be decorated with.\nWe’ve seen attributes like [Test], [Category], and [Re-\npeat] previously. We’re going to implement a new attribute\nthat will let you specify a maximum amount of time a test can\ntake to run. If it doesn’t complete in the expected time, the\ntest will fail (the test will also fail if its assertions fail, just as\nin a regular test.)\n",
      "content_length": 970,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 195,
      "content": "WRITING NUNIT EXTENSIONS\n181\nYou can extend NUnit by adding new attributes; let’s see how\nby exploring the source code to NUnit. Download the NUnit\nsource code1 (if you haven’t already) and uncompress it some-\nwhere convenient on your disk—we’ll wait.\nTo\nstart\nexploring,\nwe\nshould\nlook\nat\nsomething\nsim-\nilar\nto\nwhat\nwe’re\ntrying\nto\naccomplish.\nThe\n[Re-\npeat(x)] attribute shown above seems like a good place\nto start.\nThe source code for the Repeat attribute is in\nsrc/NUnitExtensions/framework/RepeatAttribute.cs.\nIf you take a look, all it contains is literally the deﬁnition\nfor the Repeat attribute. Something else must interpret the\nattribute, so let’s look for that.\nIf you grep the source for “RepeatAttribute”, it leads you to\nsrc/NUnitExtensions/core/RepeatedTestDecorator.cs.\nThe RepeatedTestDecorator provides a couple of static\nmethods; the important one of interest to us right now is the\nDecorate() method that takes a TestCase as a parameter\nand returns a TestCase. This follows the Decorator design\npattern. The RepeatedTestDecorator’s Decorate method for\na TestCase does a couple of things; we’ll hit the highlights.\nFirst, it ensures that the TestCase method has the RepeatAt-\ntribute associated with it. If the TestCase method does not\nhave an associated RepeatAttribute, it skips the decoration\nand just returns the TestCase as-is. If the TestCase method\ndoes have an associated RepeatAttribute, it gets the Count\nvalue out of the RepeatAttribute’s Count property. It then\nconstructs a new RepeatedTestCase with the original Test-\nCase and the Count property. So, if the [Test] was marked\nwith [Repeat(x)], it wraps the underlying TestCase object\nwith a RepeatedTestCase object.\nLet’s\ntake\na\nlook\nat\nthe\nRepeatedTestCase\nobject\nin\nsrc/NUnitExtensions/core/RepeatedTestCase.cs.\nIt’s\npretty obvious how this works: the Run() method runs the\noriginal, wrapped TestCase by Count number of times. Test-\nCaseResult is a collection parameter for the results of the\ntest runs.\n1http://sourceforge.net/projects/nunit\n",
      "content_length": 2030,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 196,
      "content": "USING NUNIT CORE ADDINS\n182\nMissing: Review at the unit tests for these objects.\nMissing: Finish off this content\nCreating a New Attribute\nMissing: Finish off this content\nA.2\nUsing NUnit Core Addins\nMissing: Content for this section will be added in a later\nbeta.\n",
      "content_length": 265,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 197,
      "content": "Appendix B\nGotchas\nHere are some popular “gotchas,” that is, issues, problems, or\nmisconceptions that have popped up over and over again to\ntrap the unwary.\nB.1\nAs Long As The Code Works\nSome folks seem to think that it’s okay to live with broken unit\ntests as long as the code itself works. Code without tests—\nor code with broken tests—is broken.\nYou just don’t know\nwhere, or when. In this case, you’ve really got the worst of\nboth worlds: all that effort writing tests in the ﬁrst place is\nwasted, and you still have no conﬁdence that the code is doing\nwhat it ought.\nNote that a test that has no assert statements or (mock object\nveriﬁcation) will count as “passed.” This is arguably a bug in\nNUnit, but at any rate a test without asserts still counts as\nbroken.\nIf the tests are broken, treat it just as if the code were broken.\nB.2\n“Smoke” Tests\nSome developers believe that a “smoke test” is good enough\nfor unit testing. That is, if a method makes it all the way to\nthe end without blowing up, then it passed.\n",
      "content_length": 1019,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 198,
      "content": "“WORKS ON MY MACHINE”\n184\nYou can readily identify this sort of a test: there are no asserts\nwithin the test itself, just one big Assert.IsTrue(true) at\nthe end. Maybe the slightly more adventurous will have mul-\ntiple Assert.IsTrue(true)’s throughout, but no more than\nthat. All they are testing is, “did it make it this far?”\nAnd that’s just not enough. Without validating any data or\nother behavior, all you’re doing is lulling yourself into a false\nsense of security—you might think the code is tested, but it is\nnot.\nWatch out for this style of testing, and correct it as soon as\npossible. Real testing checks results. Anything else is just\nwasting everyone’s time.\nB.3\n“Works On My Machine”\nAnother pathologic problem that turns up on some projects\nis that old excuse, “It’s not broken, it works on my machine.”\nThis points to a bug that has some correlation with the envi-\nronment. When this happens, ask yourself:\n• Is everything under version control?\n• Is the development environment consistent on the af-\nfected machines?\n• Is it a genuine bug that just happens to manifest itself\non another machine (because it’s faster, or has more or\nless memory, etc.)?\nEnd users, in particular, don’t like to hear that the code works\non your machine and not theirs.\nAll tests must pass on all machines; otherwise the code is\nbroken.\nB.4\nFloating-Point Problems\nQuite a few developers appear to have missed that one day in\nclass when they talked about ﬂoating-point numbers. It’s a\nfact of life that there are ﬂoating point numbers that can only\nbe approximately represented in computer hardware.\nThe\n",
      "content_length": 1599,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 199,
      "content": "TESTS TAKE TOO LONG\n185\ncomputer only has so many bits to work with, so something\nhas to give.\nThis means that 1.333 + 1.333 isn’t going to equal 2.666\nexactly. It will be close, but not exact. That’s why the NUnit\nﬂoating-point asserts require you to specify a tolerance along\nwith the desired values (see the discussion on page 35).\nBut still you need to be aware that “close enough” may be\ndeceptive at times. Your tests may be too lenient for the real\nworld’s requirements, for instance. Or you might puzzle at an\nerror message that says:\nFailures:\n1) TestXyz.TestMe :\nexpected:<1.00000000>\nbut was:<1.00000000>\nat TestXyz.TestMe() in TestXyz.cs:line 10\n“Gosh, they sure look equal to me!” But they aren’t—there\nmust be a difference that’s smaller than is being displayed by\nthe print method.\nAs a side note, you can get a similar problem when using\ndate and time types. Two dates might look equal as they are\nnormally displayed—but maybe the milliseconds aren’t equal.\nB.5\nTests Take Too Long\nUnit tests need to run fairly quickly. After all, you’ll be run-\nning them a lot. But suddenly you might notice that the tests\nare taking too long. It’s slowing you down as you write tests\nand code during the day.\nThat means it’s time to go through and look at your tests with\na fresh eye. Cull out individual tests that take longer than av-\nerage to run, and group them together using the [Category]\nattribute discussed on page 45.\nYou can run these optional, longer-running tests once a day\nwith the build, or when you check in, but not have to run\nthem every single time you change code.\nJust don’t move them so far out of the way that they never get\nrun.\n",
      "content_length": 1657,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 200,
      "content": "TESTS KEEP BREAKING\n186\nB.6\nTests Keep Breaking\nSome teams notice that the tests keep breaking over and over\nagain. Small changes to the code base suddenly break tests\nall over the place, and it takes a remarkable amount of effort\nto get everything working again.\nThis is usually a sign of excessive coupling. Test code might\nbe too tightly-coupled to external data, to other parts of the\nsystem, and so on. Remember that a singleton is really just\na global variable wearing pretty clothes—if other bits of code\ncan muck with its state, they will, and usually when you least\nexpect it.\nAs soon as you identify this as a problem, you need to ﬁx it.\nIsolate the necessary parts of the system to make the tests\nmore robust, using the same techniques you would use to\nminimize coupling in production code. See [HT00] for more\ndetails on orthogonality and coupling, or [FBB+99] for infor-\nmation on refactoring and design smells, and don’t forget to\nuse Mock Objects (Chapter 6) to decouple yourself from the\nreal world.\nB.7\nTests Fail on Some Machines\nHere’s a common nightmare scenario: all the tests run ﬁne—\non most machines. But on certain machines they fail consis-\ntently. Maybe on some machines they even fail intermittently.\nWhat on earth could be going on? What could be different on\nthese different machines?\nThe obvious answer is differences in the version of the oper-\nating system, libraries, the C# runtime engine, the database\ndriver; that sort of thing. Different versions of software have\ndifferent bugs, workarounds, and features, so it’s quite possi-\nble that machines conﬁgured differently might behave differ-\nently.\nBut what if the machines are conﬁgured with identical soft-\nware, and you still get different results?\nIt might be that one machine runs a little faster than the\nother, and the difference in timing reveals a race condition\n",
      "content_length": 1857,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 201,
      "content": "TESTS PASS IN ONE TEST RUNNER, NOT THE OTHER\n187\nor other problem with concurrency. The same thing can show\nup on single vs. multiple-processor machines.\nIt’s a real bug, it just happened not to have shown up before.\nTrack it down on the affected machine using the usual meth-\nods. Prove the bug exists on that machine as best you can,\nand verify that all tests pass on all machines when you are\ndone.\nB.8\nTests Pass in One Test Runner, Not the\nOther\nYou may ﬁnd a situation where all the tests pass for you us-\ning nunit-gui, the GUI test runner, but fail in the automated\nbuild, which uses nunit-console. This can be an indicator\nof hidden global state, circular object dependencies, or Fi-\nnalizer bugs.\nThat last one can be especially subtle.\nFor instance, there\nwas a case where the developer wrote their ﬁnalizer like it\nwas a C++ destructor—they were accessing the object’s ﬁelds.\nBut in the .NET environment, the ﬁelds may be garbage col-\nlected before the Finalizer is executed. The result? An in-\ntermittent NullReferenceException.\nIn this case, it only\nhappened in the nunit-console test runner when launched\nfrom nant via CruiseControl.NET, aligning the stars of the\ngarbage collection universe just so.\nBut once diagnosed, it\nalso explained seemingly random, unreproducible crashes in\nthe ﬁeld as well.1\nMore likely, nunit-console and other test runners can run\ntests in slightly different order, which may expose hidden de-\npendancies.\nB.9\nThread state issues\nSometimes we see strange InvalidOperationException,\nThreadStateException,\nor\nCOM-based\nexceptions\nget\nthrown when code runs under NUnit, but not in production.\n1For more on garbage collection “gotchas,” see [Sub05].\n",
      "content_length": 1690,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 202,
      "content": "C# 2.0-SPECIFIC ISSUES\n188\nThis can sometimes be related to the apartment-type being\nmulti-threaded when it should be single-threaded and nice\nversa. These are usually referred to by the acronyms MTA and\nSTA, respectively. This is deep .NET voodoo we don’t want to\nget stuck in, but there are a couple of NUnit commandline\noptions to try: -thread and -domain. See the NUnit docu-\nmentation for more more information on these options. If you\nhave a burning desire to learn more, a quick perusal through\nCLR via C#[Ric06] or a web search will give you more infor-\nmation.\nB.10\nC# 2.0-speciﬁc Issues\nSo far, we haven’t mentioned too many things speciﬁc to C#\n2.0, so how do you use NUnit on a project that uses C# 2.0?\nJust as you normally would, with a couple of minor excep-\ntions.\nFirst, you’ll need to use a version of NUnit that is compiled\nwith a C# 2.0 compiler. There are separate packages on the\nNUnit web site for .NET 1.1 and 2.0 versions. By the way, it’s\nperfectly safe and okay to use the .NET 2.0-compiled NUnit\non a C# 1.1 project; the developers will just have to have .NET\n2.0 or mono 1.1 or newer installed to run the tests.\nAnother notable thing to watch out for is the interaction of\nAssert.IsNull() and Assert.IsNotNull() with Nullable\ntypes.\nNullable types, a C# 2.0 feature, allows value types\nlike int, DateTime, enums, or structs to have a “null” value\nwhen it is not initialized. This feature was added so that the\nlanguage could map more closely to the way databases repre-\nsent data (for more information, see [Ric06]).\nIf you write a test like this:\n[Test]\npublic void NullableInt() {\nint? first;\nNullable<int> second;\nAssert.IsNull(first);\nAssert.IsNull(second);\n}\n",
      "content_length": 1693,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 203,
      "content": "C# 2.0-SPECIFIC ISSUES\n189\nIt will fail. The reason why is because the value isn’t liter-\nally null. The ﬁrst line and second lines of code are seman-\ntically identical; the question mark syntax is just some syn-\ntactic sugar to make it easier to consume in C#. Looking at\nthe second declaration, you can see it is a struct of type Nul-\nlable<T>. This will never be null.\nTo correctly test whether the Nullable type has a value or not,\ncheck it’s HasValue property:\nAssert.IsTrue(first.HasValue)\n",
      "content_length": 496,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 204,
      "content": "Appendix C\nResources\nC.1\nOn The Web\nCruise Control .NET\n⇒http://ccnet.thoughtworks.com\nCruiseControl.NET is an automated Continuous Integration server\nfor .NET that integrates with NAnt, NUnit, NCover, and most major\nopen source and proprietary version control systems.\nDotGNU\n⇒http://dotgnu.org\nAn open source implementation of the ECMA standards upon which\nC# and .NET are based. Sports C# and .NET 1.1 support as well an\noptimizing JIT compiler as of this writing. Not as complete as mono,\nanother open source implementation.\nDotNetMock\n⇒http://sourceforge.net/projects/dotnetmock\nA repository for Mock Object information in the .NET environment,\nas well as testing in general.\nmono\n⇒http://mono-project.com\nAnother open source implementation of the ECMA standards upon\nwhich C# and .NET are based. Supports C# and .NET 2.0 as well as\nan optimizing JIT compiler.\nNCover\n⇒http://ncover.org\nA simple code coverage tool that runs from the command line and\noutputs an XML ﬁle with the code coverage statistics. Requires de-\n",
      "content_length": 1023,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 205,
      "content": "ON THE WEB\n191\nbug information for monitored assemblies, and produces line-by-line\nvisit counts. Also includes a simple XSLT transform to make the out-\nput readable in a browser.\nNCoverExplorer\n⇒http://kiwidude.com/blog\nA WinForms GUI and commandline UI for summarizing and explor-\ning the XML ﬁles that NCover emits.\nAlso includes NAnt tasks,\nstylesheets and tasks for CruiseControl.NET. Allows for failure of a\nbuild if code coverage gathered during the build and test are below a\ncertain watermark.\nNMock\n⇒http://nmock.org\nNMock is a dynamic mock-object library for .NET.\nNUnit\n⇒http://nunit.org\nThis xUnit-based unit testing tool for Microsoft .NET is written en-\ntirely in C# and has been completely redesigned to take advantage\nof many .NET language features, including custom attributes and\nother reﬂection related capabilities. NUnit brings xUnit to all .NET\nlanguages.\nPragmatic Programming\n⇒http://www.pragmaticprogrammer.com\nHome page for Pragmatic Programming and your authors. Here you’ll\nﬁnd all of the source code examples from this book, additional re-\nsources, updated URLs and errata, and news on additional volumes\nin this series and other resources.\nSharpDevelop\n⇒http://www.sharpdevelop.net\nA fully-featured and stable open-source IDE for .NET development.\nHas tight integration with NAnt, NUnit, NCover, code analysis, and\nsource control.i\nTestDriven.NET\n⇒http://www.testdriven.net\nVisual-Studio integration for NUnit and NCover.\nxUnit\n⇒http://www.xprogramming.com/software.htm\nUnit testing frameworks for many, many different languages and en-\nvironments.\n",
      "content_length": 1579,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 206,
      "content": "BIBLIOGRAPHY\n192\nC.2\nBibliography\n[Cla04]\nMike Clark. Pragmatic Project Automation. How to\nBuild, Deploy, and Monitor Java Applications. The\nPragmatic Programmers, LLC, Raleigh, NC, and\nDallas, TX, 2004.\n[FBB+99]\nMartin Fowler, Kent Beck, John Brant, William\nOpdyke, and Don Roberts.\nRefactoring: Improv-\ning the Design of Existing Code.\nAddison Wesley\nLongman, Reading, MA, 1999.\n[Fea04]\nMichael Feathers. Working Effectively with Legacy\nCode. Prentice Hall, Englewood Cliffs, NJ, 2004.\n[HT00]\nAndrew Hunt and David Thomas. The Pragmatic\nProgrammer: From Journeyman to Master.\nAddi-\nson-Wesley, Reading, MA, 2000.\n[Mey97]\nBertrand Meyer.\nObject-Oriented Software Con-\nstruction. Prentice Hall, Englewood Cliffs, NJ, sec-\nond edition, 1997.\n[MFC01]\nTim Mackinnon, Steve Freeman, and Philip Craig.\nEndo-testing:\nUnit testing with mock objects.\nIn Giancarlo Succi and Michele Marchesi, edi-\ntors, Extreme Programming Examined, chapter 17,\npages 287–302. Addison Wesley Longman, Read-\ning, MA, 2001.\n[Ric06]\nJeffrey Richter. CLR via C. Microsoft Press, Red-\nmond, WA, second edition, 2006.\n[SH06]\nVenkat Subramaniam and Andy Hunt. Practices of\nan Agile Developer: Working in the Real World. The\nPragmatic Programmers, LLC, Raleigh, NC, and\nDallas, TX, 2006.\n[Sub05]\nVenkat Subramaniam. .NET Gotchas. O’Reilly &\nAssociates, Inc, Sebastopol, CA, 2005.\n[TH03]\nDavid Thomas and Andrew Hunt. Pragmatic Ver-\nsion Control Using CVS. The Pragmatic Program-\nmers, LLC, Raleigh, NC, and Dallas, TX, 2003.\n",
      "content_length": 1492,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 207,
      "content": "BIBLIOGRAPHY\n193\n[wCA04]\nKent Beck with Cynthia Andres. Extreme Program-\nming Explained: Embrace Change. Addison-Wes-\nley, Reading, MA, second edition, 2004.\n",
      "content_length": 158,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 208,
      "content": "Pragmatic Unit Testing: Summary\nGeneral Principles:\n2 Test anything that might break\n2 Test everything that does break\n2 New code is guilty until proven innocent\n2 Write at least as much test code as\nproduction code\n2 Run local tests with each compile\n2 Run all tests before check-in to repository\nQuestions to Ask:\n2 If the code ran correctly, how\nwould I know?\n2 How am I going to test this?\n2 What else can go wrong?\n2 Could this same kind of problem\nhappen anywhere else?\nWhat to Test: Use Your RIGHT-BICEP\n2 Are the results right?\n2 Are all the boundary conditions CORRECT?\n2 Can you check inverse relationships?\n2 Can you cross-check results using other\nmeans?\n2 Can you force error conditions to happen?\n2 Are performance characteristics within\nbounds?\nGood tests are A TRIP\n2 Automatic\n2 Thorough\n2 Repeatable\n2 Independent\n2 Professional\nCORRECT Boundary Conditions\n2 Conformance — Does the value conform to an expected format?\n2 Ordering — Is the set of values ordered or unordered as appropriate?\n2 Range — Is the value within reasonable minimum and maximum values?\n2 Reference — Does the code reference anything external that isn’t under direct\ncontrol of the code itself?\n2 Existence — Does the value exist? (e.g., is non-null, non-zero, present in a set, etc.)\n2 Cardinality — Are there exactly enough values?\n2 Time (absolute and relative) — Is everything happening in order? At the right time?\nIn time?\nhttp://www.pragmaticprogrammer.com/titles/utc2\n",
      "content_length": 1466,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 209,
      "content": "Appendix E\nAnswers to Exercises\nExercise 1:\nfrom page 86\nA simple stack class. Push String objects onto the stack, and Pop\nthem off according to normal stack semantics. This class provides\nthe following methods:\nusing System;\npublic interface StackExercise {\n/// <summary>\n/// Return and remove the most recent item from\n/// the top of the\nstack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n/// </exception>\nString Pop();\n/// <summary>\n/// Add an item to the top of the stack.\n/// </summary>\n/// <param name=\"item\">A String to push\n/// on the stack</param>\nvoid Push(String item);\n/// <summary>\n/// Return but do not remove the most recent\n/// item from the top of the stack.\n/// </summary>\n/// <exception cref=\"StackEmptyException\">\n/// Throws exception if the stack is empty.\n/// </exception>\nString Top();\n/// <summary>\n/// Returns true if the stack is empty.\n",
      "content_length": 921,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 210,
      "content": "APPENDIX E. ANSWERS TO EXERCISES\n196\n/// </summary>\nbool IsEmpty();\n}\nStackExercise.cs\nHere are some hints to get you started: what is likely to break? How\nshould the stack behave when it is ﬁrst initialized? After it’s been\nused for a while? Does it really do what it claims to do?\nAnswer 1:\n• For a brand-new stack, IsEmpty() should be true, Top() and\nPop() should throw exceptions.\n• Starting with an empty stack, call Push() to push a test string\nonto the stack. Verify that Top() returns that string several\ntimes in a row, and that IsEmpty() returns false.\n• Call Pop() to remove the test string, and verify that it is the\nsame string.1 IsEmpty() should now be true. Call Pop() again\nverify an exception is thrown.\n• Now do the same test again, but this time add multiple items to\nthe stack. Make sure you get the right ones back, in the right\norder (the most recent item added should be the one returned).\n• Push a null onto the stack and Pop it; conﬁrm you get a null\nback.\n• Ensure you can use the stack after it has thrown exceptions.\nExercise 2:\nfrom page 87\nA shopping cart. This class lets you add, delete, and count the items\nin a shopping cart.\nWhat sort of boundary conditions might come up? Are there any im-\nplicit restrictions on what you can delete? Are there any interesting\nissues if the cart is empty?\npublic interface ShoppingCart {\n/// <summary>\n/// Add this many of this item to the\n/// shopping cart.\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\nvoid AddItems(Item anItem, int quantity);\n/// <summary>\n1In this case, the Is.EqualTo() constraint isn’t good enough; you need\nIs.Same() to ensure it’s the same object.\n",
      "content_length": 1680,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 211,
      "content": "APPENDIX E. ANSWERS TO EXERCISES\n197\n/// Delete this many of this item from the\n/// shopping cart\n/// </summary>\n/// <exception cref=\"ArgumentOutOfRangeException\">\n/// </exception>\n/// <exception cref=\"NoSuchItemException\">\n/// </exception>\nvoid DeleteItems(Item anItem, int quantity);\n/// <summary>\n/// Count of all items in the cart\n/// (that is, all items x qty each)\n/// </summary>\nint ItemCount { get; }\n/// Return iterator of all items\nIEnumerable GetEnumerator();\n}\nShoppingCart.cs\nAnswer 2:\n• Call AddItems with quantity of 0 and ItemCount should re-\nmain the same.\n• Call DeleteItem with quantity of 0 and ItemCount should re-\nmain the same.\n• Call AddItems with a negative quantity and it should raise an\nexception.\n• Call DeleteItem with a negative quantity and it should raise\nan exception.\n• Call AddItems and the item count should increase, whether\nthe item exists already or not.\n• Call DeleteItem where the item doesn’t exist and it should\nraise an exception.\n• Call DeleteItem when there are no items in the cart and Item-\nCount should remain at 0.\n• Call DeleteItem where the quantity is larger than the number\nof those items in the cart and it should raise an exception.\n• Call GetEnumerator when there are no items in the cart and\nit should return an empty iterator (i.e., it’s a real IEnumerable\nobject (not null) that contains no items).\n• Call AddItem several times for a couple of items and verify that\ncontents of the cart match what was added (as reported via\nGetEnumerator() and ItemCount()).\nHint: you can combine several of these asserts into a single test. For\ninstance, you might start with an empty cart, add 3 of an item, then\ndelete one of them at a time.\n",
      "content_length": 1690,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 212,
      "content": "APPENDIX E. ANSWERS TO EXERCISES\n198\nExercise 3:\nfrom page 88\nA fax scheduler. This code will send faxes from a speciﬁed ﬁle name\nto a U.S. phone number. There is a validation requirement; a U.S.\nphone number with area code must be of the form xnn-nnn-nnnn,\nwhere x must be a digit in the range [2..9] and n can be [0..9].\nThe following blocks are reserved and are not currently valid area\ncodes: x11, x9n, 37n, 96n.\nThe method’s signature is:\n///\n/// Send the named file as a fax to the\n/// given phone number.\n/// <exception cref=\"MissingOrBadFileException\">\n/// </exception>\n/// <exception cref=\"PhoneFormatException\">\n/// </exception>\n/// <exception cref=\"PhoneAreaCodeException\">\n/// </exception>\npublic bool SendFax(String phone, String filename)\nGiven these requirements, what tests for boundary conditions can\nyou think of?\nAnswer 3:\n• Phone numbers with an area code of 111, 211, up to 911, 290,\n291, etc, 999, 370-379, or 960-969 should throw a Phone-\nAreaCodeException.\n• A phone number with too many digits (in one of each set of\nnumber, area code, preﬁx, number) should throw a PhoneFor-\nmatException.\n• A phone number with not enough digits (in one of each set)\nshould throw a PhoneFormatException.\n• A phone number with illegal characters (spaces, letters, etc.)\nshould throw a PhoneFormatException.\n• A phone number that’s missing dashes should throw a Phone-\nFormatException.\n• A phone number with multiple dashes should throw a Phone-\nFormatException.\n• A null phone number should throw a PhoneFormatException.\n• A ﬁle that doesn’t exist should throw a MissingOrBadFile-\nException.\n• A null ﬁlename should also throw that exception.\n• An empty ﬁle should throw a MissingOrBadFileException.\n",
      "content_length": 1708,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 213,
      "content": "APPENDIX E. ANSWERS TO EXERCISES\n199\n• A ﬁle that’s not in the correct format should throw a Missing-\nOrBadFileException.\nExercise 4:\nfrom page 88\nAn automatic sewing machine that does embroidery. The class\nthat controls it takes a few basic commands. The coordinates (0,0)\nrepresent the lower-left corner of the machine. x and y increase as\nyou move toward the upper-right corner, whose coordinates are x =\nTableSize.Width - 1 and y = TableSize.Height - 1.\nCoordinates are speciﬁed in fractions of centimeters.\npublic void MoveTo(double x, double y);\npublic void SewTo(double x, double y);\npublic void SetWorkpieceSize(double width,\ndouble height);\npublic Size WorkpieceSize { get; }\npublic Size TableSize { get; }\nThere are some real-world constraints that might be interesting: you\ncan’t sew thin air, of course, and you can’t sew a workpiece bigger\nthan the machine.\nGiven these requirements, what boundary conditions can you think\nof?\nAnswer 4:\n• Huge value for one or both coordinates\n• Huge value for workpiece size\n• Zero or negative value for one or both coordinates\n• Zero or negative value for workpiece size\n• Coordinates that move off the workpiece\n• Workpiece bigger than the table\nExercise 5:\nfrom page 89\nAudio/Video Editing Transport. A class that provides methods to\ncontrol a VCR or tape deck. There’s the notion of a “current position”\nthat lies somewhere between the beginning of tape (BOT) and the end\nof tape (EOT).\nYou can ask for the current position and move from there to another\ngiven position.\nFast-forward moves from current position toward\nEOT by some amount. Rewind moves from current position toward\nBOT by some amount.\n",
      "content_length": 1653,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 214,
      "content": "APPENDIX E. ANSWERS TO EXERCISES\n200\nWhen tapes are ﬁrst loaded, they are positioned at BOT automati-\ncally.\nusing System;\npublic interface AVTransport {\n/// Move the current position ahead by this many\n/// seconds. Fast-forwarding past end-of-tape\n/// leaves the position at end-of-tape\nvoid FastForward(double seconds);\n/// Move the current position backwards by this\n/// many seconds. Rewinding past zero leaves\n/// the position at zero\nvoid Rewind(double seconds);\n/// Return current time position in seconds\ndouble CurrentTimePosition();\n/// Mark the current time position with label\nvoid MarkTimePosition(String name);\n/// Change the current position to the one\n/// associated with the marked name\nvoid GotoMark(String name);\n}\nAVTransport.cs\nAnswer 5:\n• Verify that the initial position is BOT.\n• Fast forward by some allowed amount (not past end of tape),\nthen rewind by same amount. Should be at initial location.\n• Rewind by some allowed amount (not before the beginning of\ntape), then fast forward by same amount. Should be at initial\nlocation.\n• Fast forward past end of tape, then rewind by same amount.\nShould be before the initial location by an appropriate amount\nto reﬂect the fact that you can’t advance the location past the\nend of tape.\n• Try the same thing in the other direction (rewind past begin-\nning of tape).\n• Mark various positions and return to them after moving the\ncurrent position around.\n• Mark a position and return to it without moving in between.\n",
      "content_length": 1484,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 215,
      "content": "APPENDIX E. ANSWERS TO EXERCISES\n201\nExercise 6:\nfrom page 89\nAudio/Video Editing Transport, Release 2.0. As above, but now\nyou can position in seconds, minutes, or frames (there are exactly\n30 frames per second in this example), and you can move relative to\nthe beginning or the end.\nAnswer 6:\nCross-check results using different units: move in one\nunit and verify your position using another unit; move forward in\none unit and back in another, and so on.\nExercise 7:\nfrom page 163\nDesign an interest calculator that calculates the amount of interest\nbased on the number of working days in-between two dates.\nUse\ntest-ﬁrst design, and take it one step at a time.\nAnswer 7:\nHere’s a possible scenario of steps you might take.\nThere is no right answer; this exercise is simply to get you to think\nabout test-ﬁrst design.\n1. Begin by simply calculating the days between any two dates\nﬁrst. The tests might include:\n• Use the same value for ﬁrst date and last date.\n• Try the normal case where ﬁrst date < last date.\n• Try the error case where ﬁrst date > last date.\n• Try dates that span a year boundary (from October 1 2003\nto March 1, 2004 for instance).\n• Try dates more than a year apart (from October 1 2003 to\nDecember 1, 2006).\n2. Next, exclude weekends from the calculation, using the same\nsorts of tests.\n3. Now exclude public and/or corporate holidays. This raises a\npotentially interesting question: how do you specify holidays?\nYou had to face that issue when writing the tests; do you think\ndoing so improved your interface?\n4. Finally, perform the interest calculation itself. You might start\noff with tests such as:\n• Interest amount should never be negative (an invariant).\n• Interest when ﬁrst date equals last date should be 0.0.\n",
      "content_length": 1746,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 216,
      "content": "Index\nSymbols\n0–1–n rule, 82\nA\nA-TRIP, 117\nAccessors, 124\nActual, 34\nAddCropMarks(), 162\nADO (mock objects), 109\nAgile, 61\nAmount of test code, 125\nAnonymous array, 19\nArianne 5 rocket, 6\nAssert\ncustom, 77\ndeﬁnition, 34\nAssert class, 34\nAreEqual(), 34\nAssert.AreEqual(), 17\nAssert.AreSame(), 36\nAssert.Fail(), 37\nAssert.IsFalse(), 36\nAssert.IsNotNull(), 36\nAssert.IsNull(), 36\nAssert.IsTrue(), 16, 36, 184\nAssert.That(), 39\nAssumptions, 80\nAutomatic, 118\nAutomation, x\nB\nBad magic, 117\nBean, see Enterprise Java Beans\n(EJB)\nBearing.cs, 76\nBig ball of mud, 137\nBlank, 81\nBoolean conditions, 16, 36\nBoundary conditions, 64, 71\nBreaking the build/tests, 134\nBroccoli, 1\nBug\nsee also Debugging; Error\nBugs\nclumping, 120, 121\nelusive, 187\nﬁxing, 126\nidentifying likely, 60\nin sort routines, 74\nisolating, 11, 41\nlist position, 29, 74\nmemory, 184\nphantom, 122\nrewriting due to, 11\ntraceable to unit tests, 123\nBuild machine, 118\nBusiness logic, 84, 159\nC\nC#\nlibrary versions, 186\nCardinality, 82\nCareer limiting move, 12\n[Category], 45\ncheckInvariant(), 78\nClean room, 164\nCode examples\nﬁnding the source to, xii\nCoding\nsee also Coupled code;\nDecoupled code;\nMetadata; Source code\ncontrol system (SCCS)\nCollateral damage, 160\n",
      "content_length": 1220,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 217,
      "content": "COMMENT\n203\nFROG\ndeﬁnition, 9\nComment\nsee also Documentation\nComponent-based systems, see\nModular system\nConcurrency, 84, 86, 187\nConﬁdence, 4\nConformance, 72\nContinuous build/integration,\n118, 136\nContract\nsee also Design by contract\n(DBC)\nCopy and paste, 53, 124\nCORRECT, 71\nCosts, 11\nCoupled code\nsee also Decoupled code\nCoupling, 90, 186\nCross-checking, 67\nCruiseControl, 118, 190\nCVS, 134\nD\nData\nsee also Metadata\nData structures, 77\nDaylight savings time, 85\nDebugging, 2, 10\nDecoupled code\nsee also Coupled code\nDelphi\nsee also Object Pascal\nDependencies, 79, 186\nDependency, reducing, see\nModular system;\nOrthogonality\nDeveloper sandbox, 122, 128\nDocumentation\nsee also Comment; Web\ndocumentation\nDon’t repeat yourself, see DRY\nprinciple\nDonne, John, 123\nDotGNU, 190\nDotNetMock, 108–116, 190\nDownloading source code, see\nExample code\nDRY principle, 124, 164\ndeﬁnition, 53n\nsee also Duplication\nDuck, rubber, see Rubber duck\nDynamic mock objects, 101\nE\nE-mail address format, 72\nElephant\nhow to eat, 139\nEncapsulation, 76, 129\nEngineering, 6\nEnvironmental constraints, 68\nEqualConstraint, 39\nEquality, 16\ndeceptive, 185\nError\nsee also Exception\nError conditions, 68\nException, 30, 34, 54, 56, 81,\n140\nExcuses, 8\nExercises\nA/V transport, 89, 199\nfax machine, 88, 198\ninterest calculator, 163\nsewing machine, 88, 199\nshopping cart, 87, 196\nstack, 86, 195\nExistence, 81\nExpected, 34\n[ExpectedException], 55, 57\nExpert, see Guru\nExternal dependencies, 79, 186\nExtreme Programming, 128, 139\nF\nFactory class, 163\nfakes, 94\nFeedback, xi, 126, 136, 162\nFence post errors, 82\nFileAssert.AreEqual(), 52\nFileAssert.AreNotEqual(), 52\nFiles, 94\nFilterRanges(), 69\nFinally, 155\nﬁxture\ndeﬁnition, 43\nFloating-point numbers, 35, 184\nFormal testing, 4\nFree Software Foundation, see\nGNU Project\nFrog, boiled, see Boiled frog\n",
      "content_length": 1814,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 218,
      "content": "GMT\n204\nORTHOGONALITY\nG\nGMT, 85\nGood neighbor, 154\n“Good-enough software”, see\nSoftware, quality\nH\nHas.Length(), 40\nHouse of cards, 4\nI\nIDE, 13, 118\nImproving tests, 126\nIndependence, see Orthogonality\nIndependent, 49, 122\nIndexing concepts, 79\nInput data validation, 163\nInspection, code, see Code\nreviews\nInvariant, 77, 78, 159\non an index, 160\nInverse relationships, 66\nIs.AtLeast(), 40\nIs.AtMost, 39\nIs.Empty, 40\nIs.EqualTo(), 39\nIs.InstanceOfType(), 40\nIs.Not.EqualTo, 39\nIs.Null, 40\nIs.SubsetOf(), 51\nJ\nJamItIntoPark(), 80\nJavaDoc, see Java\nK\nKaizen\nsee also Knowledge portfolio\nKitchenOrder(), 75\nL\nLanguage, programming\nsee also Mini-language\nLargest(), 17–30\nLargest.cs, 18\nLargestDataFileTests, 62\nLargestTest.cs,\nhyperpage41, 19 −−43\nLargestTest, 30\nLayered system, see Modular\nsystem\nLegacy code, 136, 137\nLibrarian, see Project librarian\nLighting doubles, 90\nList.Contains, 51\nLogging\nsee also Tracing\nLong-running tests, 185\nM\nMember variables, see Accessor\nfunctions\nMessage, 34\nMock objects, 14, 90–116, 118,\n186\ndeﬁnition, 91\ndynamic, 101\nsteps to using, 91\nMoneyAssert.cs, 53\nmono, 190\nMyStack.cs, 77–79\nMyStackTest(), 78\nN\nNCover, 120, 190\nNCoverExplorer, 191\nNMock, 191\nNMock2, 105–106\nNotConstraint, 39\nNull, 36, 81\nNumeric overﬂow, 7n\nNUnit, 191\nattributes, 45, 49, 55, 57\ncustom asserts, 53\nand exceptions, 54\nminimum framework, 41\norder of tests, 123\nselecting tests, 43\nnunit.mocks, 100–104\nO\nObject identity, 36\nOff-by-one errors, 29, 82\nOpen Source\ndeﬁnition, 21\nOrdering, 74, see Workﬂow\nOrthogonality\nsee also Modular system\n",
      "content_length": 1554,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 219,
      "content": "PAIR PROGRAMMING\n205\n[TE A RDO W N]\nP\nPair programming, 139\nParrots, killer, see Branding\nPay-as-you go model, 10\nPerformance, 69\nPhantom bugs, 122\nPostconditions\ndeﬁnition, 80\nPragmatic Automation, x\nPragmatic Programmers\nemail address, xiv\nwebsite, xin\nPragmatic Programming, 191\nPragmatic Starter Kit, ix\nPragmatic Version Control, ix,\n134\nPreconditions\ndeﬁnition, 80\nPrivate access, 129\nProduction code, 5, 124\ndeﬁnition, 32\nProduction system, 14\nProfessional, 123, 139\nProject\nsee also Automation;\nTeam, project\nProperties ﬁle, 146\nProtected access, 129\nPrototype, 13\nPublic access, 129\nR\nRange, 75\nRecipe.cs, 151\nRecipeFile.cs, 151\nRecipes.cs, 146–150\nRecipeTest.cs, 153\nRefactoring, 146, 186\nReference, 79\nRegression, 69\nRepeatable, 122\nRequirements, 7, 30, 61, 84, 185\nRestaurant order, 74\nResults\nanalyzing, 8, 118, 184\nRetrospectives, 139\nReturn on investment, 137\nReviews, 139\nRight, 61\nRIGHT-BICEP, 60\nS\nSample programs, see Example\ncode\nSandbox, 122, 128\nScientiﬁc applications, 35\nSelf-contained components, see\nOrthogonality; Cohesion\nSendFax(), 88, 198\nSeparation of concerns, 143\n[SetUp], 49\nSetup code\nexecution order, 50\nSharpDevelop, 191\nShell, command\nsee also Command shell\n“Shy” code, 143\nSide-effects, 81\nSingle testing phase, 11\nsleep, 144\nSleepUntilNextHour(), 143\nSmoke test, 183\nSoftware engineering, 6\nSort routines, 74\nSource code\ndocumentation, see\nComments\ndownloading, see Example\ncode\nreviews, see Code reviews\nSQL (mock objects), 109\nStand-ins, 90\nStandardPaperFactory, 163\nStarting a project\nsee also Requirement\nStream, 94\nString constants, 155\nStructured walkthroughs, see\nCode reviews\nStubs, 92\nstubs, 92\nSubVersion, 134\nSupplier, see Vendor\nSVN, 134\nSynchronized, 86\nSyntax vs. semantics, 13\nSystem.Data, 109\nT\nTeam communication, 140\nTeam environment, 134\n[TearDown], 49\n",
      "content_length": 1812,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 220,
      "content": "TEARDOWN CODE\n206\nZERO\nTeardown code\nexecution order, 50\n[Test], 42\nTest code\nand property accessors, 124\nbroken, 41, 183, 186\ncleanup, 155\ncompiling, 33\ncorrelate to bugs, 123\nand data ﬁles, 61\nenvironment, 184\nﬁrst test, 18\ninvoking, 118\nlinear, 124\nlocating, 129\nlong running, 185\nordering, 123\nvs. production code, 33, 125\nrequired actions, 33\nresults, 8\nreviewing, 140\nselecting, 43\ntesting, 125\nTest coverage analysis tools, 120,\n121\nTest data, 64\nTest setup\nper-ﬁxture, 51\nper-test, 49\nTest-driven design, 140, 161\nTestAdd(), 127\nTestDriven.NET, 191\n[TestFixture], 42\nTesting\nacceptance, 3, 14\nand design, architecture,\n30, 143\ncourtesy, 132\nenvironment, 184\nexcuses, 8\nformal, 4\nfrequency, 135\nfunctional, 14\nGUI, 158\nmetrics, 121\nperformance, 3, 14\nregression, 69, 137\nresponsibility, 164\nsee also Unit testing\nText.Matches(), 52\nText.StartsWith(), 52\nThorough, 119\nTime, 8, 11, 84, 185\nTimeouts, 85\nTolerance, 185\nTracing\nsee also Logging\nTraveling salesman algorithm, 45\nU\nUML, see Uniﬁed modeling\nlanguage (UML)\nUnit testing\ndeﬁnition, 3\nintentional sabotage, 127\npotential dangers, 117\nusing, 42\nUTC, 85\nV\nValidation, 61\nand veriﬁcation, 3, 14\nformatted data, 73\ninput data, 163\nuser input, 164\nVersion control, ix, 134\nW\nWalkthoughs, see Code reviews\nWall-clock time, 85\nWhac-a-Mole, 9\nWriting\nsee also Documentation\nX\nXML, 63\nxUnit, 191\nZ\nZero, 81\n",
      "content_length": 1363,
      "extraction_method": "PyMuPDF_fallback"
    }
  ]
}