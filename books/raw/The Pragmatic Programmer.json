{
  "metadata": {
    "title": "The Pragmatic Programmer",
    "author": "Andrew Hunt and David Thomas",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 352,
    "conversion_date": "2025-12-25T18:21:37.666940",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "The Pragmatic Programmer.pdf",
    "extraction_method": "Unstructured"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 2-9)",
      "start_page": 2,
      "end_page": 9,
      "detection_method": "topic_boundary",
      "content": "“This is the sort of book I will buy a dozen copies of when it comes out so I can give it to my clients.”\n\nEric Vought, Software Engineer\n\n“Most modern books on software development fail to cover the basics of what makes a great software developer, instead spending their time on syntax or technology where in reality the greatest leverage possible for any software team is in having talented developers who really know their craft well. An excellent book.”\n\nPete McBreen, Independent Consultant\n\n“Since reading this book, I have implemented many of the practical suggestions and tips it contains. Across the board, they have saved my company time and money while helping me get my job done quicker! This should be a desktop reference for everyone who works with code for a living.”\n\nJared Richardson, Senior Software Developer, iRenaissance, Inc.\n\n“I would like to see this issued to every new employee at my company. . . .”\n\nChris Cleeland, Senior Software Engineer, Object Computing, Inc.\n\nThePragmaticProgrammer\n\nThis page intentionally left blank\n\nThePragmaticProgrammer From Journeyman to Master\n\nAndrew Hunt David Thomas\n\nADDISON–WESLEY An imprint of Addison Wesley Longman, Inc.\n\nReading, Massachusetts Harlow, England Menlo Park, California Berkeley, California Don Mills, Ontario Sydney Bonn Amsterdam Tokyo Mexico City\n\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and Addison– Wesley was aware of a trademark claim, the designations have been printed in initial capital letters or in all capitals.\n\nLyrics from the song “The Boxer” on page 157 are Copyright c 1968 Paul Simon. Used by permission of the Publisher: Paul Simon Music. Lyrics from the song “Alice’s Restaurant” on page 220 are by Arlo Guthrie, c 1966, 1967 (renewed) by APPLESEED MUSIC INC. All Rights Reserved. Used by Permission.\n\nThe authors and publisher have taken care in the preparation of this book, but make no express or implied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.\n\nThe publisher offers discounts on this book when ordered in quantity for special sales. For more information, please contact:\n\nAWL Direct Sales Addison Wesley Longman, Inc. One Jacob Way Reading, Massachusetts 01867 (781) 944-3700\n\nVisit AWL on the Web: www.awl.com/cseng\n\nLibrary of Congress Cataloging-in-Publication Data\n\nHunt, Andrew, 1964–\n\nThe Pragmatic Programmer / Andrew Hunt, David Thomas.\n\np. cm.\n\nIncludes bibliographical references. ISBN 0-201-61622-X 1. Computer programming.\n\nI. Thomas, David, 1956–\n\n.\n\nII. Title. QA76.6.H857 1999 005.1--dc21\n\n99–43581 CIP\n\nCopyright c 2000 by Addison Wesley Longman, Inc.\n\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by any means, electronic, mechanical, photo- copying, recording, or otherwise, without the prior written permission of the publisher. Printed in the United States of America. Published simultaneously in Canada.\n\nISBN 0-201-61622-X\n\nText printed in the United States on recycled paper at Courier Stoughton in Stoughton, Massachusetts.\n\n25th\n\nPrinting\n\nFebruary 2010\n\nForEllieandJuliet, ElizabethandZachary, StuartandHenry\n\nThis page intentionally left blank\n\nContents\n\nFOREWORD\n\nPREFACE\n\n1 A PRAGMATIC PHILOSOPHY\n\n1. The Cat Ate My Source Code . . . . . . . . . . . . . . . . .\n\n2. Software Entropy . . . . . . . . . . . . . . . . . . . . . . . .\n\n3. Stone Soup and Boiled Frogs . . . . . . . . . . . . . . . . .\n\n4. Good-Enough Software . . . . . . . . . . . . . . . . . . . .\n\n5. Your Knowledge Portfolio . . . . . . . . . . . . . . . . . . .\n\n6. Communicate!\n\n. . . . . . . . . . . . . . . . . . . . . . . . .\n\n2 A PRAGMATIC APPROACH\n\n7. The Evils of Duplication . . . . . . . . . . . . . . . . . . . .\n\n8. Orthogonality . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n9. Reversibility . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n10. Tracer Bullets . . . . . . . . . . . . . . . . . . . . . . . . .\n\n11. Prototypes and Post-it Notes . . . . . . . . . . . . . . . . .\n\n12. Domain Languages . . . . . . . . . . . . . . . . . . . . . .\n\n13. Estimating . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n3 THE BASIC TOOLS\n\n14. The Power of Plain Text . . . . . . . . . . . . . . . . . . . .\n\n15. Shell Games . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n16. Power Editing . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n17. Source Code Control . . . . . . . . . . . . . . . . . . . . . .\n\n18. Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n19. Text Manipulation . . . . . . . . . . . . . . . . . . . . . . . 99\n\n19. Text Manipulation . . . . . . . . . . . . . . . . . . . . . . . 99\n\n20. Code Generators . . . . . . . . . . . . . . . . . . . . . . . . 102\n\nix\n\nxiii\n\nxvii\n\n1\n\n2\n\n4\n\n7\n\n9\n\n12\n\n18\n\n25\n\n26\n\n34\n\n44\n\n48\n\n53\n\n57\n\n64\n\n71\n\n73\n\n77\n\n82\n\n86",
      "page_number": 2
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 10-17)",
      "start_page": 10,
      "end_page": 17,
      "detection_method": "topic_boundary",
      "content": "x\n\nCONTENTS\n\n4 PRAGMATIC PARANOIA 21. Design by Contract\n\n. . . . . . . . . . . . . . . . . . . . . . 109\n\n107\n\n22. Dead Programs Tell No Lies\n\n. . . . . . . . . . . . . . . . . 120\n\n23. Assertive Programming . . . . . . . . . . . . . . . . . . . . 122\n\n24. When to Use Exceptions . . . . . . . . . . . . . . . . . . . 125\n\n25. How to Balance Resources . . . . . . . . . . . . . . . . . . 129\n\n5 BEND, OR BREAK\n\n137\n\n26. Decoupling and the Law of Demeter . . . . . . . . . . . . . 138\n\n27. Metaprogramming . . . . . . . . . . . . . . . . . . . . . . . 144\n\n28. Temporal Coupling . . . . . . . . . . . . . . . . . . . . . . . 150\n\n29. It’s Just a View . . . . . . . . . . . . . . . . . . . . . . . . . 157\n\n30. Blackboards . . . . . . . . . . . . . . . . . . . . . . . . . . 165\n\n6 WHILE YOU ARE CODING\n\n171\n\n31. Programming by Coincidence . . . . . . . . . . . . . . . . 172\n\n32. Algorithm Speed . . . . . . . . . . . . . . . . . . . . . . . . 177\n\n33. Refactoring . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\n\n34. Code That’s Easy to Test\n\n. . . . . . . . . . . . . . . . . . . 189\n\n35. Evil Wizards\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . 198\n\n7 BEFORE THE PROJECT\n\n201\n\n36. The Requirements Pit . . . . . . . . . . . . . . . . . . . . . 202\n\n37. Solving Impossible Puzzles . . . . . . . . . . . . . . . . . . 212\n\n38. Not Until You’re Ready . . . . . . . . . . . . . . . . . . . . 215\n\n39. The Speciﬁcation Trap . . . . . . . . . . . . . . . . . . . . 217\n\n40. Circles and Arrows . . . . . . . . . . . . . . . . . . . . . . . 220\n\n8 PRAGMATIC PROJECTS\n\n223\n\n41. Pragmatic Teams . . . . . . . . . . . . . . . . . . . . . . . . 224\n\n42. Ubiquitous Automation . . . . . . . . . . . . . . . . . . . . 230\n\n43. Ruthless Testing . . . . . . . . . . . . . . . . . . . . . . . . 237\n\n44. It’s All Writing . . . . . . . . . . . . . . . . . . . . . . . . . 248\n\n45. Great Expectations . . . . . . . . . . . . . . . . . . . . . . 255\n\n46. Pride and Prejudice . . . . . . . . . . . . . . . . . . . . . . 258\n\nCONTENTS\n\nAppendices\n\nA RESOURCES\n\nProfessional Societies . . . . . . . . . . . . . . . . . . . . . . . . 262\n\nBuilding a Library . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n\nInternet Resources . . . . . . . . . . . . . . . . . . . . . . . . . 266\n\nBibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275\n\nB ANSWERS TO EXERCISES\n\nINDEX\n\nxi\n\n261\n\n279\n\n309\n\nThis page intentionally left blank\n\nForeword\n\nAs a reviewer I got an early opportunity to read the book you are hold- ing. It was great, even in draft form. Dave Thomas and Andy Hunt have something to say, and they know how to say it. I saw what they were doing and I knew it would work. I asked to write this foreword so that I could explain why.\n\nSimply put, this book tells you how to program in a way that you can follow. You wouldn’t think that that would be a hard thing to do, but it is. Why? For one thing, not all programming books are written by pro- grammers. Many are compiled by language designers, or the journalists who work with them to promote their creations. Those books tell you how to talk in a programming language—which is certainly important, but that is only a small part of what a programmer does.\n\nWhat does a programmer do besides talk in programming language? Well, that is a deeper issue. Most programmers would have trouble explaining what they do. Programming is a job ﬁlled with details, and keeping track of those details requires focus. Hours drift by and the code appears. You look up and there are all of those statements. If you don’t think carefully, you might think that programming is just typing statements in a programming language. You would be wrong, of course, but you wouldn’t be able to tell by looking around the programming section of the bookstore.\n\nIn The Pragmatic Programmer Dave and Andy tell us how to program in a way that we can follow. How did they get so smart? Aren’t they just as focused on details as other programmers? The answer is that they paid attention to what they were doing while they were doing it—and then they tried to do it better.\n\nImagine that you are sitting in a meeting. Maybe you are thinking that the meeting could go on forever and that you would rather be programming. Dave and Andy would be thinking about why they were\n\nxiii\n\nxiv\n\nFOREWORD\n\nhaving the meeting, and wondering if there is something else they could do that would take the place of the meeting, and deciding if that some- thing could be automated so that the work of the meeting just happens in the future. Then they would do it.\n\nThat is just the way Dave and Andy think. That meeting wasn’t some- thing keeping them from programming. It was programming. And it was programming that could be improved. I know they think this way because it is tip number two: Think About Your Work.\n\nSo imagine that these guys are thinking this way for a few years. Pretty soon they would have a collection of solutions. Now imagine them using their solutions in their work for a few more years, and discarding the ones that are too hard or don’t always produce results. Well, that approach just about deﬁnes pragmatic. Now imagine them taking a year or two more to write their solutions down. You might think, That information would be a gold mine. And you would be right.\n\nThe authors tell us how they program. And they tell us in a way that we can follow. But there is more to this second statement than you might think. Let me explain.\n\nThe authors have been careful to avoid proposing a theory of software development. This is fortunate, because if they had they would be obliged to warp each chapter to defend their theory. Such warping is the tradition in, say, the physical sciences, where theories eventually become laws or are quietly discarded. Programming on the other hand has few (if any) laws. So programming advice shaped around wanna-be laws may sound good in writing, but it fails to satisfy in practice. This is what goes wrong with so many methodology books.\n\nI’ve studied this problem for a dozen years and found the most promise in a device called a pattern language. In short, a pattern is a solution, and a pattern language is a system of solutions that reinforce each other. A whole community has formed around the search for these systems.\n\nThis book is more than a collection of tips. It is a pattern language in sheep’s clothing. I say that because each tip is drawn from experi- ence, told as concrete advice, and related to others to form a system. These are the characteristics that allow us to learn and follow a pattern language. They work the same way here.\n\nFOREWORD\n\nYou can follow the advice in this book because it is concrete. You won’t ﬁnd vague abstractions. Dave and Andy write directly for you, as if each tip was a vital strategy for energizing your programming career. They make it simple, they tell a story, they use a light touch, and then they follow that up with answers to questions that will come up when you try.\n\nAnd there is more. After you read ten or ﬁfteen tips you will begin to see an extra dimension to the work. We sometimes call it QWAN, short for the quality without a name. The book has a philosophy that will ooze into your consciousness and mix with your own. It doesn’t preach. It just tells what works. But in the telling more comes through. That’s the beauty of the book: It embodies its philosophy, and it does so unpre- tentiously.\n\nSo here it is: an easy to read—and use—book about the whole practice of programming. I’ve gone on and on about why it works. You probably only care that it does work. It does. You will see.\n\n—Ward Cunningham\n\nxv\n\nThis page intentionally left blank\n\nPreface\n\nThis book will help you become a better programmer.\n\nIt doesn’t matter whether you are a lone developer, a member of a large project team, or a consultant working with many clients at once. This book will help you, as an individual, to do better work. This book isn’t theoretical—we concentrate on practical topics, on using your experi- ence to make more informed decisions. The word pragmatic comes from the Latin pragmaticus—“skilled in business”—which itself is derived , meaning “to do.” This is a book about doing. from the Greek\n\nProgramming is a craft. At its simplest, it comes down to getting a computer to do what you want it to do (or what your user wants it to do). As a programmer, you are part listener, part advisor, part interpreter, and part dictator. You try to capture elusive requirements and ﬁnd a way of expressing them so that a mere machine can do them justice. You try to document your work so that others can understand it, and you try to engineer your work so that others can build on it. What’s more, you try to do all this against the relentless ticking of the project clock. You work small miracles every day.\n\nIt’s a difﬁcult job.\n\nThere are many people offering you help. Tool vendors tout the mir- acles their products perform. Methodology gurus promise that their techniques guarantee results. Everyone claims that their programming language is the best, and every operating system is the answer to all conceivable ills.\n\nOf course, none of this is true. There are no easy answers. There is no such thing as a best solution, be it a tool, a language, or an operat- ing system. There can only be systems that are more appropriate in a particular set of circumstances.\n\nxvii",
      "page_number": 10
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 18-25)",
      "start_page": 18,
      "end_page": 25,
      "detection_method": "topic_boundary",
      "content": "xviii\n\nPREFACE\n\nThis is where pragmatism comes in. You shouldn’t be wedded to any particular technology, but have a broad enough background and expe- rience base to allow you to choose good solutions in particular situ- ations. Your background stems from an understanding of the basic principles of computer science, and your experience comes from a wide range of practical projects. Theory and practice combine to make you strong.\n\nYou adjust your approach to suit the current circumstances and envi- ronment. You judge the relative importance of all the factors affecting a project and use your experience to produce appropriate solutions. And you do this continuously as the work progresses. Pragmatic Program- mers get the job done, and do it well.\n\nWho Should Read This Book? This book is aimed at people who want to become more effective and more productive programmers. Perhaps you feel frustrated that you don’t seem to be achieving your potential. Perhaps you look at col- leagues who seem to be using tools to make themselves more produc- tive than you. Maybe your current job uses older technologies, and you want to know how newer ideas can be applied to what you do.\n\nWe don’t pretend to have all (or even most) of the answers, nor are all of our ideas applicable in all situations. All we can say is that if you follow our approach, you’ll gain experience rapidly, your produc- tivity will increase, and you’ll have a better understanding of the entire development process. And you’ll write better software.\n\nWhat Makes aPragmaticProgrammer? Each developer is unique, with individual strengths and weaknesses, preferences and dislikes. Over time, each will craft his or her own personal environment. That environment will reﬂect the programmer’s individuality just as forcefully as his or her hobbies, clothing, or hair- cut. However, if you’re a Pragmatic Programmer, you’ll share many of the following characteristics:\n\nEarly adopter/fast adapter. You have an instinct for technologies and techniques, and you love trying things out. When given some-\n\nPREFACE\n\nthing new, you can grasp it quickly and integrate it with the rest of your knowledge. Your conﬁdence is born of experience.\n\nInquisitive. You tend to ask questions. That’s neat—how did you do that? Did you have problems with that library? What’s this BeOS I’ve heard about? How are symbolic links implemented? You are a pack rat for little facts, each of which may affect some decision years from now.\n\nCritical thinker. You rarely take things as given without ﬁrst get- ting the facts. When colleagues say “because that’s the way it’s done,” or a vendor promises the solution to all your problems, you smell a challenge.\n\nRealistic. You try to understand the underlying nature of each problem you face. This realism gives you a good feel for how difﬁ- cult things are, and how long things will take. Understanding for yourself that a process should be difﬁcult or will take a while to complete gives you the stamina to keep at it.\n\nJack of all trades. You try hard to be familiar with a broad range of technologies and environments, and you work to keep abreast of new developments. Although your current job may require you to be a specialist, you will always be able to move on to new areas and new challenges.\n\nWe’ve left the most basic characteristics until last. All Pragmatic Pro- grammers share them. They’re basic enough to state as tips:\n\nTIP 1\n\nCare About Your Craft\n\nWe feel that there is no point in developing software unless you care about doing it well.\n\nTIP 2\n\nThink! About Your Work\n\nIn order to be a Pragmatic Programmer, we’re challenging you to think about what you’re doing while you’re doing it. This isn’t a one-time audit of current practices—it’s an ongoing critical appraisal of every\n\nxix\n\nxx\n\nPREFACE\n\ndecision you make, every day, and on every development. Never run on auto-pilot. Constantly be thinking, critiquing your work in real time. The old IBM corporate motto, THINK!, is the Pragmatic Programmer’s mantra.\n\nIf this sounds like hard work to you, then you’re exhibiting the realistic characteristic. This is going to take up some of your valuable time—time that is probably already under tremendous pressure. The reward is a more active involvement with a job you love, a feeling of mastery over an increasing range of subjects, and pleasure in a feeling of continuous improvement. Over the long term, your time investment will be repaid as you and your team become more efﬁcient, write code that’s easier to maintain, and spend less time in meetings.\n\nIndividual Pragmatists,LargeTeams Some people feel that there is no room for individuality on large teams or complex projects. “Software construction is an engineering disci- pline,” they say, “that breaks down if individual team members make decisions for themselves.”\n\nWe disagree.\n\nThe construction of software should be an engineering discipline. How- ever, this doesn’t preclude individual craftsmanship. Think about the large cathedrals built in Europe during the Middle Ages. Each took thousands of person-years of effort, spread over many decades. Lessons learned were passed down to the next set of builders, who advanced the state of structural engineering with their accomplishments. But the carpenters, stonecutters, carvers, and glass workers were all craftspeo- ple, interpreting the engineering requirements to produce a whole that transcended the purely mechanical side of the construction. It was their belief in their individual contributions that sustained the projects:\n\nWe who cut mere stones must always be envisioning cathedrals.\n\n— Quarry worker’s creed\n\nWithin the overall structure of a project there is always room for in- dividuality and craftsmanship. This is particularly true given the cur- rent state of software engineering. One hundred years from now, our engineering may seem as archaic as the techniques used by medieval\n\nPREFACE\n\ncathedral builders seem to today’s civil engineers, while our craftsman- ship will still be honored.\n\nIt’s aContinuous Process\n\nA tourist visiting England’s Eton College asked the gardener how he got the lawns so perfect. “That’s easy,” he replied, “You just brush off the dew every morning, mow them every other day, and roll them once a week.”\n\n“Is that all?” asked the tourist.\n\n“Absolutely,” replied the gardener. “Do that for 500 years and you’ll have a nice lawn, too.”\n\nGreat lawns need small amounts of daily care, and so do great pro- grammers. Management consultants like to drop the word kaizen in conversations. “Kaizen” is a Japanese term that captures the concept of continuously making many small improvements. It was considered to be one of the main reasons for the dramatic gains in productivity and quality in Japanese manufacturing and was widely copied throughout the world. Kaizen applies to individuals, too. Every day, work to reﬁne the skills you have and to add new tools to your repertoire. Unlike the Eton lawns, you’ll start seeing results in a matter of days. Over the years, you’ll be amazed at how your experience has blossomed and your skills have grown.\n\nHowthe Book Is Organized This book is written as a collection of short sections. Each section is self-contained, and addresses a particular topic. You’ll ﬁnd numerous cross references, which help put each topic in context. Feel free to read the sections in any order—this isn’t a book you need to read front-to- back.\n\nOccasionally you’ll come across a box labeled Tip nn (such as Tip 1, “Care About Your Craft” on page xix). As well as emphasizing points in the text, we feel the tips have a life of their own—we live by them daily. You’ll ﬁnd a summary of all the tips on a pull-out card inside the back cover.\n\nxxi\n\nxxii\n\nPREFACE\n\nAppendix A contains a set of resources: the book’s bibliography, a list of URLs to Web resources, and a list of recommended periodicals, books, and professional organizations. Throughout the book you’ll ﬁnd refer- ences to the bibliography and to the list of URLs—such as [KP99] and [URL 18], respectively.\n\nWe’ve included exercises and challenges where appropriate. Exercises normally have relatively straightforward answers, while the challenges are more open-ended. To give you an idea of our thinking, we’ve in- cluded our answers to the exercises in Appendix B, but very few have a single correct solution. The challenges might form the basis of group discussions or essay work in advanced programming courses.\n\nWhat’s in aName?\n\n“When I use a word,” Humpty Dumpty said, in rather a scornful tone, “it means just what I choose it to mean—neither more nor less.” Lewis Carroll, Through theLooking-Glass\n\nScattered throughout the book you’ll ﬁnd various bits of jargon—either perfectly good English words that have been corrupted to mean some- thing technical, or horrendous made-up words that have been assigned meanings by computer scientists with a grudge against the language. The ﬁrst time we use each of these jargon words, we try to deﬁne it, or at least give a hint to its meaning. However, we’re sure that some have fallen through the cracks, and others, such as object and rela- tional database, are in common enough usage that adding a deﬁnition would be boring. If you do come across a term you haven’t seen be- fore, please don’t just skip over it. Take time to look it up, perhaps on the Web, or maybe in a computer science textbook. And, if you get a chance, drop us an e-mail and complain, so we can add a deﬁnition to the next edition.\n\nHaving said all this, we decided to get revenge against the computer sci- entists. Sometimes, there are perfectly good jargon words for concepts, words that we’ve decided to ignore. Why? Because the existing jargon is normally restricted to a particular problem domain, or to a partic- ular phase of development. However, one of the basic philosophies of this book is that most of the techniques we’re recommending are uni- versal: modularity applies to code, designs, documentation, and team\n\nPREFACE\n\norganization, for instance. When we wanted to use the conventional jargon word in a broader context, it got confusing—we couldn’t seem to overcome the baggage the original term brought with it. When this happened, we contributed to the decline of the language by inventing our own terms.\n\nSource Code andOtherResources Most of the code shown in this book is extracted from compilable source ﬁles, available for download from our Web site:\n\nwww.pragmaticprogrammer.com\n\nThere you’ll also ﬁnd links to resources we ﬁnd useful, along with updates to the book and news of other Pragmatic Programmer devel- opments.\n\nSendUs Feedback We’d appreciate hearing from you. Comments, suggestions, errors in the text, and problems in the examples are all welcome. E-mail us at\n\nppbook@pragmaticprogrammer.com\n\nAcknowledgments When we started writing this book, we had no idea how much of a team effort it would end up being.\n\nAddison-Wesley has been brilliant, taking a couple of wet-behind-the- ears hackers and walking us through the whole book-production pro- cess, from idea to camera-ready copy. Many thanks to John Wait and Meera Ravindiran for their initial support, Mike Hendrickson, our enthusiastic editor (and a mean cover designer!), Lorraine Ferrier and John Fuller for their help with production, and the indefatigable Julie DeBaggis for keeping us all together.\n\nThen there were the reviewers: Greg Andress, Mark Cheers, Chris Clee- land, Alistair Cockburn, Ward Cunningham, Martin Fowler, Thanh T. Giang, Robert L. Glass, Scott Henninger, Michael Hunter, Brian\n\nxxiii\n\nxxiv\n\nPREFACE\n\nKirby, John Lakos, Pete McBreen, Carey P. Morris, Jared Richardson, Kevin Ruland, Eric Starr, Eric Vought, Chris Van Wyk, and Deborra Zukowski. Without their careful comments and valuable insights, this book would be less readable, less accurate, and twice as long. Thank you all for your time and wisdom.\n\nThe second printing of this book beneﬁted greatly from the eagle eyes of our readers. Many thanks to Brian Blank, Paul Boal, Tom Ekberg, Brent Fulgham, Louis Paul Hebert, Henk-Jan Olde Loohuis, Alan Lund, Gareth McCaughan, Yoshiki Shibata, and Volker Wurst, both for ﬁnd- ing the mistakes and for having the grace to point them out gently.\n\nOver the years, we have worked with a large number of progressive clients, where we gained and reﬁned the experience we write about here. Recently, we’ve been fortunate to work with Peter Gehrke on sev- eral large projects. His support and enthusiasm for our techniques are much appreciated.\n\nThis book was produced using LATEX, pic, Perl, dvips, ghostview, ispell, GNU make, CVS, Emacs, XEmacs, EGCS, GCC, Java, iContract, and SmallEiffel, using the Bash and zsh shells under Linux. The stagger- ing thing is that all of this tremendous software is freely available. We owe a huge “thank you” to the thousands of Pragmatic Programmers worldwide who have contributed these and other works to us all. We’d particularly like to thank Reto Kramer for his help with iContract.\n\nLast, but in no way least, we owe a huge debt to our families. Not only have they put up with late night typing, huge telephone bills, and our permanent air of distraction, but they’ve had the grace to read what we’ve written, time after time. Thank you for letting us dream.\n\nAndy Hunt Dave Thomas\n\nChapter 1\n\nA Pragmatic Philosophy\n\nWhat distinguishes Pragmatic Programmers? We feel it’s an attitude, a style, a philosophy of approaching problems and their solutions. They think beyond the immediate problem, always trying to place it in its larger context, always trying to be aware of the bigger picture. After all, without this larger context, how can you be pragmatic? How can you make intelligent compromises and informed decisions?\n\nAnother key to their success is that they take responsibility for every- thing they do, which we discuss in The Cat Ate My Source Code. Being responsible, Pragmatic Programmers won’t sit idly by and watch their projects fall apart through neglect. In Software Entropy, we tell you how to keep your projects pristine.\n\nMost people ﬁnd change difﬁcult to accept, sometimes for good reasons, sometimes because of plain old inertia. In Stone Soup and Boiled Frogs, we look at a strategy for instigating change and (in the interests of balance) present the cautionary tale of an amphibian that ignored the dangers of gradual change.\n\nOne of the beneﬁts of understanding the context in which you work is that it becomes easier to know just how good your software has to be. Sometimes near-perfection is the only option, but often there are trade-offs involved. We explore this in Good-Enough Software.\n\nOf course, you need to have a broad base of knowledge and experience to pull all of this off. Learning is a continuous and ongoing process. In Your Knowledge Portfolio, we discuss some strategies for keeping the momentum up.\n\n1",
      "page_number": 18
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 26-33)",
      "start_page": 26,
      "end_page": 33,
      "detection_method": "topic_boundary",
      "content": "1\n\n2\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nFinally, none of us works in a vacuum. We all spend a large amount of time interacting with others. Communicate! lists ways we can do this better.\n\nPragmatic programming stems from a philosophy of pragmatic think- ing. This chapter sets the basis for that philosophy.\n\nThe Cat Ate My Source Code\n\nThe greatest of all weaknesses is the fear of appearing weak.\n\nJ. B. Bossuet, Politics from HolyWrit, 1709\n\nOne of the cornerstones of the pragmatic philosophy is the idea of tak- ing responsibility for yourself and your actions in terms of your career advancement, your project, and your day-to-day work. A Pragmatic Pro- grammer takes charge of his or her own career, and isn’t afraid to admit ignorance or error. It’s not the most pleasant aspect of programming, to be sure, but it will happen—even on the best of projects. Despite thorough testing, good documentation, and solid automation, things go wrong. Deliveries are late. Unforeseen technical problems come up.\n\nThese things happen, and we try to deal with them as professionally as we can. This means being honest and direct. We can be proud of our abilities, but we must be honest about our shortcomings—our igno- rance as well as our mistakes.\n\nTake Responsibility Responsibility is something you actively agree to. You make a commit- ment to ensure that something is done right, but you don’t necessarily have direct control over every aspect of it. In addition to doing your own personal best, you must analyze the situation for risks that are beyond your control. You have the right not to take on a responsibility for an impossible situation, or one in which the risks are too great. You’ll have to make the call based on your own ethics and judgment.\n\nWhen you do accept the responsibility for an outcome, you should ex- pect to be held accountable for it. When you make a mistake (as we all do) or an error in judgment, admit it honestly and try to offer options.\n\nTHE CAT ATE MY SOURCE CODE\n\nDon’t blame someone or something else, or make up an excuse. Don’t blame all the problems on a vendor, a programming language, manage- ment, or your coworkers. Any and all of these may play a role, but it is up to you to provide solutions, not excuses.\n\nIf there was a risk that the vendor wouldn’t come through for you, then you should have had a contingency plan. If the disk crashes—taking all of your source code with it—and you don’t have a backup, it’s your fault. Telling your boss “the cat ate my source code” just won’t cut it.\n\nTIP 3\n\nProvide Options, Don’t Make Lame Excuses\n\nBefore you approach anyone to tell them why something can’t be done, is late, or is broken, stop and listen to yourself. Talk to the rubber duck on your monitor, or the cat. Does your excuse sound reasonable, or stupid? How’s it going to sound to your boss?\n\nRun through the conversation in your mind. What is the other person ” or “Didn’t you con- likely to say? Will they ask, “Have you tried this sider that?” How will you respond? Before you go and tell them the bad news, is there anything else you can try? Sometimes, you just know what they are going to say, so save them the trouble.\n\nInstead of excuses, provide options. Don’t say it can’t be done; explain what can be done to salvage the situation. Does code have to be thrown out? Educate them on the value of refactoring (see Refactoring, page 184). Do you need to spend time prototyping to determine the best way to proceed (see Prototypes and Post-it Notes, page 53)? Do you need to introduce better testing (see Code That’s Easy to Test, page 189, and Ruthless Testing, page 237) or automation (see Ubiquitous Automation, page 230) to prevent it from happening again? Perhaps you need ad- ditional resources. Don’t be afraid to ask, or to admit that you need help.\n\nTry to ﬂush out the lame excuses before voicing them aloud. If you must, tell your cat ﬁrst. After all, if little Tiddles is going to take the blame. .. .\n\n3\n\n2\n\n4\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nRelated sections include:\n\nPrototypes and Post-it Notes, page 53 Refactoring, page 184 Code That’s Easy to Test, page 189 Ubiquitous Automation, page 230 Ruthless Testing, page 237\n\nChallenges\n\nHow do you react when someone—such as a bank teller, an auto mechanic, or a clerk—comes to you with a lame excuse? What do you think of them and their company as a result?\n\nSoftware Entropy\n\nWhile software development is immune from almost all physical laws, entropy hits us hard. Entropy is a term from physics that refers to the amount of “disorder” in a system. Unfortunately, the laws of thermo- dynamics guarantee that the entropy in the universe tends toward a maximum. When disorder increases in software, programmers call it “software rot.”\n\nThere are many factors that can contribute to software rot. The most important one seems to be the psychology, or culture, at work on a project. Even if you are a team of one, your project’s psychology can be a very delicate thing. Despite the best laid plans and the best peo- ple, a project can still experience ruin and decay during its lifetime. Yet there are other projects that, despite enormous difﬁculties and con- stant setbacks, successfully ﬁght nature’s tendency toward disorder and manage to come out pretty well.\n\nWhat makes the difference?\n\nIn inner cities, some buildings are beautiful and clean, while others are rotting hulks. Why? Researchers in the ﬁeld of crime and urban decay discovered a fascinating trigger mechanism, one that very quickly turns a clean, intact, inhabited building into a smashed and abandoned derelict [WK82].\n\nSOFTWARE ENTROPY\n\nA broken window.\n\nOne broken window, left unrepaired for any substantial length of time, instills in the inhabitants of the building a sense of abandonment—a sense that the powers that be don’t care about the building. So another window gets broken. People start littering. Grafﬁti appears. Serious structural damage begins. In a relatively short space of time, the build- ing becomes damaged beyond the owner’s desire to ﬁx it, and the sense of abandonment becomes reality.\n\nThe “Broken Window Theory” has inspired police departments in New York and other major cities to crack down on the small stuff in order to keep out the big stuff. It works: keeping on top of broken windows, grafﬁti, and other small infractions has reduced the serious crime level.\n\nTIP 4\n\nDon’t Live with Broken Windows\n\nDon’t leave “broken windows” (bad designs, wrong decisions, or poor code) unrepaired. Fix each one as soon as it is discovered. If there is insufﬁcient time to ﬁx it properly, then board it up. Perhaps you can comment out the offending code, or display a \"Not Implemented\" mes- sage, or substitute dummy data instead. Take some action to prevent further damage and to show that you’re on top of the situation.\n\nWe’ve seen clean, functional systems deteriorate pretty quickly once windows start breaking. There are other factors that can contribute to software rot, and we’ll touch on some of them elsewhere, but neglect accelerates the rot faster than any other factor.\n\nYou may be thinking that no one has the time to go around cleaning up all the broken glass of a project. If you continue to think like that, then you’d better plan on getting a dumpster, or moving to another neighborhood. Don’t let entropy win.\n\nPuttingOut Fires By contrast, there’s the story of an obscenely rich acquaintance of Andy’s. His house was immaculate, beautiful, loaded with priceless antiques, objets d’art, and so on. One day, a tapestry that was hang- ing a little too close to his living room ﬁreplace caught on ﬁre. The ﬁre\n\n5\n\n6\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\ndepartment rushed in to save the day—and his house. But before they dragged their big, dirty hoses into the house, they stopped—with the ﬁre raging—to roll out a mat between the front door and the source of the ﬁre.\n\nThey didn’t want to mess up the carpet.\n\nA pretty extreme case, to be sure, but that’s the way it must be with software. One broken window—a badly designed piece of code, a poor management decision that the team must live with for the duration of the project—is all it takes to start the decline. If you ﬁnd yourself working on a project with quite a few broken windows, it’s all too easy to slip into the mindset of “All the rest of this code is crap, I’ll just follow suit.” It doesn’t matter if the project has been ﬁne up to this point. In the original experiment leading to the “Broken Window Theory,” an abandoned car sat for a week untouched. But once a single window was broken, the car was stripped and turned upside down within hours.\n\nBy the same token, if you ﬁnd yourself on a team and a project where the code is pristinely beautiful—cleanly written, well designed, and elegant—you will likely take extra special care not to mess it up, just like the ﬁreﬁghters. Even if there’s a ﬁre raging (deadline, release date, trade show demo, etc.), you don’t want to be the ﬁrst one to make a mess.\n\nRelated sections include:\n\nStone Soup and Boiled Frogs, page 7 Refactoring, page 184 Pragmatic Teams, page 224\n\nChallenges\n\nHelp strengthen your team by surveying your computing “neighborhood.” Choose two or three “broken windows” and discuss with your colleagues what the problems are and what could be done to ﬁx them.\n\nCan you tell when a window ﬁrst gets broken? What is your reaction? If it was the result of someone else’s decision, or a management edict, what can you do about it?\n\n3\n\nSTONE SOUP AND BOILED FROGS\n\nStone Soup and Boiled Frogs\n\nThe three soldiers returning home from war were hungry. When they saw the village ahead their spirits lifted—they were sure the villagers would give them a meal. But when they got there, they found the doors locked and the windows closed. After many years of war, the villagers were short of food, and hoarded what they had.\n\nUndeterred, the soldiers boiled a pot of water and carefully placed three stones into it. The amazed villagers came out to watch.\n\n“This is stone soup,” the soldiers explained. “Is that all you put in it?” asked the villagers. “Absolutely—although some say it tastes even better with a few .” A villager ran off, returning in no time with a basket of carrots from carrots his hoard.\n\nA couple of minutes later, the villagers again asked “Is that it?”\n\n“Well,” said the soldiers, “a couple of potatoes give it body.” Off ran another villager.\n\nOver the next hour, the soldiers listed more ingredients that would enhance the soup: beef, leeks, salt, and herbs. Each time a different villager would run off to raid their personal stores.\n\nEventually they had produced a large pot of steaming soup. The soldiers removed the stones, and they sat down with the entire village to enjoy the ﬁrst square meal any of them had eaten in months.\n\nThere are a couple of morals in the stone soup story. The villagers are tricked by the soldiers, who use the villagers’ curiosity to get food from them. But more importantly, the soldiers act as a catalyst, bringing the village together so they can jointly produce something that they couldn’t have done by themselves—a synergistic result. Eventually ev- eryone wins.\n\nEvery now and then, you might want to emulate the soldiers.\n\nYou may be in a situation where you know exactly what needs doing and how to do it. The entire system just appears before your eyes—you know it’s right. But ask permission to tackle the whole thing and you’ll be met with delays and blank stares. People will form committees, bud- gets will need approval, and things will get complicated. Everyone will guard their own resources. Sometimes this is called “start-up fatigue.”\n\n7\n\n8\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nIt’s time to bring out the stones. Work out what you can reasonably ask for. Develop it well. Once you’ve got it, show people, and let them marvel. Then say “of course, it would be better if we added .” Pretend it’s not important. Sit back and wait for them to start asking you to add the functionality you originally wanted. People ﬁnd it easier to join an ongoing success. Show them a glimpse of the future and you’ll get them to rally around.1\n\nTIP 5\n\nBe a Catalyst for Change\n\nTheVillagers’Side On the other hand, the stone soup story is also about gentle and grad- ual deception. It’s about focusing too tightly. The villagers think about the stones and forget about the rest of the world. We all fall for it, every day. Things just creep up on us.\n\nWe’ve all seen the symptoms. Projects slowly and inexorably get totally out of hand. Most software disasters start out too small to notice, and most project overruns happen a day at a time. Systems drift from their speciﬁcations feature by feature, while patch after patch gets added to a piece of code until there’s nothing of the original left. It’s often the accumulation of small things that breaks morale and teams.\n\nTIP 6\n\nRemember the Big Picture\n\nWe’ve never tried this—honest. But they say that if you take a frog and drop it into boiling water, it will jump straight back out again. However, if you place the frog in a pan of cold water, then gradually heat it, the frog won’t notice the slow increase in temperature and will stay put until cooked.\n\n1. While doing this, you may be comforted by the line attributed to Rear Admiral Dr. Grace Hopper: “It’s easier to ask forgiveness than it is to get permission.”\n\nGOOD-ENOUGH SOFTWARE\n\nNote that the frog’s problem is different from the broken windows issue discussed in Section 2. In the Broken Window Theory, people lose the will to ﬁght entropy because they perceive that no one else cares. The frog just doesn’t notice the change.\n\nDon’t be like the frog. Keep an eye on the big picture. Constantly review what’s happening around you, not just what you personally are doing.\n\nRelated sections include:\n\nSoftware Entropy, page 4 Programming by Coincidence, page 172 Refactoring, page 184 The Requirements Pit, page 202 Pragmatic Teams, page 224\n\nChallenges\n\nWhile reviewing a draft of this book, John Lakos raised the following is- sue: The soldiers progressively deceive the villagers, but the change they catalyze does them all good. However, by progressively deceiving the frog, you’re doing it harm. Can you determine whether you’re making stone soup or frog soup when you try to catalyze change? Is the decision subjec- tive or objective?\n\n4 Good-Enough Software\n\nStriving to better, oft we mar what’s well.\n\nKing Lear 1.4\n\nThere’s an old(ish) joke about a U.S. company that places an order for 100,000 integrated circuits with a Japanese manufacturer. Part of the speciﬁcation was the defect rate: one chip in 10,000. A few weeks later the order arrived: one large box containing thousands of ICs, and a small one containing just ten. Attached to the small box was a label that read: “These are the faulty ones.”\n\n9",
      "page_number": 26
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 34-41)",
      "start_page": 34,
      "end_page": 41,
      "detection_method": "topic_boundary",
      "content": "10\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nIf only we really had this kind of control over quality. But the real world just won’t let us produce much that’s truly perfect, particularly not bug-free software. Time, technology, and temperament all conspire against us.\n\nHowever, this doesn’t have to be frustrating. As Ed Yourdon described in an article in IEEE Software [You95], you can discipline yourself to write software that’s good enough—good enough for your users, for fu- ture maintainers, for your own peace of mind. You’ll ﬁnd that you are more productive and your users are happier. And you may well ﬁnd that your programs are actually better for their shorter incubation.\n\nBefore we go any further, we need to qualify what we’re about to say. The phrase “good enough” does not imply sloppy or poorly produced code. All systems must meet their users’ requirements to be success- ful. We are simply advocating that users be given an opportunity to participate in the process of deciding when what you’ve produced is good enough.\n\nInvolveYour UsersintheTrade-Off\n\nNormally you’re writing software for other people. Often you’ll remem- ber to get requirements from them.2 But how often do you ask them how good they want their software to be? Sometimes there’ll be no choice. If you’re working on pacemakers, the space shuttle, or a low- level library that will be widely disseminated, the requirements will be more stringent and your options more limited. However, if you’re working on a brand new product, you’ll have different constraints. The marketing people will have promises to keep, the eventual end users may have made plans based on a delivery schedule, and your company will certainly have cash-ﬂow constraints. It would be unprofessional to ignore these users’ requirements simply to add new features to the pro- gram, or to polish up the code just one more time. We’re not advocating panic: it is equally unprofessional to promise impossible time scales and to cut basic engineering corners to meet a deadline.\n\n2.\n\nThat was supposed to be a joke!\n\nGOOD-ENOUGH SOFTWARE\n\nThe scope and quality of the system you produce should be speciﬁed as part of that system’s requirements.\n\nTIP 7\n\nMake Quality a Requirements Issue\n\nOften you’ll be in situations where trade-offs are involved. Surprisingly, many users would rather use software with some rough edges today than wait a year for the multimedia version. Many IT departments with tight budgets would agree. Great software today is often preferable to perfect software tomorrow. If you give your users something to play with early, their feedback will often lead you to a better eventual solution (see Tracer Bullets, page 48).\n\nKnowWhentoStop In some ways, programming is like painting. You start with a blank canvas and certain basic raw materials. You use a combination of sci- ence, art, and craft to determine what to do with them. You sketch out an overall shape, paint the underlying environment, then ﬁll in the details. You constantly step back with a critical eye to view what you’ve done. Every now and then you’ll throw a canvas away and start again.\n\nBut artists will tell you that all the hard work is ruined if you don’t know when to stop. If you add layer upon layer, detail over detail, the painting becomes lost in the paint.\n\nDon’t spoil a perfectly good program by overembellishment and over- reﬁnement. Move on, and let your code stand in its own right for a while. It may not be perfect. Don’t worry: it could never be perfect. (In Chapter 6, page 171, we’ll discuss philosophies for developing code in an imperfect world.)\n\nRelated sections include: Tracer Bullets, page 48 The Requirements Pit, page 202 Pragmatic Teams, page 224 Great Expectations, page 255\n\n11\n\n5\n\n12\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nChallenges\n\nLook at the manufacturers of the software tools and operating systems that you use. Can you ﬁnd any evidence that these companies are comfortable shipping software they know is not perfect? As a user, would you rather (1) wait for them to get all the bugs out, (2) have complex software and accept some bugs, or (3) opt for simpler software with fewer defects?\n\nConsider the effect of modularization on the delivery of software. Will it take more or less time to get a monolithic block of software to the required quality compared with a system designed in modules? Can you ﬁnd com- mercial examples?\n\nYour Knowledge Portfolio\n\nAn investment in knowledge always pays the best interest.\n\nBenjamin Franklin\n\nAh, good old Ben Franklin—never at a loss for a pithy homily. Why, if we could just be early to bed and early to rise, we’d be great programmers— right? The early bird might get the worm, but what happens to the early worm?\n\nIn this case, though, Ben really hit the nail on the head. Your knowledge and experience are your most important professional assets.\n\nUnfortunately, they’re expiring assets.3 Your knowledge becomes out of date as new techniques, languages, and environments are developed. Changing market forces may render your experience obsolete or irrele- vant. Given the speed at which Web-years ﬂy by, this can happen pretty quickly.\n\nAs the value of your knowledge declines, so does your value to your company or client. We want to prevent this from ever happening.\n\n3. a warehouse full of bananas and a ticket to a ball game.\n\nAn expiring asset is something whose value diminishes over time. Examples include\n\nYOUR KNOWLEDGE PORTFOLIO\n\nYour KnowledgePortfolio We like to think of all the facts programmers know about computing, the application domains they work in, and all their experience as their Knowledge Portfolios. Managing a knowledge portfolio is very similar to managing a ﬁnancial portfolio:\n\n1. Serious investors invest regularly—as a habit.\n\n2. Diversiﬁcation is the key to long-term success.\n\n3. Smart investors balance their portfolios between conservative and\n\nhigh-risk, high-reward investments.\n\n4. Investors try to buy low and sell high for maximum return.\n\n5. Portfolios should be reviewed and rebalanced periodically.\n\nTo be successful in your career, you must manage your knowledge port- folio using these same guidelines.\n\nBuilding Your Portfolio\n\nInvest regularly. Just as in ﬁnancial investing, you must invest in your knowledge portfolio regularly. Even if it’s just a small amount, the habit itself is as important as the sums. A few sample goals are listed in the next section.\n\nDiversify. The more different things you know, the more valuable you are. As a baseline, you need to know the ins and outs of the particular technology you are working with currently. But don’t stop there. The face of computing changes rapidly—hot technology today may well be close to useless (or at least not in demand) to- morrow. The more technologies you are comfortable with, the better you will be able to adjust to change.\n\nTechnology exists along a spectrum from risky, Manage risk. potentially high-reward to low-risk, low-reward standards. It’s not a good idea to invest all of your money in high-risk stocks that might collapse suddenly, nor should you invest all of it conserva- tively and miss out on possible opportunities. Don’t put all your technical eggs in one basket.\n\n13\n\n14\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nBuy low, sell high. Learning an emerging technology before it be- comes popular can be just as hard as ﬁnding an undervalued stock, but the payoff can be just as rewarding. Learning Java when it ﬁrst came out may have been risky, but it paid off handsomely for the early adopters who are now at the top of that ﬁeld.\n\nReview and rebalance. This is a very dynamic industry. That hot technology you started investigating last month might be stone cold by now. Maybe you need to brush up on that database technology that you haven’t used in a while. Or perhaps you could be bet- ter positioned for that new job opening if you tried out that other language.. ..\n\nOf all these guidelines, the most important one is the simplest to do:\n\nTIP 8\n\nInvest Regularly in Your Knowledge Portfolio\n\nGoals Now that you have some guidelines on what and when to add to your knowledge portfolio, what’s the best way to go about acquiring intellec- tual capital with which to fund your portfolio? Here are a few sugges- tions.\n\nLearn at least one new language every year. Different languages solve the same problems in different ways. By learning several dif- ferent approaches, you can help broaden your thinking and avoid getting stuck in a rut. Additionally, learning many languages is far easier now, thanks to the wealth of freely available software on the Internet (see page 267).\n\nRead a technical book each quarter. Bookstores are full of techni- cal books on interesting topics related to your current project. Once you’re in the habit, read a book a month. After you’ve mastered the technologies you’re currently using, branch out and study some that don’t relate to your project.\n\nIt is important to remember that Read nontechnical books, too. computers are used by people—people whose needs you are trying to satisfy. Don’t forget the human side of the equation.\n\nYOUR KNOWLEDGE PORTFOLIO\n\nTake classes. Look for interesting courses at your local commu- nity college or university, or perhaps at the next trade show that comes to town.\n\nParticipate in local user groups. Don’t just go and listen, but actively participate. Isolation can be deadly to your career; ﬁnd out what people are working on outside of your company.\n\nIf you’ve worked only in Experiment with different environments. Windows, play with Unix at home (the freely available Linux is per- fect for this). If you’ve used only makefiles and an editor, try an IDE, and vice versa.\n\nStay current. Subscribe to trade magazines and other journals (see page 262 for recommendations). Choose some that cover tech- nology different from that of your current project.\n\nGet wired. Want to know the ins and outs of a new language or other technology? Newsgroups are a great way to ﬁnd out what experiences other people are having with it, the particular jargon they use, and so on. Surf the Web for papers, commercial sites, and any other sources of information you can ﬁnd.\n\nIt’s important to continue investing. Once you feel comfortable with some new language or bit of technology, move on. Learn another one.\n\nIt doesn’t matter whether you ever use any of these technologies on a project, or even whether you put them on your resume. The process of learning will expand your thinking, opening you to new possibilities and new ways of doing things. The cross-pollination of ideas is important; try to apply the lessons you’ve learned to your current project. Even if your project doesn’t use that technology, perhaps you can borrow some ideas. Get familiar with object orientation, for instance, and you’ll write plain C programs differently.\n\nOpportunities for Learning So you’re reading voraciously, you’re on top of all the latest breaking developments in your ﬁeld (not an easy thing to do), and somebody asks you a question. You don’t have the faintest idea what the answer is, and freely admit as much.\n\n15\n\n16\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nDon’t let it stop there. Take it as a personal challenge to ﬁnd the answer. Ask a guru. (If you don’t have a guru in your ofﬁce, you should be able to ﬁnd one on the Internet: see the box on on the facing page.) Search the Web. Go to the library.4\n\nIf you can’t ﬁnd the answer yourself, ﬁnd out who can. Don’t let it rest. Talking to other people will help build your personal network, and you may surprise yourself by ﬁnding solutions to other, unrelated problems along the way. And that old portfolio just keeps getting bigger. .. .\n\nAll of this reading and researching takes time, and time is already in short supply. So you need to plan ahead. Always have something to read in an otherwise dead moment. Time spent waiting for doctors and dentists can be a great opportunity to catch up on your reading—but be sure to bring your own magazine with you, or you might ﬁnd yourself thumbing through a dog-eared 1973 article about Papua New Guinea.\n\nCritical Thinking The last important point is to think critically about what you read and hear. You need to ensure that the knowledge in your portfolio is accurate and unswayed by either vendor or media hype. Beware of the zealots who insist that their dogma provides the only answer—it may or may not be applicable to you and your project.\n\nNever underestimate the power of commercialism. Just because a Web search engine lists a hit ﬁrst doesn’t mean that it’s the best match; the content provider can pay to get top billing. Just because a bookstore features a book prominently doesn’t mean it’s a good book, or even popular; they may have been paid to place it there.\n\nTIP 9\n\nCritically Analyze What You Read and Hear\n\nUnfortunately, there are very few simple answers anymore. But with your extensive portfolio, and by applying some critical analysis to the\n\n4. ﬁlled with research material and staff.\n\nIn this era of the Web, many people seem to have forgotten about real live libraries\n\nYOUR KNOWLEDGE PORTFOLIO\n\nCare and Cultivation of Gurus\n\nWith the global adoption of the Internet, gurus suddenly are as close as your Enter key. So, how do you ﬁnd one, and how do you get one to talk with you?\n\nWe ﬁnd there are some simple tricks.\n\nKnow exactly what you want to ask, and be as speciﬁc as you can be.\n\nFrame your question carefully and politely. Remember that you’re asking a favor; don’t seem to be demanding an answer.\n\nOnce you’ve framed your question, stop and look again for the answer. Pick out some keywords and search the Web. Look for appropriate FAQs (lists of frequently asked questions with an- swers).\n\nDecide if you want to ask publicly or privately. Usenet news- groups are wonderful meeting places for experts on just about any topic, but some people are wary of these groups’ public nature. Alternatively, you can always e-mail your guru directly. Either way, use a meaningful subject line. (“Need Help!!!” doesn’t cut it.)\n\nSit back and be patient. People are busy, and it may take days to get a speciﬁc answer.\n\nFinally, please be sure to thank anyone who responds to you. And if you see people asking questions youcan answer, play your part and participate.\n\ntorrent of technical publications you will read, you can understand the complex answers.\n\nChallenges\n\nStart learning a new language this week. Always programmed in C++? Try Smalltalk [URL 13] or Squeak [URL 14]. Doing Java? Try Eiffel [URL 10] or TOM [URL 15]. See page 267 for sources of other free compilers and environments.\n\nStart reading a new book (but ﬁnish this one ﬁrst!). If you are doing very detailed implementation and coding, read a book on design and architec- ture. If you are doing high-level design, read a book on coding techniques.\n\n17",
      "page_number": 34
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 42-49)",
      "start_page": 42,
      "end_page": 49,
      "detection_method": "topic_boundary",
      "content": "18\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nGet out and talk technology with people who aren’t involved in your cur- rent project, or who don’t work for the same company. Network in your company cafeteria, or maybe seek out fellow enthusiasts at a local user’s group meeting.\n\n6 Communicate!\n\nI believe that it is better to be looked over than it is to be overlooked.\n\nMae West, BelleoftheNineties, 1934\n\nMaybe we can learn a lesson from Ms. West. It’s not just what you’ve got, but also how you package it. Having the best ideas, the ﬁnest code, or the most pragmatic thinking is ultimately sterile unless you can com- municate with other people. A good idea is an orphan without effective communication.\n\nAs developers, we have to communicate on many levels. We spend hours in meetings, listening and talking. We work with end users, trying to understand their needs. We write code, which communicates our intentions to a machine and documents our thinking for future generations of developers. We write proposals and memos requesting and justifying resources, reporting our status, and suggesting new approaches. And we work daily within our teams to advocate our ideas, modify existing practices, and suggest new ones. A large part of our day is spent communicating, so we need to do it well.\n\nWe’ve put together a list of ideas that we ﬁnd useful.\n\nKnow WhatYou Want toSay Probably the most difﬁcult part of the more formal styles of commu- nication used in business is working out exactly what it is you want to say. Fiction writers plot out their books in detail before they start, but people writing technical documents are often happy to sit down at a keyboard, enter “1. Introduction,” and start typing whatever comes into their heads next.\n\nPlan what you want to say. Write an outline. Then ask yourself, “Does this get across whatever I’m trying to say?” Reﬁne it until it does.\n\nCOMMUNICATE!\n\nThis approach is not just applicable to writing documents. When you’re faced with an important meeting or a phone call with a major client, jot down the ideas you want to communicate, and plan a couple of strategies for getting them across.\n\nKnow YourAudience You’re communicating only if you’re conveying information. To do that, you need to understand the needs, interests, and capabilities of your audience. We’ve all sat in meetings where a development geek glazes over the eyes of the vice president of marketing with a long monologue on the merits of some arcane technology. This isn’t communicating: it’s just talking, and it’s annoying.5\n\nForm a strong mental picture of your audience. The acrostic WISDOM, shown in Figure 1.1 on the following page, may help.\n\nSay you want to suggest a Web-based system to allow your end users to submit bug reports. You can present this system in many differ- ent ways, depending on your audience. End users will appreciate that they can submit bug reports 24 hours a day without waiting on the phone. Your marketing department will be able to use this fact to boost sales. Managers in the support department will have two reasons to be happy: fewer staff will be needed, and problem reporting will be automated. Finally, developers may enjoy getting experience with Web- based client-server technologies and a new database engine. By making the appropriate pitch to each group, you’ll get them all excited about your project.\n\nChooseYourMoment It’s six o’clock on Friday afternoon, following a week when the auditors have been in. Your boss’s youngest is in the hospital, it’s pouring rain outside, and the commute home is guaranteed to be a nightmare. This probably isn’t a good time to ask her for a memory upgrade for your PC.\n\nAs part of understanding what your audience needs to hear, you need to work out what their priorities are. Catch a manager who’s just been given a hard time by her boss because some source code got lost, and\n\n5.\n\nThe word annoy comes from the Old French enui, which also means “to bore.”\n\n19\n\n20\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nFigure 1.1. The WISDOM acrostic—understanding an audience\n\nWhat do you want them to learn?\n\nWhat is their interest in what you’ve got to say?\n\nHow sophisticated are they?\n\nHow much detail do they want?\n\nWhom do you want to own the information?\n\nHow can you motivate them to listen to you?\n\nyou’ll have a more receptive listener to your ideas on source code repos- itories. Make what you’re saying relevant in time, as well as in content. Sometimes all it takes is the simple question “Is this a good time to talk about...?”\n\nChoosea Style Adjust the style of your delivery to suit your audience. Some people want a formal “just the facts” brieﬁng. Others like a long, wide-ranging chat before getting down to business. When it comes to written docu- ments, some like to receive large bound reports, while others expect a simple memo or e-mail. If in doubt, ask.\n\nRemember, however, that you are half of the communication transac- tion. If someone says they need a paragraph describing something and you can’t see any way of doing it in less than several pages, tell them so. Remember, that kind of feedback is a form of communication, too.\n\nMake ItLookGood Your ideas are important. They deserve a good-looking vehicle to convey them to your audience.\n\nToo many developers (and their managers) concentrate solely on con- tent when producing written documents. We think this is a mistake. Any chef will tell you that you can slave in the kitchen for hours only to ruin your efforts with poor presentation.\n\nThere is no excuse today for producing poor-looking printed docu- ments. Modern word processors (along with layout systems such as LATEX and troff) can produce stunning output. You need to learn just a few basic commands. If your word processor supports style sheets, use\n\nCOMMUNICATE!\n\nthem. (Your company may already have deﬁned style sheets that you can use.) Learn how to set page headers and footers. Look at the sam- ple documents included with your package to get ideas on style and layout. Check the spelling, ﬁrst automatically and then by hand. After awl, their are spelling miss steaks that the chequer can knot ketch.\n\nInvolveYourAudience We often ﬁnd that the documents we produce end up being less im- portant than the process we go through to produce them. If possible, involve your readers with early drafts of your document. Get their feed- back, and pick their brains. You’ll build a good working relationship, and you’ll probably produce a better document in the process.\n\nBea Listener There’s one technique that you must use if you want people to listen to you: listen to them. Even if this is a situation where you have all the information, even if this is a formal meeting with you standing in front of 20 suits—if you don’t listen to them, they won’t listen to you.\n\nEncourage people to talk by asking questions, or have them summarize what you tell them. Turn the meeting into a dialog, and you’ll make your point more effectively. Who knows, you might even learn some- thing.\n\nGetBack to People If you ask someone a question, you feel they’re impolite if they don’t respond. But how often do you fail to get back to people when they send you an e-mail or a memo asking for information or requesting some action? In the rush of everyday life, it’s easy to forget. Always respond to e-mails and voice mails, even if the response is simply “I’ll get back to you later.” Keeping people informed makes them far more forgiving of the occasional slip, and makes them feel that you haven’t forgotten them.\n\nTIP 10\n\nIt’s Both What You Say and the Way You Say It\n\nUnless you work in a vacuum, you need to be able to communicate. The more effective that communication, the more inﬂuential you become.\n\n21\n\n22\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nE-Mail Communication\n\nEverything we’ve said about communicating in writing applies equally to electronic mail. E-mail has evolved to the point where it is a main- stay of intra- and intercorporate communications. E-mail is used to discuss contracts, to settle disputes, and as evidence in court. But for some reason, people who would never send out a shabby paper document are happy to ﬂing nasty-looking e-mail around the world.\n\nOur e-mail tips are simple:\n\nProofread before you hit SEND.\n\nCheck the spelling.\n\nKeep the format simple. Some people read e-mail using propor- tional fonts, so the ASCII art pictures you laboriously created will look to them like hen-scratchings.\n\nUse rich-text or HTML formatted mail only if you know that all your recipients can read it. Plain text is universal.\n\nTry to keep quoting to a minimum. No one likes to receive back their own 100-line e-mail with “I agree” tacked on.\n\nIf you’re quoting other people’s e-mail, be sure to attribute it, and quote it inline (rather than as an attachment).\n\nDon’t ﬂame unless you want it to come back and haunt you later.\n\nCheck your list of recipients before sending. A recentWallStreet Journal article described an employee who took to distributing criticisms of his boss over departmental e-mail, without realizing that his boss was included on the distribution list.\n\nArchive and organize your e-mail—both the important stuff you receive and the mail you send.\n\nAs various Microsoft and Netscape employees discovered during the 1999 Department of Justice investigation, e-mail is forever. Try to give the same attention and care to e-mail as you would to any written memo or report.\n\nCOMMUNICATE!\n\nSummary\n\nKnow what you want to say.\n\nKnow your audience.\n\nChoose your moment.\n\nChoose a style.\n\nMake it look good.\n\nInvolve your audience.\n\nBe a listener.\n\nGet back to people.\n\nRelated sections include:\n\nPrototypes and Post-it Notes, page 53 Pragmatic Teams, page 224\n\nChallenges\n\nThere are several good books that contain sections on communications within development teams [Bro95, McC95, DL99]. Make it a point to try to read all three over the next 18 months. In addition, the book Dinosaur Brains [Ber96] discusses the emotional baggage we all bring to the work environment.\n\nThe next time you have to give a presentation, or write a memo advocating some position, try working through the WISDOM acrostic on page 20 before you start. See if it helps you understand how to position what you say. If appropriate, talk to your audience afterward and see how accurate your assessment of their needs was.\n\n23\n\nThis page intentionally left blank\n\nChapter 2\n\nA Pragmatic Approach\n\nThere are certain tips and tricks that apply at all levels of software development, ideas that are almost axiomatic, and processes that are virtually universal. However, these approaches are rarely documented as such; you’ll mostly ﬁnd them written down as odd sentences in dis- cussions of design, project management, or coding.\n\nIn this chapter we’ll bring these ideas and processes together. The ﬁrst two sections, The Evils of Duplication and Orthogonality, are closely related. The ﬁrst warns you not to duplicate knowledge throughout your systems, the second not to split any one piece of knowledge across multiple system components.\n\nAs the pace of change increases, it becomes harder and harder to keep our applications relevant. In Reversibility, we’ll look at some techniques that help insulate your projects from their changing environment.\n\nThe next two sections are also related. In Tracer Bullets, we talk about a style of development that allows you to gather requirements, test designs, and implement code at the same time. If this sounds too good to be true, it is: tracer bullet developments are not always applicable. When they’re not, Prototypes and Post-it Notes shows you how to use prototyping to test architectures, algorithms, interfaces, and ideas.\n\nAs computer science slowly matures, designers are producing increas- ingly higher-level languages. While the compiler that accepts “make it so” hasn’t yet been invented, in Domain Languages we present some more modest suggestions that you can implement for yourself.\n\n25",
      "page_number": 42
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 50-57)",
      "start_page": 50,
      "end_page": 57,
      "detection_method": "topic_boundary",
      "content": "7\n\n26\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nFinally, we all work in a world of limited time and resources. You can survive both of these scarcities better (and keep your bosses happier) if you get good at working out how long things will take, which we cover in Estimating.\n\nBy keeping these fundamental principles in mind during development, you can write code that’s better, faster, and stronger. You can even make it look easy.\n\nThe Evils of Duplication\n\nGiving a computer two contradictory pieces of knowledge was Captain James T. Kirk’s preferred way of disabling a marauding artiﬁcial intel- ligence. Unfortunately, the same principle can be effective in bringing down your code.\n\nAs programmers, we collect, organize, maintain, and harness knowl- edge. We document knowledge in speciﬁcations, we make it come alive in running code, and we use it to provide the checks needed during testing.\n\nUnfortunately, knowledge isn’t stable. It changes—often rapidly. Your understanding of a requirement may change following a meeting with the client. The government changes a regulation and some business logic gets outdated. Tests may show that the chosen algorithm won’t work. All this instability means that we spend a large part of our time in maintenance mode, reorganizing and reexpressing the knowledge in our systems.\n\nMost people assume that maintenance begins when an application is released, that maintenance means ﬁxing bugs and enhancing features. We think these people are wrong. Programmers are constantly in main- tenance mode. Our understanding changes day by day. New require- ments arrive as we’re designing or coding. Perhaps the environment changes. Whatever the reason, maintenance is not a discrete activity, but a routine part of the entire development process.\n\nTHE EVILS OF DUPLICATION\n\nWhen we perform maintenance, we have to ﬁnd and change the rep- resentations of things—those capsules of knowledge embedded in the application. The problem is that it’s easy to duplicate knowledge in the speciﬁcations, processes, and programs that we develop, and when we do so, we invite a maintenance nightmare—one that starts well before the application ships.\n\nWe feel that the only way to develop software reliably, and to make our developments easier to understand and maintain, is to follow what we call the DRY principle:\n\nEVERY PIECE OF KNOWLEDGE MUST HAVE A SINGLE, UNAMBIGU- OUS, AUTHORITATIVE REPRESENTATION WITHIN A SYSTEM.\n\nWhy do we call it DRY?\n\nTIP 11\n\nDRY—Don’t Repeat Yourself\n\nThe alternative is to have the same thing expressed in two or more places. If you change one, you have to remember to change the others, or, like the alien computers, your program will be brought to its knees by a contradiction. It isn’t a question of whether you’ll remember: it’s a question of when you’ll forget.\n\nYou’ll ﬁnd the DRY principle popping up time and time again through- out this book, often in contexts that have nothing to do with coding. We feel that it is one of the most important tools in the Pragmatic Pro- grammer’s tool box.\n\nIn this section we’ll outline the problems of duplication and suggest general strategies for dealing with it.\n\nHowDoes DuplicationArise? Most of the duplication we see falls into one of the following categories:\n\nImposed duplication. Developers feel they have no choice—the environment seems to require duplication.\n\nInadvertent duplication. Developers don’t realize that they are duplicating information.\n\n27\n\n28\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nImpatient duplication. Developers get lazy and duplicate because it seems easier.\n\nInterdeveloper duplication. Multiple people on a team (or on dif- ferent teams) duplicate a piece of information.\n\nLet’s look at these four i’s of duplication in more detail.\n\nImposedDuplication Sometimes, duplication seems to be forced on us. Project standards may require documents that contain duplicated information, or docu- ments that duplicate information in the code. Multiple target platforms each require their own programming languages, libraries, and devel- opment environments, which makes us duplicate shared deﬁnitions and procedures. Programming languages themselves require certain structures that duplicate information. We have all worked in situations where we felt powerless to avoid duplication. And yet often there are ways of keeping each piece of knowledge in one place, honoring the DRY principle, and making our lives easier at the same time. Here are some techniques:\n\nMultiple representations of information. At the coding level, we often need to have the same information represented in different forms. Maybe we’re writing a client-server application, using different lan- guages on the client and server, and need to represent some shared structure on both. Perhaps we need a class whose attributes mirror the schema of a database table. Maybe you’re writing a book and want to include excerpts of programs that you also will compile and test.\n\nWith a bit of ingenuity you can normally remove the need for dupli- cation. Often the answer is to write a simple ﬁlter or code generator. Structures in multiple languages can be built from a common metadata representation using a simple code generator each time the software is built (an example of this is shown in Figure 3.4, page 106). Class deﬁni- tions can be generated automatically from the online database schema, or from the metadata used to build the schema in the ﬁrst place. The code extracts in this book are inserted by a preprocessor each time we format the text. The trick is to make the process active: this cannot be a one-time conversion, or we’re back in a position of duplicating data.\n\nTHE EVILS OF DUPLICATION\n\nDocumentation in code. Programmers are taught to comment their code: good code has lots of comments. Unfortunately, they are never taught why code needs comments: bad code requires lots of comments.\n\nThe DRY principle tells us to keep the low-level knowledge in the code, where it belongs, and reserve the comments for other, high-level expla- nations. Otherwise, we’re duplicating knowledge, and every change means changing both the code and the comments. The comments will inevitably become out of date, and untrustworthy comments are worse than no comments at all. (See It’s All Writing, page 248, for more infor- mation on comments.)\n\nDocumentation and code. You write documentation, then you write code. Something changes, and you amend the documentation and up- date the code. The documentation and code both contain representa- tions of the same knowledge. And we all know that in the heat of the moment, with deadlines looming and important clients clamoring, we tend to defer the updating of documentation.\n\nDave once worked on an international telex switch. Quite understand- ably, the client demanded an exhaustive test speciﬁcation and required that the software pass all tests on each delivery. To ensure that the tests accurately reﬂected the speciﬁcation, the team generated them programmatically from the document itself. When the client amended their speciﬁcation, the test suite changed automatically. Once the team convinced the client that the procedure was sound, generating accep- tance tests typically took only a few seconds.\n\nLanguage issues. Many languages impose considerable duplication in the source. Often this comes about when the language separates a module’s interface from its implementation. C and C++ have header ﬁles that duplicate the names and type information of exported vari- ables, functions, and (for C++) classes. Object Pascal even duplicates this information in the same ﬁle. If you are using remote procedure calls or CORBA [URL 29], you’ll duplicate interface information between the interface speciﬁcation and the code that implements it.\n\nThere is no easy technique for overcoming the requirements of a lan- guage. While some development environments hide the need for header ﬁles by generating them automatically, and Object Pascal allows you to abbreviate repeated function declarations, you are generally stuck with\n\n29\n\n30\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nwhat you’re given. At least with most language-based issues, a header ﬁle that disagrees with the implementation will generate some form of compilation or linkage error. You can still get things wrong, but at least you’ll be told about it fairly early on.\n\nThink also about comments in header and implementation ﬁles. There is absolutely no point in duplicating a function or class header com- ment between the two ﬁles. Use the header ﬁles to document interface issues, and the implementation ﬁles to document the nitty-gritty details that users of your code don’t need to know.\n\nInadvertentDuplication Sometimes, duplication comes about as the result of mistakes in the design.\n\nLet’s look at an example from the distribution industry. Say our anal- ysis reveals that, among other attributes, a truck has a type, a license number, and a driver. Similarly, a delivery route is a combination of a route, a truck, and a driver. We code up some classes based on this understanding.\n\nBut what happens when Sally calls in sick and we have to change drivers? Both Truck and DeliveryRoute contain a driver. Which one do we change? Clearly this duplication is bad. Normalize it according to the underlying business model—does a truck really have a driver as part of its underlying attribute set? Does a route? Or maybe there needs to be a third object that knits together a driver, a truck, and a route. Whatever the eventual solution, avoid this kind of unnormalized data.\n\nThere is a slightly less obvious kind of unnormalized data that occurs when we have multiple data elements that are mutually dependent. Let’s look at a class representing a line:\n\nclass Line {\n\npublic:\n\nPoint start; Point end; double length;\n\n};\n\nAt ﬁrst sight, this class might appear reasonable. A line clearly has a start and end, and will always have a length (even if it’s zero). But we\n\nTHE EVILS OF DUPLICATION\n\nhave duplication. The length is deﬁned by the start and end points: change one of the points and the length changes. It’s better to make the length a calculated ﬁeld:\n\nclass Line {\n\npublic:\n\nPoint start; Point end; double length() { return start.distanceTo(end); }\n\n};\n\nLater on in the development process, you may choose to violate the DRY principle for performance reasons. Frequently this occurs when you need to cache data to avoid repeating expensive operations. The trick is to localize the impact. The violation is not exposed to the outside world: only the methods within the class have to worry about keeping things straight.\n\nclass Line {\n\nprivate:\n\nbool double length; Point start; Point end;\n\nchanged;\n\npublic:\n\nvoid setStart(Point p) { start = p; changed = true; } = p; changed = true; } void setEnd(Point p)\n\n{ end\n\nPoint getStart(void) Point getEnd(void)\n\n{ return start; } } { return end;\n\ndouble getLength() {\n\nif (changed) {\n\nlength = start.distanceTo(end); changed = false;\n\n} return length;\n\n}\n\n};\n\nThis example also illustrates an important issue for object-oriented lan- guages such as Java and C++. Where possible, always use accessor functions to read and write the attributes of objects.1 It will make it easier to add functionality, such as caching, in the future.\n\nThe use of accessor functions ties in with Meyer’s Uniform Access principle [Mey97b], 1. which states that “All services offered by a module should be available through a uni- form notation, which does not betray whether they are implemented through storage or through computation.”\n\n31\n\n32\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nImpatient Duplication Every project has time pressures—forces that can drive the best of us to take shortcuts. Need a routine similar to one you’ve written? You’ll be tempted to copy the original and make a few changes. Need a value to represent the maximum number of points? If I change the header ﬁle, the whole project will get rebuilt. Maybe I should just use a literal number here; and here; and here. Need a class like one in the Java runtime? The source is available, so why not just copy it and make the changes you need (license provisions notwithstanding)?\n\nIf you feel this temptation, remember the hackneyed aphorism “short cuts make for long delays.” You may well save some seconds now, but at the potential loss of hours later. Think about the issues surround- ing the Y2K ﬁasco. Many were caused by the laziness of developers not parameterizing the size of date ﬁelds or implementing centralized libraries of date services.\n\nImpatient duplication is an easy form to detect and handle, but it takes discipline and a willingness to spend time up front to save pain later.\n\nInterdeveloperDuplication On the other hand, perhaps the hardest type of duplication to detect and handle occurs between different developers on a project. Entire sets of functionality may be inadvertently duplicated, and that duplica- tion could go undetected for years, leading to maintenance problems. We heard ﬁrsthand of a U.S. state whose governmental computer sys- tems were surveyed for Y2K compliance. The audit turned up more than 10,000 programs, each containing its own version of Social Secu- rity number validation.\n\nAt a high level, deal with the problem by having a clear design, a strong technical project leader (see page 228 in Pragmatic Teams), and a well- understood division of responsibilities within the design. However, at the module level, the problem is more insidious. Commonly needed functionality or data that doesn’t fall into an obvious area of responsi- bility can get implemented many times over.\n\nWe feel that the best way to deal with this is to encourage active and frequent communication between developers. Set up forums to discuss common problems. (On past projects, we have set up private Usenet\n\nTHE EVILS OF DUPLICATION\n\nnewsgroups to allow developers to exchange ideas and ask questions. This provides a nonintrusive way of communicating—even across mul- tiple sites—while retaining a permanent history of everything said.) Appoint a team member as the project librarian, whose job is to facil- itate the exchange of knowledge. Have a central place in the source tree where utility routines and scripts can be deposited. And make a point of reading other people’s source code and documentation, either informally or during code reviews. You’re not snooping—you’re learning from them. And remember, the access is reciprocal—don’t get twisted about other people poring (pawing?) through your code, either.\n\nTIP 12\n\nMake It Easy to Reuse\n\nWhat you’re trying to do is foster an environment where it’s easier to ﬁnd and reuse existing stuff than to write it yourself. If it isn’t easy, people won’t do it. And if you fail to reuse, you risk duplicating knowl- edge.\n\nRelated sections include: Orthogonality, page 34 Text Manipulation, page 99 Code Generators, page 102 Refactoring, page 184 Pragmatic Teams, page 224 Ubiquitous Automation, page 230 It’s All Writing, page 248\n\n33",
      "page_number": 50
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 58-65)",
      "start_page": 58,
      "end_page": 65,
      "detection_method": "topic_boundary",
      "content": "34\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\n8 Orthogonality\n\nOrthogonality is a critical concept if you want to produce systems that are easy to design, build, test, and extend. However, the concept of orthogonality is rarely taught directly. Often it is an implicit feature of various other methods and techniques you learn. This is a mistake. Once you learn to apply the principle of orthogonality directly, you’ll notice an immediate improvement in the quality of systems you pro- duce.\n\nWhat IsOrthogonality? “Orthogonality” is a term borrowed from geom- etry. Two lines are orthogonal if they meet at right angles, such as the axes on a graph. In vector terms, the two lines are independent. Move along one of the lines, and your position projected onto the other doesn’t change.\n\nmove parallel to X-axis\n\nno change on Y-axis\n\nIn computing, the term has come to signify a kind of independence or decoupling. Two or more things are orthogonal if changes in one do not affect any of the others. In a well-designed system, the database code will be orthogonal to the user interface: you can change the interface without affecting the database, and swap databases without changing the interface.\n\nBefore we look at the beneﬁts of orthogonal systems, let’s ﬁrst look at a system that isn’t orthogonal.\n\nA Nonorthogonal System You’re on a helicopter tour of the Grand Canyon when the pilot, who made the obvious mistake of eating ﬁsh for lunch, suddenly groans and faints. Fortunately, he left you hovering 100 feet above the ground. You rationalize that the collective pitch lever 2 controls overall lift, so lower-\n\n2. Helicopters have four basic controls. The cyclic is the stick you hold in your right hand. Move it, and the helicopter moves in the corresponding direction. Your left hand holds the collective pitch lever. Pull up on this and you increase the pitch on all the blades, generating lift. At the end of the pitch lever is the throttle. Finally you have two foot pedals, which vary the amount of tail rotor thrust and so help turn the helicopter.\n\nORTHOGONALITY\n\ning it slightly will start a gentle descent to the ground. However, when you try it, you discover that life isn’t that simple. The helicopter’s nose drops, and you start to spiral down to the left. Suddenly you discover that you’re ﬂying a system where every control input has secondary effects. Lower the left-hand lever and you need to add compensating backward movement to the right-hand stick and push the right pedal. But then each of these changes affects all of the other controls again. Suddenly you’re juggling an unbelievably complex system, where every change impacts all the other inputs. Your workload is phenomenal: your hands and feet are constantly moving, trying to balance all the interacting forces.\n\nHelicopter controls are decidedly not orthogonal.\n\nBeneﬁtsof Orthogonality As the helicopter example illustrates, nonorthogonal systems are in- herently more complex to change and control. When components of any system are highly interdependent, there is no such thing as a local ﬁx.\n\nTIP 13\n\nEliminate Effects Between Unrelated Things\n\nWe want to design components that are self-contained: independent, and with a single, well-deﬁned purpose (what Yourdon and Constan- tine call cohesion [YC86]). When components are isolated from one another, you know that you can change one without having to worry about the rest. As long as you don’t change that component’s external interfaces, you can be comfortable that you won’t cause problems that ripple through the entire system.\n\nYou get two major beneﬁts if you write orthogonal systems: increased productivity and reduced risk.\n\nGainProductivity\n\nChanges are localized, so development time and testing time are reduced. It is easier to write relatively small, self-contained compo- nents than a single large block of code. Simple components can be\n\n35\n\n36\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\ndesigned, coded, unit tested, and then forgotten—there is no need to keep changing existing code as you add new code.\n\nAn orthogonal approach also promotes reuse. If components have speciﬁc, well-deﬁned responsibilities, they can be combined with new components in ways that were not envisioned by their original implementors. The more loosely coupled your systems, the easier they are to reconﬁgure and reengineer.\n\nThere is a fairly subtle gain in productivity when you combine dis- orthogonal components. Assume that one component does things. If they are orthogonal and tinct things and another does things. However, if the you combine them, the result does two components are not orthogonal, there will be overlap, and the result will do less. You get more functionality per unit effort by combining orthogonal components.\n\nReduce Risk An orthogonal approach reduces the risks inherent in any development.\n\nDiseased sections of code are isolated. If a module is sick, it is less likely to spread the symptoms around the rest of the system. It is also easier to slice it out and transplant in something new and healthy.\n\nThe resulting system is less fragile. Make small changes and ﬁxes to a particular area, and any problems you generate will be restricted to that area.\n\nAn orthogonal system will probably be better tested, because it will be easier to design and run tests on its components.\n\nYou will not be as tightly tied to a particular vendor, product, or platform, because the interfaces to these third-party components will be isolated to smaller parts of the overall development.\n\nLet’s look at some of the ways you can apply the principle of orthogo- nality to your work.\n\nProjectTeams Have you noticed how some project teams are efﬁcient, with everyone knowing what to do and contributing fully, while the members of other\n\nORTHOGONALITY\n\nteams are constantly bickering and don’t seem able to get out of each other’s way?\n\nOften this is an orthogonality issue. When teams are organized with lots of overlap, members are confused about responsibilities. Every change needs a meeting of the entire team, because any one of them might be affected.\n\nHow do you organize teams into groups with well-deﬁned responsibili- ties and minimal overlap? There’s no simple answer. It depends partly on the project and your analysis of the areas of potential change. It also depends on the people you have available. Our preference is to start by separating infrastructure from application. Each major infrastructure component (database, communications interface, middleware layer, and so on) gets its own subteam. Each obvious division of application functionality is similarly divided. Then we look at the people we have (or plan to have) and adjust the groupings accordingly.\n\nYou can get an informal measure of the orthogonality of a project team’s structure. Simply see how many people need to be involved in dis- cussing each change that is requested. The larger the number, the less orthogonal the group. Clearly, an orthogonal team is more efﬁcient. (Having said this, we also encourage subteams to communicate con- stantly with each other.)\n\nDesign Most developers are familiar with the need to design orthogonal sys- tems, although they may use words such as modular, component-based, and layered to describe the process. Systems should be composed of a set of cooperating modules, each of which implements functionality independent of the others. Sometimes these components are organized into layers, each providing a level of abstraction. This layered approach is a powerful way to design orthogonal systems. Because each layer uses only the abstractions provided by the layers below it, you have great ﬂexibility in changing underlying implementations without affect- ing code. Layering also reduces the risk of runaway dependencies be- tween modules. You’ll often see layering expressed in diagrams such as Figure 2.1 on the next page.\n\nThere is an easy test for orthogonal design. Once you have your com- ponents mapped out, ask yourself: If I dramatically change the require-\n\n37\n\n38\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nFigure 2.1. Typical layer diagram\n\nUser Interface\n\nDatabase access\n\nReport engine\n\nBusiness logic\n\nApplication framework\n\nStandard C library\n\nOperating system\n\nments behind a particular function, how many modules are affected? In an orthogonal system, the answer should be “one.”3 Moving a button on a GUI panel should not require a change in the database schema. Adding context-sensitive help should not change the billing subsystem.\n\nLet’s consider a complex system for monitoring and controlling a heat- ing plant. The original requirement called for a graphical user interface, but the requirements were changed to add a voice response system with touchtone telephone control of the plant. In an orthogonally designed system, you would need to change only those modules associated with the user interface to handle this: the underlying logic of controlling the plant would remain unchanged. In fact, if you structure your system carefully, you should be able to support both interfaces with the same underlying code base. It’s Just a View, page 157, talks about writing de- coupled code using the Model-View-Controller (MVC) paradigm, which works well in this situation.\n\n3. In reality, this is naive. Unless you are remarkably lucky, most real-world require- ments changes will affect multiple functions in the system. However, if you analyze the change in terms of functions, each functional change should still ideally affect just one module.\n\nORTHOGONALITY\n\nAlso ask yourself how decoupled your design is from changes in the real world. Are you using a telephone number as a customer identiﬁer? What happens when the phone company reassigns area codes? Don’t rely on the properties of things you can’t control.\n\nToolkitsand Libraries Be careful to preserve the orthogonality of your system as you introduce third-party toolkits and libraries. Choose your technologies wisely.\n\nWe once worked on a project that required that a certain body of Java code run both locally on a server machine and remotely on a client machine. The alternatives for distributing classes this way were RMI and CORBA. If a class were made remotely accessible using RMI, every call to a remote method in that class could potentially throw an excep- tion, which means that a naive implementation would require us to handle the exception whenever our remote classes were used. Using RMI here is clearly not orthogonal: code calling our remote classes should not have to be aware of their locations. The alternative—using CORBA—did not impose that restriction: we could write code that was unaware of our classes’ locations.\n\nWhen you bring in a toolkit (or even a library from other members of your team), ask yourself whether it imposes changes on your code that shouldn’t be there. If an object persistence scheme is transparent, then it’s orthogonal. If it requires you to create or access objects in a special way, then it’s not. Keeping such details isolated from your code has the added beneﬁt of making it easier to change vendors in the future.\n\nThe Enterprise Java Beans (EJB) system is an interesting example of orthogonality. In most transaction-oriented systems, the application code has to delineate the start and end of each transaction. With EJB, this information is expressed declaratively as metadata, outside any code. The same application code can run in different EJB transaction environments with no change. This is likely to be a model for many future environments.\n\nAnother interesting twist on orthogonality is Aspect-Oriented Program- ming (AOP), a research project at Xerox Parc ([KLM 97] and [URL 49]). AOP lets you express in one place behavior that would otherwise be distributed throughout your source code. For example, log messages\n\n39\n\n40\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nare normally generated by sprinkling explicit calls to some log function throughout your source. With AOP, you implement logging orthogonally to the things being logged. Using the Java version of AOP, you could write a log message when entering any method of class Fred by coding the aspect:\n\naspect Trace {\n\nadvise * Fred.*(..) {\n\nstatic before {\n\nLog.write(\"-> Entering \" + thisJoinPoint.methodName);\n\n}\n\n}\n\n}\n\nIf you weave this aspect into your code, trace messages will be gen- erated. If you don’t, you’ll see no messages. Either way, your original source is unchanged.\n\nCoding Every time you write code you run the risk of reducing the orthogonality of your application. Unless you constantly monitor not just what you are doing but also the larger context of the application, you might un- intentionally duplicate functionality in some other module, or express existing knowledge twice.\n\nThere are several techniques you can use to maintain orthogonality:\n\nKeep your code decoupled. Write shy code—modules that don’t reveal anything unnecessary to other modules and that don’t rely on other modules’ implementations. Try the Law of Demeter [LH89], which we discuss in Decoupling and the Law of Demeter, page 138. If you need to change an object’s state, get the object to do it for you. This way your code remains isolated from the other code’s imple- mentation and increases the chances that you’ll remain orthogonal.\n\nAvoid global data. Every time your code references global data, it ties itself into the other components that share that data. Even globals that you intend only to read can lead to trouble (for exam- ple, if you suddenly need to change your code to be multithreaded). In general, your code is easier to understand and maintain if you explicitly pass any required context into your modules. In object- oriented applications, context is often passed as parameters to\n\nORTHOGONALITY\n\nobjects’ constructors. In other code, you can create structures con- taining the context and pass around references to them.\n\nThe Singleton pattern in Design Patterns [GHJV95] is a way of ensuring that there is only one instance of an object of a particular class. Many people use these singleton objects as a kind of global variable (particularly in languages, such as Java, that otherwise do not support the concept of globals). Be careful with singletons— they can also lead to unnecessary linkage.\n\nAvoid similar functions. Often you’ll come across a set of functions that all look similar—maybe they share common code at the start and end, but each has a different central algorithm. Duplicate code is a symptom of structural problems. Have a look at the Strategy pattern in Design Patterns for a better implementation.\n\nGet into the habit of being constantly critical of your code. Look for any opportunities to reorganize it to improve its structure and orthogonal- ity. This process is called refactoring, and it’s so important that we’ve dedicated a section to it (see Refactoring, page 184).\n\nTesting An orthogonally designed and implemented system is easier to test. Because the interactions between the system’s components are formal- ized and limited, more of the system testing can be performed at the individual module level. This is good news, because module level (or unit) testing is considerably easier to specify and perform than integra- tion testing. In fact, we suggest that every module have its own unit test built into its code, and that these tests be performed automatically as part of the regular build process (see Code That’s Easy to Test, page 189).\n\nBuilding unit tests is itself an interesting test of orthogonality. What does it take to build and link a unit test? Do you have to drag in a large percentage of the rest of the system just to get a test to compile or link? If so, you’ve found a module that is not well decoupled from the rest of the system.\n\nBug ﬁxing is also a good time to assess the orthogonality of the system as a whole. When you come across a problem, assess how localized\n\n41",
      "page_number": 58
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 66-74)",
      "start_page": 66,
      "end_page": 74,
      "detection_method": "topic_boundary",
      "content": "42\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nthe ﬁx is. Do you change just one module, or are the changes scat- tered throughout the entire system? When you make a change, does it ﬁx everything, or do other problems mysteriously arise? This is a good opportunity to bring automation to bear. If you use a source code con- trol system (and you will after reading Source Code Control, page 86), tag bug ﬁxes when you check the code back in after testing. You can then run monthly reports analyzing trends in the number of source ﬁles affected by each bug ﬁx.\n\nDocumentation Perhaps surprisingly, orthogonality also applies to documentation. The axes are content and presentation. With truly orthogonal documenta- tion, you should be able to change the appearance dramatically without changing the content. Modern word processors provide style sheets and macros that help (see It’s All Writing, page 248).\n\nLiving with Orthogonality Orthogonality is closely related to the DRY principle introduced on page 27. With DRY, you’re looking to minimize duplication within a system, whereas with orthogonality you reduce the interdependency among the system’s components. It may be a clumsy word, but if you use the prin- ciple of orthogonality, combined closely with the DRY principle, you’ll ﬁnd that the systems you develop are more ﬂexible, more understand- able, and easier to debug, test, and maintain.\n\nIf you’re brought into a project where people are desperately struggling to make changes, and where every change seems to cause four other things to go wrong, remember the nightmare with the helicopter. The project probably is not orthogonally designed and coded. It’s time to refactor.\n\nAnd, if you’re a helicopter pilot, don’t eat the ﬁsh\n\n.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26 Source Code Control, page 86 Design by Contract, page 109 Decoupling and the Law of Demeter, page 138\n\nORTHOGONALITY\n\n43\n\nMetaprogramming, page 144 It’s Just a View, page 157 Refactoring, page 184 Code That’s Easy to Test, page 189 Evil Wizards, page 198 Pragmatic Teams, page 224 It’s All Writing, page 248\n\nChallenges\n\nConsider the difference between large GUI-oriented tools typically found on Windows systems and small but combinable command line utilities used at shell prompts. Which set is more orthogonal, and why? Which is easier to use for exactly the purpose for which it was intended? Which set is easier to combine with other tools to meet new challenges?\n\nC++ supports multiple inheritance, and Java allows a class to implement multiple interfaces. What impact does using these facilities have on orthog- onality? Is there a difference in impact between using multiple inheritance and multiple interfaces? Is there a difference between using delegation and using inheritance?\n\nExercises 1.\n\nYou are writing a class called Split, which splits input lines into ﬁelds. Which of the following two Java class signatures is the more orthogonal design?\n\nclass Split1 {\n\npublic Split1(InputStreamReader rdr) { ... public void readNextLine() throws IOException { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\nclass Split2 {\n\npublic Split2(String line) { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\n2. Which will lead to a more orthogonal design: modeless or modal dialog\n\nboxes?\n\n3. How about procedural languages versus object technology? Which results Answer on p. 280\n\n3. How about procedural languages versus object technology? Which results Answer on p. 280\n\nin a more orthogonal system?\n\nAnswer on p. 279\n\n9\n\n44\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nReversibility\n\nNothing is more dangerous than an idea if it’s the only one you have.\n\nEmil-Auguste Chartier, Propos surlareligion, 1938\n\nEngineers prefer simple, single solutions to problems. Math tests that are much more allow you to proclaim with great conﬁdence that comfortable than fuzzy, warm essays about the myriad causes of the French Revolution. Management tends to agree with the engineers: sin- gle, easy answers ﬁt nicely on spreadsheets and project plans.\n\nis today, If only the real world would cooperate! Unfortunately, while it may need to be tomorrow, and next week. Nothing is forever—and if you rely heavily on some fact, you can almost guarantee that it will change.\n\nThere is always more than one way to implement something, and there is usually more than one vendor available to provide a third-party prod- uct. If you go into a project hampered by the myopic notion that there is only one way to do it, you may be in for an unpleasant surprise. Many project teams have their eyes forcibly opened as the future unfolds:\n\n“But you said we’d use database XYZ! We are 85% done coding the project, we can’t change now!” the programmer protested. “Sorry, but our company decided to standardize on database PDQ instead—for all projects. It’s out of my hands. We’ll just have to recode. All of you will be working weekends until further notice.”\n\nChanges don’t have to be that Draconian, or even that immediate. But as time goes by, and your project progresses, you may ﬁnd yourself stuck in an untenable position. With every critical decision, the project team commits to a smaller target—a narrower version of reality that has fewer options.\n\nBy the time many critical decisions have been made, the target becomes so small that if it moves, or the wind changes direction, or a butterﬂy in Tokyo ﬂaps its wings, you miss.4 And you may miss by a huge amount.\n\n4. Take a nonlinear, or chaotic, system and apply a small change to one of its inputs. You may get a large and often unpredictable result. The clichéd butterﬂy ﬂapping its wings in Tokyo could be the start of a chain of events that ends up generating a tornado in Texas. Does this sound like any projects you know?\n\nREVERSIBILITY\n\nThe problem is that critical decisions aren’t easily reversible.\n\nOnce you decide to use this vendor’s database, or that architectural pattern, or a certain deployment model (client-server versus stand- alone, for instance), you are committed to a course of action that cannot be undone, except at great expense.\n\nReversibility Many of the topics in this book are geared to producing ﬂexible, adapt- able software. By sticking to their recommendations—especially the DRY principle (page 26), decoupling (page 138), and use of metadata (page 144)—we don’t have to make as many critical, irreversible de- cisions. This is a good thing, because we don’t always make the best decisions the ﬁrst time around. We commit to a certain technology only to discover we can’t hire enough people with the necessary skills. We lock in a certain third-party vendor just before they get bought out by their competitor. Requirements, users, and hardware change faster than we can get the software developed.\n\nSuppose you decide, early in the project, to use a relational database from vendor A. Much later, during performance testing, you discover that the database is simply too slow, but that the object database from vendor B is faster. With most conventional projects, you’d be out of luck. Most of the time, calls to third-party products are entangled throughout the code. But if you really abstracted the idea of a database out—to the point where it simply provides persistence as a service— then you have the ﬂexibility to change horses in midstream.\n\nSimilarly, suppose the project begins as a client-server model, but then, late in the game, marketing decides that servers are too expensive for some clients, and they want a stand-alone version. How hard would that be for you? Since it’s just a deployment issue, it shouldn’t take more than a few days. If it would take longer, then you haven’t thought about reversibility. The other direction is even more interesting. What if the stand-alone product you are making needs to be deployed in a client-server or n-tier fashion? That shouldn’t be hard either.\n\nThe mistake lies in assuming that any decision is cast in stone—and in not preparing for the contingencies that might arise. Instead of carving\n\n45\n\n46\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\ndecisions in stone, think of them more as being written in the sand at the beach. A big wave can come along and wipe them out at any time.\n\nTIP 14\n\nThere Are No Final Decisions\n\nFlexibleArchitecture While many people try to keep their code ﬂexible, you also need to think about maintaining ﬂexibility in the areas of architecture, deployment, and vendor integration.\n\nTechnologies such as CORBA can help insulate portions of a project from changes in development language or platform. Is the performance of Java on that platform not up to expectations? Recode the client in C++, and nothing else needs to change. Is the rules engine in C++ not ﬂexible enough? Switch over to a Smalltalk version. With a CORBA architecture, you have to take a hit only for the component you are replacing; the other components shouldn’t be affected.\n\nAre you developing for Unix? Which one? Do you have all of the porta- bility concerns addressed? Are you developing for a particular version of Windows? Which one—3.1, 95, 98, NT, CE, or 2000? How hard will it be to support other versions? If you keep decisions soft and pliable, it won’t be hard at all. If you have poor encapsulation, high coupling, and hard-coded logic or parameters in the code, it might be impossible.\n\nNot sure how marketing wants to deploy the system? Think about it up front and you can support a stand-alone, client-server, or n-tier model just by changing a conﬁguration ﬁle. We’ve written programs that do just that.\n\nNormally, you can simply hide a third-party product behind a well- deﬁned, abstract interface. In fact, we’ve always been able to do so on any project we’ve worked on. But suppose you couldn’t isolate it that cleanly. What if you had to sprinkle certain statements liberally throughout the code? Put that requirement in metadata, and use some automatic mechanism, such as Aspects (see page 39) or Perl, to insert the necessary statements into the code itself. Whatever mechanism you\n\nREVERSIBILITY\n\nuse, make it reversible. If something is added automatically, it can be taken out automatically as well.\n\nNo one knows what the future may hold, especially not us! So en- able your code to rock-n-roll: to “rock on” when it can, to roll with the punches when it must.\n\nRelated sections include:\n\nDecoupling and the Law of Demeter, page 138 Metaprogramming, page 144 It’s Just a View, page 157\n\nChallenges\n\nTime for a little quantum mechanics with Schrödinger’s cat. Suppose you have a cat in a closed box, along with a radioactive particle. The particle has exactly a 50% chance of ﬁssioning into two. If it does, the cat will be killed. If it doesn’t, the cat will be okay. So, is the cat dead or alive? According to Schrödinger, the correct answer is both. Every time a sub- nuclear reaction takes place that has two possible outcomes, the universe is cloned. In one, the event occurred, in the other it didn’t. The cat’s alive in one universe, dead in another. Only when you open the box do you know which universe you are in.\n\nNo wonder coding for the future is difﬁcult.\n\nBut think of code evolution along the same lines as a box full of Schrö- dinger’s cats: every decision results in a different version of the future. How many possible futures can your code support? Which ones are more likely? How hard will it be to support them when the time comes?\n\nDare you open the box?\n\n47\n\n10\n\n48\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nTracer Bullets\n\nReady, ﬁre, aim\n\nThere are two ways to ﬁre a machine gun in the dark.5 You can ﬁnd out exactly where your target is (range, elevation, and azimuth). You can determine the environmental conditions (temperature, humidity, air pressure, wind, and so on). You can determine the precise speci- ﬁcations of the cartridges and bullets you are using, and their inter- actions with the actual gun you are ﬁring. You can then use tables or a ﬁring computer to calculate the exact bearing and elevation of the barrel. If everything works exactly as speciﬁed, your tables are correct, and the environment doesn’t change, your bullets should land close to their target.\n\nOr you could use tracer bullets.\n\nTracer bullets are loaded at intervals on the ammo belt alongside reg- ular ammunition. When they’re ﬁred, their phosphorus ignites and leaves a pyrotechnic trail from the gun to whatever they hit. If the trac- ers are hitting the target, then so are the regular bullets.\n\nNot surprisingly, tracer bullets are preferred to the labor of calcula- tion. The feedback is immediate, and because they operate in the same environment as the real ammunition, external effects are minimized.\n\nThe analogy might be violent, but it applies to new projects, particularly when you’re building something that hasn’t been built before. Like the gunners, you’re trying to hit a target in the dark. Because your users have never seen a system like this before, their requirements may be vague. Because you may be using algorithms, techniques, languages, or libraries you aren’t familiar with, you face a large number of un- knowns. And because projects take time to complete, you can pretty much guarantee the environment you’re working in will change before you’re done.\n\nThe classic response is to specify the system to death. Produce reams of paper itemizing every requirement, tying down every unknown, and\n\nTo be pedantic, there are many ways of ﬁring a machine gun in the dark, including 5. closing your eyes and spraying out bullets. But this is an analogy, and we’re allowed to take liberties.\n\nTRACER BULLETS\n\nconstraining the environment. Fire the gun using dead reckoning. One big calculation up front, then shoot and hope.\n\nPragmatic Programmers, however, tend to prefer using tracer bullets.\n\nCodeThatGlowsintheDark Tracer bullets work because they operate in the same environment and under the same constraints as the real bullets. They get to the tar- get fast, so the gunner gets immediate feedback. And from a practical standpoint they’re a relatively cheap solution.\n\nTo get the same effect in code, we’re looking for something that gets us from a requirement to some aspect of the ﬁnal system quickly, visibly, and repeatably.\n\nTIP 15\n\nUse Tracer Bullets to Find the Target\n\nWe once undertook a complex client-server database marketing project. Part of its requirement was the ability to specify and execute temporal queries. The servers were a range of relational and specialized data- bases. The client GUI, written in Object Pascal, used a set of C libraries to provide an interface to the servers. The user’s query was stored on the server in a Lisp-like notation before being converted to optimized SQL just prior to execution. There were many unknowns and many different environments, and no one was too sure how the GUI should behave.\n\nThis was a great opportunity to use tracer code. We developed the framework for the front end, libraries for representing the queries, and a structure for converting a stored query into a database-speciﬁc query. Then we put it all together and checked that it worked. For that initial build, all we could do was submit a query that listed all the rows in a table, but it proved that the UI could talk to the libraries, the libraries could serialize and unserialize a query, and the server could generate SQL from the result. Over the following months we gradually ﬂeshed out this basic structure, adding new functionality by augmenting each component of the tracer code in parallel. When the UI added a new query type, the library grew and the SQL generation was made more sophisticated.\n\n49\n\n50\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nTracer code is not disposable: you write it for keeps. It contains all the error checking, structuring, documentation, and self-checking that any piece of production code has. It simply is not fully functional. However, once you have achieved an end-to-end connection among the compo- nents of your system, you can check how close to the target you are, adjusting if necessary. Once you’re on target, adding functionality is easy.\n\nTracer development is consistent with the idea that a project is never ﬁnished: there will always be changes required and functions to add. It is an incremental approach.\n\nThe conventional alternative is a kind of heavy engineering approach: code is divided into modules, which are coded in a vacuum. Modules are combined into subassemblies, which are then further combined, until one day you have a complete application. Only then can the appli- cation as a whole be presented to the user and tested.\n\nThe tracer code approach has many advantages:\n\nUsers get to see something working early. If you have success- fully communicated what you are doing (see Great Expectations, page 255), your users will know they are seeing something imma- ture. They won’t be disappointed by a lack of functionality; they’ll be ecstatic to see some visible progress toward their system. They also get to contribute as the project progresses, increasing their buy-in. These same users will likely be the people who’ll tell you how close to the target each iteration is.\n\nDevelopers build a structure to work in. The most daunting piece of paper is the one with nothing written on it. If you have worked out all the end-to-end interactions of your application, and have embodied them in code, then your team won’t need to pull as much out of thin air. This makes everyone more productive, and encour- ages consistency.\n\nYou have an integration platform. As the system is connected end-to-end, you have an environment to which you can add new pieces of code once they have been unit-tested. Rather than at- tempting a big-bang integration, you’ll be integrating every day (often many times a day). The impact of each new change is more apparent, and the interactions are more limited, so debugging and testing are faster and more accurate.",
      "page_number": 66
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 75-84)",
      "start_page": 75,
      "end_page": 84,
      "detection_method": "topic_boundary",
      "content": "TRACER BULLETS\n\nYou have something to demonstrate. Project sponsors and top brass have a tendency to want to see demos at the most inconve- nient times. With tracer code, you’ll always have something to show them.\n\nYou have a better feel for progress. In a tracer code development, developers tackle use cases one by one. When one is done, they move to the next. It is far easier to measure performance and to demonstrate progress to your user. Because each individual devel- opment is smaller, you avoid creating those monolithic blocks of code that are reported as 95% complete week after week.\n\nTracerBulletsDon’t AlwaysHit TheirTarget Tracer bullets show what you’re hitting. This may not always be the tar- get. You then adjust your aim until they’re on target. That’s the point.\n\nIt’s the same with tracer code. You use the technique in situations where you’re not 100% certain of where you’re going. You shouldn’t be surprised if your ﬁrst couple of attempts miss: the user says “that’s not what I meant,” or data you need isn’t available when you need it, or performance problems seem likely. Work out how to change what you’ve got to bring it nearer the target, and be thankful that you’ve used a lean development methodology. A small body of code has low inertia—it is easy and quick to change. You’ll be able to gather feed- back on your application and generate a new, more accurate version faster and at less cost than with any other method. And because every major application component is represented in your tracer code, your users can be conﬁdent that what they’re seeing is based on reality, not just a paper speciﬁcation.\n\nTracerCode versusPrototyping You might think that this tracer code concept is nothing more than prototyping under an aggressive name. There is a difference. With a prototype, you’re aiming to explore speciﬁc aspects of the ﬁnal system. With a true prototype, you will throw away whatever you lashed to- gether when trying out the concept, and recode it properly using the lessons you’ve learned.\n\nFor example, say you’re producing an application that helps shippers determine how to pack odd-sized boxes into containers. Among other\n\n51\n\n52\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nproblems, the user interface needs to be intuitive and the algorithms you use to determine optimal packing are very complex.\n\nYou could prototype a user interface for your end users in a GUI tool. You code only enough to make the interface responsive to user actions. Once they’ve agreed to the layout, you might throw it away and recode it, this time with the business logic behind it, using the target language. Similarly, you might want to prototype a number of algorithms that perform the actual packing. You might code functional tests in a high- level, forgiving language such as Perl, and code low-level performance tests in something closer to the machine. In any case, once you’d made your decision, you’d start again and code the algorithms in their ﬁnal environment, interfacing to the real world. This is prototyping, and it is very useful.\n\nThe tracer code approach addresses a different problem. You need to know how the application as a whole hangs together. You want to show your users how the interactions will work in practice, and you want to give your developers an architectural skeleton on which to hang code. In this case, you might construct a tracer consisting of a trivial imple- mentation of the container packing algorithm (maybe something like ﬁrst-come, ﬁrst-served) and a simple but working user interface. Once you have all the components in the application plumbed together, you have a framework to show your users and your developers. Over time, you add to this framework with new functionality, completing stubbed routines. But the framework stays intact, and you know the system will continue to behave the way it did when your ﬁrst tracer code was completed.\n\nThe distinction is important enough to warrant repeating. Prototyp- ing generates disposable code. Tracer code is lean but complete, and forms part of the skeleton of the ﬁnal system. Think of prototyping as the reconnaissance and intelligence gathering that takes place before a single tracer bullet is ﬁred.\n\nRelated sections include:\n\nGood-Enough Software, page 9 Prototypes and Post-it Notes, page 53 The Speciﬁcation Trap, page 217 Great Expectations, page 255\n\n11\n\nPROTOTYPES AND POST-IT NOTES\n\nPrototypes and Post-it Notes\n\nMany different industries use prototypes to try out speciﬁc ideas; pro- totyping is much cheaper than full-scale production. Car makers, for example, may build many different prototypes of a new car design. Each one is designed to test a speciﬁc aspect of the car—the aerodynamics, styling, structural characteristics, and so on. Perhaps a clay model will be built for wind tunnel testing, maybe a balsa wood and duct tape model will do for the art department, and so on. Some car companies take this a step further, and now do a great deal of modeling work on the computer, reducing costs even further. In this way, risky or uncer- tain elements can be tried out without committing to building the real item.\n\nWe build software prototypes in the same fashion, and for the same reasons—to analyze and expose risk, and to offer chances for correction at a greatly reduced cost. Like the car makers, we can target a prototype to test one or more speciﬁc aspects of a project.\n\nWe tend to think of prototypes as code-based, but they don’t always have to be. Like the car makers, we can build prototypes out of different materials. Post-it notes are great for prototyping dynamic things such as workﬂow and application logic. A user interface can be prototyped as a drawing on a whiteboard, as a nonfunctional mock-up drawn with a paint program, or with an interface builder.\n\nPrototypes are designed to answer just a few questions, so they are much cheaper and faster to develop than applications that go into pro- duction. The code can ignore unimportant details—unimportant to you at the moment, but probably very important to the user later on. If you are prototyping a GUI, for instance, you can get away with incorrect results or data. On the other hand, if you’re just investigating compu- tational or performance aspects, you can get away with a pretty poor GUI, or perhaps even no GUI at all.\n\nBut if you ﬁnd yourself in an environment where you cannot give up the details, then you need to ask yourself if you are really building a prototype at all. Perhaps a tracer bullet style of development would be more appropriate in this case (see Tracer Bullets, page 48).\n\n53\n\n54\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nThings toPrototype What sorts of things might you choose to investigate with a prototype? Anything that carries risk. Anything that hasn’t been tried before, or that is absolutely critical to the ﬁnal system. Anything unproven, exper- imental, or doubtful. Anything you aren’t comfortable with. You can prototype\n\nArchitecture\n\nNew functionality in an existing system\n\nStructure or contents of external data\n\nThird-party tools or components\n\nPerformance issues\n\nUser interface design\n\nPrototyping is a learning experience. Its value lies not in the code pro- duced, but in the lessons learned. That’s really the point of prototyping.\n\nTIP 16\n\nPrototype to Learn\n\nHowtoUsePrototypes When building a prototype, what details can you ignore?\n\nCorrectness. You may be able to use dummy data where appro- priate.\n\nCompleteness. The prototype may function only in a very limited sense, perhaps with only one preselected piece of input data and one menu item.\n\nRobustness. Error checking is likely to be incomplete or missing entirely. If you stray from the predeﬁned path, the prototype may crash and burn in a glorious display of pyrotechnics. That’s okay.\n\nIt is painful to admit this in print, but prototype code prob- Style. ably doesn’t have much in the way of comments or documenta- tion. You may produce reams of documentation as a result of your experience with the prototype, but comparatively very little on the prototype system itself.\n\nPROTOTYPES AND POST-IT NOTES\n\nSince a prototype should gloss over details, and focus in on speciﬁc aspects of the system being considered, you may want to implement prototypes using a very high-level language—higher than the rest of the project (maybe a language such as Perl, Python, or Tcl). A high- level scripting language lets you defer many details (including specify- ing data types) and still produce a functional (albeit incomplete or slow) piece of code.6 If you need to prototype user interfaces, investigate tools such as Tcl/Tk, Visual Basic, Powerbuilder, or Delphi.\n\nScripting languages work well as the “glue” to combine low-level pieces into new combinations. Under Windows, Visual Basic can glue together COM controls. More generally, you can use languages such as Perl and Python to bind together low-level C libraries—either by hand, or automatically with tools such as the freely available SWIG [URL 28]. Using this approach, you can rapidly assemble existing components into new conﬁgurations to see how things work.\n\nPrototypingArchitecture Many prototypes are constructed to model the entire system under con- sideration. As opposed to tracer bullets, none of the individual modules in the prototype system need to be particularly functional. In fact, you may not even need to code in order to prototype architecture—you can prototype on a whiteboard, with Post-it notes or index cards. What you are looking for is how the system hangs together as a whole, again de- ferring details. Here are some speciﬁc areas you may want to look for in the architectural prototype:\n\nAre the responsibilities of the major components well deﬁned and appropriate?\n\nAre the collaborations between major components well deﬁned?\n\nIs coupling minimized?\n\nCan you identify potential sources of duplication?\n\nAre interface deﬁnitions and constraints acceptable?\n\n6. stick to a language that is close in performance to the target language.\n\nIf you are investigating absolute (instead of relative) performance, you will need to\n\n55\n\nAnswer on p. 280\n\n56\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nDoes every module have an access path to the data it needs during execution? Does it have that access when it needs it?\n\nThis last item tends to generate the most surprises and the most valu- able results from the prototyping experience.\n\nHowNotto Use Prototypes Before you embark on any code-based prototyping, make sure that everyone understands that you are writing disposable code. Prototypes can be deceptively attractive to people who don’t know that they are just prototypes. You must make it very clear that this code is disposable, incomplete, and unable to be completed.\n\nIt’s easy to become misled by the apparent completeness of a demon- strated prototype, and project sponsors or management may insist on deploying the prototype (or its progeny) if you don’t set the right expec- tations. Remind them that you can build a great prototype of a new car out of balsa wood and duct tape, but you wouldn’t try to drive it in rush-hour trafﬁc!\n\nIf you feel there is a strong possibility in your environment or culture that the purpose of prototype code may be misinterpreted, you may be better off with the tracer bullet approach. You’ll end up with a solid framework on which to base future development.\n\nWhen used properly, a prototype can save you huge amounts of time, money, pain, and suffering by identifying and correcting potential prob- lem spots early in the development cycle—the time when ﬁxing mis- takes is both cheap and easy.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Communicate!, page 18 Tracer Bullets, page 48 Great Expectations, page 255\n\nExercises 4. Marketing would like to sit down and brainstorm a few Web-page designs with you. They are thinking of clickable image maps to take you to other pages, and so on. But they can’t decide on a model for the image—maybe\n\nDOMAIN LANGUAGES\n\nit’s a car, or a phone, or a house. You have a list of target pages and content; they’d like to see a few prototypes. Oh, by the way, you have 15 minutes. What tools might you use?\n\n12 Domain Languages\n\nThe limits of language are the limits of one’s world.\n\nLudwig Wittgenstein\n\nComputer languages inﬂuence how you think about a problem, and how you think about communicating. Every language comes with a list of features—buzzwords such as static versus dynamic typing, early versus late binding, inheritance models (single, multiple, or none)—all of which may suggest or obscure certain solutions. Designing a solution with Lisp in mind will produce different results than a solution based on C-style thinking, and vice versa. Conversely, and we think more importantly, the language of the problem domain may also suggest a programming solution.\n\nWe always try to write code using the vocabulary of the application domain (see The Requirements Pit, page 210, where we suggest using a project glossary). In some cases, we can go to the next level and actually program using the vocabulary, syntax, and semantics—the language— of the domain.\n\nWhen you listen to users of a proposed system, they might be able to tell you exactly how the system should work:\n\nListen for transactions deﬁned by ABC Regulation 12.3 on a set of X.25 lines, translate them to XYZ Company’s format 43B, retransmit them on the satellite uplink, and store for future analysis.\n\nIf your users have a number of such well-bounded statements, you can invent a mini-language tailored to the application domain that ex- presses exactly what they want:\n\nFrom X25LINE1 (Format=ABC123) { Put TELSTAR1 (Format=XYZ43B); Store DB;\n\n}\n\n57\n\n58\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nThis language need not be executable. Initially, it could be simply a way of capturing the user’s requirements—a speciﬁcation. However, you may want to consider taking this a step further and actually imple- menting the language. Your speciﬁcation has become executable code.\n\nAfter you’ve written the application, the users give you a new require- ment: transactions with negative balances shouldn’t be stored, and should be sent back on the X.25 lines in the original format:\n\nFrom X25LINE1 (Format=ABC123) {\n\nif (ABC123.balance < 0) {\n\nPut X25LINE1 (Format=ABC123);\n\n} else {\n\nPut TELSTAR1 (Format=XYZ43B); Store DB;\n\n}\n\n}\n\nThat was easy, wasn’t it? With the proper support in place, you can pro- gram much closer to the application domain. We’re not suggesting that your end users actually program in these languages. Instead, you’re giving yourself a tool that lets you work closer to their domain.\n\nTIP 17\n\nProgram Close to the Problem Domain\n\nWhether it’s a simple language to conﬁgure and control an application program, or a more complex language to specify rules or procedures, we think you should consider ways of moving your project closer to the problem domain. By coding at a higher level of abstraction, you are free to concentrate on solving domain problems, and can ignore petty implementation details.\n\nRemember that there are many users of an application. There’s the end user, who understands the business rules and the required outputs. There are also secondary users: operations staff, conﬁguration and test managers, support and maintenance programmers, and future genera- tions of developers. Each of these users has their own problem domain, and you can generate mini-environments and languages for all of them.\n\nDOMAIN LANGUAGES\n\nDomain-Speciﬁc Errors\n\nIf you are writing in the problem domain, you can also perform domain-speciﬁc validation, reporting problems in terms your users can understand. Take our switching application on on the facing page. Suppose the user misspelled the format name:\n\nFrom X25LINE1 (Format=AB123)\n\nIf this happened in a standard, general-purpose programming lan- guage, you might receive a standard, general-purpose error mes- sage:\n\nSyntax error: undeclared identifier\n\nBut with a mini-language, you would instead be able to issue an error message using the vocabulary of the domain:\n\n\"AB123\" is not a format. Known formats are ABC123,\n\nXYZ43B, PDQB, and 42.\n\nImplementingaMini-Language At its simplest, a mini-language may be in a line-oriented, easily parsed format. In practice, we probably use this form more than any other. It can be parsed simply using switch statements, or using regular expressions in scripting languages such as Perl. The answer to Exercise 5 on page 281 shows a simple implementation in C.\n\nYou can also implement a more complex language, with a more formal syntax. The trick here is to deﬁne the syntax ﬁrst using a notation such as BNF.7 Once you have your grammar speciﬁed, it is normally trivial to convert it into the input syntax for a parser generator. C and C++ pro- grammers have been using yacc (or its freely available implementation, bison [URL 27]) for years. These programs are documented in detail in the book Lex and Yacc [LMB92]. Java programmers can try javaCC, which can be found at [URL 26]. The answer to Exercise 7 on page 282\n\n7. good book on compiler construction or parsing will cover BNF in (exhaustive) detail.\n\nBNF, or Backus-Naur Form, lets you specify context-free grammars recursively. Any\n\n59\n\n60\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nshows a parser written using bison. As it shows, once you know the syntax, it’s really not a lot of work to write simple mini-languages.\n\nThere’s another way of implementing a mini-language: extend an exist- ing one. For example, you could integrate application-level functionality with (say) Python [URL 9] and write something like8\n\nrecord = X25LINE1.get(format=ABC123) if (record.balance < 0):\n\nX25LINE1.put(record, format=ABC123)\n\nelse:\n\nTELSTAR1.put(record, format=XYZ43B) DB.store(record)\n\nData Languagesand ImperativeLanguages The languages you implement can be used in two different ways.\n\nData languages produce some form of data structure used by an ap- plication. These languages are often used to represent conﬁguration information.\n\nFor example, the sendmail program is used throughout the world for routing e-mail over the Internet. It has many excellent features and beneﬁts, which are controlled by a thousand-line conﬁguration ﬁle, written using sendmail’s own conﬁguration language:\n\nMlocal, P=/usr/bin/procmail,\n\nF=lsDFMAw5:/|@qSPfhn9, S=10/30, R=20/40, T=DNS/RFC822/X-Unix, A=procmail -Y -a $h -d $u\n\nObviously, readability is not one of sendmail’s strengths.\n\nFor years, Microsoft has been using a data language that can describe menus, widgets, dialog boxes, and other Windows resources. Figure 2.2 on the next page shows an excerpt from a typical resource ﬁle. This is far easer to read than the sendmail example, but it is used in exactly the same way—it is compiled to generate a data structure.\n\nImperative languages take this a step further. Here the language is actually executed, and so can contain statements, control constructs, and the like (such as the script on page 58).\n\n8.\n\nThanks to Eric Vought for this example.",
      "page_number": 75
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 85-92)",
      "start_page": 85,
      "end_page": 92,
      "detection_method": "topic_boundary",
      "content": "DOMAIN LANGUAGES\n\nFigure 2.2. Windows .rc ﬁle\n\nMAIN_MENU MENU {\n\nPOPUP \"&File\" {\n\nMENUITEM \"&New\", CM_FILENEW MENUITEM \"&Open...\", CM_FILEOPEN MENUITEM \"&Save\", CM_FILESAVE\n\n}\n\n}\n\nMY_DIALOG_BOX DIALOG 6, 15, 292, 287 STYLE DS_MODALFRAME | WS_POPUP | WS_VISIBLE | WS_CAPTION | WS_SYSMENU\n\nCAPTION \"My Dialog Box\" FONT 8, \"MS Sans Serif\" {\n\nDEFPUSHBUTTON \"OK\", ID_OK, 232, 16, 50, 14 PUSHBUTTON \"Help\", ID_HELP, 232, 52, 50, 14 CONTROL \"Edit Text Control\", ID_EDIT1,\n\n\"EDIT\", WS_BORDER | WS_TABSTOP, 16, 16, 80, 56\n\nCHECKBOX \"Checkbox\", ID_CHECKBOX1, 153, 65, 42, 38,\n\nBS_AUTOCHECKBOX | WS_TABSTOP\n\n}\n\nYou can also use your own imperative languages to ease program main- tenance. For example, you may be asked to integrate information from a legacy application into your new GUI development. A common way of achieving this is by screen scraping; your application connects to the mainframe application as if it were a regular human user, issuing keystrokes and “reading” the responses it gets back. You could script the interaction using a mini-language.9\n\nlocate prompt \"SSN:\" type \"%s\" social_security_number type enter\n\nwaitfor keyboardunlock\n\nif text_at(10,14) is \"INVALID SSN\" return bad_ssn if text_at(10,14) is \"DUPLICATE SSN\" return dup_ssn # etc...\n\nWhen the application determines it is time to enter a Social Security number, it invokes the interpreter on this script, which then controls\n\n9. In fact, you can buy tools that support just this kind of scripting. You can also inves- tigate open-source packages such as Expect, which provide similar capabilities [URL 24].\n\n61\n\n62\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nthe transaction. If the interpreter is embedded within the application, the two can even share data directly (for example, via a callback mech- anism).\n\nHere you’re programming in the maintenance programmer’s domain. When the mainframe application changes, and the ﬁelds move around, the programmer can simply update your high-level description, rather than groveling around in the details of C code.\n\nStand-Alone andEmbeddedLanguages A mini-language doesn’t have to be used directly by the application to be useful. Many times we may use a speciﬁcation language to create artifacts (including metadata) that are compiled, read-in, or otherwise used by the program itself (see Metaprogramming, page 144).\n\nFor example, on page 100 we describe a system in which we used Perl to generate a large number of derivations from an original schema speciﬁcation. We invented a common language to express the database schema, and then generated all the forms of it we needed—SQL, C, Web pages, XML, and others. The application didn’t use the speciﬁca- tion directly, but it relied on the output produced from it.\n\nIt is common to embed high-level imperative languages directly into your application, so that they execute when your code runs. This is clearly a powerful capability; you can change your application’s behav- ior by changing the scripts it reads, all without compiling. This can signiﬁcantly simplify maintenance in a dynamic application domain.\n\nEasy DevelopmentorEasyMaintenance? We’ve looked at several different grammars, ranging from simple line- oriented formats to more complex grammars that look like real lan- guages. Since it takes extra effort to implement, why would you choose a more complex grammar?\n\nThe trade-off is extendibility and maintenance. While the code for pars- ing a “real” language may be harder to write, it will be much easier for people to understand, and to extend in the future with new features and functionality. Languages that are too simple may be easy to parse, but can be cryptic—much like the sendmail example on page 60.\n\nDOMAIN LANGUAGES\n\n63\n\nGiven that most applications exceed their expected lifetimes, you’re probably better off biting the bullet and adopting the more complex and readable language up front. The initial effort will be repaid many times in reduced support and maintenance costs.\n\nRelated sections include:\n\nMetaprogramming, page 144\n\nChallenges\n\nCould some of the requirements of your current project be expressed in a domain-speciﬁc language? Would it be possible to write a compiler or translator that could generate most of the code required?\n\nIf you decide to adopt mini-languages as a way of programming closer to the problem domain, you’re accepting that some effort will be required to implement them. Can you see ways in which the framework you develop for one project can be reused in others?\n\nExercises 5. We want to implement a mini-language to control a simple drawing pack- age (perhaps a turtle-graphics system). The language consists of single- letter commands. Some commands are followed by a single number. For example, the following input would draw a rectangle.\n\nP 2 D W 2 N 1 E 2 S 1 U\n\n# select pen 2 # pen down # draw west 2cm # then north 1 # then east 2 # then back south # pen up\n\nImplement the code that parses this language. It should be designed so that it is simple to add new commands.\n\n6. Design a BNF grammar to parse a time speciﬁcation. All of the following Answer on p. 282\n\n6. Design a BNF grammar to parse a time speciﬁcation. All of the following Answer on p. 282\n\nexamples should be accepted.\n\n7.\n\nImplement a parser for the BNF grammar in Exercise 6 using yacc, bison, or a similar parser-generator.\n\n8.\n\nImplement the time parser using Perl. [Hint: Regular expressions make good parsers.]\n\nAnswer on p. 281\n\nAnswer on p. 282\n\nAnswer on p. 283\n\n64\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\n13 Estimating\n\nQuick! How long will it take to send WarandPeace over a 56k modem line? How much disk space will you need for a million names and addresses? How long does a 1,000-byte block take to pass through a router? How many months will it take to deliver your project?\n\nAt one level, these are all meaningless questions—they are all missing information. And yet they can all be answered, as long as you are com- fortable estimating. And, in the process of producing an estimate, you’ll come to understand more about the world your programs inhabit.\n\nBy learning to estimate, and by developing this skill to the point where you have an intuitive feel for the magnitudes of things, you will be able to show an apparent magical ability to determine their feasibility. When someone says “we’ll send the backup over an ISDN line to the central site,” you’ll be able to know intuitively whether this is practical. When you’re coding, you’ll be able to know which subsystems need optimizing and which ones can be left alone.\n\nTIP 18\n\nEstimate to Avoid Surprises\n\nAs a bonus, at the end of this section we’ll reveal the single correct answer to give whenever anyone asks you for an estimate.\n\nHowAccurateIsAccurateEnough? To some extent, all answers are estimates. It’s just that some are more accurate than others. So the ﬁrst question you have to ask yourself when someone asks you for an estimate is the context in which your answer will be taken. Do they need high accuracy, or are they looking for a ballpark ﬁgure?\n\nIf your grandmother asks when you will arrive, she’s probably won- dering whether to make you lunch or dinner. On the other hand, a diver trapped underwater and running out of air is probably inter- ested in an answer down to the second.\n\nESTIMATING\n\nWhat’s the value of ? If you’re wondering how much edging to buy to put around a circular ﬂower bed, then “3” is probably good ” is a good approxima- enough.10 If you’re in school, then maybe “ tion. If you’re in NASA, then maybe 12 decimal places will do.\n\nOne of the interesting things about estimating is that the units you use make a difference in the interpretation of the result. If you say that something will take about 130 working days, then people will be expecting it to come in pretty close. However, if you say “Oh, about six months,” then they know to look for it any time between ﬁve and seven months from now. Both numbers represent the same duration, but “130 days” probably implies a higher degree of accuracy than you feel. We recommend that you scale time estimates as follows:\n\nDuration\n\nQuote estimate in\n\n1–15 days 3–8 weeks 8–30 weeks months 30+ weeks\n\ndays weeks\n\nthink hard before giving an estimate\n\nSo, if after doing all the necessary work, you decide that a project will take 125 working days (25 weeks), you might want to deliver an esti- mate of “about six months.”\n\nThe same concepts apply to estimates of any quantity: choose the units of your answer to reﬂect the accuracy you intend to convey.\n\nWhereDo EstimatesComeFrom? All estimates are based on models of the problem. But before we get too deeply into the techniques of building models, we have to mention a basic estimating trick that always gives good answers: ask someone who’s already done it. Before you get too committed to model building, cast around for someone who’s been in a similar situation in the past.\n\n“3” is also apparently good enough if you are a legislator. In 1897, Indiana State 10. Legislature House Bill No. 246 attempted to decree that henceforth should have the value of “3”. The Bill was tabled indeﬁnitely at its second reading when a mathematics professor pointed out that their powers did not quite extend to passing laws of nature.\n\n65\n\n66\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nSee how their problem got solved. It’s unlikely you’ll ever ﬁnd an exact match, but you’d be surprised how many times you can successfully draw on other’s experiences.\n\nUnderstand What’sBeing Asked The ﬁrst part of any estimation exercise is building an understanding of what’s being asked. As well as the accuracy issues discussed above, you need to have a grasp of the scope of the domain. Often this is implicit in the question, but you need to make it a habit to think about the scope before starting to guess. Often, the scope you choose will form part of the answer you give: “Assuming there are no trafﬁc accidents and there’s gas in the car, I should be there in 20 minutes.”\n\nBuild a ModeloftheSystem This is the fun part of estimating. From your understanding of the ques- tion being asked, build a rough and ready bare-bones mental model. If you’re estimating response times, your model may involve a server and some kind of arriving trafﬁc. For a project, the model may be the steps that your organization uses during development, along with a very rough picture of how the system might be implemented.\n\nModel building can be both creative and useful in the long term. Often, the process of building the model leads to discoveries of underlying patterns and processes that weren’t apparent on the surface. You may even want to reexamine the original question: “You asked for an esti- mate to do X. However, it looks like Y, a variant of X, could be done in about half the time, and you lose only one feature.”\n\nBuilding the model introduces inaccuracies into the estimating pro- cess. This is inevitable, and also beneﬁcial. You are trading off model simplicity for accuracy. Doubling the effort on the model may give you only a slight increase in accuracy. Your experience will tell you when to stop reﬁning.\n\nBreak theModelinto Components Once you have a model, you can decompose it into components. You’ll need to discover the mathematical rules that describe how these com- ponents interact. Sometimes a component contributes a single value\n\nESTIMATING\n\nthat is added into the result. Some components may supply multiply- ing factors, while others may be more complicated (such as those that simulate the arrival of trafﬁc at a node).\n\nYou’ll ﬁnd that each component will typically have parameters that af- fect how it contributes to the overall model. At this stage, simply identify each parameter.\n\nGiveEachParametera Value Once you have the parameters broken out, you can go through and assign each one a value. You expect to introduce some errors in this step. The trick is to work out which parameters have the most impact on the result, and concentrate on getting them about right. Typically, parameters whose values are added into a result are less signiﬁcant than those that are multiplied or divided. Doubling a line speed may double the amount of data received in an hour, while adding a 5 ms transit delay will have no noticeable effect.\n\nYou should have a justiﬁable way of calculating these critical parame- ters. For the queuing example, you might want to measure the actual transaction arrival rate of the existing system, or ﬁnd a similar sys- tem to measure. Similarly, you could measure the current time taken to serve a request, or come up with an estimate using the techniques described in this section. In fact, you’ll often ﬁnd yourself basing an estimate on other subestimates. This is where your largest errors will creep in.\n\nCalculatetheAnswers Only in the simplest of cases will an estimate have a single answer. You might be happy to say “I can walk ﬁve cross-town blocks in 15 minutes.” However, as the systems get more complex, you’ll want to hedge your answers. Run multiple calculations, varying the values of the critical parameters, until you work out which ones really drive the model. A spreadsheet can be a big help. Then couch your answer in terms of these parameters. ”The response time is roughly three quarters of a second if the system has a SCSI bus and 64MB memory, and one second with 48MB memory.” (Notice how “three quarters of a second” conveys a different feeling of accuracy than 750 ms.)\n\n67\n\n68\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nDuring the calculation phase, you may start getting answers that seem strange. Don’t be too quick to dismiss them. If your arithmetic is cor- rect, your understanding of the problem or your model is probably wrong. This is valuable information.\n\nKeepTrack of YourEstimatingProwess We think it’s a great idea to record your estimates so you can see how close you were. If an overall estimate involved calculating subestimates, keep track of these as well. Often you’ll ﬁnd your estimates are pretty good—in fact, after a while, you’ll come to expect this.\n\nWhen an estimate turns out wrong, don’t just shrug and walk away. Find out why it differed from your guess. Maybe you chose some param- eters that didn’t match the reality of the problem. Maybe your model was wrong. Whatever the reason, take some time to uncover what hap- pened. If you do, your next estimate will be better.\n\nEstimating ProjectSchedules The normal rules of estimating can break down in the face of the com- plexities and vagaries of a sizable application development. We ﬁnd that often the only way to determine the timetable for a project is by gain- ing experience on that same project. This needn’t be a paradox if you practice incremental development, repeating the following steps.\n\nCheck requirements\n\nAnalyze risk\n\nDesign, implement, integrate\n\nValidate with the users\n\nInitially, you may have only a vague idea of how many iterations will be required, or how long they may be. Some methods require you to nail this down as part of the initial plan, but for all but the most trivial of projects this is a mistake. Unless you are doing an application similar to a previous one, with the same team and the same technology, you’d just be guessing.\n\nSo you complete the coding and testing of the initial functionality and mark this as the end of the ﬁrst increment. Based on that experience, you can reﬁne your initial guess on the number of iterations and what",
      "page_number": 85
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 93-100)",
      "start_page": 93,
      "end_page": 100,
      "detection_method": "topic_boundary",
      "content": "ESTIMATING\n\ncan be included in each. The reﬁnement gets better and better each time, and conﬁdence in the schedule grows along with it.\n\nTIP 19\n\nIterate the Schedule with the Code\n\nThis may not be popular with management, who typically want a sin- gle, hard-and-fast number before the project even starts. You’ll have to help them understand that the team, their productivity, and the envi- ronment will determine the schedule. By formalizing this, and reﬁning the schedule as part of each iteration, you’ll be giving them the most accurate scheduling estimates you can.\n\nWhattoSay WhenAsked for anEstimate You say “I’ll get back to you.”\n\nYou almost always get better results if you slow the process down and spend some time going through the steps we describe in this section. Estimates given at the coffee machine will (like the coffee) come back to haunt you.\n\nRelated sections include: Algorithm Speed, page 177\n\nChallenges\n\nStart keeping a log of your estimates. For each, track how accurate you turned out to be. If your error was greater than 50%, try to ﬁnd out where your estimate went wrong.\n\nExercises 9.\n\nYou are asked “Which has a higher bandwidth: a 1Mbps communications line or a person walking between two computers with a full 4GB tape in their pocket?” What constraints will you put on your answer to ensure that the scope of your response is correct? (For example, you might say that the time taken to access the tape is ignored.)\n\n10. So, which has the higher bandwidth?\n\n69\n\nAnswer on p. 283\n\nAnswer on p. 284\n\nThis page intentionally left blank\n\nChapter 3\n\nThe Basic Tools\n\nEvery craftsman starts his or her journey with a basic set of good- quality tools. A woodworker might need rules, gauges, a couple of saws, some good planes, ﬁne chisels, drills and braces, mallets, and clamps. These tools will be lovingly chosen, will be built to last, will perform speciﬁc jobs with little overlap with other tools, and, perhaps most im- portantly, will feel right in the budding woodworker’s hands.\n\nThen begins a process of learning and adaptation. Each tool will have its own personality and quirks, and will need its own special handling. Each must be sharpened in a unique way, or held just so. Over time, each will wear according to use, until the grip looks like a mold of the woodworker’s hands and the cutting surface aligns perfectly with the angle at which the tool is held. At this point, the tools become conduits from the craftsman’s brain to the ﬁnished product—they have become extensions of his or her hands. Over time, the woodworker will add new tools, such as biscuit cutters, laser-guided miter saws, dovetail jigs— all wonderful pieces of technology. But you can bet that he or she will be happiest with one of those original tools in hand, feeling the plane sing as it slides through the wood.\n\nTools amplify your talent. The better your tools, and the better you know how to use them, the more productive you can be. Start with a basic set of generally applicable tools. As you gain experience, and as you come across special requirements, you’ll add to this basic set. Like the craftsman, expect to add to your toolbox regularly. Always be on the lookout for better ways of doing things. If you come across a situation where you feel your current tools can’t cut it, make a note to look for\n\n71\n\n72\n\nCHAPTER 3 THE BASIC TOOLS\n\nsomething different or more powerful that would have helped. Let need drive your acquisitions.\n\nMany new programmers make the mistake of adopting a single power tool, such as a particular integrated development environment (IDE), and never leave its cozy interface. This really is a mistake. We need to be comfortable beyond the limits imposed by an IDE. The only way to do this is to keep the basic tool set sharp and ready to use.\n\nIn this chapter we’ll talk about investing in your own basic toolbox. As with any good discussion on tools, we’ll start (in The Power of Plain Text) by looking at your raw materials, the stuff you’ll be shaping. From there we’ll move to the workbench, or in our case the computer. How can you use your computer to get the most out of the tools you use? We’ll discuss this in Shell Games. Now that we have material and a bench to work on, we’ll turn to the tool you’ll probably use more than any other, your editor. In Power Editing, we’ll suggest ways of making you more efﬁcient.\n\nTo ensure that we never lose any of our precious work, we should al- ways use a Source Code Control system—even for things such as our personal address book! And, since Mr. Murphy was really an optimist after all, you can’t be a great programmer until you become highly skilled at Debugging.\n\nYou’ll need some glue to bind much of the magic together. We discuss some possibilities, such as awk, Perl, and Python, in Text Manipulation.\n\nJust as woodworkers sometimes build jigs to guide the construction of complex pieces, programmers can write code that itself writes code. We discuss this in Code Generators.\n\nSpend time learning to use these tools, and at some point you’ll be sur- prised to discover your ﬁngers moving over the keyboard, manipulating text without conscious thought. The tools will have become extensions of your hands.\n\n14\n\nTHE POWER OF PLAIN TEXT\n\nThe Power of Plain Text\n\nAs Pragmatic Programmers, our base material isn’t wood or iron, it’s knowledge. We gather requirements as knowledge, and then express that knowledge in our designs, implementations, tests, and documents. And we believe that the best format for storing knowledge persistently is plain text. With plain text, we give ourselves the ability to manipulate knowledge, both manually and programmatically, using virtually every tool at our disposal.\n\nWhatIsPlainText? Plain text is made up of printable characters in a form that can be read and understood directly by people. For example, although the following snippet is made up of printable characters, it is meaningless.\n\nField19=467abe\n\nThe reader has no idea what the signiﬁcance of 467abe may be. A better choice would be to make it understandable to humans.\n\nDrawingType=UMLActivityDrawing\n\nPlain text doesn’t mean that the text is unstructured; XML, SGML, and HTML are great examples of plain text that has a well-deﬁned structure. You can do everything with plain text that you could do with some binary format, including versioning.\n\nPlain text tends to be at a higher level than a straight binary encoding, which is usually derived directly from the implementation. Suppose you wanted to store a property called uses_menus that can be either TRUE or FALSE. Using text, you might write this as\n\nmyprop.uses_menus=FALSE\n\nContrast this with 0010010101110101.\n\nThe problem with most binary formats is that the context necessary to understand the data is separate from the data itself. You are artiﬁcially divorcing the data from its meaning. The data may as well be encrypted; it is absolutely meaningless without the application logic to parse it. With plain text, however, you can achieve a self-describing data stream that is independent of the application that created it.\n\n73\n\n74\n\nCHAPTER 3 THE BASIC TOOLS\n\nTIP 20\n\nKeep Knowledge in Plain Text\n\nDrawbacks There are two major drawbacks to using plain text: (1) It may take more space to store than a compressed binary format, and (2) it may be computationally more expensive to interpret and process a plain text ﬁle.\n\nDepending on your application, either or both of these situations may be unacceptable—for example, when storing satellite telemetry data, or as the internal format of a relational database.\n\nBut even in these situations, it may be acceptable to store metadata about the raw data in plain text (see Metaprogramming, page 144).\n\nSome developers may worry that by putting metadata in plain text, they’re exposing it to the system’s users. This fear is misplaced. Binary data may be more obscure than plain text, but it is no more secure. If you worry about users seeing passwords, encrypt them. If you don’t want them changing conﬁguration parameters, include a secure hash1 of all the parameter values in the ﬁle as a checksum.\n\nThePowerof Text Since larger and slower aren’t the most frequently requested features from users, why bother with plain text? What are the beneﬁts?\n\nInsurance against obsolescence\n\nLeverage\n\nEasier testing\n\nInsurance AgainstObsolescence Human-readable forms of data, and self-describing data, will outlive all other forms of data and the applications that created them. Period.\n\n1. MD5 is often used for this purpose. For an excellent introduction to the wonderful world of cryptography, see [Sch95].\n\nTHE POWER OF PLAIN TEXT\n\nAs long as the data survives, you will have a chance to be able to use it—potentially long after the original application that wrote it is defunct.\n\nYou can parse such a ﬁle with only partial knowledge of its format; with most binary ﬁles, you must know all the details of the entire format in order to parse it successfully.\n\nConsider a data ﬁle from some legacy system2 that you are given. You know little about the original application; all that’s important to you is that it maintained a list of clients’ Social Security numbers, which you need to ﬁnd and extract. Among the data, you see\n\n<FIELD10>123-45-6789</FIELD10> ... <FIELD10>567-89-0123</FIELD10> ... <FIELD10>901-23-4567</FIELD10>\n\nRecognizing the format of a Social Security number, you can quickly write a small program to extract that data—even if you have no infor- mation on anything else in the ﬁle.\n\nBut imagine if the ﬁle had been formatted this way instead:\n\nAC27123456789B11P ... XY43567890123QTYL ... 6T2190123456788AM\n\nYou may not have recognized the signiﬁcance of the numbers quite as easily. This is the difference between human readable and human understandable.\n\nWhile we’re at it, FIELD10 doesn’t help much either. Something like\n\n<SSNO>123-45-6789</SSNO>\n\nmakes the exercise a no-brainer—and ensures that the data will outlive any project that created it.\n\nLeverage Virtually every tool in the computing universe, from source code man- agement systems to compiler environments to editors and stand-alone ﬁlters, can operate on plain text.\n\n2.\n\nAll software becomes legacy as soon as it’s written.\n\n75\n\n76\n\nCHAPTER 3 THE BASIC TOOLS\n\nThe Unix Philosophy\n\nUnix is famous for being designed around the philosophy of small, sharp tools, each intended to do one thing well. This philosophy is enabled by using a common underlying format—the line-oriented, plain text ﬁle. Databases used for system administration (users and passwords, networking conﬁguration, and so on) are all kept as plain text ﬁles. (Some systems, such as Solaris, also maintain a binary form of certain databases as a performance optimization. The plain text version is kept as an interface to the binary version.)\n\nWhen a system crashes, you may be faced with only a minimal envi- ronment to restore it (you may not be able to access graphics drivers, for instance). Situations such as this can really make you appreciate the simplicity of plain text.\n\nFor instance, suppose you have a production deployment of a large application with a complex site-speciﬁc conﬁguration ﬁle (sendmail comes to mind). If this ﬁle is in plain text, you could place it under a source code control system (see Source Code Control, page 86), so that you automatically keep a history of all changes. File comparison tools such as diff and fc allow you to see at a glance what changes have been made, while sum allows you to generate a checksum to monitor the ﬁle for accidental (or malicious) modiﬁcation.\n\nEasierTesting If you use plain text to create synthetic data to drive system tests, then it is a simple matter to add, update, or modify the test data without having to create any special tools to do so. Similarly, plain text output from regression tests can be trivially analyzed (with diff, for instance) or subjected to more thorough scrutiny with Perl, Python, or some other scripting tool.\n\nLowestCommon Denominator Even in the future of XML-based intelligent agents that travel the wild and dangerous Internet autonomously, negotiating data interchange among themselves, the ubiquitous text ﬁle will still be there. In fact, in",
      "page_number": 93
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 101-108)",
      "start_page": 101,
      "end_page": 108,
      "detection_method": "topic_boundary",
      "content": "SHELL GAMES\n\nheterogeneous environments the advantages of plain text can outweigh all of the drawbacks. You need to ensure that all parties can communi- cate using a common standard. Plain text is that standard.\n\nRelated sections include:\n\nSource Code Control, page 86 Code Generators, page 102 Metaprogramming, page 144 Blackboards, page 165 Ubiquitous Automation, page 230 It’s All Writing, page 248\n\nChallenges\n\nDesign a small address book database (name, phone number, and so on) using a straightforward binary representation in your language of choice. Do this before reading the rest of this challenge.\n\n1. Translate that format into a plain text format using XML.\n\n2. For each version, add a new, variable-length ﬁeld called directions in\n\nwhich you might enter directions to each person’s house.\n\nWhat issues come up regarding versioning and extensibility? Which form was easier to modify? What about converting existing data?\n\n15 Shell Games\n\nEvery woodworker needs a good, solid, reliable workbench, somewhere to hold work pieces at a convenient height while he or she works them. The workbench becomes the center of the wood shop, the craftsman returning to it time and time again as a piece takes shape.\n\nFor a programmer manipulating ﬁles of text, that workbench is the command shell. From the shell prompt, you can invoke your full reper- toire of tools, using pipes to combine them in ways never dreamt of by their original developers. From the shell, you can launch applications, debuggers, browsers, editors, and utilities. You can search for ﬁles,\n\n77\n\n78\n\nCHAPTER 3 THE BASIC TOOLS\n\nquery the status of the system, and ﬁlter output. And by programming the shell, you can build complex macro commands for activities you perform often.\n\nFor programmers raised on GUI interfaces and integrated development environments (IDEs), this might seem an extreme position. After all, can’t you do everything equally well by pointing and clicking?\n\nThe simple answer is “no.” GUI interfaces are wonderful, and they can be faster and more convenient for some simple operations. Moving ﬁles, reading MIME-encoded e-mail, and typing letters are all things that you might want to do in a graphical environment. But if you do all your work using GUIs, you are missing out on the full capabilities of your environment. You won’t be able to automate common tasks, or use the full power of the tools available to you. And you won’t be able to combine your tools to create customized macro tools. A beneﬁt of GUIs is WYSIWYG—what you see is what you get. The disadvantage is WYSIAYG—what you see is all you get.\n\nGUI environments are normally limited to the capabilities that their designers intended. If you need to go beyond the model the designer provided, you are usually out of luck—and more often than not, you do need to go beyond the model. Pragmatic Programmers don’t just cut code, or develop object models, or write documentation, or automate the build process—we do all of these things. The scope of any one tool is usually limited to the tasks that the tool is expected to perform. For instance, suppose you need to integrate a code preprocessor (to implement design-by-contract, or multi-processing pragmas, or some such) into your IDE. Unless the designer of the IDE explicitly provided hooks for this capability, you can’t do it.\n\nYou may already be comfortable working from the command prompt, in which case you can safely skip this section. Otherwise, you may need to be convinced that the shell is your friend.\n\nAs a Pragmatic Programmer, you will constantly want to perform ad hoc operations—things that the GUI may not support. The command line is better suited when you want to quickly combine a couple of commands to perform a query or some other task. Here are a few examples.\n\nSHELL GAMES\n\nFindall.cﬁlesmodiﬁedmorerecently thanyourMakeﬁle.\n\nShell ... find . -name ’*.c’ -newer Makefile -print\n\nGUI..... Open the Explorer, navigate to the correct directory, click on the Makeﬁle, and note the modiﬁcation time. Then bring up Tools/Find, and enter *.c for the ﬁle speciﬁcation. Select the date tab, and enter the date you noted for the Makeﬁle in the ﬁrst date ﬁeld. Then hit OK.\n\nConstructazip/tararchiveofmysource.\n\nShell ... zip archive.zip *.h *.c\n\n– or –\n\ntar cvf archive.tar *.h *.c\n\nGUI..... Bring up a ZIP utility (such as the shareware WinZip [URL 41]), select “Create New Archive,” enter its name, select the source directory in the add dialog, set the ﬁlter to “*.c”, click “Add,” set the ﬁlter to “*.h”, click “Add,” then close the archive.\n\nWhichJavaﬁleshavenotbeenchangedinthelastweek?\n\nShell ... find . -name ’*.java’ -mtime +7 -print\n\nGUI..... Click and navigate to “Find ﬁles,” click the “Named” ﬁeld and type in “*.java”, select the “Date Modiﬁed” tab. Then select “Between.” Click on the starting date and type in the starting date of the beginning of the project. Click on the ending date and type in the date of a week ago today (be sure to have a calendar handy). Click on “Find Now.”\n\nOfthoseﬁles,whichusethe awt libraries?\n\nShell ... find . -name ’*.java’ -mtime +7 -print |\n\nxargs grep ’java.awt’\n\nGUI..... Load each ﬁle in the list from the previous example into an editor and search for the string “java.awt”. Write down the name of each ﬁle containing a match.\n\nClearly the list could go on. The shell commands may be obscure or terse, but they are powerful and concise. And, because shell commands can be combined into script ﬁles (or command ﬁles under Windows\n\n79\n\n80\n\nCHAPTER 3 THE BASIC TOOLS\n\nsystems), you can build sequences of commands to automate things you do often.\n\nTIP 21\n\nUse the Power of Command Shells\n\nGain familiarity with the shell, and you’ll ﬁnd your productivity soaring. Need to create a list of all the unique package names explicitly imported by your Java code? The following stores it in a ﬁle called “list.”\n\ngrep ’^import ’ *.java |\n\nsed -e’s/.*import *//’ -e’s/;.*$//’ | sort -u >list\n\nIf you haven’t spent much time exploring the capabilities of the com- mand shell on the systems you use, this might appear daunting. How- ever, invest some energy in becoming familiar with your shell and things will soon start falling into place. Play around with your command shell, and you’ll be surprised at how much more productive it makes you.\n\nShell UtilitiesandWindows Systems Although the command shells provided with Windows systems are im- proving gradually, Windows command-line utilities are still inferior to their Unix counterparts. However, all is not lost.\n\nCygnus Solutions has a package called Cygwin [URL 31]. As well as providing a Unix compatibility layer for Windows, Cygwin comes with a collection of more than 120 Unix utilities, including such favorites as ls, grep, and find. The utilities and libraries may be downloaded and used for free, but be sure to read their license.3 The Cygwin distribution comes with the Bash shell.\n\nThe GNU General Public License [URL 57] is a kind of legal virus that Open Source 3. developers use to protect their (and your) rights. You should spend some time reading it. In essence, it says that you can use and modify GPL’d software, but if you distribute any modiﬁcations they must be licensed according to the GPL (and marked as such), and you must make source available. That’s the virus part—whenever you derive a work from a GPL’d work, your derived work must also be GPL’d. However, it does not limit you in any way when simply using the tools—the ownership and licensing of software developed using the tools are up to you.\n\nSHELL GAMES\n\nUsing Unix Tools Under Windows\n\nWe love the availability of high-quality Unix tools under Windows, and use them daily. However, be aware that there are integration issues. Unlike their MS-DOS counterparts, these utilities are sensitive to the case of ﬁlenames, so ls a*.bat won’t ﬁnd AUTOEXEC.BAT. You may also come across problems with ﬁlenames containing spaces, and with differences in path separators. Finally, there are interesting problems when running MS-DOS programs that expect MS-DOS–style arguments under the Unix shells. For example, the Java utilities from JavaSoft use a colon as their CLASSPATH separator under Unix, but use a semicolon under MS-DOS. As a result, a Bash or ksh script that runs on a Unix box will run identically under Windows, but the command line it passes to Java will be interpreted incorrectly.\n\nAlternatively, David Korn (of Korn shell fame) has put together a pack- age called UWIN. This has the same aims as the Cygwin distribution—it is a Unix development environment under Windows. UWIN comes with a version of the Korn shell. Commercial versions are available from Global Technologies, Ltd. [URL 30]. In addition, AT&T allows free down- loading of the package for evaluation and academic use. Again, read their license before using.\n\nFinally, Tom Christiansen is (at the time of writing) putting together Perl Power Tools, an attempt to implement all the familiar Unix utilities portably, in Perl [URL 32].\n\nRelated sections include:\n\nUbiquitous Automation, page 230\n\nChallenges\n\nAre there things that you’re currently doing manually in a GUI? Do you ever pass instructions to colleagues that involve a number of individual “click this button,” “select this item” steps? Could these be automated?\n\nWhenever you move to a new environment, make a point of ﬁnding out what shells are available. See if you can bring your current shell with you.\n\nInvestigate alternatives to your current shell. If you come across a problem your shell can’t address, see if an alternative shell would cope better.\n\n81\n\n16\n\n82\n\nCHAPTER 3 THE BASIC TOOLS\n\nPower Editing\n\nWe’ve talked before about tools being an extension of your hand. Well, this applies to editors more than to any other software tool. You need to be able to manipulate text as effortlessly as possible, because text is the basic raw material of programming. Let’s look at some common features and functions that help you get the most from your editing environment.\n\nOne Editor We think it is better to know one editor very well, and use it for all edit- ing tasks: code, documentation, memos, system administration, and so on. Without a single editor, you face a potential modern day Babel of confusion. You may have to use the built-in editor in each language’s IDE for coding, and an all-in-one ofﬁce product for documentation, and maybe a different built-in editor for sending e-mail. Even the keystrokes you use to edit command lines in the shell may be different.4 It is difﬁ- cult to be proﬁcient in any of these environments if you have a different set of editing conventions and commands in each.\n\nYou need to be proﬁcient. Simply typing linearly and using a mouse to cut and paste is not enough. You just can’t be as effective that way or as you can with a powerful editor under your ﬁngers. Typing BACKSPACE ten times to move the cursor left to the beginning of a line isn’t as efﬁcient as typing a single key such as ^A, Home, or 0.\n\nTIP 22\n\nUse a Single Editor Well\n\nChoose an editor, know it thoroughly, and use it for all editing tasks. If you use a single editor (or set of keybindings) across all text editing activities, you don’t have to stop and think to accomplish text manip- ulation: the necessary keystrokes will be a reﬂex. The editor will be\n\n4. your editor. Bash, for instance, supports both vi and emacs keybindings.\n\nIdeally, the shell you use should have keybindings that match the ones used by\n\nPOWER EDITING\n\nan extension of your hand; the keys will sing as they slice their way through text and thought. That’s our goal.\n\nMake sure that the editor you choose is available on all platforms you use. Emacs, vi, CRiSP, Brief, and others are available across multiple platforms, often in both GUI and non-GUI (text screen) versions.\n\nEditor Features Beyond whatever features you ﬁnd particularly useful and comfortable, here are some basic abilities that we think every decent editor should have. If your editor falls short in any of these areas, then this may be the time to consider moving on to a more advanced one.\n\nConﬁgurable. All aspects of the editor should be conﬁgurable to your preferences, including fonts, colors, window sizes, and key- stroke bindings (which keys perform what commands). Using only keystrokes for common editing operations is more efﬁcient than mouse or menu-driven commands, because your hands never leave the keyboard.\n\nExtensible. An editor shouldn’t be obsolete just because a new programming language comes out. It should be able to integrate with whatever compiler environment you are using. You should be able to “teach” it the nuances of any new language or text format (XML, HTML version 9, and so on).\n\nProgrammable. You should be able to program the editor to per- form complex, multistep tasks. This can be done with macros or with a built-in scripting programming language (Emacs uses a vari- ant of Lisp, for instance).\n\nIn addition, many editors support features that are speciﬁc to a partic- ular programming language, such as:\n\nSyntax highlighting\n\nAuto-completion\n\nAuto-indentation\n\nInitial code or document boilerplate\n\nTie-in to help systems\n\nIDE-like features (compile, debug, and so on)\n\n83\n\n84\n\nCHAPTER 3 THE BASIC TOOLS\n\nFigure 3.1. Sorting lines in an editor\n\nimport java.util.Vector; import java.util.Stack; import java.net.URL; import java.awt.*;\n\nemacs: M-xsort-lines\n\nimport java.awt.*; import java.net.URL; import java.util.Stack; import java.util.Vector;\n\nvi: :.,+3!sort\n\nA feature such as syntax highlighting may sound like a frivolous extra, but in reality it can be very useful and enhance your productivity. Once you get used to seeing keywords appear in a different color or font, a mistyped keyword that doesn’t appear that way jumps out at you long before you ﬁre up the compiler.\n\nHaving the ability to compile and navigate directly to errors within the editor environment is very handy on big projects. Emacs in particular is adept at this style of interaction.\n\nProductivity A surprising number of people we’ve met use the Windows notepad utility to edit their source code. This is like using a teaspoon as a shovel—simply typing and using basic mouse-based cut and paste is not enough.\n\nWhat sort of things will you need to do that can’t be done in this way?\n\nWell, there’s cursor movement, to start with. Single keystrokes that move you in units of words, lines, blocks, or functions are far more efﬁcient than repeatedly typing a keystroke that moves you character by character or line by line.\n\nOr suppose you are writing Java code. You like to keep your import statements in alphabetical order, and someone else has checked in a few ﬁles that don’t adhere to this standard (this may sound extreme, but on a large project it can save you a lot of time scanning through a long list of import statements). You’d like to go quickly through a few ﬁles and sort a small section of them. In editors such as vi and Emacs you can do this easily (see Figure 3.1). Try that in notepad.\n\nSome editors can help streamline common operations. For instance, when you create a new ﬁle in a particular language, the editor can supply a template for you. It might include:",
      "page_number": 101
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 109-116)",
      "start_page": 109,
      "end_page": 116,
      "detection_method": "topic_boundary",
      "content": "POWER EDITING\n\nName of the class or module ﬁlled in (derived from the ﬁlename)\n\nYour name and/or copyright statements\n\nSkeletons for constructs in that language (constructor and destruc- tor declarations, for example)\n\nAnother useful feature is auto-indenting. Rather than having to indent manually (by using space or tab), the editor automatically indents for you at the appropriate time (after typing an open brace, for example). The nice part about this feature is that you can use the editor to provide a consistent indentation style for your project.5\n\nWheretoGofromHere This sort of advice is particularly hard to write because virtually every reader is at a different level of comfort and expertise with the editor(s) they are currently using. So, to summarize, and to provide some guid- ance on where to go next, ﬁnd yourself in the left-hand column of the chart, and look at the right-hand column to see what we think you should do.\n\nIfthissoundslikeyou\n\nThen think about\n\nI use only basic features of manydifferenteditors.\n\nPick a powerful editor and learn it well.\n\nI have a favorite editor, but I don’tuseallofitsfeatures.\n\nLearn them. Cut down the number of keystrokes you need to type.\n\nI have a favorite editor and useitwherepossible.\n\nTry to expand and use it for more tasks than you do already.\n\nIthinkyouarenuts.Notepad isthebesteditorevermade.\n\nAs long as you are happy and produc- tive, go for it! But if you ﬁnd yourself subject to “editor envy,” you may need to reevaluate your position.\n\nThe Linux kernel is developed this way. Here you have geographically dispersed 5. developers, many working on the same pieces of code. There is a published list of settings (in this case, for Emacs) that describes the required indentation style.\n\n85\n\n86\n\nCHAPTER 3 THE BASIC TOOLS\n\nWhat Editors AreAvailable? Having recommended that you master a decent editor, which one do we recommend? Well, we’re going to duck that question; your choice of editor is a personal one (some would even say a religious one!). However, in Appendix A, page 266, we list a number of popular editors and where to get them.\n\nChallenges\n\nSome editors use full-blown languages for customization and scripting. Emacs, for example, uses Lisp. As one of the new languages you are going to learn this year, learn the language your editor uses. For anything you ﬁnd yourself doing repeatedly, develop a set of macros (or equivalent) to handle it.\n\nDo you know everything your editor is capable of doing? Try to stump your colleagues who use the same editor. Try to accomplish any given editing task in as few keystrokes as possible.\n\n17 Source Code Control\n\nProgress, far from consisting in change, depends on retentiveness. Those who cannot remember the past are condemned to repeat it.\n\nGeorge Santayana, LifeofReason\n\nOne of the important things we look for in a user interface is the UNDO key—a single button that forgives us our mistakes. It’s even better if the environment supports multiple levels of undo and redo, so you can go back and recover from something that happened a couple of minutes ago. But what if the mistake happened last week, and you’ve turned your computer on and off ten times since then? Well, that’s one of the many beneﬁts of using a source code control system: it’s a giant UNDO key—a project-wide time machine that can return you to those halcyon days of last week, when the code actually compiled and ran.\n\nSource code control systems, or the more widely scoped conﬁguration management systems, keep track of every change you make in your source code and documentation. The better ones can keep track of\n\nSOURCE CODE CONTROL\n\ncompiler and OS versions as well. With a properly conﬁgured source code control system, you can always go back to a previous version of your software.\n\nBut a source code control system (SCCS6) does far more than undo mistakes. A good SCCS will let you track changes, answering questions such as: Who made changes in this line of code? What’s the difference between the current version and last week’s? How many lines of code did we change in this release? Which ﬁles get changed most often? This kind of information is invaluable for bug-tracking, audit, performance, and quality purposes.\n\nAn SCCS will also let you identify releases of your software. Once iden- tiﬁed, you will always be able to go back and regenerate the release, independent of changes that may have occurred later.\n\nWe often use an SCCS to manage branches in the development tree. For example, once you have released some software, you’ll normally want to continue developing for the next release. At the same time, you’ll need to deal with bugs in the current release, shipping ﬁxed versions to clients. You’ll want these bug ﬁxes rolled into the next release (if appropriate), but you don’t want to ship code under development to clients. With an SCCS you can generate branches in the development tree each time you generate a release. You apply bug ﬁxes to code in the branch, and continue developing on the main trunk. Since the bug ﬁxes may be relevant to the main trunk as well, some systems allow you to merge selected changes from the branch back into the main trunk automatically.\n\nSource code control systems may keep the ﬁles they maintain in a cen- tral repository—a great candidate for archiving.\n\nFinally, some products may allow two or more users to be working concurrently on the same set of ﬁles, even making concurrent changes in the same ﬁle. The system then manages the merging of these changes when the ﬁles are sent back to the repository. Although seemingly risky, such systems work well in practice on projects of all sizes.\n\n6. We use the uppercase SCCS to refer to generic source code control systems. There is also a speciﬁc system called “sccs,” originally released with AT&T System V Unix.\n\n87\n\n88\n\nCHAPTER 3 THE BASIC TOOLS\n\nTIP 23\n\nAlways Use Source Code Control\n\nAlways. Even if you are a single-person team on a one-week project. Even if it’s a “throw-away” prototype. Even if the stuff you’re work- ing on isn’t source code. Make sure that everything is under source code control—documentation, phone number lists, memos to vendors, makeﬁles, build and release procedures, that little shell script that burns the CD master—everything. We routinely use source code con- trol on just about everything we type (including the text of this book). Even if we’re not working on a project, our day-to-day work is secured in a repository.\n\nSource CodeControland Builds There is a tremendous hidden beneﬁt in having an entire project under the umbrella of a source code control system: you can have product builds that are automatic and repeatable.\n\nThe project build mechanism can pull the latest source out of the repos- itory automatically. It can run in the middle of the night after everyone’s (hopefully) gone home. You can run automatic regression tests to en- sure that the day’s coding didn’t break anything. The automation of the build ensures consistency—there are no manual procedures, and you won’t need developers remembering to copy code into some special build area.\n\nThe build is repeatable because you can always rebuild the source as it existed on a given date.\n\nBut My TeamIsn’tUsingSource Code Control Shame on them! Sounds like an opportunity to do some evangelizing! However, while you wait for them to see the light, perhaps you should implement your own private source control. Use one of the freely avail- able tools we list in Appendix A, and make a point of keeping your personal work safely tucked into a repository (as well as doing what- ever your project requires). Although this may seem to be duplication of effort, we can pretty much guarantee it will save you grief (and save your project money) the ﬁrst time you need to answer questions such\n\nSOURCE CODE CONTROL\n\nas “What did you do to the xyz module?” and “What broke the build?” This approach may also help convince your management that source code control really works.\n\nDon’t forget that an SCCS is equally applicable to the things you do outside of work.\n\nSource Code Control Products Appendix A, page 271, gives URLs for representative source code control systems, some commercial and others freely available. And many more products are available—look for pointers to the conﬁguration manage- ment FAQ. For an introduction to the freely-available CVS version con- trol system, see our book Pragmatic Version Control [TH03].\n\nRelated sections include: Orthogonality, page 34 The Power of Plain Text, page 73 It’s All Writing, page 248\n\nChallenges\n\nEven if you are not able to use an SCCS at work, install RCS or CVS on a personal system. Use it to manage your pet projects, documents you write, and (possibly) conﬁguration changes applied to the computer system itself.\n\nTake a look at some of the Open Source projects for which publicly ac- cessible archives are available on the Web (such as Mozilla [URL 51], KDE [URL 54], and the Gimp [URL 55]). How do you get updates of the source? How do you make changes—does the project regulate access or arbitrate the inclusion of changes?\n\n89\n\n90\n\nCHAPTER 3 THE BASIC TOOLS\n\n18 Debugging\n\nIt is a painful thing To look at your own trouble and know That you yourself and no one else has made it\n\nSophocles, Ajax\n\nThe word bug has been used to describe an “object of terror” ever since the fourteenth century. Rear Admiral Dr. Grace Hopper, the inventor of COBOL, is credited with observing the ﬁrst computer bug—literally, a moth caught in a relay in an early computer system. When asked to explain why the machine wasn’t behaving as intended, a technician reported that there was “a bug in the system,” and dutifully taped it— wings and all—into the log book.\n\nRegrettably, we still have “bugs” in the system, albeit not the ﬂying kind. But the fourteenth century meaning—a bogeyman—is perhaps even more applicable now than it was then. Software defects mani- fest themselves in a variety of ways, from misunderstood requirements to coding errors. Unfortunately, modern computer systems are still limited to doing what you tell them to do, not necessarily what you want them to do.\n\nNo one writes perfect software, so it’s a given that debugging will take up a major portion of your day. Let’s look at some of the issues involved in debugging and some general strategies for ﬁnding elusive bugs.\n\nPsychology of Debugging Debugging itself is a sensitive, emotional subject for many developers. Instead of attacking it as a puzzle to be solved, you may encounter denial, ﬁnger pointing, lame excuses, or just plain apathy.\n\nEmbrace the fact that debugging is just problem solving, and attack it as such.\n\nHaving found someone else’s bug, you can spend time and energy lay- ing blame on the ﬁlthy culprit who created it. In some workplaces this is part of the culture, and may be cathartic. However, in the technical arena, you want to concentrate on ﬁxing the problem, not the blame.\n\nDEBUGGING\n\nTIP 24\n\nFix the Problem, Not the Blame\n\nIt doesn’t really matter whether the bug is your fault or someone else’s. It is still your problem.\n\nADebugging Mindset The easiest person to deceive is one’s self.\n\nEdward Bulwer-Lytton, TheDisowned\n\nBefore you start debugging, it’s important to adopt the right mindset. You need to turn off many of the defenses you use each day to protect your ego, tune out any project pressures you may be under, and get yourself comfortable. Above all, remember the ﬁrst rule of debugging:\n\nTIP 25\n\nDon’t Panic\n\nIt’s easy to get into a panic, especially if you are facing a deadline, or have a nervous boss or client breathing down your neck while you are trying to ﬁnd the cause of the bug. But it is very important to step back a pace, and actually think about what could be causing the symptoms that you believe indicate a bug.\n\nIf your ﬁrst reaction on witnessing a bug or seeing a bug report is “that’s impossible,” you are plainly wrong. Don’t waste a single neuron on the train of thought that begins “but that can’t happen” because quite clearly it can, and has.\n\nBeware of myopia when debugging. Resist the urge to ﬁx just the symp- toms you see: it is more likely that the actual fault may be several steps removed from what you are observing, and may involve a number of other related things. Always try to discover the root cause of a problem, not just this particular appearance of it.\n\nWheretoStart Before you start to look at the bug, make sure that you are work- ing on code that compiled cleanly—without warnings. We routinely set\n\n91\n\n92\n\nCHAPTER 3 THE BASIC TOOLS\n\ncompiler warning levels as high as possible. It doesn’t make sense to waste time trying to ﬁnd a problem that the compiler could ﬁnd for you! We need to concentrate on the harder problems at hand.\n\nWhen trying to solve any problem, you need to gather all the relevant data. Unfortunately, bug reporting isn’t an exact science. It’s easy to be misled by coincidences, and you can’t afford to waste time debugging coincidences. You ﬁrst need to be accurate in your observations.\n\nAccuracy in bug reports is further diminished when they come through a third party—you may actually need to watch the user who reported the bug in action to get a sufﬁcient level of detail.\n\nAndy once worked on a large graphics application. Nearing release, the testers reported that the application crashed every time they painted a stroke with a particular brush. The programmer responsible argued that there was nothing wrong with it; he had tried painting with it, and it worked just ﬁne. This dialog went back and forth for several days, with tempers rapidly rising.\n\nFinally, we got them together in the same room. The tester selected the brush tool and painted a stroke from the upper right corner to the lower left corner. The application exploded. \"Oh,\" said the programmer, in a small voice, who then sheepishly admitted that he had made test strokes only from the lower left to the upper right, which did not expose the bug.\n\nThere are two points to this story:\n\nYou may need to interview the user who reported the bug in order to gather more data than you were initially given.\n\nArtiﬁcial tests (such as the programmer’s single brush stroke from bottom to top) don’t exercise enough of an application. You must brutally test both boundary conditions and realistic end-user usage patterns. You need to do this systematically (see Ruthless Testing, page 237).\n\nDebugging Strategies Once you think you know what is going on, it’s time to ﬁnd out what the program thinks is going on.",
      "page_number": 109
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 117-124)",
      "start_page": 117,
      "end_page": 124,
      "detection_method": "topic_boundary",
      "content": "DEBUGGING\n\nBug Reproduction\n\nNo, our bugs aren’t really multiplying (although some of them are probably old enough to do it legally). We’re talking about a different kind of reproduction.\n\nThe best way to start ﬁxing a bug is to make it reproducible. After all, if you can’t reproduce it, how will you know if it is ever ﬁxed?\n\nBut we want more than a bug that can be reproduced by following some long series of steps; we want a bug that can be reproduced with a singlecommand. It’s a lot harder to ﬁx a bug if you have to go through 15 steps to get to the point where the bug shows up. Some- times by forcing yourself to isolate the circumstances that display the bug, you’ll even gain an insight on how to ﬁx it.\n\nSee Ubiquitous Automation, page 230, for other ideas along these lines.\n\nVisualizeYourData Often, the easiest way to discern what a program is doing—or what it is going to do—is to get a good look at the data it is operating on. The simplest example of this is a straightforward “variable name = data value” approach, which may be implemented as printed text, or as ﬁelds in a GUI dialog box or list.\n\nBut you can gain a much deeper insight into your data by using a debugger that allows you to visualize your data and all of the inter- relationships that exist. There are debuggers that can represent your data as a 3D ﬂy-over through a virtual reality landscape, or as a 3D waveform plot, or just as simple structural diagrams, as shown in Fig- ure 3.2 on the next page. As you single-step through your program, pictures like these can be worth much more than a thousand words, as the bug you’ve been hunting suddenly jumps out at you.\n\nEven if your debugger has limited support for visualizing data, you can still do it yourself—either by hand, with paper and pencil, or with external plotting programs.\n\nThe DDD debugger has some visualization capabilities, and is freely available (see [URL 19]). It is interesting to note that DDD works with\n\n93\n\n94\n\nCHAPTER 3 THE BASIC TOOLS\n\nFigure 3.2. Sample debugger diagram of a circular linked list. The arrows repre-\n\nsent pointers to nodes.\n\n1: list (List *) 0x804db40\n\nnext\n\nvalue = 85 self = 0x804db40 next = 0x804db50\n\nvalue = 86 self = 0x804db50 next = 0x804db40\n\nnext\n\nmultiple languages, including Ada, C, C++, Fortran, Java, Modula, Pas- cal, Perl, and Python (clearly an orthogonal design).\n\nTracing Debuggers generally focus on the state of the program now. Sometimes you need more—you need to watch the state of a program or a data structure over time. Seeing a stack trace can only tell you how you got here directly. It can’t tell you what you were doing prior to this call chain, especially in event-based systems.\n\nTracing statements are those little diagnostic messages you print to the screen or to a ﬁle that say things such as “got here” and “value of x = 2.” It’s a primitive technique compared with IDE-style debuggers, but it is peculiarly effective at diagnosing several classes of errors that debuggers can’t. Tracing is invaluable in any system where time itself is a factor: concurrent processes, real-time systems, and event-based applications.\n\nYou can use tracing statements to “drill down” into the code. That is, you can add tracing statements as you descend the call tree.\n\nTrace messages should be in a regular, consistent format; you may want to parse them automatically. For instance, if you needed to track down a resource leak (such as unbalanced ﬁle opens/closes), you could trace each open and each close in a log ﬁle. By processing the log\n\nDEBUGGING\n\nCorrupt Variables? Check Their Neighborhood\n\nSometimes you’ll examine a variable, expecting to see a small integer value, and instead get something like 0x6e69614d. Before you roll up your sleeves for some serious debugging, have a quick look at the memory around this corrupted variable. Often it will give you a clue. In our case, examining the surrounding memory as characters shows us\n\n20333231 6e69614d 2c745320 746f4e0a S t , n N o t 2c6e776f 2058580a 31323433 00000a33 3 n 0 0\n\n1 2 3\n\nM a i n\n\no w n , n X X\n\n3 4 2 1\n\nLooks like someone sprayed a street address over our counter. Now we know where to look.\n\nﬁle with Perl, you could easily identify where the offending open was occurring.\n\nRubberDucking A very simple but particularly useful technique for ﬁnding the cause of a problem is simply to explain it to someone else. The other person should look over your shoulder at the screen, and nod his or her head constantly (like a rubber duck bobbing up and down in a bathtub). They do not need to say a word; the simple act of explaining, step by step, what the code is supposed to do often causes the problem to leap off the screen and announce itself.7\n\nIt sounds simple, but in explaining the problem to another person you must explicitly state things that you may take for granted when go- ing through the code yourself. By having to verbalize some of these assumptions, you may suddenly gain new insight into the problem.\n\n7. Why “rubber ducking”? While an undergraduate at Imperial College in London, Dave did a lot of work with a research assistant named Greg Pugh, one of the best developers Dave has known. For several months Greg carried around a small yellow rubber duck, which he’d place on his terminal while coding. It was a while before Dave had the courage to ask. . . .\n\n95\n\n96\n\nCHAPTER 3 THE BASIC TOOLS\n\nProcessof Elimination In most projects, the code you are debugging may be a mixture of appli- cation code written by you and others on your project team, third-party products (database, connectivity, graphical libraries, specialized com- munications or algorithms, and so on) and the platform environment (operating system, system libraries, and compilers).\n\nIt is possible that a bug exists in the OS, the compiler, or a third-party product—but this should not be your ﬁrst thought. It is much more likely that the bug exists in the application code under development. It is generally more proﬁtable to assume that the application code is incorrectly calling into a library than to assume that the library itself is broken. Even if the problem does lie with a third party, you’ll still have to eliminate your code before submitting the bug report.\n\nWe worked on a project where a senior engineer was convinced that the select system call was broken on Solaris. No amount of persuasion or logic could change his mind (the fact that every other networking appli- cation on the box worked ﬁne was irrelevant). He spent weeks writing work-arounds, which, for some odd reason, didn’t seem to ﬁx the prob- lem. When ﬁnally forced to sit down and read the documentation on select, he discovered the problem and corrected it in a matter of min- utes. We now use the phrase “select is broken” as a gentle reminder whenever one of us starts blaming the system for a fault that is likely to be our own.\n\nTIP 26\n\n“select” Isn’t Broken\n\nRemember, if you see hoof prints, think horses—not zebras. The OS is probably not broken. And the database is probably just ﬁne.\n\nIf you “changed only one thing” and the system stopped working, that one thing was likely to be responsible, directly or indirectly, no matter how farfetched it seems. Sometimes the thing that changed is outside of your control: new versions of the OS, compiler, database, or other third- party software can wreak havoc with previously correct code. New bugs might show up. Bugs for which you had a work-around get ﬁxed, break- ing the work-around. APIs change, functionality changes; in short, it’s a whole new ball game, and you must retest the system under these\n\nDEBUGGING\n\nnew conditions. So keep a close eye on the schedule when considering an upgrade; you may want to wait until after the next release.\n\nIf, however, you have no obvious place to start looking, you can always rely on a good old-fashioned binary search. See if the symptoms are present at either of two far away spots in the code. Then look in the middle. If the problem is present, then the bug lies between the start and the middle point; otherwise, it is between the middle point and the end. You can continue in this fashion until you narrow down the spot sufﬁciently to identify the problem.\n\nTheElement of Surprise When you ﬁnd yourself surprised by a bug (perhaps even muttering “that’s impossible” under your breath where we can’t hear you), you must reevaluate truths you hold dear. In that linked list routine—the one you knew was bulletproof and couldn’t possibly be the cause of this bug—did you test all the boundary conditions? That other piece of code you’ve been using for years—it couldn’t possibly still have a bug in it. Could it?\n\nOf course it can. The amount of surprise you feel when something goes wrong is directly proportional to the amount of trust and faith you have in the code being run. That’s why, when faced with a “surprising” fail- ure, you must realize that one or more of your assumptions is wrong. Don’t gloss over a routine or piece of code involved in the bug because you “know” it works. Prove it. Prove it in this context, with this data, with these boundary conditions.\n\nTIP 27\n\nDon’t Assume It—Prove It\n\nWhen you come across a surprise bug, beyond merely ﬁxing it, you need to determine why this failure wasn’t caught earlier. Consider whether you need to amend the unit or other tests so that they would have caught it.\n\nAlso, if the bug is the result of bad data that was propagated through a couple of levels before causing the explosion, see if better parame- ter checking in those routines would have isolated it earlier (see the\n\n97\n\n98\n\nCHAPTER 3 THE BASIC TOOLS\n\ndiscussions on crashing early and assertions on pages 120 and 122, respectively).\n\nWhile you’re at it, are there any other places in the code that may be susceptible to this same bug? Now is the time to ﬁnd and ﬁx them. Make sure that whatever happened, you’ll know if it happens again.\n\nIf it took a long time to ﬁx this bug, ask yourself why. Is there anything you can do to make ﬁxing this bug easier the next time around? Per- haps you could build in better testing hooks, or write a log ﬁle analyzer.\n\nFinally, if the bug is the result of someone’s wrong assumption, discuss the problem with the whole team: if one person misunderstands, then it’s possible many people do.\n\nDo all this, and hopefully you won’t be surprised next time.\n\nDebugging Checklist\n\nIs the problem being reported a direct result of the underlying bug, or merely a symptom?\n\nIs the bug really in the compiler? Is it in the OS? Or is it in your code?\n\nIf you explained this problem in detail to a coworker, what would you say?\n\nIf the suspect code passes its unit tests, are the tests complete enough? What happens if you run the unit test with this data?\n\nDo the conditions that caused this bug exist anywhere else in the system?\n\nRelated sections include:\n\nAssertive Programming, page 122 Programming by Coincidence, page 172 Ubiquitous Automation, page 230 Ruthless Testing, page 237\n\nChallenges\n\nDebugging is challenge enough.\n\n19\n\nTEXT MANIPULATION\n\nText Manipulation\n\nPragmatic Programmers manipulate text the same way woodworkers shape wood. In previous sections we discussed some speciﬁc tools— shells, editors, debuggers—that we use. These are similar to a wood- worker’s chisels, saws, and planes—tools specialized to do one or two jobs well. However, every now and then we need to perform some trans- formation not readily handled by the basic tool set. We need a general- purpose text manipulation tool.\n\nText manipulation languages are to programming what routers8 are to woodworking. They are noisy, messy, and somewhat brute force. Make mistakes with them, and entire pieces can be ruined. Some peo- ple swear they have no place in the toolbox. But in the right hands, both routers and text manipulation languages can be incredibly pow- erful and versatile. You can quickly trim something into shape, make joints, and carve. Used properly, these tools have surprising ﬁnesse and subtlety. But they take time to master.\n\nThere is a growing number of good text manipulation languages. Unix developers often like to use the power of their command shells, aug- mented with tools such as awk and sed. People who prefer a more structured tool like the object-oriented nature of Python [URL 9]. Some people use Tcl [URL 23] as their tool of choice. We happen to prefer Ruby [TFH04] and Perl [URL 8] for hacking out short scripts.\n\nThese languages are important enabling technologies. Using them, you can quickly hack up utilities and prototype ideas—jobs that might take ﬁve or ten times as long using conventional languages. And that mul- tiplying factor is crucially important to the kind of experimenting that we do. Spending 30 minutes trying out a crazy idea is a whole lot bet- ter than spending ﬁve hours. Spending a day automating important components of a project is acceptable; spending a week might not be. In their book The Practice of Programming [KP99], Kernighan and Pike built the same program in ﬁve different languages. The Perl version was the shortest (17 lines, compared with C’s 150). With Perl you can\n\n8. Here router means the tool that spins cutting blades very, very fast, not a device for interconnecting networks.\n\n99\n\n100\n\nCHAPTER 3 THE BASIC TOOLS\n\nmanipulate text, interact with programs, talk over networks, drive Web pages, perform arbitrary precision arithmetic, and write programs that look like Snoopy swearing.\n\nTIP 28\n\nLearn a Text Manipulation Language\n\nTo show the wide-ranging applicability of text manipulation languages, here’s a sample of some applications we’ve developed over the last few years.\n\nDatabase schema maintenance. A set of Perl scripts took a plain text ﬁle containing a database schema deﬁnition and from it gen- erated:\n\n– The SQL statements to create the database – Flat data ﬁles to populate a data dictionary – C code libraries to access the database – Scripts to check database integrity – Web pages containing schema descriptions and diagrams – An XML version of the schema\n\nIt is good OO programming style to restrict Java property access. access to an object’s properties, forcing external classes to get and set them via methods. However, in the common case where a prop- erty is represented inside the class by a simple member variable, creating a get and set method for each variable is tedious and me- chanical. We have a Perl script that modiﬁes the source ﬁles and inserts the correct method deﬁnitions for all appropriately ﬂagged variables.\n\nTest data generation. We had tens of thousands of records of test data, spread over several different ﬁles and formats, that needed to be knitted together and converted into a form suitable for loading into a relational database. Perl did it in a couple of hours (and in the process found a couple of consistency errors in the original data).\n\nBook writing. We think it is important that any code presented in a book should have been tested ﬁrst. Most of the code in this",
      "page_number": 117
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 125-132)",
      "start_page": 125,
      "end_page": 132,
      "detection_method": "topic_boundary",
      "content": "TEXT MANIPULATION\n\nbook has been. However, using the DRY principle (see The Evils of Duplication, page 26) we didn’t want to copy and paste lines of code from the tested programs into the book. That would have meant that the code was duplicated, virtually guaranteeing that we’d for- get to update an example when the corresponding program was changed. For some examples, we also didn’t want to bore you with all the framework code needed to make our example compile and run. We turned to Perl. A relatively simple script is invoked when we format the book—it extracts a named segment of a source ﬁle, does syntax highlighting, and converts the result into the typeset- ting language we use.\n\nC to Object Pascal interface. A client had a team of developers writing Object Pascal on PCs. Their code needed to interface to a body of code written in C. We developed a short Perl script that parsed the C header ﬁles, extracting the deﬁnitions of all exported functions and the data structures they used. We then generated Object Pascal units with Pascal records for all the C structures, and imported procedure deﬁnitions for all the C functions. This generation process became part of the build, so that whenever the C header changed, a new Object Pascal unit would be constructed automatically.\n\nGenerating Web documentation. Many project teams are pub- lishing their documentation to internal Web sites. We have writ- ten many Perl programs that analyze database schemas, C or C++ source ﬁles, makeﬁles, and other project sources to produce the required HTML documentation. We also use Perl to wrap the docu- ments with standard headers and footers, and to transfer them to the Web site.\n\nWe use text manipulation languages almost every day. Many of the ideas in this book can be implemented more simply in them than in any other language of which we’re aware. These languages make it easy to write code generators, which we’ll look at next.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26\n\n101\n\n102\n\nCHAPTER 3 THE BASIC TOOLS\n\nAnswer on p. 285\n\nExercises 11. Your C program uses an enumerated type to represent one of 100 states. You’d like to be able to print out the state as a string (as opposed to a number) for debugging purposes. Write a script that reads from standard input a ﬁle containing\n\nname state_a state_b :\n\n:\n\nProduce the ﬁle name.h, which contains\n\nextern const char* NAME_names[]; typedef enum { state_a, state_b,\n\n: } NAME;\n\n:\n\nand the ﬁle name.c, which contains\n\nconst char* NAME_names[] = {\n\n\"state_a\", \"state_b\",\n\n:\n\n:\n\n};\n\nAnswer on p. 286\n\n12. Halfway through writing this book, we realized that we hadn’t put the use strict directive into many of our Perl examples. Write a script that goes through the .pl ﬁles in a directory and adds a use strict at the end of the initial comment block to all ﬁles that don’t already have one. Remember to keep a backup of all ﬁles you change.\n\n20 Code Generators\n\nWhen woodworkers are faced with the task of producing the same thing over and over, they cheat. They build themselves a jig or a template. If they get the jig right once, they can reproduce a piece of work time after time. The jig takes away complexity and reduces the chances of making mistakes, leaving the craftsman free to concentrate on quality.\n\nAs programmers, we often ﬁnd ourselves in a similar position. We need to achieve the same functionality, but in different contexts. We need to repeat information in different places. Sometimes we just need to pro- tect ourselves from carpal tunnel syndrome by cutting down on repeti- tive typing.\n\nCODE GENERATORS\n\nIn the same way a woodworker invests the time in a jig, a programmer can build a code generator. Once built, it can be used throughout the life of the project at virtually no cost.\n\nTIP 29\n\nWrite Code That Writes Code\n\nThere are two main types of code generators:\n\n1. Passive code generators are run once to produce a result. From that point forward, the result becomes freestanding—it is divorced from the code generator. The wizards discussed in Evil Wizards, page 198, along with some CASE tools, are examples of passive code generators.\n\n2. Active code generators are used each time their results are required. The result is a throw-away—it can always be reproduced by the code generator. Often, active code generators read some form of script or control ﬁle to produce their results.\n\nPassiveCode Generators Passive code generators save typing. They are basically parameterized templates, generating a given output from a set of inputs. Once the result is produced, it becomes a full-ﬂedged source ﬁle in the project; it will be edited, compiled, and placed under source control just like any other ﬁle. Its origins will be forgotten.\n\nPassive code generators have many uses:\n\nCreating new source ﬁles. A passive code generator can produce templates, source code control directives, copyright notices, and standard comment blocks for each new ﬁle in a project. We have our editors set up to do this whenever we create a new ﬁle: edit a new Java program, and the new editor buffer will automatically contain a comment block, package directive, and the outline class declaration, already ﬁlled in.\n\nPerforming one-off conversions among programming languages. We started writing this book using the troff system, but we switched to LATEX after 15 sections had been completed. We wrote a code gen- erator that read the troff source and converted it to LATEX. It was\n\n103\n\n104\n\nCHAPTER 3 THE BASIC TOOLS\n\nabout 90% accurate; the rest we did by hand. This is an interest- ing feature of passive code generators: they don’t have to be totally accurate. You get to choose how much effort you put into the gen- erator, compared with the energy you spend ﬁxing up its output.\n\nProducing lookup tables and other resources that are expensive to compute at runtime. Instead of calculating trigonometric functions, many early graphics systems used precomputed tables of sine and cosine values. Typically, these tables were produced by a passive code generator and then copied into the source.\n\nActiveCode Generators While passive code generators are simply a convenience, their active cousins are a necessity if you want to follow the DRY principle. With an active code generator, you can take a single representation of some piece of knowledge and convert it into all the forms your application needs. This is not duplication, because the derived forms are dispos- able, and are generated as needed by the code generator (hence the word active).\n\nWhenever you ﬁnd yourself trying to get two disparate environments to work together, you should consider using active code generators.\n\nPerhaps you’re developing a database application. Here, you’re dealing with two environments—the database and the programming language you are using to access it. You have a schema, and you need to deﬁne low-level structures mirroring the layout of certain database tables. You could just code these directly, but this violates the DRY princi- ple: knowledge of the schema would then be expressed in two places. When the schema changes, you need to remember to change the corre- sponding code. If a column is removed from a table, but the code base is not changed, you might not even get a compilation error. The ﬁrst you’ll know about it is when your tests start failing (or when the user calls).\n\nAn alternative is to use an active code generator—take the schema and use it to generate the source code for the structures, as shown in Figure 3.3. Now, whenever the schema changes, the code used to access it also changes, automatically. If a column is removed, then its corresponding ﬁeld in the structure will disappear, and any higher-level code that uses that column will fail to compile. You’ve caught the error at compile time,\n\nCODE GENERATORS\n\nFigure 3.3. Active code generator creates code from a database schema\n\nstruct EmployeeRow\n\nSchema\n\ntable employee table employer table beneﬁt\n\nactive code generator\n\nstruct EmployerRow\n\nstruct BenefitRow\n\nnot in production. Of course, this scheme works only if you make the code generation part of the build process itself.9\n\nAnother example of melding environments using code generators hap- pens when different programming languages are used in the same application. In order to communicate, each code base will need some information in common—data structures, message formats, and ﬁeld names, for example. Rather than duplicate this information, use a code generator. Sometimes you can parse the information out of the source ﬁles of one language and use it to generate code in a second language. Often, though, it is simpler to express it in a simpler, language-neutral representation and generate the code for both languages, as shown in Figure 3.4 on the following page. Also see the answer to Exercise 13 on page 286 for an example of how to separate the parsing of the ﬂat ﬁle representation from code generation.\n\nCodeGeneratorsNeedn’t BeComplex All this talk of active this and passive that may leave you with the impression that code generators are complex beasts. They needn’t be. Normally the most complex part is the parser, which analyzes the input ﬁle. Keep the input format simple, and the code generator becomes\n\nJust how do you go about building code from a database schema? There are several 9. ways. If the schema is held in a ﬂat ﬁle (for example, as create table statements), then a relatively simple script can parse it and generate the source. Alternatively, if you use a tool to create the schema directly in the database, then you should be able to extract the information you need directly from the database’s data dictionary. Perl provides libraries that give you access to most major databases.\n\n105\n\nAnswer on p. 286\n\n106\n\nCHAPTER 3 THE BASIC TOOLS\n\nFigure 3.4. Generating code from a language-neutralrepresentation.In the input\n\nﬁle, lines starting with ‘M’ ﬂag the start of a message deﬁnition, ‘F’ lines deﬁne\n\nﬁelds, and ‘E’ is the end of the message.\n\n# Add a product # to the ’on-order’ list M AddProduct F id F name F order_code int E\n\nint char[30]\n\ngenerateC\n\ngeneratePascal\n\n/* Add a product */ /* to the ’on-order’ list */ typedef struct {\n\n{ Add a product } { to the ’on-order’ list } AddProductMsg = packed record\n\nint id; char name[30]; int\n\norder_code;\n\nid: name: order_code: LongInt;\n\nLongInt; array[0..29] of char;\n\n} AddProductMsg;\n\nend;\n\nsimple. Have a look at the answer to Exercise 13 (page 286): the actual code generation is basically print statements.\n\nCode GeneratorsNeedn’t GenerateCode Although many of the examples in this section show code generators that produce program source, this needn’t always be the case. You can use code generators to write just about any output: HTML, XML, plain text—any text that might be an input somewhere else in your project.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26 The Power of Plain Text, page 73 Evil Wizards, page 198 Ubiquitous Automation, page 230\n\nExercises 13. Write a code generator that takes the input ﬁle in Figure 3.4, and generates output in two languages of your choice. Try to make it easy to add new languages.\n\nChapter 4\n\nPragmatic Paranoia\n\nTIP 30\n\nYou Can’t Write Perfect Software\n\nDid that hurt? It shouldn’t. Accept it as an axiom of life. Embrace it. Celebrate it. Because perfect software doesn’t exist. No one in the brief history of computing has ever written a piece of perfect software. It’s unlikely that you’ll be the ﬁrst. And unless you accept this as a fact, you’ll end up wasting time and energy chasing an impossible dream.\n\nSo, given this depressing reality, how does a Pragmatic Programmer turn it into an advantage? That’s the topic of this chapter.\n\nEveryone knows that they personally are the only good driver on Earth. The rest of the world is out there to get them, blowing through stop signs, weaving between lanes, not indicating turns, talking on the telephone, reading the paper, and just generally not living up to our standards. So we drive defensively. We look out for trouble before it happens, anticipate the unexpected, and never put ourselves into a position from which we can’t extricate ourselves.\n\nThe analogy with coding is pretty obvious. We are constantly interfac- ing with other people’s code—code that might not live up to our high standards—and dealing with inputs that may or may not be valid. So we are taught to code defensively. If there’s any doubt, we validate all information we’re given. We use assertions to detect bad data. We check for consistency, put constraints on database columns, and generally feel pretty good about ourselves.\n\n107\n\n108\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nBut Pragmatic Programmers take this a step further. They don’t trust themselves, either. Knowing that no one writes perfect code, includ- ing themselves, Pragmatic Programmers code in defenses against their own mistakes. We describe the ﬁrst defensive measure in Design by Contract: clients and suppliers must agree on rights and responsibili- ties.\n\nIn Dead Programs Tell No Lies, we want to ensure that we do no damage while we’re working the bugs out. So we try to check things often and terminate the program if things go awry.\n\nAssertive Programming describes an easy method of checking along the way—write code that actively veriﬁes your assumptions.\n\nExceptions, like any other technique, can cause more harm than good if not used properly. We’ll discuss the issues in When to Use Exceptions.\n\nAs your programs get more dynamic, you’ll ﬁnd yourself juggling sys- tem resources—memory, ﬁles, devices, and the like. In How to Balance Resources, we’ll suggest ways of ensuring that you don’t drop any of the balls.\n\nIn a world of imperfect systems, ridiculous time scales, laughable tools, and impossible requirements, let’s play it safe.\n\nWhen everybody actually is out to get you, paranoia is just good thinking.\n\nWoody Allen",
      "page_number": 125
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 133-140)",
      "start_page": 133,
      "end_page": 140,
      "detection_method": "topic_boundary",
      "content": "DESIGN BY CONTRACT\n\n21 Design by Contract\n\nNothing astonishes men so much as common sense and plain dealing.\n\nRalph Waldo Emerson, Essays\n\nDealing with computer systems is hard. Dealing with people is even harder. But as a species, we’ve had longer to ﬁgure out issues of human interactions. Some of the solutions we’ve come up with during the last few millennia can be applied to writing software as well. One of the best solutions for ensuring plain dealing is the contract.\n\nA contract deﬁnes your rights and responsibilities, as well as those of the other party. In addition, there is an agreement concerning reper- cussions if either party fails to abide by the contract.\n\nMaybe you have an employment contract that speciﬁes the hours you’ll work and the rules of conduct you must follow. In return, the company pays you a salary and other perks. Each party meets its obligations and everyone beneﬁts.\n\nIt’s an idea used the world over—both formally and informally—to help humans interact. Can we use the same concept to help software mod- ules interact? The answer is “yes.”\n\nDBC Bertrand Meyer [Mey97b] developed the concept of Design by Contract for the language Eiffel.1 It is a simple yet powerful technique that focuses on documenting (and agreeing to) the rights and responsibil- ities of software modules to ensure program correctness. What is a correct program? One that does no more and no less than it claims to do. Documenting and verifying that claim is the heart of Design by Contract (DBC, for short).\n\nEvery function and method in a software system does something. Be- fore it starts that something, the routine may have some expectation of the state of the world, and it may be able to make a statement about the state of the world when it concludes. Meyer describes these expec- tations and claims as follows:\n\n1. information on Eiffel itself, see [URL 10] and [URL 11].\n\nBased in part on earlier work by Dijkstra, Floyd, Hoare, Wirth, and others. For more\n\n109\n\n110\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nPreconditions. What must be true in order for the routine to be called; the routine’s requirements. A routine should never get called when its preconditions would be violated. It is the caller’s respon- sibility to pass good data (see the box on page 115).\n\nPostconditions. What the routine is guaranteed to do; the state of the world when the routine is done. The fact that the routine has a postcondition implies that it will conclude: inﬁnite loops aren’t allowed.\n\nClass invariants. A class ensures that this condition is always true from the perspective of a caller. During internal processing of a routine, the invariant may not hold, but by the time the routine exits and control returns to the caller, the invariant must be true. (Note that a class cannot give unrestricted write-access to any data member that participates in the invariant.)\n\nLet’s look at the contract for a routine that inserts a data value into a unique, ordered list. In iContract, a preprocessor for Java available from [URL 17], you’d specify it as\n\n/**\n\n@invariant forall Node n in elements() | * * * */ implies\n\nn.prev() != null\n\nn.value().compareTo(n.prev().value()) > 0\n\npublic class dbc_list {\n\n/**\n\n@pre contains(aNode) == false * @post contains(aNode) == true */\n\npublic void insertNode(final Node aNode) {\n\n// ...\n\nHere we are saying that nodes in this list must always be in increas- ing order. When you insert a new node, it can’t exist already, and we guarantee that the node will be found after you have inserted it.\n\nYou write these preconditions, postconditions, and invariants in the target programming language, perhaps with some extensions. For ex- ample, iContract provides predicate logic operators—forall, exists, and implies—in addition to normal Java constructs. Your assertions can query the state of any object that the method can access, but be sure that the query is free from any side effects (see page 124).\n\nDESIGN BY CONTRACT\n\nDBC and Constant Parameters\n\nOften, a postcondition will use parameters passed into a method to verify correct behavior. But if the routine is allowed to change the parameter that’s passed in, you might be able to circumvent the con- tract. Eiffel doesn’t allow this to happen, but Java does. Here, we use the Java keyword final to indicate our intentions that the param- eter shouldn’t be changed within the method. This isn’t foolproof— subclasses are free to redeclare the parameter as non-ﬁnal. Alterna- tively, you can use the iContract syntax variable@pre to get the original value of the variable as it existed on entry to the method.\n\nThe contract between a routine and any potential caller can thus be read as\n\nIf all the routine’s preconditions are met by the caller, the routine shall guarantee that all postconditions and invariants will be true when it completes.\n\nIf either party fails to live up to the terms of the contract, then a rem- edy (which was previously agreed to) is invoked—an exception is raised, or the program terminates, for instance. Whatever happens, make no mistake that failure to live up to the contract is a bug. It is not some- thing that should ever happen, which is why preconditions should not be used to perform things such as user-input validation.\n\nTIP 31\n\nDesign with Contracts\n\nIn Orthogonality, page 34, we recommended writing “shy” code. Here, the emphasis is on “lazy” code: be strict in what you will accept before you begin, and promise as little as possible in return. Remember, if your contract indicates that you’ll accept anything and promise the world in return, then you’ve got a lot of code to write!\n\nInheritance and polymorphism are the cornerstones of object-oriented languages and an area where contracts can really shine. Suppose you are using inheritance to create an “is-a-kind-of” relationship, where one class “is-a-kind-of” another class. You probably want to adhere to the Liskov Substitution Principle [Lis88]:\n\n111\n\n112\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nSubclasses must be usable through the base class interface without the need for the user to know the difference.\n\nIn other words, you want to make sure that the new subtype you have created really “is-a-kind-of” the base type—that it supports the same methods, and that the methods have the same meaning. We can do this with contracts. We need to specify a contract only once, in the base class, to have it applied to every future subclass automatically. A sub- class may, optionally, accept a wider range of input, or make stronger guarantees. But it must accept at least as much, and guarantee as much, as its parent.\n\nFor example, consider the Java base class java.awt.Component. You can treat any visual component in AWT or Swing as a Component, with- out knowing that the actual subclass is a button, a canvas, a menu, or whatever. Each individual component can provide additional, speciﬁc functionality, but it has to provide at least the basic capabilities de- ﬁned by Component. But there’s nothing to prevent you from creating a subtype of Component that provides correctly named methods that do the wrong thing. You can easily create a paint method that doesn’t paint, or a setFont method that doesn’t set the font. AWT doesn’t have contracts to catch the fact that you didn’t live up to the agreement.\n\nWithout a contract, all the compiler can do is ensure that a subclass conforms to a particular method signature. But if we put a base class contract in place, we can now ensure that any future subclass can’t alter the meanings of our methods. For instance, you might want to establish a contract for setFont such as the following, which ensures that the font you set is the font you get:\n\n/**\n\n@pre f != null * @post getFont() == f */ public void setFont(final Font f) { // ...\n\nImplementingDBC The greatest beneﬁt of using DBC may be that it forces the issue of requirements and guarantees to the forefront. Simply enumerating at design time what the input domain range is, what the boundary con- ditions are, and what the routine promises to deliver—or, more im-\n\nDESIGN BY CONTRACT\n\nportantly, what it doesn’t promise to deliver—is a huge leap forward in writing better software. By not stating these things, you are back to pro- gramming by coincidence (see page 172), which is where many projects start, ﬁnish, and fail.\n\nIn languages that do not support DBC in the code, this might be as far as you can go—and that’s not too bad. DBC is, after all, a design technique. Even without automatic checking, you can put the contract in the code as comments and still get a very real beneﬁt. If nothing else, the commented contracts give you a place to start looking when trouble strikes.\n\nAssertions While documenting these assumptions is a great start, you can get much greater beneﬁt by having the compiler check your contract for you. You can partially emulate this in some languages by using asser- tions (see Assertive Programming, page 122). Why only partially? Can’t you use assertions to do everything DBC can do?\n\nUnfortunately, the answer is no. To begin with, there is no support for propagating assertions down an inheritance hierarchy. This means that if you override a base class method that has a contract, the asser- tions that implement that contract will not be called correctly (unless you duplicate them manually in the new code). You must remember to call the class invariant (and all base class invariants) manually before you exit every method. The basic problem is that the contract is not automatically enforced.\n\nAlso, there is no built-in concept of “old” values; that is, values as they existed at the entry to a method. If you’re using assertions to enforce contracts, you must add code to the precondition to save any information you’ll want to use in the postcondition. Compare this with iContract, where the postcondition can just reference “variable@pre,” or with Eiffel, which supports “old expression.”\n\nFinally, the runtime system and libraries are not designed to support contracts, so these calls are not checked. This is a big loss, because it is often at the boundary between your code and the libraries it uses that the most problems are detected (see Dead Programs Tell No Lies, page 120 for a more detailed discussion).\n\n113\n\n114\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nLanguage Support Languages that feature built-in support of DBC (such as Eiffel and Sather [URL 12]) check pre- and postconditions automatically in the compiler and runtime system. You get the greatest beneﬁt in this case because all of the code base (libraries, too) must honor their contracts.\n\nBut what about more popular languages such as C, C++, and Java? For these languages, there are preprocessors that process contracts embedded in the original source code as special comments. The pre- processor expands these comments to code that veriﬁes the assertions.\n\nFor C and C++, you may want to investigate Nana [URL 18]. Nana doesn’t handle inheritance, but it does use the debugger at runtime to monitor assertions in a novel way.\n\nFor Java, there is iContract [URL 17]. It takes comments (in JavaDoc form) and generates a new source ﬁle with the assertion logic included.\n\nPreprocessors aren’t as good as a built-in facility. They can be messy to integrate into your project, and other libraries you use won’t have con- tracts. But they can still be very helpful; when a problem is discovered this way—especially one that you would never have found—it’s almost like magic.\n\nDBC andCrashingEarly DBC ﬁts in nicely with our concept of crashing early (see Dead Pro- grams Tell No Lies, page 120). Suppose you have a method that cal- culates square roots (such as in the Eiffel class DOUBLE). It needs a precondition that restricts the domain to positive numbers. An Eiffel precondition is declared with the keyword require, and a postcondi- tion is declared with ensure, so you could write\n\nsqrt: DOUBLE is\n\n-- Square root routine\n\nrequire\n\nsqrt_arg_must_be_positive: Current >= 0;\n\n--- ... --- calculate square root here --- ... ensure\n\n((Result*Result) - Current).abs <= epsilon*Current.abs; -- Result should be within error tolerance\n\nend;\n\nDESIGN BY CONTRACT\n\nWho’s Responsible?\n\nWho is responsible for checking the precondition, the caller or the routine being called? When implemented as part of the language, the answer is neither: the precondition is tested behind the scenes after the caller invokes the routine but before the routine itself is entered. Thus if there is any explicit checking of parameters to be done, it must be performed by the caller, because the routine itself will never see parameters that violate its precondition. (For languages without built-in support, you would need to bracket the called routine with a preamble and/or postamble that checks these assertions.)\n\nConsider a program that reads a number from the console, calcu- lates its square root (by calling sqrt), and prints the result. The sqrt function has a precondition—its argument must not be negative. If the user enters a negative number at the console, it is up to the calling code to ensure that it never gets passed to sqrt. This calling code has many options: it could terminate, it could issue a warning and read another number, or it could make the number positive and ap- pend an “ ” to the result returned by sqrt. Whatever its choice, this is deﬁnitely not sqrt’s problem.\n\nBy expressing the domain of the square root function in the precon- dition of the sqrt routine, you shift the burden of correctness to the caller—where it belongs. You can then design the sqrt routine se- cure in the knowledge that its input will be in range.\n\nIf your algorithm for calculating the square root fails (or isn’t within the speciﬁed error tolerance), you get an error message and a stack trace to show you the call chain.\n\nIf you pass sqrt a negative parameter, the Eiffel runtime prints the error “sqrt_arg_must_be_positive,” along with a stack trace. This is better than the alternative in languages such as Java, C, and C++, where passing a negative number to sqrt returns the special value NaN (Not a Number). It may be some time later in the program that you attempt to do some math on NaN, with surprising results.\n\nIt’s much easier to ﬁnd and diagnose the problem by crashing early, at the site of the problem.\n\n115\n\n116\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nOther Usesof Invariants So far we have discussed pre- and postconditions that apply to individ- ual methods and invariants that apply to all methods within a class, but there are other useful ways to use invariants.\n\nLoop Invariants Getting the boundary conditions right on a nontrivial loop can be prob- lematic. Loops are subject to the banana problem (I know how to spell “banana,” but I don’t know when to stop), fencepost errors (not know- ing whether to count the fenceposts or the spaces between them), and the ubiquitous “off by one” error [URL 52].\n\nInvariants can help in these situations: a loop invariant is a statement of the eventual goal of a loop, but is generalized so that it is also valid before the loop executes and on each iteration through the loop. You can think of it as a kind of miniature contract. The classic example is a routine that ﬁnds the maximum value in an array.\n\nint m = arr[0]; int i = 1;\n\n// example assumes arr.length > 0\n\n// Loop invariant: m = max(arr[0:i-1]) while (i < arr.length) {\n\nm = Math.max(m, arr[i]); i = i + 1;\n\n}\n\n(arr[m:n] is a notational convenience meaning a slice of the array from index m to n.) The invariant must be true before the loop runs, and the body of the loop must ensure that it remains true as the loop executes. In this way we know that the invariant also holds when the loop termi- nates, and therefore that our result is valid. Loop invariants can be coded explicitly as assertions, but they are also useful as design and documentation tools.\n\nSemantic Invariants You can use semantic invariants to express inviolate requirements, a kind of “philosophical contract.”\n\nWe once wrote a debit card transaction switch. A major requirement was that the user of a debit card should never have the same trans- action applied to their account twice. In other words, no matter what",
      "page_number": 133
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 141-148)",
      "start_page": 141,
      "end_page": 148,
      "detection_method": "topic_boundary",
      "content": "DESIGN BY CONTRACT\n\nsort of failure mode might happen, the error should be on the side of not processing a transaction rather than processing a duplicate trans- action.\n\nThis simple law, driven directly from the requirements, proved to be very helpful in sorting out complex error recovery scenarios, and guided the detailed design and implementation in many areas.\n\nBe sure not to confuse requirements that are ﬁxed, inviolate laws with those that are merely policies that might change with a new manage- ment regime. That’s why we use the term semantic invariants—it must be central to the very meaning of a thing, and not subject to the whims of policy (which is what more dynamic business rules are for).\n\nWhen you ﬁnd a requirement that qualiﬁes, make sure it becomes a well-known part of whatever documentation you are producing— whether it is a bulleted list in the requirements document that gets signed in triplicate or just a big note on the common whiteboard that everyone sees. Try to state it clearly and unambiguously. For example, in the debit card example, we might write\n\nERR IN FAVOR OF THE CONSUMER.\n\nThis is a clear, concise, unambiguous statement that’s applicable in many different areas of the system. It is our contract with all users of the system, our guarantee of behavior.\n\nDynamicContractsandAgents Until now, we have talked about contracts as ﬁxed, immutable speciﬁ- cations. But in the landscape of autonomous agents, this doesn’t need to be the case. By the deﬁnition of “autonomous,” agents are free to reject requests that they do not want to honor. They are free to renego- tiate the contract—“I can’t provide that, but if you give me this, then I might provide something else.”\n\nCertainly any system that relies on agent technology has a critical de- pendence on contractual arrangements—even if they are dynamically generated.\n\nImagine: with enough components and agents that can negotiate their own contracts among themselves to achieve a goal, we might just solve the software productivity crisis by letting software solve it for us.\n\n117\n\nAnswer on p. 288\n\n118\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nBut if we can’t use contracts by hand, we won’t be able to use them automatically. So next time you design a piece of software, design its contract as well.\n\nRelated sections include: Orthogonality, page 34 Dead Programs Tell No Lies, page 120 Assertive Programming, page 122 How to Balance Resources, page 129 Decoupling and the Law of Demeter, page 138 Temporal Coupling, page 150 Programming by Coincidence, page 172 Code That’s Easy to Test, page 189 Pragmatic Teams, page 224\n\nChallenges\n\nPoints to ponder: If DBC is so powerful, why isn’t it used more widely? Is it hard to come up with the contract? Does it make you think about issues you’d rather ignore for now? Does it force you to THINK!? Clearly, this is a dangerous tool!\n\nExercises 14. What makes a good contract? Anyone can add preconditions and postcon- ditions, but will they do you any good? Worse yet, will they actually do more harm than good? For the example below and for those in Exercises 15 and 16, decide whether the speciﬁed contract is good, bad, or ugly, and explain why.\n\nFirst, let’s look at an Eiffel example. Here we have a routine for adding a STRING to a doubly linked, circular list (remember that preconditions are labeled with require, and postconditions with ensure).\n\n-- Add a unique item to a doubly linked list, -- and return the newly created NODE.\n\nadd_item (item : STRING) : NODE is\n\nrequire\n\nitem /= Void find_item(item) = Void\n\ndeferred ensure\n\n-- ’/=’ is ’not equal’. -- Must be unique -- Abstract base class.\n\nresult.next.previous = result -- Check the newly result.previous.next = result -- added node’s links. find_item(item) = result\n\n-- Should find it.\n\nend\n\nDESIGN BY CONTRACT\n\n119\n\n15. Next, let’s try an example in Java—somewhat similar to the example in Exercise 14. insertNumber inserts an integer into an ordered list. Pre- and postconditions are labeled as in iContract (see [URL 17]). Answer on p. 288\n\nprivate int data[]; /**\n\n@post data[index-1] < data[index] && data[index] == aValue * */\n\npublic Node insertNumber (final int aValue) {\n\nint index = findPlaceToInsert(aValue); ...\n\n16. Here’s a fragment from a stack class in Java. Is this a good contract?\n\n/**\n\n@pre anItem != null * @post pop() == anItem // Verify that it’s * */ // Require real data\n\npublic void push(final String anItem)\n\n17. The classic examples of DBC (as in Exercises 14–16) show an implemen- tation of an ADT (Abstract Data Type)—typically a stack or queue. But not many people really write these kinds of low-level classes. Answer on p. 289\n\nSo, for this exercise, design an interface to a kitchen blender. It will even- tually be a Web-based, Internet-enabled, CORBA-ﬁed blender, but for now we just need the interface to control it. It has ten speed settings (0 means off). You can’t operate it empty, and you can change the speed only one unit at a time (that is, from 0 to 1, and from 1 to 2, not from 0 to 2).\n\nHere are the methods. Add appropriate pre- and postconditions and an invariant.\n\nint getSpeed() void setSpeed(int x) boolean isFull() void fill() void empty()\n\n18. How many numbers are in the series\n\n?\n\nAnswer on p. 289\n\nAnswer on p. 290\n\n120\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\n22 Dead Programs Tell No Lies\n\nHave you noticed that sometimes other people can detect that things aren’t well with you before you’re aware of the problem yourself? It’s the same with other people’s code. If something is starting to go awry with one of our programs, sometimes it is a library routine that catches it ﬁrst. Maybe a stray pointer has caused us to overwrite a ﬁle handle with something meaningless. The next call to read will catch it. Perhaps a buffer overrun has trashed a counter we’re about to use to determine how much memory to allocate. Maybe we’ll get a failure from malloc. A logic error a couple of million instructions ago means that the selector for a case statement is no longer the expected 1, 2, or 3. We’ll hit the default case (which is one reason why each and every case/switch statement needs to have a default clause—we want to know when the “impossible” has happened).\n\nIt’s easy to fall into the “it can’t happen” mentality. Most of us have written code that didn’t check that a ﬁle closed successfully, or that a trace statement got written as we expected. And all things being equal, it’s likely that we didn’t need to—the code in question wouldn’t fail under any normal conditions. But we’re coding defensively. We’re look- ing for rogue pointers in other parts of our program trashing the stack. We’re checking that the correct versions of shared libraries were actu- ally loaded.\n\nAll errors give you information. You could convince yourself that the error can’t happen, and choose to ignore it. Instead, Pragmatic Pro- grammers tell themselves that if there is an error, something very, very bad has happened.\n\nTIP 32\n\nCrash Early\n\nCrash,Don’t Trash One of the beneﬁts of detecting problems as soon as you can is that you can crash earlier. And many times, crashing your program is the best thing you can do. The alternative may be to continue, writing corrupted\n\nDEAD PROGRAMS TELL NO LIES\n\ndata to some vital database or commanding the washing machine into its twentieth consecutive spin cycle.\n\nThe Java language and libraries have embraced this philosophy. When something unexpected happens within the runtime system, it throws a RuntimeException. If not caught, this will percolate up to the top level of the program and cause it to halt, displaying a stack trace.\n\nYou can do the same in other languages. If you don’t have an exception mechanism, or if your libraries don’t throw exceptions, then make sure you handle the errors yourself. In C, macros can be very useful for this:\n\n#define CHECK(LINE, EXPECTED)\n\n{ int rc = LINE;\n\nif (rc != EXPECTED)\n\nut_abort(__FILE__, __LINE__, #LINE, rc, EXPECTED); }\n\nvoid ut_abort(char *file, int ln, char *line, int rc, int exp) {\n\nfprintf(stderr, \"%s line %d n’%s’: expected %d, got %d n\", file, ln, line, exp, rc);\n\nexit(1);\n\n}\n\nThen you can wrap calls that should never fail using\n\nCHECK(stat(\"/tmp\", &stat_buff), 0);\n\nIf it should fail, you’d get a message written to stderr:\n\nsource.c line 19 ’stat(\"/tmp\", &stat_buff)’: expected 0, got -1\n\nClearly it is sometimes inappropriate simply to exit a running program. You may have claimed resources that might not get released, or you may need to write log messages, tidy up open transactions, or inter- act with other processes. The techniques we discuss in When to Use Exceptions, page 125, will help here. However, the basic principle stays the same—when your code discovers that something that was supposed to be impossible just happened, your program is no longer viable. Any- thing it does from this point forward becomes suspect, so terminate it as soon as possible. A dead program normally does a lot less damage than a crippled one.\n\nRelated sections include:\n\nDesign by Contract, page 109 When to Use Exceptions, page 125\n\n121\n\n122\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\n23 Assertive Programming\n\nThere is a luxury in self-reproach. When we blame ourselves we feel no one else has a right to blame us.\n\nOscar Wilde, ThePicture ofDorianGray\n\nIt seems that there’s a mantra that every programmer must memorize early in his or her career. It is a fundamental tenet of computing, a core belief that we learn to apply to requirements, designs, code, comments, just about everything we do. It goes\n\nTHIS CAN NEVER HAPPEN\n\n“This code won’t be used 30 years from now, so two-digit dates are ﬁne.” “This application will never be used abroad, so why internationalize it?” “count can’t be negative.” “This printf can’t fail.”\n\nLet’s not practice this kind of self-deception, particularly when coding.\n\nTIP 33\n\nIf It Can’t Happen, Use Assertions to Ensure That It Won’t\n\nWhenever you ﬁnd yourself thinking “but of course that could never happen,” add code to check it. The easiest way to do this is with asser- tions. In most C and C++ implementations, you’ll ﬁnd some form of assert or _assert macro that checks a Boolean condition. These macros can be invaluable. If a pointer passed in to your procedure should never be NULL, then check for it:\n\nvoid writeString(char *string) { assert(string != NULL); ...\n\nAssertions are also useful checks on an algorithm’s operation. Maybe you’ve written a clever sort algorithm. Check that it works:\n\nfor (int i = 0; i < num_entries-1; i++) { assert(sorted[i] <= sorted[i+1]);\n\n}\n\nOf course, the condition passed to an assertion should not have a side effect (see the box on page 124). Also remember that assertions may be turned off at compile time—never put code that must be executed into an assert.\n\nASSERTIVE PROGRAMMING\n\nDon’t use assertions in place of real error handling. Assertions check for things that should never happen: you don’t want to be writing code such as\n\nprintf(\"Enter ’Y’ or ’N’: \"); ch = getchar(); assert((ch == ’Y’) || (ch == ’N’));\n\n/* bad idea! */\n\nAnd just because the supplied assert macros call exit when an as- sertion fails, there’s no reason why versions you write should. If you need to free resources, have an assertion failure generate an exception, longjmp to an exit point, or call an error handler. Just make sure the code you execute in those dying milliseconds doesn’t rely on the infor- mation that triggered the assertion failure in the ﬁrst place.\n\nLeaveAssertions Turned On There is a common misunderstanding about assertions, promulgated by the people who write compilers and language environments. It goes something like this:\n\nAssertions add some overhead to code. Because they check for things that should never happen, they’ll get triggered only by a bug in the code. Once the code has been tested and shipped, they are no longer needed, and should be turned off to make the code run faster. Assertions are a debugging facility.\n\nThere are two patently wrong assumptions here. First, they assume that testing ﬁnds all the bugs. In reality, for any complex program you are unlikely to test even a miniscule percentage of the permutations your code will be put through (see Ruthless Testing, page 245). Second, the optimists are forgetting that your program runs in a dangerous world. During testing, rats probably won’t gnaw through a communi- cations cable, someone playing a game won’t exhaust memory, and log ﬁles won’t ﬁll the hard drive. These things might happen when your program runs in a production environment. Your ﬁrst line of defense is checking for any possible error, and your second is using assertions to try to detect those you’ve missed.\n\nTurning off assertions when you deliver a program to production is like crossing a high wire without a net because you once made it across in practice. There’s dramatic value, but it’s hard to get life insurance.\n\nEven if you do have performance issues, turn off only those assertions that really hit you. The sort example above may be a critical part of\n\n123\n\n124\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nAssertions and Side Effects\n\nIt is embarrassing when the code we add to detect errors actually ends up creating new errors. This can happen with assertions if eval- uating the condition has side effects. For example, in Java it would be a bad idea to code something such as\n\nwhile (iter.hasMoreElements()) {\n\nTest.ASSERT(iter.nextElement() != null);\n\nObject obj = iter.nextElement();\n\n// ....\n\n}\n\nThe .nextElement() call in the ASSERT has the side effect of moving the iterator past the element being fetched, and so the loop will process only half the elements in the collection. It would be better to write\n\nwhile (iter.hasMoreElements()) {\n\nObject obj = iter.nextElement();\n\nTest.ASSERT(obj != null);\n\n// ....\n\n}\n\nThis problem is a kind of “Heisenbug”—debugging that changes the behavior of the system being debugged (see [URL 52]).\n\nyour application, and may need to be fast. Adding the check means another pass through the data, which might be unacceptable. Make that particular check optional,2 but leave the rest in.\n\nRelated sections include:\n\nDebugging, page 90 Design by Contract, page 109 How to Balance Resources, page 129 Programming by Coincidence, page 172\n\n2. In C-based languages, you can either use the preprocessor or use if statements to make assertions optional. Many implementations turn off code generation for the assert macro if a compile-time ﬂag is set (or not set). Otherwise, you can place the code within an if statement with a constant condition, which many compilers (including most common Java systems) will optimize away.",
      "page_number": 141
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 149-156)",
      "start_page": 149,
      "end_page": 156,
      "detection_method": "topic_boundary",
      "content": "WHEN TO USE EXCEPTIONS\n\nExercises 19. A quick reality check. Which of these “impossible” things can happen?\n\n1. A month with fewer than 28 days\n\n2. stat(\".\",&sb) == -1 (that is, can’t access the current directory)\n\n3. In C++:\n\na = 2; b = 3; if (a + b != 5) exit(1);\n\n4. A triangle with an interior angle sum\n\n5. A minute that doesn’t have 60 seconds\n\n6. In Java: (a + 1) <= a\n\n20. Develop a simple assertion checking class for Java.\n\n24 When to Use Exceptions\n\nIn Dead Programs Tell No Lies, page 120, we suggested that it is good practice to check for every possible error—particularly the unexpected ones. However, in practice this can lead to some pretty ugly code; the normal logic of your program can end up being totally obscured by error handling, particularly if you subscribe to the “a routine must have a single return statement” school of programming (we don’t). We’ve seen code that looks something like the following:\n\nretcode = OK; if (socket.read(name) != OK) {\n\nretcode = BAD_READ;\n\n} else {\n\nprocessName(name); if (socket.read(address) != OK) {\n\nretcode = BAD_READ;\n\n} else {\n\nprocessAddress(address); if (socket.read(telNo) != OK) {\n\nretcode = BAD_READ;\n\n} else {\n\n// etc, etc...\n\n}\n\n}\n\n} return retcode;\n\nFortunately, if the programming language supports exceptions, you can rewrite this code in a far neater way:\n\n125\n\nAnswer on p. 290\n\nAnswer on p. 291\n\n126\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nretcode = OK;\n\ntry {\n\nsocket.read(name); process(name);\n\nsocket.read(address); processAddress(address);\n\nsocket.read(telNo); // etc, etc...\n\n} catch (IOException e) { retcode = BAD_READ; Logger.log(\"Error reading individual: \" + e.getMessage());\n\n}\n\nreturn retcode;\n\nThe normal ﬂow of control is now clear, with all the error handling moved off to a single place.\n\nWhatIsExceptional? One of the problems with exceptions is knowing when to use them. We believe that exceptions should rarely be used as part of a program’s normal ﬂow; exceptions should be reserved for unexpected events. Assume that an uncaught exception will terminate your program and ask yourself, “Will this code still run if I remove all the exception han- dlers?” If the answer is “no,” then maybe exceptions are being used in nonexceptional circumstances.\n\nFor example, if your code tries to open a ﬁle for reading and that ﬁle does not exist, should an exception be raised?\n\nOur answer is, “It depends.” If the ﬁle should have been there, then an exception is warranted. Something unexpected happened—a ﬁle you were expecting to exist seems to have disappeared. On the other hand, if you have no idea whether the ﬁle should exist or not, then it doesn’t seem exceptional if you can’t ﬁnd it, and an error return is appropriate.\n\nLet’s look at an example of the ﬁrst case. The following code opens the ﬁle /etc/passwd, which should exist on all Unix systems. If it fails, it passes on the FileNotFoundException to its caller.\n\npublic void open_passwd() throws FileNotFoundException {\n\n// This may throw FileNotFoundException... ipstream = new FileInputStream(\"/etc/passwd\");\n\n// ...\n\n}\n\nWHEN TO USE EXCEPTIONS\n\nHowever, the second case may involve opening a ﬁle speciﬁed by the user on the command line. Here an exception isn’t warranted, and the code looks different:\n\npublic boolean open_user_file(String name)\n\nthrows FileNotFoundException {\n\nFile f = new File(name);\n\nif (!f.exists()) { return false;\n\n}\n\nipstream = new FileInputStream(f); return true;\n\n}\n\nNote that the FileInputStream call can still generate an exception, which the routine passes on. However, the exception will be generated under only truly exceptional circumstances; simply trying to open a ﬁle that does not exist will generate a conventional error return.\n\nTIP 34\n\nUse Exceptions for Exceptional Problems\n\nWhy do we suggest this approach to exceptions? Well, an exception represents an immediate, nonlocal transfer of control—it’s a kind of cascading goto. Programs that use exceptions as part of their normal processing suffer from all the readability and maintainability problems of classic spaghetti code. These programs break encapsulation: rou- tines and their callers are more tightly coupled via exception handling.\n\nErrorHandlersAreanAlternative An error handler is a routine that is called when an error is detected. You can register a routine to handle a speciﬁc category of errors. When one of these errors occurs, the handler will be called.\n\nThere are times when you may want to use error handlers, either in- stead of or alongside exceptions. Clearly, if you are using a language such as C, which does not support exceptions, this is one of your few other options (see the challenge on the next page). However, sometimes error handlers can be used even in languages (such as Java) that have a good exception handling scheme built in.\n\n127\n\nAnswer on p. 292\n\n128\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nConsider the implementation of a client-server application, using Java’s Remote Method Invocation (RMI) facility. Because of the way RMI is implemented, every call to a remote routine must be prepared to han- dle a RemoteException. Adding code to handle these exceptions can become tedious, and means that it is difﬁcult to write code that works with both local and remote routines. A possible work-around is to wrap your remote objects in a class that is not remote. This class then imple- ments an error handler interface, allowing the client code to register a routine to be called when a remote exception is detected.\n\nRelated sections include:\n\nDead Programs Tell No Lies, page 120\n\nChallenges\n\nLanguages that do not support exceptions often have some other nonlocal transfer of control mechanism (C has longjmp/setjmp, for example). Con- sider how you could implement some kind of ersatz exception mechanism using these facilities. What are the beneﬁts and dangers? What special steps do you need to take to ensure that resources are not orphaned? Does it make sense to use this kind of solution whenever you code in C?\n\nExercises 21. While designing a new container class, you identify the following possible\n\nerror conditions:\n\n1. No memory available for a new element in the add routine\n\n2. Requested entry not found in the fetch routine\n\n3. null pointer passed to the add routine\n\nHow should each be handled? Should an error be generated, should an exception be raised, or should the condition be ignored?\n\nHOW TO BALANCE RESOURCES\n\n25 How to Balance Resources\n\n“I brought you into this world,” my father would say, “and I can take you out. It don’t make no difference to me. I’ll just make another one like you.”\n\nBill Cosby, Fatherhood\n\nWe all manage resources whenever we code: memory, transactions, threads, ﬁles, timers—all kinds of things with limited availability. Most of the time, resource usage follows a predictable pattern: you allocate the resource, use it, and then deallocate it.\n\nHowever, many developers have no consistent plan for dealing with re- source allocation and deallocation. So let us suggest a simple tip:\n\nTIP 35\n\nFinish What You Start\n\nThis tip is easy to apply in most circumstances. It simply means that the routine or object that allocates a resource should be responsible for deallocating it. Let’s see how it applies by looking at an example of some bad code—an application that opens a ﬁle, reads customer information from it, updates a ﬁeld, and writes the result back. We’ve eliminated error handling to make the example clearer.\n\nvoid readCustomer(const char *fName, Customer *cRec) {\n\ncFile = fopen(fName, \"r+\"); fread(cRec, sizeof(*cRec), 1, cFile);\n\n}\n\nvoid writeCustomer(Customer *cRec) {\n\nrewind(cFile); fwrite(cRec, sizeof(*cRec), 1, cFile); fclose(cFile);\n\n}\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nCustomer cRec;\n\nreadCustomer(fName, &cRec);\n\ncRec.balance = newBalance;\n\nwriteCustomer(&cRec);\n\n}\n\nAt ﬁrst sight, the routine updateCustomer looks pretty good. It seems to implement the logic we require—reading a record, updating the bal- ance, and writing the record back out. However, this tidiness hides a\n\n129\n\n130\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nmajor problem. The routines readCustomer and writeCustomer are tightly coupled3—they share the global variable cFile. readCustomer opens the ﬁle and stores the ﬁle pointer in cFile, and writeCustomer uses that stored pointer to close the ﬁle when it ﬁnishes. This global variable doesn’t even appear in the updateCustomer routine.\n\nWhy is this bad? Let’s consider the unfortunate maintenance program- mer who is told that the speciﬁcation has changed—the balance should be updated only if the new value is not negative. She goes into the source and changes updateCustomer:\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nCustomer cRec;\n\nreadCustomer(fName, &cRec);\n\nif (newBalance >= 0.0) {\n\ncRec.balance = newBalance;\n\nwriteCustomer(&cRec);\n\n}\n\n}\n\nAll seems ﬁne during testing. However, when the code goes into produc- tion, it collapses after several hours, complaining of too many open ﬁles. Because writeCustomer is not getting called in some circumstances, the ﬁle is not getting closed.\n\nA very bad solution to this problem would be to deal with the special case in updateCustomer:\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nCustomer cRec;\n\nreadCustomer(fName, &cRec);\n\nif (newBalance >= 0.0) {\n\ncRec.balance = newBalance;\n\nwriteCustomer(&cRec);\n\n} else\n\nfclose(cFile);\n\n}\n\nThis will ﬁx the problem—the ﬁle will now get closed regardless of the new balance—but the ﬁx now means that three routines are coupled through the global cFile. We’re falling into a trap, and things are going to start going downhill rapidly if we continue on this course.\n\n3. Demeter, page 138.\n\nFor a discussion of the dangers of coupled code, see Decoupling and the Law of\n\nHOW TO BALANCE RESOURCES\n\nThe ﬁnish what you start tip tells us that, ideally, the routine that allo- cates a resource should also free it. We can apply it here by refactoring the code slightly:\n\nvoid readCustomer(FILE *cFile, Customer *cRec) {\n\nfread(cRec, sizeof(*cRec), 1, cFile);\n\n}\n\nvoid writeCustomer(FILE *cFile, Customer *cRec) {\n\nrewind(cFile); fwrite(cRec, sizeof(*cRec), 1, cFile);\n\n}\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nFILE *cFile; Customer cRec;\n\ncFile = fopen(fName, \"r+\"); readCustomer(cFile, &cRec); if (newBalance >= 0.0) {\n\ncRec.balance = newBalance; writeCustomer(cFile, &cRec);\n\n} fclose(cFile);\n\n// >--- // // // // // // <---\n\n| | | | |\n\n}\n\nNow all the responsibility for the ﬁle is in the updateCustomer routine. It opens the ﬁle and (ﬁnishing what it starts) closes it before exiting. The routine balances the use of the ﬁle: the open and close are in the same place, and it is apparent that for every open there will be a correspond- ing close. The refactoring also removes an ugly global variable.\n\nNestAllocations The basic pattern for resource allocation can be extended for routines that need more than one resource at a time. There are just two more suggestions:\n\n1. Deallocate resources in the opposite order to that in which you allocate them. That way you won’t orphan resources if one resource contains references to another.\n\n2. When allocating the same set of resources in different places in your code, always allocate them in the same order. This will reduce the possibility of deadlock. (If process A claims resource1 and is about to claim resource2, while process B has claimed resource2 and is trying to get resource1, the two processes will wait forever.)\n\nIt doesn’t matter what kind of resources we’re using—transactions, memory, ﬁles, threads, windows—the basic pattern applies: whoever\n\n131\n\n132\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nallocates a resource should be responsible for deallocating it. However, in some languages we can develop the concept further.\n\nObjects andExceptions The equilibrium between allocations and deallocations is reminiscent of a class’s constructor and destructor. The class represents a resource, the constructor gives you a particular object of that resource type, and the destructor removes it from your scope.\n\nIf you are programming in an object-oriented language, you may ﬁnd it useful to encapsulate resources in classes. Each time you need a particular resource type, you instantiate an object of that class. When the object goes out of scope, or is reclaimed by the garbage collector, the object’s destructor then deallocates the wrapped resource.\n\nThis approach has particular beneﬁts when you’re working with lan- guages such as C++, where exceptions can interfere with resource deal- location.\n\nBalancingandExceptions Languages that support exceptions can make resource deallocation tricky. If an exception is thrown, how do you guarantee that every- thing allocated prior to the exception is tidied up? The answer depends to some extent on the language.\n\nBalancing ResourceswithC++Exceptions C++ supports a try catch exception mechanism. Unfortunately, this means that there are always at least two possible paths when exiting a routine that catches and then rethrows an exception:\n\nvoid doSomething(void) {\n\nNode *n = new Node;\n\ntry {\n\n// do something\n\n} catch (...) { delete n; throw;\n\n}\n\ndelete n;\n\n}",
      "page_number": 149
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 157-164)",
      "start_page": 157,
      "end_page": 164,
      "detection_method": "topic_boundary",
      "content": "HOW TO BALANCE RESOURCES\n\nNotice that the node we create is freed in two places—once in the rou- tine’s normal exit path, and once in the exception handler. This is an obvious violation of the DRY principle and a maintenance problem wait- ing to happen.\n\nHowever, we can use the semantics of C++ to our advantage. Local objects are automatically destroyed on exiting from their enclosing block. This gives us a couple of options. If the circumstances permit, we can change “n” from a pointer to an actual Node object on the stack:\n\nvoid doSomething1(void) {\n\nNode n;\n\ntry {\n\n// do something\n\n} catch (...) {\n\nthrow;\n\n}\n\n}\n\nHere we rely on C++ to handle the destruction of the Node object auto- matically, whether an exception is thrown or not.\n\nIf the switch from a pointer is not possible, the same effect can be achieved by wrapping the resource (in this case, a Node pointer) within another class.\n\n// Wrapper class for Node resources class NodeResource {\n\nNode *n;\n\npublic:\n\nNodeResource() { n = new Node; } ~NodeResource() { delete n; }\n\nNode *operator->() { return n; }\n\n};\n\nvoid doSomething2(void) {\n\nNodeResource n;\n\ntry {\n\n// do something\n\n} catch (...) {\n\nthrow;\n\n}\n\n}\n\nNow the wrapper class, NodeResource, ensures that when its objects are destroyed the corresponding nodes are also destroyed. For conve- nience, the wrapper provides a dereferencing operator ->, so that its users can access the ﬁelds in the contained Node object directly.\n\n133\n\n134\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nBecause this technique is so useful, the standard C++ library provides the template class auto_ptr, which gives you automatic wrappers for dynamically allocated objects.\n\nvoid doSomething3(void) {\n\nauto_ptr<Node> p (new Node);\n\n// Access the Node as p->...\n\n// Node automatically deleted at end\n\n}\n\nBalancing ResourcesinJava Unlike C++, Java implements a lazy form of automatic object destruc- tion. Unreferenced objects are considered to be candidates for garbage collection, and their finalize method will get called should garbage collection ever claim them. While a convenience for developers, who no longer get the blame for most memory leaks, it makes it difﬁcult to implement resource clean-up using the C++ scheme. Fortunately, the designers of the Java language thoughtfully added a language fea- ture to compensate, the finally clause. When a try block contains a finally clause, code in that clause is guaranteed to be executed if any statement in the try block is executed. It doesn’t matter whether an exception is thrown (or even if the code in the try block executes a return)—the code in the finally clause will get run. This means we can balance our resource usage with code such as\n\npublic void doSomething() throws IOException {\n\nFile tmpFile = new File(tmpFileName); FileWriter tmp = new FileWriter(tmpFile);\n\ntry {\n\n// do some work\n\n} finally {\n\ntmpFile.delete();\n\n}\n\n}\n\nThe routine uses a temporary ﬁle, which we want to delete, regardless of how the routine exits. The finally block allows us to express this concisely.\n\nWhenYou Can’t BalanceResources There are times when the basic resource allocation pattern just isn’t appropriate. Commonly this is found in programs that use dynamic\n\nHOW TO BALANCE RESOURCES\n\ndata structures. One routine will allocate an area of memory and link it into some larger structure, where it may stay for some time.\n\nThe trick here is to establish a semantic invariant for memory alloca- tion. You need to decide who is responsible for data in an aggregate data structure. What happens when you deallocate the top-level structure? You have three main options:\n\n1. The top-level structure is also responsible for freeing any substruc- tures that it contains. These structures then recursively delete data they contain, and so on.\n\n2. The top-level structure is simply deallocated. Any structures that it pointed to (that are not referenced elsewhere) are orphaned.\n\n3. The top-level structure refuses to deallocate itself if it contains any\n\nsubstructures.\n\nThe choice here depends on the circumstances of each individual data structure. However, you need to make it explicit for each, and imple- ment your decision consistently. Implementing any of these options in a procedural language such as C can be a problem: data structures themselves are not active. Our preference in these circumstances is to write a module for each major structure that provides standard alloca- tion and deallocation facilities for that structure. (This module can also provide facilities such as debug printing, serialization, deserialization, and traversal hooks.)\n\nFinally, if keeping track of resources gets tricky, you can write your own form of limited automatic garbage collection by implementing a reference counting scheme on your dynamically allocated objects. The book More Effective C++ [Mey96] dedicates a section to this topic.\n\nChecking theBalance Because Pragmatic Programmers trust no one, including ourselves, we feel that it is always a good idea to build code that actually checks that resources are indeed freed appropriately. For most applications, this normally means producing wrappers for each type of resource, and us- ing these wrappers to keep track of all allocations and deallocations. At certain points in your code, the program logic will dictate that the resources will be in a certain state: use the wrappers to check this.\n\n135\n\nAnswer on p. 292\n\nAnswer on p. 292\n\n136\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nFor example, a long-running program that services requests will prob- ably have a single point at the top of its main processing loop where it waits for the next request to arrive. This is a good place to ensure that resource usage has not increased since the last execution of the loop.\n\nAt a lower, but no less useful level, you can invest in tools that (among other things) check your running programs for memory leaks. Purify (www.rational.com) and Insure++ (www.parasoft.com) are popular choices.\n\nRelated sections include:\n\nDesign by Contract, page 109 Assertive Programming, page 122 Decoupling and the Law of Demeter, page 138\n\nChallenges\n\nAlthough there are no guaranteed ways of ensuring that you always free resources, certain design techniques, when applied consistently, will help. In the text we discussed how establishing a semantic invariant for major data structures could direct memory deallocation decisions. Consider how Design by Contract, page 109, could help reﬁne this idea.\n\nExercises 22. Some C and C++ developers make a point of setting a pointer to NULL after\n\nthey deallocate the memory it references. Why is this a good idea?\n\n23. Some Java developers make a point of setting an object variable to NULL\n\nafter they have ﬁnished using the object. Why is this a good idea?\n\nChapter 5\n\nBend, or Break\n\nLife doesn’t stand still.\n\nNeither can the code that we write. In order to keep up with today’s near-frantic pace of change, we need to make every effort to write code that’s as loose—as ﬂexible—as possible. Otherwise we may ﬁnd our code quickly becoming outdated, or too brittle to ﬁx, and may ultimately be left behind in the mad dash toward the future.\n\nIn Reversibility, on page 44, we talked about the perils of irreversible decisions. In this chapter, we’ll tell you how to make reversible deci- sions, so your code can stay ﬂexible and adaptable in the face of an uncertain world.\n\nFirst we need to look at coupling—the dependencies among modules of code. In Decoupling and the Law of Demeter we’ll show how to keep separate concepts separate, and decrease coupling.\n\nA good way to stay ﬂexible is to write less code. Changing code leaves you open to the possibility of introducing new bugs. Metaprogramming will explain how to move details out of the code completely, where they can be changed more safely and easily.\n\nIn Temporal Coupling, we’ll look at two aspects of time as they relate to coupling. Do you depend on the “tick” coming before the “tock”? Not if you want to stay ﬂexible.\n\nA key concept in creating ﬂexible code is the separation of a data model from a view, or presentation, of that model. We’ll decouple models from views in It’s Just a View.\n\n137\n\n138\n\nCHAPTER 5 BEND, OR BREAK\n\nFinally, there’s a technique for decoupling modules even further by pro- viding a meeting place where modules can exchange data anonymously and asynchronously. This is the topic of Blackboards.\n\nArmed with these techniques, you can write code that will “roll with the punches.”\n\n26 Decoupling and the Law of Demeter\n\nGood fences make good neighbors.\n\nRobert Frost, “Mending Wall”\n\nIn Orthogonality, page 34, and Design by Contract, page 109, we sug- gested that writing “shy” code is beneﬁcial. But “shy” works two ways: don’t reveal yourself to others, and don’t interact with too many people.\n\nSpies, dissidents, revolutionaries, and such are often organized into small groups of people called cells. Although individuals in each cell may know each other, they have no knowledge of those in other cells. If one cell is discovered, no amount of truth serum will reveal the names of others outside the cell. Eliminating interactions between cells pro- tects everyone.\n\nWe feel that this is a good principle to apply to coding as well. Organize your code into cells (modules) and limit the interaction between them. If one module then gets compromised and has to be replaced, the other modules should be able to carry on.\n\nMinimize Coupling What’s wrong with having modules that know about each other? Noth- ing in principle—we don’t need to be as paranoid as spies or dissidents. However, you do need to be careful about how many other modules you interact with and, more importantly, how you came to interact with them.\n\nSuppose you are remodeling your house, or building a house from scratch. A typical arrangement involves a “general contractor.” You hire the contractor to get the work done, but the contractor may or may\n\nDECOUPLING AND THE LAW OF DEMETER\n\nnot do the construction personally; the work may be offered to various subcontractors. But as the client, you are not involved in dealing with the subcontractors directly—the general contractor assumes that set of headaches on your behalf.\n\nWe’d like to follow this same model in software. When we ask an object for a particular service, we’d like the service to be performed on our behalf. We do not want the object to give us a third-party object that we have to deal with to get the required service.\n\nFor example, suppose you are writing a class that generates a graph of scientiﬁc recorder data. You have data recorders spread around the world; each recorder object contains a location object giving its position and time zone. You want to let your users select a recorder and plot its data, labeled with the correct time zone. You might write\n\npublic void plotDate(Date aDate, Selection aSelection) {\n\nTimeZone tz =\n\n...\n\naSelection.getRecorder().getLocation().getTimeZone();\n\n}\n\nBut now the plotting routine is unnecessarily coupled to three classes— Selection, Recorder, and Location. This style of coding dramat- ically increases the number of classes on which our class depends. Why is this a bad thing? It increases the risk that an unrelated change somewhere else in the system will affect your code. For instance, if Fred makes a change to Location such that it no longer directly contains a TimeZone, you have to change your code as well.\n\nRather than digging though a hierarchy yourself, just ask for what you need directly:\n\npublic void plotDate(Date aDate, TimeZone aTz) {\n\n...\n\n}\n\nplotDate(someDate, someSelection.getTimeZone());\n\nWe added a method to Selection to get the time zone on our behalf: the plotting routine doesn’t care whether the time zone comes from the Recorder directly, from some contained object within Recorder, or whether Selection makes up a different time zone entirely. The selection routine, in turn, should probably just ask the recorder for its time zone, leaving it up to the recorder to get it from its contained Location object.\n\n139\n\n140\n\nCHAPTER 5 BEND, OR BREAK\n\nTraversing relationships between objects directly can quickly lead to a combinatorial explosion1 of dependency relationships. You can see symptoms of this phenomenon in a number of ways:\n\n1. Large C or C++ projects where the command to link a unit test is\n\nlonger than the test program itself\n\n2. “Simple” changes to one module that propagate through unrelated\n\nmodules in the system\n\n3. Developers who are afraid to change code because they aren’t sure\n\nwhat might be affected\n\nSystems with many unnecessary dependencies are very hard (and ex- pensive) to maintain, and tend to be highly unstable. In order to keep the dependencies to a minimum, we’ll use the Law of Demeter to design our methods and functions.\n\nTheLawof Demeterfor Functions The Law of Demeter for functions [LH89] attempts to minimize coupling between modules in any given program. It tries to prevent you from reaching into an object to gain access to a third object’s methods. The law is summarized in Figure 5.1 on the next page.\n\nBy writing “shy” code that honors the Law of Demeter as much as pos- sible, we can achieve our objective:\n\nTIP 36\n\nMinimize Coupling Between Modules\n\nDoes ItReallyMakea Difference? While it sounds good in theory, does following the Law of Demeter really help to create more maintainable code?\n\nStudies have shown [BBM96] that classes in C++ with larger response sets are more prone to error than classes with smaller response sets (a\n\n1. If in the other\n\nobjects all know about each other, then a change to just one object can result\n\nobjects needing changes.",
      "page_number": 157
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 165-173)",
      "start_page": 165,
      "end_page": 173,
      "detection_method": "topic_boundary",
      "content": "DECOUPLING AND THE LAW OF DEMETER\n\nFigure 5.1. Law of Demeter for functions\n\nclass Demeter { private: A *a; int func();\n\npublic:\n\n//... void example(B& b);\n\nThe Law of Demeter for functions states that any method of an object should call only methods belonging to:\n\n}\n\nvoid Demeter::example(B& b) {\n\nC c; int f = func();\n\nitself\n\nb.invert();\n\nany parameters that were passed in to the method\n\na = new A();\n\na->setActive();\n\nany objects it created\n\nc.print();\n\nany directly held component objects\n\n}\n\nresponse set is deﬁned to be the number of functions directly invoked by methods of the class).\n\nBecause following the Law of Demeter reduces the size of the response set in the calling class, it follows that classes designed in this way will also tend to have fewer errors (see [URL 56] for more papers and information on the Demeter project).\n\nUsing The Law of Demeter will make your code more adaptable and robust, but at a cost: as a “general contractor,” your module must dele- gate and manage any and all subcontractors directly, without involving clients of your module. In practice, this means that you will be writing a large number of wrapper methods that simply forward the request on to a delegate. These wrapper methods will impose both a runtime cost and a space overhead, which may be signiﬁcant—even prohibitive—in some applications.\n\nAs with any technique, you must balance the pros and cons for your particular application. In database schema design it is common prac- tice to “denormalize” the schema for a performance improvement: to\n\n141\n\n142\n\nCHAPTER 5 BEND, OR BREAK\n\nPhysical Decoupling\n\nIn this section we’re concerned largely with designing to keep things logically decoupled within systems. However, there is another kind of interdependence that becomes highly signiﬁcant as systems grow larger. In his book Large-ScaleC++SoftwareDesign [Lak96], John Lakos addresses the issues surrounding the relationships among the ﬁles, directories, and libraries that make up a system. Large projects that ignore thesephysicaldesignproblems wind up with build cycles that are measured in days and unit tests that may drag in the entire system as support code, among other problems. Mr. Lakos argues convincingly that logical and physical design must proceed in tandem—that undoing the damage done to a large body of code by cyclic dependencies is extremely difﬁcult. We recommend this book if you are involved in large-scale developments, even if C++ isn’t your implementation language.\n\nviolate the rules of normalization in exchange for speed. A similar trade- off can be made here as well. In fact, by reversing the Law of Demeter and tightly coupling several modules, you may realize an important performance gain. As long as it is well known and acceptable for those modules to be coupled, your design is ﬁne.\n\nOtherwise, you may ﬁnd yourself on the road to a brittle, inﬂexible future. Or no future at all.\n\nRelated sections include: Orthogonality, page 34 Reversibility, page 44 Design by Contract, page 109 How to Balance Resources, page 129 It’s Just a View, page 157 Pragmatic Teams, page 224 Ruthless Testing, page 237\n\nChallenges\n\nWe’ve discussed how using delegation makes it easier to obey the Law of Demeter and hence reduce coupling. However, writing all of the methods\n\nDECOUPLING AND THE LAW OF DEMETER\n\n143\n\nneeded to forward calls to delegated classes is boring and error prone. What are the advantages and disadvantages of writing a preprocessor that generates these calls automatically? Should this preprocessor be run only once, or should it be used as part of the build?\n\nExercises 24. We discussed the concept of physical decoupling in the box on on the facing page. Which of the following C++ header ﬁles is more tightly coupled to the rest of the system?\n\nperson1.h:\n\nperson2.h:\n\n#include \"date.h\"\n\nclass Date;\n\nclass Person1 { private:\n\nclass Person2 { private:\n\nDate myBirthdate;\n\nDate *myBirthdate;\n\npublic:\n\npublic:\n\nPerson1(Date &birthDate); // ...\n\nPerson2(Date &birthDate); // ...\n\n25. For the example below and for those in Exercises 26 and 27, determine if the method calls shown are allowed according to the Law of Demeter. This ﬁrst one is in Java. public void showBalance(BankAccount acct) {\n\nMoney amt = acct.getBalance(); printToScreen(amt.printFormat());\n\n}\n\n26. This example is also in Java.\n\npublic class Colada {\n\nprivate Blender myBlender; private Vector myStuff;\n\npublic Colada() {\n\nmyBlender = new Blender(); myStuff = new Vector();\n\n} private void doSomething() {\n\nmyBlender.addIngredients(myStuff.elements());\n\n}\n\n}\n\n27. This example is in C++.\n\nvoid processTransaction(BankAccount acct, int) {\n\nPerson *who; Money amt;\n\namt.setValue(123.45); acct.setBalance(amt); who = acct.getOwner(); markWorkflow(who->name(), SET_BALANCE);\n\n}\n\nAnswer on p. 293\n\nAnswer on p. 294\n\nAnswer on p. 294\n\n144\n\nCHAPTER 5 BEND, OR BREAK\n\n27 Metaprogramming\n\nNo amount of genius can overcome a preoccupation with detail.\n\nLevy’s Eighth Law\n\nDetails mess up our pristine code—especially if they change frequently. Every time we have to go in and change the code to accommodate some change in business logic, or in the law, or in management’s personal tastes of the day, we run the risk of breaking the system—of introducing a new bug.\n\nSo we say “out with the details!” Get them out of the code. While we’re at it, we can make our code highly conﬁgurable and “soft”—that is, easily adaptable to changes.\n\nDynamic Conﬁguration First, we want to make our systems highly conﬁgurable. Not just things such as screen colors and prompt text, but deeply ingrained items such as the choice of algorithms, database products, middleware technology, and user-interface style. These items should be implemented as con- ﬁguration options, not through integration or engineering.\n\nTIP 37\n\nConﬁgure, Don’t Integrate\n\nUse metadata to describe conﬁguration options for an application: tun- ing parameters, user preferences, the installation directory, and so on.\n\nWhat exactly is metadata? Strictly speaking, metadata is data about data. The most common example is probably a database schema or data dictionary. A schema contains data that describes ﬁelds (columns) in terms of names, storage lengths, and other attributes. You should be able to access and manipulate this information just as you would any other data in the database.\n\nWe use the term in its broadest sense. Metadata is any data that describes the application—how it should run, what resources it should use, and so on. Typically, metadata is accessed and used at runtime, not at compile time. You use metadata all the time—at least your pro- grams do. Suppose you click on an option to hide the toolbar on your\n\nMETAPROGRAMMING\n\nWeb browser. The browser will store that preference, as metadata, in some sort of internal database.\n\nThis database might be in a proprietary format, or it might use a stan- dard mechanism. Under Windows, either an initialization ﬁle (using the sufﬁx .ini) or entries in the system Registry are typical. Under Unix, the X Window System provides similar functionality using Application Default ﬁles. Java uses Property ﬁles. In all of these environments, you specify a key to retrieve a value. Alternatively, more powerful and ﬂex- ible implementations of metadata use an embedded scripting language (see Domain Languages, page 57, for details).\n\nThe Netscape browser has actually implemented preferences using both of these techniques. In Version 3, preferences were saved as simple key/value pairs:\n\nSHOW_TOOLBAR: False\n\nLater, Version 4 preferences looked more like JavaScript:\n\nuser_pref(\"custtoolbar.Browser.Navigation_Toolbar.open\", false);\n\nMetadata-DrivenApplications But we want to go beyond using metadata for simple preferences. We want to conﬁgure and drive the application via metadata as much as possible. Our goal is to think declaratively (specifying what is to be done, not how) and create highly dynamic and adaptable programs. We do this by adopting a general rule: program for the general case, and put the speciﬁcs somewhere else—outside the compiled code base.\n\nTIP 38\n\nPut Abstractions in Code, Details in Metadata\n\nThere are several beneﬁts to this approach:\n\nIt forces you to decouple your design, which results in a more ﬂex- ible and adaptable program.\n\nIt forces you to create a more robust, abstract design by deferring details—deferring them all the way out of the program.\n\n145\n\n146\n\nCHAPTER 5 BEND, OR BREAK\n\nYou can customize the application without recompiling it. You can also use this level of customization to provide easy work-arounds for critical bugs in live production systems.\n\nMetadata can be expressed in a manner that’s much closer to the problem domain than a general-purpose programming language might be (see Domain Languages, page 57).\n\nYou may even be able to implement several different projects using the same application engine, but with different metadata.\n\nWe want to defer deﬁnition of most details until the last moment, and leave the details as soft—as easy to change—as we can. By crafting a solution that allows us to make changes quickly, we stand a better chance of coping with the ﬂood of directional shifts that swamp many projects (see Reversibility, page 44).\n\nBusinessLogic So you’ve made the choice of database engine a conﬁguration option, and provided metadata to determine the user-interface style. Can we do more? Deﬁnitely.\n\nBecause business policy and rules are more likely to change than any other aspect of the project, it makes sense to maintain them in a very ﬂexible format.\n\nFor example, your purchasing application may include various corpo- rate policies. Maybe you pay small suppliers in 45 days and large ones in 90 days. Make the deﬁnitions of the supplier types, as well as the time periods themselves, conﬁgurable. Take the opportunity to gener- alize.\n\nMaybe you are writing a system with horrendous workﬂow require- ments. Actions start and stop according to complex (and changing) business rules. Consider encoding them in some kind of rule-based (or expert) system, embedded within your application. That way, you’ll conﬁgure it by writing rules, not cutting code.\n\nLess complex logic can be expressed using a mini-language, removing the need to recompile and redeploy when the environment changes. Have a look at page 58 for an example.\n\nMETAPROGRAMMING\n\nWhen to Conﬁgure\n\nAs mentioned in ThePowerofPlainText, page 73, we recommend representing conﬁguration metadata in plain text—it makes life that much easier.\n\nBut when should a program read this conﬁguration? Many programs will scan such things only at startup, which is unfortunate. If you need to change the conﬁguration, this forces you to restart the application. A more ﬂexible approach is to write programs that can reload their conﬁguration while they’re running. This ﬂexibility comes at a cost: it is more complex to implement.\n\nSo consider how your application will be used: if it is a long-running server process, you will want to provide some way to reread and apply metadata while the program is running. For a small client GUI appli- cation that restarts quickly, you may not need to.\n\nThis phenomenon is not limited to application code. We’ve all been annoyed at operating systems that force us to reboot when we install some simple application or change an innocuous parameter.\n\nAn Example:Enterprise JavaBeans Enterprise Java Beans (EJB) is a framework for simplifying program- ming in a distributed, transaction-based environment. We mention it here because EJB illustrates how metadata can be used both to conﬁg- ure applications and to reduce the complexity of writing code.\n\nSuppose you want to create some Java software that will participate in transactions across different machines, between different database vendors, and with different thread and load-balancing models.\n\nThe good news is, you don’t have to worry about all that. You write a bean—a self-contained object that follows certain conventions—and place it in a bean container that manages much of the low-level detail on your behalf. You can write the code for a bean without including any transaction operations or thread management; EJB uses metadata to specify how transactions should be handled.\n\nThread allocation and load balancing are speciﬁed as metadata to the underlying transaction service that the container uses. This separation\n\n147\n\n148\n\nCHAPTER 5 BEND, OR BREAK\n\nallows us great ﬂexibility to conﬁgure the environment dynamically, at runtime.\n\nThe bean’s container can manage transactions on the bean’s behalf in one of several different styles (including an option where you control your own commits and rollbacks). All of the parameters that affect the bean’s behavior are speciﬁed in the bean’s deployment descriptor—a serialized object that contains the metadata we need.\n\nDistributed systems such as EJB are leading the way into a new world of conﬁgurable, dynamic systems.\n\nCooperativeConﬁguration We’ve talked about users and developers conﬁguring dynamic applica- tions. But what happens if you let applications conﬁgure each other— software that adapts itself to its environment? Unplanned, spur-of-the- moment conﬁguration of existing software is a powerful concept.\n\nOperating systems already conﬁgure themselves to hardware as they boot, and Web browsers update themselves with new components auto- matically.\n\nYour larger applications probably already have issues with handling dif- ferent versions of data and different releases of libraries and operating systems. Perhaps a more dynamic approach will help.\n\nDon’t WriteDodo-Code Without metadata, your code is not as adaptable or ﬂexible as it could be. Is this a bad thing? Well, out here in the real world, species that don’t adapt die.\n\nThe dodo didn’t adapt to the presence of humans and their livestock on the island of Mauritius, and quickly became extinct.2 It was the ﬁrst documented extinction of a species at the hand of man.\n\nDon’t let your project (or your career) go the way of the dodo.\n\n2. for sport.\n\nIt didn’t help that the settlers beat the placid (read stupid) birds to death with clubs\n\nMETAPROGRAMMING\n\nRelated sections include: Orthogonality, page 34 Reversibility, page 44 Domain Languages, page 57 The Power of Plain Text, page 73\n\nChallenges\n\nFor your current project, consider how much of the application might be moved out of the program itself to metadata. What would the resultant “engine” look like? Would you be able to reuse that engine in the context of a different application?\n\nExercises 28. Which of the following things would be better represented as code within\n\na program, and which externally as metadata?\n\n1. Communication port assignments\n\n2. An editor’s support for highlighting the syntax of various languages\n\n3. An editor’s support for different graphic devices\n\n4. A state machine for a parser or scanner\n\n5. Sample values and results for use in unit testing\n\n149\n\nAnswer on p. 295",
      "page_number": 165
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 174-181)",
      "start_page": 174,
      "end_page": 181,
      "detection_method": "topic_boundary",
      "content": "28\n\n150\n\nCHAPTER 5 BEND, OR BREAK\n\nTemporal Coupling\n\nWhat is temporal coupling all about, you may ask. It’s about time.\n\nTime is an often ignored aspect of software architectures. The only time that preoccupies us is the time on the schedule, the time left until we ship—but this is not what we’re talking about here. Instead, we are talking about the role of time as a design element of the software itself. There are two aspects of time that are important to us: concurrency (things happening at the same time) and ordering (the relative positions of things in time).\n\nWe don’t usually approach programming with either of these aspects in mind. When people ﬁrst sit down to design an architecture or write a program, things tend to be linear. That’s the way most people think— do this and then always do that. But thinking this way leads to tempo- ral coupling: coupling in time. Method A must always be called before method B; only one report can be run at a time; you must wait for the screen to redraw before the button click is received. Tick must happen before tock.\n\nThis approach is not very ﬂexible, and not very realistic.\n\nWe need to allow for concurrency3 and to think about decoupling any time or order dependencies. In doing so, we can gain ﬂexibility and reduce any time-based dependencies in many areas of development: workﬂow analysis, architecture, design, and deployment.\n\nWorkﬂow On many projects, we need to model and analyze the users’ workﬂows as part of requirements analysis. We’d like to ﬁnd out what can happen at the same time, and what must happen in a strict order. One way to do this is to capture their description of workﬂow using a notation such as the UML activity diagram.4\n\n3. We won’t go into the details of concurrent or parallel programming here; a good computer science textbook should cover the basics, including scheduling, deadlock, star- vation, mutual exclusion/semaphores, and so on.\n\n4.\n\nFor more information on all of the UML diagram types, see [FS97].\n\nTEMPORAL COUPLING\n\nAn activity diagram consists of a set of actions drawn as rounded boxes. The arrow leaving an action leads to either another action (which can start once the ﬁrst action completes) or to a thick line called a synchro- nization bar. Once all the actions leading into a synchronization bar are complete, you can then proceed along any arrows leaving the bar. An action with no arrows leading into it can be started at any time.\n\nYou can use activity diagrams to maximize parallelism by identifying activities that could be performed in parallel, but aren’t.\n\nTIP 39\n\nAnalyze Workﬂow to Improve Concurrency\n\nFor instance, in our blender project (Exercise 17, page 119), users may initially describe their current workﬂow as follows.\n\n1. Open blender 2. Open piña colada mix 3. Put mix in blender 4. Measure 1/2 cup white rum 5. Pour in rum 6. Add 2 cups of ice 7. Close blender 8. Liquefy for 2 minutes 9. Open blender\n\n10. Get glasses 11. Get pink umbrellas 12. Serve\n\nEven though they describe these actions serially, and may even per- form them serially, we notice that many of them could be performed in parallel, as we show in the activity diagram in Figure 5.2 on the next page.\n\nIt can be eye-opening to see where the dependencies really exist. In this instance, the top-level tasks (1, 2, 4, 10, and 11) can all happen concurrently, up front. Tasks 3, 5, and 6 can happen in parallel later.\n\nIf you were in a piña colada-making contest, these optimizations may make all the difference.\n\n151\n\n152\n\nCHAPTER 5 BEND, OR BREAK\n\nFigure 5.2. UML activity diagram: making a piña colada\n\n2.\n\nOpen mix\n\n1.\n\nOpen blender\n\n4.\n\nMeasure rum\n\n3.\n\nPut mix in\n\n6.\n\nAdd two cups ice\n\n5.\n\nPour in rum\n\n7.\n\nClose blender\n\n11.\n\nGet pink umbrellas\n\n8.\n\nLiquefy\n\n10.\n\nGet glasses\n\n9.\n\nOpen blender\n\n12.\n\nServe\n\nArchitecture We wrote an On-Line Transaction Processing (OLTP) system a few years ago. At its simplest, all the system had to do was read a request and process the transaction against the database. But we wrote a three- tier, multiprocessing distributed application: each component was an independent entity that ran concurrently with all other components. While this sounds like more work, it wasn’t: taking advantage of tem- poral decoupling made it easier to write. Let’s take a closer look at this project.\n\nThe system takes in requests from a large number of data communica- tion lines and processes transactions against a back-end database.\n\nThe design addresses the following constraints:\n\nTEMPORAL COUPLING\n\nFigure 5.3. OLTP architecture overview\n\nInput task #1\n\nApp’n\n\nApp. logic #1\n\nDatabase\n\nInput task #2\n\nDatabase handler\n\nQueue\n\nApp. logic #n\n\nQueue\n\nInput task #n\n\nDatabase operations take a relatively long time to complete.\n\nFor each transaction, we must not block communication services while a database transaction is being processed.\n\nDatabase performance suffers with too many concurrent sessions.\n\nMultiple transactions are in progress concurrently on each data line.\n\nThe solution that gave us the best performance and cleanest architec- ture looked something like Figure 5.3.\n\nEach box represents a separate process; processes communicate via work queues. Each input process monitors one incoming communica- tion line, and makes requests to the application server. All requests are asynchronous: as soon as the input process makes its current request, it goes back to monitoring the line for more trafﬁc. Similarly, the appli- cation server makes requests of the database process,5 and is notiﬁed when the individual transaction is complete.\n\nThis example also shows a way to get quick and dirty load balancing among multiple consumer processes: the hungry consumer model.\n\n5. Even though we show the database as a single, monolithic entity, it is not. The database software is partitioned into several processes and client threads, but this is handled internally by the database software and isn’t part of our example.\n\n153\n\n154\n\nCHAPTER 5 BEND, OR BREAK\n\nIn a hungry consumer model, you replace the central scheduler with a number of independent consumer tasks and a centralized work queue. Each consumer task grabs a piece from the work queue and goes on about the business of processing it. As each task ﬁnishes its work, it goes back to the queue for some more. This way, if any particular task gets bogged down, the others can pick up the slack, and each individual component can proceed at its own pace. Each component is temporally decoupled from the others.\n\nTIP 40\n\nDesign Using Services\n\nInstead of components, we have really created services—independent, concurrent objects behind well-deﬁned, consistent interfaces.\n\nDesign for Concurrency The rising acceptance of Java as a platform has exposed more devel- opers to multithreaded programming. But programming with threads imposes some design constraints—and that’s a good thing. Those con- straints are actually so helpful that we want to abide by them whenever we program. It will help us decouple our code and ﬁght programming by coincidence (see page 172).\n\nWith linear code, it’s easy to make assumptions that lead to sloppy programming. But concurrency forces you to think through things a bit more carefully—you’re not alone at the party anymore. Because things can now happen at the “same time,” you may suddenly see some time- based dependencies.\n\nTo begin with, any global or static variables must be protected from concurrent access. Now may be a good time to ask yourself why you need a global variable in the ﬁrst place. In addition, you need to make sure that you present consistent state information, regardless of the order of calls. For example, when is it valid to query the state of your object? If your object is in an invalid state between certain calls, you may be relying on a coincidence that no one can call your object at that point in time.\n\nTEMPORAL COUPLING\n\nSuppose you have a windowing subsystem where the widgets are ﬁrst created and then shown on the display in two separate steps. You aren’t allowed to set state in the widget until it is shown. Depending on how the code is set up, you may be relying on the fact that no other object can use the created widget until you’ve shown it on the screen.\n\nBut this may not be true in a concurrent system. Objects must always be in a valid state when called, and they can be called at the most awk- ward times. You must ensure that an object is in a valid state any time it could possibly be called. Often this problem shows up with classes that deﬁne separate constructor and initialization routines (where the constructor doesn’t leave the object in an initialized state). Using class invariants, discussed in Design by Contract, page 109, will help you avoid this trap.\n\nCleanerInterfaces Thinking about concurrency and time-ordered dependencies can lead you to design cleaner interfaces as well. Consider the C library routine strtok, which breaks a string into tokens.\n\nThe design of strtok isn’t thread safe,6 but that isn’t the worst part: look at the time dependency. You must make the ﬁrst call to strtok with the variable you want to parse, and all successive calls with a NULL instead. If you pass in a non-NULL value, it restarts the parse on that buffer instead. Without even considering threads, suppose you wanted to use strtok to parse two separate strings at the same time:\n\nchar buf1[BUFSIZ]; char buf2[BUFSIZ]; char *p, *q;\n\nstrcpy(buf1, \"this is a test\"); strcpy(buf2, \"this ain’t gonna work\");\n\np = strtok(buf1, \" \"); q = strtok(buf2, \" \"); while (p && q) {\n\nprintf(\"%s %s n\", p, q); p = strtok(NULL, \" \"); q = strtok(NULL, \" \");\n\n}\n\n6. It uses static data to maintain the current position in the buffer. The static data isn’t protected against concurrent access, so it isn’t thread safe. In addition, it clobbers the ﬁrst argument you pass in, which can lead to some nasty surprises.\n\n155\n\n156\n\nCHAPTER 5 BEND, OR BREAK\n\nThe code as shown will not work: there is implicit state retained in strtok between calls. You have to use strtok on just one buffer at a time.\n\nNow in Java, the design of a string parser has to be different. It must be thread safe and present a consistent state.\n\nStringTokenizer st1 = new StringTokenizer(\"this is a test\"); StringTokenizer st2 = new StringTokenizer(\"this test will work\");\n\nwhile (st1.hasMoreTokens() && st2.hasMoreTokens()) {\n\nSystem.out.println(st1.nextToken()); System.out.println(st2.nextToken());\n\n}\n\nStringTokenizer is a much cleaner, more maintainable, interface. It contains no surprises, and won’t cause mysterious bugs in the future, as strtok might.\n\nTIP 41\n\nAlways Design for Concurrency\n\nDeployment Once you’ve designed an architecture with an element of concurrency, it becomes easier to think about handling many concurrent services: the model becomes pervasive.\n\nNow you can be ﬂexible as to how the application is deployed: stand- alone, client-server, or n-tier. By architecting your system as inde- pendent services, you can make the conﬁguration dynamic as well. By planning for concurrency, and decoupling operations in time, you have all these options—including the stand-alone option, where you can choose not to be concurrent.\n\nGoing the other way (trying to add concurrency to a nonconcurrent application) is much harder. If we design to allow for concurrency, we can more easily meet scalability or performance requirements when the time comes—and if the time never comes, we still have the beneﬁt of a cleaner design.\n\nIsn’t it about time?\n\n29\n\nIT’S JUST A VIEW\n\nRelated sections include:\n\nDesign by Contract, page 109 Programming by Coincidence, page 172\n\nChallenges\n\nHow many tasks do you perform in parallel when you get ready for work in the morning? Could you express this in a UML activity diagram? Can you ﬁnd some way to get ready more quickly by increasing concurrency?\n\nIt’s Just a View\n\nStill, a man hears What he wants to hear And disregards the rest La la la. ..\n\nSimon and Garfunkel, “The Boxer”\n\nEarly on we are taught not to write a program as a single big chunk, but that we should “divide and conquer” and separate a program into mod- ules. Each module has its own responsibilities; in fact, a good deﬁnition of a module (or class) is that it has a single, well-deﬁned responsibility.\n\nBut once you separate a program into different modules based on responsibility, you have a new problem. At runtime, how do the objects talk to each other? How do you manage the logical dependencies between them? That is, how do you synchronize changes in state (or updates to data values) in these different objects? It needs to be done in a clean, ﬂexible manner—we don’t want them to know too much about each other. We want each module to be like the man in the song and just hear what it wants to hear.\n\nWe’ll start off with the concept of an event. An event is simply a special message that says “something interesting just happened” (interesting, of course, lies in the eye of the beholder). We can use events to signal changes in one object that some other object may be interested in.\n\nUsing events in this way minimizes coupling between those objects— the sender of the event doesn’t need to have any explicit knowledge of\n\n157",
      "page_number": 174
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 182-189)",
      "start_page": 182,
      "end_page": 189,
      "detection_method": "topic_boundary",
      "content": "158\n\nCHAPTER 5 BEND, OR BREAK\n\nthe receiver. In fact, there could be multiple receivers, each one focused on its own agenda (of which the sender is blissfully unaware).\n\nWe need to exercise some care in using events, however. In an early ver- sion of Java, for example, one routine received all the events destined for a particular application. Not exactly the road to easy maintenance or evolution.\n\nPublish/Subscribe Why is it bad to push all the events through a single routine? It vio- lates object encapsulation—that one routine now has to have intimate knowledge of the interactions among many objects. It also increases the coupling—and we’re trying to decrease coupling. Because the objects themselves have to have knowledge of these events as well, you are probably going to violate the DRY principle, orthogonality, and perhaps even sections of the Geneva Convention. You may have seen this kind of code—it is usually dominated by a huge case statement or multiway if-then. We can do better.\n\nObjects should be able to register to receive only the events they need, and should never be sent events they don’t need. We don’t want to spam our objects! Instead, we can use a publish/subscribe protocol, illustrated using the UML sequence diagram in Figure 5.4 on the next page.7\n\nA sequence diagram shows the ﬂow of messages among several objects, with objects arranged in columns. Each message is shown as a labeled arrow from the sender’s column to the receiver’s column. An asterisk in the label means that more than one message of this type can be sent.\n\nIf we are interested in certain events generated by a Publisher, all we have to do is register ourselves. The Publisher keeps track of all in- terested Subscriber objects; when the Publisher generates an event of interest, it will call each Subscriber in turn and notify them that the event has occurred.\n\n7.\n\nSee also the Observer pattern in [GHJV95] for more information.\n\nIT’S JUST A VIEW\n\nFigure 5.4. Publish/subscribe protocol\n\nSubscriber one\n\nSubscriber two\n\nPublisher\n\nregister\n\nnotify*\n\nregister\n\nnotify*\n\nnotify*\n\nunsubscribe\n\nnotify*\n\nThere are several variations on this theme—mirroring other commu- nication styles. Objects may use publish/subscribe on a peer-to-peer basis (as we saw above); they may use a “software bus” where a centralized object maintains the database of listeners and dispatches messages appropriately. You might even have a scheme where critical events get broadcast to all listeners—registered or not. One possible implementation of events in a distributed environment is illustrated by the CORBA Event Service, described in the box on the following page.\n\nWe can use this publish/subscribe mechanism to implement a very important design concept: the separation of a model from views of the model. Let’s start with a GUI-based example, using the Smalltalk design in which this concept was born.\n\nModel-View-Controller Suppose you have a spreadsheet application. In addition to the num- bers in the spreadsheet itself, you also have a graph that displays the\n\n159\n\n160\n\nCHAPTER 5 BEND, OR BREAK\n\nThe CORBA Event Service\n\nThe CORBA Event Service allows participating objects to send and receive event notiﬁcations via a common bus, the eventchannel. The event channel arbitrates event handling, and also decouples event producers from event consumers. It works in two basic ways: push and pull.\n\nIn push mode, event suppliers inform the event channel that an event has occurred. The channel then automatically distributes that event to all client objects that have registered interest.\n\nIn pull mode, clients periodically poll the event channel, which in turn polls the supplier that offers event data corresponding to the request.\n\nAlthough the CORBA Event Service can be used to implement all of the event models discussed in this section, you can also view it as a different animal. CORBA facilitates communication among objects written in different programming languages running on geographi- cally dispersed machines with different architectures. Sitting on top of CORBA, the event service gives you a decoupled way of interact- ing with applications around the world, written by people you’ve never met, using programming languages you’d rather not know about.\n\nnumbers as a bar chart and a running total dialog box that shows the sum of a column in the spreadsheet.\n\nObviously, we don’t want to have three separate copies of the data. So we create a model—the data itself, with common operations to manip- ulate it. Then we can create separate views that display the data in different ways: as a spreadsheet, as a graph, or in a totals box. Each of these views may have its own controller. The graph view may have a controller that allows you to zoom in or out, or pan around the data, for example. None of this affects the data itself, just that view.\n\nThis is the key concept behind the Model-View-Controller (MVC) idiom: separating the model from both the GUI that represents it and the con- trols that manage the view.8\n\n8. the view and controller are a single component.\n\nThe view and controller are tightly coupled, and in some implementations of MVC\n\nIT’S JUST A VIEW\n\nBy doing so, you can take advantage of some interesting possibilities. You can support multiple views of the same data model. You can use common viewers on many different data models. You can even support multiple controllers to provide nontraditional input mechanisms.\n\nTIP 42\n\nSeparate Views from Models\n\nBy loosening the coupling between the model and the view/controller, you buy yourself a lot of ﬂexibility at low cost. In fact, this technique is one of the most important ways of maintaining reversibility (see Reversibility, page 44).\n\nJavaTree View A good example of an MVC design can be found in the Java tree widget. The tree widget (which displays a clickable, traversable tree) is actually a set of several different classes organized in an MVC pattern.\n\nTo produce a fully functional tree widget, all you need to do is provide a data source that conforms to the TreeModel interface. Your code now becomes the model for the tree.\n\nThe view is created by the TreeCellRenderer and TreeCellEditor classes, which can be inherited from and customized to provide differ- ent colors, fonts, and icons in the widget. JTree acts as the controller for the tree widget and provides some general viewing functionality.\n\nBecause we have decoupled the model from the view, we simplify the programming a great deal. You don’t have to think about programming a tree widget anymore. Instead, you just provide a data source.\n\nSuppose the vice president comes up to you and wants a quick appli- cation that lets her navigate the company’s organizational chart, which is held in a legacy database on the mainframe. Just write a wrapper that takes the mainframe data, presents it as a TreeModel, and voilà: you have a fully navigable tree widget.\n\nNow you can get fancy and start using the viewer classes; you can change how nodes are rendered, and use special icons, fonts, or colors. When the VP comes back and says the new corporate standards dictate\n\n161\n\n162\n\nCHAPTER 5 BEND, OR BREAK\n\nthe use of a Skull and Crossbones icon for certain employees, you can make the changes to TreeCellRenderer without touching any other code.\n\nBeyond GUIs While MVC is typically taught in the context of GUI development, it is really a general-purpose programming technique. The view is an inter- pretation of the model (perhaps a subset)—it doesn’t need to be graph- ical. The controller is more of a coordination mechanism, and doesn’t have to be related to any sort of input device.\n\nModel. The abstract data model representing the target object. The model has no direct knowledge of any views or controllers.\n\nView. A way to interpret the model. It subscribes to changes in the model and logical events from the controller.\n\nController. A way to control the view and provide the model with new data. It publishes events to both the model and the view.\n\nLet’s look at a nongraphical example.\n\nBaseball is a unique institution. Where else can you learn such gems of trivia as “this has become the highest-scoring game played on a Tues- day, in the rain, under artiﬁcial lights, between teams whose names start with a vowel?” Suppose we were charged with developing software to support those intrepid announcers who must dutifully report on the scores, the statistics, and the trivia.\n\nClearly we need information on the game in progress—the teams play- ing, the conditions, the player at bat, the score, and so on. These facts form our models; they will be updated as new information arrives (a pitcher is changed, a player strikes out, it starts raining\n\n).\n\nWe’ll then have a number of view objects that use these models. One view might look for runs so it can update the current score. Another may receive notiﬁcations of new batters, and retrieve a brief summary of their year-to-date statistics. A third viewer may look at the data and check for new world records. We might even have a trivia viewer, responsible for coming up with those weird and useless facts that thrill the viewing public.\n\nIT’S JUST A VIEW\n\nFigure 5.5. Baseball reporting. Viewers subscribetomodels.\n\nScore collector\n\nTV feed generator\n\nScores\n\nBatter stats\n\nDisplay ﬁlter\n\nWeb page formatter\n\nRecords\n\nConditions\n\nTrivia\n\nTele- prompter\n\nsubscribes to\n\nmodel\n\nviewer\n\nBut we don’t want to ﬂood the poor announcer with all of these views directly. Instead, we’ll have each view generate notiﬁcations of “inter- esting” events, and let some higher-level object schedule what gets shown.9\n\nThese viewer objects have suddenly become models for the higher-level object, which itself might then be a model for different formatting view- ers. One formatting viewer might create the teleprompter script for the announcer, another might generate video captions directly on the satel- lite uplink, another might update the network’s or team’s Web pages (see Figure 5.5).\n\nThis kind of model-viewer network is a common (and valuable) design technique. Each link decouples raw data from the events that created it—each new viewer is an abstraction. And because the relationships are a network (not just a linear chain), we have a lot of ﬂexibility. Each\n\n9. plane to ﬂy overhead that night.\n\nThe fact that a plane ﬂies overhead probably isn’t interesting unless it’s the 100th\n\n163\n\nAnswer on p. 296\n\n164\n\nCHAPTER 5 BEND, OR BREAK\n\nmodel may have many viewers, and one viewer may work with multiple models.\n\nIn advanced systems such as this one, it can be handy to have de- bugging views—specialized views that show you in-depth details of the model. Adding a facility to trace individual events can be a great time saver as well.\n\nStill Coupled (After All TheseYears) Despite the decrease in coupling we have achieved, listeners and event generators (subscribers and publishers) still have some knowledge of each other. In Java, for instance, they must agree on common interface deﬁnitions and calling conventions.\n\nIn the next section, we’ll look at ways of reducing coupling even further by using a form of publish and subscribe where none of the participants need know about each other, or call each other directly.\n\nRelated sections include: Orthogonality, page 34 Reversibility, page 44 Decoupling and the Law of Demeter, page 138 Blackboards, page 165 It’s All Writing, page 248\n\nExercises 29. Suppose you have an airline reservation system that includes the concept\n\nof a ﬂight:\n\npublic interface Flight {\n\n// Return false if flight full. public boolean addPassenger(Passenger p); public void addToWaitList(Passenger p); public int getFlightCapacity(); public int getNumPassengers();\n\n}\n\nIf you add a passenger to the wait list, they’ll be put on the ﬂight automat- ically when an opening becomes available.\n\nBLACKBOARDS\n\nThere’s a massive reporting job that goes through looking for overbooked or full ﬂights to suggest when additional ﬂights might be scheduled. It works ﬁne, but it takes hours to run.\n\nWe’d like to have a little more ﬂexibility in processing wait-list passengers, and we’ve got to do something about that big report—it takes too long to run. Use the ideas from this section to redesign this interface.\n\n30 Blackboards\n\nThe writing is on the wall...\n\nYou may not usually associate elegance with police detectives, pictur- ing instead some sort of doughnut and coffee cliché. But consider how detectives might use a blackboard to coordinate and solve a murder investigation.\n\nSuppose the chief inspector starts off by setting up a large blackboard in the conference room. On it, he writes a single question:\n\nH. DUMPTY (MALE, EGG): ACCIDENT OR MURDER?\n\nDid Humpty really fall, or was he pushed? Each detective may make contributions to this potential murder mystery by adding facts, state- ments from witnesses, any forensic evidence that might arise, and so on. As the data accumulates, a detective might notice a connection and post that observation or speculation as well. This process continues, across all shifts, with many different people and agents, until the case is closed. A sample blackboard is shown in Figure 5.6 on the next page.\n\nSome key features of the blackboard approach are:\n\nNone of the detectives needs to know of the existence of any other detective—they watch the board for new information, and add their ﬁndings.\n\nThe detectives may be trained in different disciplines, may have different levels of education and expertise, and may not even work in the same precinct. They share a desire to solve the case, but that’s all.\n\n165",
      "page_number": 182
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 190-197)",
      "start_page": 190,
      "end_page": 197,
      "detection_method": "topic_boundary",
      "content": "166\n\nCHAPTER 5 BEND, OR BREAK\n\nFigure 5.6. Someone found a connection between Humpty’s gambling debts and\n\nthe phone logs. Perhaps he was getting threatening phone calls.\n\nH. Dumpty (Male, Egg): Accident or Murder?\n\nPhotos King’s men Eyewitnesses Grafﬁti\n\nShell fragments Gambling debts\n\nPhone logs\n\nWife’s alibi\n\nDetective 1\n\nDetective 2\n\nDetective 3\n\nDifferent detectives may come and go during the course of the pro- cess, and may work different shifts.\n\nThere are no restrictions on what may be placed on the blackboard. It may be pictures, sentences, physical evidence, and so on.\n\nWe’ve worked on a number of projects that involved a workﬂow or distributed data gathering process. With each, designing a solution around a simple blackboard model gave us a solid metaphor to work with: all of the features listed above using detectives are just as appli- cable to objects and code modules.\n\nA blackboard system lets us decouple our objects from each other com- pletely, providing a forum where knowledge consumers and producers can exchange data anonymously and asynchronously. As you might guess, it also cuts down on the amount of code we have to write.\n\nBlackboardImplementations Computer-based blackboard systems were originally invented for use in artiﬁcial intelligence applications where the problems to be solved were large and complex—speech recognition, knowledge-based reason- ing systems, and so on.\n\nModern distributed blackboard-like systems such as JavaSpaces and T Spaces [URL 50, URL 25] are based on a model of key/value pairs ﬁrst\n\nBLACKBOARDS\n\npopularized in Linda [CG90], where the concept was known as tuple space.\n\nWith these systems, you can store active Java objects—not just data— on the blackboard, and retrieve them by partial matching of ﬁelds (via templates and wildcards) or by subtypes. For example, suppose you had a type Author, which is a subtype of Person. You could search a blackboard containing Person objects by using an Author template with a lastName value of “Shakespeare.” You’d get Bill Shakespeare the author, but not Fred Shakespeare the gardener.\n\nThe main operations in JavaSpaces are:\n\nName\n\nFunction\n\nread write take\n\nSearch for and retrieve data from the space. Put an item into the space. Similar to read, but removes the item from the space as well.\n\nnotify Set up a notiﬁcation to occur whenever an object is written that matches the template.\n\nT Spaces supports a similar set of operations, but with different names and slightly different semantics. Both systems are built like a database product; they provide atomic operations and distributed transactions to ensure data integrity.\n\nSince we can store objects, we can use a blackboard to design algo- rithms based on a ﬂow of objects, not just data. It’s as if our detec- tives could pin people to the blackboard—witnesses themselves, not just their statements. Anyone can ask a witness questions in the pur- suit of the case, post the transcript, and move that witness to another area of the blackboard, where he might respond differently (if you allow the witness to read the blackboard too).\n\nA big advantage of systems such as these is that you have a single, con- sistent interface to the blackboard. When building a conventional dis- tributed application, you can spend a great deal of time crafting unique API calls for every distributed transaction and interaction in the sys- tem. With the combinatorial explosion of interfaces and interactions, the project can quickly become a nightmare.\n\n167\n\n168\n\nCHAPTER 5 BEND, OR BREAK\n\nOrganizing Your Blackboard\n\nWhen the detectives work on large cases, the blackboard may be- come cluttered, and it may become difﬁcult to locate data on the board. The solution is to partition the blackboard and start to orga- nize the data on the blackboard somehow.\n\nDifferent software systems handle this partitioning in different ways; some use fairly ﬂat zones or interest groups, while others adopt a more hierarchical treelike structure.\n\nThe blackboard style of programming removes the need for so many interfaces, making for a more elegant and consistent system.\n\nApplicationExample Suppose we are writing a program to accept and process mortgage or loan applications. The laws that govern this area are odiously com- plex, with federal, state, and local governments all having their say. The lender must prove they have disclosed certain things, and must ask for certain information—but must not ask certain other questions, and so on, and so on.\n\nBeyond the miasma of applicable law, we also have the following prob- lems to contend with.\n\nThere is no guarantee on the order in which data arrives. For instance, queries for a credit check or title search may take a sub- stantial amount of time, while items such as name and address may be available immediately.\n\nData gathering may be done by different people, distributed across different ofﬁces, in different time zones.\n\nSome data gathering may be done automatically by other systems. This data may arrive asynchronously as well.\n\nNonetheless, certain data may still be dependent on other data. For instance, you may not be able to start the title search for a car until you get proof of ownership or insurance.\n\nBLACKBOARDS\n\nArrival of new data may raise new questions and policies. Suppose the credit check comes back with a less than glowing report; now you need these ﬁve extra forms and perhaps a blood sample.\n\nYou can try to handle every possible combination and circumstance using a workﬂow system. Many such systems exist, but they can be complex and programmer intensive. As regulations change, the work- ﬂow must be reorganized: people may have to change their procedures and hard-wired code may have to be rewritten.\n\nA blackboard, in combination with a rules engine that encapsulates the legal requirements, is an elegant solution to the difﬁculties found here. Order of data arrival is irrelevant: when a fact is posted it can trigger the appropriate rules. Feedback is easily handled as well: the output of any set of rules can post to the blackboard and cause the triggering of yet more applicable rules.\n\nTIP 43\n\nUse Blackboards to Coordinate Workﬂow\n\nWe can use the blackboard to coordinate disparate facts and agents, while still maintaining independence and even isolation among partici- pants.\n\nYou can accomplish the same results with more brute-force methods, of course, but you’ll have a more brittle system. When it breaks, all the king’s horses and all the king’s men might not get your program working again.\n\nRelated sections include:\n\nThe Power of Plain Text, page 73 It’s Just a View, page 157\n\nChallenges\n\nDo you use blackboard systems in the real world—the message board by the refrigerator, or the big whiteboard at work? What makes them effective? Are messages ever posted with a consistent format? Does it matter?\n\n169\n\nAnswer on p. 297\n\n170\n\nCHAPTER 5 BEND, OR BREAK\n\nExercises 30. For each of the following applications, would a blackboard system be ap-\n\npropriate or not? Why?\n\n1. Image processing. You’d like to have a number of parallel processes grab chunks of an image, process them, and put the completed chunk back.\n\n2. Group calendaring. You’ve got people scattered across the globe, in different time zones, and speaking different languages, trying to schedule a meeting.\n\n3. Network monitoring tool. The system gathers performance statistics and collects trouble reports. You’d like to implement some agents to use this information to look for trouble in the system.\n\nChapter 6\n\nWhile You Are Coding\n\nConventional wisdom says that once a project is in the coding phase, the work is mostly mechanical, transcribing the design into executable statements. We think that this attitude is the single biggest reason that many programs are ugly, inefﬁcient, poorly structured, unmaintain- able, and just plain wrong.\n\nCoding is not mechanical. If it were, all the CASE tools that people pinned their hopes on in the early 1980s would have replaced program- mers long ago. There are decisions to be made every minute—decisions that require careful thought and judgment if the resulting program is to enjoy a long, accurate, and productive life.\n\nDevelopers who don’t actively think about their code are programming by coincidence—the code might work, but there’s no particular rea- son why. In Programming by Coincidence, we advocate a more positive involvement with the coding process.\n\nWhile most of the code we write executes quickly, we occasionally develop algorithms that have the potential to bog down even the fastest processors. In Algorithm Speed, we discuss ways to estimate the speed of code, and we give some tips on how to spot potential problems before they happen.\n\nPragmatic Programmers think critically about all code, including our own. We constantly see room for improvement in our programs and our designs. In Refactoring, we look at techniques that help us ﬁx up existing code even while we’re in the midst of a project.\n\nSomething that should be in the back of your mind whenever you’re producing code is that you’ll someday have to test it. Make code easy\n\n171\n\n31\n\n172\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nto test, and you’ll increase the likelihood that it will actually get tested, a thought we develop in Code That’s Easy to Test.\n\nFinally, in Evil Wizards, we suggest that you should be careful of tools that write reams of code on your behalf unless you understand what they’re doing.\n\nMost of us can drive a car largely on autopilot—we don’t explicitly com- mand our foot to press a pedal, or our arm to turn the wheel—we just think “slow down and turn right.” However, good, safe drivers are con- stantly reviewing the situation, checking for potential problems, and putting themselves into good positions in case the unexpected happens. The same is true of coding—it may be largely routine, but keeping your wits about you could well prevent a disaster.\n\nProgramming by Coincidence\n\nDo you ever watch old black-and-white war movies? The weary sol- dier advances cautiously out of the brush. There’s a clearing ahead: are there any land mines, or is it safe to cross? There aren’t any indica- tions that it’s a mineﬁeld—no signs, barbed wire, or craters. The soldier pokes the ground ahead of him with his bayonet and winces, expecting an explosion. There isn’t one. So he proceeds painstakingly through the ﬁeld for a while, prodding and poking as he goes. Eventually, convinced that the ﬁeld is safe, he straightens up and marches proudly forward, only to be blown to pieces.\n\nThe soldier’s initial probes for mines revealed nothing, but this was merely lucky. He was led to a false conclusion—with disastrous results.\n\nAs developers, we also work in mineﬁelds. There are hundreds of traps just waiting to catch us each day. Remembering the soldier’s tale, we should be wary of drawing false conclusions. We should avoid pro- gramming by coincidence—relying on luck and accidental successes— in favor of programming deliberately.\n\nPROGRAMMING BY COINCIDENCE\n\nHowtoProgramby Coincidence Suppose Fred is given a programming assignment. Fred types in some code, tries it, and it seems to work. Fred types in some more code, tries it, and it still seems to work. After several weeks of coding this way, the program suddenly stops working, and after hours of trying to ﬁx it, he still doesn’t know why. Fred may well spend a signiﬁcant amount of time chasing this piece of code around without ever being able to ﬁx it. No matter what he does, it just doesn’t ever seem to work right.\n\nFred doesn’t know why the code is failing because he didn’t know why it worked in the ﬁrst place. It seemed to work, given the limited “testing” that Fred did, but that was just a coincidence. Buoyed by false conﬁ- dence, Fred charged ahead into oblivion. Now, most intelligent people may know someone like Fred, but we know better. We don’t rely on coincidences—do we?\n\nSometimes we might. Sometimes it can be pretty easy to confuse a happy coincidence with a purposeful plan. Let’s look at a few examples.\n\nAccidentsofImplementation Accidents of implementation are things that happen simply because that’s the way the code is currently written. You end up relying on undocumented error or boundary conditions.\n\nSuppose you call a routine with bad data. The routine responds in a particular way, and you code based on that response. But the author didn’t intend for the routine to work that way—it was never even con- sidered. When the routine gets “ﬁxed,” your code may break. In the most extreme case, the routine you called may not even be designed to do what you want, but it seems to work okay. Calling things in the wrong order, or in the wrong context, is a related problem.\n\npaint(g); invalidate(); validate(); revalidate(); repaint(); paintImmediately(r);\n\nHere it looks like Fred is desperately trying to get something out on the screen. But these routines were never designed to be called this way; although they seem to work, that’s really just a coincidence.\n\n173",
      "page_number": 190
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 198-207)",
      "start_page": 198,
      "end_page": 207,
      "detection_method": "topic_boundary",
      "content": "174\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nTo add insult to injury, when the component ﬁnally does get drawn, Fred won’t try to go back and take out the spurious calls. “It works now, better leave well enough alone. . ..”\n\nIt’s easy to be fooled by this line of thought. Why should you take the risk of messing with something that’s working? Well, we can think of several reasons:\n\nIt may not really be working—it might just look like it is.\n\nThe boundary condition you rely on may be just an accident. In different circumstances (a different screen resolution, perhaps), it might behave differently.\n\nUndocumented behavior may change with the next release of the library.\n\nAdditional and unnecessary calls make your code slower.\n\nAdditional calls also increase the risk of introducing new bugs of their own.\n\nFor code you write that others will call, the basic principles of good modularization and of hiding implementation behind small, well-docu- mented interfaces can all help. A well-speciﬁed contract (see Design by Contract, page 109) can help eliminate misunderstandings.\n\nFor routines you call, rely only on documented behavior. If you can’t, for whatever reason, then document your assumption well.\n\nAccidents ofContext You can have “accidents of context” as well. Suppose you are writing a utility module. Just because you are currently coding for a GUI envi- ronment, does the module have to rely on a GUI being present? Are you relying on English-speaking users? Literate users? What else are you relying on that isn’t guaranteed?\n\nImplicitAssumptions Coincidences can mislead at all levels—from generating requirements through to testing. Testing is particularly fraught with false causalities and coincidental outcomes. It’s easy to assume that X causes Y, but as we said in Debugging, page 90: don’t assume it, prove it.\n\nPROGRAMMING BY COINCIDENCE\n\nAt all levels, people operate with many assumptions in mind—but these assumptions are rarely documented and are often in conﬂict between different developers. Assumptions that aren’t based on well-established facts are the bane of all projects.\n\nTIP 44\n\nDon’t Program by Coincidence\n\nHowtoProgramDeliberately We want to spend less time churning out code, catch and ﬁx errors as early in the development cycle as possible, and create fewer errors to begin with. It helps if we can program deliberately:\n\nAlways be aware of what you are doing. Fred let things get slowly out of hand, until he ended up boiled, like the frog in Stone Soup and Boiled Frogs, page 7.\n\nDon’t code blindfolded. Attempting to build an application you don’t fully understand, or to use a technology you aren’t familiar with, is an invitation to be misled by coincidences.\n\nProceed from a plan, whether that plan is in your head, on the back of a cocktail napkin, or on a wall-sized printout from a CASE tool.\n\nRely only on reliable things. Don’t depend on accidents or assump- tions. If you can’t tell the difference in particular circumstances, assume the worst.\n\nDocument your assumptions. Design by Contract, page 109, can help clarify your assumptions in your own mind, as well as help communicate them to others.\n\nDon’t just test your code, but test your assumptions as well. Don’t guess; actually try it. Write an assertion to test your assumptions (see Assertive Programming, page 122). If your assertion is right, you have improved the documentation in your code. If you discover your assumption is wrong, then count yourself lucky.\n\nPrioritize your effort. Spend time on the important aspects; more than likely, these are the hard parts. If you don’t have fundamen-\n\n175\n\nAnswer on p. 298\n\nAnswer on p. 298\n\n176\n\nCHAPTER 6 WHILE YOU ARE CODING\n\ntals or infrastructure correct, brilliant bells and whistles will be irrelevant.\n\nDon’t be a slave to history. Don’t let existing code dictate future code. All code can be replaced if it is no longer appropriate. Even within one program, don’t let what you’ve already done constrain what you do next—be ready to refactor (see Refactoring, page 184). This decision may impact the project schedule. The assumption is that the impact will be less than the cost of not making the change.1\n\nSo next time something seems to work, but you don’t know why, make sure it isn’t just a coincidence.\n\nRelated sections include:\n\nStone Soup and Boiled Frogs, page 7 Debugging, page 90 Design by Contract, page 109 Assertive Programming, page 122 Temporal Coupling, page 150 Refactoring, page 184 It’s All Writing, page 248\n\nExercises 31. Can you identify some coincidences in the following C code fragment?\n\nAssume that this code is buried deep in a library routine.\n\nfprintf(stderr,\"Error, continue?\"); gets(buf);\n\n32. This piece of C code might work some of the time, on some machines. Then\n\nagain, it might not. What’s wrong?\n\n/* Truncate string to its last maxlen chars */\n\nvoid string_tail(char *string, int maxlen) {\n\nint len = strlen(string); if (len > maxlen) {\n\nstrcpy(string, string + (len - maxlen));\n\n}\n\n}\n\n1. was given because he had his own naming conventions.\n\nYou can also go too far here. We once knew a developer who rewrote all source he\n\nALGORITHM SPEED\n\n177\n\n33. This code comes from a general-purpose Java tracing suite. The function writes a string to a log ﬁle. It passes its unit test, but fails when one of the Web developers uses it. What coincidence does it rely on? Answer on p. 299\n\npublic static void debug(String s) throws IOException { FileWriter fw = new FileWriter(\"debug.log\", true); fw.write(s); fw.flush(); fw.close();\n\n}\n\n32 Algorithm Speed\n\nIn Estimating, page 64, we talked about estimating things such as how long it takes to walk across town, or how long a project will take to ﬁn- ish. However, there is another kind of estimating that Pragmatic Pro- grammers use almost daily: estimating the resources that algorithms use—time, processor, memory, and so on.\n\nThis kind of estimating is often crucial. Given a choice between two ways of doing something, which do you pick? You know how long your program runs with 1,000 records, but how will it scale to 1,000,000? What parts of the code need optimizing?\n\nIt turns out that these questions can often be answered using common sense, some analysis, and a way of writing approximations called the “big O” notation.\n\nWhatDoWeMean by Estimating Algorithms? Most nontrivial algorithms handle some kind of variable input—sorting matrix, or decrypting a message with an strings, inverting an -bit key. Normally, the size of this input will affect the algorithm: the larger the input, the longer the running time or the more memory used.\n\nIf the relationship were always linear (so that the time increased in ), this section wouldn’t be important. direct proportion to the value of However, most signiﬁcant algorithms are not linear. The good news is that many are sublinear. A binary search, for example, doesn’t need to look at every candidate when ﬁnding a match. The bad news is that\n\n178\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nother algorithms are considerably worse than linear; runtimes or mem- ory requirements increase far faster than . An algorithm that takes a minute to process ten items may take a lifetime to process 100.\n\nWe ﬁnd that whenever we write anything containing loops or recur- sive calls, we subconsciously check the runtime and memory require- ments. This is rarely a formal process, but rather a quick conﬁrma- tion that what we’re doing is sensible in the circumstances. However, we sometimes do ﬁnd ourselves performing a more detailed analysis. That’s when the\n\nnotation comes in useful.\n\nTheO()Notation The When we write that a particular sort routine sorts time, we are simply saying that the worst-case time taken will vary . Double the number of records, and the time will as the square of as meaning on the order of. increase roughly fourfold. Think of the notation puts an upper bound on the value of the thing we’re The measuring (time, memory, and so on). If we say a function takes time, then we know that the upper bound of the time it takes will not grow faster than functions, but because the highest-order term will dominate the value increases, the convention is to remove all low-order terms, and not as to bother showing any constant multiplying factors. is the same as . This is actually a weakness , which is equivalent to algorithm may be 1,000 times faster than of the another\n\nnotation is a mathematical way of dealing with approximations.\n\nrecords in\n\n. Sometimes we come up with fairly complex\n\nnotation—one\n\nalgorithm, but you won’t know it from the notation.\n\nFigure 6.1 shows several common notations you’ll come across, along with a graph comparing running times of algorithms in each cat- egory. Clearly, things quickly start getting out of hand once we get over\n\n.\n\nFor example, suppose you’ve got a routine that takes 1 s to process 100 records. How long will it take to process 1,000? If your code is , then , then you’ll probably be waiting about it will still take 1 s. If it’s 3 s. will take some 33 s. If you’re unlucky enough to have an routine, then sit back for 100 s while it does its stuff. And if you’re using an exponential\n\nwill show a linear increase to 10 s, while an\n\nALGORITHM SPEED\n\nFigure 6.1. Runtimes of various algorithms\n\n: traveling salesman\n\n: heapsort\n\n: selection sort\n\n: sequential search\n\n: binary search\n\n: array access\n\nSome common O() notations\n\nConstant (access element in array, simple statements)\n\nLogarithmic (binary search) [The notation is shorthand for\n\n]\n\nLinear (sequential search)\n\nWorse than linear, but not much worse (aver- age runtime of quicksort, heapsort)\n\nSquare law (selection and insertion sorts)\n\nCubic (multiplication of 2\n\nmatrices)\n\nExponential (traveling salesman problem, set partitioning)\n\n179\n\n180\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nalgorithm should ﬁnish in about\n\n, you might want to make a cup of coffee—your routine years. Let us know how the universe ends.\n\nThe notation doesn’t apply just to time; you can use it to represent any other resources used by an algorithm. For example, it is often use- ful to be able to model memory consumption (see Exercise 35 on page 183).\n\nCommon SenseEstimation You can estimate the order of many basic algorithms using common sense.\n\nIf a simple loop runs from to , then the algo- Simple loops. rithm is likely to be —time increases linearly with . Exam- ples include exhaustive searches, ﬁnding the maximum value in an array, and generating checksums.\n\nIf you nest a loop inside another, then your algo- Nested loops. are the two loops’ limits. rithm becomes This commonly occurs in simple sorting algorithms, such as bub- ble sort, where the outer loop scans each element in the array in turn, and the inner loop works out where to place that element in the sorted result. Such sorting algorithms tend to be\n\n, where\n\nand\n\n.\n\nIf your algorithm halves the set of things it consid- Binary chop. ers each time around the loop, then it is likely to be logarithmic, (see Exercise 37, page 183). A binary search of a sorted list, traversing a binary tree, and ﬁnding the ﬁrst set bit in a machine word can all be\n\n.\n\nDivide and conquer. Algorithms that partition their input, work on the two halves independently, and then combine the result can . The classic example is quicksort, which works by be partitioning the data into two halves and recursively sorting each. Although technically , because its behavior degrades when it is fed sorted input, the average runtime of quicksort is\n\nCombinatoric. Whenever algorithms start looking at the permuta- tions of things, their running times may get out of hand. This is be- cause permutations involve factorials (there are\n\npermutations of the digits from 1 to 5). Time a combinatoric\n\n.\n\nALGORITHM SPEED\n\n181\n\nalgorithm for ﬁve elements: it will take six times longer to run it for six, and 42 times longer for seven. Examples include algorithms for many of the acknowledged hard problems—the traveling salesman problem, optimally packing things into a container, partitioning a set of numbers so that each set has the same total, and so on. Of- ten, heuristics are used to reduce the running times of these types of algorithms in particular problem domains.\n\nAlgorithmSpeed inPractice It’s unlikely that you’ll spend much time during your career writing sort routines. The ones in the libraries available to you will probably outper- form anything you may write without substantial effort. However, the basic kinds of algorithms we’ve described earlier pop up time and time again. Whenever you ﬁnd yourself writing a simple loop, you know that algorithm. If that loop contains an inner loop, then you have an . You should be asking yourself how large you’re looking at these values can get. If the numbers are bounded, then you’ll know how long the code will take to run. If the numbers depend on external factors (such as the number of records in an overnight batch run, or the number of names in a list of people), then you might want to stop and consider the effect that large values may have on your running time or memory consumption.\n\nTIP 45\n\nEstimate the Order of Your Algorithms\n\nThere are some approaches you can take to address potential problems. If you have an algorithm that is , try to ﬁnd a divide and conquer approach that will take you down to\n\n.\n\nIf you’re not sure how long your code will take, or how much memory it will use, try running it, varying the input record count or whatever is likely to impact the runtime. Then plot the results. You should soon get a good idea of the shape of the curve. Is it curving upward, a straight line, or ﬂattening off as the input size increases? Three or four points should give you an idea.\n\nAlso consider just what you’re doing in the code itself. A simple loop may well perform better than a complex,\n\none for smaller\n\n182\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nvalues of inner loop.\n\n, particularly if the\n\nalgorithm has an expensive\n\nIn the middle of all this theory, don’t forget that there are practical considerations as well. Runtime may look like it increases linearly for small input sets. But feed the code millions of records and suddenly the time degrades as the system starts to thrash. If you test a sort routine with random input keys, you may be surprised the ﬁrst time it encounters ordered input. Pragmatic Programmers try to cover both the theoretical and practical bases. After all this estimating, the only timing that counts is the speed of your code, running in the production environment, with real data.2 This leads to our next tip.\n\nTIP 46\n\nTest Your Estimates\n\nIf it’s tricky getting accurate timings, use code proﬁlers to count the number of times the different steps in your algorithm get executed, and plot these ﬁgures against the size of the input.\n\nBestIsn’t AlwaysBest You also need to be pragmatic about choosing appropriate algorithms— the fastest one is not always the best for the job. Given a small input set, a straightforward insertion sort will perform just as well as a quick- sort, and will take you less time to write and debug. You also need to be careful if the algorithm you choose has a high setup cost. For small input sets, this setup may dwarf the running time and make the algo- rithm inappropriate.\n\nAlso be wary of premature optimization. It’s always a good idea to make sure an algorithm really is a bottleneck before investing your precious time trying to improve it.\n\n2. In fact, while testing the sort algorithms used as an exercise for this section on a 64MB Pentium, the authors ran out of real memory while running the radix sort with more than seven million numbers. The sort started using swap space, and times degraded dramatically.\n\nALGORITHM SPEED\n\n183\n\nRelated sections include:\n\nEstimating, page 64\n\nChallenges\n\nEvery developer should have a feel for how algorithms are designed and analyzed. Robert Sedgewick has written a series of accessible books on the subject ([Sed83, SF96, Sed92] and others). We recommend adding one of his books to your collection, and making a point of reading it.\n\nFor those who like more detail than Sedgewick provides, read Donald Knuth’s deﬁnitive Art of Computer Programming books, which analyze a wide range of algorithms [Knu97a, Knu97b, Knu98].\n\nIn Exercise 34, we look at sorting arrays of long integers. What is the impact if the keys are more complex, and the overhead of key comparison is high? Does the key structure affect the efﬁciency of the sort algorithms, or is the fastest sort always fastest?\n\nExercises 34. We have coded a set of simple sort routines, which can be downloaded from our Web site (www.pragmaticprogrammer.com). Run them on vari- ous machines available to you. Do your ﬁgures follow the expected curves? What can you deduce about the relative speeds of your machines? What are the effects of various compiler optimization settings? Is the radix sort indeed linear?\n\n35. The routine below prints out the contents of a binary tree. Assuming the tree is balanced, roughly how much stack space will the routine use while printing a tree of 1,000,000 elements? (Assume that subroutine calls im- pose no signiﬁcant stack overhead.) void printTree(const Node *node) {\n\nchar buffer[1000];\n\nif (node) {\n\nprintTree(node->left);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nprintTree(node->right);\n\n}\n\n}\n\n36. Can you see any way to reduce the stack requirements of the routine in\n\nExercise 35 (apart from reducing the size of the buffer)?\n\n37. On page 180, we claimed that a binary chop is\n\n. Can you prove\n\nthis?\n\nAnswer on p. 299\n\nAnswer on p. 300\n\nAnswer on p. 301",
      "page_number": 198
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 208-216)",
      "start_page": 208,
      "end_page": 216,
      "detection_method": "topic_boundary",
      "content": "184\n\nCHAPTER 6 WHILE YOU ARE CODING\n\n33 Refactoring\n\nChange and decay in all around I see ... H. F. Lyte, “Abide With Me”\n\nAs a program evolves, it will become necessary to rethink earlier deci- sions and rework portions of the code. This process is perfectly natural. Code needs to evolve; it’s not a static thing.\n\nUnfortunately, the most common metaphor for software development is building construction (Bertrand Meyer [Mey97b] uses the term “Soft- ware Construction”). But using construction as the guiding metaphor implies these steps:\n\n1. An architect draws up blueprints.\n\n2. Contractors dig the foundation, build the superstructure, wire and\n\nplumb, and apply ﬁnishing touches.\n\n3. The tenants move in and live happily ever after, calling building\n\nmaintenance to ﬁx any problems.\n\nWell, software doesn’t quite work that way. Rather than construction, software is more like gardening—it is more organic than concrete. You plant many things in a garden according to an initial plan and condi- tions. Some thrive, others are destined to end up as compost. You may move plantings relative to each other to take advantage of the inter- play of light and shadow, wind and rain. Overgrown plants get split or pruned, and colors that clash may get moved to more aesthetically pleasing locations. You pull weeds, and you fertilize plantings that are in need of some extra help. You constantly monitor the health of the garden, and make adjustments (to the soil, the plants, the layout) as needed.\n\nBusiness people are comfortable with the metaphor of building con- struction: it is more scientiﬁc than gardening, it’s repeatable, there’s a rigid reporting hierarchy for management, and so on. But we’re not building skyscrapers—we aren’t as constrained by the boundaries of physics and the real world.\n\nThe gardening metaphor is much closer to the realities of software development. Perhaps a certain routine has grown too large, or is trying\n\nREFACTORING\n\nto accomplish too much—it needs to be split into two. Things that don’t work out as planned need to be weeded or pruned.\n\nRewriting, reworking, and re-architecting code is collectively known as refactoring.\n\nWhenShouldYou Refactor? When you come across a stumbling block because the code doesn’t quite ﬁt anymore, or you notice two things that should really be merged, or anything else at all strikes you as being “wrong,” don’t hesitate to change it. There’s no time like the present. Any number of things may cause code to qualify for refactoring:\n\nDuplication. You’ve discovered a violation of the DRY principle (The Evils of Duplication, page 26).\n\nNonorthogonal design. You’ve discovered some code or design that could be made more orthogonal (Orthogonality, page 34).\n\nOutdated knowledge. Things change, requirements drift, and your knowledge of the problem increases. Code needs to keep up.\n\nPerformance. You need to move functionality from one area of the system to another to improve performance.\n\nRefactoring your code—moving functionality around and updating ear- lier decisions—is really an exercise in pain management. Let’s face it, changing source code around can be pretty painful: it was almost work- ing, and now it’s really torn up. Many developers are reluctant to start ripping up code just because it isn’t quite right.\n\nReal-WorldComplications So you go to your boss or client and say, “This code works, but I need another week to refactor it.”\n\nWe can’t print their reply.\n\nTime pressure is often used as an excuse for not refactoring. But this excuse just doesn’t hold up: fail to refactor now, and there’ll be a far greater time investment to ﬁx the problem down the road—when there are more dependencies to reckon with. Will there be more time available then? Not in our experience.\n\n185\n\n186\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nYou might want to explain this principle to the boss by using a medical analogy: think of the code that needs refactoring as a “growth.” Remov- ing it requires invasive surgery. You can go in now, and take it out while it is still small. Or, you could wait while it grows and spreads—but re- moving it then will be both more expensive and more dangerous. Wait even longer, and you may lose the patient entirely.\n\nTIP 47\n\nRefactor Early, Refactor Often\n\nKeep track of the things that need to be refactored. If you can’t refactor something immediately, make sure that it gets placed on the schedule. Make sure that users of the affected code know that it is scheduled to be refactored and how this might affect them.\n\nHowDoYou Refactor? Refactoring started out in the Smalltalk community, and, along with other trends (such as design patterns), has started to gain a wider au- dience. But as a topic it is still fairly new; there isn’t much published on it. The ﬁrst major book on refactoring ([FBB 99], and also [URL 47]) is being published around the same time as this book.\n\nAt its heart, refactoring is redesign. Anything that you or others on your team designed can be redesigned in light of new facts, deeper under- standings, changing requirements, and so on. But if you proceed to rip up vast quantities of code with wild abandon, you may ﬁnd yourself in a worse position than when you started.\n\nClearly, refactoring is an activity that needs to be undertaken slowly, deliberately, and carefully. Martin Fowler offers the following simple tips on how to refactor without doing more harm than good (see the box on page 30 in [FS97]):\n\n1. Don’t try to refactor and add functionality at the same time.\n\n2. Make sure you have good tests before you begin refactoring. Run the tests as often as possible. That way you will know quickly if your changes have broken anything.\n\nREFACTORING\n\nAutomatic Refactoring\n\nHistorically, Smalltalk users have always enjoyed a class browser as part of the IDE. Not to be confused with Web browsers, class browsers let users navigate through and examine class hierarchies and methods.\n\nTypically, class browsers allow you to edit code, create new methods and classes, and so on. The next variation on this idea is the refac- toringbrowser.\n\nA refactoring browser can semiautomatically perform common refac- toring operations for you: splitting up a long routine into smaller ones, automatically propagating changes to method and variable names, drag and drop to assist you in moving code, and so on.\n\nAs we write this book, this technology has yet to appear outside of the Smalltalk world, but this is likely to change at the same speed that Java changes—rapidly. In the meantime, the pioneering Small- talk refactoring browser can be found online at [URL 20].\n\n3. Take short, deliberate steps: move a ﬁeld from one class to another, fuse two similar methods into a superclass. Refactoring often in- volves making many localized changes that result in a larger-scale change. If you keep your steps small, and test after each step, you will avoid prolonged debugging.\n\nWe’ll talk more about testing at this level in Code That’s Easy to Test, page 189, and larger-scale testing in Ruthless Testing, page 237, but Mr. Fowler’s point of maintaining good regression tests is the key to refactoring with conﬁdence.\n\nIt can also be helpful to make sure that drastic changes to a module— such as altering its interface or its functionality in an incompatible manner—break the build. That is, old clients of this code should fail to compile. You can then quickly ﬁnd the old clients and make the necessary changes to bring them up to date.\n\nSo next time you see a piece of code that isn’t quite as it should be, ﬁx both it and everything that depends on it. Manage the pain: if it hurts now, but is going to hurt even more later, you might as well get it over\n\n187\n\nCopyright 2002 Addison Wesley Longman, Inc\n\n188\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nwith. Remember the lessons of Software Entropy, page 4: don’t live with broken windows.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Software Entropy, page 4 Stone Soup and Boiled Frogs, page 7 The Evils of Duplication, page 26 Orthogonality, page 34 Programming by Coincidence, page 172 Code That’s Easy to Test, page 189 Ruthless Testing, page 237\n\nExercises 38. The following code has obviously been updated several times over the\n\nAnswer on p. 302\n\nyears, but the changes haven’t improved its structure. Refactor it.\n\nif (state == TEXAS) {\n\nrate = TX_RATE; amt calc = 2*basis(amt) + extra(amt)*1.05;\n\n= base * TX_RATE;\n\n} else if ((state == OHIO) || (state == MAINE)) { rate = (state == OHIO) ? OH_RATE : ME_RATE; amt calc = 2*basis(amt) + extra(amt)*1.05; if (state == OHIO)\n\n= base * rate;\n\npoints = 2;\n\n} else {\n\nrate = 1; amt calc = 2*basis(amt) + extra(amt)*1.05;\n\n= base;\n\n}\n\n39. The following Java class needs to support a few more shapes. Refactor the\n\nAnswer on p. 303\n\nclass to prepare it for the additions.\n\npublic class Shape {\n\npublic static final int SQUARE public static final int CIRCLE public static final int RIGHT_TRIANGLE = 3;\n\n= 1; = 2;\n\nprivate int private double size;\n\nshapeType;\n\npublic Shape(int shapeType, double size) {\n\nthis.shapeType = shapeType; this.size\n\n= size;\n\n}\n\n// ... other methods ...\n\nCODE THAT’S EASY TO TEST\n\n189\n\npublic double area() { switch (shapeType) { case SQUARE: case CIRCLE: case RIGHT_TRIANGLE: return size*size/2.0; } return 0;\n\nreturn size*size; return Math.PI*size*size/4.0;\n\n}\n\n}\n\n40. This Java code is part of a framework that will be used throughout your Answer on p. 303\n\n40. This Java code is part of a framework that will be used throughout your Answer on p. 303\n\npublic class Window {\n\npublic Window(int width, int height) { ... }\n\npublic void setSize(int width, int height) { ... }\n\npublic boolean overlaps(Window w) { ... }\n\npublic int getArea() { ... }\n\n}\n\n34 Code That’s Easy to Test\n\nThe Software IC is a metaphor that people like to toss around when discussing reusability and component-based development.3 The idea is that software components should be combined just as integrated circuit chips are combined. This works only if the components you are using are known to be reliable.\n\nChips are designed to be tested—not just at the factory, not just when they are installed, but also in the ﬁeld when they are deployed. More complex chips and systems may have a full Built-In Self Test (BIST) fea- ture that runs some base-level diagnostics internally, or a Test Access Mechanism (TAM) that provides a test harness that allows the external environment to provide stimuli and collect responses from the chip.\n\nWe can do the same thing in software. Like our hardware colleagues, we need to build testability into the software from the very beginning, and test each piece thoroughly before trying to wire them together.\n\n3. Cox and Novobilski in their Objective-C book Object-Oriented Programming [CN91].\n\nThe term “Software IC” (Integrated Circuit) seems to have been invented in 1986 by\n\n190\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nUnit Testing Chip-level testing for hardware is roughly equivalent to unit testing in software—testing done on each module, in isolation, to verify its behavior. We can get a better feeling for how a module will react in the big wide world once we have tested it throughly under controlled (even contrived) conditions.\n\nA software unit test is code that exercises a module. Typically, the unit test will establish some kind of artiﬁcial environment, then invoke rou- tines in the module being tested. It then checks the results that are returned, either against known values or against the results from pre- vious runs of the same test (regression testing).\n\nLater, when we assemble our “software IC’s” into a complete system, we’ll have conﬁdence that the individual parts work as expected, and then we can use the same unit test facilities to test the system as a whole. We talk about this large-scale checking of the system in Ruthless Testing, page 237.\n\nBefore we get that far, however, we need to decide what to test at the unit level. Typically, programmers throw a few random bits of data at the code and call it tested. We can do much better, using the ideas behind design by contract.\n\nTesting Against Contract We like to think of unit testing as testing against contract (see Design by Contract, page 109). We want to write test cases that ensure that a given unit honors its contract. This will tell us two things: whether the code meets the contract, and whether the contract means what we think it means. We want to test that the module delivers the functionality it promises, over a wide range of test cases and boundary conditions.\n\nWhat does this mean in practice? Let’s look at the square root routine we ﬁrst encountered on page 114. Its contract is simple:\n\nrequire\n\nargument >= 0;\n\nensure\n\n((Result * Result) - argument).abs <= epsilon*argument;\n\nThis tells us what to test:\n\nCODE THAT’S EASY TO TEST\n\nPass in a negative argument and ensure that it is rejected.\n\nPass in an argument of zero to ensure that it is accepted (this is the boundary value).\n\nPass in values between zero and the maximum expressible argu- ment and verify that the difference between the square of the result and the original argument is less than some small fraction of the argument.\n\nArmed with this contract, and assuming that our routine does its own pre- and postcondition checking, we can write a basic test script to exercise the square root function.\n\npublic void testValue(double num, double expected) {\n\ndouble result = 0.0;\n\ntry {\n\n// We may throw a\n\nresult = mySqrt(num); // precondition exception\n\n} catch (Throwable e) {\n\nif (num < 0.0)\n\nreturn;\n\nelse\n\nassert(false);\n\n// If input is < 0, then // we’re expecting the // exception, otherwise // force a test failure\n\n}\n\nassert(Math.abs(expected-result) < epsilon*expected);\n\n}\n\nThen we can call this routine to test our square root function:\n\ntestValue(-4.0, 0.0); testValue( 0.0, 0.0); testValue( 2.0, 1.4142135624); testValue(64.0, 8.0); testValue(1.0e7, 3162.2776602);\n\nThis is a pretty simple test; in the real world, any nontrivial module is likely to be dependent on a number of other modules, so how do we go about testing the combination?\n\nSuppose we have a module A that uses a LinkedList and a Sort. In order, we would test:\n\n1. LinkedList’s contract, in full\n\n2. Sort’s contract, in full\n\n3. A’s contract, which relies on the other contracts but does not di-\n\nrectly expose them\n\n191\n\n192\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nThis style of testing requires you to test subcomponents of a module ﬁrst. Once the subcomponents have been veriﬁed, then the module itself can be tested.\n\nIf LinkedList and Sort’s tests passed, but A’s test failed, we can be pretty sure that the problem is in A, or in A’s use of one of those sub- components. This technique is a great way to reduce debugging effort: we can quickly concentrate on the likely source of the problem within module A, and not waste time reexamining its subcomponents.\n\nWhy do we go to all this trouble? Above all, we want to avoid creating a “time bomb”—something that sits around unnoticed and blows up at an awkward moment later in the project. By emphasizing testing against contract, we can try to avoid as many of those downstream disasters as possible.\n\nTIP 48\n\nDesign to Test\n\nWhen you design a module, or even a single routine, you should design both its contract and the code to test that contract. By designing code to pass a test and fulﬁll its contract, you may well consider bound- ary conditions and other issues that wouldn’t occur to you otherwise. There’s no better way to ﬁx errors than by avoiding them in the ﬁrst place. In fact, by building the tests before you implement the code, you get to try out the interface before you commit to it.\n\nWriting Unit Tests The unit tests for a module shouldn’t be shoved in some far-away cor- ner of the source tree. They need to be conveniently located. For small projects, you can embed the unit test for a module in the module itself. For larger projects, we suggest moving each test into a subdirectory. Either way, remember that if it isn’t easy to ﬁnd, it won’t be used.\n\nBy making the test code readily accessible, you are providing developers who may use your code with two invaluable resources:\n\n1. Examples of how to use all the functionality of your module",
      "page_number": 208
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 217-224)",
      "start_page": 217,
      "end_page": 224,
      "detection_method": "topic_boundary",
      "content": "CODE THAT’S EASY TO TEST\n\n2. A means to build regression tests to validate any future changes to\n\nthe code\n\nIt’s convenient, but not always practical, for each class or module to contain its own unit test. In Java, for example, every class can have its own main. In all but the application’s main class ﬁle, the main routine can be used to run unit tests; it will be ignored when the application itself is run. This has the beneﬁt that the code you ship still contains the tests, which can be used to diagnose problems in the ﬁeld.\n\nIn C++ you can achieve the same effect (at compile time) by using #ifdef to compile unit test code selectively. For example, here’s a very simple unit test in C++, embedded in our module, that checks our square root function using a testValue routine similar to the Java one deﬁned previously:\n\n#ifdef __TEST__ int main(int argc, char **argv) {\n\nargc--; argv++;\n\n// skip program name\n\nif (argc < 2) {\n\n// do standard tests if no args\n\ntestValue(-4.0, 0.0); testValue( 0.0, 0.0); testValue( 2.0, 1.4142135624); testValue(64.0, 8.0); testValue(1.0e7, 3162.2776602);\n\n} else {\n\n// else use args\n\ndouble num, expected;\n\nwhile (argc >= 2) {\n\nnum = atof(argv[0]); expected = atof(argv[1]); testValue(num,expected); argc -= 2; argv += 2;\n\n}\n\n} return 0;\n\n} #endif\n\nThis unit test will either run a minimal set of tests or, if given argu- ments, allow you to pass data in from the outside world. A shell script could use this ability to run a much more complete set of tests.\n\nWhat do you do if the correct response for a unit test is to exit, or abort the program? In that case, you need to be able to select the test to run, perhaps by specifying an argument on the command line. You’ll\n\n193\n\n194\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nalso need to pass in parameters if you need to specify different starting conditions for your tests.\n\nBut providing unit tests isn’t enough. You must run them, and run them often. It also helps if the class passes its tests once in a while.\n\nUsing Test Harnesses Because we usually write a lot of test code, and do a lot of testing, we’ll make life easier on ourselves and develop a standard testing harness for the project. The main shown in the previous section is a very simple test harness, but usually we’ll need more functionality than that.\n\nA test harness can handle common operations such as logging status, analyzing output for expected results, and selecting and running the tests. Harnesses may be GUI driven, may be written in the same target language as the rest of the project, or may be implemented as a combi- nation of makefiles and Perl scripts. A simple test harness is shown in the answer to Exercise 41 on page 305.\n\nIn object-oriented languages and environments, you might create a base class that provides these common operations. Individual tests can subclass from that and add speciﬁc test code. You could use a standard naming convention and reﬂection in Java to build a list of tests dynam- ically. This technique is a nice way of honoring the DRY principle—you don’t have to maintain a list of available tests. But before you go off and start writing your own harness, you may want to investigate Kent Beck and Erich Gamma’s xUnit at [URL 22]. You might also want to look at our book Pragmatic Unit Testing [HT03] for an introduction to JUnit.\n\nRegardless of the technology you decide to use, test harnesses should include the following capabilities:\n\nA standard way to specify setup and cleanup\n\nA method for selecting individual tests or all available tests\n\nA means of analyzing output for expected (or unexpected) results\n\nA standardized form of failure reporting\n\nTests should be composable; that is, a test can be composed of subtests of subcomponents to any depth. We can use this feature to test selected parts of the system or the entire system just as easily, using the same tools.\n\nCODE THAT’S EASY TO TEST\n\nAd Hoc Testing\n\nDuring debugging, we may end up creating some particular tests on- the-ﬂy. These may be as simple as a print statement, or a piece of code entered interactively in a debugger or IDE environment.\n\nAt the end of the debugging session, you need to formalize the ad hoc test. If the code broke once, it is likely to break again. Don’t just throw away the test you created; add it to the existing unit test.\n\nFor example, using JUnit (the Java member of the xUnit family), we might write our square root test as follows:\n\npublic class JUnitExample extends TestCase {\n\npublic JUnitExample(final String name) {\n\nsuper(name);\n\n}\n\nprotected void setUp() {\n\n// Load up test data... testData.addElement(new DblPair(-4.0,0.0)); testData.addElement(new DblPair(0.0,0.0)); testData.addElement(new DblPair(64.0,8.0)); testData.addElement(new DblPair(Double.MAX_VALUE,\n\n1.3407807929942597E154));\n\n}\n\npublic void testMySqrt() {\n\ndouble num, expected, result = 0.0;\n\nEnumeration enum = testData.elements(); while (enum.hasMoreElements()) {\n\nDblPair p = (DblPair)enum.nextElement(); num expected = p.getExpected(); testValue(num, expected);\n\n= p.getNum();\n\n}\n\n}\n\npublic static Test suite() {\n\nTestSuite suite= new TestSuite(); suite.addTest(new JUnitExample(\"testMySqrt\")); return suite;\n\n}\n\n}\n\nJUnit is designed to be composable: we could add as many tests as we wanted to this suite, and each of those tests could in turn be a suite. In addition, you have your choice of a graphical or batch interface to drive the tests.\n\n195\n\n196\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nBuild a Test Window Even the best sets of tests are unlikely to ﬁnd all the bugs; there’s some- thing about the damp, warm conditions of a production environment that seems to bring them out of the woodwork.\n\nThis means you’ll often need to test a piece of software once it has been deployed—with real-world data ﬂowing though its veins. Unlike a circuit board or chip, we don’t have test pins in software, but we can provide various views into the internal state of a module, without using the debugger (which may be inconvenient or impossible in a production application).\n\nLog ﬁles containing trace messages are one such mechanism. Log mes- sages should be in a regular, consistent format; you may want to parse them automatically to deduce processing time or logic paths that the program took. Poorly or inconsistently formatted diagnostics are just so much “spew”—they are difﬁcult to read and impractical to parse.\n\nAnother mechanism for getting inside running code is the “hot-key” sequence. When this particular combination of keys is pressed, a diag- nostic control window pops up with status messages and so on. This isn’t something you normally would reveal to end users, but it can be very handy for the help desk.\n\nFor larger, more complex server code, a nifty technique for providing a view into its operation is to include a built-in Web server. Anyone can point a Web browser to the application’s HTTP port (which is usually on a nonstandard number, such as 8080) and see internal status, log entries, and possibly even some sort of a debug control panel. This may sound difﬁcult to implement, but it’s not. Freely available and embed- dable HTTP Web servers are available in a variety of modern languages. A good place to start looking is [URL 58].\n\nA Cultureof Testing All software you write will be tested—if not by you and your team, then by the eventual users—so you might as well plan on testing it thoroughly. A little forethought can go a long way toward minimizing maintenance costs and help-desk calls.\n\nCODE THAT’S EASY TO TEST\n\nDespite its hacker reputation, the Perl community has a very strong commitment to unit and regression testing. The Perl standard module installation procedure supports a regression test by invoking\n\n% make test\n\nThere’s nothing magic about Perl itself in this regard. Perl makes it easier to collate and analyze test results to ensure compliance, but the big advantage is simply that it’s a standard—tests go in a particular place, and have a certain expected output. Testing is more cultural than technical; we can instill this testing culture in a project regardless of the language being used.\n\nTIP 49\n\nTest Your Software, or Your Users Will\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Orthogonality, page 34 Design by Contract, page 109 Refactoring, page 184 Ruthless Testing, page 237\n\nExercises 41. Design a test jig for the blender interface described in the answer to Exer- cise 17 on page 289. Write a shell script that will perform a regression test for the blender. You need to test basic functionality, error and boundary conditions, and any contractual obligations. What restrictions are placed on changing the speed? Are they being honored?\n\n197\n\nAnswer on p. 305\n\n198\n\nCHAPTER 6 WHILE YOU ARE CODING\n\n35 Evil Wizards\n\nThere’s no denying it—applications are getting harder and harder to write. User interfaces in particular are becoming increasingly sophis- ticated. Twenty years ago, the average application would have a glass teletype interface (if it had an interface at all). Asynchronous terminals would typically provide a character interactive display, while pollable devices (such as the ubiquitous IBM 3270) would let you ﬁll in an entire screen before hitting SEND. Now, users expect graphical user interfaces, with context-sensitive help, cut and paste, drag and drop, OLE integra- tion, and MDI or SDI. Users are looking for Web-browser integration and thin-client support.\n\nAll the time the applications themselves are getting more complex. Most developments now use a multitier model, possibly with some middle- ware layer or a transaction monitor. These programs are expected to be dynamic and ﬂexible, and to interoperate with applications written by third parties.\n\nOh, and did we mention that we needed it all next week?\n\nDevelopers are struggling to keep up. If we were using the same kind of tools that produced the basic dumb-terminal applications 20 years ago, we’d never get anything done.\n\nSo the tool makers and infrastructure vendors have come up with a magic bullet, the wizard. Wizards are great. Do you need an MDI appli- cation with OLE container support? Just click a single button, answer a couple of simple questions, and the wizard will automatically generate skeleton code for you. The Microsoft Visual C++ environment creates over 1,200 lines of code for this scenario, automatically. Wizards are hard at work in other contexts, too. You can use wizards to create server components, implement Java beans, and handle network interfaces— all complex areas where it’s nice to have expert help.\n\nBut using a wizard designed by a guru does not automatically make Joe developer equally expert. Joe can feel pretty good—he’s just produced a mass of code and a pretty spiffy-looking program. He just adds in the speciﬁc application functionality and it’s ready to ship. But unless Joe actually understands the code that has been produced on his behalf, he’s fooling himself. He’s programming by coincidence. Wizards are a one-way street—they cut the code for you, and then move on. If the\n\nEVIL WIZARDS\n\ncode they produce isn’t quite right, or if circumstances change and you need to adapt the code, you’re on your own.\n\nWe are not against wizards. On the contrary, we dedicate an entire section (Code Generators, page 102) to writing your own. But if you do use a wizard, and you don’t understand all the code that it produces, you won’t be in control of your own application. You won’t be able to maintain it, and you’ll be struggling when it comes time to debug.\n\nTIP 50\n\nDon’t Use Wizard Code You Don’t Understand\n\nSome people feel that this is an extreme position. They say that develop- ers routinely rely on things they don’t fully understand—the quantum mechanics of integrated circuits, the interrupt structure of the proces- sor, the algorithms used to schedule processes, the code in the supplied libraries, and so on. We agree. And we’d feel the same about wizards if they were simply a set of library calls or standard operating system services that developers could rely on. But they’re not. Wizards gener- ate code that becomes an integral part of Joe’s application. The wizard code is not factored out behind a tidy interface—it is interwoven line by line with functionality that Joe writes.4 Eventually, it stops being the wizard’s code and starts being Joe’s. And no one should be producing code they don’t fully understand.\n\nRelated sections include: Orthogonality, page 34 Code Generators, page 102\n\nChallenges\n\nIf you have a GUI-building wizard available, use it to generate a skeleton application. Go through every line of code it produces. Do you understand it all? Could you have produced it yourself? Would you have produced it yourself, or is it doing things you don’t need?\n\n4. However, there are other techniques that help manage complexity. We discuss two, beans and AOP, in Orthogonality, page 34.\n\n199\n\nThis page intentionally left blank",
      "page_number": 217
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 225-232)",
      "start_page": 225,
      "end_page": 232,
      "detection_method": "topic_boundary",
      "content": "Chapter 7\n\nBefore the Project\n\nDo you ever get the feeling that your project is doomed, even before it starts? Sometimes it might be, unless you establish some basic ground rules ﬁrst. Otherwise, you might as well suggest that it be shut down now, and save the sponsor some money.\n\nAt the very beginning of a project, you’ll need to determine the require- ments. Simply listening to users is not enough: read The Requirements Pit to ﬁnd out more.\n\nConventional wisdom and constraint management are the topics of Solving Impossible Puzzles. Whether you are performing requirements, analysis, coding, or testing, difﬁcult problems will crop up. Most of the time, they won’t be as difﬁcult as they ﬁrst appear to be.\n\nWhen you think you’ve got the problems solved, you may still not feel comfortable with jumping in and starting. Is it simple procrastination, or is it something more? Not Until You’re Ready offers advice on when it may be prudent to listen to that cautionary voice inside your head.\n\nStarting too soon is one problem, but waiting too long may be even worse. In The Speciﬁcation Trap, we’ll discuss the advantages of speci- ﬁcation by example.\n\nFinally, we’ll look at some of the pitfalls of formal development pro- cesses and methodologies in Circles and Arrows. No matter how well thought out it is, and regardless of which “best practices” it includes, no method can replace thinking.\n\nWith these critical issues sorted out before the project gets under way, you can be better positioned to avoid “analysis paralysis” and actually begin your successful project.\n\n201\n\n36\n\n202\n\nCHAPTER 7 BEFORE THE PROJECT\n\nThe Requirements Pit\n\nPerfection is achieved, not when there is nothing left to add, but when there is nothing left to take away. ...\n\nAntoine de St. Exupery, Wind,Sand,andStars, 1939\n\nMany books and tutorials refer to requirements gathering as an early phase of the project. The word “gathering” seems to imply a tribe of happy analysts, foraging for nuggets of wisdom that are lying on the ground all around them while the Pastoral Symphony plays gently in the background. “Gathering” implies that the requirements are already there—you need merely ﬁnd them, place them in your basket, and be merrily on your way.\n\nIt doesn’t quite work that way. Requirements rarely lie on the surface. Normally, they’re buried deep beneath layers of assumptions, miscon- ceptions, and politics.\n\nTIP 51\n\nDon’t Gather Requirements—Dig for Them\n\nDigging for Requirements How can you recognize a true requirement while you’re digging through all the surrounding dirt? The answer is both simple and complex.\n\nThe simple answer is that a requirement is a statement of something that needs to be accomplished. Good requirements might include the following:\n\nAn employee record may be viewed only by a nominated group of people.\n\nThe cylinder-head temperature must not exceed the critical value, which varies by engine.\n\nThe editor will highlight keywords, which will be selected depending on the type of ﬁle being edited.\n\nHowever, very few requirements are as clear-cut, and that’s what makes requirements analysis complex.\n\nTHE REQUIREMENTS PIT\n\nThe ﬁrst statement in the list above may have been stated by the users as “Only an employee’s supervisors and the personnel department may view that employee’s records.” Is this statement truly a requirement? Perhaps today, but it embeds business policy in an absolute statement. Policies change regularly, so we probably don’t want to hardwire them into our requirements. Our recommendation is to document these poli- cies separately from the requirement, and hyperlink the two. Make the requirement the general statement, and give the developers the policy information as an example of the type of thing they’ll need to support in the implementation. Eventually, policy may end up as metadata in the application.\n\nThis is a relatively subtle distinction, but it’s one that will have pro- found implications for the developers. If the requirement is stated as “Only personnel can view an employee record,” the developer may end up coding an explicit test every time the application accesses these ﬁles. However, if the statement is “Only authorized users may access an employee record,” the developer will probably design and implement some kind of access control system. When policy changes (and it will), only the metadata for that system will need to be updated. In fact, gath- ering requirements in this way naturally leads you to a system that is well factored to support metadata.\n\nThe distinctions among requirements, policy, and implementation can get very blurred when user interfaces are discussed. “The system must let you choose a loan term” is a statement of requirement. “We need a list box to select the loan term” may or may not be. If the users absolutely must have a list box, then it is a requirement. If instead they are describing the ability to choose, but are using listbox as an example, then it may not be. The box on page 205 discusses a project that went horribly wrong because the users’ interface needs were ignored.\n\nIt’s important to discover the underlying reason why users do a par- ticular thing, rather than just the way they currently do it. At the end of the day, your development has to solve their business problem, not just meet their stated requirements. Documenting the reasons behind requirements will give your team invaluable information when making daily implementation decisions.\n\nThere’s a simple technique for getting inside your users’ requirements that isn’t used often enough: become a user. Are you writing a system\n\n203\n\n204\n\nCHAPTER 7 BEFORE THE PROJECT\n\nfor the help desk? Spend a couple of days monitoring the phones with an experienced support person. Are you automating a manual stock control system? Work in the warehouse for a week.1 As well as giving you insight into how the system will really be used, you’d be amazed at how the request “May I sit in for a week while you do your job?” helps build trust and establishes a basis for communication with your users. Just remember not to get in the way!\n\nTIP 52\n\nWork with a User to Think Like a User\n\nThe requirements mining process is also the time to start to build a rap- port with your user base, learning their expectations and hopes for the system you are building. See Great Expectations, page 255, for more.\n\nDocumenting Requirements So you are sitting down with the users and prying genuine require- ments from them. You come across a few likely scenarios that describe what the application needs to do. Ever the professional, you want to write these down and publish a document that everyone can use as a basis for discussions—the developers, the end users, and the project sponsors.\n\nThat’s a pretty wide audience.\n\nIvar Jacobson [Jac94] proposed the concept of use cases to capture requirements. They let you describe a particular use of the system— not in terms of user interface, but in a more abstract fashion. Unfortu- nately, Jacobson’s book was a little vague on details, so there are now many different opinions on what a use case should be. Is it formal or informal, simple prose or a structured document (like a form)? What level of detail is appropriate (remember we have a wide audience)?\n\n1. Does a week sound like a long time? It really isn’t, particularly when you’re looking at processes in which management and workers occupy different worlds. Management will give you one view of how things operate, but when you get down on the ﬂoor, you’ll ﬁnd a very different reality—one that will take time to assimilate.\n\nTHE REQUIREMENTS PIT\n\nSometimes the Interface Isthe System\n\nIn an article in Wired magazine (January 1999, page 176), pro- ducer and musician Brian Eno described an incredible piece of technology—the ultimate mixing board. It does anything to sound that can be done. And yet, instead of letting musicians make better music, or produce a recording faster or less expensively, it gets in the way; it disrupts the creative process.\n\nTo see why, you have to look at how recording engineers work. They balance sounds intuitively. Over the years, they develop an innate feedback loop between their ears and their ﬁngertips—sliding faders, rotating knobs, and so on. However, the interface to the new mixer didn’t leverage off those abilities. Instead, it forced its users to type on a keyboard or click a mouse. The functions it provided were com- prehensive, but they were packaged in unfamiliar and exotic ways. The functions the engineers needed were sometimes hidden behind obscure names, or were achieved with nonintuitive combinations of basic facilities.\n\nThat environment has a requirement to leverage existing skill sets. While slavishly duplicating what already exists doesn’t allow for progress, we must be able to provide a transitionto the future.\n\nFor example, the recording engineers may have been better served by some sort of touchscreen interface—still tactile, still mounted as a traditional mixing board might be, yet allowing the software to go be- yond the realm of ﬁxed knobs and switches. Providing a comfortable transition through familiar metaphors is one way to help get buy-in.\n\nThis example also illustrates our belief that successful tools adapt to the hands that use them. In this case, it is the tools that you build for others that must be adaptable.\n\nOne way of looking at use cases is to emphasize their goal-driven nature. Alistair Cockburn has a paper that describes this approach, as well as templates that can be used (strictly or not) as a starting place ([Coc97a], also online at [URL 46]). Figure 7.1 on the following page shows an abbreviated example of his template, while Figure 7.2 shows his sample use case.\n\nBy using a formal template as an aide-mémoire, you can be sure that you include all the information you need in a use case: performance\n\n205\n\n206\n\nCHAPTER 7 BEFORE THE PROJECT\n\nFigure 7.1. Cockburn’s use case template\n\nA. CHARACTERISTIC INFORMATION\n\n– Goal in context – Scope – Level – Preconditions – Success end condition – Failed end condition – Primary actor – Trigger\n\nB. MAIN SUCCESS SCENARIO C. EXTENSIONS D. VARIATIONS E. RELATED INFORMATION\n\n– – – – Superordinate use case – Subordinate use cases – Channel to primary actor – Secondary actors – Channel to secondary actors\n\nPriority Performance target Frequency\n\nF. SCHEDULE G. OPEN ISSUES\n\ncharacteristics, other involved parties, priority, frequency, and various errors and exceptions that can crop up (“nonfunctional requirements”). This is also a great place to record user comments such as “oh, except if we get a xxx condition, then we have to do yyy instead.” The template also serves as a ready-made agenda for meetings with your users.\n\nThis sort of organization supports the hierarchical structuring of use cases—nesting more detailed use cases inside higher-level ones. For example, post debit and post credit both elaborate on post transaction.\n\nUseCaseDiagrams Workﬂow can be captured with UML activity diagrams, and conceptual- level class diagrams can sometimes be useful for modeling the business\n\nTHE REQUIREMENTS PIT\n\nFigure 7.2. A sample use case\n\nUSE CASE 5: BUY GOODS\n\nA. CHARACTERISTIC INFORMATION\n\nGoal in context: Buyer issues request directly to our company, expects goods shipped and to be billed. Scope: Company Level: Summary Preconditions: We know buyer, their address, etc. Success end condition: Buyer has goods, we have money for the goods. Failed end condition: We have not sent the goods, buyer has not sent the money. Primary actor: Buyer, any agent (or computer) acting for the customer Trigger: Purchase request comes in.\n\nB. MAIN SUCCESS SCENARIO\n\n1. Buyer calls in with a purchase request. 2. Company captures buyer’s name, address, requested goods, etc. 3. Company gives buyer information on goods, prices, delivery dates, etc. 4. Buyer signs for order. 5. Company creates order, ships order to buyer. 6. Company ships invoice to buyer. 7. Buyer pays invoice.\n\nC. EXTENSIONS\n\n3a. Company is out of one of the ordered items: Renegotiate order. 4a. Buyer pays directly with credit card: Take payment by credit card (use\n\ncase 44).\n\n7a. Buyer returns goods: Handle returned goods (use case 105).\n\nD. VARIATIONS\n\n1. Buyer may use phone in, fax in, Web order form, electronic interchange. 7. Buyer may pay by cash, money order, check, or credit card.\n\nE. RELATED INFORMATION Priority: Top Performance target: 5 minutes for order, 45 days until paid Frequency: 200/day Superordinate use case: Manage customer relationship (use case 2). Subordinate use cases: Create order (15). Take payment by credit card (44). Handle returned goods (105). Channel to primary actor: May be phone, ﬁle, or interactive Secondary actors: Credit card company, bank, shipping service\n\nF. SCHEDULE\n\nDue date: Release 1.0\n\nG. OPEN ISSUES\n\nWhat happens if we have part of the order? What happens if credit card is stolen?\n\n207\n\n208\n\nCHAPTER 7 BEFORE THE PROJECT\n\nFigure 7.3. UML use cases—so simple a child could do it!\n\nGo home\n\nat hand. But true use cases are textual descriptions, with a hierarchy and cross-links. Use cases can contain hyperlinks to other use cases, and they can be nested within each other.\n\nIt seems incredible to us that anyone would seriously consider docu- menting information this dense using only simplistic stick people such as Figure 7.3. Don’t be a slave to any notation; use whatever method best communicates the requirements with your audience.\n\nOverspecifying A big danger in producing a requirements document is being too spe- ciﬁc. Good requirements documents remain abstract. Where require- ments are concerned, the simplest statement that accurately reﬂects the business need is best. This doesn’t mean you can be vague—you must capture the underlying semantic invariants as requirements, and document the speciﬁc or current work practices as policy.\n\nRequirements are not architecture. Requirements are not design, nor are they the user interface. Requirements are need.\n\nSeeing Further The Year 2000 problem is often blamed on short-sighted programmers, desperate to save a few bytes in the days when mainframes had less memory than a modern TV remote control.\n\nBut it wasn’t the programmers’ doing, and it wasn’t really a memory usage issue. If anything, it was the system analysts’ and designers’ fault. The Y2K problem came about from two main causes: a failure to see beyond current business practice, and a violation of the DRY principle.",
      "page_number": 225
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 233-240)",
      "start_page": 233,
      "end_page": 240,
      "detection_method": "topic_boundary",
      "content": "THE REQUIREMENTS PIT\n\nBusinesses were using the two-digit shortcut long before computers came on the scene. It was common practice. The earliest data process- ing applications merely automated existing business processes, and simply repeated the mistake. Even if the architecture required two-digit years for data input, reporting, and storage, there should have been an abstraction of a DATE that “knew” the two digits were an abbreviated form of the real date.\n\nTIP 53\n\nAbstractions Live Longer than Details\n\nDoes “seeing further” require you to predict the future? No. It means generating statements such as\n\nThe system makes active use of an abstraction of DATEs. The system will implement DATE services, such as formatting, storage, and math operations, consistently and universally.\n\nThe requirements will specify only that dates are used. It may hint that some math may be done on dates. It may tell you that dates will be stored on various forms of secondary storage. These are genuine requirements for a DATE module or class.\n\nJust OneMore Wafer-ThinMint... Many projects failures are blamed on an increase in scope—also known as feature bloat, creeping featurism, or requirements creep. This is an aspect of the boiled-frog syndrome from Stone Soup and Boiled Frogs, page 7. What can we do to prevent requirements from creeping up on us?\n\nIn the literature, you will ﬁnd descriptions of many metrics, such as bugs reported and ﬁxed, defect density, cohesion, coupling, function points, lines of code, and so on. These metrics may be tracked by hand or with software.\n\nUnfortunately, not many projects seem to track requirements actively. This means that they have no way to report on changes of scope— who requested a feature, who approved it, total number of requests approved, and so on.\n\n209\n\n210\n\nCHAPTER 7 BEFORE THE PROJECT\n\nThe key to managing growth of requirements is to point out each new feature’s impact on the schedule to the project sponsors. When the project is a year late from initial estimates and accusations start ﬂying, it can be helpful to have an accurate, complete picture of how, and when, requirements growth occurred.\n\nIt’s easy to get sucked into the “just one more feature” maelstrom, but by tracking requirements you can get a clearer picture that “just one more feature” is really the ﬁfteenth new feature added this month.\n\nMaintain a Glossary As soon as you start discussing requirements, users and domain ex- perts will use certain terms that have speciﬁc meaning to them. They may differentiate between a “client” and a “customer,” for example. It would then be inappropriate to use either word casually in the system.\n\nCreate and maintain a project glossary—one place that deﬁnes all the speciﬁc terms and vocabulary used in a project. All participants in the project, from end users to support staff, should use the glossary to ensure consistency. This implies that the glossary needs to be widely accessible—a good argument for Web-based documentation (more on that in a moment).\n\nTIP 54\n\nUse a Project Glossary\n\nIt’s very hard to succeed on a project where the users and develop- ers refer to the same thing by different names or, even worse, refer to different things by the same name.\n\nGet theWord Out In It’s All Writing, page 248, we discuss publishing of project documents to internal Web sites for easy access by all participants. This method of distribution is particularly useful for requirements documents.\n\nBy presenting requirements as a hypertext document, we can better address the needs of a diverse audience—we can give each reader what\n\nTHE REQUIREMENTS PIT\n\nthey want. Project sponsors can cruise along at a high level of abstrac- tion to ensure that business objectives are met. Programmers can use hyperlinks to “drill down” to increasing levels of detail (even referencing appropriate deﬁnitions or engineering speciﬁcations).\n\nWeb-based distribution also avoids the typical two-inch-thick binder entitled Requirements Analysis that no one ever reads and that becomes outdated the instant ink hits paper.\n\nIf it’s on the Web, the programmers may even read it.\n\nRelated sections include:\n\nStone Soup and Boiled Frogs, page 7 Good-Enough Software, page 9 Circles and Arrows, page 220 It’s All Writing, page 248 Great Expectations, page 255\n\nChallenges\n\nCan you use the software you are writing? Is it possible to have a good feel for requirements without being able to use the software yourself?\n\nPick a non-computer-related problem you currently need to solve. Gener- ate requirements for a noncomputer solution.\n\nExercises 42. Which of the following are probably genuine requirements? Restate those\n\nthat are not to make them more useful (if possible).\n\n1. The response time must be less than 500 ms.\n\n2. Dialog boxes will have a gray background.\n\n3. The application will be organized as a number of front-end processes\n\nand a back-end server.\n\n4. If a user enters non-numeric characters in a numeric ﬁeld, the system\n\nwill beep and not accept them.\n\n5. The application code and data must ﬁt within 256kB.\n\n211\n\nAnswer on p. 307\n\n212\n\nCHAPTER 7 BEFORE THE PROJECT\n\n37 Solving Impossible Puzzles\n\nGordius, the King of Phrygia, once tied a knot that no one could untie. It was said that he who solved the riddle of the Gordian Knot would rule all of Asia. So along comes Alexander the Great, who chops the knot to bits with his sword. Just a and he did end up little different interpretation of the requirements, that’s all ruling most of Asia.\n\nEvery now and again, you will ﬁnd yourself embroiled in the middle of a project when a really tough puzzle comes up: some piece of engineering that you just can’t get a handle on, or perhaps some bit of code that is turning out to be much harder to write than you thought. Maybe it looks impossible. But is it really as hard as it seems?\n\nConsider real-world puzzles—those devious little bits of wood, wrought iron, or plastic that seem to turn up as Christmas presents or at garage sales. All you have to do is remove the ring, or ﬁt the T-shaped pieces in the box, or whatever.\n\nSo you pull on the ring, or try to put the T’s in the box, and quickly discover that the obvious solutions just don’t work. The puzzle can’t be solved that way. But even though it’s obvious, that doesn’t stop people from trying the same thing—over and over—thinking there must be a way.\n\nOf course, there isn’t. The solution lies elsewhere. The secret to solving the puzzle is to identify the real (not imagined) constraints, and ﬁnd a solution therein. Some constraints are absolute; others are merely preconceived notions. Absolute constraints must be honored, however distasteful or stupid they may appear to be. On the other hand, some apparent constraints may not be real constraints at all. For example, there’s that old bar trick where you take a brand new, unopened cham- pagne bottle and bet that you can drink beer out of it. The trick is to turn the bottle upside down, and pour a small quantity of beer in the hollow in the bottom of the bottle. Many software problems can be just as sneaky.\n\nDegrees of Freedom The popular buzz-phrase “thinking outside the box” encourages us to recognize constraints that might not be applicable and to ignore them.\n\nSOLVING IMPOSSIBLE PUZZLES\n\nBut this phrase isn’t entirely accurate. If the “box” is the boundary of constraints and conditions, then the trick is to ﬁnd the box, which may be considerably larger than you think.\n\nThe key to solving puzzles is both to recognize the constraints placed on you and to recognize the degrees of freedom you do have, for in those you’ll ﬁnd your solution. This is why some puzzles are so effective; you may dismiss potential solutions too readily.\n\nFor example, can you connect all of the dots in the following puzzle and return to the starting point with just three straight lines—without lifting your pen from the paper or retracing your steps [Hol78]?\n\nYou must challenge any preconceived notions and evaluate whether or not they are real, hard-and-fast constraints.\n\nIt’s not whether you think inside the box or outside the box. The prob- lem lies in ﬁnding the box—identifying the real constraints.\n\nTIP 55\n\nDon’t Think Outside the Box—Find the Box\n\nWhen faced with an intractable problem, enumerate all the possible avenues you have before you. Don’t dismiss anything, no matter how unusable or stupid it sounds. Now go through the list and explain why a certain path cannot be taken. Are you sure? Can you prove it?\n\nConsider the Trojan horse—a novel solution to an intractable problem. How do you get troops into a walled city without being discovered? You can bet that “through the front door” was initially dismissed as suicide.\n\nCategorize and prioritize your constraints. When woodworkers begin a project, they cut the longest pieces ﬁrst, then cut the smaller pieces out of the remaining wood. In the same manner, we want to identify the most restrictive constraints ﬁrst, and ﬁt the remaining constraints within them.\n\nBy the way, a solution to the Four Posts puzzle is shown on page 307.\n\n213\n\n214\n\nCHAPTER 7 BEFORE THE PROJECT\n\nThereMust BeanEasierWay! Sometimes you will ﬁnd yourself working on a problem that seems much harder than you thought it should be. Maybe it feels like you’re going down the wrong path—that there must be an easier way than this! Perhaps you are running late on the schedule now, or even despair of ever getting the system to work because this particular problem is “impossible.”\n\nThat’s when you step back a pace and ask yourself these questions:\n\nIs there an easier way?\n\nAre you trying to solve the right problem, or have you been dis- tracted by a peripheral technicality?\n\nWhy is this thing a problem?\n\nWhat is it that’s making it so hard to solve?\n\nDoes it have to be done this way?\n\nDoes it have to be done at all?\n\nMany times a surprising revelation will come to you as you try to answer one of these questions. Many times a reinterpretation of the require- ments can make a whole set of problems go away—just like the Gordian knot.\n\nAll you need are the real constraints, the misleading constraints, and the wisdom to know the difference.\n\nChallenges\n\nTake a hard look at whatever difﬁcult problem you are embroiled in today. Can you cut the Gordian knot? Ask yourself the key questions we outlined above, especially “Does it have to be done this way?”\n\nWere you handed a set of constraints when you signed on to your current project? Are they all still applicable, and is the interpretation of them still valid?\n\nNOT UNTIL YOU’RE READY\n\n38 Not Until You’re Ready\n\nHe who hesitates is sometimes saved.\n\nJames Thurber, TheGlassintheField\n\nGreat performers share a trait: they know when to start and when to wait. The diver stands on the high-board, waiting for the perfect moment to jump. The conductor stands before the orchestra, arms raised, until she senses that the moment is right to start the piece.\n\nYou are a great performer. You too need to listen to the voice that whis- pers “wait.” If you sit down to start typing and there’s some nagging doubt in your mind, heed it.\n\nTIP 56\n\nListen to Nagging Doubts—Start When You’re Ready\n\nThere used to be a style of tennis coaching called “inner tennis.” You’d spend hours hitting balls over the net, not particularly trying for accu- racy, but instead verbalizing just where the ball hit relative to some target (often a chair). The idea was that the feedback would train your subconscious and reﬂexes, so that you improved without consciously knowing how or why.\n\nAs a developer, you’ve been doing the same kind of thing during your entire career. You’ve been trying things and seeing which worked and which didn’t. You’ve been accumulating experience and wisdom. When you feel a nagging doubt, or experience some reluctance when faced with a task, heed it. You may not be able to put your ﬁnger on exactly what’s wrong, but give it time and your doubts will probably crystal- lize into something more solid, something you can address. Software development is still not a science. Let your instincts contribute to your performance.\n\nGoodJudgment or Procrastination? Everyone fears the blank sheet of paper. Starting a new project (or even a new module in an existing project) can be an unnerving experience. Many of us would prefer to put off making the initial commitment of\n\n215\n\n216\n\nCHAPTER 7 BEFORE THE PROJECT\n\nstarting. So how can you tell when you’re simply procrastinating, rather than responsibly waiting for all the pieces to fall into place?\n\nA technique that has worked for us in these circumstances is to start prototyping. Choose an area that you feel will be difﬁcult and begin producing some kind of proof of concept. One of two things will typi- cally happen. Shortly after starting, you may feel that you’re wasting your time. This boredom is probably a good indication that your initial reluctance was just a desire to put off the commitment to start. Give up on the prototype, and hack into the real development.\n\nOn the other hand, as the prototype progresses you may have one of those moments of revelation when you suddenly realize that some basic premise was wrong. Not only that, but you’ll see clearly how you can put it right. You’ll feel comfortable abandoning the prototype and launching into the project proper. Your instincts were right, and you’ve just saved yourself and your team a considerable amount of wasted effort.\n\nWhen you make the decision to prototype as a way of investigating your unease, be sure to remember why you’re doing it. The last thing you want is to ﬁnd yourself several weeks into serious development before remembering that you started out writing a prototype.\n\nSomewhat cynically, starting work on a prototype might also be more politically acceptable than simply announcing that “I don’t feel right about starting” and ﬁring up solitaire.\n\nChallenges\n\nDiscuss the fear-of-starting syndrome with your colleagues. Do others ex- perience the same thing? Do they heed it? What tricks do they use to overcome it? Can a group help overcome an individual’s reluctance, or is that just peer pressure?",
      "page_number": 233
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 241-248)",
      "start_page": 241,
      "end_page": 248,
      "detection_method": "topic_boundary",
      "content": "39\n\nTHE SPECIFICATION TRAP\n\nThe Speciﬁcation Trap\n\nThe Landing Pilot is the Non-Handling Pilot until the ‘decision altitude’ call, when the Handling Non-Landing Pilot hands the handling to the Non-Handling Land- ing Pilot, unless the latter calls ‘go-around,’ in which case the Handling Non- Landing Pilot continues handling and the Non-Handling Landing Pilot continues non-handling until the next call of ‘land’ or ‘go-around’ as appropriate. In view of recent confusions over these rules, it was deemed necessary to restate them clearly.\n\nBritish Airways memorandum, quoted in Pilot Magazine, December 1996\n\nProgram speciﬁcation is the process of taking a requirement and reduc- ing it down to the point where a programmer’s skill can take over. It is an act of communication, explaining and clarifying the world in such a way as to remove major ambiguities. As well as talking to the developer who will be performing the initial implementation, the speciﬁcation is a record for future generations of programmers who will be maintaining and enhancing the code. The speciﬁcation is also an agreement with the user—a codiﬁcation of their needs and an implicit contract that the ﬁnal system will be in line with that requirement.\n\nWriting a speciﬁcation is quite a responsibility.\n\nThe problem is that many designers ﬁnd it difﬁcult to stop. They feel that unless every little detail is pinned down in excruciating detail they haven’t earned their daily dollar.\n\nThis is a mistake for several reasons. First, it’s naive to assume that a speciﬁcation will ever capture every detail and nuance of a system or its requirement. In restricted problem domains, there are formal methods that can describe a system, but they still require the designer to explain the meaning of the notation to the end users—there is still a human interpretation going on to mess things up. Even without the problems inherent in this interpretation, it is very unlikely that the average user knows going in to a project exactly what they need. They may say they have an understanding of the requirement, and they may sign off on the 200-page document you produce, but you can guarantee that once they see the running system you’ll be inundated with change requests.\n\nSecond, there is a problem with the expressive power of language it- self. All the diagramming techniques and formal methods still rely on\n\n217\n\n218\n\nCHAPTER 7 BEFORE THE PROJECT\n\nnatural language expressions of the operations to be performed.2 And natural language is really not up to the job. Look at the wording of any contract: in an attempt to be precise, lawyers have to bend the language in the most unnatural ways.\n\nHere’s a challenge for you. Write a short description that tells someone how to tie bows in their shoelaces. Go on, try it!\n\nIf you are anything like us, you probably gave up somewhere around “now roll your thumb and foreﬁnger so that the free end passes under and inside the left lace. .. .” It is a phenomenally difﬁcult thing to do. And yet most of us can tie our shoes without conscious thought.\n\nTIP 57\n\nSome Things Are Better Done than Described\n\nFinally, there is the straightjacket effect. A design that leaves the coder no room for interpretation robs the programming effort of any skill and art. Some would say this is for the best, but they’re wrong. Often, it is only during coding that certain options become apparent. While coding, you may think “Look at that. Because of the particular way I coded this routine, I could add this additional functionality with almost no effort” or “The speciﬁcation says to do this, but I could achieve an almost identical result by doing it a different way, and I could do it in half the time.” Clearly, you shouldn’t just hack in and make the changes, but you wouldn’t even have spotted the opportunity if you were constrained by an overly prescriptive design.\n\nAs a Pragmatic Programmer, you should tend to view requirements gathering, design, and implementation as different facets of the same process—the delivery of a quality system. Distrust environments where requirements are gathered, speciﬁcations are written, and then coding starts, all in isolation. Instead, try to adopt a seamless approach: spec- iﬁcation and implementation are simply different aspects of the same process—an attempt to capture and codify a requirement. Each should\n\n2. There are some formal techniques that attempt to express operations algebraically, but these techniques are rarely used in practice. They still require that the analysts explain the meaning to the end users.\n\nTHE SPECIFICATION TRAP\n\nﬂow directly into the next, with no artiﬁcial boundaries. You’ll ﬁnd that a healthy development process encourages feedback from implementa- tion and testing into the speciﬁcation process.\n\nJust to be clear, we are not against generating speciﬁcations. Indeed, we recognize that there are times where incredibly detailed speciﬁcations are demanded—for contractual reasons, because of the environment where you work, or because of the nature of the product you are de- veloping.3 Just be aware that you reach a point of diminishing, or even negative, returns as the speciﬁcations get more and more detailed. Also be careful about building speciﬁcations layered on top of speciﬁcations, without any supporting implementation or prototyping; it’s all too easy to specify something that can’t be built.\n\nThe longer you allow speciﬁcations to be security blankets, protecting developers from the scary world of writing code, the harder it will be to move on to hacking out code. Don’t fall into this speciﬁcation spiral: at some point, you need to start coding! If you ﬁnd your team all wrapped up in warm, comfy speciﬁcations, break them out. Look at prototyping, or consider a tracer bullet development.\n\nRelated sections include: Tracer Bullets, page 48\n\nChallenges\n\nThe shoelace example mentioned in the text is an interesting illustration of the problems of written descriptions. Did you consider describing the process using diagrams rather than words? Photographs? Some formal notation from topology? Models with wire laces? How would you teach a toddler?\n\nSometimes a picture is worth more than any number of words. Sometimes it is worthless. If you ﬁnd yourself overspecifying, would pictures or special notations help? How detailed do they have to be? When is a drawing tool better than a whiteboard?\n\n3. Detailed speciﬁcations are clearly appropriate for life-critical systems. We feel they should also be produced for interfaces and libraries used by others. When your entire output is seen as a set of routine calls, you’d better make sure those calls are well speciﬁed.\n\n219\n\n220\n\nCHAPTER 7 BEFORE THE PROJECT\n\n40 Circles and Arrows\n\n[photographs] with circles and arrows and a paragraph on the back of each one explaining what each one was, to be used as evidence against us. ..\n\nArlo Guthrie, “Alice’s Restaurant”\n\nFrom structured programming, through chief programmer teams, CASE tools, waterfall development, the spiral model, Jackson, ER diagrams, Booch clouds, OMT, Objectory, and Coad/Yourdon, to today’s UML, computing has never been short of methods intended to make pro- gramming more like engineering. Each method gathers its disciples, and each enjoys a period of popularity. Then each is replaced by the next. Of all of them, perhaps only the ﬁrst—structured programming— has enjoyed a long life.\n\nYet some developers, adrift in a sea of sinking projects, keep clinging to the latest fad just as shipwreck victims latch onto passing driftwood. As each new piece ﬂoats by they painfully swim over, hoping it will be better. At the end of the day, though, it doesn’t matter how good the ﬂotsam is, the developers are still aimlessly adrift.\n\nDon’t get us wrong. We like (some) formal techniques and methods. But we believe that blindly adopting any technique without putting it into the context of your development practices and capabilities is a recipe for disappointment.\n\nTIP 58\n\nDon’t Be a Slave to Formal Methods\n\nFormal methods have some serious shortcomings.\n\nMost formal methods capture requirements using a combination of diagrams and some supporting words. These pictures represent the designers’ understanding of the requirements. However in many cases these diagrams are meaningless to the end users, so the designers have to interpret them. Therefore, there is no real formal checking of the requirements by the actual user of the system— everything is based on the designers’ explanations, just as in old- fashioned written requirements. We see some beneﬁt in capturing requirements this way, but we prefer, where possible, to show the user a prototype and let them play with it.\n\nCIRCLES AND ARROWS\n\nFormal methods seem to encourage specialization. One group of people works on a data model, another looks at the architecture, while requirements gatherers collect use cases (or their equivalent). We’ve seen this lead to poor communication and wasted effort. There is also a tendency to fall back into the us versus them mental- ity of designers against coders. We prefer to understand the whole of the system we’re working on. It may not be possible to have an in-depth grasp of every aspect of a system, but you should know how the components interact, where the data lives, and what the requirements are.\n\nWe like to write adaptable, dynamic systems, using metadata to allow us to change the character of applications at runtime. Most current formal methods combine a static object or data model with some kind of event- or activity-charting mechanism. We haven’t yet come across one that allows us to illustrate the kind of dynamism we feel systems should exhibit. In fact, most formal methods will lead you astray, encouraging you to set up static relationships between objects that really should be knitted together dynamically.\n\nDoMethods PayOff? In a 1999 CACM article [Gla99b], Robert Glass reviews the research into the productivity and quality improvements gained using seven different software development technologies (4GLs, structured tech- niques, CASE tools, formal methods, clean room methodology, process models, and object orientation). He reports that the initial hype sur- rounding all of these methods was overblown. Although there is an indication that some methods have beneﬁts, these beneﬁts start to manifest themselves only after a signiﬁcant productivity and quality drop while the technique is adopted and its users train themselves. Never underestimate the cost of adopting new tools and methods. Be prepared to treat the ﬁrst projects using these techniques as a learning experience.\n\nShouldWeUseFormalMethods? Absolutely. But always remember that formal development methods are just one more tool in the toolbox. If, after careful analysis, you feel you need to use a formal method, then embrace it—but remember who is in charge. Never become a slave to a methodology: circles and\n\n221\n\n222\n\nCHAPTER 7 BEFORE THE PROJECT\n\narrows make poor masters. Pragmatic Programmers look at methodolo- gies critically, then extract the best from each and meld them into a set of working practices that gets better each month. This is crucial. You should work constantly to reﬁne and improve your processes. Never accept the rigid conﬁnes of a methodology as the limits of your world.\n\nDon’t give in to the false authority of a method. People may walk into meetings with an acre of class diagrams and 150 use cases, but all that paper is still just their fallible interpretation of requirements and design. Try not to think about how much a tool cost when you look at its output.\n\nTIP 59\n\nExpensive Tools Do Not Produce Better Designs\n\nFormal methods certainly have their place in development. However, if you come across a project where the philosophy is “the class diagram is the application, the rest is mechanical coding,” you know you’re looking at a waterlogged project team and a long paddle home.\n\nRelated sections include:\n\nThe Requirements Pit, page 202\n\nChallenges\n\nUse case diagrams are part of the UML process for gathering requirements (see The Requirements Pit, page 202). Are they an effective way of commu- nicating with your users? If not, why are you using them?\n\nHow can you tell if a formal method is bringing your team beneﬁts? What can you measure? What constitutes an improvement? Can you distinguish between beneﬁts of the tool and increased experience on the part of team members?\n\nWhere is the break-even point for introducing new methods to your team? How do you evaluate the trade-off between future beneﬁts and current losses of productivity as the tool is introduced?\n\nAre tools that work for large projects good for small ones? How about the other way around?\n\nChapter 8\n\nPragmatic Projects\n\nAs your project gets under way, we need to move away from issues of individual philosophy and coding to talk about larger, project-sized issues. We aren’t going to go into speciﬁcs of project management, but we will talk about a handful of critical areas that can make or break any project.\n\nAs soon as you have more than one person working on a project, you need to establish some ground rules and delegate parts of the project accordingly. In Pragmatic Teams, we’ll show how to do this while hon- oring the pragmatic philosophy.\n\nThe single most important factor in making project-level activities work consistently and reliably is to automate your procedures. We’ll explain why, and show some real-life examples in Ubiquitous Automation.\n\nEarlier, we talked about testing as you code. In Ruthless Testing, we go to the next step of project-wide testing philosophy and tools—especially if you don’t have a large QA staff at your beck and call.\n\nThe only thing that developers dislike more than testing is documenta- tion. Whether you have technical writers helping you or are doing it on your own, we’ll show you how to make the chore less painful and more productive in It’s All Writing.\n\nSuccess is in the eye of the beholder—the sponsor of the project. The perception of success is what counts, and in Great Expectations we’ll show you some tricks to delight every project’s sponsor.\n\n223\n\n41\n\n224\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nThe last tip in the book is a direct consequence of all the rest. In Pride and Prejudice, we encourage you to sign your work, and to take pride in what you do.\n\nPragmatic Teams\n\nAt Group L, Stoffel oversees six ﬁrst-rate programmers, a managerial challenge roughly comparable to herding cats.\n\nThe Washington Post Magazine, June 9, 1985\n\nSo far in this book we’ve looked at pragmatic techniques that help an individual be a better programmer. Can these methods work for teams as well?\n\nThe answer is a resounding “yes!” There are advantages to being a prag- matic individual, but these advantages are multiplied manyfold if the individual is working on a pragmatic team.\n\nIn this section we’ll look brieﬂy at how pragmatic techniques can be applied to teams as a whole. These notes are only a start. Once you’ve got a group of pragmatic developers working in an enabling environ- ment, they’ll quickly develop and reﬁne their own team dynamics that work for them.\n\nLet’s recast some of the previous sections in terms of teams.\n\nNo Broken Windows Quality is a team issue. The most diligent developer placed on a team that just doesn’t care will ﬁnd it difﬁcult to maintain the enthusiasm needed to ﬁx niggling problems. The problem is further exacerbated if the team actively discourages the developer from spending time on these ﬁxes.\n\nTeams as a whole should not tolerate broken windows—those small imperfections that no one ﬁxes. The team must take responsibility for the quality of the product, supporting developers who understand the no broken windows philosophy we describe in Software Entropy, page 4, and encouraging those who haven’t yet discovered it.",
      "page_number": 241
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 249-256)",
      "start_page": 249,
      "end_page": 256,
      "detection_method": "topic_boundary",
      "content": "PRAGMATIC TEAMS\n\nSome team methodologies have a quality ofﬁcer—someone to whom the team delegates the responsibility for the quality of the deliverable. This is clearly ridiculous: quality can come only from the individual contri- butions of all team members.\n\nBoiledFrogs Remember the poor frog in the pan of water, back in Stone Soup and Boiled Frogs, page 7? It doesn’t notice the gradual change in its en- vironment, and ends up cooked. The same can happen to individuals who aren’t vigilant. It can be difﬁcult to keep an eye on your overall environment in the heat of project development.\n\nIt’s even easier for teams as a whole to get boiled. People assume that someone else is handling an issue, or that the team leader must have OK’d a change that your user is requesting. Even the best-intentioned teams can be oblivious to signiﬁcant changes in their projects.\n\nFight this. Make sure everyone actively monitors the environment for changes. Maybe appoint a chief water tester. Have this person check constantly for increased scope, decreased time scales, additional fea- tures, new environments—anything that wasn’t in the original agree- ment. Keep metrics on new requirements (see page 209). The team needn’t reject changes out of hand—you simply need to be aware that they’re happening. Otherwise, it’ll be you in the hot water.\n\nCommunicate It’s obvious that developers in a team must talk to each other. We gave some suggestions to facilitate this in Communicate! on page 18. How- ever, it’s easy to forget that the team itself has a presence within the organization. The team as an entity needs to communicate clearly with the rest of the world.\n\nTo outsiders, the worst project teams are those that appear sullen and reticent. They hold meetings with no structure, where no one wants to talk. Their documents are a mess: no two look the same, and each uses different terminology.\n\nGreat project teams have a distinct personality. People look forward to meetings with them, because they know that they’ll see a well-prepared\n\n225\n\n226\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nperformance that makes everyone feel good. The documentation they produce is crisp, accurate, and consistent. The team speaks with one voice.1 They may even have a sense of humor.\n\nThere is a simple marketing trick that helps teams communicate as one: generate a brand. When you start a project, come up with a name for it, ideally something off-the-wall. (In the past, we’ve named projects after things such as killer parrots that prey on sheep, optical illusions, and mythical cities.) Spend 30 minutes coming up with a zany logo, and use it on your memos and reports. Use your team’s name liberally when talking with people. It sounds silly, but it gives your team an identity to build on, and the world something memorable to associate with your work.\n\nDon’t RepeatYourself In The Evils of Duplication, page 26, we talked about the difﬁculties of eliminating duplicated work between members of a team. This duplica- tion leads to wasted effort, and can result in a maintenance nightmare. Clearly good communication can help here, but sometimes something extra is needed.\n\nSome teams appoint a member as the project librarian, responsible for coordinating documentation and code repositories. Other team mem- bers can use this person as the ﬁrst port of call when they’re look- ing for something. A good librarian will also be able to spot impending duplication by reading the material that they’re handling.\n\nWhen the project’s too big for one librarian (or when no one wants to play the role), appoint people as focal points for various functional aspects of the work. If people want to talk over date handling, they should know to talk with Mary. If there’s a database schema issue, see Fred.\n\nAnd don’t forget the value of groupware systems and local Usenet news- groups for communicating and archiving questions and answers.\n\n1. robust debate. Good developers tend to be passionate about their work.\n\nThe team speaks with one voice—externally. Internally, we strongly encourage lively,\n\nPRAGMATIC TEAMS\n\nOrthogonality Traditional team organization is based on the old-fashioned waterfall method of software construction. Individuals are assigned roles based on their job function. You’ll ﬁnd business analysts, architects, design- ers, programmers, testers, documenters, and the like.2 There is an implicit hierarchy here—the closer to the user you’re allowed, the more senior you are.\n\nTaking things to the extreme, some development cultures dictate strict divisions of responsibility; coders aren’t allowed to talk to testers, who in turn aren’t allowed to talk to the chief architect, and so on. Some organizations then compound the problem by having different sub- teams report through separate management chains.\n\nIt is a mistake to think that the activities of a project—analysis, design, coding, and testing—can happen in isolation. They can’t. These are different views of the same problem, and artiﬁcially separating them can cause a boatload of trouble. Programmers who are two or three levels removed from the actual users of their code are unlikely to be aware of the context in which their work is used. They will not be able to make informed decisions.\n\nTIP 60\n\nOrganize Around Functionality, Not Job Functions\n\nWe favor splitting teams functionally. Divide your people into small teams, each responsible for a particular functional aspect of the ﬁnal system. Let the teams organize themselves internally, building on indi- vidual strengths as they can. Each team has responsibilities to others in the project, as deﬁned by their agreed-upon commitments. The exact set of commitments changes with each project, as does the allocation of people into teams.\n\nFunctionality here does not necessarily mean end-user use cases. The database access layer counts, as does the help subsystem. We’re look- ing for cohesive, largely self-contained teams of people—exactly the\n\n2. roles within a project team! [Kru98]\n\nIn The Rational Uniﬁed Process: An Introduction, the author identiﬁes 27 separate\n\n227\n\n228\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nsame criteria we should be using when we modularize code. There are warning signs that the team organization is wrong—a classic example is having two subteams working on the same program module or class.\n\nHow does this functional style of organization help? Organize our re- sources using the same techniques we use to organize code, using techniques such as contracts (Design by Contract, page 109), decou- pling (Decoupling and the Law of Demeter, page 138), and orthogonality (Orthogonality, page 34), and we help isolate the team as a whole from the effects of change. If the user suddenly decides to change database vendors, only the database team should be affected. Should marketing suddenly decide to use an off-the-shelf tool for the calendar function, the calendar group takes a hit. Properly executed, this kind of group approach can dramatically reduce the number of interactions between individuals’ work, reducing time scales, increasing quality, and cutting down on the number of defects. This approach can also lead to a more committed set of developers. Each team knows that they alone are re- sponsible for a particular function, so they feel more ownership of their output.\n\nHowever, this approach works only with responsible developers and strong project management. Creating a pool of autonomous teams and letting them loose without leadership is a recipe for disaster. The project needs at least two “heads”—one technical, the other administrative. The technical head sets the development philosophy and style, assigns responsibilities to teams, and arbitrates the inevitable “discussions” between people. The technical head also looks constantly at the big pic- ture, trying to ﬁnd any unnecessary commonality between teams that could reduce the orthogonality of the overall effort. The administrative head, or project manager, schedules the resources that the teams need, monitors and reports on progress, and helps decide priorities in terms of business needs. The administrative head might also act as the team’s ambassador when communicating with the outside world.\n\nTeams on larger projects need additional resources: a librarian who indexes and stores code and documentation, a tool builder who pro- vides common tools and environments, operational support, and so on.\n\nThis type of team organization is similar in spirit to the old chief pro- grammer team concept, ﬁrst documented in 1972 [Bak72].\n\nPRAGMATIC TEAMS\n\nAutomation A great way to ensure both consistency and accuracy is to automate everything the team does. Why lay code out manually when your editor can do it automatically as you type? Why complete test forms when the overnight build can run tests automatically?\n\nAutomation is an essential component of every project team—important enough for us to dedicate an entire section to it, starting on the follow- ing page. To ensure that things get automated, appoint one or more team members as tool builders to construct and deploy the tools that automate the project drudgery. Have them produce makeﬁles, shell scripts, editor templates, utility programs, and the like.\n\nKnowWhentoStopAdding Paint Remember that teams are made up of individuals. Give each member the ability to shine in his or her own way. Give them just enough struc- ture to support them and to ensure that the project delivers against its requirements. Then, like the painter in Good-Enough Software, page 11, resist the temptation to add more paint.\n\nRelated sections include:\n\nSoftware Entropy, page 4 Stone Soup and Boiled Frogs, page 7 Good-Enough Software, page 9 Communicate!, page 18 The Evils of Duplication, page 26 Orthogonality, page 34 Design by Contract, page 109 Decoupling and the Law of Demeter, page 138 Ubiquitous Automation, page 230\n\nChallenges\n\nLook around for successful teams outside the area of software develop- ment. What makes them successful? Do they use any of the processes discussed in this section?\n\n229\n\n230\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nNext time you start a project, try convincing people to brand it. Give your organization time to become used to the idea, and then do a quick audit to see what difference it made, both within the team and externally.\n\nTeam Algebra: In school, we are given problems such as “If it takes 4 work- ers 6 hours to dig a ditch, how long would it take 8 workers?” In real life, however, what factors affect the answer to: “If it takes 4 programmers 6 months to develop an application, how long would it take 8 programmers?” In how many scenarios is the time actually reduced?\n\n42 Ubiquitous Automation\n\nCivilization advances by extending the number of important operations we can perform without thinking.\n\nAlfred North Whitehead\n\nAt the dawn of the age of automobiles, the instructions for starting a Model-T Ford were more than two pages long. With modern cars, you just turn the key—the starting procedure is automatic and foolproof. A person following a list of instructions might ﬂood the engine, but the automatic starter won’t.\n\nAlthough computing is still an industry at the Model-T stage, we can’t afford to go through two pages of instructions again and again for some common operation. Whether it is the build and release procedure, code review paperwork, or any other recurring task on the project, it has to be automatic. We may have to build the starter and fuel injector from scratch, but once it’s done, we can just turn the key from then on.\n\nIn addition, we want to ensure consistency and repeatability on the project. Manual procedures leave consistency up to chance; repeatabil- ity isn’t guaranteed, especially if aspects of the procedure are open to interpretation by different people.\n\nUBIQUITOUS AUTOMATION\n\nAllon Automatic We were once at a client site where all the developers were using the same IDE. Their system administrator gave each developer a set of instructions on installing add-on packages to the IDE. These instruc- tions ﬁlled many pages—pages full of click here, scroll there, drag this, double-click that, and do it again.\n\nNot surprisingly, every developer’s machine was loaded slightly differ- ently. Subtle differences in the application’s behavior occurred when different developers ran the same code. Bugs would appear on one machine but not on others. Tracking down version differences of any one component usually revealed a surprise.\n\nTIP 61\n\nDon’t Use Manual Procedures\n\nPeople just aren’t as repeatable as computers are. Nor should we expect them to be. A shell script or batch ﬁle will execute the same instruc- tions, in the same order, time after time. It can be put under source control, so you can examine changes to the procedure over time as well (“but it used to work. .. ”).\n\nAnother favorite tool of automation is cron (or “at” on Windows NT). It allows us to schedule unattended tasks to run periodically—usually in the middle of the night. For example, the following crontab ﬁle speci- ﬁes that a project’s nightly command be run at ﬁve minutes past mid- night every day, that the backup be run at 3:15 a.m. on weekdays, and that expense_reports be run at midnight on the ﬁrst of the month.\n\n# MIN HOUR DAY MONTH DAYOFWEEK # ---------------------------------------------------------------\n\nCOMMAND\n\n5 15 0\n\n0 3 0\n\n* 1\n\n* *\n\n1-5 *\n\n/projects/Manhattan/bin/nightly /usr/local/bin/backup /home/accounting/expense_reports\n\nUsing cron, we can schedule backups, the nightly build, Web site main- tenance, and anything else that needs to be done—unattended, auto- matically.\n\n231\n\n232\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nCompiling theProject Compiling the project is a chore that should be reliable and repeat- able. We generally compile projects with makeﬁles, even when using an IDE environment. There are several advantages in using makeﬁles. It is a scripted, automatic procedure. We can add in hooks to generate code for us, and run regression tests automatically. IDEs have their advantages, but with IDEs alone it can be hard to achieve the level of automation that we’re looking for. We want to check out, build, test, and ship with a single command.\n\nGenerating Code In The Evils of Duplication, page 26, we advocated generating code to derive knowledge from common sources. We can exploit make’s depen- dency analysis mechanism to make this process easy. It’s a pretty sim- ple matter to add rules to a makeﬁle to generate a ﬁle from some other source automatically. For example, suppose we wanted to take an XML ﬁle, generate a Java ﬁle from it, and compile the result.\n\n.SUFFIXES: .java .class .xml\n\n.xml.java:\n\nperl convert.pl $< > $@\n\n.java.class:\n\n$(JAVAC) $(JAVAC_FLAGS) $<\n\nType make test.class, and make will automatically look for a ﬁle named test.xml, build a .java ﬁle by running a Perl script, and then compile that ﬁle to produce test.class.\n\nWe can use the same sort of rules to generate source code, header ﬁles, or documentation automatically from some other form as well (see Code Generators, page 102).\n\nRegressionTests You can also use the makeﬁle to run regression tests for you, either for an individual module or for an entire subsystem. You can easily test the entire project with just one command at the top of the source tree, or you can test an individual module by using the same command in a single directory. See Ruthless Testing, page 237, for more on regression testing.",
      "page_number": 249
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 257-264)",
      "start_page": 257,
      "end_page": 264,
      "detection_method": "topic_boundary",
      "content": "UBIQUITOUS AUTOMATION\n\nRecursive make\n\nMany projects set up recursive, hierarchical makeﬁles for project builds and testing. But be aware of some potential problems.\n\nmake calculates dependencies between the various targets it has to build. But it can analyze only the dependencies that exist within one single make invocation. In particular, a recursive make has no knowl- edge of dependencies that other invocations of make may have. If you are careful and precise, you can get the proper results, but it’s easy to cause extra work unnecessarily—or miss a dependency and not recompile when it’s needed.\n\nIn addition, build dependencies may not be the same as test depen- dencies, and you may need separate hierarchies.\n\nBuildAutomation A build is a procedure that takes an empty directory (and a known com- pilation environment) and builds the project from scratch, producing whatever you hope to produce as a ﬁnal deliverable—a CD-ROM mas- ter image or a self-extracting archive, for instance. Typically a project build will encompass the following steps.\n\n1. Check out the source code from the repository.\n\n2. Build the project from scratch, typically from a top-level makeﬁle. Each build is marked with some form of release or version number, or perhaps a date stamp.\n\n3. Create a distributable image. This procedure may entail ﬁxing ﬁle ownership and permissions, and producing all examples, docu- mentation, README ﬁles, and anything else that will ship with the product, in the exact format that will be required when you ship.3\n\n4. Run speciﬁed tests ( make test).\n\n3. If you are producing a CD-ROM in ISO9660 format, for example, you would run the program that produces a bit-for-bit image of the 9660 ﬁle system. Why wait until the night before you ship to make sure it works?\n\n233\n\n234\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nFor most projects, this level of build is run automatically every night. In this nightly build, you will typically run more complete tests than an individual might run while building some speciﬁc portion of the project. The important point is to have the full build run all available tests. You want to know if a regression test failed because of one of today’s code changes. By identifying the problem close to the source, you stand a better chance of ﬁnding and ﬁxing it.\n\nWhen you don’t run tests regularly, you may discover that the appli- cation broke due to a code change made three months ago. Good luck ﬁnding that one.\n\nFinal Builds Final builds, which you intend to ship as products, may have different requirements from the regular nightly build. A ﬁnal build may require that the repository be locked, or tagged with the release number, that optimization and debug ﬂags be set differently, and so on. We like to use a separate make target (such as make final) that sets all of these parameters at once.\n\nRemember that if the product is compiled differently from earlier ver- sions, then you must test against this version all over again.\n\nAutomatic Administrivia Wouldn’t it be nice if programmers could actually devote all of their time to programming? Unfortunately, this is rarely the case. There is e-mail to be answered, paperwork to be ﬁlled out, documents to be posted to the Web, and so on. You may decide to create a shell script to do some of the dirty work, but you still have to remember to run the script when needed.\n\nBecause memory is the second thing you lose as you age,4 we don’t want to rely on it too heavily. We can run scripts to perform proce- dures for us automatically, based on the content of source code and documents. Our goal is to maintain an automatic, unattended, content- driven workﬂow.\n\n4. What’s the ﬁrst? I forget.\n\nUBIQUITOUS AUTOMATION\n\nWebSite Generation Many development teams use an internal Web site for project commu- nication, and we think this is a great idea. But we don’t want to spend too much time maintaining the Web site, and we don’t want to let it get stale or out of date. Misleading information is worse than no informa- tion at all.\n\nDocumentation that is extracted from code, requirements analyses, design documents, and any drawings, charts, or graphs all need to be published to the Web on a regular basis. We like to publish these documents automatically as part of the nightly build or as a hook into the source code check-in procedure.\n\nHowever it is done, Web content should be generated automatically from information in the repository and published without human inter- vention. This is really another application of the DRY principle: infor- mation exists in one form as checked-in code and documents. The view from the Web browser is simply that—just a view. You shouldn’t have to maintain that view by hand.\n\nAny information generated by the nightly build should be accessible on the development Web site: results of the build itself (for example, the build results might be presented as a one-page summary that includes compiler warnings, errors, and current status), regression tests, per- formance statistics, coding metrics and any other static analysis, and so on.\n\nApprovalProcedures Some projects have various administrative workﬂows that must be fol- lowed. For instance, code or design reviews need to be scheduled and followed through, approvals may need to be granted, and so on. We can use automation—and especially the Web site—to help ease the paper- work burden.\n\nSuppose you wanted to automate code review scheduling and approval. You might put a special marker in each source code ﬁle:\n\n/* Status: needs_review */\n\nA simple script could go through all of the source code and look for all ﬁles that had a status of needs_review, indicating that they were ready to be reviewed. You could then post a list of those ﬁles as a\n\n235\n\n236\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nWeb page, automatically send e-mail to the appropriate people, or even schedule a meeting automatically using some calendar software.\n\nYou can set up a form on a Web page for the reviewers to register approval or disapproval. After the review, the status can be automat- ically changed to reviewed. Whether you have a code walk-through with all the participants is up to you; you can still do the paperwork automatically. (In an article in the April 1999 CACM, Robert Glass sum- marizes research that seems to indicate that, while code inspection is effective, conducting reviews in meetings is not [Gla99a].)\n\nThe Cobbler’s Children The cobbler’s children have no shoes. Often, people who develop soft- ware use the poorest tools to do the job.\n\nBut we have all the raw materials we need to craft better tools. We have cron. We have make, Ant, and CruiseControl for automation (see [Cla04]). And we have Ruby, Perl, and other high-level scripting lan- guages for quickly developing custom tools, Web page generators, code generators, test harnesses, and so on.\n\nLet the computer do the repetitious, the mundane—it will do a better job of it than we would. We’ve got more important and more difﬁcult things to do.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 The Evils of Duplication, page 26 The Power of Plain Text, page 73 Shell Games, page 77 Debugging, page 90 Code Generators, page 102 Pragmatic Teams, page 224 Ruthless Testing, page 237 It’s All Writing, page 248\n\nChallenges\n\nLook at your habits throughout the workday. Do you see any repetitive tasks? Do you type the same sequence of commands over and over again?\n\nRUTHLESS TESTING\n\nTry writing a few shell scripts to automate the process. Do you always click on the same sequence of icons repeatedly? Can you create a macro to do all that for you?\n\nHow much of your project paperwork can be automated? Given the high expense of programming staff,5 determine how much of the project’s bud- get is being wasted on administrative procedures. Can you justify the amount of time it would take to craft an automated solution based on the overall cost savings it would achieve?\n\n43 Ruthless Testing\n\nMost developers hate testing. They tend to test gently, subconsciously knowing where the code will break and avoiding the weak spots. Prag- matic Programmers are different. We are driven to ﬁnd our bugs now, so we don’t have to endure the shame of others ﬁnding our bugs later.\n\nFinding bugs is somewhat like ﬁshing with a net. We use ﬁne, small nets (unit tests) to catch the minnows, and big, coarse nets (integration tests) to catch the killer sharks. Sometimes the ﬁsh manage to escape, so we patch any holes that we ﬁnd, in hopes of catching more and more slippery defects that are swimming about in our project pool.\n\nTIP 62\n\nTest Early. Test Often. Test Automatically.\n\nWe want to start testing as soon as we have code. Those tiny minnows have a nasty habit of becoming giant, man-eating sharks pretty fast, and catching a shark is quite a bit harder. But we don’t want to have to do all that testing by hand.\n\n5. per head—that’s salary plus beneﬁts, training, ofﬁce space and overhead, and so on.\n\nFor estimating purposes, you can ﬁgure an industry average of about US$100,000\n\n237\n\n238\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nMany teams develop elaborate test plans for their projects. Sometimes they will even use them. But we’ve found that teams that use auto- mated tests have a much better chance of success. Tests that run with every build are much more effective than test plans that sit on a shelf.\n\nThe earlier a bug is found, the cheaper it is to remedy. “Code a little, test a little” is a popular saying in the Smalltalk world,6 and we can adopt that mantra as our own by writing test code at the same time (or even before) we write the production code.\n\nIn fact, a good project may well have more test code than production code. The time it takes to produce this test code is worth the effort. It ends up being much cheaper in the long run, and you actually stand a chance of producing a product with close to zero defects.\n\nAdditionally, knowing that you’ve passed the test gives you a high de- gree of conﬁdence that a piece of code is “done.”\n\nTIP 63\n\nCoding Ain’t Done ’Til All the Tests Run\n\nJust because you have ﬁnished hacking out a piece of code doesn’t mean you can go tell your boss or your client that it’s done. It’s not. First of all, code is never really done. More importantly, you can’t claim that it is usable by anyone until it passes all of the available tests.\n\nWe need to look at three main aspects of project-wide testing: what to test, how to test, and when to test.\n\nWhat toTest There are several major types of software testing that you need to per- form:\n\nUnit testing\n\nIntegration testing\n\nValidation and veriﬁcation\n\n6. less testing.”\n\neXtreme Programming [URL 45] calls this concept “continuous integration, relent-\n\nRUTHLESS TESTING\n\nResource exhaustion, errors, and recovery\n\nPerformance testing\n\nUsability testing\n\nThis list is by no means complete, and some specialized projects will require various other types of testing as well. But it gives us a good starting point.\n\nUnit Testing A unit test is code that exercises a module. We covered this topic by itself in Code That’s Easy to Test, page 189. Unit testing is the founda- tion of all the other forms of testing that we’ll discuss in this section. If the parts don’t work by themselves, they probably won’t work well together. All of the modules you are using must pass their own unit tests before you can proceed.\n\nOnce all of the pertinent modules have passed their individual tests, you’re ready for the next stage. You need to test how all the modules use and interact with each other throughout the system.\n\nIntegrationTesting Integration testing shows that the major subsystems that make up the project work and play well with each other. With good contracts in place and well tested, any integration issues can be detected easily. Other- wise, integration becomes a fertile breeding ground for bugs. In fact, it is often the single largest source of bugs in the system.\n\nIntegration testing is really just an extension of the unit testing we’ve described—only now you’re testing how entire subsystems honor their contracts.\n\nValidationand Veriﬁcation As soon as you have an executable user interface or prototype, you need to answer an all-important question: the users told you what they wanted, but is it what they need?\n\nDoes it meet the functional requirements of the system? This, too, needs to be tested. A bug-free system that answers the wrong ques- tion isn’t very useful. Be conscious of end-user access patterns and\n\n239\n\n240\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nhow they differ from developer test data (for an example, see the story about brush strokes on page 92).\n\nResource Exhaustion,Errors,and Recovery\n\nNow that you have a pretty good idea that the system will behave cor- rectly under ideal conditions, you need to discover how it will behave under real-world conditions. In the real world, your programs don’t have limitless resources; they run out of things. A few limits your code may encounter include:\n\nMemory\n\nDisk space\n\nCPU bandwidth\n\nWall-clock time\n\nDisk bandwidth\n\nNetwork bandwidth\n\nColor palette\n\nVideo resolution\n\nYou might actually check for disk space or memory allocation failures, but how often do you test for the others? Will your application ﬁt on screen colors? Will it run on a a with -bit color without looking like a postage stamp? Will the batch job ﬁnish before the archive starts?\n\nscreen with\n\nYou can detect environmental limitations, such as the video speci- ﬁcations, and adapt as appropriate. Not all failures are recoverable, however. If your code detects that memory has been exhausted, your options are limited: you may not have enough resources left to do any- thing except fail.\n\nWhen the system does fail,7 will it fail gracefully? Will it try, as best it can, to save its state and prevent loss of work? Or will it “GPF” or “core-dump” in the user’s face?\n\n7. Our copy editor wanted us to change this sentence to “If the system does fail We resisted. .”",
      "page_number": 257
    },
    {
      "number": 33,
      "title": "Segment 33 (pages 265-272)",
      "start_page": 265,
      "end_page": 272,
      "detection_method": "topic_boundary",
      "content": "RUTHLESS TESTING\n\nPerformanceTesting Performance testing, stress testing, or testing under load may be an important aspect of the project as well.\n\nAsk yourself if the software meets the performance requirements under real-world conditions—with the expected number of users, or connec- tions, or transactions per second. Is it scalable?\n\nFor some applications, you may need specialized testing hardware or software to simulate the load realistically.\n\nUsabilityTesting Usability testing is different from the types of testing discussed so far. It is performed with real users, under real environmental conditions.\n\nLook at usability in terms of human factors. Were there any misun- derstandings during requirements analysis that need to be addressed? Does the software ﬁt the user like an extension of the hand? (Not only do we want our own tools to ﬁt our hands, but we want the tools we create for users to ﬁt their hands as well.)\n\nAs with validation and veriﬁcation, you need to perform usability test- ing as early as you can, while there is still time to make corrections. For larger projects, you may want to bring in human factors specialists. (If nothing else, it’s fun to play with the one-way mirrors).\n\nFailure to meet usability criteria is just as big a bug as dividing by zero.\n\nHowtoTest We’ve looked at what to test. Now we’ll turn our attention to how to test, including:\n\nRegression testing\n\nTest data\n\nExercising GUI systems\n\nTesting the tests\n\nTesting thoroughly\n\n241\n\n242\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nDesign/Methodology Testing\n\nCan you test the design of the code itself and the methodology you used to build the software? After a fashion, yes you can. You do this by analyzing metrics—measurements of various aspects of the code. The simplest metric (and often the least interesting) is linesofcode— how big is the code itself?\n\nThere are a wide variety of other metrics you can use to examine code, including:\n\nMcCabe Cyclomatic Complexity Metric (measures complexity of decision structures) Inheritance fan-in (number of base classes) and fan-out (number of derived modules using this one as a parent) Response set (see DecouplingandtheLawofDemeter, page 138) Class coupling ratios (see [URL 48])\n\nSome metrics are designed to give you a “passing grade,” while oth- ers are useful only by comparison. That is, you calculate these met- rics for every module in the system and see how a particular module relates to its brethren. Standard statistical techniques (such as mean and standard deviation) are usually used here.\n\nIf you ﬁnd a module whose metrics are markedly different from all the rest, you need to ask yourself if that is appropriate. For some modules, it may be okay to “blow the curve.” But for those that don’t have a good excuse, it can indicate potential problems.\n\nRegressionTesting A regression test compares the output of the current test with previous (or known) values. We can ensure that bugs we ﬁxed today didn’t break things that were working yesterday. This is an important safety net, and it cuts down on unpleasant surprises.\n\nAll of the tests we’ve mentioned so far can be run as regression tests, ensuring that we haven’t lost any ground as we develop new code. We can run regressions to verify performance, contracts, validity, and so on.\n\nRUTHLESS TESTING\n\nTestData Where do we get the data to run all these tests? There are only two kinds of data: real-world data and synthetic data. We actually need to use both, because the different natures of these kinds of data will expose different bugs in our software.\n\nReal-world data comes from some actual source. Possibly it has been collected from an existing system, a competitor’s system, or a prototype of some sort. It represents typical user data. The big surprises come as you discover what typical means. This is most likely to reveal defects and misunderstandings in requirements analysis.\n\nSynthetic data is artiﬁcially generated, perhaps under certain statistical constraints. You may need to use synthetic data for any of the following reasons.\n\nYou need a lot of data, possibly more than any real-world sample could provide. You might be able to use the real-world data as a seed to generate a larger sample set, and tweak certain ﬁelds that need to be unique.\n\nYou need data to stress the boundary conditions. This data may be completely synthetic: date ﬁelds containing February 29, 1999, huge record sizes, or addresses with foreign postal codes.\n\nYou need data that exhibits certain statistical properties. Want to see what happens if every third transaction fails? Remember the sort algorithm that slows to a crawl when handed presorted data? You can present data in random or sorted order to expose this kind of weakness.\n\nExercisingGUISystems Testing GUI-intensive systems often requires specialized testing tools. These tools may be based on a simple event capture/playback model, or they may require specially written scripts to drive the GUI. Some systems combine elements of both.\n\nLess sophisticated tools enforce a high degree of coupling between the version of software being tested and the test script itself: if you move a dialog box or make a button smaller, the test may not be able to\n\n243\n\n244\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nﬁnd it, and may fail. Most modern GUI testing tools use a number of different techniques to get around this problem, and try to adjust to minor layout differences.\n\nHowever, you can’t automate everything. Andy worked on a graphics system that allowed the user to create and display nondeterministic visual effects which simulated various natural phenomena. Unfortu- nately, during testing you couldn’t just grab a bitmap and compare the output with a previous run, because it was designed to be different every time. For situations such as this one, you may have no choice but to rely on manual interpretation of test results.\n\nOne of the many advantages of writing decoupled code (see Decou- pling and the Law of Demeter, page 138) is more modular testing. For instance, for data processing applications that have a GUI front end, your design should be decoupled enough so that you can test the ap- plication logic without having a GUI present. This idea is similar to testing your subcomponents ﬁrst. Once the application logic has been validated, it becomes easier to locate bugs that show up with the user interface in place (it’s likely that the bugs were created by the user- interface code).\n\nTestingtheTests Because we can’t write perfect software, it follows that we can’t write perfect test software either. We need to test the tests.\n\nThink of our set of test suites as an elaborate security system, designed to sound the alarm when a bug shows up. How better to test a security system than to try to break in?\n\nAfter you have written a test to detect a particular bug, cause the bug deliberately and make sure the test complains. This ensures that the test will catch the bug if it happens for real.\n\nTIP 64\n\nUse Saboteurs to Test Your Testing\n\nIf you are really serious about testing, you might want to appoint a project saboteur. The saboteur’s role is to take a separate copy of the\n\nRUTHLESS TESTING\n\nsource tree, introduce bugs on purpose, and verify that the tests will catch them.\n\nWhen writing tests, make sure that alarms sound when they should.\n\nTestingThoroughly Once you are conﬁdent that your tests are correct, and are ﬁnding bugs you create, how do you know if you have tested the code base thoroughly enough?\n\nThe short answer is “you don’t,” and you never will. But there are prod- ucts on the market that can help. These coverage analysis tools watch your code during testing and keep track of which lines of code have been executed and which haven’t. These tools help give you a general feel for how comprehensive your testing is, but don’t expect to see 100% coverage.\n\nEven if you do happen to hit every line of code, that’s not the whole picture. What is important is the number of states that your program may have. States are not equivalent to lines of code. For instance, sup- pose you have a function that takes two integers, each of which can be a number from 0 to 999.\n\nint test(int a, int b) { return a / (a + b);\n\n}\n\nIn theory, this three-line function has 1,000,000 logical states, 999,999 of which will work correctly and one that will not (when a + b equals zero). Simply knowing that you executed this line of code doesn’t tell you that—you would need to identify all possible states of the program. Unfortunately, in general this is a really hard problem. Hard as in, “The sun will be a cold hard lump before you can solve it.”\n\nTIP 65\n\nTest State Coverage, Not Code Coverage\n\nEven with good code coverage, the data you use for testing still has a huge impact, and, more importantly, the order in which you traverse code may have the largest impact of all.\n\n245\n\n246\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nWhentoTest Many projects tend to leave testing to the last minute—right where it will be cut against the sharp edge of a deadline.8 We need to start much sooner than that. As soon as any production code exists, it needs to be tested.\n\nMost testing should be done automatically. It’s important to note that by “automatically” we mean that the test results are interpreted auto- matically as well. See Ubiquitous Automation, page 230, for more on this subject.\n\nWe like to test as frequently as we can, and always before we check code into the source repository. Some source code control systems, such as Aegis, can do this automatically. Otherwise, we just type\n\n% make test\n\nUsually, it isn’t a problem to run regressions on all of the individual unit tests and integration tests as often as needed.\n\nBut some tests may not be easily run on a such a frequent basis. Stress tests, for instance, may require special setup or equipment, and some hand holding. These tests may be run less often—weekly or monthly, perhaps. But it is important that they be run on a regular, scheduled basis. If it can’t be done automatically, then make sure it appears on the schedule, with all the necessary resources allocated to the task.\n\nTightening theNet Finally, we’d like to reveal the single most important concept in testing. It is an obvious one, and virtually every textbook says to do it this way. But for some reason, most projects still do not.\n\nIf a bug slips through the net of existing tests, you need to add a new test to trap it next time.\n\n8. passes at the risk of being shot—Webster’s Collegiate Dictionary.\n\ndead line ded-l¯ın n (1864) a line drawn within or around a prison that a prisoner\n\nRUTHLESS TESTING\n\nTIP 66\n\nFind Bugs Once\n\nOnce a human tester ﬁnds a bug, it should be the last time a human tester ﬁnds that bug. The automated tests should be modiﬁed to check for that particular bug from then on, every time, with no exceptions, no matter how trivial, and no matter how much the developer complains and says, “Oh, that will never happen again.”\n\nBecause it will happen again. And we just don’t have the time to go chasing after bugs that the automated tests could have found for us. We have to spend our time writing new code—and new bugs.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Debugging, page 90 Decoupling and the Law of Demeter, page 138 Refactoring, page 184 Code That’s Easy to Test, page 189 Ubiquitous Automation, page 230\n\nChallenges\n\nCan you automatically test your project? Many teams are forced to answer “no.” Why? Is it too hard to deﬁne the acceptable results? Won’t this make it hard to prove to the sponsors that the project is “done”?\n\nIs it too hard to test the application logic independent of the GUI? What does this say about the GUI? About coupling?\n\n247\n\n44\n\n248\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nIt’s All Writing\n\nThe palest ink is better than the best memory.\n\nChinese Proverb\n\nTypically, developers don’t give much thought to documentation. At best it is an unfortunate necessity; at worst it is treated as a low-priority task in the hope that management will forget about it at the end of the project.\n\nPragmatic Programmers embrace documentation as an integral part of the overall development process. Writing documentation can be made easier by not duplicating effort or wasting time, and by keeping docu- mentation close at hand—in the code itself, if possible.\n\nThese aren’t exactly original or novel thoughts; the idea of wedding code and documentation appears in Donald Knuth’s work on literate programming and in Sun’s JavaDoc utility, among others. We want to downplay the dichotomy between code and documentation, and instead treat them as two views of the same model (see It’s Just a View, page 157). In fact, we want to go a little further and apply all of our pragmatic principles to documentation as well as to code.\n\nTIP 67\n\nTreat English as Just Another Programming Language\n\nThere are basically two kinds of documentation produced for a project: internal and external. Internal documentation includes source code comments, design and test documents, and so on. External documen- tation is anything shipped or published to the outside world, such as user manuals. But regardless of the intended audience, or the role of the writer (developer or technical writer), all documentation is a mir- ror of the code. If there’s a discrepancy, the code is what matters—for better or worse.\n\nTIP 68\n\nBuild Documentation In, Don’t Bolt It On\n\nWe’ll start with internal documentation.",
      "page_number": 265
    },
    {
      "number": 34,
      "title": "Segment 34 (pages 273-282)",
      "start_page": 273,
      "end_page": 282,
      "detection_method": "topic_boundary",
      "content": "IT’S ALL WRITING\n\nComments inCode Producing formatted documents from the comments and declarations in source code is fairly straightforward, but ﬁrst we have to ensure that we actually have comments in the code. Code should have comments, but too many comments can be just as bad as too few.\n\nIn general, comments should discuss why something is done, its pur- pose and its goal. The code already shows how it is done, so comment- ing on this is redundant—and is a violation of the DRY principle.\n\nCommenting source code gives you the perfect opportunity to docu- ment those elusive bits of a project that can’t be documented anywhere else: engineering trade-offs, why decisions were made, what other alter- natives were discarded, and so on.\n\nWe like to see a simple module-level header comment, comments for signiﬁcant data and type declarations, and a brief per-class and per- method header, describing how the function is used and anything that it does that is not obvious.\n\nVariable names, of course, should be well chosen and meaningful. foo, for instance, is meaningless, as is doit or manager or stuff. Hun- garian notation (where you encode the variable’s type information in the name itself) is utterly inappropriate in object-oriented systems. Remember that you (and others after you) will be reading the code many hundreds of times, but only writing it a few times. Take the time to spell out connectionPool instead of cp.\n\nEven worse than meaningless names are misleading names. Have you ever had someone explain inconsistencies in legacy code such as, “The routine called getData really writes data to disk”? The human brain will repeatedly foul this up—it’s called the Stroop Effect [Str35]. You can try the following experiment yourself to see the effects of such in- terference. Get some colored pens, and use them to write down the names of colors. However, never write a color name using that color pen. You could write the word “blue” in green, the word “brown” in red, and so on. (Alternatively, we have a sample set of colors already drawn on our Web site at www.pragmaticprogrammer.com.) Once you have the color names drawn, try to say aloud the color with which each word is drawn, as fast as you can. At some point you’ll trip up and start read- ing the names of the colors, and not the colors themselves. Names are\n\n249\n\n250\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\ndeeply meaningful to your brain, and misleading names add chaos to your code.\n\nYou can document parameters, but ask yourself if it is really necessary in all cases. The level of comment suggested by the JavaDoc tool seems appropriate:\n\n/**\n\nFind the peak (highest) value within a specified date * range of samples. * * @param aRange Range of dates to search for data. * @param aThreshold Minimum value to consider. * @return the value, or <code>null</code> if no value found * greater than or equal to the threshold. */ public Sample findPeak(DateRange aRange, double aThreshold);\n\nHere’s a list of things that should not appear in source comments.\n\nA list of the functions exported by code in the ﬁle. There are pro- grams that analyze source for you. Use them, and the list is guar- anteed to be up to date.\n\nRevision history. This is what source code control systems are for (see Source Code Control, page 86). However, it can be useful to include information on the date of last change and the person who made it.9\n\nA list of other ﬁles this ﬁle uses. This can be determined more accurately using automatic tools.\n\nIf it must appear in the ﬁle, don’t maintain it The name of the ﬁle. by hand. RCS and similar systems can keep this information up to date automatically. If you move or rename the ﬁle, you don’t want to have to remember to edit the header.\n\nOne of the most important pieces of information that should appear in the source ﬁle is the author’s name—not necessarily who edited the ﬁle last, but the owner. Attaching responsibility and accountabil- ity to source code does wonders in keeping people honest (see Pride and Prejudice, page 258).\n\n9.\n\nThis kind of information, as well as the ﬁlename, is provided by the RCS $Id$ tag.\n\nIT’S ALL WRITING\n\nThe project may also require certain copyright notices or other legal boilerplate to appear in each source ﬁle. Get your editor to insert these for you automatically.\n\nWith meaningful comments in place, tools such as JavaDoc [URL 7] and DOC++ [URL 21] can extract and format them to automatically produce API-level documentation. This is one speciﬁc example of a more general technique we use—executable documents.\n\nExecutableDocuments Suppose we have a speciﬁcation that lists the columns in a database table. We’ll then have a separate set of SQL commands to create the actual table in the database, and probably some kind of programming language record structure to hold the contents of a row in the table. The same information is repeated three times. Change any one of these three sources, and the other two are immediately out of date. This is a clear violation of the DRY principle.\n\nTo correct this problem, we need to choose the authoritative source of information. This may be the speciﬁcation, it may be a database schema tool, or it may be some third source altogether. Let’s choose the speciﬁcation document as the source. It’s now our model for this process. We then need to ﬁnd a way to export the information it con- tains as different views—a database schema and a high-level language record, for example.10\n\nIf your document is stored as plain text with markup commands (using HTML, LATEX, or troff, for example), then you can use tools such as Perl to extract the schema and reformat it automatically. If your document is in a word processor’s binary format, then see the box on the following page for some options.\n\nYour document is now an integral part of the project development. The only way to change the schema is to change the document. You are guaranteeing that the speciﬁcation, schema, and code all agree. You minimize the amount of work you have to do for each change, and you can update the views of the change automatically.\n\n10. See It’s Just a View, page 157, for more on models and views.\n\n251\n\n252\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nWhat if My Document Isn’t Plain Text?\n\nUnfortunately, more and more project documents are now being writ- ten using word processors that store the ﬁle on disk in some propri- etary format. We say “unfortunately” because this severely restricts your options to process the document automatically. However, you still have a couple of options:\n\nWrite macros. Most sophisticated word processors now have a macro language. With some effort you can program them to export tagged sections of your documents into the alternative forms you need. If programming at this level is too painful, you could always export the appropriate section into a standard for- mat plain text ﬁle, and then use a tool such as Perl to convert this into the ﬁnal forms.\n\nMake thedocument subordinate. Rather than have the doc- ument as the deﬁnitive source, use another representation. (In the database example, you might want to use the schema as the authoritative information.) Then write a tool that exports this in- formation into a form that the document can import. Be careful, however. You need to ensure that this information is imported ev- ery time the document is printed, rather than just once when the document is created.\n\nWe can generate API-level documentation from source code using tools such as JavaDoc and DOC++ in a similar fashion. The model is the source code: one view of the model can be compiled; other views are meant to be printed out or viewed on the Web. Our goal is always to work on the model—whether the model is the code itself or some other document—and have all views updated automatically (see Ubiquitous Automation, page 230, for more on automatic processes).\n\nSuddenly, documentation isn’t so bad.\n\nTechnical Writers Up until now, we’ve talked only about internal documentation—written by the programmers themselves. But what happens when you have professional technical writers involved in the project? All too often, pro- grammers just throw material “over the wall” to technical writers and\n\nIT’S ALL WRITING\n\nlet them fend for themselves to produce user manuals, promotional pieces, and so on.\n\nThis is a mistake. Just because programmers aren’t writing these docu- ments doesn’t mean that we can forsake pragmatic principles. We want the writers to embrace the same basic principles that a Pragmatic Pro- grammer does—especially honoring the DRY principle, orthogonality, the model-view concept, and the use of automation and scripting.\n\nPrint Itor WeaveIt One problem inherent with published, paper documentation is that it can become out of date as soon as it’s printed. Documentation of any form is just a snapshot.\n\nSo we try to produce all documentation in a form that can be published online, on the Web, complete with hyperlinks. It’s easier to keep this view of the documentation up to date than to track down every existing paper copy, burn it, and reprint and redistribute new copies. It’s also a better way to address the needs of a wide audience. Remember, though, to put a date stamp or version number on each Web page. This way the reader can get a good idea of what’s up to date, what’s changed recently, and what hasn’t.\n\nMany times you need to present the same documentation in different formats: a printed document, Web pages, online help, or perhaps a slide show. The typical solution relies heavily on cut-and-paste, creating a number of new independent documents from the original. This is a bad idea: a document’s presentation should be independent of its content.\n\nIf you are using a markup system, you have the ﬂexibility to implement as many different output formats as you need. You can choose to have\n\n<H1>Chapter Title</H1>\n\ngenerate a new chapter in the report version of the document and title a new slide in the slide show. Technologies such as XSL and CSS11 can be used to generate multiple output formats from this one markup.\n\n11. eXtensible Style Language and Cascading Style Sheets, two technologies designed to help separate presentation from content.\n\n253\n\n254\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nIf you are using a word processor, you’ll probably have similar capa- bilities. If you remembered to use styles to identify different document elements, then by applying different style sheets you can drastically alter the look of the ﬁnal output. Most word processors now allow you to convert your document to formats such as HTML for Web publishing.\n\nMarkup Languages Finally, for large-scale documentation projects, we recommend looking at some of the more modern schemes for marking up documentation.\n\nMany technical authors now use DocBook to deﬁne their documents. DocBook is an SGML-based markup standard that carefully identiﬁes every component in a document. The document can be passed through a DSSSL processor to render it into any number of different formats. The Linux documentation project uses DocBook to publish information in RTF, TEX, info, PostScript, and HTML formats.\n\nAs long as your original markup is rich enough to express all the con- cepts you need (including hyperlinks), translation to any other pub- lishable form can be both easy and automatic. You can produce online help, published manuals, product highlights for the Web site, and even a tip-a-day calendar, all from the same source—which of course is under source control and is built along with the nightly build (see Ubiq- uitous Automation, page 230).\n\nDocumentation and code are different views of the same underlying model, but the view is all that should be different. Don’t let documen- tation become a second-class citizen, banished from the main project workﬂow. Treat documentation with the same care you treat code, and the users (and maintainers who follow) will sing your praises.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26 Orthogonality, page 34 The Power of Plain Text, page 73 Source Code Control, page 86 It’s Just a View, page 157 Programming by Coincidence, page 172 The Requirements Pit, page 202 Ubiquitous Automation, page 230\n\nGREAT EXPECTATIONS\n\nChallenges\n\nDid you write an explanatory comment for the source code you just wrote? Why not? Pressed for time? Not sure if the code will really work—are you just trying out an idea as a prototype? You’ll throw the code away after- wards, right? It won’t make it into the project uncommented and experi- mental, will it?\n\nSometimes it is uncomfortable to document the design of source code be- cause the design isn’t clear in your mind; it’s still evolving. You don’t feel that you should waste effort describing what something does until it actu- ally does it. Does this sound like programming by coincidence (page 172)?\n\n45 Great Expectations\n\nBe astonished, O ye heavens, at this, and be horribly afraid...\n\nJeremiah 2:12\n\nA company announces record proﬁts, and its share price drops 20%. The ﬁnancial news that night explains that the company failed to meet analysts’ expectations. A child opens an expensive Christmas present and bursts into tears—it wasn’t the cheap doll the child was hoping for. A project team works miracles to implement a phenomenally complex application, only to have it shunned by its users because it doesn’t have a help system.\n\nIn an abstract sense, an application is successful if it correctly imple- ments its speciﬁcations. Unfortunately, this pays only abstract bills.\n\nIn reality, the success of a project is measured by how well it meets the expectations of its users. A project that falls below their expectations is deemed a failure, no matter how good the deliverable is in absolute terms. However, like the parent of the child expecting the cheap doll, go too far and you’ll be a failure, too.\n\nTIP 69\n\nGently Exceed Your Users’ Expectations\n\nHowever, the execution of this tip requires some work.\n\n255\n\n256\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nCommunicating Expectations Users initially come to you with some vision of what they want. It may be incomplete, inconsistent, or technically impossible, but it is theirs, and, like the child at Christmas, they have some emotion invested in it. You cannot just ignore it.\n\nAs your understanding of their needs develops, you’ll ﬁnd areas where their expectations cannot be met, or where their expectations are per- haps too conservative. Part of your role is to communicate this. Work with your users so that their understanding of what you’ll be deliv- ering is accurate. And do this throughout the development process. Never lose sight of the business problems your application is intended to solve.\n\nSome consultants call this process “managing expectations”—actively controlling what users should hope to get from their systems. We think this is a somewhat elitist position. Our role is not to control the hopes of our users. Instead, we need to work with them to come to a common understanding of the development process and the ﬁnal deliverable, along with those expectations they have not yet verbalized. If the team is communicating ﬂuently with the outside world, this process is almost automatic; everyone should understand what’s expected and how it will be built.\n\nThere are some important techniques that can be used to facilitate this process. Of these, Tracer Bullets, page 48, and Prototypes and Post- it Notes, page 53, are the most important. Both let the team construct something that the user can see. Both are ideal ways of communicating your understanding of their requirements. And both let you and your users practice communicating with each other.\n\nTheExtra Mile If you work closely with your users, sharing their expectations and com- municating what you’re doing, then there will be few surprises when the project gets delivered.\n\nThis is a BAD THING. Try to surprise your users. Not scare them, mind you, but delight them.\n\nGREAT EXPECTATIONS\n\nGive them that little bit more than they were expecting. The extra bit of effort it requires to add some user-oriented feature to the system will pay for itself time and time again in goodwill.\n\nListen to your users as the project progresses for clues about what features would really delight them. Some things you can add relatively easily that look good to the average user include:\n\nBalloon or ToolTip help\n\nKeyboard shortcuts\n\nA quick reference guide as a supplement to the user’s manual\n\nColorization\n\nLog ﬁle analyzers\n\nAutomated installation\n\nTools for checking the integrity of the system\n\nThe ability to run multiple versions of the system for training\n\nA splash screen customized for their organization\n\nAll of these things are relatively superﬁcial, and don’t really overburden the system with feature bloat. However, each tells your users that the development team cared about producing a great system, one that was intended for real use. Just remember not to break the system adding these new features.\n\nRelated sections include:\n\nGood-Enough Software, page 9 Tracer Bullets, page 48 Prototypes and Post-it Notes, page 53 The Requirements Pit, page 202\n\nChallenges\n\nSometimes the toughest critics of a project are the people who worked on it. Have you ever experienced disappointment that your own expectations weren’t met by something you produced? How could that be? Maybe there’s more than logic at work here.\n\nWhat do your users comment on when you deliver software? Is their atten- tion to the various areas of the application proportional to the effort you invested in each? What delights them?\n\n257\n\n46\n\n258\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nPride and Prejudice\n\nYou have delighted us long enough.\n\nJane Austen, PrideandPrejudice\n\nPragmatic Programmers don’t shirk from responsibility. Instead, we rejoice in accepting challenges and in making our expertise well known. If we are responsible for a design, or a piece of code, we do a job we can be proud of.\n\nTIP 70\n\nSign Your Work\n\nCraftsmen of an earlier age were proud to sign their work. You should be, too.\n\nProject teams are still made up of people, however, and this rule can cause trouble. On some projects, the idea of code ownership can cause cooperation problems. People may become territorial, or unwilling to work on common foundation elements. The project may end up like a bunch of insular little ﬁefdoms. You become prejudiced in favor of your code and against your coworkers.\n\nThat’s not what we want. You shouldn’t jealously defend your code against interlopers; by the same token, you should treat other peo- ple’s code with respect. The Golden Rule (“Do unto others as you would have them do unto you”) and a foundation of mutual respect among the developers is critical to make this tip work.\n\nAnonymity, especially on large projects, can provide a breeding ground for sloppiness, mistakes, sloth, and bad code. It becomes too easy to see yourself as just a cog in the wheel, producing lame excuses in endless status reports instead of good code.\n\nWhile code must be owned, it doesn’t have to be owned by an individual. In fact, Kent Beck’s successful eXtreme Programming method [URL 45] recommends communal ownership of code (but this also requires additional practices, such as pair programming, to guard against the dangers of anonymity).",
      "page_number": 273
    },
    {
      "number": 35,
      "title": "Segment 35 (pages 283-290)",
      "start_page": 283,
      "end_page": 290,
      "detection_method": "topic_boundary",
      "content": "PRIDE AND PREJUDICE\n\nWe want to see pride of ownership. “I wrote this, and I stand behind my work.” Your signature should come to be recognized as an indicator of quality. People should see your name on a piece of code and expect it to be solid, well written, tested, and documented. A really professional job. Written by a real professional.\n\nA Pragmatic Programmer.\n\n259\n\nThis page intentionally left blank\n\nAppendix A\n\nResources\n\nThe only reason we were able to cover so much ground in this book is that we viewed many of our subjects from a high altitude. If we’d given them the in-depth coverage they deserved, the book would have been ten times longer.\n\nWe started the book with the suggestion that Pragmatic Programmers should always be learning. In this appendix we’ve listed resources that may help you with this process.\n\nIn the section Professional Societies, we give details of the IEEE and the ACM. We recommend that Pragmatic Programmers join one (or both) of these societies. Then, in Building a Library, we highlight periodicals, books, and Web sites that we feel contain high-quality and pertinent information (or that are just plain fun).\n\nThroughout the book we referenced many software resources accessible via the Internet. In the Internet Resources section, we list the URLs of these resources, along with a short description of each. However, the nature of the Web means that many of these links may well be stale by the time you read this book. You could try one of the many search engines for a more up-to-date link, or visit our Web site at www. pragmaticprogrammer.com and check our links section.\n\nFinally, this appendix contains the book’s bibliography.\n\n261\n\n262\n\nAPPENDIX A RESOURCES\n\nProfessional Societies There are two world-class professional societies for programmers: the Association for Computing Machinery (ACM)1 and the IEEE Computer Society.2 We recommend that all programmers belong to one (or both) of these societies. In addition, developers outside the United States may want to join their national societies, such as the BCS in the United Kingdom.\n\nMembership in a professional society has many beneﬁts. The confer- ences and local meetings give you great opportunities to meet people with similar interests, and the special interest groups and technical committees give you the opportunity to participate in setting standards and guidelines used around the world. You’ll also get a lot out of their publications, from high-level discussions of industry practice to low- level computing theory.\n\nBuilding aLibrary We’re big on reading. As we noted in Your Knowledge Portfolio, page 12, a good programmer is always learning. Keeping current with books and periodicals can help. Here are some that we like.\n\nPeriodicals If you’re like us, you’ll save old magazines and periodicals until they’re piled high enough to turn the bottom ones to ﬂat sheets of diamond. This means it’s worth being fairly selective. Here are a few periodicals we read.\n\nIEEE Computer. Sent to members of the IEEE Computer Society, Computer has a practical focus but is not afraid of theory. Some issues are oriented around a theme, while others are simply col-\n\n1.\n\nACM Member Services, PO Box 11414, New York, NY 10286, USA.\n\nwww.acm.org\n\n2.\n\n1730 Massachusetts Avenue NW, Washington, DC 20036-1992, USA.\n\nwww.computer.org\n\nBUILDING A LIBRARY\n\nlections of interesting articles. This magazine has a good signal-to- noise ratio.\n\nIEEE Software. This is another great bimonthly publication of the IEEE Computer Society aimed at software practitioners.\n\nCommunications of the ACM. The basic magazine received by all members of the ACM, CACM has been a standard in the indus- try for decades, and has probably published more seminal articles than any other source.\n\nSIGPLAN. Produced by the ACM Special Interest Group on Pro- gramming Languages, SIGPLAN is an optional addition to your ACM membership. It is often used for publishing language speciﬁ- cations, along with articles of interest to everyone who likes looking deeply into programming.\n\nDr. Dobbs Journal. A monthly magazine, available by subscription and on newsstands, Dr. Dobbs is quirky, but has articles ranging from bit-level practice to heavy theory.\n\nThe Perl Journal. to The Perl Journal (www.tpj.com).\n\nIf you like Perl, you should probably subscribe\n\nSoftware Development Magazine. A monthly magazine focusing on general issues of project management and software development.\n\nWeeklyTradePapers There are several weekly newspapers published for developers and their managers. These papers are largely a collection of company press re- leases, redressed as articles. However, the content is still valuable—it lets you track what is going on, keep abreast of new product announce- ments, and follow industry alliances as they are forged and broken. Don’t expect a lot of in-depth technical coverage, though.\n\n263\n\n264\n\nAPPENDIX A RESOURCES\n\nBooks\n\nComputing books can be expensive, but choose carefully and they’re a worthwhile investment. You may want to check out our Pragmatic Bookshelf titles at http://pragmaticprogrammer.com. Additionally, here are a handful of the many other books we like.\n\nAnalysis and Design\n\nObject-Oriented Software Construction, 2nd Edition. Bertrand Meyer’s epic book on the fundamentals of object-oriented develop- ment, all in about 1,300 pages [Mey97b].\n\nDesignPatterns. A design pattern describes a way to solve a par- ticular class of problems at a higher level than a programming lan- guage idiom. This now-classic book [GHJV95] by the Gang of Four describes 23 basic design patterns, including Proxy, Visitor, and Singleton.\n\nAnalysisPatterns. A treasure trove of high-level, architectural pat- terns taken from a wide variety of real-world projects and distilled in book form. A relatively quick way to gain the insight of many years of modeling experience [Fow96].\n\nTeams andProjects\n\nThe Mythical Man Month. Fred Brooks’ classic on the perils of organizing project teams, recently updated [Bro95].\n\nDynamics of Software Development. A series of short essays on building software in large teams, focusing on the dynamics between team members, and between the team and the rest of the world [McC95].\n\nSurviving Object-Oriented Projects: A Manager’s Guide. Alistair Cockburn’s “reports from the trenches” illustrate many of the perils and pitfalls of managing an OO project—especially your ﬁrst one. Mr. Cockburn provides tips and techniques to get you through the most common problems [Coc97b].\n\nBUILDING A LIBRARY\n\nSpeciﬁc Environments\n\nUnix. W. Richard Stevens has several excellent books including Advanced Programming in the Unix Environment and the Unix Net- work Programming books [Ste92, Ste98, Ste99].\n\nWindows. Marshall Brain’s Win32 System Services [Bra95] is a concise reference to the low-level APIs. Charles Petzold’s Program- ming Windows [Pet98] is the bible of Windows GUI development.\n\nC++. As soon as you ﬁnd yourself on a C++ project, run, don’t walk, to the bookstore and get Scott Meyer’s Effective C++, and possibly More Effective C++ [Mey97a, Mey96]. For building systems of any appreciable size, you need John Lakos’ Large-Scale C++ Software Design [Lak96]. For advanced techniques, turn to Jim Coplien’s Advanced C++ Programming Styles and Idioms [Cop92].\n\nIn addition, the O’Reilly Nutshell series (www.ora.com) gives quick, comprehensive treatments of miscellaneous topics and languages such as perl, yacc, sendmail, Windows internals, and regular expressions.\n\nThe Web Finding good content on the Web is hard. Here are several links that we check at least once a week.\n\nSlashdot. Billed as “News for nerds. Stuff that matters,” Slashdot is one of the net homes of the Linux community. As well as regular updates on Linux news, the site offers information on technologies that are cool and issues that affect developers.\n\nwww.slashdot.org\n\nCetus Links. Thousands of links on object-oriented topics.\n\nwww.cetus-links.org\n\nWikiWikiWeb. The Portland Pattern Repository and patterns dis- cussion. Not just a great resource, the WikiWikiWeb site is an in- teresting experiment in collective editing of ideas.\n\nwww.c2.com\n\n265\n\n266\n\nAPPENDIX A RESOURCES\n\nInternet Resources The links below are to resources available on the Internet. They were valid at the time of writing, but (the Net being what it is) they may well be out of date by the time you read this. If so, you could try a general search for the ﬁlenames, or come to the Pragmatic Programmer Web site (www.pragmaticprogrammer.com) and follow our links.\n\nEditors Emacs and vi are not the only cross-platform editors, but they are freely available and widely used. A quick scan through a magazine such as Dr. Dobbs will turn up several commercial alternatives.\n\nEmacs Both Emacs and XEmacs are available on Unix and Windows platforms.\n\n[URL 1] The Emacs Editor\n\nwww.gnu.org\n\nThe ultimate in big editors, containing every feature that any editor has\n\never had, Emacs has a near-vertical learning curve, but repays hand-\n\nsomely once you’ve mastered it. It also makes a great mail and news reader,\n\naddress book, calendar and diary, adventure game,\n\n.\n\n[URL 2] The XEmacs Editor\n\nwww.xemacs.org\n\nSpawned from the original Emacs some years ago, XEmacs is reputed to\n\nhave cleaner internals and a better-looking interface.\n\nvi There are at least 15 different vi clones available. Of these, vim is prob- ably ported to the most platforms, and so would be a good choice of editor if you ﬁnd yourself working in many different environments.\n\n[URL 3] The Vim Editor\n\nftp://ftp.fu-berlin.de/misc/editors/vim\n\nFrom the documentation: “There are a lot of enhancements above vi: multi\n\nlevel undo, multi windows and buffers, syntax highlighting, command line\n\nediting, ﬁlename completion, on-line help, visual selection, etc\n\n.”",
      "page_number": 283
    },
    {
      "number": 36,
      "title": "Segment 36 (pages 291-299)",
      "start_page": 291,
      "end_page": 299,
      "detection_method": "topic_boundary",
      "content": "INTERNET RESOURCES\n\n[URL 4] The elvis Editor\n\nelvis.the-little-red-haired-girl.org\n\nAn enhanced vi clone with support for X.\n\n[URL 5] Emacs Viper Mode\n\nhttp://www.cs.sunysb.edu/~kifer/emacs.html\n\nViper is a set of macros that make Emacs look like vi. Some may doubt\n\nthe wisdom of taking the world’s largest editor and extending it to emulate\n\nan editor whose strength is its compactness. Others claim it combines the\n\nbest of both worlds.\n\nCompilers, Languages,and DevelopmentTools [URL 6] The GNU C/C++ Compiler\n\nwww.fsf.org/software/gcc/gcc.html\n\nOne of the most popular C and C++ compilers on the planet. It also does\n\nObjective-C. (At the time of writing, the egcs project, which previously\n\nsplintered from gcc, is in the process of merging back into the fold.)\n\n[URL 7] The Java Language from Sun\n\njava.sun.com\n\nHome of Java, including downloadable SDKs, documentation, tutorials,\n\nnews, and more.\n\n[URL 8] Perl Language Home Page\n\nwww.perl.com\n\nO’Reilly hosts this set of Perl-related resources.\n\n[URL 9] The Python Language\n\nwww.python.org\n\nThe Python object-oriented programming language is interpreted and in-\n\nteractive, with a slightly quirky syntax and a wide and loyal following.\n\n[URL 10] SmallEiffel\n\nSmallEiffel.loria.fr\n\nThe GNU Eiffel compiler runs on any machine that has an ANSI C compiler\n\nand a Posix runtime environment.\n\n[URL 11] ISE Eiffel\n\nwww.eiffel.com\n\nInteractive Software Engineering is the originator of Design by Contract,\n\nand sells a commercial Eiffel compiler and related tools.\n\n267\n\n268\n\nAPPENDIX A RESOURCES\n\n[URL 12] Sather\n\nwww.icsi.berkeley.edu/~sather\n\nSather is an experimental language that grew out of Eiffel. It aims to sup-\n\nport higher-order functions and iteration abstraction as well as Common\n\nLisp, CLU, or Scheme, and to be as efﬁcient as C, C++, or Fortran.\n\n[URL 13] VisualWorks\n\nwww.cincom.com\n\nHome of the VisualWorks Smalltalk environment. Noncommercial versions\n\nfor Windows and Linux are available for free.\n\n[URL 14] The Squeak Language Environment\n\nsqueak.cs.uiuc.edu\n\nSqueak is a freely available, portable implementation of Smalltalk-80 writ-\n\nten in itself; it can produce C code output for higher performance.\n\n[URL 15] The TOM Programming Language\n\nwww.gerbil.org/tom\n\nA very dynamic language with roots in Objective-C.\n\n[URL 16] The Beowulf Project\n\nwww.beowulf.org\n\nA project that builds high-performance computers out of networked clus-\n\nters of inexpensive Linux boxes.\n\n[URL 17] iContract—Design by Contract Tool for Java\n\nwww.reliable-systems.com\n\nDesign by Contract formalism of preconditions, postconditions, and invari-\n\nants, implemented as a preprocessor for Java. Honors inheritance, imple-\n\nments existential quantiﬁers, and more.\n\n[URL 18] Nana—Logging and Assertions for C and C++\n\nwww.gnu.org/software/nana/nana.html\n\nImproved support for assertion checking and logging in C and C++. It also\n\nprovides some support for Design by Contract.\n\n[URL 19] DDD—Data Display Debugger\n\nhttp://www.gnu.org/software/ddd/\n\nA free graphical front end for Unix debuggers.\n\n[URL 20] John Brant’s Refactoring Browser\n\nst-www.cs.uiuc.edu/users/brant/Refactory\n\nA popular refactoring browser for Smalltalk.\n\nINTERNET RESOURCES\n\n[URL 21] DOC++ Documentation Generator\n\nwww.zib.de/Visual/software/doc++/index.html\n\nDOC++ is a documentation system for C/C++ and Java that generates both LATEX and HTML output for sophisticated online browsing of your documentation directly from the C++ header or Java class ﬁles.\n\n[URL 22] xUnit—Unit Testing Framework\n\nwww.XProgramming.com\n\nA simple but powerful concept, the xUnit unit testing framework provides\n\na consistent platform for testing software written in a variety of languages.\n\n[URL 23] The Tcl Language\n\nwww.scriptics.com\n\nTcl (“Tool Command Language”) is a scripting language designed to be easy\n\nto embed into an application.\n\n[URL 24] Expect—Automate Interaction with Programs\n\nexpect.nist.gov\n\nAn extension built on Tcl [URL 23], expect allows you to script interac-\n\ntion with programs. As well as helping you write command ﬁles that (for\n\nexample) fetch ﬁles from remote servers or extend the power of your shell,\n\nexpect can be useful when performing regression testing. A graphical ver-\n\nsion, expectk, lets you wrap non-GUI applications with a windowing front\n\nend.\n\n[URL 25] T Spaces\n\nwww.almaden.ibm.com/cs/TSpaces\n\nFrom their Web page: “T Spaces is a network communication buffer with\n\ndatabase capabilities. It enables communication between applications and\n\ndevices in a network of heterogeneous computers and operating systems.\n\nT Spaces provides group communication services, database services, URL-\n\nbased ﬁle transfer services, and event notiﬁcation services.”\n\n[URL 26] javaCC—Java Compiler-Compiler\n\nwww.webgain.com/products/java_cc\n\nA parser generator that is tightly coupled to the Java language.\n\n[URL 27] The bison Parser Generator\n\nwww.gnu.org/software/bison/bison.html\n\nbison takes an input grammar speciﬁcation and generates from it the C\n\nsource code of a suitable parser.\n\n269\n\n270\n\nAPPENDIX A RESOURCES\n\n[URL 28] SWIG—Simpliﬁed Wrapper and Interface Generator\n\nwww.swig.org\n\nSWIG is a software development tool that connects programs written in C,\n\nC++, and Objective-C with a variety of high-level programming languages\n\nsuch as Perl, Python, and Tcl/Tk, as well as Java, Eiffel, and Guile.\n\n[URL 29] The Object Management Group, Inc.\n\nwww.omg.org\n\nThe OMG is the steward of various speciﬁcations for producing distributed\n\nobject-based systems. Their work includes the Common Object Request\n\nBroker Architecture (CORBA) and the Internet Inter-ORB Protocol (IIOP).\n\nCombined, these speciﬁcations make it possible for objects to communi-\n\ncate with each other, even if they are written in different languages and\n\nrun on different types of computers.\n\nUnix Tools Under DOS [URL 30] The UWIN Development Tools\n\nwww.gtlinc.com/uwin.html\n\nGlobal Technologies, Inc., Old Bridge, NJ\n\nThe UWIN package provides Windows Dynamic Link Libraries (DLLs) that\n\nemulate a large portion of the Unix C level library interface. Using this\n\ninterface, GTL has ported a large number of Unix command-line tools to\n\nWindows. See also [URL 31].\n\n[URL 31] The Cygnus Cygwin Tools\n\nsourceware.cygnus.com/cygwin/\n\nCygnus Solutions, Sunnyvale, CA\n\nThe Cygnus package also emulates the the Unix C library interface, and\n\nprovides a large array of Unix command-line tools under the Windows op-\n\nerating system.\n\n[URL 32] Perl Power Tools\n\nwww.perl.com/pub/language/ppt/\n\nA project to reimplement the classic Unix command set in Perl, making the\n\ncommands available on all platforms that support Perl (and that’s a lot of\n\nplatforms).\n\nINTERNET RESOURCES\n\nSource Code Control Tools [URL 33] RCS—Revision Control System\n\nwww.cs.purdue.edu/homes/trinkle/RCS/\n\nGNU source code control system for Unix and Windows NT.\n\n[URL 34] CVS—Concurrent Version System\n\nwww.cvshome.com\n\nFreely available source code control system for Unix and Windows NT.\n\nExtends RCS by supporting a client-server model and concurrent access\n\nto ﬁles.\n\n[URL 35] Aegis Transaction-Based Conﬁguration Management\n\nhttp://www.canb.auug.org.au/~millerp/aegis.html\n\nA process-oriented revision control tool that imposes project standards\n\n(such as verifying that checked-in code passes tests).\n\n[URL 36] ClearCase\n\nwww.rational.com\n\nVersion control, workspace and build management, process control.\n\n[URL 37] MKS Source Integrity\n\nwww.mks.com\n\nVersion control and conﬁguration management. Some versions incorporate\n\nfeatures allowing remote developers to work on the same ﬁles simultane-\n\nously (much like CVS).\n\n[URL 38] PVCS Conﬁguration Management\n\nwww.merant.com\n\nA source code control system, very popular for Windows systems.\n\n[URL 39] Visual SourceSafe\n\nwww.microsoft.com\n\nA version control system that integrates with Microsoft’s visual develop-\n\nment tools.\n\n[URL 40] Perforce\n\nwww.perforce.com\n\nA client-server software conﬁguration management system.\n\n271\n\n272\n\nAPPENDIX A RESOURCES\n\nOther Tools [URL 41] WinZip—Archive Utility for Windows\n\nwww.winzip.com\n\nNico Mak Computing, Inc., Mansﬁeld, CT\n\nA Windows-based ﬁle archive utility. Supports both zip and tar formats.\n\n[URL 42] The Z Shell\n\nsunsite.auc.dk/zsh\n\nA shell designed for interactive use, although it is also a powerful scripting\n\nlanguage. Many of the useful features of bash, ksh, and tcsh were incor-\n\nporated into zsh; many original features were added.\n\n[URL 43] A Free SMB Client for Unix Systems samba.anu.edu.au/pub/samba/\n\nSamba lets you share ﬁles and other resources between Unix and Windows systems. Samba includes:\n\nAn SMB server, to provide Windows NT and LAN Manager-style ﬁle and print services to SMB clients such as Windows 95, Warp Server, smbfs, and others.\n\nA Netbios nameserver, which among other things gives browsing sup- port. Samba can be the master browser on your LAN if you wish.\n\nAn ftp-like SMB client that allows you to access PC resources (disks and printers) from Unix, Netware, and other operating systems.\n\nPapersand Publications [URL 44] The comp.object FAQ\n\nwww.cyberdyne-object-sys.com/oofaq2\n\nA substantial and well-organized FAQ for the comp.object newsgroup.\n\n[URL 45] eXtreme Programming\n\nwww.XProgramming.com\n\nFrom the Web site: “In XP, we use a very lightweight combination of prac-\n\ntices to create a team that can rapidly produce extremely reliable, efﬁcient,\n\nwell-factored software. Many of the XP practices were created and tested as\n\npart of the Chrysler C3 project, which is a very successful payroll system\n\nimplemented in Smalltalk.”\n\n[URL 46] Alistair Cockburn’s Home Page\n\nmembers.aol.com/acockburn\n\nLook for “Structuring Use Cases with Goals” and use case templates.\n\nINTERNET RESOURCES\n\n[URL 47] Martin Fowler’s Home Page\n\nourworld.compuserve.com/homepages/martin_fowler\n\nAuthor of Analysis Patterns and co-author of UML Distilled and Refactor- ing: Improving the Design of Existing Code. Martin Fowler’s home page dis-\n\ncusses his books and his work with the UML.\n\n[URL 48] Robert C. Martin’s Home Page\n\nwww.objectmentor.com\n\nGood introductory papers on object-oriented techniques, including depen-\n\ndency analysis and metrics.\n\n[URL 49] Aspect-Oriented Programming\n\nwww.parc.xerox.com/csl/projects/aop/\n\nAn approach to adding functionality to code, both orthogonally and declar-\n\natively.\n\n[URL 50] JavaSpaces Speciﬁcation\n\njava.sun.com/products/javaspaces\n\nA Linda-like system for Java that supports distributed persistence and\n\ndistributed algorithms.\n\n[URL 51] Netscape Source Code\n\nwww.mozilla.org\n\nThe development source of the Netscape browser.\n\n[URL 52] The Jargon File\n\nwww.jargon.org\n\nEric S. Raymond\n\nDeﬁnitions for many common (and not so common) computer industry\n\nterms, along with a good dose of folklore.\n\n[URL 53] Eric S. Raymond’s Papers\n\nwww.tuxedo.org/~esr\n\nEric’s papers on The Cathedral and the Bazaar and Homesteading the Noo- sphere describing the psychosocietal basis for and implications of the Open\n\nSource movement.\n\n[URL 54] The K Desktop Environment\n\nwww.kde.org\n\nFrom their Web page: “KDE is a powerful graphical desktop environment for Unix workstations. KDE is an Internet project and truly open in every sense.”\n\n273\n\n274\n\nAPPENDIX A RESOURCES\n\n[URL 55] The GNU Image Manipulation Program\n\nwww.gimp.org\n\nGimp is a freely distributed program used for image creation, composition,\n\nand retouching.\n\n[URL 56] The Demeter Project\n\nwww.ccs.neu.edu/research/demeter\n\nResearch focused on making software easier to maintain and evolve using\n\nAdaptive Programming.\n\nMiscellaneous [URL 57] The GNU Project\n\nwww.gnu.org\n\nFree Software Foundation, Boston, MA\n\nThe Free Software Foundation is a tax-exempt charity that raises funds\n\nfor the GNU project. The GNU project’s goal is to produce a complete, free,\n\nUnix-like system. Many of the tools they’ve developed along the way have\n\nbecome industry standards.\n\n[URL 58] Web Server Information\n\nwww.netcraft.com/survey/servers.html\n\nLinks to the home pages of over 50 different web servers. Some are com-\n\nmercial products, while others are freely available.\n\nBibliography\n\n[Bak72]\n\nF. T. Baker. Chief programmer team management of pro- IBM Systems Journal, 11(1):56–73, duction programming. 1972.\n\n[BBM96] V. Basili, L. Briand, and W. L. Melo. A validation of object- IEEE Trans- oriented design metrics as quality indicators. actions on Software Engineering, 22(10):751–761, October 1996.\n\n[Ber96]\n\nAlbert J. Bernstein. Dinosaur Brains: Dealing with All Those Impossible People at Work. Ballantine Books, New York, NY, 1996.\n\nBIBLIOGRAPHY\n\n[Bra95]\n\nMarshall Brain. Win32 System Services. Prentice Hall, En- glewood Cliffs, NJ, 1995.\n\n[Bro95]\n\nFrederick P. Brooks, Jr. The Mythical Man Month: Essays on Software Engineering. Addison-Wesley, Reading, MA, an- niversary edition, 1995.\n\n[CG90]\n\nN. Carriero and D. Gelenter. How to Write Parallel Programs: A First Course. MIT Press, Cambridge, MA, 1990.\n\n[Cla04]\n\nMike Clark. Pragmatic Project Automation. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2004.\n\n[CN91]\n\nBrad J. Cox and Andrex J. Novobilski. Object-Oriented Programming, An Evolutionary Approach. Addison-Wesley, Reading, MA, 1991.\n\n[Coc97a] Alistair Cockburn. Goals and use cases. Journal of Object\n\nOriented Programming, 9(7):35–40, September 1997.\n\n[Coc97b] Alistair Cockburn.\n\nSurviving Object-Oriented Projects: A Manager’s Guide. Addison Wesley Longman, Reading, MA, 1997.\n\n[Cop92]\n\nJames O. Coplien. Advanced C++ Programming Styles and Idioms. Addison-Wesley, Reading, MA, 1992.\n\n[DL99]\n\nTom Demarco and Timothy Lister. Peopleware: Productive Projects and Teams. Dorset House, New York, NY, second edition, 1999.\n\n[FBB 99] Martin Fowler, Kent Beck, John Brant, William Opdyke, and Don Roberts. Refactoring: Improving the Design of Existing Code. Addison Wesley Longman, Reading, MA, 1999.\n\n[Fow96] Martin Fowler. Analysis Patterns: Reusable Object Models. Addison Wesley Longman, Reading, MA, 1996.\n\n[FS99]\n\nMartin Fowler and Kendall Scott. UML Distilled: Applying the Standard Object Modeling Language. Addison Wesley Long- man, Reading, MA, second edition, 1999.\n\n[GHJV95] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. Design Patterns: Elements of Reusable Object- Oriented Software. Addison-Wesley, Reading, MA, 1995.\n\n275",
      "page_number": 291
    },
    {
      "number": 37,
      "title": "Segment 37 (pages 300-308)",
      "start_page": 300,
      "end_page": 308,
      "detection_method": "topic_boundary",
      "content": "276\n\nAPPENDIX A RESOURCES\n\n[Gla99a] Robert L. Glass.\n\nInspections—Some surprising ﬁndings.\n\nCommunications of the ACM, 42(4):17–19, April 1999.\n\n[Gla99b] Robert L. Glass. The realities of software technology payoffs.\n\nCommunications of the ACM, 42(2):74–79, February 1999.\n\n[Hol78]\n\nMichael Holt. Math Puzzles and Games. Dorset Press, New York, NY, 1978.\n\n[HT03]\n\nAndy Hunt and Dave Thomas. Pragmatic Unit Testing In Java with JUnit. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2003.\n\n[Jac94]\n\nIvar Jacobson. Object-Oriented Software Engineering: A Use- Case Driven Approach. Addison-Wesley, Reading, MA, 1994.\n\n[KLM 97] Gregor Kiczales, John Lamping, Anurag Mendhekar, Chris Maeda, Cristina Videira Lopes, Jean-Marc Loingtier, and In European John Irwin. Aspect-oriented programming. Conference on Object-Oriented Programming (ECOOP), vol- ume LNCS 1241. Springer-Verlag, June 1997.\n\n[Knu97a] Donald Ervin Knuth. The Art of Computer Programming: Fun- damental Algorithms, volume 1. Addison Wesley Longman, Reading, MA, third edition, 1997.\n\n[Knu97b] Donald Ervin Knuth. The Art of Computer Programming: Seminumerical Algorithms, volume 2. Addison Wesley Long- man, Reading, MA, third edition, 1997.\n\n[Knu98] Donald Ervin Knuth. The Art of Computer Programming: Sorting and Searching, volume 3. Addison Wesley Longman, Reading, MA, second edition, 1998.\n\n[KP99]\n\nBrian W. Kernighan and Rob Pike. The Practice of Program- ming. Addison Wesley Longman, Reading, MA, 1999.\n\n[Kru98]\n\nPhilippe Kruchten. The Rational Uniﬁed Process: An Intro- duction. Addison Wesley Longman, Reading, MA, 1998.\n\n[Lak96]\n\nJohn Lakos. Large-Scale C++ Software Design. Addison Wesley Longman, Reading, MA, 1996.\n\nBIBLIOGRAPHY\n\n[LH89]\n\nKarl J. Lieberherr and Ian Holland. Assuring good style for object-oriented programs. IEEE Software, pages 38–48, September 1989.\n\n[Lis88]\n\nBarbara Liskov. Data abstraction and hierarchy. SIGPLAN Notices, 23(5), May 1988.\n\n[LMB92]\n\nJohn R. Levine, Tony Mason, and Doug Brown. Lex and Yacc. O’Reilly & Associates, Inc., Sebastopol, CA, second edition, 1992.\n\n[McC95]\n\nJim McCarthy. Dynamics of Software Development. Mi- crosoft Press, Redmond, WA, 1995.\n\n[Mey96]\n\nScott Meyers. More Effective C++: 35 New Ways to Improve Your Programs and Designs. Addison-Wesley, Reading, MA, 1996.\n\n[Mey97a] Scott Meyers. Effective C++: 50 Speciﬁc Ways to Improve Your Programs and Designs. Addison Wesley Longman, Reading, MA, second edition, 1997.\n\n[Mey97b] Bertrand Meyer. Object-Oriented Software Construction.\n\nPrentice Hall, Englewood Cliffs, NJ, second edition, 1997.\n\n[Pet98]\n\nProgramming Windows, The Deﬁnitive Charles Petzold. Guide to the Win32 API. Microsoft Press, Redmond, WA, ﬁfth edition, 1998.\n\n[Sch95]\n\nApplied Cryptography: Protocols, Algo- Bruce Schneier. rithms, and Source Code in C. John Wiley & Sons, New York, NY, second edition, 1995.\n\n[Sed83]\n\nRobert Sedgewick. Algorithms. Addison-Wesley, Reading, MA, 1983.\n\n[Sed92]\n\nRobert Sedgewick. Algorithms in C++. Addison-Wesley, Reading, MA, 1992.\n\n[SF96]\n\nRobert Sedgewick and Phillipe Flajolet. An Introduction to the Analysis of Algorithms. Addison-Wesley, Reading, MA, 1996.\n\n[Ste92]\n\nW. Richard Stevens. Advanced Programming in the Unix En- vironment. Addison-Wesley, Reading, MA, 1992.\n\n277\n\n278\n\nAPPENDIX A RESOURCES\n\n[Ste98]\n\nW. Richard Stevens. Unix Network Programming, Volume 1: Networking APIs: Sockets and Xti. Prentice Hall, Englewood Cliffs, NJ, second edition, 1998.\n\n[Ste99]\n\nW. Richard Stevens. Unix Network Programming, Volume 2: Interprocess Communications. Prentice Hall, Englewood Cliffs, NJ, second edition, 1999.\n\n[Str35]\n\nJames Ridley Stroop. Studies of interference in serial verbal reactions. Journal of Experimental Psychology, 18:643–662, 1935.\n\n[TFH04] Dave Thomas, Chad Fowler, and Andy Hunt. Programming Ruby, The Pragmatic Programmers’ Guide. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2004.\n\n[TH03]\n\nDave Thomas and Andy Hunt. Pragmatic Version Control Using CVS. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2003.\n\n[WK82]\n\nJames Q. Wilson and George Kelling. The police and neigh- borhood safety. The Atlantic Monthly, 249(3):29–38, March 1982.\n\n[YC86]\n\nEdward Yourdon and Larry L. Constantine. Structured De- sign: Fundamentals of a Discipline of Computer Program and Systems Design. Prentice Hall, Englewood Cliffs, NJ, second edition, 1986.\n\n[You95]\n\nEdward Yourdon. When good-enough software is best. IEEE Software, May 1995.\n\nAppendix B\n\nAnswers to Exercises\n\nExercise 1: fromOrthogonality onpage43 You are writing a class called Split, which splits input lines into ﬁelds. Which of the following two Java class signatures is the more orthogonal design?\n\nclass Split1 {\n\npublic Split1(InputStreamReader rdr) { ... public void readNextLine() throws IOException { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\nclass Split2 {\n\npublic Split2(String line) { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\nAnswer 1: To our way of thinking, class Split2 is more orthogonal. It con- centrates on its own task, splitting lines, and ignores details such as where the lines are coming from. Not only does this make the code easier to develop, but it also makes it more ﬂexible. Split2 can split lines read from a ﬁle, generated by another routine, or passed in via the environment.\n\nExercise 2: fromOrthogonality onpage43 Which will lead to a more orthogonal design: modeless or modal dialog boxes?\n\nAnswer 2: If done correctly, probably modeless. A system that uses mode- less dialog boxes will be less concerned with what is going on at any particular moment in time. It will likely have a better intermodule communications in- frastructure than a modal system, which may have built-in assumptions about the state of the system—assumptions that lead to increased coupling and de- creased orthogonality.\n\n279\n\n280\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 3: fromOrthogonalityonpage43 How about procedural languages versus object technology? Which results in a more orthogonal system?\n\nAnswer 3: This is a little tricky. Object technology can provide a more orthog- onal system, but because it has more features to abuse, it is actually easier to create a nonorthogonal system using objects than it is using a procedural lan- guage. Features such as multiple inheritance, exceptions, operator overload- ing, and parent-method overriding (via subclassing) provide ample opportunity to increase coupling in nonobvious ways.\n\nWith object technology and a little extra effort, you can achieve a much more orthogonal system. But while you can always write “spaghetti code” in a pro- cedural language, object-oriented languages used poorly can add meatballs to your spaghetti.\n\nExercise 4: fromPrototypesandPost-itNotesonpage56 Marketing would like to sit down and brainstorm a few Web-page designs with you. They are thinking of clickable image maps to take you to other pages, and so on. But they can’t decide on a model for the image—maybe it’s a car, or a phone, or a house. You have a list of target pages and content; they’d like to see a few prototypes. Oh, by the way, you have 15 minutes. What tools might you use?\n\nAnswer 4: Low-tech to the rescue! Draw a few cartoons with markers on a whiteboard—a car, a phone, and a house. It doesn’t have to be great art; stick- ﬁgure outlines are ﬁne. Put Post-it notes that describe the contents of target pages on the clickable areas. As the meeting progresses, you can reﬁne the drawings and placements of the Post-it notes.\n\nExercise 5: fromDomainLanguagesonpage63 We want to implement a mini-language to control a simple drawing package (perhaps a turtle-graphics system). The language consists of single-letter com- mands. Some commands are followed by a single number. For example, the following input would draw a rectangle.\n\nP 2 D W 2 N 1 E 2 S 1 U\n\n# select pen 2 # pen down # draw west 2cm # then north 1 # then east 2 # then back south # pen up\n\nImplement the code that parses this language. It should be designed so that it is simple to add new commands.\n\nAnswer 5: Because we want to make the language extendable, we’ll make the parser table driven. Each entry in the table contains the command letter, a ﬂag to say whether an argument is required, and the name of the routine to call to handle that particular command.\n\ntypedef struct {\n\nchar cmd; int hasArg; void (*func)(int, int); /* routine to call */\n\n/* the command letter */ /* does it take an argument */\n\n} Command;\n\nstatic Command cmds[] = {\n\n{ ’P’, ARG, { ’U’, NO_ARG, doPenUp }, { ’D’, NO_ARG, doPenDown }, { ’N’, ARG, { ’E’, ARG, { ’S’, ARG, { ’W’, ARG,\n\ndoSelectPen },\n\ndoPenDir }, doPenDir }, doPenDir }, doPenDir }\n\n};\n\nThe main program is pretty simple: read a line, look up the command, get the argument if required, then call the handler function.\n\nwhile (fgets(buff, sizeof(buff), stdin)) {\n\nCommand *cmd = findCommand(*buff);\n\nif (cmd) {\n\nint\n\narg = 0;\n\nif (cmd->hasArg && !getArg(buff+1, &arg)) {\n\nfprintf(stderr, \"’%c’ needs an argument n\", *buff); continue;\n\n}\n\ncmd->func(*buff, arg);\n\n}\n\n}\n\nThe function that looks up a command performs a linear search of the table, returning either the matching entry or NULL.\n\nCommand *findCommand(int cmd) {\n\nint i;\n\nfor (i = 0; i < ARRAY_SIZE(cmds); i++) {\n\nif (cmds[i].cmd == cmd)\n\nreturn cmds + i;\n\n}\n\nfprintf(stderr, \"Unknown command ’%c’ n\", cmd); return 0;\n\n}\n\nFinally, reading the numeric argument is pretty simple using sscanf.\n\nint getArg(const char *buff, int *result) { return sscanf(buff, \"%d\", result) == 1;\n\n}\n\n281\n\n282\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 6: fromDomainLanguagesonpage63 Design a BNF grammar to parse a time speciﬁcation. All of the following exam- ples should be accepted.\n\n4pm, 7:38pm, 23:42, 3:16, 3:16am\n\nAnswer 6: Using BNF, a time speciﬁcation could be\n\ntime\n\nhour hour hour\n\nampm : minute : minute\n\nampm\n\nampm\n\nam pm\n\nhour\n\ndigit digit\n\ndigit\n\nminute\n\ndigit\n\ndigit\n\ndigit\n\n0 1 2 3 4 5 6 7 8 9\n\nExercise 7: fromDomainLanguagesonpage63 Implement a parser for the BNF grammar in Exercise 6 using yacc, bison, or a similar parser-generator.\n\nAnswer 7: We coded our example using bison, the GNU version of yacc. For clarity, we’re just showing the body of the parser here. Look at the source on our Web site for the full implementation.\n\ntime:\n\nspec END_TOKEN { if ($1 >= 24*60) yyerror(\"Time is too large\");\n\nprintf(\"%d minutes past midnight n\", $1); exit(0);\n\n}\n\n;\n\nspec:\n\nhour ’:’ minute { $$ = $1 + $3; }\n\n| hour ’:’ minute ampm\n\n{ if ($1 > 11*60) yyerror(\"Hour out of range\");\n\n$$ = $1 + $3 + $4;\n\n}\n\n| hour ampm\n\n{ if ($1 > 11*60) yyerror(\"Hour out of range\");\n\n$$ = $1 + $2;\n\n}\n\n;\n\nhour:\n\nhour_num { if ($1 > 23) yyerror(\"Hour out of range\");\n\n$$ = $1 * 60;\n\n};\n\nminute:\n\nDIGIT DIGIT { $$ = $1*10 + $2;\n\nif ($$ > 59) yyerror(\"minute out of range\");\n\n};\n\nampm:\n\nAM | PM ;\n\n{ $$ = AM_MINS; } { $$ = PM_MINS; }\n\nhour_num: DIGIT\n\n| DIGIT DIGIT ;\n\n{ $$ = $1; } { $$ = $1*10 + $2; }\n\nExercise 8: fromDomainLanguagesonpage63 Implement the time parser using Perl. [Hint: Regular expressions make good parsers.]\n\nAnswer 8:\n\n$_ = shift;\n\n/^( d d?)(am|pm)$/\n\n&& doTime($1, 0,\n\n$2, 12);\n\n/^( d d?):( d d)(am|pm)$/ && doTime($1, $2, $3, 12);\n\n/^( d d?):( d d)$/\n\n&& doTime($1, $2, 0, 24);\n\ndie \"Invalid time $_ n\";\n\n# # doTime(hour, min, ampm, maxHour) # sub doTime($$$$) {\n\nmy ($hour, $min, $offset, $maxHour) = @_; die \"Invalid hour: $hour\" if ($hour >= $maxHour); $hour += 12 if ($offset eq \"pm\"); print $hour*60 + $min, \" minutes past midnight n\"; exit(0);\n\n}\n\nExercise 9: fromEstimatingonpage69 You are asked “Which has a higher bandwidth: a 1Mbps communications line or a person walking between two computers with a full 4GB tape in their pocket?” What constraints will you put on your answer to ensure that the scope of your response is correct? (For example, you might say that the time taken to access the tape is ignored.)\n\nAnswer 9: Our answer must be couched in several assumptions:\n\nThe tape contains the information we need to be transferred.\n\nWe know the speed at which the person walks.\n\nWe know the distance between the machines.\n\nWe are not accounting for the time it takes to transfer information to and from the tape.\n\n283\n\n284\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nThe overhead of storing data on a tape is roughly equal to the overhead of sending it over a communications line.\n\nExercise 10: fromEstimating onpage69 So, which has the higher bandwidth?\n\nAnswer 10: Subject to the caveats in Answer 9: A 4GB tape contains bits, so a 1Mbps line would have to pump data for about seconds, or roughly hours, to transfer the equivalent amount of information. If the person mph, then our two machines would need to be at is walking at a constant least miles apart for the communications line to outperform our courier. Otherwise, the person wins.\n\nExercise 11: fromTextManipulation onpage102 Your C program uses an enumerated type to represent one of 100 states. You’d like to be able to print out the state as a string (as opposed to a number) for debugging purposes. Write a script that reads from standard input a ﬁle containing\n\nname state_a state_b :\n\n:\n\nProduce the ﬁle name.h, which contains\n\nextern const char* NAME_names[]; typedef enum { state_a, state_b,\n\n: } NAME;\n\n:\n\nand the ﬁle name.c, which contains\n\nconst char* NAME_names[] = {\n\n\"state_a\", \"state_b\",\n\n:\n\n:\n\n};",
      "page_number": 300
    },
    {
      "number": 38,
      "title": "Segment 38 (pages 309-316)",
      "start_page": 309,
      "end_page": 316,
      "detection_method": "topic_boundary",
      "content": "Answer 11: We implemented our answer using Perl.\n\nmy @consts;\n\nmy $name = <>; die \"Invalid format - missing name\" unless defined($name);\n\nchomp $name;\n\n# Read in the rest of the file while (<>) {\n\nchomp; s/^ s*//; s/ s*$//;\n\ndie \"Invalid line: $_\" unless /^( w+)$/;\n\npush @consts, $_;\n\n}\n\n# Now generate the file open(HDR, \">$name.h\") or die \"Can’t open $name.h: $!\"; open(SRC, \">$name.c\") or die \"Can’t open $name.c: $!\";\n\nmy $uc_name = uc($name); my $array_name = $uc_name . \"_names\";\n\nprint HDR \"/* File generated automatically - do not edit */ n\"; print HDR \"extern const char *$ {array_name}[];\"; print HDR \"typedef enum { n\n\n\";\n\nprint HDR join \", n \", @consts;\n\nprint HDR \" n} $uc_name; n n\";\n\nprint SRC \"/* File generated automatically - do not edit */ n\";\n\nprint SRC \"const char *$ {array_name}[] = { n\n\n\"\";\n\nprint SRC join \" \", n\n\n\"\", @consts;\n\nprint SRC \" \" n}; n\";\n\nclose(SRC); close(HDR);\n\nUsing the DRY principle, we won’t cut and paste this new ﬁle into our code. Instead, we’ll #include it—the ﬂat ﬁle is the master source of these constants. This means that we’ll need a makeﬁle to regenerate the header when the ﬁle changes. The following extract is from the test bed in our source tree (available on the Web site).\n\netest.c etest.h: etest.inc enumerated.pl\n\nperl enumerated.pl etest.inc\n\nExercise 12: fromTextManipulationonpage102 Halfway through writing this book, we realized that we hadn’t put the use strict directive into many of our Perl examples. Write a script that goes through the .pl ﬁles in a directory and adds a use strict at the end of the initial comment block to all ﬁles that don’t already have one. Remember to keep a backup of all ﬁles you change.\n\n285\n\n286\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nAnswer 12: Here’s our answer, written in Perl.\n\nmy $dir = shift or die \"Missing directory\";\n\nfor my $file (glob(\"$dir/*.pl\")) {\n\nopen(IP, \"$file\") or die \"Opening $file: $!\"; undef $/; my $content = <IP>; # read whole file as one string. close(IP);\n\n# Turn off input record separator --\n\nif ($content !~ /^use strict/m) {\n\nrename $file, \"$file.bak\" or die \"Renaming $file: $!\"; open(OP, \">$file\") or die \"Creating $file: $!\";\n\n# Put ’use strict’ on first line that # doesn’t start ’#’ $content =~ s/^(?!#)/ nuse strict; n n/m;\n\nprint OP $content; close(OP);\n\nprint \"Updated $file n\";\n\n} else {\n\nprint \"$file already strict n\";\n\n}\n\n}\n\nExercise 13: fromCodeGeneratorsonpage106 Write a code generator that takes the input ﬁle in Figure 3.4, page 106, and generates output in two languages of your choice. Try to make it easy to add new languages.\n\nAnswer 13: We use Perl to implement our solution. It dynamically loads a module to generate the requested language, so adding new languages is easy. The main routine loads the back end (based on a command-line parameter), then reads its input and calls code generation routines based on the content of each line. We’re not particularly fussy about error handling—we’ll get to know pretty quickly if things go wrong.\n\nmy $lang = shift or die \"Missing language\"; $lang .= \"_cg.pm\";\n\nrequire \"$lang\" or die \"Couldn’t load $lang\";\n\n# Read and parse the file\n\nmy $name;\n\nwhile (<>) {\n\nchomp; if\n\n(/^ s*$/)\n\n{ CG::blankLine(); }\n\nelsif (/^ #(.*)/)\n\n{ CG::comment($1); }\n\nelsif (/^M s*(.+)/) { CG::startMsg($1); $name = $1; } elsif (/^E/) elsif (/^F s*( w+) s+( w+)$/)\n\n{ CG::endMsg($name); }\n\n{ CG::simpleType($1,$2); }\n\nelsif (/^F s*( w+) s+( w+) [( d+) ]$/)\n\n{ CG::arrayType($1,$2,$3); }\n\nelse {\n\ndie \"Invalid line: $_\";\n\n}\n\n}\n\nWriting a language back end is simple: provide a module that implements the required six entry points. Here’s the C generator:\n\n#!/usr/bin/perl -w package CG; use strict;\n\n# Code generator for ’C’ (see cg_base.pl)\n\nsub blankLine() { print \" n\"; }\n\nsub comment()\n\n{ print \"/*$_[0] */ n\"; }\n\nsub startMsg() { print \"typedef struct { n\"; }\n\nsub endMsg()\n\n{ print \"} $_[0]; n n\"; }\n\nsub arrayType() {\n\nmy ($name, $type, $size) = @_;\n\nprint \"\n\n$type $name [$size]; n\";\n\n}\n\nsub simpleType() {\n\nmy ($name, $type) = @_; print \"\n\n$type $name; n\";\n\n}\n\n1;\n\nAnd here’s the one for Pascal:\n\n#!/usr/bin/perl -w package CG; use strict;\n\n# Code generator for ’Pascal’ (see cg_base.pl)\n\nsub blankLine() { print \" n\"; }\n\nsub comment()\n\n{ print \"{$_[0] } n\"; }\n\nsub startMsg() { print \"$_[0] = packed record n\"; }\n\nsub endMsg()\n\n{ print \"end; n n\"; }\n\nsub arrayType() {\n\nmy ($name, $type, $size) = @_; $size--; print \"\n\n$name: array[0..$size] of $type; n\";\n\n}\n\nsub simpleType() {\n\nmy ($name, $type) = @_; print \"\n\n$name: $type; n\";\n\n}\n\n1;\n\n287\n\n288\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 14: fromDesignbyContractonpage118 What makes a good contract? Anyone can add preconditions and postcondi- tions, but will they do you any good? Worse yet, will they actually do more harm than good? For the example below and for those in Exercises 15 and 16, decide whether the speciﬁed contract is good, bad, or ugly, and explain why.\n\nFirst, let’s look at an Eiffel example. Here we have a routine for adding a STRING to a doubly linked, circular list (remember that preconditions are labeled with require, and postconditions with ensure).\n\n-- Add a unique item to a doubly linked list, -- and return the newly created NODE.\n\nadd_item (item : STRING) : NODE is\n\nrequire\n\nitem /= Void find_item(item) = Void\n\ndeferred ensure\n\n-- ’/=’ is ’not equal’. -- Must be unique -- Abstract base class.\n\nresult.next.previous = result -- Check the newly result.previous.next = result -- added node’s links. find_item(item) = result\n\n-- Should find it.\n\nend\n\nAnswer 14: This Eiffel example is good. We require non-null data to be passed in, and we guarantee that the semantics of a circular, doubly linked list are honored. It also helps to be able to ﬁnd the string we stored. Because this is a deferred class, the actual class that implements it is free to use what- ever underlying mechanism it wants to. It may choose to use pointers, or an array, or whatever; as long as it honors the contract, we don’t care.\n\nExercise 15: fromDesignbyContractonpage119 Next, let’s try an example in Java—somewhat similar to the example in Exercise 14. insertNumber inserts an integer into an ordered list. Pre- and postcondi- tions are labeled as in iContract (see [URL 17]).\n\nprivate int data[]; /**\n\n@post data[index-1] < data[index] && * data[index] == aValue */\n\npublic Node insertNumber (final int aValue) {\n\nint index = findPlaceToInsert(aValue); ...\n\nAnswer 15: This is bad. The math in the index clause (index-1) won’t work on boundary conditions such as the ﬁrst entry. The postcondition assumes a particular implementation: we want contracts to be more abstract than that.\n\nExercise 16: fromDesignbyContractonpage119 Here’s a fragment from a stack class in Java. Is this a good contract?\n\n/**\n\n@pre anItem != null * @post pop() == anItem // Verify that it’s * */ // Require real data\n\npublic void push(final String anItem)\n\nAnswer 16: It’s a good contract, but a bad implementation. Here, the infa- mous “Heisenbug” [URL 52] rears its ugly head. The programmer probably just made a simple typo—pop instead of top. While this is a simple and contrived example, side effects in assertions (or in any unexpected place in the code) can be very difﬁcult to diagnose.\n\nExercise 17: fromDesignbyContractonpage119 The classic examples of DBC (as in Exercises 14–16) show an implementation of an ADT (Abstract Data Type)—typically a stack or queue. But not many people really write these kinds of low-level classes.\n\nSo, for this exercise, design an interface to a kitchen blender. It will eventually be a Web-based, Internet-enabled, CORBA-ﬁed blender, but for now we just need the interface to control it. It has ten speed settings (0 means off). You can’t operate it empty, and you can change the speed only one unit at a time (that is, from 0 to 1, and from 1 to 2, not from 0 to 2).\n\nHere are the methods. Add appropriate pre- and postconditions and an invari- ant.\n\nint getSpeed() void setSpeed(int x) boolean isFull() void fill() void empty()\n\nAnswer 17: We’ll show the function signatures in Java, with the pre- and postconditions labeled as in iContract.\n\nFirst, the invariant for the class:\n\n/**\n\n@invariant getSpeed() > 0 * * @invariant getSpeed() >= 0 && * */ getSpeed() < 10\n\nimplies isFull()\n\n// Don’t run empty\n\n// Range check\n\nNext, the pre- and postconditions:\n\n289\n\n290\n\nAPPENDIX B ANSWERS TO EXERCISES\n\n/**\n\n@pre Math.abs(getSpeed() - x) <= 1 // Only change by one * @pre x >= 0 && x < 10 * @post getSpeed() == x */ // Range check // Honor requested speed\n\npublic void setSpeed(final int x)\n\n/**\n\n@pre !isFull() * @post isFull() */\n\n// Don’t fill it twice // Ensure it was done\n\nvoid fill()\n\n/**\n\n@pre isFull() * @post !isFull() */\n\n// Don’t empty it twice // Ensure it was done\n\nvoid empty()\n\nExercise 18: fromDesignbyContractonpage119 How many numbers are in the series\n\n?\n\nAnswer 18: enced a fencepost error.\n\nThere are 21 terms in the series. If you said 20, you just experi-\n\nExercise 19: fromAssertiveProgrammingonpage125 A quick reality check. Which of these “impossible” things can happen?\n\n1. A month with fewer than 28 days 2. stat(\".\",&sb) == -1 (that is, can’t access the current directory) 3. In C++: 4. A triangle with an interior angle sum 5. A minute that doesn’t have 60 seconds 6. In Java: (a + 1) <= a a = 2; b = 3; if (a + b != 5) exit(1);\n\nAnswer 19:\n\n1. September, 1752 had only 19 days. This was done to synchronize calen-\n\ndars as part of the Gregorian Reformation.\n\n2. The directory could have been removed by another process, you might not have permission to read it, &sb might be invalid—you get the picture.\n\n3. We sneakily didn’t specify the types of a and b. Operator overloading might have deﬁned +, =, or != to have unexpected behavior. Also, a and b may be aliases for the same variable, so the second assignment will overwrite the value stored in the ﬁrst.\n\n4. In non-Euclidean geometry, the sum of the angles of a triangle will not add\n\nup to\n\n. Think of a triangle mapped on the surface of a sphere.\n\n5. Leap minutes may have 61 or 62 seconds.\n\n6. Overﬂow may leave the result of a + 1 negative (this can also happen in\n\nC and C++).\n\nExercise 20: fromAssertiveProgrammingonpage125 Develop a simple assertion checking class for Java.\n\nAnswer 20: We chose to implement a very simple class with a single static method, TEST, that prints a message and a stack trace if the passed condition parameter is false.\n\npackage com.pragprog.util;\n\nimport java.lang.System; import java.lang.Thread;\n\n// for exit() // for dumpStack()\n\npublic class Assert {\n\n/** Write a message, print a stack trace and exit if\n\nour parameter is false. */\n\npublic static void TEST(boolean condition) {\n\nif (!condition) {\n\nSystem.out.println(\"==== Assertion Failed ====\"); Thread.dumpStack(); System.exit(1);\n\n}\n\n}\n\n// Testbed. If our argument is ’okay’, try an assertion that // succeeds, if ’fail’ try one that fails\n\npublic static final void main(String args[]) {\n\nif (args[0].compareTo(\"okay\") == 0) {\n\nTEST(1 == 1);\n\n} else if (args[0].compareTo(\"fail\") == 0) {\n\nTEST(1 == 2);\n\n} else {\n\nthrow new RuntimeException(\"Bad argument\");\n\n}\n\n}\n\n}\n\nExercise 21: fromWhentoUseExceptionsonpage128 While designing a new container class, you identify the following possible error conditions:\n\n1. No memory available for a new element in the add routine\n\n2. Requested entry not found in the fetch routine\n\n3. null pointer passed to the add routine\n\n291\n\n292\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nHow should each be handled? Should an error be generated, should an excep- tion be raised, or should the condition be ignored?\n\nAnswer 21: Running out of memory is an exceptional condition, so we feel that case (1) should raise an exception.\n\nFailure to ﬁnd an entry is probably quite a normal occurrence. The application that calls our collection class may well write code that checks to see if an entry is present before adding a potential duplicate. We feel that case (2) should just return an error.\n\nCase (3) is more problematic—if the value null is signiﬁcant to the application, then it may be justiﬁably added to the container. If, however, it makes no sense to store null values, an exception should probably be thrown.\n\nExercise 22: fromHowtoBalanceResourcesonpage136 Some C and C++ developers make a point of setting a pointer to NULL after they deallocate the memory it references. Why is this a good idea?\n\nAnswer 22: In most C and C++ implementations, there is no way of checking that a pointer actually points to valid memory. A common mistake is to deal- locate a block of memory and reference that memory later in the program. By then, the memory pointed to may well have been reallocated to some other pur- pose. By setting the pointer to NULL, the programmers hope to prevent these rogue references—in most cases, dereferencing a NULL pointer will generate a runtime error.\n\nExercise 23: fromHowtoBalanceResourcesonpage136 Some Java developers make a point of setting an object variable to NULL after they have ﬁnished using the object. Why is this a good idea?\n\nAnswer 23: By setting the reference to NULL, you reduce the number of point- ers to the referenced object by one. Once this count reaches zero, the object is eligible for garbage collection. Setting the references to NULL can be signiﬁ- cant for long-running programs, where the programmers need to ensure that memory utilization doesn’t increase over time.",
      "page_number": 309
    },
    {
      "number": 39,
      "title": "Segment 39 (pages 317-324)",
      "start_page": 317,
      "end_page": 324,
      "detection_method": "topic_boundary",
      "content": "Exercise 24: fromDecouplingandtheLawofDemeteronpage143 We discussed the concept of physical decoupling in the box on page 142. Which of the following C++ header ﬁles is more tightly coupled to the rest of the system?\n\nperson1.h:\n\nperson2.h:\n\n#include \"date.h\"\n\nclass Date;\n\nclass Person1 { private:\n\nclass Person2 { private:\n\nDate myBirthdate;\n\nDate *myBirthdate;\n\npublic:\n\npublic:\n\nPerson1(Date &birthDate); // ...\n\nPerson2(Date &birthDate); // ...\n\nAnswer 24: A header ﬁle is supposed to deﬁne the interface between the corresponding implementation and the rest of the world. The header ﬁle itself has no need to know about the internals of the Date class—it merely needs to tell the compiler that the constructor takes a Date as a parameter. So, unless the header ﬁle uses Dates in inline functions, the second snippet will work ﬁne.\n\nWhat’s wrong with the ﬁrst snippet? On a small project, nothing, except that you are unnecessarily making everything that uses a Person1 class also in- clude the header ﬁle for Date. Once this kind of usage gets common in a project, you soon ﬁnd that including one header ﬁle ends up including most of the rest of the system—a serious drag on compilation times.\n\nExercise 25: fromDecouplingandtheLawofDemeteronpage143 For the example below and for those in Exercises 26 and 27, determine if the method calls shown are allowed according to the Law of Demeter. This ﬁrst one is in Java.\n\npublic void showBalance(BankAccount acct) {\n\nMoney amt = acct.getBalance(); printToScreen(amt.printFormat());\n\n}\n\nAnswer 25: The variable acct is passed in as a parameter, so the getBal- ance call is allowed. Calling amt.printFormat(), however, is not. We don’t “own” amt and it wasn’t passed to us. We could eliminate showBalance’s cou- pling to Money with something like this:\n\nvoid showBalance(BankAccount b) {\n\nb.printBalance();\n\n}\n\n293\n\n294\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 26: fromDecouplingandtheLawofDemeteronpage143 This example is also in Java.\n\npublic class Colada {\n\nprivate Blender myBlender; private Vector myStuff;\n\npublic Colada() {\n\nmyBlender = new Blender(); myStuff = new Vector();\n\n} private void doSomething() {\n\nmyBlender.addIngredients(myStuff.elements());\n\n}\n\n}\n\nAnswer 26: the calls to addIngredients and elements are allowed.\n\nSince Colada creates and owns both myBlender and myStuff,\n\nExercise 27: fromDecouplingandtheLawofDemeteronpage143 This example is in C++.\n\nvoid processTransaction(BankAccount acct, int) {\n\nPerson *who; Money amt;\n\namt.setValue(123.45); acct.setBalance(amt); who = acct.getOwner(); markWorkflow(who->name(), SET_BALANCE);\n\n}\n\nAnswer 27: In this case, processTransaction owns amt—it is created on the stack. acct is passed in, so both setValue and setBalance are allowed. But processTransaction does not own who, so the call who->name() is in violation. The Law of Demeter suggests replacing this line with\n\nmarkWorkflow(acct.name(), SET_BALANCE);\n\nThe code in processTransaction should not have to know which subobject within a BankAccount holds the name—this structural knowledge should not show through BankAccount’s contract. Instead, we ask the BankAccount for the name on the account. It knows where it keeps the name (maybe in a Person, in a Business, or in a polymorphic Customer object).\n\nExercise 28: fromMetaprogrammingonpage149 Which of the following things would be better represented as code within a program, and which externally as metadata?\n\n1. Communication port assignments 2. An editor’s support for highlighting the syntax of various languages 3. An editor’s support for different graphic devices 4. A state machine for a parser or scanner 5. Sample values and results for use in unit testing\n\nAnswer 28: There are no deﬁnitive answers here—the questions were intended primarily to give you food for thought. However, this is what we think:\n\n1. Communication port assignments. Clearly, this information should be stored as metadata. But to what level of detail? Some Windows communi- cations programs let you select only baud rate and port (say COM1 to COM4). But perhaps you need to specify word size, parity, stop bits, and the duplex setting as well. Try to allow the ﬁnest level of detail where practical.\n\n2. An editor’s support for highlighting the syntax of various languages. This should be implemented as metadata. You wouldn’t want to have to hack code just because the latest version of Java introduced a new keyword.\n\n3. An editor’s support for different graphic devices. This would probably be difﬁcult to implement strictly as metadata. You would not want to burden your application with multiple device drivers only to select one at runtime. You could, however, use metadata to specify the name of the driver and dynamically load the code. This is another good argument for keeping the metadata in a human-readable format; if you use the program to set up a dysfunctional video driver, you may not be able to use the program to set it back.\n\n4. A state machine for a parser or scanner. This depends on what you are parsing or scanning. If you are parsing some data that is rigidly deﬁned by a standards body and is unlikely to change without an act of Congress, then hard coding it is ﬁne. But if you are faced with a more volatile situa- tion, it may be beneﬁcial to deﬁne the state tables externally.\n\n5. Sample values and results for use in unit testing. Most applications deﬁne these values inline in the testing harness, but you can get better ﬂexibility by moving the test data—and the deﬁnition of the acceptable results—out of the code itself.\n\n295\n\n296\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 29: fromIt’sJustaViewonpage164 Suppose you have an airline reservation system that includes the concept of a ﬂight:\n\npublic interface Flight {\n\n// Return false if flight full. public boolean addPassenger(Passenger p); public void addToWaitList(Passenger p); public int getFlightCapacity(); public int getNumPassengers();\n\n}\n\nIf you add a passenger to the wait list, they’ll be put on the ﬂight automatically when an opening becomes available.\n\nThere’s a massive reporting job that goes through looking for overbooked or full ﬂights to suggest when additional ﬂights might be scheduled. It works ﬁne, but it takes hours to run.\n\nWe’d like to have a little more ﬂexibility in processing wait-list passengers, and we’ve got to do something about that big report—it takes too long to run. Use the ideas from this section to redesign this interface.\n\nAnswer 29: We’ll take Flight and add some additional methods for main- taining two lists of listeners: one for wait-list notiﬁcation, and the other for full-ﬂight notiﬁcation.\n\npublic interface Passenger {\n\npublic void waitListAvailable();\n\n}\n\npublic interface Flight {\n\n... public void addWaitListListener(Passenger p); public void removeWaitListListener(Passenger p);\n\npublic void addFullListener(FullListener b); public void removeFullListener(FullListener b); ...\n\n}\n\npublic interface BigReport extends FullListener {\n\npublic void FlightFullAlert(Flight f);\n\n}\n\nIf we try to add a Passenger and fail because the ﬂight is full, we can, option- ally, put the Passenger on the wait list. When a spot opens up, waitList- Available will be called. This method can then choose to add the Passenger automatically, or have a service representative call the customer to ask if they are still interested, or whatever. We now have the ﬂexibility to perform different behaviors on a per-customer basis.\n\nNext, we want to avoid having the BigReport troll through tons of records look- ing for full ﬂights. By having BigReport registered as a listener on Flights,\n\neach individual Flight can report when it is full—or nearly full, if we want. Now users can get live, up-to-the-minute reports from BigReport instantly, without waiting hours for it to run as it did previously.\n\nExercise 30: fromBlackboardsonpage170 For each of the following applications, would a blackboard system be appropri- ate or not? Why?\n\n1. Image processing. You’d like to have a number of parallel processes grab chunks of an image, process them, and put the completed chunk back.\n\n2. Group calendaring. You’ve got people scattered across the globe, in dif- ferent time zones, and speaking different languages, trying to schedule a meeting.\n\n3. Network monitoring tool. The system gathers performance statistics and collects trouble reports. You’d like to implement some agents to use this information to look for trouble in the system.\n\nAnswer 30:\n\n1. Image processing. For simple scheduling of a workload among the paral- lel processes, a shared work queue may be more than adequate. You might want to consider a blackboard system if there is feedback involved—that is, if the results of one processed chunk affect other chunks, as in machine vision applications, or complex 3D image-warp transforms.\n\n2. Group calendaring. This might be a good ﬁt. You can post scheduled meetings and availability to the blackboard. You have entities functioning autonomously, feedback from decisions is important, and participants may come and go. You might want to consider partitioning this kind of blackboard system depending on who is searching: junior staff may care about only the im- mediate ofﬁce, human resources may want only English-speaking ofﬁces worldwide, and the CEO may want the whole enchilada.\n\nThere is also some ﬂexibility on data formats: we are free to ignore formats or languages we don’t understand. We have to understand different for- mats only for those ofﬁces that have meetings with each other, and we do not need to expose all participants to a full transitive closure of all possi- ble formats. This reduces coupling to where it is necessary, and does not constrain us artiﬁcially.\n\n3. Network monitoring tool. This is very similar to the mortgage/loan appli- cation program described on page 168. You’ve got trouble reports sent in by users and statistics reported automatically, all posting to the black- board. A human or software agent can analyze the blackboard to diagnose\n\n297\n\n298\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nnetwork failures: two errors on a line might just be cosmic rays, but 20,000 errors and you’ve got a hardware problem. Just as the detectives solve the murder mystery, you can have multiple entities analyzing and contributing ideas to solve the network problems.\n\nExercise 31: fromProgrammingbyCoincidenceonpage176 Can you identify some coincidences in the following C code fragment? Assume that this code is buried deep in a library routine.\n\nfprintf(stderr,\"Error, continue?\"); gets(buf);\n\nAnswer 31: There are several potential problems with this code. First, it assumes a tty environment. That may be ﬁne if the assumption is true, but what if this code is called from a GUI environment where neither stderr nor stdin is open?\n\nSecond, there is the problematic gets, which will write as many characters as it receives into the buffer passed in. Malicious users have used this failing to create buffer overrun security holes in many different systems. Never use gets().\n\nThird, the code assumes the user understands English.\n\nFinally, no one in their right mind would ever bury user interaction such as this in a library routine.\n\nExercise 32: fromProgrammingbyCoincidenceonpage176 This piece of C code might work some of the time, on some machines. Then again, it might not. What’s wrong?\n\n/* Truncate string to its last maxlen chars */\n\nvoid string_tail(char *string, int maxlen) {\n\nint len = strlen(string); if (len > maxlen) {\n\nstrcpy(string, string + (len - maxlen));\n\n}\n\n}\n\nAnswer 32: It might happen to work on some architectures, but only by coincidence.\n\nPOSIX strcpy isn’t guaranteed to work for overlapping strings.\n\nExercise 33: fromProgrammingbyCoincidenceonpage177 This code comes from a general-purpose Java tracing suite. The function writes a string to a log ﬁle. It passes its unit test, but fails when one of the Web developers uses it. What coincidence does it rely on?\n\npublic static void debug(String s) throws IOException { FileWriter fw = new FileWriter(\"debug.log\", true); fw.write(s); fw.flush(); fw.close();\n\n}\n\nAnswer 33: It won’t work in an applet context with security restrictions against writing to the local disk. Again, when you have a choice of running in GUI contexts or not, you may want to check dynamically to see what the current environment is like. In this case, you may want to put a log ﬁle some- where other than the local disk if it isn’t accessible.\n\nExercise 34: fromAlgorithmSpeedonpage183 We have coded a set of simple sort routines, which can be downloaded from our Web site (www.pragmaticprogrammer.com). Run them on various machines available to you. Do your ﬁgures follow the expected curves? What can you deduce about the relative speeds of your machines? What are the effects of various compiler optimization settings? Is the radix sort indeed linear?\n\nAnswer 34: Clearly, we can’t give any absolute answers to this exercise. How- ever, we can give you a couple of pointers.\n\nIf you ﬁnd that your results don’t follow a smooth curve, you might want to check to see if some other activity is using some of your processor’s power. You probably won’t get good ﬁgures on a multiuser system, and even if you are the only user you may ﬁnd that background processes periodically take cycles away from your programs. You might also want to check memory: if the application starts using swap space, performance will nose dive.\n\nIt is interesting to experiment with different compilers and different optimiza- tion settings. We found some that pretty startling speed-ups were possible by enabling aggressive optimization. We also found that on the wider RISC archi- tectures the manufacturer’s compilers often outperformed the more portable GCC. Presumably, the manufacturer is privy to the secrets of efﬁcient code generation on these machines.\n\n299\n\n300\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 35: fromAlgorithmSpeedonpage183 The routine below prints out the contents of a binary tree. Assuming the tree is balanced, roughly how much stack space will the routine use while print- ing a tree of 1,000,000 elements? (Assume that subroutine calls impose no signiﬁcant stack overhead.)\n\nvoid printTree(const Node *node) {\n\nchar buffer[1000];\n\nif (node) {\n\nprintTree(node->left);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nprintTree(node->right);\n\n}\n\n}\n\nAnswer 35: The printTree routine uses about 1,000 bytes of stack space for the buffer variable. It calls itself recursively to descend through the tree, and each nested call adds another 1,000 bytes to the stack. It also calls itself when it gets to the leaf nodes, but exits immediately when it discovers that the pointer passed in is NULL. If the depth of the tree is , the maximum stack requirement is therefore roughly\n\n.\n\nA balanced binary tree holds twice as many elements at each level. A tree of , elements. Our million-element , or holds depth , or 20 levels. tree will therefore need\n\nWe’d therefore expect our routine to use roughly 21,000 bytes of stack.\n\nExercise 36: fromAlgorithmSpeedonpage183 Can you see any way to reduce the stack requirements of the routine in Exer- cise 35 (apart from reducing the size of the buffer)?\n\nAnswer 36: A couple of optimizations come to mind. First, the printTree routine calls itself on leaf nodes, only to exit because there are no children. That call increases the maximum stack depth by about 1,000 bytes. We can also eliminate the tail recursion (the second recursive call), although this won’t affect the worst-case stack usage.\n\nwhile (node) {\n\nif (node->left) printTree(node->left);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nnode = node->right;\n\n}",
      "page_number": 317
    },
    {
      "number": 40,
      "title": "Segment 40 (pages 325-332)",
      "start_page": 325,
      "end_page": 332,
      "detection_method": "topic_boundary",
      "content": "The biggest gain, however, comes from allocating just a single buffer, shared by all invocations of printTree. Pass this buffer as a parameter to the recur- sive calls, and only 1,000 bytes will be allocated, regardless of the depth of recursion.\n\nvoid printTreePrivate(const Node *node, char *buffer) {\n\nif (node) {\n\nprintTreePrivate(node->left, buffer);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nprintTreePrivate(node->right, buffer);\n\n}\n\n}\n\nvoid newPrintTree(const Node *node) {\n\nchar buffer[1000];\n\nprintTreePrivate(node, buffer);\n\n}\n\nExercise 37: fromAlgorithmSpeedonpage183 On page 180, we claimed that a binary chop is\n\n. Can you prove this?\n\nAnswer 37: There are a couple of ways of getting there. One is to turn the problem on its head. If the array has just one element, we don’t iterate around the loop. Each additional iteration doubles the size of the array we can search. The general formula for the array size is therefore is the number of iterations. If you take logs to the base 2 of each side, you get\n\n, where\n\n, which by the deﬁnition of logs becomes\n\n.\n\nExercise 38: fromRefactoringonpage188 The following code has obviously been updated several times over the years, but the changes haven’t improved its structure. Refactor it.\n\nif (state == TEXAS) {\n\nrate = TX_RATE; amt = base * TX_RATE; calc = 2*basis(amt) + extra(amt)*1.05;\n\n} else if ((state == OHIO) || (state == MAINE)) { rate = (state == OHIO) ? OH_RATE : ME_RATE; amt = base * rate; calc = 2*basis(amt) + extra(amt)*1.05; if (state == OHIO)\n\npoints = 2;\n\n} else {\n\nrate = 1; amt = base; calc = 2*basis(amt) + extra(amt)*1.05;\n\n}\n\n301\n\n302\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nAnswer 38: We might suggest a fairly mild restructuring here: make sure that every test is performed just once, and make all the calculations common. If the expression 2*basis(...)*1.05 appears in other places in the program, we should probably make it a function. We haven’t bothered here.\n\nWe’ve added a rate_lookup array, initialized so that entries other than Texas, Ohio, and Maine have a value of 1. This approach makes it easy to add values for other states in the future. Depending on the expected usage pattern, we might want to make the points ﬁeld an array lookup as well.\n\nrate = rate_lookup[state];\n\namt = base * rate; calc = 2*basis(amt) + extra(amt)*1.05;\n\nif (state == OHIO)\n\npoints = 2;\n\nExercise 39: fromRefactoringonpage188 The following Java class needs to support a few more shapes. Refactor the class to prepare it for the additions.\n\npublic class Shape {\n\npublic static final int SQUARE public static final int CIRCLE public static final int RIGHT_TRIANGLE = 3;\n\n= 1; = 2;\n\nprivate int private double size;\n\nshapeType;\n\npublic Shape(int shapeType, double size) {\n\nthis.shapeType = shapeType; this.size\n\n= size;\n\n}\n\n// ... other methods ...\n\npublic double area() { switch (shapeType) { case SQUARE: case CIRCLE: case RIGHT_TRIANGLE: return size*size/2.0; } return 0;\n\nreturn size*size; return Math.PI*size*size/4.0;\n\n}\n\n}\n\nAnswer 39: When you see someone using enumerated types (or their equiv- alent in Java) to distinguish between variants of a type, you can often improve the code by subclassing:\n\npublic class Shape {\n\nprivate double size;\n\npublic Shape(double size) {\n\nthis.size = size;\n\n}\n\npublic double getSize() { return size; }\n\n}\n\npublic class Square extends Shape {\n\npublic Square(double size) {\n\nsuper(size);\n\n}\n\npublic double area() {\n\ndouble size = getSize(); return size*size;\n\n}\n\n}\n\npublic class Circle extends Shape {\n\npublic Circle(double size) {\n\nsuper(size);\n\n}\n\npublic double area() {\n\ndouble size = getSize(); return Math.PI*size*size/4.0;\n\n}\n\n} // etc...\n\nExercise 40: fromRefactoringonpage189 This Java code is part of a framework that will be used throughout your project. Refactor it to be more general and easier to extend in the future.\n\npublic class Window {\n\npublic Window(int width, int height) { ... }\n\npublic void setSize(int width, int height) { ... }\n\npublic boolean overlaps(Window w) { ... }\n\npublic int getArea() { ... }\n\n}\n\nAnswer 40: This case is interesting. At ﬁrst sight, it seems reasonable that a window should have a width and a height. However, consider the future. Let’s imagine that we want to support arbitrarily shaped windows (which will be difﬁcult if the Window class knows all about rectangles and their properties).\n\nWe’d suggest abstracting the shape of the window out of the Window class itself.\n\n303\n\n304\n\nAPPENDIX B ANSWERS TO EXERCISES\n\npublic abstract class Shape {\n\n// ...\n\npublic abstract boolean overlaps(Shape s); public abstract int getArea();\n\n}\n\npublic class Window {\n\nprivate Shape shape;\n\npublic Window(Shape shape) {\n\nthis.shape = shape; ...\n\n}\n\npublic void setShape(Shape shape) {\n\nthis.shape = shape; ...\n\n}\n\npublic boolean overlaps(Window w) { return shape.overlaps(w.shape);\n\n}\n\npublic int getArea() {\n\nreturn shape.getArea();\n\n}\n\n}\n\nNote that in this approach we’ve used delegation rather than subclassing: a window is not a “kind-of” shape—a window “has-a” shape. It uses a shape to do its job. You’ll often ﬁnd delegation useful when refactoring.\n\nWe could also have extended this example by introducing a Java interface that speciﬁed the methods a class must support to support the shape functions. This is a good idea. It means that when you extend the concept of a shape, the compiler will warn you about classes that you have affected. We recommend using interfaces this way when you delegate all the functions of some other class.\n\nExercise 41: fromCodeThat’sEasytoTestonpage197 Design a test jig for the blender interface described in the answer to Exercise 17 on page 289. Write a shell script that will perform a regression test for the blender. You need to test basic functionality, error and boundary conditions, and any contractual obligations. What restrictions are placed on changing the speed? Are they being honored?\n\nAnswer 41: First, we’ll add a main to act as a unit test driver. It will accept a very small, simple language as an argument: “E” to empty the blender, “F” to ﬁll it, digits 0-9 to set the speed, and so on.\n\npublic static void main(String args[]) {\n\n// Create the blender to test dbc_ex blender = new dbc_ex();\n\n// And test it according to the string on standard input try {\n\nint a; char c;\n\nwhile ((a = System.in.read()) != -1) {\n\nc = (char)a;\n\nif (Character.isWhitespace(c)) {\n\ncontinue;\n\n}\n\nif (Character.isDigit(c)) {\n\nblender.setSpeed(Character.digit(c, 10));\n\n} else {\n\nswitch (c) {\n\ncase ’F’: blender.fill(); break; case ’E’: blender.empty(); break;\n\ncase ’s’: System.out.println(\"SPEED: \" +\n\nblender.getSpeed());\n\nbreak;\n\ncase ’f’: System.out.println(\"FULL \" +\n\nblender.isFull());\n\nbreak;\n\ndefault: throw new RuntimeException( \"Unknown Test directive\");\n\n}\n\n}\n\n}\n\n} catch (java.io.IOException e) {\n\nSystem.err.println(\"Test jig failed: \" + e.getMessage());\n\n}\n\nSystem.err.println(\"Completed blending n\"); System.exit(0);\n\n}\n\nNext comes the shell script to drive the tests.\n\n305\n\n306\n\nAPPENDIX B ANSWERS TO EXERCISES\n\n#!/bin/sh\n\nCMD=\"java dbc.dbc_ex\" failcount=0\n\nexpect_okay() {\n\nif echo \"$*\" | $CMD #>/dev/null 2>&1 then : else\n\necho \"FAILED! $*\" failcount=‘expr $failcount + 1‘\n\nfi\n\n}\n\nexpect_fail() {\n\nif echo \"$*\" | $CMD >/dev/null 2>&1 then\n\necho \"FAILED! (Should have failed): $*\" failcount=‘expr $failcount + 1‘\n\nfi\n\n}\n\nreport() {\n\nif [ $failcount -gt 0 ] then\n\necho -e \" n n*** FAILED $failcount TESTS n\" exit 1 # In case we are part of something larger\n\nelse\n\nexit 0 # In case we are part of something larger\n\nfi\n\n}\n\n# # Start the tests # expect_okay F123456789876543210E # Should run thru # Fails, speed too high expect_fail F5 expect_fail 1 # Fails, empty expect_fail F10E1 # Fails, empty expect_fail F1238 # Fails, skips expect_okay FE expect_fail F1E expect_okay F10E # Should be ok report\n\n# Never turn on # Emptying while running\n\n# Report results\n\nThe tests check to see if illegal speed changes are detected, if you try to empty the blender while running, and so on. We put this in the makeﬁle so we can compile and run the regression test by simply typing\n\n% make % make test\n\nNote that we have the test exit with 0 or 1 so we can use this as part of a larger test as well.\n\nThere was nothing in the requirements that spoke of driving this component via a script, or even using a language. End users will never see it. But we have a powerful tool that we can use to test our code, quickly and exhaustively.\n\nExercise 42: fromTheRequirementsPitonpage211 Which of the following are probably genuine requirements? Restate those that are not to make them more useful (if possible).\n\n1. The response time must be less than 500 ms.\n\n2. Dialog boxes will have a gray background.\n\n3. The application will be organized as a number of front-end processes and\n\na back-end server.\n\n4. If a user enters non-numeric characters in a numeric ﬁeld, the system will\n\nbeep and not accept them.\n\n5. The application code and data must ﬁt within 256kB.\n\nAnswer 42:\n\n1. This statement sounds like a real requirement: there may be constraints\n\nplaced on the application by its environment.\n\n2. Even though this may be a corporate standard, it isn’t a requirement. It would be better stated as “The dialog background must be conﬁgurable by the end user. As shipped, the color will be gray.” Even better would be the broader statement “All visual elements of the application (colors, fonts, and languages) must be conﬁgurable by the end user.”\n\n3. This statement is not a requirement, it’s architecture. When faced with something like this, you have to dig deep to ﬁnd out what the user is thinking.\n\n4. The underlying requirement is probably something closer to “The system will prevent the user from making invalid entries in ﬁelds, and will warn the user when these entries are made.”\n\n5. This statement is probably a hard requirement.\n\nA solution to the Four Posts puzzle posed on page 213.\n\n307\n\nThis page intentionally left blank",
      "page_number": 325
    },
    {
      "number": 41,
      "title": "Segment 41 (pages 333-340)",
      "start_page": 333,
      "end_page": 340,
      "detection_method": "topic_boundary",
      "content": "Index A\n\nAccessor function, 31 ACM, see Association for Computing\n\nMachinery Active code generator, 104 Activity diagram, 150 Advanced C++ Programming Styles and\n\nIdioms, 265\n\nAdvanced Programming in the Unix Environment, 264\n\nAegis transaction-based conﬁguration management, 246, 271\n\nAgent, 76, 117, 297 Algorithm\n\nbinary chop, 180 choosing, 182 combinatoric, 180 divide-and-conquer, 180 estimating, 177, 178 linear, 177\n\nnotation, 178, 181\n\nquicksort, 180 runtime, 181 sublinear, 177 Allocations, nesting, 131 Analysis Patterns, 264 Anonymity, 258 AOP, see Aspect-Oriented Programming Architecture\n\ndeployment, 156 ﬂexibility, 46 prototyping, 55 temporal decoupling, 152 Art of Computer Programming, 183 Artiﬁcial intelligence, marauding, 26 Aspect-Oriented Programming (AOP),\n\n39, 273 Assertion, 113, 122, 175 side effects, 124\n\n309\n\nturning off, 123\n\nAssociation for Computing Machinery\n\n(ACM), 262\n\nCommunications of the ACM, 263 SIGPLAN, 263 Assumptions, testing, 175 “at” command, 231 Audience, 21\n\nneeds, 19 auto_ptr, 134 Automation, 230\n\napproval procedures, 235 build, 88, 233 compiling, 232 cron, 231 documentation, 251 scripts, 234 team, 229 testing, 29, 238 Web site generation, 235\n\nawk, 99\n\nB\n\nBackus-Naur Form (BNF), 59n Base class, 112 bash shell, 80, 82n Bean, see Enterprise Java Beans (EJB) Beck, Kent, 194, 258 Beowulf project, 268 “Big ” notation, 177 “Big picture”, 8 Binary chop, 97, 180 Binary format, 73\n\nproblems parsing, 75\n\nbison, 59, 269 BIST, see Built-In Self Test Blackboard system, 165\n\npartitioning, 168 workﬂow, 169\n\n310\n\nINDEX\n\nBlender example\n\ncontract for, 119, 289 regression test jig, 305 workﬂow, 151\n\nBNF, see Backus-Naur Form (BNF) Boiled frog, 8, 175, 225 Boundary condition, 173, 243 Brain, Marshall, 265 Branding, 226 Brant, John, 268 “Broken Window Theory”, 5 vs. stone soup, 9\n\nBrooks, Fred, 264 Browser, class, 187 Browser, refactoring, 187, 268 Bug, 90\n\nfailed contract as, 111 see also Debugging; Error\n\nBuild\n\nautomation, 88, 233 dependencies, 233 ﬁnal, 234 nightly, 231 refactoring, 187\n\nBuilt-In Self Test (BIST), 189 Business logic, 146 Business policy, 203\n\nC\n\nC language\n\nassertions, 122 DBC, 114 duplication, 29 error handling, 121 error messages, 115 macros, 121 Object Pascal interface, 101\n\nC++ language, 46\n\nassertions, 122 auto_ptr, 134 books, 265 DBC, 114 decoupling, 142 DOC++, 251, 269 duplication, 29 error messages, 115 exceptions, 132 unit tests, 193\n\nCaching, 31\n\nCall, routine, 115, 173 Cascading Style Sheets (CSS), 253 Cat\n\nblaming, 3 herding, 224 Schrödinger’s, 47\n\nCatalyzing change, 8 Cathedrals, xx Cetus links, 265 Change, catalyzing, 8 Christiansen, Tom, 81 Class\n\nassertions, 113 base, 112 coupling, 139, 142 coupling ratios, 242 encapsulating resource, 132 invariant, 110, 113 number of states, 245 resource allocation, 132 subclass, 112 wrapper, 132, 133, 135, 141\n\nClass browser, 187 ClearCase, 271 Cockburn, Alistair, xxiii, 205, 264, 272 Code generator, 28, 102\n\nactive, 104 makeﬁles, 232 parsers, 105 passive, 103 Code proﬁler, 182 Code reviews, 33, 236 Coding\n\nalgorithm speed, 177 comments, 29, 249 coupled, 130 coverage analysis, 245 database schema, 104 defensive, 107 and documentation, 29, 248 estimating, 68 exceptions, 125 implementation, 173 iterative, 69 “lazy”, 111 metrics, 242 modules, 138 multiple representations, 28 orthogonality, 34, 36, 40\n\nownership, 258 prototypes, 55 server code, 196 “shy”, 40, 138 speciﬁcations, 219 tracer bullets, 49–51 unit testing, 190, 192 see also Coupled code; Decoupled code; Metadata; Source code control system (SCCS)\n\nCohesion, 35 COM, see Component Object Model Combinatorial explosion, 140, 167 Combinatoric algorithm, 180 Command shell, 77 bash, 80 Cygwin, 80 vs. GUI, 78 UWIN, 81 Windows, 80 Comment, 29, 249\n\navoiding duplication, 29 DBC, 113 parameters, 250 types of, 249 unnecessary, 250 see also Documentation\n\nCommon Object Request Broker\n\n(CORBA), 29, 39, 46\n\nEvent Service, 160\n\nCommunicating, 18\n\naudience, 19, 21 duplication, 32 e-mail, 22 and formal methods, 221 presentation, 20 style, 20 teams, 225 users, 256 writing, 18\n\nCommunications of the ACM, 263 Comp.object FAQ, 272 Compiling, 232\n\ncompilers, 267 DBC, 113 warnings and debugging, 92\n\nComponent Object Model (COM), 55 Component-based systems, see Modular system\n\nINDEX\n\n311\n\nConcurrency, 150\n\ndesign, 154 interfaces, 155 and Programming by Coincidence,\n\n154\n\nrequirements analysis of, 150 workﬂow, 150\n\nConcurrent Version System (CVS), 271 Conﬁguration\n\ncooperative, 148 dynamic, 144 metadata, 147\n\nConﬁguration management, 86, 271 Constantine, Larry L., 35 Constraint management, 213 Constructor, 132\n\ninitialization, 155 Contact, authors’ e-mail, xxiii Context, use instead of globals, 40 Contract, 109, 174\n\nsee also Design by contract (DBC)\n\nController (MVC), 162 Coplien, Jim, 265 CORBA, see Common Object Request\n\nBroker\n\nCoupled code, 130\n\ncoupling ratios, 242 minimizing, 138, 158 performance, 142 temporal coupling, 150 see also Decoupled code\n\nCoverage analysis, 245 Cox, Brad J., 189n Crash, 120 Critical thinking, 16 cron, 231 CSS, see Cascading Style Sheets CVS, see Concurrent Version System Cygwin, 80, 270\n\nD\n\nData\n\nblackboard system, 169 caching, 31 dictionary, 144 dynamic data structures, 135 global, 40 language, 60 normalizing, 30\n\n312\n\nINDEX\n\nreadable vs. understandable, 75 test, 100, 243 views, 160 visualizing, 93 see also Metadata\n\nData Display Debugger (DDD), 93, 268 Database\n\nactive code generator, 104 schema, 105f, 141, 144 schema maintenance, 100\n\nDBC, see Design by contract DDD, see Data Display Debugger Deadline, 6, 246 Deadlock, 131 Debugging, 90\n\nassertions, 123 binary search, 97 bug location, 96 bug reproduction, 93 checklist, 98 compiler warnings and, 92 corrupt variables, 95 “Heisenbug”, 124 rubber ducking, 95 and source code branching, 87 surprise bug, 97 and testing, 92, 195 time bomb, 192 tracing, 94 view, 164 visualizing data, 93\n\nDecision making, 46 Decoupled code, 38, 40 architecture, 152 blackboard system, 166 Law of Demeter, 140 metadata, 145 minimizing coupling, 138 modular testing, 244 physical decoupling, 142 temporal coupling, 150 workﬂow, 150 see also Coupled code\n\nDefensive coding, 107 Delegation, 304 Delphi, 55\n\nsee also Object Pascal\n\nDemeter project, 274 Demeter, Law of, 140\n\nDependency, reducing, see Modular system; Orthogonality\n\nDeployment, 156 Deployment descriptor, 148 Design\n\naccessor functions, 31 concurrency, 154 context, 174 deployment, 156 design/methodology testing, 242 metadata, 145 orthogonality, 34, 37 physical, 142 refactoring, 186 using services, 154\n\nDesign by contract (DBC), 109, 155\n\nand agents, 117 assertions, 113 class invariant, 110 as comments, 113 dynamic contracts, 117 iContract, 268 language support, 114 list insertion example, 110 pre- and postcondition, 110, 113,\n\n114\n\npredicates, 110 unit testing, 190\n\nDesign Patterns, 264\n\nobserver, 158 singleton, 41 strategy, 41\n\nDestructor, 132 Detectives, 165 Development tree, 87 Development, iterative, 69 Divide-and-conquer algorithm, 180 DOC++ documentation generator, 251,\n\n269\n\nDocBook, 254 Documentation\n\nautomatic updating, 251 and code, 29, 248 comments, 29, 113, 249, 251 executable, 251 formats, 253 HTML, 101 hypertext, 210 internal/external, 248\n\ninvariant, 117 mark-up languages, 254 orthogonality, 42 outline, 18 requirements, 204 technical writers, 252 word processors, 252, 254 writing speciﬁcations, 218 see also Comment; Web\n\ndocumentation\n\nDodo, 148 Domain, problem, 58, 66 Don’t repeat yourself, see DRY\n\nprinciple\n\nDownloading source code, see Example\n\ncode\n\nDr. Dobbs Journal, 263 DRY principle, 27, 29, 42 see also Duplication Duck, rubber, see Rubber duck Dumpty, Humpty, xxii, 165 Duplication, 26\n\ncode generators avoid, 28 and code reviews, 33 design errors, 30 documentation and code, 29 DRY principle, 27, 29 interdeveloper, 32 in languages, 29 multiple representations, 28 teams, 226 under time pressure, 32 types of, 27\n\nDynamic conﬁguration, 144 Dynamic data structure, 135 Dynamics of Software Development, 264\n\nE\n\nE-mail, 22\n\naddress for feedback, xxiii\n\nEditor, 82\n\nauto-indenting, 85 cursor movement, 84 features, 83 generating code, 103 how many to learn, 82 template, 84 types of, 266 Windows notepad, 84\n\nINDEX\n\nEffective C++, 265 Eiffel, 109, 114, 267 EJB, see Enterprise Java Beans elvis editor, 267 Emacs editor, 84, 266\n\nViper vi emulator, 267 Embedded mini-language, 62, 145 Embellishment, 11 Encapsulation, object, 127, 158 Eno, Brian, 205 Enterprise Java Beans (EJB), 39, 147 Entropy, 4 Error\n\nDBC messages, 115 design, 30 domain-speciﬁc, 59 early crash, 120 log messages, 196 orthogonality, 41 testing, 240, 247 see also Exception\n\nError handler, 127 Estimating, 64\n\naccuracy, 64 algorithms, 177, 178 iterative, 69 models, 66 problem domain, 66 project schedules, 68 records, 68 testing, 182 Eton College, xxi Event, 157 Event channel, 160 Example code\n\nadd logging, 40 airline reservations, 164, 296 assert macro, 122 auto_ptr example, 134 bad resource balancing, 129, 130 downloading, xxiii exception error handling, 125 good resource balancing, 131 JavaDoc example, 250 method chaining, 139 normalized class, 31 open password ﬁle, 126 open user ﬁle, 127\n\n313\n\n314\n\nINDEX\n\nresources and exceptions, 132,\n\n133\n\nside effect, 124 spaghetti error handling, 125 square root, 190 string parsing with\n\nStringTokenizer, 156\n\nstring parsing with strtok, 155 unnormalized class, 30\n\nExample code by name\n\nAOP, 40 Misc.java, 156 assert, 122 bad_balance.c, 129, 130 balance.cc, 134 balance.c, 131–133 class Line, 30, 31 exception, 125 findPeak, 250 interface Flight, 164, 296 misc.c, 155 openpasswd.java, 126 openuserfile.java, 127 plotDate, 139 side_effect, 124 spaghetti, 125 sqrt, 190 Exception, 121\n\neffects of, 127 and error handlers, 127 missing ﬁles, 126 resource balancing, 132 when to use, 125\n\nExcuses, 3 Executable document, 251 expect, 269 Expert, see Guru Expiring asset, 12 eXtensible Style Language (XSL), 253 Extinction, 148 eXtreme Programming, 238n, 258, 272\n\nF\n\nFeature creep, 10 Feedback, e-mail address, xxiii File\n\nexception, 126 header, 29 implementation, 29\n\nlog, 196 makeﬁle, 232 source, 103 Final build, 234 Fish, dangers of, 34 Flexibility, 46 Formal methods, 220, 221 Four Posts Puzzle, 213 Fowler, Martin, xxiii, 186, 273 Free Software Foundation, see GNU\n\nProject\n\nFrog, boiled, see Boiled frog Function\n\naccessor, 31 Law of Demeter for similar, 41\n\ns, 140\n\nG\n\nGamma, Erich, 194 Garbage collection, 134 Gardening metaphor, 184 Gehrke, Peter, xxiv Glass, Robert, 221, 236 Global variables, 40, 130, 154 Glossary, project, 210 GNU Project, 274\n\nC/C++ compiler, 267 General Public License (GPL), 80 GNU Image Manipulation Program\n\n(GIMP), 274 SmallEiffel, 267\n\n“Good-enough software”, see Software,\n\nquality\n\nGordian knot, 212 Goto, 127 GUI system\n\nvs. command shell, 78 interface, 78 testing, 244\n\nGuru, 17, 198\n\nH\n\nHash, secure, 74 Header ﬁle, 29 “Heisenbug”, 124, 289 Helicopter, 34n Hopper, Grace, 8n, 90 “Hot-key” sequence, 196\n\nHTTP Web server, 196 Human factors, 241 Humpty Dumpty, xxii, 165 Hungarian notation, 249 Hungry consumer model, 153 Hypertext document, 210\n\nI\n\niContract, 110, 114, 268 IDE, see Integrated Development\n\nEnvironment IEEE Computer Society, 262 IEEE Computer, 262 IEEE Software, 263 Imperative language, 60 Implementation\n\naccidents, 173 coding, 173 speciﬁcations, 219 Imposed duplication, 28 Inadvertent duplication, 30 Indentation, automatic, 85 Independence, see Orthogonality Infrastructure, 37 Inheritance, 111\n\nassertions, 113 fan-in/fan-out, 242\n\nInner tennis, 215 Inspection, code, see Code reviews Insure++, 136 Integrated circuit, 189n Integrated Development Environment\n\n(IDE), 72, 232\n\nIntegration platform, 50 Integration testing, 239 Interface\n\nblackboard system, 168 C/Object Pascal, 101 concurrency, 155 error handler, 128 GUI, 78 prototyping, 55 user, 203\n\nInvariant, 110, 113, 155\n\nloop, 116 semantic, 116, 135\n\nISO9660 format, 233n Iterative development, 69\n\nINDEX\n\nJ\n\nJacobson, Ivar, 204 Jargon, xxii, 210 Jargon ﬁle, 273 Java, 46, 267\n\ncode generation, 232 DBC, 114 Enterprise Java Beans, 39, 147 error messages, 115 exceptions, 121 iContract, 110, 114, 268 javaCC, 59, 269 JavaDoc, 248, 251 JavaSpaces, 166, 273 JUnit, 195 multithreaded programming, 154 property access, 100 property ﬁles, 145 resource balancing, 134 RMI, 128 string parser, 156 tree view, 161 unit tests, 193 and Windows shells, 81\n\nJavaDoc, see Java\n\nK\n\nK Desktop Environment, 273 Kaizen, xxi, 14\n\nsee also Knowledge portfolio\n\nKernighan, Brian, 99 Keybinding, 82 Kirk, James T., 26 Knowledge\n\nproducers and consumers, 166\n\nKnowledge portfolio, 12 building, 13 critical thinking, 16 learning and reading, 14 researching, 15 Knuth, Donald, 183, 248 Korn, David, 81 Kramer, Reto, xxiv Kruchten, Phillipe, 227n\n\nL\n\nLakos, John, xxiv, 9, 142, 265 Lame excuses, 3\n\n315\n\n316\n\nINDEX\n\nLanguage, programming\n\nconversions, 103, 105 DBC, 114 domain, 57 duplication in, 29 learning, 14 prototypes, 55 scripting, 55, 145 speciﬁcation, 58, 62 text manipulation, 99 see also Mini-language\n\nLarge-Scale C++ Software Design, 142,\n\n265 LATEX system, 103 Law of Demeter, 140 Lawns, care of, xxi Layered design, 37 Layered system, see Modular system “lazy” code, 111 Lex and Yacc, 59 Librarian, see Project librarian Library code, 39 Linda model, 167 Linear algorithms, 177 Linux, 15, 254, 265 Liskov Substitution Principle, 111 Listening, 21 Literate programming, 248 Logging, 39, 196\n\nsee also Tracing\n\nLookup table, 104 Loop\n\nnested, 180 simple, 180\n\nLoop invariant, 116\n\nM\n\nMacro, 78, 86\n\nassertions, 122 documentation, 252 error handling, 121\n\nMaintenance, 26\n\nimperative languages, 61\n\nMakeﬁle, 232\n\nrecursive, 233\n\nManaging expectations, 256 Mark-up language, 254 Martin, Robert C., 273\n\nMcCabe Cyclomatic Complexity Metric,\n\n242\n\nMember variables, see Accessor\n\nfunctions Memory allocation, 135 Metadata, 144, 203\n\nbusiness logic, 146 conﬁguration, 147 controlling transactions, 39 decoupled code, 145 and formal methods, 221 in plain text, 74\n\nMetric, 242 Meyer, Bertrand, 31n, 109, 184, 264 Meyer, Scott, 265 Microsoft Visual C++, 198 Microsoft Windows, 46 Mini-language, 59\n\ndata language, 60 embedded, 62 imperative, 60 parsing, 62 stand-alone, 62\n\nMixing board, 205 MKS Source Integrity, 271 Model, 160\n\ncalculations, 67 components and parameters, 66 and estimating, 66 executable documents, 251 view, 162\n\nModel-view-controller (MVC), 38, 160 Modular system, 37 coding, 138 prototyping, 55 resource allocation, 135 reversibility, 45 testing, 41, 190, 244\n\nMore Effective C++, 265 Mozilla, 273 Multithreaded programming, 154 MVC, see Model-view-controller The Mythical Man Month, 264\n\nN\n\nName, variable, 249 Nana, 114, 268 Nest allocations, 131 Nested loop, 180",
      "page_number": 333
    },
    {
      "number": 42,
      "title": "Segment 42 (pages 341-348)",
      "start_page": 341,
      "end_page": 348,
      "detection_method": "topic_boundary",
      "content": "Netscape, 145, 273 Newsgroup, 15, 17, 33 Nonorthogonal system, 34 Normalize, 30 Novobilski, Andrew J., 189n\n\nO\n\nnotation, 178, 181\n\nObject\n\ncoupling, 140n destruction, 133, 134 persistence, 39 publish/subscribe protocol, 158 singleton, 41 valid/invalid state, 154 viewer, 163\n\nObject Management Group (OMG), 270 Object Pascal, 29\n\nC interface, 101\n\nObject-Oriented Programming, 189n Object-Oriented Software Construction,\n\n264 Obsolescence, 74 OLTP, see On-Line Transaction\n\nProcessing system\n\nOMG, see Object Management Group On-Line Transaction Processing system\n\n(OLTP), 152\n\nOptions, providing, 3 Ordering, see Workﬂow Orthogonality, 34\n\ncoding, 34, 36, 40 design, 37 documentation, 42 DRY principle, 42 nonorthogonal system, 34 productivity, 35 project teams, 36, 227 testing, 41 toolkits & libraries, 39 see also Modular system\n\nOver embellishment, 11\n\nP\n\nPain management, 185 paint() method, 173 Painting, 11 Papua New Guinea, 16\n\nINDEX\n\nParallel programming, 150 Parrots, killer, see Branding Parsing, 59\n\ncode generators, 105 log messages, 196 mini-language, 62 strings, 155 Partitioning, 168 Pascal, 29 Passive code generator, 103 Performance testing, 241 Perl, 55, 62, 99\n\nC/Object Pascal interface, 101 database schema generation, 100 home page, 267 Java property access, 100 power tools, 270 test data generation, 100 testing, 197 and typesetting, 100 Unix utilities in, 81 web documentation, 101\n\nPerl Journal, 263 Persistence, 39, 45 Petzold, Charles, 265 Pike, Rob, 99 Pilot\n\nlanding, handling, etc., 217 who ate ﬁsh, 34\n\nPlain text, 73\n\nvs. binary format, 73 drawbacks, 74 executable documents, 251 leverage, 75 obsolescence, 74 and easier testing, 76 Unix, 76 Polymorphism, 111 Post-it note, 53, 55 Powerbuilder, 55 The Practice of Programming, 99 Pragmatic programmer\n\ncharacteristics, xviii e-mail address, xxiii Web site, xxiii\n\nPre- and postcondition, 110, 113, 114 Predicate logic, 110 Preprocessor, 114 Presentation, 20\n\n317\n\n318\n\nINDEX\n\nProblem domain, 58, 66 metadata, 146\n\nProblem solving, 213\n\nchecklist for, 214\n\nProductivity, 10, 35 Programming by coincidence, 173 Programming staff\n\nexpense of, 237 Programming Windows, 265 Project\n\nglossary, 210 “heads”, 228 saboteur, 244 schedules, 68 see also Automation;\n\nTeam, project\n\nProject librarian, 33, 226 Prototyping, 53, 216 architecture, 55 disposable code, 56 kinds of, 54 and programming languages, 55 and tracer code, 51 using, 54\n\nPublish/subscribe protocol, 158 Pugh, Greg, 95n Purify, 136 PVCS Conﬁguration Management, 271 Python, 55, 99, 267\n\nQ\n\nQuality\n\ncontrol, 9 requirements, 11 teams, 225\n\nQuarry worker’s creed, xx Quicksort algorithm, 180\n\nR\n\nRational Uniﬁed Process, 227n Raymond, Eric S., 273 RCS, see Revision Control System Real-world data, 243 Refactoring, 5, 185\n\nautomatic, 187 and design, 186 testing, 187 time constraints, 185\n\nRefactoring browser, 187, 268 Reﬁnement, excessive, 11 Regression, 76, 197, 232, 242 Relationship\n\nhas-a, 304 kind-of, 111, 304\n\nReleases, and SCCS, 87 Remote Method Invocation (RMI), 128\n\nexception handling, 39\n\nRemote procedure call (RPC), 29, 39 Repository, 87 Requirement, 11, 202\n\nbusiness problem, 203 changing, 26 creep, 209 DBC, 110 distribution, 211 documenting, 204 in domain language, 58 expressing as invariant, 116 formal methods, 220 glossary, 210 over specifying, 208 and policy, 203 usability testing, 241 user interface, 203\n\nResearching, 15 Resource balancing, 129 C++ exceptions, 132 checking, 135 coupled code, 130 dynamic data structures, 135 encapsulation in class, 132 Java, 134 nest allocations, 131\n\nResponse set, 141, 242 Responsibility, 2, 250, 258 Reuse, 33, 36 Reversibility, 44\n\nﬂexible architecture, 46\n\nRevision Control System (RCS), 250,\n\n271\n\nRisk management, 13 orthogonality, 36\n\nRMI, see Remote Method Invocation Rock-n-roll, 47 RPC, see Remote procedure call Rubber ducking, 3, 95 Rules engine, 169\n\nS\n\nSaboteur, 244 Samba, 272 Sample programs, see Example code Sather, 114, 268 SCCS, see Source code control system Schedule, project, 68 Schrödinger, Erwin (and his cat), 47 Scope, requirement, 209 Screen scraping, 61 Scripting language, 55, 145 Secure hash, 74 sed, 99 Sedgewick, Robert, 183 Self-contained components, see Orthogonality; Cohesion\n\nSemantic invariant, 116, 135 sendmail program, 60 Sequence diagram, 158 Server code, 196 Services, design using, 154 Shell, command, 77 vs. GUI, 78 see also Command shell\n\n“Shy code”, 40 Side effect, 124 SIGPLAN, 263 Simple loop, 180 Singleton object, 41 Slashdot, 265 SmallEiffel, 267 Smalltalk, 46, 186, 187, 268, 272 Software\n\ndevelopment technologies, 221 quality, 9 requirements, 11\n\nSoftware bus, 159 “Software Construction”, 184 Software Development Magazine, 263 Software IC, 189n “Software rot”, 4 Solaris, 76 Source code\n\ncat eating, 3 documentation, see Comments downloading, see Example code duplication in, 29 generating, 103 reviews, see Code reviews\n\nINDEX\n\nSource code control system (SCCS), 86\n\nAegis, 246 builds using, 88 CVS, 271 development tree, 87 plain text and, 76 RCS, 250, 271 repository, 87 tools, 271 Specialization, 221 Speciﬁcation, 58\n\nimplementation, 219 language, 62 as security blanket, 219 writing, 218\n\nSpy cells, 138 Squeak, 268 Stand-alone mini-language, 62 “Start-up fatigue”, 7 Starting a project\n\nproblem solving, 212 prototyping, 216 speciﬁcations, 217 see also Requirement\n\nStevens, W. Richard, 264 Stone soup, 7\n\nvs. broken windows, 9\n\nStone-cutter’s creed, xx String parser, 155 Stroop effect, 249 strtok routine, 155 Structured walkthroughs, see Code\n\nreviews\n\nStyle sheet, 20, 254 Style, communication, 20 Subclass, 112 Sublinear algorithm, 177 Supplier, see Vendor Surviving Object-Oriented Projects: A Manager’s Guide, 264\n\nSWIG, 55, 270 Synchronization bar, 151 Syntax highlighting, 84 Synthetic data, 243\n\nT\n\nT Spaces, 166, 269 TAM, see Test Access Mechanism Tcl, 55, 99, 269\n\n319\n\n320\n\nINDEX\n\nTeam, project, 36, 224 automation, 229 avoiding duplication, 32 code review, 236 communication, 225 duplication, 226 functionality, 227 organization, 227 pragmatism in, xx quality, 225 tool builders, 229\n\nTechnical writer, 252 Template, use case, 205 Temporal coupling, 150 Test Access Mechanism (TAM), 189 Test harness, 194 Testing\n\nautomated, 238\n\nfrom speciﬁcation, 29\n\nbug ﬁxing, 247 coverage analysis, 245 and culture, 197 debugging, 92, 196 design/methodology, 242 effectiveness, 244 estimates, 182 frequency, 246 GUI systems, 244 integration, 239 orthogonality, 36, 41 performance, 241 role of plain text, 76 refactoring, 187 regression, 76, 197, 232, 242 resource exhaustion, 240 saboteur, 244 test data, 100, 243 usability, 241 validation and veriﬁcation, 239 see also Unit testing Text manipulation language, 99 TOM programming language, 268 Toolkits, 39 Tools, adaptable, 205 Tracer code, 49\n\nadvantages of, 50 and prototyping, 51\n\nTracing, 94\n\nsee also Logging\n\nTrade paper, 263 Trade-offs, 249 Transactions, EJB, 39 Tree widget, 161 troff system, 103 Tuple space, 167\n\nU\n\nUML, see Uniﬁed modeling language\n\n(UML) UNDO key, 86 Uniﬁed modeling language (UML) activity diagram, 150 sequence diagram, 158 use case diagram, 208\n\nUniform Access Principle, 31n Unit testing, 190\n\nDBC, 190 modules, 239 test harness, 194 test window, 196 writing tests, 193\n\nUnix, 46, 76\n\nApplication Default ﬁles, 145 books, 264 Cygwin, 270 DOS tools, 270 Samba, 272 UWIN, 81, 270\n\nUnix Network Programming, 264 Usability testing, 241 Use case, 204\n\ndiagrams, 206\n\nUsenet newsgroup, 15, 17, 33 User\n\nexpectations, 256 groups, 18 interface, 203 requirements, 10\n\nUWIN, 81, 270\n\nV\n\nVariable\n\ncorrupt, 95 global, 130, 154 name, 249\n\nVendor\n\nlibraries, 39 reducing reliance on, 36, 39, 46\n\nvi editor, 266 View\n\ndebugging, 164 executable documents, 251 Java tree view, 161 model-view-controller, 160, 162 model-viewer network, 162\n\nvim editor, 266 Visual Basic, 55 Visual C++, 198 Visual SourceSafe, 271 VisualWorks, 268\n\nW\n\nWalkthoughs, see Code reviews Warnings, compilation, 92 Web documentation, 101, 210, 253 automatic generation, 235 news and information, 265\n\nWeb server, 196 Web site, pragmatic programmer, xxiii What You See Is What You Get (WYSIWYG), 78\n\nWikiWikiWeb, 265 Win32 System Services, 265 Windows, 46\n\n“at” command, 231 books, 265 Cygwin, 80 metadata, 145 notepad, 84\n\nINDEX\n\nUnix utilities, 80, 81 UWIN, 81\n\nWinZip, 272 WISDOM acrostic, 20 Wizard, 198 Word processor, 252, 254 Workﬂow, 150\n\nblackboard system, 169 content-driven, 234 Wrapper, 132, 133, 135, 141 Writing, 18\n\nsee also Documentation\n\nwww.pragmaticprogrammer.com, xxiii WYSIWYG, see What You See Is What\n\nYou Get\n\nX\n\nXEmacs editor, 266 Xerox Parc, 39 XSL, see eXtensible Style Language xUnit, 194, 269\n\nY\n\nyacc, 59 Yourdon, Edward, 10, 35 Y2K problem, 32, 208\n\nZ\n\nZ shell, 272\n\n321\n\n(cid:10)(cid:12)(cid:9)(cid:13)(cid:14)(cid:11)(cid:3)(cid:5)(cid:2)(cid:7)(cid:13)(cid:11)(cid:1) THE TRUSTED TECHNOLOGY LEARNING SOURCE\n\nInformIT is a brand of Pearson and the online presence for the world’s leading technology publishers. It’s your source for reliable and qualified content and knowledge, providing access to the top brands, authors, and contributors from the tech community.\n\n(cid:4)(cid:8)(cid:6)(cid:14)(cid:12)(cid:3)(cid:5)(cid:1)at(cid:1)(cid:3)(cid:12)(cid:9)(cid:13)(cid:14)(cid:11)(cid:3)(cid:5)\n\nLooking for a book, eBook, or training video on a new technology? Seeking timely and relevant information and tutorials? Looking for expert opinions, advice, and tips? InformIT has the solution.\n\n\n\nLearn about new releases and special promotions by subscribing to a wide variety of newsletters. Visit informit.com/newsletters.\n\nAccess FREE podcasts from experts at informit.com/podcasts.\n\nRead the latest author articles and sample chapters at\n\ninformit.com/articles.\n\n\n\nAccess thousands of books and videos in the Safari Books Online digital library at safari.informit.com.\n\nGet tips from expert blogs at informit.com/blogs.\n\nVisit informit.com/learn to discover all the ways you can access the hottest technology content.\n\nAre You Part of the(cid:1)(cid:3)(cid:5) Crowd?\n\nConnect with Pearson authors and editors via RSS feeds, Facebook, Twitter, YouTube, and more! Visit informit.com/socialconnect.\n\n(cid:10)(cid:12)(cid:9)(cid:13)(cid:14)(cid:11)(cid:3)(cid:5)(cid:2)(cid:7)(cid:13)(cid:11)(cid:1)THE TRUSTED TECHNOLOGY LEARNING SOURCE\n\nTHIS PRODUCT\n\ninformit.com/register\n\nRegister the Addison-Wesley, Exam Cram, Prentice Hall, Que, and Sams products you own to unlock great beneﬁ ts.\n\nTo begin the registration process, simply go to informit.com/register to sign in or create an account. You will then be prompted to enter the 10- or 13-digit ISBN that appears on the back cover of your product.\n\nRegistering your products can unlock the following beneﬁ ts:\n\nAccess to supplemental content,\n\nincluding bonus chapters, source code, or project ﬁ les. • A coupon to be used on your\n\nnext purchase.\n\nRegistration beneﬁ ts vary by product. Beneﬁ ts will be listed on your Account page under Registered Products.\n\nAbout InformIT — THE TRUSTED TECHNOLOGY LEARNING SOURCE\n\nINFORMIT IS HOME TO THE LEADING TECHNOLOGY PUBLISHING IMPRINTS Addison-Wesley Professional, Cisco Press, Exam Cram, IBM Press, Prentice Hall\n\nProfessional, Que, and Sams. Here you will gain access to quality and trusted content and\n\nresources from the authors, creators, innovators, and leaders of technology. Whether you’re\n\nlooking for a book on a new technology, a helpful article, timely newsletters, or access to\n\nthe Safari Books Online digital library, InformIT has a solution for you.\n\n(cid:7)(cid:9)(cid:6)(cid:10)(cid:11)(cid:8)(cid:3)(cid:4)(cid:2)(cid:5)(cid:10)(cid:8)(cid:1)\n\nAddison-Wesley | Cisco Press | Exam Cram IBM Press | Que | Prentice Hall | Sams\n\nTHE TRUSTED TECHNOLOGY LEARNING SOURCE\n\nSAFARI BOOKS ONLINE\n\nThe Pragmatic Programmer\n\nThis card summarizes the tips and checklists found in The Pragmatic Programmer.\n\nFor more information about THE PRAGMATIC PROGRAMMERS LLC, source code for the examples, up-to-date pointers to Web resources, and an online bibliography, visit us at www.pragmaticprogrammer.com. Quick Reference Guide\n\nTIPS 1 TO 22\n\n1. Care About Your Craft ........................... xix Why spend your life developing software unless you care about doing it well?\n\n12. Make It Easy to Reuse .......................... 33 If it’s easy to reuse, people will. Create an environ- ment that supports reuse.\n\n2. Think! About Your Work.........................xix Turn off the autopilot and take control. Constantly critique and appraise your work.\n\n13. Eliminate Effects Between Unrelated Things .... 35 Design components that are self-contained, inde- pendent, and have a single, well-deﬁned purpose.\n\n3. Provide Options, Don’t Make Lame Excuses........3 Instead of excuses, provide options. Don’t say it can’t be done; explain what can be done.\n\n14. There Are No Final Decisions ................... 46 No decision is cast in stone. Instead, consider each as being written in the sand at the beach, and plan for change.\n\n4. Don’t Live with Broken Windows...................5 Fix bad designs, wrong decisions, and poor code when you see them.\n\n15. Use Tracer Bullets to Find the Target ........... 49 Tracer bullets let you home in on your target by trying things and seeing how close they land.\n\n5. Be a Catalyst for Change...........................8 You can’t force change on people. Instead, show them how the future might be and help them par- ticipate in creating it.\n\n16. Prototype to Learn..............................54 Prototyping is a learning experience. Its value lies not in the code you produce, but in the lessons you learn.\n\n6. Remember the Big Picture.........................8 Don’t get so engrossed in the details that you forget to check what’s happening around you.\n\n17. Program Close to the Problem Domain .......... 58 Design and code in your user’s language.\n\n7. Make Quality a Requirements Issue .............. 11 Involve your users in determining the project’s real quality requirements.\n\n18. Estimate to Avoid Surprises .................... 64 Estimate before you start. You’ll spot potential problems up front.\n\n8. Invest Regularly in Your Knowledge Portfolio.....14 Make learning a habit.\n\n19. Iterate the Schedule with the Code..............69 Use experience you gain as you implement to reﬁne the project time scales.\n\n9. Critically Analyze What You Read and Hear ...... 16 Don’t be swayed by vendors, media hype, or dogma. Analyze information in terms of you and your project.\n\n20. Keep Knowledge in Plain Text...................74 Plain text won’t become obsolete. It helps leverage your work and simpliﬁes debugging and testing.\n\n10. It’s Both What You Say and the Way You Say It..21 There’s no point in having great ideas if you don’t communicate them effectively.\n\n21. Use the Power of Command Shells .............. 80 Use the shell when graphical user interfaces don’t cut it.\n\n11. DRY—Don’t Repeat Yourself....................27 Every piece of knowledge must have a single, un- ambiguous, authoritative representation within a system.\n\n22. Use a Single Editor Well ........................ 82 The editor should be an extension of your hand; make sure your editor is conﬁgurable, extensible, and programmable.\n\n1",
      "page_number": 341
    },
    {
      "number": 43,
      "title": "Segment 43 (pages 349-352)",
      "start_page": 349,
      "end_page": 352,
      "detection_method": "topic_boundary",
      "content": "TIPS 23 TO 46\n\n23. Always Use Source Code Control ............... 88 Source code control is a time machine for your work—you can go back.\n\n24. Fix the Problem, Not the Blame ................. 91 It doesn’t really matter whether the bug is your fault or someone else’s—it is still your problem, and it still needs to be ﬁxed.\n\n25. Don’t Panic When Debugging ................... 91 Take a deep breath and THINK! about what could be causing the bug.\n\n26. “select” Isn’t Broken............................96 It is rare to ﬁnd a bug in the OS or the compiler, or even a third-party product or library. The bug is most likely in the application.\n\n27. Don’t Assume It—Prove It ....................... 97 Prove your assumptions in the actual environ- ment—with real data and boundary conditions.\n\n28. Learn a Text Manipulation Language ..........100 You spend a large part of each day working with text. Why not have the computer do some of it for you?\n\n29. Write Code That Writes Code..................103 Code generators increase your productivity and help avoid duplication.\n\n30. You Can’t Write Perfect Software .............. 107 Software can’t be perfect. Protect your code and users from the inevitable errors.\n\n31. Design with Contracts.........................111 Use contracts to document and verify that code does no more and no less than it claims to do.\n\n32. Crash Early...................................120 A dead program normally does a lot less damage than a crippled one.\n\n33. Use Assertions to Prevent the Impossible ..... 122 Assertions validate your assumptions. Use them to protect your code from an uncertain world.\n\n34. Use Exceptions for Exceptional Problems ..... 127 Exceptions can suffer from all the readability and maintainability problems of classic spaghetti code. Reserve exceptions for exceptional things.\n\n2\n\n35. Finish What You Start.........................129 Where possible, the routine or object that allocates a resource should be responsible for deallocating it.\n\n36. Minimize Coupling Between Modules..........140 Avoid coupling by writing “shy” code and applying the Law of Demeter.\n\n37. Conﬁgure, Don’t Integrate .....................144 Implement technology choices for an application as conﬁguration options, not through integration or engineering.\n\n38. Put Abstractions in Code, Details in Metadata.145 Program for the general case, and put the speciﬁcs outside the compiled code base.\n\n39. Analyze Workﬂow to Improve Concurrency....151 Exploit concurrency in your user’s workﬂow.\n\n40. Design Using Services.........................154 Design in terms of services—independent, concur- rent objects behind well-deﬁned, consistent inter- faces.\n\n41. Always Design for Concurrency ............... 156 Allow for concurrency, and you’ll design cleaner in- terfaces with fewer assumptions.\n\n42. Separate Views from Models...................161 Gain ﬂexibility at low cost by designing your appli- cation in terms of models and views.\n\n43. Use Blackboards to Coordinate Workﬂow......169 Use blackboards to coordinate disparate facts and agents, while maintaining independence and isola- tion among participants.\n\n44. Don’t Program by Coincidence ................ 175 Rely only on reliable things. Beware of accidental complexity, and don’t confuse a happy coincidence with a purposeful plan.\n\n45. Estimate the Order of Your Algorithms........181 Get a feel for how long things are likely to take be- fore you write code.\n\n46. Test Your Estimates...........................182 Mathematical analysis of algorithms doesn’t tell you everything. Try timing your code in its target environment.\n\nTIPS 47 TO 70\n\n47. Refactor Early, Refactor Often ................. 186 Just as you might weed and rearrange a gar- den, rewrite, rework, and re-architect code when it needs it. Fix the root of the problem.\n\n48. Design to Test.................................192 Start thinking about testing before you write a line of code.\n\n49. Test Your Software, or Your Users Will.........197 Test ruthlessly. Don’t make your users ﬁnd bugs for you.\n\n50. Don’t Use Wizard Code You Don’t Understand . 199 Wizards can generate reams of code. Make sure you understand all of it before you incorporate it into your project.\n\n51. Don’t Gather Requirements—Dig for Them.....202 Requirements rarely lie on the surface. They’re buried deep beneath layers of assumptions, mis- conceptions, and politics.\n\n52. Work with a User to Think Like a User.........204 It’s the best way to gain insight into how the sys- tem will really be used.\n\n53. Abstractions Live Longer than Details.........209 Invest in the abstraction, not the implementation. Abstractions can survive the barrage of changes from different implementations and new technolo- gies.\n\n54. Use a Project Glossary ........................ 210 Create and maintain a single source of all the spe- ciﬁc terms and vocabulary for a project.\n\n55. Don’t Think Outside the Box—Find the Box....213 When faced with an impossible problem, identify the real constraints. Ask yourself: “Does it have to be done this way? Does it have to be done at all?”\n\n56. Start When You’re Ready......................215 You’ve been building experience all your life. Don’t ignore niggling doubts.\n\n57. Some Things Are Better Done than Described . 218 into the speciﬁcation spiral—at some Don’t fall point you need to start coding.\n\n58. Don’t Be a Slave to Formal Methods ........... 220 Don’t blindly adopt any technique without putting it into the context of your development practices and capabilities.\n\n3\n\n59. Costly Tools Don’t Produce Better Designs .... 222 Beware of vendor hype, industry dogma, and the aura of the price tag. Judge tools on their merits.\n\n60. Organize Teams Around Functionality ........ 227 Don’t separate designers from coders, testers from data modelers. Build teams the way you build code.\n\n61. Don’t Use Manual Procedures ................. 231 A shell script or batch ﬁle will execute the same instructions, in the same order, time after time.\n\n62. Test Early. Test Often. Test Automatically. .... 237 Tests that run with every build are much more ef- fective than test plans that sit on a shelf.\n\n63. Coding Ain’t Done ’Til All the Tests Run.......238 ’Nuff said.\n\n64. Use Saboteurs to Test Your Testing............244 Introduce bugs on purpose in a separate copy of the source to verify that testing will catch them.\n\n65. Test State Coverage, Not Code Coverage .......245 Identify and test signiﬁcant program states. Just testing lines of code isn’t enough.\n\n66. Find Bugs Once ............................... 247 Once a human tester ﬁnds a bug, it should be the last time a human tester ﬁnds that bug. Automatic tests should check for it from then on.\n\n67. English is Just a Programming Language ...... 248 Write documents as you would write code: honor the DRY principle, use metadata, MVC, automatic generation, and so on.\n\n68. Build Documentation In, Don’t Bolt It On......248 Documentation created separately from code is less likely to be correct and up to date.\n\n69. Gently Exceed Your Users’ Expectations ...... 255 Come to understand your users’ expectations, then deliver just that little bit more.\n\n70. Sign Your Work ............................... 258 Craftsmen of an earlier age were proud to sign their work. You should be, too.\n\nChecklists\n\n✔Languages to Learn...................page 17 Tired of C, C++, and Java? Try CLOS, Dylan, Eif- fel, Objective C, Prolog, Smalltalk, or TOM. Each of these languages has different capabilities and a different “ﬂavor.” Try a small project at home using one or more of them.\n\n✔The WISDOM Acrostic ................. page 20\n\n✔Law of Demeter for Functions.....page 141 An object’s method should call only methods be- longing to: Itself Any parameters passed in Objects it creates Component objects\n\nWhat do you want them to learn?\n\nWhat is their interest in what you’ve got to say?\n\nHow sophisticated are they?\n\nHow much detail do they want?\n\nWhom do you want to own the information?\n\nHow can you motivate them to listen to you?\n\n✔How to Maintain Orthogonality.....page 34 Design independent, well-deﬁned components. Keep your code decoupled. Avoid global data. Refactor similar functions.\n\n✔How to Program Deliberately ...... page 172\n\nStay aware of what you’re doing. Don’t code blindfolded. Proceed from a plan. Rely only on reliable things. Document your assumptions. Test assumptions as well as code. Prioritize your effort. Don’t be a slave to history.\n\n✔Things to prototype...................page 53\n\nArchitecture New functionality in an existing system Structure or contents of external data Third-party tools or components Performance issues User interface design\n\n✔When to Refactor.....................page 185 You discover a violation of the DRY principle. You ﬁnd things that could be more orthogonal. Your knowledge improves. The requirements evolve. You need to improve performance.\n\n✔Architectural Questions.............page 55\n\nAre responsibilities well deﬁned? Are the collaborations well deﬁned? Is coupling minimized? Can you identify potential duplication? Are interface deﬁnitions and constraints accept- able? Can modules access needed data—when needed?\n\n✔Cutting the Gordian Knot .......... page 212 When solving impossible problems, ask yourself:\n\nIs there an easier way? Am I solving the right problem? Why is this a problem? What makes it hard? Do I have to do it this way? Does it have to be done at all?\n\n✔Aspects of Testing...................page 237\n\n✔Debugging Checklist..................page 98 Is the problem being reported a direct result of the underlying bug, or merely a symptom? Is the bug really in the compiler? Is it in the OS? Or is it in your code? If you explained this problem in detail to a coworker, what would you say? If the suspect code passes its unit tests, are the tests complete enough? What happens if you run the unit test with this data? Do the conditions that caused this bug exist anywhere else in the system?\n\nUnit testing Integration testing Validation and veriﬁcation Resource exhaustion, errors, and recovery Performance testing Usability testing Testing the tests themselves\n\nChecklists from The Pragmatic Programmer, by Andrew Hunt and David Thomas. Visit www.pragmaticprogrammer.com. Copyright c 2000 by Addison Wesley Longman, Inc.\n\n4",
      "page_number": 349
    }
  ],
  "pages": [
    {
      "page_number": 2,
      "content": "What others in the trenches say about The Pragmatic Programmer.. .\n\n“The cool thing about this book is that it’s great for keeping the programming process fresh. [The book] helps you to continue to grow and clearly comes from people who have been there.”\n\nKent Beck, author of Extreme Programming Explained: Embrace Change\n\n“I found this book to be a great mix of solid advice and wonderful analogies!”\n\nMartin Fowler, author of Refactoring and UML Distilled\n\n“I would buy a copy, read it twice, then tell all my colleagues to run out and grab a copy. This is a book I would never loan because I would worry about it being lost.”\n\nKevin Ruland, Management Science, MSG-Logistics\n\n“The wisdom and practical experience of the authors is obvious. The topics presented are relevant and useful. . . . By far its greatest strength for me has been the outstanding analogies—tracer bullets, broken windows, and the fabulous helicopter-based explanation of the need for orthogonality, especially in a crisis situation. I have little doubt that this book will eventually become an excellent source of useful information for journeymen programmers and expert mentors alike.”\n\nJohn Lakos, author of Large-Scale C++ Software Design",
      "content_length": 1218,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 3,
      "content": "“This is the sort of book I will buy a dozen copies of when it comes out so I can give it to my clients.”\n\nEric Vought, Software Engineer\n\n“Most modern books on software development fail to cover the basics of what makes a great software developer, instead spending their time on syntax or technology where in reality the greatest leverage possible for any software team is in having talented developers who really know their craft well. An excellent book.”\n\nPete McBreen, Independent Consultant\n\n“Since reading this book, I have implemented many of the practical suggestions and tips it contains. Across the board, they have saved my company time and money while helping me get my job done quicker! This should be a desktop reference for everyone who works with code for a living.”\n\nJared Richardson, Senior Software Developer, iRenaissance, Inc.\n\n“I would like to see this issued to every new employee at my company. . . .”\n\nChris Cleeland, Senior Software Engineer, Object Computing, Inc.",
      "content_length": 991,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 4,
      "content": "ThePragmaticProgrammer",
      "content_length": 22,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 5,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 6,
      "content": "ThePragmaticProgrammer From Journeyman to Master\n\nAndrew Hunt David Thomas\n\nADDISON–WESLEY An imprint of Addison Wesley Longman, Inc.\n\nReading, Massachusetts Harlow, England Menlo Park, California Berkeley, California Don Mills, Ontario Sydney Bonn Amsterdam Tokyo Mexico City",
      "content_length": 276,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 7,
      "content": "Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and Addison– Wesley was aware of a trademark claim, the designations have been printed in initial capital letters or in all capitals.\n\nLyrics from the song “The Boxer” on page 157 are Copyright c 1968 Paul Simon. Used by permission of the Publisher: Paul Simon Music. Lyrics from the song “Alice’s Restaurant” on page 220 are by Arlo Guthrie, c 1966, 1967 (renewed) by APPLESEED MUSIC INC. All Rights Reserved. Used by Permission.\n\nThe authors and publisher have taken care in the preparation of this book, but make no express or implied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.\n\nThe publisher offers discounts on this book when ordered in quantity for special sales. For more information, please contact:\n\nAWL Direct Sales Addison Wesley Longman, Inc. One Jacob Way Reading, Massachusetts 01867 (781) 944-3700\n\nVisit AWL on the Web: www.awl.com/cseng\n\nLibrary of Congress Cataloging-in-Publication Data\n\nHunt, Andrew, 1964–\n\nThe Pragmatic Programmer / Andrew Hunt, David Thomas.\n\np. cm.\n\nIncludes bibliographical references. ISBN 0-201-61622-X 1. Computer programming.\n\nI. Thomas, David, 1956–\n\n.\n\nII. Title. QA76.6.H857 1999 005.1--dc21\n\n99–43581 CIP\n\nCopyright c 2000 by Addison Wesley Longman, Inc.\n\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by any means, electronic, mechanical, photo- copying, recording, or otherwise, without the prior written permission of the publisher. Printed in the United States of America. Published simultaneously in Canada.\n\nISBN 0-201-61622-X\n\nText printed in the United States on recycled paper at Courier Stoughton in Stoughton, Massachusetts.\n\n25th\n\nPrinting\n\nFebruary 2010",
      "content_length": 2051,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 8,
      "content": "ForEllieandJuliet, ElizabethandZachary, StuartandHenry",
      "content_length": 54,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 9,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 10,
      "content": "Contents\n\nFOREWORD\n\nPREFACE\n\n1 A PRAGMATIC PHILOSOPHY\n\n1. The Cat Ate My Source Code . . . . . . . . . . . . . . . . .\n\n2. Software Entropy . . . . . . . . . . . . . . . . . . . . . . . .\n\n3. Stone Soup and Boiled Frogs . . . . . . . . . . . . . . . . .\n\n4. Good-Enough Software . . . . . . . . . . . . . . . . . . . .\n\n5. Your Knowledge Portfolio . . . . . . . . . . . . . . . . . . .\n\n6. Communicate!\n\n. . . . . . . . . . . . . . . . . . . . . . . . .\n\n2 A PRAGMATIC APPROACH\n\n7. The Evils of Duplication . . . . . . . . . . . . . . . . . . . .\n\n8. Orthogonality . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n9. Reversibility . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n10. Tracer Bullets . . . . . . . . . . . . . . . . . . . . . . . . .\n\n11. Prototypes and Post-it Notes . . . . . . . . . . . . . . . . .\n\n12. Domain Languages . . . . . . . . . . . . . . . . . . . . . .\n\n13. Estimating . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n3 THE BASIC TOOLS\n\n14. The Power of Plain Text . . . . . . . . . . . . . . . . . . . .\n\n15. Shell Games . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n16. Power Editing . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n17. Source Code Control . . . . . . . . . . . . . . . . . . . . . .\n\n18. Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n19. Text Manipulation . . . . . . . . . . . . . . . . . . . . . . . 99\n\n19. Text Manipulation . . . . . . . . . . . . . . . . . . . . . . . 99\n\n20. Code Generators . . . . . . . . . . . . . . . . . . . . . . . . 102\n\nix\n\nxiii\n\nxvii\n\n1\n\n2\n\n4\n\n7\n\n9\n\n12\n\n18\n\n25\n\n26\n\n34\n\n44\n\n48\n\n53\n\n57\n\n64\n\n71\n\n73\n\n77\n\n82\n\n86",
      "content_length": 1638,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 11,
      "content": "x\n\nCONTENTS\n\n4 PRAGMATIC PARANOIA 21. Design by Contract\n\n. . . . . . . . . . . . . . . . . . . . . . 109\n\n107\n\n22. Dead Programs Tell No Lies\n\n. . . . . . . . . . . . . . . . . 120\n\n23. Assertive Programming . . . . . . . . . . . . . . . . . . . . 122\n\n24. When to Use Exceptions . . . . . . . . . . . . . . . . . . . 125\n\n25. How to Balance Resources . . . . . . . . . . . . . . . . . . 129\n\n5 BEND, OR BREAK\n\n137\n\n26. Decoupling and the Law of Demeter . . . . . . . . . . . . . 138\n\n27. Metaprogramming . . . . . . . . . . . . . . . . . . . . . . . 144\n\n28. Temporal Coupling . . . . . . . . . . . . . . . . . . . . . . . 150\n\n29. It’s Just a View . . . . . . . . . . . . . . . . . . . . . . . . . 157\n\n30. Blackboards . . . . . . . . . . . . . . . . . . . . . . . . . . 165\n\n6 WHILE YOU ARE CODING\n\n171\n\n31. Programming by Coincidence . . . . . . . . . . . . . . . . 172\n\n32. Algorithm Speed . . . . . . . . . . . . . . . . . . . . . . . . 177\n\n33. Refactoring . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\n\n34. Code That’s Easy to Test\n\n. . . . . . . . . . . . . . . . . . . 189\n\n35. Evil Wizards\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . 198\n\n7 BEFORE THE PROJECT\n\n201\n\n36. The Requirements Pit . . . . . . . . . . . . . . . . . . . . . 202\n\n37. Solving Impossible Puzzles . . . . . . . . . . . . . . . . . . 212\n\n38. Not Until You’re Ready . . . . . . . . . . . . . . . . . . . . 215\n\n39. The Speciﬁcation Trap . . . . . . . . . . . . . . . . . . . . 217\n\n40. Circles and Arrows . . . . . . . . . . . . . . . . . . . . . . . 220\n\n8 PRAGMATIC PROJECTS\n\n223\n\n41. Pragmatic Teams . . . . . . . . . . . . . . . . . . . . . . . . 224\n\n42. Ubiquitous Automation . . . . . . . . . . . . . . . . . . . . 230\n\n43. Ruthless Testing . . . . . . . . . . . . . . . . . . . . . . . . 237\n\n44. It’s All Writing . . . . . . . . . . . . . . . . . . . . . . . . . 248\n\n45. Great Expectations . . . . . . . . . . . . . . . . . . . . . . 255\n\n46. Pride and Prejudice . . . . . . . . . . . . . . . . . . . . . . 258",
      "content_length": 2024,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 12,
      "content": "CONTENTS\n\nAppendices\n\nA RESOURCES\n\nProfessional Societies . . . . . . . . . . . . . . . . . . . . . . . . 262\n\nBuilding a Library . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n\nInternet Resources . . . . . . . . . . . . . . . . . . . . . . . . . 266\n\nBibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275\n\nB ANSWERS TO EXERCISES\n\nINDEX\n\nxi\n\n261\n\n279\n\n309",
      "content_length": 385,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 13,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 14,
      "content": "Foreword\n\nAs a reviewer I got an early opportunity to read the book you are hold- ing. It was great, even in draft form. Dave Thomas and Andy Hunt have something to say, and they know how to say it. I saw what they were doing and I knew it would work. I asked to write this foreword so that I could explain why.\n\nSimply put, this book tells you how to program in a way that you can follow. You wouldn’t think that that would be a hard thing to do, but it is. Why? For one thing, not all programming books are written by pro- grammers. Many are compiled by language designers, or the journalists who work with them to promote their creations. Those books tell you how to talk in a programming language—which is certainly important, but that is only a small part of what a programmer does.\n\nWhat does a programmer do besides talk in programming language? Well, that is a deeper issue. Most programmers would have trouble explaining what they do. Programming is a job ﬁlled with details, and keeping track of those details requires focus. Hours drift by and the code appears. You look up and there are all of those statements. If you don’t think carefully, you might think that programming is just typing statements in a programming language. You would be wrong, of course, but you wouldn’t be able to tell by looking around the programming section of the bookstore.\n\nIn The Pragmatic Programmer Dave and Andy tell us how to program in a way that we can follow. How did they get so smart? Aren’t they just as focused on details as other programmers? The answer is that they paid attention to what they were doing while they were doing it—and then they tried to do it better.\n\nImagine that you are sitting in a meeting. Maybe you are thinking that the meeting could go on forever and that you would rather be programming. Dave and Andy would be thinking about why they were\n\nxiii",
      "content_length": 1875,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 15,
      "content": "xiv\n\nFOREWORD\n\nhaving the meeting, and wondering if there is something else they could do that would take the place of the meeting, and deciding if that some- thing could be automated so that the work of the meeting just happens in the future. Then they would do it.\n\nThat is just the way Dave and Andy think. That meeting wasn’t some- thing keeping them from programming. It was programming. And it was programming that could be improved. I know they think this way because it is tip number two: Think About Your Work.\n\nSo imagine that these guys are thinking this way for a few years. Pretty soon they would have a collection of solutions. Now imagine them using their solutions in their work for a few more years, and discarding the ones that are too hard or don’t always produce results. Well, that approach just about deﬁnes pragmatic. Now imagine them taking a year or two more to write their solutions down. You might think, That information would be a gold mine. And you would be right.\n\nThe authors tell us how they program. And they tell us in a way that we can follow. But there is more to this second statement than you might think. Let me explain.\n\nThe authors have been careful to avoid proposing a theory of software development. This is fortunate, because if they had they would be obliged to warp each chapter to defend their theory. Such warping is the tradition in, say, the physical sciences, where theories eventually become laws or are quietly discarded. Programming on the other hand has few (if any) laws. So programming advice shaped around wanna-be laws may sound good in writing, but it fails to satisfy in practice. This is what goes wrong with so many methodology books.\n\nI’ve studied this problem for a dozen years and found the most promise in a device called a pattern language. In short, a pattern is a solution, and a pattern language is a system of solutions that reinforce each other. A whole community has formed around the search for these systems.\n\nThis book is more than a collection of tips. It is a pattern language in sheep’s clothing. I say that because each tip is drawn from experi- ence, told as concrete advice, and related to others to form a system. These are the characteristics that allow us to learn and follow a pattern language. They work the same way here.",
      "content_length": 2312,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 16,
      "content": "FOREWORD\n\nYou can follow the advice in this book because it is concrete. You won’t ﬁnd vague abstractions. Dave and Andy write directly for you, as if each tip was a vital strategy for energizing your programming career. They make it simple, they tell a story, they use a light touch, and then they follow that up with answers to questions that will come up when you try.\n\nAnd there is more. After you read ten or ﬁfteen tips you will begin to see an extra dimension to the work. We sometimes call it QWAN, short for the quality without a name. The book has a philosophy that will ooze into your consciousness and mix with your own. It doesn’t preach. It just tells what works. But in the telling more comes through. That’s the beauty of the book: It embodies its philosophy, and it does so unpre- tentiously.\n\nSo here it is: an easy to read—and use—book about the whole practice of programming. I’ve gone on and on about why it works. You probably only care that it does work. It does. You will see.\n\n—Ward Cunningham\n\nxv",
      "content_length": 1022,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 17,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 18,
      "content": "Preface\n\nThis book will help you become a better programmer.\n\nIt doesn’t matter whether you are a lone developer, a member of a large project team, or a consultant working with many clients at once. This book will help you, as an individual, to do better work. This book isn’t theoretical—we concentrate on practical topics, on using your experi- ence to make more informed decisions. The word pragmatic comes from the Latin pragmaticus—“skilled in business”—which itself is derived , meaning “to do.” This is a book about doing. from the Greek\n\nProgramming is a craft. At its simplest, it comes down to getting a computer to do what you want it to do (or what your user wants it to do). As a programmer, you are part listener, part advisor, part interpreter, and part dictator. You try to capture elusive requirements and ﬁnd a way of expressing them so that a mere machine can do them justice. You try to document your work so that others can understand it, and you try to engineer your work so that others can build on it. What’s more, you try to do all this against the relentless ticking of the project clock. You work small miracles every day.\n\nIt’s a difﬁcult job.\n\nThere are many people offering you help. Tool vendors tout the mir- acles their products perform. Methodology gurus promise that their techniques guarantee results. Everyone claims that their programming language is the best, and every operating system is the answer to all conceivable ills.\n\nOf course, none of this is true. There are no easy answers. There is no such thing as a best solution, be it a tool, a language, or an operat- ing system. There can only be systems that are more appropriate in a particular set of circumstances.\n\nxvii",
      "content_length": 1716,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 19,
      "content": "xviii\n\nPREFACE\n\nThis is where pragmatism comes in. You shouldn’t be wedded to any particular technology, but have a broad enough background and expe- rience base to allow you to choose good solutions in particular situ- ations. Your background stems from an understanding of the basic principles of computer science, and your experience comes from a wide range of practical projects. Theory and practice combine to make you strong.\n\nYou adjust your approach to suit the current circumstances and envi- ronment. You judge the relative importance of all the factors affecting a project and use your experience to produce appropriate solutions. And you do this continuously as the work progresses. Pragmatic Program- mers get the job done, and do it well.\n\nWho Should Read This Book? This book is aimed at people who want to become more effective and more productive programmers. Perhaps you feel frustrated that you don’t seem to be achieving your potential. Perhaps you look at col- leagues who seem to be using tools to make themselves more produc- tive than you. Maybe your current job uses older technologies, and you want to know how newer ideas can be applied to what you do.\n\nWe don’t pretend to have all (or even most) of the answers, nor are all of our ideas applicable in all situations. All we can say is that if you follow our approach, you’ll gain experience rapidly, your produc- tivity will increase, and you’ll have a better understanding of the entire development process. And you’ll write better software.\n\nWhat Makes aPragmaticProgrammer? Each developer is unique, with individual strengths and weaknesses, preferences and dislikes. Over time, each will craft his or her own personal environment. That environment will reﬂect the programmer’s individuality just as forcefully as his or her hobbies, clothing, or hair- cut. However, if you’re a Pragmatic Programmer, you’ll share many of the following characteristics:\n\nEarly adopter/fast adapter. You have an instinct for technologies and techniques, and you love trying things out. When given some-",
      "content_length": 2066,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 20,
      "content": "PREFACE\n\nthing new, you can grasp it quickly and integrate it with the rest of your knowledge. Your conﬁdence is born of experience.\n\nInquisitive. You tend to ask questions. That’s neat—how did you do that? Did you have problems with that library? What’s this BeOS I’ve heard about? How are symbolic links implemented? You are a pack rat for little facts, each of which may affect some decision years from now.\n\nCritical thinker. You rarely take things as given without ﬁrst get- ting the facts. When colleagues say “because that’s the way it’s done,” or a vendor promises the solution to all your problems, you smell a challenge.\n\nRealistic. You try to understand the underlying nature of each problem you face. This realism gives you a good feel for how difﬁ- cult things are, and how long things will take. Understanding for yourself that a process should be difﬁcult or will take a while to complete gives you the stamina to keep at it.\n\nJack of all trades. You try hard to be familiar with a broad range of technologies and environments, and you work to keep abreast of new developments. Although your current job may require you to be a specialist, you will always be able to move on to new areas and new challenges.\n\nWe’ve left the most basic characteristics until last. All Pragmatic Pro- grammers share them. They’re basic enough to state as tips:\n\nTIP 1\n\nCare About Your Craft\n\nWe feel that there is no point in developing software unless you care about doing it well.\n\nTIP 2\n\nThink! About Your Work\n\nIn order to be a Pragmatic Programmer, we’re challenging you to think about what you’re doing while you’re doing it. This isn’t a one-time audit of current practices—it’s an ongoing critical appraisal of every\n\nxix",
      "content_length": 1725,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 21,
      "content": "xx\n\nPREFACE\n\ndecision you make, every day, and on every development. Never run on auto-pilot. Constantly be thinking, critiquing your work in real time. The old IBM corporate motto, THINK!, is the Pragmatic Programmer’s mantra.\n\nIf this sounds like hard work to you, then you’re exhibiting the realistic characteristic. This is going to take up some of your valuable time—time that is probably already under tremendous pressure. The reward is a more active involvement with a job you love, a feeling of mastery over an increasing range of subjects, and pleasure in a feeling of continuous improvement. Over the long term, your time investment will be repaid as you and your team become more efﬁcient, write code that’s easier to maintain, and spend less time in meetings.\n\nIndividual Pragmatists,LargeTeams Some people feel that there is no room for individuality on large teams or complex projects. “Software construction is an engineering disci- pline,” they say, “that breaks down if individual team members make decisions for themselves.”\n\nWe disagree.\n\nThe construction of software should be an engineering discipline. How- ever, this doesn’t preclude individual craftsmanship. Think about the large cathedrals built in Europe during the Middle Ages. Each took thousands of person-years of effort, spread over many decades. Lessons learned were passed down to the next set of builders, who advanced the state of structural engineering with their accomplishments. But the carpenters, stonecutters, carvers, and glass workers were all craftspeo- ple, interpreting the engineering requirements to produce a whole that transcended the purely mechanical side of the construction. It was their belief in their individual contributions that sustained the projects:\n\nWe who cut mere stones must always be envisioning cathedrals.\n\n— Quarry worker’s creed\n\nWithin the overall structure of a project there is always room for in- dividuality and craftsmanship. This is particularly true given the cur- rent state of software engineering. One hundred years from now, our engineering may seem as archaic as the techniques used by medieval",
      "content_length": 2129,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 22,
      "content": "PREFACE\n\ncathedral builders seem to today’s civil engineers, while our craftsman- ship will still be honored.\n\nIt’s aContinuous Process\n\nA tourist visiting England’s Eton College asked the gardener how he got the lawns so perfect. “That’s easy,” he replied, “You just brush off the dew every morning, mow them every other day, and roll them once a week.”\n\n“Is that all?” asked the tourist.\n\n“Absolutely,” replied the gardener. “Do that for 500 years and you’ll have a nice lawn, too.”\n\nGreat lawns need small amounts of daily care, and so do great pro- grammers. Management consultants like to drop the word kaizen in conversations. “Kaizen” is a Japanese term that captures the concept of continuously making many small improvements. It was considered to be one of the main reasons for the dramatic gains in productivity and quality in Japanese manufacturing and was widely copied throughout the world. Kaizen applies to individuals, too. Every day, work to reﬁne the skills you have and to add new tools to your repertoire. Unlike the Eton lawns, you’ll start seeing results in a matter of days. Over the years, you’ll be amazed at how your experience has blossomed and your skills have grown.\n\nHowthe Book Is Organized This book is written as a collection of short sections. Each section is self-contained, and addresses a particular topic. You’ll ﬁnd numerous cross references, which help put each topic in context. Feel free to read the sections in any order—this isn’t a book you need to read front-to- back.\n\nOccasionally you’ll come across a box labeled Tip nn (such as Tip 1, “Care About Your Craft” on page xix). As well as emphasizing points in the text, we feel the tips have a life of their own—we live by them daily. You’ll ﬁnd a summary of all the tips on a pull-out card inside the back cover.\n\nxxi",
      "content_length": 1814,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 23,
      "content": "xxii\n\nPREFACE\n\nAppendix A contains a set of resources: the book’s bibliography, a list of URLs to Web resources, and a list of recommended periodicals, books, and professional organizations. Throughout the book you’ll ﬁnd refer- ences to the bibliography and to the list of URLs—such as [KP99] and [URL 18], respectively.\n\nWe’ve included exercises and challenges where appropriate. Exercises normally have relatively straightforward answers, while the challenges are more open-ended. To give you an idea of our thinking, we’ve in- cluded our answers to the exercises in Appendix B, but very few have a single correct solution. The challenges might form the basis of group discussions or essay work in advanced programming courses.\n\nWhat’s in aName?\n\n“When I use a word,” Humpty Dumpty said, in rather a scornful tone, “it means just what I choose it to mean—neither more nor less.” Lewis Carroll, Through theLooking-Glass\n\nScattered throughout the book you’ll ﬁnd various bits of jargon—either perfectly good English words that have been corrupted to mean some- thing technical, or horrendous made-up words that have been assigned meanings by computer scientists with a grudge against the language. The ﬁrst time we use each of these jargon words, we try to deﬁne it, or at least give a hint to its meaning. However, we’re sure that some have fallen through the cracks, and others, such as object and rela- tional database, are in common enough usage that adding a deﬁnition would be boring. If you do come across a term you haven’t seen be- fore, please don’t just skip over it. Take time to look it up, perhaps on the Web, or maybe in a computer science textbook. And, if you get a chance, drop us an e-mail and complain, so we can add a deﬁnition to the next edition.\n\nHaving said all this, we decided to get revenge against the computer sci- entists. Sometimes, there are perfectly good jargon words for concepts, words that we’ve decided to ignore. Why? Because the existing jargon is normally restricted to a particular problem domain, or to a partic- ular phase of development. However, one of the basic philosophies of this book is that most of the techniques we’re recommending are uni- versal: modularity applies to code, designs, documentation, and team",
      "content_length": 2264,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 24,
      "content": "PREFACE\n\norganization, for instance. When we wanted to use the conventional jargon word in a broader context, it got confusing—we couldn’t seem to overcome the baggage the original term brought with it. When this happened, we contributed to the decline of the language by inventing our own terms.\n\nSource Code andOtherResources Most of the code shown in this book is extracted from compilable source ﬁles, available for download from our Web site:\n\nwww.pragmaticprogrammer.com\n\nThere you’ll also ﬁnd links to resources we ﬁnd useful, along with updates to the book and news of other Pragmatic Programmer devel- opments.\n\nSendUs Feedback We’d appreciate hearing from you. Comments, suggestions, errors in the text, and problems in the examples are all welcome. E-mail us at\n\nppbook@pragmaticprogrammer.com\n\nAcknowledgments When we started writing this book, we had no idea how much of a team effort it would end up being.\n\nAddison-Wesley has been brilliant, taking a couple of wet-behind-the- ears hackers and walking us through the whole book-production pro- cess, from idea to camera-ready copy. Many thanks to John Wait and Meera Ravindiran for their initial support, Mike Hendrickson, our enthusiastic editor (and a mean cover designer!), Lorraine Ferrier and John Fuller for their help with production, and the indefatigable Julie DeBaggis for keeping us all together.\n\nThen there were the reviewers: Greg Andress, Mark Cheers, Chris Clee- land, Alistair Cockburn, Ward Cunningham, Martin Fowler, Thanh T. Giang, Robert L. Glass, Scott Henninger, Michael Hunter, Brian\n\nxxiii",
      "content_length": 1579,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 25,
      "content": "xxiv\n\nPREFACE\n\nKirby, John Lakos, Pete McBreen, Carey P. Morris, Jared Richardson, Kevin Ruland, Eric Starr, Eric Vought, Chris Van Wyk, and Deborra Zukowski. Without their careful comments and valuable insights, this book would be less readable, less accurate, and twice as long. Thank you all for your time and wisdom.\n\nThe second printing of this book beneﬁted greatly from the eagle eyes of our readers. Many thanks to Brian Blank, Paul Boal, Tom Ekberg, Brent Fulgham, Louis Paul Hebert, Henk-Jan Olde Loohuis, Alan Lund, Gareth McCaughan, Yoshiki Shibata, and Volker Wurst, both for ﬁnd- ing the mistakes and for having the grace to point them out gently.\n\nOver the years, we have worked with a large number of progressive clients, where we gained and reﬁned the experience we write about here. Recently, we’ve been fortunate to work with Peter Gehrke on sev- eral large projects. His support and enthusiasm for our techniques are much appreciated.\n\nThis book was produced using LATEX, pic, Perl, dvips, ghostview, ispell, GNU make, CVS, Emacs, XEmacs, EGCS, GCC, Java, iContract, and SmallEiffel, using the Bash and zsh shells under Linux. The stagger- ing thing is that all of this tremendous software is freely available. We owe a huge “thank you” to the thousands of Pragmatic Programmers worldwide who have contributed these and other works to us all. We’d particularly like to thank Reto Kramer for his help with iContract.\n\nLast, but in no way least, we owe a huge debt to our families. Not only have they put up with late night typing, huge telephone bills, and our permanent air of distraction, but they’ve had the grace to read what we’ve written, time after time. Thank you for letting us dream.\n\nAndy Hunt Dave Thomas",
      "content_length": 1735,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 26,
      "content": "Chapter 1\n\nA Pragmatic Philosophy\n\nWhat distinguishes Pragmatic Programmers? We feel it’s an attitude, a style, a philosophy of approaching problems and their solutions. They think beyond the immediate problem, always trying to place it in its larger context, always trying to be aware of the bigger picture. After all, without this larger context, how can you be pragmatic? How can you make intelligent compromises and informed decisions?\n\nAnother key to their success is that they take responsibility for every- thing they do, which we discuss in The Cat Ate My Source Code. Being responsible, Pragmatic Programmers won’t sit idly by and watch their projects fall apart through neglect. In Software Entropy, we tell you how to keep your projects pristine.\n\nMost people ﬁnd change difﬁcult to accept, sometimes for good reasons, sometimes because of plain old inertia. In Stone Soup and Boiled Frogs, we look at a strategy for instigating change and (in the interests of balance) present the cautionary tale of an amphibian that ignored the dangers of gradual change.\n\nOne of the beneﬁts of understanding the context in which you work is that it becomes easier to know just how good your software has to be. Sometimes near-perfection is the only option, but often there are trade-offs involved. We explore this in Good-Enough Software.\n\nOf course, you need to have a broad base of knowledge and experience to pull all of this off. Learning is a continuous and ongoing process. In Your Knowledge Portfolio, we discuss some strategies for keeping the momentum up.\n\n1",
      "content_length": 1565,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 27,
      "content": "1\n\n2\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nFinally, none of us works in a vacuum. We all spend a large amount of time interacting with others. Communicate! lists ways we can do this better.\n\nPragmatic programming stems from a philosophy of pragmatic think- ing. This chapter sets the basis for that philosophy.\n\nThe Cat Ate My Source Code\n\nThe greatest of all weaknesses is the fear of appearing weak.\n\nJ. B. Bossuet, Politics from HolyWrit, 1709\n\nOne of the cornerstones of the pragmatic philosophy is the idea of tak- ing responsibility for yourself and your actions in terms of your career advancement, your project, and your day-to-day work. A Pragmatic Pro- grammer takes charge of his or her own career, and isn’t afraid to admit ignorance or error. It’s not the most pleasant aspect of programming, to be sure, but it will happen—even on the best of projects. Despite thorough testing, good documentation, and solid automation, things go wrong. Deliveries are late. Unforeseen technical problems come up.\n\nThese things happen, and we try to deal with them as professionally as we can. This means being honest and direct. We can be proud of our abilities, but we must be honest about our shortcomings—our igno- rance as well as our mistakes.\n\nTake Responsibility Responsibility is something you actively agree to. You make a commit- ment to ensure that something is done right, but you don’t necessarily have direct control over every aspect of it. In addition to doing your own personal best, you must analyze the situation for risks that are beyond your control. You have the right not to take on a responsibility for an impossible situation, or one in which the risks are too great. You’ll have to make the call based on your own ethics and judgment.\n\nWhen you do accept the responsibility for an outcome, you should ex- pect to be held accountable for it. When you make a mistake (as we all do) or an error in judgment, admit it honestly and try to offer options.",
      "content_length": 1970,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 28,
      "content": "THE CAT ATE MY SOURCE CODE\n\nDon’t blame someone or something else, or make up an excuse. Don’t blame all the problems on a vendor, a programming language, manage- ment, or your coworkers. Any and all of these may play a role, but it is up to you to provide solutions, not excuses.\n\nIf there was a risk that the vendor wouldn’t come through for you, then you should have had a contingency plan. If the disk crashes—taking all of your source code with it—and you don’t have a backup, it’s your fault. Telling your boss “the cat ate my source code” just won’t cut it.\n\nTIP 3\n\nProvide Options, Don’t Make Lame Excuses\n\nBefore you approach anyone to tell them why something can’t be done, is late, or is broken, stop and listen to yourself. Talk to the rubber duck on your monitor, or the cat. Does your excuse sound reasonable, or stupid? How’s it going to sound to your boss?\n\nRun through the conversation in your mind. What is the other person ” or “Didn’t you con- likely to say? Will they ask, “Have you tried this sider that?” How will you respond? Before you go and tell them the bad news, is there anything else you can try? Sometimes, you just know what they are going to say, so save them the trouble.\n\nInstead of excuses, provide options. Don’t say it can’t be done; explain what can be done to salvage the situation. Does code have to be thrown out? Educate them on the value of refactoring (see Refactoring, page 184). Do you need to spend time prototyping to determine the best way to proceed (see Prototypes and Post-it Notes, page 53)? Do you need to introduce better testing (see Code That’s Easy to Test, page 189, and Ruthless Testing, page 237) or automation (see Ubiquitous Automation, page 230) to prevent it from happening again? Perhaps you need ad- ditional resources. Don’t be afraid to ask, or to admit that you need help.\n\nTry to ﬂush out the lame excuses before voicing them aloud. If you must, tell your cat ﬁrst. After all, if little Tiddles is going to take the blame. .. .\n\n3",
      "content_length": 2003,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 29,
      "content": "2\n\n4\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nRelated sections include:\n\nPrototypes and Post-it Notes, page 53 Refactoring, page 184 Code That’s Easy to Test, page 189 Ubiquitous Automation, page 230 Ruthless Testing, page 237\n\nChallenges\n\nHow do you react when someone—such as a bank teller, an auto mechanic, or a clerk—comes to you with a lame excuse? What do you think of them and their company as a result?\n\nSoftware Entropy\n\nWhile software development is immune from almost all physical laws, entropy hits us hard. Entropy is a term from physics that refers to the amount of “disorder” in a system. Unfortunately, the laws of thermo- dynamics guarantee that the entropy in the universe tends toward a maximum. When disorder increases in software, programmers call it “software rot.”\n\nThere are many factors that can contribute to software rot. The most important one seems to be the psychology, or culture, at work on a project. Even if you are a team of one, your project’s psychology can be a very delicate thing. Despite the best laid plans and the best peo- ple, a project can still experience ruin and decay during its lifetime. Yet there are other projects that, despite enormous difﬁculties and con- stant setbacks, successfully ﬁght nature’s tendency toward disorder and manage to come out pretty well.\n\nWhat makes the difference?\n\nIn inner cities, some buildings are beautiful and clean, while others are rotting hulks. Why? Researchers in the ﬁeld of crime and urban decay discovered a fascinating trigger mechanism, one that very quickly turns a clean, intact, inhabited building into a smashed and abandoned derelict [WK82].",
      "content_length": 1636,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 30,
      "content": "SOFTWARE ENTROPY\n\nA broken window.\n\nOne broken window, left unrepaired for any substantial length of time, instills in the inhabitants of the building a sense of abandonment—a sense that the powers that be don’t care about the building. So another window gets broken. People start littering. Grafﬁti appears. Serious structural damage begins. In a relatively short space of time, the build- ing becomes damaged beyond the owner’s desire to ﬁx it, and the sense of abandonment becomes reality.\n\nThe “Broken Window Theory” has inspired police departments in New York and other major cities to crack down on the small stuff in order to keep out the big stuff. It works: keeping on top of broken windows, grafﬁti, and other small infractions has reduced the serious crime level.\n\nTIP 4\n\nDon’t Live with Broken Windows\n\nDon’t leave “broken windows” (bad designs, wrong decisions, or poor code) unrepaired. Fix each one as soon as it is discovered. If there is insufﬁcient time to ﬁx it properly, then board it up. Perhaps you can comment out the offending code, or display a \"Not Implemented\" mes- sage, or substitute dummy data instead. Take some action to prevent further damage and to show that you’re on top of the situation.\n\nWe’ve seen clean, functional systems deteriorate pretty quickly once windows start breaking. There are other factors that can contribute to software rot, and we’ll touch on some of them elsewhere, but neglect accelerates the rot faster than any other factor.\n\nYou may be thinking that no one has the time to go around cleaning up all the broken glass of a project. If you continue to think like that, then you’d better plan on getting a dumpster, or moving to another neighborhood. Don’t let entropy win.\n\nPuttingOut Fires By contrast, there’s the story of an obscenely rich acquaintance of Andy’s. His house was immaculate, beautiful, loaded with priceless antiques, objets d’art, and so on. One day, a tapestry that was hang- ing a little too close to his living room ﬁreplace caught on ﬁre. The ﬁre\n\n5",
      "content_length": 2030,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 31,
      "content": "6\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\ndepartment rushed in to save the day—and his house. But before they dragged their big, dirty hoses into the house, they stopped—with the ﬁre raging—to roll out a mat between the front door and the source of the ﬁre.\n\nThey didn’t want to mess up the carpet.\n\nA pretty extreme case, to be sure, but that’s the way it must be with software. One broken window—a badly designed piece of code, a poor management decision that the team must live with for the duration of the project—is all it takes to start the decline. If you ﬁnd yourself working on a project with quite a few broken windows, it’s all too easy to slip into the mindset of “All the rest of this code is crap, I’ll just follow suit.” It doesn’t matter if the project has been ﬁne up to this point. In the original experiment leading to the “Broken Window Theory,” an abandoned car sat for a week untouched. But once a single window was broken, the car was stripped and turned upside down within hours.\n\nBy the same token, if you ﬁnd yourself on a team and a project where the code is pristinely beautiful—cleanly written, well designed, and elegant—you will likely take extra special care not to mess it up, just like the ﬁreﬁghters. Even if there’s a ﬁre raging (deadline, release date, trade show demo, etc.), you don’t want to be the ﬁrst one to make a mess.\n\nRelated sections include:\n\nStone Soup and Boiled Frogs, page 7 Refactoring, page 184 Pragmatic Teams, page 224\n\nChallenges\n\nHelp strengthen your team by surveying your computing “neighborhood.” Choose two or three “broken windows” and discuss with your colleagues what the problems are and what could be done to ﬁx them.\n\nCan you tell when a window ﬁrst gets broken? What is your reaction? If it was the result of someone else’s decision, or a management edict, what can you do about it?",
      "content_length": 1847,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 32,
      "content": "3\n\nSTONE SOUP AND BOILED FROGS\n\nStone Soup and Boiled Frogs\n\nThe three soldiers returning home from war were hungry. When they saw the village ahead their spirits lifted—they were sure the villagers would give them a meal. But when they got there, they found the doors locked and the windows closed. After many years of war, the villagers were short of food, and hoarded what they had.\n\nUndeterred, the soldiers boiled a pot of water and carefully placed three stones into it. The amazed villagers came out to watch.\n\n“This is stone soup,” the soldiers explained. “Is that all you put in it?” asked the villagers. “Absolutely—although some say it tastes even better with a few .” A villager ran off, returning in no time with a basket of carrots from carrots his hoard.\n\nA couple of minutes later, the villagers again asked “Is that it?”\n\n“Well,” said the soldiers, “a couple of potatoes give it body.” Off ran another villager.\n\nOver the next hour, the soldiers listed more ingredients that would enhance the soup: beef, leeks, salt, and herbs. Each time a different villager would run off to raid their personal stores.\n\nEventually they had produced a large pot of steaming soup. The soldiers removed the stones, and they sat down with the entire village to enjoy the ﬁrst square meal any of them had eaten in months.\n\nThere are a couple of morals in the stone soup story. The villagers are tricked by the soldiers, who use the villagers’ curiosity to get food from them. But more importantly, the soldiers act as a catalyst, bringing the village together so they can jointly produce something that they couldn’t have done by themselves—a synergistic result. Eventually ev- eryone wins.\n\nEvery now and then, you might want to emulate the soldiers.\n\nYou may be in a situation where you know exactly what needs doing and how to do it. The entire system just appears before your eyes—you know it’s right. But ask permission to tackle the whole thing and you’ll be met with delays and blank stares. People will form committees, bud- gets will need approval, and things will get complicated. Everyone will guard their own resources. Sometimes this is called “start-up fatigue.”\n\n7",
      "content_length": 2177,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 33,
      "content": "8\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nIt’s time to bring out the stones. Work out what you can reasonably ask for. Develop it well. Once you’ve got it, show people, and let them marvel. Then say “of course, it would be better if we added .” Pretend it’s not important. Sit back and wait for them to start asking you to add the functionality you originally wanted. People ﬁnd it easier to join an ongoing success. Show them a glimpse of the future and you’ll get them to rally around.1\n\nTIP 5\n\nBe a Catalyst for Change\n\nTheVillagers’Side On the other hand, the stone soup story is also about gentle and grad- ual deception. It’s about focusing too tightly. The villagers think about the stones and forget about the rest of the world. We all fall for it, every day. Things just creep up on us.\n\nWe’ve all seen the symptoms. Projects slowly and inexorably get totally out of hand. Most software disasters start out too small to notice, and most project overruns happen a day at a time. Systems drift from their speciﬁcations feature by feature, while patch after patch gets added to a piece of code until there’s nothing of the original left. It’s often the accumulation of small things that breaks morale and teams.\n\nTIP 6\n\nRemember the Big Picture\n\nWe’ve never tried this—honest. But they say that if you take a frog and drop it into boiling water, it will jump straight back out again. However, if you place the frog in a pan of cold water, then gradually heat it, the frog won’t notice the slow increase in temperature and will stay put until cooked.\n\n1. While doing this, you may be comforted by the line attributed to Rear Admiral Dr. Grace Hopper: “It’s easier to ask forgiveness than it is to get permission.”",
      "content_length": 1713,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 34,
      "content": "GOOD-ENOUGH SOFTWARE\n\nNote that the frog’s problem is different from the broken windows issue discussed in Section 2. In the Broken Window Theory, people lose the will to ﬁght entropy because they perceive that no one else cares. The frog just doesn’t notice the change.\n\nDon’t be like the frog. Keep an eye on the big picture. Constantly review what’s happening around you, not just what you personally are doing.\n\nRelated sections include:\n\nSoftware Entropy, page 4 Programming by Coincidence, page 172 Refactoring, page 184 The Requirements Pit, page 202 Pragmatic Teams, page 224\n\nChallenges\n\nWhile reviewing a draft of this book, John Lakos raised the following is- sue: The soldiers progressively deceive the villagers, but the change they catalyze does them all good. However, by progressively deceiving the frog, you’re doing it harm. Can you determine whether you’re making stone soup or frog soup when you try to catalyze change? Is the decision subjec- tive or objective?\n\n4 Good-Enough Software\n\nStriving to better, oft we mar what’s well.\n\nKing Lear 1.4\n\nThere’s an old(ish) joke about a U.S. company that places an order for 100,000 integrated circuits with a Japanese manufacturer. Part of the speciﬁcation was the defect rate: one chip in 10,000. A few weeks later the order arrived: one large box containing thousands of ICs, and a small one containing just ten. Attached to the small box was a label that read: “These are the faulty ones.”\n\n9",
      "content_length": 1460,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 35,
      "content": "10\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nIf only we really had this kind of control over quality. But the real world just won’t let us produce much that’s truly perfect, particularly not bug-free software. Time, technology, and temperament all conspire against us.\n\nHowever, this doesn’t have to be frustrating. As Ed Yourdon described in an article in IEEE Software [You95], you can discipline yourself to write software that’s good enough—good enough for your users, for fu- ture maintainers, for your own peace of mind. You’ll ﬁnd that you are more productive and your users are happier. And you may well ﬁnd that your programs are actually better for their shorter incubation.\n\nBefore we go any further, we need to qualify what we’re about to say. The phrase “good enough” does not imply sloppy or poorly produced code. All systems must meet their users’ requirements to be success- ful. We are simply advocating that users be given an opportunity to participate in the process of deciding when what you’ve produced is good enough.\n\nInvolveYour UsersintheTrade-Off\n\nNormally you’re writing software for other people. Often you’ll remem- ber to get requirements from them.2 But how often do you ask them how good they want their software to be? Sometimes there’ll be no choice. If you’re working on pacemakers, the space shuttle, or a low- level library that will be widely disseminated, the requirements will be more stringent and your options more limited. However, if you’re working on a brand new product, you’ll have different constraints. The marketing people will have promises to keep, the eventual end users may have made plans based on a delivery schedule, and your company will certainly have cash-ﬂow constraints. It would be unprofessional to ignore these users’ requirements simply to add new features to the pro- gram, or to polish up the code just one more time. We’re not advocating panic: it is equally unprofessional to promise impossible time scales and to cut basic engineering corners to meet a deadline.\n\n2.\n\nThat was supposed to be a joke!",
      "content_length": 2063,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 36,
      "content": "GOOD-ENOUGH SOFTWARE\n\nThe scope and quality of the system you produce should be speciﬁed as part of that system’s requirements.\n\nTIP 7\n\nMake Quality a Requirements Issue\n\nOften you’ll be in situations where trade-offs are involved. Surprisingly, many users would rather use software with some rough edges today than wait a year for the multimedia version. Many IT departments with tight budgets would agree. Great software today is often preferable to perfect software tomorrow. If you give your users something to play with early, their feedback will often lead you to a better eventual solution (see Tracer Bullets, page 48).\n\nKnowWhentoStop In some ways, programming is like painting. You start with a blank canvas and certain basic raw materials. You use a combination of sci- ence, art, and craft to determine what to do with them. You sketch out an overall shape, paint the underlying environment, then ﬁll in the details. You constantly step back with a critical eye to view what you’ve done. Every now and then you’ll throw a canvas away and start again.\n\nBut artists will tell you that all the hard work is ruined if you don’t know when to stop. If you add layer upon layer, detail over detail, the painting becomes lost in the paint.\n\nDon’t spoil a perfectly good program by overembellishment and over- reﬁnement. Move on, and let your code stand in its own right for a while. It may not be perfect. Don’t worry: it could never be perfect. (In Chapter 6, page 171, we’ll discuss philosophies for developing code in an imperfect world.)\n\nRelated sections include: Tracer Bullets, page 48 The Requirements Pit, page 202 Pragmatic Teams, page 224 Great Expectations, page 255\n\n11",
      "content_length": 1686,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 37,
      "content": "5\n\n12\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nChallenges\n\nLook at the manufacturers of the software tools and operating systems that you use. Can you ﬁnd any evidence that these companies are comfortable shipping software they know is not perfect? As a user, would you rather (1) wait for them to get all the bugs out, (2) have complex software and accept some bugs, or (3) opt for simpler software with fewer defects?\n\nConsider the effect of modularization on the delivery of software. Will it take more or less time to get a monolithic block of software to the required quality compared with a system designed in modules? Can you ﬁnd com- mercial examples?\n\nYour Knowledge Portfolio\n\nAn investment in knowledge always pays the best interest.\n\nBenjamin Franklin\n\nAh, good old Ben Franklin—never at a loss for a pithy homily. Why, if we could just be early to bed and early to rise, we’d be great programmers— right? The early bird might get the worm, but what happens to the early worm?\n\nIn this case, though, Ben really hit the nail on the head. Your knowledge and experience are your most important professional assets.\n\nUnfortunately, they’re expiring assets.3 Your knowledge becomes out of date as new techniques, languages, and environments are developed. Changing market forces may render your experience obsolete or irrele- vant. Given the speed at which Web-years ﬂy by, this can happen pretty quickly.\n\nAs the value of your knowledge declines, so does your value to your company or client. We want to prevent this from ever happening.\n\n3. a warehouse full of bananas and a ticket to a ball game.\n\nAn expiring asset is something whose value diminishes over time. Examples include",
      "content_length": 1683,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 38,
      "content": "YOUR KNOWLEDGE PORTFOLIO\n\nYour KnowledgePortfolio We like to think of all the facts programmers know about computing, the application domains they work in, and all their experience as their Knowledge Portfolios. Managing a knowledge portfolio is very similar to managing a ﬁnancial portfolio:\n\n1. Serious investors invest regularly—as a habit.\n\n2. Diversiﬁcation is the key to long-term success.\n\n3. Smart investors balance their portfolios between conservative and\n\nhigh-risk, high-reward investments.\n\n4. Investors try to buy low and sell high for maximum return.\n\n5. Portfolios should be reviewed and rebalanced periodically.\n\nTo be successful in your career, you must manage your knowledge port- folio using these same guidelines.\n\nBuilding Your Portfolio\n\nInvest regularly. Just as in ﬁnancial investing, you must invest in your knowledge portfolio regularly. Even if it’s just a small amount, the habit itself is as important as the sums. A few sample goals are listed in the next section.\n\nDiversify. The more different things you know, the more valuable you are. As a baseline, you need to know the ins and outs of the particular technology you are working with currently. But don’t stop there. The face of computing changes rapidly—hot technology today may well be close to useless (or at least not in demand) to- morrow. The more technologies you are comfortable with, the better you will be able to adjust to change.\n\nTechnology exists along a spectrum from risky, Manage risk. potentially high-reward to low-risk, low-reward standards. It’s not a good idea to invest all of your money in high-risk stocks that might collapse suddenly, nor should you invest all of it conserva- tively and miss out on possible opportunities. Don’t put all your technical eggs in one basket.\n\n13",
      "content_length": 1788,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 39,
      "content": "14\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nBuy low, sell high. Learning an emerging technology before it be- comes popular can be just as hard as ﬁnding an undervalued stock, but the payoff can be just as rewarding. Learning Java when it ﬁrst came out may have been risky, but it paid off handsomely for the early adopters who are now at the top of that ﬁeld.\n\nReview and rebalance. This is a very dynamic industry. That hot technology you started investigating last month might be stone cold by now. Maybe you need to brush up on that database technology that you haven’t used in a while. Or perhaps you could be bet- ter positioned for that new job opening if you tried out that other language.. ..\n\nOf all these guidelines, the most important one is the simplest to do:\n\nTIP 8\n\nInvest Regularly in Your Knowledge Portfolio\n\nGoals Now that you have some guidelines on what and when to add to your knowledge portfolio, what’s the best way to go about acquiring intellec- tual capital with which to fund your portfolio? Here are a few sugges- tions.\n\nLearn at least one new language every year. Different languages solve the same problems in different ways. By learning several dif- ferent approaches, you can help broaden your thinking and avoid getting stuck in a rut. Additionally, learning many languages is far easier now, thanks to the wealth of freely available software on the Internet (see page 267).\n\nRead a technical book each quarter. Bookstores are full of techni- cal books on interesting topics related to your current project. Once you’re in the habit, read a book a month. After you’ve mastered the technologies you’re currently using, branch out and study some that don’t relate to your project.\n\nIt is important to remember that Read nontechnical books, too. computers are used by people—people whose needs you are trying to satisfy. Don’t forget the human side of the equation.",
      "content_length": 1892,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 40,
      "content": "YOUR KNOWLEDGE PORTFOLIO\n\nTake classes. Look for interesting courses at your local commu- nity college or university, or perhaps at the next trade show that comes to town.\n\nParticipate in local user groups. Don’t just go and listen, but actively participate. Isolation can be deadly to your career; ﬁnd out what people are working on outside of your company.\n\nIf you’ve worked only in Experiment with different environments. Windows, play with Unix at home (the freely available Linux is per- fect for this). If you’ve used only makefiles and an editor, try an IDE, and vice versa.\n\nStay current. Subscribe to trade magazines and other journals (see page 262 for recommendations). Choose some that cover tech- nology different from that of your current project.\n\nGet wired. Want to know the ins and outs of a new language or other technology? Newsgroups are a great way to ﬁnd out what experiences other people are having with it, the particular jargon they use, and so on. Surf the Web for papers, commercial sites, and any other sources of information you can ﬁnd.\n\nIt’s important to continue investing. Once you feel comfortable with some new language or bit of technology, move on. Learn another one.\n\nIt doesn’t matter whether you ever use any of these technologies on a project, or even whether you put them on your resume. The process of learning will expand your thinking, opening you to new possibilities and new ways of doing things. The cross-pollination of ideas is important; try to apply the lessons you’ve learned to your current project. Even if your project doesn’t use that technology, perhaps you can borrow some ideas. Get familiar with object orientation, for instance, and you’ll write plain C programs differently.\n\nOpportunities for Learning So you’re reading voraciously, you’re on top of all the latest breaking developments in your ﬁeld (not an easy thing to do), and somebody asks you a question. You don’t have the faintest idea what the answer is, and freely admit as much.\n\n15",
      "content_length": 2007,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 41,
      "content": "16\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nDon’t let it stop there. Take it as a personal challenge to ﬁnd the answer. Ask a guru. (If you don’t have a guru in your ofﬁce, you should be able to ﬁnd one on the Internet: see the box on on the facing page.) Search the Web. Go to the library.4\n\nIf you can’t ﬁnd the answer yourself, ﬁnd out who can. Don’t let it rest. Talking to other people will help build your personal network, and you may surprise yourself by ﬁnding solutions to other, unrelated problems along the way. And that old portfolio just keeps getting bigger. .. .\n\nAll of this reading and researching takes time, and time is already in short supply. So you need to plan ahead. Always have something to read in an otherwise dead moment. Time spent waiting for doctors and dentists can be a great opportunity to catch up on your reading—but be sure to bring your own magazine with you, or you might ﬁnd yourself thumbing through a dog-eared 1973 article about Papua New Guinea.\n\nCritical Thinking The last important point is to think critically about what you read and hear. You need to ensure that the knowledge in your portfolio is accurate and unswayed by either vendor or media hype. Beware of the zealots who insist that their dogma provides the only answer—it may or may not be applicable to you and your project.\n\nNever underestimate the power of commercialism. Just because a Web search engine lists a hit ﬁrst doesn’t mean that it’s the best match; the content provider can pay to get top billing. Just because a bookstore features a book prominently doesn’t mean it’s a good book, or even popular; they may have been paid to place it there.\n\nTIP 9\n\nCritically Analyze What You Read and Hear\n\nUnfortunately, there are very few simple answers anymore. But with your extensive portfolio, and by applying some critical analysis to the\n\n4. ﬁlled with research material and staff.\n\nIn this era of the Web, many people seem to have forgotten about real live libraries",
      "content_length": 1977,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 42,
      "content": "YOUR KNOWLEDGE PORTFOLIO\n\nCare and Cultivation of Gurus\n\nWith the global adoption of the Internet, gurus suddenly are as close as your Enter key. So, how do you ﬁnd one, and how do you get one to talk with you?\n\nWe ﬁnd there are some simple tricks.\n\nKnow exactly what you want to ask, and be as speciﬁc as you can be.\n\nFrame your question carefully and politely. Remember that you’re asking a favor; don’t seem to be demanding an answer.\n\nOnce you’ve framed your question, stop and look again for the answer. Pick out some keywords and search the Web. Look for appropriate FAQs (lists of frequently asked questions with an- swers).\n\nDecide if you want to ask publicly or privately. Usenet news- groups are wonderful meeting places for experts on just about any topic, but some people are wary of these groups’ public nature. Alternatively, you can always e-mail your guru directly. Either way, use a meaningful subject line. (“Need Help!!!” doesn’t cut it.)\n\nSit back and be patient. People are busy, and it may take days to get a speciﬁc answer.\n\nFinally, please be sure to thank anyone who responds to you. And if you see people asking questions youcan answer, play your part and participate.\n\ntorrent of technical publications you will read, you can understand the complex answers.\n\nChallenges\n\nStart learning a new language this week. Always programmed in C++? Try Smalltalk [URL 13] or Squeak [URL 14]. Doing Java? Try Eiffel [URL 10] or TOM [URL 15]. See page 267 for sources of other free compilers and environments.\n\nStart reading a new book (but ﬁnish this one ﬁrst!). If you are doing very detailed implementation and coding, read a book on design and architec- ture. If you are doing high-level design, read a book on coding techniques.\n\n17",
      "content_length": 1751,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 43,
      "content": "18\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nGet out and talk technology with people who aren’t involved in your cur- rent project, or who don’t work for the same company. Network in your company cafeteria, or maybe seek out fellow enthusiasts at a local user’s group meeting.\n\n6 Communicate!\n\nI believe that it is better to be looked over than it is to be overlooked.\n\nMae West, BelleoftheNineties, 1934\n\nMaybe we can learn a lesson from Ms. West. It’s not just what you’ve got, but also how you package it. Having the best ideas, the ﬁnest code, or the most pragmatic thinking is ultimately sterile unless you can com- municate with other people. A good idea is an orphan without effective communication.\n\nAs developers, we have to communicate on many levels. We spend hours in meetings, listening and talking. We work with end users, trying to understand their needs. We write code, which communicates our intentions to a machine and documents our thinking for future generations of developers. We write proposals and memos requesting and justifying resources, reporting our status, and suggesting new approaches. And we work daily within our teams to advocate our ideas, modify existing practices, and suggest new ones. A large part of our day is spent communicating, so we need to do it well.\n\nWe’ve put together a list of ideas that we ﬁnd useful.\n\nKnow WhatYou Want toSay Probably the most difﬁcult part of the more formal styles of commu- nication used in business is working out exactly what it is you want to say. Fiction writers plot out their books in detail before they start, but people writing technical documents are often happy to sit down at a keyboard, enter “1. Introduction,” and start typing whatever comes into their heads next.\n\nPlan what you want to say. Write an outline. Then ask yourself, “Does this get across whatever I’m trying to say?” Reﬁne it until it does.",
      "content_length": 1884,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 44,
      "content": "COMMUNICATE!\n\nThis approach is not just applicable to writing documents. When you’re faced with an important meeting or a phone call with a major client, jot down the ideas you want to communicate, and plan a couple of strategies for getting them across.\n\nKnow YourAudience You’re communicating only if you’re conveying information. To do that, you need to understand the needs, interests, and capabilities of your audience. We’ve all sat in meetings where a development geek glazes over the eyes of the vice president of marketing with a long monologue on the merits of some arcane technology. This isn’t communicating: it’s just talking, and it’s annoying.5\n\nForm a strong mental picture of your audience. The acrostic WISDOM, shown in Figure 1.1 on the following page, may help.\n\nSay you want to suggest a Web-based system to allow your end users to submit bug reports. You can present this system in many differ- ent ways, depending on your audience. End users will appreciate that they can submit bug reports 24 hours a day without waiting on the phone. Your marketing department will be able to use this fact to boost sales. Managers in the support department will have two reasons to be happy: fewer staff will be needed, and problem reporting will be automated. Finally, developers may enjoy getting experience with Web- based client-server technologies and a new database engine. By making the appropriate pitch to each group, you’ll get them all excited about your project.\n\nChooseYourMoment It’s six o’clock on Friday afternoon, following a week when the auditors have been in. Your boss’s youngest is in the hospital, it’s pouring rain outside, and the commute home is guaranteed to be a nightmare. This probably isn’t a good time to ask her for a memory upgrade for your PC.\n\nAs part of understanding what your audience needs to hear, you need to work out what their priorities are. Catch a manager who’s just been given a hard time by her boss because some source code got lost, and\n\n5.\n\nThe word annoy comes from the Old French enui, which also means “to bore.”\n\n19",
      "content_length": 2080,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 45,
      "content": "20\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nFigure 1.1. The WISDOM acrostic—understanding an audience\n\nWhat do you want them to learn?\n\nWhat is their interest in what you’ve got to say?\n\nHow sophisticated are they?\n\nHow much detail do they want?\n\nWhom do you want to own the information?\n\nHow can you motivate them to listen to you?\n\nyou’ll have a more receptive listener to your ideas on source code repos- itories. Make what you’re saying relevant in time, as well as in content. Sometimes all it takes is the simple question “Is this a good time to talk about...?”\n\nChoosea Style Adjust the style of your delivery to suit your audience. Some people want a formal “just the facts” brieﬁng. Others like a long, wide-ranging chat before getting down to business. When it comes to written docu- ments, some like to receive large bound reports, while others expect a simple memo or e-mail. If in doubt, ask.\n\nRemember, however, that you are half of the communication transac- tion. If someone says they need a paragraph describing something and you can’t see any way of doing it in less than several pages, tell them so. Remember, that kind of feedback is a form of communication, too.\n\nMake ItLookGood Your ideas are important. They deserve a good-looking vehicle to convey them to your audience.\n\nToo many developers (and their managers) concentrate solely on con- tent when producing written documents. We think this is a mistake. Any chef will tell you that you can slave in the kitchen for hours only to ruin your efforts with poor presentation.\n\nThere is no excuse today for producing poor-looking printed docu- ments. Modern word processors (along with layout systems such as LATEX and troff) can produce stunning output. You need to learn just a few basic commands. If your word processor supports style sheets, use",
      "content_length": 1815,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 46,
      "content": "COMMUNICATE!\n\nthem. (Your company may already have deﬁned style sheets that you can use.) Learn how to set page headers and footers. Look at the sam- ple documents included with your package to get ideas on style and layout. Check the spelling, ﬁrst automatically and then by hand. After awl, their are spelling miss steaks that the chequer can knot ketch.\n\nInvolveYourAudience We often ﬁnd that the documents we produce end up being less im- portant than the process we go through to produce them. If possible, involve your readers with early drafts of your document. Get their feed- back, and pick their brains. You’ll build a good working relationship, and you’ll probably produce a better document in the process.\n\nBea Listener There’s one technique that you must use if you want people to listen to you: listen to them. Even if this is a situation where you have all the information, even if this is a formal meeting with you standing in front of 20 suits—if you don’t listen to them, they won’t listen to you.\n\nEncourage people to talk by asking questions, or have them summarize what you tell them. Turn the meeting into a dialog, and you’ll make your point more effectively. Who knows, you might even learn some- thing.\n\nGetBack to People If you ask someone a question, you feel they’re impolite if they don’t respond. But how often do you fail to get back to people when they send you an e-mail or a memo asking for information or requesting some action? In the rush of everyday life, it’s easy to forget. Always respond to e-mails and voice mails, even if the response is simply “I’ll get back to you later.” Keeping people informed makes them far more forgiving of the occasional slip, and makes them feel that you haven’t forgotten them.\n\nTIP 10\n\nIt’s Both What You Say and the Way You Say It\n\nUnless you work in a vacuum, you need to be able to communicate. The more effective that communication, the more inﬂuential you become.\n\n21",
      "content_length": 1945,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 47,
      "content": "22\n\nCHAPTER 1 A PRAGMATIC PHILOSOPHY\n\nE-Mail Communication\n\nEverything we’ve said about communicating in writing applies equally to electronic mail. E-mail has evolved to the point where it is a main- stay of intra- and intercorporate communications. E-mail is used to discuss contracts, to settle disputes, and as evidence in court. But for some reason, people who would never send out a shabby paper document are happy to ﬂing nasty-looking e-mail around the world.\n\nOur e-mail tips are simple:\n\nProofread before you hit SEND.\n\nCheck the spelling.\n\nKeep the format simple. Some people read e-mail using propor- tional fonts, so the ASCII art pictures you laboriously created will look to them like hen-scratchings.\n\nUse rich-text or HTML formatted mail only if you know that all your recipients can read it. Plain text is universal.\n\nTry to keep quoting to a minimum. No one likes to receive back their own 100-line e-mail with “I agree” tacked on.\n\nIf you’re quoting other people’s e-mail, be sure to attribute it, and quote it inline (rather than as an attachment).\n\nDon’t ﬂame unless you want it to come back and haunt you later.\n\nCheck your list of recipients before sending. A recentWallStreet Journal article described an employee who took to distributing criticisms of his boss over departmental e-mail, without realizing that his boss was included on the distribution list.\n\nArchive and organize your e-mail—both the important stuff you receive and the mail you send.\n\nAs various Microsoft and Netscape employees discovered during the 1999 Department of Justice investigation, e-mail is forever. Try to give the same attention and care to e-mail as you would to any written memo or report.",
      "content_length": 1699,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 48,
      "content": "COMMUNICATE!\n\nSummary\n\nKnow what you want to say.\n\nKnow your audience.\n\nChoose your moment.\n\nChoose a style.\n\nMake it look good.\n\nInvolve your audience.\n\nBe a listener.\n\nGet back to people.\n\nRelated sections include:\n\nPrototypes and Post-it Notes, page 53 Pragmatic Teams, page 224\n\nChallenges\n\nThere are several good books that contain sections on communications within development teams [Bro95, McC95, DL99]. Make it a point to try to read all three over the next 18 months. In addition, the book Dinosaur Brains [Ber96] discusses the emotional baggage we all bring to the work environment.\n\nThe next time you have to give a presentation, or write a memo advocating some position, try working through the WISDOM acrostic on page 20 before you start. See if it helps you understand how to position what you say. If appropriate, talk to your audience afterward and see how accurate your assessment of their needs was.\n\n23",
      "content_length": 921,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 49,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 50,
      "content": "Chapter 2\n\nA Pragmatic Approach\n\nThere are certain tips and tricks that apply at all levels of software development, ideas that are almost axiomatic, and processes that are virtually universal. However, these approaches are rarely documented as such; you’ll mostly ﬁnd them written down as odd sentences in dis- cussions of design, project management, or coding.\n\nIn this chapter we’ll bring these ideas and processes together. The ﬁrst two sections, The Evils of Duplication and Orthogonality, are closely related. The ﬁrst warns you not to duplicate knowledge throughout your systems, the second not to split any one piece of knowledge across multiple system components.\n\nAs the pace of change increases, it becomes harder and harder to keep our applications relevant. In Reversibility, we’ll look at some techniques that help insulate your projects from their changing environment.\n\nThe next two sections are also related. In Tracer Bullets, we talk about a style of development that allows you to gather requirements, test designs, and implement code at the same time. If this sounds too good to be true, it is: tracer bullet developments are not always applicable. When they’re not, Prototypes and Post-it Notes shows you how to use prototyping to test architectures, algorithms, interfaces, and ideas.\n\nAs computer science slowly matures, designers are producing increas- ingly higher-level languages. While the compiler that accepts “make it so” hasn’t yet been invented, in Domain Languages we present some more modest suggestions that you can implement for yourself.\n\n25",
      "content_length": 1579,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 51,
      "content": "7\n\n26\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nFinally, we all work in a world of limited time and resources. You can survive both of these scarcities better (and keep your bosses happier) if you get good at working out how long things will take, which we cover in Estimating.\n\nBy keeping these fundamental principles in mind during development, you can write code that’s better, faster, and stronger. You can even make it look easy.\n\nThe Evils of Duplication\n\nGiving a computer two contradictory pieces of knowledge was Captain James T. Kirk’s preferred way of disabling a marauding artiﬁcial intel- ligence. Unfortunately, the same principle can be effective in bringing down your code.\n\nAs programmers, we collect, organize, maintain, and harness knowl- edge. We document knowledge in speciﬁcations, we make it come alive in running code, and we use it to provide the checks needed during testing.\n\nUnfortunately, knowledge isn’t stable. It changes—often rapidly. Your understanding of a requirement may change following a meeting with the client. The government changes a regulation and some business logic gets outdated. Tests may show that the chosen algorithm won’t work. All this instability means that we spend a large part of our time in maintenance mode, reorganizing and reexpressing the knowledge in our systems.\n\nMost people assume that maintenance begins when an application is released, that maintenance means ﬁxing bugs and enhancing features. We think these people are wrong. Programmers are constantly in main- tenance mode. Our understanding changes day by day. New require- ments arrive as we’re designing or coding. Perhaps the environment changes. Whatever the reason, maintenance is not a discrete activity, but a routine part of the entire development process.",
      "content_length": 1777,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 52,
      "content": "THE EVILS OF DUPLICATION\n\nWhen we perform maintenance, we have to ﬁnd and change the rep- resentations of things—those capsules of knowledge embedded in the application. The problem is that it’s easy to duplicate knowledge in the speciﬁcations, processes, and programs that we develop, and when we do so, we invite a maintenance nightmare—one that starts well before the application ships.\n\nWe feel that the only way to develop software reliably, and to make our developments easier to understand and maintain, is to follow what we call the DRY principle:\n\nEVERY PIECE OF KNOWLEDGE MUST HAVE A SINGLE, UNAMBIGU- OUS, AUTHORITATIVE REPRESENTATION WITHIN A SYSTEM.\n\nWhy do we call it DRY?\n\nTIP 11\n\nDRY—Don’t Repeat Yourself\n\nThe alternative is to have the same thing expressed in two or more places. If you change one, you have to remember to change the others, or, like the alien computers, your program will be brought to its knees by a contradiction. It isn’t a question of whether you’ll remember: it’s a question of when you’ll forget.\n\nYou’ll ﬁnd the DRY principle popping up time and time again through- out this book, often in contexts that have nothing to do with coding. We feel that it is one of the most important tools in the Pragmatic Pro- grammer’s tool box.\n\nIn this section we’ll outline the problems of duplication and suggest general strategies for dealing with it.\n\nHowDoes DuplicationArise? Most of the duplication we see falls into one of the following categories:\n\nImposed duplication. Developers feel they have no choice—the environment seems to require duplication.\n\nInadvertent duplication. Developers don’t realize that they are duplicating information.\n\n27",
      "content_length": 1682,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 53,
      "content": "28\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nImpatient duplication. Developers get lazy and duplicate because it seems easier.\n\nInterdeveloper duplication. Multiple people on a team (or on dif- ferent teams) duplicate a piece of information.\n\nLet’s look at these four i’s of duplication in more detail.\n\nImposedDuplication Sometimes, duplication seems to be forced on us. Project standards may require documents that contain duplicated information, or docu- ments that duplicate information in the code. Multiple target platforms each require their own programming languages, libraries, and devel- opment environments, which makes us duplicate shared deﬁnitions and procedures. Programming languages themselves require certain structures that duplicate information. We have all worked in situations where we felt powerless to avoid duplication. And yet often there are ways of keeping each piece of knowledge in one place, honoring the DRY principle, and making our lives easier at the same time. Here are some techniques:\n\nMultiple representations of information. At the coding level, we often need to have the same information represented in different forms. Maybe we’re writing a client-server application, using different lan- guages on the client and server, and need to represent some shared structure on both. Perhaps we need a class whose attributes mirror the schema of a database table. Maybe you’re writing a book and want to include excerpts of programs that you also will compile and test.\n\nWith a bit of ingenuity you can normally remove the need for dupli- cation. Often the answer is to write a simple ﬁlter or code generator. Structures in multiple languages can be built from a common metadata representation using a simple code generator each time the software is built (an example of this is shown in Figure 3.4, page 106). Class deﬁni- tions can be generated automatically from the online database schema, or from the metadata used to build the schema in the ﬁrst place. The code extracts in this book are inserted by a preprocessor each time we format the text. The trick is to make the process active: this cannot be a one-time conversion, or we’re back in a position of duplicating data.",
      "content_length": 2202,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 54,
      "content": "THE EVILS OF DUPLICATION\n\nDocumentation in code. Programmers are taught to comment their code: good code has lots of comments. Unfortunately, they are never taught why code needs comments: bad code requires lots of comments.\n\nThe DRY principle tells us to keep the low-level knowledge in the code, where it belongs, and reserve the comments for other, high-level expla- nations. Otherwise, we’re duplicating knowledge, and every change means changing both the code and the comments. The comments will inevitably become out of date, and untrustworthy comments are worse than no comments at all. (See It’s All Writing, page 248, for more infor- mation on comments.)\n\nDocumentation and code. You write documentation, then you write code. Something changes, and you amend the documentation and up- date the code. The documentation and code both contain representa- tions of the same knowledge. And we all know that in the heat of the moment, with deadlines looming and important clients clamoring, we tend to defer the updating of documentation.\n\nDave once worked on an international telex switch. Quite understand- ably, the client demanded an exhaustive test speciﬁcation and required that the software pass all tests on each delivery. To ensure that the tests accurately reﬂected the speciﬁcation, the team generated them programmatically from the document itself. When the client amended their speciﬁcation, the test suite changed automatically. Once the team convinced the client that the procedure was sound, generating accep- tance tests typically took only a few seconds.\n\nLanguage issues. Many languages impose considerable duplication in the source. Often this comes about when the language separates a module’s interface from its implementation. C and C++ have header ﬁles that duplicate the names and type information of exported vari- ables, functions, and (for C++) classes. Object Pascal even duplicates this information in the same ﬁle. If you are using remote procedure calls or CORBA [URL 29], you’ll duplicate interface information between the interface speciﬁcation and the code that implements it.\n\nThere is no easy technique for overcoming the requirements of a lan- guage. While some development environments hide the need for header ﬁles by generating them automatically, and Object Pascal allows you to abbreviate repeated function declarations, you are generally stuck with\n\n29",
      "content_length": 2399,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 55,
      "content": "30\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nwhat you’re given. At least with most language-based issues, a header ﬁle that disagrees with the implementation will generate some form of compilation or linkage error. You can still get things wrong, but at least you’ll be told about it fairly early on.\n\nThink also about comments in header and implementation ﬁles. There is absolutely no point in duplicating a function or class header com- ment between the two ﬁles. Use the header ﬁles to document interface issues, and the implementation ﬁles to document the nitty-gritty details that users of your code don’t need to know.\n\nInadvertentDuplication Sometimes, duplication comes about as the result of mistakes in the design.\n\nLet’s look at an example from the distribution industry. Say our anal- ysis reveals that, among other attributes, a truck has a type, a license number, and a driver. Similarly, a delivery route is a combination of a route, a truck, and a driver. We code up some classes based on this understanding.\n\nBut what happens when Sally calls in sick and we have to change drivers? Both Truck and DeliveryRoute contain a driver. Which one do we change? Clearly this duplication is bad. Normalize it according to the underlying business model—does a truck really have a driver as part of its underlying attribute set? Does a route? Or maybe there needs to be a third object that knits together a driver, a truck, and a route. Whatever the eventual solution, avoid this kind of unnormalized data.\n\nThere is a slightly less obvious kind of unnormalized data that occurs when we have multiple data elements that are mutually dependent. Let’s look at a class representing a line:\n\nclass Line {\n\npublic:\n\nPoint start; Point end; double length;\n\n};\n\nAt ﬁrst sight, this class might appear reasonable. A line clearly has a start and end, and will always have a length (even if it’s zero). But we",
      "content_length": 1895,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 56,
      "content": "THE EVILS OF DUPLICATION\n\nhave duplication. The length is deﬁned by the start and end points: change one of the points and the length changes. It’s better to make the length a calculated ﬁeld:\n\nclass Line {\n\npublic:\n\nPoint start; Point end; double length() { return start.distanceTo(end); }\n\n};\n\nLater on in the development process, you may choose to violate the DRY principle for performance reasons. Frequently this occurs when you need to cache data to avoid repeating expensive operations. The trick is to localize the impact. The violation is not exposed to the outside world: only the methods within the class have to worry about keeping things straight.\n\nclass Line {\n\nprivate:\n\nbool double length; Point start; Point end;\n\nchanged;\n\npublic:\n\nvoid setStart(Point p) { start = p; changed = true; } = p; changed = true; } void setEnd(Point p)\n\n{ end\n\nPoint getStart(void) Point getEnd(void)\n\n{ return start; } } { return end;\n\ndouble getLength() {\n\nif (changed) {\n\nlength = start.distanceTo(end); changed = false;\n\n} return length;\n\n}\n\n};\n\nThis example also illustrates an important issue for object-oriented lan- guages such as Java and C++. Where possible, always use accessor functions to read and write the attributes of objects.1 It will make it easier to add functionality, such as caching, in the future.\n\nThe use of accessor functions ties in with Meyer’s Uniform Access principle [Mey97b], 1. which states that “All services offered by a module should be available through a uni- form notation, which does not betray whether they are implemented through storage or through computation.”\n\n31",
      "content_length": 1604,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 57,
      "content": "32\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nImpatient Duplication Every project has time pressures—forces that can drive the best of us to take shortcuts. Need a routine similar to one you’ve written? You’ll be tempted to copy the original and make a few changes. Need a value to represent the maximum number of points? If I change the header ﬁle, the whole project will get rebuilt. Maybe I should just use a literal number here; and here; and here. Need a class like one in the Java runtime? The source is available, so why not just copy it and make the changes you need (license provisions notwithstanding)?\n\nIf you feel this temptation, remember the hackneyed aphorism “short cuts make for long delays.” You may well save some seconds now, but at the potential loss of hours later. Think about the issues surround- ing the Y2K ﬁasco. Many were caused by the laziness of developers not parameterizing the size of date ﬁelds or implementing centralized libraries of date services.\n\nImpatient duplication is an easy form to detect and handle, but it takes discipline and a willingness to spend time up front to save pain later.\n\nInterdeveloperDuplication On the other hand, perhaps the hardest type of duplication to detect and handle occurs between different developers on a project. Entire sets of functionality may be inadvertently duplicated, and that duplica- tion could go undetected for years, leading to maintenance problems. We heard ﬁrsthand of a U.S. state whose governmental computer sys- tems were surveyed for Y2K compliance. The audit turned up more than 10,000 programs, each containing its own version of Social Secu- rity number validation.\n\nAt a high level, deal with the problem by having a clear design, a strong technical project leader (see page 228 in Pragmatic Teams), and a well- understood division of responsibilities within the design. However, at the module level, the problem is more insidious. Commonly needed functionality or data that doesn’t fall into an obvious area of responsi- bility can get implemented many times over.\n\nWe feel that the best way to deal with this is to encourage active and frequent communication between developers. Set up forums to discuss common problems. (On past projects, we have set up private Usenet",
      "content_length": 2258,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 58,
      "content": "THE EVILS OF DUPLICATION\n\nnewsgroups to allow developers to exchange ideas and ask questions. This provides a nonintrusive way of communicating—even across mul- tiple sites—while retaining a permanent history of everything said.) Appoint a team member as the project librarian, whose job is to facil- itate the exchange of knowledge. Have a central place in the source tree where utility routines and scripts can be deposited. And make a point of reading other people’s source code and documentation, either informally or during code reviews. You’re not snooping—you’re learning from them. And remember, the access is reciprocal—don’t get twisted about other people poring (pawing?) through your code, either.\n\nTIP 12\n\nMake It Easy to Reuse\n\nWhat you’re trying to do is foster an environment where it’s easier to ﬁnd and reuse existing stuff than to write it yourself. If it isn’t easy, people won’t do it. And if you fail to reuse, you risk duplicating knowl- edge.\n\nRelated sections include: Orthogonality, page 34 Text Manipulation, page 99 Code Generators, page 102 Refactoring, page 184 Pragmatic Teams, page 224 Ubiquitous Automation, page 230 It’s All Writing, page 248\n\n33",
      "content_length": 1180,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 59,
      "content": "34\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\n8 Orthogonality\n\nOrthogonality is a critical concept if you want to produce systems that are easy to design, build, test, and extend. However, the concept of orthogonality is rarely taught directly. Often it is an implicit feature of various other methods and techniques you learn. This is a mistake. Once you learn to apply the principle of orthogonality directly, you’ll notice an immediate improvement in the quality of systems you pro- duce.\n\nWhat IsOrthogonality? “Orthogonality” is a term borrowed from geom- etry. Two lines are orthogonal if they meet at right angles, such as the axes on a graph. In vector terms, the two lines are independent. Move along one of the lines, and your position projected onto the other doesn’t change.\n\nmove parallel to X-axis\n\nno change on Y-axis\n\nIn computing, the term has come to signify a kind of independence or decoupling. Two or more things are orthogonal if changes in one do not affect any of the others. In a well-designed system, the database code will be orthogonal to the user interface: you can change the interface without affecting the database, and swap databases without changing the interface.\n\nBefore we look at the beneﬁts of orthogonal systems, let’s ﬁrst look at a system that isn’t orthogonal.\n\nA Nonorthogonal System You’re on a helicopter tour of the Grand Canyon when the pilot, who made the obvious mistake of eating ﬁsh for lunch, suddenly groans and faints. Fortunately, he left you hovering 100 feet above the ground. You rationalize that the collective pitch lever 2 controls overall lift, so lower-\n\n2. Helicopters have four basic controls. The cyclic is the stick you hold in your right hand. Move it, and the helicopter moves in the corresponding direction. Your left hand holds the collective pitch lever. Pull up on this and you increase the pitch on all the blades, generating lift. At the end of the pitch lever is the throttle. Finally you have two foot pedals, which vary the amount of tail rotor thrust and so help turn the helicopter.",
      "content_length": 2053,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 60,
      "content": "ORTHOGONALITY\n\ning it slightly will start a gentle descent to the ground. However, when you try it, you discover that life isn’t that simple. The helicopter’s nose drops, and you start to spiral down to the left. Suddenly you discover that you’re ﬂying a system where every control input has secondary effects. Lower the left-hand lever and you need to add compensating backward movement to the right-hand stick and push the right pedal. But then each of these changes affects all of the other controls again. Suddenly you’re juggling an unbelievably complex system, where every change impacts all the other inputs. Your workload is phenomenal: your hands and feet are constantly moving, trying to balance all the interacting forces.\n\nHelicopter controls are decidedly not orthogonal.\n\nBeneﬁtsof Orthogonality As the helicopter example illustrates, nonorthogonal systems are in- herently more complex to change and control. When components of any system are highly interdependent, there is no such thing as a local ﬁx.\n\nTIP 13\n\nEliminate Effects Between Unrelated Things\n\nWe want to design components that are self-contained: independent, and with a single, well-deﬁned purpose (what Yourdon and Constan- tine call cohesion [YC86]). When components are isolated from one another, you know that you can change one without having to worry about the rest. As long as you don’t change that component’s external interfaces, you can be comfortable that you won’t cause problems that ripple through the entire system.\n\nYou get two major beneﬁts if you write orthogonal systems: increased productivity and reduced risk.\n\nGainProductivity\n\nChanges are localized, so development time and testing time are reduced. It is easier to write relatively small, self-contained compo- nents than a single large block of code. Simple components can be\n\n35",
      "content_length": 1835,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 61,
      "content": "36\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\ndesigned, coded, unit tested, and then forgotten—there is no need to keep changing existing code as you add new code.\n\nAn orthogonal approach also promotes reuse. If components have speciﬁc, well-deﬁned responsibilities, they can be combined with new components in ways that were not envisioned by their original implementors. The more loosely coupled your systems, the easier they are to reconﬁgure and reengineer.\n\nThere is a fairly subtle gain in productivity when you combine dis- orthogonal components. Assume that one component does things. If they are orthogonal and tinct things and another does things. However, if the you combine them, the result does two components are not orthogonal, there will be overlap, and the result will do less. You get more functionality per unit effort by combining orthogonal components.\n\nReduce Risk An orthogonal approach reduces the risks inherent in any development.\n\nDiseased sections of code are isolated. If a module is sick, it is less likely to spread the symptoms around the rest of the system. It is also easier to slice it out and transplant in something new and healthy.\n\nThe resulting system is less fragile. Make small changes and ﬁxes to a particular area, and any problems you generate will be restricted to that area.\n\nAn orthogonal system will probably be better tested, because it will be easier to design and run tests on its components.\n\nYou will not be as tightly tied to a particular vendor, product, or platform, because the interfaces to these third-party components will be isolated to smaller parts of the overall development.\n\nLet’s look at some of the ways you can apply the principle of orthogo- nality to your work.\n\nProjectTeams Have you noticed how some project teams are efﬁcient, with everyone knowing what to do and contributing fully, while the members of other",
      "content_length": 1875,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 62,
      "content": "ORTHOGONALITY\n\nteams are constantly bickering and don’t seem able to get out of each other’s way?\n\nOften this is an orthogonality issue. When teams are organized with lots of overlap, members are confused about responsibilities. Every change needs a meeting of the entire team, because any one of them might be affected.\n\nHow do you organize teams into groups with well-deﬁned responsibili- ties and minimal overlap? There’s no simple answer. It depends partly on the project and your analysis of the areas of potential change. It also depends on the people you have available. Our preference is to start by separating infrastructure from application. Each major infrastructure component (database, communications interface, middleware layer, and so on) gets its own subteam. Each obvious division of application functionality is similarly divided. Then we look at the people we have (or plan to have) and adjust the groupings accordingly.\n\nYou can get an informal measure of the orthogonality of a project team’s structure. Simply see how many people need to be involved in dis- cussing each change that is requested. The larger the number, the less orthogonal the group. Clearly, an orthogonal team is more efﬁcient. (Having said this, we also encourage subteams to communicate con- stantly with each other.)\n\nDesign Most developers are familiar with the need to design orthogonal sys- tems, although they may use words such as modular, component-based, and layered to describe the process. Systems should be composed of a set of cooperating modules, each of which implements functionality independent of the others. Sometimes these components are organized into layers, each providing a level of abstraction. This layered approach is a powerful way to design orthogonal systems. Because each layer uses only the abstractions provided by the layers below it, you have great ﬂexibility in changing underlying implementations without affect- ing code. Layering also reduces the risk of runaway dependencies be- tween modules. You’ll often see layering expressed in diagrams such as Figure 2.1 on the next page.\n\nThere is an easy test for orthogonal design. Once you have your com- ponents mapped out, ask yourself: If I dramatically change the require-\n\n37",
      "content_length": 2256,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 63,
      "content": "38\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nFigure 2.1. Typical layer diagram\n\nUser Interface\n\nDatabase access\n\nReport engine\n\nBusiness logic\n\nApplication framework\n\nStandard C library\n\nOperating system\n\nments behind a particular function, how many modules are affected? In an orthogonal system, the answer should be “one.”3 Moving a button on a GUI panel should not require a change in the database schema. Adding context-sensitive help should not change the billing subsystem.\n\nLet’s consider a complex system for monitoring and controlling a heat- ing plant. The original requirement called for a graphical user interface, but the requirements were changed to add a voice response system with touchtone telephone control of the plant. In an orthogonally designed system, you would need to change only those modules associated with the user interface to handle this: the underlying logic of controlling the plant would remain unchanged. In fact, if you structure your system carefully, you should be able to support both interfaces with the same underlying code base. It’s Just a View, page 157, talks about writing de- coupled code using the Model-View-Controller (MVC) paradigm, which works well in this situation.\n\n3. In reality, this is naive. Unless you are remarkably lucky, most real-world require- ments changes will affect multiple functions in the system. However, if you analyze the change in terms of functions, each functional change should still ideally affect just one module.",
      "content_length": 1485,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 64,
      "content": "ORTHOGONALITY\n\nAlso ask yourself how decoupled your design is from changes in the real world. Are you using a telephone number as a customer identiﬁer? What happens when the phone company reassigns area codes? Don’t rely on the properties of things you can’t control.\n\nToolkitsand Libraries Be careful to preserve the orthogonality of your system as you introduce third-party toolkits and libraries. Choose your technologies wisely.\n\nWe once worked on a project that required that a certain body of Java code run both locally on a server machine and remotely on a client machine. The alternatives for distributing classes this way were RMI and CORBA. If a class were made remotely accessible using RMI, every call to a remote method in that class could potentially throw an excep- tion, which means that a naive implementation would require us to handle the exception whenever our remote classes were used. Using RMI here is clearly not orthogonal: code calling our remote classes should not have to be aware of their locations. The alternative—using CORBA—did not impose that restriction: we could write code that was unaware of our classes’ locations.\n\nWhen you bring in a toolkit (or even a library from other members of your team), ask yourself whether it imposes changes on your code that shouldn’t be there. If an object persistence scheme is transparent, then it’s orthogonal. If it requires you to create or access objects in a special way, then it’s not. Keeping such details isolated from your code has the added beneﬁt of making it easier to change vendors in the future.\n\nThe Enterprise Java Beans (EJB) system is an interesting example of orthogonality. In most transaction-oriented systems, the application code has to delineate the start and end of each transaction. With EJB, this information is expressed declaratively as metadata, outside any code. The same application code can run in different EJB transaction environments with no change. This is likely to be a model for many future environments.\n\nAnother interesting twist on orthogonality is Aspect-Oriented Program- ming (AOP), a research project at Xerox Parc ([KLM 97] and [URL 49]). AOP lets you express in one place behavior that would otherwise be distributed throughout your source code. For example, log messages\n\n39",
      "content_length": 2297,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 65,
      "content": "40\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nare normally generated by sprinkling explicit calls to some log function throughout your source. With AOP, you implement logging orthogonally to the things being logged. Using the Java version of AOP, you could write a log message when entering any method of class Fred by coding the aspect:\n\naspect Trace {\n\nadvise * Fred.*(..) {\n\nstatic before {\n\nLog.write(\"-> Entering \" + thisJoinPoint.methodName);\n\n}\n\n}\n\n}\n\nIf you weave this aspect into your code, trace messages will be gen- erated. If you don’t, you’ll see no messages. Either way, your original source is unchanged.\n\nCoding Every time you write code you run the risk of reducing the orthogonality of your application. Unless you constantly monitor not just what you are doing but also the larger context of the application, you might un- intentionally duplicate functionality in some other module, or express existing knowledge twice.\n\nThere are several techniques you can use to maintain orthogonality:\n\nKeep your code decoupled. Write shy code—modules that don’t reveal anything unnecessary to other modules and that don’t rely on other modules’ implementations. Try the Law of Demeter [LH89], which we discuss in Decoupling and the Law of Demeter, page 138. If you need to change an object’s state, get the object to do it for you. This way your code remains isolated from the other code’s imple- mentation and increases the chances that you’ll remain orthogonal.\n\nAvoid global data. Every time your code references global data, it ties itself into the other components that share that data. Even globals that you intend only to read can lead to trouble (for exam- ple, if you suddenly need to change your code to be multithreaded). In general, your code is easier to understand and maintain if you explicitly pass any required context into your modules. In object- oriented applications, context is often passed as parameters to",
      "content_length": 1927,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 66,
      "content": "ORTHOGONALITY\n\nobjects’ constructors. In other code, you can create structures con- taining the context and pass around references to them.\n\nThe Singleton pattern in Design Patterns [GHJV95] is a way of ensuring that there is only one instance of an object of a particular class. Many people use these singleton objects as a kind of global variable (particularly in languages, such as Java, that otherwise do not support the concept of globals). Be careful with singletons— they can also lead to unnecessary linkage.\n\nAvoid similar functions. Often you’ll come across a set of functions that all look similar—maybe they share common code at the start and end, but each has a different central algorithm. Duplicate code is a symptom of structural problems. Have a look at the Strategy pattern in Design Patterns for a better implementation.\n\nGet into the habit of being constantly critical of your code. Look for any opportunities to reorganize it to improve its structure and orthogonal- ity. This process is called refactoring, and it’s so important that we’ve dedicated a section to it (see Refactoring, page 184).\n\nTesting An orthogonally designed and implemented system is easier to test. Because the interactions between the system’s components are formal- ized and limited, more of the system testing can be performed at the individual module level. This is good news, because module level (or unit) testing is considerably easier to specify and perform than integra- tion testing. In fact, we suggest that every module have its own unit test built into its code, and that these tests be performed automatically as part of the regular build process (see Code That’s Easy to Test, page 189).\n\nBuilding unit tests is itself an interesting test of orthogonality. What does it take to build and link a unit test? Do you have to drag in a large percentage of the rest of the system just to get a test to compile or link? If so, you’ve found a module that is not well decoupled from the rest of the system.\n\nBug ﬁxing is also a good time to assess the orthogonality of the system as a whole. When you come across a problem, assess how localized\n\n41",
      "content_length": 2148,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 67,
      "content": "42\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nthe ﬁx is. Do you change just one module, or are the changes scat- tered throughout the entire system? When you make a change, does it ﬁx everything, or do other problems mysteriously arise? This is a good opportunity to bring automation to bear. If you use a source code con- trol system (and you will after reading Source Code Control, page 86), tag bug ﬁxes when you check the code back in after testing. You can then run monthly reports analyzing trends in the number of source ﬁles affected by each bug ﬁx.\n\nDocumentation Perhaps surprisingly, orthogonality also applies to documentation. The axes are content and presentation. With truly orthogonal documenta- tion, you should be able to change the appearance dramatically without changing the content. Modern word processors provide style sheets and macros that help (see It’s All Writing, page 248).\n\nLiving with Orthogonality Orthogonality is closely related to the DRY principle introduced on page 27. With DRY, you’re looking to minimize duplication within a system, whereas with orthogonality you reduce the interdependency among the system’s components. It may be a clumsy word, but if you use the prin- ciple of orthogonality, combined closely with the DRY principle, you’ll ﬁnd that the systems you develop are more ﬂexible, more understand- able, and easier to debug, test, and maintain.\n\nIf you’re brought into a project where people are desperately struggling to make changes, and where every change seems to cause four other things to go wrong, remember the nightmare with the helicopter. The project probably is not orthogonally designed and coded. It’s time to refactor.\n\nAnd, if you’re a helicopter pilot, don’t eat the ﬁsh\n\n.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26 Source Code Control, page 86 Design by Contract, page 109 Decoupling and the Law of Demeter, page 138",
      "content_length": 1898,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 68,
      "content": "ORTHOGONALITY\n\n43\n\nMetaprogramming, page 144 It’s Just a View, page 157 Refactoring, page 184 Code That’s Easy to Test, page 189 Evil Wizards, page 198 Pragmatic Teams, page 224 It’s All Writing, page 248\n\nChallenges\n\nConsider the difference between large GUI-oriented tools typically found on Windows systems and small but combinable command line utilities used at shell prompts. Which set is more orthogonal, and why? Which is easier to use for exactly the purpose for which it was intended? Which set is easier to combine with other tools to meet new challenges?\n\nC++ supports multiple inheritance, and Java allows a class to implement multiple interfaces. What impact does using these facilities have on orthog- onality? Is there a difference in impact between using multiple inheritance and multiple interfaces? Is there a difference between using delegation and using inheritance?\n\nExercises 1.\n\nYou are writing a class called Split, which splits input lines into ﬁelds. Which of the following two Java class signatures is the more orthogonal design?\n\nclass Split1 {\n\npublic Split1(InputStreamReader rdr) { ... public void readNextLine() throws IOException { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\nclass Split2 {\n\npublic Split2(String line) { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\n2. Which will lead to a more orthogonal design: modeless or modal dialog\n\nboxes?\n\n3. How about procedural languages versus object technology? Which results Answer on p. 280\n\n3. How about procedural languages versus object technology? Which results Answer on p. 280\n\nin a more orthogonal system?\n\nAnswer on p. 279",
      "content_length": 1680,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 69,
      "content": "9\n\n44\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nReversibility\n\nNothing is more dangerous than an idea if it’s the only one you have.\n\nEmil-Auguste Chartier, Propos surlareligion, 1938\n\nEngineers prefer simple, single solutions to problems. Math tests that are much more allow you to proclaim with great conﬁdence that comfortable than fuzzy, warm essays about the myriad causes of the French Revolution. Management tends to agree with the engineers: sin- gle, easy answers ﬁt nicely on spreadsheets and project plans.\n\nis today, If only the real world would cooperate! Unfortunately, while it may need to be tomorrow, and next week. Nothing is forever—and if you rely heavily on some fact, you can almost guarantee that it will change.\n\nThere is always more than one way to implement something, and there is usually more than one vendor available to provide a third-party prod- uct. If you go into a project hampered by the myopic notion that there is only one way to do it, you may be in for an unpleasant surprise. Many project teams have their eyes forcibly opened as the future unfolds:\n\n“But you said we’d use database XYZ! We are 85% done coding the project, we can’t change now!” the programmer protested. “Sorry, but our company decided to standardize on database PDQ instead—for all projects. It’s out of my hands. We’ll just have to recode. All of you will be working weekends until further notice.”\n\nChanges don’t have to be that Draconian, or even that immediate. But as time goes by, and your project progresses, you may ﬁnd yourself stuck in an untenable position. With every critical decision, the project team commits to a smaller target—a narrower version of reality that has fewer options.\n\nBy the time many critical decisions have been made, the target becomes so small that if it moves, or the wind changes direction, or a butterﬂy in Tokyo ﬂaps its wings, you miss.4 And you may miss by a huge amount.\n\n4. Take a nonlinear, or chaotic, system and apply a small change to one of its inputs. You may get a large and often unpredictable result. The clichéd butterﬂy ﬂapping its wings in Tokyo could be the start of a chain of events that ends up generating a tornado in Texas. Does this sound like any projects you know?",
      "content_length": 2229,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 70,
      "content": "REVERSIBILITY\n\nThe problem is that critical decisions aren’t easily reversible.\n\nOnce you decide to use this vendor’s database, or that architectural pattern, or a certain deployment model (client-server versus stand- alone, for instance), you are committed to a course of action that cannot be undone, except at great expense.\n\nReversibility Many of the topics in this book are geared to producing ﬂexible, adapt- able software. By sticking to their recommendations—especially the DRY principle (page 26), decoupling (page 138), and use of metadata (page 144)—we don’t have to make as many critical, irreversible de- cisions. This is a good thing, because we don’t always make the best decisions the ﬁrst time around. We commit to a certain technology only to discover we can’t hire enough people with the necessary skills. We lock in a certain third-party vendor just before they get bought out by their competitor. Requirements, users, and hardware change faster than we can get the software developed.\n\nSuppose you decide, early in the project, to use a relational database from vendor A. Much later, during performance testing, you discover that the database is simply too slow, but that the object database from vendor B is faster. With most conventional projects, you’d be out of luck. Most of the time, calls to third-party products are entangled throughout the code. But if you really abstracted the idea of a database out—to the point where it simply provides persistence as a service— then you have the ﬂexibility to change horses in midstream.\n\nSimilarly, suppose the project begins as a client-server model, but then, late in the game, marketing decides that servers are too expensive for some clients, and they want a stand-alone version. How hard would that be for you? Since it’s just a deployment issue, it shouldn’t take more than a few days. If it would take longer, then you haven’t thought about reversibility. The other direction is even more interesting. What if the stand-alone product you are making needs to be deployed in a client-server or n-tier fashion? That shouldn’t be hard either.\n\nThe mistake lies in assuming that any decision is cast in stone—and in not preparing for the contingencies that might arise. Instead of carving\n\n45",
      "content_length": 2263,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 71,
      "content": "46\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\ndecisions in stone, think of them more as being written in the sand at the beach. A big wave can come along and wipe them out at any time.\n\nTIP 14\n\nThere Are No Final Decisions\n\nFlexibleArchitecture While many people try to keep their code ﬂexible, you also need to think about maintaining ﬂexibility in the areas of architecture, deployment, and vendor integration.\n\nTechnologies such as CORBA can help insulate portions of a project from changes in development language or platform. Is the performance of Java on that platform not up to expectations? Recode the client in C++, and nothing else needs to change. Is the rules engine in C++ not ﬂexible enough? Switch over to a Smalltalk version. With a CORBA architecture, you have to take a hit only for the component you are replacing; the other components shouldn’t be affected.\n\nAre you developing for Unix? Which one? Do you have all of the porta- bility concerns addressed? Are you developing for a particular version of Windows? Which one—3.1, 95, 98, NT, CE, or 2000? How hard will it be to support other versions? If you keep decisions soft and pliable, it won’t be hard at all. If you have poor encapsulation, high coupling, and hard-coded logic or parameters in the code, it might be impossible.\n\nNot sure how marketing wants to deploy the system? Think about it up front and you can support a stand-alone, client-server, or n-tier model just by changing a conﬁguration ﬁle. We’ve written programs that do just that.\n\nNormally, you can simply hide a third-party product behind a well- deﬁned, abstract interface. In fact, we’ve always been able to do so on any project we’ve worked on. But suppose you couldn’t isolate it that cleanly. What if you had to sprinkle certain statements liberally throughout the code? Put that requirement in metadata, and use some automatic mechanism, such as Aspects (see page 39) or Perl, to insert the necessary statements into the code itself. Whatever mechanism you",
      "content_length": 1997,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 72,
      "content": "REVERSIBILITY\n\nuse, make it reversible. If something is added automatically, it can be taken out automatically as well.\n\nNo one knows what the future may hold, especially not us! So en- able your code to rock-n-roll: to “rock on” when it can, to roll with the punches when it must.\n\nRelated sections include:\n\nDecoupling and the Law of Demeter, page 138 Metaprogramming, page 144 It’s Just a View, page 157\n\nChallenges\n\nTime for a little quantum mechanics with Schrödinger’s cat. Suppose you have a cat in a closed box, along with a radioactive particle. The particle has exactly a 50% chance of ﬁssioning into two. If it does, the cat will be killed. If it doesn’t, the cat will be okay. So, is the cat dead or alive? According to Schrödinger, the correct answer is both. Every time a sub- nuclear reaction takes place that has two possible outcomes, the universe is cloned. In one, the event occurred, in the other it didn’t. The cat’s alive in one universe, dead in another. Only when you open the box do you know which universe you are in.\n\nNo wonder coding for the future is difﬁcult.\n\nBut think of code evolution along the same lines as a box full of Schrö- dinger’s cats: every decision results in a different version of the future. How many possible futures can your code support? Which ones are more likely? How hard will it be to support them when the time comes?\n\nDare you open the box?\n\n47",
      "content_length": 1401,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 73,
      "content": "10\n\n48\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nTracer Bullets\n\nReady, ﬁre, aim\n\nThere are two ways to ﬁre a machine gun in the dark.5 You can ﬁnd out exactly where your target is (range, elevation, and azimuth). You can determine the environmental conditions (temperature, humidity, air pressure, wind, and so on). You can determine the precise speci- ﬁcations of the cartridges and bullets you are using, and their inter- actions with the actual gun you are ﬁring. You can then use tables or a ﬁring computer to calculate the exact bearing and elevation of the barrel. If everything works exactly as speciﬁed, your tables are correct, and the environment doesn’t change, your bullets should land close to their target.\n\nOr you could use tracer bullets.\n\nTracer bullets are loaded at intervals on the ammo belt alongside reg- ular ammunition. When they’re ﬁred, their phosphorus ignites and leaves a pyrotechnic trail from the gun to whatever they hit. If the trac- ers are hitting the target, then so are the regular bullets.\n\nNot surprisingly, tracer bullets are preferred to the labor of calcula- tion. The feedback is immediate, and because they operate in the same environment as the real ammunition, external effects are minimized.\n\nThe analogy might be violent, but it applies to new projects, particularly when you’re building something that hasn’t been built before. Like the gunners, you’re trying to hit a target in the dark. Because your users have never seen a system like this before, their requirements may be vague. Because you may be using algorithms, techniques, languages, or libraries you aren’t familiar with, you face a large number of un- knowns. And because projects take time to complete, you can pretty much guarantee the environment you’re working in will change before you’re done.\n\nThe classic response is to specify the system to death. Produce reams of paper itemizing every requirement, tying down every unknown, and\n\nTo be pedantic, there are many ways of ﬁring a machine gun in the dark, including 5. closing your eyes and spraying out bullets. But this is an analogy, and we’re allowed to take liberties.",
      "content_length": 2132,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 74,
      "content": "TRACER BULLETS\n\nconstraining the environment. Fire the gun using dead reckoning. One big calculation up front, then shoot and hope.\n\nPragmatic Programmers, however, tend to prefer using tracer bullets.\n\nCodeThatGlowsintheDark Tracer bullets work because they operate in the same environment and under the same constraints as the real bullets. They get to the tar- get fast, so the gunner gets immediate feedback. And from a practical standpoint they’re a relatively cheap solution.\n\nTo get the same effect in code, we’re looking for something that gets us from a requirement to some aspect of the ﬁnal system quickly, visibly, and repeatably.\n\nTIP 15\n\nUse Tracer Bullets to Find the Target\n\nWe once undertook a complex client-server database marketing project. Part of its requirement was the ability to specify and execute temporal queries. The servers were a range of relational and specialized data- bases. The client GUI, written in Object Pascal, used a set of C libraries to provide an interface to the servers. The user’s query was stored on the server in a Lisp-like notation before being converted to optimized SQL just prior to execution. There were many unknowns and many different environments, and no one was too sure how the GUI should behave.\n\nThis was a great opportunity to use tracer code. We developed the framework for the front end, libraries for representing the queries, and a structure for converting a stored query into a database-speciﬁc query. Then we put it all together and checked that it worked. For that initial build, all we could do was submit a query that listed all the rows in a table, but it proved that the UI could talk to the libraries, the libraries could serialize and unserialize a query, and the server could generate SQL from the result. Over the following months we gradually ﬂeshed out this basic structure, adding new functionality by augmenting each component of the tracer code in parallel. When the UI added a new query type, the library grew and the SQL generation was made more sophisticated.\n\n49",
      "content_length": 2050,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 75,
      "content": "50\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nTracer code is not disposable: you write it for keeps. It contains all the error checking, structuring, documentation, and self-checking that any piece of production code has. It simply is not fully functional. However, once you have achieved an end-to-end connection among the compo- nents of your system, you can check how close to the target you are, adjusting if necessary. Once you’re on target, adding functionality is easy.\n\nTracer development is consistent with the idea that a project is never ﬁnished: there will always be changes required and functions to add. It is an incremental approach.\n\nThe conventional alternative is a kind of heavy engineering approach: code is divided into modules, which are coded in a vacuum. Modules are combined into subassemblies, which are then further combined, until one day you have a complete application. Only then can the appli- cation as a whole be presented to the user and tested.\n\nThe tracer code approach has many advantages:\n\nUsers get to see something working early. If you have success- fully communicated what you are doing (see Great Expectations, page 255), your users will know they are seeing something imma- ture. They won’t be disappointed by a lack of functionality; they’ll be ecstatic to see some visible progress toward their system. They also get to contribute as the project progresses, increasing their buy-in. These same users will likely be the people who’ll tell you how close to the target each iteration is.\n\nDevelopers build a structure to work in. The most daunting piece of paper is the one with nothing written on it. If you have worked out all the end-to-end interactions of your application, and have embodied them in code, then your team won’t need to pull as much out of thin air. This makes everyone more productive, and encour- ages consistency.\n\nYou have an integration platform. As the system is connected end-to-end, you have an environment to which you can add new pieces of code once they have been unit-tested. Rather than at- tempting a big-bang integration, you’ll be integrating every day (often many times a day). The impact of each new change is more apparent, and the interactions are more limited, so debugging and testing are faster and more accurate.",
      "content_length": 2288,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 76,
      "content": "TRACER BULLETS\n\nYou have something to demonstrate. Project sponsors and top brass have a tendency to want to see demos at the most inconve- nient times. With tracer code, you’ll always have something to show them.\n\nYou have a better feel for progress. In a tracer code development, developers tackle use cases one by one. When one is done, they move to the next. It is far easier to measure performance and to demonstrate progress to your user. Because each individual devel- opment is smaller, you avoid creating those monolithic blocks of code that are reported as 95% complete week after week.\n\nTracerBulletsDon’t AlwaysHit TheirTarget Tracer bullets show what you’re hitting. This may not always be the tar- get. You then adjust your aim until they’re on target. That’s the point.\n\nIt’s the same with tracer code. You use the technique in situations where you’re not 100% certain of where you’re going. You shouldn’t be surprised if your ﬁrst couple of attempts miss: the user says “that’s not what I meant,” or data you need isn’t available when you need it, or performance problems seem likely. Work out how to change what you’ve got to bring it nearer the target, and be thankful that you’ve used a lean development methodology. A small body of code has low inertia—it is easy and quick to change. You’ll be able to gather feed- back on your application and generate a new, more accurate version faster and at less cost than with any other method. And because every major application component is represented in your tracer code, your users can be conﬁdent that what they’re seeing is based on reality, not just a paper speciﬁcation.\n\nTracerCode versusPrototyping You might think that this tracer code concept is nothing more than prototyping under an aggressive name. There is a difference. With a prototype, you’re aiming to explore speciﬁc aspects of the ﬁnal system. With a true prototype, you will throw away whatever you lashed to- gether when trying out the concept, and recode it properly using the lessons you’ve learned.\n\nFor example, say you’re producing an application that helps shippers determine how to pack odd-sized boxes into containers. Among other\n\n51",
      "content_length": 2178,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 77,
      "content": "52\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nproblems, the user interface needs to be intuitive and the algorithms you use to determine optimal packing are very complex.\n\nYou could prototype a user interface for your end users in a GUI tool. You code only enough to make the interface responsive to user actions. Once they’ve agreed to the layout, you might throw it away and recode it, this time with the business logic behind it, using the target language. Similarly, you might want to prototype a number of algorithms that perform the actual packing. You might code functional tests in a high- level, forgiving language such as Perl, and code low-level performance tests in something closer to the machine. In any case, once you’d made your decision, you’d start again and code the algorithms in their ﬁnal environment, interfacing to the real world. This is prototyping, and it is very useful.\n\nThe tracer code approach addresses a different problem. You need to know how the application as a whole hangs together. You want to show your users how the interactions will work in practice, and you want to give your developers an architectural skeleton on which to hang code. In this case, you might construct a tracer consisting of a trivial imple- mentation of the container packing algorithm (maybe something like ﬁrst-come, ﬁrst-served) and a simple but working user interface. Once you have all the components in the application plumbed together, you have a framework to show your users and your developers. Over time, you add to this framework with new functionality, completing stubbed routines. But the framework stays intact, and you know the system will continue to behave the way it did when your ﬁrst tracer code was completed.\n\nThe distinction is important enough to warrant repeating. Prototyp- ing generates disposable code. Tracer code is lean but complete, and forms part of the skeleton of the ﬁnal system. Think of prototyping as the reconnaissance and intelligence gathering that takes place before a single tracer bullet is ﬁred.\n\nRelated sections include:\n\nGood-Enough Software, page 9 Prototypes and Post-it Notes, page 53 The Speciﬁcation Trap, page 217 Great Expectations, page 255",
      "content_length": 2198,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 78,
      "content": "11\n\nPROTOTYPES AND POST-IT NOTES\n\nPrototypes and Post-it Notes\n\nMany different industries use prototypes to try out speciﬁc ideas; pro- totyping is much cheaper than full-scale production. Car makers, for example, may build many different prototypes of a new car design. Each one is designed to test a speciﬁc aspect of the car—the aerodynamics, styling, structural characteristics, and so on. Perhaps a clay model will be built for wind tunnel testing, maybe a balsa wood and duct tape model will do for the art department, and so on. Some car companies take this a step further, and now do a great deal of modeling work on the computer, reducing costs even further. In this way, risky or uncer- tain elements can be tried out without committing to building the real item.\n\nWe build software prototypes in the same fashion, and for the same reasons—to analyze and expose risk, and to offer chances for correction at a greatly reduced cost. Like the car makers, we can target a prototype to test one or more speciﬁc aspects of a project.\n\nWe tend to think of prototypes as code-based, but they don’t always have to be. Like the car makers, we can build prototypes out of different materials. Post-it notes are great for prototyping dynamic things such as workﬂow and application logic. A user interface can be prototyped as a drawing on a whiteboard, as a nonfunctional mock-up drawn with a paint program, or with an interface builder.\n\nPrototypes are designed to answer just a few questions, so they are much cheaper and faster to develop than applications that go into pro- duction. The code can ignore unimportant details—unimportant to you at the moment, but probably very important to the user later on. If you are prototyping a GUI, for instance, you can get away with incorrect results or data. On the other hand, if you’re just investigating compu- tational or performance aspects, you can get away with a pretty poor GUI, or perhaps even no GUI at all.\n\nBut if you ﬁnd yourself in an environment where you cannot give up the details, then you need to ask yourself if you are really building a prototype at all. Perhaps a tracer bullet style of development would be more appropriate in this case (see Tracer Bullets, page 48).\n\n53",
      "content_length": 2238,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 79,
      "content": "54\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nThings toPrototype What sorts of things might you choose to investigate with a prototype? Anything that carries risk. Anything that hasn’t been tried before, or that is absolutely critical to the ﬁnal system. Anything unproven, exper- imental, or doubtful. Anything you aren’t comfortable with. You can prototype\n\nArchitecture\n\nNew functionality in an existing system\n\nStructure or contents of external data\n\nThird-party tools or components\n\nPerformance issues\n\nUser interface design\n\nPrototyping is a learning experience. Its value lies not in the code pro- duced, but in the lessons learned. That’s really the point of prototyping.\n\nTIP 16\n\nPrototype to Learn\n\nHowtoUsePrototypes When building a prototype, what details can you ignore?\n\nCorrectness. You may be able to use dummy data where appro- priate.\n\nCompleteness. The prototype may function only in a very limited sense, perhaps with only one preselected piece of input data and one menu item.\n\nRobustness. Error checking is likely to be incomplete or missing entirely. If you stray from the predeﬁned path, the prototype may crash and burn in a glorious display of pyrotechnics. That’s okay.\n\nIt is painful to admit this in print, but prototype code prob- Style. ably doesn’t have much in the way of comments or documenta- tion. You may produce reams of documentation as a result of your experience with the prototype, but comparatively very little on the prototype system itself.",
      "content_length": 1475,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 80,
      "content": "PROTOTYPES AND POST-IT NOTES\n\nSince a prototype should gloss over details, and focus in on speciﬁc aspects of the system being considered, you may want to implement prototypes using a very high-level language—higher than the rest of the project (maybe a language such as Perl, Python, or Tcl). A high- level scripting language lets you defer many details (including specify- ing data types) and still produce a functional (albeit incomplete or slow) piece of code.6 If you need to prototype user interfaces, investigate tools such as Tcl/Tk, Visual Basic, Powerbuilder, or Delphi.\n\nScripting languages work well as the “glue” to combine low-level pieces into new combinations. Under Windows, Visual Basic can glue together COM controls. More generally, you can use languages such as Perl and Python to bind together low-level C libraries—either by hand, or automatically with tools such as the freely available SWIG [URL 28]. Using this approach, you can rapidly assemble existing components into new conﬁgurations to see how things work.\n\nPrototypingArchitecture Many prototypes are constructed to model the entire system under con- sideration. As opposed to tracer bullets, none of the individual modules in the prototype system need to be particularly functional. In fact, you may not even need to code in order to prototype architecture—you can prototype on a whiteboard, with Post-it notes or index cards. What you are looking for is how the system hangs together as a whole, again de- ferring details. Here are some speciﬁc areas you may want to look for in the architectural prototype:\n\nAre the responsibilities of the major components well deﬁned and appropriate?\n\nAre the collaborations between major components well deﬁned?\n\nIs coupling minimized?\n\nCan you identify potential sources of duplication?\n\nAre interface deﬁnitions and constraints acceptable?\n\n6. stick to a language that is close in performance to the target language.\n\nIf you are investigating absolute (instead of relative) performance, you will need to\n\n55",
      "content_length": 2031,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 81,
      "content": "Answer on p. 280\n\n56\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nDoes every module have an access path to the data it needs during execution? Does it have that access when it needs it?\n\nThis last item tends to generate the most surprises and the most valu- able results from the prototyping experience.\n\nHowNotto Use Prototypes Before you embark on any code-based prototyping, make sure that everyone understands that you are writing disposable code. Prototypes can be deceptively attractive to people who don’t know that they are just prototypes. You must make it very clear that this code is disposable, incomplete, and unable to be completed.\n\nIt’s easy to become misled by the apparent completeness of a demon- strated prototype, and project sponsors or management may insist on deploying the prototype (or its progeny) if you don’t set the right expec- tations. Remind them that you can build a great prototype of a new car out of balsa wood and duct tape, but you wouldn’t try to drive it in rush-hour trafﬁc!\n\nIf you feel there is a strong possibility in your environment or culture that the purpose of prototype code may be misinterpreted, you may be better off with the tracer bullet approach. You’ll end up with a solid framework on which to base future development.\n\nWhen used properly, a prototype can save you huge amounts of time, money, pain, and suffering by identifying and correcting potential prob- lem spots early in the development cycle—the time when ﬁxing mis- takes is both cheap and easy.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Communicate!, page 18 Tracer Bullets, page 48 Great Expectations, page 255\n\nExercises 4. Marketing would like to sit down and brainstorm a few Web-page designs with you. They are thinking of clickable image maps to take you to other pages, and so on. But they can’t decide on a model for the image—maybe",
      "content_length": 1869,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 82,
      "content": "DOMAIN LANGUAGES\n\nit’s a car, or a phone, or a house. You have a list of target pages and content; they’d like to see a few prototypes. Oh, by the way, you have 15 minutes. What tools might you use?\n\n12 Domain Languages\n\nThe limits of language are the limits of one’s world.\n\nLudwig Wittgenstein\n\nComputer languages inﬂuence how you think about a problem, and how you think about communicating. Every language comes with a list of features—buzzwords such as static versus dynamic typing, early versus late binding, inheritance models (single, multiple, or none)—all of which may suggest or obscure certain solutions. Designing a solution with Lisp in mind will produce different results than a solution based on C-style thinking, and vice versa. Conversely, and we think more importantly, the language of the problem domain may also suggest a programming solution.\n\nWe always try to write code using the vocabulary of the application domain (see The Requirements Pit, page 210, where we suggest using a project glossary). In some cases, we can go to the next level and actually program using the vocabulary, syntax, and semantics—the language— of the domain.\n\nWhen you listen to users of a proposed system, they might be able to tell you exactly how the system should work:\n\nListen for transactions deﬁned by ABC Regulation 12.3 on a set of X.25 lines, translate them to XYZ Company’s format 43B, retransmit them on the satellite uplink, and store for future analysis.\n\nIf your users have a number of such well-bounded statements, you can invent a mini-language tailored to the application domain that ex- presses exactly what they want:\n\nFrom X25LINE1 (Format=ABC123) { Put TELSTAR1 (Format=XYZ43B); Store DB;\n\n}\n\n57",
      "content_length": 1717,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 83,
      "content": "58\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nThis language need not be executable. Initially, it could be simply a way of capturing the user’s requirements—a speciﬁcation. However, you may want to consider taking this a step further and actually imple- menting the language. Your speciﬁcation has become executable code.\n\nAfter you’ve written the application, the users give you a new require- ment: transactions with negative balances shouldn’t be stored, and should be sent back on the X.25 lines in the original format:\n\nFrom X25LINE1 (Format=ABC123) {\n\nif (ABC123.balance < 0) {\n\nPut X25LINE1 (Format=ABC123);\n\n} else {\n\nPut TELSTAR1 (Format=XYZ43B); Store DB;\n\n}\n\n}\n\nThat was easy, wasn’t it? With the proper support in place, you can pro- gram much closer to the application domain. We’re not suggesting that your end users actually program in these languages. Instead, you’re giving yourself a tool that lets you work closer to their domain.\n\nTIP 17\n\nProgram Close to the Problem Domain\n\nWhether it’s a simple language to conﬁgure and control an application program, or a more complex language to specify rules or procedures, we think you should consider ways of moving your project closer to the problem domain. By coding at a higher level of abstraction, you are free to concentrate on solving domain problems, and can ignore petty implementation details.\n\nRemember that there are many users of an application. There’s the end user, who understands the business rules and the required outputs. There are also secondary users: operations staff, conﬁguration and test managers, support and maintenance programmers, and future genera- tions of developers. Each of these users has their own problem domain, and you can generate mini-environments and languages for all of them.",
      "content_length": 1772,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 84,
      "content": "DOMAIN LANGUAGES\n\nDomain-Speciﬁc Errors\n\nIf you are writing in the problem domain, you can also perform domain-speciﬁc validation, reporting problems in terms your users can understand. Take our switching application on on the facing page. Suppose the user misspelled the format name:\n\nFrom X25LINE1 (Format=AB123)\n\nIf this happened in a standard, general-purpose programming lan- guage, you might receive a standard, general-purpose error mes- sage:\n\nSyntax error: undeclared identifier\n\nBut with a mini-language, you would instead be able to issue an error message using the vocabulary of the domain:\n\n\"AB123\" is not a format. Known formats are ABC123,\n\nXYZ43B, PDQB, and 42.\n\nImplementingaMini-Language At its simplest, a mini-language may be in a line-oriented, easily parsed format. In practice, we probably use this form more than any other. It can be parsed simply using switch statements, or using regular expressions in scripting languages such as Perl. The answer to Exercise 5 on page 281 shows a simple implementation in C.\n\nYou can also implement a more complex language, with a more formal syntax. The trick here is to deﬁne the syntax ﬁrst using a notation such as BNF.7 Once you have your grammar speciﬁed, it is normally trivial to convert it into the input syntax for a parser generator. C and C++ pro- grammers have been using yacc (or its freely available implementation, bison [URL 27]) for years. These programs are documented in detail in the book Lex and Yacc [LMB92]. Java programmers can try javaCC, which can be found at [URL 26]. The answer to Exercise 7 on page 282\n\n7. good book on compiler construction or parsing will cover BNF in (exhaustive) detail.\n\nBNF, or Backus-Naur Form, lets you specify context-free grammars recursively. Any\n\n59",
      "content_length": 1770,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 85,
      "content": "60\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nshows a parser written using bison. As it shows, once you know the syntax, it’s really not a lot of work to write simple mini-languages.\n\nThere’s another way of implementing a mini-language: extend an exist- ing one. For example, you could integrate application-level functionality with (say) Python [URL 9] and write something like8\n\nrecord = X25LINE1.get(format=ABC123) if (record.balance < 0):\n\nX25LINE1.put(record, format=ABC123)\n\nelse:\n\nTELSTAR1.put(record, format=XYZ43B) DB.store(record)\n\nData Languagesand ImperativeLanguages The languages you implement can be used in two different ways.\n\nData languages produce some form of data structure used by an ap- plication. These languages are often used to represent conﬁguration information.\n\nFor example, the sendmail program is used throughout the world for routing e-mail over the Internet. It has many excellent features and beneﬁts, which are controlled by a thousand-line conﬁguration ﬁle, written using sendmail’s own conﬁguration language:\n\nMlocal, P=/usr/bin/procmail,\n\nF=lsDFMAw5:/|@qSPfhn9, S=10/30, R=20/40, T=DNS/RFC822/X-Unix, A=procmail -Y -a $h -d $u\n\nObviously, readability is not one of sendmail’s strengths.\n\nFor years, Microsoft has been using a data language that can describe menus, widgets, dialog boxes, and other Windows resources. Figure 2.2 on the next page shows an excerpt from a typical resource ﬁle. This is far easer to read than the sendmail example, but it is used in exactly the same way—it is compiled to generate a data structure.\n\nImperative languages take this a step further. Here the language is actually executed, and so can contain statements, control constructs, and the like (such as the script on page 58).\n\n8.\n\nThanks to Eric Vought for this example.",
      "content_length": 1786,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 86,
      "content": "DOMAIN LANGUAGES\n\nFigure 2.2. Windows .rc ﬁle\n\nMAIN_MENU MENU {\n\nPOPUP \"&File\" {\n\nMENUITEM \"&New\", CM_FILENEW MENUITEM \"&Open...\", CM_FILEOPEN MENUITEM \"&Save\", CM_FILESAVE\n\n}\n\n}\n\nMY_DIALOG_BOX DIALOG 6, 15, 292, 287 STYLE DS_MODALFRAME | WS_POPUP | WS_VISIBLE | WS_CAPTION | WS_SYSMENU\n\nCAPTION \"My Dialog Box\" FONT 8, \"MS Sans Serif\" {\n\nDEFPUSHBUTTON \"OK\", ID_OK, 232, 16, 50, 14 PUSHBUTTON \"Help\", ID_HELP, 232, 52, 50, 14 CONTROL \"Edit Text Control\", ID_EDIT1,\n\n\"EDIT\", WS_BORDER | WS_TABSTOP, 16, 16, 80, 56\n\nCHECKBOX \"Checkbox\", ID_CHECKBOX1, 153, 65, 42, 38,\n\nBS_AUTOCHECKBOX | WS_TABSTOP\n\n}\n\nYou can also use your own imperative languages to ease program main- tenance. For example, you may be asked to integrate information from a legacy application into your new GUI development. A common way of achieving this is by screen scraping; your application connects to the mainframe application as if it were a regular human user, issuing keystrokes and “reading” the responses it gets back. You could script the interaction using a mini-language.9\n\nlocate prompt \"SSN:\" type \"%s\" social_security_number type enter\n\nwaitfor keyboardunlock\n\nif text_at(10,14) is \"INVALID SSN\" return bad_ssn if text_at(10,14) is \"DUPLICATE SSN\" return dup_ssn # etc...\n\nWhen the application determines it is time to enter a Social Security number, it invokes the interpreter on this script, which then controls\n\n9. In fact, you can buy tools that support just this kind of scripting. You can also inves- tigate open-source packages such as Expect, which provide similar capabilities [URL 24].\n\n61",
      "content_length": 1582,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 87,
      "content": "62\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nthe transaction. If the interpreter is embedded within the application, the two can even share data directly (for example, via a callback mech- anism).\n\nHere you’re programming in the maintenance programmer’s domain. When the mainframe application changes, and the ﬁelds move around, the programmer can simply update your high-level description, rather than groveling around in the details of C code.\n\nStand-Alone andEmbeddedLanguages A mini-language doesn’t have to be used directly by the application to be useful. Many times we may use a speciﬁcation language to create artifacts (including metadata) that are compiled, read-in, or otherwise used by the program itself (see Metaprogramming, page 144).\n\nFor example, on page 100 we describe a system in which we used Perl to generate a large number of derivations from an original schema speciﬁcation. We invented a common language to express the database schema, and then generated all the forms of it we needed—SQL, C, Web pages, XML, and others. The application didn’t use the speciﬁca- tion directly, but it relied on the output produced from it.\n\nIt is common to embed high-level imperative languages directly into your application, so that they execute when your code runs. This is clearly a powerful capability; you can change your application’s behav- ior by changing the scripts it reads, all without compiling. This can signiﬁcantly simplify maintenance in a dynamic application domain.\n\nEasy DevelopmentorEasyMaintenance? We’ve looked at several different grammars, ranging from simple line- oriented formats to more complex grammars that look like real lan- guages. Since it takes extra effort to implement, why would you choose a more complex grammar?\n\nThe trade-off is extendibility and maintenance. While the code for pars- ing a “real” language may be harder to write, it will be much easier for people to understand, and to extend in the future with new features and functionality. Languages that are too simple may be easy to parse, but can be cryptic—much like the sendmail example on page 60.",
      "content_length": 2100,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 88,
      "content": "DOMAIN LANGUAGES\n\n63\n\nGiven that most applications exceed their expected lifetimes, you’re probably better off biting the bullet and adopting the more complex and readable language up front. The initial effort will be repaid many times in reduced support and maintenance costs.\n\nRelated sections include:\n\nMetaprogramming, page 144\n\nChallenges\n\nCould some of the requirements of your current project be expressed in a domain-speciﬁc language? Would it be possible to write a compiler or translator that could generate most of the code required?\n\nIf you decide to adopt mini-languages as a way of programming closer to the problem domain, you’re accepting that some effort will be required to implement them. Can you see ways in which the framework you develop for one project can be reused in others?\n\nExercises 5. We want to implement a mini-language to control a simple drawing pack- age (perhaps a turtle-graphics system). The language consists of single- letter commands. Some commands are followed by a single number. For example, the following input would draw a rectangle.\n\nP 2 D W 2 N 1 E 2 S 1 U\n\n# select pen 2 # pen down # draw west 2cm # then north 1 # then east 2 # then back south # pen up\n\nImplement the code that parses this language. It should be designed so that it is simple to add new commands.\n\n6. Design a BNF grammar to parse a time speciﬁcation. All of the following Answer on p. 282\n\n6. Design a BNF grammar to parse a time speciﬁcation. All of the following Answer on p. 282\n\nexamples should be accepted.\n\n7.\n\nImplement a parser for the BNF grammar in Exercise 6 using yacc, bison, or a similar parser-generator.\n\n8.\n\nImplement the time parser using Perl. [Hint: Regular expressions make good parsers.]\n\nAnswer on p. 281\n\nAnswer on p. 282\n\nAnswer on p. 283",
      "content_length": 1782,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 89,
      "content": "64\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\n13 Estimating\n\nQuick! How long will it take to send WarandPeace over a 56k modem line? How much disk space will you need for a million names and addresses? How long does a 1,000-byte block take to pass through a router? How many months will it take to deliver your project?\n\nAt one level, these are all meaningless questions—they are all missing information. And yet they can all be answered, as long as you are com- fortable estimating. And, in the process of producing an estimate, you’ll come to understand more about the world your programs inhabit.\n\nBy learning to estimate, and by developing this skill to the point where you have an intuitive feel for the magnitudes of things, you will be able to show an apparent magical ability to determine their feasibility. When someone says “we’ll send the backup over an ISDN line to the central site,” you’ll be able to know intuitively whether this is practical. When you’re coding, you’ll be able to know which subsystems need optimizing and which ones can be left alone.\n\nTIP 18\n\nEstimate to Avoid Surprises\n\nAs a bonus, at the end of this section we’ll reveal the single correct answer to give whenever anyone asks you for an estimate.\n\nHowAccurateIsAccurateEnough? To some extent, all answers are estimates. It’s just that some are more accurate than others. So the ﬁrst question you have to ask yourself when someone asks you for an estimate is the context in which your answer will be taken. Do they need high accuracy, or are they looking for a ballpark ﬁgure?\n\nIf your grandmother asks when you will arrive, she’s probably won- dering whether to make you lunch or dinner. On the other hand, a diver trapped underwater and running out of air is probably inter- ested in an answer down to the second.",
      "content_length": 1792,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 90,
      "content": "ESTIMATING\n\nWhat’s the value of ? If you’re wondering how much edging to buy to put around a circular ﬂower bed, then “3” is probably good ” is a good approxima- enough.10 If you’re in school, then maybe “ tion. If you’re in NASA, then maybe 12 decimal places will do.\n\nOne of the interesting things about estimating is that the units you use make a difference in the interpretation of the result. If you say that something will take about 130 working days, then people will be expecting it to come in pretty close. However, if you say “Oh, about six months,” then they know to look for it any time between ﬁve and seven months from now. Both numbers represent the same duration, but “130 days” probably implies a higher degree of accuracy than you feel. We recommend that you scale time estimates as follows:\n\nDuration\n\nQuote estimate in\n\n1–15 days 3–8 weeks 8–30 weeks months 30+ weeks\n\ndays weeks\n\nthink hard before giving an estimate\n\nSo, if after doing all the necessary work, you decide that a project will take 125 working days (25 weeks), you might want to deliver an esti- mate of “about six months.”\n\nThe same concepts apply to estimates of any quantity: choose the units of your answer to reﬂect the accuracy you intend to convey.\n\nWhereDo EstimatesComeFrom? All estimates are based on models of the problem. But before we get too deeply into the techniques of building models, we have to mention a basic estimating trick that always gives good answers: ask someone who’s already done it. Before you get too committed to model building, cast around for someone who’s been in a similar situation in the past.\n\n“3” is also apparently good enough if you are a legislator. In 1897, Indiana State 10. Legislature House Bill No. 246 attempted to decree that henceforth should have the value of “3”. The Bill was tabled indeﬁnitely at its second reading when a mathematics professor pointed out that their powers did not quite extend to passing laws of nature.\n\n65",
      "content_length": 1968,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 91,
      "content": "66\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nSee how their problem got solved. It’s unlikely you’ll ever ﬁnd an exact match, but you’d be surprised how many times you can successfully draw on other’s experiences.\n\nUnderstand What’sBeing Asked The ﬁrst part of any estimation exercise is building an understanding of what’s being asked. As well as the accuracy issues discussed above, you need to have a grasp of the scope of the domain. Often this is implicit in the question, but you need to make it a habit to think about the scope before starting to guess. Often, the scope you choose will form part of the answer you give: “Assuming there are no trafﬁc accidents and there’s gas in the car, I should be there in 20 minutes.”\n\nBuild a ModeloftheSystem This is the fun part of estimating. From your understanding of the ques- tion being asked, build a rough and ready bare-bones mental model. If you’re estimating response times, your model may involve a server and some kind of arriving trafﬁc. For a project, the model may be the steps that your organization uses during development, along with a very rough picture of how the system might be implemented.\n\nModel building can be both creative and useful in the long term. Often, the process of building the model leads to discoveries of underlying patterns and processes that weren’t apparent on the surface. You may even want to reexamine the original question: “You asked for an esti- mate to do X. However, it looks like Y, a variant of X, could be done in about half the time, and you lose only one feature.”\n\nBuilding the model introduces inaccuracies into the estimating pro- cess. This is inevitable, and also beneﬁcial. You are trading off model simplicity for accuracy. Doubling the effort on the model may give you only a slight increase in accuracy. Your experience will tell you when to stop reﬁning.\n\nBreak theModelinto Components Once you have a model, you can decompose it into components. You’ll need to discover the mathematical rules that describe how these com- ponents interact. Sometimes a component contributes a single value",
      "content_length": 2092,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 92,
      "content": "ESTIMATING\n\nthat is added into the result. Some components may supply multiply- ing factors, while others may be more complicated (such as those that simulate the arrival of trafﬁc at a node).\n\nYou’ll ﬁnd that each component will typically have parameters that af- fect how it contributes to the overall model. At this stage, simply identify each parameter.\n\nGiveEachParametera Value Once you have the parameters broken out, you can go through and assign each one a value. You expect to introduce some errors in this step. The trick is to work out which parameters have the most impact on the result, and concentrate on getting them about right. Typically, parameters whose values are added into a result are less signiﬁcant than those that are multiplied or divided. Doubling a line speed may double the amount of data received in an hour, while adding a 5 ms transit delay will have no noticeable effect.\n\nYou should have a justiﬁable way of calculating these critical parame- ters. For the queuing example, you might want to measure the actual transaction arrival rate of the existing system, or ﬁnd a similar sys- tem to measure. Similarly, you could measure the current time taken to serve a request, or come up with an estimate using the techniques described in this section. In fact, you’ll often ﬁnd yourself basing an estimate on other subestimates. This is where your largest errors will creep in.\n\nCalculatetheAnswers Only in the simplest of cases will an estimate have a single answer. You might be happy to say “I can walk ﬁve cross-town blocks in 15 minutes.” However, as the systems get more complex, you’ll want to hedge your answers. Run multiple calculations, varying the values of the critical parameters, until you work out which ones really drive the model. A spreadsheet can be a big help. Then couch your answer in terms of these parameters. ”The response time is roughly three quarters of a second if the system has a SCSI bus and 64MB memory, and one second with 48MB memory.” (Notice how “three quarters of a second” conveys a different feeling of accuracy than 750 ms.)\n\n67",
      "content_length": 2100,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 93,
      "content": "68\n\nCHAPTER 2 A PRAGMATIC APPROACH\n\nDuring the calculation phase, you may start getting answers that seem strange. Don’t be too quick to dismiss them. If your arithmetic is cor- rect, your understanding of the problem or your model is probably wrong. This is valuable information.\n\nKeepTrack of YourEstimatingProwess We think it’s a great idea to record your estimates so you can see how close you were. If an overall estimate involved calculating subestimates, keep track of these as well. Often you’ll ﬁnd your estimates are pretty good—in fact, after a while, you’ll come to expect this.\n\nWhen an estimate turns out wrong, don’t just shrug and walk away. Find out why it differed from your guess. Maybe you chose some param- eters that didn’t match the reality of the problem. Maybe your model was wrong. Whatever the reason, take some time to uncover what hap- pened. If you do, your next estimate will be better.\n\nEstimating ProjectSchedules The normal rules of estimating can break down in the face of the com- plexities and vagaries of a sizable application development. We ﬁnd that often the only way to determine the timetable for a project is by gain- ing experience on that same project. This needn’t be a paradox if you practice incremental development, repeating the following steps.\n\nCheck requirements\n\nAnalyze risk\n\nDesign, implement, integrate\n\nValidate with the users\n\nInitially, you may have only a vague idea of how many iterations will be required, or how long they may be. Some methods require you to nail this down as part of the initial plan, but for all but the most trivial of projects this is a mistake. Unless you are doing an application similar to a previous one, with the same team and the same technology, you’d just be guessing.\n\nSo you complete the coding and testing of the initial functionality and mark this as the end of the ﬁrst increment. Based on that experience, you can reﬁne your initial guess on the number of iterations and what",
      "content_length": 1974,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 94,
      "content": "ESTIMATING\n\ncan be included in each. The reﬁnement gets better and better each time, and conﬁdence in the schedule grows along with it.\n\nTIP 19\n\nIterate the Schedule with the Code\n\nThis may not be popular with management, who typically want a sin- gle, hard-and-fast number before the project even starts. You’ll have to help them understand that the team, their productivity, and the envi- ronment will determine the schedule. By formalizing this, and reﬁning the schedule as part of each iteration, you’ll be giving them the most accurate scheduling estimates you can.\n\nWhattoSay WhenAsked for anEstimate You say “I’ll get back to you.”\n\nYou almost always get better results if you slow the process down and spend some time going through the steps we describe in this section. Estimates given at the coffee machine will (like the coffee) come back to haunt you.\n\nRelated sections include: Algorithm Speed, page 177\n\nChallenges\n\nStart keeping a log of your estimates. For each, track how accurate you turned out to be. If your error was greater than 50%, try to ﬁnd out where your estimate went wrong.\n\nExercises 9.\n\nYou are asked “Which has a higher bandwidth: a 1Mbps communications line or a person walking between two computers with a full 4GB tape in their pocket?” What constraints will you put on your answer to ensure that the scope of your response is correct? (For example, you might say that the time taken to access the tape is ignored.)\n\n10. So, which has the higher bandwidth?\n\n69\n\nAnswer on p. 283\n\nAnswer on p. 284",
      "content_length": 1531,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 95,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 96,
      "content": "Chapter 3\n\nThe Basic Tools\n\nEvery craftsman starts his or her journey with a basic set of good- quality tools. A woodworker might need rules, gauges, a couple of saws, some good planes, ﬁne chisels, drills and braces, mallets, and clamps. These tools will be lovingly chosen, will be built to last, will perform speciﬁc jobs with little overlap with other tools, and, perhaps most im- portantly, will feel right in the budding woodworker’s hands.\n\nThen begins a process of learning and adaptation. Each tool will have its own personality and quirks, and will need its own special handling. Each must be sharpened in a unique way, or held just so. Over time, each will wear according to use, until the grip looks like a mold of the woodworker’s hands and the cutting surface aligns perfectly with the angle at which the tool is held. At this point, the tools become conduits from the craftsman’s brain to the ﬁnished product—they have become extensions of his or her hands. Over time, the woodworker will add new tools, such as biscuit cutters, laser-guided miter saws, dovetail jigs— all wonderful pieces of technology. But you can bet that he or she will be happiest with one of those original tools in hand, feeling the plane sing as it slides through the wood.\n\nTools amplify your talent. The better your tools, and the better you know how to use them, the more productive you can be. Start with a basic set of generally applicable tools. As you gain experience, and as you come across special requirements, you’ll add to this basic set. Like the craftsman, expect to add to your toolbox regularly. Always be on the lookout for better ways of doing things. If you come across a situation where you feel your current tools can’t cut it, make a note to look for\n\n71",
      "content_length": 1766,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 97,
      "content": "72\n\nCHAPTER 3 THE BASIC TOOLS\n\nsomething different or more powerful that would have helped. Let need drive your acquisitions.\n\nMany new programmers make the mistake of adopting a single power tool, such as a particular integrated development environment (IDE), and never leave its cozy interface. This really is a mistake. We need to be comfortable beyond the limits imposed by an IDE. The only way to do this is to keep the basic tool set sharp and ready to use.\n\nIn this chapter we’ll talk about investing in your own basic toolbox. As with any good discussion on tools, we’ll start (in The Power of Plain Text) by looking at your raw materials, the stuff you’ll be shaping. From there we’ll move to the workbench, or in our case the computer. How can you use your computer to get the most out of the tools you use? We’ll discuss this in Shell Games. Now that we have material and a bench to work on, we’ll turn to the tool you’ll probably use more than any other, your editor. In Power Editing, we’ll suggest ways of making you more efﬁcient.\n\nTo ensure that we never lose any of our precious work, we should al- ways use a Source Code Control system—even for things such as our personal address book! And, since Mr. Murphy was really an optimist after all, you can’t be a great programmer until you become highly skilled at Debugging.\n\nYou’ll need some glue to bind much of the magic together. We discuss some possibilities, such as awk, Perl, and Python, in Text Manipulation.\n\nJust as woodworkers sometimes build jigs to guide the construction of complex pieces, programmers can write code that itself writes code. We discuss this in Code Generators.\n\nSpend time learning to use these tools, and at some point you’ll be sur- prised to discover your ﬁngers moving over the keyboard, manipulating text without conscious thought. The tools will have become extensions of your hands.",
      "content_length": 1885,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 98,
      "content": "14\n\nTHE POWER OF PLAIN TEXT\n\nThe Power of Plain Text\n\nAs Pragmatic Programmers, our base material isn’t wood or iron, it’s knowledge. We gather requirements as knowledge, and then express that knowledge in our designs, implementations, tests, and documents. And we believe that the best format for storing knowledge persistently is plain text. With plain text, we give ourselves the ability to manipulate knowledge, both manually and programmatically, using virtually every tool at our disposal.\n\nWhatIsPlainText? Plain text is made up of printable characters in a form that can be read and understood directly by people. For example, although the following snippet is made up of printable characters, it is meaningless.\n\nField19=467abe\n\nThe reader has no idea what the signiﬁcance of 467abe may be. A better choice would be to make it understandable to humans.\n\nDrawingType=UMLActivityDrawing\n\nPlain text doesn’t mean that the text is unstructured; XML, SGML, and HTML are great examples of plain text that has a well-deﬁned structure. You can do everything with plain text that you could do with some binary format, including versioning.\n\nPlain text tends to be at a higher level than a straight binary encoding, which is usually derived directly from the implementation. Suppose you wanted to store a property called uses_menus that can be either TRUE or FALSE. Using text, you might write this as\n\nmyprop.uses_menus=FALSE\n\nContrast this with 0010010101110101.\n\nThe problem with most binary formats is that the context necessary to understand the data is separate from the data itself. You are artiﬁcially divorcing the data from its meaning. The data may as well be encrypted; it is absolutely meaningless without the application logic to parse it. With plain text, however, you can achieve a self-describing data stream that is independent of the application that created it.\n\n73",
      "content_length": 1884,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 99,
      "content": "74\n\nCHAPTER 3 THE BASIC TOOLS\n\nTIP 20\n\nKeep Knowledge in Plain Text\n\nDrawbacks There are two major drawbacks to using plain text: (1) It may take more space to store than a compressed binary format, and (2) it may be computationally more expensive to interpret and process a plain text ﬁle.\n\nDepending on your application, either or both of these situations may be unacceptable—for example, when storing satellite telemetry data, or as the internal format of a relational database.\n\nBut even in these situations, it may be acceptable to store metadata about the raw data in plain text (see Metaprogramming, page 144).\n\nSome developers may worry that by putting metadata in plain text, they’re exposing it to the system’s users. This fear is misplaced. Binary data may be more obscure than plain text, but it is no more secure. If you worry about users seeing passwords, encrypt them. If you don’t want them changing conﬁguration parameters, include a secure hash1 of all the parameter values in the ﬁle as a checksum.\n\nThePowerof Text Since larger and slower aren’t the most frequently requested features from users, why bother with plain text? What are the beneﬁts?\n\nInsurance against obsolescence\n\nLeverage\n\nEasier testing\n\nInsurance AgainstObsolescence Human-readable forms of data, and self-describing data, will outlive all other forms of data and the applications that created them. Period.\n\n1. MD5 is often used for this purpose. For an excellent introduction to the wonderful world of cryptography, see [Sch95].",
      "content_length": 1519,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 100,
      "content": "THE POWER OF PLAIN TEXT\n\nAs long as the data survives, you will have a chance to be able to use it—potentially long after the original application that wrote it is defunct.\n\nYou can parse such a ﬁle with only partial knowledge of its format; with most binary ﬁles, you must know all the details of the entire format in order to parse it successfully.\n\nConsider a data ﬁle from some legacy system2 that you are given. You know little about the original application; all that’s important to you is that it maintained a list of clients’ Social Security numbers, which you need to ﬁnd and extract. Among the data, you see\n\n<FIELD10>123-45-6789</FIELD10> ... <FIELD10>567-89-0123</FIELD10> ... <FIELD10>901-23-4567</FIELD10>\n\nRecognizing the format of a Social Security number, you can quickly write a small program to extract that data—even if you have no infor- mation on anything else in the ﬁle.\n\nBut imagine if the ﬁle had been formatted this way instead:\n\nAC27123456789B11P ... XY43567890123QTYL ... 6T2190123456788AM\n\nYou may not have recognized the signiﬁcance of the numbers quite as easily. This is the difference between human readable and human understandable.\n\nWhile we’re at it, FIELD10 doesn’t help much either. Something like\n\n<SSNO>123-45-6789</SSNO>\n\nmakes the exercise a no-brainer—and ensures that the data will outlive any project that created it.\n\nLeverage Virtually every tool in the computing universe, from source code man- agement systems to compiler environments to editors and stand-alone ﬁlters, can operate on plain text.\n\n2.\n\nAll software becomes legacy as soon as it’s written.\n\n75",
      "content_length": 1608,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 101,
      "content": "76\n\nCHAPTER 3 THE BASIC TOOLS\n\nThe Unix Philosophy\n\nUnix is famous for being designed around the philosophy of small, sharp tools, each intended to do one thing well. This philosophy is enabled by using a common underlying format—the line-oriented, plain text ﬁle. Databases used for system administration (users and passwords, networking conﬁguration, and so on) are all kept as plain text ﬁles. (Some systems, such as Solaris, also maintain a binary form of certain databases as a performance optimization. The plain text version is kept as an interface to the binary version.)\n\nWhen a system crashes, you may be faced with only a minimal envi- ronment to restore it (you may not be able to access graphics drivers, for instance). Situations such as this can really make you appreciate the simplicity of plain text.\n\nFor instance, suppose you have a production deployment of a large application with a complex site-speciﬁc conﬁguration ﬁle (sendmail comes to mind). If this ﬁle is in plain text, you could place it under a source code control system (see Source Code Control, page 86), so that you automatically keep a history of all changes. File comparison tools such as diff and fc allow you to see at a glance what changes have been made, while sum allows you to generate a checksum to monitor the ﬁle for accidental (or malicious) modiﬁcation.\n\nEasierTesting If you use plain text to create synthetic data to drive system tests, then it is a simple matter to add, update, or modify the test data without having to create any special tools to do so. Similarly, plain text output from regression tests can be trivially analyzed (with diff, for instance) or subjected to more thorough scrutiny with Perl, Python, or some other scripting tool.\n\nLowestCommon Denominator Even in the future of XML-based intelligent agents that travel the wild and dangerous Internet autonomously, negotiating data interchange among themselves, the ubiquitous text ﬁle will still be there. In fact, in",
      "content_length": 1985,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 102,
      "content": "SHELL GAMES\n\nheterogeneous environments the advantages of plain text can outweigh all of the drawbacks. You need to ensure that all parties can communi- cate using a common standard. Plain text is that standard.\n\nRelated sections include:\n\nSource Code Control, page 86 Code Generators, page 102 Metaprogramming, page 144 Blackboards, page 165 Ubiquitous Automation, page 230 It’s All Writing, page 248\n\nChallenges\n\nDesign a small address book database (name, phone number, and so on) using a straightforward binary representation in your language of choice. Do this before reading the rest of this challenge.\n\n1. Translate that format into a plain text format using XML.\n\n2. For each version, add a new, variable-length ﬁeld called directions in\n\nwhich you might enter directions to each person’s house.\n\nWhat issues come up regarding versioning and extensibility? Which form was easier to modify? What about converting existing data?\n\n15 Shell Games\n\nEvery woodworker needs a good, solid, reliable workbench, somewhere to hold work pieces at a convenient height while he or she works them. The workbench becomes the center of the wood shop, the craftsman returning to it time and time again as a piece takes shape.\n\nFor a programmer manipulating ﬁles of text, that workbench is the command shell. From the shell prompt, you can invoke your full reper- toire of tools, using pipes to combine them in ways never dreamt of by their original developers. From the shell, you can launch applications, debuggers, browsers, editors, and utilities. You can search for ﬁles,\n\n77",
      "content_length": 1569,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 103,
      "content": "78\n\nCHAPTER 3 THE BASIC TOOLS\n\nquery the status of the system, and ﬁlter output. And by programming the shell, you can build complex macro commands for activities you perform often.\n\nFor programmers raised on GUI interfaces and integrated development environments (IDEs), this might seem an extreme position. After all, can’t you do everything equally well by pointing and clicking?\n\nThe simple answer is “no.” GUI interfaces are wonderful, and they can be faster and more convenient for some simple operations. Moving ﬁles, reading MIME-encoded e-mail, and typing letters are all things that you might want to do in a graphical environment. But if you do all your work using GUIs, you are missing out on the full capabilities of your environment. You won’t be able to automate common tasks, or use the full power of the tools available to you. And you won’t be able to combine your tools to create customized macro tools. A beneﬁt of GUIs is WYSIWYG—what you see is what you get. The disadvantage is WYSIAYG—what you see is all you get.\n\nGUI environments are normally limited to the capabilities that their designers intended. If you need to go beyond the model the designer provided, you are usually out of luck—and more often than not, you do need to go beyond the model. Pragmatic Programmers don’t just cut code, or develop object models, or write documentation, or automate the build process—we do all of these things. The scope of any one tool is usually limited to the tasks that the tool is expected to perform. For instance, suppose you need to integrate a code preprocessor (to implement design-by-contract, or multi-processing pragmas, or some such) into your IDE. Unless the designer of the IDE explicitly provided hooks for this capability, you can’t do it.\n\nYou may already be comfortable working from the command prompt, in which case you can safely skip this section. Otherwise, you may need to be convinced that the shell is your friend.\n\nAs a Pragmatic Programmer, you will constantly want to perform ad hoc operations—things that the GUI may not support. The command line is better suited when you want to quickly combine a couple of commands to perform a query or some other task. Here are a few examples.",
      "content_length": 2226,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 104,
      "content": "SHELL GAMES\n\nFindall.cﬁlesmodiﬁedmorerecently thanyourMakeﬁle.\n\nShell ... find . -name ’*.c’ -newer Makefile -print\n\nGUI..... Open the Explorer, navigate to the correct directory, click on the Makeﬁle, and note the modiﬁcation time. Then bring up Tools/Find, and enter *.c for the ﬁle speciﬁcation. Select the date tab, and enter the date you noted for the Makeﬁle in the ﬁrst date ﬁeld. Then hit OK.\n\nConstructazip/tararchiveofmysource.\n\nShell ... zip archive.zip *.h *.c\n\n– or –\n\ntar cvf archive.tar *.h *.c\n\nGUI..... Bring up a ZIP utility (such as the shareware WinZip [URL 41]), select “Create New Archive,” enter its name, select the source directory in the add dialog, set the ﬁlter to “*.c”, click “Add,” set the ﬁlter to “*.h”, click “Add,” then close the archive.\n\nWhichJavaﬁleshavenotbeenchangedinthelastweek?\n\nShell ... find . -name ’*.java’ -mtime +7 -print\n\nGUI..... Click and navigate to “Find ﬁles,” click the “Named” ﬁeld and type in “*.java”, select the “Date Modiﬁed” tab. Then select “Between.” Click on the starting date and type in the starting date of the beginning of the project. Click on the ending date and type in the date of a week ago today (be sure to have a calendar handy). Click on “Find Now.”\n\nOfthoseﬁles,whichusethe awt libraries?\n\nShell ... find . -name ’*.java’ -mtime +7 -print |\n\nxargs grep ’java.awt’\n\nGUI..... Load each ﬁle in the list from the previous example into an editor and search for the string “java.awt”. Write down the name of each ﬁle containing a match.\n\nClearly the list could go on. The shell commands may be obscure or terse, but they are powerful and concise. And, because shell commands can be combined into script ﬁles (or command ﬁles under Windows\n\n79",
      "content_length": 1715,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 105,
      "content": "80\n\nCHAPTER 3 THE BASIC TOOLS\n\nsystems), you can build sequences of commands to automate things you do often.\n\nTIP 21\n\nUse the Power of Command Shells\n\nGain familiarity with the shell, and you’ll ﬁnd your productivity soaring. Need to create a list of all the unique package names explicitly imported by your Java code? The following stores it in a ﬁle called “list.”\n\ngrep ’^import ’ *.java |\n\nsed -e’s/.*import *//’ -e’s/;.*$//’ | sort -u >list\n\nIf you haven’t spent much time exploring the capabilities of the com- mand shell on the systems you use, this might appear daunting. How- ever, invest some energy in becoming familiar with your shell and things will soon start falling into place. Play around with your command shell, and you’ll be surprised at how much more productive it makes you.\n\nShell UtilitiesandWindows Systems Although the command shells provided with Windows systems are im- proving gradually, Windows command-line utilities are still inferior to their Unix counterparts. However, all is not lost.\n\nCygnus Solutions has a package called Cygwin [URL 31]. As well as providing a Unix compatibility layer for Windows, Cygwin comes with a collection of more than 120 Unix utilities, including such favorites as ls, grep, and find. The utilities and libraries may be downloaded and used for free, but be sure to read their license.3 The Cygwin distribution comes with the Bash shell.\n\nThe GNU General Public License [URL 57] is a kind of legal virus that Open Source 3. developers use to protect their (and your) rights. You should spend some time reading it. In essence, it says that you can use and modify GPL’d software, but if you distribute any modiﬁcations they must be licensed according to the GPL (and marked as such), and you must make source available. That’s the virus part—whenever you derive a work from a GPL’d work, your derived work must also be GPL’d. However, it does not limit you in any way when simply using the tools—the ownership and licensing of software developed using the tools are up to you.",
      "content_length": 2039,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 106,
      "content": "SHELL GAMES\n\nUsing Unix Tools Under Windows\n\nWe love the availability of high-quality Unix tools under Windows, and use them daily. However, be aware that there are integration issues. Unlike their MS-DOS counterparts, these utilities are sensitive to the case of ﬁlenames, so ls a*.bat won’t ﬁnd AUTOEXEC.BAT. You may also come across problems with ﬁlenames containing spaces, and with differences in path separators. Finally, there are interesting problems when running MS-DOS programs that expect MS-DOS–style arguments under the Unix shells. For example, the Java utilities from JavaSoft use a colon as their CLASSPATH separator under Unix, but use a semicolon under MS-DOS. As a result, a Bash or ksh script that runs on a Unix box will run identically under Windows, but the command line it passes to Java will be interpreted incorrectly.\n\nAlternatively, David Korn (of Korn shell fame) has put together a pack- age called UWIN. This has the same aims as the Cygwin distribution—it is a Unix development environment under Windows. UWIN comes with a version of the Korn shell. Commercial versions are available from Global Technologies, Ltd. [URL 30]. In addition, AT&T allows free down- loading of the package for evaluation and academic use. Again, read their license before using.\n\nFinally, Tom Christiansen is (at the time of writing) putting together Perl Power Tools, an attempt to implement all the familiar Unix utilities portably, in Perl [URL 32].\n\nRelated sections include:\n\nUbiquitous Automation, page 230\n\nChallenges\n\nAre there things that you’re currently doing manually in a GUI? Do you ever pass instructions to colleagues that involve a number of individual “click this button,” “select this item” steps? Could these be automated?\n\nWhenever you move to a new environment, make a point of ﬁnding out what shells are available. See if you can bring your current shell with you.\n\nInvestigate alternatives to your current shell. If you come across a problem your shell can’t address, see if an alternative shell would cope better.\n\n81",
      "content_length": 2052,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 107,
      "content": "16\n\n82\n\nCHAPTER 3 THE BASIC TOOLS\n\nPower Editing\n\nWe’ve talked before about tools being an extension of your hand. Well, this applies to editors more than to any other software tool. You need to be able to manipulate text as effortlessly as possible, because text is the basic raw material of programming. Let’s look at some common features and functions that help you get the most from your editing environment.\n\nOne Editor We think it is better to know one editor very well, and use it for all edit- ing tasks: code, documentation, memos, system administration, and so on. Without a single editor, you face a potential modern day Babel of confusion. You may have to use the built-in editor in each language’s IDE for coding, and an all-in-one ofﬁce product for documentation, and maybe a different built-in editor for sending e-mail. Even the keystrokes you use to edit command lines in the shell may be different.4 It is difﬁ- cult to be proﬁcient in any of these environments if you have a different set of editing conventions and commands in each.\n\nYou need to be proﬁcient. Simply typing linearly and using a mouse to cut and paste is not enough. You just can’t be as effective that way or as you can with a powerful editor under your ﬁngers. Typing BACKSPACE ten times to move the cursor left to the beginning of a line isn’t as efﬁcient as typing a single key such as ^A, Home, or 0.\n\nTIP 22\n\nUse a Single Editor Well\n\nChoose an editor, know it thoroughly, and use it for all editing tasks. If you use a single editor (or set of keybindings) across all text editing activities, you don’t have to stop and think to accomplish text manip- ulation: the necessary keystrokes will be a reﬂex. The editor will be\n\n4. your editor. Bash, for instance, supports both vi and emacs keybindings.\n\nIdeally, the shell you use should have keybindings that match the ones used by",
      "content_length": 1871,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 108,
      "content": "POWER EDITING\n\nan extension of your hand; the keys will sing as they slice their way through text and thought. That’s our goal.\n\nMake sure that the editor you choose is available on all platforms you use. Emacs, vi, CRiSP, Brief, and others are available across multiple platforms, often in both GUI and non-GUI (text screen) versions.\n\nEditor Features Beyond whatever features you ﬁnd particularly useful and comfortable, here are some basic abilities that we think every decent editor should have. If your editor falls short in any of these areas, then this may be the time to consider moving on to a more advanced one.\n\nConﬁgurable. All aspects of the editor should be conﬁgurable to your preferences, including fonts, colors, window sizes, and key- stroke bindings (which keys perform what commands). Using only keystrokes for common editing operations is more efﬁcient than mouse or menu-driven commands, because your hands never leave the keyboard.\n\nExtensible. An editor shouldn’t be obsolete just because a new programming language comes out. It should be able to integrate with whatever compiler environment you are using. You should be able to “teach” it the nuances of any new language or text format (XML, HTML version 9, and so on).\n\nProgrammable. You should be able to program the editor to per- form complex, multistep tasks. This can be done with macros or with a built-in scripting programming language (Emacs uses a vari- ant of Lisp, for instance).\n\nIn addition, many editors support features that are speciﬁc to a partic- ular programming language, such as:\n\nSyntax highlighting\n\nAuto-completion\n\nAuto-indentation\n\nInitial code or document boilerplate\n\nTie-in to help systems\n\nIDE-like features (compile, debug, and so on)\n\n83",
      "content_length": 1746,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 109,
      "content": "84\n\nCHAPTER 3 THE BASIC TOOLS\n\nFigure 3.1. Sorting lines in an editor\n\nimport java.util.Vector; import java.util.Stack; import java.net.URL; import java.awt.*;\n\nemacs: M-xsort-lines\n\nimport java.awt.*; import java.net.URL; import java.util.Stack; import java.util.Vector;\n\nvi: :.,+3!sort\n\nA feature such as syntax highlighting may sound like a frivolous extra, but in reality it can be very useful and enhance your productivity. Once you get used to seeing keywords appear in a different color or font, a mistyped keyword that doesn’t appear that way jumps out at you long before you ﬁre up the compiler.\n\nHaving the ability to compile and navigate directly to errors within the editor environment is very handy on big projects. Emacs in particular is adept at this style of interaction.\n\nProductivity A surprising number of people we’ve met use the Windows notepad utility to edit their source code. This is like using a teaspoon as a shovel—simply typing and using basic mouse-based cut and paste is not enough.\n\nWhat sort of things will you need to do that can’t be done in this way?\n\nWell, there’s cursor movement, to start with. Single keystrokes that move you in units of words, lines, blocks, or functions are far more efﬁcient than repeatedly typing a keystroke that moves you character by character or line by line.\n\nOr suppose you are writing Java code. You like to keep your import statements in alphabetical order, and someone else has checked in a few ﬁles that don’t adhere to this standard (this may sound extreme, but on a large project it can save you a lot of time scanning through a long list of import statements). You’d like to go quickly through a few ﬁles and sort a small section of them. In editors such as vi and Emacs you can do this easily (see Figure 3.1). Try that in notepad.\n\nSome editors can help streamline common operations. For instance, when you create a new ﬁle in a particular language, the editor can supply a template for you. It might include:",
      "content_length": 1985,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 110,
      "content": "POWER EDITING\n\nName of the class or module ﬁlled in (derived from the ﬁlename)\n\nYour name and/or copyright statements\n\nSkeletons for constructs in that language (constructor and destruc- tor declarations, for example)\n\nAnother useful feature is auto-indenting. Rather than having to indent manually (by using space or tab), the editor automatically indents for you at the appropriate time (after typing an open brace, for example). The nice part about this feature is that you can use the editor to provide a consistent indentation style for your project.5\n\nWheretoGofromHere This sort of advice is particularly hard to write because virtually every reader is at a different level of comfort and expertise with the editor(s) they are currently using. So, to summarize, and to provide some guid- ance on where to go next, ﬁnd yourself in the left-hand column of the chart, and look at the right-hand column to see what we think you should do.\n\nIfthissoundslikeyou\n\nThen think about\n\nI use only basic features of manydifferenteditors.\n\nPick a powerful editor and learn it well.\n\nI have a favorite editor, but I don’tuseallofitsfeatures.\n\nLearn them. Cut down the number of keystrokes you need to type.\n\nI have a favorite editor and useitwherepossible.\n\nTry to expand and use it for more tasks than you do already.\n\nIthinkyouarenuts.Notepad isthebesteditorevermade.\n\nAs long as you are happy and produc- tive, go for it! But if you ﬁnd yourself subject to “editor envy,” you may need to reevaluate your position.\n\nThe Linux kernel is developed this way. Here you have geographically dispersed 5. developers, many working on the same pieces of code. There is a published list of settings (in this case, for Emacs) that describes the required indentation style.\n\n85",
      "content_length": 1760,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 111,
      "content": "86\n\nCHAPTER 3 THE BASIC TOOLS\n\nWhat Editors AreAvailable? Having recommended that you master a decent editor, which one do we recommend? Well, we’re going to duck that question; your choice of editor is a personal one (some would even say a religious one!). However, in Appendix A, page 266, we list a number of popular editors and where to get them.\n\nChallenges\n\nSome editors use full-blown languages for customization and scripting. Emacs, for example, uses Lisp. As one of the new languages you are going to learn this year, learn the language your editor uses. For anything you ﬁnd yourself doing repeatedly, develop a set of macros (or equivalent) to handle it.\n\nDo you know everything your editor is capable of doing? Try to stump your colleagues who use the same editor. Try to accomplish any given editing task in as few keystrokes as possible.\n\n17 Source Code Control\n\nProgress, far from consisting in change, depends on retentiveness. Those who cannot remember the past are condemned to repeat it.\n\nGeorge Santayana, LifeofReason\n\nOne of the important things we look for in a user interface is the UNDO key—a single button that forgives us our mistakes. It’s even better if the environment supports multiple levels of undo and redo, so you can go back and recover from something that happened a couple of minutes ago. But what if the mistake happened last week, and you’ve turned your computer on and off ten times since then? Well, that’s one of the many beneﬁts of using a source code control system: it’s a giant UNDO key—a project-wide time machine that can return you to those halcyon days of last week, when the code actually compiled and ran.\n\nSource code control systems, or the more widely scoped conﬁguration management systems, keep track of every change you make in your source code and documentation. The better ones can keep track of",
      "content_length": 1857,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 112,
      "content": "SOURCE CODE CONTROL\n\ncompiler and OS versions as well. With a properly conﬁgured source code control system, you can always go back to a previous version of your software.\n\nBut a source code control system (SCCS6) does far more than undo mistakes. A good SCCS will let you track changes, answering questions such as: Who made changes in this line of code? What’s the difference between the current version and last week’s? How many lines of code did we change in this release? Which ﬁles get changed most often? This kind of information is invaluable for bug-tracking, audit, performance, and quality purposes.\n\nAn SCCS will also let you identify releases of your software. Once iden- tiﬁed, you will always be able to go back and regenerate the release, independent of changes that may have occurred later.\n\nWe often use an SCCS to manage branches in the development tree. For example, once you have released some software, you’ll normally want to continue developing for the next release. At the same time, you’ll need to deal with bugs in the current release, shipping ﬁxed versions to clients. You’ll want these bug ﬁxes rolled into the next release (if appropriate), but you don’t want to ship code under development to clients. With an SCCS you can generate branches in the development tree each time you generate a release. You apply bug ﬁxes to code in the branch, and continue developing on the main trunk. Since the bug ﬁxes may be relevant to the main trunk as well, some systems allow you to merge selected changes from the branch back into the main trunk automatically.\n\nSource code control systems may keep the ﬁles they maintain in a cen- tral repository—a great candidate for archiving.\n\nFinally, some products may allow two or more users to be working concurrently on the same set of ﬁles, even making concurrent changes in the same ﬁle. The system then manages the merging of these changes when the ﬁles are sent back to the repository. Although seemingly risky, such systems work well in practice on projects of all sizes.\n\n6. We use the uppercase SCCS to refer to generic source code control systems. There is also a speciﬁc system called “sccs,” originally released with AT&T System V Unix.\n\n87",
      "content_length": 2215,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 113,
      "content": "88\n\nCHAPTER 3 THE BASIC TOOLS\n\nTIP 23\n\nAlways Use Source Code Control\n\nAlways. Even if you are a single-person team on a one-week project. Even if it’s a “throw-away” prototype. Even if the stuff you’re work- ing on isn’t source code. Make sure that everything is under source code control—documentation, phone number lists, memos to vendors, makeﬁles, build and release procedures, that little shell script that burns the CD master—everything. We routinely use source code con- trol on just about everything we type (including the text of this book). Even if we’re not working on a project, our day-to-day work is secured in a repository.\n\nSource CodeControland Builds There is a tremendous hidden beneﬁt in having an entire project under the umbrella of a source code control system: you can have product builds that are automatic and repeatable.\n\nThe project build mechanism can pull the latest source out of the repos- itory automatically. It can run in the middle of the night after everyone’s (hopefully) gone home. You can run automatic regression tests to en- sure that the day’s coding didn’t break anything. The automation of the build ensures consistency—there are no manual procedures, and you won’t need developers remembering to copy code into some special build area.\n\nThe build is repeatable because you can always rebuild the source as it existed on a given date.\n\nBut My TeamIsn’tUsingSource Code Control Shame on them! Sounds like an opportunity to do some evangelizing! However, while you wait for them to see the light, perhaps you should implement your own private source control. Use one of the freely avail- able tools we list in Appendix A, and make a point of keeping your personal work safely tucked into a repository (as well as doing what- ever your project requires). Although this may seem to be duplication of effort, we can pretty much guarantee it will save you grief (and save your project money) the ﬁrst time you need to answer questions such",
      "content_length": 1979,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 114,
      "content": "SOURCE CODE CONTROL\n\nas “What did you do to the xyz module?” and “What broke the build?” This approach may also help convince your management that source code control really works.\n\nDon’t forget that an SCCS is equally applicable to the things you do outside of work.\n\nSource Code Control Products Appendix A, page 271, gives URLs for representative source code control systems, some commercial and others freely available. And many more products are available—look for pointers to the conﬁguration manage- ment FAQ. For an introduction to the freely-available CVS version con- trol system, see our book Pragmatic Version Control [TH03].\n\nRelated sections include: Orthogonality, page 34 The Power of Plain Text, page 73 It’s All Writing, page 248\n\nChallenges\n\nEven if you are not able to use an SCCS at work, install RCS or CVS on a personal system. Use it to manage your pet projects, documents you write, and (possibly) conﬁguration changes applied to the computer system itself.\n\nTake a look at some of the Open Source projects for which publicly ac- cessible archives are available on the Web (such as Mozilla [URL 51], KDE [URL 54], and the Gimp [URL 55]). How do you get updates of the source? How do you make changes—does the project regulate access or arbitrate the inclusion of changes?\n\n89",
      "content_length": 1300,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 115,
      "content": "90\n\nCHAPTER 3 THE BASIC TOOLS\n\n18 Debugging\n\nIt is a painful thing To look at your own trouble and know That you yourself and no one else has made it\n\nSophocles, Ajax\n\nThe word bug has been used to describe an “object of terror” ever since the fourteenth century. Rear Admiral Dr. Grace Hopper, the inventor of COBOL, is credited with observing the ﬁrst computer bug—literally, a moth caught in a relay in an early computer system. When asked to explain why the machine wasn’t behaving as intended, a technician reported that there was “a bug in the system,” and dutifully taped it— wings and all—into the log book.\n\nRegrettably, we still have “bugs” in the system, albeit not the ﬂying kind. But the fourteenth century meaning—a bogeyman—is perhaps even more applicable now than it was then. Software defects mani- fest themselves in a variety of ways, from misunderstood requirements to coding errors. Unfortunately, modern computer systems are still limited to doing what you tell them to do, not necessarily what you want them to do.\n\nNo one writes perfect software, so it’s a given that debugging will take up a major portion of your day. Let’s look at some of the issues involved in debugging and some general strategies for ﬁnding elusive bugs.\n\nPsychology of Debugging Debugging itself is a sensitive, emotional subject for many developers. Instead of attacking it as a puzzle to be solved, you may encounter denial, ﬁnger pointing, lame excuses, or just plain apathy.\n\nEmbrace the fact that debugging is just problem solving, and attack it as such.\n\nHaving found someone else’s bug, you can spend time and energy lay- ing blame on the ﬁlthy culprit who created it. In some workplaces this is part of the culture, and may be cathartic. However, in the technical arena, you want to concentrate on ﬁxing the problem, not the blame.",
      "content_length": 1837,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 116,
      "content": "DEBUGGING\n\nTIP 24\n\nFix the Problem, Not the Blame\n\nIt doesn’t really matter whether the bug is your fault or someone else’s. It is still your problem.\n\nADebugging Mindset The easiest person to deceive is one’s self.\n\nEdward Bulwer-Lytton, TheDisowned\n\nBefore you start debugging, it’s important to adopt the right mindset. You need to turn off many of the defenses you use each day to protect your ego, tune out any project pressures you may be under, and get yourself comfortable. Above all, remember the ﬁrst rule of debugging:\n\nTIP 25\n\nDon’t Panic\n\nIt’s easy to get into a panic, especially if you are facing a deadline, or have a nervous boss or client breathing down your neck while you are trying to ﬁnd the cause of the bug. But it is very important to step back a pace, and actually think about what could be causing the symptoms that you believe indicate a bug.\n\nIf your ﬁrst reaction on witnessing a bug or seeing a bug report is “that’s impossible,” you are plainly wrong. Don’t waste a single neuron on the train of thought that begins “but that can’t happen” because quite clearly it can, and has.\n\nBeware of myopia when debugging. Resist the urge to ﬁx just the symp- toms you see: it is more likely that the actual fault may be several steps removed from what you are observing, and may involve a number of other related things. Always try to discover the root cause of a problem, not just this particular appearance of it.\n\nWheretoStart Before you start to look at the bug, make sure that you are work- ing on code that compiled cleanly—without warnings. We routinely set\n\n91",
      "content_length": 1591,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 117,
      "content": "92\n\nCHAPTER 3 THE BASIC TOOLS\n\ncompiler warning levels as high as possible. It doesn’t make sense to waste time trying to ﬁnd a problem that the compiler could ﬁnd for you! We need to concentrate on the harder problems at hand.\n\nWhen trying to solve any problem, you need to gather all the relevant data. Unfortunately, bug reporting isn’t an exact science. It’s easy to be misled by coincidences, and you can’t afford to waste time debugging coincidences. You ﬁrst need to be accurate in your observations.\n\nAccuracy in bug reports is further diminished when they come through a third party—you may actually need to watch the user who reported the bug in action to get a sufﬁcient level of detail.\n\nAndy once worked on a large graphics application. Nearing release, the testers reported that the application crashed every time they painted a stroke with a particular brush. The programmer responsible argued that there was nothing wrong with it; he had tried painting with it, and it worked just ﬁne. This dialog went back and forth for several days, with tempers rapidly rising.\n\nFinally, we got them together in the same room. The tester selected the brush tool and painted a stroke from the upper right corner to the lower left corner. The application exploded. \"Oh,\" said the programmer, in a small voice, who then sheepishly admitted that he had made test strokes only from the lower left to the upper right, which did not expose the bug.\n\nThere are two points to this story:\n\nYou may need to interview the user who reported the bug in order to gather more data than you were initially given.\n\nArtiﬁcial tests (such as the programmer’s single brush stroke from bottom to top) don’t exercise enough of an application. You must brutally test both boundary conditions and realistic end-user usage patterns. You need to do this systematically (see Ruthless Testing, page 237).\n\nDebugging Strategies Once you think you know what is going on, it’s time to ﬁnd out what the program thinks is going on.",
      "content_length": 2000,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 118,
      "content": "DEBUGGING\n\nBug Reproduction\n\nNo, our bugs aren’t really multiplying (although some of them are probably old enough to do it legally). We’re talking about a different kind of reproduction.\n\nThe best way to start ﬁxing a bug is to make it reproducible. After all, if you can’t reproduce it, how will you know if it is ever ﬁxed?\n\nBut we want more than a bug that can be reproduced by following some long series of steps; we want a bug that can be reproduced with a singlecommand. It’s a lot harder to ﬁx a bug if you have to go through 15 steps to get to the point where the bug shows up. Some- times by forcing yourself to isolate the circumstances that display the bug, you’ll even gain an insight on how to ﬁx it.\n\nSee Ubiquitous Automation, page 230, for other ideas along these lines.\n\nVisualizeYourData Often, the easiest way to discern what a program is doing—or what it is going to do—is to get a good look at the data it is operating on. The simplest example of this is a straightforward “variable name = data value” approach, which may be implemented as printed text, or as ﬁelds in a GUI dialog box or list.\n\nBut you can gain a much deeper insight into your data by using a debugger that allows you to visualize your data and all of the inter- relationships that exist. There are debuggers that can represent your data as a 3D ﬂy-over through a virtual reality landscape, or as a 3D waveform plot, or just as simple structural diagrams, as shown in Fig- ure 3.2 on the next page. As you single-step through your program, pictures like these can be worth much more than a thousand words, as the bug you’ve been hunting suddenly jumps out at you.\n\nEven if your debugger has limited support for visualizing data, you can still do it yourself—either by hand, with paper and pencil, or with external plotting programs.\n\nThe DDD debugger has some visualization capabilities, and is freely available (see [URL 19]). It is interesting to note that DDD works with\n\n93",
      "content_length": 1967,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 119,
      "content": "94\n\nCHAPTER 3 THE BASIC TOOLS\n\nFigure 3.2. Sample debugger diagram of a circular linked list. The arrows repre-\n\nsent pointers to nodes.\n\n1: list (List *) 0x804db40\n\nnext\n\nvalue = 85 self = 0x804db40 next = 0x804db50\n\nvalue = 86 self = 0x804db50 next = 0x804db40\n\nnext\n\nmultiple languages, including Ada, C, C++, Fortran, Java, Modula, Pas- cal, Perl, and Python (clearly an orthogonal design).\n\nTracing Debuggers generally focus on the state of the program now. Sometimes you need more—you need to watch the state of a program or a data structure over time. Seeing a stack trace can only tell you how you got here directly. It can’t tell you what you were doing prior to this call chain, especially in event-based systems.\n\nTracing statements are those little diagnostic messages you print to the screen or to a ﬁle that say things such as “got here” and “value of x = 2.” It’s a primitive technique compared with IDE-style debuggers, but it is peculiarly effective at diagnosing several classes of errors that debuggers can’t. Tracing is invaluable in any system where time itself is a factor: concurrent processes, real-time systems, and event-based applications.\n\nYou can use tracing statements to “drill down” into the code. That is, you can add tracing statements as you descend the call tree.\n\nTrace messages should be in a regular, consistent format; you may want to parse them automatically. For instance, if you needed to track down a resource leak (such as unbalanced ﬁle opens/closes), you could trace each open and each close in a log ﬁle. By processing the log",
      "content_length": 1574,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 120,
      "content": "DEBUGGING\n\nCorrupt Variables? Check Their Neighborhood\n\nSometimes you’ll examine a variable, expecting to see a small integer value, and instead get something like 0x6e69614d. Before you roll up your sleeves for some serious debugging, have a quick look at the memory around this corrupted variable. Often it will give you a clue. In our case, examining the surrounding memory as characters shows us\n\n20333231 6e69614d 2c745320 746f4e0a S t , n N o t 2c6e776f 2058580a 31323433 00000a33 3 n 0 0\n\n1 2 3\n\nM a i n\n\no w n , n X X\n\n3 4 2 1\n\nLooks like someone sprayed a street address over our counter. Now we know where to look.\n\nﬁle with Perl, you could easily identify where the offending open was occurring.\n\nRubberDucking A very simple but particularly useful technique for ﬁnding the cause of a problem is simply to explain it to someone else. The other person should look over your shoulder at the screen, and nod his or her head constantly (like a rubber duck bobbing up and down in a bathtub). They do not need to say a word; the simple act of explaining, step by step, what the code is supposed to do often causes the problem to leap off the screen and announce itself.7\n\nIt sounds simple, but in explaining the problem to another person you must explicitly state things that you may take for granted when go- ing through the code yourself. By having to verbalize some of these assumptions, you may suddenly gain new insight into the problem.\n\n7. Why “rubber ducking”? While an undergraduate at Imperial College in London, Dave did a lot of work with a research assistant named Greg Pugh, one of the best developers Dave has known. For several months Greg carried around a small yellow rubber duck, which he’d place on his terminal while coding. It was a while before Dave had the courage to ask. . . .\n\n95",
      "content_length": 1811,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 121,
      "content": "96\n\nCHAPTER 3 THE BASIC TOOLS\n\nProcessof Elimination In most projects, the code you are debugging may be a mixture of appli- cation code written by you and others on your project team, third-party products (database, connectivity, graphical libraries, specialized com- munications or algorithms, and so on) and the platform environment (operating system, system libraries, and compilers).\n\nIt is possible that a bug exists in the OS, the compiler, or a third-party product—but this should not be your ﬁrst thought. It is much more likely that the bug exists in the application code under development. It is generally more proﬁtable to assume that the application code is incorrectly calling into a library than to assume that the library itself is broken. Even if the problem does lie with a third party, you’ll still have to eliminate your code before submitting the bug report.\n\nWe worked on a project where a senior engineer was convinced that the select system call was broken on Solaris. No amount of persuasion or logic could change his mind (the fact that every other networking appli- cation on the box worked ﬁne was irrelevant). He spent weeks writing work-arounds, which, for some odd reason, didn’t seem to ﬁx the prob- lem. When ﬁnally forced to sit down and read the documentation on select, he discovered the problem and corrected it in a matter of min- utes. We now use the phrase “select is broken” as a gentle reminder whenever one of us starts blaming the system for a fault that is likely to be our own.\n\nTIP 26\n\n“select” Isn’t Broken\n\nRemember, if you see hoof prints, think horses—not zebras. The OS is probably not broken. And the database is probably just ﬁne.\n\nIf you “changed only one thing” and the system stopped working, that one thing was likely to be responsible, directly or indirectly, no matter how farfetched it seems. Sometimes the thing that changed is outside of your control: new versions of the OS, compiler, database, or other third- party software can wreak havoc with previously correct code. New bugs might show up. Bugs for which you had a work-around get ﬁxed, break- ing the work-around. APIs change, functionality changes; in short, it’s a whole new ball game, and you must retest the system under these",
      "content_length": 2251,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 122,
      "content": "DEBUGGING\n\nnew conditions. So keep a close eye on the schedule when considering an upgrade; you may want to wait until after the next release.\n\nIf, however, you have no obvious place to start looking, you can always rely on a good old-fashioned binary search. See if the symptoms are present at either of two far away spots in the code. Then look in the middle. If the problem is present, then the bug lies between the start and the middle point; otherwise, it is between the middle point and the end. You can continue in this fashion until you narrow down the spot sufﬁciently to identify the problem.\n\nTheElement of Surprise When you ﬁnd yourself surprised by a bug (perhaps even muttering “that’s impossible” under your breath where we can’t hear you), you must reevaluate truths you hold dear. In that linked list routine—the one you knew was bulletproof and couldn’t possibly be the cause of this bug—did you test all the boundary conditions? That other piece of code you’ve been using for years—it couldn’t possibly still have a bug in it. Could it?\n\nOf course it can. The amount of surprise you feel when something goes wrong is directly proportional to the amount of trust and faith you have in the code being run. That’s why, when faced with a “surprising” fail- ure, you must realize that one or more of your assumptions is wrong. Don’t gloss over a routine or piece of code involved in the bug because you “know” it works. Prove it. Prove it in this context, with this data, with these boundary conditions.\n\nTIP 27\n\nDon’t Assume It—Prove It\n\nWhen you come across a surprise bug, beyond merely ﬁxing it, you need to determine why this failure wasn’t caught earlier. Consider whether you need to amend the unit or other tests so that they would have caught it.\n\nAlso, if the bug is the result of bad data that was propagated through a couple of levels before causing the explosion, see if better parame- ter checking in those routines would have isolated it earlier (see the\n\n97",
      "content_length": 1987,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 123,
      "content": "98\n\nCHAPTER 3 THE BASIC TOOLS\n\ndiscussions on crashing early and assertions on pages 120 and 122, respectively).\n\nWhile you’re at it, are there any other places in the code that may be susceptible to this same bug? Now is the time to ﬁnd and ﬁx them. Make sure that whatever happened, you’ll know if it happens again.\n\nIf it took a long time to ﬁx this bug, ask yourself why. Is there anything you can do to make ﬁxing this bug easier the next time around? Per- haps you could build in better testing hooks, or write a log ﬁle analyzer.\n\nFinally, if the bug is the result of someone’s wrong assumption, discuss the problem with the whole team: if one person misunderstands, then it’s possible many people do.\n\nDo all this, and hopefully you won’t be surprised next time.\n\nDebugging Checklist\n\nIs the problem being reported a direct result of the underlying bug, or merely a symptom?\n\nIs the bug really in the compiler? Is it in the OS? Or is it in your code?\n\nIf you explained this problem in detail to a coworker, what would you say?\n\nIf the suspect code passes its unit tests, are the tests complete enough? What happens if you run the unit test with this data?\n\nDo the conditions that caused this bug exist anywhere else in the system?\n\nRelated sections include:\n\nAssertive Programming, page 122 Programming by Coincidence, page 172 Ubiquitous Automation, page 230 Ruthless Testing, page 237\n\nChallenges\n\nDebugging is challenge enough.",
      "content_length": 1438,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 124,
      "content": "19\n\nTEXT MANIPULATION\n\nText Manipulation\n\nPragmatic Programmers manipulate text the same way woodworkers shape wood. In previous sections we discussed some speciﬁc tools— shells, editors, debuggers—that we use. These are similar to a wood- worker’s chisels, saws, and planes—tools specialized to do one or two jobs well. However, every now and then we need to perform some trans- formation not readily handled by the basic tool set. We need a general- purpose text manipulation tool.\n\nText manipulation languages are to programming what routers8 are to woodworking. They are noisy, messy, and somewhat brute force. Make mistakes with them, and entire pieces can be ruined. Some peo- ple swear they have no place in the toolbox. But in the right hands, both routers and text manipulation languages can be incredibly pow- erful and versatile. You can quickly trim something into shape, make joints, and carve. Used properly, these tools have surprising ﬁnesse and subtlety. But they take time to master.\n\nThere is a growing number of good text manipulation languages. Unix developers often like to use the power of their command shells, aug- mented with tools such as awk and sed. People who prefer a more structured tool like the object-oriented nature of Python [URL 9]. Some people use Tcl [URL 23] as their tool of choice. We happen to prefer Ruby [TFH04] and Perl [URL 8] for hacking out short scripts.\n\nThese languages are important enabling technologies. Using them, you can quickly hack up utilities and prototype ideas—jobs that might take ﬁve or ten times as long using conventional languages. And that mul- tiplying factor is crucially important to the kind of experimenting that we do. Spending 30 minutes trying out a crazy idea is a whole lot bet- ter than spending ﬁve hours. Spending a day automating important components of a project is acceptable; spending a week might not be. In their book The Practice of Programming [KP99], Kernighan and Pike built the same program in ﬁve different languages. The Perl version was the shortest (17 lines, compared with C’s 150). With Perl you can\n\n8. Here router means the tool that spins cutting blades very, very fast, not a device for interconnecting networks.\n\n99",
      "content_length": 2221,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 125,
      "content": "100\n\nCHAPTER 3 THE BASIC TOOLS\n\nmanipulate text, interact with programs, talk over networks, drive Web pages, perform arbitrary precision arithmetic, and write programs that look like Snoopy swearing.\n\nTIP 28\n\nLearn a Text Manipulation Language\n\nTo show the wide-ranging applicability of text manipulation languages, here’s a sample of some applications we’ve developed over the last few years.\n\nDatabase schema maintenance. A set of Perl scripts took a plain text ﬁle containing a database schema deﬁnition and from it gen- erated:\n\n– The SQL statements to create the database – Flat data ﬁles to populate a data dictionary – C code libraries to access the database – Scripts to check database integrity – Web pages containing schema descriptions and diagrams – An XML version of the schema\n\nIt is good OO programming style to restrict Java property access. access to an object’s properties, forcing external classes to get and set them via methods. However, in the common case where a prop- erty is represented inside the class by a simple member variable, creating a get and set method for each variable is tedious and me- chanical. We have a Perl script that modiﬁes the source ﬁles and inserts the correct method deﬁnitions for all appropriately ﬂagged variables.\n\nTest data generation. We had tens of thousands of records of test data, spread over several different ﬁles and formats, that needed to be knitted together and converted into a form suitable for loading into a relational database. Perl did it in a couple of hours (and in the process found a couple of consistency errors in the original data).\n\nBook writing. We think it is important that any code presented in a book should have been tested ﬁrst. Most of the code in this",
      "content_length": 1741,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 126,
      "content": "TEXT MANIPULATION\n\nbook has been. However, using the DRY principle (see The Evils of Duplication, page 26) we didn’t want to copy and paste lines of code from the tested programs into the book. That would have meant that the code was duplicated, virtually guaranteeing that we’d for- get to update an example when the corresponding program was changed. For some examples, we also didn’t want to bore you with all the framework code needed to make our example compile and run. We turned to Perl. A relatively simple script is invoked when we format the book—it extracts a named segment of a source ﬁle, does syntax highlighting, and converts the result into the typeset- ting language we use.\n\nC to Object Pascal interface. A client had a team of developers writing Object Pascal on PCs. Their code needed to interface to a body of code written in C. We developed a short Perl script that parsed the C header ﬁles, extracting the deﬁnitions of all exported functions and the data structures they used. We then generated Object Pascal units with Pascal records for all the C structures, and imported procedure deﬁnitions for all the C functions. This generation process became part of the build, so that whenever the C header changed, a new Object Pascal unit would be constructed automatically.\n\nGenerating Web documentation. Many project teams are pub- lishing their documentation to internal Web sites. We have writ- ten many Perl programs that analyze database schemas, C or C++ source ﬁles, makeﬁles, and other project sources to produce the required HTML documentation. We also use Perl to wrap the docu- ments with standard headers and footers, and to transfer them to the Web site.\n\nWe use text manipulation languages almost every day. Many of the ideas in this book can be implemented more simply in them than in any other language of which we’re aware. These languages make it easy to write code generators, which we’ll look at next.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26\n\n101",
      "content_length": 2008,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 127,
      "content": "102\n\nCHAPTER 3 THE BASIC TOOLS\n\nAnswer on p. 285\n\nExercises 11. Your C program uses an enumerated type to represent one of 100 states. You’d like to be able to print out the state as a string (as opposed to a number) for debugging purposes. Write a script that reads from standard input a ﬁle containing\n\nname state_a state_b :\n\n:\n\nProduce the ﬁle name.h, which contains\n\nextern const char* NAME_names[]; typedef enum { state_a, state_b,\n\n: } NAME;\n\n:\n\nand the ﬁle name.c, which contains\n\nconst char* NAME_names[] = {\n\n\"state_a\", \"state_b\",\n\n:\n\n:\n\n};\n\nAnswer on p. 286\n\n12. Halfway through writing this book, we realized that we hadn’t put the use strict directive into many of our Perl examples. Write a script that goes through the .pl ﬁles in a directory and adds a use strict at the end of the initial comment block to all ﬁles that don’t already have one. Remember to keep a backup of all ﬁles you change.\n\n20 Code Generators\n\nWhen woodworkers are faced with the task of producing the same thing over and over, they cheat. They build themselves a jig or a template. If they get the jig right once, they can reproduce a piece of work time after time. The jig takes away complexity and reduces the chances of making mistakes, leaving the craftsman free to concentrate on quality.\n\nAs programmers, we often ﬁnd ourselves in a similar position. We need to achieve the same functionality, but in different contexts. We need to repeat information in different places. Sometimes we just need to pro- tect ourselves from carpal tunnel syndrome by cutting down on repeti- tive typing.",
      "content_length": 1580,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 128,
      "content": "CODE GENERATORS\n\nIn the same way a woodworker invests the time in a jig, a programmer can build a code generator. Once built, it can be used throughout the life of the project at virtually no cost.\n\nTIP 29\n\nWrite Code That Writes Code\n\nThere are two main types of code generators:\n\n1. Passive code generators are run once to produce a result. From that point forward, the result becomes freestanding—it is divorced from the code generator. The wizards discussed in Evil Wizards, page 198, along with some CASE tools, are examples of passive code generators.\n\n2. Active code generators are used each time their results are required. The result is a throw-away—it can always be reproduced by the code generator. Often, active code generators read some form of script or control ﬁle to produce their results.\n\nPassiveCode Generators Passive code generators save typing. They are basically parameterized templates, generating a given output from a set of inputs. Once the result is produced, it becomes a full-ﬂedged source ﬁle in the project; it will be edited, compiled, and placed under source control just like any other ﬁle. Its origins will be forgotten.\n\nPassive code generators have many uses:\n\nCreating new source ﬁles. A passive code generator can produce templates, source code control directives, copyright notices, and standard comment blocks for each new ﬁle in a project. We have our editors set up to do this whenever we create a new ﬁle: edit a new Java program, and the new editor buffer will automatically contain a comment block, package directive, and the outline class declaration, already ﬁlled in.\n\nPerforming one-off conversions among programming languages. We started writing this book using the troff system, but we switched to LATEX after 15 sections had been completed. We wrote a code gen- erator that read the troff source and converted it to LATEX. It was\n\n103",
      "content_length": 1888,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 129,
      "content": "104\n\nCHAPTER 3 THE BASIC TOOLS\n\nabout 90% accurate; the rest we did by hand. This is an interest- ing feature of passive code generators: they don’t have to be totally accurate. You get to choose how much effort you put into the gen- erator, compared with the energy you spend ﬁxing up its output.\n\nProducing lookup tables and other resources that are expensive to compute at runtime. Instead of calculating trigonometric functions, many early graphics systems used precomputed tables of sine and cosine values. Typically, these tables were produced by a passive code generator and then copied into the source.\n\nActiveCode Generators While passive code generators are simply a convenience, their active cousins are a necessity if you want to follow the DRY principle. With an active code generator, you can take a single representation of some piece of knowledge and convert it into all the forms your application needs. This is not duplication, because the derived forms are dispos- able, and are generated as needed by the code generator (hence the word active).\n\nWhenever you ﬁnd yourself trying to get two disparate environments to work together, you should consider using active code generators.\n\nPerhaps you’re developing a database application. Here, you’re dealing with two environments—the database and the programming language you are using to access it. You have a schema, and you need to deﬁne low-level structures mirroring the layout of certain database tables. You could just code these directly, but this violates the DRY princi- ple: knowledge of the schema would then be expressed in two places. When the schema changes, you need to remember to change the corre- sponding code. If a column is removed from a table, but the code base is not changed, you might not even get a compilation error. The ﬁrst you’ll know about it is when your tests start failing (or when the user calls).\n\nAn alternative is to use an active code generator—take the schema and use it to generate the source code for the structures, as shown in Figure 3.3. Now, whenever the schema changes, the code used to access it also changes, automatically. If a column is removed, then its corresponding ﬁeld in the structure will disappear, and any higher-level code that uses that column will fail to compile. You’ve caught the error at compile time,",
      "content_length": 2335,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 130,
      "content": "CODE GENERATORS\n\nFigure 3.3. Active code generator creates code from a database schema\n\nstruct EmployeeRow\n\nSchema\n\ntable employee table employer table beneﬁt\n\nactive code generator\n\nstruct EmployerRow\n\nstruct BenefitRow\n\nnot in production. Of course, this scheme works only if you make the code generation part of the build process itself.9\n\nAnother example of melding environments using code generators hap- pens when different programming languages are used in the same application. In order to communicate, each code base will need some information in common—data structures, message formats, and ﬁeld names, for example. Rather than duplicate this information, use a code generator. Sometimes you can parse the information out of the source ﬁles of one language and use it to generate code in a second language. Often, though, it is simpler to express it in a simpler, language-neutral representation and generate the code for both languages, as shown in Figure 3.4 on the following page. Also see the answer to Exercise 13 on page 286 for an example of how to separate the parsing of the ﬂat ﬁle representation from code generation.\n\nCodeGeneratorsNeedn’t BeComplex All this talk of active this and passive that may leave you with the impression that code generators are complex beasts. They needn’t be. Normally the most complex part is the parser, which analyzes the input ﬁle. Keep the input format simple, and the code generator becomes\n\nJust how do you go about building code from a database schema? There are several 9. ways. If the schema is held in a ﬂat ﬁle (for example, as create table statements), then a relatively simple script can parse it and generate the source. Alternatively, if you use a tool to create the schema directly in the database, then you should be able to extract the information you need directly from the database’s data dictionary. Perl provides libraries that give you access to most major databases.\n\n105",
      "content_length": 1946,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 131,
      "content": "Answer on p. 286\n\n106\n\nCHAPTER 3 THE BASIC TOOLS\n\nFigure 3.4. Generating code from a language-neutralrepresentation.In the input\n\nﬁle, lines starting with ‘M’ ﬂag the start of a message deﬁnition, ‘F’ lines deﬁne\n\nﬁelds, and ‘E’ is the end of the message.\n\n# Add a product # to the ’on-order’ list M AddProduct F id F name F order_code int E\n\nint char[30]\n\ngenerateC\n\ngeneratePascal\n\n/* Add a product */ /* to the ’on-order’ list */ typedef struct {\n\n{ Add a product } { to the ’on-order’ list } AddProductMsg = packed record\n\nint id; char name[30]; int\n\norder_code;\n\nid: name: order_code: LongInt;\n\nLongInt; array[0..29] of char;\n\n} AddProductMsg;\n\nend;\n\nsimple. Have a look at the answer to Exercise 13 (page 286): the actual code generation is basically print statements.\n\nCode GeneratorsNeedn’t GenerateCode Although many of the examples in this section show code generators that produce program source, this needn’t always be the case. You can use code generators to write just about any output: HTML, XML, plain text—any text that might be an input somewhere else in your project.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26 The Power of Plain Text, page 73 Evil Wizards, page 198 Ubiquitous Automation, page 230\n\nExercises 13. Write a code generator that takes the input ﬁle in Figure 3.4, and generates output in two languages of your choice. Try to make it easy to add new languages.",
      "content_length": 1410,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 132,
      "content": "Chapter 4\n\nPragmatic Paranoia\n\nTIP 30\n\nYou Can’t Write Perfect Software\n\nDid that hurt? It shouldn’t. Accept it as an axiom of life. Embrace it. Celebrate it. Because perfect software doesn’t exist. No one in the brief history of computing has ever written a piece of perfect software. It’s unlikely that you’ll be the ﬁrst. And unless you accept this as a fact, you’ll end up wasting time and energy chasing an impossible dream.\n\nSo, given this depressing reality, how does a Pragmatic Programmer turn it into an advantage? That’s the topic of this chapter.\n\nEveryone knows that they personally are the only good driver on Earth. The rest of the world is out there to get them, blowing through stop signs, weaving between lanes, not indicating turns, talking on the telephone, reading the paper, and just generally not living up to our standards. So we drive defensively. We look out for trouble before it happens, anticipate the unexpected, and never put ourselves into a position from which we can’t extricate ourselves.\n\nThe analogy with coding is pretty obvious. We are constantly interfac- ing with other people’s code—code that might not live up to our high standards—and dealing with inputs that may or may not be valid. So we are taught to code defensively. If there’s any doubt, we validate all information we’re given. We use assertions to detect bad data. We check for consistency, put constraints on database columns, and generally feel pretty good about ourselves.\n\n107",
      "content_length": 1483,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 133,
      "content": "108\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nBut Pragmatic Programmers take this a step further. They don’t trust themselves, either. Knowing that no one writes perfect code, includ- ing themselves, Pragmatic Programmers code in defenses against their own mistakes. We describe the ﬁrst defensive measure in Design by Contract: clients and suppliers must agree on rights and responsibili- ties.\n\nIn Dead Programs Tell No Lies, we want to ensure that we do no damage while we’re working the bugs out. So we try to check things often and terminate the program if things go awry.\n\nAssertive Programming describes an easy method of checking along the way—write code that actively veriﬁes your assumptions.\n\nExceptions, like any other technique, can cause more harm than good if not used properly. We’ll discuss the issues in When to Use Exceptions.\n\nAs your programs get more dynamic, you’ll ﬁnd yourself juggling sys- tem resources—memory, ﬁles, devices, and the like. In How to Balance Resources, we’ll suggest ways of ensuring that you don’t drop any of the balls.\n\nIn a world of imperfect systems, ridiculous time scales, laughable tools, and impossible requirements, let’s play it safe.\n\nWhen everybody actually is out to get you, paranoia is just good thinking.\n\nWoody Allen",
      "content_length": 1266,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 134,
      "content": "DESIGN BY CONTRACT\n\n21 Design by Contract\n\nNothing astonishes men so much as common sense and plain dealing.\n\nRalph Waldo Emerson, Essays\n\nDealing with computer systems is hard. Dealing with people is even harder. But as a species, we’ve had longer to ﬁgure out issues of human interactions. Some of the solutions we’ve come up with during the last few millennia can be applied to writing software as well. One of the best solutions for ensuring plain dealing is the contract.\n\nA contract deﬁnes your rights and responsibilities, as well as those of the other party. In addition, there is an agreement concerning reper- cussions if either party fails to abide by the contract.\n\nMaybe you have an employment contract that speciﬁes the hours you’ll work and the rules of conduct you must follow. In return, the company pays you a salary and other perks. Each party meets its obligations and everyone beneﬁts.\n\nIt’s an idea used the world over—both formally and informally—to help humans interact. Can we use the same concept to help software mod- ules interact? The answer is “yes.”\n\nDBC Bertrand Meyer [Mey97b] developed the concept of Design by Contract for the language Eiffel.1 It is a simple yet powerful technique that focuses on documenting (and agreeing to) the rights and responsibil- ities of software modules to ensure program correctness. What is a correct program? One that does no more and no less than it claims to do. Documenting and verifying that claim is the heart of Design by Contract (DBC, for short).\n\nEvery function and method in a software system does something. Be- fore it starts that something, the routine may have some expectation of the state of the world, and it may be able to make a statement about the state of the world when it concludes. Meyer describes these expec- tations and claims as follows:\n\n1. information on Eiffel itself, see [URL 10] and [URL 11].\n\nBased in part on earlier work by Dijkstra, Floyd, Hoare, Wirth, and others. For more\n\n109",
      "content_length": 1984,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 135,
      "content": "110\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nPreconditions. What must be true in order for the routine to be called; the routine’s requirements. A routine should never get called when its preconditions would be violated. It is the caller’s respon- sibility to pass good data (see the box on page 115).\n\nPostconditions. What the routine is guaranteed to do; the state of the world when the routine is done. The fact that the routine has a postcondition implies that it will conclude: inﬁnite loops aren’t allowed.\n\nClass invariants. A class ensures that this condition is always true from the perspective of a caller. During internal processing of a routine, the invariant may not hold, but by the time the routine exits and control returns to the caller, the invariant must be true. (Note that a class cannot give unrestricted write-access to any data member that participates in the invariant.)\n\nLet’s look at the contract for a routine that inserts a data value into a unique, ordered list. In iContract, a preprocessor for Java available from [URL 17], you’d specify it as\n\n/**\n\n@invariant forall Node n in elements() | * * * */ implies\n\nn.prev() != null\n\nn.value().compareTo(n.prev().value()) > 0\n\npublic class dbc_list {\n\n/**\n\n@pre contains(aNode) == false * @post contains(aNode) == true */\n\npublic void insertNode(final Node aNode) {\n\n// ...\n\nHere we are saying that nodes in this list must always be in increas- ing order. When you insert a new node, it can’t exist already, and we guarantee that the node will be found after you have inserted it.\n\nYou write these preconditions, postconditions, and invariants in the target programming language, perhaps with some extensions. For ex- ample, iContract provides predicate logic operators—forall, exists, and implies—in addition to normal Java constructs. Your assertions can query the state of any object that the method can access, but be sure that the query is free from any side effects (see page 124).",
      "content_length": 1952,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 136,
      "content": "DESIGN BY CONTRACT\n\nDBC and Constant Parameters\n\nOften, a postcondition will use parameters passed into a method to verify correct behavior. But if the routine is allowed to change the parameter that’s passed in, you might be able to circumvent the con- tract. Eiffel doesn’t allow this to happen, but Java does. Here, we use the Java keyword final to indicate our intentions that the param- eter shouldn’t be changed within the method. This isn’t foolproof— subclasses are free to redeclare the parameter as non-ﬁnal. Alterna- tively, you can use the iContract syntax variable@pre to get the original value of the variable as it existed on entry to the method.\n\nThe contract between a routine and any potential caller can thus be read as\n\nIf all the routine’s preconditions are met by the caller, the routine shall guarantee that all postconditions and invariants will be true when it completes.\n\nIf either party fails to live up to the terms of the contract, then a rem- edy (which was previously agreed to) is invoked—an exception is raised, or the program terminates, for instance. Whatever happens, make no mistake that failure to live up to the contract is a bug. It is not some- thing that should ever happen, which is why preconditions should not be used to perform things such as user-input validation.\n\nTIP 31\n\nDesign with Contracts\n\nIn Orthogonality, page 34, we recommended writing “shy” code. Here, the emphasis is on “lazy” code: be strict in what you will accept before you begin, and promise as little as possible in return. Remember, if your contract indicates that you’ll accept anything and promise the world in return, then you’ve got a lot of code to write!\n\nInheritance and polymorphism are the cornerstones of object-oriented languages and an area where contracts can really shine. Suppose you are using inheritance to create an “is-a-kind-of” relationship, where one class “is-a-kind-of” another class. You probably want to adhere to the Liskov Substitution Principle [Lis88]:\n\n111",
      "content_length": 2005,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 137,
      "content": "112\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nSubclasses must be usable through the base class interface without the need for the user to know the difference.\n\nIn other words, you want to make sure that the new subtype you have created really “is-a-kind-of” the base type—that it supports the same methods, and that the methods have the same meaning. We can do this with contracts. We need to specify a contract only once, in the base class, to have it applied to every future subclass automatically. A sub- class may, optionally, accept a wider range of input, or make stronger guarantees. But it must accept at least as much, and guarantee as much, as its parent.\n\nFor example, consider the Java base class java.awt.Component. You can treat any visual component in AWT or Swing as a Component, with- out knowing that the actual subclass is a button, a canvas, a menu, or whatever. Each individual component can provide additional, speciﬁc functionality, but it has to provide at least the basic capabilities de- ﬁned by Component. But there’s nothing to prevent you from creating a subtype of Component that provides correctly named methods that do the wrong thing. You can easily create a paint method that doesn’t paint, or a setFont method that doesn’t set the font. AWT doesn’t have contracts to catch the fact that you didn’t live up to the agreement.\n\nWithout a contract, all the compiler can do is ensure that a subclass conforms to a particular method signature. But if we put a base class contract in place, we can now ensure that any future subclass can’t alter the meanings of our methods. For instance, you might want to establish a contract for setFont such as the following, which ensures that the font you set is the font you get:\n\n/**\n\n@pre f != null * @post getFont() == f */ public void setFont(final Font f) { // ...\n\nImplementingDBC The greatest beneﬁt of using DBC may be that it forces the issue of requirements and guarantees to the forefront. Simply enumerating at design time what the input domain range is, what the boundary con- ditions are, and what the routine promises to deliver—or, more im-",
      "content_length": 2113,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 138,
      "content": "DESIGN BY CONTRACT\n\nportantly, what it doesn’t promise to deliver—is a huge leap forward in writing better software. By not stating these things, you are back to pro- gramming by coincidence (see page 172), which is where many projects start, ﬁnish, and fail.\n\nIn languages that do not support DBC in the code, this might be as far as you can go—and that’s not too bad. DBC is, after all, a design technique. Even without automatic checking, you can put the contract in the code as comments and still get a very real beneﬁt. If nothing else, the commented contracts give you a place to start looking when trouble strikes.\n\nAssertions While documenting these assumptions is a great start, you can get much greater beneﬁt by having the compiler check your contract for you. You can partially emulate this in some languages by using asser- tions (see Assertive Programming, page 122). Why only partially? Can’t you use assertions to do everything DBC can do?\n\nUnfortunately, the answer is no. To begin with, there is no support for propagating assertions down an inheritance hierarchy. This means that if you override a base class method that has a contract, the asser- tions that implement that contract will not be called correctly (unless you duplicate them manually in the new code). You must remember to call the class invariant (and all base class invariants) manually before you exit every method. The basic problem is that the contract is not automatically enforced.\n\nAlso, there is no built-in concept of “old” values; that is, values as they existed at the entry to a method. If you’re using assertions to enforce contracts, you must add code to the precondition to save any information you’ll want to use in the postcondition. Compare this with iContract, where the postcondition can just reference “variable@pre,” or with Eiffel, which supports “old expression.”\n\nFinally, the runtime system and libraries are not designed to support contracts, so these calls are not checked. This is a big loss, because it is often at the boundary between your code and the libraries it uses that the most problems are detected (see Dead Programs Tell No Lies, page 120 for a more detailed discussion).\n\n113",
      "content_length": 2201,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 139,
      "content": "114\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nLanguage Support Languages that feature built-in support of DBC (such as Eiffel and Sather [URL 12]) check pre- and postconditions automatically in the compiler and runtime system. You get the greatest beneﬁt in this case because all of the code base (libraries, too) must honor their contracts.\n\nBut what about more popular languages such as C, C++, and Java? For these languages, there are preprocessors that process contracts embedded in the original source code as special comments. The pre- processor expands these comments to code that veriﬁes the assertions.\n\nFor C and C++, you may want to investigate Nana [URL 18]. Nana doesn’t handle inheritance, but it does use the debugger at runtime to monitor assertions in a novel way.\n\nFor Java, there is iContract [URL 17]. It takes comments (in JavaDoc form) and generates a new source ﬁle with the assertion logic included.\n\nPreprocessors aren’t as good as a built-in facility. They can be messy to integrate into your project, and other libraries you use won’t have con- tracts. But they can still be very helpful; when a problem is discovered this way—especially one that you would never have found—it’s almost like magic.\n\nDBC andCrashingEarly DBC ﬁts in nicely with our concept of crashing early (see Dead Pro- grams Tell No Lies, page 120). Suppose you have a method that cal- culates square roots (such as in the Eiffel class DOUBLE). It needs a precondition that restricts the domain to positive numbers. An Eiffel precondition is declared with the keyword require, and a postcondi- tion is declared with ensure, so you could write\n\nsqrt: DOUBLE is\n\n-- Square root routine\n\nrequire\n\nsqrt_arg_must_be_positive: Current >= 0;\n\n--- ... --- calculate square root here --- ... ensure\n\n((Result*Result) - Current).abs <= epsilon*Current.abs; -- Result should be within error tolerance\n\nend;",
      "content_length": 1880,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 140,
      "content": "DESIGN BY CONTRACT\n\nWho’s Responsible?\n\nWho is responsible for checking the precondition, the caller or the routine being called? When implemented as part of the language, the answer is neither: the precondition is tested behind the scenes after the caller invokes the routine but before the routine itself is entered. Thus if there is any explicit checking of parameters to be done, it must be performed by the caller, because the routine itself will never see parameters that violate its precondition. (For languages without built-in support, you would need to bracket the called routine with a preamble and/or postamble that checks these assertions.)\n\nConsider a program that reads a number from the console, calcu- lates its square root (by calling sqrt), and prints the result. The sqrt function has a precondition—its argument must not be negative. If the user enters a negative number at the console, it is up to the calling code to ensure that it never gets passed to sqrt. This calling code has many options: it could terminate, it could issue a warning and read another number, or it could make the number positive and ap- pend an “ ” to the result returned by sqrt. Whatever its choice, this is deﬁnitely not sqrt’s problem.\n\nBy expressing the domain of the square root function in the precon- dition of the sqrt routine, you shift the burden of correctness to the caller—where it belongs. You can then design the sqrt routine se- cure in the knowledge that its input will be in range.\n\nIf your algorithm for calculating the square root fails (or isn’t within the speciﬁed error tolerance), you get an error message and a stack trace to show you the call chain.\n\nIf you pass sqrt a negative parameter, the Eiffel runtime prints the error “sqrt_arg_must_be_positive,” along with a stack trace. This is better than the alternative in languages such as Java, C, and C++, where passing a negative number to sqrt returns the special value NaN (Not a Number). It may be some time later in the program that you attempt to do some math on NaN, with surprising results.\n\nIt’s much easier to ﬁnd and diagnose the problem by crashing early, at the site of the problem.\n\n115",
      "content_length": 2173,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 141,
      "content": "116\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nOther Usesof Invariants So far we have discussed pre- and postconditions that apply to individ- ual methods and invariants that apply to all methods within a class, but there are other useful ways to use invariants.\n\nLoop Invariants Getting the boundary conditions right on a nontrivial loop can be prob- lematic. Loops are subject to the banana problem (I know how to spell “banana,” but I don’t know when to stop), fencepost errors (not know- ing whether to count the fenceposts or the spaces between them), and the ubiquitous “off by one” error [URL 52].\n\nInvariants can help in these situations: a loop invariant is a statement of the eventual goal of a loop, but is generalized so that it is also valid before the loop executes and on each iteration through the loop. You can think of it as a kind of miniature contract. The classic example is a routine that ﬁnds the maximum value in an array.\n\nint m = arr[0]; int i = 1;\n\n// example assumes arr.length > 0\n\n// Loop invariant: m = max(arr[0:i-1]) while (i < arr.length) {\n\nm = Math.max(m, arr[i]); i = i + 1;\n\n}\n\n(arr[m:n] is a notational convenience meaning a slice of the array from index m to n.) The invariant must be true before the loop runs, and the body of the loop must ensure that it remains true as the loop executes. In this way we know that the invariant also holds when the loop termi- nates, and therefore that our result is valid. Loop invariants can be coded explicitly as assertions, but they are also useful as design and documentation tools.\n\nSemantic Invariants You can use semantic invariants to express inviolate requirements, a kind of “philosophical contract.”\n\nWe once wrote a debit card transaction switch. A major requirement was that the user of a debit card should never have the same trans- action applied to their account twice. In other words, no matter what",
      "content_length": 1882,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 142,
      "content": "DESIGN BY CONTRACT\n\nsort of failure mode might happen, the error should be on the side of not processing a transaction rather than processing a duplicate trans- action.\n\nThis simple law, driven directly from the requirements, proved to be very helpful in sorting out complex error recovery scenarios, and guided the detailed design and implementation in many areas.\n\nBe sure not to confuse requirements that are ﬁxed, inviolate laws with those that are merely policies that might change with a new manage- ment regime. That’s why we use the term semantic invariants—it must be central to the very meaning of a thing, and not subject to the whims of policy (which is what more dynamic business rules are for).\n\nWhen you ﬁnd a requirement that qualiﬁes, make sure it becomes a well-known part of whatever documentation you are producing— whether it is a bulleted list in the requirements document that gets signed in triplicate or just a big note on the common whiteboard that everyone sees. Try to state it clearly and unambiguously. For example, in the debit card example, we might write\n\nERR IN FAVOR OF THE CONSUMER.\n\nThis is a clear, concise, unambiguous statement that’s applicable in many different areas of the system. It is our contract with all users of the system, our guarantee of behavior.\n\nDynamicContractsandAgents Until now, we have talked about contracts as ﬁxed, immutable speciﬁ- cations. But in the landscape of autonomous agents, this doesn’t need to be the case. By the deﬁnition of “autonomous,” agents are free to reject requests that they do not want to honor. They are free to renego- tiate the contract—“I can’t provide that, but if you give me this, then I might provide something else.”\n\nCertainly any system that relies on agent technology has a critical de- pendence on contractual arrangements—even if they are dynamically generated.\n\nImagine: with enough components and agents that can negotiate their own contracts among themselves to achieve a goal, we might just solve the software productivity crisis by letting software solve it for us.\n\n117",
      "content_length": 2077,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 143,
      "content": "Answer on p. 288\n\n118\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nBut if we can’t use contracts by hand, we won’t be able to use them automatically. So next time you design a piece of software, design its contract as well.\n\nRelated sections include: Orthogonality, page 34 Dead Programs Tell No Lies, page 120 Assertive Programming, page 122 How to Balance Resources, page 129 Decoupling and the Law of Demeter, page 138 Temporal Coupling, page 150 Programming by Coincidence, page 172 Code That’s Easy to Test, page 189 Pragmatic Teams, page 224\n\nChallenges\n\nPoints to ponder: If DBC is so powerful, why isn’t it used more widely? Is it hard to come up with the contract? Does it make you think about issues you’d rather ignore for now? Does it force you to THINK!? Clearly, this is a dangerous tool!\n\nExercises 14. What makes a good contract? Anyone can add preconditions and postcon- ditions, but will they do you any good? Worse yet, will they actually do more harm than good? For the example below and for those in Exercises 15 and 16, decide whether the speciﬁed contract is good, bad, or ugly, and explain why.\n\nFirst, let’s look at an Eiffel example. Here we have a routine for adding a STRING to a doubly linked, circular list (remember that preconditions are labeled with require, and postconditions with ensure).\n\n-- Add a unique item to a doubly linked list, -- and return the newly created NODE.\n\nadd_item (item : STRING) : NODE is\n\nrequire\n\nitem /= Void find_item(item) = Void\n\ndeferred ensure\n\n-- ’/=’ is ’not equal’. -- Must be unique -- Abstract base class.\n\nresult.next.previous = result -- Check the newly result.previous.next = result -- added node’s links. find_item(item) = result\n\n-- Should find it.\n\nend",
      "content_length": 1714,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 144,
      "content": "DESIGN BY CONTRACT\n\n119\n\n15. Next, let’s try an example in Java—somewhat similar to the example in Exercise 14. insertNumber inserts an integer into an ordered list. Pre- and postconditions are labeled as in iContract (see [URL 17]). Answer on p. 288\n\nprivate int data[]; /**\n\n@post data[index-1] < data[index] && data[index] == aValue * */\n\npublic Node insertNumber (final int aValue) {\n\nint index = findPlaceToInsert(aValue); ...\n\n16. Here’s a fragment from a stack class in Java. Is this a good contract?\n\n/**\n\n@pre anItem != null * @post pop() == anItem // Verify that it’s * */ // Require real data\n\npublic void push(final String anItem)\n\n17. The classic examples of DBC (as in Exercises 14–16) show an implemen- tation of an ADT (Abstract Data Type)—typically a stack or queue. But not many people really write these kinds of low-level classes. Answer on p. 289\n\nSo, for this exercise, design an interface to a kitchen blender. It will even- tually be a Web-based, Internet-enabled, CORBA-ﬁed blender, but for now we just need the interface to control it. It has ten speed settings (0 means off). You can’t operate it empty, and you can change the speed only one unit at a time (that is, from 0 to 1, and from 1 to 2, not from 0 to 2).\n\nHere are the methods. Add appropriate pre- and postconditions and an invariant.\n\nint getSpeed() void setSpeed(int x) boolean isFull() void fill() void empty()\n\n18. How many numbers are in the series\n\n?\n\nAnswer on p. 289\n\nAnswer on p. 290",
      "content_length": 1480,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 145,
      "content": "120\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\n22 Dead Programs Tell No Lies\n\nHave you noticed that sometimes other people can detect that things aren’t well with you before you’re aware of the problem yourself? It’s the same with other people’s code. If something is starting to go awry with one of our programs, sometimes it is a library routine that catches it ﬁrst. Maybe a stray pointer has caused us to overwrite a ﬁle handle with something meaningless. The next call to read will catch it. Perhaps a buffer overrun has trashed a counter we’re about to use to determine how much memory to allocate. Maybe we’ll get a failure from malloc. A logic error a couple of million instructions ago means that the selector for a case statement is no longer the expected 1, 2, or 3. We’ll hit the default case (which is one reason why each and every case/switch statement needs to have a default clause—we want to know when the “impossible” has happened).\n\nIt’s easy to fall into the “it can’t happen” mentality. Most of us have written code that didn’t check that a ﬁle closed successfully, or that a trace statement got written as we expected. And all things being equal, it’s likely that we didn’t need to—the code in question wouldn’t fail under any normal conditions. But we’re coding defensively. We’re look- ing for rogue pointers in other parts of our program trashing the stack. We’re checking that the correct versions of shared libraries were actu- ally loaded.\n\nAll errors give you information. You could convince yourself that the error can’t happen, and choose to ignore it. Instead, Pragmatic Pro- grammers tell themselves that if there is an error, something very, very bad has happened.\n\nTIP 32\n\nCrash Early\n\nCrash,Don’t Trash One of the beneﬁts of detecting problems as soon as you can is that you can crash earlier. And many times, crashing your program is the best thing you can do. The alternative may be to continue, writing corrupted",
      "content_length": 1939,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 146,
      "content": "DEAD PROGRAMS TELL NO LIES\n\ndata to some vital database or commanding the washing machine into its twentieth consecutive spin cycle.\n\nThe Java language and libraries have embraced this philosophy. When something unexpected happens within the runtime system, it throws a RuntimeException. If not caught, this will percolate up to the top level of the program and cause it to halt, displaying a stack trace.\n\nYou can do the same in other languages. If you don’t have an exception mechanism, or if your libraries don’t throw exceptions, then make sure you handle the errors yourself. In C, macros can be very useful for this:\n\n#define CHECK(LINE, EXPECTED)\n\n{ int rc = LINE;\n\nif (rc != EXPECTED)\n\nut_abort(__FILE__, __LINE__, #LINE, rc, EXPECTED); }\n\nvoid ut_abort(char *file, int ln, char *line, int rc, int exp) {\n\nfprintf(stderr, \"%s line %d n’%s’: expected %d, got %d n\", file, ln, line, exp, rc);\n\nexit(1);\n\n}\n\nThen you can wrap calls that should never fail using\n\nCHECK(stat(\"/tmp\", &stat_buff), 0);\n\nIf it should fail, you’d get a message written to stderr:\n\nsource.c line 19 ’stat(\"/tmp\", &stat_buff)’: expected 0, got -1\n\nClearly it is sometimes inappropriate simply to exit a running program. You may have claimed resources that might not get released, or you may need to write log messages, tidy up open transactions, or inter- act with other processes. The techniques we discuss in When to Use Exceptions, page 125, will help here. However, the basic principle stays the same—when your code discovers that something that was supposed to be impossible just happened, your program is no longer viable. Any- thing it does from this point forward becomes suspect, so terminate it as soon as possible. A dead program normally does a lot less damage than a crippled one.\n\nRelated sections include:\n\nDesign by Contract, page 109 When to Use Exceptions, page 125\n\n121",
      "content_length": 1868,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 147,
      "content": "122\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\n23 Assertive Programming\n\nThere is a luxury in self-reproach. When we blame ourselves we feel no one else has a right to blame us.\n\nOscar Wilde, ThePicture ofDorianGray\n\nIt seems that there’s a mantra that every programmer must memorize early in his or her career. It is a fundamental tenet of computing, a core belief that we learn to apply to requirements, designs, code, comments, just about everything we do. It goes\n\nTHIS CAN NEVER HAPPEN\n\n“This code won’t be used 30 years from now, so two-digit dates are ﬁne.” “This application will never be used abroad, so why internationalize it?” “count can’t be negative.” “This printf can’t fail.”\n\nLet’s not practice this kind of self-deception, particularly when coding.\n\nTIP 33\n\nIf It Can’t Happen, Use Assertions to Ensure That It Won’t\n\nWhenever you ﬁnd yourself thinking “but of course that could never happen,” add code to check it. The easiest way to do this is with asser- tions. In most C and C++ implementations, you’ll ﬁnd some form of assert or _assert macro that checks a Boolean condition. These macros can be invaluable. If a pointer passed in to your procedure should never be NULL, then check for it:\n\nvoid writeString(char *string) { assert(string != NULL); ...\n\nAssertions are also useful checks on an algorithm’s operation. Maybe you’ve written a clever sort algorithm. Check that it works:\n\nfor (int i = 0; i < num_entries-1; i++) { assert(sorted[i] <= sorted[i+1]);\n\n}\n\nOf course, the condition passed to an assertion should not have a side effect (see the box on page 124). Also remember that assertions may be turned off at compile time—never put code that must be executed into an assert.",
      "content_length": 1696,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 148,
      "content": "ASSERTIVE PROGRAMMING\n\nDon’t use assertions in place of real error handling. Assertions check for things that should never happen: you don’t want to be writing code such as\n\nprintf(\"Enter ’Y’ or ’N’: \"); ch = getchar(); assert((ch == ’Y’) || (ch == ’N’));\n\n/* bad idea! */\n\nAnd just because the supplied assert macros call exit when an as- sertion fails, there’s no reason why versions you write should. If you need to free resources, have an assertion failure generate an exception, longjmp to an exit point, or call an error handler. Just make sure the code you execute in those dying milliseconds doesn’t rely on the infor- mation that triggered the assertion failure in the ﬁrst place.\n\nLeaveAssertions Turned On There is a common misunderstanding about assertions, promulgated by the people who write compilers and language environments. It goes something like this:\n\nAssertions add some overhead to code. Because they check for things that should never happen, they’ll get triggered only by a bug in the code. Once the code has been tested and shipped, they are no longer needed, and should be turned off to make the code run faster. Assertions are a debugging facility.\n\nThere are two patently wrong assumptions here. First, they assume that testing ﬁnds all the bugs. In reality, for any complex program you are unlikely to test even a miniscule percentage of the permutations your code will be put through (see Ruthless Testing, page 245). Second, the optimists are forgetting that your program runs in a dangerous world. During testing, rats probably won’t gnaw through a communi- cations cable, someone playing a game won’t exhaust memory, and log ﬁles won’t ﬁll the hard drive. These things might happen when your program runs in a production environment. Your ﬁrst line of defense is checking for any possible error, and your second is using assertions to try to detect those you’ve missed.\n\nTurning off assertions when you deliver a program to production is like crossing a high wire without a net because you once made it across in practice. There’s dramatic value, but it’s hard to get life insurance.\n\nEven if you do have performance issues, turn off only those assertions that really hit you. The sort example above may be a critical part of\n\n123",
      "content_length": 2264,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 149,
      "content": "124\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nAssertions and Side Effects\n\nIt is embarrassing when the code we add to detect errors actually ends up creating new errors. This can happen with assertions if eval- uating the condition has side effects. For example, in Java it would be a bad idea to code something such as\n\nwhile (iter.hasMoreElements()) {\n\nTest.ASSERT(iter.nextElement() != null);\n\nObject obj = iter.nextElement();\n\n// ....\n\n}\n\nThe .nextElement() call in the ASSERT has the side effect of moving the iterator past the element being fetched, and so the loop will process only half the elements in the collection. It would be better to write\n\nwhile (iter.hasMoreElements()) {\n\nObject obj = iter.nextElement();\n\nTest.ASSERT(obj != null);\n\n// ....\n\n}\n\nThis problem is a kind of “Heisenbug”—debugging that changes the behavior of the system being debugged (see [URL 52]).\n\nyour application, and may need to be fast. Adding the check means another pass through the data, which might be unacceptable. Make that particular check optional,2 but leave the rest in.\n\nRelated sections include:\n\nDebugging, page 90 Design by Contract, page 109 How to Balance Resources, page 129 Programming by Coincidence, page 172\n\n2. In C-based languages, you can either use the preprocessor or use if statements to make assertions optional. Many implementations turn off code generation for the assert macro if a compile-time ﬂag is set (or not set). Otherwise, you can place the code within an if statement with a constant condition, which many compilers (including most common Java systems) will optimize away.",
      "content_length": 1590,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 150,
      "content": "WHEN TO USE EXCEPTIONS\n\nExercises 19. A quick reality check. Which of these “impossible” things can happen?\n\n1. A month with fewer than 28 days\n\n2. stat(\".\",&sb) == -1 (that is, can’t access the current directory)\n\n3. In C++:\n\na = 2; b = 3; if (a + b != 5) exit(1);\n\n4. A triangle with an interior angle sum\n\n5. A minute that doesn’t have 60 seconds\n\n6. In Java: (a + 1) <= a\n\n20. Develop a simple assertion checking class for Java.\n\n24 When to Use Exceptions\n\nIn Dead Programs Tell No Lies, page 120, we suggested that it is good practice to check for every possible error—particularly the unexpected ones. However, in practice this can lead to some pretty ugly code; the normal logic of your program can end up being totally obscured by error handling, particularly if you subscribe to the “a routine must have a single return statement” school of programming (we don’t). We’ve seen code that looks something like the following:\n\nretcode = OK; if (socket.read(name) != OK) {\n\nretcode = BAD_READ;\n\n} else {\n\nprocessName(name); if (socket.read(address) != OK) {\n\nretcode = BAD_READ;\n\n} else {\n\nprocessAddress(address); if (socket.read(telNo) != OK) {\n\nretcode = BAD_READ;\n\n} else {\n\n// etc, etc...\n\n}\n\n}\n\n} return retcode;\n\nFortunately, if the programming language supports exceptions, you can rewrite this code in a far neater way:\n\n125\n\nAnswer on p. 290\n\nAnswer on p. 291",
      "content_length": 1373,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 151,
      "content": "126\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nretcode = OK;\n\ntry {\n\nsocket.read(name); process(name);\n\nsocket.read(address); processAddress(address);\n\nsocket.read(telNo); // etc, etc...\n\n} catch (IOException e) { retcode = BAD_READ; Logger.log(\"Error reading individual: \" + e.getMessage());\n\n}\n\nreturn retcode;\n\nThe normal ﬂow of control is now clear, with all the error handling moved off to a single place.\n\nWhatIsExceptional? One of the problems with exceptions is knowing when to use them. We believe that exceptions should rarely be used as part of a program’s normal ﬂow; exceptions should be reserved for unexpected events. Assume that an uncaught exception will terminate your program and ask yourself, “Will this code still run if I remove all the exception han- dlers?” If the answer is “no,” then maybe exceptions are being used in nonexceptional circumstances.\n\nFor example, if your code tries to open a ﬁle for reading and that ﬁle does not exist, should an exception be raised?\n\nOur answer is, “It depends.” If the ﬁle should have been there, then an exception is warranted. Something unexpected happened—a ﬁle you were expecting to exist seems to have disappeared. On the other hand, if you have no idea whether the ﬁle should exist or not, then it doesn’t seem exceptional if you can’t ﬁnd it, and an error return is appropriate.\n\nLet’s look at an example of the ﬁrst case. The following code opens the ﬁle /etc/passwd, which should exist on all Unix systems. If it fails, it passes on the FileNotFoundException to its caller.\n\npublic void open_passwd() throws FileNotFoundException {\n\n// This may throw FileNotFoundException... ipstream = new FileInputStream(\"/etc/passwd\");\n\n// ...\n\n}",
      "content_length": 1692,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 152,
      "content": "WHEN TO USE EXCEPTIONS\n\nHowever, the second case may involve opening a ﬁle speciﬁed by the user on the command line. Here an exception isn’t warranted, and the code looks different:\n\npublic boolean open_user_file(String name)\n\nthrows FileNotFoundException {\n\nFile f = new File(name);\n\nif (!f.exists()) { return false;\n\n}\n\nipstream = new FileInputStream(f); return true;\n\n}\n\nNote that the FileInputStream call can still generate an exception, which the routine passes on. However, the exception will be generated under only truly exceptional circumstances; simply trying to open a ﬁle that does not exist will generate a conventional error return.\n\nTIP 34\n\nUse Exceptions for Exceptional Problems\n\nWhy do we suggest this approach to exceptions? Well, an exception represents an immediate, nonlocal transfer of control—it’s a kind of cascading goto. Programs that use exceptions as part of their normal processing suffer from all the readability and maintainability problems of classic spaghetti code. These programs break encapsulation: rou- tines and their callers are more tightly coupled via exception handling.\n\nErrorHandlersAreanAlternative An error handler is a routine that is called when an error is detected. You can register a routine to handle a speciﬁc category of errors. When one of these errors occurs, the handler will be called.\n\nThere are times when you may want to use error handlers, either in- stead of or alongside exceptions. Clearly, if you are using a language such as C, which does not support exceptions, this is one of your few other options (see the challenge on the next page). However, sometimes error handlers can be used even in languages (such as Java) that have a good exception handling scheme built in.\n\n127",
      "content_length": 1743,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 153,
      "content": "Answer on p. 292\n\n128\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nConsider the implementation of a client-server application, using Java’s Remote Method Invocation (RMI) facility. Because of the way RMI is implemented, every call to a remote routine must be prepared to han- dle a RemoteException. Adding code to handle these exceptions can become tedious, and means that it is difﬁcult to write code that works with both local and remote routines. A possible work-around is to wrap your remote objects in a class that is not remote. This class then imple- ments an error handler interface, allowing the client code to register a routine to be called when a remote exception is detected.\n\nRelated sections include:\n\nDead Programs Tell No Lies, page 120\n\nChallenges\n\nLanguages that do not support exceptions often have some other nonlocal transfer of control mechanism (C has longjmp/setjmp, for example). Con- sider how you could implement some kind of ersatz exception mechanism using these facilities. What are the beneﬁts and dangers? What special steps do you need to take to ensure that resources are not orphaned? Does it make sense to use this kind of solution whenever you code in C?\n\nExercises 21. While designing a new container class, you identify the following possible\n\nerror conditions:\n\n1. No memory available for a new element in the add routine\n\n2. Requested entry not found in the fetch routine\n\n3. null pointer passed to the add routine\n\nHow should each be handled? Should an error be generated, should an exception be raised, or should the condition be ignored?",
      "content_length": 1568,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 154,
      "content": "HOW TO BALANCE RESOURCES\n\n25 How to Balance Resources\n\n“I brought you into this world,” my father would say, “and I can take you out. It don’t make no difference to me. I’ll just make another one like you.”\n\nBill Cosby, Fatherhood\n\nWe all manage resources whenever we code: memory, transactions, threads, ﬁles, timers—all kinds of things with limited availability. Most of the time, resource usage follows a predictable pattern: you allocate the resource, use it, and then deallocate it.\n\nHowever, many developers have no consistent plan for dealing with re- source allocation and deallocation. So let us suggest a simple tip:\n\nTIP 35\n\nFinish What You Start\n\nThis tip is easy to apply in most circumstances. It simply means that the routine or object that allocates a resource should be responsible for deallocating it. Let’s see how it applies by looking at an example of some bad code—an application that opens a ﬁle, reads customer information from it, updates a ﬁeld, and writes the result back. We’ve eliminated error handling to make the example clearer.\n\nvoid readCustomer(const char *fName, Customer *cRec) {\n\ncFile = fopen(fName, \"r+\"); fread(cRec, sizeof(*cRec), 1, cFile);\n\n}\n\nvoid writeCustomer(Customer *cRec) {\n\nrewind(cFile); fwrite(cRec, sizeof(*cRec), 1, cFile); fclose(cFile);\n\n}\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nCustomer cRec;\n\nreadCustomer(fName, &cRec);\n\ncRec.balance = newBalance;\n\nwriteCustomer(&cRec);\n\n}\n\nAt ﬁrst sight, the routine updateCustomer looks pretty good. It seems to implement the logic we require—reading a record, updating the bal- ance, and writing the record back out. However, this tidiness hides a\n\n129",
      "content_length": 1673,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 155,
      "content": "130\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nmajor problem. The routines readCustomer and writeCustomer are tightly coupled3—they share the global variable cFile. readCustomer opens the ﬁle and stores the ﬁle pointer in cFile, and writeCustomer uses that stored pointer to close the ﬁle when it ﬁnishes. This global variable doesn’t even appear in the updateCustomer routine.\n\nWhy is this bad? Let’s consider the unfortunate maintenance program- mer who is told that the speciﬁcation has changed—the balance should be updated only if the new value is not negative. She goes into the source and changes updateCustomer:\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nCustomer cRec;\n\nreadCustomer(fName, &cRec);\n\nif (newBalance >= 0.0) {\n\ncRec.balance = newBalance;\n\nwriteCustomer(&cRec);\n\n}\n\n}\n\nAll seems ﬁne during testing. However, when the code goes into produc- tion, it collapses after several hours, complaining of too many open ﬁles. Because writeCustomer is not getting called in some circumstances, the ﬁle is not getting closed.\n\nA very bad solution to this problem would be to deal with the special case in updateCustomer:\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nCustomer cRec;\n\nreadCustomer(fName, &cRec);\n\nif (newBalance >= 0.0) {\n\ncRec.balance = newBalance;\n\nwriteCustomer(&cRec);\n\n} else\n\nfclose(cFile);\n\n}\n\nThis will ﬁx the problem—the ﬁle will now get closed regardless of the new balance—but the ﬁx now means that three routines are coupled through the global cFile. We’re falling into a trap, and things are going to start going downhill rapidly if we continue on this course.\n\n3. Demeter, page 138.\n\nFor a discussion of the dangers of coupled code, see Decoupling and the Law of",
      "content_length": 1723,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 156,
      "content": "HOW TO BALANCE RESOURCES\n\nThe ﬁnish what you start tip tells us that, ideally, the routine that allo- cates a resource should also free it. We can apply it here by refactoring the code slightly:\n\nvoid readCustomer(FILE *cFile, Customer *cRec) {\n\nfread(cRec, sizeof(*cRec), 1, cFile);\n\n}\n\nvoid writeCustomer(FILE *cFile, Customer *cRec) {\n\nrewind(cFile); fwrite(cRec, sizeof(*cRec), 1, cFile);\n\n}\n\nvoid updateCustomer(const char *fName, double newBalance) {\n\nFILE *cFile; Customer cRec;\n\ncFile = fopen(fName, \"r+\"); readCustomer(cFile, &cRec); if (newBalance >= 0.0) {\n\ncRec.balance = newBalance; writeCustomer(cFile, &cRec);\n\n} fclose(cFile);\n\n// >--- // // // // // // <---\n\n| | | | |\n\n}\n\nNow all the responsibility for the ﬁle is in the updateCustomer routine. It opens the ﬁle and (ﬁnishing what it starts) closes it before exiting. The routine balances the use of the ﬁle: the open and close are in the same place, and it is apparent that for every open there will be a correspond- ing close. The refactoring also removes an ugly global variable.\n\nNestAllocations The basic pattern for resource allocation can be extended for routines that need more than one resource at a time. There are just two more suggestions:\n\n1. Deallocate resources in the opposite order to that in which you allocate them. That way you won’t orphan resources if one resource contains references to another.\n\n2. When allocating the same set of resources in different places in your code, always allocate them in the same order. This will reduce the possibility of deadlock. (If process A claims resource1 and is about to claim resource2, while process B has claimed resource2 and is trying to get resource1, the two processes will wait forever.)\n\nIt doesn’t matter what kind of resources we’re using—transactions, memory, ﬁles, threads, windows—the basic pattern applies: whoever\n\n131",
      "content_length": 1863,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 157,
      "content": "132\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nallocates a resource should be responsible for deallocating it. However, in some languages we can develop the concept further.\n\nObjects andExceptions The equilibrium between allocations and deallocations is reminiscent of a class’s constructor and destructor. The class represents a resource, the constructor gives you a particular object of that resource type, and the destructor removes it from your scope.\n\nIf you are programming in an object-oriented language, you may ﬁnd it useful to encapsulate resources in classes. Each time you need a particular resource type, you instantiate an object of that class. When the object goes out of scope, or is reclaimed by the garbage collector, the object’s destructor then deallocates the wrapped resource.\n\nThis approach has particular beneﬁts when you’re working with lan- guages such as C++, where exceptions can interfere with resource deal- location.\n\nBalancingandExceptions Languages that support exceptions can make resource deallocation tricky. If an exception is thrown, how do you guarantee that every- thing allocated prior to the exception is tidied up? The answer depends to some extent on the language.\n\nBalancing ResourceswithC++Exceptions C++ supports a try catch exception mechanism. Unfortunately, this means that there are always at least two possible paths when exiting a routine that catches and then rethrows an exception:\n\nvoid doSomething(void) {\n\nNode *n = new Node;\n\ntry {\n\n// do something\n\n} catch (...) { delete n; throw;\n\n}\n\ndelete n;\n\n}",
      "content_length": 1546,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 158,
      "content": "HOW TO BALANCE RESOURCES\n\nNotice that the node we create is freed in two places—once in the rou- tine’s normal exit path, and once in the exception handler. This is an obvious violation of the DRY principle and a maintenance problem wait- ing to happen.\n\nHowever, we can use the semantics of C++ to our advantage. Local objects are automatically destroyed on exiting from their enclosing block. This gives us a couple of options. If the circumstances permit, we can change “n” from a pointer to an actual Node object on the stack:\n\nvoid doSomething1(void) {\n\nNode n;\n\ntry {\n\n// do something\n\n} catch (...) {\n\nthrow;\n\n}\n\n}\n\nHere we rely on C++ to handle the destruction of the Node object auto- matically, whether an exception is thrown or not.\n\nIf the switch from a pointer is not possible, the same effect can be achieved by wrapping the resource (in this case, a Node pointer) within another class.\n\n// Wrapper class for Node resources class NodeResource {\n\nNode *n;\n\npublic:\n\nNodeResource() { n = new Node; } ~NodeResource() { delete n; }\n\nNode *operator->() { return n; }\n\n};\n\nvoid doSomething2(void) {\n\nNodeResource n;\n\ntry {\n\n// do something\n\n} catch (...) {\n\nthrow;\n\n}\n\n}\n\nNow the wrapper class, NodeResource, ensures that when its objects are destroyed the corresponding nodes are also destroyed. For conve- nience, the wrapper provides a dereferencing operator ->, so that its users can access the ﬁelds in the contained Node object directly.\n\n133",
      "content_length": 1456,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 159,
      "content": "134\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nBecause this technique is so useful, the standard C++ library provides the template class auto_ptr, which gives you automatic wrappers for dynamically allocated objects.\n\nvoid doSomething3(void) {\n\nauto_ptr<Node> p (new Node);\n\n// Access the Node as p->...\n\n// Node automatically deleted at end\n\n}\n\nBalancing ResourcesinJava Unlike C++, Java implements a lazy form of automatic object destruc- tion. Unreferenced objects are considered to be candidates for garbage collection, and their finalize method will get called should garbage collection ever claim them. While a convenience for developers, who no longer get the blame for most memory leaks, it makes it difﬁcult to implement resource clean-up using the C++ scheme. Fortunately, the designers of the Java language thoughtfully added a language fea- ture to compensate, the finally clause. When a try block contains a finally clause, code in that clause is guaranteed to be executed if any statement in the try block is executed. It doesn’t matter whether an exception is thrown (or even if the code in the try block executes a return)—the code in the finally clause will get run. This means we can balance our resource usage with code such as\n\npublic void doSomething() throws IOException {\n\nFile tmpFile = new File(tmpFileName); FileWriter tmp = new FileWriter(tmpFile);\n\ntry {\n\n// do some work\n\n} finally {\n\ntmpFile.delete();\n\n}\n\n}\n\nThe routine uses a temporary ﬁle, which we want to delete, regardless of how the routine exits. The finally block allows us to express this concisely.\n\nWhenYou Can’t BalanceResources There are times when the basic resource allocation pattern just isn’t appropriate. Commonly this is found in programs that use dynamic",
      "content_length": 1744,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 160,
      "content": "HOW TO BALANCE RESOURCES\n\ndata structures. One routine will allocate an area of memory and link it into some larger structure, where it may stay for some time.\n\nThe trick here is to establish a semantic invariant for memory alloca- tion. You need to decide who is responsible for data in an aggregate data structure. What happens when you deallocate the top-level structure? You have three main options:\n\n1. The top-level structure is also responsible for freeing any substruc- tures that it contains. These structures then recursively delete data they contain, and so on.\n\n2. The top-level structure is simply deallocated. Any structures that it pointed to (that are not referenced elsewhere) are orphaned.\n\n3. The top-level structure refuses to deallocate itself if it contains any\n\nsubstructures.\n\nThe choice here depends on the circumstances of each individual data structure. However, you need to make it explicit for each, and imple- ment your decision consistently. Implementing any of these options in a procedural language such as C can be a problem: data structures themselves are not active. Our preference in these circumstances is to write a module for each major structure that provides standard alloca- tion and deallocation facilities for that structure. (This module can also provide facilities such as debug printing, serialization, deserialization, and traversal hooks.)\n\nFinally, if keeping track of resources gets tricky, you can write your own form of limited automatic garbage collection by implementing a reference counting scheme on your dynamically allocated objects. The book More Effective C++ [Mey96] dedicates a section to this topic.\n\nChecking theBalance Because Pragmatic Programmers trust no one, including ourselves, we feel that it is always a good idea to build code that actually checks that resources are indeed freed appropriately. For most applications, this normally means producing wrappers for each type of resource, and us- ing these wrappers to keep track of all allocations and deallocations. At certain points in your code, the program logic will dictate that the resources will be in a certain state: use the wrappers to check this.\n\n135",
      "content_length": 2185,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 161,
      "content": "Answer on p. 292\n\nAnswer on p. 292\n\n136\n\nCHAPTER 4 PRAGMATIC PARANOIA\n\nFor example, a long-running program that services requests will prob- ably have a single point at the top of its main processing loop where it waits for the next request to arrive. This is a good place to ensure that resource usage has not increased since the last execution of the loop.\n\nAt a lower, but no less useful level, you can invest in tools that (among other things) check your running programs for memory leaks. Purify (www.rational.com) and Insure++ (www.parasoft.com) are popular choices.\n\nRelated sections include:\n\nDesign by Contract, page 109 Assertive Programming, page 122 Decoupling and the Law of Demeter, page 138\n\nChallenges\n\nAlthough there are no guaranteed ways of ensuring that you always free resources, certain design techniques, when applied consistently, will help. In the text we discussed how establishing a semantic invariant for major data structures could direct memory deallocation decisions. Consider how Design by Contract, page 109, could help reﬁne this idea.\n\nExercises 22. Some C and C++ developers make a point of setting a pointer to NULL after\n\nthey deallocate the memory it references. Why is this a good idea?\n\n23. Some Java developers make a point of setting an object variable to NULL\n\nafter they have ﬁnished using the object. Why is this a good idea?",
      "content_length": 1371,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 162,
      "content": "Chapter 5\n\nBend, or Break\n\nLife doesn’t stand still.\n\nNeither can the code that we write. In order to keep up with today’s near-frantic pace of change, we need to make every effort to write code that’s as loose—as ﬂexible—as possible. Otherwise we may ﬁnd our code quickly becoming outdated, or too brittle to ﬁx, and may ultimately be left behind in the mad dash toward the future.\n\nIn Reversibility, on page 44, we talked about the perils of irreversible decisions. In this chapter, we’ll tell you how to make reversible deci- sions, so your code can stay ﬂexible and adaptable in the face of an uncertain world.\n\nFirst we need to look at coupling—the dependencies among modules of code. In Decoupling and the Law of Demeter we’ll show how to keep separate concepts separate, and decrease coupling.\n\nA good way to stay ﬂexible is to write less code. Changing code leaves you open to the possibility of introducing new bugs. Metaprogramming will explain how to move details out of the code completely, where they can be changed more safely and easily.\n\nIn Temporal Coupling, we’ll look at two aspects of time as they relate to coupling. Do you depend on the “tick” coming before the “tock”? Not if you want to stay ﬂexible.\n\nA key concept in creating ﬂexible code is the separation of a data model from a view, or presentation, of that model. We’ll decouple models from views in It’s Just a View.\n\n137",
      "content_length": 1402,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 163,
      "content": "138\n\nCHAPTER 5 BEND, OR BREAK\n\nFinally, there’s a technique for decoupling modules even further by pro- viding a meeting place where modules can exchange data anonymously and asynchronously. This is the topic of Blackboards.\n\nArmed with these techniques, you can write code that will “roll with the punches.”\n\n26 Decoupling and the Law of Demeter\n\nGood fences make good neighbors.\n\nRobert Frost, “Mending Wall”\n\nIn Orthogonality, page 34, and Design by Contract, page 109, we sug- gested that writing “shy” code is beneﬁcial. But “shy” works two ways: don’t reveal yourself to others, and don’t interact with too many people.\n\nSpies, dissidents, revolutionaries, and such are often organized into small groups of people called cells. Although individuals in each cell may know each other, they have no knowledge of those in other cells. If one cell is discovered, no amount of truth serum will reveal the names of others outside the cell. Eliminating interactions between cells pro- tects everyone.\n\nWe feel that this is a good principle to apply to coding as well. Organize your code into cells (modules) and limit the interaction between them. If one module then gets compromised and has to be replaced, the other modules should be able to carry on.\n\nMinimize Coupling What’s wrong with having modules that know about each other? Noth- ing in principle—we don’t need to be as paranoid as spies or dissidents. However, you do need to be careful about how many other modules you interact with and, more importantly, how you came to interact with them.\n\nSuppose you are remodeling your house, or building a house from scratch. A typical arrangement involves a “general contractor.” You hire the contractor to get the work done, but the contractor may or may",
      "content_length": 1756,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 164,
      "content": "DECOUPLING AND THE LAW OF DEMETER\n\nnot do the construction personally; the work may be offered to various subcontractors. But as the client, you are not involved in dealing with the subcontractors directly—the general contractor assumes that set of headaches on your behalf.\n\nWe’d like to follow this same model in software. When we ask an object for a particular service, we’d like the service to be performed on our behalf. We do not want the object to give us a third-party object that we have to deal with to get the required service.\n\nFor example, suppose you are writing a class that generates a graph of scientiﬁc recorder data. You have data recorders spread around the world; each recorder object contains a location object giving its position and time zone. You want to let your users select a recorder and plot its data, labeled with the correct time zone. You might write\n\npublic void plotDate(Date aDate, Selection aSelection) {\n\nTimeZone tz =\n\n...\n\naSelection.getRecorder().getLocation().getTimeZone();\n\n}\n\nBut now the plotting routine is unnecessarily coupled to three classes— Selection, Recorder, and Location. This style of coding dramat- ically increases the number of classes on which our class depends. Why is this a bad thing? It increases the risk that an unrelated change somewhere else in the system will affect your code. For instance, if Fred makes a change to Location such that it no longer directly contains a TimeZone, you have to change your code as well.\n\nRather than digging though a hierarchy yourself, just ask for what you need directly:\n\npublic void plotDate(Date aDate, TimeZone aTz) {\n\n...\n\n}\n\nplotDate(someDate, someSelection.getTimeZone());\n\nWe added a method to Selection to get the time zone on our behalf: the plotting routine doesn’t care whether the time zone comes from the Recorder directly, from some contained object within Recorder, or whether Selection makes up a different time zone entirely. The selection routine, in turn, should probably just ask the recorder for its time zone, leaving it up to the recorder to get it from its contained Location object.\n\n139",
      "content_length": 2116,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 165,
      "content": "140\n\nCHAPTER 5 BEND, OR BREAK\n\nTraversing relationships between objects directly can quickly lead to a combinatorial explosion1 of dependency relationships. You can see symptoms of this phenomenon in a number of ways:\n\n1. Large C or C++ projects where the command to link a unit test is\n\nlonger than the test program itself\n\n2. “Simple” changes to one module that propagate through unrelated\n\nmodules in the system\n\n3. Developers who are afraid to change code because they aren’t sure\n\nwhat might be affected\n\nSystems with many unnecessary dependencies are very hard (and ex- pensive) to maintain, and tend to be highly unstable. In order to keep the dependencies to a minimum, we’ll use the Law of Demeter to design our methods and functions.\n\nTheLawof Demeterfor Functions The Law of Demeter for functions [LH89] attempts to minimize coupling between modules in any given program. It tries to prevent you from reaching into an object to gain access to a third object’s methods. The law is summarized in Figure 5.1 on the next page.\n\nBy writing “shy” code that honors the Law of Demeter as much as pos- sible, we can achieve our objective:\n\nTIP 36\n\nMinimize Coupling Between Modules\n\nDoes ItReallyMakea Difference? While it sounds good in theory, does following the Law of Demeter really help to create more maintainable code?\n\nStudies have shown [BBM96] that classes in C++ with larger response sets are more prone to error than classes with smaller response sets (a\n\n1. If in the other\n\nobjects all know about each other, then a change to just one object can result\n\nobjects needing changes.",
      "content_length": 1594,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 166,
      "content": "DECOUPLING AND THE LAW OF DEMETER\n\nFigure 5.1. Law of Demeter for functions\n\nclass Demeter { private: A *a; int func();\n\npublic:\n\n//... void example(B& b);\n\nThe Law of Demeter for functions states that any method of an object should call only methods belonging to:\n\n}\n\nvoid Demeter::example(B& b) {\n\nC c; int f = func();\n\nitself\n\nb.invert();\n\nany parameters that were passed in to the method\n\na = new A();\n\na->setActive();\n\nany objects it created\n\nc.print();\n\nany directly held component objects\n\n}\n\nresponse set is deﬁned to be the number of functions directly invoked by methods of the class).\n\nBecause following the Law of Demeter reduces the size of the response set in the calling class, it follows that classes designed in this way will also tend to have fewer errors (see [URL 56] for more papers and information on the Demeter project).\n\nUsing The Law of Demeter will make your code more adaptable and robust, but at a cost: as a “general contractor,” your module must dele- gate and manage any and all subcontractors directly, without involving clients of your module. In practice, this means that you will be writing a large number of wrapper methods that simply forward the request on to a delegate. These wrapper methods will impose both a runtime cost and a space overhead, which may be signiﬁcant—even prohibitive—in some applications.\n\nAs with any technique, you must balance the pros and cons for your particular application. In database schema design it is common prac- tice to “denormalize” the schema for a performance improvement: to\n\n141",
      "content_length": 1558,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 167,
      "content": "142\n\nCHAPTER 5 BEND, OR BREAK\n\nPhysical Decoupling\n\nIn this section we’re concerned largely with designing to keep things logically decoupled within systems. However, there is another kind of interdependence that becomes highly signiﬁcant as systems grow larger. In his book Large-ScaleC++SoftwareDesign [Lak96], John Lakos addresses the issues surrounding the relationships among the ﬁles, directories, and libraries that make up a system. Large projects that ignore thesephysicaldesignproblems wind up with build cycles that are measured in days and unit tests that may drag in the entire system as support code, among other problems. Mr. Lakos argues convincingly that logical and physical design must proceed in tandem—that undoing the damage done to a large body of code by cyclic dependencies is extremely difﬁcult. We recommend this book if you are involved in large-scale developments, even if C++ isn’t your implementation language.\n\nviolate the rules of normalization in exchange for speed. A similar trade- off can be made here as well. In fact, by reversing the Law of Demeter and tightly coupling several modules, you may realize an important performance gain. As long as it is well known and acceptable for those modules to be coupled, your design is ﬁne.\n\nOtherwise, you may ﬁnd yourself on the road to a brittle, inﬂexible future. Or no future at all.\n\nRelated sections include: Orthogonality, page 34 Reversibility, page 44 Design by Contract, page 109 How to Balance Resources, page 129 It’s Just a View, page 157 Pragmatic Teams, page 224 Ruthless Testing, page 237\n\nChallenges\n\nWe’ve discussed how using delegation makes it easier to obey the Law of Demeter and hence reduce coupling. However, writing all of the methods",
      "content_length": 1740,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 168,
      "content": "DECOUPLING AND THE LAW OF DEMETER\n\n143\n\nneeded to forward calls to delegated classes is boring and error prone. What are the advantages and disadvantages of writing a preprocessor that generates these calls automatically? Should this preprocessor be run only once, or should it be used as part of the build?\n\nExercises 24. We discussed the concept of physical decoupling in the box on on the facing page. Which of the following C++ header ﬁles is more tightly coupled to the rest of the system?\n\nperson1.h:\n\nperson2.h:\n\n#include \"date.h\"\n\nclass Date;\n\nclass Person1 { private:\n\nclass Person2 { private:\n\nDate myBirthdate;\n\nDate *myBirthdate;\n\npublic:\n\npublic:\n\nPerson1(Date &birthDate); // ...\n\nPerson2(Date &birthDate); // ...\n\n25. For the example below and for those in Exercises 26 and 27, determine if the method calls shown are allowed according to the Law of Demeter. This ﬁrst one is in Java. public void showBalance(BankAccount acct) {\n\nMoney amt = acct.getBalance(); printToScreen(amt.printFormat());\n\n}\n\n26. This example is also in Java.\n\npublic class Colada {\n\nprivate Blender myBlender; private Vector myStuff;\n\npublic Colada() {\n\nmyBlender = new Blender(); myStuff = new Vector();\n\n} private void doSomething() {\n\nmyBlender.addIngredients(myStuff.elements());\n\n}\n\n}\n\n27. This example is in C++.\n\nvoid processTransaction(BankAccount acct, int) {\n\nPerson *who; Money amt;\n\namt.setValue(123.45); acct.setBalance(amt); who = acct.getOwner(); markWorkflow(who->name(), SET_BALANCE);\n\n}\n\nAnswer on p. 293\n\nAnswer on p. 294\n\nAnswer on p. 294",
      "content_length": 1547,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 169,
      "content": "144\n\nCHAPTER 5 BEND, OR BREAK\n\n27 Metaprogramming\n\nNo amount of genius can overcome a preoccupation with detail.\n\nLevy’s Eighth Law\n\nDetails mess up our pristine code—especially if they change frequently. Every time we have to go in and change the code to accommodate some change in business logic, or in the law, or in management’s personal tastes of the day, we run the risk of breaking the system—of introducing a new bug.\n\nSo we say “out with the details!” Get them out of the code. While we’re at it, we can make our code highly conﬁgurable and “soft”—that is, easily adaptable to changes.\n\nDynamic Conﬁguration First, we want to make our systems highly conﬁgurable. Not just things such as screen colors and prompt text, but deeply ingrained items such as the choice of algorithms, database products, middleware technology, and user-interface style. These items should be implemented as con- ﬁguration options, not through integration or engineering.\n\nTIP 37\n\nConﬁgure, Don’t Integrate\n\nUse metadata to describe conﬁguration options for an application: tun- ing parameters, user preferences, the installation directory, and so on.\n\nWhat exactly is metadata? Strictly speaking, metadata is data about data. The most common example is probably a database schema or data dictionary. A schema contains data that describes ﬁelds (columns) in terms of names, storage lengths, and other attributes. You should be able to access and manipulate this information just as you would any other data in the database.\n\nWe use the term in its broadest sense. Metadata is any data that describes the application—how it should run, what resources it should use, and so on. Typically, metadata is accessed and used at runtime, not at compile time. You use metadata all the time—at least your pro- grams do. Suppose you click on an option to hide the toolbar on your",
      "content_length": 1852,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 170,
      "content": "METAPROGRAMMING\n\nWeb browser. The browser will store that preference, as metadata, in some sort of internal database.\n\nThis database might be in a proprietary format, or it might use a stan- dard mechanism. Under Windows, either an initialization ﬁle (using the sufﬁx .ini) or entries in the system Registry are typical. Under Unix, the X Window System provides similar functionality using Application Default ﬁles. Java uses Property ﬁles. In all of these environments, you specify a key to retrieve a value. Alternatively, more powerful and ﬂex- ible implementations of metadata use an embedded scripting language (see Domain Languages, page 57, for details).\n\nThe Netscape browser has actually implemented preferences using both of these techniques. In Version 3, preferences were saved as simple key/value pairs:\n\nSHOW_TOOLBAR: False\n\nLater, Version 4 preferences looked more like JavaScript:\n\nuser_pref(\"custtoolbar.Browser.Navigation_Toolbar.open\", false);\n\nMetadata-DrivenApplications But we want to go beyond using metadata for simple preferences. We want to conﬁgure and drive the application via metadata as much as possible. Our goal is to think declaratively (specifying what is to be done, not how) and create highly dynamic and adaptable programs. We do this by adopting a general rule: program for the general case, and put the speciﬁcs somewhere else—outside the compiled code base.\n\nTIP 38\n\nPut Abstractions in Code, Details in Metadata\n\nThere are several beneﬁts to this approach:\n\nIt forces you to decouple your design, which results in a more ﬂex- ible and adaptable program.\n\nIt forces you to create a more robust, abstract design by deferring details—deferring them all the way out of the program.\n\n145",
      "content_length": 1724,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 171,
      "content": "146\n\nCHAPTER 5 BEND, OR BREAK\n\nYou can customize the application without recompiling it. You can also use this level of customization to provide easy work-arounds for critical bugs in live production systems.\n\nMetadata can be expressed in a manner that’s much closer to the problem domain than a general-purpose programming language might be (see Domain Languages, page 57).\n\nYou may even be able to implement several different projects using the same application engine, but with different metadata.\n\nWe want to defer deﬁnition of most details until the last moment, and leave the details as soft—as easy to change—as we can. By crafting a solution that allows us to make changes quickly, we stand a better chance of coping with the ﬂood of directional shifts that swamp many projects (see Reversibility, page 44).\n\nBusinessLogic So you’ve made the choice of database engine a conﬁguration option, and provided metadata to determine the user-interface style. Can we do more? Deﬁnitely.\n\nBecause business policy and rules are more likely to change than any other aspect of the project, it makes sense to maintain them in a very ﬂexible format.\n\nFor example, your purchasing application may include various corpo- rate policies. Maybe you pay small suppliers in 45 days and large ones in 90 days. Make the deﬁnitions of the supplier types, as well as the time periods themselves, conﬁgurable. Take the opportunity to gener- alize.\n\nMaybe you are writing a system with horrendous workﬂow require- ments. Actions start and stop according to complex (and changing) business rules. Consider encoding them in some kind of rule-based (or expert) system, embedded within your application. That way, you’ll conﬁgure it by writing rules, not cutting code.\n\nLess complex logic can be expressed using a mini-language, removing the need to recompile and redeploy when the environment changes. Have a look at page 58 for an example.",
      "content_length": 1918,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 172,
      "content": "METAPROGRAMMING\n\nWhen to Conﬁgure\n\nAs mentioned in ThePowerofPlainText, page 73, we recommend representing conﬁguration metadata in plain text—it makes life that much easier.\n\nBut when should a program read this conﬁguration? Many programs will scan such things only at startup, which is unfortunate. If you need to change the conﬁguration, this forces you to restart the application. A more ﬂexible approach is to write programs that can reload their conﬁguration while they’re running. This ﬂexibility comes at a cost: it is more complex to implement.\n\nSo consider how your application will be used: if it is a long-running server process, you will want to provide some way to reread and apply metadata while the program is running. For a small client GUI appli- cation that restarts quickly, you may not need to.\n\nThis phenomenon is not limited to application code. We’ve all been annoyed at operating systems that force us to reboot when we install some simple application or change an innocuous parameter.\n\nAn Example:Enterprise JavaBeans Enterprise Java Beans (EJB) is a framework for simplifying program- ming in a distributed, transaction-based environment. We mention it here because EJB illustrates how metadata can be used both to conﬁg- ure applications and to reduce the complexity of writing code.\n\nSuppose you want to create some Java software that will participate in transactions across different machines, between different database vendors, and with different thread and load-balancing models.\n\nThe good news is, you don’t have to worry about all that. You write a bean—a self-contained object that follows certain conventions—and place it in a bean container that manages much of the low-level detail on your behalf. You can write the code for a bean without including any transaction operations or thread management; EJB uses metadata to specify how transactions should be handled.\n\nThread allocation and load balancing are speciﬁed as metadata to the underlying transaction service that the container uses. This separation\n\n147",
      "content_length": 2049,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 173,
      "content": "148\n\nCHAPTER 5 BEND, OR BREAK\n\nallows us great ﬂexibility to conﬁgure the environment dynamically, at runtime.\n\nThe bean’s container can manage transactions on the bean’s behalf in one of several different styles (including an option where you control your own commits and rollbacks). All of the parameters that affect the bean’s behavior are speciﬁed in the bean’s deployment descriptor—a serialized object that contains the metadata we need.\n\nDistributed systems such as EJB are leading the way into a new world of conﬁgurable, dynamic systems.\n\nCooperativeConﬁguration We’ve talked about users and developers conﬁguring dynamic applica- tions. But what happens if you let applications conﬁgure each other— software that adapts itself to its environment? Unplanned, spur-of-the- moment conﬁguration of existing software is a powerful concept.\n\nOperating systems already conﬁgure themselves to hardware as they boot, and Web browsers update themselves with new components auto- matically.\n\nYour larger applications probably already have issues with handling dif- ferent versions of data and different releases of libraries and operating systems. Perhaps a more dynamic approach will help.\n\nDon’t WriteDodo-Code Without metadata, your code is not as adaptable or ﬂexible as it could be. Is this a bad thing? Well, out here in the real world, species that don’t adapt die.\n\nThe dodo didn’t adapt to the presence of humans and their livestock on the island of Mauritius, and quickly became extinct.2 It was the ﬁrst documented extinction of a species at the hand of man.\n\nDon’t let your project (or your career) go the way of the dodo.\n\n2. for sport.\n\nIt didn’t help that the settlers beat the placid (read stupid) birds to death with clubs",
      "content_length": 1738,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 174,
      "content": "METAPROGRAMMING\n\nRelated sections include: Orthogonality, page 34 Reversibility, page 44 Domain Languages, page 57 The Power of Plain Text, page 73\n\nChallenges\n\nFor your current project, consider how much of the application might be moved out of the program itself to metadata. What would the resultant “engine” look like? Would you be able to reuse that engine in the context of a different application?\n\nExercises 28. Which of the following things would be better represented as code within\n\na program, and which externally as metadata?\n\n1. Communication port assignments\n\n2. An editor’s support for highlighting the syntax of various languages\n\n3. An editor’s support for different graphic devices\n\n4. A state machine for a parser or scanner\n\n5. Sample values and results for use in unit testing\n\n149\n\nAnswer on p. 295",
      "content_length": 821,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 175,
      "content": "28\n\n150\n\nCHAPTER 5 BEND, OR BREAK\n\nTemporal Coupling\n\nWhat is temporal coupling all about, you may ask. It’s about time.\n\nTime is an often ignored aspect of software architectures. The only time that preoccupies us is the time on the schedule, the time left until we ship—but this is not what we’re talking about here. Instead, we are talking about the role of time as a design element of the software itself. There are two aspects of time that are important to us: concurrency (things happening at the same time) and ordering (the relative positions of things in time).\n\nWe don’t usually approach programming with either of these aspects in mind. When people ﬁrst sit down to design an architecture or write a program, things tend to be linear. That’s the way most people think— do this and then always do that. But thinking this way leads to tempo- ral coupling: coupling in time. Method A must always be called before method B; only one report can be run at a time; you must wait for the screen to redraw before the button click is received. Tick must happen before tock.\n\nThis approach is not very ﬂexible, and not very realistic.\n\nWe need to allow for concurrency3 and to think about decoupling any time or order dependencies. In doing so, we can gain ﬂexibility and reduce any time-based dependencies in many areas of development: workﬂow analysis, architecture, design, and deployment.\n\nWorkﬂow On many projects, we need to model and analyze the users’ workﬂows as part of requirements analysis. We’d like to ﬁnd out what can happen at the same time, and what must happen in a strict order. One way to do this is to capture their description of workﬂow using a notation such as the UML activity diagram.4\n\n3. We won’t go into the details of concurrent or parallel programming here; a good computer science textbook should cover the basics, including scheduling, deadlock, star- vation, mutual exclusion/semaphores, and so on.\n\n4.\n\nFor more information on all of the UML diagram types, see [FS97].",
      "content_length": 2003,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 176,
      "content": "TEMPORAL COUPLING\n\nAn activity diagram consists of a set of actions drawn as rounded boxes. The arrow leaving an action leads to either another action (which can start once the ﬁrst action completes) or to a thick line called a synchro- nization bar. Once all the actions leading into a synchronization bar are complete, you can then proceed along any arrows leaving the bar. An action with no arrows leading into it can be started at any time.\n\nYou can use activity diagrams to maximize parallelism by identifying activities that could be performed in parallel, but aren’t.\n\nTIP 39\n\nAnalyze Workﬂow to Improve Concurrency\n\nFor instance, in our blender project (Exercise 17, page 119), users may initially describe their current workﬂow as follows.\n\n1. Open blender 2. Open piña colada mix 3. Put mix in blender 4. Measure 1/2 cup white rum 5. Pour in rum 6. Add 2 cups of ice 7. Close blender 8. Liquefy for 2 minutes 9. Open blender\n\n10. Get glasses 11. Get pink umbrellas 12. Serve\n\nEven though they describe these actions serially, and may even per- form them serially, we notice that many of them could be performed in parallel, as we show in the activity diagram in Figure 5.2 on the next page.\n\nIt can be eye-opening to see where the dependencies really exist. In this instance, the top-level tasks (1, 2, 4, 10, and 11) can all happen concurrently, up front. Tasks 3, 5, and 6 can happen in parallel later.\n\nIf you were in a piña colada-making contest, these optimizations may make all the difference.\n\n151",
      "content_length": 1514,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 177,
      "content": "152\n\nCHAPTER 5 BEND, OR BREAK\n\nFigure 5.2. UML activity diagram: making a piña colada\n\n2.\n\nOpen mix\n\n1.\n\nOpen blender\n\n4.\n\nMeasure rum\n\n3.\n\nPut mix in\n\n6.\n\nAdd two cups ice\n\n5.\n\nPour in rum\n\n7.\n\nClose blender\n\n11.\n\nGet pink umbrellas\n\n8.\n\nLiquefy\n\n10.\n\nGet glasses\n\n9.\n\nOpen blender\n\n12.\n\nServe\n\nArchitecture We wrote an On-Line Transaction Processing (OLTP) system a few years ago. At its simplest, all the system had to do was read a request and process the transaction against the database. But we wrote a three- tier, multiprocessing distributed application: each component was an independent entity that ran concurrently with all other components. While this sounds like more work, it wasn’t: taking advantage of tem- poral decoupling made it easier to write. Let’s take a closer look at this project.\n\nThe system takes in requests from a large number of data communica- tion lines and processes transactions against a back-end database.\n\nThe design addresses the following constraints:",
      "content_length": 991,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 178,
      "content": "TEMPORAL COUPLING\n\nFigure 5.3. OLTP architecture overview\n\nInput task #1\n\nApp’n\n\nApp. logic #1\n\nDatabase\n\nInput task #2\n\nDatabase handler\n\nQueue\n\nApp. logic #n\n\nQueue\n\nInput task #n\n\nDatabase operations take a relatively long time to complete.\n\nFor each transaction, we must not block communication services while a database transaction is being processed.\n\nDatabase performance suffers with too many concurrent sessions.\n\nMultiple transactions are in progress concurrently on each data line.\n\nThe solution that gave us the best performance and cleanest architec- ture looked something like Figure 5.3.\n\nEach box represents a separate process; processes communicate via work queues. Each input process monitors one incoming communica- tion line, and makes requests to the application server. All requests are asynchronous: as soon as the input process makes its current request, it goes back to monitoring the line for more trafﬁc. Similarly, the appli- cation server makes requests of the database process,5 and is notiﬁed when the individual transaction is complete.\n\nThis example also shows a way to get quick and dirty load balancing among multiple consumer processes: the hungry consumer model.\n\n5. Even though we show the database as a single, monolithic entity, it is not. The database software is partitioned into several processes and client threads, but this is handled internally by the database software and isn’t part of our example.\n\n153",
      "content_length": 1451,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 179,
      "content": "154\n\nCHAPTER 5 BEND, OR BREAK\n\nIn a hungry consumer model, you replace the central scheduler with a number of independent consumer tasks and a centralized work queue. Each consumer task grabs a piece from the work queue and goes on about the business of processing it. As each task ﬁnishes its work, it goes back to the queue for some more. This way, if any particular task gets bogged down, the others can pick up the slack, and each individual component can proceed at its own pace. Each component is temporally decoupled from the others.\n\nTIP 40\n\nDesign Using Services\n\nInstead of components, we have really created services—independent, concurrent objects behind well-deﬁned, consistent interfaces.\n\nDesign for Concurrency The rising acceptance of Java as a platform has exposed more devel- opers to multithreaded programming. But programming with threads imposes some design constraints—and that’s a good thing. Those con- straints are actually so helpful that we want to abide by them whenever we program. It will help us decouple our code and ﬁght programming by coincidence (see page 172).\n\nWith linear code, it’s easy to make assumptions that lead to sloppy programming. But concurrency forces you to think through things a bit more carefully—you’re not alone at the party anymore. Because things can now happen at the “same time,” you may suddenly see some time- based dependencies.\n\nTo begin with, any global or static variables must be protected from concurrent access. Now may be a good time to ask yourself why you need a global variable in the ﬁrst place. In addition, you need to make sure that you present consistent state information, regardless of the order of calls. For example, when is it valid to query the state of your object? If your object is in an invalid state between certain calls, you may be relying on a coincidence that no one can call your object at that point in time.",
      "content_length": 1904,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 180,
      "content": "TEMPORAL COUPLING\n\nSuppose you have a windowing subsystem where the widgets are ﬁrst created and then shown on the display in two separate steps. You aren’t allowed to set state in the widget until it is shown. Depending on how the code is set up, you may be relying on the fact that no other object can use the created widget until you’ve shown it on the screen.\n\nBut this may not be true in a concurrent system. Objects must always be in a valid state when called, and they can be called at the most awk- ward times. You must ensure that an object is in a valid state any time it could possibly be called. Often this problem shows up with classes that deﬁne separate constructor and initialization routines (where the constructor doesn’t leave the object in an initialized state). Using class invariants, discussed in Design by Contract, page 109, will help you avoid this trap.\n\nCleanerInterfaces Thinking about concurrency and time-ordered dependencies can lead you to design cleaner interfaces as well. Consider the C library routine strtok, which breaks a string into tokens.\n\nThe design of strtok isn’t thread safe,6 but that isn’t the worst part: look at the time dependency. You must make the ﬁrst call to strtok with the variable you want to parse, and all successive calls with a NULL instead. If you pass in a non-NULL value, it restarts the parse on that buffer instead. Without even considering threads, suppose you wanted to use strtok to parse two separate strings at the same time:\n\nchar buf1[BUFSIZ]; char buf2[BUFSIZ]; char *p, *q;\n\nstrcpy(buf1, \"this is a test\"); strcpy(buf2, \"this ain’t gonna work\");\n\np = strtok(buf1, \" \"); q = strtok(buf2, \" \"); while (p && q) {\n\nprintf(\"%s %s n\", p, q); p = strtok(NULL, \" \"); q = strtok(NULL, \" \");\n\n}\n\n6. It uses static data to maintain the current position in the buffer. The static data isn’t protected against concurrent access, so it isn’t thread safe. In addition, it clobbers the ﬁrst argument you pass in, which can lead to some nasty surprises.\n\n155",
      "content_length": 2018,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 181,
      "content": "156\n\nCHAPTER 5 BEND, OR BREAK\n\nThe code as shown will not work: there is implicit state retained in strtok between calls. You have to use strtok on just one buffer at a time.\n\nNow in Java, the design of a string parser has to be different. It must be thread safe and present a consistent state.\n\nStringTokenizer st1 = new StringTokenizer(\"this is a test\"); StringTokenizer st2 = new StringTokenizer(\"this test will work\");\n\nwhile (st1.hasMoreTokens() && st2.hasMoreTokens()) {\n\nSystem.out.println(st1.nextToken()); System.out.println(st2.nextToken());\n\n}\n\nStringTokenizer is a much cleaner, more maintainable, interface. It contains no surprises, and won’t cause mysterious bugs in the future, as strtok might.\n\nTIP 41\n\nAlways Design for Concurrency\n\nDeployment Once you’ve designed an architecture with an element of concurrency, it becomes easier to think about handling many concurrent services: the model becomes pervasive.\n\nNow you can be ﬂexible as to how the application is deployed: stand- alone, client-server, or n-tier. By architecting your system as inde- pendent services, you can make the conﬁguration dynamic as well. By planning for concurrency, and decoupling operations in time, you have all these options—including the stand-alone option, where you can choose not to be concurrent.\n\nGoing the other way (trying to add concurrency to a nonconcurrent application) is much harder. If we design to allow for concurrency, we can more easily meet scalability or performance requirements when the time comes—and if the time never comes, we still have the beneﬁt of a cleaner design.\n\nIsn’t it about time?",
      "content_length": 1616,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 182,
      "content": "29\n\nIT’S JUST A VIEW\n\nRelated sections include:\n\nDesign by Contract, page 109 Programming by Coincidence, page 172\n\nChallenges\n\nHow many tasks do you perform in parallel when you get ready for work in the morning? Could you express this in a UML activity diagram? Can you ﬁnd some way to get ready more quickly by increasing concurrency?\n\nIt’s Just a View\n\nStill, a man hears What he wants to hear And disregards the rest La la la. ..\n\nSimon and Garfunkel, “The Boxer”\n\nEarly on we are taught not to write a program as a single big chunk, but that we should “divide and conquer” and separate a program into mod- ules. Each module has its own responsibilities; in fact, a good deﬁnition of a module (or class) is that it has a single, well-deﬁned responsibility.\n\nBut once you separate a program into different modules based on responsibility, you have a new problem. At runtime, how do the objects talk to each other? How do you manage the logical dependencies between them? That is, how do you synchronize changes in state (or updates to data values) in these different objects? It needs to be done in a clean, ﬂexible manner—we don’t want them to know too much about each other. We want each module to be like the man in the song and just hear what it wants to hear.\n\nWe’ll start off with the concept of an event. An event is simply a special message that says “something interesting just happened” (interesting, of course, lies in the eye of the beholder). We can use events to signal changes in one object that some other object may be interested in.\n\nUsing events in this way minimizes coupling between those objects— the sender of the event doesn’t need to have any explicit knowledge of\n\n157",
      "content_length": 1698,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 183,
      "content": "158\n\nCHAPTER 5 BEND, OR BREAK\n\nthe receiver. In fact, there could be multiple receivers, each one focused on its own agenda (of which the sender is blissfully unaware).\n\nWe need to exercise some care in using events, however. In an early ver- sion of Java, for example, one routine received all the events destined for a particular application. Not exactly the road to easy maintenance or evolution.\n\nPublish/Subscribe Why is it bad to push all the events through a single routine? It vio- lates object encapsulation—that one routine now has to have intimate knowledge of the interactions among many objects. It also increases the coupling—and we’re trying to decrease coupling. Because the objects themselves have to have knowledge of these events as well, you are probably going to violate the DRY principle, orthogonality, and perhaps even sections of the Geneva Convention. You may have seen this kind of code—it is usually dominated by a huge case statement or multiway if-then. We can do better.\n\nObjects should be able to register to receive only the events they need, and should never be sent events they don’t need. We don’t want to spam our objects! Instead, we can use a publish/subscribe protocol, illustrated using the UML sequence diagram in Figure 5.4 on the next page.7\n\nA sequence diagram shows the ﬂow of messages among several objects, with objects arranged in columns. Each message is shown as a labeled arrow from the sender’s column to the receiver’s column. An asterisk in the label means that more than one message of this type can be sent.\n\nIf we are interested in certain events generated by a Publisher, all we have to do is register ourselves. The Publisher keeps track of all in- terested Subscriber objects; when the Publisher generates an event of interest, it will call each Subscriber in turn and notify them that the event has occurred.\n\n7.\n\nSee also the Observer pattern in [GHJV95] for more information.",
      "content_length": 1939,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 184,
      "content": "IT’S JUST A VIEW\n\nFigure 5.4. Publish/subscribe protocol\n\nSubscriber one\n\nSubscriber two\n\nPublisher\n\nregister\n\nnotify*\n\nregister\n\nnotify*\n\nnotify*\n\nunsubscribe\n\nnotify*\n\nThere are several variations on this theme—mirroring other commu- nication styles. Objects may use publish/subscribe on a peer-to-peer basis (as we saw above); they may use a “software bus” where a centralized object maintains the database of listeners and dispatches messages appropriately. You might even have a scheme where critical events get broadcast to all listeners—registered or not. One possible implementation of events in a distributed environment is illustrated by the CORBA Event Service, described in the box on the following page.\n\nWe can use this publish/subscribe mechanism to implement a very important design concept: the separation of a model from views of the model. Let’s start with a GUI-based example, using the Smalltalk design in which this concept was born.\n\nModel-View-Controller Suppose you have a spreadsheet application. In addition to the num- bers in the spreadsheet itself, you also have a graph that displays the\n\n159",
      "content_length": 1123,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 185,
      "content": "160\n\nCHAPTER 5 BEND, OR BREAK\n\nThe CORBA Event Service\n\nThe CORBA Event Service allows participating objects to send and receive event notiﬁcations via a common bus, the eventchannel. The event channel arbitrates event handling, and also decouples event producers from event consumers. It works in two basic ways: push and pull.\n\nIn push mode, event suppliers inform the event channel that an event has occurred. The channel then automatically distributes that event to all client objects that have registered interest.\n\nIn pull mode, clients periodically poll the event channel, which in turn polls the supplier that offers event data corresponding to the request.\n\nAlthough the CORBA Event Service can be used to implement all of the event models discussed in this section, you can also view it as a different animal. CORBA facilitates communication among objects written in different programming languages running on geographi- cally dispersed machines with different architectures. Sitting on top of CORBA, the event service gives you a decoupled way of interact- ing with applications around the world, written by people you’ve never met, using programming languages you’d rather not know about.\n\nnumbers as a bar chart and a running total dialog box that shows the sum of a column in the spreadsheet.\n\nObviously, we don’t want to have three separate copies of the data. So we create a model—the data itself, with common operations to manip- ulate it. Then we can create separate views that display the data in different ways: as a spreadsheet, as a graph, or in a totals box. Each of these views may have its own controller. The graph view may have a controller that allows you to zoom in or out, or pan around the data, for example. None of this affects the data itself, just that view.\n\nThis is the key concept behind the Model-View-Controller (MVC) idiom: separating the model from both the GUI that represents it and the con- trols that manage the view.8\n\n8. the view and controller are a single component.\n\nThe view and controller are tightly coupled, and in some implementations of MVC",
      "content_length": 2097,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 186,
      "content": "IT’S JUST A VIEW\n\nBy doing so, you can take advantage of some interesting possibilities. You can support multiple views of the same data model. You can use common viewers on many different data models. You can even support multiple controllers to provide nontraditional input mechanisms.\n\nTIP 42\n\nSeparate Views from Models\n\nBy loosening the coupling between the model and the view/controller, you buy yourself a lot of ﬂexibility at low cost. In fact, this technique is one of the most important ways of maintaining reversibility (see Reversibility, page 44).\n\nJavaTree View A good example of an MVC design can be found in the Java tree widget. The tree widget (which displays a clickable, traversable tree) is actually a set of several different classes organized in an MVC pattern.\n\nTo produce a fully functional tree widget, all you need to do is provide a data source that conforms to the TreeModel interface. Your code now becomes the model for the tree.\n\nThe view is created by the TreeCellRenderer and TreeCellEditor classes, which can be inherited from and customized to provide differ- ent colors, fonts, and icons in the widget. JTree acts as the controller for the tree widget and provides some general viewing functionality.\n\nBecause we have decoupled the model from the view, we simplify the programming a great deal. You don’t have to think about programming a tree widget anymore. Instead, you just provide a data source.\n\nSuppose the vice president comes up to you and wants a quick appli- cation that lets her navigate the company’s organizational chart, which is held in a legacy database on the mainframe. Just write a wrapper that takes the mainframe data, presents it as a TreeModel, and voilà: you have a fully navigable tree widget.\n\nNow you can get fancy and start using the viewer classes; you can change how nodes are rendered, and use special icons, fonts, or colors. When the VP comes back and says the new corporate standards dictate\n\n161",
      "content_length": 1968,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 187,
      "content": "162\n\nCHAPTER 5 BEND, OR BREAK\n\nthe use of a Skull and Crossbones icon for certain employees, you can make the changes to TreeCellRenderer without touching any other code.\n\nBeyond GUIs While MVC is typically taught in the context of GUI development, it is really a general-purpose programming technique. The view is an inter- pretation of the model (perhaps a subset)—it doesn’t need to be graph- ical. The controller is more of a coordination mechanism, and doesn’t have to be related to any sort of input device.\n\nModel. The abstract data model representing the target object. The model has no direct knowledge of any views or controllers.\n\nView. A way to interpret the model. It subscribes to changes in the model and logical events from the controller.\n\nController. A way to control the view and provide the model with new data. It publishes events to both the model and the view.\n\nLet’s look at a nongraphical example.\n\nBaseball is a unique institution. Where else can you learn such gems of trivia as “this has become the highest-scoring game played on a Tues- day, in the rain, under artiﬁcial lights, between teams whose names start with a vowel?” Suppose we were charged with developing software to support those intrepid announcers who must dutifully report on the scores, the statistics, and the trivia.\n\nClearly we need information on the game in progress—the teams play- ing, the conditions, the player at bat, the score, and so on. These facts form our models; they will be updated as new information arrives (a pitcher is changed, a player strikes out, it starts raining\n\n).\n\nWe’ll then have a number of view objects that use these models. One view might look for runs so it can update the current score. Another may receive notiﬁcations of new batters, and retrieve a brief summary of their year-to-date statistics. A third viewer may look at the data and check for new world records. We might even have a trivia viewer, responsible for coming up with those weird and useless facts that thrill the viewing public.",
      "content_length": 2028,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 188,
      "content": "IT’S JUST A VIEW\n\nFigure 5.5. Baseball reporting. Viewers subscribetomodels.\n\nScore collector\n\nTV feed generator\n\nScores\n\nBatter stats\n\nDisplay ﬁlter\n\nWeb page formatter\n\nRecords\n\nConditions\n\nTrivia\n\nTele- prompter\n\nsubscribes to\n\nmodel\n\nviewer\n\nBut we don’t want to ﬂood the poor announcer with all of these views directly. Instead, we’ll have each view generate notiﬁcations of “inter- esting” events, and let some higher-level object schedule what gets shown.9\n\nThese viewer objects have suddenly become models for the higher-level object, which itself might then be a model for different formatting view- ers. One formatting viewer might create the teleprompter script for the announcer, another might generate video captions directly on the satel- lite uplink, another might update the network’s or team’s Web pages (see Figure 5.5).\n\nThis kind of model-viewer network is a common (and valuable) design technique. Each link decouples raw data from the events that created it—each new viewer is an abstraction. And because the relationships are a network (not just a linear chain), we have a lot of ﬂexibility. Each\n\n9. plane to ﬂy overhead that night.\n\nThe fact that a plane ﬂies overhead probably isn’t interesting unless it’s the 100th\n\n163",
      "content_length": 1247,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 189,
      "content": "Answer on p. 296\n\n164\n\nCHAPTER 5 BEND, OR BREAK\n\nmodel may have many viewers, and one viewer may work with multiple models.\n\nIn advanced systems such as this one, it can be handy to have de- bugging views—specialized views that show you in-depth details of the model. Adding a facility to trace individual events can be a great time saver as well.\n\nStill Coupled (After All TheseYears) Despite the decrease in coupling we have achieved, listeners and event generators (subscribers and publishers) still have some knowledge of each other. In Java, for instance, they must agree on common interface deﬁnitions and calling conventions.\n\nIn the next section, we’ll look at ways of reducing coupling even further by using a form of publish and subscribe where none of the participants need know about each other, or call each other directly.\n\nRelated sections include: Orthogonality, page 34 Reversibility, page 44 Decoupling and the Law of Demeter, page 138 Blackboards, page 165 It’s All Writing, page 248\n\nExercises 29. Suppose you have an airline reservation system that includes the concept\n\nof a ﬂight:\n\npublic interface Flight {\n\n// Return false if flight full. public boolean addPassenger(Passenger p); public void addToWaitList(Passenger p); public int getFlightCapacity(); public int getNumPassengers();\n\n}\n\nIf you add a passenger to the wait list, they’ll be put on the ﬂight automat- ically when an opening becomes available.",
      "content_length": 1432,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 190,
      "content": "BLACKBOARDS\n\nThere’s a massive reporting job that goes through looking for overbooked or full ﬂights to suggest when additional ﬂights might be scheduled. It works ﬁne, but it takes hours to run.\n\nWe’d like to have a little more ﬂexibility in processing wait-list passengers, and we’ve got to do something about that big report—it takes too long to run. Use the ideas from this section to redesign this interface.\n\n30 Blackboards\n\nThe writing is on the wall...\n\nYou may not usually associate elegance with police detectives, pictur- ing instead some sort of doughnut and coffee cliché. But consider how detectives might use a blackboard to coordinate and solve a murder investigation.\n\nSuppose the chief inspector starts off by setting up a large blackboard in the conference room. On it, he writes a single question:\n\nH. DUMPTY (MALE, EGG): ACCIDENT OR MURDER?\n\nDid Humpty really fall, or was he pushed? Each detective may make contributions to this potential murder mystery by adding facts, state- ments from witnesses, any forensic evidence that might arise, and so on. As the data accumulates, a detective might notice a connection and post that observation or speculation as well. This process continues, across all shifts, with many different people and agents, until the case is closed. A sample blackboard is shown in Figure 5.6 on the next page.\n\nSome key features of the blackboard approach are:\n\nNone of the detectives needs to know of the existence of any other detective—they watch the board for new information, and add their ﬁndings.\n\nThe detectives may be trained in different disciplines, may have different levels of education and expertise, and may not even work in the same precinct. They share a desire to solve the case, but that’s all.\n\n165",
      "content_length": 1763,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 191,
      "content": "166\n\nCHAPTER 5 BEND, OR BREAK\n\nFigure 5.6. Someone found a connection between Humpty’s gambling debts and\n\nthe phone logs. Perhaps he was getting threatening phone calls.\n\nH. Dumpty (Male, Egg): Accident or Murder?\n\nPhotos King’s men Eyewitnesses Grafﬁti\n\nShell fragments Gambling debts\n\nPhone logs\n\nWife’s alibi\n\nDetective 1\n\nDetective 2\n\nDetective 3\n\nDifferent detectives may come and go during the course of the pro- cess, and may work different shifts.\n\nThere are no restrictions on what may be placed on the blackboard. It may be pictures, sentences, physical evidence, and so on.\n\nWe’ve worked on a number of projects that involved a workﬂow or distributed data gathering process. With each, designing a solution around a simple blackboard model gave us a solid metaphor to work with: all of the features listed above using detectives are just as appli- cable to objects and code modules.\n\nA blackboard system lets us decouple our objects from each other com- pletely, providing a forum where knowledge consumers and producers can exchange data anonymously and asynchronously. As you might guess, it also cuts down on the amount of code we have to write.\n\nBlackboardImplementations Computer-based blackboard systems were originally invented for use in artiﬁcial intelligence applications where the problems to be solved were large and complex—speech recognition, knowledge-based reason- ing systems, and so on.\n\nModern distributed blackboard-like systems such as JavaSpaces and T Spaces [URL 50, URL 25] are based on a model of key/value pairs ﬁrst",
      "content_length": 1554,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 192,
      "content": "BLACKBOARDS\n\npopularized in Linda [CG90], where the concept was known as tuple space.\n\nWith these systems, you can store active Java objects—not just data— on the blackboard, and retrieve them by partial matching of ﬁelds (via templates and wildcards) or by subtypes. For example, suppose you had a type Author, which is a subtype of Person. You could search a blackboard containing Person objects by using an Author template with a lastName value of “Shakespeare.” You’d get Bill Shakespeare the author, but not Fred Shakespeare the gardener.\n\nThe main operations in JavaSpaces are:\n\nName\n\nFunction\n\nread write take\n\nSearch for and retrieve data from the space. Put an item into the space. Similar to read, but removes the item from the space as well.\n\nnotify Set up a notiﬁcation to occur whenever an object is written that matches the template.\n\nT Spaces supports a similar set of operations, but with different names and slightly different semantics. Both systems are built like a database product; they provide atomic operations and distributed transactions to ensure data integrity.\n\nSince we can store objects, we can use a blackboard to design algo- rithms based on a ﬂow of objects, not just data. It’s as if our detec- tives could pin people to the blackboard—witnesses themselves, not just their statements. Anyone can ask a witness questions in the pur- suit of the case, post the transcript, and move that witness to another area of the blackboard, where he might respond differently (if you allow the witness to read the blackboard too).\n\nA big advantage of systems such as these is that you have a single, con- sistent interface to the blackboard. When building a conventional dis- tributed application, you can spend a great deal of time crafting unique API calls for every distributed transaction and interaction in the sys- tem. With the combinatorial explosion of interfaces and interactions, the project can quickly become a nightmare.\n\n167",
      "content_length": 1960,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 193,
      "content": "168\n\nCHAPTER 5 BEND, OR BREAK\n\nOrganizing Your Blackboard\n\nWhen the detectives work on large cases, the blackboard may be- come cluttered, and it may become difﬁcult to locate data on the board. The solution is to partition the blackboard and start to orga- nize the data on the blackboard somehow.\n\nDifferent software systems handle this partitioning in different ways; some use fairly ﬂat zones or interest groups, while others adopt a more hierarchical treelike structure.\n\nThe blackboard style of programming removes the need for so many interfaces, making for a more elegant and consistent system.\n\nApplicationExample Suppose we are writing a program to accept and process mortgage or loan applications. The laws that govern this area are odiously com- plex, with federal, state, and local governments all having their say. The lender must prove they have disclosed certain things, and must ask for certain information—but must not ask certain other questions, and so on, and so on.\n\nBeyond the miasma of applicable law, we also have the following prob- lems to contend with.\n\nThere is no guarantee on the order in which data arrives. For instance, queries for a credit check or title search may take a sub- stantial amount of time, while items such as name and address may be available immediately.\n\nData gathering may be done by different people, distributed across different ofﬁces, in different time zones.\n\nSome data gathering may be done automatically by other systems. This data may arrive asynchronously as well.\n\nNonetheless, certain data may still be dependent on other data. For instance, you may not be able to start the title search for a car until you get proof of ownership or insurance.",
      "content_length": 1707,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 194,
      "content": "BLACKBOARDS\n\nArrival of new data may raise new questions and policies. Suppose the credit check comes back with a less than glowing report; now you need these ﬁve extra forms and perhaps a blood sample.\n\nYou can try to handle every possible combination and circumstance using a workﬂow system. Many such systems exist, but they can be complex and programmer intensive. As regulations change, the work- ﬂow must be reorganized: people may have to change their procedures and hard-wired code may have to be rewritten.\n\nA blackboard, in combination with a rules engine that encapsulates the legal requirements, is an elegant solution to the difﬁculties found here. Order of data arrival is irrelevant: when a fact is posted it can trigger the appropriate rules. Feedback is easily handled as well: the output of any set of rules can post to the blackboard and cause the triggering of yet more applicable rules.\n\nTIP 43\n\nUse Blackboards to Coordinate Workﬂow\n\nWe can use the blackboard to coordinate disparate facts and agents, while still maintaining independence and even isolation among partici- pants.\n\nYou can accomplish the same results with more brute-force methods, of course, but you’ll have a more brittle system. When it breaks, all the king’s horses and all the king’s men might not get your program working again.\n\nRelated sections include:\n\nThe Power of Plain Text, page 73 It’s Just a View, page 157\n\nChallenges\n\nDo you use blackboard systems in the real world—the message board by the refrigerator, or the big whiteboard at work? What makes them effective? Are messages ever posted with a consistent format? Does it matter?\n\n169",
      "content_length": 1640,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 195,
      "content": "Answer on p. 297\n\n170\n\nCHAPTER 5 BEND, OR BREAK\n\nExercises 30. For each of the following applications, would a blackboard system be ap-\n\npropriate or not? Why?\n\n1. Image processing. You’d like to have a number of parallel processes grab chunks of an image, process them, and put the completed chunk back.\n\n2. Group calendaring. You’ve got people scattered across the globe, in different time zones, and speaking different languages, trying to schedule a meeting.\n\n3. Network monitoring tool. The system gathers performance statistics and collects trouble reports. You’d like to implement some agents to use this information to look for trouble in the system.",
      "content_length": 658,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 196,
      "content": "Chapter 6\n\nWhile You Are Coding\n\nConventional wisdom says that once a project is in the coding phase, the work is mostly mechanical, transcribing the design into executable statements. We think that this attitude is the single biggest reason that many programs are ugly, inefﬁcient, poorly structured, unmaintain- able, and just plain wrong.\n\nCoding is not mechanical. If it were, all the CASE tools that people pinned their hopes on in the early 1980s would have replaced program- mers long ago. There are decisions to be made every minute—decisions that require careful thought and judgment if the resulting program is to enjoy a long, accurate, and productive life.\n\nDevelopers who don’t actively think about their code are programming by coincidence—the code might work, but there’s no particular rea- son why. In Programming by Coincidence, we advocate a more positive involvement with the coding process.\n\nWhile most of the code we write executes quickly, we occasionally develop algorithms that have the potential to bog down even the fastest processors. In Algorithm Speed, we discuss ways to estimate the speed of code, and we give some tips on how to spot potential problems before they happen.\n\nPragmatic Programmers think critically about all code, including our own. We constantly see room for improvement in our programs and our designs. In Refactoring, we look at techniques that help us ﬁx up existing code even while we’re in the midst of a project.\n\nSomething that should be in the back of your mind whenever you’re producing code is that you’ll someday have to test it. Make code easy\n\n171",
      "content_length": 1608,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 197,
      "content": "31\n\n172\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nto test, and you’ll increase the likelihood that it will actually get tested, a thought we develop in Code That’s Easy to Test.\n\nFinally, in Evil Wizards, we suggest that you should be careful of tools that write reams of code on your behalf unless you understand what they’re doing.\n\nMost of us can drive a car largely on autopilot—we don’t explicitly com- mand our foot to press a pedal, or our arm to turn the wheel—we just think “slow down and turn right.” However, good, safe drivers are con- stantly reviewing the situation, checking for potential problems, and putting themselves into good positions in case the unexpected happens. The same is true of coding—it may be largely routine, but keeping your wits about you could well prevent a disaster.\n\nProgramming by Coincidence\n\nDo you ever watch old black-and-white war movies? The weary sol- dier advances cautiously out of the brush. There’s a clearing ahead: are there any land mines, or is it safe to cross? There aren’t any indica- tions that it’s a mineﬁeld—no signs, barbed wire, or craters. The soldier pokes the ground ahead of him with his bayonet and winces, expecting an explosion. There isn’t one. So he proceeds painstakingly through the ﬁeld for a while, prodding and poking as he goes. Eventually, convinced that the ﬁeld is safe, he straightens up and marches proudly forward, only to be blown to pieces.\n\nThe soldier’s initial probes for mines revealed nothing, but this was merely lucky. He was led to a false conclusion—with disastrous results.\n\nAs developers, we also work in mineﬁelds. There are hundreds of traps just waiting to catch us each day. Remembering the soldier’s tale, we should be wary of drawing false conclusions. We should avoid pro- gramming by coincidence—relying on luck and accidental successes— in favor of programming deliberately.",
      "content_length": 1873,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 198,
      "content": "PROGRAMMING BY COINCIDENCE\n\nHowtoProgramby Coincidence Suppose Fred is given a programming assignment. Fred types in some code, tries it, and it seems to work. Fred types in some more code, tries it, and it still seems to work. After several weeks of coding this way, the program suddenly stops working, and after hours of trying to ﬁx it, he still doesn’t know why. Fred may well spend a signiﬁcant amount of time chasing this piece of code around without ever being able to ﬁx it. No matter what he does, it just doesn’t ever seem to work right.\n\nFred doesn’t know why the code is failing because he didn’t know why it worked in the ﬁrst place. It seemed to work, given the limited “testing” that Fred did, but that was just a coincidence. Buoyed by false conﬁ- dence, Fred charged ahead into oblivion. Now, most intelligent people may know someone like Fred, but we know better. We don’t rely on coincidences—do we?\n\nSometimes we might. Sometimes it can be pretty easy to confuse a happy coincidence with a purposeful plan. Let’s look at a few examples.\n\nAccidentsofImplementation Accidents of implementation are things that happen simply because that’s the way the code is currently written. You end up relying on undocumented error or boundary conditions.\n\nSuppose you call a routine with bad data. The routine responds in a particular way, and you code based on that response. But the author didn’t intend for the routine to work that way—it was never even con- sidered. When the routine gets “ﬁxed,” your code may break. In the most extreme case, the routine you called may not even be designed to do what you want, but it seems to work okay. Calling things in the wrong order, or in the wrong context, is a related problem.\n\npaint(g); invalidate(); validate(); revalidate(); repaint(); paintImmediately(r);\n\nHere it looks like Fred is desperately trying to get something out on the screen. But these routines were never designed to be called this way; although they seem to work, that’s really just a coincidence.\n\n173",
      "content_length": 2026,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 199,
      "content": "174\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nTo add insult to injury, when the component ﬁnally does get drawn, Fred won’t try to go back and take out the spurious calls. “It works now, better leave well enough alone. . ..”\n\nIt’s easy to be fooled by this line of thought. Why should you take the risk of messing with something that’s working? Well, we can think of several reasons:\n\nIt may not really be working—it might just look like it is.\n\nThe boundary condition you rely on may be just an accident. In different circumstances (a different screen resolution, perhaps), it might behave differently.\n\nUndocumented behavior may change with the next release of the library.\n\nAdditional and unnecessary calls make your code slower.\n\nAdditional calls also increase the risk of introducing new bugs of their own.\n\nFor code you write that others will call, the basic principles of good modularization and of hiding implementation behind small, well-docu- mented interfaces can all help. A well-speciﬁed contract (see Design by Contract, page 109) can help eliminate misunderstandings.\n\nFor routines you call, rely only on documented behavior. If you can’t, for whatever reason, then document your assumption well.\n\nAccidents ofContext You can have “accidents of context” as well. Suppose you are writing a utility module. Just because you are currently coding for a GUI envi- ronment, does the module have to rely on a GUI being present? Are you relying on English-speaking users? Literate users? What else are you relying on that isn’t guaranteed?\n\nImplicitAssumptions Coincidences can mislead at all levels—from generating requirements through to testing. Testing is particularly fraught with false causalities and coincidental outcomes. It’s easy to assume that X causes Y, but as we said in Debugging, page 90: don’t assume it, prove it.",
      "content_length": 1830,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 200,
      "content": "PROGRAMMING BY COINCIDENCE\n\nAt all levels, people operate with many assumptions in mind—but these assumptions are rarely documented and are often in conﬂict between different developers. Assumptions that aren’t based on well-established facts are the bane of all projects.\n\nTIP 44\n\nDon’t Program by Coincidence\n\nHowtoProgramDeliberately We want to spend less time churning out code, catch and ﬁx errors as early in the development cycle as possible, and create fewer errors to begin with. It helps if we can program deliberately:\n\nAlways be aware of what you are doing. Fred let things get slowly out of hand, until he ended up boiled, like the frog in Stone Soup and Boiled Frogs, page 7.\n\nDon’t code blindfolded. Attempting to build an application you don’t fully understand, or to use a technology you aren’t familiar with, is an invitation to be misled by coincidences.\n\nProceed from a plan, whether that plan is in your head, on the back of a cocktail napkin, or on a wall-sized printout from a CASE tool.\n\nRely only on reliable things. Don’t depend on accidents or assump- tions. If you can’t tell the difference in particular circumstances, assume the worst.\n\nDocument your assumptions. Design by Contract, page 109, can help clarify your assumptions in your own mind, as well as help communicate them to others.\n\nDon’t just test your code, but test your assumptions as well. Don’t guess; actually try it. Write an assertion to test your assumptions (see Assertive Programming, page 122). If your assertion is right, you have improved the documentation in your code. If you discover your assumption is wrong, then count yourself lucky.\n\nPrioritize your effort. Spend time on the important aspects; more than likely, these are the hard parts. If you don’t have fundamen-\n\n175",
      "content_length": 1781,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 201,
      "content": "Answer on p. 298\n\nAnswer on p. 298\n\n176\n\nCHAPTER 6 WHILE YOU ARE CODING\n\ntals or infrastructure correct, brilliant bells and whistles will be irrelevant.\n\nDon’t be a slave to history. Don’t let existing code dictate future code. All code can be replaced if it is no longer appropriate. Even within one program, don’t let what you’ve already done constrain what you do next—be ready to refactor (see Refactoring, page 184). This decision may impact the project schedule. The assumption is that the impact will be less than the cost of not making the change.1\n\nSo next time something seems to work, but you don’t know why, make sure it isn’t just a coincidence.\n\nRelated sections include:\n\nStone Soup and Boiled Frogs, page 7 Debugging, page 90 Design by Contract, page 109 Assertive Programming, page 122 Temporal Coupling, page 150 Refactoring, page 184 It’s All Writing, page 248\n\nExercises 31. Can you identify some coincidences in the following C code fragment?\n\nAssume that this code is buried deep in a library routine.\n\nfprintf(stderr,\"Error, continue?\"); gets(buf);\n\n32. This piece of C code might work some of the time, on some machines. Then\n\nagain, it might not. What’s wrong?\n\n/* Truncate string to its last maxlen chars */\n\nvoid string_tail(char *string, int maxlen) {\n\nint len = strlen(string); if (len > maxlen) {\n\nstrcpy(string, string + (len - maxlen));\n\n}\n\n}\n\n1. was given because he had his own naming conventions.\n\nYou can also go too far here. We once knew a developer who rewrote all source he",
      "content_length": 1514,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 202,
      "content": "ALGORITHM SPEED\n\n177\n\n33. This code comes from a general-purpose Java tracing suite. The function writes a string to a log ﬁle. It passes its unit test, but fails when one of the Web developers uses it. What coincidence does it rely on? Answer on p. 299\n\npublic static void debug(String s) throws IOException { FileWriter fw = new FileWriter(\"debug.log\", true); fw.write(s); fw.flush(); fw.close();\n\n}\n\n32 Algorithm Speed\n\nIn Estimating, page 64, we talked about estimating things such as how long it takes to walk across town, or how long a project will take to ﬁn- ish. However, there is another kind of estimating that Pragmatic Pro- grammers use almost daily: estimating the resources that algorithms use—time, processor, memory, and so on.\n\nThis kind of estimating is often crucial. Given a choice between two ways of doing something, which do you pick? You know how long your program runs with 1,000 records, but how will it scale to 1,000,000? What parts of the code need optimizing?\n\nIt turns out that these questions can often be answered using common sense, some analysis, and a way of writing approximations called the “big O” notation.\n\nWhatDoWeMean by Estimating Algorithms? Most nontrivial algorithms handle some kind of variable input—sorting matrix, or decrypting a message with an strings, inverting an -bit key. Normally, the size of this input will affect the algorithm: the larger the input, the longer the running time or the more memory used.\n\nIf the relationship were always linear (so that the time increased in ), this section wouldn’t be important. direct proportion to the value of However, most signiﬁcant algorithms are not linear. The good news is that many are sublinear. A binary search, for example, doesn’t need to look at every candidate when ﬁnding a match. The bad news is that",
      "content_length": 1814,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 203,
      "content": "178\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nother algorithms are considerably worse than linear; runtimes or mem- ory requirements increase far faster than . An algorithm that takes a minute to process ten items may take a lifetime to process 100.\n\nWe ﬁnd that whenever we write anything containing loops or recur- sive calls, we subconsciously check the runtime and memory require- ments. This is rarely a formal process, but rather a quick conﬁrma- tion that what we’re doing is sensible in the circumstances. However, we sometimes do ﬁnd ourselves performing a more detailed analysis. That’s when the\n\nnotation comes in useful.\n\nTheO()Notation The When we write that a particular sort routine sorts time, we are simply saying that the worst-case time taken will vary . Double the number of records, and the time will as the square of as meaning on the order of. increase roughly fourfold. Think of the notation puts an upper bound on the value of the thing we’re The measuring (time, memory, and so on). If we say a function takes time, then we know that the upper bound of the time it takes will not grow faster than functions, but because the highest-order term will dominate the value increases, the convention is to remove all low-order terms, and not as to bother showing any constant multiplying factors. is the same as . This is actually a weakness , which is equivalent to algorithm may be 1,000 times faster than of the another\n\nnotation is a mathematical way of dealing with approximations.\n\nrecords in\n\n. Sometimes we come up with fairly complex\n\nnotation—one\n\nalgorithm, but you won’t know it from the notation.\n\nFigure 6.1 shows several common notations you’ll come across, along with a graph comparing running times of algorithms in each cat- egory. Clearly, things quickly start getting out of hand once we get over\n\n.\n\nFor example, suppose you’ve got a routine that takes 1 s to process 100 records. How long will it take to process 1,000? If your code is , then , then you’ll probably be waiting about it will still take 1 s. If it’s 3 s. will take some 33 s. If you’re unlucky enough to have an routine, then sit back for 100 s while it does its stuff. And if you’re using an exponential\n\nwill show a linear increase to 10 s, while an",
      "content_length": 2248,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 204,
      "content": "ALGORITHM SPEED\n\nFigure 6.1. Runtimes of various algorithms\n\n: traveling salesman\n\n: heapsort\n\n: selection sort\n\n: sequential search\n\n: binary search\n\n: array access\n\nSome common O() notations\n\nConstant (access element in array, simple statements)\n\nLogarithmic (binary search) [The notation is shorthand for\n\n]\n\nLinear (sequential search)\n\nWorse than linear, but not much worse (aver- age runtime of quicksort, heapsort)\n\nSquare law (selection and insertion sorts)\n\nCubic (multiplication of 2\n\nmatrices)\n\nExponential (traveling salesman problem, set partitioning)\n\n179",
      "content_length": 568,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 205,
      "content": "180\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nalgorithm should ﬁnish in about\n\n, you might want to make a cup of coffee—your routine years. Let us know how the universe ends.\n\nThe notation doesn’t apply just to time; you can use it to represent any other resources used by an algorithm. For example, it is often use- ful to be able to model memory consumption (see Exercise 35 on page 183).\n\nCommon SenseEstimation You can estimate the order of many basic algorithms using common sense.\n\nIf a simple loop runs from to , then the algo- Simple loops. rithm is likely to be —time increases linearly with . Exam- ples include exhaustive searches, ﬁnding the maximum value in an array, and generating checksums.\n\nIf you nest a loop inside another, then your algo- Nested loops. are the two loops’ limits. rithm becomes This commonly occurs in simple sorting algorithms, such as bub- ble sort, where the outer loop scans each element in the array in turn, and the inner loop works out where to place that element in the sorted result. Such sorting algorithms tend to be\n\n, where\n\nand\n\n.\n\nIf your algorithm halves the set of things it consid- Binary chop. ers each time around the loop, then it is likely to be logarithmic, (see Exercise 37, page 183). A binary search of a sorted list, traversing a binary tree, and ﬁnding the ﬁrst set bit in a machine word can all be\n\n.\n\nDivide and conquer. Algorithms that partition their input, work on the two halves independently, and then combine the result can . The classic example is quicksort, which works by be partitioning the data into two halves and recursively sorting each. Although technically , because its behavior degrades when it is fed sorted input, the average runtime of quicksort is\n\nCombinatoric. Whenever algorithms start looking at the permuta- tions of things, their running times may get out of hand. This is be- cause permutations involve factorials (there are\n\npermutations of the digits from 1 to 5). Time a combinatoric\n\n.",
      "content_length": 1975,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 206,
      "content": "ALGORITHM SPEED\n\n181\n\nalgorithm for ﬁve elements: it will take six times longer to run it for six, and 42 times longer for seven. Examples include algorithms for many of the acknowledged hard problems—the traveling salesman problem, optimally packing things into a container, partitioning a set of numbers so that each set has the same total, and so on. Of- ten, heuristics are used to reduce the running times of these types of algorithms in particular problem domains.\n\nAlgorithmSpeed inPractice It’s unlikely that you’ll spend much time during your career writing sort routines. The ones in the libraries available to you will probably outper- form anything you may write without substantial effort. However, the basic kinds of algorithms we’ve described earlier pop up time and time again. Whenever you ﬁnd yourself writing a simple loop, you know that algorithm. If that loop contains an inner loop, then you have an . You should be asking yourself how large you’re looking at these values can get. If the numbers are bounded, then you’ll know how long the code will take to run. If the numbers depend on external factors (such as the number of records in an overnight batch run, or the number of names in a list of people), then you might want to stop and consider the effect that large values may have on your running time or memory consumption.\n\nTIP 45\n\nEstimate the Order of Your Algorithms\n\nThere are some approaches you can take to address potential problems. If you have an algorithm that is , try to ﬁnd a divide and conquer approach that will take you down to\n\n.\n\nIf you’re not sure how long your code will take, or how much memory it will use, try running it, varying the input record count or whatever is likely to impact the runtime. Then plot the results. You should soon get a good idea of the shape of the curve. Is it curving upward, a straight line, or ﬂattening off as the input size increases? Three or four points should give you an idea.\n\nAlso consider just what you’re doing in the code itself. A simple loop may well perform better than a complex,\n\none for smaller",
      "content_length": 2092,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 207,
      "content": "182\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nvalues of inner loop.\n\n, particularly if the\n\nalgorithm has an expensive\n\nIn the middle of all this theory, don’t forget that there are practical considerations as well. Runtime may look like it increases linearly for small input sets. But feed the code millions of records and suddenly the time degrades as the system starts to thrash. If you test a sort routine with random input keys, you may be surprised the ﬁrst time it encounters ordered input. Pragmatic Programmers try to cover both the theoretical and practical bases. After all this estimating, the only timing that counts is the speed of your code, running in the production environment, with real data.2 This leads to our next tip.\n\nTIP 46\n\nTest Your Estimates\n\nIf it’s tricky getting accurate timings, use code proﬁlers to count the number of times the different steps in your algorithm get executed, and plot these ﬁgures against the size of the input.\n\nBestIsn’t AlwaysBest You also need to be pragmatic about choosing appropriate algorithms— the fastest one is not always the best for the job. Given a small input set, a straightforward insertion sort will perform just as well as a quick- sort, and will take you less time to write and debug. You also need to be careful if the algorithm you choose has a high setup cost. For small input sets, this setup may dwarf the running time and make the algo- rithm inappropriate.\n\nAlso be wary of premature optimization. It’s always a good idea to make sure an algorithm really is a bottleneck before investing your precious time trying to improve it.\n\n2. In fact, while testing the sort algorithms used as an exercise for this section on a 64MB Pentium, the authors ran out of real memory while running the radix sort with more than seven million numbers. The sort started using swap space, and times degraded dramatically.",
      "content_length": 1871,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 208,
      "content": "ALGORITHM SPEED\n\n183\n\nRelated sections include:\n\nEstimating, page 64\n\nChallenges\n\nEvery developer should have a feel for how algorithms are designed and analyzed. Robert Sedgewick has written a series of accessible books on the subject ([Sed83, SF96, Sed92] and others). We recommend adding one of his books to your collection, and making a point of reading it.\n\nFor those who like more detail than Sedgewick provides, read Donald Knuth’s deﬁnitive Art of Computer Programming books, which analyze a wide range of algorithms [Knu97a, Knu97b, Knu98].\n\nIn Exercise 34, we look at sorting arrays of long integers. What is the impact if the keys are more complex, and the overhead of key comparison is high? Does the key structure affect the efﬁciency of the sort algorithms, or is the fastest sort always fastest?\n\nExercises 34. We have coded a set of simple sort routines, which can be downloaded from our Web site (www.pragmaticprogrammer.com). Run them on vari- ous machines available to you. Do your ﬁgures follow the expected curves? What can you deduce about the relative speeds of your machines? What are the effects of various compiler optimization settings? Is the radix sort indeed linear?\n\n35. The routine below prints out the contents of a binary tree. Assuming the tree is balanced, roughly how much stack space will the routine use while printing a tree of 1,000,000 elements? (Assume that subroutine calls im- pose no signiﬁcant stack overhead.) void printTree(const Node *node) {\n\nchar buffer[1000];\n\nif (node) {\n\nprintTree(node->left);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nprintTree(node->right);\n\n}\n\n}\n\n36. Can you see any way to reduce the stack requirements of the routine in\n\nExercise 35 (apart from reducing the size of the buffer)?\n\n37. On page 180, we claimed that a binary chop is\n\n. Can you prove\n\nthis?\n\nAnswer on p. 299\n\nAnswer on p. 300\n\nAnswer on p. 301",
      "content_length": 1890,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 209,
      "content": "184\n\nCHAPTER 6 WHILE YOU ARE CODING\n\n33 Refactoring\n\nChange and decay in all around I see ... H. F. Lyte, “Abide With Me”\n\nAs a program evolves, it will become necessary to rethink earlier deci- sions and rework portions of the code. This process is perfectly natural. Code needs to evolve; it’s not a static thing.\n\nUnfortunately, the most common metaphor for software development is building construction (Bertrand Meyer [Mey97b] uses the term “Soft- ware Construction”). But using construction as the guiding metaphor implies these steps:\n\n1. An architect draws up blueprints.\n\n2. Contractors dig the foundation, build the superstructure, wire and\n\nplumb, and apply ﬁnishing touches.\n\n3. The tenants move in and live happily ever after, calling building\n\nmaintenance to ﬁx any problems.\n\nWell, software doesn’t quite work that way. Rather than construction, software is more like gardening—it is more organic than concrete. You plant many things in a garden according to an initial plan and condi- tions. Some thrive, others are destined to end up as compost. You may move plantings relative to each other to take advantage of the inter- play of light and shadow, wind and rain. Overgrown plants get split or pruned, and colors that clash may get moved to more aesthetically pleasing locations. You pull weeds, and you fertilize plantings that are in need of some extra help. You constantly monitor the health of the garden, and make adjustments (to the soil, the plants, the layout) as needed.\n\nBusiness people are comfortable with the metaphor of building con- struction: it is more scientiﬁc than gardening, it’s repeatable, there’s a rigid reporting hierarchy for management, and so on. But we’re not building skyscrapers—we aren’t as constrained by the boundaries of physics and the real world.\n\nThe gardening metaphor is much closer to the realities of software development. Perhaps a certain routine has grown too large, or is trying",
      "content_length": 1943,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 210,
      "content": "REFACTORING\n\nto accomplish too much—it needs to be split into two. Things that don’t work out as planned need to be weeded or pruned.\n\nRewriting, reworking, and re-architecting code is collectively known as refactoring.\n\nWhenShouldYou Refactor? When you come across a stumbling block because the code doesn’t quite ﬁt anymore, or you notice two things that should really be merged, or anything else at all strikes you as being “wrong,” don’t hesitate to change it. There’s no time like the present. Any number of things may cause code to qualify for refactoring:\n\nDuplication. You’ve discovered a violation of the DRY principle (The Evils of Duplication, page 26).\n\nNonorthogonal design. You’ve discovered some code or design that could be made more orthogonal (Orthogonality, page 34).\n\nOutdated knowledge. Things change, requirements drift, and your knowledge of the problem increases. Code needs to keep up.\n\nPerformance. You need to move functionality from one area of the system to another to improve performance.\n\nRefactoring your code—moving functionality around and updating ear- lier decisions—is really an exercise in pain management. Let’s face it, changing source code around can be pretty painful: it was almost work- ing, and now it’s really torn up. Many developers are reluctant to start ripping up code just because it isn’t quite right.\n\nReal-WorldComplications So you go to your boss or client and say, “This code works, but I need another week to refactor it.”\n\nWe can’t print their reply.\n\nTime pressure is often used as an excuse for not refactoring. But this excuse just doesn’t hold up: fail to refactor now, and there’ll be a far greater time investment to ﬁx the problem down the road—when there are more dependencies to reckon with. Will there be more time available then? Not in our experience.\n\n185",
      "content_length": 1827,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 211,
      "content": "186\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nYou might want to explain this principle to the boss by using a medical analogy: think of the code that needs refactoring as a “growth.” Remov- ing it requires invasive surgery. You can go in now, and take it out while it is still small. Or, you could wait while it grows and spreads—but re- moving it then will be both more expensive and more dangerous. Wait even longer, and you may lose the patient entirely.\n\nTIP 47\n\nRefactor Early, Refactor Often\n\nKeep track of the things that need to be refactored. If you can’t refactor something immediately, make sure that it gets placed on the schedule. Make sure that users of the affected code know that it is scheduled to be refactored and how this might affect them.\n\nHowDoYou Refactor? Refactoring started out in the Smalltalk community, and, along with other trends (such as design patterns), has started to gain a wider au- dience. But as a topic it is still fairly new; there isn’t much published on it. The ﬁrst major book on refactoring ([FBB 99], and also [URL 47]) is being published around the same time as this book.\n\nAt its heart, refactoring is redesign. Anything that you or others on your team designed can be redesigned in light of new facts, deeper under- standings, changing requirements, and so on. But if you proceed to rip up vast quantities of code with wild abandon, you may ﬁnd yourself in a worse position than when you started.\n\nClearly, refactoring is an activity that needs to be undertaken slowly, deliberately, and carefully. Martin Fowler offers the following simple tips on how to refactor without doing more harm than good (see the box on page 30 in [FS97]):\n\n1. Don’t try to refactor and add functionality at the same time.\n\n2. Make sure you have good tests before you begin refactoring. Run the tests as often as possible. That way you will know quickly if your changes have broken anything.",
      "content_length": 1910,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 212,
      "content": "REFACTORING\n\nAutomatic Refactoring\n\nHistorically, Smalltalk users have always enjoyed a class browser as part of the IDE. Not to be confused with Web browsers, class browsers let users navigate through and examine class hierarchies and methods.\n\nTypically, class browsers allow you to edit code, create new methods and classes, and so on. The next variation on this idea is the refac- toringbrowser.\n\nA refactoring browser can semiautomatically perform common refac- toring operations for you: splitting up a long routine into smaller ones, automatically propagating changes to method and variable names, drag and drop to assist you in moving code, and so on.\n\nAs we write this book, this technology has yet to appear outside of the Smalltalk world, but this is likely to change at the same speed that Java changes—rapidly. In the meantime, the pioneering Small- talk refactoring browser can be found online at [URL 20].\n\n3. Take short, deliberate steps: move a ﬁeld from one class to another, fuse two similar methods into a superclass. Refactoring often in- volves making many localized changes that result in a larger-scale change. If you keep your steps small, and test after each step, you will avoid prolonged debugging.\n\nWe’ll talk more about testing at this level in Code That’s Easy to Test, page 189, and larger-scale testing in Ruthless Testing, page 237, but Mr. Fowler’s point of maintaining good regression tests is the key to refactoring with conﬁdence.\n\nIt can also be helpful to make sure that drastic changes to a module— such as altering its interface or its functionality in an incompatible manner—break the build. That is, old clients of this code should fail to compile. You can then quickly ﬁnd the old clients and make the necessary changes to bring them up to date.\n\nSo next time you see a piece of code that isn’t quite as it should be, ﬁx both it and everything that depends on it. Manage the pain: if it hurts now, but is going to hurt even more later, you might as well get it over\n\n187",
      "content_length": 2015,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 213,
      "content": "Copyright 2002 Addison Wesley Longman, Inc\n\n188\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nwith. Remember the lessons of Software Entropy, page 4: don’t live with broken windows.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Software Entropy, page 4 Stone Soup and Boiled Frogs, page 7 The Evils of Duplication, page 26 Orthogonality, page 34 Programming by Coincidence, page 172 Code That’s Easy to Test, page 189 Ruthless Testing, page 237\n\nExercises 38. The following code has obviously been updated several times over the\n\nAnswer on p. 302\n\nyears, but the changes haven’t improved its structure. Refactor it.\n\nif (state == TEXAS) {\n\nrate = TX_RATE; amt calc = 2*basis(amt) + extra(amt)*1.05;\n\n= base * TX_RATE;\n\n} else if ((state == OHIO) || (state == MAINE)) { rate = (state == OHIO) ? OH_RATE : ME_RATE; amt calc = 2*basis(amt) + extra(amt)*1.05; if (state == OHIO)\n\n= base * rate;\n\npoints = 2;\n\n} else {\n\nrate = 1; amt calc = 2*basis(amt) + extra(amt)*1.05;\n\n= base;\n\n}\n\n39. The following Java class needs to support a few more shapes. Refactor the\n\nAnswer on p. 303\n\nclass to prepare it for the additions.\n\npublic class Shape {\n\npublic static final int SQUARE public static final int CIRCLE public static final int RIGHT_TRIANGLE = 3;\n\n= 1; = 2;\n\nprivate int private double size;\n\nshapeType;\n\npublic Shape(int shapeType, double size) {\n\nthis.shapeType = shapeType; this.size\n\n= size;\n\n}\n\n// ... other methods ...",
      "content_length": 1427,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 214,
      "content": "CODE THAT’S EASY TO TEST\n\n189\n\npublic double area() { switch (shapeType) { case SQUARE: case CIRCLE: case RIGHT_TRIANGLE: return size*size/2.0; } return 0;\n\nreturn size*size; return Math.PI*size*size/4.0;\n\n}\n\n}\n\n40. This Java code is part of a framework that will be used throughout your Answer on p. 303\n\n40. This Java code is part of a framework that will be used throughout your Answer on p. 303\n\npublic class Window {\n\npublic Window(int width, int height) { ... }\n\npublic void setSize(int width, int height) { ... }\n\npublic boolean overlaps(Window w) { ... }\n\npublic int getArea() { ... }\n\n}\n\n34 Code That’s Easy to Test\n\nThe Software IC is a metaphor that people like to toss around when discussing reusability and component-based development.3 The idea is that software components should be combined just as integrated circuit chips are combined. This works only if the components you are using are known to be reliable.\n\nChips are designed to be tested—not just at the factory, not just when they are installed, but also in the ﬁeld when they are deployed. More complex chips and systems may have a full Built-In Self Test (BIST) fea- ture that runs some base-level diagnostics internally, or a Test Access Mechanism (TAM) that provides a test harness that allows the external environment to provide stimuli and collect responses from the chip.\n\nWe can do the same thing in software. Like our hardware colleagues, we need to build testability into the software from the very beginning, and test each piece thoroughly before trying to wire them together.\n\n3. Cox and Novobilski in their Objective-C book Object-Oriented Programming [CN91].\n\nThe term “Software IC” (Integrated Circuit) seems to have been invented in 1986 by",
      "content_length": 1729,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 215,
      "content": "190\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nUnit Testing Chip-level testing for hardware is roughly equivalent to unit testing in software—testing done on each module, in isolation, to verify its behavior. We can get a better feeling for how a module will react in the big wide world once we have tested it throughly under controlled (even contrived) conditions.\n\nA software unit test is code that exercises a module. Typically, the unit test will establish some kind of artiﬁcial environment, then invoke rou- tines in the module being tested. It then checks the results that are returned, either against known values or against the results from pre- vious runs of the same test (regression testing).\n\nLater, when we assemble our “software IC’s” into a complete system, we’ll have conﬁdence that the individual parts work as expected, and then we can use the same unit test facilities to test the system as a whole. We talk about this large-scale checking of the system in Ruthless Testing, page 237.\n\nBefore we get that far, however, we need to decide what to test at the unit level. Typically, programmers throw a few random bits of data at the code and call it tested. We can do much better, using the ideas behind design by contract.\n\nTesting Against Contract We like to think of unit testing as testing against contract (see Design by Contract, page 109). We want to write test cases that ensure that a given unit honors its contract. This will tell us two things: whether the code meets the contract, and whether the contract means what we think it means. We want to test that the module delivers the functionality it promises, over a wide range of test cases and boundary conditions.\n\nWhat does this mean in practice? Let’s look at the square root routine we ﬁrst encountered on page 114. Its contract is simple:\n\nrequire\n\nargument >= 0;\n\nensure\n\n((Result * Result) - argument).abs <= epsilon*argument;\n\nThis tells us what to test:",
      "content_length": 1932,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 216,
      "content": "CODE THAT’S EASY TO TEST\n\nPass in a negative argument and ensure that it is rejected.\n\nPass in an argument of zero to ensure that it is accepted (this is the boundary value).\n\nPass in values between zero and the maximum expressible argu- ment and verify that the difference between the square of the result and the original argument is less than some small fraction of the argument.\n\nArmed with this contract, and assuming that our routine does its own pre- and postcondition checking, we can write a basic test script to exercise the square root function.\n\npublic void testValue(double num, double expected) {\n\ndouble result = 0.0;\n\ntry {\n\n// We may throw a\n\nresult = mySqrt(num); // precondition exception\n\n} catch (Throwable e) {\n\nif (num < 0.0)\n\nreturn;\n\nelse\n\nassert(false);\n\n// If input is < 0, then // we’re expecting the // exception, otherwise // force a test failure\n\n}\n\nassert(Math.abs(expected-result) < epsilon*expected);\n\n}\n\nThen we can call this routine to test our square root function:\n\ntestValue(-4.0, 0.0); testValue( 0.0, 0.0); testValue( 2.0, 1.4142135624); testValue(64.0, 8.0); testValue(1.0e7, 3162.2776602);\n\nThis is a pretty simple test; in the real world, any nontrivial module is likely to be dependent on a number of other modules, so how do we go about testing the combination?\n\nSuppose we have a module A that uses a LinkedList and a Sort. In order, we would test:\n\n1. LinkedList’s contract, in full\n\n2. Sort’s contract, in full\n\n3. A’s contract, which relies on the other contracts but does not di-\n\nrectly expose them\n\n191",
      "content_length": 1555,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 217,
      "content": "192\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nThis style of testing requires you to test subcomponents of a module ﬁrst. Once the subcomponents have been veriﬁed, then the module itself can be tested.\n\nIf LinkedList and Sort’s tests passed, but A’s test failed, we can be pretty sure that the problem is in A, or in A’s use of one of those sub- components. This technique is a great way to reduce debugging effort: we can quickly concentrate on the likely source of the problem within module A, and not waste time reexamining its subcomponents.\n\nWhy do we go to all this trouble? Above all, we want to avoid creating a “time bomb”—something that sits around unnoticed and blows up at an awkward moment later in the project. By emphasizing testing against contract, we can try to avoid as many of those downstream disasters as possible.\n\nTIP 48\n\nDesign to Test\n\nWhen you design a module, or even a single routine, you should design both its contract and the code to test that contract. By designing code to pass a test and fulﬁll its contract, you may well consider bound- ary conditions and other issues that wouldn’t occur to you otherwise. There’s no better way to ﬁx errors than by avoiding them in the ﬁrst place. In fact, by building the tests before you implement the code, you get to try out the interface before you commit to it.\n\nWriting Unit Tests The unit tests for a module shouldn’t be shoved in some far-away cor- ner of the source tree. They need to be conveniently located. For small projects, you can embed the unit test for a module in the module itself. For larger projects, we suggest moving each test into a subdirectory. Either way, remember that if it isn’t easy to ﬁnd, it won’t be used.\n\nBy making the test code readily accessible, you are providing developers who may use your code with two invaluable resources:\n\n1. Examples of how to use all the functionality of your module",
      "content_length": 1893,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 218,
      "content": "CODE THAT’S EASY TO TEST\n\n2. A means to build regression tests to validate any future changes to\n\nthe code\n\nIt’s convenient, but not always practical, for each class or module to contain its own unit test. In Java, for example, every class can have its own main. In all but the application’s main class ﬁle, the main routine can be used to run unit tests; it will be ignored when the application itself is run. This has the beneﬁt that the code you ship still contains the tests, which can be used to diagnose problems in the ﬁeld.\n\nIn C++ you can achieve the same effect (at compile time) by using #ifdef to compile unit test code selectively. For example, here’s a very simple unit test in C++, embedded in our module, that checks our square root function using a testValue routine similar to the Java one deﬁned previously:\n\n#ifdef __TEST__ int main(int argc, char **argv) {\n\nargc--; argv++;\n\n// skip program name\n\nif (argc < 2) {\n\n// do standard tests if no args\n\ntestValue(-4.0, 0.0); testValue( 0.0, 0.0); testValue( 2.0, 1.4142135624); testValue(64.0, 8.0); testValue(1.0e7, 3162.2776602);\n\n} else {\n\n// else use args\n\ndouble num, expected;\n\nwhile (argc >= 2) {\n\nnum = atof(argv[0]); expected = atof(argv[1]); testValue(num,expected); argc -= 2; argv += 2;\n\n}\n\n} return 0;\n\n} #endif\n\nThis unit test will either run a minimal set of tests or, if given argu- ments, allow you to pass data in from the outside world. A shell script could use this ability to run a much more complete set of tests.\n\nWhat do you do if the correct response for a unit test is to exit, or abort the program? In that case, you need to be able to select the test to run, perhaps by specifying an argument on the command line. You’ll\n\n193",
      "content_length": 1718,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 219,
      "content": "194\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nalso need to pass in parameters if you need to specify different starting conditions for your tests.\n\nBut providing unit tests isn’t enough. You must run them, and run them often. It also helps if the class passes its tests once in a while.\n\nUsing Test Harnesses Because we usually write a lot of test code, and do a lot of testing, we’ll make life easier on ourselves and develop a standard testing harness for the project. The main shown in the previous section is a very simple test harness, but usually we’ll need more functionality than that.\n\nA test harness can handle common operations such as logging status, analyzing output for expected results, and selecting and running the tests. Harnesses may be GUI driven, may be written in the same target language as the rest of the project, or may be implemented as a combi- nation of makefiles and Perl scripts. A simple test harness is shown in the answer to Exercise 41 on page 305.\n\nIn object-oriented languages and environments, you might create a base class that provides these common operations. Individual tests can subclass from that and add speciﬁc test code. You could use a standard naming convention and reﬂection in Java to build a list of tests dynam- ically. This technique is a nice way of honoring the DRY principle—you don’t have to maintain a list of available tests. But before you go off and start writing your own harness, you may want to investigate Kent Beck and Erich Gamma’s xUnit at [URL 22]. You might also want to look at our book Pragmatic Unit Testing [HT03] for an introduction to JUnit.\n\nRegardless of the technology you decide to use, test harnesses should include the following capabilities:\n\nA standard way to specify setup and cleanup\n\nA method for selecting individual tests or all available tests\n\nA means of analyzing output for expected (or unexpected) results\n\nA standardized form of failure reporting\n\nTests should be composable; that is, a test can be composed of subtests of subcomponents to any depth. We can use this feature to test selected parts of the system or the entire system just as easily, using the same tools.",
      "content_length": 2157,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 220,
      "content": "CODE THAT’S EASY TO TEST\n\nAd Hoc Testing\n\nDuring debugging, we may end up creating some particular tests on- the-ﬂy. These may be as simple as a print statement, or a piece of code entered interactively in a debugger or IDE environment.\n\nAt the end of the debugging session, you need to formalize the ad hoc test. If the code broke once, it is likely to break again. Don’t just throw away the test you created; add it to the existing unit test.\n\nFor example, using JUnit (the Java member of the xUnit family), we might write our square root test as follows:\n\npublic class JUnitExample extends TestCase {\n\npublic JUnitExample(final String name) {\n\nsuper(name);\n\n}\n\nprotected void setUp() {\n\n// Load up test data... testData.addElement(new DblPair(-4.0,0.0)); testData.addElement(new DblPair(0.0,0.0)); testData.addElement(new DblPair(64.0,8.0)); testData.addElement(new DblPair(Double.MAX_VALUE,\n\n1.3407807929942597E154));\n\n}\n\npublic void testMySqrt() {\n\ndouble num, expected, result = 0.0;\n\nEnumeration enum = testData.elements(); while (enum.hasMoreElements()) {\n\nDblPair p = (DblPair)enum.nextElement(); num expected = p.getExpected(); testValue(num, expected);\n\n= p.getNum();\n\n}\n\n}\n\npublic static Test suite() {\n\nTestSuite suite= new TestSuite(); suite.addTest(new JUnitExample(\"testMySqrt\")); return suite;\n\n}\n\n}\n\nJUnit is designed to be composable: we could add as many tests as we wanted to this suite, and each of those tests could in turn be a suite. In addition, you have your choice of a graphical or batch interface to drive the tests.\n\n195",
      "content_length": 1551,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 221,
      "content": "196\n\nCHAPTER 6 WHILE YOU ARE CODING\n\nBuild a Test Window Even the best sets of tests are unlikely to ﬁnd all the bugs; there’s some- thing about the damp, warm conditions of a production environment that seems to bring them out of the woodwork.\n\nThis means you’ll often need to test a piece of software once it has been deployed—with real-world data ﬂowing though its veins. Unlike a circuit board or chip, we don’t have test pins in software, but we can provide various views into the internal state of a module, without using the debugger (which may be inconvenient or impossible in a production application).\n\nLog ﬁles containing trace messages are one such mechanism. Log mes- sages should be in a regular, consistent format; you may want to parse them automatically to deduce processing time or logic paths that the program took. Poorly or inconsistently formatted diagnostics are just so much “spew”—they are difﬁcult to read and impractical to parse.\n\nAnother mechanism for getting inside running code is the “hot-key” sequence. When this particular combination of keys is pressed, a diag- nostic control window pops up with status messages and so on. This isn’t something you normally would reveal to end users, but it can be very handy for the help desk.\n\nFor larger, more complex server code, a nifty technique for providing a view into its operation is to include a built-in Web server. Anyone can point a Web browser to the application’s HTTP port (which is usually on a nonstandard number, such as 8080) and see internal status, log entries, and possibly even some sort of a debug control panel. This may sound difﬁcult to implement, but it’s not. Freely available and embed- dable HTTP Web servers are available in a variety of modern languages. A good place to start looking is [URL 58].\n\nA Cultureof Testing All software you write will be tested—if not by you and your team, then by the eventual users—so you might as well plan on testing it thoroughly. A little forethought can go a long way toward minimizing maintenance costs and help-desk calls.",
      "content_length": 2065,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 222,
      "content": "CODE THAT’S EASY TO TEST\n\nDespite its hacker reputation, the Perl community has a very strong commitment to unit and regression testing. The Perl standard module installation procedure supports a regression test by invoking\n\n% make test\n\nThere’s nothing magic about Perl itself in this regard. Perl makes it easier to collate and analyze test results to ensure compliance, but the big advantage is simply that it’s a standard—tests go in a particular place, and have a certain expected output. Testing is more cultural than technical; we can instill this testing culture in a project regardless of the language being used.\n\nTIP 49\n\nTest Your Software, or Your Users Will\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Orthogonality, page 34 Design by Contract, page 109 Refactoring, page 184 Ruthless Testing, page 237\n\nExercises 41. Design a test jig for the blender interface described in the answer to Exer- cise 17 on page 289. Write a shell script that will perform a regression test for the blender. You need to test basic functionality, error and boundary conditions, and any contractual obligations. What restrictions are placed on changing the speed? Are they being honored?\n\n197\n\nAnswer on p. 305",
      "content_length": 1222,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 223,
      "content": "198\n\nCHAPTER 6 WHILE YOU ARE CODING\n\n35 Evil Wizards\n\nThere’s no denying it—applications are getting harder and harder to write. User interfaces in particular are becoming increasingly sophis- ticated. Twenty years ago, the average application would have a glass teletype interface (if it had an interface at all). Asynchronous terminals would typically provide a character interactive display, while pollable devices (such as the ubiquitous IBM 3270) would let you ﬁll in an entire screen before hitting SEND. Now, users expect graphical user interfaces, with context-sensitive help, cut and paste, drag and drop, OLE integra- tion, and MDI or SDI. Users are looking for Web-browser integration and thin-client support.\n\nAll the time the applications themselves are getting more complex. Most developments now use a multitier model, possibly with some middle- ware layer or a transaction monitor. These programs are expected to be dynamic and ﬂexible, and to interoperate with applications written by third parties.\n\nOh, and did we mention that we needed it all next week?\n\nDevelopers are struggling to keep up. If we were using the same kind of tools that produced the basic dumb-terminal applications 20 years ago, we’d never get anything done.\n\nSo the tool makers and infrastructure vendors have come up with a magic bullet, the wizard. Wizards are great. Do you need an MDI appli- cation with OLE container support? Just click a single button, answer a couple of simple questions, and the wizard will automatically generate skeleton code for you. The Microsoft Visual C++ environment creates over 1,200 lines of code for this scenario, automatically. Wizards are hard at work in other contexts, too. You can use wizards to create server components, implement Java beans, and handle network interfaces— all complex areas where it’s nice to have expert help.\n\nBut using a wizard designed by a guru does not automatically make Joe developer equally expert. Joe can feel pretty good—he’s just produced a mass of code and a pretty spiffy-looking program. He just adds in the speciﬁc application functionality and it’s ready to ship. But unless Joe actually understands the code that has been produced on his behalf, he’s fooling himself. He’s programming by coincidence. Wizards are a one-way street—they cut the code for you, and then move on. If the",
      "content_length": 2351,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 224,
      "content": "EVIL WIZARDS\n\ncode they produce isn’t quite right, or if circumstances change and you need to adapt the code, you’re on your own.\n\nWe are not against wizards. On the contrary, we dedicate an entire section (Code Generators, page 102) to writing your own. But if you do use a wizard, and you don’t understand all the code that it produces, you won’t be in control of your own application. You won’t be able to maintain it, and you’ll be struggling when it comes time to debug.\n\nTIP 50\n\nDon’t Use Wizard Code You Don’t Understand\n\nSome people feel that this is an extreme position. They say that develop- ers routinely rely on things they don’t fully understand—the quantum mechanics of integrated circuits, the interrupt structure of the proces- sor, the algorithms used to schedule processes, the code in the supplied libraries, and so on. We agree. And we’d feel the same about wizards if they were simply a set of library calls or standard operating system services that developers could rely on. But they’re not. Wizards gener- ate code that becomes an integral part of Joe’s application. The wizard code is not factored out behind a tidy interface—it is interwoven line by line with functionality that Joe writes.4 Eventually, it stops being the wizard’s code and starts being Joe’s. And no one should be producing code they don’t fully understand.\n\nRelated sections include: Orthogonality, page 34 Code Generators, page 102\n\nChallenges\n\nIf you have a GUI-building wizard available, use it to generate a skeleton application. Go through every line of code it produces. Do you understand it all? Could you have produced it yourself? Would you have produced it yourself, or is it doing things you don’t need?\n\n4. However, there are other techniques that help manage complexity. We discuss two, beans and AOP, in Orthogonality, page 34.\n\n199",
      "content_length": 1842,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 225,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 226,
      "content": "Chapter 7\n\nBefore the Project\n\nDo you ever get the feeling that your project is doomed, even before it starts? Sometimes it might be, unless you establish some basic ground rules ﬁrst. Otherwise, you might as well suggest that it be shut down now, and save the sponsor some money.\n\nAt the very beginning of a project, you’ll need to determine the require- ments. Simply listening to users is not enough: read The Requirements Pit to ﬁnd out more.\n\nConventional wisdom and constraint management are the topics of Solving Impossible Puzzles. Whether you are performing requirements, analysis, coding, or testing, difﬁcult problems will crop up. Most of the time, they won’t be as difﬁcult as they ﬁrst appear to be.\n\nWhen you think you’ve got the problems solved, you may still not feel comfortable with jumping in and starting. Is it simple procrastination, or is it something more? Not Until You’re Ready offers advice on when it may be prudent to listen to that cautionary voice inside your head.\n\nStarting too soon is one problem, but waiting too long may be even worse. In The Speciﬁcation Trap, we’ll discuss the advantages of speci- ﬁcation by example.\n\nFinally, we’ll look at some of the pitfalls of formal development pro- cesses and methodologies in Circles and Arrows. No matter how well thought out it is, and regardless of which “best practices” it includes, no method can replace thinking.\n\nWith these critical issues sorted out before the project gets under way, you can be better positioned to avoid “analysis paralysis” and actually begin your successful project.\n\n201",
      "content_length": 1583,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 227,
      "content": "36\n\n202\n\nCHAPTER 7 BEFORE THE PROJECT\n\nThe Requirements Pit\n\nPerfection is achieved, not when there is nothing left to add, but when there is nothing left to take away. ...\n\nAntoine de St. Exupery, Wind,Sand,andStars, 1939\n\nMany books and tutorials refer to requirements gathering as an early phase of the project. The word “gathering” seems to imply a tribe of happy analysts, foraging for nuggets of wisdom that are lying on the ground all around them while the Pastoral Symphony plays gently in the background. “Gathering” implies that the requirements are already there—you need merely ﬁnd them, place them in your basket, and be merrily on your way.\n\nIt doesn’t quite work that way. Requirements rarely lie on the surface. Normally, they’re buried deep beneath layers of assumptions, miscon- ceptions, and politics.\n\nTIP 51\n\nDon’t Gather Requirements—Dig for Them\n\nDigging for Requirements How can you recognize a true requirement while you’re digging through all the surrounding dirt? The answer is both simple and complex.\n\nThe simple answer is that a requirement is a statement of something that needs to be accomplished. Good requirements might include the following:\n\nAn employee record may be viewed only by a nominated group of people.\n\nThe cylinder-head temperature must not exceed the critical value, which varies by engine.\n\nThe editor will highlight keywords, which will be selected depending on the type of ﬁle being edited.\n\nHowever, very few requirements are as clear-cut, and that’s what makes requirements analysis complex.",
      "content_length": 1544,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 228,
      "content": "THE REQUIREMENTS PIT\n\nThe ﬁrst statement in the list above may have been stated by the users as “Only an employee’s supervisors and the personnel department may view that employee’s records.” Is this statement truly a requirement? Perhaps today, but it embeds business policy in an absolute statement. Policies change regularly, so we probably don’t want to hardwire them into our requirements. Our recommendation is to document these poli- cies separately from the requirement, and hyperlink the two. Make the requirement the general statement, and give the developers the policy information as an example of the type of thing they’ll need to support in the implementation. Eventually, policy may end up as metadata in the application.\n\nThis is a relatively subtle distinction, but it’s one that will have pro- found implications for the developers. If the requirement is stated as “Only personnel can view an employee record,” the developer may end up coding an explicit test every time the application accesses these ﬁles. However, if the statement is “Only authorized users may access an employee record,” the developer will probably design and implement some kind of access control system. When policy changes (and it will), only the metadata for that system will need to be updated. In fact, gath- ering requirements in this way naturally leads you to a system that is well factored to support metadata.\n\nThe distinctions among requirements, policy, and implementation can get very blurred when user interfaces are discussed. “The system must let you choose a loan term” is a statement of requirement. “We need a list box to select the loan term” may or may not be. If the users absolutely must have a list box, then it is a requirement. If instead they are describing the ability to choose, but are using listbox as an example, then it may not be. The box on page 205 discusses a project that went horribly wrong because the users’ interface needs were ignored.\n\nIt’s important to discover the underlying reason why users do a par- ticular thing, rather than just the way they currently do it. At the end of the day, your development has to solve their business problem, not just meet their stated requirements. Documenting the reasons behind requirements will give your team invaluable information when making daily implementation decisions.\n\nThere’s a simple technique for getting inside your users’ requirements that isn’t used often enough: become a user. Are you writing a system\n\n203",
      "content_length": 2496,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 229,
      "content": "204\n\nCHAPTER 7 BEFORE THE PROJECT\n\nfor the help desk? Spend a couple of days monitoring the phones with an experienced support person. Are you automating a manual stock control system? Work in the warehouse for a week.1 As well as giving you insight into how the system will really be used, you’d be amazed at how the request “May I sit in for a week while you do your job?” helps build trust and establishes a basis for communication with your users. Just remember not to get in the way!\n\nTIP 52\n\nWork with a User to Think Like a User\n\nThe requirements mining process is also the time to start to build a rap- port with your user base, learning their expectations and hopes for the system you are building. See Great Expectations, page 255, for more.\n\nDocumenting Requirements So you are sitting down with the users and prying genuine require- ments from them. You come across a few likely scenarios that describe what the application needs to do. Ever the professional, you want to write these down and publish a document that everyone can use as a basis for discussions—the developers, the end users, and the project sponsors.\n\nThat’s a pretty wide audience.\n\nIvar Jacobson [Jac94] proposed the concept of use cases to capture requirements. They let you describe a particular use of the system— not in terms of user interface, but in a more abstract fashion. Unfortu- nately, Jacobson’s book was a little vague on details, so there are now many different opinions on what a use case should be. Is it formal or informal, simple prose or a structured document (like a form)? What level of detail is appropriate (remember we have a wide audience)?\n\n1. Does a week sound like a long time? It really isn’t, particularly when you’re looking at processes in which management and workers occupy different worlds. Management will give you one view of how things operate, but when you get down on the ﬂoor, you’ll ﬁnd a very different reality—one that will take time to assimilate.",
      "content_length": 1974,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 230,
      "content": "THE REQUIREMENTS PIT\n\nSometimes the Interface Isthe System\n\nIn an article in Wired magazine (January 1999, page 176), pro- ducer and musician Brian Eno described an incredible piece of technology—the ultimate mixing board. It does anything to sound that can be done. And yet, instead of letting musicians make better music, or produce a recording faster or less expensively, it gets in the way; it disrupts the creative process.\n\nTo see why, you have to look at how recording engineers work. They balance sounds intuitively. Over the years, they develop an innate feedback loop between their ears and their ﬁngertips—sliding faders, rotating knobs, and so on. However, the interface to the new mixer didn’t leverage off those abilities. Instead, it forced its users to type on a keyboard or click a mouse. The functions it provided were com- prehensive, but they were packaged in unfamiliar and exotic ways. The functions the engineers needed were sometimes hidden behind obscure names, or were achieved with nonintuitive combinations of basic facilities.\n\nThat environment has a requirement to leverage existing skill sets. While slavishly duplicating what already exists doesn’t allow for progress, we must be able to provide a transitionto the future.\n\nFor example, the recording engineers may have been better served by some sort of touchscreen interface—still tactile, still mounted as a traditional mixing board might be, yet allowing the software to go be- yond the realm of ﬁxed knobs and switches. Providing a comfortable transition through familiar metaphors is one way to help get buy-in.\n\nThis example also illustrates our belief that successful tools adapt to the hands that use them. In this case, it is the tools that you build for others that must be adaptable.\n\nOne way of looking at use cases is to emphasize their goal-driven nature. Alistair Cockburn has a paper that describes this approach, as well as templates that can be used (strictly or not) as a starting place ([Coc97a], also online at [URL 46]). Figure 7.1 on the following page shows an abbreviated example of his template, while Figure 7.2 shows his sample use case.\n\nBy using a formal template as an aide-mémoire, you can be sure that you include all the information you need in a use case: performance\n\n205",
      "content_length": 2290,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 231,
      "content": "206\n\nCHAPTER 7 BEFORE THE PROJECT\n\nFigure 7.1. Cockburn’s use case template\n\nA. CHARACTERISTIC INFORMATION\n\n– Goal in context – Scope – Level – Preconditions – Success end condition – Failed end condition – Primary actor – Trigger\n\nB. MAIN SUCCESS SCENARIO C. EXTENSIONS D. VARIATIONS E. RELATED INFORMATION\n\n– – – – Superordinate use case – Subordinate use cases – Channel to primary actor – Secondary actors – Channel to secondary actors\n\nPriority Performance target Frequency\n\nF. SCHEDULE G. OPEN ISSUES\n\ncharacteristics, other involved parties, priority, frequency, and various errors and exceptions that can crop up (“nonfunctional requirements”). This is also a great place to record user comments such as “oh, except if we get a xxx condition, then we have to do yyy instead.” The template also serves as a ready-made agenda for meetings with your users.\n\nThis sort of organization supports the hierarchical structuring of use cases—nesting more detailed use cases inside higher-level ones. For example, post debit and post credit both elaborate on post transaction.\n\nUseCaseDiagrams Workﬂow can be captured with UML activity diagrams, and conceptual- level class diagrams can sometimes be useful for modeling the business",
      "content_length": 1229,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 232,
      "content": "THE REQUIREMENTS PIT\n\nFigure 7.2. A sample use case\n\nUSE CASE 5: BUY GOODS\n\nA. CHARACTERISTIC INFORMATION\n\nGoal in context: Buyer issues request directly to our company, expects goods shipped and to be billed. Scope: Company Level: Summary Preconditions: We know buyer, their address, etc. Success end condition: Buyer has goods, we have money for the goods. Failed end condition: We have not sent the goods, buyer has not sent the money. Primary actor: Buyer, any agent (or computer) acting for the customer Trigger: Purchase request comes in.\n\nB. MAIN SUCCESS SCENARIO\n\n1. Buyer calls in with a purchase request. 2. Company captures buyer’s name, address, requested goods, etc. 3. Company gives buyer information on goods, prices, delivery dates, etc. 4. Buyer signs for order. 5. Company creates order, ships order to buyer. 6. Company ships invoice to buyer. 7. Buyer pays invoice.\n\nC. EXTENSIONS\n\n3a. Company is out of one of the ordered items: Renegotiate order. 4a. Buyer pays directly with credit card: Take payment by credit card (use\n\ncase 44).\n\n7a. Buyer returns goods: Handle returned goods (use case 105).\n\nD. VARIATIONS\n\n1. Buyer may use phone in, fax in, Web order form, electronic interchange. 7. Buyer may pay by cash, money order, check, or credit card.\n\nE. RELATED INFORMATION Priority: Top Performance target: 5 minutes for order, 45 days until paid Frequency: 200/day Superordinate use case: Manage customer relationship (use case 2). Subordinate use cases: Create order (15). Take payment by credit card (44). Handle returned goods (105). Channel to primary actor: May be phone, ﬁle, or interactive Secondary actors: Credit card company, bank, shipping service\n\nF. SCHEDULE\n\nDue date: Release 1.0\n\nG. OPEN ISSUES\n\nWhat happens if we have part of the order? What happens if credit card is stolen?\n\n207",
      "content_length": 1822,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 233,
      "content": "208\n\nCHAPTER 7 BEFORE THE PROJECT\n\nFigure 7.3. UML use cases—so simple a child could do it!\n\nGo home\n\nat hand. But true use cases are textual descriptions, with a hierarchy and cross-links. Use cases can contain hyperlinks to other use cases, and they can be nested within each other.\n\nIt seems incredible to us that anyone would seriously consider docu- menting information this dense using only simplistic stick people such as Figure 7.3. Don’t be a slave to any notation; use whatever method best communicates the requirements with your audience.\n\nOverspecifying A big danger in producing a requirements document is being too spe- ciﬁc. Good requirements documents remain abstract. Where require- ments are concerned, the simplest statement that accurately reﬂects the business need is best. This doesn’t mean you can be vague—you must capture the underlying semantic invariants as requirements, and document the speciﬁc or current work practices as policy.\n\nRequirements are not architecture. Requirements are not design, nor are they the user interface. Requirements are need.\n\nSeeing Further The Year 2000 problem is often blamed on short-sighted programmers, desperate to save a few bytes in the days when mainframes had less memory than a modern TV remote control.\n\nBut it wasn’t the programmers’ doing, and it wasn’t really a memory usage issue. If anything, it was the system analysts’ and designers’ fault. The Y2K problem came about from two main causes: a failure to see beyond current business practice, and a violation of the DRY principle.",
      "content_length": 1555,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 234,
      "content": "THE REQUIREMENTS PIT\n\nBusinesses were using the two-digit shortcut long before computers came on the scene. It was common practice. The earliest data process- ing applications merely automated existing business processes, and simply repeated the mistake. Even if the architecture required two-digit years for data input, reporting, and storage, there should have been an abstraction of a DATE that “knew” the two digits were an abbreviated form of the real date.\n\nTIP 53\n\nAbstractions Live Longer than Details\n\nDoes “seeing further” require you to predict the future? No. It means generating statements such as\n\nThe system makes active use of an abstraction of DATEs. The system will implement DATE services, such as formatting, storage, and math operations, consistently and universally.\n\nThe requirements will specify only that dates are used. It may hint that some math may be done on dates. It may tell you that dates will be stored on various forms of secondary storage. These are genuine requirements for a DATE module or class.\n\nJust OneMore Wafer-ThinMint... Many projects failures are blamed on an increase in scope—also known as feature bloat, creeping featurism, or requirements creep. This is an aspect of the boiled-frog syndrome from Stone Soup and Boiled Frogs, page 7. What can we do to prevent requirements from creeping up on us?\n\nIn the literature, you will ﬁnd descriptions of many metrics, such as bugs reported and ﬁxed, defect density, cohesion, coupling, function points, lines of code, and so on. These metrics may be tracked by hand or with software.\n\nUnfortunately, not many projects seem to track requirements actively. This means that they have no way to report on changes of scope— who requested a feature, who approved it, total number of requests approved, and so on.\n\n209",
      "content_length": 1804,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 235,
      "content": "210\n\nCHAPTER 7 BEFORE THE PROJECT\n\nThe key to managing growth of requirements is to point out each new feature’s impact on the schedule to the project sponsors. When the project is a year late from initial estimates and accusations start ﬂying, it can be helpful to have an accurate, complete picture of how, and when, requirements growth occurred.\n\nIt’s easy to get sucked into the “just one more feature” maelstrom, but by tracking requirements you can get a clearer picture that “just one more feature” is really the ﬁfteenth new feature added this month.\n\nMaintain a Glossary As soon as you start discussing requirements, users and domain ex- perts will use certain terms that have speciﬁc meaning to them. They may differentiate between a “client” and a “customer,” for example. It would then be inappropriate to use either word casually in the system.\n\nCreate and maintain a project glossary—one place that deﬁnes all the speciﬁc terms and vocabulary used in a project. All participants in the project, from end users to support staff, should use the glossary to ensure consistency. This implies that the glossary needs to be widely accessible—a good argument for Web-based documentation (more on that in a moment).\n\nTIP 54\n\nUse a Project Glossary\n\nIt’s very hard to succeed on a project where the users and develop- ers refer to the same thing by different names or, even worse, refer to different things by the same name.\n\nGet theWord Out In It’s All Writing, page 248, we discuss publishing of project documents to internal Web sites for easy access by all participants. This method of distribution is particularly useful for requirements documents.\n\nBy presenting requirements as a hypertext document, we can better address the needs of a diverse audience—we can give each reader what",
      "content_length": 1794,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 236,
      "content": "THE REQUIREMENTS PIT\n\nthey want. Project sponsors can cruise along at a high level of abstrac- tion to ensure that business objectives are met. Programmers can use hyperlinks to “drill down” to increasing levels of detail (even referencing appropriate deﬁnitions or engineering speciﬁcations).\n\nWeb-based distribution also avoids the typical two-inch-thick binder entitled Requirements Analysis that no one ever reads and that becomes outdated the instant ink hits paper.\n\nIf it’s on the Web, the programmers may even read it.\n\nRelated sections include:\n\nStone Soup and Boiled Frogs, page 7 Good-Enough Software, page 9 Circles and Arrows, page 220 It’s All Writing, page 248 Great Expectations, page 255\n\nChallenges\n\nCan you use the software you are writing? Is it possible to have a good feel for requirements without being able to use the software yourself?\n\nPick a non-computer-related problem you currently need to solve. Gener- ate requirements for a noncomputer solution.\n\nExercises 42. Which of the following are probably genuine requirements? Restate those\n\nthat are not to make them more useful (if possible).\n\n1. The response time must be less than 500 ms.\n\n2. Dialog boxes will have a gray background.\n\n3. The application will be organized as a number of front-end processes\n\nand a back-end server.\n\n4. If a user enters non-numeric characters in a numeric ﬁeld, the system\n\nwill beep and not accept them.\n\n5. The application code and data must ﬁt within 256kB.\n\n211\n\nAnswer on p. 307",
      "content_length": 1495,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 237,
      "content": "212\n\nCHAPTER 7 BEFORE THE PROJECT\n\n37 Solving Impossible Puzzles\n\nGordius, the King of Phrygia, once tied a knot that no one could untie. It was said that he who solved the riddle of the Gordian Knot would rule all of Asia. So along comes Alexander the Great, who chops the knot to bits with his sword. Just a and he did end up little different interpretation of the requirements, that’s all ruling most of Asia.\n\nEvery now and again, you will ﬁnd yourself embroiled in the middle of a project when a really tough puzzle comes up: some piece of engineering that you just can’t get a handle on, or perhaps some bit of code that is turning out to be much harder to write than you thought. Maybe it looks impossible. But is it really as hard as it seems?\n\nConsider real-world puzzles—those devious little bits of wood, wrought iron, or plastic that seem to turn up as Christmas presents or at garage sales. All you have to do is remove the ring, or ﬁt the T-shaped pieces in the box, or whatever.\n\nSo you pull on the ring, or try to put the T’s in the box, and quickly discover that the obvious solutions just don’t work. The puzzle can’t be solved that way. But even though it’s obvious, that doesn’t stop people from trying the same thing—over and over—thinking there must be a way.\n\nOf course, there isn’t. The solution lies elsewhere. The secret to solving the puzzle is to identify the real (not imagined) constraints, and ﬁnd a solution therein. Some constraints are absolute; others are merely preconceived notions. Absolute constraints must be honored, however distasteful or stupid they may appear to be. On the other hand, some apparent constraints may not be real constraints at all. For example, there’s that old bar trick where you take a brand new, unopened cham- pagne bottle and bet that you can drink beer out of it. The trick is to turn the bottle upside down, and pour a small quantity of beer in the hollow in the bottom of the bottle. Many software problems can be just as sneaky.\n\nDegrees of Freedom The popular buzz-phrase “thinking outside the box” encourages us to recognize constraints that might not be applicable and to ignore them.",
      "content_length": 2157,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 238,
      "content": "SOLVING IMPOSSIBLE PUZZLES\n\nBut this phrase isn’t entirely accurate. If the “box” is the boundary of constraints and conditions, then the trick is to ﬁnd the box, which may be considerably larger than you think.\n\nThe key to solving puzzles is both to recognize the constraints placed on you and to recognize the degrees of freedom you do have, for in those you’ll ﬁnd your solution. This is why some puzzles are so effective; you may dismiss potential solutions too readily.\n\nFor example, can you connect all of the dots in the following puzzle and return to the starting point with just three straight lines—without lifting your pen from the paper or retracing your steps [Hol78]?\n\nYou must challenge any preconceived notions and evaluate whether or not they are real, hard-and-fast constraints.\n\nIt’s not whether you think inside the box or outside the box. The prob- lem lies in ﬁnding the box—identifying the real constraints.\n\nTIP 55\n\nDon’t Think Outside the Box—Find the Box\n\nWhen faced with an intractable problem, enumerate all the possible avenues you have before you. Don’t dismiss anything, no matter how unusable or stupid it sounds. Now go through the list and explain why a certain path cannot be taken. Are you sure? Can you prove it?\n\nConsider the Trojan horse—a novel solution to an intractable problem. How do you get troops into a walled city without being discovered? You can bet that “through the front door” was initially dismissed as suicide.\n\nCategorize and prioritize your constraints. When woodworkers begin a project, they cut the longest pieces ﬁrst, then cut the smaller pieces out of the remaining wood. In the same manner, we want to identify the most restrictive constraints ﬁrst, and ﬁt the remaining constraints within them.\n\nBy the way, a solution to the Four Posts puzzle is shown on page 307.\n\n213",
      "content_length": 1834,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 239,
      "content": "214\n\nCHAPTER 7 BEFORE THE PROJECT\n\nThereMust BeanEasierWay! Sometimes you will ﬁnd yourself working on a problem that seems much harder than you thought it should be. Maybe it feels like you’re going down the wrong path—that there must be an easier way than this! Perhaps you are running late on the schedule now, or even despair of ever getting the system to work because this particular problem is “impossible.”\n\nThat’s when you step back a pace and ask yourself these questions:\n\nIs there an easier way?\n\nAre you trying to solve the right problem, or have you been dis- tracted by a peripheral technicality?\n\nWhy is this thing a problem?\n\nWhat is it that’s making it so hard to solve?\n\nDoes it have to be done this way?\n\nDoes it have to be done at all?\n\nMany times a surprising revelation will come to you as you try to answer one of these questions. Many times a reinterpretation of the require- ments can make a whole set of problems go away—just like the Gordian knot.\n\nAll you need are the real constraints, the misleading constraints, and the wisdom to know the difference.\n\nChallenges\n\nTake a hard look at whatever difﬁcult problem you are embroiled in today. Can you cut the Gordian knot? Ask yourself the key questions we outlined above, especially “Does it have to be done this way?”\n\nWere you handed a set of constraints when you signed on to your current project? Are they all still applicable, and is the interpretation of them still valid?",
      "content_length": 1455,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 240,
      "content": "NOT UNTIL YOU’RE READY\n\n38 Not Until You’re Ready\n\nHe who hesitates is sometimes saved.\n\nJames Thurber, TheGlassintheField\n\nGreat performers share a trait: they know when to start and when to wait. The diver stands on the high-board, waiting for the perfect moment to jump. The conductor stands before the orchestra, arms raised, until she senses that the moment is right to start the piece.\n\nYou are a great performer. You too need to listen to the voice that whis- pers “wait.” If you sit down to start typing and there’s some nagging doubt in your mind, heed it.\n\nTIP 56\n\nListen to Nagging Doubts—Start When You’re Ready\n\nThere used to be a style of tennis coaching called “inner tennis.” You’d spend hours hitting balls over the net, not particularly trying for accu- racy, but instead verbalizing just where the ball hit relative to some target (often a chair). The idea was that the feedback would train your subconscious and reﬂexes, so that you improved without consciously knowing how or why.\n\nAs a developer, you’ve been doing the same kind of thing during your entire career. You’ve been trying things and seeing which worked and which didn’t. You’ve been accumulating experience and wisdom. When you feel a nagging doubt, or experience some reluctance when faced with a task, heed it. You may not be able to put your ﬁnger on exactly what’s wrong, but give it time and your doubts will probably crystal- lize into something more solid, something you can address. Software development is still not a science. Let your instincts contribute to your performance.\n\nGoodJudgment or Procrastination? Everyone fears the blank sheet of paper. Starting a new project (or even a new module in an existing project) can be an unnerving experience. Many of us would prefer to put off making the initial commitment of\n\n215",
      "content_length": 1819,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 241,
      "content": "216\n\nCHAPTER 7 BEFORE THE PROJECT\n\nstarting. So how can you tell when you’re simply procrastinating, rather than responsibly waiting for all the pieces to fall into place?\n\nA technique that has worked for us in these circumstances is to start prototyping. Choose an area that you feel will be difﬁcult and begin producing some kind of proof of concept. One of two things will typi- cally happen. Shortly after starting, you may feel that you’re wasting your time. This boredom is probably a good indication that your initial reluctance was just a desire to put off the commitment to start. Give up on the prototype, and hack into the real development.\n\nOn the other hand, as the prototype progresses you may have one of those moments of revelation when you suddenly realize that some basic premise was wrong. Not only that, but you’ll see clearly how you can put it right. You’ll feel comfortable abandoning the prototype and launching into the project proper. Your instincts were right, and you’ve just saved yourself and your team a considerable amount of wasted effort.\n\nWhen you make the decision to prototype as a way of investigating your unease, be sure to remember why you’re doing it. The last thing you want is to ﬁnd yourself several weeks into serious development before remembering that you started out writing a prototype.\n\nSomewhat cynically, starting work on a prototype might also be more politically acceptable than simply announcing that “I don’t feel right about starting” and ﬁring up solitaire.\n\nChallenges\n\nDiscuss the fear-of-starting syndrome with your colleagues. Do others ex- perience the same thing? Do they heed it? What tricks do they use to overcome it? Can a group help overcome an individual’s reluctance, or is that just peer pressure?",
      "content_length": 1770,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 242,
      "content": "39\n\nTHE SPECIFICATION TRAP\n\nThe Speciﬁcation Trap\n\nThe Landing Pilot is the Non-Handling Pilot until the ‘decision altitude’ call, when the Handling Non-Landing Pilot hands the handling to the Non-Handling Land- ing Pilot, unless the latter calls ‘go-around,’ in which case the Handling Non- Landing Pilot continues handling and the Non-Handling Landing Pilot continues non-handling until the next call of ‘land’ or ‘go-around’ as appropriate. In view of recent confusions over these rules, it was deemed necessary to restate them clearly.\n\nBritish Airways memorandum, quoted in Pilot Magazine, December 1996\n\nProgram speciﬁcation is the process of taking a requirement and reduc- ing it down to the point where a programmer’s skill can take over. It is an act of communication, explaining and clarifying the world in such a way as to remove major ambiguities. As well as talking to the developer who will be performing the initial implementation, the speciﬁcation is a record for future generations of programmers who will be maintaining and enhancing the code. The speciﬁcation is also an agreement with the user—a codiﬁcation of their needs and an implicit contract that the ﬁnal system will be in line with that requirement.\n\nWriting a speciﬁcation is quite a responsibility.\n\nThe problem is that many designers ﬁnd it difﬁcult to stop. They feel that unless every little detail is pinned down in excruciating detail they haven’t earned their daily dollar.\n\nThis is a mistake for several reasons. First, it’s naive to assume that a speciﬁcation will ever capture every detail and nuance of a system or its requirement. In restricted problem domains, there are formal methods that can describe a system, but they still require the designer to explain the meaning of the notation to the end users—there is still a human interpretation going on to mess things up. Even without the problems inherent in this interpretation, it is very unlikely that the average user knows going in to a project exactly what they need. They may say they have an understanding of the requirement, and they may sign off on the 200-page document you produce, but you can guarantee that once they see the running system you’ll be inundated with change requests.\n\nSecond, there is a problem with the expressive power of language it- self. All the diagramming techniques and formal methods still rely on\n\n217",
      "content_length": 2384,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 243,
      "content": "218\n\nCHAPTER 7 BEFORE THE PROJECT\n\nnatural language expressions of the operations to be performed.2 And natural language is really not up to the job. Look at the wording of any contract: in an attempt to be precise, lawyers have to bend the language in the most unnatural ways.\n\nHere’s a challenge for you. Write a short description that tells someone how to tie bows in their shoelaces. Go on, try it!\n\nIf you are anything like us, you probably gave up somewhere around “now roll your thumb and foreﬁnger so that the free end passes under and inside the left lace. .. .” It is a phenomenally difﬁcult thing to do. And yet most of us can tie our shoes without conscious thought.\n\nTIP 57\n\nSome Things Are Better Done than Described\n\nFinally, there is the straightjacket effect. A design that leaves the coder no room for interpretation robs the programming effort of any skill and art. Some would say this is for the best, but they’re wrong. Often, it is only during coding that certain options become apparent. While coding, you may think “Look at that. Because of the particular way I coded this routine, I could add this additional functionality with almost no effort” or “The speciﬁcation says to do this, but I could achieve an almost identical result by doing it a different way, and I could do it in half the time.” Clearly, you shouldn’t just hack in and make the changes, but you wouldn’t even have spotted the opportunity if you were constrained by an overly prescriptive design.\n\nAs a Pragmatic Programmer, you should tend to view requirements gathering, design, and implementation as different facets of the same process—the delivery of a quality system. Distrust environments where requirements are gathered, speciﬁcations are written, and then coding starts, all in isolation. Instead, try to adopt a seamless approach: spec- iﬁcation and implementation are simply different aspects of the same process—an attempt to capture and codify a requirement. Each should\n\n2. There are some formal techniques that attempt to express operations algebraically, but these techniques are rarely used in practice. They still require that the analysts explain the meaning to the end users.",
      "content_length": 2187,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 244,
      "content": "THE SPECIFICATION TRAP\n\nﬂow directly into the next, with no artiﬁcial boundaries. You’ll ﬁnd that a healthy development process encourages feedback from implementa- tion and testing into the speciﬁcation process.\n\nJust to be clear, we are not against generating speciﬁcations. Indeed, we recognize that there are times where incredibly detailed speciﬁcations are demanded—for contractual reasons, because of the environment where you work, or because of the nature of the product you are de- veloping.3 Just be aware that you reach a point of diminishing, or even negative, returns as the speciﬁcations get more and more detailed. Also be careful about building speciﬁcations layered on top of speciﬁcations, without any supporting implementation or prototyping; it’s all too easy to specify something that can’t be built.\n\nThe longer you allow speciﬁcations to be security blankets, protecting developers from the scary world of writing code, the harder it will be to move on to hacking out code. Don’t fall into this speciﬁcation spiral: at some point, you need to start coding! If you ﬁnd your team all wrapped up in warm, comfy speciﬁcations, break them out. Look at prototyping, or consider a tracer bullet development.\n\nRelated sections include: Tracer Bullets, page 48\n\nChallenges\n\nThe shoelace example mentioned in the text is an interesting illustration of the problems of written descriptions. Did you consider describing the process using diagrams rather than words? Photographs? Some formal notation from topology? Models with wire laces? How would you teach a toddler?\n\nSometimes a picture is worth more than any number of words. Sometimes it is worthless. If you ﬁnd yourself overspecifying, would pictures or special notations help? How detailed do they have to be? When is a drawing tool better than a whiteboard?\n\n3. Detailed speciﬁcations are clearly appropriate for life-critical systems. We feel they should also be produced for interfaces and libraries used by others. When your entire output is seen as a set of routine calls, you’d better make sure those calls are well speciﬁed.\n\n219",
      "content_length": 2107,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 245,
      "content": "220\n\nCHAPTER 7 BEFORE THE PROJECT\n\n40 Circles and Arrows\n\n[photographs] with circles and arrows and a paragraph on the back of each one explaining what each one was, to be used as evidence against us. ..\n\nArlo Guthrie, “Alice’s Restaurant”\n\nFrom structured programming, through chief programmer teams, CASE tools, waterfall development, the spiral model, Jackson, ER diagrams, Booch clouds, OMT, Objectory, and Coad/Yourdon, to today’s UML, computing has never been short of methods intended to make pro- gramming more like engineering. Each method gathers its disciples, and each enjoys a period of popularity. Then each is replaced by the next. Of all of them, perhaps only the ﬁrst—structured programming— has enjoyed a long life.\n\nYet some developers, adrift in a sea of sinking projects, keep clinging to the latest fad just as shipwreck victims latch onto passing driftwood. As each new piece ﬂoats by they painfully swim over, hoping it will be better. At the end of the day, though, it doesn’t matter how good the ﬂotsam is, the developers are still aimlessly adrift.\n\nDon’t get us wrong. We like (some) formal techniques and methods. But we believe that blindly adopting any technique without putting it into the context of your development practices and capabilities is a recipe for disappointment.\n\nTIP 58\n\nDon’t Be a Slave to Formal Methods\n\nFormal methods have some serious shortcomings.\n\nMost formal methods capture requirements using a combination of diagrams and some supporting words. These pictures represent the designers’ understanding of the requirements. However in many cases these diagrams are meaningless to the end users, so the designers have to interpret them. Therefore, there is no real formal checking of the requirements by the actual user of the system— everything is based on the designers’ explanations, just as in old- fashioned written requirements. We see some beneﬁt in capturing requirements this way, but we prefer, where possible, to show the user a prototype and let them play with it.",
      "content_length": 2028,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 246,
      "content": "CIRCLES AND ARROWS\n\nFormal methods seem to encourage specialization. One group of people works on a data model, another looks at the architecture, while requirements gatherers collect use cases (or their equivalent). We’ve seen this lead to poor communication and wasted effort. There is also a tendency to fall back into the us versus them mental- ity of designers against coders. We prefer to understand the whole of the system we’re working on. It may not be possible to have an in-depth grasp of every aspect of a system, but you should know how the components interact, where the data lives, and what the requirements are.\n\nWe like to write adaptable, dynamic systems, using metadata to allow us to change the character of applications at runtime. Most current formal methods combine a static object or data model with some kind of event- or activity-charting mechanism. We haven’t yet come across one that allows us to illustrate the kind of dynamism we feel systems should exhibit. In fact, most formal methods will lead you astray, encouraging you to set up static relationships between objects that really should be knitted together dynamically.\n\nDoMethods PayOff? In a 1999 CACM article [Gla99b], Robert Glass reviews the research into the productivity and quality improvements gained using seven different software development technologies (4GLs, structured tech- niques, CASE tools, formal methods, clean room methodology, process models, and object orientation). He reports that the initial hype sur- rounding all of these methods was overblown. Although there is an indication that some methods have beneﬁts, these beneﬁts start to manifest themselves only after a signiﬁcant productivity and quality drop while the technique is adopted and its users train themselves. Never underestimate the cost of adopting new tools and methods. Be prepared to treat the ﬁrst projects using these techniques as a learning experience.\n\nShouldWeUseFormalMethods? Absolutely. But always remember that formal development methods are just one more tool in the toolbox. If, after careful analysis, you feel you need to use a formal method, then embrace it—but remember who is in charge. Never become a slave to a methodology: circles and\n\n221",
      "content_length": 2237,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 247,
      "content": "222\n\nCHAPTER 7 BEFORE THE PROJECT\n\narrows make poor masters. Pragmatic Programmers look at methodolo- gies critically, then extract the best from each and meld them into a set of working practices that gets better each month. This is crucial. You should work constantly to reﬁne and improve your processes. Never accept the rigid conﬁnes of a methodology as the limits of your world.\n\nDon’t give in to the false authority of a method. People may walk into meetings with an acre of class diagrams and 150 use cases, but all that paper is still just their fallible interpretation of requirements and design. Try not to think about how much a tool cost when you look at its output.\n\nTIP 59\n\nExpensive Tools Do Not Produce Better Designs\n\nFormal methods certainly have their place in development. However, if you come across a project where the philosophy is “the class diagram is the application, the rest is mechanical coding,” you know you’re looking at a waterlogged project team and a long paddle home.\n\nRelated sections include:\n\nThe Requirements Pit, page 202\n\nChallenges\n\nUse case diagrams are part of the UML process for gathering requirements (see The Requirements Pit, page 202). Are they an effective way of commu- nicating with your users? If not, why are you using them?\n\nHow can you tell if a formal method is bringing your team beneﬁts? What can you measure? What constitutes an improvement? Can you distinguish between beneﬁts of the tool and increased experience on the part of team members?\n\nWhere is the break-even point for introducing new methods to your team? How do you evaluate the trade-off between future beneﬁts and current losses of productivity as the tool is introduced?\n\nAre tools that work for large projects good for small ones? How about the other way around?",
      "content_length": 1790,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 248,
      "content": "Chapter 8\n\nPragmatic Projects\n\nAs your project gets under way, we need to move away from issues of individual philosophy and coding to talk about larger, project-sized issues. We aren’t going to go into speciﬁcs of project management, but we will talk about a handful of critical areas that can make or break any project.\n\nAs soon as you have more than one person working on a project, you need to establish some ground rules and delegate parts of the project accordingly. In Pragmatic Teams, we’ll show how to do this while hon- oring the pragmatic philosophy.\n\nThe single most important factor in making project-level activities work consistently and reliably is to automate your procedures. We’ll explain why, and show some real-life examples in Ubiquitous Automation.\n\nEarlier, we talked about testing as you code. In Ruthless Testing, we go to the next step of project-wide testing philosophy and tools—especially if you don’t have a large QA staff at your beck and call.\n\nThe only thing that developers dislike more than testing is documenta- tion. Whether you have technical writers helping you or are doing it on your own, we’ll show you how to make the chore less painful and more productive in It’s All Writing.\n\nSuccess is in the eye of the beholder—the sponsor of the project. The perception of success is what counts, and in Great Expectations we’ll show you some tricks to delight every project’s sponsor.\n\n223",
      "content_length": 1424,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 249,
      "content": "41\n\n224\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nThe last tip in the book is a direct consequence of all the rest. In Pride and Prejudice, we encourage you to sign your work, and to take pride in what you do.\n\nPragmatic Teams\n\nAt Group L, Stoffel oversees six ﬁrst-rate programmers, a managerial challenge roughly comparable to herding cats.\n\nThe Washington Post Magazine, June 9, 1985\n\nSo far in this book we’ve looked at pragmatic techniques that help an individual be a better programmer. Can these methods work for teams as well?\n\nThe answer is a resounding “yes!” There are advantages to being a prag- matic individual, but these advantages are multiplied manyfold if the individual is working on a pragmatic team.\n\nIn this section we’ll look brieﬂy at how pragmatic techniques can be applied to teams as a whole. These notes are only a start. Once you’ve got a group of pragmatic developers working in an enabling environ- ment, they’ll quickly develop and reﬁne their own team dynamics that work for them.\n\nLet’s recast some of the previous sections in terms of teams.\n\nNo Broken Windows Quality is a team issue. The most diligent developer placed on a team that just doesn’t care will ﬁnd it difﬁcult to maintain the enthusiasm needed to ﬁx niggling problems. The problem is further exacerbated if the team actively discourages the developer from spending time on these ﬁxes.\n\nTeams as a whole should not tolerate broken windows—those small imperfections that no one ﬁxes. The team must take responsibility for the quality of the product, supporting developers who understand the no broken windows philosophy we describe in Software Entropy, page 4, and encouraging those who haven’t yet discovered it.",
      "content_length": 1700,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 250,
      "content": "PRAGMATIC TEAMS\n\nSome team methodologies have a quality ofﬁcer—someone to whom the team delegates the responsibility for the quality of the deliverable. This is clearly ridiculous: quality can come only from the individual contri- butions of all team members.\n\nBoiledFrogs Remember the poor frog in the pan of water, back in Stone Soup and Boiled Frogs, page 7? It doesn’t notice the gradual change in its en- vironment, and ends up cooked. The same can happen to individuals who aren’t vigilant. It can be difﬁcult to keep an eye on your overall environment in the heat of project development.\n\nIt’s even easier for teams as a whole to get boiled. People assume that someone else is handling an issue, or that the team leader must have OK’d a change that your user is requesting. Even the best-intentioned teams can be oblivious to signiﬁcant changes in their projects.\n\nFight this. Make sure everyone actively monitors the environment for changes. Maybe appoint a chief water tester. Have this person check constantly for increased scope, decreased time scales, additional fea- tures, new environments—anything that wasn’t in the original agree- ment. Keep metrics on new requirements (see page 209). The team needn’t reject changes out of hand—you simply need to be aware that they’re happening. Otherwise, it’ll be you in the hot water.\n\nCommunicate It’s obvious that developers in a team must talk to each other. We gave some suggestions to facilitate this in Communicate! on page 18. How- ever, it’s easy to forget that the team itself has a presence within the organization. The team as an entity needs to communicate clearly with the rest of the world.\n\nTo outsiders, the worst project teams are those that appear sullen and reticent. They hold meetings with no structure, where no one wants to talk. Their documents are a mess: no two look the same, and each uses different terminology.\n\nGreat project teams have a distinct personality. People look forward to meetings with them, because they know that they’ll see a well-prepared\n\n225",
      "content_length": 2044,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 251,
      "content": "226\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nperformance that makes everyone feel good. The documentation they produce is crisp, accurate, and consistent. The team speaks with one voice.1 They may even have a sense of humor.\n\nThere is a simple marketing trick that helps teams communicate as one: generate a brand. When you start a project, come up with a name for it, ideally something off-the-wall. (In the past, we’ve named projects after things such as killer parrots that prey on sheep, optical illusions, and mythical cities.) Spend 30 minutes coming up with a zany logo, and use it on your memos and reports. Use your team’s name liberally when talking with people. It sounds silly, but it gives your team an identity to build on, and the world something memorable to associate with your work.\n\nDon’t RepeatYourself In The Evils of Duplication, page 26, we talked about the difﬁculties of eliminating duplicated work between members of a team. This duplica- tion leads to wasted effort, and can result in a maintenance nightmare. Clearly good communication can help here, but sometimes something extra is needed.\n\nSome teams appoint a member as the project librarian, responsible for coordinating documentation and code repositories. Other team mem- bers can use this person as the ﬁrst port of call when they’re look- ing for something. A good librarian will also be able to spot impending duplication by reading the material that they’re handling.\n\nWhen the project’s too big for one librarian (or when no one wants to play the role), appoint people as focal points for various functional aspects of the work. If people want to talk over date handling, they should know to talk with Mary. If there’s a database schema issue, see Fred.\n\nAnd don’t forget the value of groupware systems and local Usenet news- groups for communicating and archiving questions and answers.\n\n1. robust debate. Good developers tend to be passionate about their work.\n\nThe team speaks with one voice—externally. Internally, we strongly encourage lively,",
      "content_length": 2028,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 252,
      "content": "PRAGMATIC TEAMS\n\nOrthogonality Traditional team organization is based on the old-fashioned waterfall method of software construction. Individuals are assigned roles based on their job function. You’ll ﬁnd business analysts, architects, design- ers, programmers, testers, documenters, and the like.2 There is an implicit hierarchy here—the closer to the user you’re allowed, the more senior you are.\n\nTaking things to the extreme, some development cultures dictate strict divisions of responsibility; coders aren’t allowed to talk to testers, who in turn aren’t allowed to talk to the chief architect, and so on. Some organizations then compound the problem by having different sub- teams report through separate management chains.\n\nIt is a mistake to think that the activities of a project—analysis, design, coding, and testing—can happen in isolation. They can’t. These are different views of the same problem, and artiﬁcially separating them can cause a boatload of trouble. Programmers who are two or three levels removed from the actual users of their code are unlikely to be aware of the context in which their work is used. They will not be able to make informed decisions.\n\nTIP 60\n\nOrganize Around Functionality, Not Job Functions\n\nWe favor splitting teams functionally. Divide your people into small teams, each responsible for a particular functional aspect of the ﬁnal system. Let the teams organize themselves internally, building on indi- vidual strengths as they can. Each team has responsibilities to others in the project, as deﬁned by their agreed-upon commitments. The exact set of commitments changes with each project, as does the allocation of people into teams.\n\nFunctionality here does not necessarily mean end-user use cases. The database access layer counts, as does the help subsystem. We’re look- ing for cohesive, largely self-contained teams of people—exactly the\n\n2. roles within a project team! [Kru98]\n\nIn The Rational Uniﬁed Process: An Introduction, the author identiﬁes 27 separate\n\n227",
      "content_length": 2020,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 253,
      "content": "228\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nsame criteria we should be using when we modularize code. There are warning signs that the team organization is wrong—a classic example is having two subteams working on the same program module or class.\n\nHow does this functional style of organization help? Organize our re- sources using the same techniques we use to organize code, using techniques such as contracts (Design by Contract, page 109), decou- pling (Decoupling and the Law of Demeter, page 138), and orthogonality (Orthogonality, page 34), and we help isolate the team as a whole from the effects of change. If the user suddenly decides to change database vendors, only the database team should be affected. Should marketing suddenly decide to use an off-the-shelf tool for the calendar function, the calendar group takes a hit. Properly executed, this kind of group approach can dramatically reduce the number of interactions between individuals’ work, reducing time scales, increasing quality, and cutting down on the number of defects. This approach can also lead to a more committed set of developers. Each team knows that they alone are re- sponsible for a particular function, so they feel more ownership of their output.\n\nHowever, this approach works only with responsible developers and strong project management. Creating a pool of autonomous teams and letting them loose without leadership is a recipe for disaster. The project needs at least two “heads”—one technical, the other administrative. The technical head sets the development philosophy and style, assigns responsibilities to teams, and arbitrates the inevitable “discussions” between people. The technical head also looks constantly at the big pic- ture, trying to ﬁnd any unnecessary commonality between teams that could reduce the orthogonality of the overall effort. The administrative head, or project manager, schedules the resources that the teams need, monitors and reports on progress, and helps decide priorities in terms of business needs. The administrative head might also act as the team’s ambassador when communicating with the outside world.\n\nTeams on larger projects need additional resources: a librarian who indexes and stores code and documentation, a tool builder who pro- vides common tools and environments, operational support, and so on.\n\nThis type of team organization is similar in spirit to the old chief pro- grammer team concept, ﬁrst documented in 1972 [Bak72].",
      "content_length": 2462,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 254,
      "content": "PRAGMATIC TEAMS\n\nAutomation A great way to ensure both consistency and accuracy is to automate everything the team does. Why lay code out manually when your editor can do it automatically as you type? Why complete test forms when the overnight build can run tests automatically?\n\nAutomation is an essential component of every project team—important enough for us to dedicate an entire section to it, starting on the follow- ing page. To ensure that things get automated, appoint one or more team members as tool builders to construct and deploy the tools that automate the project drudgery. Have them produce makeﬁles, shell scripts, editor templates, utility programs, and the like.\n\nKnowWhentoStopAdding Paint Remember that teams are made up of individuals. Give each member the ability to shine in his or her own way. Give them just enough struc- ture to support them and to ensure that the project delivers against its requirements. Then, like the painter in Good-Enough Software, page 11, resist the temptation to add more paint.\n\nRelated sections include:\n\nSoftware Entropy, page 4 Stone Soup and Boiled Frogs, page 7 Good-Enough Software, page 9 Communicate!, page 18 The Evils of Duplication, page 26 Orthogonality, page 34 Design by Contract, page 109 Decoupling and the Law of Demeter, page 138 Ubiquitous Automation, page 230\n\nChallenges\n\nLook around for successful teams outside the area of software develop- ment. What makes them successful? Do they use any of the processes discussed in this section?\n\n229",
      "content_length": 1519,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 255,
      "content": "230\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nNext time you start a project, try convincing people to brand it. Give your organization time to become used to the idea, and then do a quick audit to see what difference it made, both within the team and externally.\n\nTeam Algebra: In school, we are given problems such as “If it takes 4 work- ers 6 hours to dig a ditch, how long would it take 8 workers?” In real life, however, what factors affect the answer to: “If it takes 4 programmers 6 months to develop an application, how long would it take 8 programmers?” In how many scenarios is the time actually reduced?\n\n42 Ubiquitous Automation\n\nCivilization advances by extending the number of important operations we can perform without thinking.\n\nAlfred North Whitehead\n\nAt the dawn of the age of automobiles, the instructions for starting a Model-T Ford were more than two pages long. With modern cars, you just turn the key—the starting procedure is automatic and foolproof. A person following a list of instructions might ﬂood the engine, but the automatic starter won’t.\n\nAlthough computing is still an industry at the Model-T stage, we can’t afford to go through two pages of instructions again and again for some common operation. Whether it is the build and release procedure, code review paperwork, or any other recurring task on the project, it has to be automatic. We may have to build the starter and fuel injector from scratch, but once it’s done, we can just turn the key from then on.\n\nIn addition, we want to ensure consistency and repeatability on the project. Manual procedures leave consistency up to chance; repeatabil- ity isn’t guaranteed, especially if aspects of the procedure are open to interpretation by different people.",
      "content_length": 1735,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 256,
      "content": "UBIQUITOUS AUTOMATION\n\nAllon Automatic We were once at a client site where all the developers were using the same IDE. Their system administrator gave each developer a set of instructions on installing add-on packages to the IDE. These instruc- tions ﬁlled many pages—pages full of click here, scroll there, drag this, double-click that, and do it again.\n\nNot surprisingly, every developer’s machine was loaded slightly differ- ently. Subtle differences in the application’s behavior occurred when different developers ran the same code. Bugs would appear on one machine but not on others. Tracking down version differences of any one component usually revealed a surprise.\n\nTIP 61\n\nDon’t Use Manual Procedures\n\nPeople just aren’t as repeatable as computers are. Nor should we expect them to be. A shell script or batch ﬁle will execute the same instruc- tions, in the same order, time after time. It can be put under source control, so you can examine changes to the procedure over time as well (“but it used to work. .. ”).\n\nAnother favorite tool of automation is cron (or “at” on Windows NT). It allows us to schedule unattended tasks to run periodically—usually in the middle of the night. For example, the following crontab ﬁle speci- ﬁes that a project’s nightly command be run at ﬁve minutes past mid- night every day, that the backup be run at 3:15 a.m. on weekdays, and that expense_reports be run at midnight on the ﬁrst of the month.\n\n# MIN HOUR DAY MONTH DAYOFWEEK # ---------------------------------------------------------------\n\nCOMMAND\n\n5 15 0\n\n0 3 0\n\n* 1\n\n* *\n\n1-5 *\n\n/projects/Manhattan/bin/nightly /usr/local/bin/backup /home/accounting/expense_reports\n\nUsing cron, we can schedule backups, the nightly build, Web site main- tenance, and anything else that needs to be done—unattended, auto- matically.\n\n231",
      "content_length": 1826,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 257,
      "content": "232\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nCompiling theProject Compiling the project is a chore that should be reliable and repeat- able. We generally compile projects with makeﬁles, even when using an IDE environment. There are several advantages in using makeﬁles. It is a scripted, automatic procedure. We can add in hooks to generate code for us, and run regression tests automatically. IDEs have their advantages, but with IDEs alone it can be hard to achieve the level of automation that we’re looking for. We want to check out, build, test, and ship with a single command.\n\nGenerating Code In The Evils of Duplication, page 26, we advocated generating code to derive knowledge from common sources. We can exploit make’s depen- dency analysis mechanism to make this process easy. It’s a pretty sim- ple matter to add rules to a makeﬁle to generate a ﬁle from some other source automatically. For example, suppose we wanted to take an XML ﬁle, generate a Java ﬁle from it, and compile the result.\n\n.SUFFIXES: .java .class .xml\n\n.xml.java:\n\nperl convert.pl $< > $@\n\n.java.class:\n\n$(JAVAC) $(JAVAC_FLAGS) $<\n\nType make test.class, and make will automatically look for a ﬁle named test.xml, build a .java ﬁle by running a Perl script, and then compile that ﬁle to produce test.class.\n\nWe can use the same sort of rules to generate source code, header ﬁles, or documentation automatically from some other form as well (see Code Generators, page 102).\n\nRegressionTests You can also use the makeﬁle to run regression tests for you, either for an individual module or for an entire subsystem. You can easily test the entire project with just one command at the top of the source tree, or you can test an individual module by using the same command in a single directory. See Ruthless Testing, page 237, for more on regression testing.",
      "content_length": 1825,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 258,
      "content": "UBIQUITOUS AUTOMATION\n\nRecursive make\n\nMany projects set up recursive, hierarchical makeﬁles for project builds and testing. But be aware of some potential problems.\n\nmake calculates dependencies between the various targets it has to build. But it can analyze only the dependencies that exist within one single make invocation. In particular, a recursive make has no knowl- edge of dependencies that other invocations of make may have. If you are careful and precise, you can get the proper results, but it’s easy to cause extra work unnecessarily—or miss a dependency and not recompile when it’s needed.\n\nIn addition, build dependencies may not be the same as test depen- dencies, and you may need separate hierarchies.\n\nBuildAutomation A build is a procedure that takes an empty directory (and a known com- pilation environment) and builds the project from scratch, producing whatever you hope to produce as a ﬁnal deliverable—a CD-ROM mas- ter image or a self-extracting archive, for instance. Typically a project build will encompass the following steps.\n\n1. Check out the source code from the repository.\n\n2. Build the project from scratch, typically from a top-level makeﬁle. Each build is marked with some form of release or version number, or perhaps a date stamp.\n\n3. Create a distributable image. This procedure may entail ﬁxing ﬁle ownership and permissions, and producing all examples, docu- mentation, README ﬁles, and anything else that will ship with the product, in the exact format that will be required when you ship.3\n\n4. Run speciﬁed tests ( make test).\n\n3. If you are producing a CD-ROM in ISO9660 format, for example, you would run the program that produces a bit-for-bit image of the 9660 ﬁle system. Why wait until the night before you ship to make sure it works?\n\n233",
      "content_length": 1792,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 259,
      "content": "234\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nFor most projects, this level of build is run automatically every night. In this nightly build, you will typically run more complete tests than an individual might run while building some speciﬁc portion of the project. The important point is to have the full build run all available tests. You want to know if a regression test failed because of one of today’s code changes. By identifying the problem close to the source, you stand a better chance of ﬁnding and ﬁxing it.\n\nWhen you don’t run tests regularly, you may discover that the appli- cation broke due to a code change made three months ago. Good luck ﬁnding that one.\n\nFinal Builds Final builds, which you intend to ship as products, may have different requirements from the regular nightly build. A ﬁnal build may require that the repository be locked, or tagged with the release number, that optimization and debug ﬂags be set differently, and so on. We like to use a separate make target (such as make final) that sets all of these parameters at once.\n\nRemember that if the product is compiled differently from earlier ver- sions, then you must test against this version all over again.\n\nAutomatic Administrivia Wouldn’t it be nice if programmers could actually devote all of their time to programming? Unfortunately, this is rarely the case. There is e-mail to be answered, paperwork to be ﬁlled out, documents to be posted to the Web, and so on. You may decide to create a shell script to do some of the dirty work, but you still have to remember to run the script when needed.\n\nBecause memory is the second thing you lose as you age,4 we don’t want to rely on it too heavily. We can run scripts to perform proce- dures for us automatically, based on the content of source code and documents. Our goal is to maintain an automatic, unattended, content- driven workﬂow.\n\n4. What’s the ﬁrst? I forget.",
      "content_length": 1898,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 260,
      "content": "UBIQUITOUS AUTOMATION\n\nWebSite Generation Many development teams use an internal Web site for project commu- nication, and we think this is a great idea. But we don’t want to spend too much time maintaining the Web site, and we don’t want to let it get stale or out of date. Misleading information is worse than no informa- tion at all.\n\nDocumentation that is extracted from code, requirements analyses, design documents, and any drawings, charts, or graphs all need to be published to the Web on a regular basis. We like to publish these documents automatically as part of the nightly build or as a hook into the source code check-in procedure.\n\nHowever it is done, Web content should be generated automatically from information in the repository and published without human inter- vention. This is really another application of the DRY principle: infor- mation exists in one form as checked-in code and documents. The view from the Web browser is simply that—just a view. You shouldn’t have to maintain that view by hand.\n\nAny information generated by the nightly build should be accessible on the development Web site: results of the build itself (for example, the build results might be presented as a one-page summary that includes compiler warnings, errors, and current status), regression tests, per- formance statistics, coding metrics and any other static analysis, and so on.\n\nApprovalProcedures Some projects have various administrative workﬂows that must be fol- lowed. For instance, code or design reviews need to be scheduled and followed through, approvals may need to be granted, and so on. We can use automation—and especially the Web site—to help ease the paper- work burden.\n\nSuppose you wanted to automate code review scheduling and approval. You might put a special marker in each source code ﬁle:\n\n/* Status: needs_review */\n\nA simple script could go through all of the source code and look for all ﬁles that had a status of needs_review, indicating that they were ready to be reviewed. You could then post a list of those ﬁles as a\n\n235",
      "content_length": 2059,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 261,
      "content": "236\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nWeb page, automatically send e-mail to the appropriate people, or even schedule a meeting automatically using some calendar software.\n\nYou can set up a form on a Web page for the reviewers to register approval or disapproval. After the review, the status can be automat- ically changed to reviewed. Whether you have a code walk-through with all the participants is up to you; you can still do the paperwork automatically. (In an article in the April 1999 CACM, Robert Glass sum- marizes research that seems to indicate that, while code inspection is effective, conducting reviews in meetings is not [Gla99a].)\n\nThe Cobbler’s Children The cobbler’s children have no shoes. Often, people who develop soft- ware use the poorest tools to do the job.\n\nBut we have all the raw materials we need to craft better tools. We have cron. We have make, Ant, and CruiseControl for automation (see [Cla04]). And we have Ruby, Perl, and other high-level scripting lan- guages for quickly developing custom tools, Web page generators, code generators, test harnesses, and so on.\n\nLet the computer do the repetitious, the mundane—it will do a better job of it than we would. We’ve got more important and more difﬁcult things to do.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 The Evils of Duplication, page 26 The Power of Plain Text, page 73 Shell Games, page 77 Debugging, page 90 Code Generators, page 102 Pragmatic Teams, page 224 Ruthless Testing, page 237 It’s All Writing, page 248\n\nChallenges\n\nLook at your habits throughout the workday. Do you see any repetitive tasks? Do you type the same sequence of commands over and over again?",
      "content_length": 1677,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 262,
      "content": "RUTHLESS TESTING\n\nTry writing a few shell scripts to automate the process. Do you always click on the same sequence of icons repeatedly? Can you create a macro to do all that for you?\n\nHow much of your project paperwork can be automated? Given the high expense of programming staff,5 determine how much of the project’s bud- get is being wasted on administrative procedures. Can you justify the amount of time it would take to craft an automated solution based on the overall cost savings it would achieve?\n\n43 Ruthless Testing\n\nMost developers hate testing. They tend to test gently, subconsciously knowing where the code will break and avoiding the weak spots. Prag- matic Programmers are different. We are driven to ﬁnd our bugs now, so we don’t have to endure the shame of others ﬁnding our bugs later.\n\nFinding bugs is somewhat like ﬁshing with a net. We use ﬁne, small nets (unit tests) to catch the minnows, and big, coarse nets (integration tests) to catch the killer sharks. Sometimes the ﬁsh manage to escape, so we patch any holes that we ﬁnd, in hopes of catching more and more slippery defects that are swimming about in our project pool.\n\nTIP 62\n\nTest Early. Test Often. Test Automatically.\n\nWe want to start testing as soon as we have code. Those tiny minnows have a nasty habit of becoming giant, man-eating sharks pretty fast, and catching a shark is quite a bit harder. But we don’t want to have to do all that testing by hand.\n\n5. per head—that’s salary plus beneﬁts, training, ofﬁce space and overhead, and so on.\n\nFor estimating purposes, you can ﬁgure an industry average of about US$100,000\n\n237",
      "content_length": 1618,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 263,
      "content": "238\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nMany teams develop elaborate test plans for their projects. Sometimes they will even use them. But we’ve found that teams that use auto- mated tests have a much better chance of success. Tests that run with every build are much more effective than test plans that sit on a shelf.\n\nThe earlier a bug is found, the cheaper it is to remedy. “Code a little, test a little” is a popular saying in the Smalltalk world,6 and we can adopt that mantra as our own by writing test code at the same time (or even before) we write the production code.\n\nIn fact, a good project may well have more test code than production code. The time it takes to produce this test code is worth the effort. It ends up being much cheaper in the long run, and you actually stand a chance of producing a product with close to zero defects.\n\nAdditionally, knowing that you’ve passed the test gives you a high de- gree of conﬁdence that a piece of code is “done.”\n\nTIP 63\n\nCoding Ain’t Done ’Til All the Tests Run\n\nJust because you have ﬁnished hacking out a piece of code doesn’t mean you can go tell your boss or your client that it’s done. It’s not. First of all, code is never really done. More importantly, you can’t claim that it is usable by anyone until it passes all of the available tests.\n\nWe need to look at three main aspects of project-wide testing: what to test, how to test, and when to test.\n\nWhat toTest There are several major types of software testing that you need to per- form:\n\nUnit testing\n\nIntegration testing\n\nValidation and veriﬁcation\n\n6. less testing.”\n\neXtreme Programming [URL 45] calls this concept “continuous integration, relent-",
      "content_length": 1666,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 264,
      "content": "RUTHLESS TESTING\n\nResource exhaustion, errors, and recovery\n\nPerformance testing\n\nUsability testing\n\nThis list is by no means complete, and some specialized projects will require various other types of testing as well. But it gives us a good starting point.\n\nUnit Testing A unit test is code that exercises a module. We covered this topic by itself in Code That’s Easy to Test, page 189. Unit testing is the founda- tion of all the other forms of testing that we’ll discuss in this section. If the parts don’t work by themselves, they probably won’t work well together. All of the modules you are using must pass their own unit tests before you can proceed.\n\nOnce all of the pertinent modules have passed their individual tests, you’re ready for the next stage. You need to test how all the modules use and interact with each other throughout the system.\n\nIntegrationTesting Integration testing shows that the major subsystems that make up the project work and play well with each other. With good contracts in place and well tested, any integration issues can be detected easily. Other- wise, integration becomes a fertile breeding ground for bugs. In fact, it is often the single largest source of bugs in the system.\n\nIntegration testing is really just an extension of the unit testing we’ve described—only now you’re testing how entire subsystems honor their contracts.\n\nValidationand Veriﬁcation As soon as you have an executable user interface or prototype, you need to answer an all-important question: the users told you what they wanted, but is it what they need?\n\nDoes it meet the functional requirements of the system? This, too, needs to be tested. A bug-free system that answers the wrong ques- tion isn’t very useful. Be conscious of end-user access patterns and\n\n239",
      "content_length": 1781,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 265,
      "content": "240\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nhow they differ from developer test data (for an example, see the story about brush strokes on page 92).\n\nResource Exhaustion,Errors,and Recovery\n\nNow that you have a pretty good idea that the system will behave cor- rectly under ideal conditions, you need to discover how it will behave under real-world conditions. In the real world, your programs don’t have limitless resources; they run out of things. A few limits your code may encounter include:\n\nMemory\n\nDisk space\n\nCPU bandwidth\n\nWall-clock time\n\nDisk bandwidth\n\nNetwork bandwidth\n\nColor palette\n\nVideo resolution\n\nYou might actually check for disk space or memory allocation failures, but how often do you test for the others? Will your application ﬁt on screen colors? Will it run on a a with -bit color without looking like a postage stamp? Will the batch job ﬁnish before the archive starts?\n\nscreen with\n\nYou can detect environmental limitations, such as the video speci- ﬁcations, and adapt as appropriate. Not all failures are recoverable, however. If your code detects that memory has been exhausted, your options are limited: you may not have enough resources left to do any- thing except fail.\n\nWhen the system does fail,7 will it fail gracefully? Will it try, as best it can, to save its state and prevent loss of work? Or will it “GPF” or “core-dump” in the user’s face?\n\n7. Our copy editor wanted us to change this sentence to “If the system does fail We resisted. .”",
      "content_length": 1473,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 266,
      "content": "RUTHLESS TESTING\n\nPerformanceTesting Performance testing, stress testing, or testing under load may be an important aspect of the project as well.\n\nAsk yourself if the software meets the performance requirements under real-world conditions—with the expected number of users, or connec- tions, or transactions per second. Is it scalable?\n\nFor some applications, you may need specialized testing hardware or software to simulate the load realistically.\n\nUsabilityTesting Usability testing is different from the types of testing discussed so far. It is performed with real users, under real environmental conditions.\n\nLook at usability in terms of human factors. Were there any misun- derstandings during requirements analysis that need to be addressed? Does the software ﬁt the user like an extension of the hand? (Not only do we want our own tools to ﬁt our hands, but we want the tools we create for users to ﬁt their hands as well.)\n\nAs with validation and veriﬁcation, you need to perform usability test- ing as early as you can, while there is still time to make corrections. For larger projects, you may want to bring in human factors specialists. (If nothing else, it’s fun to play with the one-way mirrors).\n\nFailure to meet usability criteria is just as big a bug as dividing by zero.\n\nHowtoTest We’ve looked at what to test. Now we’ll turn our attention to how to test, including:\n\nRegression testing\n\nTest data\n\nExercising GUI systems\n\nTesting the tests\n\nTesting thoroughly\n\n241",
      "content_length": 1487,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 267,
      "content": "242\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nDesign/Methodology Testing\n\nCan you test the design of the code itself and the methodology you used to build the software? After a fashion, yes you can. You do this by analyzing metrics—measurements of various aspects of the code. The simplest metric (and often the least interesting) is linesofcode— how big is the code itself?\n\nThere are a wide variety of other metrics you can use to examine code, including:\n\nMcCabe Cyclomatic Complexity Metric (measures complexity of decision structures) Inheritance fan-in (number of base classes) and fan-out (number of derived modules using this one as a parent) Response set (see DecouplingandtheLawofDemeter, page 138) Class coupling ratios (see [URL 48])\n\nSome metrics are designed to give you a “passing grade,” while oth- ers are useful only by comparison. That is, you calculate these met- rics for every module in the system and see how a particular module relates to its brethren. Standard statistical techniques (such as mean and standard deviation) are usually used here.\n\nIf you ﬁnd a module whose metrics are markedly different from all the rest, you need to ask yourself if that is appropriate. For some modules, it may be okay to “blow the curve.” But for those that don’t have a good excuse, it can indicate potential problems.\n\nRegressionTesting A regression test compares the output of the current test with previous (or known) values. We can ensure that bugs we ﬁxed today didn’t break things that were working yesterday. This is an important safety net, and it cuts down on unpleasant surprises.\n\nAll of the tests we’ve mentioned so far can be run as regression tests, ensuring that we haven’t lost any ground as we develop new code. We can run regressions to verify performance, contracts, validity, and so on.",
      "content_length": 1807,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 268,
      "content": "RUTHLESS TESTING\n\nTestData Where do we get the data to run all these tests? There are only two kinds of data: real-world data and synthetic data. We actually need to use both, because the different natures of these kinds of data will expose different bugs in our software.\n\nReal-world data comes from some actual source. Possibly it has been collected from an existing system, a competitor’s system, or a prototype of some sort. It represents typical user data. The big surprises come as you discover what typical means. This is most likely to reveal defects and misunderstandings in requirements analysis.\n\nSynthetic data is artiﬁcially generated, perhaps under certain statistical constraints. You may need to use synthetic data for any of the following reasons.\n\nYou need a lot of data, possibly more than any real-world sample could provide. You might be able to use the real-world data as a seed to generate a larger sample set, and tweak certain ﬁelds that need to be unique.\n\nYou need data to stress the boundary conditions. This data may be completely synthetic: date ﬁelds containing February 29, 1999, huge record sizes, or addresses with foreign postal codes.\n\nYou need data that exhibits certain statistical properties. Want to see what happens if every third transaction fails? Remember the sort algorithm that slows to a crawl when handed presorted data? You can present data in random or sorted order to expose this kind of weakness.\n\nExercisingGUISystems Testing GUI-intensive systems often requires specialized testing tools. These tools may be based on a simple event capture/playback model, or they may require specially written scripts to drive the GUI. Some systems combine elements of both.\n\nLess sophisticated tools enforce a high degree of coupling between the version of software being tested and the test script itself: if you move a dialog box or make a button smaller, the test may not be able to\n\n243",
      "content_length": 1929,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 269,
      "content": "244\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nﬁnd it, and may fail. Most modern GUI testing tools use a number of different techniques to get around this problem, and try to adjust to minor layout differences.\n\nHowever, you can’t automate everything. Andy worked on a graphics system that allowed the user to create and display nondeterministic visual effects which simulated various natural phenomena. Unfortu- nately, during testing you couldn’t just grab a bitmap and compare the output with a previous run, because it was designed to be different every time. For situations such as this one, you may have no choice but to rely on manual interpretation of test results.\n\nOne of the many advantages of writing decoupled code (see Decou- pling and the Law of Demeter, page 138) is more modular testing. For instance, for data processing applications that have a GUI front end, your design should be decoupled enough so that you can test the ap- plication logic without having a GUI present. This idea is similar to testing your subcomponents ﬁrst. Once the application logic has been validated, it becomes easier to locate bugs that show up with the user interface in place (it’s likely that the bugs were created by the user- interface code).\n\nTestingtheTests Because we can’t write perfect software, it follows that we can’t write perfect test software either. We need to test the tests.\n\nThink of our set of test suites as an elaborate security system, designed to sound the alarm when a bug shows up. How better to test a security system than to try to break in?\n\nAfter you have written a test to detect a particular bug, cause the bug deliberately and make sure the test complains. This ensures that the test will catch the bug if it happens for real.\n\nTIP 64\n\nUse Saboteurs to Test Your Testing\n\nIf you are really serious about testing, you might want to appoint a project saboteur. The saboteur’s role is to take a separate copy of the",
      "content_length": 1932,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 270,
      "content": "RUTHLESS TESTING\n\nsource tree, introduce bugs on purpose, and verify that the tests will catch them.\n\nWhen writing tests, make sure that alarms sound when they should.\n\nTestingThoroughly Once you are conﬁdent that your tests are correct, and are ﬁnding bugs you create, how do you know if you have tested the code base thoroughly enough?\n\nThe short answer is “you don’t,” and you never will. But there are prod- ucts on the market that can help. These coverage analysis tools watch your code during testing and keep track of which lines of code have been executed and which haven’t. These tools help give you a general feel for how comprehensive your testing is, but don’t expect to see 100% coverage.\n\nEven if you do happen to hit every line of code, that’s not the whole picture. What is important is the number of states that your program may have. States are not equivalent to lines of code. For instance, sup- pose you have a function that takes two integers, each of which can be a number from 0 to 999.\n\nint test(int a, int b) { return a / (a + b);\n\n}\n\nIn theory, this three-line function has 1,000,000 logical states, 999,999 of which will work correctly and one that will not (when a + b equals zero). Simply knowing that you executed this line of code doesn’t tell you that—you would need to identify all possible states of the program. Unfortunately, in general this is a really hard problem. Hard as in, “The sun will be a cold hard lump before you can solve it.”\n\nTIP 65\n\nTest State Coverage, Not Code Coverage\n\nEven with good code coverage, the data you use for testing still has a huge impact, and, more importantly, the order in which you traverse code may have the largest impact of all.\n\n245",
      "content_length": 1709,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 271,
      "content": "246\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nWhentoTest Many projects tend to leave testing to the last minute—right where it will be cut against the sharp edge of a deadline.8 We need to start much sooner than that. As soon as any production code exists, it needs to be tested.\n\nMost testing should be done automatically. It’s important to note that by “automatically” we mean that the test results are interpreted auto- matically as well. See Ubiquitous Automation, page 230, for more on this subject.\n\nWe like to test as frequently as we can, and always before we check code into the source repository. Some source code control systems, such as Aegis, can do this automatically. Otherwise, we just type\n\n% make test\n\nUsually, it isn’t a problem to run regressions on all of the individual unit tests and integration tests as often as needed.\n\nBut some tests may not be easily run on a such a frequent basis. Stress tests, for instance, may require special setup or equipment, and some hand holding. These tests may be run less often—weekly or monthly, perhaps. But it is important that they be run on a regular, scheduled basis. If it can’t be done automatically, then make sure it appears on the schedule, with all the necessary resources allocated to the task.\n\nTightening theNet Finally, we’d like to reveal the single most important concept in testing. It is an obvious one, and virtually every textbook says to do it this way. But for some reason, most projects still do not.\n\nIf a bug slips through the net of existing tests, you need to add a new test to trap it next time.\n\n8. passes at the risk of being shot—Webster’s Collegiate Dictionary.\n\ndead line ded-l¯ın n (1864) a line drawn within or around a prison that a prisoner",
      "content_length": 1727,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 272,
      "content": "RUTHLESS TESTING\n\nTIP 66\n\nFind Bugs Once\n\nOnce a human tester ﬁnds a bug, it should be the last time a human tester ﬁnds that bug. The automated tests should be modiﬁed to check for that particular bug from then on, every time, with no exceptions, no matter how trivial, and no matter how much the developer complains and says, “Oh, that will never happen again.”\n\nBecause it will happen again. And we just don’t have the time to go chasing after bugs that the automated tests could have found for us. We have to spend our time writing new code—and new bugs.\n\nRelated sections include:\n\nThe Cat Ate My Source Code, page 2 Debugging, page 90 Decoupling and the Law of Demeter, page 138 Refactoring, page 184 Code That’s Easy to Test, page 189 Ubiquitous Automation, page 230\n\nChallenges\n\nCan you automatically test your project? Many teams are forced to answer “no.” Why? Is it too hard to deﬁne the acceptable results? Won’t this make it hard to prove to the sponsors that the project is “done”?\n\nIs it too hard to test the application logic independent of the GUI? What does this say about the GUI? About coupling?\n\n247",
      "content_length": 1120,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 273,
      "content": "44\n\n248\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nIt’s All Writing\n\nThe palest ink is better than the best memory.\n\nChinese Proverb\n\nTypically, developers don’t give much thought to documentation. At best it is an unfortunate necessity; at worst it is treated as a low-priority task in the hope that management will forget about it at the end of the project.\n\nPragmatic Programmers embrace documentation as an integral part of the overall development process. Writing documentation can be made easier by not duplicating effort or wasting time, and by keeping docu- mentation close at hand—in the code itself, if possible.\n\nThese aren’t exactly original or novel thoughts; the idea of wedding code and documentation appears in Donald Knuth’s work on literate programming and in Sun’s JavaDoc utility, among others. We want to downplay the dichotomy between code and documentation, and instead treat them as two views of the same model (see It’s Just a View, page 157). In fact, we want to go a little further and apply all of our pragmatic principles to documentation as well as to code.\n\nTIP 67\n\nTreat English as Just Another Programming Language\n\nThere are basically two kinds of documentation produced for a project: internal and external. Internal documentation includes source code comments, design and test documents, and so on. External documen- tation is anything shipped or published to the outside world, such as user manuals. But regardless of the intended audience, or the role of the writer (developer or technical writer), all documentation is a mir- ror of the code. If there’s a discrepancy, the code is what matters—for better or worse.\n\nTIP 68\n\nBuild Documentation In, Don’t Bolt It On\n\nWe’ll start with internal documentation.",
      "content_length": 1733,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 274,
      "content": "IT’S ALL WRITING\n\nComments inCode Producing formatted documents from the comments and declarations in source code is fairly straightforward, but ﬁrst we have to ensure that we actually have comments in the code. Code should have comments, but too many comments can be just as bad as too few.\n\nIn general, comments should discuss why something is done, its pur- pose and its goal. The code already shows how it is done, so comment- ing on this is redundant—and is a violation of the DRY principle.\n\nCommenting source code gives you the perfect opportunity to docu- ment those elusive bits of a project that can’t be documented anywhere else: engineering trade-offs, why decisions were made, what other alter- natives were discarded, and so on.\n\nWe like to see a simple module-level header comment, comments for signiﬁcant data and type declarations, and a brief per-class and per- method header, describing how the function is used and anything that it does that is not obvious.\n\nVariable names, of course, should be well chosen and meaningful. foo, for instance, is meaningless, as is doit or manager or stuff. Hun- garian notation (where you encode the variable’s type information in the name itself) is utterly inappropriate in object-oriented systems. Remember that you (and others after you) will be reading the code many hundreds of times, but only writing it a few times. Take the time to spell out connectionPool instead of cp.\n\nEven worse than meaningless names are misleading names. Have you ever had someone explain inconsistencies in legacy code such as, “The routine called getData really writes data to disk”? The human brain will repeatedly foul this up—it’s called the Stroop Effect [Str35]. You can try the following experiment yourself to see the effects of such in- terference. Get some colored pens, and use them to write down the names of colors. However, never write a color name using that color pen. You could write the word “blue” in green, the word “brown” in red, and so on. (Alternatively, we have a sample set of colors already drawn on our Web site at www.pragmaticprogrammer.com.) Once you have the color names drawn, try to say aloud the color with which each word is drawn, as fast as you can. At some point you’ll trip up and start read- ing the names of the colors, and not the colors themselves. Names are\n\n249",
      "content_length": 2345,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 275,
      "content": "250\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\ndeeply meaningful to your brain, and misleading names add chaos to your code.\n\nYou can document parameters, but ask yourself if it is really necessary in all cases. The level of comment suggested by the JavaDoc tool seems appropriate:\n\n/**\n\nFind the peak (highest) value within a specified date * range of samples. * * @param aRange Range of dates to search for data. * @param aThreshold Minimum value to consider. * @return the value, or <code>null</code> if no value found * greater than or equal to the threshold. */ public Sample findPeak(DateRange aRange, double aThreshold);\n\nHere’s a list of things that should not appear in source comments.\n\nA list of the functions exported by code in the ﬁle. There are pro- grams that analyze source for you. Use them, and the list is guar- anteed to be up to date.\n\nRevision history. This is what source code control systems are for (see Source Code Control, page 86). However, it can be useful to include information on the date of last change and the person who made it.9\n\nA list of other ﬁles this ﬁle uses. This can be determined more accurately using automatic tools.\n\nIf it must appear in the ﬁle, don’t maintain it The name of the ﬁle. by hand. RCS and similar systems can keep this information up to date automatically. If you move or rename the ﬁle, you don’t want to have to remember to edit the header.\n\nOne of the most important pieces of information that should appear in the source ﬁle is the author’s name—not necessarily who edited the ﬁle last, but the owner. Attaching responsibility and accountabil- ity to source code does wonders in keeping people honest (see Pride and Prejudice, page 258).\n\n9.\n\nThis kind of information, as well as the ﬁlename, is provided by the RCS $Id$ tag.",
      "content_length": 1780,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 276,
      "content": "IT’S ALL WRITING\n\nThe project may also require certain copyright notices or other legal boilerplate to appear in each source ﬁle. Get your editor to insert these for you automatically.\n\nWith meaningful comments in place, tools such as JavaDoc [URL 7] and DOC++ [URL 21] can extract and format them to automatically produce API-level documentation. This is one speciﬁc example of a more general technique we use—executable documents.\n\nExecutableDocuments Suppose we have a speciﬁcation that lists the columns in a database table. We’ll then have a separate set of SQL commands to create the actual table in the database, and probably some kind of programming language record structure to hold the contents of a row in the table. The same information is repeated three times. Change any one of these three sources, and the other two are immediately out of date. This is a clear violation of the DRY principle.\n\nTo correct this problem, we need to choose the authoritative source of information. This may be the speciﬁcation, it may be a database schema tool, or it may be some third source altogether. Let’s choose the speciﬁcation document as the source. It’s now our model for this process. We then need to ﬁnd a way to export the information it con- tains as different views—a database schema and a high-level language record, for example.10\n\nIf your document is stored as plain text with markup commands (using HTML, LATEX, or troff, for example), then you can use tools such as Perl to extract the schema and reformat it automatically. If your document is in a word processor’s binary format, then see the box on the following page for some options.\n\nYour document is now an integral part of the project development. The only way to change the schema is to change the document. You are guaranteeing that the speciﬁcation, schema, and code all agree. You minimize the amount of work you have to do for each change, and you can update the views of the change automatically.\n\n10. See It’s Just a View, page 157, for more on models and views.\n\n251",
      "content_length": 2046,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 277,
      "content": "252\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nWhat if My Document Isn’t Plain Text?\n\nUnfortunately, more and more project documents are now being writ- ten using word processors that store the ﬁle on disk in some propri- etary format. We say “unfortunately” because this severely restricts your options to process the document automatically. However, you still have a couple of options:\n\nWrite macros. Most sophisticated word processors now have a macro language. With some effort you can program them to export tagged sections of your documents into the alternative forms you need. If programming at this level is too painful, you could always export the appropriate section into a standard for- mat plain text ﬁle, and then use a tool such as Perl to convert this into the ﬁnal forms.\n\nMake thedocument subordinate. Rather than have the doc- ument as the deﬁnitive source, use another representation. (In the database example, you might want to use the schema as the authoritative information.) Then write a tool that exports this in- formation into a form that the document can import. Be careful, however. You need to ensure that this information is imported ev- ery time the document is printed, rather than just once when the document is created.\n\nWe can generate API-level documentation from source code using tools such as JavaDoc and DOC++ in a similar fashion. The model is the source code: one view of the model can be compiled; other views are meant to be printed out or viewed on the Web. Our goal is always to work on the model—whether the model is the code itself or some other document—and have all views updated automatically (see Ubiquitous Automation, page 230, for more on automatic processes).\n\nSuddenly, documentation isn’t so bad.\n\nTechnical Writers Up until now, we’ve talked only about internal documentation—written by the programmers themselves. But what happens when you have professional technical writers involved in the project? All too often, pro- grammers just throw material “over the wall” to technical writers and",
      "content_length": 2038,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 278,
      "content": "IT’S ALL WRITING\n\nlet them fend for themselves to produce user manuals, promotional pieces, and so on.\n\nThis is a mistake. Just because programmers aren’t writing these docu- ments doesn’t mean that we can forsake pragmatic principles. We want the writers to embrace the same basic principles that a Pragmatic Pro- grammer does—especially honoring the DRY principle, orthogonality, the model-view concept, and the use of automation and scripting.\n\nPrint Itor WeaveIt One problem inherent with published, paper documentation is that it can become out of date as soon as it’s printed. Documentation of any form is just a snapshot.\n\nSo we try to produce all documentation in a form that can be published online, on the Web, complete with hyperlinks. It’s easier to keep this view of the documentation up to date than to track down every existing paper copy, burn it, and reprint and redistribute new copies. It’s also a better way to address the needs of a wide audience. Remember, though, to put a date stamp or version number on each Web page. This way the reader can get a good idea of what’s up to date, what’s changed recently, and what hasn’t.\n\nMany times you need to present the same documentation in different formats: a printed document, Web pages, online help, or perhaps a slide show. The typical solution relies heavily on cut-and-paste, creating a number of new independent documents from the original. This is a bad idea: a document’s presentation should be independent of its content.\n\nIf you are using a markup system, you have the ﬂexibility to implement as many different output formats as you need. You can choose to have\n\n<H1>Chapter Title</H1>\n\ngenerate a new chapter in the report version of the document and title a new slide in the slide show. Technologies such as XSL and CSS11 can be used to generate multiple output formats from this one markup.\n\n11. eXtensible Style Language and Cascading Style Sheets, two technologies designed to help separate presentation from content.\n\n253",
      "content_length": 2003,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 279,
      "content": "254\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nIf you are using a word processor, you’ll probably have similar capa- bilities. If you remembered to use styles to identify different document elements, then by applying different style sheets you can drastically alter the look of the ﬁnal output. Most word processors now allow you to convert your document to formats such as HTML for Web publishing.\n\nMarkup Languages Finally, for large-scale documentation projects, we recommend looking at some of the more modern schemes for marking up documentation.\n\nMany technical authors now use DocBook to deﬁne their documents. DocBook is an SGML-based markup standard that carefully identiﬁes every component in a document. The document can be passed through a DSSSL processor to render it into any number of different formats. The Linux documentation project uses DocBook to publish information in RTF, TEX, info, PostScript, and HTML formats.\n\nAs long as your original markup is rich enough to express all the con- cepts you need (including hyperlinks), translation to any other pub- lishable form can be both easy and automatic. You can produce online help, published manuals, product highlights for the Web site, and even a tip-a-day calendar, all from the same source—which of course is under source control and is built along with the nightly build (see Ubiq- uitous Automation, page 230).\n\nDocumentation and code are different views of the same underlying model, but the view is all that should be different. Don’t let documen- tation become a second-class citizen, banished from the main project workﬂow. Treat documentation with the same care you treat code, and the users (and maintainers who follow) will sing your praises.\n\nRelated sections include:\n\nThe Evils of Duplication, page 26 Orthogonality, page 34 The Power of Plain Text, page 73 Source Code Control, page 86 It’s Just a View, page 157 Programming by Coincidence, page 172 The Requirements Pit, page 202 Ubiquitous Automation, page 230",
      "content_length": 1987,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 280,
      "content": "GREAT EXPECTATIONS\n\nChallenges\n\nDid you write an explanatory comment for the source code you just wrote? Why not? Pressed for time? Not sure if the code will really work—are you just trying out an idea as a prototype? You’ll throw the code away after- wards, right? It won’t make it into the project uncommented and experi- mental, will it?\n\nSometimes it is uncomfortable to document the design of source code be- cause the design isn’t clear in your mind; it’s still evolving. You don’t feel that you should waste effort describing what something does until it actu- ally does it. Does this sound like programming by coincidence (page 172)?\n\n45 Great Expectations\n\nBe astonished, O ye heavens, at this, and be horribly afraid...\n\nJeremiah 2:12\n\nA company announces record proﬁts, and its share price drops 20%. The ﬁnancial news that night explains that the company failed to meet analysts’ expectations. A child opens an expensive Christmas present and bursts into tears—it wasn’t the cheap doll the child was hoping for. A project team works miracles to implement a phenomenally complex application, only to have it shunned by its users because it doesn’t have a help system.\n\nIn an abstract sense, an application is successful if it correctly imple- ments its speciﬁcations. Unfortunately, this pays only abstract bills.\n\nIn reality, the success of a project is measured by how well it meets the expectations of its users. A project that falls below their expectations is deemed a failure, no matter how good the deliverable is in absolute terms. However, like the parent of the child expecting the cheap doll, go too far and you’ll be a failure, too.\n\nTIP 69\n\nGently Exceed Your Users’ Expectations\n\nHowever, the execution of this tip requires some work.\n\n255",
      "content_length": 1764,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 281,
      "content": "256\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nCommunicating Expectations Users initially come to you with some vision of what they want. It may be incomplete, inconsistent, or technically impossible, but it is theirs, and, like the child at Christmas, they have some emotion invested in it. You cannot just ignore it.\n\nAs your understanding of their needs develops, you’ll ﬁnd areas where their expectations cannot be met, or where their expectations are per- haps too conservative. Part of your role is to communicate this. Work with your users so that their understanding of what you’ll be deliv- ering is accurate. And do this throughout the development process. Never lose sight of the business problems your application is intended to solve.\n\nSome consultants call this process “managing expectations”—actively controlling what users should hope to get from their systems. We think this is a somewhat elitist position. Our role is not to control the hopes of our users. Instead, we need to work with them to come to a common understanding of the development process and the ﬁnal deliverable, along with those expectations they have not yet verbalized. If the team is communicating ﬂuently with the outside world, this process is almost automatic; everyone should understand what’s expected and how it will be built.\n\nThere are some important techniques that can be used to facilitate this process. Of these, Tracer Bullets, page 48, and Prototypes and Post- it Notes, page 53, are the most important. Both let the team construct something that the user can see. Both are ideal ways of communicating your understanding of their requirements. And both let you and your users practice communicating with each other.\n\nTheExtra Mile If you work closely with your users, sharing their expectations and com- municating what you’re doing, then there will be few surprises when the project gets delivered.\n\nThis is a BAD THING. Try to surprise your users. Not scare them, mind you, but delight them.",
      "content_length": 1984,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 282,
      "content": "GREAT EXPECTATIONS\n\nGive them that little bit more than they were expecting. The extra bit of effort it requires to add some user-oriented feature to the system will pay for itself time and time again in goodwill.\n\nListen to your users as the project progresses for clues about what features would really delight them. Some things you can add relatively easily that look good to the average user include:\n\nBalloon or ToolTip help\n\nKeyboard shortcuts\n\nA quick reference guide as a supplement to the user’s manual\n\nColorization\n\nLog ﬁle analyzers\n\nAutomated installation\n\nTools for checking the integrity of the system\n\nThe ability to run multiple versions of the system for training\n\nA splash screen customized for their organization\n\nAll of these things are relatively superﬁcial, and don’t really overburden the system with feature bloat. However, each tells your users that the development team cared about producing a great system, one that was intended for real use. Just remember not to break the system adding these new features.\n\nRelated sections include:\n\nGood-Enough Software, page 9 Tracer Bullets, page 48 Prototypes and Post-it Notes, page 53 The Requirements Pit, page 202\n\nChallenges\n\nSometimes the toughest critics of a project are the people who worked on it. Have you ever experienced disappointment that your own expectations weren’t met by something you produced? How could that be? Maybe there’s more than logic at work here.\n\nWhat do your users comment on when you deliver software? Is their atten- tion to the various areas of the application proportional to the effort you invested in each? What delights them?\n\n257",
      "content_length": 1638,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 283,
      "content": "46\n\n258\n\nCHAPTER 8 PRAGMATIC PROJECTS\n\nPride and Prejudice\n\nYou have delighted us long enough.\n\nJane Austen, PrideandPrejudice\n\nPragmatic Programmers don’t shirk from responsibility. Instead, we rejoice in accepting challenges and in making our expertise well known. If we are responsible for a design, or a piece of code, we do a job we can be proud of.\n\nTIP 70\n\nSign Your Work\n\nCraftsmen of an earlier age were proud to sign their work. You should be, too.\n\nProject teams are still made up of people, however, and this rule can cause trouble. On some projects, the idea of code ownership can cause cooperation problems. People may become territorial, or unwilling to work on common foundation elements. The project may end up like a bunch of insular little ﬁefdoms. You become prejudiced in favor of your code and against your coworkers.\n\nThat’s not what we want. You shouldn’t jealously defend your code against interlopers; by the same token, you should treat other peo- ple’s code with respect. The Golden Rule (“Do unto others as you would have them do unto you”) and a foundation of mutual respect among the developers is critical to make this tip work.\n\nAnonymity, especially on large projects, can provide a breeding ground for sloppiness, mistakes, sloth, and bad code. It becomes too easy to see yourself as just a cog in the wheel, producing lame excuses in endless status reports instead of good code.\n\nWhile code must be owned, it doesn’t have to be owned by an individual. In fact, Kent Beck’s successful eXtreme Programming method [URL 45] recommends communal ownership of code (but this also requires additional practices, such as pair programming, to guard against the dangers of anonymity).",
      "content_length": 1709,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 284,
      "content": "PRIDE AND PREJUDICE\n\nWe want to see pride of ownership. “I wrote this, and I stand behind my work.” Your signature should come to be recognized as an indicator of quality. People should see your name on a piece of code and expect it to be solid, well written, tested, and documented. A really professional job. Written by a real professional.\n\nA Pragmatic Programmer.\n\n259",
      "content_length": 372,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 285,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 286,
      "content": "Appendix A\n\nResources\n\nThe only reason we were able to cover so much ground in this book is that we viewed many of our subjects from a high altitude. If we’d given them the in-depth coverage they deserved, the book would have been ten times longer.\n\nWe started the book with the suggestion that Pragmatic Programmers should always be learning. In this appendix we’ve listed resources that may help you with this process.\n\nIn the section Professional Societies, we give details of the IEEE and the ACM. We recommend that Pragmatic Programmers join one (or both) of these societies. Then, in Building a Library, we highlight periodicals, books, and Web sites that we feel contain high-quality and pertinent information (or that are just plain fun).\n\nThroughout the book we referenced many software resources accessible via the Internet. In the Internet Resources section, we list the URLs of these resources, along with a short description of each. However, the nature of the Web means that many of these links may well be stale by the time you read this book. You could try one of the many search engines for a more up-to-date link, or visit our Web site at www. pragmaticprogrammer.com and check our links section.\n\nFinally, this appendix contains the book’s bibliography.\n\n261",
      "content_length": 1277,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 287,
      "content": "262\n\nAPPENDIX A RESOURCES\n\nProfessional Societies There are two world-class professional societies for programmers: the Association for Computing Machinery (ACM)1 and the IEEE Computer Society.2 We recommend that all programmers belong to one (or both) of these societies. In addition, developers outside the United States may want to join their national societies, such as the BCS in the United Kingdom.\n\nMembership in a professional society has many beneﬁts. The confer- ences and local meetings give you great opportunities to meet people with similar interests, and the special interest groups and technical committees give you the opportunity to participate in setting standards and guidelines used around the world. You’ll also get a lot out of their publications, from high-level discussions of industry practice to low- level computing theory.\n\nBuilding aLibrary We’re big on reading. As we noted in Your Knowledge Portfolio, page 12, a good programmer is always learning. Keeping current with books and periodicals can help. Here are some that we like.\n\nPeriodicals If you’re like us, you’ll save old magazines and periodicals until they’re piled high enough to turn the bottom ones to ﬂat sheets of diamond. This means it’s worth being fairly selective. Here are a few periodicals we read.\n\nIEEE Computer. Sent to members of the IEEE Computer Society, Computer has a practical focus but is not afraid of theory. Some issues are oriented around a theme, while others are simply col-\n\n1.\n\nACM Member Services, PO Box 11414, New York, NY 10286, USA.\n\nwww.acm.org\n\n2.\n\n1730 Massachusetts Avenue NW, Washington, DC 20036-1992, USA.\n\nwww.computer.org",
      "content_length": 1654,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 288,
      "content": "BUILDING A LIBRARY\n\nlections of interesting articles. This magazine has a good signal-to- noise ratio.\n\nIEEE Software. This is another great bimonthly publication of the IEEE Computer Society aimed at software practitioners.\n\nCommunications of the ACM. The basic magazine received by all members of the ACM, CACM has been a standard in the indus- try for decades, and has probably published more seminal articles than any other source.\n\nSIGPLAN. Produced by the ACM Special Interest Group on Pro- gramming Languages, SIGPLAN is an optional addition to your ACM membership. It is often used for publishing language speciﬁ- cations, along with articles of interest to everyone who likes looking deeply into programming.\n\nDr. Dobbs Journal. A monthly magazine, available by subscription and on newsstands, Dr. Dobbs is quirky, but has articles ranging from bit-level practice to heavy theory.\n\nThe Perl Journal. to The Perl Journal (www.tpj.com).\n\nIf you like Perl, you should probably subscribe\n\nSoftware Development Magazine. A monthly magazine focusing on general issues of project management and software development.\n\nWeeklyTradePapers There are several weekly newspapers published for developers and their managers. These papers are largely a collection of company press re- leases, redressed as articles. However, the content is still valuable—it lets you track what is going on, keep abreast of new product announce- ments, and follow industry alliances as they are forged and broken. Don’t expect a lot of in-depth technical coverage, though.\n\n263",
      "content_length": 1553,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 289,
      "content": "264\n\nAPPENDIX A RESOURCES\n\nBooks\n\nComputing books can be expensive, but choose carefully and they’re a worthwhile investment. You may want to check out our Pragmatic Bookshelf titles at http://pragmaticprogrammer.com. Additionally, here are a handful of the many other books we like.\n\nAnalysis and Design\n\nObject-Oriented Software Construction, 2nd Edition. Bertrand Meyer’s epic book on the fundamentals of object-oriented develop- ment, all in about 1,300 pages [Mey97b].\n\nDesignPatterns. A design pattern describes a way to solve a par- ticular class of problems at a higher level than a programming lan- guage idiom. This now-classic book [GHJV95] by the Gang of Four describes 23 basic design patterns, including Proxy, Visitor, and Singleton.\n\nAnalysisPatterns. A treasure trove of high-level, architectural pat- terns taken from a wide variety of real-world projects and distilled in book form. A relatively quick way to gain the insight of many years of modeling experience [Fow96].\n\nTeams andProjects\n\nThe Mythical Man Month. Fred Brooks’ classic on the perils of organizing project teams, recently updated [Bro95].\n\nDynamics of Software Development. A series of short essays on building software in large teams, focusing on the dynamics between team members, and between the team and the rest of the world [McC95].\n\nSurviving Object-Oriented Projects: A Manager’s Guide. Alistair Cockburn’s “reports from the trenches” illustrate many of the perils and pitfalls of managing an OO project—especially your ﬁrst one. Mr. Cockburn provides tips and techniques to get you through the most common problems [Coc97b].",
      "content_length": 1619,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 290,
      "content": "BUILDING A LIBRARY\n\nSpeciﬁc Environments\n\nUnix. W. Richard Stevens has several excellent books including Advanced Programming in the Unix Environment and the Unix Net- work Programming books [Ste92, Ste98, Ste99].\n\nWindows. Marshall Brain’s Win32 System Services [Bra95] is a concise reference to the low-level APIs. Charles Petzold’s Program- ming Windows [Pet98] is the bible of Windows GUI development.\n\nC++. As soon as you ﬁnd yourself on a C++ project, run, don’t walk, to the bookstore and get Scott Meyer’s Effective C++, and possibly More Effective C++ [Mey97a, Mey96]. For building systems of any appreciable size, you need John Lakos’ Large-Scale C++ Software Design [Lak96]. For advanced techniques, turn to Jim Coplien’s Advanced C++ Programming Styles and Idioms [Cop92].\n\nIn addition, the O’Reilly Nutshell series (www.ora.com) gives quick, comprehensive treatments of miscellaneous topics and languages such as perl, yacc, sendmail, Windows internals, and regular expressions.\n\nThe Web Finding good content on the Web is hard. Here are several links that we check at least once a week.\n\nSlashdot. Billed as “News for nerds. Stuff that matters,” Slashdot is one of the net homes of the Linux community. As well as regular updates on Linux news, the site offers information on technologies that are cool and issues that affect developers.\n\nwww.slashdot.org\n\nCetus Links. Thousands of links on object-oriented topics.\n\nwww.cetus-links.org\n\nWikiWikiWeb. The Portland Pattern Repository and patterns dis- cussion. Not just a great resource, the WikiWikiWeb site is an in- teresting experiment in collective editing of ideas.\n\nwww.c2.com\n\n265",
      "content_length": 1651,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 291,
      "content": "266\n\nAPPENDIX A RESOURCES\n\nInternet Resources The links below are to resources available on the Internet. They were valid at the time of writing, but (the Net being what it is) they may well be out of date by the time you read this. If so, you could try a general search for the ﬁlenames, or come to the Pragmatic Programmer Web site (www.pragmaticprogrammer.com) and follow our links.\n\nEditors Emacs and vi are not the only cross-platform editors, but they are freely available and widely used. A quick scan through a magazine such as Dr. Dobbs will turn up several commercial alternatives.\n\nEmacs Both Emacs and XEmacs are available on Unix and Windows platforms.\n\n[URL 1] The Emacs Editor\n\nwww.gnu.org\n\nThe ultimate in big editors, containing every feature that any editor has\n\never had, Emacs has a near-vertical learning curve, but repays hand-\n\nsomely once you’ve mastered it. It also makes a great mail and news reader,\n\naddress book, calendar and diary, adventure game,\n\n.\n\n[URL 2] The XEmacs Editor\n\nwww.xemacs.org\n\nSpawned from the original Emacs some years ago, XEmacs is reputed to\n\nhave cleaner internals and a better-looking interface.\n\nvi There are at least 15 different vi clones available. Of these, vim is prob- ably ported to the most platforms, and so would be a good choice of editor if you ﬁnd yourself working in many different environments.\n\n[URL 3] The Vim Editor\n\nftp://ftp.fu-berlin.de/misc/editors/vim\n\nFrom the documentation: “There are a lot of enhancements above vi: multi\n\nlevel undo, multi windows and buffers, syntax highlighting, command line\n\nediting, ﬁlename completion, on-line help, visual selection, etc\n\n.”",
      "content_length": 1647,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 292,
      "content": "INTERNET RESOURCES\n\n[URL 4] The elvis Editor\n\nelvis.the-little-red-haired-girl.org\n\nAn enhanced vi clone with support for X.\n\n[URL 5] Emacs Viper Mode\n\nhttp://www.cs.sunysb.edu/~kifer/emacs.html\n\nViper is a set of macros that make Emacs look like vi. Some may doubt\n\nthe wisdom of taking the world’s largest editor and extending it to emulate\n\nan editor whose strength is its compactness. Others claim it combines the\n\nbest of both worlds.\n\nCompilers, Languages,and DevelopmentTools [URL 6] The GNU C/C++ Compiler\n\nwww.fsf.org/software/gcc/gcc.html\n\nOne of the most popular C and C++ compilers on the planet. It also does\n\nObjective-C. (At the time of writing, the egcs project, which previously\n\nsplintered from gcc, is in the process of merging back into the fold.)\n\n[URL 7] The Java Language from Sun\n\njava.sun.com\n\nHome of Java, including downloadable SDKs, documentation, tutorials,\n\nnews, and more.\n\n[URL 8] Perl Language Home Page\n\nwww.perl.com\n\nO’Reilly hosts this set of Perl-related resources.\n\n[URL 9] The Python Language\n\nwww.python.org\n\nThe Python object-oriented programming language is interpreted and in-\n\nteractive, with a slightly quirky syntax and a wide and loyal following.\n\n[URL 10] SmallEiffel\n\nSmallEiffel.loria.fr\n\nThe GNU Eiffel compiler runs on any machine that has an ANSI C compiler\n\nand a Posix runtime environment.\n\n[URL 11] ISE Eiffel\n\nwww.eiffel.com\n\nInteractive Software Engineering is the originator of Design by Contract,\n\nand sells a commercial Eiffel compiler and related tools.\n\n267",
      "content_length": 1521,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 293,
      "content": "268\n\nAPPENDIX A RESOURCES\n\n[URL 12] Sather\n\nwww.icsi.berkeley.edu/~sather\n\nSather is an experimental language that grew out of Eiffel. It aims to sup-\n\nport higher-order functions and iteration abstraction as well as Common\n\nLisp, CLU, or Scheme, and to be as efﬁcient as C, C++, or Fortran.\n\n[URL 13] VisualWorks\n\nwww.cincom.com\n\nHome of the VisualWorks Smalltalk environment. Noncommercial versions\n\nfor Windows and Linux are available for free.\n\n[URL 14] The Squeak Language Environment\n\nsqueak.cs.uiuc.edu\n\nSqueak is a freely available, portable implementation of Smalltalk-80 writ-\n\nten in itself; it can produce C code output for higher performance.\n\n[URL 15] The TOM Programming Language\n\nwww.gerbil.org/tom\n\nA very dynamic language with roots in Objective-C.\n\n[URL 16] The Beowulf Project\n\nwww.beowulf.org\n\nA project that builds high-performance computers out of networked clus-\n\nters of inexpensive Linux boxes.\n\n[URL 17] iContract—Design by Contract Tool for Java\n\nwww.reliable-systems.com\n\nDesign by Contract formalism of preconditions, postconditions, and invari-\n\nants, implemented as a preprocessor for Java. Honors inheritance, imple-\n\nments existential quantiﬁers, and more.\n\n[URL 18] Nana—Logging and Assertions for C and C++\n\nwww.gnu.org/software/nana/nana.html\n\nImproved support for assertion checking and logging in C and C++. It also\n\nprovides some support for Design by Contract.\n\n[URL 19] DDD—Data Display Debugger\n\nhttp://www.gnu.org/software/ddd/\n\nA free graphical front end for Unix debuggers.\n\n[URL 20] John Brant’s Refactoring Browser\n\nst-www.cs.uiuc.edu/users/brant/Refactory\n\nA popular refactoring browser for Smalltalk.",
      "content_length": 1650,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 294,
      "content": "INTERNET RESOURCES\n\n[URL 21] DOC++ Documentation Generator\n\nwww.zib.de/Visual/software/doc++/index.html\n\nDOC++ is a documentation system for C/C++ and Java that generates both LATEX and HTML output for sophisticated online browsing of your documentation directly from the C++ header or Java class ﬁles.\n\n[URL 22] xUnit—Unit Testing Framework\n\nwww.XProgramming.com\n\nA simple but powerful concept, the xUnit unit testing framework provides\n\na consistent platform for testing software written in a variety of languages.\n\n[URL 23] The Tcl Language\n\nwww.scriptics.com\n\nTcl (“Tool Command Language”) is a scripting language designed to be easy\n\nto embed into an application.\n\n[URL 24] Expect—Automate Interaction with Programs\n\nexpect.nist.gov\n\nAn extension built on Tcl [URL 23], expect allows you to script interac-\n\ntion with programs. As well as helping you write command ﬁles that (for\n\nexample) fetch ﬁles from remote servers or extend the power of your shell,\n\nexpect can be useful when performing regression testing. A graphical ver-\n\nsion, expectk, lets you wrap non-GUI applications with a windowing front\n\nend.\n\n[URL 25] T Spaces\n\nwww.almaden.ibm.com/cs/TSpaces\n\nFrom their Web page: “T Spaces is a network communication buffer with\n\ndatabase capabilities. It enables communication between applications and\n\ndevices in a network of heterogeneous computers and operating systems.\n\nT Spaces provides group communication services, database services, URL-\n\nbased ﬁle transfer services, and event notiﬁcation services.”\n\n[URL 26] javaCC—Java Compiler-Compiler\n\nwww.webgain.com/products/java_cc\n\nA parser generator that is tightly coupled to the Java language.\n\n[URL 27] The bison Parser Generator\n\nwww.gnu.org/software/bison/bison.html\n\nbison takes an input grammar speciﬁcation and generates from it the C\n\nsource code of a suitable parser.\n\n269",
      "content_length": 1846,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 295,
      "content": "270\n\nAPPENDIX A RESOURCES\n\n[URL 28] SWIG—Simpliﬁed Wrapper and Interface Generator\n\nwww.swig.org\n\nSWIG is a software development tool that connects programs written in C,\n\nC++, and Objective-C with a variety of high-level programming languages\n\nsuch as Perl, Python, and Tcl/Tk, as well as Java, Eiffel, and Guile.\n\n[URL 29] The Object Management Group, Inc.\n\nwww.omg.org\n\nThe OMG is the steward of various speciﬁcations for producing distributed\n\nobject-based systems. Their work includes the Common Object Request\n\nBroker Architecture (CORBA) and the Internet Inter-ORB Protocol (IIOP).\n\nCombined, these speciﬁcations make it possible for objects to communi-\n\ncate with each other, even if they are written in different languages and\n\nrun on different types of computers.\n\nUnix Tools Under DOS [URL 30] The UWIN Development Tools\n\nwww.gtlinc.com/uwin.html\n\nGlobal Technologies, Inc., Old Bridge, NJ\n\nThe UWIN package provides Windows Dynamic Link Libraries (DLLs) that\n\nemulate a large portion of the Unix C level library interface. Using this\n\ninterface, GTL has ported a large number of Unix command-line tools to\n\nWindows. See also [URL 31].\n\n[URL 31] The Cygnus Cygwin Tools\n\nsourceware.cygnus.com/cygwin/\n\nCygnus Solutions, Sunnyvale, CA\n\nThe Cygnus package also emulates the the Unix C library interface, and\n\nprovides a large array of Unix command-line tools under the Windows op-\n\nerating system.\n\n[URL 32] Perl Power Tools\n\nwww.perl.com/pub/language/ppt/\n\nA project to reimplement the classic Unix command set in Perl, making the\n\ncommands available on all platforms that support Perl (and that’s a lot of\n\nplatforms).",
      "content_length": 1629,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 296,
      "content": "INTERNET RESOURCES\n\nSource Code Control Tools [URL 33] RCS—Revision Control System\n\nwww.cs.purdue.edu/homes/trinkle/RCS/\n\nGNU source code control system for Unix and Windows NT.\n\n[URL 34] CVS—Concurrent Version System\n\nwww.cvshome.com\n\nFreely available source code control system for Unix and Windows NT.\n\nExtends RCS by supporting a client-server model and concurrent access\n\nto ﬁles.\n\n[URL 35] Aegis Transaction-Based Conﬁguration Management\n\nhttp://www.canb.auug.org.au/~millerp/aegis.html\n\nA process-oriented revision control tool that imposes project standards\n\n(such as verifying that checked-in code passes tests).\n\n[URL 36] ClearCase\n\nwww.rational.com\n\nVersion control, workspace and build management, process control.\n\n[URL 37] MKS Source Integrity\n\nwww.mks.com\n\nVersion control and conﬁguration management. Some versions incorporate\n\nfeatures allowing remote developers to work on the same ﬁles simultane-\n\nously (much like CVS).\n\n[URL 38] PVCS Conﬁguration Management\n\nwww.merant.com\n\nA source code control system, very popular for Windows systems.\n\n[URL 39] Visual SourceSafe\n\nwww.microsoft.com\n\nA version control system that integrates with Microsoft’s visual develop-\n\nment tools.\n\n[URL 40] Perforce\n\nwww.perforce.com\n\nA client-server software conﬁguration management system.\n\n271",
      "content_length": 1294,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 297,
      "content": "272\n\nAPPENDIX A RESOURCES\n\nOther Tools [URL 41] WinZip—Archive Utility for Windows\n\nwww.winzip.com\n\nNico Mak Computing, Inc., Mansﬁeld, CT\n\nA Windows-based ﬁle archive utility. Supports both zip and tar formats.\n\n[URL 42] The Z Shell\n\nsunsite.auc.dk/zsh\n\nA shell designed for interactive use, although it is also a powerful scripting\n\nlanguage. Many of the useful features of bash, ksh, and tcsh were incor-\n\nporated into zsh; many original features were added.\n\n[URL 43] A Free SMB Client for Unix Systems samba.anu.edu.au/pub/samba/\n\nSamba lets you share ﬁles and other resources between Unix and Windows systems. Samba includes:\n\nAn SMB server, to provide Windows NT and LAN Manager-style ﬁle and print services to SMB clients such as Windows 95, Warp Server, smbfs, and others.\n\nA Netbios nameserver, which among other things gives browsing sup- port. Samba can be the master browser on your LAN if you wish.\n\nAn ftp-like SMB client that allows you to access PC resources (disks and printers) from Unix, Netware, and other operating systems.\n\nPapersand Publications [URL 44] The comp.object FAQ\n\nwww.cyberdyne-object-sys.com/oofaq2\n\nA substantial and well-organized FAQ for the comp.object newsgroup.\n\n[URL 45] eXtreme Programming\n\nwww.XProgramming.com\n\nFrom the Web site: “In XP, we use a very lightweight combination of prac-\n\ntices to create a team that can rapidly produce extremely reliable, efﬁcient,\n\nwell-factored software. Many of the XP practices were created and tested as\n\npart of the Chrysler C3 project, which is a very successful payroll system\n\nimplemented in Smalltalk.”\n\n[URL 46] Alistair Cockburn’s Home Page\n\nmembers.aol.com/acockburn\n\nLook for “Structuring Use Cases with Goals” and use case templates.",
      "content_length": 1727,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 298,
      "content": "INTERNET RESOURCES\n\n[URL 47] Martin Fowler’s Home Page\n\nourworld.compuserve.com/homepages/martin_fowler\n\nAuthor of Analysis Patterns and co-author of UML Distilled and Refactor- ing: Improving the Design of Existing Code. Martin Fowler’s home page dis-\n\ncusses his books and his work with the UML.\n\n[URL 48] Robert C. Martin’s Home Page\n\nwww.objectmentor.com\n\nGood introductory papers on object-oriented techniques, including depen-\n\ndency analysis and metrics.\n\n[URL 49] Aspect-Oriented Programming\n\nwww.parc.xerox.com/csl/projects/aop/\n\nAn approach to adding functionality to code, both orthogonally and declar-\n\natively.\n\n[URL 50] JavaSpaces Speciﬁcation\n\njava.sun.com/products/javaspaces\n\nA Linda-like system for Java that supports distributed persistence and\n\ndistributed algorithms.\n\n[URL 51] Netscape Source Code\n\nwww.mozilla.org\n\nThe development source of the Netscape browser.\n\n[URL 52] The Jargon File\n\nwww.jargon.org\n\nEric S. Raymond\n\nDeﬁnitions for many common (and not so common) computer industry\n\nterms, along with a good dose of folklore.\n\n[URL 53] Eric S. Raymond’s Papers\n\nwww.tuxedo.org/~esr\n\nEric’s papers on The Cathedral and the Bazaar and Homesteading the Noo- sphere describing the psychosocietal basis for and implications of the Open\n\nSource movement.\n\n[URL 54] The K Desktop Environment\n\nwww.kde.org\n\nFrom their Web page: “KDE is a powerful graphical desktop environment for Unix workstations. KDE is an Internet project and truly open in every sense.”\n\n273",
      "content_length": 1484,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 299,
      "content": "274\n\nAPPENDIX A RESOURCES\n\n[URL 55] The GNU Image Manipulation Program\n\nwww.gimp.org\n\nGimp is a freely distributed program used for image creation, composition,\n\nand retouching.\n\n[URL 56] The Demeter Project\n\nwww.ccs.neu.edu/research/demeter\n\nResearch focused on making software easier to maintain and evolve using\n\nAdaptive Programming.\n\nMiscellaneous [URL 57] The GNU Project\n\nwww.gnu.org\n\nFree Software Foundation, Boston, MA\n\nThe Free Software Foundation is a tax-exempt charity that raises funds\n\nfor the GNU project. The GNU project’s goal is to produce a complete, free,\n\nUnix-like system. Many of the tools they’ve developed along the way have\n\nbecome industry standards.\n\n[URL 58] Web Server Information\n\nwww.netcraft.com/survey/servers.html\n\nLinks to the home pages of over 50 different web servers. Some are com-\n\nmercial products, while others are freely available.\n\nBibliography\n\n[Bak72]\n\nF. T. Baker. Chief programmer team management of pro- IBM Systems Journal, 11(1):56–73, duction programming. 1972.\n\n[BBM96] V. Basili, L. Briand, and W. L. Melo. A validation of object- IEEE Trans- oriented design metrics as quality indicators. actions on Software Engineering, 22(10):751–761, October 1996.\n\n[Ber96]\n\nAlbert J. Bernstein. Dinosaur Brains: Dealing with All Those Impossible People at Work. Ballantine Books, New York, NY, 1996.",
      "content_length": 1345,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 300,
      "content": "BIBLIOGRAPHY\n\n[Bra95]\n\nMarshall Brain. Win32 System Services. Prentice Hall, En- glewood Cliffs, NJ, 1995.\n\n[Bro95]\n\nFrederick P. Brooks, Jr. The Mythical Man Month: Essays on Software Engineering. Addison-Wesley, Reading, MA, an- niversary edition, 1995.\n\n[CG90]\n\nN. Carriero and D. Gelenter. How to Write Parallel Programs: A First Course. MIT Press, Cambridge, MA, 1990.\n\n[Cla04]\n\nMike Clark. Pragmatic Project Automation. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2004.\n\n[CN91]\n\nBrad J. Cox and Andrex J. Novobilski. Object-Oriented Programming, An Evolutionary Approach. Addison-Wesley, Reading, MA, 1991.\n\n[Coc97a] Alistair Cockburn. Goals and use cases. Journal of Object\n\nOriented Programming, 9(7):35–40, September 1997.\n\n[Coc97b] Alistair Cockburn.\n\nSurviving Object-Oriented Projects: A Manager’s Guide. Addison Wesley Longman, Reading, MA, 1997.\n\n[Cop92]\n\nJames O. Coplien. Advanced C++ Programming Styles and Idioms. Addison-Wesley, Reading, MA, 1992.\n\n[DL99]\n\nTom Demarco and Timothy Lister. Peopleware: Productive Projects and Teams. Dorset House, New York, NY, second edition, 1999.\n\n[FBB 99] Martin Fowler, Kent Beck, John Brant, William Opdyke, and Don Roberts. Refactoring: Improving the Design of Existing Code. Addison Wesley Longman, Reading, MA, 1999.\n\n[Fow96] Martin Fowler. Analysis Patterns: Reusable Object Models. Addison Wesley Longman, Reading, MA, 1996.\n\n[FS99]\n\nMartin Fowler and Kendall Scott. UML Distilled: Applying the Standard Object Modeling Language. Addison Wesley Long- man, Reading, MA, second edition, 1999.\n\n[GHJV95] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. Design Patterns: Elements of Reusable Object- Oriented Software. Addison-Wesley, Reading, MA, 1995.\n\n275",
      "content_length": 1746,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 301,
      "content": "276\n\nAPPENDIX A RESOURCES\n\n[Gla99a] Robert L. Glass.\n\nInspections—Some surprising ﬁndings.\n\nCommunications of the ACM, 42(4):17–19, April 1999.\n\n[Gla99b] Robert L. Glass. The realities of software technology payoffs.\n\nCommunications of the ACM, 42(2):74–79, February 1999.\n\n[Hol78]\n\nMichael Holt. Math Puzzles and Games. Dorset Press, New York, NY, 1978.\n\n[HT03]\n\nAndy Hunt and Dave Thomas. Pragmatic Unit Testing In Java with JUnit. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2003.\n\n[Jac94]\n\nIvar Jacobson. Object-Oriented Software Engineering: A Use- Case Driven Approach. Addison-Wesley, Reading, MA, 1994.\n\n[KLM 97] Gregor Kiczales, John Lamping, Anurag Mendhekar, Chris Maeda, Cristina Videira Lopes, Jean-Marc Loingtier, and In European John Irwin. Aspect-oriented programming. Conference on Object-Oriented Programming (ECOOP), vol- ume LNCS 1241. Springer-Verlag, June 1997.\n\n[Knu97a] Donald Ervin Knuth. The Art of Computer Programming: Fun- damental Algorithms, volume 1. Addison Wesley Longman, Reading, MA, third edition, 1997.\n\n[Knu97b] Donald Ervin Knuth. The Art of Computer Programming: Seminumerical Algorithms, volume 2. Addison Wesley Long- man, Reading, MA, third edition, 1997.\n\n[Knu98] Donald Ervin Knuth. The Art of Computer Programming: Sorting and Searching, volume 3. Addison Wesley Longman, Reading, MA, second edition, 1998.\n\n[KP99]\n\nBrian W. Kernighan and Rob Pike. The Practice of Program- ming. Addison Wesley Longman, Reading, MA, 1999.\n\n[Kru98]\n\nPhilippe Kruchten. The Rational Uniﬁed Process: An Intro- duction. Addison Wesley Longman, Reading, MA, 1998.\n\n[Lak96]\n\nJohn Lakos. Large-Scale C++ Software Design. Addison Wesley Longman, Reading, MA, 1996.",
      "content_length": 1704,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 302,
      "content": "BIBLIOGRAPHY\n\n[LH89]\n\nKarl J. Lieberherr and Ian Holland. Assuring good style for object-oriented programs. IEEE Software, pages 38–48, September 1989.\n\n[Lis88]\n\nBarbara Liskov. Data abstraction and hierarchy. SIGPLAN Notices, 23(5), May 1988.\n\n[LMB92]\n\nJohn R. Levine, Tony Mason, and Doug Brown. Lex and Yacc. O’Reilly & Associates, Inc., Sebastopol, CA, second edition, 1992.\n\n[McC95]\n\nJim McCarthy. Dynamics of Software Development. Mi- crosoft Press, Redmond, WA, 1995.\n\n[Mey96]\n\nScott Meyers. More Effective C++: 35 New Ways to Improve Your Programs and Designs. Addison-Wesley, Reading, MA, 1996.\n\n[Mey97a] Scott Meyers. Effective C++: 50 Speciﬁc Ways to Improve Your Programs and Designs. Addison Wesley Longman, Reading, MA, second edition, 1997.\n\n[Mey97b] Bertrand Meyer. Object-Oriented Software Construction.\n\nPrentice Hall, Englewood Cliffs, NJ, second edition, 1997.\n\n[Pet98]\n\nProgramming Windows, The Deﬁnitive Charles Petzold. Guide to the Win32 API. Microsoft Press, Redmond, WA, ﬁfth edition, 1998.\n\n[Sch95]\n\nApplied Cryptography: Protocols, Algo- Bruce Schneier. rithms, and Source Code in C. John Wiley & Sons, New York, NY, second edition, 1995.\n\n[Sed83]\n\nRobert Sedgewick. Algorithms. Addison-Wesley, Reading, MA, 1983.\n\n[Sed92]\n\nRobert Sedgewick. Algorithms in C++. Addison-Wesley, Reading, MA, 1992.\n\n[SF96]\n\nRobert Sedgewick and Phillipe Flajolet. An Introduction to the Analysis of Algorithms. Addison-Wesley, Reading, MA, 1996.\n\n[Ste92]\n\nW. Richard Stevens. Advanced Programming in the Unix En- vironment. Addison-Wesley, Reading, MA, 1992.\n\n277",
      "content_length": 1572,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 303,
      "content": "278\n\nAPPENDIX A RESOURCES\n\n[Ste98]\n\nW. Richard Stevens. Unix Network Programming, Volume 1: Networking APIs: Sockets and Xti. Prentice Hall, Englewood Cliffs, NJ, second edition, 1998.\n\n[Ste99]\n\nW. Richard Stevens. Unix Network Programming, Volume 2: Interprocess Communications. Prentice Hall, Englewood Cliffs, NJ, second edition, 1999.\n\n[Str35]\n\nJames Ridley Stroop. Studies of interference in serial verbal reactions. Journal of Experimental Psychology, 18:643–662, 1935.\n\n[TFH04] Dave Thomas, Chad Fowler, and Andy Hunt. Programming Ruby, The Pragmatic Programmers’ Guide. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2004.\n\n[TH03]\n\nDave Thomas and Andy Hunt. Pragmatic Version Control Using CVS. The Pragmatic Programmers, LLC, Raleigh, NC, and Dallas, TX, 2003.\n\n[WK82]\n\nJames Q. Wilson and George Kelling. The police and neigh- borhood safety. The Atlantic Monthly, 249(3):29–38, March 1982.\n\n[YC86]\n\nEdward Yourdon and Larry L. Constantine. Structured De- sign: Fundamentals of a Discipline of Computer Program and Systems Design. Prentice Hall, Englewood Cliffs, NJ, second edition, 1986.\n\n[You95]\n\nEdward Yourdon. When good-enough software is best. IEEE Software, May 1995.",
      "content_length": 1200,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 304,
      "content": "Appendix B\n\nAnswers to Exercises\n\nExercise 1: fromOrthogonality onpage43 You are writing a class called Split, which splits input lines into ﬁelds. Which of the following two Java class signatures is the more orthogonal design?\n\nclass Split1 {\n\npublic Split1(InputStreamReader rdr) { ... public void readNextLine() throws IOException { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\nclass Split2 {\n\npublic Split2(String line) { ... public int numFields() { ... public String getField(int fieldNo) { ...\n\n}\n\nAnswer 1: To our way of thinking, class Split2 is more orthogonal. It con- centrates on its own task, splitting lines, and ignores details such as where the lines are coming from. Not only does this make the code easier to develop, but it also makes it more ﬂexible. Split2 can split lines read from a ﬁle, generated by another routine, or passed in via the environment.\n\nExercise 2: fromOrthogonality onpage43 Which will lead to a more orthogonal design: modeless or modal dialog boxes?\n\nAnswer 2: If done correctly, probably modeless. A system that uses mode- less dialog boxes will be less concerned with what is going on at any particular moment in time. It will likely have a better intermodule communications in- frastructure than a modal system, which may have built-in assumptions about the state of the system—assumptions that lead to increased coupling and de- creased orthogonality.\n\n279",
      "content_length": 1437,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 305,
      "content": "280\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 3: fromOrthogonalityonpage43 How about procedural languages versus object technology? Which results in a more orthogonal system?\n\nAnswer 3: This is a little tricky. Object technology can provide a more orthog- onal system, but because it has more features to abuse, it is actually easier to create a nonorthogonal system using objects than it is using a procedural lan- guage. Features such as multiple inheritance, exceptions, operator overload- ing, and parent-method overriding (via subclassing) provide ample opportunity to increase coupling in nonobvious ways.\n\nWith object technology and a little extra effort, you can achieve a much more orthogonal system. But while you can always write “spaghetti code” in a pro- cedural language, object-oriented languages used poorly can add meatballs to your spaghetti.\n\nExercise 4: fromPrototypesandPost-itNotesonpage56 Marketing would like to sit down and brainstorm a few Web-page designs with you. They are thinking of clickable image maps to take you to other pages, and so on. But they can’t decide on a model for the image—maybe it’s a car, or a phone, or a house. You have a list of target pages and content; they’d like to see a few prototypes. Oh, by the way, you have 15 minutes. What tools might you use?\n\nAnswer 4: Low-tech to the rescue! Draw a few cartoons with markers on a whiteboard—a car, a phone, and a house. It doesn’t have to be great art; stick- ﬁgure outlines are ﬁne. Put Post-it notes that describe the contents of target pages on the clickable areas. As the meeting progresses, you can reﬁne the drawings and placements of the Post-it notes.\n\nExercise 5: fromDomainLanguagesonpage63 We want to implement a mini-language to control a simple drawing package (perhaps a turtle-graphics system). The language consists of single-letter com- mands. Some commands are followed by a single number. For example, the following input would draw a rectangle.\n\nP 2 D W 2 N 1 E 2 S 1 U\n\n# select pen 2 # pen down # draw west 2cm # then north 1 # then east 2 # then back south # pen up\n\nImplement the code that parses this language. It should be designed so that it is simple to add new commands.",
      "content_length": 2201,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 306,
      "content": "Answer 5: Because we want to make the language extendable, we’ll make the parser table driven. Each entry in the table contains the command letter, a ﬂag to say whether an argument is required, and the name of the routine to call to handle that particular command.\n\ntypedef struct {\n\nchar cmd; int hasArg; void (*func)(int, int); /* routine to call */\n\n/* the command letter */ /* does it take an argument */\n\n} Command;\n\nstatic Command cmds[] = {\n\n{ ’P’, ARG, { ’U’, NO_ARG, doPenUp }, { ’D’, NO_ARG, doPenDown }, { ’N’, ARG, { ’E’, ARG, { ’S’, ARG, { ’W’, ARG,\n\ndoSelectPen },\n\ndoPenDir }, doPenDir }, doPenDir }, doPenDir }\n\n};\n\nThe main program is pretty simple: read a line, look up the command, get the argument if required, then call the handler function.\n\nwhile (fgets(buff, sizeof(buff), stdin)) {\n\nCommand *cmd = findCommand(*buff);\n\nif (cmd) {\n\nint\n\narg = 0;\n\nif (cmd->hasArg && !getArg(buff+1, &arg)) {\n\nfprintf(stderr, \"’%c’ needs an argument n\", *buff); continue;\n\n}\n\ncmd->func(*buff, arg);\n\n}\n\n}\n\nThe function that looks up a command performs a linear search of the table, returning either the matching entry or NULL.\n\nCommand *findCommand(int cmd) {\n\nint i;\n\nfor (i = 0; i < ARRAY_SIZE(cmds); i++) {\n\nif (cmds[i].cmd == cmd)\n\nreturn cmds + i;\n\n}\n\nfprintf(stderr, \"Unknown command ’%c’ n\", cmd); return 0;\n\n}\n\nFinally, reading the numeric argument is pretty simple using sscanf.\n\nint getArg(const char *buff, int *result) { return sscanf(buff, \"%d\", result) == 1;\n\n}\n\n281",
      "content_length": 1486,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 307,
      "content": "282\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 6: fromDomainLanguagesonpage63 Design a BNF grammar to parse a time speciﬁcation. All of the following exam- ples should be accepted.\n\n4pm, 7:38pm, 23:42, 3:16, 3:16am\n\nAnswer 6: Using BNF, a time speciﬁcation could be\n\ntime\n\nhour hour hour\n\nampm : minute : minute\n\nampm\n\nampm\n\nam pm\n\nhour\n\ndigit digit\n\ndigit\n\nminute\n\ndigit\n\ndigit\n\ndigit\n\n0 1 2 3 4 5 6 7 8 9\n\nExercise 7: fromDomainLanguagesonpage63 Implement a parser for the BNF grammar in Exercise 6 using yacc, bison, or a similar parser-generator.\n\nAnswer 7: We coded our example using bison, the GNU version of yacc. For clarity, we’re just showing the body of the parser here. Look at the source on our Web site for the full implementation.\n\ntime:\n\nspec END_TOKEN { if ($1 >= 24*60) yyerror(\"Time is too large\");\n\nprintf(\"%d minutes past midnight n\", $1); exit(0);\n\n}\n\n;\n\nspec:\n\nhour ’:’ minute { $$ = $1 + $3; }\n\n| hour ’:’ minute ampm\n\n{ if ($1 > 11*60) yyerror(\"Hour out of range\");\n\n$$ = $1 + $3 + $4;\n\n}\n\n| hour ampm\n\n{ if ($1 > 11*60) yyerror(\"Hour out of range\");\n\n$$ = $1 + $2;\n\n}\n\n;\n\nhour:\n\nhour_num { if ($1 > 23) yyerror(\"Hour out of range\");\n\n$$ = $1 * 60;\n\n};",
      "content_length": 1177,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 308,
      "content": "minute:\n\nDIGIT DIGIT { $$ = $1*10 + $2;\n\nif ($$ > 59) yyerror(\"minute out of range\");\n\n};\n\nampm:\n\nAM | PM ;\n\n{ $$ = AM_MINS; } { $$ = PM_MINS; }\n\nhour_num: DIGIT\n\n| DIGIT DIGIT ;\n\n{ $$ = $1; } { $$ = $1*10 + $2; }\n\nExercise 8: fromDomainLanguagesonpage63 Implement the time parser using Perl. [Hint: Regular expressions make good parsers.]\n\nAnswer 8:\n\n$_ = shift;\n\n/^( d d?)(am|pm)$/\n\n&& doTime($1, 0,\n\n$2, 12);\n\n/^( d d?):( d d)(am|pm)$/ && doTime($1, $2, $3, 12);\n\n/^( d d?):( d d)$/\n\n&& doTime($1, $2, 0, 24);\n\ndie \"Invalid time $_ n\";\n\n# # doTime(hour, min, ampm, maxHour) # sub doTime($$$$) {\n\nmy ($hour, $min, $offset, $maxHour) = @_; die \"Invalid hour: $hour\" if ($hour >= $maxHour); $hour += 12 if ($offset eq \"pm\"); print $hour*60 + $min, \" minutes past midnight n\"; exit(0);\n\n}\n\nExercise 9: fromEstimatingonpage69 You are asked “Which has a higher bandwidth: a 1Mbps communications line or a person walking between two computers with a full 4GB tape in their pocket?” What constraints will you put on your answer to ensure that the scope of your response is correct? (For example, you might say that the time taken to access the tape is ignored.)\n\nAnswer 9: Our answer must be couched in several assumptions:\n\nThe tape contains the information we need to be transferred.\n\nWe know the speed at which the person walks.\n\nWe know the distance between the machines.\n\nWe are not accounting for the time it takes to transfer information to and from the tape.\n\n283",
      "content_length": 1466,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 309,
      "content": "284\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nThe overhead of storing data on a tape is roughly equal to the overhead of sending it over a communications line.\n\nExercise 10: fromEstimating onpage69 So, which has the higher bandwidth?\n\nAnswer 10: Subject to the caveats in Answer 9: A 4GB tape contains bits, so a 1Mbps line would have to pump data for about seconds, or roughly hours, to transfer the equivalent amount of information. If the person mph, then our two machines would need to be at is walking at a constant least miles apart for the communications line to outperform our courier. Otherwise, the person wins.\n\nExercise 11: fromTextManipulation onpage102 Your C program uses an enumerated type to represent one of 100 states. You’d like to be able to print out the state as a string (as opposed to a number) for debugging purposes. Write a script that reads from standard input a ﬁle containing\n\nname state_a state_b :\n\n:\n\nProduce the ﬁle name.h, which contains\n\nextern const char* NAME_names[]; typedef enum { state_a, state_b,\n\n: } NAME;\n\n:\n\nand the ﬁle name.c, which contains\n\nconst char* NAME_names[] = {\n\n\"state_a\", \"state_b\",\n\n:\n\n:\n\n};",
      "content_length": 1145,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 310,
      "content": "Answer 11: We implemented our answer using Perl.\n\nmy @consts;\n\nmy $name = <>; die \"Invalid format - missing name\" unless defined($name);\n\nchomp $name;\n\n# Read in the rest of the file while (<>) {\n\nchomp; s/^ s*//; s/ s*$//;\n\ndie \"Invalid line: $_\" unless /^( w+)$/;\n\npush @consts, $_;\n\n}\n\n# Now generate the file open(HDR, \">$name.h\") or die \"Can’t open $name.h: $!\"; open(SRC, \">$name.c\") or die \"Can’t open $name.c: $!\";\n\nmy $uc_name = uc($name); my $array_name = $uc_name . \"_names\";\n\nprint HDR \"/* File generated automatically - do not edit */ n\"; print HDR \"extern const char *$ {array_name}[];\"; print HDR \"typedef enum { n\n\n\";\n\nprint HDR join \", n \", @consts;\n\nprint HDR \" n} $uc_name; n n\";\n\nprint SRC \"/* File generated automatically - do not edit */ n\";\n\nprint SRC \"const char *$ {array_name}[] = { n\n\n\"\";\n\nprint SRC join \" \", n\n\n\"\", @consts;\n\nprint SRC \" \" n}; n\";\n\nclose(SRC); close(HDR);\n\nUsing the DRY principle, we won’t cut and paste this new ﬁle into our code. Instead, we’ll #include it—the ﬂat ﬁle is the master source of these constants. This means that we’ll need a makeﬁle to regenerate the header when the ﬁle changes. The following extract is from the test bed in our source tree (available on the Web site).\n\netest.c etest.h: etest.inc enumerated.pl\n\nperl enumerated.pl etest.inc\n\nExercise 12: fromTextManipulationonpage102 Halfway through writing this book, we realized that we hadn’t put the use strict directive into many of our Perl examples. Write a script that goes through the .pl ﬁles in a directory and adds a use strict at the end of the initial comment block to all ﬁles that don’t already have one. Remember to keep a backup of all ﬁles you change.\n\n285",
      "content_length": 1690,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 311,
      "content": "286\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nAnswer 12: Here’s our answer, written in Perl.\n\nmy $dir = shift or die \"Missing directory\";\n\nfor my $file (glob(\"$dir/*.pl\")) {\n\nopen(IP, \"$file\") or die \"Opening $file: $!\"; undef $/; my $content = <IP>; # read whole file as one string. close(IP);\n\n# Turn off input record separator --\n\nif ($content !~ /^use strict/m) {\n\nrename $file, \"$file.bak\" or die \"Renaming $file: $!\"; open(OP, \">$file\") or die \"Creating $file: $!\";\n\n# Put ’use strict’ on first line that # doesn’t start ’#’ $content =~ s/^(?!#)/ nuse strict; n n/m;\n\nprint OP $content; close(OP);\n\nprint \"Updated $file n\";\n\n} else {\n\nprint \"$file already strict n\";\n\n}\n\n}\n\nExercise 13: fromCodeGeneratorsonpage106 Write a code generator that takes the input ﬁle in Figure 3.4, page 106, and generates output in two languages of your choice. Try to make it easy to add new languages.\n\nAnswer 13: We use Perl to implement our solution. It dynamically loads a module to generate the requested language, so adding new languages is easy. The main routine loads the back end (based on a command-line parameter), then reads its input and calls code generation routines based on the content of each line. We’re not particularly fussy about error handling—we’ll get to know pretty quickly if things go wrong.\n\nmy $lang = shift or die \"Missing language\"; $lang .= \"_cg.pm\";\n\nrequire \"$lang\" or die \"Couldn’t load $lang\";\n\n# Read and parse the file\n\nmy $name;\n\nwhile (<>) {\n\nchomp; if\n\n(/^ s*$/)\n\n{ CG::blankLine(); }\n\nelsif (/^ #(.*)/)\n\n{ CG::comment($1); }\n\nelsif (/^M s*(.+)/) { CG::startMsg($1); $name = $1; } elsif (/^E/) elsif (/^F s*( w+) s+( w+)$/)\n\n{ CG::endMsg($name); }\n\n{ CG::simpleType($1,$2); }",
      "content_length": 1696,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 312,
      "content": "elsif (/^F s*( w+) s+( w+) [( d+) ]$/)\n\n{ CG::arrayType($1,$2,$3); }\n\nelse {\n\ndie \"Invalid line: $_\";\n\n}\n\n}\n\nWriting a language back end is simple: provide a module that implements the required six entry points. Here’s the C generator:\n\n#!/usr/bin/perl -w package CG; use strict;\n\n# Code generator for ’C’ (see cg_base.pl)\n\nsub blankLine() { print \" n\"; }\n\nsub comment()\n\n{ print \"/*$_[0] */ n\"; }\n\nsub startMsg() { print \"typedef struct { n\"; }\n\nsub endMsg()\n\n{ print \"} $_[0]; n n\"; }\n\nsub arrayType() {\n\nmy ($name, $type, $size) = @_;\n\nprint \"\n\n$type $name [$size]; n\";\n\n}\n\nsub simpleType() {\n\nmy ($name, $type) = @_; print \"\n\n$type $name; n\";\n\n}\n\n1;\n\nAnd here’s the one for Pascal:\n\n#!/usr/bin/perl -w package CG; use strict;\n\n# Code generator for ’Pascal’ (see cg_base.pl)\n\nsub blankLine() { print \" n\"; }\n\nsub comment()\n\n{ print \"{$_[0] } n\"; }\n\nsub startMsg() { print \"$_[0] = packed record n\"; }\n\nsub endMsg()\n\n{ print \"end; n n\"; }\n\nsub arrayType() {\n\nmy ($name, $type, $size) = @_; $size--; print \"\n\n$name: array[0..$size] of $type; n\";\n\n}\n\nsub simpleType() {\n\nmy ($name, $type) = @_; print \"\n\n$name: $type; n\";\n\n}\n\n1;\n\n287",
      "content_length": 1133,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 313,
      "content": "288\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 14: fromDesignbyContractonpage118 What makes a good contract? Anyone can add preconditions and postcondi- tions, but will they do you any good? Worse yet, will they actually do more harm than good? For the example below and for those in Exercises 15 and 16, decide whether the speciﬁed contract is good, bad, or ugly, and explain why.\n\nFirst, let’s look at an Eiffel example. Here we have a routine for adding a STRING to a doubly linked, circular list (remember that preconditions are labeled with require, and postconditions with ensure).\n\n-- Add a unique item to a doubly linked list, -- and return the newly created NODE.\n\nadd_item (item : STRING) : NODE is\n\nrequire\n\nitem /= Void find_item(item) = Void\n\ndeferred ensure\n\n-- ’/=’ is ’not equal’. -- Must be unique -- Abstract base class.\n\nresult.next.previous = result -- Check the newly result.previous.next = result -- added node’s links. find_item(item) = result\n\n-- Should find it.\n\nend\n\nAnswer 14: This Eiffel example is good. We require non-null data to be passed in, and we guarantee that the semantics of a circular, doubly linked list are honored. It also helps to be able to ﬁnd the string we stored. Because this is a deferred class, the actual class that implements it is free to use what- ever underlying mechanism it wants to. It may choose to use pointers, or an array, or whatever; as long as it honors the contract, we don’t care.\n\nExercise 15: fromDesignbyContractonpage119 Next, let’s try an example in Java—somewhat similar to the example in Exercise 14. insertNumber inserts an integer into an ordered list. Pre- and postcondi- tions are labeled as in iContract (see [URL 17]).\n\nprivate int data[]; /**\n\n@post data[index-1] < data[index] && * data[index] == aValue */\n\npublic Node insertNumber (final int aValue) {\n\nint index = findPlaceToInsert(aValue); ...\n\nAnswer 15: This is bad. The math in the index clause (index-1) won’t work on boundary conditions such as the ﬁrst entry. The postcondition assumes a particular implementation: we want contracts to be more abstract than that.",
      "content_length": 2106,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 314,
      "content": "Exercise 16: fromDesignbyContractonpage119 Here’s a fragment from a stack class in Java. Is this a good contract?\n\n/**\n\n@pre anItem != null * @post pop() == anItem // Verify that it’s * */ // Require real data\n\npublic void push(final String anItem)\n\nAnswer 16: It’s a good contract, but a bad implementation. Here, the infa- mous “Heisenbug” [URL 52] rears its ugly head. The programmer probably just made a simple typo—pop instead of top. While this is a simple and contrived example, side effects in assertions (or in any unexpected place in the code) can be very difﬁcult to diagnose.\n\nExercise 17: fromDesignbyContractonpage119 The classic examples of DBC (as in Exercises 14–16) show an implementation of an ADT (Abstract Data Type)—typically a stack or queue. But not many people really write these kinds of low-level classes.\n\nSo, for this exercise, design an interface to a kitchen blender. It will eventually be a Web-based, Internet-enabled, CORBA-ﬁed blender, but for now we just need the interface to control it. It has ten speed settings (0 means off). You can’t operate it empty, and you can change the speed only one unit at a time (that is, from 0 to 1, and from 1 to 2, not from 0 to 2).\n\nHere are the methods. Add appropriate pre- and postconditions and an invari- ant.\n\nint getSpeed() void setSpeed(int x) boolean isFull() void fill() void empty()\n\nAnswer 17: We’ll show the function signatures in Java, with the pre- and postconditions labeled as in iContract.\n\nFirst, the invariant for the class:\n\n/**\n\n@invariant getSpeed() > 0 * * @invariant getSpeed() >= 0 && * */ getSpeed() < 10\n\nimplies isFull()\n\n// Don’t run empty\n\n// Range check\n\nNext, the pre- and postconditions:\n\n289",
      "content_length": 1699,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 315,
      "content": "290\n\nAPPENDIX B ANSWERS TO EXERCISES\n\n/**\n\n@pre Math.abs(getSpeed() - x) <= 1 // Only change by one * @pre x >= 0 && x < 10 * @post getSpeed() == x */ // Range check // Honor requested speed\n\npublic void setSpeed(final int x)\n\n/**\n\n@pre !isFull() * @post isFull() */\n\n// Don’t fill it twice // Ensure it was done\n\nvoid fill()\n\n/**\n\n@pre isFull() * @post !isFull() */\n\n// Don’t empty it twice // Ensure it was done\n\nvoid empty()\n\nExercise 18: fromDesignbyContractonpage119 How many numbers are in the series\n\n?\n\nAnswer 18: enced a fencepost error.\n\nThere are 21 terms in the series. If you said 20, you just experi-\n\nExercise 19: fromAssertiveProgrammingonpage125 A quick reality check. Which of these “impossible” things can happen?\n\n1. A month with fewer than 28 days 2. stat(\".\",&sb) == -1 (that is, can’t access the current directory) 3. In C++: 4. A triangle with an interior angle sum 5. A minute that doesn’t have 60 seconds 6. In Java: (a + 1) <= a a = 2; b = 3; if (a + b != 5) exit(1);\n\nAnswer 19:\n\n1. September, 1752 had only 19 days. This was done to synchronize calen-\n\ndars as part of the Gregorian Reformation.\n\n2. The directory could have been removed by another process, you might not have permission to read it, &sb might be invalid—you get the picture.\n\n3. We sneakily didn’t specify the types of a and b. Operator overloading might have deﬁned +, =, or != to have unexpected behavior. Also, a and b may be aliases for the same variable, so the second assignment will overwrite the value stored in the ﬁrst.\n\n4. In non-Euclidean geometry, the sum of the angles of a triangle will not add\n\nup to\n\n. Think of a triangle mapped on the surface of a sphere.",
      "content_length": 1670,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 316,
      "content": "5. Leap minutes may have 61 or 62 seconds.\n\n6. Overﬂow may leave the result of a + 1 negative (this can also happen in\n\nC and C++).\n\nExercise 20: fromAssertiveProgrammingonpage125 Develop a simple assertion checking class for Java.\n\nAnswer 20: We chose to implement a very simple class with a single static method, TEST, that prints a message and a stack trace if the passed condition parameter is false.\n\npackage com.pragprog.util;\n\nimport java.lang.System; import java.lang.Thread;\n\n// for exit() // for dumpStack()\n\npublic class Assert {\n\n/** Write a message, print a stack trace and exit if\n\nour parameter is false. */\n\npublic static void TEST(boolean condition) {\n\nif (!condition) {\n\nSystem.out.println(\"==== Assertion Failed ====\"); Thread.dumpStack(); System.exit(1);\n\n}\n\n}\n\n// Testbed. If our argument is ’okay’, try an assertion that // succeeds, if ’fail’ try one that fails\n\npublic static final void main(String args[]) {\n\nif (args[0].compareTo(\"okay\") == 0) {\n\nTEST(1 == 1);\n\n} else if (args[0].compareTo(\"fail\") == 0) {\n\nTEST(1 == 2);\n\n} else {\n\nthrow new RuntimeException(\"Bad argument\");\n\n}\n\n}\n\n}\n\nExercise 21: fromWhentoUseExceptionsonpage128 While designing a new container class, you identify the following possible error conditions:\n\n1. No memory available for a new element in the add routine\n\n2. Requested entry not found in the fetch routine\n\n3. null pointer passed to the add routine\n\n291",
      "content_length": 1411,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 317,
      "content": "292\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nHow should each be handled? Should an error be generated, should an excep- tion be raised, or should the condition be ignored?\n\nAnswer 21: Running out of memory is an exceptional condition, so we feel that case (1) should raise an exception.\n\nFailure to ﬁnd an entry is probably quite a normal occurrence. The application that calls our collection class may well write code that checks to see if an entry is present before adding a potential duplicate. We feel that case (2) should just return an error.\n\nCase (3) is more problematic—if the value null is signiﬁcant to the application, then it may be justiﬁably added to the container. If, however, it makes no sense to store null values, an exception should probably be thrown.\n\nExercise 22: fromHowtoBalanceResourcesonpage136 Some C and C++ developers make a point of setting a pointer to NULL after they deallocate the memory it references. Why is this a good idea?\n\nAnswer 22: In most C and C++ implementations, there is no way of checking that a pointer actually points to valid memory. A common mistake is to deal- locate a block of memory and reference that memory later in the program. By then, the memory pointed to may well have been reallocated to some other pur- pose. By setting the pointer to NULL, the programmers hope to prevent these rogue references—in most cases, dereferencing a NULL pointer will generate a runtime error.\n\nExercise 23: fromHowtoBalanceResourcesonpage136 Some Java developers make a point of setting an object variable to NULL after they have ﬁnished using the object. Why is this a good idea?\n\nAnswer 23: By setting the reference to NULL, you reduce the number of point- ers to the referenced object by one. Once this count reaches zero, the object is eligible for garbage collection. Setting the references to NULL can be signiﬁ- cant for long-running programs, where the programmers need to ensure that memory utilization doesn’t increase over time.",
      "content_length": 1977,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 318,
      "content": "Exercise 24: fromDecouplingandtheLawofDemeteronpage143 We discussed the concept of physical decoupling in the box on page 142. Which of the following C++ header ﬁles is more tightly coupled to the rest of the system?\n\nperson1.h:\n\nperson2.h:\n\n#include \"date.h\"\n\nclass Date;\n\nclass Person1 { private:\n\nclass Person2 { private:\n\nDate myBirthdate;\n\nDate *myBirthdate;\n\npublic:\n\npublic:\n\nPerson1(Date &birthDate); // ...\n\nPerson2(Date &birthDate); // ...\n\nAnswer 24: A header ﬁle is supposed to deﬁne the interface between the corresponding implementation and the rest of the world. The header ﬁle itself has no need to know about the internals of the Date class—it merely needs to tell the compiler that the constructor takes a Date as a parameter. So, unless the header ﬁle uses Dates in inline functions, the second snippet will work ﬁne.\n\nWhat’s wrong with the ﬁrst snippet? On a small project, nothing, except that you are unnecessarily making everything that uses a Person1 class also in- clude the header ﬁle for Date. Once this kind of usage gets common in a project, you soon ﬁnd that including one header ﬁle ends up including most of the rest of the system—a serious drag on compilation times.\n\nExercise 25: fromDecouplingandtheLawofDemeteronpage143 For the example below and for those in Exercises 26 and 27, determine if the method calls shown are allowed according to the Law of Demeter. This ﬁrst one is in Java.\n\npublic void showBalance(BankAccount acct) {\n\nMoney amt = acct.getBalance(); printToScreen(amt.printFormat());\n\n}\n\nAnswer 25: The variable acct is passed in as a parameter, so the getBal- ance call is allowed. Calling amt.printFormat(), however, is not. We don’t “own” amt and it wasn’t passed to us. We could eliminate showBalance’s cou- pling to Money with something like this:\n\nvoid showBalance(BankAccount b) {\n\nb.printBalance();\n\n}\n\n293",
      "content_length": 1864,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 319,
      "content": "294\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 26: fromDecouplingandtheLawofDemeteronpage143 This example is also in Java.\n\npublic class Colada {\n\nprivate Blender myBlender; private Vector myStuff;\n\npublic Colada() {\n\nmyBlender = new Blender(); myStuff = new Vector();\n\n} private void doSomething() {\n\nmyBlender.addIngredients(myStuff.elements());\n\n}\n\n}\n\nAnswer 26: the calls to addIngredients and elements are allowed.\n\nSince Colada creates and owns both myBlender and myStuff,\n\nExercise 27: fromDecouplingandtheLawofDemeteronpage143 This example is in C++.\n\nvoid processTransaction(BankAccount acct, int) {\n\nPerson *who; Money amt;\n\namt.setValue(123.45); acct.setBalance(amt); who = acct.getOwner(); markWorkflow(who->name(), SET_BALANCE);\n\n}\n\nAnswer 27: In this case, processTransaction owns amt—it is created on the stack. acct is passed in, so both setValue and setBalance are allowed. But processTransaction does not own who, so the call who->name() is in violation. The Law of Demeter suggests replacing this line with\n\nmarkWorkflow(acct.name(), SET_BALANCE);\n\nThe code in processTransaction should not have to know which subobject within a BankAccount holds the name—this structural knowledge should not show through BankAccount’s contract. Instead, we ask the BankAccount for the name on the account. It knows where it keeps the name (maybe in a Person, in a Business, or in a polymorphic Customer object).",
      "content_length": 1415,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 320,
      "content": "Exercise 28: fromMetaprogrammingonpage149 Which of the following things would be better represented as code within a program, and which externally as metadata?\n\n1. Communication port assignments 2. An editor’s support for highlighting the syntax of various languages 3. An editor’s support for different graphic devices 4. A state machine for a parser or scanner 5. Sample values and results for use in unit testing\n\nAnswer 28: There are no deﬁnitive answers here—the questions were intended primarily to give you food for thought. However, this is what we think:\n\n1. Communication port assignments. Clearly, this information should be stored as metadata. But to what level of detail? Some Windows communi- cations programs let you select only baud rate and port (say COM1 to COM4). But perhaps you need to specify word size, parity, stop bits, and the duplex setting as well. Try to allow the ﬁnest level of detail where practical.\n\n2. An editor’s support for highlighting the syntax of various languages. This should be implemented as metadata. You wouldn’t want to have to hack code just because the latest version of Java introduced a new keyword.\n\n3. An editor’s support for different graphic devices. This would probably be difﬁcult to implement strictly as metadata. You would not want to burden your application with multiple device drivers only to select one at runtime. You could, however, use metadata to specify the name of the driver and dynamically load the code. This is another good argument for keeping the metadata in a human-readable format; if you use the program to set up a dysfunctional video driver, you may not be able to use the program to set it back.\n\n4. A state machine for a parser or scanner. This depends on what you are parsing or scanning. If you are parsing some data that is rigidly deﬁned by a standards body and is unlikely to change without an act of Congress, then hard coding it is ﬁne. But if you are faced with a more volatile situa- tion, it may be beneﬁcial to deﬁne the state tables externally.\n\n5. Sample values and results for use in unit testing. Most applications deﬁne these values inline in the testing harness, but you can get better ﬂexibility by moving the test data—and the deﬁnition of the acceptable results—out of the code itself.\n\n295",
      "content_length": 2294,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 321,
      "content": "296\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 29: fromIt’sJustaViewonpage164 Suppose you have an airline reservation system that includes the concept of a ﬂight:\n\npublic interface Flight {\n\n// Return false if flight full. public boolean addPassenger(Passenger p); public void addToWaitList(Passenger p); public int getFlightCapacity(); public int getNumPassengers();\n\n}\n\nIf you add a passenger to the wait list, they’ll be put on the ﬂight automatically when an opening becomes available.\n\nThere’s a massive reporting job that goes through looking for overbooked or full ﬂights to suggest when additional ﬂights might be scheduled. It works ﬁne, but it takes hours to run.\n\nWe’d like to have a little more ﬂexibility in processing wait-list passengers, and we’ve got to do something about that big report—it takes too long to run. Use the ideas from this section to redesign this interface.\n\nAnswer 29: We’ll take Flight and add some additional methods for main- taining two lists of listeners: one for wait-list notiﬁcation, and the other for full-ﬂight notiﬁcation.\n\npublic interface Passenger {\n\npublic void waitListAvailable();\n\n}\n\npublic interface Flight {\n\n... public void addWaitListListener(Passenger p); public void removeWaitListListener(Passenger p);\n\npublic void addFullListener(FullListener b); public void removeFullListener(FullListener b); ...\n\n}\n\npublic interface BigReport extends FullListener {\n\npublic void FlightFullAlert(Flight f);\n\n}\n\nIf we try to add a Passenger and fail because the ﬂight is full, we can, option- ally, put the Passenger on the wait list. When a spot opens up, waitList- Available will be called. This method can then choose to add the Passenger automatically, or have a service representative call the customer to ask if they are still interested, or whatever. We now have the ﬂexibility to perform different behaviors on a per-customer basis.\n\nNext, we want to avoid having the BigReport troll through tons of records look- ing for full ﬂights. By having BigReport registered as a listener on Flights,",
      "content_length": 2046,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 322,
      "content": "each individual Flight can report when it is full—or nearly full, if we want. Now users can get live, up-to-the-minute reports from BigReport instantly, without waiting hours for it to run as it did previously.\n\nExercise 30: fromBlackboardsonpage170 For each of the following applications, would a blackboard system be appropri- ate or not? Why?\n\n1. Image processing. You’d like to have a number of parallel processes grab chunks of an image, process them, and put the completed chunk back.\n\n2. Group calendaring. You’ve got people scattered across the globe, in dif- ferent time zones, and speaking different languages, trying to schedule a meeting.\n\n3. Network monitoring tool. The system gathers performance statistics and collects trouble reports. You’d like to implement some agents to use this information to look for trouble in the system.\n\nAnswer 30:\n\n1. Image processing. For simple scheduling of a workload among the paral- lel processes, a shared work queue may be more than adequate. You might want to consider a blackboard system if there is feedback involved—that is, if the results of one processed chunk affect other chunks, as in machine vision applications, or complex 3D image-warp transforms.\n\n2. Group calendaring. This might be a good ﬁt. You can post scheduled meetings and availability to the blackboard. You have entities functioning autonomously, feedback from decisions is important, and participants may come and go. You might want to consider partitioning this kind of blackboard system depending on who is searching: junior staff may care about only the im- mediate ofﬁce, human resources may want only English-speaking ofﬁces worldwide, and the CEO may want the whole enchilada.\n\nThere is also some ﬂexibility on data formats: we are free to ignore formats or languages we don’t understand. We have to understand different for- mats only for those ofﬁces that have meetings with each other, and we do not need to expose all participants to a full transitive closure of all possi- ble formats. This reduces coupling to where it is necessary, and does not constrain us artiﬁcially.\n\n3. Network monitoring tool. This is very similar to the mortgage/loan appli- cation program described on page 168. You’ve got trouble reports sent in by users and statistics reported automatically, all posting to the black- board. A human or software agent can analyze the blackboard to diagnose\n\n297",
      "content_length": 2412,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 323,
      "content": "298\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nnetwork failures: two errors on a line might just be cosmic rays, but 20,000 errors and you’ve got a hardware problem. Just as the detectives solve the murder mystery, you can have multiple entities analyzing and contributing ideas to solve the network problems.\n\nExercise 31: fromProgrammingbyCoincidenceonpage176 Can you identify some coincidences in the following C code fragment? Assume that this code is buried deep in a library routine.\n\nfprintf(stderr,\"Error, continue?\"); gets(buf);\n\nAnswer 31: There are several potential problems with this code. First, it assumes a tty environment. That may be ﬁne if the assumption is true, but what if this code is called from a GUI environment where neither stderr nor stdin is open?\n\nSecond, there is the problematic gets, which will write as many characters as it receives into the buffer passed in. Malicious users have used this failing to create buffer overrun security holes in many different systems. Never use gets().\n\nThird, the code assumes the user understands English.\n\nFinally, no one in their right mind would ever bury user interaction such as this in a library routine.\n\nExercise 32: fromProgrammingbyCoincidenceonpage176 This piece of C code might work some of the time, on some machines. Then again, it might not. What’s wrong?\n\n/* Truncate string to its last maxlen chars */\n\nvoid string_tail(char *string, int maxlen) {\n\nint len = strlen(string); if (len > maxlen) {\n\nstrcpy(string, string + (len - maxlen));\n\n}\n\n}\n\nAnswer 32: It might happen to work on some architectures, but only by coincidence.\n\nPOSIX strcpy isn’t guaranteed to work for overlapping strings.",
      "content_length": 1667,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 324,
      "content": "Exercise 33: fromProgrammingbyCoincidenceonpage177 This code comes from a general-purpose Java tracing suite. The function writes a string to a log ﬁle. It passes its unit test, but fails when one of the Web developers uses it. What coincidence does it rely on?\n\npublic static void debug(String s) throws IOException { FileWriter fw = new FileWriter(\"debug.log\", true); fw.write(s); fw.flush(); fw.close();\n\n}\n\nAnswer 33: It won’t work in an applet context with security restrictions against writing to the local disk. Again, when you have a choice of running in GUI contexts or not, you may want to check dynamically to see what the current environment is like. In this case, you may want to put a log ﬁle some- where other than the local disk if it isn’t accessible.\n\nExercise 34: fromAlgorithmSpeedonpage183 We have coded a set of simple sort routines, which can be downloaded from our Web site (www.pragmaticprogrammer.com). Run them on various machines available to you. Do your ﬁgures follow the expected curves? What can you deduce about the relative speeds of your machines? What are the effects of various compiler optimization settings? Is the radix sort indeed linear?\n\nAnswer 34: Clearly, we can’t give any absolute answers to this exercise. How- ever, we can give you a couple of pointers.\n\nIf you ﬁnd that your results don’t follow a smooth curve, you might want to check to see if some other activity is using some of your processor’s power. You probably won’t get good ﬁgures on a multiuser system, and even if you are the only user you may ﬁnd that background processes periodically take cycles away from your programs. You might also want to check memory: if the application starts using swap space, performance will nose dive.\n\nIt is interesting to experiment with different compilers and different optimiza- tion settings. We found some that pretty startling speed-ups were possible by enabling aggressive optimization. We also found that on the wider RISC archi- tectures the manufacturer’s compilers often outperformed the more portable GCC. Presumably, the manufacturer is privy to the secrets of efﬁcient code generation on these machines.\n\n299",
      "content_length": 2168,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 325,
      "content": "300\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nExercise 35: fromAlgorithmSpeedonpage183 The routine below prints out the contents of a binary tree. Assuming the tree is balanced, roughly how much stack space will the routine use while print- ing a tree of 1,000,000 elements? (Assume that subroutine calls impose no signiﬁcant stack overhead.)\n\nvoid printTree(const Node *node) {\n\nchar buffer[1000];\n\nif (node) {\n\nprintTree(node->left);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nprintTree(node->right);\n\n}\n\n}\n\nAnswer 35: The printTree routine uses about 1,000 bytes of stack space for the buffer variable. It calls itself recursively to descend through the tree, and each nested call adds another 1,000 bytes to the stack. It also calls itself when it gets to the leaf nodes, but exits immediately when it discovers that the pointer passed in is NULL. If the depth of the tree is , the maximum stack requirement is therefore roughly\n\n.\n\nA balanced binary tree holds twice as many elements at each level. A tree of , elements. Our million-element , or holds depth , or 20 levels. tree will therefore need\n\nWe’d therefore expect our routine to use roughly 21,000 bytes of stack.\n\nExercise 36: fromAlgorithmSpeedonpage183 Can you see any way to reduce the stack requirements of the routine in Exer- cise 35 (apart from reducing the size of the buffer)?\n\nAnswer 36: A couple of optimizations come to mind. First, the printTree routine calls itself on leaf nodes, only to exit because there are no children. That call increases the maximum stack depth by about 1,000 bytes. We can also eliminate the tail recursion (the second recursive call), although this won’t affect the worst-case stack usage.\n\nwhile (node) {\n\nif (node->left) printTree(node->left);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nnode = node->right;\n\n}",
      "content_length": 1815,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 326,
      "content": "The biggest gain, however, comes from allocating just a single buffer, shared by all invocations of printTree. Pass this buffer as a parameter to the recur- sive calls, and only 1,000 bytes will be allocated, regardless of the depth of recursion.\n\nvoid printTreePrivate(const Node *node, char *buffer) {\n\nif (node) {\n\nprintTreePrivate(node->left, buffer);\n\ngetNodeAsString(node, buffer); puts(buffer);\n\nprintTreePrivate(node->right, buffer);\n\n}\n\n}\n\nvoid newPrintTree(const Node *node) {\n\nchar buffer[1000];\n\nprintTreePrivate(node, buffer);\n\n}\n\nExercise 37: fromAlgorithmSpeedonpage183 On page 180, we claimed that a binary chop is\n\n. Can you prove this?\n\nAnswer 37: There are a couple of ways of getting there. One is to turn the problem on its head. If the array has just one element, we don’t iterate around the loop. Each additional iteration doubles the size of the array we can search. The general formula for the array size is therefore is the number of iterations. If you take logs to the base 2 of each side, you get\n\n, where\n\n, which by the deﬁnition of logs becomes\n\n.\n\nExercise 38: fromRefactoringonpage188 The following code has obviously been updated several times over the years, but the changes haven’t improved its structure. Refactor it.\n\nif (state == TEXAS) {\n\nrate = TX_RATE; amt = base * TX_RATE; calc = 2*basis(amt) + extra(amt)*1.05;\n\n} else if ((state == OHIO) || (state == MAINE)) { rate = (state == OHIO) ? OH_RATE : ME_RATE; amt = base * rate; calc = 2*basis(amt) + extra(amt)*1.05; if (state == OHIO)\n\npoints = 2;\n\n} else {\n\nrate = 1; amt = base; calc = 2*basis(amt) + extra(amt)*1.05;\n\n}\n\n301",
      "content_length": 1620,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 327,
      "content": "302\n\nAPPENDIX B ANSWERS TO EXERCISES\n\nAnswer 38: We might suggest a fairly mild restructuring here: make sure that every test is performed just once, and make all the calculations common. If the expression 2*basis(...)*1.05 appears in other places in the program, we should probably make it a function. We haven’t bothered here.\n\nWe’ve added a rate_lookup array, initialized so that entries other than Texas, Ohio, and Maine have a value of 1. This approach makes it easy to add values for other states in the future. Depending on the expected usage pattern, we might want to make the points ﬁeld an array lookup as well.\n\nrate = rate_lookup[state];\n\namt = base * rate; calc = 2*basis(amt) + extra(amt)*1.05;\n\nif (state == OHIO)\n\npoints = 2;\n\nExercise 39: fromRefactoringonpage188 The following Java class needs to support a few more shapes. Refactor the class to prepare it for the additions.\n\npublic class Shape {\n\npublic static final int SQUARE public static final int CIRCLE public static final int RIGHT_TRIANGLE = 3;\n\n= 1; = 2;\n\nprivate int private double size;\n\nshapeType;\n\npublic Shape(int shapeType, double size) {\n\nthis.shapeType = shapeType; this.size\n\n= size;\n\n}\n\n// ... other methods ...\n\npublic double area() { switch (shapeType) { case SQUARE: case CIRCLE: case RIGHT_TRIANGLE: return size*size/2.0; } return 0;\n\nreturn size*size; return Math.PI*size*size/4.0;\n\n}\n\n}",
      "content_length": 1381,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 328,
      "content": "Answer 39: When you see someone using enumerated types (or their equiv- alent in Java) to distinguish between variants of a type, you can often improve the code by subclassing:\n\npublic class Shape {\n\nprivate double size;\n\npublic Shape(double size) {\n\nthis.size = size;\n\n}\n\npublic double getSize() { return size; }\n\n}\n\npublic class Square extends Shape {\n\npublic Square(double size) {\n\nsuper(size);\n\n}\n\npublic double area() {\n\ndouble size = getSize(); return size*size;\n\n}\n\n}\n\npublic class Circle extends Shape {\n\npublic Circle(double size) {\n\nsuper(size);\n\n}\n\npublic double area() {\n\ndouble size = getSize(); return Math.PI*size*size/4.0;\n\n}\n\n} // etc...\n\nExercise 40: fromRefactoringonpage189 This Java code is part of a framework that will be used throughout your project. Refactor it to be more general and easier to extend in the future.\n\npublic class Window {\n\npublic Window(int width, int height) { ... }\n\npublic void setSize(int width, int height) { ... }\n\npublic boolean overlaps(Window w) { ... }\n\npublic int getArea() { ... }\n\n}\n\nAnswer 40: This case is interesting. At ﬁrst sight, it seems reasonable that a window should have a width and a height. However, consider the future. Let’s imagine that we want to support arbitrarily shaped windows (which will be difﬁcult if the Window class knows all about rectangles and their properties).\n\nWe’d suggest abstracting the shape of the window out of the Window class itself.\n\n303",
      "content_length": 1435,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 329,
      "content": "304\n\nAPPENDIX B ANSWERS TO EXERCISES\n\npublic abstract class Shape {\n\n// ...\n\npublic abstract boolean overlaps(Shape s); public abstract int getArea();\n\n}\n\npublic class Window {\n\nprivate Shape shape;\n\npublic Window(Shape shape) {\n\nthis.shape = shape; ...\n\n}\n\npublic void setShape(Shape shape) {\n\nthis.shape = shape; ...\n\n}\n\npublic boolean overlaps(Window w) { return shape.overlaps(w.shape);\n\n}\n\npublic int getArea() {\n\nreturn shape.getArea();\n\n}\n\n}\n\nNote that in this approach we’ve used delegation rather than subclassing: a window is not a “kind-of” shape—a window “has-a” shape. It uses a shape to do its job. You’ll often ﬁnd delegation useful when refactoring.\n\nWe could also have extended this example by introducing a Java interface that speciﬁed the methods a class must support to support the shape functions. This is a good idea. It means that when you extend the concept of a shape, the compiler will warn you about classes that you have affected. We recommend using interfaces this way when you delegate all the functions of some other class.\n\nExercise 41: fromCodeThat’sEasytoTestonpage197 Design a test jig for the blender interface described in the answer to Exercise 17 on page 289. Write a shell script that will perform a regression test for the blender. You need to test basic functionality, error and boundary conditions, and any contractual obligations. What restrictions are placed on changing the speed? Are they being honored?",
      "content_length": 1450,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 330,
      "content": "Answer 41: First, we’ll add a main to act as a unit test driver. It will accept a very small, simple language as an argument: “E” to empty the blender, “F” to ﬁll it, digits 0-9 to set the speed, and so on.\n\npublic static void main(String args[]) {\n\n// Create the blender to test dbc_ex blender = new dbc_ex();\n\n// And test it according to the string on standard input try {\n\nint a; char c;\n\nwhile ((a = System.in.read()) != -1) {\n\nc = (char)a;\n\nif (Character.isWhitespace(c)) {\n\ncontinue;\n\n}\n\nif (Character.isDigit(c)) {\n\nblender.setSpeed(Character.digit(c, 10));\n\n} else {\n\nswitch (c) {\n\ncase ’F’: blender.fill(); break; case ’E’: blender.empty(); break;\n\ncase ’s’: System.out.println(\"SPEED: \" +\n\nblender.getSpeed());\n\nbreak;\n\ncase ’f’: System.out.println(\"FULL \" +\n\nblender.isFull());\n\nbreak;\n\ndefault: throw new RuntimeException( \"Unknown Test directive\");\n\n}\n\n}\n\n}\n\n} catch (java.io.IOException e) {\n\nSystem.err.println(\"Test jig failed: \" + e.getMessage());\n\n}\n\nSystem.err.println(\"Completed blending n\"); System.exit(0);\n\n}\n\nNext comes the shell script to drive the tests.\n\n305",
      "content_length": 1085,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 331,
      "content": "306\n\nAPPENDIX B ANSWERS TO EXERCISES\n\n#!/bin/sh\n\nCMD=\"java dbc.dbc_ex\" failcount=0\n\nexpect_okay() {\n\nif echo \"$*\" | $CMD #>/dev/null 2>&1 then : else\n\necho \"FAILED! $*\" failcount=‘expr $failcount + 1‘\n\nfi\n\n}\n\nexpect_fail() {\n\nif echo \"$*\" | $CMD >/dev/null 2>&1 then\n\necho \"FAILED! (Should have failed): $*\" failcount=‘expr $failcount + 1‘\n\nfi\n\n}\n\nreport() {\n\nif [ $failcount -gt 0 ] then\n\necho -e \" n n*** FAILED $failcount TESTS n\" exit 1 # In case we are part of something larger\n\nelse\n\nexit 0 # In case we are part of something larger\n\nfi\n\n}\n\n# # Start the tests # expect_okay F123456789876543210E # Should run thru # Fails, speed too high expect_fail F5 expect_fail 1 # Fails, empty expect_fail F10E1 # Fails, empty expect_fail F1238 # Fails, skips expect_okay FE expect_fail F1E expect_okay F10E # Should be ok report\n\n# Never turn on # Emptying while running\n\n# Report results\n\nThe tests check to see if illegal speed changes are detected, if you try to empty the blender while running, and so on. We put this in the makeﬁle so we can compile and run the regression test by simply typing\n\n% make % make test\n\nNote that we have the test exit with 0 or 1 so we can use this as part of a larger test as well.\n\nThere was nothing in the requirements that spoke of driving this component via a script, or even using a language. End users will never see it. But we have a powerful tool that we can use to test our code, quickly and exhaustively.",
      "content_length": 1445,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 332,
      "content": "Exercise 42: fromTheRequirementsPitonpage211 Which of the following are probably genuine requirements? Restate those that are not to make them more useful (if possible).\n\n1. The response time must be less than 500 ms.\n\n2. Dialog boxes will have a gray background.\n\n3. The application will be organized as a number of front-end processes and\n\na back-end server.\n\n4. If a user enters non-numeric characters in a numeric ﬁeld, the system will\n\nbeep and not accept them.\n\n5. The application code and data must ﬁt within 256kB.\n\nAnswer 42:\n\n1. This statement sounds like a real requirement: there may be constraints\n\nplaced on the application by its environment.\n\n2. Even though this may be a corporate standard, it isn’t a requirement. It would be better stated as “The dialog background must be conﬁgurable by the end user. As shipped, the color will be gray.” Even better would be the broader statement “All visual elements of the application (colors, fonts, and languages) must be conﬁgurable by the end user.”\n\n3. This statement is not a requirement, it’s architecture. When faced with something like this, you have to dig deep to ﬁnd out what the user is thinking.\n\n4. The underlying requirement is probably something closer to “The system will prevent the user from making invalid entries in ﬁelds, and will warn the user when these entries are made.”\n\n5. This statement is probably a hard requirement.\n\nA solution to the Four Posts puzzle posed on page 213.\n\n307",
      "content_length": 1465,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 333,
      "content": "This page intentionally left blank",
      "content_length": 34,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 334,
      "content": "Index A\n\nAccessor function, 31 ACM, see Association for Computing\n\nMachinery Active code generator, 104 Activity diagram, 150 Advanced C++ Programming Styles and\n\nIdioms, 265\n\nAdvanced Programming in the Unix Environment, 264\n\nAegis transaction-based conﬁguration management, 246, 271\n\nAgent, 76, 117, 297 Algorithm\n\nbinary chop, 180 choosing, 182 combinatoric, 180 divide-and-conquer, 180 estimating, 177, 178 linear, 177\n\nnotation, 178, 181\n\nquicksort, 180 runtime, 181 sublinear, 177 Allocations, nesting, 131 Analysis Patterns, 264 Anonymity, 258 AOP, see Aspect-Oriented Programming Architecture\n\ndeployment, 156 ﬂexibility, 46 prototyping, 55 temporal decoupling, 152 Art of Computer Programming, 183 Artiﬁcial intelligence, marauding, 26 Aspect-Oriented Programming (AOP),\n\n39, 273 Assertion, 113, 122, 175 side effects, 124\n\n309\n\nturning off, 123\n\nAssociation for Computing Machinery\n\n(ACM), 262\n\nCommunications of the ACM, 263 SIGPLAN, 263 Assumptions, testing, 175 “at” command, 231 Audience, 21\n\nneeds, 19 auto_ptr, 134 Automation, 230\n\napproval procedures, 235 build, 88, 233 compiling, 232 cron, 231 documentation, 251 scripts, 234 team, 229 testing, 29, 238 Web site generation, 235\n\nawk, 99\n\nB\n\nBackus-Naur Form (BNF), 59n Base class, 112 bash shell, 80, 82n Bean, see Enterprise Java Beans (EJB) Beck, Kent, 194, 258 Beowulf project, 268 “Big ” notation, 177 “Big picture”, 8 Binary chop, 97, 180 Binary format, 73\n\nproblems parsing, 75\n\nbison, 59, 269 BIST, see Built-In Self Test Blackboard system, 165\n\npartitioning, 168 workﬂow, 169",
      "content_length": 1552,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 335,
      "content": "310\n\nINDEX\n\nBlender example\n\ncontract for, 119, 289 regression test jig, 305 workﬂow, 151\n\nBNF, see Backus-Naur Form (BNF) Boiled frog, 8, 175, 225 Boundary condition, 173, 243 Brain, Marshall, 265 Branding, 226 Brant, John, 268 “Broken Window Theory”, 5 vs. stone soup, 9\n\nBrooks, Fred, 264 Browser, class, 187 Browser, refactoring, 187, 268 Bug, 90\n\nfailed contract as, 111 see also Debugging; Error\n\nBuild\n\nautomation, 88, 233 dependencies, 233 ﬁnal, 234 nightly, 231 refactoring, 187\n\nBuilt-In Self Test (BIST), 189 Business logic, 146 Business policy, 203\n\nC\n\nC language\n\nassertions, 122 DBC, 114 duplication, 29 error handling, 121 error messages, 115 macros, 121 Object Pascal interface, 101\n\nC++ language, 46\n\nassertions, 122 auto_ptr, 134 books, 265 DBC, 114 decoupling, 142 DOC++, 251, 269 duplication, 29 error messages, 115 exceptions, 132 unit tests, 193\n\nCaching, 31\n\nCall, routine, 115, 173 Cascading Style Sheets (CSS), 253 Cat\n\nblaming, 3 herding, 224 Schrödinger’s, 47\n\nCatalyzing change, 8 Cathedrals, xx Cetus links, 265 Change, catalyzing, 8 Christiansen, Tom, 81 Class\n\nassertions, 113 base, 112 coupling, 139, 142 coupling ratios, 242 encapsulating resource, 132 invariant, 110, 113 number of states, 245 resource allocation, 132 subclass, 112 wrapper, 132, 133, 135, 141\n\nClass browser, 187 ClearCase, 271 Cockburn, Alistair, xxiii, 205, 264, 272 Code generator, 28, 102\n\nactive, 104 makeﬁles, 232 parsers, 105 passive, 103 Code proﬁler, 182 Code reviews, 33, 236 Coding\n\nalgorithm speed, 177 comments, 29, 249 coupled, 130 coverage analysis, 245 database schema, 104 defensive, 107 and documentation, 29, 248 estimating, 68 exceptions, 125 implementation, 173 iterative, 69 “lazy”, 111 metrics, 242 modules, 138 multiple representations, 28 orthogonality, 34, 36, 40",
      "content_length": 1791,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 336,
      "content": "ownership, 258 prototypes, 55 server code, 196 “shy”, 40, 138 speciﬁcations, 219 tracer bullets, 49–51 unit testing, 190, 192 see also Coupled code; Decoupled code; Metadata; Source code control system (SCCS)\n\nCohesion, 35 COM, see Component Object Model Combinatorial explosion, 140, 167 Combinatoric algorithm, 180 Command shell, 77 bash, 80 Cygwin, 80 vs. GUI, 78 UWIN, 81 Windows, 80 Comment, 29, 249\n\navoiding duplication, 29 DBC, 113 parameters, 250 types of, 249 unnecessary, 250 see also Documentation\n\nCommon Object Request Broker\n\n(CORBA), 29, 39, 46\n\nEvent Service, 160\n\nCommunicating, 18\n\naudience, 19, 21 duplication, 32 e-mail, 22 and formal methods, 221 presentation, 20 style, 20 teams, 225 users, 256 writing, 18\n\nCommunications of the ACM, 263 Comp.object FAQ, 272 Compiling, 232\n\ncompilers, 267 DBC, 113 warnings and debugging, 92\n\nComponent Object Model (COM), 55 Component-based systems, see Modular system\n\nINDEX\n\n311\n\nConcurrency, 150\n\ndesign, 154 interfaces, 155 and Programming by Coincidence,\n\n154\n\nrequirements analysis of, 150 workﬂow, 150\n\nConcurrent Version System (CVS), 271 Conﬁguration\n\ncooperative, 148 dynamic, 144 metadata, 147\n\nConﬁguration management, 86, 271 Constantine, Larry L., 35 Constraint management, 213 Constructor, 132\n\ninitialization, 155 Contact, authors’ e-mail, xxiii Context, use instead of globals, 40 Contract, 109, 174\n\nsee also Design by contract (DBC)\n\nController (MVC), 162 Coplien, Jim, 265 CORBA, see Common Object Request\n\nBroker\n\nCoupled code, 130\n\ncoupling ratios, 242 minimizing, 138, 158 performance, 142 temporal coupling, 150 see also Decoupled code\n\nCoverage analysis, 245 Cox, Brad J., 189n Crash, 120 Critical thinking, 16 cron, 231 CSS, see Cascading Style Sheets CVS, see Concurrent Version System Cygwin, 80, 270\n\nD\n\nData\n\nblackboard system, 169 caching, 31 dictionary, 144 dynamic data structures, 135 global, 40 language, 60 normalizing, 30",
      "content_length": 1917,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 337,
      "content": "312\n\nINDEX\n\nreadable vs. understandable, 75 test, 100, 243 views, 160 visualizing, 93 see also Metadata\n\nData Display Debugger (DDD), 93, 268 Database\n\nactive code generator, 104 schema, 105f, 141, 144 schema maintenance, 100\n\nDBC, see Design by contract DDD, see Data Display Debugger Deadline, 6, 246 Deadlock, 131 Debugging, 90\n\nassertions, 123 binary search, 97 bug location, 96 bug reproduction, 93 checklist, 98 compiler warnings and, 92 corrupt variables, 95 “Heisenbug”, 124 rubber ducking, 95 and source code branching, 87 surprise bug, 97 and testing, 92, 195 time bomb, 192 tracing, 94 view, 164 visualizing data, 93\n\nDecision making, 46 Decoupled code, 38, 40 architecture, 152 blackboard system, 166 Law of Demeter, 140 metadata, 145 minimizing coupling, 138 modular testing, 244 physical decoupling, 142 temporal coupling, 150 workﬂow, 150 see also Coupled code\n\nDefensive coding, 107 Delegation, 304 Delphi, 55\n\nsee also Object Pascal\n\nDemeter project, 274 Demeter, Law of, 140\n\nDependency, reducing, see Modular system; Orthogonality\n\nDeployment, 156 Deployment descriptor, 148 Design\n\naccessor functions, 31 concurrency, 154 context, 174 deployment, 156 design/methodology testing, 242 metadata, 145 orthogonality, 34, 37 physical, 142 refactoring, 186 using services, 154\n\nDesign by contract (DBC), 109, 155\n\nand agents, 117 assertions, 113 class invariant, 110 as comments, 113 dynamic contracts, 117 iContract, 268 language support, 114 list insertion example, 110 pre- and postcondition, 110, 113,\n\n114\n\npredicates, 110 unit testing, 190\n\nDesign Patterns, 264\n\nobserver, 158 singleton, 41 strategy, 41\n\nDestructor, 132 Detectives, 165 Development tree, 87 Development, iterative, 69 Divide-and-conquer algorithm, 180 DOC++ documentation generator, 251,\n\n269\n\nDocBook, 254 Documentation\n\nautomatic updating, 251 and code, 29, 248 comments, 29, 113, 249, 251 executable, 251 formats, 253 HTML, 101 hypertext, 210 internal/external, 248",
      "content_length": 1954,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 338,
      "content": "invariant, 117 mark-up languages, 254 orthogonality, 42 outline, 18 requirements, 204 technical writers, 252 word processors, 252, 254 writing speciﬁcations, 218 see also Comment; Web\n\ndocumentation\n\nDodo, 148 Domain, problem, 58, 66 Don’t repeat yourself, see DRY\n\nprinciple\n\nDownloading source code, see Example\n\ncode\n\nDr. Dobbs Journal, 263 DRY principle, 27, 29, 42 see also Duplication Duck, rubber, see Rubber duck Dumpty, Humpty, xxii, 165 Duplication, 26\n\ncode generators avoid, 28 and code reviews, 33 design errors, 30 documentation and code, 29 DRY principle, 27, 29 interdeveloper, 32 in languages, 29 multiple representations, 28 teams, 226 under time pressure, 32 types of, 27\n\nDynamic conﬁguration, 144 Dynamic data structure, 135 Dynamics of Software Development, 264\n\nE\n\nE-mail, 22\n\naddress for feedback, xxiii\n\nEditor, 82\n\nauto-indenting, 85 cursor movement, 84 features, 83 generating code, 103 how many to learn, 82 template, 84 types of, 266 Windows notepad, 84\n\nINDEX\n\nEffective C++, 265 Eiffel, 109, 114, 267 EJB, see Enterprise Java Beans elvis editor, 267 Emacs editor, 84, 266\n\nViper vi emulator, 267 Embedded mini-language, 62, 145 Embellishment, 11 Encapsulation, object, 127, 158 Eno, Brian, 205 Enterprise Java Beans (EJB), 39, 147 Entropy, 4 Error\n\nDBC messages, 115 design, 30 domain-speciﬁc, 59 early crash, 120 log messages, 196 orthogonality, 41 testing, 240, 247 see also Exception\n\nError handler, 127 Estimating, 64\n\naccuracy, 64 algorithms, 177, 178 iterative, 69 models, 66 problem domain, 66 project schedules, 68 records, 68 testing, 182 Eton College, xxi Event, 157 Event channel, 160 Example code\n\nadd logging, 40 airline reservations, 164, 296 assert macro, 122 auto_ptr example, 134 bad resource balancing, 129, 130 downloading, xxiii exception error handling, 125 good resource balancing, 131 JavaDoc example, 250 method chaining, 139 normalized class, 31 open password ﬁle, 126 open user ﬁle, 127\n\n313",
      "content_length": 1948,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 339,
      "content": "314\n\nINDEX\n\nresources and exceptions, 132,\n\n133\n\nside effect, 124 spaghetti error handling, 125 square root, 190 string parsing with\n\nStringTokenizer, 156\n\nstring parsing with strtok, 155 unnormalized class, 30\n\nExample code by name\n\nAOP, 40 Misc.java, 156 assert, 122 bad_balance.c, 129, 130 balance.cc, 134 balance.c, 131–133 class Line, 30, 31 exception, 125 findPeak, 250 interface Flight, 164, 296 misc.c, 155 openpasswd.java, 126 openuserfile.java, 127 plotDate, 139 side_effect, 124 spaghetti, 125 sqrt, 190 Exception, 121\n\neffects of, 127 and error handlers, 127 missing ﬁles, 126 resource balancing, 132 when to use, 125\n\nExcuses, 3 Executable document, 251 expect, 269 Expert, see Guru Expiring asset, 12 eXtensible Style Language (XSL), 253 Extinction, 148 eXtreme Programming, 238n, 258, 272\n\nF\n\nFeature creep, 10 Feedback, e-mail address, xxiii File\n\nexception, 126 header, 29 implementation, 29\n\nlog, 196 makeﬁle, 232 source, 103 Final build, 234 Fish, dangers of, 34 Flexibility, 46 Formal methods, 220, 221 Four Posts Puzzle, 213 Fowler, Martin, xxiii, 186, 273 Free Software Foundation, see GNU\n\nProject\n\nFrog, boiled, see Boiled frog Function\n\naccessor, 31 Law of Demeter for similar, 41\n\ns, 140\n\nG\n\nGamma, Erich, 194 Garbage collection, 134 Gardening metaphor, 184 Gehrke, Peter, xxiv Glass, Robert, 221, 236 Global variables, 40, 130, 154 Glossary, project, 210 GNU Project, 274\n\nC/C++ compiler, 267 General Public License (GPL), 80 GNU Image Manipulation Program\n\n(GIMP), 274 SmallEiffel, 267\n\n“Good-enough software”, see Software,\n\nquality\n\nGordian knot, 212 Goto, 127 GUI system\n\nvs. command shell, 78 interface, 78 testing, 244\n\nGuru, 17, 198\n\nH\n\nHash, secure, 74 Header ﬁle, 29 “Heisenbug”, 124, 289 Helicopter, 34n Hopper, Grace, 8n, 90 “Hot-key” sequence, 196",
      "content_length": 1786,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 340,
      "content": "HTTP Web server, 196 Human factors, 241 Humpty Dumpty, xxii, 165 Hungarian notation, 249 Hungry consumer model, 153 Hypertext document, 210\n\nI\n\niContract, 110, 114, 268 IDE, see Integrated Development\n\nEnvironment IEEE Computer Society, 262 IEEE Computer, 262 IEEE Software, 263 Imperative language, 60 Implementation\n\naccidents, 173 coding, 173 speciﬁcations, 219 Imposed duplication, 28 Inadvertent duplication, 30 Indentation, automatic, 85 Independence, see Orthogonality Infrastructure, 37 Inheritance, 111\n\nassertions, 113 fan-in/fan-out, 242\n\nInner tennis, 215 Inspection, code, see Code reviews Insure++, 136 Integrated circuit, 189n Integrated Development Environment\n\n(IDE), 72, 232\n\nIntegration platform, 50 Integration testing, 239 Interface\n\nblackboard system, 168 C/Object Pascal, 101 concurrency, 155 error handler, 128 GUI, 78 prototyping, 55 user, 203\n\nInvariant, 110, 113, 155\n\nloop, 116 semantic, 116, 135\n\nISO9660 format, 233n Iterative development, 69\n\nINDEX\n\nJ\n\nJacobson, Ivar, 204 Jargon, xxii, 210 Jargon ﬁle, 273 Java, 46, 267\n\ncode generation, 232 DBC, 114 Enterprise Java Beans, 39, 147 error messages, 115 exceptions, 121 iContract, 110, 114, 268 javaCC, 59, 269 JavaDoc, 248, 251 JavaSpaces, 166, 273 JUnit, 195 multithreaded programming, 154 property access, 100 property ﬁles, 145 resource balancing, 134 RMI, 128 string parser, 156 tree view, 161 unit tests, 193 and Windows shells, 81\n\nJavaDoc, see Java\n\nK\n\nK Desktop Environment, 273 Kaizen, xxi, 14\n\nsee also Knowledge portfolio\n\nKernighan, Brian, 99 Keybinding, 82 Kirk, James T., 26 Knowledge\n\nproducers and consumers, 166\n\nKnowledge portfolio, 12 building, 13 critical thinking, 16 learning and reading, 14 researching, 15 Knuth, Donald, 183, 248 Korn, David, 81 Kramer, Reto, xxiv Kruchten, Phillipe, 227n\n\nL\n\nLakos, John, xxiv, 9, 142, 265 Lame excuses, 3\n\n315",
      "content_length": 1850,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 341,
      "content": "316\n\nINDEX\n\nLanguage, programming\n\nconversions, 103, 105 DBC, 114 domain, 57 duplication in, 29 learning, 14 prototypes, 55 scripting, 55, 145 speciﬁcation, 58, 62 text manipulation, 99 see also Mini-language\n\nLarge-Scale C++ Software Design, 142,\n\n265 LATEX system, 103 Law of Demeter, 140 Lawns, care of, xxi Layered design, 37 Layered system, see Modular system “lazy” code, 111 Lex and Yacc, 59 Librarian, see Project librarian Library code, 39 Linda model, 167 Linear algorithms, 177 Linux, 15, 254, 265 Liskov Substitution Principle, 111 Listening, 21 Literate programming, 248 Logging, 39, 196\n\nsee also Tracing\n\nLookup table, 104 Loop\n\nnested, 180 simple, 180\n\nLoop invariant, 116\n\nM\n\nMacro, 78, 86\n\nassertions, 122 documentation, 252 error handling, 121\n\nMaintenance, 26\n\nimperative languages, 61\n\nMakeﬁle, 232\n\nrecursive, 233\n\nManaging expectations, 256 Mark-up language, 254 Martin, Robert C., 273\n\nMcCabe Cyclomatic Complexity Metric,\n\n242\n\nMember variables, see Accessor\n\nfunctions Memory allocation, 135 Metadata, 144, 203\n\nbusiness logic, 146 conﬁguration, 147 controlling transactions, 39 decoupled code, 145 and formal methods, 221 in plain text, 74\n\nMetric, 242 Meyer, Bertrand, 31n, 109, 184, 264 Meyer, Scott, 265 Microsoft Visual C++, 198 Microsoft Windows, 46 Mini-language, 59\n\ndata language, 60 embedded, 62 imperative, 60 parsing, 62 stand-alone, 62\n\nMixing board, 205 MKS Source Integrity, 271 Model, 160\n\ncalculations, 67 components and parameters, 66 and estimating, 66 executable documents, 251 view, 162\n\nModel-view-controller (MVC), 38, 160 Modular system, 37 coding, 138 prototyping, 55 resource allocation, 135 reversibility, 45 testing, 41, 190, 244\n\nMore Effective C++, 265 Mozilla, 273 Multithreaded programming, 154 MVC, see Model-view-controller The Mythical Man Month, 264\n\nN\n\nName, variable, 249 Nana, 114, 268 Nest allocations, 131 Nested loop, 180",
      "content_length": 1889,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 342,
      "content": "Netscape, 145, 273 Newsgroup, 15, 17, 33 Nonorthogonal system, 34 Normalize, 30 Novobilski, Andrew J., 189n\n\nO\n\nnotation, 178, 181\n\nObject\n\ncoupling, 140n destruction, 133, 134 persistence, 39 publish/subscribe protocol, 158 singleton, 41 valid/invalid state, 154 viewer, 163\n\nObject Management Group (OMG), 270 Object Pascal, 29\n\nC interface, 101\n\nObject-Oriented Programming, 189n Object-Oriented Software Construction,\n\n264 Obsolescence, 74 OLTP, see On-Line Transaction\n\nProcessing system\n\nOMG, see Object Management Group On-Line Transaction Processing system\n\n(OLTP), 152\n\nOptions, providing, 3 Ordering, see Workﬂow Orthogonality, 34\n\ncoding, 34, 36, 40 design, 37 documentation, 42 DRY principle, 42 nonorthogonal system, 34 productivity, 35 project teams, 36, 227 testing, 41 toolkits & libraries, 39 see also Modular system\n\nOver embellishment, 11\n\nP\n\nPain management, 185 paint() method, 173 Painting, 11 Papua New Guinea, 16\n\nINDEX\n\nParallel programming, 150 Parrots, killer, see Branding Parsing, 59\n\ncode generators, 105 log messages, 196 mini-language, 62 strings, 155 Partitioning, 168 Pascal, 29 Passive code generator, 103 Performance testing, 241 Perl, 55, 62, 99\n\nC/Object Pascal interface, 101 database schema generation, 100 home page, 267 Java property access, 100 power tools, 270 test data generation, 100 testing, 197 and typesetting, 100 Unix utilities in, 81 web documentation, 101\n\nPerl Journal, 263 Persistence, 39, 45 Petzold, Charles, 265 Pike, Rob, 99 Pilot\n\nlanding, handling, etc., 217 who ate ﬁsh, 34\n\nPlain text, 73\n\nvs. binary format, 73 drawbacks, 74 executable documents, 251 leverage, 75 obsolescence, 74 and easier testing, 76 Unix, 76 Polymorphism, 111 Post-it note, 53, 55 Powerbuilder, 55 The Practice of Programming, 99 Pragmatic programmer\n\ncharacteristics, xviii e-mail address, xxiii Web site, xxiii\n\nPre- and postcondition, 110, 113, 114 Predicate logic, 110 Preprocessor, 114 Presentation, 20\n\n317",
      "content_length": 1948,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 343,
      "content": "318\n\nINDEX\n\nProblem domain, 58, 66 metadata, 146\n\nProblem solving, 213\n\nchecklist for, 214\n\nProductivity, 10, 35 Programming by coincidence, 173 Programming staff\n\nexpense of, 237 Programming Windows, 265 Project\n\nglossary, 210 “heads”, 228 saboteur, 244 schedules, 68 see also Automation;\n\nTeam, project\n\nProject librarian, 33, 226 Prototyping, 53, 216 architecture, 55 disposable code, 56 kinds of, 54 and programming languages, 55 and tracer code, 51 using, 54\n\nPublish/subscribe protocol, 158 Pugh, Greg, 95n Purify, 136 PVCS Conﬁguration Management, 271 Python, 55, 99, 267\n\nQ\n\nQuality\n\ncontrol, 9 requirements, 11 teams, 225\n\nQuarry worker’s creed, xx Quicksort algorithm, 180\n\nR\n\nRational Uniﬁed Process, 227n Raymond, Eric S., 273 RCS, see Revision Control System Real-world data, 243 Refactoring, 5, 185\n\nautomatic, 187 and design, 186 testing, 187 time constraints, 185\n\nRefactoring browser, 187, 268 Reﬁnement, excessive, 11 Regression, 76, 197, 232, 242 Relationship\n\nhas-a, 304 kind-of, 111, 304\n\nReleases, and SCCS, 87 Remote Method Invocation (RMI), 128\n\nexception handling, 39\n\nRemote procedure call (RPC), 29, 39 Repository, 87 Requirement, 11, 202\n\nbusiness problem, 203 changing, 26 creep, 209 DBC, 110 distribution, 211 documenting, 204 in domain language, 58 expressing as invariant, 116 formal methods, 220 glossary, 210 over specifying, 208 and policy, 203 usability testing, 241 user interface, 203\n\nResearching, 15 Resource balancing, 129 C++ exceptions, 132 checking, 135 coupled code, 130 dynamic data structures, 135 encapsulation in class, 132 Java, 134 nest allocations, 131\n\nResponse set, 141, 242 Responsibility, 2, 250, 258 Reuse, 33, 36 Reversibility, 44\n\nﬂexible architecture, 46\n\nRevision Control System (RCS), 250,\n\n271\n\nRisk management, 13 orthogonality, 36\n\nRMI, see Remote Method Invocation Rock-n-roll, 47 RPC, see Remote procedure call Rubber ducking, 3, 95 Rules engine, 169",
      "content_length": 1917,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 344,
      "content": "S\n\nSaboteur, 244 Samba, 272 Sample programs, see Example code Sather, 114, 268 SCCS, see Source code control system Schedule, project, 68 Schrödinger, Erwin (and his cat), 47 Scope, requirement, 209 Screen scraping, 61 Scripting language, 55, 145 Secure hash, 74 sed, 99 Sedgewick, Robert, 183 Self-contained components, see Orthogonality; Cohesion\n\nSemantic invariant, 116, 135 sendmail program, 60 Sequence diagram, 158 Server code, 196 Services, design using, 154 Shell, command, 77 vs. GUI, 78 see also Command shell\n\n“Shy code”, 40 Side effect, 124 SIGPLAN, 263 Simple loop, 180 Singleton object, 41 Slashdot, 265 SmallEiffel, 267 Smalltalk, 46, 186, 187, 268, 272 Software\n\ndevelopment technologies, 221 quality, 9 requirements, 11\n\nSoftware bus, 159 “Software Construction”, 184 Software Development Magazine, 263 Software IC, 189n “Software rot”, 4 Solaris, 76 Source code\n\ncat eating, 3 documentation, see Comments downloading, see Example code duplication in, 29 generating, 103 reviews, see Code reviews\n\nINDEX\n\nSource code control system (SCCS), 86\n\nAegis, 246 builds using, 88 CVS, 271 development tree, 87 plain text and, 76 RCS, 250, 271 repository, 87 tools, 271 Specialization, 221 Speciﬁcation, 58\n\nimplementation, 219 language, 62 as security blanket, 219 writing, 218\n\nSpy cells, 138 Squeak, 268 Stand-alone mini-language, 62 “Start-up fatigue”, 7 Starting a project\n\nproblem solving, 212 prototyping, 216 speciﬁcations, 217 see also Requirement\n\nStevens, W. Richard, 264 Stone soup, 7\n\nvs. broken windows, 9\n\nStone-cutter’s creed, xx String parser, 155 Stroop effect, 249 strtok routine, 155 Structured walkthroughs, see Code\n\nreviews\n\nStyle sheet, 20, 254 Style, communication, 20 Subclass, 112 Sublinear algorithm, 177 Supplier, see Vendor Surviving Object-Oriented Projects: A Manager’s Guide, 264\n\nSWIG, 55, 270 Synchronization bar, 151 Syntax highlighting, 84 Synthetic data, 243\n\nT\n\nT Spaces, 166, 269 TAM, see Test Access Mechanism Tcl, 55, 99, 269\n\n319",
      "content_length": 1981,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 345,
      "content": "320\n\nINDEX\n\nTeam, project, 36, 224 automation, 229 avoiding duplication, 32 code review, 236 communication, 225 duplication, 226 functionality, 227 organization, 227 pragmatism in, xx quality, 225 tool builders, 229\n\nTechnical writer, 252 Template, use case, 205 Temporal coupling, 150 Test Access Mechanism (TAM), 189 Test harness, 194 Testing\n\nautomated, 238\n\nfrom speciﬁcation, 29\n\nbug ﬁxing, 247 coverage analysis, 245 and culture, 197 debugging, 92, 196 design/methodology, 242 effectiveness, 244 estimates, 182 frequency, 246 GUI systems, 244 integration, 239 orthogonality, 36, 41 performance, 241 role of plain text, 76 refactoring, 187 regression, 76, 197, 232, 242 resource exhaustion, 240 saboteur, 244 test data, 100, 243 usability, 241 validation and veriﬁcation, 239 see also Unit testing Text manipulation language, 99 TOM programming language, 268 Toolkits, 39 Tools, adaptable, 205 Tracer code, 49\n\nadvantages of, 50 and prototyping, 51\n\nTracing, 94\n\nsee also Logging\n\nTrade paper, 263 Trade-offs, 249 Transactions, EJB, 39 Tree widget, 161 troff system, 103 Tuple space, 167\n\nU\n\nUML, see Uniﬁed modeling language\n\n(UML) UNDO key, 86 Uniﬁed modeling language (UML) activity diagram, 150 sequence diagram, 158 use case diagram, 208\n\nUniform Access Principle, 31n Unit testing, 190\n\nDBC, 190 modules, 239 test harness, 194 test window, 196 writing tests, 193\n\nUnix, 46, 76\n\nApplication Default ﬁles, 145 books, 264 Cygwin, 270 DOS tools, 270 Samba, 272 UWIN, 81, 270\n\nUnix Network Programming, 264 Usability testing, 241 Use case, 204\n\ndiagrams, 206\n\nUsenet newsgroup, 15, 17, 33 User\n\nexpectations, 256 groups, 18 interface, 203 requirements, 10\n\nUWIN, 81, 270\n\nV\n\nVariable\n\ncorrupt, 95 global, 130, 154 name, 249\n\nVendor\n\nlibraries, 39 reducing reliance on, 36, 39, 46",
      "content_length": 1785,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 346,
      "content": "vi editor, 266 View\n\ndebugging, 164 executable documents, 251 Java tree view, 161 model-view-controller, 160, 162 model-viewer network, 162\n\nvim editor, 266 Visual Basic, 55 Visual C++, 198 Visual SourceSafe, 271 VisualWorks, 268\n\nW\n\nWalkthoughs, see Code reviews Warnings, compilation, 92 Web documentation, 101, 210, 253 automatic generation, 235 news and information, 265\n\nWeb server, 196 Web site, pragmatic programmer, xxiii What You See Is What You Get (WYSIWYG), 78\n\nWikiWikiWeb, 265 Win32 System Services, 265 Windows, 46\n\n“at” command, 231 books, 265 Cygwin, 80 metadata, 145 notepad, 84\n\nINDEX\n\nUnix utilities, 80, 81 UWIN, 81\n\nWinZip, 272 WISDOM acrostic, 20 Wizard, 198 Word processor, 252, 254 Workﬂow, 150\n\nblackboard system, 169 content-driven, 234 Wrapper, 132, 133, 135, 141 Writing, 18\n\nsee also Documentation\n\nwww.pragmaticprogrammer.com, xxiii WYSIWYG, see What You See Is What\n\nYou Get\n\nX\n\nXEmacs editor, 266 Xerox Parc, 39 XSL, see eXtensible Style Language xUnit, 194, 269\n\nY\n\nyacc, 59 Yourdon, Edward, 10, 35 Y2K problem, 32, 208\n\nZ\n\nZ shell, 272\n\n321",
      "content_length": 1075,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 347,
      "content": "(cid:10)(cid:12)(cid:9)(cid:13)(cid:14)(cid:11)(cid:3)(cid:5)(cid:2)(cid:7)(cid:13)(cid:11)(cid:1) THE TRUSTED TECHNOLOGY LEARNING SOURCE\n\nInformIT is a brand of Pearson and the online presence for the world’s leading technology publishers. It’s your source for reliable and qualified content and knowledge, providing access to the top brands, authors, and contributors from the tech community.\n\n(cid:4)(cid:8)(cid:6)(cid:14)(cid:12)(cid:3)(cid:5)(cid:1)at(cid:1)(cid:3)(cid:12)(cid:9)(cid:13)(cid:14)(cid:11)(cid:3)(cid:5)\n\nLooking for a book, eBook, or training video on a new technology? Seeking timely and relevant information and tutorials? Looking for expert opinions, advice, and tips? InformIT has the solution.\n\n\n\nLearn about new releases and special promotions by subscribing to a wide variety of newsletters. Visit informit.com/newsletters.\n\nAccess FREE podcasts from experts at informit.com/podcasts.\n\nRead the latest author articles and sample chapters at\n\ninformit.com/articles.\n\n\n\nAccess thousands of books and videos in the Safari Books Online digital library at safari.informit.com.\n\nGet tips from expert blogs at informit.com/blogs.\n\nVisit informit.com/learn to discover all the ways you can access the hottest technology content.\n\nAre You Part of the(cid:1)(cid:3)(cid:5) Crowd?\n\nConnect with Pearson authors and editors via RSS feeds, Facebook, Twitter, YouTube, and more! Visit informit.com/socialconnect.\n\n(cid:10)(cid:12)(cid:9)(cid:13)(cid:14)(cid:11)(cid:3)(cid:5)(cid:2)(cid:7)(cid:13)(cid:11)(cid:1)THE TRUSTED TECHNOLOGY LEARNING SOURCE",
      "content_length": 1564,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 348,
      "content": "THIS PRODUCT\n\ninformit.com/register\n\nRegister the Addison-Wesley, Exam Cram, Prentice Hall, Que, and Sams products you own to unlock great beneﬁ ts.\n\nTo begin the registration process, simply go to informit.com/register to sign in or create an account. You will then be prompted to enter the 10- or 13-digit ISBN that appears on the back cover of your product.\n\nRegistering your products can unlock the following beneﬁ ts:\n\nAccess to supplemental content,\n\nincluding bonus chapters, source code, or project ﬁ les. • A coupon to be used on your\n\nnext purchase.\n\nRegistration beneﬁ ts vary by product. Beneﬁ ts will be listed on your Account page under Registered Products.\n\nAbout InformIT — THE TRUSTED TECHNOLOGY LEARNING SOURCE\n\nINFORMIT IS HOME TO THE LEADING TECHNOLOGY PUBLISHING IMPRINTS Addison-Wesley Professional, Cisco Press, Exam Cram, IBM Press, Prentice Hall\n\nProfessional, Que, and Sams. Here you will gain access to quality and trusted content and\n\nresources from the authors, creators, innovators, and leaders of technology. Whether you’re\n\nlooking for a book on a new technology, a helpful article, timely newsletters, or access to\n\nthe Safari Books Online digital library, InformIT has a solution for you.\n\n(cid:7)(cid:9)(cid:6)(cid:10)(cid:11)(cid:8)(cid:3)(cid:4)(cid:2)(cid:5)(cid:10)(cid:8)(cid:1)\n\nAddison-Wesley | Cisco Press | Exam Cram IBM Press | Que | Prentice Hall | Sams\n\nTHE TRUSTED TECHNOLOGY LEARNING SOURCE\n\nSAFARI BOOKS ONLINE",
      "content_length": 1460,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 349,
      "content": "The Pragmatic Programmer\n\nThis card summarizes the tips and checklists found in The Pragmatic Programmer.\n\nFor more information about THE PRAGMATIC PROGRAMMERS LLC, source code for the examples, up-to-date pointers to Web resources, and an online bibliography, visit us at www.pragmaticprogrammer.com. Quick Reference Guide\n\nTIPS 1 TO 22\n\n1. Care About Your Craft ........................... xix Why spend your life developing software unless you care about doing it well?\n\n12. Make It Easy to Reuse .......................... 33 If it’s easy to reuse, people will. Create an environ- ment that supports reuse.\n\n2. Think! About Your Work.........................xix Turn off the autopilot and take control. Constantly critique and appraise your work.\n\n13. Eliminate Effects Between Unrelated Things .... 35 Design components that are self-contained, inde- pendent, and have a single, well-deﬁned purpose.\n\n3. Provide Options, Don’t Make Lame Excuses........3 Instead of excuses, provide options. Don’t say it can’t be done; explain what can be done.\n\n14. There Are No Final Decisions ................... 46 No decision is cast in stone. Instead, consider each as being written in the sand at the beach, and plan for change.\n\n4. Don’t Live with Broken Windows...................5 Fix bad designs, wrong decisions, and poor code when you see them.\n\n15. Use Tracer Bullets to Find the Target ........... 49 Tracer bullets let you home in on your target by trying things and seeing how close they land.\n\n5. Be a Catalyst for Change...........................8 You can’t force change on people. Instead, show them how the future might be and help them par- ticipate in creating it.\n\n16. Prototype to Learn..............................54 Prototyping is a learning experience. Its value lies not in the code you produce, but in the lessons you learn.\n\n6. Remember the Big Picture.........................8 Don’t get so engrossed in the details that you forget to check what’s happening around you.\n\n17. Program Close to the Problem Domain .......... 58 Design and code in your user’s language.\n\n7. Make Quality a Requirements Issue .............. 11 Involve your users in determining the project’s real quality requirements.\n\n18. Estimate to Avoid Surprises .................... 64 Estimate before you start. You’ll spot potential problems up front.\n\n8. Invest Regularly in Your Knowledge Portfolio.....14 Make learning a habit.\n\n19. Iterate the Schedule with the Code..............69 Use experience you gain as you implement to reﬁne the project time scales.\n\n9. Critically Analyze What You Read and Hear ...... 16 Don’t be swayed by vendors, media hype, or dogma. Analyze information in terms of you and your project.\n\n20. Keep Knowledge in Plain Text...................74 Plain text won’t become obsolete. It helps leverage your work and simpliﬁes debugging and testing.\n\n10. It’s Both What You Say and the Way You Say It..21 There’s no point in having great ideas if you don’t communicate them effectively.\n\n21. Use the Power of Command Shells .............. 80 Use the shell when graphical user interfaces don’t cut it.\n\n11. DRY—Don’t Repeat Yourself....................27 Every piece of knowledge must have a single, un- ambiguous, authoritative representation within a system.\n\n22. Use a Single Editor Well ........................ 82 The editor should be an extension of your hand; make sure your editor is conﬁgurable, extensible, and programmable.\n\n1",
      "content_length": 3454,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 350,
      "content": "TIPS 23 TO 46\n\n23. Always Use Source Code Control ............... 88 Source code control is a time machine for your work—you can go back.\n\n24. Fix the Problem, Not the Blame ................. 91 It doesn’t really matter whether the bug is your fault or someone else’s—it is still your problem, and it still needs to be ﬁxed.\n\n25. Don’t Panic When Debugging ................... 91 Take a deep breath and THINK! about what could be causing the bug.\n\n26. “select” Isn’t Broken............................96 It is rare to ﬁnd a bug in the OS or the compiler, or even a third-party product or library. The bug is most likely in the application.\n\n27. Don’t Assume It—Prove It ....................... 97 Prove your assumptions in the actual environ- ment—with real data and boundary conditions.\n\n28. Learn a Text Manipulation Language ..........100 You spend a large part of each day working with text. Why not have the computer do some of it for you?\n\n29. Write Code That Writes Code..................103 Code generators increase your productivity and help avoid duplication.\n\n30. You Can’t Write Perfect Software .............. 107 Software can’t be perfect. Protect your code and users from the inevitable errors.\n\n31. Design with Contracts.........................111 Use contracts to document and verify that code does no more and no less than it claims to do.\n\n32. Crash Early...................................120 A dead program normally does a lot less damage than a crippled one.\n\n33. Use Assertions to Prevent the Impossible ..... 122 Assertions validate your assumptions. Use them to protect your code from an uncertain world.\n\n34. Use Exceptions for Exceptional Problems ..... 127 Exceptions can suffer from all the readability and maintainability problems of classic spaghetti code. Reserve exceptions for exceptional things.\n\n2\n\n35. Finish What You Start.........................129 Where possible, the routine or object that allocates a resource should be responsible for deallocating it.\n\n36. Minimize Coupling Between Modules..........140 Avoid coupling by writing “shy” code and applying the Law of Demeter.\n\n37. Conﬁgure, Don’t Integrate .....................144 Implement technology choices for an application as conﬁguration options, not through integration or engineering.\n\n38. Put Abstractions in Code, Details in Metadata.145 Program for the general case, and put the speciﬁcs outside the compiled code base.\n\n39. Analyze Workﬂow to Improve Concurrency....151 Exploit concurrency in your user’s workﬂow.\n\n40. Design Using Services.........................154 Design in terms of services—independent, concur- rent objects behind well-deﬁned, consistent inter- faces.\n\n41. Always Design for Concurrency ............... 156 Allow for concurrency, and you’ll design cleaner in- terfaces with fewer assumptions.\n\n42. Separate Views from Models...................161 Gain ﬂexibility at low cost by designing your appli- cation in terms of models and views.\n\n43. Use Blackboards to Coordinate Workﬂow......169 Use blackboards to coordinate disparate facts and agents, while maintaining independence and isola- tion among participants.\n\n44. Don’t Program by Coincidence ................ 175 Rely only on reliable things. Beware of accidental complexity, and don’t confuse a happy coincidence with a purposeful plan.\n\n45. Estimate the Order of Your Algorithms........181 Get a feel for how long things are likely to take be- fore you write code.\n\n46. Test Your Estimates...........................182 Mathematical analysis of algorithms doesn’t tell you everything. Try timing your code in its target environment.",
      "content_length": 3621,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 351,
      "content": "TIPS 47 TO 70\n\n47. Refactor Early, Refactor Often ................. 186 Just as you might weed and rearrange a gar- den, rewrite, rework, and re-architect code when it needs it. Fix the root of the problem.\n\n48. Design to Test.................................192 Start thinking about testing before you write a line of code.\n\n49. Test Your Software, or Your Users Will.........197 Test ruthlessly. Don’t make your users ﬁnd bugs for you.\n\n50. Don’t Use Wizard Code You Don’t Understand . 199 Wizards can generate reams of code. Make sure you understand all of it before you incorporate it into your project.\n\n51. Don’t Gather Requirements—Dig for Them.....202 Requirements rarely lie on the surface. They’re buried deep beneath layers of assumptions, mis- conceptions, and politics.\n\n52. Work with a User to Think Like a User.........204 It’s the best way to gain insight into how the sys- tem will really be used.\n\n53. Abstractions Live Longer than Details.........209 Invest in the abstraction, not the implementation. Abstractions can survive the barrage of changes from different implementations and new technolo- gies.\n\n54. Use a Project Glossary ........................ 210 Create and maintain a single source of all the spe- ciﬁc terms and vocabulary for a project.\n\n55. Don’t Think Outside the Box—Find the Box....213 When faced with an impossible problem, identify the real constraints. Ask yourself: “Does it have to be done this way? Does it have to be done at all?”\n\n56. Start When You’re Ready......................215 You’ve been building experience all your life. Don’t ignore niggling doubts.\n\n57. Some Things Are Better Done than Described . 218 into the speciﬁcation spiral—at some Don’t fall point you need to start coding.\n\n58. Don’t Be a Slave to Formal Methods ........... 220 Don’t blindly adopt any technique without putting it into the context of your development practices and capabilities.\n\n3\n\n59. Costly Tools Don’t Produce Better Designs .... 222 Beware of vendor hype, industry dogma, and the aura of the price tag. Judge tools on their merits.\n\n60. Organize Teams Around Functionality ........ 227 Don’t separate designers from coders, testers from data modelers. Build teams the way you build code.\n\n61. Don’t Use Manual Procedures ................. 231 A shell script or batch ﬁle will execute the same instructions, in the same order, time after time.\n\n62. Test Early. Test Often. Test Automatically. .... 237 Tests that run with every build are much more ef- fective than test plans that sit on a shelf.\n\n63. Coding Ain’t Done ’Til All the Tests Run.......238 ’Nuff said.\n\n64. Use Saboteurs to Test Your Testing............244 Introduce bugs on purpose in a separate copy of the source to verify that testing will catch them.\n\n65. Test State Coverage, Not Code Coverage .......245 Identify and test signiﬁcant program states. Just testing lines of code isn’t enough.\n\n66. Find Bugs Once ............................... 247 Once a human tester ﬁnds a bug, it should be the last time a human tester ﬁnds that bug. Automatic tests should check for it from then on.\n\n67. English is Just a Programming Language ...... 248 Write documents as you would write code: honor the DRY principle, use metadata, MVC, automatic generation, and so on.\n\n68. Build Documentation In, Don’t Bolt It On......248 Documentation created separately from code is less likely to be correct and up to date.\n\n69. Gently Exceed Your Users’ Expectations ...... 255 Come to understand your users’ expectations, then deliver just that little bit more.\n\n70. Sign Your Work ............................... 258 Craftsmen of an earlier age were proud to sign their work. You should be, too.",
      "content_length": 3688,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 352,
      "content": "Checklists\n\n✔Languages to Learn...................page 17 Tired of C, C++, and Java? Try CLOS, Dylan, Eif- fel, Objective C, Prolog, Smalltalk, or TOM. Each of these languages has different capabilities and a different “ﬂavor.” Try a small project at home using one or more of them.\n\n✔The WISDOM Acrostic ................. page 20\n\n✔Law of Demeter for Functions.....page 141 An object’s method should call only methods be- longing to: Itself Any parameters passed in Objects it creates Component objects\n\nWhat do you want them to learn?\n\nWhat is their interest in what you’ve got to say?\n\nHow sophisticated are they?\n\nHow much detail do they want?\n\nWhom do you want to own the information?\n\nHow can you motivate them to listen to you?\n\n✔How to Maintain Orthogonality.....page 34 Design independent, well-deﬁned components. Keep your code decoupled. Avoid global data. Refactor similar functions.\n\n✔How to Program Deliberately ...... page 172\n\nStay aware of what you’re doing. Don’t code blindfolded. Proceed from a plan. Rely only on reliable things. Document your assumptions. Test assumptions as well as code. Prioritize your effort. Don’t be a slave to history.\n\n✔Things to prototype...................page 53\n\nArchitecture New functionality in an existing system Structure or contents of external data Third-party tools or components Performance issues User interface design\n\n✔When to Refactor.....................page 185 You discover a violation of the DRY principle. You ﬁnd things that could be more orthogonal. Your knowledge improves. The requirements evolve. You need to improve performance.\n\n✔Architectural Questions.............page 55\n\nAre responsibilities well deﬁned? Are the collaborations well deﬁned? Is coupling minimized? Can you identify potential duplication? Are interface deﬁnitions and constraints accept- able? Can modules access needed data—when needed?\n\n✔Cutting the Gordian Knot .......... page 212 When solving impossible problems, ask yourself:\n\nIs there an easier way? Am I solving the right problem? Why is this a problem? What makes it hard? Do I have to do it this way? Does it have to be done at all?\n\n✔Aspects of Testing...................page 237\n\n✔Debugging Checklist..................page 98 Is the problem being reported a direct result of the underlying bug, or merely a symptom? Is the bug really in the compiler? Is it in the OS? Or is it in your code? If you explained this problem in detail to a coworker, what would you say? If the suspect code passes its unit tests, are the tests complete enough? What happens if you run the unit test with this data? Do the conditions that caused this bug exist anywhere else in the system?\n\nUnit testing Integration testing Validation and veriﬁcation Resource exhaustion, errors, and recovery Performance testing Usability testing Testing the tests themselves\n\nChecklists from The Pragmatic Programmer, by Andrew Hunt and David Thomas. Visit www.pragmaticprogrammer.com. Copyright c 2000 by Addison Wesley Longman, Inc.\n\n4",
      "content_length": 3007,
      "extraction_method": "Unstructured"
    }
  ]
}