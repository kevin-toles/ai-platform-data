{
  "metadata": {
    "title": "Principles of Transaction Processing",
    "author": "Bernstein, Philip A.,Newcomer, Eric.",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 397,
    "conversion_date": "2025-12-25T18:16:17.949307",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Principles of Transaction Processing.pdf",
    "extraction_method": "PyMuPDF_fallback (Unstructured failed)"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 2-9)",
      "start_page": 2,
      "end_page": 9,
      "detection_method": "topic_boundary",
      "content": " The Morgan Kaufmann Series in Data Management Systems (Selected Titles) \n Information Modeling and Relational Databases, \n2nd Edition \n Terry Halpin, Tony Morgan \n Joe Celko’s Thinking in Sets \n Joe Celko \n Business Metadata \n Bill Inmon, Bonnie O’Neil, Lowell Fryman \n Unleashing Web 2.0 \n Gottfried Vossen, Stephan Hagemann \n Enterprise Knowledge Management \n David Loshin \n Business Process Change, 2nd Edition \n Paul Harmon \n IT Manager’s Handbook, 2nd Edition \n Bill Holtsnider  & Brian Jaffe \n Joe Celko’s Puzzles and Answers, 2nd Edition \n Joe Celko \n Making Shoes for the Cobbler’s Children \n Charles Betz \n Joe Celko’s Analytics and OLAP in SQL \n Joe Celko \n Data Preparation for Data Mining Using SAS \n Mamdouh Refaat \n Querying XML: XQuery, XPath, and SQL/XML \nin Context \n Jim Melton and Stephen Buxton \n Data Mining: Concepts and Techniques, 2nd \nEdition \n Jiawei Han and Micheline Kamber \n Database Modeling and Design: Logical Design, \n4th Edition \n Toby J, Teorey, Sam S. Lightstone, Thomas P. \nNadeau \n Foundations of Multidimensional and Metric \nData Structures \n Hanan Samet \n Joe Celko’s SQL for Smarties: Advanced SQL \nProgramming, 3rd Edition \n Joe Celko \n Moving Objects Databases \n Ralf Hartmut G ü ting and Markus Schneider \n Joe Celko’s SQL Programming Style \n Joe Celko \n Data Mining, Second Edition: Concepts and \nTechniques \n Ian Witten and Eibe Frank \n Fuzzy Modeling and Genetic Algorithms for Data \nMining and Exploration \n Earl Cox \n Data Modeling Essentials, 3rd Edition \n Graeme C. Simsion and Graham C. Witt \n Location -Based Services \n Jochen Schiller and Agn è s Voisard \n Database Modeling with Microsoft ® Visio for \nEnterprise Architects \n Terry Halpin, Ken Evans, Patrick Hallock, Bill \nMaclean \n Designing Data-Intensive Web Applications \n Stephano Ceri, Piero Fraternali, Aldo Bongio, \nMarco Brambilla, Sara Comai, Maristella Matera \n Mining the Web: Discovering Knowledge from \nHypertext Data \n Soumen Chakrabarti \n Advanced SQL: 1999 — Understanding Object-\nRelational and Other Advanced Features \n Jim Melton \n Database Tuning: Principles, Experiments, and \nTroubleshooting Techniques \n Dennis Shasha, Philippe Bonnet \n SQL :1999 — Understanding Relational Language \nComponents \n Jim Melton, Alan R. Simon \n Information Visualization in Data Mining and \nKnowledge Discovery \n Edited by Usama Fayyad, Georges G. Grinstein, \nAndreas Wierse \n Transactional Information Systems \n Gerhard Weikum and Gottfried Vossen \n Spatial Databases \n Philippe Rigaux, Michel Scholl, and Agnes \nVoisard \n Managing Reference Data in Enterprise \nDatabase \n Malcolm Chisholm \n Understanding SQL and Java Together \n Jim Melton and Andrew Eisenberg \n Database : Principles, Programming, and \nPerformance, 2nd Edition \n Patrick and Elizabeth O’Neil \n The Object Data Standard \n Edited by R. G. G. Cattell, Douglas Barry \n Data on the Web: From Relations to \nSemistructured Data and XML \n Serge Abiteboul, Peter Buneman, Dan Suciu \n Data Mining: Practical Machine Learning Tools \nand Techniques with Java Implementations \n Ian Witten, Eibe Frank \n Joe Celko’s Data and Databases: Concepts in \nPractice \n Joe Celko \n Developing Time-Oriented Database Applications \nin SQL \n Richard T. Snodgrass \n Web Farming for the Data Warehouse \n Richard D. Hackathorn \n Management of Heterogeneous and Autonomous \nDatabase Systems \n Edited by Ahmed Elmagarmid, Marek \nRusinkiewicz, Amit Sheth \n Object -Relational DBMSs, 2nd Edition \n Michael Stonebraker and Paul Brown, with \nDorothy Moore \n Universal Database Management: A Guide to \nObject/Relational Technology \n Cynthia Maro Saracco \n Readings in Database Systems, 3rd Edition \n Edited by Michael Stonebraker, Joseph M. \nHellerstein \n Understanding SQL’s Stored Procedures: \nA Complete Guide to SQL/PSM \n Jim Melton \n Principles of Multimedia Database Systems \n V . S. Subrahmanian \n Principles of Database Query Processing for \nAdvanced Applications \n Clement T. Yu, Weiyi Meng \n Advanced Database Systems \n Carlo Zaniolo, Stefano Ceri, Christos Faloutsos, \nRichard T. Snodgrass, V. S. Subrahmanian, \nRoberto Zicari \n Principles of Transaction Processing, 2nd Edition \n Philip A. Bernstein, Eric Newcomer \n Using the New DB2: IBMs Object-Relational \nDatabase System \n Don Chamberlin \n Distributed Algorithms \n Nancy A. Lynch \n Active Database Systems: Triggers and Rules for \nAdvanced Database Processing \n Edited by Jennifer Widom, Stefano Ceri \n Migrating Legacy Systems: Gateways, Interfaces, \n & the Incremental Approach \n Michael L. Brodie, Michael Stonebraker \n Atomic Transactions \n Nancy Lynch, Michael Merritt, William Weihl, \nAlan Fekete \n Query Processing for Advanced Database \nSystems \n Edited by Johann Christoph Freytag, David \nMaier, Gottfried Vossen \n Transaction Processing \n Jim Gray, Andreas Reuter \n Database Transaction Models for Advanced \nApplications \n Edited by Ahmed K. Elmagarmid \n A Guide to Developing Client/Server SQL \nApplications \n Setrag Khoshaﬁ an, Arvola Chan, Anna Wong, \nHarry K. T. Wong \n\n\n Principles of \nTransaction Processing \n Second Edition \n Philip A. Bernstein \n Eric Newcomer \n \n \nAMSTERDAM • BOSTON • HEIDELBERG • LONDON  \nNEW YORK • OXFORD • PARIS • SAN DIEGO  \nSAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO\nMorgan Kaufmann Publishers is an imprint of Elsevier\n\n\n  Morgan Kaufmann Publishers is an imprint of Elsevier \n 30 Corporate Drive, Suite 400, Burlington, MA 01803, USA \n Copyright © 2009 by Elsevier Inc. All rights reserved. \n Designations used by companies to distinguish their products are often claimed as trademarks or \nregistered trademarks. In all instances in which Morgan Kaufmann Publishers is aware of a claim, \nthe product names appear in initial capital or all capital letters. All trademarks that appear or are \notherwise referred to in this work belong to their respective owners. Neither Morgan Kaufmann \nPublishers nor the authors and other contributors of this work have any relationship or afﬁ liation \nwith such trademark owners nor do such trademark owners conﬁ rm, endorse or approve the contents \nof this work. Readers, however, should contact the appropriate companies for more information \nregarding trademarks and any related registrations. \n No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any \nform or by any means — electronic, mechanical, photocopying, scanning, or otherwise — without \nprior written permission of the publisher. \n Permissions may be sought directly from Elsevier’s Science  & Technology Rights Department \nin Oxford, UK: phone: ( \u0002 44) 1865 843830, fax: ( \u0002 44) 1865 853333, E-mail:  mail to:\npermissions@elsevier.com . You may also complete your request online via the Elsevier \nhomepage ( http://www.elsevier.com ), by selecting  “ Support  & Contact ” then  “ Copyright and \nPermission ” and then  “ Obtaining Permissions. ” \n Library of Congress Cataloging-in-Publication Data \n Bernstein, Philip A.\nPrinciples of transaction processing/Philip A. Bernstein, Eric Newcomer.—2nd ed.\n p. cm. — (The Morgan Kaufmann series in data management systems)\nIncludes bibliographical references and index.\nISBN 978-1-55860-623-4 (pbk.)\n1. Transaction systems (Computer systems) I. Newcomer, Eric. II. Title.\nQA76.545.B47 2009\n005.74 \u0003 5–dc22\n2009003605 \n For information on all Morgan Kaufmann publications, \n visit our Web site at  www.mkp.com or  www.elsevierdirect.com \n Printed in the United States of America \n 09 10 11 12 13  5 4 3 2 1 \n \n\n\n  For Jim Gray, wherever he may be \n\n\nThis page intentionally left blank\n\n\n Preface  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\n Trademarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xvii\n CHAPTER 1  Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n  1.1 The Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1\n  1.2 TP System Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5\n  1.3 Atomicity, Consistency, Isolation, and Durability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\n  1.4 Two-Phase Commit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .15\n  1.5 Transaction Processing Performance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .17\n  1.6 Availability  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .22\n  1.7 Styles of Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24\n  1.8 TP System Conﬁ gurations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .28\n  1.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .29\n CHAPTER 2  Transaction Processing Abstractions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n  2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\n  2.2 Transactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\n  2.3 Processes and Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .41\n  2.4 Remote Procedure Call . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .46\n  2.5 Shared State . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .57\n  2.6 Scalability  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n  2.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n CHAPTER 3 Transaction Processing Application Architecture  . . . . . . . . . . . . . . . . . . . . 73\n  3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .73\n  3.2 Application Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\n  3.3 Front-End Program . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78\n  3.4 Request Controller  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .88\n  3.5 Transaction Servers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .91\n  3.6 Transactional Middleware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .92\n  3.7 Database Servers Versus Transactional Middleware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .94\n  3.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .96\n CHAPTER 4 Queued Transaction Processing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n   4.1 Why Use Queues? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\n   4.2 The Queued Transaction Processing Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .102\n  4.3 Client Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .104\n  4.4 Handling Non-Undoable  Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .107\n  4.5 The Queue Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .108\n  4.6 Publish-Subscribe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .112\n  4.7 Other Message-Oriented Middleware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .113\n Contents  \n\n\nviii  Contents\n  4.8 Queuing Products and Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .115\n  4.9 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\n CHAPTER 5 Business Process Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n  5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .121\n  5.2 Business Process Deﬁ nition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123\n  5.3 Business Process Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .124\n  5.4 Transactional Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\n  5.5 Making Process State Durable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .129\n  5.6 Other Models of Business Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\n  5.7 Products and Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\n  5.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\n CHAPTER 6 Locking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n  6.1 Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .141\n  6.2 Implementation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .145\n  6.3 Deadlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .150\n  6.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .154\n  6.5 Hot Spots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n  6.6 Query-Update Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .163\n  6.7 Avoiding Phantoms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .169\n  6.8 Optimistic Concurrency Control  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .171\n  6.9 B-Tree Locking  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172\n  6.10 Multigranularity Locking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .178\n  6.11 Locking Nested Transactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .181\n  6.12 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\n  6.13 Appendix: Basic Serializability Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .183\n CHAPTER 7 System Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n  7.1 Causes of System Failure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .185\n  7.2 A Model for System Recovery  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .188\n  7.3 Introduction to Database Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .194\n  7.4 The System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .196\n  7.5 Database Recovery Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\n  7.6 Shadow-Paging Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .203\n  7.7 Log-Based Database Recovery Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .207\n  7.8 Optimizing Restart in Log-Based Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .211\n  7.9 Media Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .217\n  7.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\n CHAPTER 8 Two-Phase Commit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\n  8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .223\n  8.2 The Two-Phase Commit Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .224\n  8.3 Failure Handling  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .228\n  8.4 Optimizations and Variations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .232\n\n\nContents  ix\n  8.5 Process Structuring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .238\n  8.6 User Checklist . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\n  8.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\n CHAPTER 9 Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n  9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245\n  9.2 Replicated Servers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245\n  9.3 Synchronizing Updates to Replicated Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\n  9.4 Single-Master Primary-Copy Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .252\n  9.5 Multimaster Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\n  9.6 Other Replication Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .273\n  9.7 Data Sharing Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .274\n  9.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .278\n CHAPTER 10 Transactional Middleware Products and Standards . . . . . . . . . . . . . . . . . 281\n  10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .281\n  10.2 Web Browser Front-End Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .283\n  10.3 .NET Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .285\n  10.4 Java Enterprise Edition  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .297\n  10.5 Service-Oriented Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .311\n  10.6 Persistence Abstraction Mechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .315\n  10.7 Legacy TP Monitors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .324\n  10.8 TP Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .339\n  10.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .346\n CHAPTER 11 Future Trends . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\n  11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .349\n  11.2 Cloud Computing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .349\n  11.3 Scalable Distributed Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .351\n  11.4 Memory Technology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .353\n  11.5 Streams and Event Processing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .353\n  11.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\n Glossary of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355\n Bibliographic Notes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359\n Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\n Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371 \n",
      "page_number": 2
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 10-17)",
      "start_page": 10,
      "end_page": 17,
      "detection_method": "topic_boundary",
      "content": "This page intentionally left blank\n\n\n WHY READ THIS BOOK? \n Transaction processing has been an important software technology for 40 years. Large enterprises in transpor-\ntation, ﬁ nance, retail, telecommunications, manufacturing, government, and the military are utterly dependent \non transaction processing applications for electronic reservations, banking, stock exchanges, order processing, \nmusic and video services, shipment tracking, government services, telephone switching, inventory control, and \ncommand and control. Many large hardware and software vendors receive much of their revenue from compo-\nnents of transaction processing systems, such as IBM, HP, Oracle, Microsoft, Dell, Red Hat, and EMC. The \nmarket for transaction processing products and services is many tens of billions of dollars per year. As con-\nsumers, we all use this technology every day to withdraw cash, buy gas, rent movies, and make purchases on \nthe Internet. \n How exactly do these transaction processing systems work? This question was once of interest only to com-\nputer professionals in the commercial data processing ﬁ eld. Now, given the widespread use of transaction pro-\ncessing in today’s economy, it is of interest to a much broader engineering audience. Despite this interest, there is \nlittle written for a system professional to get a readable, technically solid introduction to this complex technology. \nThis book ﬁ lls the gap. \n The software environment of most large-scale transaction processing systems is based on transactional mid-\ndleware, which helps knit together many software components. These components include front-end applications \nto drive web browsers and other devices, middle-tier applications to route requests to the server that can run \nthem, and server applications that execute business logic. Examples of transactional middleware include IBM’s \nCICS; Microsoft’s .NET Enterprise Services; and Java Enterprise Edition products, such as IBM WebSphere \nApplication Server, Oracle’s WebLogic Server, and Red Hat’s JBoss Application Server. The ﬁ rst half of this \nbook focuses on transactional middleware technology. \n For many software engineers, transactional middleware is obscure technology — strange software glue that \nseems to be needed beyond operating systems, database systems, communication systems, and application pro-\ngramming languages. This book demystiﬁ es transactional middleware by explaining how it contributes to the \nperformance, security, scalability, availability, manageability, and ease-of-use of transaction processing systems. \nThe ﬁ rst half of the book explains transactional middleware outside and in — the features it offers to application \nprogrammers and how it is constructed to offer these features. \n The transaction abstraction itself is largely implemented by database systems. They ensure that each trans-\naction executes in its entirety, is isolated from interference by other transactions, and generates results that will \nsurvive hardware and software failures. This behavior is implemented by locking, logging, communication \nprotocols, and replication. These technologies are the subject of the second half of this book. \n This book is an introduction to transaction processing, intended to meet the needs of a broad audience, \nincluding: \n ■  Application programmers with an interest in building transaction processing applications \n ■  Database administrators who manage database systems used for transaction processing \n ■  Application analysts who design applications for deployment on transaction processing systems \n ■  Product developers in related areas, such as database systems, operating systems, and communications \n Preface \n\n\nxii  Preface\n ■  Marketing and technical support engineers for both systems and application products \n ■  Computer science undergraduates and graduate students looking for an introduction to this topic \n Our focus is on the principles of transaction processing, not on a prescription for how to build a transaction \nprocessing application — “ how come? ” not  “ how to. ” We include examples from many products, to illustrate \nhow the principles have been applied and where ideas originated. But we do not dwell heavily on any one \nproduct. We present technology that is practical and used in products and pay only modest attention to good \nideas that are not commonly used in practice. \n We do not assume any special prerequisites, other than  “ system sophistication. ” We expect most readers \nwill have some familiarity with SQL and database systems, but this background isn’t necessary. \n After ﬁ nishing the book, you will understand how transactional middleware works and when to use it, and \nhow transactional middleware and database systems work together to support reliable distributed transaction \nprocessing applications. You will be able to learn quickly how to use any transactional middleware product or \ndatabase system to support the development and management of transaction processing applications. \n WHAT’S NEW IN THIS SECOND EDITION? \n The short answer is  “ a lot. ” There are several new chapters and rewritten chapters, and many new and revised \nsections of the rest. \n Two main goals drove these changes. Our ﬁ rst goal was to present the new and revised transaction archi-\ntectures and technologies that have appeared since we published the ﬁ rst edition twelve years ago. Back then, \nInternet-based electronic commerce was just beginning. Now, it is established as a major segment of many \nbusiness-to-consumer and business-to-business markets. The growth of this segment, along with the com-\nmoditization of server hardware and operating systems, has led to major changes in transaction processing \nproducts. Web browsers are now a dominant technology for interacting with transaction processing systems. \nTransactional middleware has evolved from on-line transaction processing monitors to many new product cat-\negories that are designed to work well over the Internet, such as application servers, object request brokers, \nmessage-oriented middleware, and workﬂ ow systems. Object-oriented programming and service-oriented \narchitecture have become mainstream. And database systems have become more complete transaction process-\ning environments. These changes are all reﬂ ected in this second edition. \n Our second main goal was to add coverage and depth of classical transaction processing topics, to make the \nbook more complete. In part, this is based on the ﬁ rst author’s experience in using the book as a textbook for a \ngraduate computer science course for professional masters ’ students at the University of Washington. It is also \nin response to technological improvements, where formerly exotic technologies are now widely used. \n Concretely , the major changes are as follows: The three chapters on transactional middleware have been \nentirely rewritten — two on principles and a long one on example products and standards, including details of \nJava Enterprise Edition and Microsoft .NET. There is a new chapter on business process management. The \nchapter on locking has new sections on optimistic concurrency control, B-tree locking, multigranularity locking,\nand nested transactions. There are new sections on the TPC-E benchmark, state management, scalability, \nshadow-paging, data sharing systems, consensus algorithms, log-based replication, and multimaster replica-\ntion. Concepts of service-oriented architecture (SOA), REST, and Web Services are sprinkled throughout the \nbook. There are numerous smaller additions of technical detail in many sections. Signiﬁ cant changes can be \nfound in every chapter. \n Supplementary material will be available on the publisher’s web page for this book. Initially, it will include \na selection of problems, grouped by chapter. We will add other technical material over time. \n\n\nPreface  xiii\n SUMMARY OF TOPICS \n The enterprise that pays for a transaction processing system wants it to give fast service, be inexpensive to \nbuy and operate, and be scalable as usage grows and new applications are added. Application programmers \nwant to be insulated from the complexity of the many different kinds of technologies required to run a transac-\ntion processing system, such as transaction protocols, message protocols, transactional remote procedure calls, \npersistent queues, multithreaded processes, resource pooling, session management, and replication protocols. \nAn application programmer’s job is to understand what the business wants the transaction to do and to write a \nprogram that does it. The system software should make it possible to run that program on a system that is fast, \nefﬁ cient, scalable, and reliable. This is what transactional middleware does, which is the main subject of the \nﬁ rst half of this book, Chapters 1 through 5. Today’s products and standards for transactional middleware are \ndescribed in Chapter 10. \n Users of a transaction processing system want to think of it as a sequential processor of transactions, one \nthat’s inﬁ nitely reliable, gives them its full and undivided attention while it executes their transaction, exe-\ncutes the whole transaction (not just part of it), and saves the result of their transaction forever. This is a tall \norder and doesn’t at all describe what’s really going on inside the system: The system executes many transac-\ntions concurrently; it fails from time to time due to software and hardware errors, often at the worst possible \nmoment (when it’s running  your transaction); and it has limited storage capacity. Yet, through a combination \nof software techniques, the system approximates the behavior that users want. Those techniques are the main \nsubject of Chapters 6 through 9. \n As computing technology evolves, transaction processing technology will evolve to support it. We discuss \nsome major trends in Chapter 11: cloud computing, scalable distributed computing, ﬂ ash storage, and streams \nand event processing. \n Here is a summary of what you’ll ﬁ nd in each chapter: \n Chapter 1, Introduction: Gives a broad-brush overview of transaction processing application and system \nstructure. It describes service-oriented computing, the ACID properties of transactions, the two-phase \ncommit protocol, the industry-standard TPC performance benchmarks, high availability requirements, and \nthe relationship of transaction processing to batch processing, real-time, and data warehousing systems. \n Chapter 2, Transaction Processing Abstractions: Describes the main software abstractions found in transac-\ntion processing systems: transactions; processes and threads; remote procedure call; techniques for man-\naging shared state, such as transaction context, sessions, and cookies; and scalability techniques, such as \ncaching, resource pooling, partitioning, and replication. \n Chapter 3, Transaction Processing Application Architecture: Explains the value of multitier application \narchitecture and then delves into each tier in detail: front ends that use forms and web servers to com-\nmunicate with end-user devices; request controllers that bracket transactions; and transaction servers that \nexecute transactions. It also explains how transactional middleware and database servers structure these \nactivities. \n Chapter 4, Queued Transaction Processing: Shows how a persistent message queue adds reliability. It gives \ndetailed walk-throughs of recovery scenarios and shows how queues drive publish-subscribe, broker-based \nand bus-based message-oriented middleware. It also explains the internals of queue managers, with IBM’s \nWebsphere MQ and Oracle’s Stream AQ as examples. \n Chapter 5, Business Process Management: Describes mechanisms to support the creation, management, and \nmonitoring of business processes that execute as multiple related transactions. It explains how to obtain \n\n\nxiv  Preface\n suitable atomicity, isolation, and durability of multitransaction requests. It summarizes the business process \nexecution language (BPEL) standard and, as an example, business process mechanisms in Microsoft SQL \nService Broker. \n Chapter 6, Locking: Shows how and why two-phase locking works and how application programmers affect \nits correctness and performance. It describes lock manager implementation and deadlock handling. It then \nexplains in detail how performance can be controlled by lock granularity, optimistic methods, batching, \navoiding hot spots, avoiding phantoms, and supporting query-update workloads using lower degrees of iso-\nlation and multiversion methods. Finally, it covers B-tree locking and multigranularity locking used in SQL \ndatabase systems, and nested transaction locking. \n Chapter 7, System Recovery: Identiﬁ es what causes failures, and how transactions help mask their effects. It \ndiscusses checkpoint-based application recovery, using stateless servers to simplify recovery, and warm and \nhot standby systems that use process pairs to reduce recovery time. It then explains how database systems \nuse logging to recover from transaction failures, system failures, and media failures. It explains the undo \nand redo paradigm, how and why logging algorithms work, log checkpointing, recovery algorithms, shadow \npaging, some fancy popular logging optimizations (including the ARIES algorithm), and archive recovery. \n Chapter 8, Two-Phase Commit: Explains the two-phase commit protocol in detail. It carefully walks through \nrecovery situations and shows where and why the user must get involved. It presents popular optimiza-\ntions such as presumed abort, phase zero, and transfer of coordination. And it explains how database sys-\ntems and transaction managers interoperate using the XA interface of the X/Open transaction management \narchitecture. \n Chapter 9, Replication: Describes the tradeoffs of replicating servers versus replicating resources and shows \nhow the correctness criterion, one-copy serializability, applies to each of them. It presents the two most \npopular approaches to replication: primary-copy replication, where updates to a primary are propagated \nto secondaries; and multimaster replication, where updates are applied to any copy and then propagate to \nother copies. It also explains synchronization of replicated caches that connect to a shared database. It cov-\ners algorithms for electing a primary, quorum consensus, establishing the latest state, and replica recovery. \n Chapter 10, Transactional Middleware Products and Standards: Describes popular products and standards \nfor transactional middleware, such as Java Enterprise Edition, Microsoft’s .NET Enterprise Services, legacy \ntransaction processing monitors (CICS, IMS, Tuxedo, ACMS, and Pathway), and other service-oriented \nmiddleware. Component technologies include Windows Communications Foundation, Enterprise Java \nBeans, Java Database Connectors, Java Transaction API, and the Spring Framework , which appear in prod-\nucts from IBM, Oracle, Progress, and in open source software. It also describes transaction standards from \nOMG and X/Open, and Web Services standards from OASIS. \n Chapter 11, Future Trends: Discusses major directions where transaction processing technology is headed: \ncloud computing platforms, composing scalable systems using distributed computing components, the use \nof ﬂ ash storage to replace disks, and data and event streams from sensor devices as a source of transaction \nrequests. \n GUIDANCE FOR INSTRUCTORS \n The ﬁ rst author has taught transaction processing courses several dozen times over the past 25 years. Details \nof his most recent offerings are on the web site of the Department of Computer Science and Engineering at \n\n\nPreface  xv\n the University of Washington,  http://www.cs.washington.edu/education/courses/csep545/ , where you’ll ﬁ nd \nassignments, projects, and video-recorded lectures. \n The syllabus that has worked best for a formal university course is to use the ﬁ rst half of the course to \ncover Chapter 1 of this book followed by principles of concurrency control (Sections 6.1 – 6.4 of Chapter 6) \nand recovery (Chapter 7). These topics immerse students in challenging technical details that are best learned \nthrough structured homework assignments and are amenable to a conventional exam. This gets students to the \npoint where they can work on a course project. \n Transaction processing is a systems engineering problem, with many interacting parts. We have tried three \ndifferent kinds of course projects to help students deepen their understanding of how the parts ﬁ t together: case \nstudies of applications; building an application using commercial products (such as Microsoft .NET or Java \nEnterprise Edition); and building a transactional middleware system for running distributed transactions. The \nlast of these projects has been the most effective by far, from both the students ’ and instructor’s viewpoint. So \nin recent offerings, we require that all students do this project. \n The project involves building a skeleton of a travel reservation system for ﬂ ights, hotel rooms, and rental \ncars. This requires them to build a resource manager with locking and recovery, a two-phase commit proto-\ncol, and transactional middleware to move requests around. We found this was too much work for a 10-week \nquarter, even for graduate students who are full-time professional programmers. So we give them some of the \ncomponents to start with. The software is downloadable from the course web site. \n ACKNOWLEDGMENTS \n This book began over 20 years ago as course notes developed by the ﬁ rst author. Over the years, the course has \nbeen presented to over a thousand people at Digital Equipment Corp., the Wang Institute of Graduate Studies \n(gone, but not forgotten), Microsoft Corp., and University of Washington. The  “ students, ” most of them prac-\nticing engineers, suggested countless ideas that have become part of this book. We thank them all for the rich \ndetail they provided. \n Many people gave generously of their time to review selected chapters. They corrected our blunders, pointed \nout holes, and often ﬁ lled them in. We are very grateful to Brian Milnes, who reviewed the entire book in detail \nand added much from his experience in running large Internet TP systems. We greatly appreciate the help we \nreceived on various chapters from John Apps, Darach Ennis, Mike Keith, David Kubelka, Mark Little, Peter \nNiblett, Betty O’Neil, Pat O’Neil, Gera Shegalov, Tony Storey, Satish Thatte, Roger Wolter, and especially Lev \nNovik, who was a partner in developing the new section on multimaster replication. \n It was a major challenge to include many examples of products, applications, and benchmarks, and to get \nthem right. We could never have done it without the substantial assistance of the engineers who work on those \nartifacts. They reviewed several iterations, to help us think through every detail. While we take full responsibility\nfor any errors that slipped through, we are pleased to share the credit with Keith Evans, Max Feingold, Tom \nFreund, Jonathan Halliday, Jeurgen Hoeller, Rajkumar Irudayaraj, Jim Johnson, Ed Lassettre, Charles Levine, \nAnne Thomas Manes, Miko Matsumura, Laurence Melloul, Dean Meltz, Geoff Nichols, Greg Pavlik, Mike \nPizzo, Ian Robinson, Adrian Trenaman, Steve Vinoski, John Wells, and Jesse Yurkovich. \n Although much of this edition is new, much is not. In writing the ﬁ rst edition, we beneﬁ ted enormously \nfrom the help of Jim Gray and Joe Twomey. We also appreciate the help we received from Mario Bocca, Dexter \nBradshaw, Ian Carrie, Ed Cobb, Gagan Chopra, Dick Dievendorff, Keith Evans, Wayne Duquaine, Terry Dwyer, \nKo Fujimura, Per Gyllstrom, Vassos Hadzilacos, Brad Hammond, Pat Helland, Greg Hope, Larry Jacobs, Roger \nKing, Walt Kohler, Barbara Klein, Dave Lomet, Susan Malaika, Michael C. Morrison, M. Tamer Ozsu, Wes Saeger, \nDavid Schorow, Randy Smerik, Alex Thomasian, Karen Watterson, and Tom Wimberg. \n\n\nxvi  Preface\n We thank Vassos Hadzilacos, Nat Goodman, and the Addison-Wesley Publishing Company for permis-\nsion to republish excerpts from  Concurrency Control and Recovery in Database Systems , by P. Bernstein, \nV. Hadzilacos, and N. Goodman, primarily in Chapter 8. \n We thank our editors, Rick Adams, Diane Cerra, and Denise Penrose for their encouragement, ﬂ exibility, \nand good advice, as well as the production staff at Elsevier, and especially Jeff Freeland, for their efﬁ ciency and \ncareful attention in the production of the book. \n Finally , we thank our families and friends for indulging our moaning, keeping us happy, and accepting our \nlimited companionship without complaint, while all our discretionary time was consumed by this writing. It’s \nover  … for awhile    . \n \n\n\n Trademarks  \n \n The following trademarks or registered trademarks are the property of the following organizations: \n Dreamweaver is a trademark or registered trademark of Adobe Systems Incorporated. \n AMD is a trademark or registered trademark of Advanced Micro Devices, Inc. \n Amazon.com is a trademark or registered trademark of Amazon.com, Inc. \n Netscape is a trademark or registered trademark of AOL, LLC. \n Apache, Apache API, Apache ActiveMQ, Apache CXF, Apache HTTP Server, Apache Kandula2, Apache \nTomcat,  Apache OpenJPA, Apache Qpid, and Apache ServiceMix are trademarks or registered trademarks \nof The Apache Software Foundation. \n ARM is a trademark or registered trademark of ARM Limited. \n Atomikos is a trademark or registered trademark of Atomikos BVBA. \n Raima RDM is a trademark or registered trademark of Birdstep Technology ASA. \n VisiBroker is a trademark or registered trademark of Borland Software Corporation. \n SiteMinder and Unicenter are trademarks or registered trademarks of CA. \n RabbitMQ is a trademark or registered trademark of Cohesive Flexible Technologies Corporation and Lshift \nLtd. \n Eclipse, SOA Tools Platform Project, Rich Client Platform, and Higgins are trademarks or registered trade-\nmarks of The Eclipse Foundation. \n Delphi is a trademark or registered trademark of Embarcadero Technologies, Inc. \n Google is a trademark or registered trademark of Google, Inc. \n ACMS, DATATRIEVE, DECforms, DECdtm, Guardian, HP, Non-Stop, OpenView, OpenVMS, Pathway, \nReliable Transaction Router, TDMS, TP Ware, TP Web Connector, VAX, VMSCluster, and Web Services \nIntegration Toolkit are trademarks or registered trademarks of Hewlett-Packard Development Company. \n TPBroker is a trademark or registered trademark of Hitachi Computer Products, Inc. \n OpenAMQ is a trademark or registered trademark of iMatix Corporation. \n Intel is a trademark or registered trademark of Intel Corporation. \n i5/OS, AIX, CICS, DB2, IBM, IMS, Informix, OS/400, Power PC, Tivoli, Tx Series VSE, UDB, WebSphere, \nand zOS are trademarks or registered trademarks of International Business Machines Corporation. \n Linux is a trademark or registered trademark of the Linux Mark Institute. \n eXtremeDB and McObject are trademarks or registered trademarks of McObject LLC. \n Active Directory, BizTalk, Expression, Microsoft, SQL Server, Visual Basic, Visual C#, Visual J#, Visual \nStudio, Windows, Windows Cardspace, Windows Server, Windows Vista, and Xbox are trademarks or reg-\nistered trademarks of Microsoft Corporation. \n",
      "page_number": 10
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 18-25)",
      "start_page": 18,
      "end_page": 25,
      "detection_method": "topic_boundary",
      "content": "xviii  Trademarks\n Motorola is a trademark or registered trademark of Motorola, Inc. \n BPMN, CORBA, IIOP, Object Management Group, OMG, UML, and Uniﬁ ed Modeling Language are trade-\nmarks or registered trademarks of the Object Management Group. \n UNIX and X/Open are trademarks or registered trademarks of The Open Group. \n CDD, Coherence, Oracle, Rdb, Streams, TimesTen, TopLink, Tuxedo, and WebLogic are trademarks or regis-\ntered trademarks of Oracle Corporation. \n OW2 is a trademark or registered trademark of OW2 Consortium. \n Artix, Orbix, Sonic, Sonic ESB, and SonicMQ are trademarks or registered trademarks of Progress Software \nCorporation. \n Python is a trademark or registered trademark of The Python Software Foundation. \n Enterprise MRG, Hibernate, JBoss, and Red Hat are trademarks or registered trademarks of Red Hat, Inc. \n SABRE, Sabre Holdings, and Travelocity are trademarks or registered trademarks of an afﬁ liate of Sabre \nHoldings Corporation. \n Salesforce is a trademark or registered trademark of Salesforce.com, Inc. \n SPARC is a trademark or registered trademark of SPARC International. \n Spring Framework and SpringSource dm Server are trademarks or registered trademarks of SpringSource. \n MySQL, NetBeans, and all trademarks and logos that contain Java, Solaris, or Sun, are trademarks or regis-\ntered trademarks of Sun Microsystems, Inc. \n PowerBuilder and Sybase are trademarks or registered trademarks of Sybase, Inc. \n TIBCO and TIBCO Enterprise Message Service are trademarks or registered trademarks of Tibco Software, \nInc. \n TPC, TPC-A, TPC-B, TPC-C, TPC-E, and TPC-H are trademarks or registered trademarks of the Transaction \nProcessing Performance Council. \n Web Services Interoperability Organization and WS-I are trademarks or registered trademarks of the Web \nServices Interoperability Organization. \n Yahoo! is a trademark or registered trademark of Yahoo! Inc. \n FastCGI is © Copyright 1996 – 2008 by Open Market, Rob Saccoccio, and others. \n PostgreSQL is Copyright © 1996 – 2008 by the PostgreSQL Global Development Group. \n \n\n\n 1.1  THE BASICS \n The Problem \n A  business transaction is an interaction in the real world, usually between an enterprise and a person or \nanother enterprise, where something is exchanged. For example, it could involve exchanging money, products, \ninformation, or service requests. Usually some bookkeeping is required to record what happened. Often this \nbookkeeping is done by a computer, for better scalability, reliability, and cost. Communications between the \nparties involved in the business transaction is often done over a computer network, such as the Internet. This is \n transaction processing (TP) — the processing of business transactions by computers connected by computer \nnetworks. There are many requirements on computer-based transaction processing, such as the following: \n ■  A business transaction requires the execution of multiple operations. For example, consider the purchase \nof an item from an on-line catalog. One operation records the payment and another operation records \nthe commitment to ship the item to the customer. It is easy to imagine a simple program that would do \nthis work. However, when scalability, reliability, and cost enter the picture, things can quickly get very \ncomplicated. \n ■  Transaction volume and database size adds complexity and undermines efﬁ ciency. We’ve all had the expe-\nrience of being delayed because a sales person is waiting for a cash register terminal to respond or because \nit takes too long to download a web page. Yet companies want to serve their customers quickly and with \nthe least cost. \n ■  To scale up a system for high performance, transactions must execute concurrently. Uncontrolled con-\ncurrent transactions can generate wrong answers. At a rock concert, when dozens of operations are com-\npeting to reserve the same remaining seats, it’s important that only one customer is assigned to each seat. \nFairness is also an issue. For example, Amazon.com spent considerable effort to ensure that when its \nﬁ rst thousand Xboxes went on sale, each of the 50,000 customers who were vying for an Xbox had a fair \nchance to get one. \n ■  If a transaction runs, it must run in its entirety. In a retail sale, the item should either be exchanged for \nmoney or not sold at all. When failures occur, as they inevitably do, it’s important to avoid partially com-\npleted work, such as accepting payment and not shipping the item, or vice versa. This would make the \ncustomer or the business very unhappy. \n Introduction \n 1 \nCHAPTER\n\n\n2  CHAPTER 1 Introduction\n ■  Each transaction should either return an acknowledgment that it executed or return a negative acknowl-\nedgment that it did not execute. Those acknowledgments are important. If no acknowledgment arrives, \nthe user doesn’t know whether to resubmit a request to run the transaction again. \n ■  The system should be incrementally scalable. When a business grows, it must increase its capacity for run-\nning transactions, preferably by making an incremental purchase — not by replacing its current machine by \na bigger one or, worse yet, by rebuilding the application to handle the increased workload. \n ■  When an electronic commerce (e-commerce) web site stops working, the retail enterprise is closed for \nbusiness. Systems that run transactions are often  “ mission critical ” to the business activity they support. \nThey should hardly ever be down. \n ■  Records of transactions, once completed, must be permanent and authoritative. This is often a legal \nrequirement, as in ﬁ nancial transactions. Transactions must never be lost. \n ■  The system must be able to operate well in a geographically distributed environment. Often, this implies \nthat the system itself is distributed, with machines at multiple locations. Sometimes, this is due to a legal \nrequirement that the system must operate in the country where the business is performed. Other times, dis-\ntributed processing is used to meet technical requirements, such as efﬁ ciency, incremental scalability, and \nresistance to failures (using backup systems). \n ■  The system should be able to personalize each user’s on-line experience based on past usage patterns. \nFor a retail customer, it should identify relevant discounts and advertisements and offer products custom-\nized to that user. \n ■  The system must be able to scale up predictably and inexpensively to handle Internet loads of millions of \npotential users. There is no way to control how many users log in at the same time or which transactions \nthey may choose to access. \n ■  The system should be easy to manage. Otherwise, the system management staff required to operate a \nlarge-scale system can become too large and hence too costly. Complex system management also increases \nthe chance of errors and hence downtime, which in turn causes human costs such as increased stress and \nunscheduled nighttime work. \n In summary, transaction processing systems have to handle high volumes efﬁ ciently, avoid errors due to \nconcurrent operation, avoid producing partial results, grow incrementally, avoid downtime, never lose results, \noffer geographical distribution, be customizable, scale up gracefully, and be easy to manage. It’s a tall order. \nThis book describes how it’s done. It explains the underlying principles of automating business transactions, \nboth for traditional businesses and over the Internet; explores the complexities of fundamental technologies, \nsuch as logging and locking; and surveys today’s commercial transactional middleware products that provide \nfeatures necessary for building TP applications. \n What Is a Transaction? \n An  on-line transaction is the execution of a program that performs an administrative function by accessing a \nshared database, usually on behalf of an on-line user. Like many system deﬁ nitions, this one is impressionistic \nand not meant to be exact in all its details. One detail is important: A transaction is always the  execution of a \nprogram. The program contains the steps involved in the business transaction — for example, recording the sale \nof a book and reserving the item from inventory. \n\n\n We ’ll use the words  transaction program to mean the program whose execution is the transaction. \nSometimes the word  “ transaction ” is used to describe the message sent to a computer system to request the exe-\ncution of a transaction, but we’ll use different words for that: a  request message . So a transaction always means \nthe execution of a program. \n We say that a transaction performs an administrative function, although that isn’t always the case. For \nexample, it could be a real-time function, such as making a call in a telephone switching system or controlling \na machine tool in a factory process-control system. But usually there’s money involved, such as selling a ticket \nor transferring money from one account to another. \n Most transaction programs access shared data, but not all of them do. Some perform a pure communications \nfunction, such as forwarding a message from one system to another. Some perform a system administration \nfunction, such as resetting a device. An application in which no programs access shared data is not considered \ntrue transaction processing, because such an application does not require many of the special mechanisms that \na TP system offers. \n There is usually an on-line user, such as a home user at a web browser or a ticket agent at a ticketing device. \nBut some systems have no user involved, such as a system recording messages from a satellite. Some transac-\ntion programs operate  off-line , or in batch mode, which means that the multiple steps involved may take longer \nthan a user is able to wait for the program’s results to be returned — more than, say, ten seconds. For example, \nmost of the work to sell you a product on-line happens after you’ve entered your order: a person or robot gets \nyour order, picks it from a shelf, deletes it from inventory, prints a shipping label, packs it, and hands it off to \nthe shipping company. \n Transaction Processing Applications \n A  transaction processing application is a collection of transaction programs designed to do the functions \nnecessary to automate a given business activity. The ﬁ rst on-line transaction processing application to receive \nwidespread use was an airline reservation system: the SABRE system developed in the early 1960s as a joint \nventure between IBM and American Airlines. SABRE was one of the biggest computer system efforts under-\ntaken by anyone at that time, and still is a very large TP system. SABRE was spun off from American Airlines \nand is now managed by a separate company, Sabre Holdings Corporation, which provides services to more \nthan 200 airlines and thousands of travel agencies, and which runs the Travelocity web site. It can handle a \nlarge number of ﬂ ights, allow passengers to reserve seats and order special meals months in advance, offer \nbonuses for frequent ﬂ yers, and schedule aircraft maintenance and other operational activities for airlines. Its \npeak performance has surpassed 20,000 messages per second. \n Today , there are many other types of TP applications and new ones are emerging all the time. We sum-\nmarize some of them in  Figure 1.1 . As the cost of running transactions and of managing large databases \ndecreases, more types of administrative functions will be worth automating as TP applications, both to reduce \nthe cost of administration and to generate revenue as a service to customers. \n In its early years, the TP application market was driven primarily by large companies needing to support \nadministrative functions for large numbers of customers. Such systems often involve thousands of terminals, \ndozens of disk drives, and many large processors, and can run hundreds of thousands of transactions per day. \nLarge TP systems are becoming even more important due to the popularity of on-line services on the Internet. \nHowever, with the downsizing of systems has come the need for small TP applications too, ones with just a \nfew browsers connected to a small server machine, to handle orders for a small catalog business, course reg-\nistrations for a school, or patient visits to a dental ofﬁ ce. All these applications — large and small — rely on the \nsame underlying system structure and software abstractions. \n1.1 The Basics  3\n\n\n4  CHAPTER 1 Introduction\n TP systems also are being offered as services to other companies. For example, Amazon.com hosts other \ncompanies ’ web storefronts. Some airlines develop and operate reservation services for other airlines. Some \nvendors of packaged applications are now offering their application as a service that can be invoked by a third \nparty’s application over the Internet, which in turn helps the third party offer other TP services to their custom-\ners. Given the expense, expertise, and management attention required to build and run a high-quality TP sys-\ntem, this trend toward out-sourcing TP applications is likely to grow. \n A Transaction Program’s Main Functions \n A transaction program generally does three things: \n 1.  Gets input from a web browser or other kind of device, such as a bar-code reader or robot sensor. \n 2.  Does the real work being requested. \n 3.  Produces a response and, possibly, sends it back to the browser or device that provided the input. \n Each invocation of the transaction program results in an independent unit of work that executes exactly \nonce and produces permanent results. We’ll have more to say about these properties of a transaction program \nshortly. \n Most TP applications include some code that does not execute as a transaction. This other code executes \nas an ordinary program, not necessarily as an independent unit of work that executes exactly once and pro-\nduces permanent results. We use the term TP application in this larger sense. It includes transaction programs, \nprograms that gather input for transactions, and maintenance functions, such as deleting obsolete inventory \nrecords, reconﬁ guring the runtime system, and updating validation tables used for error-checking. \nApplication\nExample Transaction\nBanking\nWithdraw money from an account\nSecurities trading\nPurchase 100 shares of stock\nInsurance\nPay an insurance premium\nInventory control\nRecord the fulfillment of an order\nManufacturing\nLog a step of an assembly process\nRetail point-of-sale\nRecord a sale\nGovernment\nRegister an automobile\nOnline shopping\nPlace an order using an on-line catalog\nTransportation\nTrack a shipment\nTelecommunications\nConnect a telephone call\nMilitary Command and Control\nFire a missile\nMedia\nGrant permission to download a video\n FIGURE 1.1 \n Transaction Processing Applications. Transaction processing covers most sectors of the economy. \n\n\n 1.2  TP SYSTEM ARCHITECTURE \n A  TP system is the computer system — both hardware and software — that hosts the transaction programs. The \nsoftware parts of a TP system usually are structured in a special way. As you can see from  Figure 1.2 , the TP \nsystem has several main components. Different parts of the application execute in each of these components. \n 1.  End-user device: An  end user is someone who requests the execution of transactions, such as a customer \nof a bank or of an Internet retailer. An end-user device could be a physical device, such as a cash register \nor gasoline pump. Or it could be a web browser running on a desktop device, such as a personal computer \n(PC). If it is a dumb device, it simply displays data that is sent to it and sends data that the user types in. \nIf it is a smart device, then it executes application code that is the front-end program. \n 2.  Front-end program: A  front-end program is an application code that interacts with the end-user device. \nUsually it sends and receives menus and forms, to offer the user a selection of transactions to run and \nto collect the user’s input. Often, the device is a web browser and the front-end program is an applica-\ntion managed by a web server that communicates with the browser via HTTP. The front-end program \nvalidates the user’s input and then sends a request message to another part of the system whose job is to \nactually execute the transaction. \n 3.  Request controller: A  request controller is responsible for receiving messages from front-end programs \nand turning each message into one or more calls to the proper transaction programs. In a centralized \nsystem, this is simply a matter of calling a local program. In a distributed TP system, it requires sending \nthe message to a system where the program exists and can execute. If more than one program is needed, \nit tracks the state of the request as it moves between programs. \n 4.  Transaction server: A  transaction server is a process that runs the parts of the transaction program that \nperform the work the user requested, typically by reading and writing a shared database, possibly call-\ning other programs, and possibly returning a reply that is routed back to the device that provided the \ninput for the request. \n 5.  Database system: A  database system manages shared data that is needed by the application to do its job. \nIf Buy-a-Book\n  {call  A}; \nIf Find-Order\n  {call  B}; \nIf Cancel-Order\n  {call C};\nTransaction\nServer A \nRequest\nController\nEnd-user\nDevice \nDatabase\nFront-end\nProgram\nSend Form\nReceive Form\nBuy-a-Book \nBook: \nAmount:\nBuy-a-Book \nBook: TP\n$50\nAmount:\n FIGURE 1.2 \n Transaction Application Parts. A transaction application gathers input, routes the input to a program that can execute the \nrequest, and then executes the appropriate transaction program. \n1.2 TP System Architecture  5\n\n\n6  CHAPTER 1 Introduction\n For example, in an Internet-based order processing application, a user submits orders via a web browser. \nThe front-end program is managed by a web server, which reads and writes forms and menus and perhaps \nmaintains a shopping cart. A request controller routes requests from the web server to the transaction server \nthat can process the order the user requested. The transaction server processes the order, which requires access-\ning the database that keeps track of orders, catalog information, and warehouse inventory, and perhaps contacts \nanother transaction server to bill a credit card for the order. \n The transaction programs that run in the server are of a limited number of types that match operational busi-\nness procedures, such as shipping an order or transferring funds. Typically there are a few dozen and usually no \nmore than a few hundred. When applications become larger than this, usually they are partitioned into indepen-\ndent applications of smaller size. Each one of these programs generally does a small amount of work. There’s \nno standard concept of an average size of a transaction program, because they all differ based on the applica-\ntion. But a typical transaction might have between zero and 30 disk accesses, a few thousand up to a few million \ninstructions, and at least two messages, but often many more depending on how distributed it is. It may be dis-\ntributed because different application services are needed to process it or because multiple machines are needed \nto handle the application load. The program generally is expected to execute within a second or two, so that the \nuser can get a quick response. Later on we’ll see another, more technical reason for keeping transactions short, \nhaving to do with locking conﬂ icts. \n Database systems play a big role in supporting transaction programs, often a bigger role than the applica-\ntion programs themselves. Although the database can be small enough to ﬁ t in main memory, it is often much \nlarger than that. Some databases for TP require a large number of nonvolatile storage devices, such as mag-\nnetic or solid state disks, pushing both storage and database system software technology to the limit. To scale \neven larger, the database may be replicated or partitioned onto multiple machines. \n Another major category of TP software products is  transactional middleware , which is a layer of software \ncomponents between TP applications and lower level components such as the operating system, database sys-\ntem, and system management tools. These components perform a variety of functions. They can help the appli-\ncation make the most efﬁ cient use of operating system processes, database connections, and communications \nsessions, to enable an application to scale up. For example, they may provide functions that client applications \ncan use to route requests to the right server applications. They can integrate the transaction abstraction with the \napplication, operating system, and database system, for example, to enable the execution of distributed transac-\ntions, sometimes across heterogeneous environments. They can integrate system management tools to simplify \napplication management, for example, so that system managers can balance the load across multiple servers in \na distributed system. And they may offer a programming interface and/or  conﬁ gurable properties that simplify \nthe use of related services that originate in the operating system and database system. \n Transactional middleware product categories have evolved rapidly over the past ﬁ fteen years. Before the advent \nof the World Wide Web (WWW), transactional middleware products were called TP monitors or on-line TP (OLTP) \nmonitors. During the mid 1990s, application server products were introduced to help application developers cope \nwith new problems introduced by the Web, such as integrating with web servers and web browsers. Initially, appli-\ncation servers formed a bridge between existing commercial systems managed by TP monitors and the Internet. In \na relatively short time, the functionality of application servers and TP monitors converged. During the same period, \nmessage-oriented transactional middleware and object request brokers became popular. Message-oriented middle-\nware became the foundation of a product category called enterprise application integration systems. The adoption \nof standard Internet-based protocols for application communication, called Web Services, has led to the enterprise \nservice bus, another transactional middleware product. And ﬁ nally, workﬂ ow products have become popular to \nhelp users deﬁ ne and manage long-running business processes. Although transactional middleware products usu-\nally are marketed as a complete environment for developing and executing TP applications, customers sometimes \nuse components from multiple transactional middleware products to assemble their TP environments. \n\n\n Service Oriented Computing \n Service Oriented Architecture (SOA) is a style of design in which applications are composed in whole or in \npart of reusable services. SOA aligns information systems technology well with business objectives by mod-\neling an application as a composition of reusable services. In contrast to the object-oriented (OO) paradigm, \nservices are designed to model functions rather than things. They are a natural abstraction of the concept of \nbusiness services; that is, services that a business provides to its customers and partners. A service can be \nimplemented using an object, but it need not be. For example, it may be implemented using a procedure, stored \nprocedure, asynchronous message queue, or script. Services are characterized by the messages they exchange \nand by the interface contracts deﬁ ned between the service requester and provider, rather than by the programs \nthat are used to implement them. \n Service orientation has been around for a long time as a concept. However, only recently has it become \nmainstream, with many large-scale web sites for web search, social networking, and e-commerce now offer-\ning service-oriented access to their functions. In part, this wide availability is due to the advent of standard \nWeb Services protocols. Web Services is an implementation technology that enables independent programs \nto invoke one another reliably and securely over a network, especially the Internet. Many vendors now sup-\nport Web Services protocols. This enables one to implement SOA in a multivendor environment, which is a \nrequirement for most enterprises. \n A TP system that is created in whole or in part using the SOA approach may include multiple reusable \nservices offered by a single transaction program or by multiple distributed services. An SOA-based TP system \nmay include both synchronous and asynchronous communications mechanisms, depending on the message \nexchange patterns that a given service supports and the execution environment in which it runs. SOA-based TP \nsystems may be assembled using a combination of services from a variety of applications and using a variety \nof operating systems, middleware platforms, and programming languages. \n Figure 1.3 illustrates the components of a service-oriented architecture. They include a service provider that \noffers a service, a requester that invokes a service, and a registry (sometimes called a repository) that publishes \nservice descriptions. The service descriptions typically include the service interface, the name and format of \ndata to be exchanged, the communications protocol to be used, and the quality of service that the interaction is \nrequired to support (such as its security and reliability characteristics and its transaction behavior). \n A caller communicates with a service by sending messages, guided by a message exchange pattern. The \nbasic pattern is a one-way asynchronous request message, where a caller sends a request message to the ser-\nvice provider and the service provider receives the message and executes the requested service. Other common \npatterns are request-response and publish-subscribe. \nRegistry \nService\nRequester\nService\nProvider\nPublish (WSDL)\nFind (UDDI) \nInvoke (SOAP)\n FIGURE 1.3 \n Basic Architecture of Service Orientation. A service provider publishes its interface in the registry. A service requester \nuses the registry to ﬁ nd a service provider and invokes it. The corresponding Web Service technologies are WSDL, \nUDDI, and SOAP. \n1.2 TP System Architecture  7\n",
      "page_number": 18
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 26-33)",
      "start_page": 26,
      "end_page": 33,
      "detection_method": "topic_boundary",
      "content": "8  CHAPTER 1 Introduction\n The registry is an optional component because the requester can obtain service description information in \nother ways. For example, a developer who writes the requester can ﬁ nd the service description on a web site or \nbe given the service description by the service’s owner. \n One mechanism to implement SOA is Web Services, where a service requester invokes a service provider \nusing the protocol SOAP. 1 The service interface offered by the service provider is deﬁ ned in the Web Services \nDescription Language (WSDL). The service provider makes this interface known by publishing it in a regis-\ntry. The registry offers access to service descriptions via the Universal Description, Discovery, and Integration \n(UDDI) protocol. A service requester and provider can be running in different execution environments, such as \nJava Enterprise Edition or Microsoft. NET. \n Web Service interfaces are available for virtually all information technology product categories: application \nservers, object request brokers, message oriented middleware systems, database management systems, and pack-\naged applications. Thus, they provide  interoperability , meaning that applications running on disparate software \nsystems can communicate with each other. Web Services support transaction interoperability too, as deﬁ ned in \nthe Web Services Transactions speciﬁ cations (discussed in Section 10.8). \n Services simplify the assembly of new applications from existing ones by combining services. Tools and \ntechniques are emerging to simplify the assembly of services, such as the Service Component Architecture for \nJava and the Windows Communication Foundation for Windows. \n A TP application may exist as a combination of reusable services. The use of reusable services doesn’t change \nthe functions of the front-end program, request controller, or transaction server. However, it may affect the way \nthe functions are designed, modeled, and implemented. For example, in  Figure 1.2 , the decision to build the \nrequest controller as a reusable Web Service may affect the choice of implementation technologies, such as deﬁ n-\ning the interface to the request controller using WSDL and invoking it using SOAP. That decision may also affect \nthe design by enabling an end-user device such as a web browser to call the request controller service(s) directly, \nbypassing the front-end program. We’ll talk a lot more about TP software architecture in Chapter 3. \n Representational State Transfer (REST) is another approach to SOA, rather different than that of Web \nServices. The term REST is used in two distinct but related ways: to denote the protocol infrastructure used for \nthe World Wide Web, namely the Hypertext Transfer Protocol (HTTP); and to denote a software architectural \npattern that can be implemented by web protocols. We use it here in the former sense, which we call REST/\nHTTP. We will discuss the REST architectural pattern in Section 3.3. \n REST /HTTP focuses on the reuse of resources using a small set of generic HTTP operations, notably GET \n(i.e., read), PUT (i.e., update), POST (i.e., insert), and DELETE. This is in contrast to Web Services, which uses \nservices that are customized for a particular application. Each HTTP operation is applied to a resource identi-\nﬁ ed by a Uniform Resource Identiﬁ er (URI). A registry function, as shown in  Figure 1.3 , is needed to translate \neach URI into a network address where the resource can be found. On the Internet, this is implemented by the \nDomain Name System, which translates domain names such as  www.mydomain.com into IP addresses. \n In REST, generic HTTP operations are used to perform application-speciﬁ c functions. For example, instead of \ninvoking a Web Service AddCustomer, you could use REST to invoke the POST operation with a URI that makes \nit clear that a customer is being inserted, such as  www.company-xyz.com/customers . In general, the application-\nspeciﬁ c information that identiﬁ es the function and its parameters must be embodied in the representation of the \nresource. This is why this style of communication is called representational state transfer. In practice, the represen-\ntation that is transferred is often in a standard, stylized form, such as JavaScript Object Notation (JSON). \n The format of the representation is speciﬁ ed in the HTTP header; the  content-type and  accept ﬁ elds \nspecify the format of the input and output, respectively. Thus, instead of specifying data types in a service’s \n 1 Originally, SOAP was an acronym for Simple Object Access Protocol. However, the SOAP 1.2 speciﬁ cation explicitly says it should \nno longer be treated as an acronym. \n\n\n interface deﬁ nition, the caller speciﬁ es the data types it would like to receive. This ﬂ exibility makes it easier \nfor diverse kinds of callers to invoke the service. \n REST /HTTP is popular for its speed and simplicity. Web Services require parameters in SOAP messages to \nbe represented in XML, which is expensive to parse. XML is self-describing and highly interoperable, but these \nbeneﬁ ts are not always important, for example, for simple services. A very simple interface makes it easier and \nfaster to manipulate in limited languages such as JavaScript. \n Hardware Architecture \n The computers that run these programs have a range of processing power. A display device could be a character-\nat-a-time terminal, a handheld device, a low-end PC, or a powerful workstation. Front-end programs, request \ncontrollers, transaction servers, and database systems could run on any kind of server machine, ranging from a \nlow-end server machine, to a high-end multiprocessor mainframe, to a distributed system. A distributed system \ncould consist of many computers, localized within a machine room or campus or geographically dispersed in a \nregion or worldwide. \n Some of these systems are quite small, such as a few display devices connected to a small machine on a PC \nLocal Area Network (LAN). Big TP systems tend to be enterprise- wide or Internet-wide, such as airline and \nﬁ nancial systems, Internet retailers, and auction sites. The big airline systems have on the order of 100,000 dis-\nplay devices (terminals, ticket printers, and boarding-pass printers) and thousands of disk drives, and execute \nthousands of transactions per second at their peak load. The biggest Internet systems have hundreds of millions \nof users, with tens of millions of them actively using the system at any one time. \n Given this range of capabilities of computers that are used for TP, we need some terminology to distinguish \namong them. We use standard words for them, but in some cases with narrower meanings than is common in \nother contexts. \n We deﬁ ne a  machine to be a computer that is running a single operating system image. It could use a single-\ncore or multicore processor, or it could be a shared-memory multiprocessor. Or it might be a virtual machine \nthat is sharing the underlying hardware with other virtual machines. A  server machine is a machine that exe-\ncutes programs on behalf of client programs that typically execute on other computers. A  system is a set of one \nor more machines that work together to perform some function. For example, a  TP system is a system that sup-\nports one or more TP applications. A  node (of a network) is a system that is accessed by other machines as if it \n were one machine. It may consist of several machines, each with its own network address. However, the system \nas a whole also has a network address, which is usually how other machines access it. \n A  server process is an operating system process,  P , that executes programs on behalf of client programs exe-\ncuting in other processes on the same or different machines as the one where  P is running. We often use the word \n “ server ” instead of  “ server machine ” or  “ server process ” when the meaning is obvious from context. \n 1.3  ATOMICITY, CONSISTENCY, ISOLATION, AND DURABILITY \n There are four critical properties of transactions that we need to understand at the outset: \n ■  Atomicity: The transaction executes completely or not at all. \n ■  Consistency: The transaction preserves the internal consistency of the database. \n ■  Isolation: The transaction executes as if it were running alone, with no other transactions. \n ■  Durability: The transaction’s results will not be lost in a failure. \n1.3 Atomicity, Consistency, Isolation, and Durability  9\n\n\n10  CHAPTER 1 Introduction\n This leads to an entertaining acronym, ACID. People often say that a TP system executes ACID transac-\ntions, in which case the TP system has  “ passed the ACID test. ” Let’s look at each of these properties in turn and \nexamine how they relate to each other. \n Atomicity \n First , a transaction needs to be  atomic (or  all-or-nothing ), meaning that it executes completely or not at all. \nThere must not be any possibility that only part of a transaction program is executed. \n For example, suppose we have a transaction program that moves $100 from account A to account B. It takes \n$100 out of account A and adds it to account B. When this runs as a transaction, it has to be atomic — either both \nor neither of the updates execute. It must not be possible for it to execute one of the updates and not the other. \n The TP system guarantees atomicity through database mechanisms that track the execution of the transac-\ntion. If the transaction program should fail for some reason before it completes its work, the TP system will \nundo the effects of any updates that the transaction program has already done. Only if it gets to the very end and \nperforms all of its updates will the TP system allow the updates to become a permanent part of the database. \n If the TP system fails, then as part of its recovery actions it undoes the effects of all updates by all transac-\ntions that were executing at the time of the failure. This ensures the database is returned to a known state fol-\nlowing a failure, reducing the requirement for manual intervention during restart. \n By using the atomicity property, we can write a transaction program that emulates an atomic business trans-\naction, such as a bank account withdrawal, a ﬂ ight reservation, or a sale of stock shares. Each of these business \nactions requires updating multiple data items. By implementing the business action by a transaction, we ensure \nthat either all the updates are performed or none are. \n The successful completion of a transaction is called  commit . The failure of a transaction is called  abort . \n Handling Real-World Operations \n During its execution, a transaction may produce output that is displayed back to the user. However, since the \ntransaction program is all-or-nothing, until the transaction actually commits, any results that the transaction \nmight display to the user should not be taken seriously, because it’s still possible that the transaction will abort. \nAnything displayed on the display device could be wiped out in the database on abort. \n Thus , any value that the transaction displays may be used by the end-user only if the transaction commits \nand not if the transaction aborts. This requires some care on the part of users (see  Figure 1.4 ). If the system \nactually displays some of the results of a transaction before the transaction commits, and if the user utilizes \nany of these results as input to another transaction, then we have a problem. If the ﬁ rst transaction aborts and \nthe second transaction commits, then the all-or-nothing property has been broken. That is, some of the results \nof the ﬁ rst transaction will be reﬂ ected in the results of the second transaction. But other results of the ﬁ rst \ntransaction, such as its database updates, were not performed because the transaction aborted. \n Some systems solve this problem simply by not displaying the result of a transaction until after the transac-\ntion commits, so the user can’t inadvertently make use of the transaction’s output and then have it subsequently \nabort. But this too has its problems (see  Figure 1.5 ): If the transaction commits before displaying any of its \nresults, and the system crashes before the transaction actually displays any of the results, then the user won’t \nget a chance to see the output. Again, the transaction is not all-or-nothing; it executed all its database updates \nbefore it committed, but did not display its output. \n We can make the problem more concrete by looking at it in the context of an automated teller machine \n(ATM) (see  Figure 1.6 ). The output, for example, may be an operation that dispenses $100 from the ATM. If \nthe system dispenses the $100 before the transaction commits, and the transaction ends up aborting, then the \n\n\n bank gives up the money but does not record that fact in the database. If the transaction commits and the sys-\ntem fails before it dispenses the $100, then the database says the $100 was given to the customer, but in fact \nthe customer never got the money. In both cases, the transaction’s behavior is not all-or-nothing. \n A closely-related problem is that of ensuring that each transaction executes exactly once. To do this, the \ntransaction needs to send an acknowledgment to its caller, such as sending a message to the ATM to dispense \nmoney, if and only if it commits. However, sending this acknowledgment is not enough to guarantee exactly-\nonce behavior because the caller cannot be sure how to interpret the absence of an acknowledgment. If the caller \nfails to receive an acknowledgment, it might be because the transaction aborted, in which case the caller needs to \nresubmit a request to run a transaction (to ensure the transaction executes once). Or it might be that the transac-\ntion committed but the acknowledgment got lost, in which case the caller must not resubmit a request to run the \ntransaction because that would cause the transaction to execute twice. So if the caller wants exactly-once behav-\nior, it needs to be sure that a transaction did not and will not commit before it’s safe to resubmit the request to \nrun the transaction. \n Although these seem like unsolvable problems, they can actually be solved using persistent queues, which \nwe’ll describe in some detail in Chapter 4. \nT1: Start\n \n read/write database\n \n . . .\n \n display results\n \n . . .\n \n error detected\n    If error then Abort\nT2: Start\n     display form\n     . . .\n     get input from display\n     . . .\n   Commit\nUser sees results\nUser provides input\n FIGURE 1.4 \n Reading Uncommitted Results. The user read the uncommitted results of transaction T 1  and fed them as input to \ntransaction T2. Since T1 aborts, the input to T2 is incorrect. \nT1: Start\n \n . . .\n    Commit\nDisplay results\nSystem crashes, so user \nnever sees the results.\n FIGURE 1.5 \n Displaying Results after Commits. This solves the problem of  Figure 1.4 , but if the transaction crashes before displaying \nthe results, the results are lost forever. \n1.3 Atomicity, Consistency, Isolation, and Durability  11\n\n\n12  CHAPTER 1 Introduction\n Compensating Transactions \n Commitment is an irrevocable action. Once a transaction is committed, it can no longer be aborted. People \ndo make mistakes, of course. So it may turn out later that it was a mistake to have executed a transaction that \ncommitted. At this point, the only course of action is to run another transaction that reverses the effect of the \none that committed. This is called a  compensating transaction . For example, if a deposit transaction was in \nerror, then one can later run a withdrawal transaction that reverses its effect. \n Sometimes , a perfect compensation is impossible, because the transaction performed some irreversible act. \nFor example, it may have caused a paint gun to spray-paint a part the wrong color, and the part is long gone \nfrom the paint gun’s work area when the error is detected. In this case, the compensating transaction may be to \nrecord the error in a database and send an e-mail message to someone who can take appropriate action. \n Virtually any transaction can be executed incorrectly. So a well-designed TP application should include a \ncompensating transaction type for every type of transaction. \n Multistep Business Processes \n Some business activities do not execute as a single transaction. For example, the activity of recording an order \ntypically executes in a separate transaction from the one that processes the order. Since recording an order is \nrelatively simple, the system can give excellent response time to the person who entered the order. The process-\ning of the order usually requires several time-consuming activities that may require multiple transactions, such \nas checking the customer’s credit, forwarding the order to a warehouse that has the requested goods in stock, \nand fulﬁ lling the order by picking, packing, and shipping it. \n Even though the business process executes as multiple transactions, the user may still want atomicity. Since \nmultiple transactions are involved, this often requires compensating transactions. For example, if an order is \naccepted by the system in one transaction, but later on another transaction determines that the order can’t be ful-\nﬁ lled, then a compensating transaction is needed to reverse the effect of the transaction that accepted the order. \nTo avoid an unhappy customer, this often involves the universal compensating transaction, namely, an apology \nand a free gift certiﬁ cate. It might also involve offering the customer a choice of either cancelling or telling the \nretailer to hold the order until the requested items have been restocked. \nStart\n     Record withdrawal\n     Dispense money\nCommit\nStart\n     Record withdrawal\nCommit\nDispense money\nTeller Machine \nTransaction 1\nSystem crashes and\ntransaction aborts,\nbut money is dispensed.\n(Bank is unhappy.)\nTransaction commits,\nthen the system crashes,\nso the money is not dispensed.\n(Customer is unhappy.)\nTeller Machine \nTransaction 2\n FIGURE 1.6 \n The Problem of Getting All-or-Nothing Behavior with Real-World Operations. Whether the program dispenses money before \nor after it commits, it’s possible that only one of the operations executes: dispense the money or record the withdrawal. \n\n\n Transactional middleware can help manage the execution of multistep business processes. For example, it \ncan keep track of the state of a multistep process, so if the process is unable to complete then the middleware \ncan invoke compensating transactions for the steps that have already executed. These functions and others are \ndiscussed in Chapter 5,  Business Process Management . \n Consistency \n A second property of transactions is consistency — a transaction program should maintain the consistency of \nthe database. That is, if you execute the transaction all by itself on a database that’s initially consistent, then \nwhen the transaction ﬁ nishes executing the database is again consistent. \n By consistent, we mean  “ internally consistent. ” In database terms, this means that the database at least satis-\nﬁ es all its integrity constraints. There are several kinds of integrity constraints that database systems can typically \nmaintain: \n ■  All primary key values are unique (e.g., no two employee records have the same employee number). \n ■  The database has referential integrity, meaning that records reference only objects that exist (e.g., the Part \nrecord and Customer record that are referenced by an Order record really exist). \n ■  Certain data values are in a particular range (e.g., age is less than 120 and social security number is not null). \n There are other kinds of integrity constraints that database systems typically cannot maintain but may nev-\nertheless be important, such as the following: \n ■  The sum of expenses in each department is less than or equal to the department’s budget. \n ■  The salary of an employee is bounded by the salary range of the employee’s job level. \n ■  The salary of an employee cannot decrease unless the employee is demoted to a lower job level. \n Ensuring that transactions maintain the consistency of the database is good programming practice. However, \nunlike atomicity, isolation, and durability, consistency is a responsibility shared between transaction programs \nand the TP system that executes those programs. That is, a TP system ensures that transactions are atomic, \nisolated, and durable, whether or not they are programmed to preserve consistency. Thus, strictly speaking, the \nACID test for transaction systems is a bit too strong, because the TP system does its part for the C in ACID \nonly by guaranteeing AID. It’s the application programmer’s responsibility to ensure the transaction program \npreserves consistency. \n There are consistency issues that reach out past the TP system and into the physical world that the TP \napplication describes. An example is the constraint that the number of physical items in inventory equals the \nnumber of items on the warehouse shelf. This constraint depends on actions in the physical world, such as cor-\nrectly reporting the restocking and shipment of items in the warehouse. Ultimately, this is what the enterprise \nregards as consistency. \n Isolation \n The third property of a transaction is called  isolation . We say that a set of transactions is isolated if the effect \nof the system running them is the same as if the system ran them one at a time. The technical deﬁ nition of iso-\nlation is serializability. An execution is  serializable (meaning isolated) if its effect is the same as running the \ntransactions serially, one after the next, in sequence, with no overlap in executing any two of them. This has \nthe same effect as running the transactions one at a time. \n A classic example of a non-isolated  execution is a banking system, where two transactions each try to with-\ndraw the last $100 in an account. If both transactions read the account balance before either of them updates it, \n1.3 Atomicity, Consistency, Isolation, and Durability  13\n\n\n14  CHAPTER 1 Introduction\n then both transactions will determine there’s enough money to satisfy their requests, and both will withdraw the \nlast $100. Clearly, this is the wrong result. Moreover, it isn’t a serializable result. In a serial execution, only the \nﬁ rst transaction to execute would be able to withdraw the last $100. The second one would ﬁ nd an empty account. \n Notice that isolation is different from atomicity. In the example, both transactions executed completely, so \nthey were atomic. However, they were not isolated and therefore produced undesirable behavior. \n If the execution is serializable, then from the point of view of an end-user who submits a request to run a \ntransaction, the system looks like a standalone system that’s running that transaction all by itself. Between the \ntime he or she runs two transactions, other transactions from other users may run. But during the period that the \nsystem is processing that one user’s transaction, the user has the illusion that the system is doing no other work. \nThis is only an illusion. It’s too inefﬁ cient for the system to actually run transactions serially, because there is a \nlot of internal parallelism in the system that must be exploited by running transactions concurrently. \n If each transaction preserves consistency, then any serial execution (i.e., sequence) of such transactions pre-\nserves consistency. Since each serializable execution is equivalent to a serial execution, a serializable execution \nof the transactions will preserve database consistency too. It is the combination of transaction consistency and \nisolation that ensures that the execution of a set of transactions preserves database consistency. \n The database typically sets locks on data accessed by each transaction. The effect of setting the locks is to \nmake the execution appear to be serial. In fact, internally, the system is running transactions in parallel, but \nthrough this locking mechanism the system gives the illusion that the transactions are running serially, one after \nthe next. In Chapter 6, we will describe those mechanisms in more detail and present the rather subtle argument \nwhy locking actually produces serializable executions. \n A common misconception is that serializability isn’t important because the database system will maintain \nconsistency by enforcing integrity constraints. However, as we saw in the previous section on consistency, there \nare many consistency constraints that database systems can’t enforce. Moreover, sometimes users don’t tell the \ndatabase system to enforce certain constraints because they degrade performance. The last line of defense is \nthat the transaction program itself maintains consistency and that the system guarantees serializability. \n Durability \n The fourth property of a transaction is durability.  Durability means that when a transaction completes execut-\ning, all its updates are stored in  stable storage ; that is, storage that will survive the failure of power or the \noperating system. Today, stable storage (also called  nonvolatile or  persistent storage ) typically consists of \nmagnetic disk drives, though solid-state disks that use ﬂ ash memory are making inroads as a viable alternative. \nEven if the transaction program fails, or the operating system fails, once the transaction has committed, its \nresults are durably stored on stable storage and can be found there after the system recovers from the failure. \n Durability is important because each transaction usually is providing a service to the user that amounts \nto a contract between the user and the enterprise that is providing the service. For example, if you’re moving \nmoney from one account to another, once you get a reply from the transaction saying that it executed, you \nexpect that the result is permanent. It’s a legal agreement between the user and the system that the money has \nbeen moved between these two accounts. So it’s essential that the transaction actually makes sure that the \nupdates are stored on some stable storage device, to ensure that the updates cannot possibly be lost after the \ntransaction ﬁ nishes executing. Moreover, the durability of the result must be maintained for a long period, until \nit is explicitly overwritten or deleted by a later transaction. For example, even if a checking account is unused \nfor several years, the owner expects to ﬁ nd her money there the next time she accesses it. \n The durability property usually is obtained by having the TP system append a copy of all the transaction’s \nupdates to a log ﬁ le while the transaction program is running. When the transaction program issues the com-\nmit operation, the system ﬁ rst ensures that all the records written to the log ﬁ le are out on stable storage, and then \n\n\n returns to the transaction program, indicating that the transaction has indeed committed and that the results are \ndurable. The updates may be written to the database right away, or they may be written a little later. However, if the \nsystem fails after the transaction commits and before the updates go to the database, then after the system recovers \nfrom the failure it must repair the database. To do this, it reads the log and checks that each update by a commit-\nted transaction actually made it to the database. If not, it reapplies the update to the database. When this recovery \nactivity is complete, the system resumes normal operation. Thus, after the system recovers, any new transaction \nwill read a database state that includes all the updates of transactions that committed before the failure (as well as \nthose that committed after the recovery). We describe log-based recovery algorithms in Chapter 7. \n 1.4  TWO-PHASE COMMIT \n When a transaction updates data on two or more database systems, we still have to ensure the atomicity property, \nnamely, that either both database systems durably install the updates or neither does. This is challenging, because \nthe database systems can independently fail and recover. This is certainly a problem when the database systems \nreside on different nodes of a distributed system. But it can even be a problem on a single machine if the database \nsystems run as server processes with private storage since the processes can fail independently. The solution is a \nprotocol called  two-phase commit ( 2PC ), which is executed by a module called the  transaction manager . \n The crux of the problem is that a transaction can commit its updates on one database system, but a second \ndatabase system can fail before the transaction commits there too. In this case, when the failed system recov-\ners, it must be able to commit the transaction. To commit the transaction, the recovering system must have a \ncopy of the transaction’s updates that executed there. Since a system can lose the contents of main memory \nwhen it fails, it must store a durable copy of the transaction’s updates before it fails, so it will have them after \nit recovers. This line of reasoning leads to the essence of two-phase commit: Each database system accessed \nby a transaction must durably store its portion of the transaction’s updates before the transaction commits any-\nwhere. That way, if a system  S fails after the transaction commits at another system  S \u0003 but before the transac-\ntion commits at  S , then the transaction can commit at  S after  S recovers (see  Figure 1.7 ). \nNew York System\nUpdate X\nCommit\na.  Without two-phase commit.  The \n  transaction updates X and Y, but\n   the failure causes the update to \n   Y to be lost.\nb.  With two-phase commit.  The London\n   system durably saved the update to Y,\n   so it can commit after it recovers.\nLondon System\nUpdate Y\nSystem fails\n. . .\nSystem recovers\nThe system lost the update to\nY when it failed, so it can’t\ncommit the transaction after\nit recovers.\nSince the system saved the\nupdate to disk before it failed,\nit can commit the transaction\nafter it recovers.\nNew York System\nUpdate X\nWrite X to disk\nCommit\nLondon System\nUpdate Y\nWrite Y to disk\nSystem fails\n. . .\nSystem recovers\n FIGURE 1.7 \n How Two-Phase Commit Ensures Atomicity. With two-phase commit, each system durably stores its updates before the \ntransaction commits, so it can commit the transaction when it recovers. \n1.4 Two-Phase Commit  15\n",
      "page_number": 26
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 34-42)",
      "start_page": 34,
      "end_page": 42,
      "detection_method": "topic_boundary",
      "content": "16  CHAPTER 1 Introduction\n To understand two-phase commit, it helps to visualize the overall architecture in which the transaction \nmanager operates. The standard model, shown in  Figure 1.8 , was introduced by IBM’s CICS and popularized \nby Oracle’s Tuxedo and X/Open (now part of The Open Group, see Chapter 10). In this model, the transaction \nmanager talks to applications, resource managers, and other transaction managers. The concept of  “ resource ” \nincludes databases, queues, ﬁ les, messages, and other shared objects that can be accessed within a transaction. \nEach resource manager offers operations that must execute only if the transaction that called the operations \ncommits. \n The transaction manager processes the basic transaction operations for applications: Start, Commit, and \nAbort. An application calls Start to begin executing a new transaction. It calls Commit to ask the transaction \nmanager to commit the transaction. It calls Abort to tell the transaction manager to abort the transaction. \n The transaction manager is primarily a bookkeeper that keeps track of transactions in order to ensure ato-\nmicity when more than one resource is involved. Typically, there’s one transaction manager on each node of a \ndistributed computer system. When an application issues a Start operation, the transaction manager dispenses a \nunique ID for the transaction called a  transaction identiﬁ er . During the execution of the transaction, it keeps \ntrack of all the resource managers that the transaction accesses. This requires some cooperation with the appli-\ncation, resource managers, and communication system. Whenever the transaction accesses a new resource \nmanager, somebody has to tell the transaction manager. This is important because when it comes time to com-\nmit the transaction, the transaction manager has to know all the resource managers to talk to in order to execute \nthe two-phase commit protocol. \n When a transaction program ﬁ nishes execution and issues the commit operation, that commit operation \ngoes to the transaction manager, which processes the operation by executing the two-phase commit protocol. \nSimilarly, if the transaction manager receives an abort operation, it tells the resource managers to undo all the \ntransaction’s updates; that is, to abort the transaction at each resource manager. Thus, each resource manager \nmust understand the concept of transaction, in the sense that it undoes or permanently installs the transaction’s \nupdates depending on whether the transaction aborts or commits. \n When running two-phase commit, the transaction manager sends out two rounds of messages — one for each \nphase of the commitment activity. In the ﬁ rst round of messages it tells all the resource managers to prepare to \ncommit by writing a copy of the results of the transaction to stable storage, but not actually to commit the trans-\naction. At this point, the resource managers are said to be  prepared to commit . When the transaction manager \ngets acknowledgments back from all the resource managers, it knows that the whole transaction has been pre-\npared. That is, it knows that all resource managers stored a durable copy of the transaction’s updates but none \nof them have committed the transaction. So it sends a second round of messages to tell the resource managers \nto actually commit.  Figure 1.9 gives an example execution of two-phase commit with two resource managers \ninvolved. \nApplication Program\nResource Manager\nTransaction Manager\n FIGURE 1.8 \n X/Open Transaction Model (XA). The transaction manager processes Start, Commit, and Abort. It talks to resource \nmanagers to run two-phase commit. \n\n\n Two -phase commit avoids the problem in  Figure 1.7(a) because all resource managers have a durable copy \nof the transaction’s updates before any of them commit. Therefore, even if a system fails during the commitment \nactivity, as the London system did in the ﬁ gure, it can commit the transaction after it recovers. However, to make \nthis all work, the protocol must handle every possible failure and recovery scenario. For example, in  Figure \n1.7(b) , it must tell the London system to commit the transaction. The details of how two-phase commit handles \nall these scenarios is described in Chapter 8. \n Two -phase commit is required whenever a transaction accesses two or more resource managers. Thus, one \nkey question that designers of TP applications must answer is whether or not to distribute their transaction \nprograms among multiple resources. Using two-phase commit adds overhead (due to two-phase commit mes-\nsages), but the option to distribute can provide better scalability (adding more systems to increase capacity) \nand availability (since one system can fail while others remain operational). \n 1.5  TRANSACTION PROCESSING PERFORMANCE \n Performance is a critical aspect of TP systems. No one likes waiting more than a few seconds for an automated \nteller machine to dispense cash or for a hotel web site to accept a reservation request. So response time to end-users \nis one important measure of TP system performance. Companies that rely on TP systems, such as banks, airlines, \nand commercial web sites, also want to get the most transaction throughput for the money they invest in a TP sys-\ntem. They also care about system scalability; that is, how much they can grow their system as their business grows. \n It ’s very challenging to conﬁ gure a TP system to meet response time and throughput requirements at mini-\nmum cost. It requires choosing the number of systems, how much storage capacity they’ll have, which process-\ning and database functions are assigned to each system, and how the systems are connected to displays and to \neach other. Even if you know the performance of the component products being assembled, it’s hard to predict \nhow the overall system will perform. Therefore, users and vendors implement benchmarks to obtain guidance \non how to conﬁ gure systems and to compare competing products. \n Vendor benchmarks are deﬁ ned by an independent consortium called the Transaction Processing Performance \nCouncil (TPC;  www.tpc.org ). The benchmarks enable apples-to-apples comparisons of different vendors ’ hardware \nResource Manager\nin New York\nResource Manager\nin London\nResource Manager\nin New York\nResource Manager\nin London\nTransaction Manager\n1. Prepare\n2. I am prepared\n1. Prepare\n2. I am prepared\n3. Commit\n4. OK\n3. Commit\n4. OK\nTransaction Manager\nPhase one\nPhase two\n FIGURE 1.9 \n The Two-Phase Commit Protocol. In Phase One, every resource manager durably saves the transaction’s updates before \nreplying  “ I am Prepared. ” Thus, all resource managers have durably stored the transaction’s updates before any of \nthem commits in phase two. \n1.5 Transaction Processing Performance  17\n\n\n18  CHAPTER 1 Introduction\n and software products. Each TPC benchmark deﬁ nes standard transaction programs and characterizes a system’s \nperformance by the throughput that the system can process under certain workload conditions, database size, \nresponse time guarantees, and so on. Published results must be accompanied by a  full disclosure report , which \nallows other vendors to review benchmark compliance and gives users more detailed performance information \nbeyond the summary performance measures. \n The benchmarks use two main measures of a system’s performance, throughput, and cost-per-through-\nput-unit. Throughput is the maximum throughput it can attain, measured in  transactions per second (tps) or \n transactions per minute (tpm) . Each benchmark deﬁ nes a response time requirement for each transaction \ntype (typically 1 – 5 seconds). The throughput can be measured only when 90% of the transactions meet their \nresponse time requirements and when the average of all transaction response times is less than their response \ntime requirement. The latter ensures that all transactions execute within an acceptable period of time. \n As an aside, Internet web sites usually measure 90% and 99% response times. Even if the average perfor-\nmance is fast, it’s bad if one in a hundred transactions is too slow. Since customers often run multiple trans-\nactions, that translates into several percent of customers receiving poor service. Many such customers don’t \nreturn. \n The benchmarks ’ cost-per-throughput-unit is measured in dollars per tps or tpm. The cost is calculated as \nthe list purchase price of the hardware and software, plus three years ’ vendor-supplied maintenance on that \nhardware and software (called the  cost of ownership ). \n The deﬁ nitions of TPC benchmarks are worth understanding to enable one to interpret TPC performance \nreports. Each of these reports, published on the TPC web site, is the result of a system benchmark evaluation \nperformed by a system vendor and subsequently validated by an independent auditor. Although their main pur-\npose is to allow customers to compare TP system products, these reports are also worth browsing for educa-\ntional reasons, to give one a feel for the performance range of state-of-the-art systems. They are also useful as \nguidance for the design and presentation of a custom benchmark study for a particular user application. \n The TPC-A and TPC-B Benchmarks \n The ﬁ rst two benchmarks promoted by TPC, called TPC-A and TPC-B, model an ATM application that debits \nor credits a checking account. When TPC-A/B were introduced, around 1989, they were carefully crafted to \nexercise the main bottlenecks customers were experiencing in TP systems. The benchmark was so successful \nin encouraging vendors to eliminate these bottlenecks that within a few years nearly all database systems per-\nformed very well on TPC-A/B. Therefore, the benchmarks were retired and replaced by TPC-C in 1995. Still, \nit’s instructive to look at the bottlenecks the benchmarks were designed to exercise, since these bottlenecks can \nstill arise today on a poorly designed system or application. \n Both benchmarks run the same transaction program. The only difference is that TPC-A includes terminals \nand a network in the overall system, while TPC-B does not. In both cases, the transaction program performs \nthe sequence of operations shown in  Figure 1.10 (except that TPC-B does not perform the read/write terminal \noperations). \n In TPC-A/B, the database consists of: \n ■  Account records, one record for each customer’s account (total of 100,000 accounts) \n ■  A teller record for each teller, which stores the amount of money in the teller’s cash drawer (total of \n10 tellers) \n ■  One record for each bank branch (one branch minimum), which contains the sum of all the accounts at \nthat branch \n ■  A history ﬁ le, which records a description of each transaction that actually executes \n\n\n The transaction reads a 100-byte input message, including the account number and amount of money to \nwithdraw or deposit. The transaction uses that input to ﬁ nd the account record and update it appropriately. \nIt updates the history ﬁ le to indicate that this transaction has executed. It updates the teller and bank branch \nrecords to indicate the amount of money deposited or withdrawn at that teller and bank branch, respectively. \nFinally, for TPC-A, it sends a message back to the display device to conﬁ rm the completion of the transaction. \n The benchmark exercises several potential bottlenecks on a TP system: \n ■  There’s a large number of account records. The system must have 100,000 account records for each trans-\naction per second it can perform. To randomly access so many records, the database must be indexed. \n ■  The end of the history ﬁ le can be a bottleneck, because every transaction has to write to it and therefore \nto lock and synchronize against it. This synchronization can delay transactions. \n ■  Similarly, the branch record can be a bottleneck, because all of the tellers at each branch are reading and \nwriting it. However, TPC-A/B minimizes this effect by requiring a teller to execute a transaction only \nevery 10 seconds. \n Given a ﬁ xed conﬁ guration, the performance and price/performance of any TP application depends on the \namount of computer resources needed to execute it: the number of processor instructions, I/Os to stable storage, \nand communications messages. Thus, an important step in understanding the performance of any TP application \nis to count the resources required for each transaction. In TPC-A/B, for each transaction a high performance \nimplementation uses a few hundred thousand instructions, two or three I/Os to stable storage, and two interac-\ntions with the display. When running these benchmarks, a typical system spends more than half of the processor \ninstructions inside the database system and maybe another third of the instructions in message communications \nbetween the parts of the application. Only a small fraction of the processor directly executes the transaction pro-\ngram. This isn’t very surprising, because the transaction program mostly just sends messages and initiates data-\nbase operations. The transaction program itself does very little, which is typical of many TP applications. \n The TPC-C Benchmark \n The TPC-C benchmark was introduced in 1992. It is based on an order-entry application for a wholesale sup-\nplier. Compared to TPC-A/B, it includes a wider variety of transactions, some  “ heavy weight ” transactions \n(which do a lot of work), and a more complex database. \n The database centers around a  warehouse , which tracks the  stock of  items that it  supplies to  customers \nwithin a sales  district , and tracks those customers ’  orders , which consist of  order-lines . The database size is \nproportional to the number of warehouses (see  Table 1.1 ). \nStart\n  Read message from terminal (100 bytes)\n  Read and write account record (random access)\n  Write history record (sequential access)\n  Read and write teller record (random access)\n  Read and write branch record (random access)\n  Write message to terminal (200 bytes)\nCommit       \n FIGURE 1.10 \n TPC-A/B Transaction Program. The program models a debit/credit transaction for a bank. \n1.5 Transaction Processing Performance  19\n\n\n20  CHAPTER 1 Introduction\n There are ﬁ ve types of transactions: \n ■  New-Order: To enter a new order, ﬁ rst retrieve the records describing the given warehouse, customer, \nand district, and then update the district (increment the next available order number). Insert a record in \nthe Order and New-Order tables. For each of the 5 to 15 (average 10) items ordered, retrieve the item \nrecord (abort if it doesn’t exist), retrieve and update the stock record, and insert an order-line record. \n ■  Payment: To enter a payment, ﬁ rst retrieve and update the records describing the given warehouse, dis-\ntrict, and customer, and then insert a history record. If the customer is identiﬁ ed by name, rather than id \nnumber, then additional customer records (average of two) must be retrieved to ﬁ nd the right customer. \n ■  Order-Status: To determine the status of a given customer’s latest order, retrieve the given customer \nrecord (or records, if identiﬁ ed by name, as in Payment), and retrieve the customer’s latest order and cor-\nresponding order-lines. \n ■  Delivery: To process a new order for each of a warehouse’s 10 districts, get the oldest new-order record \nin each district, delete it, retrieve and update the corresponding customer record, order record, and the \norder’s corresponding order-line records. This can be done as one transaction or 10 transactions. \n ■  Stock-Level: To determine, in a warehouse’s district, the number of recently sold items whose stock \nlevel is below a given threshold, retrieve the record describing the given district (which has the next \norder number). Retrieve order lines for the previous 20 orders in that district, and for each item ordered, \ndetermine if the given threshold exceeds the amount in stock. \n The transaction rate metric is the number of New-Order transactions per minute, denoted  tpmC , given that \nall the other constraints are met. The New-Order, Payment, and Order-Status transactions have a response time \nrequirement of ﬁ ve seconds. The Stock-Level transaction has a response time of 20 seconds and has relaxed \nconsistency requirements. The Delivery transaction runs as a periodic batch. The workload requires executing \nan equal number of New-Order and Payment transactions, and one Order-Status, Delivery, and Stock-Level \ntransaction for every 10 New-Orders. \n Table 1.1  Database for the TPC-C Benchmark. The database consists of the tables in the left column, which \nsupport an order-entry application \n Table Name \n Number of Rows per \nWarehouse \n Bytes-per-Row \n Size of Table (in bytes) \nper Warehouse \n Warehouse \n  1 \n 89 \n .089  K \n District \n 10 \n 95 \n .95  K \n Customer \n 30  K \n 655 \n 19.65  K \n History \n 30  K \n 46 \n 1.38  K \n Order \n 30  K \n 24 \n 720  K \n New-Order \n  9  K \n 8 \n 72  K \n Order-Line \n 300  K \n 54 \n 16.2  M \n Stock \n 100  K \n 306 \n 306  M \n Item \n 100  K \n 82 \n 8.2  M \n\n\n The TPC-C workload is many times heavier per transaction than TPC-A/B and exhibits higher contention \nfor shared data. Moreover, it exercises a wider variety of performance-sensitive functions, such as deferred \ntransaction execution, access via secondary keys, and transaction aborts. It is regarded as a more realistic \nworkload than TPC-A/B, which is why it replaced TPC-A/B as the standard TP systems benchmark. \n The TPC-E Benchmark \n The TPC-E benchmark was introduced in 2007. Compared to TPC-C, it represents larger and more complex \ndatabases and transaction workloads that are more representative of current TP applications. And it uses a stor-\nage conﬁ guration that is less expensive to test and run. It is based on a stock trading application for a broker-\nage ﬁ rm where transactions are related to stock trades, customer inquiries, activity feeds from markets, and \nmarket analysis by brokers. Unlike previous benchmarks, TPC-E does not include transactional middleware \ncomponents and solely measures database performance. \n TPC -E includes 10 transaction types, summarized in  Table 1.2 , which are a mix of read-only and read-\nwrite transactions. For each type, the table shows the percentage of transactions of that type and the number of \ndatabase tables it accesses, which give a feeling for the execution cost of the type. \n There are various parameters that introduce variation into the workload. For example, trade requests are \nsplit 50-50 between buy and sell and 60-40 between market order and limit order. In addition, customers are \nassigned to one of three tiers, depending on how often they trade securities — the higher the tier, the more \naccounts per customer and trades per customer. \n The database schema has 33 tables divided into four sets: market data (11 tables), customer data (9 tables), \nbroker data (9 tables), and static reference data (4 tables). Most tables have fewer than six columns and less \nthan 100 bytes per row. At the extremes, the Customer table has 23 columns, and several tables store text \ninformation with hundreds of bytes per row (or even more for the News Item table). \n Table 1.2  TPC-E Transaction Types \n Transaction \nType \n Percent of \nTransactions \n Database \nTables \nAccessed \n Description \n Trade Order \n 10.1% \n 17 \n Buy or sell a security \n Trade Result \n 10% \n 15 \n Complete the execution of a buy or sell order \n Trade Status \n 19% \n 6 \n Get the status of an order \n Trade Update \n 2% \n 6 \n Make corrections to a set of trades \n Customer Position \n 13% \n 7 \n Get the value of a customer’s assets \n Market Feed \n 1% \n 2 \n Process an update of current market activity (e.g., ticker tape) \n Market Watch \n 18% \n 4 \n Track market trends (e.g., for a customer’s  “ watch list ” ) \n Security Detail \n 14% \n 12 \n Get a detailed data about a security \n Trade Lookup \n 8% \n 6 \n Get information about a set of trades \n Broker Volume \n 4.9% \n 6 \n Get a summary of the volume and value of pending orders of a \nset of brokers \n1.5 Transaction Processing Performance  21\n\n\n22  CHAPTER 1 Introduction\n A driver program generates the transactions and their inputs, submits them to a test system, and measures \nthe rate of completed transactions. The result is the  measured transactions per second (tpsE), which is the \nnumber of Trade Result transactions executed per second, given the mix of the other transaction types. Each \ntransaction type has a response time limit of one to three seconds, depending on transaction type. In contrast to \nTPC-C, application functions related to front-end programs are excluded. Thus, the results measure the server-\nside database management system. Like previous TPC benchmarks, TPC-E includes a measure for the cost per \ntransaction per second ($/tpsE). \n TPC -E provides data generation code to initialize the database with the result of 300 days of initial trading, \ndaily market closing price information for ﬁ ve years, and quarterly company report data for ﬁ ve years. Beyond \nthat, the database size scales up as a function of the  nominal tpsE, which is the transaction rate the benchmark \nsponsor is aiming for . The measured tpsE must be within 80 to 102% of the nominal tpsE. The database must \nhave 500 customers for each nominal tpsE. Other database tables scale relative to the number of customer \nrows. For example, for each 1000 Customers, there must be 685 Securities and 500 Companies. Some tables \ninclude a row describing each trade and therefore grow quite large for a given run. \n Compared to TPC-C, TPC-E is a more complex workload. It makes heavier use of SQL database features, \nsuch as referential integrity and transaction isolation levels (to be discussed in Chapter 6). It uses a more com-\nplex SQL schema. Transactions execute more complex SQL statements and several of them have to make mul-\ntiple calls to the database, which cannot be batched in one round-trip. And there is no trivial partitioning of the \ndatabase that will enable scalability (to be discussed in Section 2.6). Despite all this newly introduced complex-\nity, the benchmark generates a much lower I/O load than TPC-C for a comparable transaction rate. This makes \nthe benchmark cheaper to run, which is important to vendors when they run high-end scalability tests where \nlarge machine conﬁ gurations are needed. \n In addition to its TP benchmarks, the TPC publishes a widely used benchmark for decision support systems, \nTPC-H. It also periodically considers new TP benchmark proposals. Consult the TPC web site,  www.tpc.org , \nfor current details. \n 1.6  AVAILABILITY \n Availability is the fraction of time a TP system is up and running and able to do useful work — that is, it isn’t \ndown due to hardware or software failures, operator errors, preventative maintenance, power failures, or the \nlike. Availability is an important measure of the capability of a TP system because the TP application usually \nis offering a service that’s  “ mission critical, ” one that’s essential to the operation of the enterprise, such as air-\nline reservations, managing checking accounts in a bank, processing stock transactions in a stock exchange, or \noffering a retail storefront on the Internet. Obviously, if this type of system is unavailable, the business stops \noperating. Therefore, the system  must operate nearly all the time. \n Just how highly available does a system have to be? We see from the table in  Figure 1.11 that if the system \nis available 96% of the time, that means it’s down nearly an hour a day. That’s too much time for many types \nof businesses, which would consider 96% availability to be unacceptable. \n An availability of 99% means that the system is down about 100 minutes per week (i.e., 7 days/week  \u0004  24 \nhours/day  \u0004  60 minutes/hour  \u0004  1/100). Many TP applications would ﬁ nd this unacceptable if it came in one \n100-minute period of unavailability. It might be tolerable, provided that it comes in short outages of just a few \nminutes at a time. But in many cases, even this may not be tolerable, for example in the operation of a stock \nexchange where short periods of downtime can produce big ﬁ nancial losses. \n An availability of 99.9% means that the system is down for about an hour per month, or under two min-\nutes per day. Further, 99.999% availability means that the system is down ﬁ ve minutes a year. That number \n\n\n may seem incredibly ambitious, but it  is attainable; telephone systems typically have that level of availability. \nPeople sometimes talk about availability in terms of the number of 9s that are attained; for example,  “ ﬁ ve 9s ” \nmeans 99.999% available. \n Some systems need to operate for only part of the day, such as 9  AM to 5  PM on weekdays. In that case, avail-\nability usually is measured relative to the hours when the system is expected to be operational. Thus, 99.9% avail-\nability means that it is down at most 2.4 minutes per week (i.e., 40 hours/week  \u0004  60 minutes/hour  \u0004  1/1000). \n Today ’s TP system customers typically expect availability levels of at least 99%, although it certainly depends \non how much money they’re willing to spend. Generally, attaining high availability requires attention to four \nfactors: \n ■  The environment — making the physical environment more robust to avoid failures of power, communi-\ncations, air conditioning, and the like \n ■  System management — avoiding failures due to operational errors by system managers and vendors ’ ﬁ eld \nservice \n ■  Hardware — having redundant hardware, so that if some component fails, the system can immediately \nand automatically replace it with another component that’s ready to take over \n ■  Software — improving the reliability of software and ensuring it can automatically and quickly recover \nafter a failure \n This book is about software, and regrettably, of the four factors, software is the major contributor to avail-\nability problems. Software failures can be divided into three categories: application failures, database system \nfailures, and operating system failures. \n Because we’re using transactions, when an application fails, any uncommitted transaction it was executing \naborts automatically. Its updates are backed out, because of the atomicity property. There’s really nothing that \nthe system has to do other than re-execute  the transaction after the application is running again. \n When the database system fails, all the uncommitted transactions that were accessing the database system \nat that time have to abort, because their updates may be lost during the database system failure. A system man-\nagement component of the operating system, database system, or transactional middleware has to detect the \nfailure of the database system and tell the database system to reinitialize itself. During the reinitialization pro-\ncess, the database system backs out the updates of all the transactions that were active at the time of the failure, \nthereby getting the database into a clean state, where it contains the results only of committed transactions. \n A failure of the operating system requires it to reboot. All programs, applications, and database systems exe-\ncuting at the time of failure are now dead. Everything has to be reinitialized after the operating system reboots. \nOn an ordinary computer system all this normally takes between several minutes and an hour, depending on \nhow big the system is, how many transactions were active at the time of failure, how long it takes to back out the \nuncommitted transactions, how efﬁ cient the initialization program is, and so on. Very high availability systems, \nsuch as those intended to be available in excess of 99%, typically are designed for very fast recovery. Even when \nDowntime\nAvailability (%)\n1 hour/day\n95.8\n1 hour/week\n99.41\n1 hour/month\n99.86\n1 hour/year\n99.9886\n1 hour/20 years\n99.99942\n FIGURE 1.11 \n Downtime at Different Availability Level. The number of nines after the decimal point is of practical signiﬁ cance. \n1.6 Availability  23\n\n\n24  CHAPTER 1 Introduction\n they fail, they are down only for a very short time. They usually use some form of replicated processing to get \nthis fast recovery. When one component fails, they quickly delegate processing work to a copy of the component \nthat is ready and waiting to pick up the load. \n The transaction abstraction helps the programmer quite a bit in attaining high availability, because the sys-\ntem is able to recover into a clean state by aborting transactions. And it can continue from where it left off by \nrerunning transactions that aborted as a result of the failure. Without the transaction abstraction, the recovery \nprogram would have to be application-speciﬁ c. It would have to analyze the state of the database at the time \nof the failure to ﬁ gure out what work to undo and what to rerun. We discuss high availability issues and tech-\nniques in more detail in Chapter 7, and replication technology in Chapter 9. \n In addition to application, database system, and operating system failures, operator errors are a major con-\ntributor to unplanned downtime. Many of these errors can be attributed to system management software that is \nhard to understand and use. If the software is difﬁ cult to tune, upgrade, or operate, then operators make mis-\ntakes. The ideal system management software is fully automated and requires no human intervention for such \nroutine activities. \n 1.7  STYLES OF SYSTEMS \n We ’ve been talking about TP as a style of  application , one that runs short transaction programs that access \na shared database. TP is also a style of  system , a way of conﬁ guring software components to do the type of \nwork required by a TP application. It’s useful to compare this style of system with other styles that you may be \nfamiliar with, to see where the differences are and why TP systems are constructed differently from the others. \nThere are several other kinds of systems that we can look at here: \n ■  Batch processing systems, where you submit a job and later receive output in the form of a ﬁ le \n ■  Real-time systems, where you submit requests to do a small amount of work that has to be done before \nsome very early deadline \n ■  Data warehouse systems, where reporting programs and  ad hoc queries access data that is integrated \nfrom multiple data sources \n Designing a system to perform one of these types of processing is called  system engineering . Rather than \nengineering a speciﬁ c component, such as an operating system or a database system, you engineer an inte-\ngrated system by combining different kinds of components to perform a certain type of work. Often, systems \nare engineered to handle multiple styles, but for the purposes of comparing and contrasting the different styles, \nwe’ll discuss them as if each type of system were running in a separately engineered environment. Let’s look \nat requirements for each of these styles of computing and see how they compare to a TP system. \n Batch Processing Systems \n A batch is a set of requests that are processed together, often long after the requests were submitted. Data \nprocessing systems of the 1960s and early 1970s were primarily batch processing systems. Today, batch work-\nloads are still with us. But instead of running them on systems dedicated for batch processing, they often exe-\ncute on systems that also run a TP workload. TP systems can execute the batches during nonpeak periods, \nsince the batch workload has ﬂ exible response-time requirements. To make the comparison between TP and \nbatch clear, we will compare a TP system running a pure TP workload against a classical batch system running \na pure batch workload, even though mixtures of the two are now commonplace. \n",
      "page_number": 34
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 43-50)",
      "start_page": 43,
      "end_page": 50,
      "detection_method": "topic_boundary",
      "content": " A batch processing system executes each batch as a sequence of transactions, one transaction at a time. \nSince transactions execute serially there’s no problem with serializability. By contrast, in a TP system many \ntransactions can execute at the same time, and so the system has extra work to ensure serializability. \n For example, computing the value of a stock market portfolio could be done as a batch application, running \nonce a day after the close of ﬁ nancial markets. Computing a monthly bill for telephone customers could be a \nbatch application, running daily for a different subset of the customer base each day. Generating tax reporting \ndocuments could be a batch application executed once per quarter or once per year. \n The main performance measure of batch processing is throughput, that is, the amount of work done per unit \nof time. Response time is less important. A batch could take minutes, hours, or even days to execute. By con-\ntrast, TP systems have important response time requirements, because generally there’s a user waiting at a dis-\nplay for the transaction’s output. \n A classical batch processing application takes its input as a record-oriented ﬁ le whose records represent \na sequence of request messages. Its output is also normally stored in a ﬁ le. By contrast, TP systems typically \nhave large networks of display devices for capturing requests and displaying results. \n Batch processing can be optimized by ordering the input requests consistently with the order of the data in \nthe database. For example, if the requests correspond to giving airline mileage credit for recent ﬂ ights to mileage \naward customers, the records of customer ﬂ ights can be ordered by mileage award account number. That way, \nit’s easy and efﬁ cient to process the records by a merge procedure that reads the mileage award account database \nin account number order. By contrast, TP requests come in a random order. Because of the fast response time \nrequirement, the system can’t spend time sorting the input in an order consistent with the database. It has to be \nable to access the data randomly, in the order in which the data is requested. \n Classical batch processing takes the request message ﬁ le and existing database ﬁ le(s) as input and produces \na new master output database as a result of running transactions for the requests. If the batch processing pro-\ngram should fail, there’s no harm done because the input ﬁ le and input database are unmodiﬁ ed — simply throw \nout the output ﬁ le and run the batch program again. By contrast, a TP system updates its database on-line as \nrequests arrive. So a failure may leave the database in an inconsistent state, because it contains the results of \nuncompleted transactions. This atomicity problem for transactions in a TP environment doesn’t exist in a batch \nenvironment. \n Finally , in batch the load on the system is ﬁ xed and predictable, so the system can be engineered for that load. \nFor example, you can schedule the system to run the batch at a given time and set aside sufﬁ cient capacity to do \nit, because you know exactly what the load is going to be. By contrast, a TP load generally varies during the day. \nThere are peak periods when there’s a lot of activity and slow periods when there’s very little. The system has to \nbe sized to handle the peak load and also designed to make use of extra capacity during slack periods. \n Real-Time Systems \n TP systems are similar to real-time systems, such as a system collecting input from a satellite or controlling \na factory’s shop ﬂ oor equipment. TP essentially is a kind of real-time system, with a real-time response time \ndemand of 1 to 2 seconds. It responds to a real-world process consisting of end-users interacting with display \ndevices, which communicate with application programs accessing a shared database. So not surprisingly, there \nare many similarities between the two kinds of systems. \n Real -time systems and TP systems both have predictable loads with periodic peaks. Real-time systems usu-\nally emphasize gathering input rather than processing it, whereas TP systems generally do both. \n Due to the variety of real-world processes they control, real-time systems generally have to deal with more \nspecialized devices than TP, such as laboratory equipment, factory shop ﬂ oor equipment, or sensors and con-\ntrol systems in an automobile or airplane. \n1.7 Styles of Systems  25\n\n\n26  CHAPTER 1 Introduction\n Real -time systems generally don’t need or use special mechanisms for atomicity and durability. They sim-\nply process the input as quickly as they can. If they lose some of that input, they ignore the loss and keep on \nrunning. To see why, consider the example of a system that collects input from a monitoring satellite. It’s not \ngood if the system misses some of the data coming in. But the system certainly can’t stop operating to go back \nto ﬁ x things up like a TP system would do — the data keeps coming in and the system must do its best to con-\ntinue processing it. By contrast, a TP environment can generally stop accepting input for a short time or can \nbuffer the input for awhile. If there is a failure, it can stop collecting input, run a recovery procedure, and then \nresume processing input. Thus, the fault-tolerance requirements between the two types of systems are rather \ndifferent. \n Real -time systems are generally not concerned with serializability. In most real-time applications, processing \nof input messages involves no access to shared data. Since the processing of two different inputs does not affect \neach other, even if they’re processed concurrently, they’ll behave like a serial execution. No special mechanisms, \nsuch as locking, are needed. When processing real-time inputs to shared data, the notion of serializability is as \nrelevant as it is to TP. However, in this case, real-time applications generally make direct use of low-level syn-\nchronization primitives for mutual exclusion, rather than relying on a general-purpose synchronization mecha-\nnism that is hidden behind the transaction abstraction. \n Data Warehouse Systems \n TP systems process the data in its raw state as it arrives.  Data warehouse systems integrate data from multiple \nsources into a database suitable for querying. \n For example, a distribution company decides each year how to allocate its marketing and advertising budget. \nIt uses a TP system to process sales orders that includes the type and value of each order. The customer database \ntells each customer’s location, annual revenue, and growth rate. The ﬁ nance database includes cost and income \ninformation, and tells which product lines are most proﬁ table. The company pulls data from these three data \nsources into a data warehouse. Business analysts can query the data warehouse to determine how best to allocate \npromotional resources. \n Data warehouse systems execute two kinds of workloads: a batch workload to extract data from the sources, \ncleaning the data to reconcile discrepancies between them, transforming the data into a common shape that’s \nconvenient for querying, and loading it into the warehouse; and queries against the warehouse, which can range \nfrom short interactive requests to complex analyses that generate large reports. Both of these workloads are \nquite different than TP, which consists of short updates and queries. Also unlike TP, a data warehouse’s content \ncan be somewhat out-of-date, since users are looking for trends that are not much affected by the very latest\nupdates. In fact, sometimes it’s important to run on a static database copy, so that the results of successive \nqueries are comparable. Running queries on a data warehouse rather than a TP database is also helpful for per-\nformance reasons, since data warehouse queries would slow down update transactions, a topic we’ll discuss in \nsome detail in Chapter 6. Our comparison of system styles so far is summarized in  Figure 1.12 . \n Other System Types \n Two other system types that are related to TP are timesharing and client-server. \n Timesharing \n In a timesharing system, a display device is connected to an operating system process, and within that pro-\ncess the user can invoke programs that interact frequently with the display. Before the widespread use of PCs, \nwhen timesharing systems were popular, TP systems often were confused with timesharing, because they both \n\n\n involve managing lots of display devices connected to a common server. But they’re really quite different in \nterms of load, performance requirements, and availability requirements: \n ■  A timesharing system has a highly unpredictable load, since users continually make different demands \non the system. By comparison, a TP load is very regular, running similar load patterns every day. \n ■  Timesharing systems have less stringent availability and atomicity requirements than TP systems. The \nTP concept of ACID execution doesn’t apply. \n ■  Timesharing applications are not mission-critical to the same degree as TP applications and therefore \nhave weaker availability requirements. \n ■  Timesharing system performance is measured in terms of system capacity, such as instructions per sec-\nond and number of on-line users. Unlike TP, there are no generally accepted benchmarks that accurately \nrepresent the behavior of a wide range of timesharing applications. \n Client-Server \n In a client-server system, a large number of personal computers communicate with shared servers on a local area \nnetwork. This kind of system is very similar to a TP environment, where a large number of display devices con-\nnect to shared servers that run transactions. In some sense, TP systems were the original client-server systems \nwith very simple desktop devices, namely, dumb terminals. As desktop devices have become more powerful, TP \nsystems and personal computer systems have been converging into a single type of computing environment with \ndifferent kinds of servers, such as ﬁ le servers, communication servers, and TP servers. \n There are many more system types than we have space to include here. Some examples are embedded systems, \ncomputer-aided design systems, data streaming systems, electronic switching systems, and trafﬁ c control systems. \nIsolation\nserializable, multi-\nprogrammed execution\nserial, uni-\nprogrammed\nexecution\nno transaction\nconcept\nno transaction\nconcept\nWorkload\nhigh variance\npredictable\npredictability\ndepends on the\napplication\npredictable loading,\nhigh variance queries\nPerformance\nmetric \nresponse time and\nthroughput  \nthroughput\nresponse time,\nthroughput, missed\ndeadlines\nthroughput for\nloading, response\ntime for queries\nInput\nnetwork of display\ndevices submitting\nrequests\nrecord-oriented file\nnetwork of devices\nsubmitting data and\noperations \nnetwork of display\ndevices submitting\nqueries\nData Access\nrandom access\naccesses sorted to be\nconsistent with\ndatabase order\nunconstrained\npossibly sorted\nfor loading,\nunconstrained for\nqueries\nRecovery\nafter failure, ensure\ndatabase has committed\nupdates and no others\nafter failure, rerun\nthe batch to produce\na new master file\napplication’s\nresponsibility\napplication’s\nresponsibility\nTransaction\nProcessing\nBatch\nReal-time\nData Warehouse\n FIGURE 1.12 \n Comparison of System Types. Transaction processing has different characteristics than the other styles, and therefore \nrequires systems that are specially engineered to the purpose. \n1.7 Styles of Systems  27\n\n\n28  CHAPTER 1 Introduction\n Why Engineer a TP System? \n Each system type that we looked at is designed for certain usage patterns. Although it is engineered for that \nusage pattern, it actually can be used in other ways. For example, people have used timesharing systems to run \nTP applications. These applications typically do not scale very well or use operating system resources very \nefﬁ ciently, but it can be done. For example, people have built special-purpose TP systems using real-time sys-\ntems, and batch systems to run on a timesharing system. \n TP has enough special requirements that it’s worth engineering the system for that purpose. The amount of \nmoney businesses spend on TP systems justiﬁ es the additional engineering work vendors do to tailor their sys-\ntem products for TP — for better performance, reliability, and ease-of-use. \n 1.8  TP SYSTEM CONFIGURATIONS \n When learning the principles of transaction processing, it is helpful to have a feel for the range of systems \nwhere these principles are applied. We already saw some examples in Section 1.5 on TP benchmarks. Although \nthose benchmark applications have limited functionality, they nevertheless are meant to be representative of \nthe kind of functionality that is implemented for complete practical applications. \n In any given price range, including the very high end, the capabilities of TP applications and systems con-\ntinually grow, in large part due to the steadily declining cost of computing and communication. These growing \ncapabilities enable businesses to increase the functionality of classical TP applications, such as travel reserva-\ntions and banking. In addition, every few years, these capabilities enable entirely new categories of businesses. \nIn the past decade, examples include large-scale Internet retailers and social networking web sites. \n There is no such thing as an average TP application or system. Rather, systems that implement TP applications \ncome in a wide range of sizes, from single servers to data centers with thousands of machines. And the applica-\ntions themselves exhibit a wide range of complexity, from a single database with few dozen transaction types to \nthousands of databases running hundreds of millions of lines of code. Therefore, whatever one might say about \ntypical TP installations will apply only to a small fraction of them and will likely be outdated within a few years. \n A low-end system could be a departmental application supporting a small number of users who perform \na common function. Such an application might run comfortably on a single server machine. For example, the \nsales and marketing team of a small company might use a TP application to capture sales orders, record cus-\ntomer responses to sales campaigns, alert sales people when product support agreements need to be renewed, \nand track the steps in resolving customer complaints. Even though the load on the system is rather light, the \napplication might require hundreds of transaction types to support many different business functions. \n By contrast, the workload of a large Internet service might require thousands of server machines. This is \ntypical for large-scale on-line shopping, ﬁ nancial services, travel services, multimedia services (e.g., sharing \nof music, photos, and videos), and social networking. To ensure the service is available 24 hours a day, 7 days \na week (a.k.a. 24  \u0004  7), it often is supported by multiple geographically distributed data centers. Thus if one \ndata center fails, others can pick up its load. \n Like hardware conﬁ guration, software conﬁ gurations cover a wide range. The system software used to \noperate a TP system may be proprietary or open source. It may use the latest system software products or \nones that were introduced decades ago. It may only include a SQL database system and web server, or it may \ninclude several layers of transactional middleware and specialized database software. \n The range of technical issues that need to be addressed is largely independent of the hardware or software \nconﬁ guration that is chosen. These issues include selecting a programming model; ensuring the ACID properties; \nand maximizing availability, scalability, manageability, and performance. These issues are the main subject of \nthis book. \n\n\n 1.9  SUMMARY \n A  transaction is the execution of a program that performs an administrative function by accessing a shared data-\nbase. Transactions can execute on-line, while a user is waiting, or off-line (in batch mode) if the execution takes \nlonger than a user can wait for results. The end-user requests the execution of a transaction program by sending a \nrequest message. \n A transaction processing application is a collection of transaction programs designed to automate a given \nbusiness activity. A TP application consists of a relatively small number of predeﬁ ned types of transaction pro-\ngrams. TP applications can run on a wide range of computer sizes and may be centralized or distributed, running \non local area or wide area networks. TP applications are mapped to a specially engineered hardware and soft-\nware environment called a TP system. \n The three parts of a TP application correspond to the three major functions of a TP system: \n 1.  Obtain input from a display or special device and construct a request. \n 2.  Accept a request message and call the correct transaction program. \n 3.  Execute the transaction program to complete the work required by the request. \n Database management plays a signiﬁ cant role in a TP system. Transactional middleware components sup-\nply functions to help get the best price/performance out of a TP system and provide a structure in which TP \napplications execute. \n There are four critical properties of a transaction: atomicity, consistency, isolation, and durability. Consistency \nis the responsibility of the program. The remaining three properties are the responsibility of the TP system. \n ■  Atomicity: Each transaction performs all its operations or none of them. Successful transactions commit; \nfailed transactions abort. Commit makes database changes permanent; abort undoes or erases database \nchanges. \n ■  Consistency: Each transaction is programmed to preserve database consistency. \n ■  Isolation: Each transaction executes as if it were running alone. That is, the effect of running a set of \ntransactions is the same as running them one at a time. This behavior is called serializability and usually is \nimplemented by locking. \n ■  Durability: The result of a committed transaction is guaranteed to be on stable storage, that is, one that \nsurvives power failures and operating system failures, such as a magnetic or solid-state disk. \n If a transaction updates multiple databases or resource managers, then the two - phase commit protocol is \nrequired. In phase one, it ensures all resource managers have saved the transaction’s updates to stable storage. If \nphase one succeeds, then phase two tells all resource managers to commit. This ensures atomicity, that is, that \nthe transaction commits at all resource managers or aborts at all of them. Two-phase commit usually is imple-\nmented by a transaction manager, which tracks which resource managers are accessed by each transaction and \nruns the two-phase commit protocol. \n Performance is a critical aspect of TP. A TP system must scale up to run many transactions per time unit, \nwhile giving one- or two-second response time. The standard measures  of performance are the TPC bench-\nmarks, which compare TP systems based on their maximum transaction rate and price per transaction for a stan-\ndardized application workload. \n A TP system is often critical to proper functioning of the enterprise that uses it. Therefore, another important \nproperty of TP systems is availability; that is, the fraction of time the system is running and able to do work. \nAvailability is determined by how frequently a TP system fails and how quickly it can recover from failures. \n TP systems have rather different characteristics than batch, real-time, and data warehouse systems. They \ntherefore require specialized implementations that are tuned to the purpose. These techniques are the main \nsubject of this book. \n \n1.9 Summary  29\n\n\nThis page intentionally left blank\n\n\n 2.1  INTRODUCTION \n This chapter discusses ﬁ ve software abstractions that are used heavily in TP systems: \n ■  Transactions \n ■  Processes and threads \n ■  Remote procedure calls \n ■  Transaction context, sessions, and other techniques for managing shared state \n ■  Caching, resource pooling, partitioning, and replication \n These abstractions involve both the application programming interface and mechanisms to support it. \nUnderstanding them is fundamental to developing and engineering a TP system. \n We start with the transaction abstraction, where we focus on the semantics of the programming model. We \npresent pseudocode that illustrates how a transaction is delimited and thus establishes the relationship between a \nprogram and the TP infrastructure. This sets the stage to discuss the signiﬁ cant abstractions relevant to that infra-\nstructure — processes, threads, and remote procedure call — where the focus shifts from the programming model to \nhow the mechanisms work. Then we present the main abstractions involved in state management, which are at the \ncore of the leading programming and deployment models used in transactional middleware. Finally, we talk about \nabstractions that are used to enhance the performance and scalability of TP applications: caching of state; pooling \nof sessions, threads, and other resources; and partitioning and replication of databases and server processes. \n 2.2  TRANSACTIONS \n The transaction abstraction affects three aspects of a TP system: \n ■  The programming model; that is, the style in which application programs are written \n ■  The application programming interface (API); that is, the commands available to the application programmer \n ■  Components of the system software that support TP applications \n It is up to the application programmer to bracket the set of operations that should be executed as part of the same \ntransaction. This section focuses on the semantics that is  implied by the transaction brackets. For the most part, we \nuse pseudocode to express this bracketing explicitly, because it is easy to understand and exposes the semantic \n Transaction Processing Abstractions  2 \nCHAPTER\n\n\n32  CHAPTER 2 Transaction Processing Abstractions\n issues that are at stake. Other styles of programming are described later in this section. Product-speciﬁ c program-\nming models and APIs for transaction bracketing are presented in Chapter 10. System software components that \nsupport TP applications are discussed in Chapter 3. \n Transaction Bracketing \n Transaction bracketing offers the application programmer commands to Start, Commit, and Abort a transaction. \nThese are expressed explicitly in some programming models and implicitly in others, but in either case these are \nthe commands whose execution begins and terminates a transaction. \n The commands to bracket a transaction are used to identify which operations execute in the scope of a trans-\naction. The Start command creates a new transaction. After an application invokes a Start command, all of its \noperations execute within that transaction until the application invokes Commit or Abort. In particular, if the \napplication calls a procedure, that procedure ordinarily executes within the same transaction as its caller. After \ninvoking Commit or Abort, the application is no longer executing a transaction until it invokes Start again. \n Sometimes , a procedure is designed to be executed either as an independent transaction or as a step within \na larger transaction. For example, consider the following two procedures: \n ■  DebitChecking(acct, amt) . Withdraw a given amount of money ( amt ) from a given checking account \n( acct ). \n ■  PayLoan(loan,  amt) . Pay back a given amount of money ( amt ) on a given loan ( loan ). \n Each of these procedures could execute as an independent ACID transaction. In that case, you would expect \nto see Start at the beginning of the body of each of the procedures and Commit at the end. Example procedures \nfor  DebitChecking and  PayLoan are shown in  Figure 2.1 . \nBoolean DebitChecking(acct, amt) {\n \nint acct, amt;\n \nStart;\n \nBoolean success = true;\n \n// Code to perform the withdrawal goes here.\n \n// Set “success = false” if the withdrawal fails,\n \n// e.g., due to insufficient funds\n \nif success Commit else Abort;\n \nreturn success;\n}\nBoolean PayLoan(loan, amt) {\n \nint loan, amt;\n \nStart;\n \nBoolean success = true;\n \n// Code to perform the payment goes here.\n \n// Set “success = false” if the payment fails,\n \n// e.g., because the loan has already been paid\n \nif success Commit else Abort;\n \nreturn success;\n}       \n FIGURE 2.1 \n Explicit Transaction Brackets. The DebitChecking and PayLoan procedures explicitly bracket their transactions with \na Start command and a Commit or Abort command. \n",
      "page_number": 43
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 51-59)",
      "start_page": 51,
      "end_page": 59,
      "detection_method": "topic_boundary",
      "content": " As long as a transaction executes a single procedure, it is quite straightforward to bracket the transaction \nusing Start, Commit, and Abort. Things get more complicated if a procedure that is running a transaction calls \nanother procedure to do part of the work of the transaction. For example, suppose there is a procedure  PayLoan\nFromChecking(acct, loan, amt) that calls the  DebitChecking and  PayLoan procedures to withdraw \nmoney from a checking account to pay back part of a loan, as shown in  Figure 2.2 . \n We would like the  PayLoanFromChecking procedure to execute as an ACID transaction. We therefore \nbracket the body of the procedure with calls to Start and Commit. This  PayLoanFromChecking transaction \nincludes its calls to the  DebitChecking and  PayLoan procedures. However, there is a potential problem with \nthis, namely, that  DebitChecking and  PayLoan also invoke the Start and Commit commands. Thus, as they’re \ncurrently written,  DebitChecking and  PayLoan would execute separate transactions that commit indepen-\ndently of  PayLoanFromChecking , which is not what we want. That is, we cannot compose  DebitChecking \nand  PayLoan into a larger transaction. We call this the  transaction composability problem . \n One solution is to have the system ignore invocations of the Start command when it is executed by a program \nthat is already running within a transaction. In this approach, when the  PayLoanFromChecking procedure calls \nthe  DebitChecking procedure, the Start command in the  DebitChecking procedure in  Figure 2.1 would not \ncause a new transaction to be created. However, the system cannot completely ignore this second Start com-\nmand. It must remember that this second Start command was invoked, so it will know that it should ignore \nthe execution of the corresponding Commit command in  DebitChecking . That is, the Commit command in \n Figure 2.1 should not commit the  “ outer ” transaction created by  PayLoanFromChecking . More generally, the \nsystem maintains a start-count for each executing application, which is initialized to zero. Each execution of the \nStart command increments the start-count and each Commit decrements it. Only the last Commit, which decre-\nments the count back to zero, causes the transaction to commit. \n What if the  DebitChecking procedure issues the Abort command? One possible interpretation is that if an \ninner procedure calls Abort, then the transaction that the procedure is executing really does need to abort. Thus, \nunlike the Commit command, the Abort command in the  DebitChecking procedure causes an abort of the outer \ntransaction created by  PayLoanFromChecking . In some systems, it is simply an error for a procedure that has \nexecuted a second Start command to subsequently invoke an Abort command. In others, the invocation of Abort \nis ignored. Another possible interpretation is that it is an attempt to abort only the work that was performed since \nthe last Start command executed. This semantics is  discussed in the later subsection,  Nested Transactions . \n Another solution to the transaction composability problem is to remove the Start and Commit com-\nmands from  DebitChecking and  PayLoan , so they can be invoked within the transaction bracketed by the \n PayLoanFromChecking procedure. Using this approach, the  DebitChecking procedure would be replaced \nby the one in  Figure 2.3 . To enable  DebitChecking to execute as an independent transaction, one can write \nBoolean PayLoanFromChecking(acct, loan, amt) {\n \nint  acct, loan, amt;\n \nStart;\n \nif ¬DebitChecking(acct, amt) {Abort; return false;};\n \nif ¬PayLoan(loan, amt) {Abort; return false;};\n \nCommit;\n \nreturn true;\n}  \n FIGURE 2.2 \n A Composite Transaction. The transaction  PayLoanFromChecking is written by composing the  DebitChecking \nand  PayLoan procedures. \n2.2 Transactions  33\n\n\n34  CHAPTER 2 Transaction Processing Abstractions\n a  “ wrapper ” procedure  CallDebitChecking that includes the transaction brackets, also shown in  Figure 2.3 . \nThis approach avoids the need to rewrite application code when existing procedures are composed in new ways. \nAnother programming model that realizes this beneﬁ t is described in a later subsection entitled,  Transaction \nBracketing in Object-Oriented Programming . \n The impact of the transaction composability problem is something that needs to be evaluated and under-\nstood in the context of whichever programming model or models you are using. \n Transaction Identiﬁ ers \n As we explained in Chapter 1, each transaction has a unique transaction identiﬁ er (transaction ID), which is \nassigned when the transaction is started. The transaction ID is assigned by whichever component is responsible \nfor creating the transaction in response to the Start command. That component could be a transaction manager \n(see Section 1.4) or a transactional resource manager such as a database system, ﬁ le system, or queue manager. \n There are two major types of transaction IDs: global and local. The transaction manager assigns a global \nID, which is needed when more than one transactional resource participates in a transaction. If the transac-\ntional resource managers also assign transaction IDs, then these are local IDs that are correlated with the \nglobal transaction ID since they all refer to the same transaction. \n Whenever a transaction accesses a transactional resource, it needs to supply its transaction ID, to tell the \nresource’s manager on which transaction’s behalf the access is being made. The resource manager needs this \ninformation to enforce the ACID properties. In particular, it needs it for write accesses, so that it knows which \nwrite operations to permanently install or undo when the transaction commits or aborts. \n When an application program invokes Commit or Abort, it needs to pass the transaction ID as a parameter. \nThis tells the transaction manager which transaction it is supposed to commit or abort. \n Since the application needs to supply its transaction ID to resource managers and the transaction manager, \nit needs to manage its transaction ID. It could do this explicitly. That is, the Start operation could return a \nBoolean DebitChecking(acct, amt) {\n \nint acct, amt;\n \nBoolean success = true;\n \n// Code to perform the withdrawal goes here.\n \n// Set “success = false” if the withdrawal fails,\n \n// e.g., due to insufficient funds\n \nreturn success;\n}\nBoolean CallDebitChecking(acct, amt) {\n \nint acct, amt;\n \nStart;\n \nBoolean success = DebitChecking(acct, amt);\n \nif success Commit else Abort;\n \nreturn success;\n}        \n FIGURE 2.3 \n Enabling Composability. The Start, Commit, and Abort commands are removed in this revised version of the \n DebitChecking procedure ( Figure 2.1 ), so it can be invoked in a larger transaction, such as  PayLoanFromChecking \n( Figure 2.2 ). A wrapper procedure  CallDebitChecking is added, which includes the transaction brackets needed to \nexecute  DebitChecking as an independent transaction. \n\n\n transaction ID explicitly to the application, and the application could pass that transaction ID to every resource \nit accesses. \n Most systems hide this complexity from the application programmer. Instead of returning the transaction ID to \nthe program P that invokes Start, the system typically makes the transaction ID part of a hidden  context , which is \ndata that is associated with P but is manipulated only by the system, not by P. In particular, using the context the \nsystem transparently attaches the transaction ID to all database operations and Commit and Abort operations. This \nis more convenient for application programmers — it’s one less piece of bookkeeping for them to deal with. It also \navoids errors, because if the application passes the wrong transaction identiﬁ er, the system could malfunction. \n Typically , the hidden context is associated with a thread, which is a sequential ﬂ ow of control through a pro-\ngram. A thread can have only one transaction ID in its context, so there is no ambiguity about which transaction \nshould be associated with each database operation and Commit or Abort. Threads are discussed in detail in the \nnext section. \n Notice that there are no transaction IDs in  Figure 2.1 through  Figure 2.3 . The transaction ID is simply part \nof the hidden program context. Throughout this chapter, we will assume that transaction IDs are hidden in this \nway, although as we will see some programming models allow access to this transaction context. \n Chained Transactions \n In some programming models, an application is assumed to be always executing within a transaction, so there is \nno need for the developer to start a transaction explicitly. Instead, an application simply speciﬁ es the boundary \nbetween each pair of transactions. This  “ boundary operation ” commits one transaction and immediately starts \nanother transaction, thereby ensuring that the program is always executing a transaction. In IBM’s CICS product,\nthe verb called  syncpoint works in this way. Microsoft SQL Server offers an implicit transaction mode that \nworks this way too. \n This programming style is called  chained transactions , because the sequence of transactions executed by a \nprogram forms a chain, one transaction after the next, with no gaps in between. The alternative is an  unchained \nmodel, where after a program ﬁ nishes one transaction, it need not start the execution of another transaction right \naway. For example, this can be done using the Start and Commit commands for explicit transaction bracketing. \nMost of today’s programming models use the unchained model, requiring that the developer explicitly deﬁ nes \nthe start of each new transaction. \n On the face of it, the unchained model sounds more ﬂ exible, since there may be times when you would \nwant an application to do work outside of a transaction. However, in fact there is really very little purpose in it. \nThe only beneﬁ t is in systems where a transaction has signiﬁ cant overhead even if it doesn’t access recoverable \ndata. In that case, the unchained model avoids this overhead. \n On the other hand, the unchained model has two signiﬁ cant disadvantages. First, if the code that executes \noutside a transaction updates any transactional resources, then each of those updates in effect executes as a \nseparate transaction. This is usually more expensive than grouping sets of updates into a single transaction. \nThat is, it is sometimes important to group together updates into a single transaction for performance rea-\nsons. Second, the unchained model gives the programmer an opportunity to break the consistency property of \ntransactions by accidentally executing a set of updates outside of a transaction. For these reasons, the chained \nmodel usually is considered preferable to the unchained model. \n Transaction Bracketing in Object-Oriented Programming \n With the advent of object-oriented programming for TP applications, a richer style of chained transaction \nmodel has become popular. In this approach each method is tagged with a  transaction attribute that indicates \n2.2 Transactions  35\n\n\n36  CHAPTER 2 Transaction Processing Abstractions\n its transactional behavior, thereby avoiding explicit transaction bracketing in the application code itself. The \ntransaction attribute can have one of the following values: \n ■  Requires New: Every invocation of the method starts executing in a new transaction, whether or not the \ncaller is already executing in a transaction. \n ■  Required: If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method starts executing in a new transaction. \n ■  Supported: If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method does not execute within a transaction. \n ■  Not Supported: The called method does not execute within a transaction, even if the program that created \nthe object is running within a transaction. 1 \n This style of programming was introduced in the mid-1990s in Microsoft Transaction Server, which evolved \nlater into COM \u0002 in Microsoft’s .NET Enterprise Services. In that system, a transaction attribute is attached to \na component, which is a set of classes, and applies to all classes in the component. In its intended usage, the \ncaller creates an object of the class (rather than calling a method of an existing object), at which time the trans-\naction attribute is interpreted to decide whether it is part of the caller’s transaction, is part of a new transaction, \nis not part of any transaction, or throws an exception. The called object is destroyed when the transaction ends. \n The concept of transaction attribute was adopted and extended by OMG’s CORBA standard and Enterprise \nJava Beans (EJB, now part of Java Enterprise Edition (Java EE)). It is now widely used in transactional mid-\ndleware products, as well as in Web Services. In EJB, the attributes tag each method and apply per method \ncall, not just when the called object is created. A class can be tagged with a transaction attribute, in which case \nit applies to all untagged methods. EJB also adds attributes to cover some other transaction options, in par-\nticular, Mandatory, where the called method runs in the caller’s transaction if it exists and otherwise throws an \nexception. \n Microsoft introduced per-method transaction attributes in Windows Communication Foundation in .NET \n3.0. It uses separate attributes to specify whether the method executes as a transaction and whether the caller’s \ntransaction context propagates to the called method (i.e., the difference between Required and Requires New). \n Let us call a method invocation  top-level if it caused a new transaction to be started. That is, it is top-level \nif it is tagged with Requires New or is tagged with Required and its caller was not executing in a transaction. \nGenerally speaking, a transaction commits when its top-level method terminates without an error. If it throws \nan exception during its execution, then its transaction aborts. \n A top-level method can call other methods whose transaction attribute is Required, Mandatory, or Supported. \nThis submethod executes in the same transaction as the top-level method. If the submethod terminates without \nerror, the top-level method can assume that it is ﬁ ne to commit the transaction. However, the top-level method \nis not obligated to commit, for example, if it encounters an error later in the execution of another submethod. In \nsome execution models, a submethod can continue to execute after announcing that the transaction can be com-\nmitted as far as it is concerned. \n If the submethod throws an exception, then the top-level method must abort the transaction. In some execu-\ntion models, the exception immediately causes the transaction to abort, as if the submethod had issued the \nAbort command. In other models, it is left to the top-level method to cause the abort to happen. \n Instead of having a method automatically vote to commit or abort depending on whether it terminates nor-\nmally or throws an exception, an option is available to give the developer more explicit control. For example, \n 1 Microsoft supports an additional value, Disabled, which has the same transaction behavior as Not Supported. A newly created object \nuses the  “ context ” of its caller, whereas for Not Supported the newly created object is given a fresh context of its own. Contexts are \nexplained in Section 2.5. \n\n\n in the .NET Framework, a program can do this by calling SetComplete and SetAbort. Java EE is similar, offer-\ning the setRollbackOnly command for a subobject to tell the top-level object to abort. \n The approach of using transaction attributes is declarative in that the attributes are attached to interface def-\ninitions or method implementations. Microsoft’s .NET framework also offers a runtime layer, exposed through \nthe class TransactionScope, that allows a program to invoke the functionality of the transaction  bracketing \nattributes shown previously. A program deﬁ nes a transaction bracket by creating a TransactionScope object \nwith one of the following options: \n ■  Requires New: The program starts executing within a new transaction, whether or not it was previously \nexecuting in the context of a transaction. \n ■  Required: If the program was executing in the context of a transaction, then it continues doing so. \nOtherwise, it starts a new transaction. \n ■  Suppress: The program is now executing outside of a transaction. \n In the case of Requires New and Suppress, if the program was running within a transaction  T when it created \nthe new transaction scope  S , then  T remains alive but has no activity until  S exits. \n Additional details of these approaches to transaction bracketing appear in Section 10.3 for .NET and \nSection 10.4 for Java EE. \n Nested Transactions \n The  nested transaction programming model addresses the transaction composability problem by capturing \nthe program-subprogram structure of an application within the transaction structure itself. In nested transac-\ntions, each transaction can have subtransactions. For example, the  PayLoanFromChecking transaction can \nhave two subtransactions  DebitChecking and  PayLoan . \n Like ordinary  “ ﬂ at ” (i.e., non-nested) transactions, subtransactions are bracketed by the Start, Commit, and \nAbort operations. In fact, the programs of  Figure 2.1 and  Figure 2.2 could be a nested transaction. What is dif-\nferent about nested transactions is not the bracketing operations — it’s their semantics. They behave as follows: \n 1.  If a program is already executing inside a transaction and issues a Start command, then Start creates a \n subtransaction of its parent transaction, rather than creating a new, independent transaction. For exam-\nple, if  DebitChecking is called from  PayLoanFromChecking , the Start in  DebitChecking starts a \nsubtransaction. \n 2.  If a program is  not already executing inside a transaction and issues a Start command, then Start creates \na new, independent transaction, called a  top-level transaction, which is not a subtransaction of another \ntransaction. For example, Start in  PayLoanFromChecking creates a top-level transaction. \n 3.  The Commit and Abort operations executed by a top-level transaction have their usual seman-\ntics. That is, Commit permanently installs the transaction’s updates and allows them to be read by \nother transactions. Abort undoes all the transaction’s updates. For example, Commit and Abort in \n PayLoanFromChecking have these effects. \n 4.  If a subtransaction  S aborts, then all the operations of  S are undone. This includes all the subtransac-\ntions of  S . However, the abort does not cause the abort of  S ’s parent. The parent is simply notiﬁ ed that \nits child subtransaction aborted. For example, Abort in  DebitChecking aborts the subtransaction, but \nnot its parent transaction that was started by  PayLoanFromChecking . \n 5.  While a subtransaction is executing, data items that it has updated are isolated and hence not vis-\nible to other transactions and subtransactions (just like the ﬂ at transaction model). For example, if \n2.2 Transactions  37\n\n\n38  CHAPTER 2 Transaction Processing Abstractions\n PayLoanFromChecking executed its subtransactions  DebitChecking and  PayLoan concurrently \nand those subtransactions read and wrote some shared data (which they don’t in this example), then \n DebitChecking would not see  PayLoan ’s updates until after  PayLoan commits, and  PayLoan would \nnot see  DebitChecking ’s updates until after  DebitChecking commits. \n 6.  When a subtransaction commits, the data items it has updated are made visible to other subtransactions. \nFor example, after  PayLoan commits, any data it has updated would be visible to  DebitChecking (if \nthey shared data). \n Consider the properties of subtransactions relative to the ACID properties. Rule (4) means that a subtrans-\naction is atomic (i.e., all-or-nothing) relative to other subtransactions of the same parent. Rule (5) means that \na subtransaction is isolated relative to other transactions and subtransactions. However, a subtransaction is not \ndurable. Rule (6) implies that its results become visible once it commits, but by rule (3) the results become \npermanent only when the top-level transaction that contains it commits. \n The nested transaction model provides a nice solution to the transaction composability problem. In our \nexample,  DebitChecking and  PayLoan in  Figure 2.1 can execute as subtransactions within a top-level trans-\naction executed by  PayLoanFromChecking or as independent top-level transactions, without writing an arti-\nﬁ cial wrapper transaction like  CallDebitChecking in  Figure 2.3 . \n Although nested transactions are appealing from an application programming perspective, they are not sup-\nported in many commercial products. \n Exception Handling \n An application program that brackets a transaction must say what to do if the transaction fails and therefore \naborts. For example, suppose the program divides by zero, or one of the underlying database systems deadlocks \nand aborts the transaction. The result would be an  unsolicited abort — one that the application did not cause \ndirectly by calling the Abort command. Alternatively, the whole computer system could go down. For example, \nthe operating system might crash, in which case all the transactions that were running at the time of the crash \nare affected. Thus, an application program that brackets a transaction must provide error handling for two types \nof exceptions — transaction failures and system failures. \n For each type of exception, the application should specify an  exception handler , which is a program that \nexecutes after the system recovers from the error. To write an exception handler, a programmer needs to know \nexactly what state information is available to the exception handler; that is, the reason for the error and what \nstate was lost due to the error. Two other issues are how the exception handler is called and whether it is run-\nning in a transaction. \n Information about the cause of the abort should be available to the exception handler, usually as a status \nvariable that the exception handler can read. If the abort was caused by the execution of a program statement, \nthen the program needs to know both the exception that caused the statement to malfunction and the reason for \nthe abort — they might not be the same. For example, it’s possible that there was some error in the assignment \nstatement due to an overﬂ ow in some variable, but the real reason for the abort was an unavailable database \nsystem. The exception handler must be able to tell the difference between these two kinds of exceptions. \n When a transaction aborts, all the transactional resources it accessed are restored to the state they had \nbefore the transaction started. This is what an abort means, undo all the transaction’s effects. Nontransactional \nresources — such as a local variable in the application program, or a communications message sent to another \nprogram — are completely unaffected by the abort. In other words, actions on nontransactional resources are \nnot undone as a result of the abort. \n\n\n It ’s generally best if a transaction failure automatically causes the program to branch to an exception han-\ndler. Otherwise the application program needs an explicit test, such as an  IF -statement, after each and every \nstatement, which checks the status returned by the previous statement and calls the appropriate exception han-\ndler in the event of a transaction abort. \n In the chained model, the exception handler is automatically part of a new transaction, because the previous \ntransaction aborted and, by deﬁ nition, the chained model is always executing inside of some transaction. In the \nunchained model, the exception handler is responsible for demarcating a transaction in which the exception \nhandling logic executes. It  could execute the handler code outside of a transaction, although as we said earlier \nthis is usually undesirable. \n If the whole system goes down, all the transactions that were active at the time of the failure abort. Since \na system failure causes the contents of main memory to be lost, transactions cannot resume execution when \nthe system recovers. So the recovery procedure for transaction programs needs to apply to the application as a \nwhole, not to individual transactions. The only state that the recovery procedure can rely on is information that \nwas saved in a database or some other stable storage area before the system failed. A popular way to do this is \nto save request messages on persistent queues. The technology to do this is described in Chapter 4. \n Some applications execute several transactions in response to a user request. This is called a  business pro-\ncess or  workﬂ ow . If the system fails while a business process is executing, then it may be that some but not all \nof the transactions involved in the business process committed. In this case, the application’s exception handler \nmay execute compensating transactions for the business process ’ transactions that already committed. Business \nprocess engines typically include this type of functionality. More details appear in Chapter 5. \n Savepoints \n If a transaction periodically saves its state, then at recovery time the exception handler can restore that state \ninstead of undoing all the transaction’s effects. This idea leads to an abstraction called savepoints. \n A  savepoint is a point in a program where the application saves all its state, generally by issuing a  save-\npoint command . The savepoint command tells the database system and other resource managers to mark this \npoint in their execution, so they can return their resources to this state later, if asked to do so. This is useful for \nhandling exceptions that only require undoing part of the work of the transaction, as in  Figure 2.4 . \nvoid Application\n     {  Start;\n        do some work;\n        . . .\n        Savepoint (“A”);\n        do some more work;\n        . . .\n        if (error)       \n           { Restore (“A”);\n             take corrective action;\n             Commit;\n           }\n        else Commit;\n     }      \n FIGURE 2.4 \n Using Savepoints. The program saves its state at savepoint  “ A. ” It can restore the state later if there’s an error. \n2.2 Transactions  39\n\n\n40  CHAPTER 2 Transaction Processing Abstractions\n A savepoint can be used to handle broken input requests. Suppose a transaction issues a savepoint imme-\ndiately after receiving an input request, as in the program  Application in  Figure 2.5 . If the system needs \nto spontaneously abort the transaction, it need not actually abort, but instead can roll back the transaction to \nits ﬁ rst savepoint, as in  ExceptionHandlerForApplication in  Figure 2.5 . This undoes all the transac-\ntion’s updates to transactional resources, but it leaves the exception handler with the opportunity to generate a \ndiagnostic and then commit the transaction. This is useful if the transaction needs to abort because there was \nincorrect data in the request. If the whole transaction had aborted, then the get-input-request operation would \nbe undone, which implies that the request will be re-executed . Since the request was incorrect, it is better to \ngenerate the diagnostic and commit. Among other things, this avoids having the request re-execute  incorrectly \nover and over, forever. \n Unfortunately , in some execution models the exception handler of a transactional application must abort \nthe transaction. In this case, a mechanism outside the transaction needs to recognize that the broken request \nshould not be re-executed  time after time. Queuing systems usually offer this function, which is described in \nChapter 4. \n Some database systems support the savepoint feature. Since the SQL standard requires that each SQL \noperation be atomic, the database system does its own internal savepoint before executing each SQL update \noperation. That way, if the SQL operation fails, it can return to its state before executing that operation. Since \nthe database system supports savepoints anyway, only modest additional work is needed to have it make save-\npoints available to applications. \n In general, savepoints seem like a good idea, especially for transactions that execute for a long time, so that \nnot all their work is lost in the event of a failure. Although it’s available in some systems, it’s a feature that \nreportedly is not widely used by application programmers. \n Using Savepoints to Support Nested Transactions \n Since a savepoint can be used to undo part of a transaction but not all of it, it has some of the characteristics of \nnested transactions. In fact, if a transaction executes a sequential program, then it can use savepoints to obtain \nthe behavior of nested transactions if the system adheres to the following rules: \n 1.  When a subtransaction ﬁ rst accesses a resource manager, it issues a savepoint operation. \n 2.  When a subtransaction aborts, the system restores the savepoint that the subtransaction previously \nestablished at each resource manager that the subtransaction accessed. \n 3.  To commit a subtransaction, no special action is required by the resource managers. However, future \naccesses to resource managers are now done on behalf of the subtransaction’s parent. \nVoid Application\n     {  Start;\n        get-input-request;\n        Savepoint (“B”);\n        do some more work;\n        Commit;\n      }\nVoid ExceptionHandlerForApplication\n     {  Restore (“B”);\n        generate diagnostic;\n        Commit;\n      }\n FIGURE 2.5 \n Using Savepoints for Broken Requests. The application’s savepoint after getting the request enables its exception handler \nto generate a diagnostic and then commit. If the transaction were to abort, the get-input-request would be undone, so \nthe broken request would be re-executed. \n\n\n This implementation works only if the transaction program is sequential. If it has internal concurrency, then \nit can have concurrently executing subtransactions, each of which can independently commit or abort. Since a \nsavepoint applies to the state of the top-level transaction, there will not always be a savepoint state that can \nselectively undo only those updates of one of the concurrently executing subtransactions. \n Consider the example in  Figure 2.6 , where  functionX starts a transaction and then calls  functionY \nand  functionZ concurrently, indicated by the  “ concurrent block ” bracketed by  cobegin and  coend . Both \n functionY and  functionZ access a resource manager RM_A that supports savepoints. Each of them has \ntransaction brackets and therefore should run as a subtransaction. Since  functionY and  functionZ are exe-\ncuting concurrently, their operations can be interleaved in any order. Consider the following steps : \n 1.  functionY accesses RM_A, and since this is its ﬁ rst access it issues a savepoint at RM_A (rule 1, in \nthe previous list ) . \n 2.  functionZ accesses RM_A, and therefore also issues a savepoint at RM_A (rule 1 in the previous list). \n 3.  functionY performs an update at RM_A. \n 4.  functionZ performs an update at RM_A. \n 5.  functionZ commits its subtransaction. \n 6.  functionY aborts its subtransaction. \n According to rule 2 (in the previous list),  in step 6 the system should restore the savepoint created on behalf of \n functionY . However, this will undo the update performed by  functionZ , which is incorrect, since  functionZ \ncommits in step 5. \n 2.3  PROCESSES AND THREADS \n Why We Need Threads \n A processor has a state, called the  processor context , that consists of a control thread and an address space. \nThe  control thread consists of the values stored in the processor’s registers, such as the instruction counter, \nvoid functionX;\n{ Start;\n  cobegin;\n    functionZ;\n    functionY;\n  coend;\n  Commit; }\n}\nvoid functionY;\n{ Start;\n   Access RM_A;\n   Update RM_A;\n   . . .\n   if (b) Commit\n   Else Abort;\n}  \n1\n3\n6\nvoid functionZ;\n{ Start;\n   Access RM_A;\n   Update RM_A;\n   . . .\n   if (b) Commit\n   Else Abort;\n}  \n2\n4\n5\nRM_A\n FIGURE 2.6 \n Savepoints Aren’t Enough for Concurrent Subtransactions. If  functionZ commits and  functionY aborts, there is no \nsavepoint in RM_A that produces the right state. \n2.3 Processes and Threads  41\n",
      "page_number": 51
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 60-67)",
      "start_page": 60,
      "end_page": 67,
      "detection_method": "topic_boundary",
      "content": "42  CHAPTER 2 Transaction Processing Abstractions\n the stack pointer, and data registers. It also includes certain memory areas that are assigned to the processor but \nare not directly addressable by the program running on the processor, such as a processor stack. An  address \nspace is a mapping of the processor’s view of memory to the physical memory, typically represented in regis-\nters that point to page tables. \n In a multiprogrammed system, every active program has an associated processor state. For a program that’s \ncurrently executing, it is the state of the physical processor on which it’s running. For programs that were exe-\ncuting and are temporarily idle, the state is saved in main memory and will be reloaded into a processor when \nthe program resumes execution. \n The architecture of a TP system is affected by whether components share an address space, whether that \naddress space has one thread or multiple threads executing, and whether there are hardware, operating system, \nor language mechanisms to protect programs that share an address space from inappropriately modifying each \nother’s memory. For example, traditional timesharing systems, such as early UNIX operating systems, were \nstructured so that each display device had its own process, each process had exactly one thread executing, and \nall programs that ran on behalf of that display device executed in that one process. As we’ll see, TP systems \ndon’t work this way. \n In the timesharing model one could implement a TP system by combining all three TP application functions \ninto one big sequential program, rather than splitting them across front-end, middle-tier, and back-end servers. \nThe TP application would simply be a sequential program that consists of an inﬁ nite loop that gets an input \nmessage from a display device, starts a transaction, calls the appropriate transaction server program to run the \nrequest, commits or aborts that transaction, and returns to the top of the loop to do it again. Each display device \nwould be connected to a process that runs this program, thereby executing transactions on behalf of that display. \n There are many disadvantages, however, of using this execution model. The most important is that there \nare just too many processes. A system with tens or hundreds of thousands of display devices would have tens \nor hundreds of thousands of processes, because it needs one process for every display device. Most operating \nsystems do not work well with such a large number of processes, for many reasons: \n ■  Some operating system functions sequentially scan lists of processes. If the list is too long, it takes too \nlong to perform these operating system functions. \n ■  There is a lot of context switching between these processes, which involves swapping out register values \nof one process and loading those of another process, including invalidating and reloading the processor’s \ncache memory. \n ■  There’s usually a certain amount of memory for each process that has to remain in physical main memory \nand can’t be paged at all. Given this high memory consumption, many processes may have some of their \nvirtual memory out on disk, which has to be paged in when the transaction is invoked, adding extra delay. \n ■  Distributing transactions on multiple nodes require even more processes, because each display device \nneeds a process running on every system doing work on behalf of that display. \n ■  It is difﬁ cult to control the load on such a system. The only knob you can turn is to reduce the number of \nactive processes. Since each process is associated with a display device, shutting down a process effec-\ntively turns off a display — bad news for the person using that display. It would be better to shut down only \ncertain low-priority types of transactions, but this is hard to control because those transaction types are \nburied in the application. It would require some application programming to control the load in this way. \n ■  With a large number of processes, the complexity of sharing data structures between processes is sig-\nniﬁ cantly higher and requires more costly synchronization. Additionally, resources shared between pro-\ncesses can become orphaned under certain failure scenarios. \n\n\n Due to all these disadvantages, from a very early stage in the history of TP systems, transactional middle-\nware started supporting multithreaded processes. Like all abstractions supported by transactional middleware, \nthis threading abstraction is made available in a uniform way across all the operating systems that the transaction \nmiddleware supports. \n A multithreaded process supports many control threads in a single address space. Each thread is an inde-\npendent path of execution through the process. All the threads in the process execute the same program and \nuse the same process memory. But each of them has a save area for register values and private variables (e.g., \nthe process stack). See  Figure 2.7 . Thus, a multithreaded process has many executions of its program running \nconcurrently, one for each of its threads. \n Threads save memory, since the process ’ memory is shared by many threads. It avoids some of the expense \nof context switching, since a processor can switch between threads without switching address spaces. And it \nreduces the number of processes, since threads can be used instead of processes and there can be many threads \nper process. \n In a system with dedicated display devices, a single multithreaded process can manage multiple displays. \nIn this case, a thread can be used to execute a program on behalf of a display. When the process switches atten-\ntion between display devices, it switches to a different thread. Compared to a process-per-display, this reduces \nthe number of processes and the number of context switches. \n Initially , threads were dynamically allocated to display devices when the display was actively executing a \nrequest. Later, as the cost of processors and memory declined, a thread was statically allocated to each display \ndevice. \n Implementing Threads \n Threads can be implemented by middleware or by the operating system. There are beneﬁ ts to each approach. \n Middleware Threads \n If threads are implemented by transactional middleware, then the operating system doesn’t know about the \nthreads. It’s just running an ordinary process. Basically the transactional middleware is fooling the operating \nsystem by turning the process’s attention to different display devices by itself. However, this may produce \ninterference between these two levels of scheduling. Since the operating system is scheduling processes and the \ntransactional middleware is scheduling threads within the process, they may end up working at cross-purposes. \n There is one technical difﬁ culty with having the transactional middleware implement threads. If a transac-\ntion server, executing in a multithreaded process, tries to read data from disk or tries to read a communications \nThread 1\nsave area\n• registers\n• stack\nProcess’ program area\nProcess’ data area\nThread 2\nsave area\n• registers\n• stack\nThread 3\nsave area\n• registers\n• stack\nThread n\nsave area\n• registers\n• stack\nMemory shared\nby all threads\n FIGURE 2.7 \n Memory Structure of a Multithreaded Process. In addition to the usual program and data areas, there is a save area for \neach thread, instead of one save area for the whole process as in a single-threaded process. \n2.3 Processes and Threads  43\n\n\n44  CHAPTER 2 Transaction Processing Abstractions\n message, and the data that it needs is not yet available, then the operating system ordinarily will put the process \nto sleep. If there’s only one thread running, this is the right thing to do — put the process to sleep until it has \nsome work to do. But if there are multiple threads running inside the process, then all the threads, and therefore \nall the displays, end up getting delayed. This is bad, because some of those other displays could do useful work \nwhile the ﬁ rst display’s I/O operation is in progress. \n For this reason, the transactional middleware has to trap any of those synchronous I/O operations (generally \nreads) to avoid putting the process to sleep. Instead, it sends an asynchronous message to the disk, database \nsystem, or communications system, and asks to get a software interrupt back when the operation is complete. \nAfter the message is sent, the transactional middleware can continue operating by calling another thread that \nhas useful work to do. When the I/O operation that corresponds to the message has ﬁ nished, it will send a soft-\nware interrupt to the transactional middleware, which then wakes up the thread that was waiting for that result. \nThe cost of this approach to multithreading is that all the calls to I/O operations have to be intercepted by the \ntransactional middleware. \n For example, the mainframe version of IBM’s CICS transactional middleware product has worked this way \nstarting from its earliest implementations. It offers I/O operations that can be invoked from ordinary appli-\ncation programs, such as COBOL and C. Some transactional middleware products trap all synchronous I/O \noperations. \n Operating System Threads \n If the operating system supports multithreading, it keeps track of all the threads on its own. For example, since \nthe mid-1990s, Windows and UNIX operating systems support this. When a thread issues a synchronous I/O \noperation, the operating system puts that thread to sleep. But it recognizes when there are other active threads \nthat it can call and calls another thread that’s ready to execute (in that process), rather than putting the whole \nprocess to sleep. This avoids unnecessary context switching. Another beneﬁ t of operating system multithread-\ning is that if the process is running on a shared memory (i.e., symmetric) multiprocessor (SMP) or a multicore \nprocessor, it can assign the threads of the same process to different processors in the machine and thereby get \nparallelism among the threads of the process. \n A difﬁ culty of operating system multithreading, however, is performance overhead. Since it is the operat-\ning system that is involved in switching threads, this involves system calls. These are generally more expensive \nthan thread operations executed at the user level, which is where the transactional middleware is operating. \n There is a second disadvantage of multithreading, which is a problem whether it is implemented by the \nmiddleware or the operating system. Since there are multiple threads running inside the same process, there’s \nlittle or no memory protection between them. An error in the execution of one thread could potentially damage \nmemory for the entire process, thereby causing all the threads to malfunction. This could also lead to a security \nleak, if one thread reads memory that is private to another thread. With operating system threads, this prob-\nlem can be somewhat mitigated by providing a protected memory area for special subsystems, such as transac-\ntional middleware functions, which can be protected from user level code. It can also be mitigated by the use of \nstrongly-typed  programming languages, such as Java and C#, which can make fairly strong guarantees that an \nexecuting program will access only memory dedicated to its use. \n A third disadvantage of multithreading is that a multithreaded process cannot use a single-threaded process \nthat retains context information for only one thread. The canonical example of this is early database system \nproducts. Until the mid-1980s, most database systems were single-threaded and could execute only one trans-\naction at a time. The database system executed as a runtime library in each single-threaded application process. \nThus, if a multithreaded process invoked a database system, all threads in the process would have to be run-\nning the same transaction, which is obviously not what is intended when using multithreaded applications for \n\n\n TP. This problem was solved by the database system vendors who re-engineered their products to run as inde-\npendent multithreaded processes, where each thread could run a different transaction. This enables each thread \nof a multithreaded application process to have an independent connection to a database system and have the \ndatabase system execute that connection in a thread (and hence in a transaction) that’s private to the connec-\ntion. Most database systems today work this way, though there is still a market for database systems that run in \nthe application process (e.g., for embedded systems). We will have more to say about multithreaded database \nservers in Section 3.7. \n In summary, multithreading offers signiﬁ cant efﬁ ciency improvements, but must be used carefully to avoid \nblocking during I/O operations, interference between transactional middleware and operating system schedul-\ning, performance overhead in thread context switching, and corruption of unprotected memory. Overall, for \nmost applications, operating system multithreading is superior to transactional middleware multithreading, \nsince it avoids the ﬁ rst two of these problems and can beneﬁ t from multicore and SMP conﬁ gurations. For this \nreason, operating system multithreading has become ubiquitous in current TP products. The use of transac-\ntional middleware multithreading is now mostly limited to older products. \n Server Classes \n When multithreaded operating system processes are not available, a good alternative is to use a set of pro-\ncesses to emulate a pool of threads. That is, instead of having one multithreaded process, the system uses a set \nof single-threaded processes, all of which are running the same program (see  Figure 2.8 ). This often is called a \n server class . In this case, for each server program, there is a set of server processes that runs it. \n Server classes have a number of nice features. Most of them stem from the fact that each process in the \nserver class is an ordinary single-threaded process and therefore avoids the disadvantages of multithreading, \nsuch as the following: \n ■  Since the process is single-threaded, there’s no harm in putting it to sleep if it is blocked during a syn-\nchronous I/O operation. Therefore, there is no need for the transactional middleware to trap synchronous \nI/O; the normal blocking behavior of the operating system is just ﬁ ne. \n ■  There’s no possible conﬂ ict between process and thread scheduling and no possible memory corruption \nproblems from threads in the same process. \n ■  Processes in a server class fail independently. That is, a server class is largely unaffected by the failure of \nany individual process in the server class, since other processes continue to run. This is in contrast to a \nT\nh\nr\ne\na\nd \n1\nT\nh\nr\ne\na\nd \n2\nT\nh\nr\ne\na\nd \nn\nMultithreaded\nServer Process\nServer Class (many single-threaded processes)\nServer\nProcess\n1\nServer\nProcess\n2\nServer\nProcess\nn\n FIGURE 2.8 \n Multithreaded Process vs. Server Class. In both cases, there is one server program and many threads executing it. The \ndifference is whether the threads execute in one process (multithreaded server) or many processes (server class). \n2.3 Processes and Threads  45\n\n\n46  CHAPTER 2 Transaction Processing Abstractions\n multithreaded process, where the failure of one thread can bring down the whole process, especially if it \ncorrupts the memory of other threads. \n ■  Each process in a server class can use single-threaded services, such as a single-threaded database sys-\ntem that executes as a runtime library. This was an important beneﬁ t before the advent of multithreaded \ndatabase systems. \n For these reasons, and to avoid the expense of implementing multithreading, server classes were quite pop-\nular in transactional middleware products before the advent of multithreaded operating systems, as in the case \nof HP’s ACMS and Pathway legacy TP monitors. \n However , server classes do have disadvantages. One is that there is a process per thread. As we explained \nearlier, operating systems don’t work well with too many processes. So server classes can be used only when \nthe number of required server threads is relatively small. \n Another disadvantage of server classes is that they require an additional mechanism to dispatch calls to \nthe server class to a particular server process. The problem is how to balance the load across the servers in the \nserver class. The caller could randomize its selection of server, thereby balancing the load across multiple serv-\ners, on the average. Or, the processes in the server class could share a queue of unprocessed requests. If a busy \nprocess receives a call, it simply adds it to the queue, where another process can pick it up. Or, the server class \ncould have a single process that receives all requests and routes each one to an idle process. The latter is easy \nto implement, but costs an extra context switch, since each call has to invoke the server class’s router process \nbefore going to a server. We will have more to say about load balancing in Section 2.6. \n 2.4  REMOTE PROCEDURE CALL \n Remote procedure call (RPC) is a programming mechanism that enables a program in one process to invoke \na program in another process using an ordinary procedure call, as if the two programs were executing in the \nsame process (or more precisely, in the same address space). \n There are several beneﬁ ts to programming in the RPC style. First, the programmer can still write and reason \nabout a program as if all the program’s procedures were linked together in a single process. Therefore, the pro-\ngrammer can focus on correctly modularizing the program and ignore the underlying communications mecha-\nnism. In particular, the programmer can ignore that the program is really distributed, which would add signiﬁ cant \ncomplexity to the programming task if it were made visible. \n Second , the RPC style avoids certain programming errors because of the simple request-response message \nprotocol that it implies. Using RPC, a program receives a return for every call. Either the caller receives a return \nmessage from the called procedure, or the system returns a suitable exception to the caller so it can take appro-\npriate action. By contrast, using asynchronous message passing, a program has explicit statements to send and \nreceive messages. These send and receive operations issued by communicating programs deﬁ ne a communica-\ntion protocol. This requires the programmer to handle the message sequences and errors directly. For example, \neach program must be ready to receive a message after the message is sent to it. Programs have to cope with \ncertain error conditions, such as waiting for a message that never arrives, or giving up waiting for a message and \ncoping with that message if it does eventually arrive later. In RPC, these problems are dealt with by the RPC \nimplementation rather than by the application program. \n Third , RPC implementations can hide the differences in parameter format between the programming lan-\nguages in which the client’s and server’s program are written. RPC implementations also can hide differences \namong processors such as Intel x86, AMD, PowerPC, and SPARC and the differences among operating sys-\ntems such as Windows and Linux. \n\n\n To understand how RPC works, consider the example in  Figure 2.9 . This program consists of three procedures: \n ■  PayCreditCard , which pays a credit card bill \n ■  DebitChecking , which subtracts money from a checking account \n ■  PayBill , which calls  PayCreditCard and  DebitChecking to pay a credit card bill from a checking \naccount \n Let us assume that these three procedures execute in separate processes, possibly on different nodes of a net-\nwork. Therefore, the invocations of  PayCreditCard and  DebitChecking by  PayBill are remote procedure \ncalls. \nBoolean Procedure PayBill (acct#, card#)\n{ int     acct#, card#;\n  long    amount;\n  Boolean ok;\n  Start;  /* start a transaction */\n  amount = PayCreditCard(card#);\n  ok = DebitChecking(acct#, amount);\n  if (!ok) Abort else Commit;\n  return (ok);\n}\nlong Procedure PayCreditCard (card#);\n{ int  card#;\n  long amount;\n  /* get the credit card balance owed */\n  Exec SQL Select AMOUNT\n           Into :amount\n           From CREDIT_CARD\n           Where (ACCT_NO = :card#);\n  /* set the balance owed to zero */\n  Exec SQL Update CREDIT_CARD\n           Set AMOUNT = 0\n           Where (ACCT_NO = :card#);\n  return (amount);\n}\nBoolean Procedure DebitChecking (acct#, amount);\n{ int  acct#;\n  long amount;\n  /* debit amount from checking balance if balance is sufficient */\n  Exec SQL Update ACCOUNTS\n           Set BALANCE = BALANCE - :amount\n           Where (ACCT_NO = :acct# and BALANCE ≥ amount);\n  /* SQL Code = 0 if previous statement succeeds */\n  return (SQLCODE == 0);\n}\n FIGURE 2.9 \n Credit Card Payment Example.  PayBill brackets the transaction and calls two subprograms,  PayCreditCard and \n DebitChecking , which it calls by RPC. \n2.4 Remote Procedure Call  47\n\n\n48  CHAPTER 2 Transaction Processing Abstractions\n PayCreditCard  takes a credit card account number as input, returns the amount of money owed on that \naccount, and zeroes out the amount owed. The ﬁ rst SQL statement selects the amount of money from the credit \ncard table, which contains the amount of money owed on each account number. The second statement zeroes \nout that amount (i.e., the entire balance is paid off) and returns the amount actually owed for the account. \n DebitChecking  subtracts a given amount of money from a given account. In the SQL statement, if the \nbalance in that account is greater than or equal to the amount of money to be debited, then it subtracts the \namount of money to be debited from the account balance. In this case, the SQL statement succeeds and there-\nfore sets SQLCODE to zero, so  DebitChecking returns true. On the other hand, if the balance in that account \nis less than the amount of money to be debited, then the SQL statement does not update the account balance. \nSince the SQL statement failed, SQLCODE is not set to zero and  DebitChecking returns false. \n Each of these programs is useful by itself. The  PayCreditCard program can be used to process credit card \nbills. The  DebitChecking program can be used to process debits and credits against a checking account from \nan ATM. Using these two programs, we can easily write a  PayBill program that implements a  bill-paying \ns ervice by paying a customer’s credit card bill out of his or her checking account. \n The  PayBill program takes a checking account number and credit card number and tries to pay the credit \ncard bill out of the checking account. The program starts a transaction, pays the credit card bill (which returns the \namount of money owed), and tries to debit that money from the checking account. If the  DebitChecking program \nreturns true — meaning that there was enough money to pay the bill — the program commits. If it returns false, then \nthere wasn’t enough money to pay the bill and the transaction aborts. In both cases the  PayCreditCard program \nupdates the credit card table. But if the  PayBill program aborts the transaction, the abort automatically undoes \nthat update, thereby leaving the bill for that credit card account unpaid. (If  DebitChecking returns false, its SQL \nupdate failed and has no effect on the  ACCOUNTS table.) \n Transactional RPC \n The RPC runtime system has some extra work to do to allow a transaction to invoke an RPC. It has to pass the \ntransaction context from the caller to the callee (which may be hidden, as in  Figure 2.9 and earlier examples) \nand must throw transaction-related exceptions back to the caller. In addition to the transaction ID, the context \nmay include security credentials, the identity of the system that started the transaction, and other system infor-\nmation that is required by the callee to continue operating within the same transaction. An RPC mechanism \nthat does this additional work is called a  transactional RPC . \n A transactional RPC system may also need to do some work to support two-phase commit. For example, \nas part of making an RPC call, it may need to call the transaction manager on the caller’s and callee’s systems \nto notify them that the transaction has now moved to a new system. This information is needed later when the \ntwo-phase commit protocol is initiated, so the transaction managers know which systems are participants in \nthe transaction. We’ll discuss these issues at length in Chapter 8. \n Sometimes , the RPC mechanism itself is used to transmit the two-phase commit messages. This is an imple-\nmentation strategy for the vendor of the two-phase commit implementation. It is a sensible one, but has no effect \non the functionality available to application developers. This is  not what is meant by the term  “ transactional RPC. ” \n Binding Clients and Servers \n The programs shown in  Figure 2.9 are incomplete in that they don’t show how the caller and callee procedures \ndiscover each other’s interfaces and establish connections that enable them to communicate. First of all, to \nmake remote procedure call worthwhile in this situation, the  PayBill program would probably be running in \na different process, possibly on a different system, than the  PayCreditCard or  DebitChecking programs. \n\n\n To compile and run the programs on these different systems,  PayBill needs to reference the external proce-\ndures  PayCreditCard and  DebitChecking . This is done by writing an  interface deﬁ nition for each pro-\ngram to be called — in this case  PayCreditCard and  DebitChecking . \n Interface Deﬁ nitions \n An interface deﬁ nition speciﬁ es the name and type of the program and its parameters. It is processed by the \n interface compiler or  stub compiler , which may be part of the programming language compiler if the latter \nhas built-in RPC functionality. The interface compiler produces several outputs, one of which is a header ﬁ le \n(consisting of data structures) for the caller to use. In this case the interface compiler would produce header ﬁ les \nfor  PayCreditCard and  DebitChecking that could be included with the  PayBill program so that it can be \ncompiled. The interface compiler also produces  proxy and  stub procedures, which are the programs that inter-\nface the  PayBill caller to the  PayCreditCard and  DebitChecking servers via the network. The caller’s \nprogram is linked with a proxy and the server’s program is linked with a stub. The interface compiler produces \nboth the header ﬁ les and the proxy and stub procedures.  Figure 2.10 illustrates the interface compiler operation. \n Marshaling \n Another function of the proxy and stub procedures is to lay out the procedure name and parameters into a \nstream, which can be sent in a message. This is called  marshaling . \n Some care is needed to avoid marshaling too much information, such as repeatedly copying and sending \nthe same object class information. In addition, it is sometimes hard to maintain identity when sending items of \na type. For example, Java enumerations don’t maintain identity over RPC. \n As part of marshaling parameters, the proxy can translate them between the format of the caller and the cal-\nlee. In the previous examples, all the programs were written using the same language, but that needn’t be the \ncase. The  PayCreditCard and  DebitChecking programs might have been written some time ago in one lan-\nguage, whereas the  PayBill program was added later to introduce the new service and was written in a different \nlanguage. In this case the client proxy translates the parameters into a standard format that the callee can under-\nstand, and the server stub translates that into the appropriate format for the procedures called  PayCreditCard \nand  DebitChecking . \nInterface Definition\nHeader Files\nProxy\nStub\nCompiler\n FIGURE 2.10 \n Interface Compiler Operation. The interface compiler produces header ﬁ les for the caller and callee to use, and proxy \nand stub procedures that provide an interface between the caller and callee and the underlying network. \n2.4 Remote Procedure Call  49\n",
      "page_number": 60
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 68-75)",
      "start_page": 68,
      "end_page": 75,
      "detection_method": "topic_boundary",
      "content": "50  CHAPTER 2 Transaction Processing Abstractions\n Communication Binding \n Besides linking in the proxy and stub, there is the issue of creating a communication binding between these \nprograms so they can communicate over the network. The runtime system has to know where each server \nprocess exists (e.g.,  PayCreditCard and  DebitChecking ), so it can create bindings to each server process \nwhen asked (e.g., by  PayBill ). Two activities are involved: \n ■  Each server program must  export or publish its interface, to tell all the systems on the network that it \nsupports this interface. It must also tell where on the network it can be found. \n ■  When the  PayBill program wants to connect to the server, it must create a communications connection \nusing that information exported by the server. \n These activities are ordinarily supported by a  registry service . For a Web Service, its interface is typically \ncontained within a Web Services Description Language (WSDL) ﬁ le that can be retrieved from a registry. A reg-\nistry is used to store and retrieve the interface information and is accessible from any computer in the distributed \nsystem. For example, when the  PayCreditCard program is initialized in a process, its location can be written \nto the registry service (step 1 in  Figure 2.11 ). This location could be  “ process 17315 ” of network node 32.143, \nURL  www.xyz.net (which is deﬁ ned in the WSDL ﬁ le). When the  PayBill program asks to connect to the \n PayCreditCard program, it calls the registry service (one of the RPC runtime calls mentioned earlier) to ﬁ nd out \nwhere  PayCreditCard is located (step 2). The registry service returns the instances of  PayCreditCard it knows \nabout (in this case, there is one). If there are any running,  PayBill may connect to any one of them (step 3). \nSome implementations of communication bindings automate server selection to balance the load across multiple \nidentical servers. Having received the network address of the server process number (in this case 32.143.17315), \nthe  PayBill process can now communicate with the server, so it can issue RPCs to  PayCreditCard . \n Mapping interface or server names into network addresses has to be a dynamic function, to support peri-\nodic reconﬁ guration. For example, if a server on one system fails, and the system manager recreates that server \non another system, the mapping needs to be updated to reﬂ ect the new location of the server. The system man-\nager may also want to move servers around to rebalance the load across servers, for example due to changing \ninput patterns. \n The registry that supports the binding activity needs to be accessible from all machines in the distributed sys-\ntem. This functionality ordinarily is supported by a network directory service, usually by replicating its c ontents \n3. Create a communication binding\nfor a given network address.\n1. Store server’s name\n \nand network address.\n2. Get network address\n \nfor a given server name.\nServer\nClient\nRegistry Service\n FIGURE 2.11 \n Using a Registry Service. When it’s initialized, the server stores its name and address in the registry service. Later, the \nclient gets the server’s address and uses it to create a communication binding. \n\n\n on many servers. For this reason, registries are often implemented on top of a network directory. For good per-\nformance, the network directory provides a client layer that caches recently accessed information. The client \nusually has connections to multiple directory services, so it can quickly switch between them if one fails. \n Instead of using a replicated repository, a simpler primary-copy approach may be supported. In this approach, \na central copy of the repository is maintained, and each system keeps a cached copy that is periodically refreshed. \nThis arrangement gives fast access to the cached mapping during normal operation. When a reconﬁ guration \nrequires that the central copy be updated, the central copy must notify the other systems to refresh their caches. \n Much of this work is done by the RPC runtime system, but some may be exposed to the application. For \nexample, the application may have to issue calls to get the network address and create a communications bind-\ning. Most systems hide this. A distinguishing feature among different implementations of RPC is how much of \nthis complexity the application programmer has to cope with. \n Dispatching \n When an RPC call arrives at the target system, the RPC runtime library needs to invoke the designated server \nprocess. If the multithreaded process or server pool doesn’t exist, then the runtime creates it. If the server is \na multithreaded process, then the runtime needs to assign the call to a thread. It can create a new thread to \nprocess the call, assign the call to an existing thread, or put the call packet on a queue (e.g., if the process is \nalready executing its maximum allowable number of active threads). If a server pool is used, then it assigns the \ncall to a server process, or if all server processes are busy it enqueues the request. \n Application Programmer’s View \n Although the RPC style does simplify some aspects of application programming, it may also introduce some \nnew complexities. First, to write these programs, one may have to write interface deﬁ nitions for the servers. \nThis is a new programming task that isn’t needed in the single-process case. \n Second , to support synchronous waiting by the caller, one needs a multithreaded client so that blocking \na caller doesn’t stall the client process. Programmers ﬁ nd it challenging to write  thread-safe applications \nfor multithreaded servers. Program-level locking problems slow throughput, consume processor cycles, or \nworse — a single memory corruption can stop many threads. As the number of available processor cores is pro-\njected to increase dramatically in the coming years, ﬁ nding ways to simplify thread-safe programming is a hot \nresearch topic in computer science. \n Third , the client and server programs need startup code to connect up or  bind the programs together before \nthey ﬁ rst communicate. This includes importing and exporting interfaces, deﬁ ning security characteristics, set-\nting up communication sessions, and so on. Although much of this can be hidden, sometimes a lot of it isn’t. \nFinally, communication failures generate some new kinds of exceptions, such as a return message that never \nshows up because of a communications or server failure. Such exceptions don’t arise in the sequential case \nwhen the programs are running inside of the same process. \n Object-Oriented RPC \n In an object-oriented programming model, procedures are deﬁ ned as methods of classes. There are two types \nof methods,  class methods and  object methods . A class method is invoked on the class itself, such as the \nmethod  new , which creates an object (i.e., instance) of the class. Most methods are object methods, which \nare invoked on an object of the class, not the class itself. For example, the procedures in  Figure 2.9 could be \ndeﬁ ned as object methods of three classes:  PayBill as a method of the Billing class,  PayCreditCard as a \nmethod of the CreditCard class, and  DebitChecking as a method of the CheckingAccount class. (Class deﬁ -\nnitions are not shown in  Figure 2.9 .) \n2.4 Remote Procedure Call  51\n\n\n52  CHAPTER 2 Transaction Processing Abstractions\n To invoke an object method, the caller uses a reference (i.e., a binding) to the object. This could be created \nby the caller when it invokes the method  new . If the class is remote, then this invocation of  new is itself an \nRPC, which returns a reference to a new object of the remote class. The object lives in the remote class, while \nthe reference is local to the caller. The reference is thus a local  surrogate for the remote object. The caller can \nnow invoke an object method on the surrogate, which the caller’s runtime system recognizes as an RPC to the \nreal object that resides in the remote class. \n As an optimization, the invocation of the method  new usually is executed locally in the caller’s process \nby creating the surrogate and not yet calling the method  new on the remote class. When the caller invokes an \nobject method on the newly created object for the ﬁ rst time, the caller’s runtime system sends both the invoca-\ntion of the method  new and the object method in a single message to the remote class. This saves a message \nround-trip between the caller and the remote class. Since the only thing that the caller can do with the newly \ncreated object is to invoke methods on the object, there’s no loss of functionality in grouping the remote invo-\ncation of the method  new with the ﬁ rst invocation of a method on it. \n A remote object may need to live across multiple object method calls, so that the object can retain state \ninformation that is accessible to later invocations of the object’s methods. For example, the ﬁ rst invocation of \nan object could invoke an ExecuteQuery method, which executes an SQL query. Later invocations of the object \ncould invoke a GetNext method, each of which returns the next few rows that are in the result of that query. \nOther examples of retained state are discussed in Section 2.5. \n Callbacks \n A callback enables the callee of an RPC to invoke the caller. The caller of the RPC includes a so-called  con-\ntext handle as a parameter to the RPC. The callee can use the context handle to call back to the caller. One use \nof callbacks is to pass along a large parameter from caller to callee a-chunk-at-a-time. That is, instead of send-\ning the large parameter in the original RPC to the callee, the caller sends a context handle. The callee can use \nthis context handle to call back to the caller to get a chunk of the parameter. It executes multiple callbacks until \nit has received the entire large parameter. \n The context handle passed in a callback could be an object. In a sense, a callback is an object-oriented RPC \nin reverse; it is the RPC callee that holds a reference to the caller, rather than having the caller hold a reference \nto the callee. \n An RPC Walkthrough \n Now that we have explained the main components of an RPC system, let’s walk through an example to see \nwhat happens, beginning-to-end. In  Figure 2.12 , the client application calls the server application. The client \napplication could be the  PayBill program, for example, and the server application could be  PayCreditCard . \nAs we discussed, there are proxy and stub programs and a runtime system along the path. \n The client application issues a call to the server, say  PayCreditCard . This  “ Call  PayCreditCard ” state-\nment actually calls the client’s  PayCreditCard proxy (1). The proxy is a procedure with the same interface \nas the server application; it looks exactly like  PayCreditCard to the client. Of course the  PayCreditCard \nproxy doesn’t actually do the work. All it does is send a message to the server. \n The  PayCreditCard proxy marshals the parameters of  PayCreditCard into a packet (2). It then calls \nthe communications runtime for the RPC, which sends the packet as a message to the server process (3). \n The RPC runtime creates a communications binding between the processes and adds it as a parameter to \nsubsequent send and receive operations. The client’s RPC runtime sends each message to the server’s RPC run-\ntime. The server’s RPC runtime contains a binding of message types to processes and procedures within them \nand uses it to direct each message to the right procedure. \n\n\n The server process’s RPC runtime system receives the message (4). It looks at the packet’s header and sees \nthat this is a call to the  PayCreditCard program, so it calls the  PayCreditCard server stub. The server stub \nunmarshals the arguments and performs an ordinary local procedure call to the  PayCreditCard program (5). \nThe  PayCreditCard program takes the call and runs just as if it had been called by a local caller instead of a \nremote caller (6). \n When  PayCreditCard completes, the whole mechanism runs in reverse:  PayCreditCard does a return \noperation to the program that called it. From  PayCreditCard ’s viewpoint, that’s the server stub. When it returns \nto the server stub, it passes a return value and perhaps some output parameters. The server stub marshals those \nvalues into a packet and passes them back to the RPC runtime system, which sends a message back to the caller. \n The caller’s system receives the packet and hands it to the correct process. The process’s RPC runtime \nreturns to the correct proxy for this call, which unmarshals the results and passes them back as part of its return \nstatement to the original  PayCreditCard call, the client’s call. \n5.  The server stub \nunpacks the arguments \nand calls the server \nprogram.\nClient’s System\n1.  The client\ncalls the local\nproxy.\n3.  The client runtime\nsystem sends the call\npacket (arguments\nand procedure name).\n2.  The client proxy\nmarshals arguments to\nPayCreditCard. \nClient\nApplication\nCall\nPayCreditCard\nPay-\nCreditCard\nReturn to\nPayBill\nPACK\nARGUMENT\nPACK\nRETURN\nUNPACK\nARGUMENT\nUNPACK\nRESULT\nRECEIVE\nRECEIVE\nWAIT\nWORK\nSEND\nSEND\nRETURN\nPACKET\nCALL\nPACKET\nClient\nProxy\nRPC\nRuntime\nRPC\nRuntime\nServer’s System\nServer\nStub\nServer\nApplication\n4.  The server runtime\nreceives the message\nand calls the right stub.\n6.  The PayCreditCard program \nruns as if it were called locally. Its \nresults flow back to the caller by \nreversing the procedure that \nexecuted the call, this time going \nfrom server to client.\n FIGURE 2.12 \n RPC Implementation. The numbers indicate the sequence of actions to process a call from the client to the \n PayCreditCard server program. \n2.4 Remote Procedure Call  53\n\n\n54  CHAPTER 2 Transaction Processing Abstractions\n System Characteristics of RPC \n An RPC system needs to be engineered for security, fault tolerance, performance, and manageability. Some \nRPC systems are engineered speciﬁ cally for interoperability across multiple programming languages, data for-\nmats, and operating systems. We discuss these system issues in the following subsections. \n Security of RPC \n When a client binds to a server, the client ﬁ rst calls the runtime system to ﬁ nd the server’s address and to cre-\nate a communications binding to the server. A secure gatekeeper is needed to control the creation of these \nbindings, since not all clients should be able to connect to any server for any purpose. As an extreme example, \nit shouldn’t be possible for any workstation to declare itself the network-wide  electronic mail server, since it \nwould allow the workstation to eavesdrop on everyone’s mail. \n In general, when a client connects to a server, it wants to know who it is actually talking to — that the server \nis who it says it is. Moreover, the server wants to authenticate the client, to be sure the client is who it claims to \nbe. This requires  authentication ; that is, a secure way to establish the identity of a system, a user, a machine, \nand so forth. Thus, when binding takes place, the runtime system should authenticate the names of the client \nand the server (see  Figure 2.13 ). This ensures, for example, that the server can prove that it really is the mail \nserver, and the client can prove that it’s really a client that’s allowed to connect to this server. \n Having authenticated the client, the server still needs to exercise  access control ; that is, to check whether a \nclient is authorized to use the procedure. Access control is entirely up to the server. The server’s transactional \nmiddleware or operating system may help by offering operations to maintain a list of authorized clients, called an \n access control list . But it’s up to the server to check the access control list before doing work on behalf of a client. \n Fault Tolerance in RPC \n A common fault tolerance problem is determining what a program should do if it issues an operation but \ndoesn’t get a reply that tells whether the operation executed correctly. We saw an example of this in Section \n1.3,  Handling Real-World Operations , in dealing with a missing reply to a request to dispense $100 from an \nATM. This problem also arises in RPC when a client issues a call and does not receive a reply. The key ques-\ntion is whether it is safe to retry the operation. \n Suppose a client calls a server that processes the call by updating a database, such as the  DebitChecking \nprogram in  Figure 2.9 . If the client does not receive a return message, it’s not safe to try the call again, since \nit’s possible that the original call executed, but the return message got lost. Calling  DebitChecking again \nwould debit the account a second time, which is not the desired outcome. \n The property that says it is safe to retry is called idempotence. An operation is  idempotent if any number of \nexecutions of the operation has the same effect as one execution. In general, queries are idempotent — it doesn’t \nClient\nServer\nAccess\nControl\nList\n1  Create a communication binding, passing\n \nin the authenticated client identity.\n2   Acknowledge the communication binding,\n \npassing back the authenticated server identity.\n3  RPC to the server, which checks that the\n \nclient is authorized to make this particular call.\n1\n2\n3\n FIGURE 2.13 \n RPC Security. The communication system authenticates the client and server when it creates a communication binding \nbetween them (in 1 and 2). The server checks the client’s authorization on subsequent calls for service (in 3). \n\n\n matter how many times you call, you always get back the same answer (if there are no intervening updates) \nand there are no side effects. Most update operations are not idempotent. For example,  DebitChecking is not \nidempotent because executing it twice has a different effect than executing it just once. \n A server is idempotent if all the operations it supports are idempotent. It is useful if a server declares that \nit is idempotent (e.g., its operations are all queries). The RPC runtime system learns that fact when it creates a \nbinding to the server. In this case, if the client RPC runtime sends a call but does not receive a reply, it can try \nto call again and hope that the second call gets through. If the server is not idempotent, however, it’s not safe to \nretry the call. In this case, the client could send a control message that says  “ Are you there? ” or  “ Have you pro-\ncessed my previous message? ” but it can’t actually send the call a second time, since it might end up executing \nthe call twice. \n Even if it resends calls (to an idempotent server) or it sends many  “ Are you there? ” messages (to a non-idem-\npotent server), the caller might never receive a reply. Eventually, the RPC runtime will give up waiting and return \nan exception to the caller. The caller cannot tell whether the call executed or not. It just knows that it didn’t receive \na reply from the server. It’s possible that a server will reply later, after the RPC runtime returns an exception. At \nthis point, it’s too late to do anything useful with the reply message, so the RPC runtime simply discards it. \n Looking at the issue a bit more abstractly, the goal is to execute an idempotent operation  at least once  and \nto execute a non-idempotent  operation  at most once . Often, the goal is to execute the operation  exactly once . \nTransactions can help. A call executes exactly once if the server is declared non-idempotent  and the RPC exe-\ncutes within a transaction that ultimately commits. We will explore exactly-once behavior further in Chapter 4. \n System Management \n We ’ve discussed RPC assuming that both the client and server process are already up and running, but of course \nsomebody has to make all this happen to begin with. These are system management activities: to create cli-\nent and server processes and communications sessions to support RPC bindings. Sometimes these are dynamic \nfunctions that are part of the RPC system. In TP systems, they are usually static functions that are part of initial-\nizing the application, done in the transactional middleware. \n The system manager also has to track the behavior of the system. This requires software to monitor all the \nlow-level system components and make them visible with abstractions that are intelligible to the system man-\nager. For example, if someone calls the Help Desk saying,  “ I can’t run transactions from my PC, ” the system \nmanager has to check, among other things, whether the PC is communicating with the server, whether the server \nprocesses are running, whether the client and server are running compatible versions of the proxy and stub, and \nso on. Similarly, if there are performance problems, the system manager has to track the message load for each \nof the systems, determine whether the server has enough threads to run all the incoming calls, and so on. \n Interoperability of RPC \n In the example, suppose that the client and server applications use different programming languages with dif-\nferent data formats. In that case, the client proxy and the server stub need to translate the parameters between \nthe client’s and server’s format. There are two ways to do this: \n ■  Put the parameters into a standard, canonical format that every server knows how to interpret. \n ■  Ensure that the server’s stub can interpret the client’s format, known as  receiver-makes-it-right . \n Canonical forms include XML Schema, CDR (used in RMI/IIOP), and XDR (used in the Sun RPC). When \nusing a canonical format, the client proxy translates the parameters into the standard format, the server trans-\nlates them out of standard format, and likewise for the return parameters — the server stub puts them into stan-\ndard format and the client proxy puts them back into client format. \n2.4 Remote Procedure Call  55\n\n\n56  CHAPTER 2 Transaction Processing Abstractions\n This is ﬁ ne if the client and server are running different languages, but what if they’re running the same \nlanguage? For example, suppose they’re both using Java or C#. The client proxy is going through all the extra \nwork of taking the data out of Java format and putting it into standard format, and then the server is taking it out \nof standard format and putting it back into Java format. For this reason, the receiver-makes-it-right technique \noften is used. The client proxy marshals the parameters in the client’s format, not in a standard format, and \ntags them with the name of the format it’s using. When the receiver gets the parameters, if it sees that they’re in \nthe same format that the server is using, it just passes them unmodiﬁ ed to the server. However, if they’re not \nin the right format, it does the translation, either via a standard format or directly into the target format. This \nsaves the translation expense in many calls, but requires the server to support format translations for every \nformat it might see as input. \n Even when the client and server are running the same language in the same execution environment, some \nmachine-dependent translation may be required. This arises because there are two different ways of laying out \nbytes in words in computer memory, sometimes called little-endian and big-endian. The difference is whether \nthe bytes are laid out in increasing addresses starting with the least-signiﬁ cant byte (little-endian) or most-\nsigniﬁ cant byte (big-endian) within the word. In other words, is the low-order bit in the ﬁ rst or last position of \nthe word. (Intel and compatible processors use little-endian. Motorola, PowerPC, SPARC, and Java wire for-\nmat use big-endian. ARM and some PowerPC and SPARC processors are switchable.) When moving packets \nbetween systems, it may be necessary to translate between little-endian and big-endian format, even if both \nsystems are running the same implementation of the same language. Again this can be hidden by the proxies \nand stubs using one of the parameter translation mechanisms. \n Performance of RPC \n RPC is a heavily used mechanism when a TP system is distributed. Each transaction that’s split between two \nTP systems, such as between a client PC and a server back-end, needs at least one RPC to send the request and \nreturn the reply. It’s very important that this executes quickly. If it isn’t very fast, people will avoid using it, \nwhich completely defeats its purpose. \n There are basically three parts to the execution, which were illustrated in  Figure 2.12 . One is the proxy \nand stub programs that marshal and unmarshal parameters. The second is the RPC runtime and communica-\ntions software, which passes packets between the stub and the network hardware. And then there’s the network \ntransfer itself, which physically passes the messages through the communications hardware and over the wire \nto the other system. \n In most RPC systems, the time spent performing a call is evenly split among these three activities, all of \nwhich are somewhat slow. In a local area network, the overall performance is typically in the range of about \n10,000 to 15,000 machine-language instructions per remote procedure call, which is several hundred times \nslower than a local procedure call. So it’s very important to optimize this. There are lower-functionality research \nimplementations in the 1500 to 2000 instruction range. For web services that rely on text-based data formats, \nsuch as XML, performance is typically even slower. Techniques to make the system run faster include avoid-\ning extra acknowledgment messages, using the receiver-makes-it-right technique to make the proxies and stubs \nfaster, optimizing for the case where all the parameters ﬁ t in one packet to avoid extra control information and \nextra packets, optimizing the case where client and server processes are on the same machine to avoid the full \ncost of a context switch, and speeding up the network protocol. \n How to Compare RPC Systems \n RPC has become a standard feature of distributed computing systems, whether or not those systems run trans-\nactions. For example, Microsoft’s Windows operating systems and Linux support RPC as a built-in function. \n\n\n To get RPC integrated with transactions often requires using some transactional middleware. Many operating \nsystems have some of this integration built in. This appeared ﬁ rst in Tandem’s Guardian operating system and \nthen in Digital’s OpenVMS (both now part of HP). \n When shopping for a transactional middleware product, simply knowing that it supports RPC, or even RPC \nwith transactions, is not enough. You really have to go to the next layer of detail to understand the exact pro-\ngramming model and how difﬁ cult it is to write programs. Some of these interfaces are low-level and hard to \nprogram, whereas others are high-level and relatively easy to program. \n One thing to look for when evaluating RPC systems is which languages and data types are supported. For \nexample, some systems support only a generic proxy and stub procedure, which require application program-\nming to marshal parameters. Most proxies and stubs are unable to translate complex data structures such as an \narray. Or they may handle it as a parameter, but only for a certain language. Bulk data transfer is difﬁ cult using \nsome RPC systems, for example scrolling through a long table a portion at a time. \n Another issue is whether transactional RPC is supported. If so, what types of context are transparently \npropagated and what types are the application programmer’s responsibility? The types of context might include \nuser context, device context, security context, ﬁ le or database context, and of course transaction context. \n Popular RPC implementations include the Remote Method Invocation (RMI) in Java, the Internet Inter-ORB \nProtocol (IIOP) from CORBA , and the Microsoft RPC on Windows. RMI, IIOP, and Microsoft RPC closely \nfollow the concepts and implement the mechanisms described in the previous sections. \n 2.5  SHARED STATE \n There are many situations in which components of a TP system need to share state information about users, \nactivities, and the components themselves. Some examples of state information are the following: \n ■  Transaction — the transaction ID of the programs executing a transaction \n ■  Users — a user’s authenticated identity or the address of the user’s device \n ■  Activities — the identity or contents of the last message that one component sent to another, or temporary \ninformation shared between a client and the system, such as the contents of a shopping cart \n ■  Components — the identity of transaction managers that need to participate in committing a transaction, \nor the identity of processes that can handle a certain kind of request \n The rest of this section explores these kinds of state and mechanisms to share it. \n The kind of shared state we are interested in here is usually short-lived. That is, it is a state that can be dis-\ncarded after a few seconds, minutes, or hours, though in some cases it may be much longer than that. Often it \nis information that describes a current activity of limited duration, such as a transaction or a shopping session. \nIt is usually shared mostly for convenience or performance, to avoid having to send it repeatedly when compo-\nnents communicate. If this shared state is lost due to a failure, it can be reconstructed in the same way it was \ncreated in the ﬁ rst place — a nuisance and an expense, but not a catastrophe. \n Of course, a TP system also needs to manage long-lived, permanent state. Examples of such state are data-\nbases that contain information about accounts, loans, and customers in a bank; or information about products, \nwarehouses, and shipments in a retail business. In a sense, this information describes the state of the enterprise. \nThis is the information that transactions are keeping track of. Unlike the short-lived state, it must not be lost in \nthe event of a failure. This kind of long-lived state information is a very important part of TP systems, but it is \n not the kind of state that is the subject of this section. \n2.5 Shared State  57\n",
      "page_number": 68
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 76-84)",
      "start_page": 76,
      "end_page": 84,
      "detection_method": "topic_boundary",
      "content": "58  CHAPTER 2 Transaction Processing Abstractions\n Transaction Context \n Earlier in this chapter, we saw that each transaction has a transaction ID, and that each program that executes a \ntransaction has context information that includes its transaction ID. Thus, the transaction ID is state shared by \nthe programs executing a transaction. \n There are two design issues for any kind of shared state: how to establish the shared state and how to stop \nsharing and release the state. For transaction IDs, the ﬁ rst issue is addressed by native transactional RPC and \nWS-Transactions for SOAP. They propagate transaction context from caller to callee, to ensure that all pro-\ngrams executing the transaction have the same transaction context. \n The second issue is addressed in different ways, depending on whether the program is a resource manager \nthat needs to participate in two-phase commit. If so, then it retains the transaction context until after it pro-\ncesses the Commit operation in the second phase of two-phase commit. If not, and if it does not need to retain \ntransaction state across calls, then it can release its transaction state when it returns from the transactional RPC \nthat called it. If it does need to retain transaction state across calls, then it retains the transaction state until \nsome later time, determined either by two-phase commit or by the program itself. \n For example, in .NET, a program can release its transaction context by calling  SetComplete or  SetAbort \nbefore returning from a call. As we explained earlier, these operations tell the system that the transaction may \nor may not be committed (respectively) insofar as the caller is concerned. To retain the transaction context, the \nprogram calls  EnableCommit or  DisableCommit . These operations tell the system that the transaction may or \nmay not be committed (respectively) insofar as the caller is concerned, but unlike  SetComplete and  SetAbort , \nthey do not release the transaction context. These two situations — releasing or retaining transaction context — are \nspecial cases of stateless and stateful servers, which are discussed in more detail later in this section. \n In Java EE, context is managed using a context object that is created when the transaction is \nstarted. The Java APIs to release context are  javax.transaction.UserTransaction.commit and \n rollback — there’s no equivalent for  SetComplete but for  SetAbor t the Java extensions (Javax) API pro-\nvides  setRollbackOnly . \n Sessions \n A  communication session is a lasting connection between two system components, typically two processes, \nthat want to share state. The main reason to establish a session is to avoid having the components send the \nshared state information in each message. This saves not only the transmission cost, but also the sender’s cost \nof obtaining the state information when composing the message and the receiver’s cost of validating and sav-\ning the state information when receiving the message. The following are some examples of state information \nthat might be shared by a session: \n ■  The network address of both components, so they do not need to incur costly address lookups every time \nthey send a message to each other \n ■  Access control information, so each party knows that the other one is authorized to be sending it mes-\nsages, thereby avoiding some security checks on each message \n ■  A cryptographic key, so the components can encrypt information that they exchange in later messages \n ■  The identity of the last message each component sent and received, so they can resynchronize in case a \nmessage is not delivered correctly \n ■  The transaction ID of the transaction that both components are currently executing \n A session is created between two components by exchanging messages that contain the state to be shared. \nFor example, a component C 1 can send a message  REQUEST-SESSION(id, x) to component C 2 , which asks it to \n\n\n become a party to a new session that is identiﬁ ed by id and whose initial state is x. C 2 replies with a message \n ACCEPT-SESSION(id) , which tells C 1 that C 2 received the  REQUEST-SESSION message, agrees to be a party to the \nsession, and has retained the initial session state x. Usually, this is enough to establish the session. However, \nsometimes C 2 needs to be sure that C 1 received its  ACCEPT-SESSION message before it sends C 1 another message. \nIn that case it should require that C 1 acknowledge C 2 ’s  ACCEPT-SESSION message by sending a message  CONFIRM-\nSESSION(id) . In the latter case, the protocol to establish the session is called a  three-way handshake (see \n Figure 2.14 ). \n Sometimes a session is established as a side-effect of another message. For example, it might be a side-\neffect of the ﬁ rst RPC call from a client to a server, and it stays around until it times out. \n Each component that is involved in a session needs to allocate some memory that holds the shared state \nassociated with the session. This is usually a modest cost per session. However, the memory cost can be signif-\nicant if a component is communicating with a large number of other components, such as server with sessions \nto a million clients over the Internet. This is one good reason why HTTP is not a session-oriented protocol. \n Most sessions are transient. This means that if one of the components that is involved in a session fails, then \nthe session disappears. Continuing with our example, suppose component C 2 fails and loses the contents of its \nmain memory. Then it loses the state information that comprises the session. The other component C 1 involved \nin the session may still be operating normally, but it will eventually time out waiting for a message from C 2 , \nat which point it discards the session. If C 2 recovers quickly, before C 1 times out, then C 2 might reply to C 1 ’s \nattempt to re-establish contact. However, since C 2 lost the session due to its failure, it no longer has the shared \nstate of the session when it recovers. Therefore, it should reply to C 1 ’s message with a negative acknowledg-\nment, thereby telling C 1 to discard the session. If C 1 and C 2 want to re-establish their session after C 2 has recov-\nered, then they have to recreate the session from scratch. \n If C 2 had sessions with only a few other components at the time it failed, then re-establishing the sessions \ndoes not cost very much. However, if it had a large number of sessions at the time it failed, then re-establishing \nthem all at recovery time can be very time-consuming. During that time, C 2 is still unavailable. If one of the \ncomponents with which C 2 is re-establishing a session is slow to respond to the  REQUEST-SESSION or, even worse, \nis unavailable, then C 2 ’s availability may be seriously degraded waiting for that session to be established. \n A given pair of components may have more than one session between them. For example, they may have a \ntransport session for the network connection, a session for the application state, and a session for end user infor-\nmation. Although in principle these sessions could be bundled into a single session between the components, \nin practice they are usually maintained independently, because they have different characteristics. For example, \nthey may be established in different ways, use different recovery strategies, and have different lifetimes. \n To summarize, the beneﬁ t of using sessions is to avoid resending and reprocessing the same information \nover and over again in every message exchange between a pair of components. The costs are the time to estab-\nlish the session and to recover it after a failure, which in turn negatively affects availability. \n1.  REQUEST-SESSION(id, x) \n2.   ACCEPT-SESSION(id)\n3.  CONFIRM-SESSION(id)\nComponent\nC2\nComponent\nC1\n FIGURE 2.14 \n Three-Way Handshake to Create a Session. Component C 1  initiates the protocol by requesting to establish a session. C 2 \nagrees to be a party to the session. Finally, C 1 acknowledges receipt of that agreement. \n2.5 Shared State  59\n\n\n60  CHAPTER 2 Transaction Processing Abstractions\n One common use of sessions in TP is to connect an application component to a database system. The session \nstate typically includes a database name, an authenticated user ID, and the transaction ID of the current trans-\naction being executed by the application component. When the application component creates the session via \n REQUEST-SESSION , it includes the user ID and password as parameters. They are validated by the database system \nbefore it replies with  ACCEPT-SESSION . The database system executes all the operations it receives from the applica-\ntion component on behalf of the session’s user. Thus, operations only succeed if the session’s user has privileges \nfor them. All the operations execute within the session’s transaction. After the application commits the transac-\ntion, the session either automatically starts a new transaction (i.e., if it uses the chained transaction model) or it no \nlonger is operating in the context of a transaction (i.e., if it uses the unchained transaction model). \n Another common use of sessions in TP is to connect transaction managers that participate in the two-phase \ncommit protocol for a given transaction. The protocol for establishing sessions between these participants is a \nmajor part of a two-phase commit implementation and is discussed in Chapter 8. \n Stateless Servers \n Consider a session between a client process and a server process, where the client calls the server using RPC \nin the context of the session, so both the client and server can use the session’s shared state. There are three \nproblems that arise in this arrangement: \n 1.  The session ties the client to a particular server process. In a distributed system with multiple server pro-\ncesses that are running the same application, it is desirable for a given client to be able to send different \nrequests to different server processes; for example, to use the most lightly loaded one. However, if the \nclient is relying on the server to retain state information about their past interactions, then it does not have \nthe freedom to send different requests to different servers. All its requests have to go to the same server, \nnamely, the one that is keeping track of their shared state. \n 2.  If the server fails, then the session is lost. Since the client was depending on the server to remember the \nstate of the session, the server needs to rebuild that state after it recovers. The server can do this either \nby having the client resend that state or by recovering the state from persistent storage, which in turn \nrequires that the server saved the state in persistent storage before it failed. \n 3.  If the server is servicing requests from a large number of clients, then it costs a lot of memory for it to \nretain a shared state. Moreover, the problem of rebuilding sessions after a failure becomes more acute. \n For these three reasons, it is sometimes recommended that server processes be  stateless . That is, there is no \nsession between the client and server processes, and the server retains no application state after it services and \nreplies to a client’s request. Thus, it processes each request message from a clean state. Let us reconsider the \npreceding three problems for stateless server processes. First, if there are multiple server processes running the \nsame application, then successive calls from a client can go to any of the server processes since none of them \nretain any state from the client’s previous calls. Second, if a stateless server process fails, then it has no applica-\ntion state that it needs to recover. And third, a stateless server process does not incur the memory cost of retain-\ning shared state. \n The recommendation that servers be stateless applies mainly to communication between middle-tier serv-\ners and front-end processes associated with an end-user (i.e., clients), such as a browser or other presenta-\ntion manager on a desktop device. This is a case where these three problems are likely to appear: (1) a client \nmay want to send different requests to different servers, depending on server load; (2) re-establishing client-\nserver sessions may be problematic, because clients can shut down unexpectedly for long periods and because \n\n\n a server would need a large number of these sessions since there is typically a large number of clients; and \n(3) the server would need to dedicate a lot of memory to retain shared state. \n By contrast, this recommendation usually does not apply to communication between a middle-tier server \nand a back-end server, which are often database systems. As mentioned earlier, there usually  are sessions \nbetween a middle-tier server and each back-end database system it invokes. Therefore, the back-end server \nis stateful with respect to the middle-tier servers that call it. Thus, the preceding three problems need to be \naddressed. We will discuss solutions in the next section. \n It may sound a little strange to hear about stateless middle-tier server processes, because of course a TP \napplication needs to store a lot of application state in databases. The point is that this database state is the only \nstate that the stateless server process depends on. The server process itself does not retain state. Thus, if the \nserver fails and subsequently recovers, it doesn’t need to rebuild its internal state, because all the state that it \nneeds is ready and waiting in the databases it can access. \n A well-known example of a stateless middle-tier process is the use of a web server for HTTP requests \nfor static web pages. All the state needed by the web server is stored in ﬁ les. After servicing a request, a web \nserver does not need to retain any state about the request or response. Since such web servers are stateless, if \nthere are multiple web server processes, then each request can be serviced by a different web server. And if a \nweb server fails and is then restarted, it has no state that needs to be recovered. \n Stateful Applications \n Having just explored reasons why stateless applications are beneﬁ cial, let us now examine cases where a middle-\ntier application needs to retain state information across multiple front-end requests. Here are four examples: \n 1.  A user request requires the execution of several transactions, and the output of one transaction may \nneed to be retained as input to the next. \n 2.  A middle-tier server wants to retain information about a user’s past interactions, which it will use for \ncustomizing the information it displays on later interactions. \n 3.  A front end establishes a secure connection with a server using authentication information, which \nrequires it to cache a token. \n 4.  A user wants to accumulate a shopping cart full of merchandise before actually making the purchase. \n In each of these scenarios, the state that is retained across client requests has to be stored somewhere. There \nare several places to put it, such as the following: \n ■  Save it in persistent storage, such as a database system. The operation that stores the state should be part \nof the transaction that produces the state, so that the state is retained if and only if the transaction that \nproduces it commits. \n ■  Save it in shared persistent storage, but not within a transaction. \n ■  Store it in volatile memory or in a database that is local to one server process. This makes the server \nstateful. Whether or not there is a communication session, future requests from the same client need to \nbe processed by the server that has the shared state. \n ■  Return it to the caller that requested the transaction execution. It is then the caller’s responsibility to save \nthe state and pass it back to the server on its next invocation of that server. \n Wherever the state is stored, it must be labeled with the identity of the client and/or server, so that both client \nand server can ﬁ nd the state when they need it. \n2.5 Shared State  61\n\n\n62  CHAPTER 2 Transaction Processing Abstractions\n Let us explore these ways of managing state and client-server identities in examples (1) to (4) in the  pre-\nvious list. The ﬁ rst scenario is a business process, that is, a user request that requires the execution of mul-\ntiple transactions. A variety of state information is accumulated during a business process execution. This state \nincludes a list of the business process steps whose transactions have committed and those that have yet to be \nexecuted. It may also include results that were returned by the transactions that committed, since these results \nmay be needed to construct input to other transactions in the business process (see  Figure 2.15 ). For example, \nif a travel reservation executes as a business process, then the arrival time of the ﬂ ight that is returned by the \nﬂ ight reservation transaction may be needed to construct the input to a car rental reservation transaction, since \nthat input requires a pick-up time. This information also needs to be saved so it can be returned to the client \nwhen the business process has ﬁ nished executing. \n Like any transaction, each transaction that executes as part of a business process should execute at most \nonce. Therefore, the business process state must be maintained in persistent storage. If it were stored in volatile \nmemory instead of persistent storage, and the contents of that memory were lost due to a failure, then it could \nnot be reconstructed by executing the business process ’ transactions again (because transactions should execute \nat most once). For the same reason, the state must be updated by each transaction that executes as part of the \nbusiness process. Suppose the application is written so that the result of the transaction is stored in the business \nprocess state after the transaction committed. If a failure occurs between the time the transaction commits and \nthe time its results are supposed to be written to the business process state, then those results would be lost. \n In scenario (2) the server keeps track of a user’s interactions over a long period of time. For example, it \nmay remember all the user’s past orders and past window-shopping. It may use this information to suggest \nnew products that are likely to be of interest based on that past behavior. In this case, the shared state needs to \nbe identiﬁ ed by a long-lived name. The user’s e-mail address commonly is used for this purpose. But in some \ncases it might not be good enough, since the user may access the server both from home and the ofﬁ ce, and \nmay switch e-mail providers from time to time. The user’s full name and address might be better, although this \ntoo has problems due to variations in spelling and typos. Thus, depending on the requirements, selecting and \nusing long-lived names can be a nontrivial design problem. \n In scenario (3) a client browser establishes a secure connection with a server by exchanging authentication \ninformation. The connection establishes trust between the client and server so that the authentication informa-\ntion does not have to be passed on each subsequent call. The server caches the authentication token and identi-\nﬁ es it with the connection to the browser. This is handy because then the user does not have to log in again and \ncan submit multiple requests during the same session to the same resource. Since the connection is established \nas secure, the user’s credentials do not have to be presented on each request. \n Scenario (4) concerns creating and maintaining a shopping cart. Each item that a user selects to buy is put \ninto the user’s shopping cart. Since a user may be shopping for awhile, the shopping cart may be stored in a \nT1\nPersistent\nResource \nSave output\nT2\nT3\nT4\n FIGURE 2.15 \n Retaining State in a Business Process. Each transaction in a business process saves the process state for use by the \nnext transaction in the sequence. \n\n\n database or other persistent storage, to avoid the expense of using main memory for information that is infre-\nquently accessed. This need not be written in the context of a transaction. However, the shopping cart is not \nthe permanent state. The server system retains the shopping cart until either the user checks out and purchases \nthe items in the cart, or until a time-out has occurred after which the server disposes of the shopping cart. The \nshopping cart is the shared state between the user and the system. So is the user ID that the system needs to \nknow in order to ﬁ nd the user’s shopping cart while processing each of the user’s operations. \n What user ID should be associated with the shopping cart? If the server is stateful, the session ID can be \nused to identify the user and hence the shopping cart. If the session goes away before the customer purchases \nthe contents of the shopping cart, then the shopping cart can be deleted. If the server is stateless, and the user \nhas not identiﬁ ed herself to the server, then the system must generate a user ID. Since the server is stateless, \nthat user ID must accompany every call by that user to the server. One way to do this is to ensure that all calls \nfrom the client to the server, and all return messages, include the server-generated user ID. Since this is rather \ninconvenient, a different mechanism has been adopted for web browsers, called cookies. \n A  cookie is a small amount of information sent by a server to a web browser that the web browser then \nstores persistently and returns to the same server on subsequent calls. For example, when an anonymous user \nplaces his or her ﬁ rst item in a shopping cart, the server that performs the action could generate a user ID for \nthat user and return it in a cookie. The user’s subsequent requests to that server would contain the cookie and \ntherefore would tell the server which shopping cart is relevant to those subsequent requests. Thus, the cookie is \nthe shared state between the web browser and the server. \n A cookie has a name, domain, and path, which together identify the cookie. It also has a value, which is \nthe content of the cookie, such as a server-generated user ID for the shopping cart. For privacy reasons, the \nbrowser should send the cookie with HTTP requests only to the cookie’s domain (e.g., books.elsevier.com). \nSince cookies are easily sniffed, they are also usually encrypted. Each cookie also has an expiration date, after \nwhich the browser should dispose of the cookie. \n Cookies are sometimes not available, for example, because a user disabled them in the browser. In this \ncase, the server can use a different technique, called  URL rewriting . Before the server sends an HTML page \nback to the browser, it rewrites all the URLs on the page to include the user’s session ID. For example, it could \nappend  “ ;jsessionid \u0005 1234 ” to every URL on the page. That way, any action that the user takes on that page \ncauses the session ID to be sent back to the server. \n URL rewriting is less secure than an encrypted cookie, since it can be seen by others. Moreover, an unsus-\npecting user might copy the rewritten URL into an e-mail to send to a friend, who might thereby have access \nto the sender’s private session information. \n In summary, maintaining the state across multiple requests requires a fair bit of design effort to choose \nwhere and how the state is identiﬁ ed and maintained. For this reason, it is worthwhile to design an application \nto limit the use of shared state whenever possible. \n 2.6  SCALABILITY \n Scaling up a TP system to handle high load involves two activities. First, one can tune and grow each indi-\nvidual server system to handle the maximum possible load. And second, one can distribute the load across \nmultiple interconnected server systems. The decision of which approach to take depends on cost-performance \nas well as other goals, such as availability, security, and manageability. In this section we focus on the mecha-\nnisms that enable scaling up system performance. \n2.6 Scalability  63\n\n\n64  CHAPTER 2 Transaction Processing Abstractions\n Scaling up a Server \n The throughput of a server system is ultimately dependent on its hardware conﬁ guration; that is, on the speed \nof its processors, on the size and speed of main memory and secondary storage, and on the bandwidth and \nlatency of its interconnects. Software too plays a major role. For a given hardware conﬁ guration, there are \ntwo techniques that are commonly used to get the most beneﬁ t from that conﬁ guration: caching and resource \npooling. \n Caching \n A cache is an area of memory containing data whose permanent home is elsewhere, such as in secondary stor-\nage or on a remote server system. Ideally, the cache contains data that frequently is accessed by programs run-\nning on the system containing the cache and that is much cheaper to access than its permanent home. Thus, the \nexpense of retrieving the data from its permanent home is amortized across a large number of accesses. This \ngreatly improves performance over a system in which every access to the data requires accessing the data’s \npermanent home. \n Since many components of a TP system need to access data that is not local to the component, caches are \nheavily used in TP. A web browser may cache pages of frequently accessed web sites, to avoid having to go \nto the web site every time those pages are requested. A web server may cache information that is needed to \nservice popular requests, such as the information displayed in response to a client’s initial request to access \nthe web site. A proxy server, which sits between the network and the web server, also offers this caching func-\ntionality. Some large data items, such as images, may be cached at a third-party’s web site that is closer to the \nend user and can therefore offer higher speed access to the information. A server running a TP application may \ncache popular data whose permanent home is a remote database system. And the database system itself may \ncache data whose permanent home is secondary storage. \n The ofﬁ cial copy of a data item in its permanent home may be updated shortly after that copy was read and put \ninto a cache. Therefore, once data has been put into a cache (somewhere other than its permanent home), it poten-\ntially is no longer up to date. Thus, a cache is most appropriate for data that is infrequently updated. For example, \nin a TP system, it is probably useful to cache catalog information, since its content changes slowly. But it may not \nbe useful to cache the latest bid in an auction that will close shortly, since it may be updated very frequently. \n The implementation of a cache requires a fast way to look up entries. This usually is done using a hash \nalgorithm that maps the identiﬁ er of a data item to its memory location in the cache. It also requires a  replace-\nment algorithm , which selects an item to remove from the cache to make room for a new item that has to be \ninserted. A commonly used replacement algorithm is  least-recently-used , which replaces the item whose last \naccess was longest in the past among all items in the cache. There is a large repertoire of cache replacement \nalgorithms used in practice. However, coverage of these algorithms is beyond the scope of this book. \n Sometimes , items in the cache are  invalidated before they need to be replaced. Invalidation is done if it \nis known that the item is unlikely to be fresh enough to be used. When a server stores an item in its cache, \nit may include an invalidation time that the cache manager enforces. For example, a web server may add an \ninvalidation time 10 minutes in the future when it caches a copy of a headline news banner, thereby ensuring it \nrefreshes the headline from the news server at least that often. \n Alternatively , the server that is the data’s permanent home may keep track of which caches have a copy \nof that data. After the server processes an update for that data, it can issue an  invalidation message to every \ncache that has a copy, which tells the cache to invalidate its copy of that data. This helps to ensure that the \ncaches are  coherent ; that is, that a data item has the same value in all caches that currently hold the data item. \nClearly, there are limits to cache coherence due to variance in the time it takes for each cache to receive an \ninvalidation message and process it. \n\n\n A cache may be updatable. Each update to a data item in the cache must be propagated back to the data item’s \npermanent home. Sometimes, this must be done explicitly by the client of the cache. That is, it stores the updated \ndata item in both the cache and the data item’s permanent home. If the cache manager knows how to map each \ncached data item to its permanent home, then the client may only need to update the cache and the cache man-\nager propagates the update to the data item’s permanent home. If the cache manager propagates the update imme-\ndiately as part of the operation to update the cache, then the cache is called  write-through . If it propagates the \nupdate lazily, potentially long after the cache was updated, then the cache is called  write-back . \n Clearly , cache coherence is affected by the way that updates to the cache are propagated. For example, if \nthe data item’s server uses invalidation messages to notify caches when the item has changed, then a write-\nthrough cache will yield better cache coherence than a write-back cache. But this better coherence has a cost. \nUsually, the cost of the write-back cache is lower, since multiple updates to the same cached data item within \na short time period incur only one write-back, and a write-back can batch multiple updates in a single message \nto the data’s permanent home. \n Since caching mechanisms are complex and important, they are built into many types of products, notably \ntransactional middleware and database systems. There are main memory database systems that are intended \nto be used for cached data. Some operate as a conventional transactional resource manager, such as Oracle’s \nTimesTen, McObject’s eXtremeDB, and Raima’s RDM. Others are designed speciﬁ cally for caching, for exam-\nple, by offering the application explicit control of when to invalidate cached data or write-back updated cached \ndata to its home location. Examples include Danga Interative’s memcached, Oracle’s Coherence and Microsoft’s \nproject codenamed  “ Velocity. ” \n Resource Pooling \n Another case where caching can improve performance is when a resource is costly to create and relatively inex-\npensive to access. Sessions are one such resource. Consider an application that requires the use of a database \nsystem. The server process that runs this application needs a session with a database system for each transac-\ntion currently running. However, each transaction typically needs the session only for a fraction of a second. \nTherefore, the server process can maintain a pool (i.e., cache) of sessions. Each transaction is given exclusive \nuse of one of the sessions while it is running. After it commits or aborts, the session is returned to the pool. \nThus, sessions are  serially reused by different transactions. \n Process threads are another example of resources that can be pooled and serially reused. The process has a \nﬁ xed number of threads. When it receives an RPC, the RPC is assigned to a thread in which to execute. After \nthe RPC ﬁ nishes executing and returns to its caller, the thread is returned to the thread pool. \n A third example is server classes, which avoid the overhead of frequent process creation. Like threads, each \nprocess receives a call. After the call completes, the process is available for reuse by another call. \n Scaling Out a System \n One way to scale up a system is to add more machines. This is called  scale-out . There are two approaches \nto scale-out, partitioning and replication, which offer different ways of distributing the workload across the \nmachines. \n Partitioning \n One way to distribute the workload is to  partition the application and its data into different types of work and \nassign each type to a different machine. For example, in a bank, one might assign the credit card application \nto one system, the loan application to a second system, and the checking account application to a third system. \n2.6 Scalability  65\n\n\n66  CHAPTER 2 Transaction Processing Abstractions\n When a request arrives, it is directed to the system that supports the relevant application. This can be done by \nstoring the mapping between applications and servers in a registry service and looking up the mapping for \neach request, as was described in Section 2.4. \n Partitioning by application type is an effective technique. However, it is an incomplete solution if an appli-\ncation needs to scale up beyond the capabilities of a single machine. Then the application itself needs to be \npartitioned. A common way to do this is  range partitioning , where different copies of the server handle dif-\nferent ranges of an input parameter. For example, a debit-credit application dealing with retail banking might \nbe split into ﬁ ve servers, each of which handles a range of account numbers (see  Figure 2.16 ). The database \nthat supports each of these servers can be local to the system that supports those account numbers. So the \nﬁ rst group of account numbers is stored on the same computer as the application program that supports those \naccount numbers, and so on. \n When the system is organized in this way, a routing function needs to forward each request to the correct \nserver based not only on the identiﬁ er of the request type, but also on one or more of the input parameters. In \nthe example, it would be the account number. This is called  parameter-based routing . \n Range partitioning can be implemented directly by the application, by having the application support the \nrouting function. Many systems provide built-in support. For example, range partitioning and parameter-based \nrouting are supported by many high-function database systems and some transaction middleware products. \n Partitioning schemes all suffer from the problem of load balancing, especially when servers are partitioned \nstatically. Usually, the workload varies over time. For example, in the system shown in  Figure 2.16 there may \nbe a burst of activity for accounts in the 20,000 to 39,999 range, thereby overloading the second server. This \nproblem may arise frequently if the load is correlated with value ranges. For example, if account numbers are \ncorrelated with geographical regions, then a peak period in one time zone will cause its partition’s servers to be \nmore heavily loaded than those of other partitions. An overloaded partition will perform poorly. It doesn’t help \nthat other servers may be less heavily loaded, because they don’t have the data required to service requests in \nthe 20,000 to 39,999 range. \nRouter\nApplication\nAccounts\nin the range\n0–19,999\nAccounts\nin the range\n20,000–39,999\nAccounts\nin the range\n40,000–59,999\nAccounts\nin the range\n60,000–79,999\nAccounts\nin the range\n80,000–99,999\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\n FIGURE 2.16 \n Parameter-based Routing. The router application forwards each request to the appropriate server based on the account \nnumber parameter in the request. \n",
      "page_number": 76
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 85-95)",
      "start_page": 85,
      "end_page": 95,
      "detection_method": "topic_boundary",
      "content": " One way to reduce the frequency of such overload situations is to use  hash partitioning , where a hash \nfunction is used to map each parameter value to a server partition. A well-designed hash function will, with \nvery high probability, spread the load evenly across servers. It therefore is less likely to exhibit load-balancing \nproblems than range partitioning. Hash partitioning commonly is used not only for partitioning a database but \nalso for partitioning a large-scale cache that is spread across many servers. \n One solution to load balancing is  automatic reconﬁ guration . That is, when a partition becomes over-\nloaded, it automatically is split into two partitions and the routing function is updated accordingly. The deci-\nsion to split a partition should be based on workload trends, not a short-term spike in load. If a partition is split \nbased on a temporary load spike, the split partitions will be underutilized after the spike dissipates. \n Another solution to load balancing is to use  table-lookup partitioning , where a mapping table explicitly \nmaps each input parameter value to a particular server. There is a signiﬁ cant cost to maintaining all this mapping \ninformation when a lot of parameter values are present, though this can be mitigated with the use of some net-\nwork switches, such as Layer 7 switches. This partitioning approach offers some signiﬁ cant beneﬁ ts over range \nand hash partitioning. One beneﬁ t is ﬁ ne-grained control over reconﬁ guration. When a server overﬂ ows, a new \nserver can be allocated and newly added parameter values can be assigned to the new server. Another beneﬁ t \nis that different parameter values can be explicitly assigned levels of service. For example, a bank may offer \ntwo levels of service to checking accounts, depending on their minimum monthly balance. This account-type \ninformation can be stored in the mapping table and the account stored at a server that supports the appropriate \nlevel of service. A third beneﬁ t is that users can be upgraded to a new release of an application one by one. By \ncontrast, with range or hash partitioning, the application would not know whether to access a user’s data in the \npartition using the old or new format. Thus, all the parameter values (e.g., accounts) in a partition would be inac-\ncessible while the upgrade was in progress. \n Whatever partitioning scheme is used, conﬁ guring a system with the right amount of server capacity is \nimportant. Servers need to be conﬁ gured for peak load, not average load, to ensure that they can offer good \nresponse time even in periods of high load. The more extra capacity (or  headroom ) that each system offers \nrelative to its expected peak load, the less likely it will become overloaded. \n Partitioning Sessions \n Partitioning also helps scale-out when communication sessions are required. In a two-tier architecture, if there \nare many clients and each client requires a session with every server, the result is a polynomial explosion in the \nnumber of sessions. For example, if there are 100,000 clients and each one has to connect to all 500 servers, \nthen each server would have 100,000 sessions, resulting in 50,000,000 sessions overall (see  Figure 2.17 ). Each \nsession consumes some main memory and requires some setup time. When there are too many sessions, this \nsession overhead can be troublesome. It can limit the ability of the server system to scale out by adding more \nservers. \n The total number of sessions can be greatly reduced by inserting a routing layer between the clients and \nservers that partitions the set of clients. Each router process connects to a subset of the clients and to all the \nservers. Thus, each client can still send messages to all servers, at the cost of an extra message hop through a \nrouter. See  Figure 2.18 . \n Now say you have 10 routers between the clients and servers, and each client is connected to one router. \nEach of the 10 routers would have 10,000 sessions to their clients and 500 sessions to all the servers, result-\ning in 10,500 sessions per router, or 105,000 sessions overall — a huge reduction from the 50,000,000 sessions \nrequired without the routing layer. \n Grouping clients by routers can be based on geographical considerations. For example, all the clients on \na given local area network might be serviced by the same router. More complex groupings may be needed \n2.6 Scalability  67\n\n\n68  CHAPTER 2 Transaction Processing Abstractions\n for fault tolerance reasons. For example, the ATMs at a bank branch may be split across two routers over two \nseparate communication lines, so the failure of one router still leaves half of the ATMs operating. \n Replication \n Another way to distribute workload is to replicate server processes and assign the replicas to different systems. \nThe replicas are identical, in the sense that they can all process the same kinds of requests. This works espe-\ncially well if the processes are stateless. In that case, each request can be assigned to any of the replicas, even \nif a previous request from the same client was processed by a different replica. \n As in the partitioning approach, it is desirable to balance the load across the replicated servers. This can be \ndone by having each request randomly choose a server to process the request, sometimes called  spraying the \nrequests across the servers. It can be done by the client that issues the request, or it can be done in a server sys-\ntem. For example, a network router that connects a server system to the Internet might have built-in load bal-\nancing functionality to forward messages based on round robin, least number of active connections, or fastest\nresponse time. \n Even if each client sends the same number of requests to each server, the load may not be distributed evenly, \nbecause one server may receive requests that require more time to service than those received by another server. \nTo avoid this unbalanced load, each client can put requests into a queue that is shared by all servers, and each \nClient\nClient\nClient\nServer\nServer\nServer\n FIGURE 2.17 \n Polynomial Explosion in Two-Tier Model. If there are f front-end programs and t transaction servers, then there are f  \u0004  t \nsessions. \nClient\nClient\nClient\nClient\nRouter\nRouter\nServer\nServer\nServer\n FIGURE 2.18 \n Multilevel Routing. By introducing routers in between clients and servers, the overall number of sessions is greatly \nreduced, compared to the two-tier model of  Figure 2.17 . \n\n\n server dequeues a request whenever it is idle. Thus, each server obtains new work if and only if it has additional \ncapacity to process it. The main disadvantage of this approach is the overhead of managing the queue. It needs \nto be accessible to all the servers, and clients and servers need to synchronize their accesses to the shared queue. \nWe will have a lot more to say about queuing mechanisms in Chapter 4. \n Replication interacts with caching. Suppose a server is replicated and a client process  C issues a request  r \nthat accesses one of those server replicas,  S . To process  r ,  S may access remote data, which  S saves in a cache. \nFor example,  C may be a web browser running on a desktop machine and  S may be a web server at a site that \nhas a large number of web servers running. The request may access a web page, which is cached by  S . A given \nclient often issues many similar requests. If  C issues a request  r \u0003 that is similar to  r and hence accesses the \nsame data as  r , then it would be cheaper to process  r \u0003 at  S rather than at a different server replica that has not \ncached the data required by  r \u0003 . In this case, we say that  C has  cache afﬁ nity for  S . Although  C can still access \nany of the server replicas, it performs better when accessing  S than any of the other server replicas. \n A more extreme example of afﬁ nity occurs when a server replica  S is maintaining shared state with respect \nto a client  C . In this case, it is essential that all requests from  C be serviced by  S , so the request has access to \nthe shared state. Notice that this problem does not arise if  C maintains the shared state. That is, if  C includes \nthe shared state with every request, then any server replica can process a request, because the server replicas \nare stateless with respect to  C . \n When replicas contain updatable data, updates must be propagated to all replicas to keep them identical. \nA common conﬁ guration is to require that all updates be applied to a primary replica, which forwards those \nupdates to the other read-only replicas. This offers simpler synchronization than immediately broadcasting \nupdates to all replicas, but introduces delay by passing all updates through the primary replica. Synchronization \nalgorithms for replicated data are covered in Chapter 9. \n Replication is a common feature of database systems. It can also be used to implement cache coherence. If \na replicated cache is updatable, then a replication mechanism can be used to propagate updates from one cache \nto all the others. \n Replication also is used to improve availability. If one replica is unavailable, then its workload can be han-\ndled by other replicas. Techniques for using replicas in this way are also covered in Chapter 9. \n 2.7  SUMMARY \n This chapter covered major software abstractions needed to make it easy to build reliable TP applications with good \nperformance: transaction bracketing, threads, remote procedure calls, state management, and scalability techniques. \n Transaction Bracketing \n Transaction bracketing offers the programmer commands to start, commit, and abort a transaction. The opera-\ntions on data that execute after the Start command and before the Commit or Abort are part of the transaction. \nIn the chained model, a new transaction begins immediately after a Commit or Abort, so all operations are part \nof some transaction. \n The transaction composability problem arises when a program running a transaction calls another program. \nThere is a choice of bracketing semantics, depending on whether the callee should or should not execute within \nthe caller’s transaction. If so, the caller’s transaction ID must be passed to the callee. \n In the nested transaction model, the callee executes in a subtransaction. A subtransaction abort undoes its \nactions, but leaves its parent transaction intact. It is up to the top-level transaction to decide whether to commit \n2.7 Summary  69\n\n\n70  CHAPTER 2 Transaction Processing Abstractions\n all its committed subtransactions ’ work, thereby making its results durable. Savepoints are a related technol-\nogy that enable single-threaded transactions to back up to a previous state, much like subtransaction abort. \n Another approach to transaction bracketing is to tag each component with an attribute that indicates \nwhether an invocation of the component should run in a new transaction, in the caller’s transaction, or in no \ntransaction. This approach commonly is used in object-oriented transactional middleware products, instead of \nexplicit commands to start, commit, and abort. \n A transaction program needs to provide compensation steps and exception handling code for transaction \nfailures and system failures. The programming model needs a way to expose the reason for the exception, the \nstate that is available if the exception handler executes after an abort or recovery from a system failure, and \nwhether the handler itself executes within a transaction. \n Processes and Threads \n Each program executing in a processor has an address space and control thread, called its processor state. In a \nmultiprogrammed computer system, each program’s processor state can be temporarily stored in main memory \nor on disk and reloaded when the program resumes execution. A TP system architecture must take into account \nwhether its related programs are running in the same or different address spaces, since this can affect perfor-\nmance and management. \n The behavior of a TP system is affected by whether the components of the system share an address space \nand control thread. Although it is possible to deploy all components of the TP system in a single-threaded \nprocess, it leads to a system with a large number of processes, typically at least one per executing transac-\ntion. Better performance and scalability usually is obtained with multithreaded processes, due to reduced main \nmemory requirements, fewer context switching operations, and ﬁ ner grained tuning opportunities. If middle-\nware implements the multithreading, then it must intercept synchronous I/O to avoid blocking the entire pro-\ncess during such operations. The more popular approach is to use threads supported by the operating system. \n When multithreading is unavailable, an alternative is server classes, where multiple copies of a TP compo-\nnent are replicated in multiple single-threaded servers. Executing the same code in a pool of single threaded \nprocesses can produce similar beneﬁ ts to executing the same code in multiple threads of the same process. \n Remote Procedure Calls \n A remote procedure call (RPC) mechanism provides a programming model and runtime environment that \nallows a program to invoke a program in another address space as if it were a local call within the same address \nspace. With an RPC, the programmer either receives a return from the call or an error indicating that the pro-\ngram didn’t run, just as if the call were performed locally. \n An RPC mechanism uses an interface deﬁ nition language to produce a proxy linked to the local program \nand a stub linked to the program in the remote address space. Proxies and stubs abstract distributed comput-\ning details such as data marshaling and the communications protocol from the programs involved in the call. \nIn an object-oriented RPC, the proxy may use a local object as a surrogate for the remote object being called. \nA transactional RPC uses the proxies and stubs to propagate the transaction context, including the transaction ID,\nfrom the caller to the callee. \n Before performing an RPC, a client needs to create a binding to the server, for example, by looking up the \nserver’s network address in a registry service. To perform an RPC securely, the client and server need to be \nauthenticated and the server needs to check that the client is authorized to do the call. The runtime needs to \nmonitor each call to ensure it succeeds. If the client runtime does not receive an acknowledgment, then it can \neither repeat the call or ping the server, depending on whether the server is idempotent. The runtime might also \ntranslate parameters between different machine formats to enable interoperability. \n\n\n All this functionality has a price. RPCs are much slower than local procedure calls and simple message \npassing. But since RPC functionality usually is needed, the only alternative is to move the burden to the appli-\ncation programmer, which makes application programming more time-consuming. Hence, transactional RPC \nis a popular feature of transactional middleware and underlying platforms. \n Shared State \n To process transaction requests correctly, components of a TP system need to share state information about \nusers, security tokens, transaction IDs, and the locations and characteristics of other system components. When \nall the components are deployed within a single address space, they can easily share this state. When the com-\nponents are distributed across multiple address spaces, this sharing becomes more challenging. \n This problem can be circumvented by using stateless servers, which do not share state with the client that \ncalls them. Instead of sharing state, each client request includes all state information that the server needs for \nprocessing the request. For example, a browser can retain a cookie, which is the server state that is stored at the \nclient and passed by the client to the server in each request. \n One important type of shared state is a transaction ID, which identiﬁ es a transaction context and is shared \nacross programs that participate in the same transactional unit of work. A transaction context typically is asso-\nciated with a thread of execution and can be propagated from one program to another, for example when using \nan RPC. \n A communication session is a way of sharing state between processes on different machines. Typical session \nstate includes transaction context and security information. By creating a shared session, two processes avoid \nhaving to pass state information on every interaction. However, sessions require messages to set up and memory \nto store their state. Thus, they are primarily useful when information is shared for a relatively long period. \n Scalability Techniques \n Several abstractions are needed to help a TP system scale up and scale out to handle large loads efﬁ ciently, \nincluding caching, resource pooling, and data partitioning and replication. Using these abstractions improves \nthe ability of a TP system to share access to data. \n Caching is a technique that stores a copy of persistent data in shared memory for faster access. The major \nbeneﬁ t of caching is faster access to data. If the true value of the data in its permanent home needs to be \nupdated, then synchronization is required to keep the cache values acceptably up to date. \n Resource pooling is a mechanism that reuses a resource for many client programs, rather than creating \na new resource for each program that needs the resource. For example database connections can be pooled. \nA database connection is allocated to a program when it needs to use the database and returned to the pool when a\nprogram’s task is completed. \n Partitioning is a technique for improving scalability by segmenting resources into related groups that can \nbe assigned to different processors. When a resource type is partitioned, the TP system routes requests for the \nresource to the partition that contains it. For example, if a database is partitioned, an access to a data item is \nrouted to the database partition that contains the data item. \n Replication is a technique for improving scalability by spreading the workload across multiple identical \nservers. Clients can either push their work onto particular servers or enqueue the work and have the servers \npull from the queues. A client may have afﬁ nity for a server that has cached data that it frequently accesses, in \nwhich case it prefers sending its workload to that server. Replication can also be used to improve availability \nby using backup replicas to handle the load of a failed replica. One major challenge of replication is to keep \nupdatable replicas mutually consistent at an affordable cost. \n2.7 Summary  71\n\n\n \nThis page intentionally left blank\n\n\n 3.1  INTRODUCTION \n From the end user’s point of view, a transaction processing (TP) application is a serial processor of requests. \nIt is a server that appears to execute an inﬁ nite loop whose body is an ACID transaction, such as the following \npseudo-program: \n Do Forever \n    /* the body of this loop is a transaction */ \n    receive a request \n    do the requested work \n    send a reply (optional) \n End \n However , as we saw in Chapter 1, the behind-the-scenes reality is more complex. Usually, the user is execut-\ning on a front-end machine that is remote from the server machine that executes the transactions. Often the \nserver is itself a distributed system, primarily so that it can scale up to handle a large number of requests. \n To process a request, the actual control ﬂ ow within a TP application is more like this: \n ■  The front-end program captures the user’s request using a combination of forms and menu selections, \ntypically executing in a web browser or more specialized input device, such as an ATM or gas pump. \n ■  The front-end program translates the input into a request message and sends it to a server. \n ■  A middle-tier or back-end server examines the request message to determine what type of transaction is \nbeing requested and which application program  P should process the request. \n ■  The server starts a transaction and invokes  P . Typically  P invokes a database system to do some of its work. \n ■  If the transaction terminates successfully, the server commits the transaction. Otherwise, it aborts the \ntransaction. \n ■  The server sends some output back to the source of the request, such as a web browser or other input \ndevice, to ﬁ nish processing the user’s request. \n TP applications that have the preceding structure require a diverse set of runtime functions. They include \nthe functions described in Chapter 2, plus many others such as presentation services, message routing, secu-\nrity, and system management. These functions are typically not all packaged together in one product. Some are \nin the operating system. Others are in the database system. Some are in independent middleware components. \n Transaction Processing Application \nArchitecture \n 3 \nCHAPTER\n\n\n74  CHAPTER 3 Transaction Processing Application Architecture\n This is a fairly complicated picture: many different services, supported by a variety of products, distributed \nacross different systems in a network. It can be a challenging environment in which to develop an applica-\ntion and to manage it while it is running. This chapter will try to simplify the challenge by explaining how the \npieces of the environment are meant to be used together to build and operate a TP application. \n 3.2  APPLICATION ARCHITECTURE \n There are three interrelated ways to decompose a TP system: by functional components, by hardware subsys-\ntems, and by operating system processes. The decomposition by functional components is shown in  Figure 3.1 . \nIt consists of front-end programs, request controllers, transaction servers, and database systems. In the past, this \nwas called a  three-tier architecture , consisting of the front-end program as the ﬁ rst tier, the database system \nas the third tier, and everything in between as the middle tier. As systems have become more layered, it is no \nlonger clear how many tiers are present. We therefore call it a  multitier architecture . \n The display device, shown in the upper left, interacts with a component that we call the  front-end program , \nwhich is responsible for gathering input and displaying output. It captures input from forms, menu selections, \nand the like; validates the input; and translates it into a request message. \n The front-end program communicates with the device in a device-speciﬁ c format. The types of display \ndevices change frequently based in large part on the cost of hardware to implement them. Today, a web browser \nrunning on a PC is a common device. In this case, the front-end program is a web browser connected to a web \nserver that uses the HTTP protocol and some variant of hypertext markup language (HTML) plus some scripting. \nFront-end Program\nRequest Controller\nQueues\nTransaction\nServer\nTransaction\nServer\nTransaction\nServer\nNetwork\nRequests flow on\nthese connections\nMessage\ninputs\nDatabase System\nDatabase\nDatabase System\nDatabase\nShared by two\ntransaction\nServers\nPrivate to one\ntransaction\nServer \n FIGURE 3.1 \n Multitier TP Application Architecture. The front-end program manages the user’s display and outputs requests. The \nrequest controller processes a request by calling transaction servers, which access databases and other transactional \nresources. \n\n\n The front-end program may respond to some requests itself. It sends other requests to the next stage of the \nsystem, either by storing them on a disk in a queue or forwarding them directly for processing by the applica-\ntion, in a component that we call the  request controller . \n The request controller component guides the execution of requests. It determines the steps required to exe-\ncute the request. It then executes those steps by invoking transaction servers. The application executing in this \ncomponent usually runs as part of an ACID transaction. \n Transaction servers are processes that run application programs that do the actual work of the request. They \nalmost always execute within a transaction. The transaction server usually communicates with one or more data-\nbase systems, which may be private to a particular transaction server or may be shared by several of them. \n Like any program, a TP application usually is constructed by composing simple components into more complex \nones. Simple transaction server applications can be composed into a compound application using local procedure \ncalls, such as composing  DebitChecking and  PayLoan into  PayLoanFromChecking as we saw in Section 2.2. \nTo compose distributed components, a distributed communications mechanism is needed, such as a remote proce-\ndure call or asynchronous message queue. Service-oriented components and workﬂ ow mechanisms can also play a \npart in this composition. Compound applications can then be composed into even higher level functions. This com-\nposition of components can have several levels, which sometimes makes the distinction between request controller \nand transaction server programs rather fuzzy. In such situations, a program may perform both request controller \nand transaction server functions. \n This multitier TP application architecture means that the TP application itself must be split into different \nparts that perform these different functions: front end, request controller, and transaction server. Most of this \nchapter is devoted to the details of what each of the components needs to do. \n Multitier Architectures \n TP systems usually have two kinds of hardware subsystems, front-end systems that sit close to the display devices, \nand back-end systems that sit close to the databases. In a simple conﬁ guration, each front-end system may be a \nPC running a web browser connected to the Internet, and the back-end system may be a single machine such as a \nshared memory multiprocessor running a web server and a database management system. In complex conﬁ gura-\ntions, both the front-end and back-end systems may contain many machines. For example, a front-end system \nmay have multiple machines that support a large number of devices in a retail store. A back-end system may be a \nlarge server farm that supports hundreds of stores, with different machines running different applications, such as \nﬁ nance, order processing, shipping, and human resources. \n A major architectural issue in TP systems is how to map the functional components of  Figure 3.1 into processes \non front-end and back-end systems. One natural way is to have each function run in a separate kind of process: \n ■  The front-end program runs in a separate process, typically either a web browser or custom software to con-\ntrol relatively low-function end-user devices. On large systems, separate front-end machines are dedicated \nto front-end programs. On small systems, they run on the same back-end machine as other components. \n ■  Each request controller runs in a separate process and communicates with the front-end programs via \nmessages. It usually runs on a back-end system. \n ■  Each transaction server runs as a process on a back-end system, preferably colocated on the same \nmachine or local area network as the database system that it most frequently accesses. It communicates \nwith request controllers and other transaction servers via messages. \n ■  Each database system runs as a process on a back-end system. \n3.2 Application Architecture  75\n\n\n76  CHAPTER 3 Transaction Processing Application Architecture\n Most modern TP applications are structured in this multitier architecture to get the following beneﬁ ts in a \ndistributed computing environment: \n ■  Flexible distribution: Functions can be moved around in the distributed system without modifying appli-\ncation programs, because the different functions already are separated into independent processes that \ncommunicate by exchanging messages. \n ■  Flexible conﬁ guration: Processes can be located to optimize performance, availability, manageability, \nand so on. \n ■  Easier scale-out: The distribution and conﬁ guration ﬂ exibility makes it easier to scale out a system by \nadding more server boxes and moving processes to them. \n ■  Flexible control: Each functional component can be independently controlled. For example, one can con-\ntrol the relative speeds of transaction servers by varying the number of threads in those servers without \naffecting the front-end program or request controller functions, which are running in separate processes. \n ■  Easier operations: In a large system, only a few people are expert at each tier’s applications. Having \nthem isolated makes them easier to debug and independently upgradable. \n ■  Fault isolation: Since the different functions are running in different processes, errors in one function \ncannot corrupt the memory of other functions, which are running in separate processes. \n The main disadvantage of this multitier architecture is its impact on performance. The functional compo-\nnents are communicating via messages between processes, instead of local procedure calls within a single pro-\ncess. The former are at least two orders-of-magnitude slower than the latter. Since even the simplest transaction \nrequires a round-trip between a front-end program and request controller and between a request controller and \ntransaction server, there is quite a lot of message overhead in this approach. \n There are other disadvantages of the multitier architecture due to its large number of moving parts. This \nleads to complexity of the design, deployment, conﬁ guration, and management of the multitier system. To miti-\ngate these problems, vendors have been steadily improving their tools for development and system management. \nBut there is still much room for improvement. \n Due to communications overhead, it is common to combine functions in a single process. For example, most \ndatabase systems support  stored procedures , which are application programs that execute within the database \nserver process. One can use this mechanism to run transaction server programs as stored procedures, thereby \neliminating a layer of processes between request controllers and the database system and hence eliminating \ncommunication overhead. Of course, this reduces the degrees of ﬂ exibility of the multitier architecture, since it \nprevents transaction server programs from being distributed independently of the database server processes in \nwhich they run. \n Taking this approach to the extreme, one can run all the functional components of the multitier architec-\nture in a database server process. This reduces the multitier architecture to a two-tier architecture. This was a \npopular approach in the early days of client – server computing in the 1980s, but fell out of favor for large-scale \nsystems due to its limited ability to scale out. However, as database servers are becoming more functional, it is \nlooking more appealing. We will discuss this trend later, in Section 3.7. \n Service-Oriented Architecture \n In addition to the multitier application architecture, application design methodologies play a role in the structure \nof TP applications. Service-oriented architecture (SOA) is one such design methodology, which was discussed \n\n\n in Chapter 1. In SOA, the designer identiﬁ es a service that a business provides for its customers and partners. The \ndesigner maps this business service to a software service, which is an operation. Typically, a set of related opera-\ntions are grouped together in a service interface. Each operation in a service interface is implemented as a soft-\nware component that can be invoked over a network by sending it a message. In SOA, operations are intended \nto be relatively independent of each other, so they can be assembled into applications in different combinations, \nconnected by different message patterns. \n In a TP system, a service can implement a transaction or a step within a transaction. That is, it can play the \nrole of a request controller or transaction server. In either case, it is invoked by sending a message to the ser-\nvice. In this sense, the notion of a service is nicely aligned with multitier TP system architecture. \n This alignment between SOA and TP depends only on the fact that SOA decomposes applications into \nindependent services. It does not depend on the particular technology that is used to deﬁ ne service interfaces \nor to communicate between services, such as RPC or Web Service standards. \n Object-Oriented Design \n Another popular application design methodology that plays a role in the structure of TP applications is object-\noriented design. Object-oriented design offers a different perspective than SOA, focusing on modeling things \nrather than functions. \n Object -oriented design maps nicely onto the TP application architecture of  Figure 3.1 as shown in  Figure 3.2 . \nIn this style of design, one starts by deﬁ ning  business objects , which are the elementary types of entities used by \nthe business. In programming terms, each business object corresponds to a class in an object-oriented program-\nming language, such as C \u0002 \u0002 , Java, C#, or Visual Basic. It encapsulates the elementary operations on that type of \nentity, called  methods . Typically, these methods change slowly, because they correspond to types of real-world \nobjects whose behavior has been well-established for a long time. For example, the following could be deﬁ ned as \nbusiness objects: \n ■  Customer: It supports methods to create a new customer, change address, change phone number, and \nreturn customer information in several different formats. \na. Multitier TP\n    application architecture\nb. Object-oriented\n    application architecture \nMenu item and form\nto open an account\nOpen an account\nCustomer\nobject \nAccount\nobject\nFront-end program\nRequest controller\n\u0005 business rules \nTransaction server\n\u0005 business objects\n FIGURE 3.2 \n Mapping Object-Oriented Application Architecture to a Multitier Model. Business objects, such as  “ Customer, ”  “ Credit \nHistory, ” and  “ Account ” run in transaction servers, and business rules such as  “ Open an Account ” run in request \ncontrollers. \n3.2 Application Architecture  77\n",
      "page_number": 85
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 96-104)",
      "start_page": 96,
      "end_page": 104,
      "detection_method": "topic_boundary",
      "content": "78  CHAPTER 3 Transaction Processing Application Architecture\n ■  Loan Account: It supports methods to create a new loan account, increase the amount owed, credit the \namount paid, and associate the loan account with a different customer. \n ■  Credit History: It supports methods to create a credit history for a given customer, add a credit event \n(such as a loan or loan payment), and return all its credit events for a given time period. \n After deﬁ ning the business objects in an application, one deﬁ nes  business rules , which are actions that \nthe business performs in response to things that happen in the real world. For example, the business rule for \nopening a new loan might involve creating a new customer object (if this is a new customer), checking the cus-\ntomer’s credit history, and if the credit history is satisfactory, then creating an account. Business rules change \nmore frequently than business objects, because they reﬂ ect changes in the way the business operates in the real \nworld. It is therefore useful to program business rules in modules that are separate from business objects. \n One can map this object-oriented application design onto TP application architecture by running business \nobjects as transaction servers and business rules as request controller programs. This is an efﬁ cient architecture, \nsince business objects make frequent access to the database that stores the object’s state and can be colocated \nwith the database. It is also a ﬂ exible structure, since business rules can be changed within request controllers \nwithout affecting the business objects (i.e., transaction servers) that they call. \n Applications created using objects can be service-enabled to participate in an SOA. Externally callable \nmethods of an object-oriented application are good candidates for services. Services might expose only por-\ntions of the functionality of the objects through the service interface. \n Simple Requests \n In this chapter, we’ll focus on simple requests. A  simple request accepts one input message from its input \ndevice (a display device or specialized device such as an ATM), executes the transaction, and sends one mes-\nsage back to the input device. Examples are making a bank account deposit, placing an order, or logging a \nshipment. Each simple request is independent of every other simple request. \n A given user interaction may actually require a sequence of related requests. For example, a user might want \nto arrange a trip, which requires reserving airline seats, reserving a car, and reserving a hotel room. A travel \nweb site may offer this as one request, even though it may actually run as three separate requests. We’ll look at \nmulti-request interactions in Chapter 5. In this chapter, we’ll assume that all requests are simple — one message \nin and one message out. \n The next three sections, Sections 3.3 through 3.5, cover the main components of TP application architec-\nture: front-end programs, request controllers, and transaction servers. They look at both the application’s func-\ntions and issues related to building the underlying component. Section 3.6 looks at transactional middleware \nthat provides support for these components. Section 3.7 revisits the two-tier versus three-tier system models, \nexploring in more detail the decision to group front-end programs, request controllers, and transaction servers \ninto the database server process. \n 3.3  FRONT-END PROGRAM \n Front-End Program Layers \n A front-end program gathers input from a user and sends it as a request message to the request controller. From \nthat point on, the TP application deals with only request messages. It doesn’t need to know any details of the \nvarious devices, forms managers, or web services that capture input for the request or that interpret the output \n\n\n of the transaction that runs the request. Only the front-end program deals with that. We call this  presentation \nindependence , because the front-end program makes the rest of the application independent of the other soft-\nware and hardware that’s interacting with the user. \n Typically the request controller offers a ﬁ xed application programming interface (API) for use by the front-\nend program. That is, the API doesn’t depend on the type of front-end device or program. This enables a single \nTP application to interact concurrently with diverse front-end devices and programs. It also makes it easy to \nadd new front-end devices and programs without modifying the rest of the TP application. \n The front-end program has two main functions (see  Figure 3.3 ): one that interacts with the user to gather \ninput and display output; and one that deals with constructing request messages and interpreting replies. We’ll \ndescribe each function in turn. \n Gathering Input Using Forms and Menus \n Form and Menu Concepts \n The front-end program gathers from a display device the input required to generate a request message. If the \ndisplay device is a terminal, PC, or workstation, the front-end program generally interacts with the user via \nmenus and forms, often executing inside a web browser. The user selects a menu item — perhaps by clicking on \nan icon or a command button, or by highlighting an entry on a pull-down menu — to identify the type of trans-\naction he or she wants to run. Then the front-end program displays a form or series of forms in which the user \nenters the input data needed for the type of request. Anyone who has made a retail purchase over the Internet \nusing a web browser recognizes this style of interaction. \n Application programmers write the programs that direct the front end’s menu management, forms manage-\nment, and data validation functions. One or more presentation technologies offers application programmers the \nability to do the following: \n ■  Deﬁ ne menus and how to navigate between them. \n ■  Deﬁ ne the ﬁ elds of each form and how they are laid out on the screen. \n ■  Identify the data validation routine to be called for each ﬁ eld on the form to ensure that the input makes \nsense. \n The system functions available to interact with forms and menus have changed a lot over the years, due \nto the evolution of desktop devices and graphical user interfaces. However, the required capabilities of forms \nand menus have not changed very much. We ﬁ rst explain the principles and then discuss how they have been \nembodied in various kinds of technology. \n The front-end program usually performs some data validation of the input form, to ensure that the input \nvalues make sense. This validation is done for each ﬁ eld, either one-by-one as each ﬁ eld is entered, or altogether\nGather Input & Display Output\nConstruct Requests\nRequests\n FIGURE 3.3 \n Layers of a Front-End Program. The front-end program gathers input by communicating with the display, then translates \nthat input into a request message. \n3.3 Front-End Program  79\n\n\n80  CHAPTER 3 Transaction Processing Application Architecture\n after the entire form has been ﬁ lled in. The goal of the validation is to minimize the chance of attempting to \nexecute the request with incorrect input. This would result in having the error detected downstream by a request \ncontroller, transaction server, or database system, thereby wasting system resources and increasing the delay in \nnotifying the user of the error. \n Data validation can sometimes be circumvented by offering a pick-list, such as a drop-down menu, that con-\ntains only the valid values for that ﬁ eld (e.g., a state or province in an address). Other checks require a cached \ncopy of valid data values that are compared to values that the user enters in the form. For example, when request-\ning a ﬂ ight reservation, the user needs to enter a valid city name or airport code. \n When validating ﬁ elds, it is usually a bad idea to compare the values entered by the end-user directly with \ndata in the back-end database. If this were done as each input ﬁ eld is entered, it would generate a high load \non the communication path between the user display and the database and on the database itself. This would \ndegrade the response time to the user and the throughput of the back end. However, using a cached copy also \nhas disadvantages. The cached copy is refreshed from the live database only periodically, so it usually isn’t com-\npletely accurate. This is satisfactory for ﬁ elds that don’t change frequently, such as department names and prod-\nuct codes, but not for frequently changing ﬁ elds, such as the number of items left in inventory for a popular \nproduct. Those ﬁ elds can be validated only by executing the transaction itself in the transaction server, which \nhas direct access to the database. \n One problem with validation logic is that it resides on the front end but is closely associated with the \nback end, where the validated input is interpreted. Thus, changes in transaction server behavior can affect the \ndata validation behavior that’s required. This affects the process for developing, deploying, and managing \napplications. \n The use of cached and potentially out-of-date data for data validation is an example of the general design \nprinciple presented in Section 2.6 for scaling up. By limiting the application’s need for accurate and consistent \ndata, the application can be replicated to scale up to a large number of web servers and browsers. If accurate \ndata were required, then it would be more costly to keep the replicas up to date. \n Form and Menu Technology \n Before the advent of the PC, terminals were the dominant device for an end-user to communicate with a TP \nsystem. Terminal devices evolved from teletype terminals, to character-at-a-time cathode-ray tube terminals, to \nblock-mode screen-at-a-time terminals. In all the cases, forms management software was used to write front-end \nprograms to communicate with such devices. In the 1970s, this functionality was built into early TP monitor \nproducts. In the 1980s, independent forms manager products became popular. They offered a What-You-See-Is-\nWhat-You-Get (WYSIWYG) forms designer and callout functions to a standard programming language. \n In the early 1990s, PCs became popular as display devices for communicating with TP applications. Early \nforms products were replaced by fourth generation languages (4GLs) and visual programming products, such \nas Microsoft’s Visual Basic, Powersoft’s (now Sybase’s) PowerBuilder, and Borland’s Delphi. The forms and \nmenus compile into programs that run on a PC, rather than on a server as had been the case for low-function \ndisplay devices. They typically use an RPC to communicate with the back-end server. This style of front-end \nprogram often is called a  thick client , because it runs in a general-purpose operating system environment. \n As web browsers became popular in the late 1990s, the  thin client architecture emerged, where the menus \nand forms are hosted in a browser.  Figure 3.4 illustrates the thick and thin client alternatives. \n The thin client architecture gets its name from the more limited functionality of the browser environment \ncompared to a general-purpose programming language and operating system. The basic interaction pattern is \nthat the browser receives and displays HTML ﬁ les and their embedded links, the user enters data (usually via \nHTML forms), and the browser returns the user’s data to the web server as a query-string in an HTTP GET or \nas the content of an HTTP POST, which the web server then processes. The same pattern is used for XHTML, \nwhich uses XML syntax to express HTML. The web server is then responsible for invoking the back-end server. \n\n\n In the thin client architecture, some of the browser controls may be used instead of or in addition to the \nforms logic, such as the browser navigation buttons. Browser-based front-end programs also may have to com-\npensate for browser-based navigations; for example, compensating for the case when the browser’s  “ back ” but-\nton is pushed before the form is completed. \n From a TP system designer’s perspective, one beneﬁ t of browsers is that there are a relatively small num-\nber of popular ones and hence a relatively small number of interfaces to support. However, early browsers did \nnot support a very expressive programming environment. The browser has become less of a thin client over \ntime with the development of more powerful programming constructs that can run in the browser, such as \ninteractive plug-ins and scripting languages. Other programming models for active content include Dynamic \nHTML, which adds client-side scripting, cascading style sheets, and the document object model to HTML; \nAJAX (Asynchronous JavaScript And XML), which enables updating of small portions of a web page instead \nof reloading the entire page; and multimedia environments such as Adobe Flash and Microsoft Silverlight. \nNew, more powerful browser-based technologies appear every year. \n Desktop systems are much less expensive than back-end TP systems and are usually paid for by users, not \nby the enterprise owning the TP system. Therefore, TP system designers want to ofﬂ oad as much processing as \npossible to the front end. However, given the power of a web browser to display complex multipart pages and \nto execute code, some care is needed to avoid overloading a page with too much functionality and thereby neg-\natively affecting performance. For example, displaying too many objects, with images assembled from several \nsources, can be a source of delay. Objects embedded in the browser also have the capability to directly invoke \na transaction server, but this can introduce scalability problems such as those discussed in Chapter 2. \n Forms Development \n Forms and menus usually are designed graphically, by creating the form on the screen. Actions may be associ-\nated with each ﬁ eld and menu item to validate as the form is ﬁ lled in, or there may be a single action to accept \nall the user input and package it in a request message. \nVisual Studio\nEclipse-based IDE\nNetBeans\nHTML Forms\nXHTML\nDynamic HTML\nAJAX\nThick Client\nWeb Server\nRequest\nController\nHTML/XML\nForms Editor\nDreamWeaver\nExpression Web\nThin Client\nEnd-user’s\ndevice\nDesign time\nRun time\nVisual Basic, C#\nJava\nEclipse RCP\n FIGURE 3.4 \n Sample Forms Tools. In a thick client, a general-purpose program on the user’s PC communicates with the back-end \nserver. A thin client uses a browser to display forms and gather input. \n3.3 Front-End Program  81\n\n\n82  CHAPTER 3 Transaction Processing Application Architecture\n Some development environments provide extensive function libraries to help build the form and process \nthe input to it, including validation. If using HTML or a variation of it, the development environment may have \nfewer built-in functions, so more processing may be needed at the request controller to compensate for the lack \nof functionality in the front-end program environment. \n Constructing Requests \n A request message from a front-end program can take the form of a remote procedure call or asynchronous \nmessage. Its format usually includes the following (see  Figure 3.5 ): \n ■  The identiﬁ er of the user; that is, the name of the user who is operating the device and is entering the \nrequest (if a human is doing this work) or of the software component that is authorized to issue the request. \nFor HTTP, this often is captured in a cookie and is omitted for some types of requests. \n ■  A device identiﬁ er of the device that’s producing the input. For example, this could be the network address \nof the device or an operating system socket that is bound to a TCP session with the device. The device’s \ntype might be available through the message protocol (e.g., in HTTP) or it may be supplied by the commu-\nnications system. For example, the device type could be a particular version of a web browser or a particular \nasynchronous terminal device. \n ■  A request type, which is the identiﬁ er of the type of transaction that the request is asking to execute. \n ■  Input parameters; each request type generally requires a certain number of parameters as input. The rest \nof the message contains those parameters, which are different for each type of request. \n There are many message format standards that deﬁ ne ﬁ elds for some of the above information. For example, \nHTTP provides a default mechanism for constructing a request using a URL. Other standard formats include \nSOAP headers and some Web Services standards, such as WS-Addressing and WS-Security. Application-\nspeciﬁ c formats also are used. For example, some ﬁ elds could be expressed in the data type part of the Web \nService Description Language. They may simply be part of an XML payload that is passed in an asynchronous \nmessage, deﬁ ned using XML Schema. Or they may be deﬁ ned by a transactional middleware product that \noffers request management functions. \n Ideally , a TP application uses one format for all its transaction types. However, an enterprise system often \nhas heterogeneous components that use different request formats. In this case, a request controller may need to \ntransform or reformat some requests into and out of different formats. This is a common function of message-\noriented middleware, which is described in Chapter 4. \n A request should also include a  request identiﬁ er , which is unique relative to other request identiﬁ ers from \nthe same client and is made visible to the user or application program that issued the request. There are two \noperations that should be offered to users and that need this identiﬁ er, Status and Cancel. The Status operation is \nissued by a user who has timed out waiting for a reply to the request. It returns the state of the request, such as \nUser ID\nDevice ID\nRequest Type\nRequest-Specific Parameters\n FIGURE 3.5 \n Typical Request Contents. It contains the ID of the user entering the request, the user’s device, the type of transaction \nbeing requested, and parameters to the request. \n\n\n whether the request has been received, has been processed and committed, or has been processed and aborted. \nThe Cancel operation attempts to kill the request before it executes. This operation cannot be guaranteed to \nsucceed. If the request has already executed and committed at the time the cancel operation is received by the \nsystem, it’s too late, because once a transaction is committed, its results are permanent (except by running a \ncompensating transaction). If the front-end program is allowed to have many requests outstanding, then the \nrequest identiﬁ er has a third use: to match each reply to the corresponding request, either by the front-end pro-\ngram or request controller. \n After the front-end program has gathered the user’s input, it sends a request message to the request control-\nler. This is typically an RPC or HTTP operation. Before RPC was widely available, transactional middleware \nproducts often implemented a custom protocol to send a request message and receive a reply. These protocols \nare still available in many of the older products, primarily for backward compatibility. Modern SOA or web-\nbased systems may also offer an asynchronous messaging capability. \n When a front-end program is tightly integrated with a transactional middleware product, the request may \nbe constructed by the middleware product with little application programming. By setting certain properties of \nthe menu item and by tagging forms ﬁ elds with the names of parameters required by the transaction program, \nthe application programmer can give the front-end program what it needs to translate that menu item and form \ndata into a request message. \n Logging \n Some front-end programs are able to keep a record of all the work going on at the front-end by logging messages. \nSometimes the display devices themselves do this. For example, some ATMs print a record of each transaction on \na paper log inside the machine, to settle later disputes. For less functional devices, the front-end program may do \nthe message logging itself and provide an interface where system managers can go back and look at that log to \nreconcile any errors that might appear later. Transactional middleware often has built-in message logging func-\ntionality to help, such as that in the Java Enterprise Edition (Java EE) and the .NET Framework. We discuss such \nreconciliation problems further in Sections 4.4 and 5.5. \n Web Servers \n Although web servers reside on back-end systems, their primary purpose is to capture input from web browsers \nand display output in the form of static or dynamically- generated content. Since they are so closely linked to the \nbehavior of web browsers, we usually regard them as part of the front-end layer of the multitier architecture. \n Web servers are designed not only to interact with a display by sending pages to web browsers, but also to \nprocess simple requests. For example, a web server can process a request for relatively static information, such \nas the root page of a web site or the table of contents of a catalog. Answering this kind of request in the web \nserver offers faster response time than forwarding the request to other middle-tier or back-end components \nfor processing. Moreover, since the requested information is static, it can be cached in the web server, further \nimproving efﬁ ciency. Over time, we expect web servers to continually grow in their capacity to handle not only \nsimple requests efﬁ ciently, but also more and more complex requests. \n Some simple requests require the invocation of an application program. One of the ﬁ rst mechanisms intro-\nduced for a web server to invoke application code was the Common Gateway Interface (CGI). A CGI program \ncan be written in any language supported by the system on which the web server is running. A speciﬁ c location \nis deﬁ ned for the CGI programs (e.g.,  http://www.example.com/wiki.cgi ). Whenever a request to a matching \nURL is received (e.g.,  http://en.wikipedia.org/wiki/URL ), the corresponding program is called, together with \n3.3 Front-End Program  83\n\n\n84  CHAPTER 3 Transaction Processing Application Architecture\n any data that the client sent as input. Output from the program is collected by the web server, augmented with \nappropriate headers, and sent back to the client. \n Each call from the web server to execute a request through CGI causes a new process to be created. The \nnew process executes the application program required to process the request. In particular, that application \nprogram could be a request controller. This is the 1970s ’ time-sharing model of executing commands, namely, \nfor every call create a process and run the called program in that process. The approach is simple, but expen-\nsive, and therefore has limited scalability. Techniques have been developed to improve the performance of \nCGI scripts, including the ability to execute compiled programs and an optimized version of the CGI protocol \ncalled FastCGI. FastCGI creates a limited pool of processes (i.e., a server class) that runs CGI programs with \ncommunications connections to the web server. These processes can be reused by multiple CGI calls, instead \nof creating a process per call. \n To avoid the overhead of process creation altogether, web servers have interfaces to execute applica-\ntion code within the web server that invokes the application, such as Microsoft’s Internet Server Application \nProgramming Interface (ISAPI) and the Apache API. This is more efﬁ cient. But the APIs are relatively low-\nlevel, which makes applications that use these APIs somewhat complex. Moreover, applications running in a \nweb server process are not as well protected from each other as they would be running in separate processes, \nas in CGI. A higher level and more portable alternative is the Java Servlet API. HTTP requests and responses \nare mapped to Servlet threads, which invoke Java objects to dynamically generate content and access resources \nexternal to the web server. \n Higher level programming environments also have been developed that simplify application programming. \nInitially, a scripting language was allowed to be embedded in web pages, such as Active Server Pages (ASP) \nand Java Server Pages (JSP). When the web server receives a URL for such a page, it loads the page and \nthen interprets the embedded script, which results in a page containing only HTML (for example), which is \nreturned to the browser that requested the page. This programming model has been quite popular and therefore \nhas been steadily improved to allow more powerful language features, more prepackaged controls, compilation \nof pages, and invocation of code outside pages using an RPC. \n Another trend is offering more modern programming languages, such as Java and C#, which have garbage \ncollection and type safety for higher programmer productivity and increased reliability. However, garbage col-\nlection hides from the user the amount of memory being used, so the equivalent of a memory leak may go \nundetected while the memory footprint increases forever. Although garbage collection often reduces application \nexecution time, even with concurrent multithreaded garbage collectors the system must sometimes stop and \ncollect garbage, thereby introducing latency. To avoid unacceptable response time, TP system implementers \nneed to watch out for these issues and minimize their effects. \n The functionality of web servers, and of front-end programs in general, changes relatively rapidly. These \nchanges are driven by several factors: the continual increase in the power of end-user devices and speed of \nnetworks that connect the front-end program to that device; the desire to offer more appealing interfaces for \nhuman – computer interaction; and the demand to improve programmer productivity when developing applica-\ntions for presentation services. We expect all these trends to continue indeﬁ nitely. \n State Management for Web Servers \n Applications running in a web server usually are designed to be stateless with respect to a browser instance. This \nis partly because browsers communicate with web servers using the HTTP protocol, which is stateless. Thus, dif-\nferent requests sent by a browser to a given back-end system may be processed by different web servers in that \nsystem. Clearly, this creates a problem if there is a state that needs to be maintained across multiple interactions \nbetween the browser and web servers. One approach is to carry along the state as application-managed parameters \n\n\n or cookies in each call. A second approach is to store that state on the back end by replicating it across multiple \nweb servers. A third approach is to store it on the back end in a location that is accessible to all the web servers \nthat can receive requests that may need that state. In the latter two approaches, the URL or a cookie needs to iden-\ntify that state so the web server knows how to ﬁ nd it. \n One reason that stateless web servers are popular is that they simplify scalability. Since web servers do not \nretain state, the dispatcher of HTTP requests can spray those requests randomly across all the web servers, thereby \nbalancing the load. Moreover, there is no state management needed to scale up a back-end system comprised of \nweb servers. One can simply add server machines, create web servers to run on the machines, and make the exis-\ntence of the web servers known to the HTTP dispatcher. \n Stateless web servers also simplify recovery. A web server may fail unexpectedly or be deliberately brought \ndown for maintenance or an upgrade. Since a web server does not retain state from one request to the next, the \nfailure of a web server affects only the speciﬁ c requests it was processing at the time it failed. If a user times out \nwaiting for a reply from a failed web server, he or she can simply reissue the request. The back-end system will \ndispatch the retry to an available web server, which is equally well prepared to process the request. Moreover, \nwhen the failed web server recovers, it can immediately start processing new requests, since it has no state that \nneeds to be recovered ﬁ rst. \n The use of stateless web servers is part of the software architectural pattern called REST (representational \nstate transfer). An example of the architectural pattern is the REST/HTTP protocol infrastructure, which we \ndiscussed in Section 1.2. The REST architectural pattern is characterized by the following set of constraints on \nservice-oriented systems: \n ■  Servers are stateless. \n ■  Operations are generic (e.g., GET and POST), so the application-speciﬁ c nature of an operation must be \ncaptured in the name and content of the resource being accessed (e.g., the URL). \n ■  The resource’s (e.g., web page’s) representation captures the name and parameters of operations being \ninvoked. \n ■  Caching is transparent, so the invocation of an operation can be answered from a cached result if it is \navailable, such as a cached copy of a static web page being requested by a GET operation. \n Together , these constraints enable scalability of clients and servers. To invoke a service, a client needs to \nknow only the name of the resource being invoked. It does not need to know the names of operations because \nthey are generic. Thus, a client can invoke a server as long as it has access to a service that can translate \nresource names into network addresses (e.g., the Internet Domain Name System (DNS)). Since servers are \nstateless, they scale out easily and more cheaply. And the use of caching helps avoid expensive communication \nand accesses to databases or ﬁ les, further improving scalability. \n The downside is that the REST architectural pattern, and stateless servers in general, can cause worse per-\nformance when interacting with shared data, because sometimes it leads to transferring more state than would \nbe needed with stateful servers. For example, since a stateless server cannot cache database records, it may \nsend a large set of records to a client, even though often only the ﬁ rst few are used. A stateful server  S can \nsolve this problem by maintaining a record cache. Or  S can use a database session with a database server-side \ncursor, which caches a large query result and returns a small set of records on each fetch operation by  S . \n In practice many web sites do not follow all the constraints of REST, making it more like an ideal architec-\nture against which to measure implementations of web technologies than a concrete programming model. The \nwidespread use of cookies is a good example, since they create resources that don’t have a URL, introduce \nstate management into a stateless protocol, and can become inconsistent when a web browser’s BACK button \nis pressed. Other common violations of REST are including parameters and methods in URLs, using POST \n3.3 Front-End Program  85\n\n\n86  CHAPTER 3 Transaction Processing Application Architecture\n for every operation instead of using GET, and misapplications of caching such that a system cannot determine \nwhich representation of a resource is authoritative or expired. \n Authentication and Encryption \n Another function performed by the front-end program is authentication, which is the activity of determining \nthe identity of the user (see  Figure 3.6 ). For example, this is required when a user accesses a bank or broker-\nage account. Not all applications require authentication. For example, retail businesses often allow users to \nmake purchases simply by providing billing and shipping information, without logging in. For applications \nthat require it, authentication usually is done by having the user enter a username and password, the results of \nwhich are visible to the application as an authentication token. \n Whenever the front-end program sends a request message to the request controller, the results of the user \nauthentication process are included. This proves to the rest of the application that the message came from a \ncertain person and allows authorization to be performed by the server. \n The user also wants to be sure that she is communicating with the correct server, not a rogue server that is \nspooﬁ ng — that is, masquerading as the server the user really wants. This requires that the server authenticate \nitself to the user. \n An additional level of security can be provided if the wire that connects the device to the system is encrypted, \nwhich reduces the threat of wiretapping. A good encryption algorithm makes it unlikely that a wiretapper would \nbe able either to decrypt messages or to spoof the system by trying to convince the system that it’s actually a \nqualiﬁ ed user. \n When the client system is communicating with the server over the Internet, server authentication and \nencryption usually is obtained using Transport Layer Security (TLS) (the successor to Secure Socket Layer \n(SSL)) on TCP/IP. This is a protocol by which the client and server exchange enough information to estab-\nlish a secure information channel, over which they exchange encrypted information that only each other can \ndecipher. \n In TLS, the client obtains from the server a certiﬁ cate, which includes the server’s public key. The server \ncertiﬁ cate is issued by a trusted certiﬁ cate authority and signed using the authority’s private key. A client can \nvalidate the certiﬁ cate using the authority’s public key. Thus, the certiﬁ cate can be used to authenticate the \nserver to the client web browser, so the latter is sure that it is talking to the intended server. The client and \nserver then exchange encryption keys and message authentication codes, which enable the client and server \nto exchange encrypted information. Often TLS is implemented by a site’s network switch, and lighter weight \nencryption is used within the site. \nUser\nBack-end\nserver\nEncryption to avoid wiretapping\nUser’s\ndevice\nWeb server\nauthenticates user\nBack end authenticates\nweb server and user\nWeb server\n FIGURE 3.6 \n Authentication and Security. Web servers and back-end servers authenticate the identity of users that communicate with \nthem. Additional security is provided by encrypting messages. \n",
      "page_number": 96
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 105-116)",
      "start_page": 105,
      "end_page": 116,
      "detection_method": "topic_boundary",
      "content": " There are many ways to arrange secure communications between the front-end program and web server, \ndepending on the desired level of security and the amount of effort devoted to performance optimization. The \nfollowing is a typical scenario: \n ■  Suppose that Alice is browsing a retail web site. She gets an encrypted cookie that identiﬁ es her as a \nuser, whether or not she’s logged in. Her browser sends the cookie back and forth over HTTP. The web \nserver of the web site can quickly decrypt basic information about Alice and her session. \n ■  After some browsing, Alice decides to buy what’s in her shopping basket. She goes to the checkout page, \nwhich uses HTTPS (i.e., TLS). All pages in the checkout process use HTTPS and hence communication \nis encrypted to protect Alice’s password, credit card number, and other personal information such as her \naddress. The HTTPS connection setup is expensive as it uses public key encryption of certiﬁ cates to give \nAlice some assurance that she’s talking to the right web site. After the certiﬁ cate is checked the HTTPS \nconnection may switch to a symmetric and cheaper connection. \n ■  The web site asks her to log in. It authenticates Alice’s login information and creates an encrypted \ncookie, which holds a key for the session information that’s stored on the back end. The web site also \nlooks up any relevant personal information it has on ﬁ le for her, such as billing and shipping address, \npreferred type of shipping, and credit card number. The web server caches the information in a local \nnondurable in-memory database and stores it as session state in a separate database that’s available to all \nweb servers. \n ■  The web site then asks Alice to ﬁ ll in or validate that personal information. It takes multiple interactions \nfor Alice to enter all this information. Since the web site uses a layer 7 network switch, which can route \nmessages by content, the switch will continue to direct her to the same server unless the server slows \ndown or crashes. If one of her interactions moves to another web server, the web server uses her cookie \nto ﬁ nd her session state in the session state database. \n ■  On the ﬁ nal web page, if Alice agrees to the purchase, the web site validates her credit card with a bank \nover another TLS connection, runs the transaction, and replies to Alice with a receipt. After that, she’s \nback to normal HTTP for more shopping. As HTTPS is more costly than HTTP, when Alice returns \nto web pages that anyone can see, the web site will switch back to unencrypted HTTP connections to \nsave cost. \n Some TP applications manage their own authentication and authorization information, whereas others use \nan external security service, such as the operating system’s security service, or an independent security service \nsuch as those provided by CA’s SiteMinder, Microsoft’s Windows Active Directory, or IBM’s Tivoli. If the \nsecurity service is made available to all back-end components, then the system can offer users a single set of \ncredentials across all applications. It might also offer a single sign-on for users, where they receive a ticket-\ngranting ticket  that can be used by multiple applications to authenticate the user. When an external security \nservice is used, the application has to be able to understand the external format, access the external service, \nand potentially federate security tokens (when more than one is used). \n In some TP applications, it’s quite important to know that a message arrived from a particular device, not \njust from any device at which a particular user logged in. This is called  geographical entitlement , because one \nis entitled to provide input based on one’s geographic location. An example would be in the securities trading \nroom of a brokerage house. When the traders show up for work, they have to display their photo identiﬁ cation \ncards to a guard before entering the trading room. They then sit down at their display devices and provide pass-\nwords to prove to the TP application that they are who they say they are. For this extra level of security to work, \nthe system must know that the request actually came from a device in the secured trading room. If someone \n3.3 Front-End Program  87\n\n\n88  CHAPTER 3 Transaction Processing Application Architecture\n connects from another location, device authentication will tell the system which device entered the request, so \nthe system can determine that the device is not entitled to enter requests, even if that someone knows the pass-\nword of an authorized user. \n Specifying the security of the TP system and monitoring the front-end program’s behavior creates require-\nments for a variety of system management functions within the front end. The front end has to allow a system \nmanager to deﬁ ne information needed to authenticate devices and users, such as passwords and valid network \naddresses. For example, the front-end program might allow the system manager to set up a default password that \nthe device owner or the user can change after logging in. The system manager may also specify that a user is \nallowed to enter only certain types of requests at certain times of day. Since there may be many users of the sys-\ntem, the complexity of this speciﬁ cation can be reduced by introducing the abstraction of a  role . Each role has a \nset of privileges, such as allowable requests and usage times, and a set of users that have those privileges. Instead \nof specifying privileges for each user, the system manager simply assigns and removes individual users from \nroles. The system manager needs to specify privileges for each role, but there are many fewer roles than users \nand the privileges for roles change less frequently than for users. Identity-based security is starting to emerge as \na way to achieve more ﬁ ne-grained authorization, such as Microsoft’s CardSpace and Eclipse’s Higgins. \n Security is a major consideration when developing and deploying TP applications and is a subject for a \nbook in itself. In-depth discussions about security mechanisms are beyond the scope of this book. \n 3.4  REQUEST CONTROLLER \n The purpose of a request controller is to execute requests by calling the transaction server programs that can \nperform the request. If the execution of the request produces output, the request controller routes the response \nback to the front-end program that sent the request. Usually the request controller brackets transactions; that \nis, it issues the Start, Commit, and Abort operations. Within a transaction, there may be calls to one or more \ntransaction servers. \n Specifying Request Controller Functions \n A request may require the execution of many transaction server programs and possibly of many transactions. \nAn application-speciﬁ c program in the request controller decides which transaction servers to call and in which \norder. On the face of it, there’s nothing special about it. It simply accepts a call that contains a request and calls \nsubroutines (transaction servers) to do most of its work. For requests that execute as a single transaction, the \napplication really is quite simple. When multiple transactions are required to process the request, there are \ncomplications, but we’ll defer those until Chapter 5. \n Most transactional middleware products allow the same language to be used both for request controller \nand transaction server functions. So it’s the application designer’s job to split the request-processing function \nbetween the request controller and the transaction server, but it is not something that is forced on the devel-\noper. Nevertheless, this split is desirable for the reasons discussed in the subsection  Multitier Architectures in \nSection 3.2. \n Some transactional middleware products support a special programming language in which to express the \nrequest controller logic. Some of these languages were introduced in the 1980s to ensure request controller appli-\ncations cannot do synchronous I/O, thereby enabling the implementation of multithreading in middleware (see \nSection 2.3). Examples are Task Deﬁ nition Language used in HP’s ACMS (originally from Digital Equipment \nCorporation) and Screen COBOL used in HP’s Pathway TP monitor (originally from Tandem Computers). \n\n\n Other languages are designed to simplify programming multi-transaction requests, such as the Web Services \nBusiness Process Execution Language. This is discussed further in Chapter 5. \n Modern transactional middleware systems handle these functions using a combination of container abstrac-\ntions, APIs, attributes, and conﬁ guration properties. \n Transaction Bracketing \n No matter what language is used to express it, the request controller generally brackets the transaction before it \nactually calls the program to do the work for the request — that is, it issues a Start operation to begin a transac-\ntion before it calls any transaction server programs. After all the transaction servers that execute on behalf of the \nrequest have returned, it issues a Commit operation to indicate that the transaction is done and should be com-\nmitted. The Start and Commit operations are issued by the system when using an implicit programming model. \n Some discipline may be required in choosing which programs issue the transaction bracketing operations \nStart, Commit, and Abort. For example, suppose the transactional middleware or underlying platform does \nnot offer a solution to the transaction composability problem, e.g., by properly handling calls to Start issued \nwithin a transaction or by using transaction attributes attached to object-oriented components (as in .NET and \nJava EE). Then the transaction server programs should not contain the Start, Commit, and Abort operations, \nbut rather should be pure objects. The request controller that calls the transaction server program should be the \none that actually starts the transaction and commits or aborts it. That way the callee can be called from several \ndifferent applications that use the same procedure in different ways, as described in the subsection  Transaction \nBracketing in Section 2.2. All the other issues related to the transaction abstraction in Section 2.2 apply here \ntoo, such as exception handing, savepoints, and chained versus unchained transaction models. \n Request Integrity \n One major complication related to transaction bracketing is ensuring the integrity of each transaction’s request \nmessage. If a transaction aborts, its request may be lost, making it impossible to re-execute  the transaction, \nwhich is very undesirable. The application should catch the abort exception and return a comprehensible mes-\nsage to the user. If it doesn’t, the user might get back an inscrutable error message (e.g.,  “ transaction aborted ” \nor  “ HTTP 500: Internal Server Error ” ), or in some bad cases no response at all. \n To avoid lost requests, the transaction that performs the request should include the operation that gets a request \nas input, say  Get-input-request as shown in  Figure 3.7 . Usually, it’s the ﬁ rst operation executed by the transaction. \nThe system should make the Get-input-request operation recoverable. That is, if the transaction aborts, then the \nGet-input-request operation is undone, just like any other recoverable transaction operation. Thus, the request \nmessage is again available as input and will cause another transaction to execute later, as desired. \n// Example A\nGet-input-request;\nStart;\n   . . .\nCommit;\n// Example B\nStart;\n   Get-input-request;\n   . . .\nCommit;\n FIGURE 3.7 \n Ensuring the Integrity of Requests. In (A), the Get-input-request operation executes before the transaction, so if the \ntransaction aborts, the request is lost. In (B), Get-input-request executes within the transaction, so if the transaction \naborts, the Get-input-request operation is undone and the request is restored. \n3.4 Request Controller  89\n\n\n90  CHAPTER 3 Transaction Processing Application Architecture\n A limit on the number of retries is needed to avoid looping forever on badly formed requests. If a request \nis determined to be badly formed, then a transaction should execute Get-input-request, report the error, and \ncommit, thereby ensuring the request doesn’t execute anymore. As discussed in Section 2.2, savepoints can be \nhelpful in structuring this activity. \n Using the explicit Get-input-request operation, the program waits until a front-end program has an input \nrequest to offer. This is common practice with dumb display devices, which was the usual situation before the \nadvent of PCs. \n The advent of client-server computing and widespread availability of RPC has made it popular for the cli-\nent to invoke the server. That is, the front-end program calls the request controller program, rather than having \nthe request controller call a Get-input-request operation. In this case, the operation that receives the client’s \ncall is the invocation of the called procedure. To avoid the request integrity problem, this  “ receive-the-client’s-\ncall ” operation must be made explicit, so it can be invoked within the context of a transaction and undone if \nthe transaction aborts. The details of how to recover a request if the transaction aborts are sufﬁ ciently complex \nso that we devote an entire chapter to them, Chapter 4, and therefore do not discuss them further here. \n Process Structure \n The request controller typically runs in a multithreaded process. The process may be dedicated to request con-\ntroller functions. Or it may be combined with front-end program functions or transaction server functions, to \nsave context switching overhead. For example, we saw how to combine web server functions with a request \ncontroller in Section 3.3,  Web Servers . Combining request controller functions in the same process as transac-\ntion server functions is usually straightforward. Since a request controller usually invokes transaction servers \nusing RPC, it is simply a matter of replacing remote procedure calls by local procedure calls. \n Since the request controller application executes within a transaction, it needs to have a transaction context \nand to pass that context to transaction servers that it invokes. If the request controller and transaction server \nrun in separate processes, then this is usually done with a transactional RPC. If they run in the same process, \nthen they automatically share thread context and hence transaction context. \n Usually , only a modest amount of processing time is required in the request controller to handle each request. \nNevertheless, this processing time is not zero, so even a multithreaded request controller has limited capacity. If \nthe system is required to handle a maximum request controller workload that exceeds the processing capacity of \na single machine, then it may be necessary to partition or replicate the request controller. For example, a request \ncontroller could be partitioned by request type, and each partition assigned to run on a different machine. As \nwith any scale-out scheme, if request controllers are replicated or partitioned, then it is desirable to have them be \nstateless with respect to their request sources, to avoid the complexity of having to route requests to the particu-\nlar copy of a request controller that has the request source’s state. \n Session Structure \n One traditional function of request controllers is to reduce the number of communication sessions by parti-\ntioning the sessions that would otherwise be required to connect front ends to transaction servers. This helps \nthe session scale-out problem that is described in Section 2.6,  Partitioning Sessions . For example, front ends \nexecuting in the same geographical location could be serviced by the same request controller. \n More complex groupings of connections between front ends and request controllers may be needed for \nfault tolerance reasons. For example, the ATMs at a bank branch may be split across two request controllers \nover two independent communication lines, so the failure of one controller or communication line still leaves \nhalf of the ATMs operating. \n\n\n Security \n If the request controller is receiving requests from untrusted front ends, then requests are a potential source of \nsecurity threats. The request controller therefore should not trust that the data it receives is well formed. For \nexample, it should not assume that a buffer it receives is null terminated or that ﬁ eld  A of a message really is the \nsize for ﬁ eld  B . The bottom line is that secure coding practices are essential when developing TP applications. \n We assume that the request controller is part of the trusted computing base. In particular, it is safe to have \nit be responsible for checking user authorization. To do this, it needs to know about the authenticated user that \nissued the request. For example, it may need to check that the user is authorized to execute the request’s request \ntype. It also needs to pass the authenticated user ID to transaction servers, since some access control can be per-\nformed only when accessing the database. For example, permission to withdraw from a bank account should be \ngiven only to users who own that account. \n In addition to user authorization, process authorization may be required. For example, a transaction server \nmay be accessible only from request controller processes that are known to have done preliminary user autho-\nrization checks and therefore are trusted. This avoids the need for the transaction server to duplicate the request \ncontroller’s check that the user is authorized to execute the request. Process authorization can be done by asso-\nciating the request controller process with an authenticated application administrator, who creates the request \ncontroller process to execute on his or her behalf. Transaction servers are then conﬁ gured to accept calls only \nfrom request controller processes executing on behalf of this application administrator. \n A session may be established between the request controller and transaction server whose session state \nincludes the authenticated application administrator information. This avoids requiring the transaction server \nto perform this security check on every access. Since the authorization state is the same for all requests, these \nsessions can be pooled, to avoid creating a new one for every request. \n It can be time consuming for a system manager to maintain all this security information. It can also be time \nconsuming for the transactional middleware to check all this security information at runtime. Simplicity of secu-\nrity management and efﬁ ciency of runtime security checking are features of transactional middleware products. \n 3.5  TRANSACTION SERVERS \n A  transaction server is the application program that does the real work of running the request. Part of that \nwork usually involves reading and writing shared databases. It always executes in the context of a transaction, \noften created by the request controller that called it. \n It can be a self-contained program or it might call other programs to do its work. Those other programs \nmight execute on the same system as the transaction server that calls it or on a remote system that requires a \ncommunications message to go from the caller to the callee. The communications must be transactional, so \nthat the transaction context ﬂ ows along with the messages. This typically is done using transactional RPC, as \ndiscussed in Section 2.4. \n For application portability, it’s desirable that the transaction servers be written using a popular program-\nming language such as COBOL, C \u0002 \u0002 , C#, FORTRAN, or Java. It is also desirable that they express database \naccesses in a widely used data manipulation language, such as SQL. This ensures that the transaction server \npart of the application can be ported to different transactional middleware environments. \n From the viewpoint of the application programmer, transaction servers are ordinary data access programs. \nThe application programmer needs to ensure the program preserves database integrity, doesn’t take too long to \nexecute and thereby create a resource bottleneck, uses timeouts to detect database server failures, returns com-\nprehensible error messages, copes with distributed databases, and so on. These are complex issues that arise \n3.5 Transaction Servers  91\n\n\n92  CHAPTER 3 Transaction Processing Application Architecture\n for any data access program. There is little that the programmer needs to do differently to run the program in a \ntransaction server process. \n Process and Session Structure \n From the viewpoint of process structure, transaction servers have several special considerations, which are \nrelated to their need to scale to high request rates and to support transaction-based communications. \n For scale-out, a transaction server  S needs to have enough threads to handle the system’s maximum required \nload. Although ﬁ guring out the right number of threads is really an experimental science, the following back-\nof-the-envelope calculation shows which factors are at stake. Suppose each transaction requires  t seconds of \nelapsed time to be processed by the transaction server. If the transaction server has one thread, then it can pro-\ncess 1 /t transactions per second. Thus, if the system needs to handle a peak load of  n transactions per second of \nthe transaction types implemented by  S , then  t  \u0004 n threads are required. Actually, somewhat more are required, \ndue to variance in elapsed processing time. The latter is dependent in large part on the time it takes to process \nits database operations, which is usually where most of the time is spent. This varies based on database server \nload, which may include database operations from other transaction servers. \n To access a database system, every active transaction in a transaction server process needs a database ses-\nsion with the database system. Thus, the number of database sessions required is comparable to the number of \nthreads in the transaction server. Since it is relatively expensive to create a database session, it is desirable that \nthey be pooled and reused. \n The use of database sessions has security implications, because part of the database session is the ID of a data-\nbase user, which usually cannot be changed after the session is created. The database system uses that ID to do an \nauthorization check of each operation executed on that session. Usually, the user ID of the database session is that \nof a dedicated account with sufﬁ cient privileges to access the data needed by the transaction server. This allows \nsessions to be reused for different requests and hence pooled. By contrast, if the user ID were that of the end user \nwho is issuing the request, then a new session would have to be created on that user’s behalf, unless the user hap-\npens to have executed another request in the very recent past and therefore already has a database session set up. \nAlso, if the user ID were that of an end user, then a database administrator would have to create a database user \naccount for every end user who can access the database. This is not feasible for TP applications that are accessed \nby a large number of end users only occasionally, a few times a year, such as a retail e-commerce site. \n The dedicated account usually is given read-write authorization on all parts of the database that may be \naccessed by the given transaction server. That is, the database system treats the transaction server as a trusted \nuser. Thus, it is up to the transaction server to check that a given end-user request is authorized to perform the \ndatabase operations required. \n 3.6  TRANSACTIONAL MIDDLEWARE \n Software vendors have developed transactional middleware products that make it easier to create, execute, and \nmanage TP applications by integrating diverse runtime functions. The main product category for this market \ntoday is the application server. Before the advent of the World Wide Web, the main product category was the \nTP monitor or On-Line TP (OLTP) monitor. Descriptions of transactional middleware products are presented \nin Chapter 10. \n The main job of transactional middleware is to provide an environment that takes applications that are writ-\nten to process a single request and scale them up to run efﬁ ciently on large, often distributed systems with many \nactive users submitting requests and many servers processing requests. By enabling this scale-up, transactional\n\n\n middleware increases the capacity and lowers the per-transaction cost of the application. From a business \nperspective, it lowers the cost of retail sales, ticket reservations, funds transfers, and such. \n Transactional middleware typically includes software in four major functional areas: \n ■  An application programming interface that offers the type of runtime functions described in earlier sec-\ntions of this chapter. It integrates these functions, thereby simplifying the environment in which appli-\ncations are programmed. Some of these functions may be directly implemented by the transactional \nmiddleware. Others may be offered by lower-level products, which the application server passes through \neither as functions in its integrated API or directly through system-level APIs. Some functions may be \ndeﬁ ned using attributes embedded in class deﬁ nitions, or as policies and conﬁ guration attributes of the \napplication execution environment. \n ■  Program development tools for building transaction programs, such as program templates for the main \napplication components, and smooth integration of its API into a particular programming language and \ndevelopment environment. \n ■  A system management interface and accompanying runtime functions to conﬁ gure a TP application for a \ndistributed system, deploy it, and then monitor and control its execution. \n ■  Integration with popular database management systems and front-end programs. \n Transactional middleware is a software framework or application execution environment in which applica-\ntion programs run and in which users interact with the computer system. The execution environment often is \ncalled a  container . The container ties together the underlying system components that are needed by all TP \napplications — multithreading, user interface services, communications system, operating system, and the data-\nbase system. It also may offer components of its own. For example, it may add transactional capability to the \nbuilt-in RPC mechanism or it may add two-phase commit, if these are absent from the operating system and/or \n database system. \n The container provides a single, smooth interface, so that developers and end users don’t need to deal with \neach of these components independently or learn multiple low-level APIs (see  Figure 3.8 ). Instead of writing \napplication programs that talk independently to the forms system, web server, operating system, communication \nRequest control\nfunctions\nTransactional\ncommunications\nTwo-phase\ncommit\nTransactional middleware API\nOther\ncommunication\nservices\nDatabase\nsystem\nservices \nOperating\nsystem\nabstractions\nSecurity\nservices \nUser\ninterface\nservices\nPolicy and\nconfiguration\nmetadata\n FIGURE 3.8 \n Transactional Middleware Container. The transactional middleware container provides services, such as request \nmanagement, transactional communications, and two-phase commit. Its container provides a single abstraction to \napplication programmers and system managers. \n3.6 Transactional Middleware  93\n\n\n94  CHAPTER 3 Transaction Processing Application Architecture\n system, and so on, the programmer writes an application using a single interface that talks to the transactional \nmiddleware. \n Some transactional middleware systems integrate their runtime functions with a particular programming \nlanguage. A notable example of this is Java EE, which consists of Java classes that encapsulate the applica-\ntion server’s functionality. Older examples of the language-speciﬁ c approach developed in the 1980s are HP’s \nScreen COBOL and Task Deﬁ nition Language (see also Section 3.4). \n Other transactional middleware products offer language-independent runtime functions. IBM’s CICS is \none example of this approach, introduced in the late 1960s and still widely used. A more recent example is \nMicrosoft’s .NET Framework, where runtime functions are available in all .NET languages. There is a trend \ntoward exposing transactional middleware features as extensions to the normal development experience, rather \nthan making them available only in a closed development environment. \n Java EE-based application servers are  portable in the sense that they run on a variety of  platforms , or \noperating systems (e.g., Windows, IBM mainframes, and many ﬂ avors of UNIX); they support the same APIs \non these platforms; and they integrate with multiple database systems and front-end programs. Thus, TP appli-\ncations can usually be ported from one Java EE application server to another with moderate effort. \n Interoperability is the ability of programs to participate as part of the same application. Programs may \nﬁ nd it hard to interoperate because they were independently developed in different languages, with incompat-\nible interfaces, and using incompatible data types. Or interoperations may be difﬁ cult because they run on dif-\nferent machines with different underlying platforms. This latter issue requires that there are implementations \nof the same protocols on the machines for communication, two-phase commit, and other shared functions. \n Interoperability can be achieved by running instances of the same application server on different machines \nthat run different platforms or by using application servers that support the same protocol. For example, \ntwo RPC protocols that are in common use by different application servers are RMI/IIOP and SOAP/HTTP. \nSometimes, interoperability is sacriﬁ ced by offering custom features, by disabling features of an interoperability \nstandard, or by using nonstandard protocols for better performance. For example, some platforms implement a \ncustom two-phase commit protocol that has special features and better performance than standard protocols. \n System management functions include load balancing, fault monitoring and repair, performance monitor-\ning and tuning, and the ability to change the conﬁ guration by creating and destroying processes, creating and \ndestroying communication sessions, and so on. For example, the transactional middleware may store a descrip-\ntion of which server processes are running on which machines. Instead of just telling the system manager that \nan operating system process has failed, the transactional middleware might say that the bank’s loan server pro-\ncess has failed, thereby giving the system manager a better idea of where the problem is and what to do about \nit. It may also automate recovery by creating a new copy of the failed process on another machine that has spare \ncapacity. System management functions also are required to set up and maintain security information to protect \naccess to displays and to ensure that only authorized users can access sensitive transaction control programs. \nThese kinds of system management functions often are provided for TP applications by generic system man-\nagement tools, such as CA’s Unicenter, IBM’s Tivoli, and HP’s OpenView. \n The transactional middleware also provides some application development tools to make it easier to write \nthe code for each of the components of a multitier architecture. We’ll describe examples of program develop-\nment in Chapter 10. \n 3.7  DATABASE SERVERS VERSUS TRANSACTIONAL MIDDLEWARE \n A database server is a relational database system that runs as a multithreaded server. It supports stored proce-\ndures that can be invoked by an RPC-like protocol. And, of course, it supports transactions. It therefore offers \n\n\n many of the main features of transactional middleware. It’s interesting to compare database servers to transac-\ntional middleware, to see where these two technologies are similar and different. \n Stored procedures are written in either a proprietary version of SQL or a general-purpose programming \nlanguage, and can issue SQL requests to the database system, just like a transaction server running in an appli-\ncation server. Thus, a request controller can directly call stored procedures, instead of ﬁ rst calling a transaction \nserver, which in turn calls a database server. Said differently, the transaction server application can be written \nas a stored procedure. In fact, the request controller application can be written as a stored procedure too. \n Figure 3.9 shows the process structure of transactional middleware and database servers. Most relational \ndatabase systems today offer this database server structure, including those from IBM, Oracle, Sybase, and \nMicrosoft. So why might one buy a transactional middleware product if the database server supports most of \nthe facilities that we’ve been discussing in this chapter? \n One reason is scalability. In a multitier system running under transactional middleware, if a machine becomes \noverloaded, one can simply reassign request controller and transaction server processes to another machine. \nToday, this isn’t very easy with most database servers, because the application runs in the same process and \ntherefore on the same machine as the database server. Spreading the workload across multiple database servers \nrequires a request controller outside the database servers to distribute the load and to multiplex sessions across \na large number of users (see Section 2.6,  Scaling Out a System ). We expect this scalability advantage of trans-\nactional middleware will decrease over time as database servers add more functionality to support partitioning \nand scalable data sharing. The capabilities of web servers also are growing, however, and are increasingly being \nused to route requests directly to a database on behalf of a web browser client. \n Like scalability, the issues that distinguish transactional middleware from database servers are changing with \neach new product release, so any list of feature distinctions we give here would be quickly outdated. However, \nwe can identify general areas where functionality differences often are found. The main ones are as follows: \n ■  Choice of programming language: Some database servers offer a more limited set of programming \nlanguages for stored procedures than application servers offer for transaction servers. And even when \nFront-end\nprogram\nRequest\nController\nTransaction\nServer\nRelational\nDBMS\nClient\nDatabase Server\nTransactional\nMiddleware\nConfiguration\nDatabase Server\nConfiguration\nRelational\nDBMS\nStored\nprocedures\n FIGURE 3.9 \n Transactional Middleware and Database Server Conﬁ gurations. The database server architecture eliminates the request \ncontroller layer of the transactional middleware. \n3.7 Database Servers Versus Transactional Middleware  95\n\n\n96  CHAPTER 3 Transaction Processing Application Architecture\n database servers support standard languages, they impose restrictions to ensure compatibility with the \ndatabase software. \n ■  Implicit transaction bracketing: Many database servers require explicit bracketing of transactions using \nStart, Commit, and Abort, rather than allowing components to be tagged with transaction attributes, such \nas Requires New, Required, and Supported. The explicit bracketing of transactions makes it more difﬁ -\ncult to compose them. \n ■  Transports: A TP system can offer both secure and reliable transport (written to a journal) between client \nand server. Most database systems don’t offer this. \n ■  Debugging: Some database servers offer weaker debugging and development tools than are available in \na general-purpose program development environment. The latter are usually fully available when using a \ntransaction server. \n ■  Interoperable distributed transactions: Most database servers offer distributed transactions with two-\nphase commit. However, they often do not offer distributed transactions across database servers from dif-\nferent vendors and other transactional resource managers, such as record-oriented ﬁ le systems and queue \nmanagers. This usually requires a two-phase commit protocol implemented by transactional middleware \nor the underlying platform. \n ■  Communications efﬁ ciency: Some database server protocols are more efﬁ cient for pipelined transfer of \nlarge data sets than transactional middleware protocols. \n ■  Protocol support: Application processes running with transactional middleware can use all platform-\nsupported protocols. By contrast, some database servers have limited protocol support. For example, \nthey may not support HTTP, so remote requests to a database server need to pass through an application \nprocess, such as a web server. \n ■  Multitransaction workﬂ ow: Some transactional middleware products have more functionality than data-\nbase servers in support of multitransaction workﬂ ows, such as the ability to conﬁ gure resource depen-\ndencies and transactional compositions. \n ■  System management: Some transactional middleware products offer a richer system management envi-\nronment than a database server offers. For example, it may allow prioritization of applications, applica-\ntion-based load control, remote name resolution, geographical entitlement, or application-based security. \n Over the past decade, the functionality gap between database servers and transactional middleware has been \ngetting smaller. Only time will tell whether this trend will continue or transactional middleware will add func-\ntionality fast enough to stay ahead of database servers for decades to come. \n 3.8  SUMMARY \n The processing of simple requests involves receiving a request, routing it to the appropriate application pro-\ngram, and then executing it. This activity usually is distributed across components of a multitier architecture, \nconsisting of the following: \n ■  Front-end programs, for interaction with an end user or special device \n ■  Request controllers, for routing a request to the correct transaction program \n ■  Transaction servers, to do the work necessary to fulﬁ ll the request, usually involving accesses to transac-\ntional resources, such as databases, and typically returning results to the caller \n\n\n This architecture is aligned with service-oriented architecture, by mapping services to transaction servers, and \nwith object-oriented design, by mapping business objects to transaction servers. \n The front-end program is responsible for interacting with the end user via menus and forms, gathering \ninput for the transaction request and the name of the transaction to be executed. After gathering input, the \nfront-end program constructs the request message and sends it to the request controller. The front-end program \nneeds a suitably secure connection to the request controller, optionally using geographical entitlement to check \nthat the user is authorized for the speciﬁ c device. Currently, the most popular technology for these functions is \nthe web browser running on the end user’s device, communicating with a web server that executes many of the \nfront-end program’s functions. When money or personally identiﬁ able information is involved, the connection \nbetween web browser and web server often is enabled by use of Transport Layer Security. \n The main goal of the request controller is routing. It decodes the request message, determines the location of \nthe transaction program to be called, and makes the call. The request controller brackets the transaction that exe-\ncutes the request. Its application code is structured to solve the transaction composability problem using what-\never mechanisms are available from the underlying middleware or platform. It ensures that each request is not \nlost if its corresponding transaction aborts. It typically runs in a multithreaded process, often partitioning front-\nend sessions by request controller for scalability. It also bridges the per-user security model of the front ends \nwith the process-oriented authorization model that usually is needed for communication with back ends. \n The transaction server executes program logic to fulﬁ ll the request, such as retrieve data from a database \nor update data with new values provided by the request. It usually is implemented as a multithreaded process, \nwhich in turn communicates with multithreaded database servers using pooled database sessions. \n Transactional middleware products provide APIs, development tools, system management tools, and integra-\ntion with popular database systems and front-end programs. Transactional middleware products typically pro-\nvide an abstraction called a container that helps TP application developers handle the complexities of transaction \nmanagement and low-level operating system functions such as multithreading, communications, and security. \n Many functions previously performed only by transactional middleware products are now features of data-\nbase servers. Transactional middleware products still provide features that database servers don’t yet have, such \nas request routing, server classes, transactions distributed across multiple types of resource managers, compos-\nable transactions by setting transaction attributes, and certain system management and administrative functions \nfor TP applications programs and systems. However, database servers are suitable for many applications and \ntheir range of applicability is growing. \n \n3.8 Summary  97\n\n\nThis page intentionally left blank\n",
      "page_number": 105
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 117-125)",
      "start_page": 117,
      "end_page": 125,
      "detection_method": "topic_boundary",
      "content": " 4.1  WHY USE QUEUES? \n In direct transaction processing, a client sends a request to a server and synchronously waits for the server to \nrun the transaction and reply. For example, using RPC, the client sends a request to the system as an RPC, \nwhich returns with a reply indicating whether or not the transaction ran. \n Even though this direct TP model is widely used in practice, it has some limitations (see  Figure 4.1 ). The \nﬁ rst problem is dealing with the failure of a server or of client-server communications, which prevents a client \nfrom communicating with the server. If a client sends a request to this server, it immediately receives an error \ntelling it that the server is down or disconnected and therefore is unable to receive the request message. At this \npoint, either the client is blocked, waiting for a server to become available, or the user has to return later and \nresubmit the request to the client. A desirable alternative, which is not possible in direct TP, is simply to ask that \nthe request be sent as soon as the server is available, without the user or client being required to wait on-line for \nthe server to do so. For example, the user might want to log off and come back later to get the reply. \n The second problem is the inverse of the ﬁ rst. The client may successfully send the request to the server. \nBut the server, after executing the transaction, may be unable to send a reply to the client, because the client \nfailed, client-server communications failed, or the server failed after completing the transaction and before \nsending the reply. In each of these failure cases, the server’s reply may be lost. So even after the failed com-\nponent has recovered, the client still may not receive a reply. It therefore doesn’t know whether its last request \nactually ran, and hence whether it should resubmit the request. \n The ﬁ rst or second problem could occur due to failed communications between the client and server. \nSuppose the client sends the request to the server and does not receive an immediate error. What does it do if \nit does not receive a reply in a timely manner? It cannot tell whether the original request failed to be delivered \nto the server due to a communication failure or server failure, or the request was delivered to the server but the \nreply failed to be delivered back to the client. Under the circumstances, it is hard to imagine how the system \ncould be programmed to execute each request exactly once, which is usually the behavior that’s desired. \n A third issue is load balancing. In direct TP, if there is a pool of servers that can handle a client’s request, \nthen the mechanism for binding a client to a server must select one of the servers from the pool. As discussed \nin Section 2.3,  Server Classes , one approach is to randomize the selection of a server, so on average, the same \nnumber of clients are connected to each server. However, this randomization is just a guess. At any given \nmoment, the actual load may not be equally balanced among the servers. That is, one server could receive \nmany requests requiring a lot of work and thereby become overloaded. At the same time, other servers may not \n Queued Transaction Processing \n 4 \nCHAPTER\n\n\n100  CHAPTER 4 Queued Transaction Processing\n be receiving any requests at all. When the variance in workload is high, this type of situation is rather likely, \nleading to poor response time for some clients some of the time. \n Finally , this whole model is based on ﬁ rst-come, ﬁ rst-served scheduling of requests. There’s no sense of \npriority in the system in which high priority requests are processed early and low priority requests are delayed \nuntil later. \n We are using the term  “ client ” here because it’s more architecturally neutral than front-end program or web \nserver. The issues of interest apply to any program that is outside the TP system and submitting requests to run \ntransactions, rather than being a participant in the transaction itself. \n Queues as the Solution \n These problems are solved by using a queue as a buffer for requests and replies between the client and \nthe server (see  Figure 4.2 ). Instead of sending a request directly to the server, a client sends it to a queue. And the \nserver receives those requests from the queue, instead of receiving them directly from the client. Similarly, the \nserver sends replies to a queue, and the client receives replies from the queue. \na. Server down\nb. Client down\nc. Unbalanced Load\nServer\nRequest\nRequest\nUrgent\nRequest\nRequest\nServer2\nServer3\nRequest\nRequest\nRequest\nServer1\nRequest\nRequest\nRequest\nRequest\nd. First-come first-served\nServer\ndown\nRequest\nClient\nClient\nReply\ndown\nServer\n FIGURE 4.1 \n Problems with Direct TP. (a) Sending a request to a down server. (b) Sending a reply to a down client. (c) Balancing the \nrequest load across many servers. (d) Scheduling requests. \nClient\nEnqueue\nDequeue\nServer\nQueue\n FIGURE 4.2 \n Queued Transaction Model. In queued TP, clients send requests to queues, and servers receive requests from queues. \nThis is in contrast to direct TP, where clients send requests to servers. \n\n\n The queue is a transactional resource. So operations on the queue are made permanent or undone, depend-\ning on whether the transaction that issued the operations commits or aborts. Usually, the queue is persistent \nand is stored on disk or some other nonvolatile storage device. \n This queued TP model solves the problems that we just listed. First, a client can send a request even if it \nis targeted for a server that is busy, down, or disconnected, as long as the queue is available. The client simply \nstores the request in the queue. If the server is available, it can execute the request right away. Otherwise, when \nthe server becomes available, it can check the queue and run requests that were submitted while it was down. \n Second , a server can send a reply to a client even if the client is down or disconnected, as long as the client’s \nreply queue is available. The server simply sends the reply to the queue. When the client recovers or is recon-\nnected to the system, it checks the queue to ﬁ nd any reply messages that are waiting. \n By using queues to capture requests and replies, we can implement exactly-once execution of requests. \nFor each request that a client submits, the client can tell whether the request is waiting to be processed (in the \nrequest queue), executing (absent from both queues), or processed (in the reply queue). There are some corner \ncases that need attention, but with queues an implementation of exactly-once execution seems within reach. \nWe will work out the details in Sections 4.2 and 4.3. \n Third , as shown in  Figure 4.3 , many servers can be receiving requests from the same queue, thereby balanc-\ning the load across many servers. This load balancing is fully dynamic. As soon as a server ﬁ nishes processing \none request, it can take another request from the queue. There is never a time when one server is overloaded \nwhile another is idle. \n Fourth , queues can be used for priority-based scheduling. Each request can be tagged with a priority, which \nis used to guide the scheduling strategy. For example, each server can dequeue requests highest-priority-ﬁ rst. \nAlternatively, to ensure low priority requests are given some service, one server can be given the job of servic-\ning low-priority requests while all other servers use highest-priority-ﬁ rst. Or each request’s priority could be \nset to be its deadline, and requests are processed in deadline order. Requests can also be scheduled manually, \nby collecting them in a queue and running them under operator control. Once there is a queue in the picture, \nthere is great ﬂ exibility in controlling the order in which requests are processed. \n A queue is also useful as an intermediary between a back-end system and a remote service, for many rea-\nsons. It can buffer the effect of network delays. It can be used to localize credentials for accessing the remote \nservice. It can be a protocol bridge by supporting different protocols for remote and local access. And it is a \nconvenient place for auditing and performance measurement of the remote service. \n This is a long list of beneﬁ ts for such a relatively simple mechanism. For this reason most transactional mid-\ndleware products and even some database systems support queues as one way of moving requests and replies \nClient\nEnqueue\nDequeue\nServer\nServer\nQueue\nClient\n•\n•\n•\n•\n•\n•\n FIGURE 4.3 \n Load Balancing Using Multiple Servers. When a server ﬁ nishes processing one request, it takes another request from the \nqueue. This dynamically balances the load across all servers. \n4.1 Why Use Queues?  101\n\n\n102  CHAPTER 4 Queued Transaction Processing\n between clients and servers. Usually, queues sit between the front-end program and the request controller, as \nshown in Figure 3.1. Since queues can be used in other parts of a system, in the rest of this chapter we will use \nthe more general client-server terminology, instead of front-end program and request controller terminology. \nHowever, to be concrete, you can think about it in the latter setting without being misled. \n 4.2  THE QUEUED TRANSACTION PROCESSING MODEL \n Server’s View of Queuing \n Let ’s look at how the queued TP model works in the context of a transaction from a server’s perspective. As in \nour description of direct TP in previous chapters, we will assume that each request is asking for just one trans-\naction to be executed. In the queued TP model, the server program starts a transaction and dequeues the next \nrequest from the request queue (see  Figure 4.4 ). The server then does the work that the request is asking for, \nenqueues the reply to the reply queue, and commits. \n Since these queues are transactional resources, if the transaction aborts, the dequeue operation that receives \nthe request is undone, thereby returning the input request to the request queue. If the abort happens at the very \nend, then the enqueue operation to the reply queue also is undone, thereby wiping out the reply from the reply \nqueue. Therefore, whenever the client checks the queues, either the request is in the request queue, the reply is \nin the reply queue, or the request can’t be checked because it is currently being processed. In any case, there’s \nnever any ambiguity as to the request’s state. It either has not yet been processed, is in the midst of being pro-\ncessed, or has been completed. \nStart\n    Dequeue (Request queue)\nprocess request\n    Enqueue (Reply queue)\nCommit\nRequest queue\nReply queue\n FIGURE 4.4 \n Managing a Queued Request within a Transaction. The request is dequeued and the reply enqueued within a transaction. \nIf the transaction aborts, the request isn’t lost. \n\n\n Client’s View of Queuing \n In  Figure 4.4 we looked at the queues from the server’s viewpoint. Now let’s look at the entire path from the \nclient to the server in the queued TP model. In this model, each request executes three transaction programs (see \n Figure 4.5 ). Transaction 1 (Submit Request) receives input from the user, constructs a request, enqueues that \nrequest onto the request queue, and then commits. Then Transaction 2 (Execute Request) runs, just as described \nin  Figure 4.4 : It starts a transaction, dequeues the request, processes the request, enqueues the reply, and com-\nmits. At this point, the request is gone from the request queue, and the reply is sitting in the reply queue. Now, \nTransaction 3 (Process Reply) runs: It starts a transaction, dequeues the reply from the reply queue, translates \nthe reply into the proper output format, delivers that output, and commits, thereby wiping out the reply from the \nreply queue. \n For example, to run a debit transaction, the client runs a transaction that enqueues a request on the request \nqueue. The debit server runs a transaction that dequeues the request, debits the account, and enqueues a reply \nthat conﬁ rms the debit. Later, the client runs a transaction to dequeue the reply and print a receipt. By contrast, \nif direct TP were used, the client would send the request directly to the server, and the server would send the \nreply directly to the client, all within one transaction and without any queues in between. \n In  Figure 4.5 the client pushes a request to the queue while the server pulls it from the queue. If desired, \nthe server (Transaction 2) can be turned into a push model by adding a dispatcher component that starts a \ntransaction, dequeues the request, calls the rest of the Transaction 2 code (i.e., starting with  “ process request ” \nin  Figure 4.5 ), and, after the latter ﬁ nishes, commits. \n Because the queues are now under transaction control, they have to be managed by a database system or \nsome other resource manager that supports transaction semantics. To optimize performance, TP systems often \nTransaction 1: //submit request\nStart\nget input\nconstruct request\n   Enqueue (request queue)\nCommit\nTransaction 3: //process reply\nStart\nDequeue (reply queue)\nDecode reply\nprocess output\nCommit\nClient\nTransaction 2: //execute request\nStart\nDequeue (request queue)\nprocess request\n   Enqueue (reply queue)\nCommit\nServer\nRequest\nqueue\nReply\nqueue\n FIGURE 4.5 \n Running a Request as Three Transactions. The client submits a request (Transaction 1), the server processes the request \nand returns a reply (Transaction 2), and the client processes the reply (Transaction 3). \n4.2 The Queued Transaction Processing Model  103\n\n\n104  CHAPTER 4 Queued Transaction Processing\n use a specialized queue manager that is tuned for the purpose. Today’s transactional middleware products typi-\ncally provide an API to an external queued messaging system that supports transaction semantics. \n Notice that to run even a single request, the system executes three transactions. The client transactions may \nbe rather lightweight, as transactions go. For example, in the simple case of  Figure 4.5 , they each do one access \nto a transactional resource, that is, a queue. But even so, queued TP uses more system resources than an ordinary \ndirect TP system in which each request runs as a single transaction. Not only are there two client transactions, \nbut the server transaction has two additional accesses to transactional resources — the request and reply queues. \nIn return for this extra overhead, the system offers the beneﬁ ts that we talked about previously; that is, communi-\ncation with unavailable servers and clients, load balancing across servers, and priority-based scheduling. \n 4.3  CLIENT RECOVERY \n An important reason to use queuing instead of direct TP is to address certain client and server failure situa-\ntions. In this section, we systematically explore the various failure situations that can arise. We do this from a \nclient’s perspective, to determine what a client should do in each case. \n We will assume the request-reply model of  Figure 4.5 . That is, a client runs Transaction 1 to construct and \nsubmit a request, and later runs Transaction 3 to receive and process the reply. Its goal is to get exactly-once \nbehavior; that is, that Transaction 2 executes exactly once and its reply is processed in Transaction 3 exactly once. \n Let us assume that there is no failure of the client, the communications between the client and the queues, \nor the queues themselves. In this case, the client’s behavior is pretty straightforward. It submits a request. Since \nthere are no failures between the client and the request queue, the client receives an acknowledgment that the \nrequest is successfully enqueued. The client then waits for a reply. If it is waiting too long, then there is presum-\nably a problem with the server — it is down, disconnected, or busy — and the client can take appropriate action, \nsuch as sending a message to a system administrator. The important point is that there is no ambiguity about the \nstate of the request. It’s either in the request queue, in the reply queue, or being processed. \n Suppose the client fails or loses connectivity to the queues, or the queues fail. This could happen for a vari-\nety of reasons, such as the failure of the client application or machine, the failure of the machine that stores the \nqueues, a network failure, or a burst of trafﬁ c that causes one of these components to be overloaded and there-\nfore unresponsive due to processing delays. At some point, the failed or unresponsive components recover and \nare running normally again, so the client can communicate with the queues. At this point the client needs to run \nrecovery actions to resynchronize with the queues. What exactly should it do? \n To keep things simple, let’s assume that the client processes one request at a time. That is, it processes the \nreply to each request before it submits another request, so it has at most one request outstanding. In that case, at \nthe time the client recovers, there are four possible states of the last request it submitted: \n A.  Transaction 1 did not run and commit. Either it didn’t run at all, or it aborted. Either way, the request was \nnot submitted. The client should resubmit the request (if possible) or else continue with a new request. \n B.  Transaction 1 committed but Transaction 2 did not. So the request was submitted, but it hasn’t executed \nyet. The client must wait until the reply is produced and then process it. \n C.  Transaction 2 committed but Transaction 3 did not. The request was submitted and executed, but the \nclient hasn’t processed the reply yet. The client can process the reply right away. \n D.  Transaction 3 committed. The request was submitted and executed, and the client already processed the \nreply. So the client’s last request is done, and the client can continue with a new request. \n To determine what recovery action to take, the client needs to ﬁ gure out which of the four states it is in. \n\n\n If each client has a private reply queue, it can make some headway in this analysis. Since the client pro-\ncesses one request at a time, the reply queue either is empty or has one reply in it. So, if the reply queue is \nnonempty, then the system must be in state C, and the client should go ahead and process the reply. If not, it \ncould be in states A, B, or D. \n To disambiguate these states, some additional state information needs to be stored somewhere. If the client \nhas access to persistent storage that supports transaction semantics, it can use that storage for state informa-\ntion. The client marks each request with a globally-unique identiﬁ er (ID) and stores the request in persistent \nstorage before enqueuing it in the request queue (see LastRequest in Transaction 0 in  Figure 4.6 ). In persistent \nstorage the client also keeps the IDs of the last request it enqueued and the last reply it dequeued, denoted \nLastEnqueuedID and LastDequeuedID, respectively. It updates these IDs as part of transactions 1 and 3 that \nenqueue a request and dequeue a reply, as shown in  Figure 4.6 . In that ﬁ gure, the expression R.ID denotes the \nID of request R. \n At recovery time, the client reads LastRequest, LastEnqueuedID, and LastDequeuedID from persistent \nstorage. It uses them to analyze the state of LastRequest as follows: \n ■  If LastRequest.ID  \u0002 LastEnqueuedID, then the system must be in state A. That is, the last request that the \nclient constructed was not successfully submitted to the request queue. Either the client failed before run-\nning Transaction 1, or Transaction 1 aborted because of the client failure or some other error. The client\ncan either resubmit the request or delete it, depending on the behavior expected by the end user. \n   Dequeue (Request queue)\n   process request\n   Enqueue (Reply queue)\nCommit\nTransaction 2: //Execute Request\nStart\nR \u0005 Dequeue (Reply queue)\ndecode reply\nprocess output\nCommit\nTransaction 3: //Process Reply\nStart\nLastDequeuedID \u0005 R.ID\nTransaction 1: //Submit Request\nStart\nR \u0005 LastRequest\nEnqueue (Request queue, R)\nCommit\nLastEnqueuedID \u0005 R.ID\nget input\nTransaction 0: //Create Request\nStart\nconstruct request R\nCommit\nLastRequest \u0005 R\nRequest queue\nReply queue\nClient\nServer\n FIGURE 4.6 \n Client Maintains Request State . The client stores the ID of the last request it enqueued and the last reply it dequeued, in \nTransactions 1 and 3, respectively. \n4.3 Client Recovery  105\n\n\n106  CHAPTER 4 Queued Transaction Processing\n ■  If LastRequest.ID  \u0005  LastDequeuedID, then the client dequeued (and presumably processed) the reply \nto the last request the client submitted, so the system is in state D. In this case, the request ID has helped \nthe client match up the last request with its reply, in addition to helping it ﬁ gure out which state it is in. \n ■  If the reply queue is nonempty, the client should dequeue the reply and process it (i.e., state C). Notice \nthat in this case, LastRequest.ID  \u0005  LastEnqueuedID and LastRequest.ID  \u0002 LastDequeuedID, so the \nprevious two cases do not apply. \n ■  Otherwise, the client should wait until the reply appears before dequeuing it (i.e., state B). \n This recovery procedure assumes that the client uses a persistent storage system that supports transaction \nsemantics. This is a fairly strong assumption. The client may not have such storage available. Even if the client \ndoes have it, the application developer may want to avoid using it for performance reasons. That is, since the \nqueue manager and persistent storage are independent resource managers, the two-phase commit protocol is \nneeded for Transactions 1 and 3, which incurs some cost. \n This cost can be avoided by storing the state information in the queue manager itself. For example, the \nclient could store LastEnqueuedID and LastDequeuedID in a separate queue dedicated for this purpose. \nAlternatively, the queue manager could maintain LastEnqueuedID and LastDequeuedID as the state of a persis-\ntent session between the client and the queue manager. The client signs up with the queue manager by opening \na session. The session information is recorded in the queue manager’s persistent storage, so the queue manager \ncan remember that the client is connected. If the client loses connectivity with the server and later reconnects, \nthe queue manager remembers that it already has a session with the client, because it is maintaining that infor-\nmation in persistent storage. So when the client attempts to reconnect, the system re-establishes the existing \nsession. Since the session state includes the request and reply IDs, the client can ask for them as input to its \nrecovery activity. \n The recovery scenario that we just described is based on the assumption that the client waits for a reply to \neach request before submitting another one. That is, the client never has more than one request outstanding. \nWhat if this assumption doesn’t hold? In that case, it is not enough for the system to maintain the ID of the last \nrequest enqueued and the last reply dequeued. Rather, it needs to remember enough information to help the cli-\nent resolve the state of all outstanding requests. For example, it could retain the ID of every request that has not \nbeen processed and the ID of the last  n replies the client has dequeued. Periodically, the client can tell the queue \nmanager the IDs of recently dequeued replies for which it has a persistent record, thereby freeing the queue \nmanager from maintaining that information. Many variations of this type of scheme are possible. \n This scenario assumes that after a client processes a reply, it no longer needs to know anything about that \nrequest’s state. For example, suppose a client runs two requests. It submits Request 1 , the server processes \nRequest 1 and sends Reply 1 , and the client processes Reply 1 . Then the client submits Request 2 , the server pro-\ncesses Request 2 and sends Reply 2 , and the client processes Reply 2 . At this point, the client can ﬁ nd out about \nthe state of Request 2 , but not about Request 1 , at least not using the recovery procedure just described. \n Finding out the state of old requests is clearly desirable functionality. Indeed, it’s functionality that we often \ndepend on in our everyday lives, such as ﬁ nding out whether we paid for a shipment that hasn’t arrived or \nwhether we were credited for mileage on an old ﬂ ight. However, this functionality usually is not offered by a \nqueuing system or queued transaction protocols like the ones we have been discussing. Rather, if it is offered, \nit needs to be supported by the application as another transaction type — a lookup function for old requests. \nTo support this type of lookup function, the application needs to maintain a record of requests that it already \nprocessed. In ﬁ nancial systems, these records are needed in any case, to support the auditability required by \naccounting rules. However, even when they’re not required, they’re often maintained as a convenience to \ncustomers. \n\n\n 4.4  HANDLING NON-UNDOABLE OPERATIONS \n Although the analysis of the previous section appears to cover all the cases, it still leaves one problem open if \nthe system is in state C, namely how to handle the statement  “ process output ” in Transaction 3 if Transaction \n3 aborts. There are three cases to consider, depending on whether the process-output statement is undoable, is \nidempotent, or has neither of these properties. \n If the process-output statement is an undoable operation, then there is no problem. If Transaction 3 aborts, \nthen process-output is undone, just like any database operation. For example, this would be the behavior if pro-\ncess-output involves only recording the execution of the request in transactional persistent storage. \n If the process-output statement is idempotent, then again there is no problem. The operation does not need \nto be undone by an abort of Transaction 3. When Transaction 3 re-executes, it re-executes the process-output \nstatement, which is safe to do if the statement is idempotent. For example, this would be the case if process-\noutput involves printing a receipt that has a unique identiﬁ cation number that is linked to the request. There is \nno harm in executing it twice, since it would generate two identical receipts. It would be a bit confusing to the \nrecipient, but it might be acceptable since there is enough information to recognize the two receipts as dupli-\ncates of each other. \n Often , the process-output statement is neither undoable nor idempotent. For example, this typically arises \nwhen processing the output involves asking a physical device to perform some action in the real world, such \nas dispensing money. As we observed in Chapter 1, it isn’t clear whether this operation should be done before \nor after the transaction commits. If the operation is done before the transaction commits, but the transaction \nactually aborts, then the operation can’t be undone, as it should be. And it is unsafe to run the operation again \nwhen Transaction 3 re-executes, because the operation is not idempotent. On the other hand, if the operation is \ndone after the transaction commits, but a failure happens after the transaction commits and before the opera-\ntion executes, then the operation is lost. \n To solve this problem, the process-output statement must be operating on a device that has  testable state . \nThis means that it must be possible for Transaction 3 to read the state of the physical device, and the physical \ndevice must change its state as a result of performing the operation required by the process-output statement. \nThat way, the transaction can record the device’s state before it performs the operation and can determine if \nthe operation ran by comparing the device’s current state to the value it recorded. For example, the transaction \nmight read the check number that is to be printed next. After printing the check, the transaction would read a \ndifferent number for the new check sitting under the print head. If it reads the same number for the check, then \nit knows the printing operation did not execute. \n Given that this device state is available, the transaction that processes replies should follow the process-a-\nreply transaction shown in  Figure 4.7 . To see why this works, suppose the client is recovering from a failure \nand through the previous analysis determines that it is in state C. It should therefore process the reply by run-\nning the process-a-reply transaction. If this is its ﬁ rst attempt at processing the reply, then there is no earlier \nlogged device state for this reply, so the transaction performs the device operation and commits. Otherwise, \nin step (3) it determines whether it’s safe to rerun the device operation associated with this reply. If the state \nof the device has changed since the previous attempt to run the transaction, then the device operation for this \nreply appears to have executed, so it is  not safe. At this point, the operator must get involved to determine what \nreally happened. For example, did the check really get printed, or was it destroyed by the device, which caused \nthe previous execution of the reply-processing transaction to abort after logging the device’s state in step (4)? \nIn the latter case, the operator has to tell the current execution of the process-a-reply transaction whether it’s \nsafe to reprint the check. \n A clever technique for logging the device’s state is to read the device state  before dequeuing the reply (i.e., \nbefore step (2) in  Figure 4.7 ) and to attach the device state to the log record for the dequeue operation. Since \n4.4 Handling Non-Undoable Operations  107\n",
      "page_number": 117
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 126-138)",
      "start_page": 126,
      "end_page": 138,
      "detection_method": "topic_boundary",
      "content": "108  CHAPTER 4 Queued Transaction Processing\n the queue manager has to log the dequeue operation anyway (since it might have to undo it), it can log the \ndevice state at the same time and thereby do one write to the log, instead of two. \n There is one case where step (3) is not needed — if the device’s operation is idempotent. For example, sup-\npose the operation causes a robot arm to move to a certain position, or suppose it sends a mail message describ-\ning the transaction. In these cases, there may be no harm in executing the operation a second time. That is, the \noperation is idempotent. So there is no reason to log the state of the device and recheck it in steps (3) and (4). \n Sometime , an operation that is not normally idempotent can be made idempotent. This is important when it isn’t \npossible to read the current state of the device. For example, sending a mail message that says  “ you just bought \n100 shares of IBM ” is not idempotent. If you issued one request to buy 100 shares and got back two acknowl-\nedgment messages like this, you would be worried whether your request executed once or twice. Moreover, at \nrecovery time, there is no device state that the client can read to tell if the message was sent. However, if the mail \nmessage says,  “ your request, with conﬁ rmation number 12345, to buy 100 shares of IBM, has executed, ” there’s \nno harm in sending it twice. You would recognize the second message as a duplicate and ignore it. \n 4.5  THE QUEUE MANAGER \n To support a queuing model, the system needs a  queue manager that stores and manages queues. A queue \nmanager is a lot like a database system. It supports the storage abstraction of a queue store. The queue store \ncan be a conventional relational database system or a custom storage system designed speciﬁ cally for queue \nmanagement. Within a queue store, the queue manager supports operations to create and destroy queues and \nmodify a queue’s attributes (e.g., owner, maximum size, queue name, user privileges). Most importantly, it \nsupports operations on messages in queues. \n Operations on Queued Messages \n The main operations on messages are enqueue and dequeue. The queue manager should also support opera-\ntions to examine a queue, such as to determine if it’s empty, and to scan a queue’s messages one by one without \nTo Process a Reply:\n1.   Start a transaction\n2.   Dequeue the reply\n3.   If there is an earlier logged device state for this reply\n      and it differs from the current device state\n      then ask the operator whether to abort this transaction\n4.   Log the current device state on persistent storage along\n      with the reply’s ID. This operation must be performed\n     whether or not the transaction commits\n5.   Perform the operation on the physical device\n6.   Commit\nReply queue\nread\nwrite\nread\nread\nwrite\nLog\n FIGURE 4.7 \n Client Procedure for Reply Processing. Step (3) determines if the reply has already been processed. Step (4) logs the \ndevice state, in case this transaction aborts and restarts, so it can run step (3) the next time around. \n\n\n dequeuing them. It might also support random access to messages in a queue; for example, to read or dequeue \nthe third message in the queue or a message with a speciﬁ c ID. \n Usually , the dequeue operation offers two options in dealing with an empty queue. If called with the non-\nblocking option, it returns with an exception that says the queue is empty. For example, this is useful if a \nserver is polling several queues and does not want to be blocked on an empty queue since another one may be \nnonempty. If called with the blocking option, the dequeue operation remains blocked until a message can be \nreturned. The latter is useful, for example, to dequeue a reply when it arrives. \n Generalized Messaging \n We have focused on using queued messages for the reliable processing of requests and replies. However, queu-\ning can be used for other kinds of messages too. That is, the enqueue and dequeue operations can be used to \nsend and receive arbitrary messages. This is a peer-to-peer messaging scenario, where the communicating par-\nties can exchange messages in a general application-deﬁ ned pattern, not just matched request-reply pairs. \n In this scenario, it is sometimes useful to use volatile queues. That is, the content of the queues do not sur-\nvive system failures. Volatile queues still offer many of the beneﬁ ts discussed in Section 4.1, such as load bal-\nancing, priority scheduling, and the ability to communicate with an unavailable server. \n Timeouts \n If a message remains in a queue for too long without being processed, it may need special attention. It is there-\nfore useful to be able to attach a timeout to a message. If the timeout expires before the message has been \ndequeued, then a timeout action is invoked, such as discarding the message or enqueuing the message on another \nqueue (e.g., an error queue) with a tag that explains the timeout. \n Handling Poisoned Messages \n Suppose a message has faulty content that causes an abort of the transaction that dequeues it. The abort will cause \nthe dequeued message to be returned to the queue. To avoid repeating this problem forever, a queue may have \na user-conﬁ gurable threshold of the maximum number of times a message can be dequeued. To avoid rejecting \na message due to a transient system problem, the queue may offer control over the minimum time between the \nretries. If the retry threshold is exceeded, the message is moved to an error queue for manual reconciliation. This \nmay be done by the application, queue manager, or dispatcher, depending on the implementation. \n Message Ordering \n The message in a queue may be ordered in a variety of ways, such as ﬁ rst-come, ﬁ rst-served, in which case an \nenqueue operation places the new message at the end of the queue, or highest-priority-ﬁ rst, in which case an \nenqueue operation places the new message before the ﬁ rst message in the queue of lower priority. \n Whatever the priority mechanism, the ordering is normally made fuzzy by the possible abort of a transac-\ntion that does a dequeue. For example, suppose transaction T 1 dequeues the ﬁ rst message M 1 from the queue \nand then T 2 dequeues the next message M 2 (see  Figure 4.8 ). If T 1 aborts, then its dequeue operation is undone, \nso M 1 is returned to the queue. However, T 2 might commit, in which case M 2 ends up being processed before \nM 1 , even though it should have been processed  after M 1 . \n To avoid this anomaly, T 2 should not be allowed to dequeue M 2 until after T 1 commits. For example, the \nqueue may be set to disallow concurrent dequeues. Unfortunately, this eliminates concurrency among transac-\ntions that dequeue from the same queue, in this case T 1 and T 2 , and therefore degrades performance. Since \nthis reduction in concurrency is only to prevent the relatively infrequent out-of-order dequeuing that results \nfrom an abort, most systems allow concurrent dequeue operations and ignore the occasional out-of-order \n4.5 The Queue Manager  109\n\n\n110  CHAPTER 4 Queued Transaction Processing\n dequeuing. However, in some applications, out-of-order processing is unacceptable, for example, for legal rea-\nsons. For example, in a stock trading system, orders submitted at the same price (to buy or sell) may be legally \nrequired to be processed in strict arrival order. To obey this rule and get satisfactory concurrency, trading sys-\ntems exploit the speciﬁ c semantics of the trading transactions themselves, for example, by batching up a set of \ntrades and committing them as a group (even though they were submitted separately). \n Filter Criteria \n Some queue managers offer clients the ability to dequeue messages based on their content. That is, rather than \nsimply dequeuing the oldest message, the client can dequeue the oldest message that has a particular value in \none of its content ﬁ elds. For example, the client might ﬁ rst dequeue a message with a ﬁ eld  “ importance ” equal \nto the value  “ high. ” If there are no such messages, then it could revert to dequeuing the oldest one. \n Nontransactional Queuing \n Most clients of the queue manager execute queue operations within a transaction. However, it is sometimes \ndesirable to execute operations as independent transactions, so the result is recorded whether or not the sur-\nrounding transaction aborts. A classic example is a security violation. Suppose a running transaction discovers \nthat the request it is executing is illegal — for example, it includes an illegal password. It is often important to \nrecord such violations, so they can be analyzed later to ﬁ nd patterns of security break-in attempts. The transac-\ntion can do this by enqueuing a security violation message on a special queue. Even if the transaction aborts, the \nsecurity violation should still be persistently recorded. Therefore, the operation to enqueue the security violation \nmessage should run as a separate transaction, which commits even if the transaction that called it aborts. \n Journaling \n Queued messages can provide a history of all the transactions that were executed by a TP system. Therefore, \nsome queue managers offer an option to save a description of all operations on messages in a journal. The \njournal may be useful for ﬁ nding lost messages or for auditing purposes; for example, to prove that certain \nmessages were submitted and/or processed, or to comply with government regulations, such as the Sarbanes-\nOxley Act. \n Queue Management \n A queue manager usually supports operations to start and stop a queue. Stopping a queue disables enqueue and \ndequeue operations. While the queue is stopped, these operations return an exception. This is a way of taking \na queue off-line, for example, if the server that processes its messages is down. It is also useful to enable and \nT1 dequeues M1\nT2 dequeues M2\nT2 commits\nT1 aborts (which returns M1 to the queue)\nT3 dequeues M1\nM1\nM2\n FIGURE 4.8 \n An Abort Destroys Priority Ordering. Although M 1  is dequeued before M 2 , since T 1  aborts, M 2  is processed before M 1 . \n\n\n disable enqueue and dequeue operations independently. For example, if a queue is full, enqueue operations can \nbe disabled so the queue will not accept any new work. \n Routing \n A queue manager usually supports ﬂ exible routing. For example, it may support queue forwarding, to move mes-\nsages from one queue to another. This is useful to reroute a client system’s input queue to another server system \nwhen the server is overloaded or down. It can also be used to save communications by batching up requests on \none system and sending them later in bulk to another system, rather than sending them one by one. Queue for-\nwarding involves reading one or more messages from one queue, moving them to the other queue, storing them \non disk, and then committing, thereby removing the messages from one queue and installing them on the other \nqueue as one transaction. \n A typical conﬁ guration that exploits queue forwarding is shown in  Figure 4.9 . The client can reliably enqueue \nrequests locally, whether or not the server system is available. Requests on the local queue can subsequently be \nforwarded to the server’s queue. The queue manager might offer an option to send an acknowledgment to the \nclient when the message reaches its ﬁ nal destination, in this case on System B, or when the transaction that \ndequeues the message has committed. \n The transaction to forward a request adds a fourth transaction to the three-transaction model and a ﬁ fth if \na reply is needed. Alternatively, a client could enqueue its requests directly to a server queue, without using a \nlocal queue as an intermediary. This saves the fourth transaction to forward the request and a ﬁ fth to return a \nreply. However, the client is unable to submit transactions when the remote queue is unavailable. Some prod-\nucts offer both queue forwarding and remote queuing. This allows a hybrid scheme, where the client enqueues \nto the remote server queue when it’s available, otherwise it uses a local queue. \n Of course, for a client to support a local queue, it needs a queue store. This requires additional hardware \nresources and system administration — the price to be paid for the additional availability. \n A queue manager may also support parameter-based routing, as was described in Section 2.6. This allows \na queue to be partitioned onto multiple systems for scale-out. It may also enable more ﬂ exible reconﬁ guration \noptions. For example, if a queue is overloaded, messages with certain parameter values can be directed to a more \nlightly loaded queue simply by changing the mapping of parameter values to queue names. \nEnqueue\nDequeue\nQueue\nQueue\nClient\nSystem A\nSystem B\nServer\n FIGURE 4.9 \n Forwarding with Local Enqueuing. The client enqueues requests to its local queue. Those requests are transparently \nforwarded to the server’s queue, where the server dequeues them locally. \n4.5 The Queue Manager  111\n\n\n112  CHAPTER 4 Queued Transaction Processing\n Dispatcher \n A queue manager usually includes a dispatcher, to support a push model as mentioned near the end of Section \n4.2. Instead of requiring an application to call the queue manager to dequeue a message, the dispatcher calls the \napplication when a new message appears on the queue. Many scheduling options are possible: It may do this \n(1) every time a new message arrives, (2) only if a new message arrives when the application is not currently \nrunning, (3) when the queue reaches a certain length, or (4) at ﬁ xed time intervals provided the queue is non-\nempty. The dispatcher may also include load control, to limit the number of application threads it can invoke. \nThat is, if the maximum number of application threads are already executing, then a new message that appears \non the queue must wait there until a thread ﬁ nishes executing its current request. \n 4.6  PUBLISH-SUBSCRIBE \n Using queued communication, each message has a single recipient — the process that dequeued the message. \nBy contrast, some applications need to send a message to multiple recipients. For example, this arises with a \nnotiﬁ cation service that broadcasts an alert when an important event occurs, such as a major change of a stock \nprice. If the sender knows the identities of all the recipients, it can broadcast the message by sending the mes-\nsage to each of them. However, this is inconvenient if there is a large number of recipients. And it may not \neven be feasible if the sender doesn’t know the identities of all the recipients. \n To handle the latter case, a different communication paradigm can be used instead, called publish-subscribe. \nIn the  publish-subscribe paradigm, a publisher sends a message to a broker that is responsible for forwarding \nthe message to many subscribers. Typically, the publisher tags each message by its type. Each subscriber regis-\nters interest in certain message types. After receiving a message from a publisher, the publish-subscribe broker \nsends the message to all subscribers that have registered an interest in that message’s type. \n The publish-subscribe paradigm is like queuing in three ways. First, the sender and receiver are decoupled, \nin the sense that they don’t communicate directly with each other. Instead, they each communicate with the mes-\nsage broker. In fact, if one equates the notion of message type with that of queue, then the similarity is even more \npronounced; in effect, senders enqueue messages to a queue for the message type and receivers dequeue them. \n Second , messages can be sent or received in the context of a transaction. In that case, the operations to send \nor receive a message are undone in the event of an abort. \n Third , subscribers can use either a pull or push model. In the pull model the subscriber can explicitly poll \nfor new messages that satisfy its subscription. In the push model when a message arrives a dispatcher forwards \nthe message to all subscribers whose subscriptions include that message. \n Given these similarities between queuing and publish-subscribe systems, the two communications para-\ndigms often are supported by a common queue management implementation. This has become especially \ncommon since the development of the Java Message Service (JMS) standard, which includes a program-\nming interface for both point-to-point messaging and publish-subscribe. Other standard interfaces that offer \npublish-subscribe capability are the CORBA-Notiﬁ cation service and WS-Eventing or WS-Notiﬁ cation for \nWeb Services. \n In the simplest version, the message type is simply a name, sometimes called a topic. In more advanced \nversions, types can be grouped into a hierarchical namespace. So a type could be a path in the namespace, such \nas  “ Equity-exchange/NY-stock-exchange/IBM ” rather than simply  “ IBM. ” \n Some publish-subscribe systems allow subscribers to identify messages using predicates that refer to the \nmessages ’ content. For example, one could subscribe to (type  \u0005  “ IBM ” ) and (price  \u0006  100) where price is a \nﬁ eld in the message content. \n\n\n Publish -subscribe systems usually offer the option of having a subscription be persistent or volatile. If it is \npersistent, then each message is delivered to all registered recipients. If a recipient is unavailable when the mes-\nsage arrives, then the message broker retains the message and resends it when the recipient becomes available. \nIf the subscription is volatile, then when each message arrives, the message broker forwards it to all registered \nrecipients. If a recipient isn’t available, then it simply doesn’t receive the message; the message broker does not \nattempt redelivery when the recipient becomes available. \n 4.7  OTHER MESSAGE-ORIENTED MIDDLEWARE \n Many TP systems are used in conjunction with other TP systems that offer related application functionality. \nWe saw a simple example of this in Section 2.4, which described the integration of TP applications that sup-\nport checking accounts and credit card accounts. To be used together, the systems need to be integrated. \n Integration is hard because independent TP applications are usually heterogeneous in three ways. They \nsupport different communications protocols, different application functions, and different message formats. To \nintegrate the applications, all three of these differences must be reconciled. \n There are two main architectures for performing this reconciliation:  broker-based and  bus-based . Broker-\nbased products, sometimes called  enterprise application integration (EAI) systems, use a broker as interme-\ndiary between client and server to perform the integration. Bus-based products, sometimes called enterprise \nservice buses (ESBs), enable clients to communicate directly with servers. However, the technical distinction \nbetween EAI and ESB products is not always this sharp. For example, both product categories are moving \ntoward incorporating business process management capabilities, which will be discussed in the next chapter. \nAs we noted in Chapter 1, the terminology for transactional middleware product categories has been evolving \nover the past 15 years, an evolution that seems likely to continue. \n Broker-Based Architecture \n In a broker-based architecture a message server provides a bridge between the heterogeneous applications (see \n Figure 4.10 ). Instead of communicating directly with the applications, a client communicates with the broker, \nwhich forwards the message to the desired application. The client can be one of the applications being inte-\ngrated or an external program such as an end-user device. \n The broker provides three functions, which correspond to the three differences to be reconciled. First, it sup-\nports all the communication protocols required to communicate with the applications. A client sends a message \nTP Application\nTP System\nProtocol Adaptor\nProtocol Adaptor\nUniform\nFunction\nInterface\nParameter\nTranslation\nTP Application\nClient\nMessage Broker\nTP System\n FIGURE 4.10 \n Broker-Based Application Integration. The Message Broker mediates message transfer from clients to TP applications. \n4.7 Other Message-Oriented Middleware  113\n\n\n114  CHAPTER 4 Queued Transaction Processing\n to the broker using any of the supported protocols. The broker can forward that message to the desired applica-\ntion using the protocol supported by that application. \n Second , the broker supports the union of all the functions offered by the applications being integrated. \nUsually, the broker offers a uniform interface to these functions, such as a canonical message format deﬁ ned \nby the broker. Thus, a client can call these functions using that uniform interface, independent of the message \nprotocol, programming language, or other technologies used by the application that implements the function. \nInternally the broker stores a mapping that tells it how to translate each function into the form required by the \napplication that implements the function. This mapping often is implemented as a set of protocol adaptors, one \nfor each of the application environments being integrated. Some brokers can also support clients that use their \nown protocols and formats and don’t enforce the use of a single uniform interface \n Third , it offers tools for translating between different parameter and message formats. The translation may \nbe based on a calculation (such as translating between date formats), a table (such as translating between coun-\ntry codes), or a lookup from an external source (such as an exchange rate server to translate a money ﬁ eld \nbetween currencies). Some applications import or export structured documents (e.g., in XML), rather than indi-\nvidual parameters. In this case document translation is used, such as an XSLT program that translates one XML \ndocument into another XML document having a different format. \n Some brokers also offer routing functions. A message may be routed based on the contents of a request or \nby requirements that are set by the client or the server. Other broker functions include logging, auditing, per-\nformance monitors, and other system management functions. \n Bus-Based Architecture \n In a bus-based architecture all TP applications are invoked using the same communications protocol, which is \nconﬁ gurable for some products (such as Microsoft’s WCF and Progress Software’s Artix). For example, they \nmay all support the Web Service protocols. If a TP system does not support the common protocol, then it needs \nto have a protocol translator that translates from the bus’s common protocol to the system-speciﬁ c technology \nfor calling the TP system’s applications (see  Figure 4.11 ). \n Since all TP systems can be invoked using the same protocol, the TP application interfaces are naturally \nexposed using the same interface deﬁ nition technology, namely, the one supported by the protocol. For exam-\nple, if Web Services are used, then interfaces are deﬁ ned using WSDL and are made available to callers using \nUDDI. \nClient\nProtocol Adaptor\nTP Application\nTP System\nProtocol Adaptor\nTP Application\nTP System\nBus\n FIGURE 4.11 \n Bus-Based Application Integration. The client talks directly to TP applications using a standard wire protocol. \n\n\n Since there is no broker between the client and the TP system it calls, the client is usually responsible for \ntranslating between formats for parameters and messages. This can be done using a shared library of transla-\ntion functions that can be bound into the client’s applications. Or it can be implemented as a service that the \nclient invokes to translate parameters before invoking the target application. \n Comparing Brokers and Buses \n The main difference between broker-based and bus-based architectures is whether messages from client to TP \nsystem pass through an intermediate message server. If so, then it’s a broker-based architecture, in which case \nthe protocol translation usually takes place in the message server. If not, then it’s a bus-based architecture, in \nwhich case the protocol translation usually takes place in the TP systems running the applications to be inte-\ngrated. However, this distinction gets muddy when a bus-based architecture offers a queuing subsystem. It’s in \nthe eye of the beholder to regard the queue subsystem as another server on the bus or as a broker that mediates \naccesses between the client and the TP system. \n The broker-based and bus-based approaches are even more similar in their approaches to the uniform deﬁ -\nnition of application functions and parameter format translation. Both architectures require a directory service \nto expose the interface deﬁ nitions of the TP applications being integrated. For parameter translation, the main \ndifference seems to be in choosing where the functionality is implemented: in the client, in a broker or transla-\ntion service, or in the TP system. \n 4.8  QUEUING PRODUCTS AND STANDARDS \n A variety of queue manager products are available. One of the original implementations was in IBM’s IMS TP \nmonitor, where queued TP was the default behavior. Queuing is integrated with many other transactional mid-\ndleware products, such as Oracle’s WebLogic and JBoss Messaging. It is also integrated in Oracle Database, \ncalled Oracle Streams AQ, and in Windows, called Microsoft Message Queue (MSMQ). Some vendors offer \nqueuing in independent products, such as TIBCO’s Enterprise Message Service, Progress ’ SonicMQ, Apache \nActiveMQ, and IBM’s Websphere MQ (MQ  \u0005  Message Queuing). A consortium sponsored by JP Morgan \nChase has proposed a messaging standard, called Advanced Message Queuing Protocol. We brieﬂ y describe \nWebSphere MQ and Oracle Streams AQ here as two examples of such products. \n IBM’s WebSphere MQ \n IBM promotes WebSphere MQ 1 as an integration solution among its various operating system and TP environ-\nments and those of other vendors. It has a proprietary API, called Message Queuing Interface (MQI), a Java \nMessaging Service (JMS) API, and a non-Java equivalent of JMS. It can be used by applications running under \nIBM’s transactional middleware such as WebSphere Application Server and CICS Transaction Server, and on \nany operating system supported by WebSphere MQ, including IBM AIX, i5/OS, OS/400, and z/OS, as well as \nHP-UX, Linux, Sun Solaris, and Microsoft Windows. \n The WebSphere MQ  queue manager accepts input from an application via the JMS API or MQI verbs. \nThe main verbs are MQPUT to enqueue a message and MQGET to dequeue a message. A named queue can \nsupport multiple concurrent enqueuers and dequeuers. \n 1 The information in this section is based on WebSphere MQ V6.0. \n4.8 Queuing Products and Standards  115\n\n\n116  CHAPTER 4 Queued Transaction Processing\n To process an MQPUT, the queue manager starts a transaction if the application is not already executing one \nand places the message in the queue. The operation is committed along with the rest of the transaction (which can \nbe the normal exit from the application) or can optionally run in its own transaction as described in the subsection \non nontransactional queuing in this section. The enqueued message consists of application data and the  message \ncontext , including a variety of parameters, such as a system-generated message ID, a ﬂ ag indicating whether the \nmessage is persistent, a message priority, the name of the destination queue when forwarding, the name of the \nreply queue (if any), message type (datagram, request, reply, report), correlation id (to link a reply to a request), \npriority, expiry time, application-deﬁ ned format type, code page identiﬁ ers (for language localization), context \ninformation (to identify the user and application that generated the message), and report options — whether the \nrecipient should conﬁ rm on arrival (when it’s enqueued), on delivery (when it’s dequeued), on expiration (if \nthe expiry time is exceeded), on positive action (the application successfully serviced it), on negative action \n(the application was unable to service it), or on exception. \n A message that is oversized for the queue manager or application can be decomposed into smaller segments. \nMoreover, several messages can be assigned to a group, which allows the application to correlate independent \nmessages, such as those that arrive from different sources but must be processed by the same application. \n An application can request that MQI operations participate in a transaction. Otherwise, by default, each \nindividual MQPUT or MQGET executes outside a transaction, meaning that the operation completes immedi-\nately whether or not the application is executing a transaction. \n WebSphere MQ offers several transaction management options for applications that are running within a \ntransaction. If the only transactional operations are MQI operations, then the transaction can be managed as a \nlocal transaction by MQ. If the transaction needs to access other transactional resources, then MQ can play the \nrole of a resource manager under an external transaction manager, such as the Java Transaction API in Java EE. \nIf no external transaction manager is present, then on non-mainframe platforms MQ’s XA-capable transaction \nmanager can coordinate the transactions across MQ and databases. \n Like many queuing products, WebSphere MQ offers the ability to enqueue persistent and nonpersistent \nmessages in the same queue. Nonpersistent messages are more efﬁ cient but less reliable. They do not incur \nlogging overhead and normally are handled in main memory, without being written to disk. Both types of \nmessages obey transaction semantics. However, a persistent message is delivered exactly once, whereas a non-\npersistent message is delivered at most once; that is, once (in the absence of failures) or not at all (if there is a \nfailure). \n Queue forwarding is handled by another component, which is much like an ordinary client that does \nMQGET from one queue manager and MQPUT to another, though it does have special access to the log for its \nsequence number management. So if MQPUT has a destination queue name that maps to a remote queue, this \ncomponent forwards the message asynchronously and transactionally, using an intermediate node if necessary, \nto the system on which the remote queue exists (see  Figure 4.12 ). The queue forwarding component uses a \ntransaction that’s internal to MQ to coordinate updates to the source and target queues. \n An application issues an MQGET to dequeue a message. The queue manager starts a transaction upon \nreceipt of an MQGET verb, dequeues the message from the message queue, and upon the commit from the \napplication, physically removes the message from the queue. If the transaction aborts, the queue manager \nreturns the message to the queue. MQGET supports a blocking option, which blocks the caller if the queue \nis empty and awakens it when a message is available or a timeout expires. It also supports a signaling option, \nwhere the caller can continue executing and is notiﬁ ed when the desired message arrives. Messages can be \nretrieved in order or by searching for a given ID or key. The queue can also be browsed, to examine the mes-\nsages of the queue without deleting them. WebSphere MQ also includes a dispatcher that triggers the execu-\ntion of an application when the ﬁ rst message arrives on a queue, whenever a new message arrives, or when the \nqueue length reaches a predeﬁ ned threshold. \n\n\n WebSphere MQ supports multiple named queues per queue manager. Each queue manager has the follow-\ning components: a connection manager for managing the connections between the application and the queues; \na message manager for remote communications; a data manager to manage the physical storage of the linked \nlists comprising the queue; a lock manager for locking queues and messages; a buffer manager for caching \ndata, ordering writes, and ﬂ ushing data to disk; a recovery manager for keeping track of active transactions in \nthe event of a failure/restart; and a log manager for handling the recovery log. The component names differ \nslightly in different products. \n Features of most message queuing systems that support JMS are similar to WebSphereMQ. \n Oracle Streams AQ \n Unlike most queue management products, which are independent middleware components, Oracle Streams AQ is \na queuing facility that is built into Oracle Database. 2 It is built on top of Oracle Streams, which enables the prop-\nagation and management of information in data streams, either within a database or from one database to another. \nAQ can be accessed from most popular programming languages via APIs for PL/SQL, Oracle Call Interface, \nOracle Objects for OLE, and extended versions of JDBC and JMS that provide access to Oracle-speciﬁ c features \nsuch as those in AQ. It also offers web-based access via SOAP through the AQ XML Servlet. \n In Oracle Streams AQ queues are mapped to a table that can be accessed using the standard types of queu-\ning operations, such as enqueue and dequeue. Since queued messages are stored in a table, they can also be \naccessed by SQL queries. \n Oracle Streams AQ is a complete queuing system offering most of the capabilities described in Section 4.5. \nThe enqueue operation takes a queue name, payload, message properties, and enqueue options as input and \nreturns a message ID. Message properties and enqueue options control the behavior of the enqueue operation. \nFor example, using message properties, the sender can control the earliest time when a message is consumed, \nQueue\nz/OS\nAIX\nOS/400\nQueue\nQueue\nEnqueuing\nApplication\n(MQPUT)\nQueue\nManager\nQueue\nManager\nQueue\nManager\nDequeuing\nApplication\n(MQGET)\n FIGURE 4.12 \n WebSphere MQ Architecture. Messages can be forwarded transparently between queue managers running on different \nplatforms. \n 2 The information in this section is based on Oracle 11  g. \n4.8 Queuing Products and Standards  117\n\n\n118  CHAPTER 4 Queued Transaction Processing\n whether a message is volatile or persistent, the retry threshold after which a poison message is added to an \nexception queue, whether the operation is transactional, and priority ordering. \n The entire history of information about a message is maintained along with the message itself. This serves as \nproof of the sending and receipt of messages and can be used for nonrepudiation of the sender and receiver. The \nhistory includes the name of the agent and database that performed the enqueue or dequeue operation and the \ntime and transaction ID of the operation. After the message is propagated to the destination queue, it still includes \nthe message ID of the source message so that the source and destination messages and their histories can be \ncorrelated. Stronger nonrepudiation can be achieved by storing the digital signature of the sender and receiver. \n The following are some additional features worth highlighting: \n ■  A message can be enqueued with an explicit set of recipients, which overrides the list of subscribers to \nthe queue. \n ■  A caller can batch multiple items in an enqueue or dequeue operation, which is less expensive than \nenqueuing or dequeuing the items one by one. \n ■  A consumer can dequeue a message without deleting it from the queue based on the queue’s retention \npolicy. The ﬁ rst dequeue runs as a select query, which returns a snapshot of the messages to be dequeued. \nSubsequent dequeues within the same transaction are performed on the same snapshot without issuing a \nnew select. \n ■  A sender can split a complex message into a message group, which the consumer can process atomically. \n ■  A caller can listen to multiple queues, waiting for a message to arrive. If the listen operation returns suc-\ncessfully, then the caller must issue a dequeue to retrieve the message. \n ■  A caller can dequeue a message without retrieving the message’s content. This is useful for deleting a \nlarge message whose content is irrelevant. \n 4.9  SUMMARY \n Queued TP is an alternative to direct TP that uses a persistent queue between client and server programs. The \nclient enqueues requests and dequeues replies. The server dequeues a request, processes the request, enqueues \na reply, and commits; if the transaction aborts, the request is replaced in the queue and can be retried. \n The main beneﬁ ts of queued TP are: \n ■  A client can submit a request even when the server is down (by enqueuing the request). \n ■  A server can reply to the client even when the client is down (by enqueuing the reply). \n ■  Communication failures do not result in lost replies or uncertain results. \n ■  Balancing the load among multiple servers is easier. \n ■  Priority can be given to some requests relative to others. \n The cost of these beneﬁ ts is the additional transactions to enqueue requests and dequeue replies. \n Clients can determine whether or not a request executed by examining its queues. An unexecuted request \nis still in the client’s request queue. An executed request has a reply in the client’s reply queue. If the queue \nmanager remembers the unique ID of the last request enqueued and reply dequeued by a client, then the client \ncan recover from a failure by synchronizing its state with the state known to the queue manager. To cope with \nfailures that make the result of nonredoable operations (such as printing a check) ambiguous, the client should \nread the state of the device and compare it to the state it logged before operating on the device. \n\n\n A queue manager is needed to support the queued communication model. It may be an independent product \nor an integral component of a transactional middleware product. It provides operations for the storage abstrac-\ntion of queues, including: \n ■  Operations on queued messages, such as enqueue, dequeue, scan a queue, and keyed access \n ■  Creating and destroying queues \n ■  Modifying a queue’s attributes (e.g., queue owner, size, queue name, privileges) \n ■  Starting and stopping a queue. \n A queue manager may support routing, either by enqueuing to a remote server, or by enqueuing locally and \nforwarding messages to a remote server. This is useful to reroute requests to another server when a primary \nserver is overloaded or down, or to batch requests that are processed only periodically. When forwarding is \ndone transactionally, it adds a fourth transaction to the model. \n Publish -subscribe is a messaging style where a publisher sends a message to a broker that is responsible for \nforwarding the message to many subscribers. Subscribers register interest in certain message types and receive \nall published messages of that type. Publish-subscribe systems usually are based on queued messaging, where \npublished messages are distributed to subscribers via queues. \n Other types of message-oriented middleware are available to integrate independent TP applications that sup-\nport different communications protocols, different application functions, and different message formats. The two \nmain architectures for performing this reconciliation are broker-based products, often called enterprise appli-\ncation integration (EAI) systems, and bus-based products, often called enterprise service buses (ESBs). They \ninclude functions for bridging different protocols, routing messages to the desired application, and translating \nbetween different message formats. \n4.9 Summary  119\n\n\nThis page intentionally left blank\n",
      "page_number": 126
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 139-146)",
      "start_page": 139,
      "end_page": 146,
      "detection_method": "topic_boundary",
      "content": " 5.1  INTRODUCTION \n A  business process is a set of related tasks that lead to a particular goal. Some business processes automate the \nexecution or tracking of tasks using software. Such processes can be modeled as a partially ordered set of steps. \nEach step may be a transaction, an execution of a program that is not a transaction, an activity performed by \na person or machine, or another multistep business process. Business processes are not limited to businesses. \nThey arise in government, academia, science, and many other complex organizations. \n The term  workﬂ ow is a commonly used synonym for the concept of a business process. The term  busi-\nness transaction is sometimes used as a synonym for a business process or a step within a business process. \n Business process management is the activity of creating, managing, adapting, and monitoring business pro-\ncesses. Sometimes a distinction is made between  orchestration and  choreography , which are essentially busi-\nness process management within an enterprise and between enterprises, respectively. \n Much of the work of business process management is comprised of traditional operational activities per-\nformed by business managers. This includes deﬁ ning and organizing the activities of an enterprise, hiring and \ntraining people to do the work, developing accounting procedures to measure cost and productivity, and identi-\nfying ways of simplifying or automating the work to reduce cost, improve quality, improve customer satisfac-\ntion, and so on. These activities are essential ingredients for successful business process management, but they \nare not our main interest here. Rather, this chapter focuses on aspects of business process management that \nrelate to the choice and use of software. \n The operation of a large enterprise usually involves hundreds or thousands of business processes. Many of \nthem offer a product or service to a customer of the enterprise, often interoperating with multiple businesses. \nThe following are a few examples: \n ■  Process an order for retail goods: Check the customer’s credit, reserve the required material from stock, \nschedule the shipment, give commission credit to the salesperson, submit a request for payment from a \ncredit card company, perform the shipment, and then validate that the order was delivered. \n ■  Transfer money: The source bank approves the transfer and sends a message to the target bank. The tar-\nget bank records the transfer, bills the account for the transfer fee, and sends an acknowledgment to the \nsource bank. The source bank bills the account for the transfer fee and sends a written acknowledgment \nto the customer. \n ■  Reserve a trip: Arrange a trip at a travel web site by reserving ﬂ ights, car rentals, and hotel rooms. \n Business Process Management \n 5 \nCHAPTER\n\n\n122  CHAPTER 5 Business Process Management\n ■  Process an order for a new computer: Analyze the conﬁ guration for feasibility. Manufacture the computer. \nShip the computer. Debit the credit card. E-mail an acknowledgment to the customer. The manufacturing \nstep is, in turn, a nested business process: identify the required components; group the components by \nsupplier; send an order to each supplier; when all the components have arrived, issue a build order; when \nthe computer is completed, send a notiﬁ cation to the parent process. \n Many business processes are internal to an organization and only indirectly in support of a product or service, \nsuch as the following: \n ■  Report a bug: A tester reports a bug in a software product. A test engineer diagnoses the problem and \nassigns it to the relevant design engineer. The design engineer ﬁ xes the problem. The test engineer \nchecks that the repaired program indeed solves the problem. The test engineer adds a test to the product’s \nregression test suite, to detect if the product exhibits the bug in a later version. \n ■  Process a shipping request: Print the shipping order. Get the products to be shipped. Package the prod-\nucts. Print a shipping label and afﬁ x it to the package. Add the postage label. Record the shipment in the \ndatabase. Place the package in the outbox. \n This chapter focuses on business processes that are at least partially automated using software, especially \nusing TP technology, such as those just listed. Partially automated business processes have steps that include \nhuman interaction, such as the following: \n ■  Adjust an insurance claim: When someone submits a claim, preliminary data must be captured. Later there \nis an inspection of the damage, which is recorded. Then the claim is approved (or not). After the damage is \nrepaired, receipts are submitted for reimbursement. Then a reimbursement check is issued. \n ■  Plan a new product version: A product manager collects ideas for new product features from customers, engi-\nneers, and sales people. The engineering group estimates the feasibility, design time, and manufacturing cost \nof each new feature. The product manager ranks the features based on cost and incremental sales expected \ndue to each feature. A business manager decides which features to include based on available engineering \nresources and on the expected increase of proﬁ t and customer satisfaction compared to other product invest-\nments being considered. The engineering manager develops a schedule to design the approved features. \n ■  Buy a piece of real estate: Find the right property. Make an offer. If the offer is accepted, have it inspected. \nIf the inspection reveals problems, renegotiate the offer. Arrange ﬁ nancing. Arrange insurance. Do the \nclosing. \n ■  Evaluate a book proposal: The editor receives a book proposal from an author. The editor negotiates changes \nto the proposal with the author. The editor sends the proposal to reviewers. The editor sends reviews to the \nauthor. The author revises the proposal. The editor either rejects the revised proposal or offers a publishing \ncontract. The author reviews and revises the contract. The editor and author sign the contract. \n Even when all steps of a business process involve human interaction, the process can beneﬁ t from software \nassistance from TP applications; for example, to track progress in a system for document management or case \nmanagement. Many business processes are a hybrid of human and automated steps where the latter execute \nas transactions, such as customer relationship management. There are packaged software products for each of \nthese applications. \n Following the traditional waterfall model of software development, business process management involves \nthe usual application development activities: specifying the business process, implementing it, deploying it, \nand monitoring and managing its execution. A lot of attention has focused on the speciﬁ cation of business \n\n\n processes, especially on software tools to visually display a process speciﬁ cation and to simulate it, thereby \nenabling business users to evaluate the appropriateness of the speciﬁ cation. Although this is an important aspect \nof business process management, it is more closely related to software design methodology and tools than to \nTP, so we will not be delving into it here. \n 5.2  BUSINESS PROCESS DEFINITION \n A business process deﬁ nition speciﬁ es the steps of the business process, the work performed by each step, the \norder in which the steps execute, and how steps communicate with each other. That is, it deﬁ nes the control \nﬂ ow and data ﬂ ow between steps. It also speciﬁ es the components of the state of the business process and how \nthey relate to each other. \n A business process deﬁ nition can be distributed among the steps of the process. For example, consider a travel \nreimbursement request. The step that captures the request from the user can include logic to send a message to the \nappropriate manager for approval. The step that captures the manager’s approval can either forward a request-for-\npayment to the accounting department (if approved) or return the original request to the employee (if rejected). \n Alternatively , the business process deﬁ nition can be expressed as a single program. In this case it is usually \na relatively simple script-like program, not a complex algorithm with complex data structures. For the travel \nreimbursement example, this program would ﬁ rst receive the request input from the user and then send a mes-\nsage to the manager for approval. Based on the manager’s reply, it would either send a request-for-payment \nmessage to the accounting department or send the rejected request to the employee. \n Independent of how the business process is deﬁ ned, it is best to encapsulate each step of the business pro-\ncess separately. This allows the business process deﬁ nition to focus on the ﬂ ow of control and data between \nsteps without being cluttered by the application logic of each step. It also is consistent with the goal of reus-\ning services in a service-oriented architecture. Each encapsulated step can be deﬁ ned as a service that can be \ninvoked in multiple business processes. \n Systems that support the execution of business processes usually offer a special-purpose programming lan-\nguage for specifying business processes. For the most part, these are ordinary languages with local variables and \nthe usual control ﬂ ow constructs, such as if-then-else, do-while, RPCs, one-way messages, parallel execution of \na set of statements, and exception handlers. In addition, there are a few constructs that are somewhat specialized \nfor business processes. One construct is to wait for the arrival of one or all of a set of messages and events (such \nas timeouts). Another is to send a message to a particular instance of another business process, thereby enabling \nbusiness processes on two systems to coordinate their activities by passing messages back and forth. \n Business processes typically are driven by events that reﬂ ect actions in the outside world: a house purchaser \nreceives a mortgage approval, an investor receives a trade conﬁ rmation, a programmer receives a bug report, or \n an author receives a draft publishing contract. It is therefore natural to specify a business process as a ﬁ nite state \nmachine. Such a machine has a ﬁ nite set of states. For each state, it speciﬁ es the set of events that can occur. Each \nevent causes the machine to perform an action and move into a different state. An example state machine appears \nin  Figure 5.1 . A ﬁ nite state machine is a convenient way to specify a business process when at each point in time \nthere are several possible events that cause the process to act, and those events can arrive in any order. This typi-\ncally arises when events correspond to actions performed by people, which can happen in arbitrary orders. \n One limitation of the ﬁ nite state machine model is the difﬁ culty of specifying transaction boundaries and \ncompensating transactions. A procedural speciﬁ cation is often more natural for capturing these aspects of a \nbusiness process deﬁ nition. \n A step of a business process may need to interact with a person. For example, a person may be needed \nto review a special order or approve a travel request. In a large organization, it is important that the business \n5.2 Business Process Deﬁ nition  123\n\n\n124  CHAPTER 5 Business Process Management\n process identify these people by their roles and not by their names. This allows multiple people to serve the \nsame role, such as using multiple expediters to handle nonstandard orders. It also allows people to change roles \ndynamically, such as enabling a manager to approve travel requests for one of her subordinates when the subor-\ndinate is on vacation. The mapping of roles to people is explicitly stored and used by the runtime environment \nto assign a step of a given business process to the right person. \n 5.3  BUSINESS PROCESS EXECUTION \n Many systems that support the execution of business processes offer a special-purpose runtime system. This \nsection summarizes the main capabilities one would expect from such a runtime system. \n First , the system needs to offer a way of installing business process deﬁ nitions so they can subsequently be \ninvoked. For the most part, this is no different than installing any service. One needs to store the executable, \nmake its interface deﬁ nition known to programs that will call it, and add its name to a registry so that a caller \ncan ﬁ nd the service to invoke it. \n Routing a request to create a business process is easy enough, since it can be guided by a registry entry. \nMessages that arrive for running business processes are more challenging. Each message, which corresponds to \nan event, needs to be routed to the proper instance of the business process. For example, when a message arrives \nthat says a particular computer has left manufacturing, the message needs to be routed to the business process \ninstance that is responsible for that order. This involves matching parameters in the message with process state. \nThis matching needs to be fast, even when there is a large number of active business processes. \n Many business processes that include steps performed by people need to allow people to modify the process \ndynamically. That is, a person performing a step might want to add a new step, skip a certain step, or reorder \nsome steps. For example, in a mortgage application process, if an underwriter ﬁ nds the customer has an unusual \ncredit history, she may add another step for a second opinion by a more experienced loan ofﬁ cer. Like other pro-\ncess behavior, these modiﬁ cations of the process should be logged so they are made available to later queries. \n State Management \n The runtime system needs to manage the state of a running process. For each process, it needs to know which \nsteps have executed, the step(s) that should execute next, the business process’s local variables, and other context \nMortgageInProcess\nreceiveAppraisal\nreceiveCreditCheck\nreceiveCancellation\ndenyApplication\napproveApplication\nMortgageApproved\nMortgageNotApproved\ntransition\nLegend\nstate\nevent\nmyEvent\nReceiveMortgageApplication\n FIGURE 5.1 \n Finite State Machine. A mortgage approval process speciﬁ ed as a ﬁ nite state machine. \n\n\n information needed for it to run. Much of the work in managing business process execution involves managing \nthe business process state. \n The runtime system should make process state available to applications. Applications need this capability \nso they can tell the user about the state of his or her partially executed business process, which is important \nbecause business processes may take a long time to execute. For example, if a user places an order and doesn’t \nreceive an acknowledgment within a few days, then the user wants to be able to investigate the state of the order. \nA general-purpose mechanism to save the state of a business process and to query that state makes it easier for \napplications to offer this kind of functionality. \n To maintain the state of a running process, the runtime needs to log all the interesting events that occur in a \nprocess, since the fact that those events occurred is part of the process’s state. For example, for each active pro-\ncess, it should log when the process starts, who invoked it, and when it ends. Also, the runtime should log when \neach step starts and ends, perhaps including its input parameters and other information about the context in which \nit runs. This information should be stored in a form that makes it easy to process queries about an individual pro-\ncess or a large number of processes. The former is needed for answering customer questions, such as the question \nearlier, to investigate the state of an order. The latter is needed by system managers to monitor performance and \nidentify slow or otherwise unhealthy processes that need attention. Aggregate information may also be useful to \nbusiness process analysts, to determine the average performance of business processes (e.g., response time for \ncertain kinds of orders), to optimize processes (e.g., certain kinds of processes that are taking too long), and to \nidentify poorly automated processes (e.g., ones that require too many manual steps for exception handling). \n A business process may execute over a long period, such as days or even months. Although a business pro-\ncess is long-running, it spends most of its time in an inactive state, waiting for an event to arrive to wake it up. It \nwould be inefﬁ cient and unreliable for the process to reside in main memory throughout its execution. It would \nbe inefﬁ cient because the process has long periods of inactivity during which its state might as well reside on \nless expensive persistent storage. It would be unreliable because main memory is volatile, so the business pro-\ncess’s state would be lost in a system failure. This is a much more serious problem than the loss of a short trans-\naction, which can simply abort and re-execute . Therefore, for safety’s sake, the business process should save its \nstate at the end of each step, as we saw in Figure 2.15. \n There are two styles of process execution that relate to process state management,  document-oriented and \n message-oriented . A document-oriented application takes a document as input, associates it with a business \nprocess, and passes the document along from one step of the business process to the next. Each step knows \nwhere to look in the document for the information that it needs for that step. Each step updates the state of the \nprocess in the document itself and saves it persistently before passing it on to the next step. Applications that \nevolved from the Electronic Data Interchange (EDI) standard typically work this way, as are many newer ones \nthat use XML documents for business-to-business e-commerce. \n By contrast, a message-oriented application looks more like a sequence of events, where each event arrives \nas a message with explicit parameters that tell the next step what to do, rather than relying on the step to ﬁ nd \nits input in a document. The state of the business process is stored in one or more databases, not in the message \nlike in a document-oriented application. \n Although most applications follow one of these two styles, there are hybrid cases that don’t fall neatly into one \nstyle or the other. That is, some process state information may be retained in messages that are passed between \nsteps, while other state information resides in databases. And document-oriented processing often invokes RPCs \nto execute one or more of the steps. \n The system needs to offer functions for saving and restoring the state of a business process. The functions \nfor saving a business process’s state might be invoked by the business process itself or by an agent that looks \nfor business processes that have been idle for a long time and should be moved out of main memory. The func-\ntion for restoring the state of a business process could be invoked by the runtime environment when a step of \n5.3 Business Process Execution  125\n\n\n126  CHAPTER 5 Business Process Management\n the process is ready to execute. We will see other uses for state management in the next section for handling \nsystem failure and recovery. \n Business process state can be used to help understand the relationships between different types of enterprise \ninformation. It is often the only place where related data entities are correlated and managed. For instance, the \nrelationship between a sales opportunity, a sales quote, a sales order, and a contract for sales is hard to main-\ntain. If these activities were reﬂ ected as entities and were coordinated by a single opportunity-to-contract pro-\ncess, then each instance of the process would have an ID that would correlate the IDs of these related activity \nentities as part of the business process state. In this sense business process state is central to creating integrated \nviews of business data. \n Given the importance of business process state, tools to analyze this state have become a recognized busi-\nness process management capability, called  business activity monitoring . This involves emitting business \nprocess state, such as event streams that populate a database. The database can be used by data mining and \nother business intelligence tools to provide visibility into every aspect of the workings of real business pro-\ncesses, including human-driven ones. \n 5.4  TRANSACTIONAL PROPERTIES \n Although it is tempting to execute all the steps of a business process within one transaction, the vast majority \nof business processes require the execution of more than one transaction. There are many reasons for this, such \nas the following: \n ■  Resource availability: At the time the request to execute the business process is taken as input, only some \nof the people or systems that are necessary to execute the request may be available. For example, when \na customer submits an order, it is immediately stored in the order processing database. But if the request \narrives after normal business hours, there may be no one to process it until the next business day. As \nanother example, one step in processing an expense claim may be getting a manager’s approval, but the \nmanager only sets aside time to approve claims twice a week. \n ■  Real-world constraints: Processing an automobile insurance claim may require the customer to bring in \nthe car for damage inspection and get two estimates for the cost of the repair. This could take weeks. \n ■  System constraints: When executing a money transfer between two banking systems (e.g., to automati-\ncally pay a credit card bill from a checking account), the two systems might not run compatible transac-\ntion protocols, such as two-phase commit, or be available at the same time. The transfer therefore has to \nrun as multiple independent transactions on each system. \n ■  Function encapsulation: Different business functions are managed independently by different depart-\nments. For example, in order processing, inventory management is done in manufacturing, scheduling a \nshipment is done by the ﬁ eld service group, commission reporting is done in the sales system, and credit \napproval is done by the ﬁ nance department. Decomposing a workﬂ ow request into steps that are pro-\ncessed by these separate systems or by separate reusable services in an SOA is more intellectually and \norganizationally manageable than designing it to run as one big transaction. \n ■  Resource contention: A long-running transaction usually holds resources, such as a lock on data or a com-\nmunications device. Contention for the resource thereby slows down other transactions trying to use the \nresource. What starts as a performance problem, due to resource contention, may turn into an availability \nproblem, since whole groups of transactions may be unable to run until the long-running transaction gives \n\n\n up its resources. For example, a money transfer between two banks could take a long time to run, because \nthe banks are connected by slow or intermittent communication. For this reason, the operation normally \nruns as (at least) two transactions: one on the source system, to debit the money from the source account; \nand then some time later, a second one on the target system to credit the money to the target account. \n So far in this book, we have assumed that each user request can be satisﬁ ed by the execution of a single \ntransaction. When queuing is used for better availability and load balancing, we added transactions that read \nfrom and write to queues to move the request around. However, even in this case, only one transaction did the \napplication-oriented work that was requested. \n This assumption breaks down for multistep business processes. One of the most important runtime require-\nments of business processes is that they do not have to execute as a single transaction. Once you split the \nexecution of a request into multiple transactions, you no longer necessarily get the beneﬁ ts of a single transac-\ntion: atomicity, isolation, and durability. Let’s look at how these properties might break and what can be done \nabout it. \n Isolation \n Consider a money transfer operation as an example, debiting $100 from account  A and then crediting that $100 \nto account  B at another bank. If these run as separate transactions, then the money transfer request is not iso-\nlated from other transactions. For example, somebody could perform an audit of the two banks while the money \nis in ﬂ ight, that is, after it is debited from account  A and before it is credited to account  B . If an auditor reads \nthose accounts, it would look like $100 had disappeared. Thus, if the audit and money transfer are considered \nto be  “ transactions, ” they are not serializable; no serial execution of the audit and money transfer could result in \nthe audit seeing the partial result of a transfer. \n Of course, running the money transfer as one transaction would eliminate the problem. But as explained \nearlier, there are many reasons why this may not be possible or desirable. Therefore, in contrast to single-\ntransaction requests, multitransaction business processes require special attention to the isolation problem. \n The isolation problem of a multitransaction business process usually requires application-speciﬁ c solu-\ntions. For example, the bank audit program must have logic that can deal with in-ﬂ ight money transfers. An \nalternative general-purpose solution is to lock data for the duration of the business process. However, for long-\nrunning business processes, this creates major resource contention, which is usually unacceptable. \n Atomicity \n In the money transfer example earlier, suppose there is a failure after committing the ﬁ rst transaction that deb-\nits account  A . This could be a failure of the business process’s application code or of the system that is running \nthat code. In either case, as a result of this failure, the ﬁ rst bank’s message to tell the second bank to credit \naccount  B may have been lost. If this occurs, then the second transaction to credit account  B will never exe-\ncute. Thus, the money transfer is not all-or-nothing. \n Any automated solution to this problem must include maintaining the state of the business process, that is, \nwhich steps of the business process did and did not execute. The mechanism will need this state after the recov-\nery from the failure that caused the business process to stop prematurely. Therefore, as we noted earlier, this \nstate should be kept in persistent storage, such as a disk. If the state is maintained in persistent storage, then it \nwill be available after recovery from the failure even if the failure was caused by a system failure in which the \ncontent of main memory was lost. \n5.4 Transactional Properties  127\n\n\n128  CHAPTER 5 Business Process Management\n Given that the state of each business process is maintained persistently, a recovery mechanism can address \nthe atomicity problem by periodically polling that state to determine whether to initiate recovery. If the recovery \nmechanism ﬁ nds a business process that has remained in the same state for longer than the process’s predeﬁ ned \ntimeout period, then it can initiate recovery. \n One way that a recovery mechanism can repair a stalled business process is to run a compensating transaction \nfor each of the steps of the business process that have already executed. This approach requires that for every \nstep of a business process, the application programmer writes code for a compensating transaction that reverses \nthe effect of the forward execution of the step. So in the money transfer example, the ﬁ rst transaction, which \ndebits $100 from account  A , has an associated compensating transaction that puts the money back into account \n A . If the system is unable to run the second transaction, which credits account  B , it can run a compensation for \nthe ﬁ rst transaction that debited account  A . A compensating transaction may not be needed for the last step if the \nsuccessful completion of that step ensures that the entire business process has completed successfully. \n Some systems include a general-purpose recovery mechanism to implement this approach, for example \nas part of the transactional middleware. For each active business process, the transactional middleware keeps \ntrack of the sequence of transactions that have run. During its forward execution, each transaction saves all the \ninformation that is needed to allow its compensating transaction to be invoked at recovery time. For example, \nit might save the name of the program that implements the compensating transaction and the parameter values \nthat should be used to invoke that program. If the recovery mechanism detects that the business process is \nunable to ﬁ nish, then it runs compensations for all the transactions that committed and thereby brings the sys-\ntem back to its initial state (see  Figure 5.2 ). Thus, it automates the execution of those compensations. This is \ncalled a  saga : a sequence of transactions that either runs to completion or that runs a compensating transaction \nfor every committed transaction in the sequence. \n In a saga, how does the system keep track of these multiple transaction steps to ensure that at any given time \nit can run the compensations if the saga terminates prematurely? One possibility is to store the saga’s state in \nqueue elements. Each transaction in the saga creates a queue element, which is a request that incorporates or ref-\nerences the history of the steps that have run so far. If at any point the saga can’t run the next step in the request, \nthe system can look at that history and invoke the compensating transaction for each of the steps in the history. \nBecause the queue elements are persistent, they can’t get lost. Even if one of the steps is aborted many times, \neventually the system will recognize the fact that the saga has not completed and will run the compensating \ntransactions for the steps in the saga that executed. \nStep 1\nCompensation 1\nCompensation 2\nCompensation 3\nStep 2\nStep 3\nFailure\nStep 4\nStep 5\n FIGURE 5.2 \n A Saga. This saga has ﬁ ve steps, each of which is a transaction. Each step’s program includes a compensating \ntransaction. Since this execution of the saga cannot proceed past step 3, it runs compensations for the three steps \nthat did execute. \n",
      "page_number": 139
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 147-154)",
      "start_page": 147,
      "end_page": 154,
      "detection_method": "topic_boundary",
      "content": " Durability \n The use of a multistep business process to implement a request does not affect the durability guarantee. The \ndurability of a business process’s updates is ensured by the durability property of the transactions that execute \nthose updates. If all of a business process’s updates to durable transactional resources execute in the context of \ntransactions, then the result of those updates is durable. \n As we saw in this section and the last, it is also important to maintain a durable copy of the intermediate \nstate of a business process. This is not a requirement for transactions. The reason is that a transaction is atomic; \nthat is, all-or-nothing. However, a multistep business process may not be atomic. To make it atomic, we need a \ndurable copy of its intermediate states. \n 5.5  MAKING PROCESS STATE DURABLE \n We have seen several reasons why business process state needs to be maintained durably. This section dis-\ncusses several techniques for doing so: \n ■  A special-purpose runtime system for business processes \n ■  Persistent queues \n ■  Pseudo-conversations \n ■  Message logging \n Using a Special-Purpose Runtime System \n Consider a system that uses a special-purpose runtime system to support business process management. Suppose \nthe runtime supports a function SaveState that stores the current state of a business process in persistent storage. \nSuppose the business process calls SaveState and then executes another step as a transaction, T. In general, exe-\ncuting a transaction is not an idempotent operation. So if the system fails and, after recovering, resumes execut-\ning the business process, it is important that the business process doesn’t execute T a second time. This problem \nis reminiscent of the problem of handling non-undoable and non-idempotent operations in Section 4.4, where \nwe wanted to process the output of a transaction (e.g., print a check) exactly once. In this case, we want to run \nT in the business process exactly once. It is essentially the same problem, except in this case the non-undoable \noperation is a transaction. \n The way we solved this problem in Section 4.4 was the equivalent of invoking SaveState immediately \nbefore running T, as illustrated in  Figure 5.3 . Then, before invoking T, check that it didn’t run once before. This \nassumes that T produces some testable state; that is, some persistent state that proves whether it did or did not \nrun. This can be arranged if the invocation of the step that corresponds to T is done via a special function in the \nbusiness process’s runtime. That function can perform the required update of persistent storage that, if needed, \ncan be checked later to determine if T ran. \n Since T is a transaction, another possible solution is to have the business process’s state be a transactional \nresource and make SaveState the last operation of the transaction. That way, the business process’s state is saved \nin persistent storage if and only if T commits. If the system fails before T commits, then at recovery time the \nbusiness process will continue executing with the last state that was saved before the execution of T. So T will \nexecute again, which is what we want since T ’s ﬁ rst execution aborted as a result of the failure. If the system \nfails after T commits, then at recovery time the business process will continue executing with the statement that \nfollows the SaveState operation. We would like this to be the statement that follows the execution of the commit \noperation for T. So we would like the SaveState operation to save the state that the transaction committed. \n5.5 Making Process State Durable  129\n\n\n130  CHAPTER 5 Business Process Management\n Notice that it is not satisfactory to invoke the SaveState operation immediately after T commits, instead \nof invoking it as part of T. The reason is that the system might fail after T commits and before executing the \nSaveState operation that follows the commit. That would result in having T execute again at recovery time, which \nis one of the outcomes we want to avoid. \n Using Queued Requests \n Another way to manage the state of a business process is to use persistent queues. The business process can be \ninitiated by a request that is stored in a queue. Each step of the business process executes as a transaction and \nproduces requests for the succeeding steps of the business process if and only if the step commits. Thus, the \nstate of the process is stored in the queue elements holding the active requests of the business process. \n Since the steps are separated in time, some requests in a business process may stay in a queue for a long \ntime. However, since the queue is persistent, the request cannot be lost. Moreover, no special recovery proce-\ndure is required. If the system fails and then recovers, the recovery procedure will restart the conﬁ guration of \nthe server processes, which includes the dispatchers associated with its queues. These dispatchers will then \nstart dequeuing requests and invoking the appropriate programs to run them. \n In this approach, there may be no one program that encapsulates the control ﬂ ow of the business process. \nInstead, that logic could be distributed among the steps of the process. Each step of the process has an associ-\nated program that performs the work of that step, which includes deﬁ ning what happens next by virtue of the \nrequests that it produces. Since no one program deﬁ nes the business process, the process has no local variables \nthat need to be stored persistently. If step S produces any information that is needed by subsequent steps, then \nS needs either to pass that information along in the requests it produces or to store it in a shared database that \nis accessible to subsequent steps. \n Instead of distributing the logic of business process steps, the business process could be encapsulated in a \nsingle program. The program executes each step as a transaction that dequeues the expected request, executes \nit, and enqueues output requests for the next steps. Since queue elements are persistent, the process can save its \nstate there instead of saving it periodically in a separate transactional resource. However, it still needs to save \nits control state periodically in a well-known location, as we described in the previous subsection, so that at \nrecovery time the business process can be resurrected and resume execution at the point where it left off. \nS3\nPersistent Resource \nSave\nState\nS1\nT\nS2\n FIGURE 5.3 \n The SaveState Operation Runs Before Transaction  T . Saving the state of the business process in step S 1  allows the state to \nbe tested before running step S 2  to prevent re-execution  of T in the event of a recovery from failure. \n\n\n The top-level request that initiates a business process often requires a reply that tells the user when the \nbusiness process is completed. For example, the reply might include the itinerary for a trip, the reimbursement \nof an insurance claim, or the acknowledgment of a money transfer. However, intermediate steps of the work-\nﬂ ow often do not need to reply to the originator of the step’s request. Rather than sending a reply to the previ-\nous step of the business process, each intermediate step feeds a request to perform the next step of the business \nprocess. Each intermediate step might also send an e-mail or other form of notiﬁ cation to the end-user of the \nlatest step that was performed (e.g., the order was received or the order was shipped), but it does not expect a \nreply to such notiﬁ cations. \n For example, consider the problem of moving orders from one ofﬁ ce to another in a global enterprise. The \nTokyo ofﬁ ce runs a transaction to enqueue an order request (see  Figure 5.4 ). The server recognizes the request \nas one that requires remote processing, so it runs a transaction that dequeues the order from the queue in Tokyo \nand enqueues it to another queue in New York. Now a server in New York dequeues the order, processes the \norder, and enqueues a shipping request. When the order ships, a transaction records that fact, enqueues a mes-\nsage containing an invoice and an acknowledgment that the order was ﬁ lled, and perhaps sends a shipping notiﬁ -\ncation to the end user. A transaction forwards the reply from the queue in New York back to the queue in Tokyo. \nThe Tokyo server prints the invoice and acknowledgment and mails it to the customer. That ﬁ nal step in Tokyo \nis effectively a reply to the original order request. The intermediate steps are a chain of steps where each step \nsends a request to perform the next step. \n Pseudo-Conversations \n Another type of business process arises from an interactive request; that is, one that interacts with a display \ndevice. As before, due to resource contention and availability, it is wise to break up the execution into several \ntransactions, one for each point of interaction. \n5.5 Making Process State Durable  131\nEnqueue\norder request.\nPrint invoice and\nacknowledgment.\nForward\norder to\nNew York.\nTokyo\nForward\nreply to\nTokyo.\nProcess\norder.\nShip\norder.\nNew York\n FIGURE 5.4 \n A Multitransaction Business Process. Each boxed action runs as a transaction. An order is entered in Tokyo, forwarded to \nNew York for processing, processed, and shipped, and a reply is forwarded to Tokyo, which prints an invoice for the order. \n\n\n132  CHAPTER 5 Business Process Management\n For example, consider an airline reservation transaction that gets a ﬂ ight number as input from a display, \nreads the number of seats available on that ﬂ ight from the database, and then displays that number and asks the \nticket agent how many seats the customer wants to reserve (see  Figure 5.5 ). After the customer says how many \nseats to reserve, this number is entered as input, the number of available seats is decremented, and the transac-\ntion commits. To make such transactions serializable, the system ordinarily holds a lock on that ﬂ ight record for \nthe duration of the transaction. This blocks other customers from making reservations on that ﬂ ight. The block-\ning delay could be signiﬁ cant, while the customer is deciding how many seats to reserve. For this reason, deter-\nmining the number of available seats usually runs as a separate transaction from reserving the seats. That way, \nthe ﬂ ight record isn’t locked while the customer is deciding how many seats to reserve. Of course, this means \nthat the number of available seats can change while the customer is deciding. That’s why the ticket agent often \nreserves seats on the ﬂ ight you inquire about, to make sure the seats don’t go away while you’re deciding; if you \ndecide not to reserve them, the agent cancels the reservation. \n In most ways, making this airline reservation is an ordinary multistep request, consisting of two transac-\ntions. The ﬁ rst displays the number of available seats and the second makes a reservation. Like other multistep \nrequests, one could implement it as a business process; for example, by moving requests between client and \nserver queues. However, these sorts of interactive situations arise often enough that some systems have a spe-\ncial mechanism, called  pseudo-conversations , where the request is shuttled back and forth between client and \nserver. \n With pseudo-conversations, each time the server processes a request message, it saves some information \nthat was gathered from that transaction step in the message that it returns to the client device (essentially a \nqueued reply). Some of this information may be displayed to the user (e.g., number of available seats). Other \ninformation may be there just as context that can be sent back from the client to the next transaction step (e.g., \nan identiﬁ er for a partially-completed reservation record). The message is saved in persistent storage on the \nclient and the server. But since there’s only one message ever in transit between them, the system doesn’t need a \nmechanism as elaborate as queues. It just needs a block of persistent storage reserved for each client. In a sense, \nthe pseudo-conversation is a session with the message containing the state being shared by the client and server. \nThus, any technique for managing persistent session state could be used. For example, the client state could be \nstored in a cookie in the web browser. \n This way of exchanging messages is called a pseudo-conversation because it looks as if it’s a conversational \ntransaction; that is, it looks interactive. In fact, it’s just a sequence of noninteractive requests, each of which has \none input and one output. \nDatabase\nInteractive Transaction\nGet flight number.\nRead flight information.\nDisplay number of available seats.\n/* possibly long delay\nGet number of seats desired.\nReserve the seats.\n FIGURE 5.5 \n An Interactive Transaction. During the delay while the user is deciding how many seats to reserve, the ﬂ ight information \nis locked, preventing other users from accessing it. \n\n\n Using Logging \n Logging is another way to make interactive requests reliable, without a pseudo-conversation or queuing. In this \napproach, the system runs the interactive request as one transaction (not a sequence of transactions) and logs \nall the transaction’s input/output operations to the display or the communications system. \n If the transaction aborts and restarts, then the system executes the restarted transaction in  “ restart mode. ” In \nthis mode the system uses the log to service the transaction’s input requests. That is, instead of reading from \nthe display, the restarted transaction reads the values produced during the previous execution, which are in the \nlog (see  Figure 5.6 ). If there are no more logged input values to read, then the system resumes processing the \nrestarted transaction’s input operations in  “ normal mode, ” by reading from the display or communication system. \n While in restart mode the system processes each of the restarted transaction’s output operations by compar-\ning it to the output that was recorded in the log during the original execution. These two outputs might differ \nbecause the restarted transaction read a different value from the database than the original transaction read. If \nso, then the system aborts the transaction and restarts it, but this time executing it in normal mode. If not, then \nthe restarted transaction continues executing in restart mode. If there are no more logged output values to com-\npare it to, then the system resumes processing the restarted transaction’s output operations in  “ normal mode, ” by \nwriting to the display or communication system.  \n The implementation of this approach can get quite complicated. There are many ways a transaction can per-\nform input and output. Each type of input and output must be logged during the original execution. And for each \ntype of operation the system must be able to reproduce the logged behavior and to detect when the restarted \ntransaction has exhibited different behavior. \nLog\nMessages\na. During normal operation, log all messages\nTransaction\nLog\nb. Use the log to recover from a transaction failure\nResume normal operation\nNo\nYes\nContinue\n3. Output\nMessage\n3. Output\nMessage\n1. Input\nMessage\n2. Transaction\n\u0005?\n FIGURE 5.6 \n Message Log for Transaction Recovery. During recovery, the transaction replays by (1) getting its input messages from \nthe log, (2) executing until it produces output, and (3) comparing its output messages to the result of the previous \nexecution. If the output is the same as its previous execution it continues the replay. \n5.5 Making Process State Durable  133\n\n\n134  CHAPTER 5 Business Process Management\n The execution of a business process can use this message logging technique to attain a similar level of \nfault tolerance as it would have using any of the techniques described earlier in this section, namely, a special-\npurpose runtime, queuing, or pseudo-conversations. However, unlike those earlier approaches, in this case the \nbusiness process must execute as one transaction and not be decomposed into multiple transactions. Therefore, \nthis technique by itself does not avoid the problems of resource contention and availability, which are two \nother reasons why it may be undesirable to execute a business process as one transaction. Thus, it’s suitable \nonly when they are not critical problems. \n 5.6  OTHER MODELS OF BUSINESS PROCESSES \n The term  “ business process ” has a strong connotation of applying the technology to business procedures in \nsupport of large enterprises. However, long-running processes also occur in science and engineering, which \nalso have developed some degree of automation support. Since their capabilities are very similar to those we \ndescribed for business processes, we summarize them only brieﬂ y. \n Scientiﬁ c Workﬂ ow \n Software systems that support scientiﬁ c experimentation need to deal with long-running processes. Scientists call \nthese workﬂ ows rather than business processes, but the concept is the same. A typical scenario is to use a pipe-\nline of tools that takes raw data from a physical scientiﬁ c experiment and transforms it into a meaningful inter-\npretation of the result of the experiment. For example, in bioinformatics, an experiment might involve putting the \nliquid result of a wet-lab experiment into a scientiﬁ c instrument, such as a mass spectrometer or micro-array. The \noutput of the instrument is a ﬁ le. That ﬁ le is then pipelined through a sequence of data analysis tools, ultimately \nproducing results that can be interpreted by a scientist. The analysis may be run thousands of times on different \nsamples. \n There are several ways in which automation of workﬂ ows can help scientists, such as the following: \n ■  A scientist can write a workﬂ ow deﬁ nition that drives the execution of the multistep experiment. The \nworkﬂ ow management system maps the computational steps onto a multiprocessor computing facility \nand monitors and manages their execution. \n ■  A scientist can review the history of workﬂ ow executions. This history, which scientists usually call \n provenance , can give the exact steps that were executed to produce a particular output. The ability to run \nqueries to ﬁ nd the provenance of certain experiments helps enable the reproducibility of experiments. \nThis is especially valuable when the process has manual steps and different executions of the workﬂ ow \nhave different manual steps. \n ■  A workﬂ ow system can capture the sequence of steps of a process so that it can be replayed many times. \nInitial experiments may involve many manual steps. But as the process is perfected, the same steps are \nexecuted in each replay. It is therefore helpful if the workﬂ ow system can transform an execution history \ninto a script that can be re-executed  many times. \n As of this writing, scientists have their own workﬂ ow management systems, which are different from those \nused for business processes. However, there is a growing awareness of the strong similarities of these two tech-\nnologies. It therefore seems likely that more technology sharing between these two communities will develop. \n\n\n Conﬁ guration Management Systems \n Conﬁ guration management systems help engineers manage shared designs. A similar kind of system, called \na product data management system, is used for discrete manufacturing. In these systems, design information \ntypically is stored in ﬁ les, which are grouped into conﬁ gurations, each of which corresponds to some com-\nponent being designed. The system offers check-out – check-in functionality. A user checks out the ﬁ les he or \nshe needs to work on. After the work is completed, the user checks them back in. The work that was done \nbetween the check-out and check-in can be thought of as a step in the design process. A design tool may be \ninvoked to evaluate the result of that step. If the result passes the test, it has to be recorded in the project man-\nagement system where the change request originated. If not, it has to be returned to the engineer to redo the \ndesign step. \n For the most part, the steps of such a conﬁ guration management process are manual. However, they \noften follow a well-deﬁ ned engineering process that could be codiﬁ ed as a business process deﬁ nition. Thus, \nthey can beneﬁ t from some degree of software automation to track the state of each process and to review \nits history long after it executed. Currently, this type of functionality usually is built as a special function \nin a conﬁ guration management product, rather than using general-purpose business process management \ntools. \n Conﬁ guration management also is used to manage complex computer systems. This is more of an opera-\ntional activity than a design activity. However, the business process functionality is largely the same. The steps \nrequired to perform certain system management functions are speciﬁ ed as a business process, such as steps to \nadd a new user to the system or to add a new server to the network. Thus, some degree of automation to track \nprocess state is valuable here too. \n One interesting aspect of conﬁ guration management compared to normal TP systems is that the steps of a \nconﬁ guration management process require application-speciﬁ c logic to make them serializable, due to concur-\nrent checkout steps. For example, suppose Alice checks out ﬁ le  F and then Bob checks out  F too. Alice modiﬁ es \n F , thereby creating  F \u0003 , and checks in  F \u0003 . Then Bob modiﬁ es his copy of  F , thereby creating  F  \u0007 , and checks in \n F  \u0007 . At check-in time, the conﬁ guration management system knows that Bob’s initial state of  F was overwrit-\nten by Alice. It therefore knows that it would be incorrect to overwrite Alice’s version  F \u0003 by Bob’s version  F  \u0007 . \nInstead, a conﬁ guration management system would ask that Bob’s changes to  F be merged into  F \u0003 . The system \nmight help by ﬁ nding the differences between  F and  F  \u0007 , and then helping Bob add those changes to  F \u0003 . Or it \nmight ﬁ nd the differences between  F and  F \u0003 and the differences between  F and  F  \u0007 , merge those changes, and \nthen apply the merged changes to  F . In both solutions, the intent is to make it appear that Bob actually made his \nmodiﬁ cations to  F \u0003 , not to  F ; that is, to make it appear that Alice’s and Bob’s modiﬁ cations ran serially. We will \nsee that this is an instance of a general problem that arises in TP when independent transactions modify different \ncopies of the same data, in this case different copies of  F . We discuss a variety of general-purpose solutions to \nthe problem in Section 9.5,  Multimaster Replication . Those solutions don’t solve the problem for conﬁ guration \nmanagement  per se , but they have the same property of identifying independent and hence conﬂ icting changes \nand requiring that they be merged together in an application-speciﬁ c way. \n 5.7  PRODUCTS AND STANDARDS \n This section offers two concrete examples to illustrate the concepts of business process management: the Web \nServices Business Process Execution Language (WS-BPEL) standard and the Service Broker component of \nMicrosoft SQL Server. \n5.7 Products and Standards  135\n\n\n136  CHAPTER 5 Business Process Management\n Web Services Business Process Execution Language \n WS -BPEL is a standard from the Organization for the Advancement of Structured Information Standards \n(OASIS), which is responsible for some of the Web Services standards. It speciﬁ es an XML syntax and execu-\ntion semantics for business processes. A business process runtime system is WS-BPEL compliant if it can exe-\ncute business processes that are expressed in WS-BPEL. \n The WS-BPEL standard does not specify a graphical notation or a programming language syntax for \nexpressing processes. Thus, a business process speciﬁ cation tool is WS-BPEL compliant as long as it compiles \nbusiness process deﬁ nitions into WS-BPEL — it can offer any notation or language syntax it wants to people \nwho design business processes. There are dozens of such notations and languages. One popular notation is \nthe Business Process Modeling Notation (BPMN), which is a graphical notation standardized by the Object \nManagement Group and supported by many tool vendors. An example is shown in  Figure 5.7 . 1 BPMN has been \nmapped successfully to WS-BPEL. \n In WS-BPEL, the steps of a business process are called  activities . WS-BPEL assumes that all activities are per-\nformed by Web Services. A process deﬁ ned in WS-BPEL describes the interfaces between a business process and \nthe Web Services with which it interacts. A WS-BPEL business process can itself be exposed as a Web Service. In \naddition, a business process describes the control ﬂ ow of the activities, state management, and exception handling. \n A variable in WS-BPEL contains a WSDL message type or an XML Schema (XSD) simple type or element \ntype. For example, a process can use a variable to store a document or message that it receives from one service \nand that it intends to send later to another service. Or it can use a variable to record state information about a \nprocess, as discussed in Section 5.3. A rich expression language is available to assign a value to a variable. In \nparticular, components of a variable can be identiﬁ ed using XPath, which is an expression language for referenc-\ning a portion of an XML document. \n Each process is itself a service. Each interaction of a process is described by a  partner link , which connects \nthe process to a partner service. Each partner link has a  partner link type , which speciﬁ es the name of the role \nof each participant in the link type and the port type over which each participant communicates. Port types are \nabstract connection points to a service, which are later made concrete through a port deﬁ nition that includes \nnetwork information. A partner link speciﬁ es the partner link type of which it is an instance and the role that the \nprocess and its partner play. In RPC terminology, the partner link type and partner link deﬁ ne a service contract \nover which service invocations can take place. \nPrepareInput\nwsInput\nCallStore\nStartRecipientList\nCallSupplier\nCallLogistic\nRetrieveldOrder\nEndRecipientList\nEnd\nStart\nwsOutput\n FIGURE 5.7 \n Sample BPMN Diagram for Order Processing Flow. The rounded rectangles denote steps, the rectangles with folded right \ncorners denote data, and the diamonds with plus signs denote fork and join. \n 1 Example screenshot from the Eclipse SOA Tools Platform Project BPMN Modeler:  http://www.eclipse.org/bpmn/images/screenshots/ \n",
      "page_number": 147
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 155-163)",
      "start_page": 155,
      "end_page": 163,
      "detection_method": "topic_boundary",
      "content": " A process communicates with another service by invoking it via a partner link, either as a one-way or \nrequest-reply operation (i.e., an RPC). Since a process is a service, it can also receive such a call from a part-\nner and, if the call is a request-reply operation, the process can subsequently send a reply to the partner. \n A process can communicate with a particular instance of a service. To do this, it identiﬁ es a set of variables \nthat are input parameters to service calls as a  correlation set . Messages to a service that have the same values \nof a correlation set will go to the same instance of that service. That is, the value of the correlation set identi-\nﬁ es the instance of the partner service. \n A process has the usual control ﬂ ow structures available, such as a sequential execution of activities, a \nparallel execution of activities (called a  ﬂ ow ), if-then-else, a case statement to select among activities (called \na  switch ), a wait activity to wait for a duration or for a deadline, and looping constructs (while, repeat-until, \nfor-each). It also offers an event block (called a  pick ) that identiﬁ es a set of event-activity pairs, where the ﬁ rst \nevent to ﬁ re causes the associated activity to execute. \n Each activity deﬁ nes a scope. Larger scopes consisting of multiple activities can be explicitly deﬁ ned. Each \nscope can have an associated fault handler and compensation handler. For example, a compensation handler \ncan be deﬁ ned using the WS-BusinessActivity protocol of WS-Transactions. There is considerable ﬂ exibility \nin deﬁ ning the behavior of these handlers to override the default. For example, suppose an employee makes a \npurchase, which is then billed to his or her department. To cancel this sequence and compensate for it, it may \nbe necessary to cancel the purchase ﬁ rst, to determine if there are cancellation fees that need to be deducted \nfrom the credit to the department. This is the opposite order of the default, which is to run compensations for \ntransactions in the reverse order that they executed. \n Scopes can also be used to control serializability. If two concurrent scopes are speciﬁ ed as  isolated , then \ntheir execution must be serializable relative to their shared variables and partner links. That is, the effect of read \nand write operations on shared variables and partner links must be the same as those effects in a serial execution \nof the two scopes. \n A process may be partially speciﬁ ed as an  abstract process , which leaves out certain details that are needed \nto execute the process. An abstract process may be useful as a description to business partners who should not \nsee all details of the process or as a stable description that is unaffected by subsequent changes to implementa-\ntion details. \n At the time of this writing, the latest release of the WS-BPEL standard is version 2.0. There are many runtime \nengines that support some version of the standard. \n SQL Server Service Broker \n Microsoft SQL Server 2005 includes a queue-based system for managing business processes, called Service \nBroker. It offers functionality to allow multiple services to cooperate in the execution of a step of a business \nprocess and to enable the step to retain persistent state of the business process to be used by later steps. It also \nreliably and transactionally delivers events and messages to a business process so that the business process can \nreliably recover from failures without missing or repeating steps. \n An application in Service Broker consists of a set of steps, which are implemented by services. Each ser-\nvice is implemented by a program bound to a queue. The program can be a stored procedure or a program \nexternal to SQL Server. To invoke a service, a program ﬁ rst creates a session with the service, called a  conver-\nsation , by calling Begin Dialog Conversation. It then sends a message over the conversation, which causes a \nmessage to be placed in the service’s queue. In the simplest case, the service starts a transaction, receives (i.e., \ndequeues) the message, does the requested work, and sends a reply message over the same conversation and \ncommits. This causes the reply to be enqueued on the caller’s queue. This is essentially the model of queued \nmessaging that we explored in Chapter 4. \n5.7 Products and Standards  137\n\n\n138  CHAPTER 5 Business Process Management\n Messages within a conversation are processed in the exact order they were placed on the queue. This order-\ning is maintained even in highly scalable multithreaded and multiprocess services. \n Service Broker expands this simple queuing model in a number of ways to support multistep business pro-\ncesses. First, it has an abstraction called  conversation group . Roughly speaking, a conversation group cor-\nresponds to a business process. It has a unique ID, which is meant to be used to identify persistent state that \nthe application associates with the business process. To invoke the ﬁ rst step of a business process, a program \ncreates a conversation without specifying a conversation group, which tells Service Broker to create a new \none. If this ﬁ rst step is part of a multistep business process, then the service that executes this step should \ninsert a row into a database table whose key is the conversation group ID. This row is used by this step and \nsubsequent steps to maintain the state of the business process. For each subsequent step, the program invok-\ning the steps should create a conversation (to the service that will perform the step) in the context of the busi-\nness process’s conversation group, so the service can access the business process’s state. For example, if the \nﬁ rst step S1 invokes two other steps, S2 and S3, then S1 should create a conversation to the services for S2 \nand S3 in the context of S1’s conversation group, thereby causing the services for S2 and S3 to execute in S1’s \nbusiness process. \n It is possible that there are several messages in a queue that pertain to the same conversation group. In the \nprevious example, this could happen if S2 and S3 do their work and reply before S1’s service is able to receive \neither reply. If S1’s service is multithreaded, then when it does get around to receiving S2’s and S3’s replies, \nit could end up with two separate threads processing those replies. To relieve the application developer from \nthe synchronization that would be required between these two threads, Service Broker has a built-in locking \nprotocol. \n Service Broker locks the conversation group for the duration of any transaction that processes a message in \nthe conversation group to ensure that this is the only service invocation (i.e., thread) that can process messages \nfor this conversation group. The service invocation should receive and process the messages for this conversa-\ntion group one by one. Following this protocol in the example would cause S1’s service to process the replies \nfrom S2 and S3 in the same transaction with no risk of another service invocation interfering with it. \n A service can become idle when there are no messages in its queue. To enable this functionality, Service \nBroker allows a service to be started in the following ways: (1) when a message arrives in its queue; (2) when \nan event is received; (3) at a scheduled time (e.g., every night at 11  PM ); or (4) when SQL Server starts up. In the \nﬁ rst three cases, the service becomes idle after it has processed all the items on its queue. In case (4), the service \nremains active indeﬁ nitely and hence consumes resources even when idle. \n To ensure that a service is sent only messages it knows how to process, Service Broker offers some message \ntype management. An application can deﬁ ne message types, each of which includes the name of the message \ntype and a validation criterion. The validation criterion can be none (no criterion), empty (requires the mes-\nsage body to be empty), XML (requires the body to be well-formed XML), or validate with schema collection \n(requires the body to conform to a given XSD schema). The validation criterion speciﬁ es what validation work \nwill be done by the recipient service at runtime for each message of this type that it receives. \n When starting a conversation, one can specify a contract that says which message types can be exchanged \nbetween the initiator (which is starting the conversation) and the target (the other party to the conversation). \nTo do this, the developer ﬁ rst speciﬁ es the contract. For each message type in the contract, it says whether the \ninitiator, target, or both can receive messages of that type. A contract does not constrain the order in which \nthese messages can be sent or whether they can be duplicated; that is up to the services that participate in the \nconversation. \n Service Broker offers a message retention option. This tells Service Broker to maintain a permanent record \nof the exact sequence of messages that were processed by a conversation; for example, to undo the steps of a \nbusiness process. \n\n\n 5.8  SUMMARY \n Many types of requests need to be executed as a multistep business process, not just as one transaction. Examples \ninclude processing an order, arranging a trip, or processing an insurance claim. Business process management is \nthe activity of creating, managing, adapting, and monitoring business processes. \n Like any application program, a business process needs to be speciﬁ ed in a formal language. This can be an \nimperative language with the usual control ﬂ ow constructs, a ﬁ nite state machine, or a graphical notation suit-\nable for a visual programming tool. \n Usually a business process is supported by a special-purpose runtime system. Since a business process may \nrun for a long time, days or even months, it must be possible for users to interrogate the process’s state. Hence, \nthe business process runtime needs to log all the interesting events that occur in a process that affect the pro-\ncess’s state. The runtime system needs to offer functions for saving the state of a business process, if the pro-\ncess is idle or in anticipation of a failure, and for restoring the state when the process becomes active again or \nrecovers from a failure. \n Breaking up a request into a multitransaction business process loses the beneﬁ ts of isolation and atomicity. \nTherefore, a business process needs to pay special attention to maintaining state in a way that avoids inter-\npreting the result of a partially executed process (and thereby break isolation) and that can interpret that state \nwhen invoking compensating transactions to cope with the failure of a partially executed process (to ensure \natomicity). \n There are several ways to maintain process state. There are special-purpose runtime systems that explicitly \nstore state information while the process executes. Some systems use persistent queues to maintain process \nstate. For business processes that engage in back-and-forth communication with a client, the client and busi-\nness process server can use a pseudo-conversation, which maintains  the state of the communication along with \nsome state information in the message. A related technique to cope with interactive transactions is to log its \nI/O, so if it fails in mid-stream, its I/O can be replayed at recovery time. \n \n5.8 Summary  139\n\n\nThis page intentionally left blank\n\n\n 6.1  INTRODUCTION \n An important property of transactions is that they are isolated. Technically, this means that the execution of \ntransactions has the same effect as running the transactions serially, one after another, in sequence, with no over-\nlap in executing any two of them. Such an execution is called  serializable , meaning that it has  the same effect as \na serial execution. A serializable execution gives each user the easy-to-understand illusion that while the system \nis processing his or her transaction, it is doing no other work. \n The most popular mechanism used to attain serializability is locking. The concept is simple: \n ■  Each transaction reserves access to the data it uses. This reservation is called a  lock . \n ■  There are  read locks and  write locks . 1 \n ■  Before reading a piece of data, a transaction sets a read lock. Before writing the data, it sets a write lock. \n ■  Read locks conﬂ ict with write locks, and write locks conﬂ ict with both read and write locks. \n ■  A transaction can obtain a lock only if no other transaction has a conﬂ icting lock on the same data item. \nThus, it can obtain a read lock on a data item  x only if no transaction has a write lock on  x . It can obtain \na write lock on  x only if no transaction has a read lock or write lock on  x . \n We say that two operations  conﬂ ict if they operate on the same data and at least one of them is a write. The \nintuition is that the execution order of conﬂ icting operations makes a difference, because it changes either the \nvalue read by a transaction (since a read operation reads a different value depending on whether it executes \nbefore or after a write operation) or the ﬁ nal value of a data item (since changing the order of two write opera-\ntions on the same data changes the ﬁ nal value of the data). Since their execution order matters, it’s important \nto control that order. \n The intuition behind locking is that it avoids interference between transactions by using conﬂ icting locks to \nsynchronize the execution order of conﬂ icting operations. If a transaction is holding a read lock, then another \ntransaction cannot set a write lock, which avoids the concurrent execution of a conﬂ icting write operation. This \nworks similarly for write locks. \n Although the concept of locking is simple, its effects on performance and correctness can be complex, \ncounterintuitive, and hard to predict. Building robust TP applications requires a solid understanding of locking. \n Locking \n 6 \nCHAPTER\n 1 Many systems call them  “ shared (or S) ” and  “ exclusive (or X) ” locks, instead of  “ read ” and  “ write ” locks. However, as a reminder \nthat there is perfect symmetry between operations and lock types, we use the operation names  “ read ” and  “ write ” instead. \n\n\n142  CHAPTER 6 Locking\n Locking affects performance. When a transaction sets a lock, it delays other transactions that need to set \na conﬂ icting lock. Everything else being equal, the more transactions that are running concurrently, the more \nlikely that such delays will happen. The frequency and length of such delays can also be affected by transac-\ntion design, database layout, and transaction and database distribution. To understand how to minimize this \nperformance impact, one must understand locking mechanisms and how they are used, and how these mecha-\nnisms and usage scenarios affect performance. \n Locking also affects correctness. Although locking usually strikes people as intuitively correct, not all uses of \nlocking lead to correct results. For example, reserving access to data before actually doing the access would seem \nto eliminate the possibility that transactions could interfere with each other. However, if serializability is the goal, \nthen simply locking data before accessing it is not quite enough: The timing of unlock operations also matters. \n Correctness and the Two-Phase Rule \n To see how unlock operations affect correctness, consider two transactions, T 1 and T 2 , which access two shared \ndata items,  x and  y . T 1 reads  x and later writes  y , and T 2 reads  y and later writes  x . 2 For example,  x and  y could be \nrecords that describe ﬁ nancial and personnel aspects of a department. T 1 reads budget information in  x and updates \nthe number of open requisitions in  y . T 2 reads the current head count and updates the committed salary budget. \n To describe executions of these transactions succinctly, we’ll use r 1 [ x ] to denote T 1 ’s read of  x , w 1 [ y ] to \ndenote T 1 ’s write of  y , and similarly for T 2 . We’ll denote lock operations in a similar way — rl 1 [ x ] to denote \nthat T 1 sets a read lock on  x , and ru 1 [ x ] to denote that T 1 unlocks  x . Given this notation, consider the following \nexecution E of T 1 and T 2 : \n \n In execution E , each transaction locks each data item before accessing it. (You should check this for each \noperation.) Yet the execution isn’t serializable. We can show this by stripping off the lock and unlock opera-\ntions, producing the following execution (see  Figure 6.1 ): \n E\nr [ ] r [ ] w [ ] w [ ]\n\u0002 \u0003 1\n2\n2\n1\nx\ny\nx\ny  \n Since execution E has the same read and write operations as execution E \u0002 and the operations are in the same \norder, E and E \u0002 have the same effect on the database (the only difference between them is the lock operations). \nTo show that E \u0002 isn’t serializable, let’s compare it to the two possible serial executions of T 1 and T 2 , namely \nT 1 T 2 and T 2 T 1 , and show that neither of them could produce the same result as E \u0002 : \n ■  In the serial execution T 1 T 2  \u0003  r 1 [ x ] w 1 [ y ] r 2 [ y ] w 2 [ x ], T 2 reads the value of  y written by T 1 . This isn’t \nwhat actually happened in E \u0002 so this doesn’t produce the same effect as E \u0002 . \n ■  In the serial execution T 2 T 1  \u0003  r 2 [ y ] w 2 [ x ] r 1 [ x ] w 1 [ y ], T 1 reads the value of  x written by T 2 . This isn’t \nwhat actually happened in E \u0002 so this too doesn’t produce the same effect as E \u0002 . \n Since T 1 T 2 and T 2 T 1 are the only possible serial executions of T 1 and T 2 , and E \u0002 doesn’t have the same effect \nas either of them, E \u0002 isn’t serializable. Since E has the same effect as E \u0002 , E isn’t serializable either. \nE\nrl\nr\nru\nT reads \nrl\nr\n\u0003\n1\n1\n1\n1\n2\n2\nx\nx\nx\nx\ny\ny\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\n⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\nwl\nw\nru\nwu\nT reads\nand writes \n2\n2\n2\n2\n2\nx\nx\ny\nx\ny\nx\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0002\n\u0003\n\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\nwl\nw\nwu\nT writes \n1\n1\n1\n1\ny\ny\ny\nx\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\nE\nrl\nr\nru\nT reads \nrl\nr\n\u0003\n1\n1\n1\n1\n2\n2\nx\nx\nx\nx\ny\ny\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\n⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\nwl\nw\nru\nwu\nT reads\nand writes \n2\n2\n2\n2\n2\nx\nx\ny\nx\ny\nx\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0002\n\u0003\n\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\nwl\nw\nwu\nT writes \n1\n1\n1\n1\ny\ny\ny\nx\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n 2 The example is a bit contrived, in that each transaction updates a data item it didn’t previously read. The example is designed to illus-\ntrate a variety of concurrency control concepts throughout the chapter. \n\n\n Each transaction in E got a lock before accessing the corresponding data item. So what went wrong? The \nproblem is the timing of T 1 ’s unlock operation on  x . It executed too soon. By releasing its lock on  x before get-\nting its lock on  y , T 1 created a window of opportunity for T 2 to ruin the execution. T 2 wrote  x after T 1 read it \n(making it appear that T 2 followed T 1 ) and it read  y before T 1 wrote it (making it appear that T 2 preceded T 1 ). \nSince T 2 can’t both precede and follow T 1 in a serial execution, the result was not serializable. \n The locking rule that guarantees serializable executions in all cases is called  two-phase locking . It says that \na transaction must obtain all its locks before releasing any of them. Or equivalently, a transaction cannot release \na lock and subsequently get a lock, as T 1 did in E. When a transaction obeys this rule, it has two phases (hence \nthe name): a growing phase during which it acquires locks, and a shrinking phase during which it releases them. \nThe operation that separates the two phases is the transaction’s ﬁ rst unlock operation, which is the ﬁ rst operation \nof the second phase. \n Two-Phase Locking Theorem: If all transactions in an execution are two-phase locked, then the execu-\ntion is serializable. \n Despite the simple intuition behind locking, there are no simple proofs of the Two-Phase Locking Theorem. \nThe original proof by Eswaran et al. appeared in 1976 and was several pages long. The simplest proof we \nknow of is by J. D. Ullman and is presented in the appendix at the end of this chapter. \n Transactions Interact Only Via Reads and Writes \n Whether or not you take the time to understand the proof, it is important to understand one assumption on \nwhich the proof is based, namely,  transactions interact only via read and write operations . This assumption \nensures that the only way that transactions can affect each other’s execution is through operations that are syn-\nchronized by locking. \n One way to break this assumption is to allow transactions to exchange messages through the communication \nsystem, as ordinary messages over a communication channel or in main memory, not via transactional queues. \nFor example, consider the following execution: send 3 [ msg ] receive 4 [ msg ] w 4 [ x ] r 3 [ x ] where  msg is a message \nsent by T 3 to T 4 . This execution is not serializable: T 4 received  msg that was sent by T 3 , making it appear that T 4 \nexecuted after T 3 ; but T 3 read the value of  x written by T 4 , making it appear that T 3 executed after T 4 . Obviously, \nin a serial execution T 3 cannot run both before and after T 4 , so the execution is not equivalent to a serial execu-\ntion and hence is not serializable. Yet two-phase locking would allow this execution to occur, which can be seen \nby adding locking operations to the execution: send 3 [ msg ] receive 4 [ msg ] wl 4 [ x ] w 4 [ x ] wu 4 [ x ] rl 3 [ x ] r 3 [ x ] ru 3 [ x ]. \nx\ny\n1. Read\n4. Write\nT1\nT2\n3. Write\n2. Read\n FIGURE 6.1 \n A Nonserializable Execution, E \u0002 , That Uses Locking. The numbers 1 – 4 indicate the order in which operations execute. \n6.1 Introduction  143\n\n\n144  CHAPTER 6 Locking\n Since  w 4 [ x ] is the last operation of T 4 , it is safe for T 4 to unlock  x , thereby allowing T 3 to read  x . So, we have \nan execution that is two-phase locked but is not serializable, which seems to contradict the Two-Phase Locking \nTheorem. \n The problem is not that the theorem is wrong, but rather that the execution broke an assumption on which \nthe theorem is based, namely, that transactions interact only via reads and writes. T 3 and T 4 interacted via \nmessage passing, and those message passing operations were not locked. Either T 3 and T 4 should not have \nexchanged messages, or those messages should have been exchanged via a write operation (to send  msg ) and a \nread operation (to receive  msg ), which would have been synchronized by locks. \n Another way of stating the assumption is that  “ all operations by which transactions can interact must be pro-\ntected by locks. ” In other words, it is all right for transactions to issue send[ msg ] and receive[ msg ], provided that \nlocks are set for these operations in a two-phase manner. Later in the chapter, we will see examples of other opera-\ntions besides read and write that are protected by locks. However, until then, for simplicity, we will assume that \nreads and writes are the only operations by which transactions can interact and therefore are the only ones that \nneed to be locked. \n Preserving Transaction Handshakes \n A more subtle way for transactions to communicate is via a human operator. For example, suppose a user reads \nthe output displayed by a transaction T 5 and uses it as input to transaction T 6 . The effect here is the same as if \nT 5 sent a message to T 6 . We discussed this example brieﬂ y in Figure 1.4. In terms of our example here, Figure \n1.4 was concerned that T 5 might abort after the user copied its output into T 6 . We therefore recommended that \na user wait until a transaction (e.g., T 5 ) has committed before using that transaction’s output as input to another \ntransaction (e.g., T 6 ). This is called a  transaction handshake . This solves the problem of a transaction reading \ninput that later is undone by an abort. However, is it safe, in view of the assumption that transactions commu-\nnicate only via reads and writes? After all, even if the user waits for T 5 to commit before using T 5 ’s output as \ninput to T 6 , a message is still effectively ﬂ owing from T 5 to T 6 . \n The following theorem tells us that it is indeed safe. \n Transaction Handshake Theorem 3 : For every two-phase locked execution, there is an equivalent serial exe-\ncution that preserves all transaction handshakes. \n In other words, it’s all right for a user to wait for T 5 to ﬁ nish before starting T 6 so that he or she can use T 5 ’s \noutput as input to T 6 . It is true that the user is breaking the assumption that transactions only interact via reads \nand writes. However, this cannot break serializability, because the direction of information transfer, from T 5 to \nT 6 , is consistent with the effective serial order in which the transactions executed. \n The Transaction Handshake Theorem seems obvious. To see that it is not, consider the following execution: \nr 1 [ x ] w 2 [ x ] r 3 [ y ] w 1 [ y ]. In this execution, the user may have seen output that was displayed by transaction T 2 and \nused it as part of the input he or she provided to transaction T 3 . The user was careful to use a transaction hand-\nshake, to make sure that T 2 committed before providing input to T 3 . This execution is serializable, in the order \nT 3 T 1 T 2 . In fact, T 3 T 1 T 2 is the only serial ordering of transactions that is equivalent to the given execution. \nHowever, this serial ordering does not preserve transaction handshakes. In the original execution, transaction \nT 2 (consisting of the single operation w 2 [ x ]) ﬁ nished before T 3 (consisting of the single operation r 3 [ y ]) started. \nThis is a transaction handshake. But in the only equivalent serial ordering, T 3  precedes T 2 . This is a problem if \nthe user transferred some of the output of T 2 into T 3 . \n 3 The proof is from Bernstein et al. (1979). \n\n\n The Transaction Handshake Theorem says that this kind of thing cannot happen when you use two-phase \nlocking. Therefore, the execution r 1 [ x ] w 2 [ x ] r 3 [ y ] w 1 [ y ] must not be obtainable via two-phase locking. To \ncheck that this is so, let’s try to add lock operations to the execution. We start by locking  x for r 1 [ x ]: rl 1 [ x ] r 1 [ x ] \nw 2 [ x ] r 3 [ y ] w 1 [ y ]. Now we need to lock  x for w 2 [ x ], but we can’t do this unless we ﬁ rst release rl 1 [ x ]. Since T 1 \nis two-phase locked, it must get its write lock on  y before it releases its read lock on  x . Thus, we have rl 1 [ x ] \nr 1 [ x ] wl 1 [ y ] ru 1 [ x ] wl 2 [ x ] w 2 [ x ] wu 2 [ y ] r 3 [ y ] w 1 [ y ]. Next, r 3 [ y ] must get a read lock on  y , but it can’t because \nT 1 still has its write lock on  y and it can’t give it up until after w 1 [ y ] executes. So there is no way r 3 [ y ] can run \nat this point in the execution, which shows that the execution could not have happened if all transactions were \ntwo-phase locked. \n Automating Locking \n An important feature of locking is that it can be hidden from the application programmer. Here’s how. \n When a transaction issues a read or write operation, the data manager that processes the operation ﬁ rst sets \na read or write lock on the data to be read or written. This is done without any special hints from the transaction \nprogram, besides the read or write operation itself. \n To ensure the two-phase rule, the data manager holds all locks until the transaction issues the Commit or \nAbort operation, at which point the data manager can release the transaction’s locks since it knows the transac-\ntion is done. This is later than the rule requires, but it’s the ﬁ rst time the data manager can be sure the transaction \nwon’t issue any more reads or writes, which would require it to set another lock. That is, if the data manager \nreleases one of the transaction’s locks before the transaction terminates, and the transaction subsequently issues \na read or write, the system would have to set a lock and thereby break the two-phase rule. \n Thus , a transaction program only needs to bracket its transactions. The data manager does the rest. Although \na data manager can hide locking from the application programmer, it often gives some control over when locks \nare set and released. This offers the programmer a measure of performance tuning, often at the expense of cor-\nrectness. We’ll discuss this in more detail later in the chapter. \n Notice that we used the term  data manager here, instead of the more generic term  “ resource manager ” that \nwe use elsewhere in this book. Since there is such a strong connotation that locking is used by database sys-\ntems, we ﬁ nd it more intuitive to use the terms data manager and data item in this chapter, rather than resource \nmanager and resource. But this is just a matter of taste. We use the terms data manager and resource manager as \nsynonyms, to mean a database system, ﬁ le system, queue manager, and so on — any system that manages access \nto transactional resources. \n Not all concurrency control algorithms use locks. One popular example is optimistic concurrency control, \nwhich is discussed in Sections 6.5 and 6.8. Three other techniques are timestamp ordering, serialization graph \ntesting, and commit ordering.  Timestamp ordering assigns each transaction a timestamp and ensures that con-\nﬂ icting operations execute in timestamp order.  Serialization graph testing tracks conﬂ icts and ensures the \nresulting serialization graph is acyclic.  Commit ordering ensures that conﬂ icting operations are consistent with \nthe relative order in which their transactions commit, which can enable interoperability of systems using dif-\nferent concurrency control mechanisms. These techniques are rarely used in practice, so we don’t discuss them \nhere. See the bibliographic notes for references. \n 6.2  IMPLEMENTATION \n Although an application programmer never has to deal directly with locks, it helps to know how locking is \nimplemented, for two reasons. First, locking can have a dramatic effect on the performance of a TP system. \n6.2 Implementation  145\n",
      "page_number": 155
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 164-171)",
      "start_page": 164,
      "end_page": 171,
      "detection_method": "topic_boundary",
      "content": "146  CHAPTER 6 Locking\n Most systems offer tuning mechanisms to optimize performance. To use these mechanisms, it’s valuable to \nunderstand their effect on the system’s internal behavior. Second, some of those optimizations can affect cor-\nrectness. Understanding locking implementation helps to understand when such optimizations are acceptable \nand what alternatives are possible. \n An implementation of locking in a data manager has three aspects: implementing a lock manager, setting \nand releasing locks, and handling deadlocks, which we discuss in turn next. \n Lock Managers \n A lock manager is a component that services the operations: \n ■  Lock(transaction-id, data-item, lock-mode): Set a lock with mode  lock-mode on behalf of transaction \n transaction-id on  data-item . \n ■  Unlock(transaction-id, data-item): Release transaction  transaction-id’s lock on  data-item . \n ■  Unlock(transaction-id): Release all transaction  transaction-id’s locks. \n Most implementations store locks in a  lock table . This is a low-level data structure in main memory, much \nlike a control table in an operating system (i.e., not like a SQL table). Lock and unlock operations cause locks \nto be inserted into and deleted from the lock table, respectively. \n Each entry in the lock table describes the locks on a data item. It contains a list of all the locks held on that \ndata item and all pending lock requests that cannot be granted yet. \n To execute a Lock operation, the lock manager sets the lock if no conﬂ icting lock is held by another transac-\ntion. Consider the lock table state shown in  Figure 6.2 . In this state the lock manager would grant a request by T 2 \nfor a read lock on  z , and would therefore add [trid 2 , read] to the list of locks being held on  z , where trid 2 is T 2 ’s \ntransaction ID. If it received a request by T 2 for a write lock on  v , it would add an entry in the lock table for data \nitem  v and then add [trid 2 , write] to the list of locks being held on  v . \n If the lock manager receives a lock request for which a conﬂ icting lock is being held, the lock manager \nadds a request for that lock, which it will grant after conﬂ icting locks are released. In this case, the transaction \nthat requires the lock is blocked until its lock request is granted. For example, a request by T 2 for a write lock \non  z would cause [trid 2 , write] to be added to  z ’s list of lock requests and T 2 to be blocked. \n The strategy for granting blocked requests requires some care to avoid indeﬁ nite postponement. For exam-\nple, in  Figure 6.2 suppose T 5 requests a read lock on  x . In principle, this request could be granted because the \nonly locks on  x are read locks. However, following this strategy, a steady stream of requests for read locks on \n x could indeﬁ nitely postpone T 3 ’s request for a write lock, since there might never be a time when there are no \nread locks on  x . Therefore, a safer approach is to add T 5 ’s request for a read lock to the end of the list of lock \nrequests, after T 3 ’s request. \n Data item identiﬁ ers usually are required to be a ﬁ xed length, say 32 bytes. The lock manager does not \nknow what each of these identiﬁ ers represents. It could be a table, page, row, or other object. It is up to the \nList of Locks Being Held \nData Item\nList of Lock Requests \n[trid1, read], [trid2, read]\n[trid3, write] \n[trid2, write]\n[trid4, read] [trid1, read] \n[trid1, read]\nx\ny\nz\n FIGURE 6.2 \n A Lock Table. Each entry in a list of locks held or requested is of the form [transaction-id, lock-mode]. \n\n\n caller of the lock manager to compress the name of the object to be locked into a data item identiﬁ er of the \nlength supported by the lock manager. \n Any data item in a database can be locked, but only a small fraction of them are locked at any one time, \nbecause only a small fraction of them are accessed at any one time by a transaction that’s actively executing. \nTherefore, instead of allocating a row in the lock table for every possible data item identiﬁ er value, the lock \ntable is implemented as a hash table, whose size is somewhat larger than the maximal number of locks that are \nheld by active transactions. The hash key is the data item identiﬁ er. \n Lock operations on each data item must be atomic relative to each other. That is, each lock operation must \ncomplete before the next one starts. Otherwise, two conﬂ icting lock requests might incorrectly be granted at the \nsame time. For example, if two requests to set a write lock on  v execute concurrently, they might both detect \nthat  v is unlocked before either of them set the lock. Therefore, both of them might set the lock. To avoid this \nbad behavior, the lock manager executes each lock or unlock operation on a data item completely before start-\ning the next one on that data item. That is, it executes lock and unlock operations on each data item atomically \nwith respect to each other. Note that lock operations on different data items can safely execute concurrently. \n The lock manager could become a bottleneck if it takes too long for a lock to be set or released. Since lock \nand unlock operations are very frequent, they could consume a lot of processor time. And since lock opera-\ntions on a data item are atomic, lock requests on popular data items might be delayed because another lock \noperation is in progress. For these reasons, lock and unlock operations must be very fast, ideally on the order \nof a few hundred machine language instructions. \n Although most systems implement locking using a lock table, this is not the only possible design. An alter-\nnative implementation is to store each object’s lock with the object itself. For example, a page lock could be \nstored in the page. \n Rather than exposing lock operations to programs that invoke read and write, locks could be set by the data \naccess operations themselves. For example, in an object-oriented system, consider a class C whose instances \n(i.e., objects) are data items. C could inherit from a generic lock manager class. Each method to access an \nobject of C could be given the responsibility to set the appropriate lock on itself. For example, a get method \ncould set a read lock and a put method could set a write lock. The lock manager class could automatically \nrelease all locks when the transaction commits, thereby relieving the object itself from invoking unlock opera-\ntions. Whether the object’s locks are stored in the object’s representation or in a lock table is an independent \nimplementation decision. \n Setting and Releasing Locks \n To understand how higher levels of the data manager choose which data items to lock, we need to know a little \nbit about data manager architecture. A typical example is a database system that supports the SQL language. \nSuch a system usually is implemented in the following layers (see  Figure 6.3 ): \n ■  Page-oriented ﬁ les: This is the lowest layer of the system, which communicates directly with the per-\nsistent storage device, such as a disk. It offers operations to read and write pages in a ﬁ le. It also imple-\nments a buffer pool that caches recently used pages. \n ■  Access methods: This layer implements record-oriented ﬁ les by formatting each page as a set of records, \neach of which can be accessed by a  logical address. It also implements indexes, to allow records to \nbe accessed based on ﬁ eld value. Typical operations are GetRecord(logical address), which returns the \nrecord with that address; OpenScan(ﬁ eld value), which returns a cursor that points to the ﬁ rst record \nwith that ﬁ eld value; and GetNextRecord(cursor), which returns the record identiﬁ ed by the cursor and \nadvances the cursor to the next record with the ﬁ eld value associated with the cursor. \n6.2 Implementation  147\n\n\n148  CHAPTER 6 Locking\n ■  Query executor: This layer implements the basic relational database operators, such as project, select, join, \nupdate, insert, and delete. It takes as input an expression consisting of one or more of these operations and, \nin the case of retrieval expressions, returns a set of records. Typically, each table is implemented as a ﬁ le at \nthe access method layer and each row is implemented as a record. So we treat the following as synonyms \nin the rest of this chapter: tables and ﬁ les, columns and ﬁ elds, and rows and records. \n ■  Query optimizer: This layer takes a SQL statement as input, parses it, and translates it into an optimized \nexpression of relational database operators that is passed to the query executor. \n Locks can be set by any or all layers of a data manager that conforms to this SQL database architecture. \nFor example, the page-oriented ﬁ le layer could set locks on pages, the record-oriented layer could set locks \non individual records, and the query executor or query optimizer layer could set locks on tables or columns of \ntables. The choice is a tradeoff between the amount of concurrency needed, the overhead of locking operations, \nand the software complexity arising from the combination of locks that are used. We will explore this choice in \nsome detail throughout the chapter. But ﬁ rst, let’s take a high level view of the main tradeoff: concurrency ver-\nsus locking overhead. \n Granularity \n The size of data items that the data manager locks is called the  locking granularity . The data manager could \nlock at a coarse granularity such as ﬁ les, at a ﬁ ne granularity such as records or ﬁ elds, or at an intermediate \ngranularity such as pages. Each approach has its beneﬁ ts and liabilities. \n If it locks at a coarse granularity, the data manager doesn’t have to set many locks, because each lock covers \nso much data. Thus, the overhead of setting and releasing locks is low. However, by locking large chunks of \ndata, the data manager usually is locking more data than a transaction needs to access. For example, with ﬁ le \ngranularity locking, even if a transaction T accesses only a few records of a ﬁ le, the data manager will lock the \nwhole ﬁ le, thereby preventing other transactions from locking any other records of the ﬁ le, most of which are \nnot accessed by transaction T. This reduces the number of transactions that can run concurrently, which both \nreduces the throughput and increases the response time of transactions. \nDatabase\nTransaction 1 \nTransaction N\nAccess Method\n(record-oriented files)  \nRecord-oriented\noperations\nPage-oriented\noperations\nSQL operations\nRelational operations\nDatabase\nSystem \nQuery Optimizer \nQuery Executor \nPage-oriented files \nSQL Operations,\nStart, Commit,  Abort\n FIGURE 6.3 \n SQL Database Architecture. A SQL operation issued by a transaction is translated through a series of layers, each of \nwhich has the option to set locks. \n\n\n If it locks at a ﬁ ne granularity, the data manager locks only the speciﬁ c data actually accessed by a trans-\naction. These locks don’t artiﬁ cially interfere with other transactions, as coarse grain locks do. However, the \ndata manager must now lock every piece of data accessed by a transaction, which can generate a lot of locking \noverhead. For example, if a transaction issues an SQL query that accesses tens of thousands of records, a data \nmanager that does record granularity locking would set tens of thousands of locks, which can be quite costly. In \naddition to the record locks, locks on associated indexes also are needed, which compounds the problem. \n There is a fundamental tradeoff between amount of concurrency and locking overhead, depending on the \ngranularity of locking. Coarse-grained locking has low overhead but low concurrency. Fine-grained locking \nhas high concurrency but high overhead. \n One compromise is to lock at the ﬁ le and page granularity. This gives a moderate degree of concurrency \nwith a moderate amount of locking overhead. It works well in systems that don’t need to run at high transaction \nrates and hence are unaffected by the reduced concurrency. It also works well in systems where transactions \nfrequently access many records per page (such as engineering design applications), so that page locks are not \nartiﬁ cially locking more data than transactions actually access. Another beneﬁ t is that it simpliﬁ es the recovery \nalgorithms for Commit and Abort, as we’ll see in Chapter 7. However, for high performance TP, record locking \nis needed, because there are too many cases where concurrent transactions need to lock different records on the \nsame page. \n Multigranularity Locking \n Most data managers need to lock data at different granularities, such as ﬁ le and page granularity; or database, \nﬁ le, and record granularity. For transactions that access a large amount of data, the data manager locks coarse \ngrain units, such as ﬁ les or tables. For transactions that access a small amount of data, it locks ﬁ ne grain units, \nsuch as pages or records. \n The trick to this approach is in detecting conﬂ icts between transactions that set conﬂ icting locks at differ-\nent granularity, such as one transaction that locks a ﬁ le and another transaction that locks pages in the ﬁ le. This \nrequires special treatment, because the lock manager has no idea that locks at different granularities might con-\nﬂ ict. For example, it treats a lock on a ﬁ le and a lock on a page in that ﬁ le as two completely independent locks \nand therefore would grant write locks on them by two different transactions. The lock manager doesn’t recog-\nnize that these locks  “ logically ” conﬂ ict. \n The technique used for coping with different locking granularities is called  multigranularity locking . In \nthis approach, transactions set ordinary locks at a ﬁ ne granularity and  intention locks at coarse granularity. \nFor example, before read-locking a page, a transaction sets an intention-read lock on the ﬁ le that contains the \npage. Each coarse grain intention lock warns other transactions that lock at coarse granularity about potential \nconﬂ icts with ﬁ ne grain locks. For example, an intention-read lock on the ﬁ le warns other transactions not to \nwrite-lock the ﬁ le, because some transaction has a read lock on a page in the ﬁ le. Details of this approach are \ndescribed in Section 6.10. \n There is some guesswork involved in choosing the right locking granularity for a transaction. For example, \na data manager may start locking individual records accessed by a transaction, but after the transaction has \naccessed hundreds of records, the data manager may conclude that a coarser granularity would work better. \nThis is called lock  escalation and is commonly supported by database systems. An alternative to lock escala-\ntion is program analysis, where the query language compiler estimates how much data will be accessed by a \ntransaction. If it estimates that a lot of data will be accessed, then it generates a hint to lock at coarse granular-\nity. Otherwise, it generates a hint to lock at ﬁ ne granularity. \n Some data managers give the transactions the option of overriding the mechanism that automatically deter-\nmines lock granularity. For example, in Microsoft SQL Server, a transaction can use the keyword PAGLOCK to \n6.2 Implementation  149\n\n\n150  CHAPTER 6 Locking\ninsist that the system use a page lock when it would otherwise use a table lock. Similarly, it can use TABLOCK \nor TABLOCKX to insist that the system use a read or write lock, respectively, on a table. Similarly, in IBM \nDB2 UDB, you can use the LOCK TABLE statement to set a read or write lock on the entire table. Such over-\nrides are useful when tuning an application whose performance is lacking due to inappropriate automatic selec-\ntion of lock granularity by the system. \n 6.3  DEADLOCKS \n When two or more transactions are competing for the same lock in conﬂ icting modes, some of them will \nbecome blocked and have to wait for others to free their locks. Sometimes, a set of transactions are all waiting \nfor each other; each of them is blocked and in turn is blocking other transactions. In this case, if none of the \ntransactions can proceed unless the system intervenes, we say the transactions are  deadlocked . \n For example, reconsider transactions T 1 and T 2 that we discussed earlier in execution E \u0002  \u0003  r 1 [ x ] r 2 [ y ] w 2 [ x ] \nw 1 [ y ] (see  Figure 6.4 ). Suppose T 1 gets a read lock on  x ( Figure 6.4a ) and then T 2 gets a read lock on  y ( Figure \n6.4b ). Now, when T 2 requests a write lock on  x , it’s blocked, waiting for T 1 to release its read lock ( Figure 6.4c ). \nWhen T 1 requests a write lock on  y , it too is blocked, waiting for T 2 to release  its read lock ( Figure 6.4d ). Since each \ntransaction is waiting for the other one, neither transaction can make progress, so the transactions are deadlocked. \n Deadlock is how two-phase locking detects nonserializable executions. At the time deadlock occurs, there \nis no possible execution order of the remaining operations that will lead to a serializable execution. In the pre-\nvious example, after T 1 and T 2 have obtained their read locks, we have the partial execution r 1 [ x ] r 2 [ y ]. There \nare only two ways to complete the execution, r 1 [ x ] r 2 [ y ] w 1 [ y ] w 2 [ x ] or r 1 [ x ] r 2 [ y ] w 2 [ x ] w 1 [ y ], both of which \nare nonserializable. \n Once a deadlock occurs, the only way for the deadlocked transactions to make progress is for at least one of \nthem to give up its lock that is blocking another transaction. Once a transaction releases a lock, the two-phase \nlocking rule says that it can’t obtain any more locks. But since each transaction in a deadlock  must obtain at least \none lock (otherwise it wouldn’t be blocked), by giving up a lock it is bound to break the two-phase locking rule. \nSo there’s no point in having a transaction release just one lock. The data manager might as well abort the transac-\ntion entirely. That is, the only way to break a deadlock is to abort one of the transactions involved in the deadlock. \n Deadlock Prevention \n In some areas of software, such as operating systems, it is appropriate to prevent deadlocks by never granting \na lock request that can lead to a deadlock. For transaction processing, this is too restrictive, because it would \nr1[x]\nr1[x] r2[y]\nr1[x] r2[y] wl2[x]-{blocked}\nr1[x] r2[y] wl2[x]-{blocked} wl1[y]-{blocked}\nData\nItem\nLocks\nHeld\nLocks\nRequested\nData\nItem\nLocks\nHeld\nLocks\nRequested\nData\nItem\nLocks\nHeld\nLocks\nRequested\nData\nItem\nLocks\nHeld\nLocks\nRequested\nx\nx\nT1,read\nT1,read\nT2,read\ny\ny\nx\nT1,read\nx\nT1,read\nT2,read\nT2,write\nT2,write\nT1,write\nT2,read\ny\ny\na.\nb.\nc.\nd.\n FIGURE 6.4 \n Execution Leading to a Deadlock. Each step of the execution is illustrated by the operations executed so far, with the \ncorresponding state of the lock table below it. \n\n\n overly limit concurrency. The reason is that transaction behavior is unpredictable. For example, in the execu-\ntion in  Figure 6.4b , once the system grants T 1 ’s request for a read lock on  x and T 2 ’s request for a read lock on \n y , deadlock is unavoidable; it doesn’t matter in which order T 1 and T 2 request their second lock. The only way \nto avoid deadlock is to delay granting T 2 ’s request to read lock  y . This is  very restrictive. It amounts to requir-\ning that T 1 and T 2 run serially; T 1 must get all of its locks before T 2 gets any of its locks. In this case, a serial \nexecution of T 1 and T 2 is the only serializable execution. But usually, transactions can be interleaved a fair bit \nand still produce a serializable execution. \n The only way to prevent deadlocks and still allow some concurrency is to exploit prior knowledge of trans-\naction access patterns. All operating system techniques to prevent deadlock have this property. In general-\npurpose TP, it is inappropriate to exploit prior knowledge. It either overly restricts the way transactions are \nprogrammed (e.g., by requiring that data be accessed in a predeﬁ ned order) or overly restricts concurrency \n(e.g., by requiring a transaction to get all of its locks before it runs). For this reason, all commercial TP prod-\nucts that use locking allow deadlocks to occur. That is, they allow transactions to get locks incrementally by \ngranting each lock request as long as it doesn’t conﬂ ict with an existing lock, and they detect deadlocks when \nthey occur. \n Deadlock Detection \n There are two techniques that are commonly used to detect deadlocks: timeout-based detection and graph-based \ndetection.  Timeout-based detection guesses that a deadlock has occurred whenever a transaction has been \nblocked for too long. It uses a timeout period that is much larger than most transactions ’ execution time (e.g., \n15 seconds) and aborts any transaction that is blocked longer than this amount of time. The main advantages of \nthis approach are that it is simple and hence easy to implement, and it works in a distributed environment with \nno added complexity or overhead. However, it does have two disadvantages. First, it may abort transactions that \naren’t really deadlocked. This mistake adds delay to the transaction that is unnecessarily aborted, since it now \nhas to restart from scratch. This sounds undesirable, but as we’ll see later when we discuss locking performance, \nthis may not be a disadvantage. Second, it may allow a deadlock to persist for too long. For example, a deadlock \nthat occurs after one second of transaction execution will be undetected until the timeout period expires. \n The alternative approach, called  graph-based detection , explicitly tracks waiting situations and periodically \nchecks them for deadlock. This is done by building a  waits-for graph, whose nodes model transactions and \nwhose edges model waiting situations. That is, if transaction T 1 is unable to get a lock because a conﬂ icting \nlock is held by transaction T 2 , then there is an edge T 1 → T 2 , meaning T 1  is waiting for T 2 . In general, the data \nmanager creates an edge T i → T k whenever transaction T i is blocked for a lock owned by transaction T k . It deletes \nthe edge when T i becomes unblocked. There is a deadlock whenever the deadlock graph has a cycle, that is, a \nsequence of edges that loops back on itself, such as T 1 → T 2 → T 1 (see  Figure 6.5 ), or T 1 → T 7 → T 4 → T 2 → T 1 . \nT1\nT1 waits-for T2’s lock on y\nT2 waits-for T1’s lock on x\nr1[x] r2[y] wl2[x]-{blocked} wl1[y]-{blocked} \nT2\n FIGURE 6.5 \n A Waits-For Graph. The graph on the left represents the waiting situations in the execution on the right (see also Figure \n6.4). Since there is a cycle involving T 1  and T 2 , they are deadlocked. \n6.3 Deadlocks  151\n\n\n152  CHAPTER 6 Locking\n Any newly added edge in the waits-for graph could cause a cycle. So it would seem that the data manager \nshould check for cycles (deadlocks) whenever it adds an edge. While this is certainly correct, it is also possible \nto check for deadlocks less frequently, such as every few seconds. A deadlock won’t disappear spontaneously, \nso there is no harm in checking only periodically; the deadlock will still be there whenever the deadlock detec-\ntor gets around to look for it. By only checking periodically, the system reduces deadlock detection cost. Like \ntimeout-based detection, it allows some deadlocks to go undetected longer than necessary. But unlike timeout, \nall detected deadlocks are real deadlocks. \n Victim Selection \n After a deadlock has been detected using graph-based detection, one of the transactions in the cycle must be \naborted. This is called the  victim . Like all transactions in the deadlock cycle, the victim is blocked. It ﬁ nds out \nthat it is the victim by receiving an error return code from the operation that was blocked, which says  “ you have \nbeen aborted. ” It’s now up to the application that issued the operation to decide what to do next. Usually, it just \nrestarts the transaction from the beginning, possibly after a short artiﬁ cial delay to give the other transactions in \nthe cycle time to ﬁ nish, so they don’t all deadlock again. \n There are many victim selection criteria that the deadlock detector can use. It could choose the one in the \ndeadlock cycle that: \n 1.  Closed the deadlock cycle: This may be the easiest to identify and is fair in the sense that it is the trans-\naction that actually caused the deadlock. \n 2.  Has the fewest number of locks: This is a measure of how much work the transaction did. Choose the \ntransaction that did the least amount of work. \n 3.  Generated the least amount of log records: Since a transaction generates a log record for each update it \nperforms (to be discussed at length in Chapter 7), this transaction is probably the cheapest to abort. \n 4.  Has the fewest number of write locks: This is another way of selecting the transaction that is probably \ncheapest to abort. \n Instead of the deadlock detector choosing a victim, the application itself can choose one . For example, \nOracle Database backs out the statement that caused the deadlock to be detected and returns an error, thereby \nleaving it up to the application to choose whether to abort this transaction or another one. 4 \n Some systems allow the transaction to inﬂ uence victim selection. For example, in Microsoft SQL Server, a \ntransaction can say  “ SET DEADLOCK_PRIORITY LOW ” or  “ SET DEADLOCK_PRIORITY NORMAL. ” If \none or more transactions in a deadlock cycle have priority LOW, one of them will be selected as victim. Among \nthose whose priority makes them eligible to be the victim, the system selects the one that is cheapest to abort. \n One consideration in victim selection is to avoid  cyclic restart , where transactions are continually restarted \ndue to deadlocks and thereby prevented from completing. One way this could happen is if the oldest transac-\ntion is always selected as victim. For example, suppose T 1 starts running, then T 2 starts, then T 1 and T 2 dead-\nlock. Since T 1 is older, it’s the victim. It aborts and restarts. Shortly thereafter, T 1 and T 2 deadlock again, but \nthis time T 2 is older (since T 1 restarted after T 2 ), so T 2 is the victim. T 2 aborts and restarts and subsequently \ndeadlocks again with T 1 . And so on. \n One way to avoid cyclic restart is to select the youngest transaction as victim. This ensures that the oldest \ntransaction in the system is never restarted due to deadlock. A transaction might still be repeatedly restarted \ndue to bad luck — if it’s always the youngest transaction in the cycle — but this is very unlikely. \n 4 In  Oracle Database Concepts ,11g Release 1 (11.1), Part Number B28318-05, Chapter 13,  “ Data Concurrency and Consistency. ” \n\n\n The problem can be avoided entirely if the transaction is given the same start time each time it is restarted, \nso that it will eventually be the oldest in the system. But this requires that the data manager accept the start-\ntime as an input parameter to the Start operation, which few data managers support. \n In the end, the application or transactional middleware usually provides the solution by tracking the num-\nber of times a transaction is restarted. An application error is reported if a transaction is restarted too many \ntimes, whether for deadlock or other reasons, at which point it is an application debugging or tuning problem \nto determine why the transaction is deadlocking so often. \n Distributed Deadlock Detection \n In practice many systems use multiple databases. They are introduced for many reasons, for example, to scale \nup the system, to separate data belonging to different applications, to simplify debugging and maintenance, or \nto add an application that requires a different data manager product. A system that uses multiple databases is \nlikely to need distributed transactions. \n In a distributed system, there are multiple data managers on different nodes of the network. A transaction \nmay access data at more than one data manager. Data managers set locks in the usual way, as if the transaction \nwere not distributed. That is, when a transaction accesses a data item at a data manager, the data manager sets \nthe appropriate lock before performing the access. \n As in the nondistributed case, sometimes a lock request becomes blocked. These blocking situations can \nexist at multiple data managers, which can lead to a deadlock that spans data managers yet is not detectable by \nany one data manager by itself. For example, let’s reconsider our favorite transactions T 1 and T 2 , and suppose \n x and  y are stored at different data managers, DM x and DM y (see  Figure 6.6 ). T 1 reads  x at DM x , setting a read \nlock, and T 2 reads  y at DM y , setting a read lock. Now, as before, T 1 tries to set a write lock on  y at DM y but is \nblocked waiting for T 2 , and T 2 tries to set a write lock  x at DM x but is blocked waiting for T 1 . This is the same \ndeadlock we observed in  Figure 6.4 and  Figure 6.5 ; T 1 is waiting for T 2 at DM y and T 2 is waiting for T 1 at \nDM x . However, neither DM x nor DM y alone can see the deadlock. They each just see one waiting situation. \n Dozens of algorithms to detect distributed deadlocks have been published by database researchers over \nthe years, but only a few are used in practice. One simple technique is to designate one data manager  D as the \ndistributed deadlock detector and have every other data manager periodically send its waits-for graph to  D. \nD has a complete view of waits-for situations across all nodes and can therefore detect distributed deadlocks. \nThis can work well for a set of data managers from a single vendor that are executing on machines that have \na high speed interconnect. However, in a more heterogeneous system, this requires more cooperation between \ndata managers than one can reasonably expect. And if communication speeds are slow, frequent exchange of \ndeadlock graphs may be impractical. \nrl1[x]\nwl2[x] {blocked}\nrl2[y]\nwl1[y] {blocked}\nDMx\nDMy\n FIGURE 6.6 \n A Distributed Deadlock. DM x and DM y are independent data managers, perhaps at different nodes of the network. At DM x , \nT 2 is waiting for T 1 , which is waiting for T 2 at DM y . The transactions are deadlocked, but neither DM x nor DM y alone can \nrecognize this fact. \n6.3 Deadlocks  153\n",
      "page_number": 164
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 172-181)",
      "start_page": 172,
      "end_page": 181,
      "detection_method": "topic_boundary",
      "content": "154  CHAPTER 6 Locking\n The most popular approach for detecting distributed deadlocks is even simpler, namely, timeout-based detec-\ntion. The implementation is trivial, it works in heterogeneous systems, and it is unaffected by slow communica-\ntions (except to select an appropriate timeout period). Moreover, it performs surprisingly well. We will see why \nin the next section. \n 6.4  PERFORMANCE \n Locking performance is almost exclusively affected by delays due to blocking, not due to deadlocks. Deadlocks \nare rare. Typically, fewer than 1% of transactions are involved in a deadlock. \n One practical reason why deadlocks are rare is that they can have very bad consequences, so database \nadministrators (DBAs) work hard to avoid them. In a poorly constructed system, a deadlock can cause a user’s \njob to sit there for minutes. If too many deadlocks occur, an entire database can be rendered unusable. So \nDBAs quickly ﬁ nd out about common deadlocks and minimize their frequency of occurrence. \n Lock Conversions \n One situation that can lead to many deadlocks is lock conversions.  A lock conversion is a request to upgrade a \nread lock to a write lock. This occurs when a transaction reads a data item, say  x , and later decides to write it, a \nrather common situation. If two transactions do this concurrently, they will deadlock; each holds a read lock on \n x and requests a conversion to a write lock, which can’t be granted. Notice that it is not safe for a transaction to \nrelease its read lock before upgrading it to a write lock, since that would break two-phase locking. \n This problem can be prevented if each transaction gets a write lock to begin with and then downgrades it \nto a read lock if the transaction decides not to write the item. This can be done, provided that the transaction \nis programmed in a relatively high-level language, such as SQL. To see how, consider a SQL Update state-\nment, which updates the subset of rows in a table that satisﬁ es the predicate in the statement’s WHERE clause. \nA na ï ve implementation would scan all the rows of the table. For each row, it sets a read lock, checks whether \nthe row satisﬁ es the WHERE clause, and if so, converts the read lock to a write lock and updates the row. To \navoid the possible lock conversion deadlock in the last step, it could instead work as follows: For each row, it \nsets a write lock, checks whether the row satisﬁ es the WHERE clause; if so, it updates the row and if not, it \nconverts the write lock to a read lock. \n Downgrading the write lock to a read lock looks like it might be breaking two-phase locking, since reduc-\ning the strength of the lock is much like releasing the lock. Ordinarily, two-phase locking would disallow this, \nbut here, since the transaction only reads the row, it’s safe: The transaction ﬁ rst sets a write lock, in case it \nneeds that lock later to avoid a deadlock. Once it realizes it will not write the row, it knows that it only needed \na read lock, so it downgrades to a read lock. \n The approach can be approximated even if the transaction is programmed in a lower level language, where \nupdates are performed by ﬁ rst reading a data item and then later issuing a write operation. However, in this case, \nthe transaction needs to give an explicit hint in the read operation that a write lock is required. Downgrading the \nlock to a read lock would require another hint; or it may not be done, at the expense of reduced concurrency. \n Although getting write locks early can reduce concurrency, the overall performance effect is beneﬁ cial \nsince it prevents a likely deadlock. Therefore, many commercial SQL data managers use this approach. \n One can improve concurrency somewhat by adding an  update lock mode . An update lock conﬂ icts with \nupdate locks and write locks, but not with read locks. In this approach, when a transaction accesses a data item \nthat it may later update, it sets an update lock instead of a write lock. If it decides to update the data item, it \n\n\n c onverts the update lock to a write lock. This lock conversion can’t lead to a lock conversion deadlock, because \nat most one transaction can have an update lock on the data item. (Two transactions must try to convert the lock \nat the same time to create a lock conversion deadlock.) On the other hand, the beneﬁ t of this approach is that an \nupdate lock does not block other transactions that read without expecting to update later on. The weakness is that \nthe request to convert the update lock to a write lock may be delayed by other read locks. If a large number of data \nitems are read and only a few of them are updated, the tradeoff is worthwhile. This approach is used in Microsoft \nSQL Server. SQL Server also allows update locks to be obtained in a SELECT (i.e., read) statement, but in this \ncase, it will not downgrade the update locks to read locks, since it doesn’t know when it is safe to do so. \n Lock Thrashing \n By reducing the frequency of lock conversion deadlocks, we have dispensed with deadlock as a major perfor-\nmance consideration, so we are left with blocking situations. Blocking affects performance in a rather dramatic \nway. Until lock usage reaches a saturation point, it introduces only modest delays — signiﬁ cant, but not a seri-\nous problem. At some point, when too many transactions request locks, a large number of transactions sud-\ndenly become blocked, and few transactions can make progress. Thus, transaction throughput stops growing. \nSurprisingly, if enough transactions are initiated, throughput actually decreases. This is called  lock thrashing \n(see  Figure 6.7 ). The main issue in locking performance is to maximize throughput without reaching the point \nwhere thrashing occurs. \n One way to understand lock thrashing is to consider the effect of slowly increasing the  transaction load , \nwhich is measured by the number of active transactions. When the system is idle, the ﬁ rst transaction to run \ncannot block due to locks, because it’s the only one requesting locks. As the number of active transactions \ngrows, each successive transaction has a higher probability of becoming blocked due to transactions already \nrunning. When the number of active transactions is high enough, the next transaction to be started has virtually \nno chance of running to completion without blocking for some lock. Worse, it probably will get some locks \nbefore encountering one that blocks it, and these locks contribute to the likelihood that other active transac-\ntions will become blocked. So, not only does it not contribute to increased throughput, but by getting some \nlocks that block other transactions, it actually reduces throughput. This leads to thrashing, where increasing \nthe workload decreases the throughput. \nThroughput\nHigh\nHigh\nNumber of Active\nTransactions\nLow\nLow\nThrashing\nRegion\n FIGURE 6.7 \n Lock Thrashing. When the number of active transactions gets too high, many transactions suddenly become blocked, \nand few transactions can make progress. \n6.4 Performance  155\n\n\n156  CHAPTER 6 Locking\n There are many techniques open to designers of data managers, databases, and applications to minimize \nblocking. However, even when all the best techniques are applied, if the transaction load is pushed high enough, \nlock thrashing can occur, provided other system bottlenecks (such as disk or communications bandwidth) don’t \nappear ﬁ rst. \n Tuning to Reduce Lock Contention \n Suppose a transaction holds a write-lock  L for  t seconds. Then the maximum transaction rate for transactions \nthat set  L is 1/ t (i.e., one transaction per  t seconds). To increase the transaction rate, we need to make  t smaller. \nThus, most techniques for minimizing blocking attempt to reduce the time a transaction holds its locks. \n One approach is to set lock  L later in the transaction’s execution, by accessing  L ’s data later. Since a trans-\naction releases its locks when it completes, the later in its execution that it sets a lock, the less time it holds \nthe lock. This may require rearranging application logic, such as storing an update in a local variable and only \napplying it to the database just before committing the transaction. \n A second approach is to reduce the transaction’s execution time. If a transaction executes faster, it com-\npletes sooner, and therefore holds its locks for a shorter period. There are several ways to reduce transaction \nexecution time: \n ■  Reduce the number of instructions it executes, called its  path length . \n ■  Buffer data effectively, so a transaction rarely has to read from disk. If data must be read from disk, do \nthe disk I/O before setting the lock, to reduce the lock holding time. \n ■  Optimize the use of other resources, such as communications, to reduce transaction execution time. \n A third approach is to split the transaction into two or more shorter transactions. This reduces lock holding \ntime, but it also loses the all-or-nothing property of the transaction, thereby requiring one of the techniques for \nmultitransaction business processes discussed in Chapter 5. This can complicate the application design, but it’s \nthe price to be paid for reduced lock contention. For example, instead of one all-or-nothing transaction, there \nare now two transactions; there needs to be recovery code for the case where the ﬁ rst one succeeds and the sec-\nond one doesn’t, something that wasn’t required when there was just one transaction. \n Recall that lock granularity affects locking performance. One can reduce conﬂ icts by moving to ﬁ ner granu-\nlarity locks. Usually, one relies on the data manager to do this, but there are cases where a database or application \ndesigner can affect granularity. For example, suppose a data manager uses record granularity locking. Consider \na ﬁ le that has some frequently updated ﬁ elds, called  hot ﬁ elds, and other infrequently updated ones, called  cold \nﬁ elds. In this case, it may be worth splitting the ﬁ le  “ vertically ” into two ﬁ les, where each record is split in half, \nwith its hot ﬁ elds in one ﬁ le and its cold ﬁ elds in the other. For example, the ﬁ le may contain information about \ncustomer accounts, and we split it with customer number, name, and balance (the hot ﬁ eld) in one ﬁ le, and cus-\ntomer number, address, and phone number (the cold ﬁ elds) in the other (see  Figure 6.8 ). Note that customer num-\nber, the key, must appear in both ﬁ les to link the two halves of each record. 5 Before splitting the ﬁ le, transactions \nthat used the cold ﬁ elds but not the hot one were delayed by locks held by transactions accessing the hot ﬁ eld. \nAfter splitting the ﬁ le, such conﬂ icts do not arise. \n In this example, even though the name ﬁ eld is not frequently updated, it is included with the hot ﬁ eld bal-\nance because in this hypothetical application name and balance are usually accessed together by the same trans-\naction. If name were included with the cold ﬁ elds address and phone number, then a transaction that updates a \nbalance would have to set a read lock on the cold half of the record, which would increase locking overhead and \ndata access cost. \n 5 In a relational database system, you could make the original table available as a view of the partitioned tables. This avoids rewriting \nexisting programs and offers more convenient access to a transaction that requires both hot and cold ﬁ elds. \n\n\n When a running system is on the verge of thrashing due to too much blocking, the main way to control the \nproblem is to reduce the transaction load. This is relatively straightforward to do: reduce the maximum number \nof threads allowed by each data manager. One good measure for determining that the system is close to thrash-\ning is the fraction of active transactions that are blocked. Various studies have shown that a value of about 30% \nis the point at which thrashing starts to occur. This fraction is available in most systems, which expose the \nnumber of active and blocked transactions. \n Recall that detecting deadlocks by timeout can make mistakes by aborting transactions that are not really \ndeadlocked. However, if a transaction is blocked for a long time, this suggests that the transaction load is too \nhigh, so aborting blocked transactions may be good to do. Of course, to get the full beneﬁ t of this load reduc-\ntion, the aborted transaction should not be immediately restarted, which would keep the transaction load at too \nhigh a level. But even if it is restarted immediately, aborting it may have a positive effect by unblocking some \ntransactions that are waiting for the aborted transaction’s locks. \n Some impractical locking policies are useful to understand, because they provide insight on how locking \nperformance is affected by certain factors. One such policy is  conservative locking : after a transaction exe-\ncutes the Start operation, it waits until it can set all the locks it needs, at which point it sets all the locks at \nonce. Since blocked transactions hold no locks, this increases the transaction load that can be handled, which \nis good. However, the approach is impractical for two reasons: First, a transaction must know exactly which \nlocks it needs before it starts. Since it ordinarily does not know this, it would be compelled to set all the locks \nthat it  might need, typically a much larger set than the exact set it  does need, which thereby increases lock con-\ntention. Second, a transaction may have to try to acquire all its locks many times before it gets all of them, so \neach attempt to get all its locks must be practically free, which it is not. \n Another interesting impractical locking approach is the  pure restart policy . In this approach, transactions \nnever wait. Rather, if a transaction requests a lock that conﬂ icts with one that is already set, it aborts and waits \nuntil the conﬂ icting lock is released before it restarts. If aborts are cheap and there is no contention for other \nresources (besides locks), a pure restart policy can sustain a higher transaction load than a standard blocking \npolicy (where transactions wait for conﬂ icting locks to be released). Of course, aborts do have a cost and often \nother resources are in limited supply, which is why the blocking policy is normally used in practice. However, \nas we’ll see in Section 6.8, there is a practical case where a pure restart policy is preferable. \nb. Partitioning into two files, with hot ﬁelds on the left and cold ﬁelds on the right\na. Original file\nCustomer\nNumber\nName\nAddress\nBalance\nPhone\nNumber\nName\nBalance\nAddress\nPhone\nNumber\nCustomer\nNumber\nCustomer\nNumber\n FIGURE 6.8 \n Splitting Hot and Cold Fields to Avoid Contention. By moving the cold ﬁ elds, Address and Phone Number, into a separate \nﬁ le, accesses to those ﬁ elds aren’t delayed by locks on the hot ﬁ elds, Name and Balance, which are now in a separate ﬁ le. \n6.4 Performance  157\n\n\n158  CHAPTER 6 Locking\n Several other practical approaches to improving locking performance are described in later sections of \nthis chapter: Section 6.5, on hot spot techniques; Section 6.6, on techniques for mixed loads of queries and \nupdates, such as weaker degrees of isolation and multiversion data; and Section 6.8, on optimistic concurrency \ncontrol. \n A Mathematical Model of Locking Performance \n Some fairly deep mathematics has been applied to locking performance. Although it isn’t necessary to under-\nstand the math to know how to reduce lock contention, the math does produce formulas that help explain \nthe observed phenomena. Some of the key formulas can be explained using a fairly simple model, which we \ndescribe here. The model can be used to estimate the probability of conﬂ icts and deadlock when designing \ntransactions. Using it in a ﬁ ve-minute calculation can save you a lot of trouble. \n In the model each transaction issues requests for  K write locks with an average time  t between lock \nrequests. The overall database has  D data items that can be locked, and there are  N transactions running at any \ngiven time (see  Figure 6.9 ). \n Since each transaction requests  K write locks, at any given time each running transaction has  K /2 write \nlocks on average. Therefore, on average there are  NK /2 locks held by the system at any given time. When a \ntransaction requests a new lock, if it makes a random selection among the  D lockable data items, then the prob-\nability it conﬂ icts with an existing lock is ( NK /2)/ D , or  NK /2 D . Since each transaction makes  K lock requests, \nthe probability it encounters a conﬂ ict sometime during its execution is  K times the probability of a conﬂ ict, \nwhich is  K  \u0004  NK /2 D , or  NK 2 /2 D . \n The probability that two transactions deadlock is the probability that a transaction T 1 is blocked (i.e., \n NK 2 /2 D ) times the probability that another transaction T 2 is blocked waiting for T 1 . Since there are  N transac-\ntions in the system and T 2 is equally likely to conﬂ ict with any of them, the probability that T 2 is blocked wait-\ning for T 1 is the probability that T 2 is blocked (i.e.,  NK 2 /2 D ) divided by  N  – 1. To simplify the formula, we’ll \nassume  N is large enough that we can use  N instead of  N  – 1. So the probability of a deadlock involving two \ntransactions is: \n \n (\n/\n)\n(\n/\n)/\n(\n/4\n)/N\n/\nNK\nD\nNK\nD N\nN K\nD\nNK\nD\n2\n2\n2\n4\n2\n4\n2\n2\n2\n4\n\u0004\n\u0003\n\u0003\n \n \nStart\nTransaction Model\n• K lock requests per transaction\n• t seconds average time between lock requests\nSystem Model\n• N transactions accessing the database\n• D data items in the database\nRequest\nlock1\nx1\nxD\nRequest\nlock2\nRequest\nlockK\n  Commit\nT1\nT2\nTN\n. . .\n. . .\n. . .\nt\nt\nt\n FIGURE 6.9 \n Mathematical Model of Transactions and System. Using this model, formulas can be derived for probability of conﬂ ict \nand deadlock, and for throughput. \n\n\n The probability of deadlock cycles that involve three or more transactions is so much smaller than for two \ntransactions that it can be ignored without losing much accuracy. Therefore, dropping the constants, we can \nsummarize the preceding analysis as follows: \n ■  The probability of a conﬂ ict is proportional to  K 2 N/D \n ■  The probability of a deadlock is proportional to  K 4 N/D 2 \n Since a typical application might have a  K of 20 (for an average transaction) and a  D of one million, you \ncan see from the previous two formulas why deadlock is so rare relative to conﬂ ict — a deadlock is  K 2 / D as \nlikely as a conﬂ ict, or only 0.0004 as likely. \n Now let’s look at transaction throughput. If transactions were never blocked, then the throughput would \nbe  N /( t  \u0004  ( K  \u0005  1)), where  t  \u0004  ( K  \u0005  1) is the transaction’s execution time. For example, if  N is 50 and each \ntransaction executes for 0.5 seconds, then the throughput would be 100 transactions per second. However, at \nany given time some fraction of transactions are blocked and therefore are not contributing to system through-\nput. We can estimate that fraction by the probability that a transaction encounters a conﬂ ict ( K 2 N /2 D ) times the \nfraction of its total execution time (including blocked time) that it spends waiting if it encounters a conﬂ ict. \nLet’s use  A to denote the latter. Thus, we have the following: \n The throughput is proportional to ( N / tt )  \u0004  (1  –  AK 2 N /2 D ), where \n ■  tt  \u0003  t  \u0004  ( K  \u0005  1) is the transaction’s execution time assuming it is never blocked \n ■  A  \u0003  fraction of total transaction execution time (including blocked time) that a transaction spends wait-\ning given that it encounters a conﬂ ict, typically 1/3 to 1/2 \n Looking at throughput, we see that using ﬁ ner grain locks increases  D , which decreases  K 2 N/D , thereby \nincreasing throughput (assuming that transactions are really accessing ﬁ ne-grained data, so that K is unaffected \nby decreasing lock granularity). Shortening transaction execution time decreases  tt , which increases  N/tt , and \nhence increases throughput. \n 6.5  HOT SPOTS \n Even when a system locks ﬁ ne-grained data items, some of those data items are so frequently updated that they \nbecome locking bottlenecks. Such data items are called  hot spots (i.e., they are so frequently accessed that the \ndata metaphorically  “ gets hot ” ). Some common kinds of hot spots are: \n ■  Summary information, such as the amount of money in a bank branch, since every debit and credit trans-\naction needs to update that value \n ■  The end-of-ﬁ le marker in a ﬁ le being used primarily for data entry, since each insert operation moves \n(i.e., updates) the end-of-ﬁ le marker and therefore needs to lock it \n ■  The next serial number to be sequentially assigned, such as order number or transaction number, since \nmany transaction types need to assign such serial numbers \n In these cases, the hot spot is already a ﬁ ne-grained data item, so moving to a ﬁ ner granularity to relieve the \nbottleneck is not an option. Other techniques are needed. \n There are four main techniques to relieve hot spot bottlenecks: \n 1.  Keep the hot data in main memory. Since accesses to main memory are fast, the transaction accessing \nthe hot data will hopefully execute quickly and therefore not hold onto its lock for too long. \n6.5 Hot Spots  159\n\n\n160  CHAPTER 6 Locking\n 2.  Delay operations on the hot spot until just before the transaction commits. That way, the transaction \nholds its lock on the hot data for the minimum amount of time. \n 3.  Replace read operations by veriﬁ cation operations that can be delayed until just before the transaction \ncommits. \n 4.  Group operations into private batches and apply the batch to the hot spot data only periodically. \n Often , these techniques are used in combination. \n The ﬁ rst technique is relatively automatic. Since the data is hot, the data manager’s cache management \nalgorithm will probably keep the data in main memory without any special attention. Still, some systems \nmake a special point of nailing down hot data in main memory, so it can’t be paged out even if it hasn’t been \naccessed in awhile. \n Delaying Operations Until Commit \n The second technique can be implemented by carefully programming a transaction so that its updates come \nat the end. One can automate this approach. Instead of executing operations on data items when they occur, \nthe data manager simply writes a description of each operation in a log. 6 After the transaction is ﬁ nished and \nready to start committing, the data manager actually executes the operations in the transaction’s log. The data \nmanager gets locks for the operations only during this actual execution. Since this execution is at the very end \nof the transaction, the lock holding time will be quite short. \n For example, consider a data entry application that is adding records to the end of a ﬁ le. Each transaction \nmust lock the end-of-ﬁ le marker from the time it starts its insertion until after it commits. Since every transac-\ntion is adding a record, the end-of-ﬁ le marker is likely to be a lock bottleneck. One can avoid this problem by \ndelaying record insertions until the transaction is ready to commit, thereby reducing the lock holding time on \nthe end-of-ﬁ le marker. This technique is used in IBM’s IMS Fast Path system for data that is declared to be a \nData Entry database. \n One problem with this technique is read operations. A transaction program usually cannot delay read oper-\nations until the end, because the values it reads affect its execution — it affects the values it writes and it affects \nits control ﬂ ow via if-statements and the like. For any read operation that must be executed when it is issued \n(and not delayed until the end of the transaction’s execution), the data manager must set a read lock. This is a \nproblem if the read lock is set on a hot spot. \n Optimistic Methods \n One way to circumvent this problem of read operations is to build reads into higher level operations that don’t \nreturn data item values to the calling program. For example, consider an operation Decrement( x ), which sub-\ntracts one from data item  x . To decrement  x , the operation needs to read the current value of  x , but it need not \nreturn that value to the caller. It therefore can be deferred until the transaction is ready to commit. However, \nsuppose instead that Decrement( x ) subtracts one from  x only if  x is positive, and it returns True or False to \nindicate whether or not it actually subtracted one from  x . Since Decrement returns a value to its caller, it can-\nnot be deferred. Unfortunately, like the second version of Decrement, many hot spot operations need to return \na value and therefore cannot be deferred. \n To circumvent the problem of deferring operations that return a value, we need to be a little more devious. \nInstead of simply deferring the operation until commit, the data manager executes the operation twice: ﬁ rst, \n 6 This log is local to the transaction. It is unrelated to the shared recovery log to be discussed at length in Chapter 7. \n\n\n when it is initially issued by the application and second, as a deferred operation at commit time (see  Figure \n6.10 ). During the operation’s ﬁ rst execution, the data manager logs the value returned by the operation along \nwith the operation itself, discards any updates that the operation performs, and releases its lock at the end of \nthe operation. At commit time, the data manager reacquires the necessary lock, executes the logged operation \nagain, but this time it allows the updates to be installed and holds the lock until the transaction is done. In addi-\ntion, it checks that the operation returns the same value  v at commit time as it did initially, by comparing the \nlogged value to  v ; if they’re not the same, it aborts the transaction. \n Let ’s apply this technique to the previous example. If Decrement( x ) returns True during the ﬁ rst execution \nof the operation, then its update is thrown out and True is logged, but no lock is held on  x . (In terms of the \nprevious paragraph  v  \u0003  True.) When Decrement( x ) is re-executed  at commit time, it sets and holds a lock, its \nupdate (if it makes one) is allowed to be installed, and the value returned by Decrement at commit time is com-\npared to the logged value True. If they are different, the transaction is aborted. The reason they could be dif-\nferent is that other transactions decremented  x between this transaction’s two Decrement operations. The ﬁ rst \nDecrement executed when  x is greater than zero, but by the time the second Decrement executes  x equals zero. \n To see why this works, consider what happens if the data manager actually sets a lock on the data during \nthe ﬁ rst execution. Then of course the operation would return the same value during the initial and deferred \nexecutions, since the data that the operation is reading couldn’t change during that period. Instead of setting a \nlock, the data manager simply checks at commit time that the operation returns the same value, which effec-\ntively checks that the execution behaves as if the lock were held. \n The reason why this helps is that it allows concurrent conﬂ icting operations on the hot spot data since the data \nisn’t locked during its initial execution. That is, for a given transaction, the value of the data read by the operation \ncan change between its two executions of Decrement, as long as that change doesn’t affect the value returned by \nthe operation. For example, suppose a transaction T 1 issues Decrement( x ) and that when Decrement( x ) executes \nthe ﬁ rst time,  x  \u0003  2, so it returns True. Suppose that before T 1 commits, another transaction T 2 decrements  x and \ncommits. Therefore, when T 1 issues its commit operation,  x  \u0003  1. But that’s all right. At commit time, T 1 ’s re-\nexecution  of Decrement( x ) decrements  x to zero and returns True, which is the same value that it returned during \nits ﬁ rst execution. Notice that T 1 and T 2 executed concurrently, even though they both updated  x . If they had used \nordinary locking, one of them would have been delayed until the other one committed and released its lock. \n To illustrate a case where an abort occurs, suppose that initially  x  \u0003  1 instead of  x  \u0003  2. So T 1 executes \nDecrement( x ) and returns True. Then T 2 decrements  x and commits (before T 1 commits). Then when T 1 re-executes \nvoid OptimisticTransaction;\n  { Start;\n     .\n     .\n     .\n     b = Decrement(x)\n     .\n     .\n     .\n    Commit;\n  \n  }\nSystem logs  “Decrement(x)” and the value returned\nSystem replays the log. If  “Decrement(x)” returns a different\nvalue than was previously logged, then abort else commit\n FIGURE 6.10 \n Using a Decrement Operation with Optimistic Locking. No locks are set when Decrement( x ) ﬁ rst executes. During the \nreplay of Decrement( x ), the system sets locks, but aborts if the result Decrement( x ) changed since the original execution. \n6.5 Hot Spots  161\n\n\n162  CHAPTER 6 Locking\n Decrement( x ) at commit time,  x  \u0003  0, so it returns False, which is different than what it returned during its ﬁ rst \nexecution, so T 1 aborts and needs to be restarted. When T 1 is re-executed , it ﬁ nds  x  \u0003  0 during its ﬁ rst execution \nof Decrement( x ) and takes appropriate action. For example, if  x represents the number of available reservations, it \nwould report that there are no more reservations available. \n This technique can be effective even for operations that don’t do any updates. For example, consider an \noperation Verify( f ), where  f is a predicate formula that references data items and evaluates to True or False. Like \nDecrement( x ), this operation can be deferred until the end of the transaction by logging not only the operation, \nbut also the value it returns (i.e., True or False). When the operation is replayed at commit time, it locks any \ndata items it accesses, and if it evaluates to a different value than it did during normal execution, its transaction \naborts. \n This Verify operation can be used with a deferred Decrement that does not return a value. For example, \nconsider an inventory application that keeps track of the number of items in stock. It can accept orders for an \nitem until there are none in stock. So, suppose that for each inventory item  i , it stores the quantity in stock, \nQuantity( i ). A transaction that processes an order for item  i should decrement Quantity( i ) provided that it \ndoesn’t make Quantity( i ) negative. It can do this by executing: \n EnoughAvailable\nVerify Quantity\n \n=\n≥\n(\n( )\n)\ni\n1  \n If EnoughAvailable then Decrement(Quantity( )) else Print(\ni\n“\n”\nInsufficient stock. ) \n The semantics here is surprisingly subtle. For example, this example works only if Decrement is deferred. This \nmethod, using a restricted form of the Verify operation, is used in IMS Fast Path in its Main Storage Databases \nfeature. \n This idea of executing an operation without setting locks, and checking that the operation is still valid at \ncommit time, is called  optimistic concurrency control . It is called optimistic because you have to be opti-\nmistic that the check at commit time is usually OK. If it fails, the penalty is rather high — you have to abort the \nwhole transaction. In the previous inventory application, for example, the technique would work well only if \nmost items are usually in stock, which is the expected case in most businesses. By contrast, two-phase locking \nis pessimistic, in that a transaction sets locks in anticipation of conﬂ icts that may never arise. Other scenarios \nwhere optimistic concurrency control is useful are presented in Section 6.8. \n Batching \n Another technique that is used to relieve hot spots is batching. Instead of having each transaction update the \nhot data when it needs it, it batches its effect across a set of transactions. For example, in a data entry applica-\ntion, instead of appending records to the shared ﬁ le in each transaction, each transaction appends the record to \na local batch (one batch for each thread of executing transactions). Since each thread has a private batch, there \nis no lock contention for the batch. Periodically, the batch is appended to the shared ﬁ le. As another example, \nconsider the problem of assigning serial numbers. Instead of reading the latest serial number within each trans-\naction, a batch of serial numbers is periodically set aside for each thread. The thread assigns serial numbers \nfrom its private batch until it runs out, at which time it gets another batch. \n Batching is effective at relieving hot spots, but it has one disadvantage — failure handling requires extra \nwork. For example, after a failure, the private batches of appended records must be gathered up and appended \nto the ﬁ le. Similarly, if it’s important that all serial numbers actually be used, then after a failure, unused serial \nnumbers have to be collected and reassigned to threads. Sometimes, the application can allow the failure han-\ndling to be ignored, for example, if lost serial numbers are not important. \n\n\n Partitioning \n The load on a hot data item can be reduced by partitioning it. For example, if  x represents the number of avail-\nable reservations and is hot, it can be partitioned into  x 1 ,  x 2 , and  x 3 , where the values of  x 1 ,  x 2 , and  x 3 are approx-\nimately equal and  x 1  \u0005  x 2  \u0005  x 3  \u0003  x . Each transaction that decrements  x randomly selects one of the partitions \nto use. Thus, instead of applying 100% of the transaction load to  x , one third of the load is applied to each parti-\ntion. The number of partitions is selected to be large enough so that the load on each partition doesn’t create a \nhot spot bottleneck. \n The main problem with partitioning is balancing the load among the partitions. In the previous example, \nwe balanced the load by randomizing each transaction’s selection of a partition. However, it’s still possible that \nmore transactions are applied to one partition than another. Therefore, it’s possible that one partition will run \nout of available reservations while other partitions still have some reservations left. To ensure that a transaction \nis denied a reservation only if all partitions have been exhausted, the application would have to try all three \npartitions. So, once two of the partitions are empty, all transactions are applied to the nonexhausted partition, \nmaking it a hot spot. It therefore may be better to deny a reservation immediately, if the partition it selected is \nempty. \n Partitioning  x also has the effect of making the value of  x more expensive to obtain. To read  x , a transac-\ntion has to read  x 1 ,  x 2 , and  x 3 and calculate their sum. This isn’t very burdensome, unless this value is required \nfrequently. In that case, the read locks on  x 1 ,  x 2 , and  x 3 obtained by each transaction that reads  x may cause a \nlocking bottleneck with respect to the transactions that update each partition. It may be satisfactory to read the \nvalues of  x 1 ,  x 2 , and  x 3 in separate transactions, which would relieve the bottleneck at the expense of getting an \naccurate value of  x . If not, then one of the techniques described in the next section is needed. \n 6.6  QUERY-UPDATE PROBLEMS \n Another major source of concurrency bottlenecks is queries; that is, read-only requests for decision support \nand reporting. Queries typically run much longer than update transactions and they access a lot of data. So, if \nthey run using two-phase locking, they often set many locks and hold those locks for a long time. This creates \nlong, often intolerably long, delays of update transactions. There are three popular approaches to circumvent-\ning this problem: data warehousing, weaker consistency guarantees, and multiversion databases. \n Data Warehousing \n A simple way to avoid lock conﬂ icts between queries and updates is to run them against different databases. \nTo do this, one creates a  data warehouse , which is a snapshot of data that is extracted from TP databases. \nQueries run against the data warehouse and updates run against the TP databases. Periodically, the contents of \nthe data warehouse is refreshed, either by reloading it from scratch or by extracting only those values from the \nTP database that have changed since the last time the data warehouse was refreshed. \n There are several reasons why it makes sense to use a data warehouse, in addition to relieving lock con-\ntention between queries and updates. First, when doing data analysis, it’s often important that the data not be \nchanging in between queries. For example, suppose you are trying to understand trends in customer behavior. \nIf the database contents changes after every query you run, then you’re never quite sure whether the differences \nyou’re seeing are due to changes in the query or changes in the underlying data. \n Second , it’s often important to run queries against data that is extracted from multiple databases. For example, \nyou may be interested in cross-correlating information in the purchase order, inventory, and sales applications. \n6.6 Query-Update Problems  163\n",
      "page_number": 172
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 182-189)",
      "start_page": 182,
      "end_page": 189,
      "detection_method": "topic_boundary",
      "content": "164  CHAPTER 6 Locking\n Often, such applications are developed independently over a long period of time, which leads to discrepancies \nbetween the data in their databases. For example, they may use different ways to encode the same information. \nAlso, since the applications run independently, there may be operational errors that cause their databases to dif-\nfer. For example, when a shipment arrives, the shipping clerk sometimes types the wrong corresponding pur-\nchase order number. For these reasons, it is common practice to transform and  “ scrub ” TP data before putting it \nin the data warehouse, so that queries see a  “ clean ” database. If queries were run against the TP data, they would \nsee data that is untransformed and partially inconsistent, making the results less useful. \n Third , it’s important that a TP system has excellent, predictable response time, even under heavy load. For \nexample, if an Internet retail store becomes a bit sluggish, the customer is likely to try a web search to ﬁ nd \nanother store. However, when data analysis queries are running, excellent response time is hard to guarantee, \nbecause such queries can put a virtually unbounded load on the data manager. This scenario is avoided by running \nqueries on a data warehouse system, where queries can slow down other queries, but not on-line transactions. \n For these reasons, data warehousing is a very popular architecture. Still, there are times when queries need \nto run against the same database as update transactions, for example, to get an up-to-the-second view of the \ndatabase. In these situations, solutions to the query-update problem are needed. \n Degrees of Isolation \n To avoid the query-update problem, many applications just give up on serializability for queries by using weaker \nlocking rules. These rules, sometimes called  degrees of isolation or  isolation levels , are codiﬁ ed in the SQL \nstandard and are therefore offered by most SQL database products. \n One such rule is called  read committed (sometimes called  Degree 2 )  isolation . If a query executes with \nread committed isolation, then the data manager holds a read lock on a data item only while the query is actu-\nally reading the data. As soon as the data is read, it releases the lock. \n The beneﬁ t of read committed isolation is performance. Some simulation studies of mixed workloads have \nshown throughput improves by a factor of three over two-phase locking. For some workloads, the performance \nimprovement is even larger. \n Read committed isolation is weaker than two-phase locking, which requires the transaction to hold read \nlocks until it has obtained all its locks. Read committed isolation does ensure that the query only reads data that \nwas produced by transactions that committed. That is, if an active update transaction is currently modifying \na data item, the query will not be able to lock it until that  updater (i.e., update transaction) has committed or \naborted. However, it does not ensure serializability. For example, if the query reads data items  x and  y , and an \nupdater is updating those data items, one possible scenario is the following: \n ■  The query reads  x and then releases its lock on  x . \n ■  Then the updater updates  x and  y , commits, and releases its locks. \n ■  Then the query reads  y . \n The query looks like it executed before the updater on  x but after the updater on  y , a result that would be \nimpossible in a serial execution. \n Under read committed isolation, a transaction that reads the same data item twice might read different val-\nues for each of the read operations. This can happen because another transaction can update the data in between \nthe two reads. For this reason, we say that read committed isolation allows  nonrepeatable reads . It’s a bit of a \nmisnomer, since the transaction is allowed to repeat a read; it’s just that it may get different values each time it \nexecutes the read. \n A slightly stronger version of read committed isolation, called  cursor stability , is offered by some SQL data-\nbase systems. In SQL, the result of a query is a set of rows that is returned to a program as a  cursor . A program \n\n\n can scan the result of the query by iterating over the cursor, one row at a time. Using read committed isolation, \na program would obtain a read lock on the row before reading it and release the lock immediately thereafter. \nUsing cursor stability, the program holds the read lock a little longer, until it asks to move to the next row using \nthe SQL fetch operation. At that point, the database system ﬁ rst releases the lock on the current row and then \nacquires the lock on the next row. Thus, the row that the cursor currently identiﬁ es is stable (i.e., read locked) \nwhile the program is looking at it — hence the term, cursor stability. \n Using cursor stability, a program can update the current row of the cursor without risking a race condition. \nSince it is holding a read lock on the row when it issues the update, the data manager can convert the read \nlock to a write lock. By contrast, if the program used read committed isolation, it would release its read lock \non the row immediately after executing its read operation and before issuing its write operation. Thus, two \nprograms could do this concurrently. They each read the record, then they each release their read lock, and \nthen they each update the record, which causes one program to overwrite the other. Cursor stability avoids this \noutcome. \n Given the performance beneﬁ ts of read committed isolation, many SQL database products make it the default \nisolation level, so that an application must add special keywords to obtain serializable (i.e., two-phase locked) \nbehavior. Even though the answers could be incorrect, customers don’t seem to mind very much. There is no \nsatisfactory technical explanation for this, though there is an intuitive explanation that might be true, at least for \nqueries: Queries often produce summary results about a database. If the database is being updated frequently, \nthen it doesn’t matter that there are small discrepancies based on serializability errors, because the query result is \nsomewhat outdated anyway, almost immediately after being presented to the user. Moreover, since this is only a \nsummary for decision support purposes, it doesn’t matter that the data isn’t exactly right. \n One can run queries in an even weaker locking mode, where it holds no locks at all. This is called  read \nuncommitted (or  dirty read or  Degree 1 )  isolation . In this case, a query can perform  dirty reads , where it \nreads uncommitted data — that is, data that may be wiped out when a transaction aborts. This will delay queries \neven less than read committed, at the cost of further inconsistencies in the values that are read. \n Notice that even if queries use either read committed or read uncommitted isolation, update transactions \ncan still use two-phase locking and can therefore be serializable with respect to each other. In this case, the \ndatabase state is still consistent in the sense that it is the result of a serializable execution of transactions. It’s \njust that queries might read inconsistent versions of that state. \n Most SQL database systems offer the option of running update transactions using read committed or even \nread uncommitted isolation, by executing a statement to set the isolation level. Running a transaction at one of \nthese lower isolation levels violates two-phase locking and can produce a non-serializable  execution. The per-\nformance may be better, but the result may be incorrect. For example, if two transactions each read and write  x \n(e.g., to increment  x ), then read committed isolation would allow both of them to read  x before either of them \nwrite  x . This is a non-serializable  execution and is almost certainly unsatisfactory to users since it causes one \nof the updates to be lost. \n When using degrees-of-isolation terminology, serializability often is characterized as Degree 3. This is \nsometimes called  repeatable reads , because unlike cursor stability, reading a data item multiple times returns \nthe same value since read locks are held throughout a transaction. The strongest level of isolation is called  seri-\nalizable , and it means just that: the execution of transactions must be equivalent to a serial execution. A sum-\nmary of the levels is in  Figure 6.11 . The degree-of-isolation terminology is used inconsistently in the literature. \nWe’ve glossed over many of the ﬁ ner points here. A more thorough discussion of the various terms and their \nsubtle differences appears in Berenson et al. (1995). \n Most database systems allow a database administrator to set the degree of isolation per database. Database \nsystems and transactional middleware also usually allow an application developer to override the database’s \ndegree of isolation for particular transaction programs. Some database systems allow a transaction to issue an \n6.6 Query-Update Problems  165\n\n\n166  CHAPTER 6 Locking\n operation that changes its degree of isolation after it has partially executed. Some systems allow the applica-\ntion to discover the degree of isolation, such as .NET ’ s System.Transactions. \n Many database systems offer degrees of isolation that are less than serializable but that don’t ﬁ t neatly into \none of the terms of the ANSI SQL standard. For example, Microsoft SQL Server offers a locking option called \nREADPAST. If a transaction is using read committed isolation and speciﬁ es the READPAST option in a SQL \nstatement, then the statement will ignore write-locked rows, rather than waiting for those locks to be released. \nThe intuition is that since the application is using read committed isolation, it isn’t expecting exact results any-\nway. So, in some cases, it is worth avoiding the delay of waiting for write locks to be released by simply skip-\nping over write-locked rows. \n We will see other examples of weaker degrees of isolation later in the chapter. \n Multiversion Data \n One good technique for ensuring that queries read consistent data without slowing down the execution of \nupdaters is  multiversion data . With multiversion data, updates do not overwrite existing copies of data items. \nInstead, when an updater modiﬁ es an existing data item, it creates a new copy of that data item, called a new \n version . So, each data item consists of a sequence of versions, one version corresponding to each update that \nwas applied to it. For example, in  Figure 6.12 a data item is a row of the table, so each version is a separate \nrow. There are three versions of employee 3, one of employee 43, and two of employee 19. \n To distinguish between different versions of the same data item, each version is tagged by the unique iden-\ntiﬁ er of the transaction that wrote it. Each version of a data item points to the previous version of that data item \n(the  “ previous transaction ” ﬁ eld in  Figure 6.12 ), so each data item has a chain of versions beginning with the \nmost recent and going back in time. In addition, the data manager maintains a list of transaction IDs of trans-\nactions that have committed, called the  commit list . \n Update transactions use two-phase locking and ignore old versions. They therefore behave as if the data-\nbase has only one version of each data item. That is, when an updater reads a data item  x , it sets a read lock on \n x and reads the latest version of  x . When it writes  x for the ﬁ rst time, it sets a write lock on  x and adds a new \nversion of  x . If it writes  x again, it simply overwrites the new version that it previously created. Commit and \nabort work in the usual way. Since update transactions use two-phase locking, they are serializable. \n The interesting capability of multiversion data is  snapshot mode , which allows a query to avoid setting \nlocks and thereby avoid locking delays. When a query executes in snapshot mode, the data manager starts \nby reading the current state of the commit list and associating it with the query for the query’s whole execu-\ntion. Whenever the query asks to read a data item, say  x , the data manager selects the latest version of  x that is \nDegree of \nIsolation\nANSI SQL Term\nBehavior\n1\nRead uncommitted\n2\nRead committed\n3\nSerializable\nDon’t set read locks\nOnly read committed data\nSerializability\n FIGURE 6.11 \n Degrees of Isolation. Degrees 1 and 2 provide less than serializable behavior, but better performance. \n\n\n tagged by a transaction ID on the query’s commit list. This is the last version of  x that was committed before \nthe query started executing. There is no need to lock this data because it can’t change. An updater will only \ncreate new versions and never modify an existing version. \n When a query executes in snapshot mode, it is effectively reading the state of the database that existed at \nthe time it started running. Thus, it reads a consistent database state. Any updates that execute after the query \nstarted running are issued by transactions that are not on the query’s commit list. These updates will be ignored \nby the data manager when it executes reads on behalf of the query. So although the query reads a consistent \ndatabase state, that state becomes increasingly out-of-date while it is running. \n A popular variation of this technique is  snapshot isolation , where an update transaction does not use two-\nphase locking. Instead, it executes reads using snapshot mode and executes writes without setting locks. When \nan update transaction T commits, the data manager checks that T’s updates are still valid. To do this, it checks \nwhether any data that T updated was also updated by another transaction T \u0002 that committed while T was run-\nning. If so, then T aborts, otherwise it commits. For example, suppose T updated  x and while T was running T \u0002 \nalso updated  x . This is a problem because neither T nor T \u0002 read the other transaction’s update to  x . When T tries \nto commit, the data manager checks T’s updates. If it sees that T \u0002 also updated  x and already committed, then \nthe data manager aborts T. This is sometimes called  “ ﬁ rst committer wins, ” because if two concurrent transac-\ntions try to write the same data, then the ﬁ rst one that ﬁ nishes commits while the second one aborts. \n Snapshot isolation provides stronger synchronization than read committed isolation. For example, it pre-\nvents a race condition where two transactions try to increment  x and both read  x before either of them writes  x . \nHowever, it is not serializable. For example, suppose transaction T 1 copies the value of  x into  y , so it reads  x and \nthen writes  y . Transaction T 2 does the opposite. To copy the value of  y into  x , it reads  y and then writes  x . If T 1 \nand T 2 execute concurrently using snapshot isolation, they will swap the values of  x and  y , which is not equiva-\nlent to a serial execution of T 1 and T 2 . Snapshot isolation is offered in Oracle Database, Microsoft SQL Server, \nand PostgreSQL. \n In principle, multiversion data can be used to offer read committed isolation. When a transaction reads a \ndata item, if the latest version of that data item currently is locked by an update transaction, then the transac-\ntion reads the previous version. The latter was surely written by a committed transaction, so this ensures read \ncommitted isolation. \nTransaction\nIdentiﬁer \nPrevious\nTransaction \nEmployee\nNumber \nName\nDepartment\nSalary\n174\nnull\n3\nTom\nHat\n$20,000\n21156\n174\n3\nTom\nToy\n$20,000\n21159\n21156\n3\nTom\nToy\n$24,000\n21687\nnull\n43\nDick\nFinance\n$40,000\n10899\nnull\n19\nHarry\nAppliance\n$27,000\n21687\n10899\n19\nHarry\nComputer\n$42,000\n FIGURE 6.12 \n An Example Multiversion Database. Each transaction creates a new version of each row that it updates. \n6.6 Query-Update Problems  167\n\n\n168  CHAPTER 6 Locking\n There is obviously some cost in maintaining old versions of data items. However, some of that cost is \nunavoidable, because recently overwritten old versions are needed to undo updates when a transaction aborts. \nIn a sense, multiversion data is making use of those old versions that are needed anyway for aborting transac-\ntions. Implementation details of transaction abort appear in the section on Database Recovery in Chapter 7. \n Multiversion Implementation Details \n There are two technicalities in making this type of mechanism run efﬁ ciently. A user of the mechanism need \nnot be aware of these issues, but for completeness, we describe them here. \n First , it is too inefﬁ cient to represent the entire commit list as a list of transaction IDs. We can keep the \ncommit list short by assigning transaction IDs sequentially (e.g., using a counter to generate them) and peri-\nodically discarding a preﬁ x of the commit list. To do this, we exploit the following observations: \n 1.  If all active transactions have a transaction ID greater than some value, say T-Oldest, and \n 2.  No new transaction will be assigned a transaction ID smaller than T-Oldest, and \n 3.  For every transaction that had a transaction ID  \u0006  T-Oldest and aborted, its updates are wiped out from \nthe database, \n 4.  Then queries don’t need to know about transaction IDs smaller than T-Oldest. \n Therefore , the commit list needs to contain only transaction IDs greater than T-Oldest. To see why, suppose \nthe data manager processes a read operation for a query on data item  x . As usual, the data manager looks for \nthe latest version of  x that is tagged by a transaction ID on the query’s commit list. If it ﬁ nds such a version, it \nreturns it, which is the standard behavior of snapshot mode. If not, then it returns the latest version  v of  x with \ntransaction ID  \u0006  T-Oldest. This is the correct version to return because none of the versions later than T-Oldest \nare on the query’s commit list, by (1) and (2) there will not be any other versions of  x with transaction ID \nbetween that of  v and T-Oldest, and by (3) version  v must be committed. To keep the list short, the data manager \nshould frequently truncate the small transaction IDs from the commit list based on the previous rule. \n One can avoid using a commit list altogether by assigning sequence numbers to transactions, where the \nsequence numbers are consistent with the effective order in which the transactions executed. This can be done by \ngetting a new sequence number when a transaction starts to commit, thereby ensuring that the sequence number \nis larger than the sequence number of every committed transaction that it conﬂ icts with. Each version is tagged \nby the sequence number of the transaction that produced it. When a query starts executing in snapshot mode, \ninstead of reading the commit list, it reads the value of the last transaction sequence number that was assigned, \nwhich becomes the sequence number for the query. When it reads a data item, it reads the version of that data \nitem with the largest sequence number tag that is less than or equal to the query’s sequence number. This type of \ntechnique is used in Oracle Database and in Microsoft SQL Server when snapshot isolation is enabled. \n A second problem is that the database can become cluttered with old versions that are useless, because no \nquery will ever read them. A version of data item  x is useless if (1) it is not the latest version of  x , and (2) all \nactive queries have a commit list that contains the transaction ID of a later version of  x , either explicitly or \nbecause its T-Oldest value exceeds the transaction ID of some later version of  x . \n In this case, no active query will read a useless version of  x ; they’ll only read later ones. No new query will \nlook at this version of  x either, because it will use an even more up-to-date commit list, which won’t include \nsmaller transaction IDs than currently running queries. So this version of  x can be discarded. \n Since useless versions are harmless, they can be discarded lazily. In some implementations, old versions of \na data item are collocated. In this case, when a data item is read, all its versions are brought into main memory. \nTherefore, when the data manager services the read operation, it can ask a background thread to scan the list of \nversions to determine if any of them are useless and, if so, delete them. \n\n\n 6.7  AVOIDING PHANTOMS \n In the standard locking model that we have been using in this chapter, insert and delete operations are modeled \nas write operations. We don’t treat them specially. However, inside the system, the data manager must be par-\nticularly careful with these operations to avoid nonserializable results. \n To see the potential problem, consider the database in  Figure 6.13 . The Accounts table has a row for each \naccount, including the account number, branch location, and balance in that account. The Assets table has the \ntotal balance for all accounts at each branch location. Now, suppose we execute the following sequence of \noperations by transactions T 1 and T 2 : \n 1.  T 1 : Read Accounts 1, 2, 3. \n 2.  T 1 : Identify the Accounts rows where Location  \u0003  B (i.e., 2 and 3) and calculate the sum of their bal-\nances ( \u0003 150). \n 3.  T 2 : Insert a new Accounts row [4, B, 100]. \n 4.  T 2 : Read the total balance for location B in Assets (returns 150). \n 5.  T 2 : Write Assets [B, 250]. \n 6.  T 2 : Commit. \n 7.  T 1 : Read Assets for location B (returns 250). \n 8.  T 1 : Commit. \n Transaction T 1 is auditing the accounts in location B. It ﬁ rst reads all the accounts in the Accounts table \n(step 1), adds up the balances in location B (step 2), and then looks up the Assets for location B (step 7) to \nmake sure they match. They don’t, because T 1 didn’t see the Accounts row inserted by T 2 , even though it did \nsee the updated value in the Assets table for location B, which included the result of T 2 ’s insertion. \nAccounts\nAssets\nAccount Number\nLocation\nBalance\n1\nA\n2\nB\n3\nB\n50\n50\n100\nLocation\nTotal\nA\nB\n50\n150\n FIGURE 6.13 \n Accounts Database to Illustrate Phantoms. \n6.7 Avoiding Phantoms  169\n\n\n170  CHAPTER 6 Locking\n This execution is not serializable. If T 1 and T 2 had executed serially, T 1 either would have seen T 2 ’s updates \nto both the Accounts table and the Assets table, or it would have seen neither of them. However, in this execu-\ntion, it saw T 2 ’s update to Assets but not its update to Accounts. \n The problem is the Accounts row [4, B, 100] that T 2 inserts. T 1 didn’t see this row when it read the Accounts \ntable, but did see T 2 ’s effect on Assets that added 100 to B’s total balance. The Accounts row [4, B, 100] is called \na  phantom , because it’s invisible during part of T 1 ’s execution but not all of it. \n The strange thing about this execution is that it appears to be allowed by two-phase locking. In the follow-\ning, we add the lock operations required by two-phase locking: \n 1.  T 1 : Lock rows 1, 2, and 3 in Accounts. Read Accounts 1, 2, 3. \n 2.  T 1 : Identify the Accounts rows where Location  \u0003  B (i.e., 2 and 3) and calculate the sum of their bal-\nances ( \u0003 150). \n 3.  T 2 : Insert a new Accounts row [4, B, 100] and lock it. \n 4.  T 2 : Lock location B’s row in Assets. Read the total balance for location B (returns 150). \n 5.  T 2 : Write Assets [B, 250]. \n 6.  T 2 : Commit and unlock location B’s row in Assets and row [4, B, 100] in Accounts. \n 7.  T 1 : Lock location B’s row in Assets. Read Assets for location B (returns 250). \n 8.  T 1 : Commit and unlock location B’s row in Assets and rows 1, 2, and 3 in Accounts. \n Is it really true that two-phase locking doesn’t guarantee serializability when there are insertion operations? \nFortunately not. There is some hidden behavior here that would cause an extra lock to be set and that isn’t shown \nin the execution. It all hinges on how T 1 knew there were exactly three rows in the Accounts table. There must \nhave been a data structure of some kind to tell it: an end-of-ﬁ le marker, a count of the number of rows in the ﬁ le, \na list of pointers to the rows in the ﬁ le, or something. Since it read that data structure to determine that it should \nread exactly rows 1, 2, and 3, it had to set a read lock on that data structure. Moreover, since T 2 added a row to the \nAccounts table, it had to lock that data structure too, in write mode, so it could update it. It would be prevented \nfrom doing so by T 1 ’s read lock on that data structure, and thus the previous execution could not occur. \n So , the phantom problem is not a problem, provided that the data manager sets locks on all shared data it \ntouches, including system structures that it uses internally on behalf of a transaction’s operation. \n Performance Implications \n This example brings up yet another common scenario that leads to performance problems, one that’s closely \nrelated to the query-update problems we saw in the previous section. The example has one transaction, T 1 , that \nscans a ﬁ le (essentially a query), and another transaction, T 2 , that inserts a row and therefore is blocked by the \nscan operation. Since T 1 needs to compare the values it reads in the Accounts table to the values it reads in the \nAssets table, it must run in a serializable way. Read committed locking isn’t good enough. This means that T 1 \nmust lock the entire table in read mode, which delays any update transaction that wants to write an existing \nrow or insert a new one. This reduction in concurrency is bound to cause some transaction delays. \n Database systems that support SQL reduce this problem somewhat by locking ranges of key values. In the \nexample, since T 1 only wants to read rows in location B, the system would set a key-range lock on rows with \n “ Location  \u0003  B. ” Transaction T 2 would have to get a key-range lock on  “ Location  \u0003  B ” to insert its new row, \nso it would be blocked as before. But other update transactions that operate on rows in other locations would \nbe permitted to run, because they would get key-range locks on other key ranges. That is, a key-range lock on \n “ Location  \u0003  B ” does not conﬂ ict with one on  “ Location  \u0003  A. ” \n Key -range locking works well in SQL because the WHERE clause in SQL has clauses like \n “ Accounts.Location  \u0003  B, ” which gives the system a strong hint about which lock to set. In an indexed ﬁ le \n\n\n system, such as COBOL ISAM implementations, it is much harder to do, since the operations issued by the \nprogram don’t give such strong hints to the ﬁ le system to ﬁ gure out which key-range locks to set. For this \nreason, key-range locking is widely supported in SQL database systems, but not in many other kinds. \n Although key-range locking is effective and relatively inexpensive, it is not free. Therefore, some systems \noffer a degree of isolation that guarantees serializability except for phantoms. Thus, it is in between read com-\nmitted and serializable. This is called  repeatable read in Microsoft SQL Server and in the ANSI SQL 92 stan-\ndard, and  read stability in IBM DB2 UDB. \n 6.8  OPTIMISTIC CONCURRENCY CONTROL \n In addition to the hot spot technique described in Section 6.5, optimistic concurrency control is useful in situ-\nations where data is cached outside the data manager. For example, a client or middle-tier server may cache \ndata that it retrieves from a data manager that resides on a remote server. In such cases, the cached data may \nbe updated in the data manager at the remote server (e.g., by other clients) without the cache being told about \nit. Therefore, any transaction that reads the cached data is at risk to use out-of-date data that can lead to a non-\nserializable  execution. As in the hot spot method, the solution is to check at commit time whether the cached \ndata has changed in the data manager in a way that invalidates the transaction’s earlier reads. If so, the transac-\ntion must abort. \n One scenario where this comes up is interactive transactions, where a user is involved in looking at data \nbefore deciding whether or how to update it. Since the user may look at the data for several minutes before \ndeciding, it is impractical to lock the data between the time it’s read and the time it’s updated. Therefore, the \napplication that interacts with the user executes one transaction to read the data and later runs a second trans-\naction to perform the user’s updates. In between the two transactions, the user decides which updates to per-\nform. Since the data isn’t locked between the reads and writes, an optimistic approach can be used. Namely, \nthe update transaction includes the values of the data items that were read earlier and on which the update \ndepends. The update transaction checks that the values that were read still have the same values in the data \nmanager. If so, then the transaction can perform its updates. \n The effect is as if the transaction had set read locks on the data during the ﬁ rst read-only transaction and held \nthem until the update transaction ran. Of course, since it didn’t hold the read locks that long, the update transac-\ntion may ﬁ nd that some of the data items that were read have changed, and therefore the transaction must abort. \nIn that case, the application needs to get involved by rereading the data that it read during the ﬁ rst transaction, \ndisplaying those new values to the user and asking the user if her previous updates are still what she wants. \n For example, suppose a building contractor is accessing an on-line supplier from a web browser over the \nInternet. The contractor wants 20 windows of a certain size, for delivery within two weeks. He issues a request \nfor catalog information on the appropriate type of windows. He shows the windows to his customer and, after \nsome discussion, they select a particular window. That purchase request should include not only the part num-\nber of the window to be purchased but also the delivery date. The update transaction that runs on the supplier’s \nserver rereads the promised delivery date and compares it to the one in the request; this is to validate the earlier \noptimistic read of the delivery date. If the delivery date can no longer be met, the application returns an error, \nelse it completes the purchase as requested. \n Notice that it’s up to the application to ﬁ gure out the data items that were read earlier and on which the \nupdate depends. In the previous example, the application needs to know that the update only depends on the \ndelivery date, not on all the other catalog information that is displayed to the contractor. \n Still , under certain assumptions, it’s possible for the application to ﬁ gure out what data items to validate \nwithout any hints from the application. For example, in Microsoft SQL Server, a cursor (which contains the \n6.8 Optimistic Concurrency Control  171\n",
      "page_number": 182
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 190-203)",
      "start_page": 190,
      "end_page": 203,
      "detection_method": "topic_boundary",
      "content": "172  CHAPTER 6 Locking\n result of a SQL query) can be declared as  Optimistic With Values . In this case, the database rows that are \nreturned in the cursor are not read-locked. Instead, if an application updates a row in the cursor, both the old \nand new value of the row are sent to the database system. The system processes the update by setting a lock on \nthe row and then checking whether the current value of the row equals the old value that was included with the \nupdate. If so, then the new value of the row is installed. If not, then the update is rejected and an exception is \nreturned. A similar option called  Optimistic With Versions is available, where each row is tagged by a \ntimestamp, which is updated every time the row is modiﬁ ed. So, instead of sending the old value of the row with \nthe update, only the old timestamp needs to be sent. If the timestamp has changed, then the update is rejected. \n Note that this SQL Server mechanism implicitly assumes that the update to the row depends only on the \nprevious value of the same row. If the update depended on the previous value of some other rows, then another \nconcurrency control technique would need to be used on those other rows. For example, those rows could be \nread using the serializable isolation level or the application could reread those rows using serializable isolation \nlevel at the time it does the update and check that their values didn’t change. \n 6.9  B-TREE LOCKING \n All database systems use some form of index to speed up content-based retrieval of records. An index is a \nmapping from key values to physical location. For example, in a relational database system an index maps col-\numn values to rows; in  Figure 6.13 an index on Location values in the Accounts table would map the column \nvalue  “ A ” to the ﬁ rst row and  “ B ” to the second and third rows. When a user submits a query to retrieve rows \nthat have a given ﬁ eld value, such as Location  \u0003  “ B, ” the database system can use the index to access exactly \nthe desired rows, instead of having to scan all rows of the table to ﬁ nd the desired ones. \n First , we explain how indexes work. Then we discuss techniques to avoid the special locking bottlenecks \nthat can arise when accessing indexes. \n B \u0003  Trees \n The most popular data structure used for implementing an index in a database system is the B-tree. A  B-tree \nconsists of a set of pages organized as a tree. The  leaf pages (i.e., those that don’t point to other pages in the \ntree) contain the data being indexed, such as rows of a table. The remaining pages, called  internal nodes , are \ndirectories of key values that are used to guide a search. \n If the internal nodes contain the data that is associated with the keys, then the tree is called a B-tree. On the \nother hand, if the internal nodes contain  only key values and not the associated data, then it is called a  B \u0005  tree . \nFor the most part, our discussion applies to both B-trees and B \u0005 trees. However, we will use B \u0005 trees in all of \nour examples since they are more commonly used in practice. \n Each page contains a sorted sequence of key values, which subdivides the range of possible key values into \nsubranges. So, a sequence of  n key values [ k 1 ,  k 2 ,  … ,  k n ] creates  n  \u0005  1 subranges: one subrange for key values \nless than  k 1 , one for key values from  k 1 to  k 2 ,  … , one for key values from  k n  \u0007 1 to  k n , and one for key values \ngreater than or equal to  k n . Associated with each subrange is a pointer to the root of a subtree that contains all \nthe keys in that subrange. \n For example, the B \u0005 tree in  Figure 6.14 has key values that are non-negative integers. The root page, P 0 , \ncontains the sorted sequence of key values 125, 490. (In the terminology of the previous paragraph,  n  \u0003  2.) \nThe pointer before 125 points to the root page of a subtree that contains all the keys in the range [0, 125) (i.e., \nzero up to but not including 125). Similarly, the pointer between 125 and 490 points to a subtree containing the \nrange [125, 490), and the pointer after 490 points to a subtree containing the range [490,  \b ). (Only the subtree \n\n\n for the range [125, 490) is shown explicitly.) Thus, the root page partitions the set of all key values into three \nranges: [0, 125), [125, 490), and [490,  \b ). \n Below the root, each page subdivides its key range, which is deﬁ ned by its parent. Looking again at the ﬁ g-\nure, we see that page P 1 subdivides the range [125, 490), which is deﬁ ned by its parent, P 0 . The subranges con-\nsist of [125, 213), [213, 352), and [352, 490). Notice that P 1 ’s ﬁ rst subrange is [125, 213), not [0, 213), because \nP 1 subdivides the range [125, 490), not [0, 490). Similarly, the last subrange is [352, 490), not [352,  \b ). The \nleaves of the tree contain the actual key values, such as 125, 145, and 199 in the leaf P 2 . These key values may \ninclude the data records themselves (such as rows in the Accounts table) or pointers to those records. \n To search for a given key value  k , you start by examining the root page and ﬁ nding the key range that con-\ntains  k . You then follow the pointer associated with that key range to another page. Then repeat the process, \nmoving down the tree. For example, to search for key value 145, you search the root and discover that range \n[125, 490) contains 145. So you follow the pointer to P 1 . In P 1 , you ﬁ nd that key range [125, 213) contains \n145, so you follow the pointer to P 2 . Searching page P 2 , you ﬁ nd key 145. To search for key 146, you would \nfollow the same sequence of pages. However, in that case, when reaching P 2 , you would ﬁ nd that the page \ndoesn’t contain 146. Since this is a leaf page, there is nowhere else to look, so you would conclude that 146 \nis not contained in the index. Notice that in all cases, the number of pages that are read equals the number of \nlevels of the tree, that is, one more than the number of pointers that need to be followed to get from the root to \na leaf. \n The B \u0005 tree effectively sorts the keys, as you can see in the leaves P 2 , P 3 , and P 4 in the ﬁ gure. You can \ntherefore get all the keys in a given range by searching for the key at the low end of the range and then scan-\nning the leaves in order until you reach the high end of the range. For example, to ﬁ nd all keys in the range \n160 to 360, you search for key 160, which takes you to page P 2 . Then you scan pages P 2 , P 3 , and P 4 . When you \nreach key value 487 on P 4 , which is the ﬁ rst key value greater than 360, you know you have found all keys in \nthe desired range. \n The B \u0005 tree in  Figure 6.14 is artiﬁ cially small, so it can ﬁ t on a printed page. In practice, each B \u0005 tree \npage is the size of a disk page and therefore can hold hundreds of keys. For example, if a page is 8  K bytes, a \nkey is 8 bytes, and a pointer is 2 bytes, then a page can hold up to 819 keys; therefore, a three-level B \u0005 tree \ncan have up to 820 2  \u0003  672,400 leaves. If each leaf holds up to 80 records, that’s over 5.3 million records in all. \nIf the tree has four levels, then it can hold up to about 4.4 billion records. As you can see from these numbers, \nit’s very rare for a B \u0005 tree to have more than four levels. \nsubtree\nwith keys\n<125 \nsubtree\nwith keys\n ≥490 \nP1\nP2\nP3\nP4\n125\n213\n217\n320\n352\n487\n145\n199\nP0\n125\n490\n213\n352\n FIGURE 6.14 \n A B \u0003 Tree. Page P 0 is the root and P 2 , P 3 , and P 4 are leaves. Each of the two triangular subtrees is an abbreviation for a \ncombination of pages like P 1  – P 4 . \n6.9 B-Tree Locking  173\n\n\n174  CHAPTER 6 Locking\n B \u0005 trees are intended to live on disk with a portion of them buffered in main memory. The root is always \ncached in main memory and usually the level below the root is cached too. Levels 3 and 4 are more problem-\natic. How much of them are cached depends on how much memory is available and how frequently the pages \nare accessed; that is, whether it’s worth caching them. However, even if levels 3 and 4 are not cached at all, to \nsearch for a key, only two disk pages need to be accessed. It’s pretty amazing, if you think about it — you can \nsearch for a key in a ﬁ le of 4 billion records and are guaranteed to ﬁ nd it in two disk accesses. \n This great performance of a B \u0005 tree depends on the tree being wide and ﬂ at. If the tree were thin and deep —\n that is, if it had many levels — then the performance would be worse. You would have to read many more pages \nto search from the root to a leaf. The main trick that makes the B \u0005 tree structure so attractive is that its update \nalgorithms are able to keep the tree wide and ﬂ at. \n B \u0003 Tree Insertions \n To insert a key value into a B \u0005 tree, you simply search for that key value. The search procedure identiﬁ es the \npage where that key value should be stored, so that’s where you store it. For example, to insert key value 353 \nin  Figure 6.14 , the search would take you to page P 4 , so you add the new record to that page. \n Inserting 353 was straightforward because there was extra space on that page. What if the desired page is \nalready full? For example, suppose each leaf can hold at most three records and you want to insert key value \n225. The search procedure takes you to page P 3 , which is full. In this case, you split the page in half. That is, you \nallocate another page, say P 5 , from free space and distribute the keys of P 3 plus 225 evenly between P 3 and P 5 , as \nshown in  Figure 6.15 . By adding page P 5 , you have effectively split the range [213, 352) into two ranges: [213, \n225) and [225, 352). This splitting of range [213, 353) must be recorded in P 3 ’s parent, P 1 , which is shown in \n Figure 6.15 . \n The split shown in  Figure 6.15 assumes that there is space in P 1 to store the extra range. If there isn’t enough \nspace, then since it’s full, P 1 would need to be split, just like P 3 was. The result is shown in  Figure 6.16 . In this \ncase, P 1 is split into P 1 and P 6 . This causes another key range to be propagated up to the root, P 0 . But since the \nroot is full, it too must be split into P 0 and P 7 . Thus, a new root, P 8 , needs to be added, which divides the total \nkey range between P 0 and P 7 . \n Notice that the tree stays wide and ﬂ at as it grows. The technical term is  “ balanced. ” It’s balanced in the \nsense that all leaves are the same distance from the root. \nsubtree\nwith keys\n<125 \nsubtree\nwith keys\n ≥490 \nP1\n225\n352\nP2\nP3\nP5\nP4\n125\n213 217\n225 320\n352 487\n145 199\nP0\n125\n490\n213\n FIGURE 6.15 \n A B \u0003 Tree After a Split. This shows the B \u0005 tree of  Figure 6.14 after inserting key 225, assuming P 1 can hold 3 keys and \nP 3 can hold 3 records. \n\n\n There are many variations of B-trees in the technical literature. The bibliographic notes provide entry \npoints for the interested reader. \n Tree Locking \n Suppose a transaction is executing a search for key value  k 1 in a B \u0005 tree. The search starts by reading the root \npage and scanning it to ﬁ nd the key range that contains  k 1 . Since it is reading all of the root, it needs to set a \nread lock on the entire root page. Similarly, it needs to lock the other pages that it searches, as it travels down \nthe tree toward the leaf that contains  k 1 . These read locks prevent any updates to the locked pages. If several \nactive transactions are using the B \u0005 tree, then large portions of the tree are read locked, which potentially \nblocks many update transactions. \n This locking bottleneck can be avoided by exploiting the fact that all transactions traverse the B \u0005 tree from \nroot to leaf. Consider a simple tree consisting of a page P (the parent), child C of P, and a child G of C (G is the \ngrandchild of P). Instead of holding read locks on all pages it touches, it is actually safe for a transaction T i to \nrelease its read lock on P after it has set a read lock C, where C covers the key range of interest. This seems more \nthan a little strange, since we have made such a big point in this chapter of being two-phase locked. If T i contin-\nues searching down the tree to lock G, then T i has broken two-phase locking — it unlocked P and later obtained a \nlock on G. However, in this special case of traversing a tree, breaking two-phase locking in this way is safe. \n The important point is that T i acquired its lock on C  before releasing its lock on P. It descends through the \ntree much like climbing down a ladder, placing one foot ﬁ rmly on the next lower rung before lifting the other \nfoot from the higher rung. This is called  lock coupling , or  crabbing (by analogy to the way a crab walks). \nThe effect is that no transaction that is obtaining conﬂ icting locks can pass T i on the way down, because T i is \nalways holding a lock on some page on the path to its ﬁ nal destination. \n A bad case would be that some transaction T k got a write lock on page P after T i released its read lock on P, \nbut got a write lock on G before T i got its read lock on G. That would violate serializability because it would \nsubtree\nwith keys\n<125 \nsubtree\nwith keys\n ≥490 \nP1\nP6\nP7\nP0\nP2\nP3\nP5\nP4\n125\n213\n213\n125\n490\n352\n217\n225 320\n352 487\n145 199\nP8\n225\n FIGURE 6.16 \n A B \u0003 Tree After a Recursive Split. This shows the B \u0005 tree of  Figure 6.15 , after inserting key 225, assuming internal nodes \ncan hold at most two keys. Thus, P 1 must split into P 1 and P 6 , which in turn causes P 0 to split into P 0 and P 7 , which causes \na new root P 8 to be created. \n6.9 B-Tree Locking  175\n\n\n176  CHAPTER 6 Locking\n appear that T k came after T i with respect to P and before T i with respect to G. But this can’t happen. If T k gets \na conﬂ icting lock on P after T i releases its lock on P, then lock coupling ensures that T k will follow T i on the \nentire path that T i takes down the tree. \n The correctness argument earlier assumes that each transaction gets the same kind of lock on all pages. If it \nswitches between two types of locks, then the argument breaks down. For example, if T k sets a write lock on P, \na read lock on C, and a write lock on G, then a non-serializable  execution could arise as follows: \n 1.  T i read locks P, T i read locks C, T i unlocks P. (At this point, T i has a read lock on C.) \n 2.  T k write locks P. (So T k follows T i at P.) \n 3.  T k read locks C. (T i and T k both have read locks on C.) \n 4.  T k unlocks P, T k write locks G, T k unlocks C, T k unlocks G. (T k arrived ﬁ rst at G, then ﬁ nishes up.) \n 5.  T i read locks G. (T i follows T k at G.) \n Since T k follows T i at P (step 2) and T i follows T k at G (step 5), the result isn’t serializable. In this case, \nwhere a transaction switches between lock types, lock coupling isn’t enough. A commonly used solution is to \ndisallow transactions from getting a weaker lock when traversing down the tree. \n After T i locks the leaf page L that it’s looking for, it can release its lock on L’s parent. At this point, it is \nholding a lock on only one page, L. In terms of locking performance, this is much better than before, where T i \nwould have held a lock on every page on the path from the root to L. Since T i is only locking L, update trans-\nactions can run concurrently as long as they aren’t trying to update a key on L. \n Insertions cause a problem for lock coupling, due to page splits. Suppose a transaction executes an insert \nof key value  k 2 into the B \u0005 tree. The insert begins by searching down the tree for the leaf that should contain \n k 2 , setting read locks on pages, just like a B \u0005 tree search. When it ﬁ nds the leaf L, it sets a write lock on it, \nso that it can insert  k 2 . If L is full, then it must be split, which requires that a new key be added to L’s parent. \nHowever, at this point, the transaction doesn’t own a lock on L’s parent. Reacquiring the lock would break the \nlock coupling protocol and thereby allow a non-serializable  execution to occur. \n One solution is to require that the insert procedure obtain write locks as it traverses down the tree. Assume \nit holds a lock on page P and has just acquired a lock on P’s child C. At this point, it checks whether C is full. \nIf not, then it releases its lock on P. If so, then it retains the lock on P because it may have to split C, in which \ncase it will need to update P. This solution is rather expensive, because the insert needs to set write locks from \nthe beginning of its search, including the root, an obvious bottleneck. An alternative solution is to search down \nthe tree using read locks only, keeping track of which pages are full. If the desired leaf turns out to be full, then \nrelease its lock and start traversing down from the root again. This time, the insert procedure holds write locks \non all the pages that need to be updated, which include the leaf L and its parent P, plus P’s parent if P is full, \nplus P’s grandparent if P’s parent is full, and so on. \n The B-Link Optimization \n Lock coupling is a signiﬁ cant performance boost over two-phase locking for B \u0005 trees. However, we can do \neven better by adding to the B \u0005 tree structure a sideways link from each page to the next page at the same \nlevel in key-sequence order. For example, the sideways links in  Figure 6.17 are shown as horizontal dashed \nlines. Notice that links are not only between siblings; that is, between pages that have a common parent. Links \nmay also connect cousins, such as the pointer from P 7 to P 2 . Thus, only the last page on each level has no side-\nways link; in the ﬁ gure, that’s P 4 on level 3, P 1 on level 2, and P 0 on level 1. \n These sideways links, called  B-links , enable the search and insert procedures to hold only one page lock \nat a time, which improves concurrency over lock coupling. The optimization exploits our knowledge about the \nkinds of updates to a B \u0005 tree that can alter its structure, namely page splits. \n\n\n When searching down a B \u0005 tree, the search procedure only holds a lock on one page at a time. So, for example, \nsuppose T 1 executes a search for key 94. The search procedure begins by locking P 0 , selecting the range [0, 125) as \nthe one that contains 94, getting the associated pointer to P 5 , and releasing its lock on P 0 . At this point, it holds no \nlocks. It repeats the process on P 5 by locking P 5 , selecting the range [56, 125), getting the associated pointer to P 7 , \nand releasing its lock on P 5 . Finally, it locks P 7 , ﬁ nds the record with key 94, and releases its lock. \n This search procedure looks rather dangerous, because at certain points in its execution, it is holding a \npointer to a page that isn’t locked. For example, after unlocking P 5 , it’s holding a pointer to P 7 , which is not \nlocked. What if another transaction somehow makes that pointer to P 7 invalid before the search procedure fol-\nlows the pointer? \n Here is where our knowledge of B \u0005 tree behavior comes in. Assume that B \u0005 tree pages are never deleted, \nwhich is a common practice since databases rarely shrink signiﬁ cantly. In that case, the only way that P 7 can \nchange in a way that affects the search is if another transaction splits P 7 . For example, suppose that when T 1 ’s \nsearch holds a pointer to P 7 but no locks, another transaction T 2 inserts key 60 on P 7 causing P 7 to split, yield-\ning the tree in  Figure 6.18 . Let’s look at the split of P 7 in more detail: T 2 write locks P 7 , allocates a new page \nP 8 , copies P 7 ’s link (to P 2 ) into P 8 (so P 8 points to P 2 ), moves records 94 and 108 from P 7 to P 8 , inserts record \n60 in P 7 , updates P 7 ’s link to point to P 8 , and unlocks P 7 . At this point, P 5 is inconsistent with P 7 and P 8 , so T 2 \nmust update P 5 to add key 94 and a pointer to P 8 . However, this update of P 5 has no effect on T 1 , which already \nread P 5 and is holding a pointer to P 7 . So, now that T 2 has unlocked P 7 , T 1 can push ahead and lock P 7 and read \n56\n213\n352\n125\nP4\nP3\nP2\nP7\nP6\nP5\nP1\nP0\n352 487\n213 217 320\n125 145 199\n56\n94 108\n6\n14\n55\n FIGURE 6.17 \n A B \u0003 Tree with Sideways Pointers. Each page points to the next page at the same level in key sequence order. \n56\n94\n213\n352\n125\nP3\nP2\nP8\nP7\nP6\nP5\nP1\nP0\n213 217 320\nP4\n352 487\n125 145 199\n94 108\n56\n60\n6\n14\n55\n FIGURE 6.18 \n The B \u0003 Tree of Figure 6.17 After Inserting 60 . Page P 7 is split into P 7 and a new page P 8 , links are updated, and the \nboundary key 94 is inserted in page P 5 . \n6.9 B-Tree Locking  177\n\n\n178  CHAPTER 6 Locking\n it. Of course, record 94, which T 1 is looking for, isn’t in P 7 anymore. Fortunately, T 1 can ﬁ gure this out. It sees \nthat the largest key in P 7 is 60. So it’s possible that record 94 got moved during a split and can be found on the \nnext higher page. This is where the link is used. Instead of giving up after failing to ﬁ nd 94 in P 7 , T 1 follows \nthe link to the next higher page, looks there for key 94, and ﬁ nds it. \n Suppose that T 1 was looking for key 95 instead of 94. When it follows the link to P 8 , and fails to ﬁ nd 95 \non P 8 , it looks for the largest key on P 8 , which in this case is 108. Since 108 is larger than 95, T 1 knows that \nthere’s no point in following P 8 ’s link to P 2 , since all keys in P 2 are larger than 108. \n 6.10  MULTIGRANULARITY LOCKING \n At the end of Section 6.2, we brieﬂ y explained how a data manager can set locks at different granularities, such \nas database, ﬁ le, and record granularity. In this section, we expand on the details. Knowledge of these details \ncan be helpful in understanding the performance characteristics of locking in data managers that use it. \n As we explained earlier, the main problem in locking at different granularities is determining when locks \nat different granularities conﬂ ict. For example, if transaction T 1 owns a write lock on ﬁ le  F , we would like T 2 \nto be prevented from setting a read lock on record  R in  F . However, as far as the lock manager is concerned, \nlocks on  F and  R are completely independent, so the lock manager would allow them both to be set. \n The trick in multigranularity locking is to require that before setting a ﬁ ne grain lock on a data item  x , a \ntransaction must ﬁ rst set a weak lock, called an  intention lock , on every coarse grain data item that contains  x . \nIntention locks conﬂ ict with read and write locks. In the previous example, since  F contains  R , T 2 would need \nto set an  intention read lock on  F before it tried to set a read lock on  R . The intention read lock on  F conﬂ icts \nwith T 1 ’s write lock on  F , so the lock manager recognizes the conﬂ ict and T 2 is delayed, as desired. \n To know which intention locks to set for a given data item  x , a data manager must know which data items \ncontain  x . This knowledge is captured in a containment hierarchy, called a  lock type graph . For example, a \nsimple lock type graph for a SQL database system is shown in  Figure 6.19a . This graph says that each row is \ncontained in a table, and each table is contained in a database. So, to set a lock on a row  R , the data manager \nneeds to set an intention lock on the table and database that contain  R . \n Locks must be set in root-to-leaf order, as deﬁ ned by the lock type graph. For example, consider the  lock \ninstance graph in  Figure 6.19b , which represents a database that conforms to the lock type graph in  Figure 6.19a . \nTo set a lock on record R 3 , a transaction T 1 ﬁ rst would have to set an intention lock on database DB A , then set an \nintention lock on table Tbl S2 . If T 1 disobeyed the root-to-leaf order and set a lock on R 3 before setting those inten-\ntion locks, it might ﬁ nd that another transaction T 2 already owns a lock on Tbl S2 that prevents T 1 from setting the \nintention lock. Thus, T 1 would have a lock on R 3 and T 2 would have a lock on the table Tbl S2 that contains R 3 , \nwhich is exactly the situation we’re trying to avoid. Locking from root to leaf prevents this bad outcome. \n Note that the hierarchy is only conceptual. It need not be physically stored. That is, the data manager \ndoesn’t need a data structure that represents the lock type graph. Rather, the data manager can rely on hard-\ncoded knowledge of the graph to decide which locks to set. \n Each lock type has a corresponding intention lock type. That is, there are  intention-to-write ( iw ) and  intention-\nto-read ( ir ) lock types, which correspond to the write and read lock types, respectively. Before setting a read lock \non a data item  x , a transaction must ﬁ rst set an ir lock on  x ’s ancestors; similarly, for setting a write lock. \n The lock conﬂ ict rules for intention locks are shown in  Figure 6.20 . To understand their meaning, consider \na data item  x (e.g., a table) and data items  y and  z that are contained by  x (e.g., two rows in table  x ): \n ■  r is compatible with ir, because it’s alright if T 1 owns a read lock on  x while T 2 owns an ir lock on  x and \na read lock on, say,  y . \n\n\n ■  r is incompatible with iw, because if T 1 owns a read lock on  x , then T 2 should not be allowed to own a \nwrite lock on  y . T 2 ’s attempt to get an iw lock on  x (before locking  y ) will conﬂ ict with T 1 ’s read lock. \n ■  w is incompatible with ir or iw, because if T 1 owns a write lock on  x , then T 2 should not be allowed to \nown a read or write lock on  y . \n ■  ir and iw locks are compatible with each other, because they indicate only that ﬁ ner grain locks are being \nheld, possibly on different data items. Suppose T 1 and T 2 own an ir and iw lock on  x , respectively. This \nmeans T 1 plans to own a read lock on some  y contained in  x and T 2 plans to own a write lock on some \n z contained in  x . This is a problem only if  y  \u0003  z . But in that case T 1 and T 2 will conﬂ ict when they both \ntry to lock  y . It would be premature to disallow T 1 and T 2 from owning their intention locks on  x since in \nmost cases they will lock different ﬁ ne grained items within  x . \n The lock type  read-with-intention-to-write ( riw ) is designed for transactions that are scanning a large \nnumber of data items but updating only some of them, such as executing a SQL Update statement. Such a \ntransaction would have to own both an r and iw lock on the same data item, such as a SQL table. It simpliﬁ es \nthe lock manager if each transaction is allowed to hold at most one lock on each data item. Therefore, the two \nDatabase\nTable\nRow\na. A lock type graph\nDBA\nTblS1\nTblS2\nR1\nR2\nR3\nR4\nR5\nb. A lock instance graph\n FIGURE 6.19 \n Graph That Drives Multigranularity Locking. The lock type graph describes the hierarchy of granularity of object types \nthat can be locked. The lock instance graph shows instances of those types. \ny\ny\ny\nn\nn\nn\nn\nn\nn\ny\nr\nw\nir\niw\nriw\nn\nn\ny\nn\nn\nn\ny\ny\nn\nn\nn\ny\nn\nn\ny\nLock Type Requested\nr\nw\nir\niw\nriw\nLock Type Held\n FIGURE 6.20 \n Lock Type Compatibility Matrix. Each entry says whether the lock type requested can be granted given that another \ntransaction holds the lock type held. \n6.10 Multigranularity Locking  179\n\n\n180  CHAPTER 6 Locking\n lock types, r and iw, are combined into one, riw. Notice that the riw lock type is compatible with another lock \ntype  lt if and only if both r and iw are compatible with  lt . In  Figure 6.20 only lock type ir has this property. \n So far, we have treated lock instance graphs that are trees. Trees have the nice property that each data item \n(except the root) has exactly one parent. Often, we need to handle lock instance graphs that are directed acyclic \ngraphs (DAGs), where a data item may be contained by two or more parents. This requires modifying the rules \nfor setting intention locks, because setting an intention lock on a parent of a data item  x does not prevent other \ntransactions from setting a conﬂ icting coarse grain lock on a different parent of  x . \n Let ’s look at the most common place where this arises, namely key-range locking, which we used in Section \n6.7 to avoid phantoms. In key-range locking, key-range is another type of object that can be locked, as shown \nin the lock type graph in  Figure 6.21a . If a table uses multiple keys, then each row is in multiple key ranges. For \nexample, in  Figure 6.22 suppose the Customer and Location columns are used as keys in the Accounts table. \nThen each row is contained in two different key ranges, one for each key. For example, Account 1 is in the \nCustomer key range for  “ Eric ” and the Location key range for  “ A. ” Suppose that transaction T 1 sets an iw lock \non DB A , Accounts, and the key range Customer  \u0003  “ Eric ” and then sets a write lock on Account 1. This does not \nprevent another transaction T 2 from setting an ir lock on DB A and Accounts and setting a read lock on the key \nrange Location  \u0003  “ A. ” Since the key range Location  \u0003  “ A ” covers the row for Account 1, this means that T 2 \nimplicitly has a read lock on Account 1, which conﬂ icts with T 1 ’s explicit write lock on Account 1. This is an \nexample of the problem described in the previous paragraph: a transaction holds an intention lock on one parent \nof  x (i.e., on key range Customer  \u0003  “ Eric, ” which is a parent Account 1), but another transaction holds a con-\nﬂ icting lock on a different parent of  x (i.e., key range Location  \u0003  “ A ” ). \nAccount Number\nCustomer\nLocation\nBalance\nEric\nEric\nJane\nAlex\n1\n2\n3\n4\nA\nB\nB\nC\n50\n50\n100\n75\n FIGURE 6.22 \n Example Database. This database corresponds to the lock instance graph of  Figure 6.21b . \nDBA\nAccounts\nAccount 1 \nb. A lock instance graph\na. A lock type graph\nDatabase\nTable\nKeyRange\nRow \nCust \u0003\n“Eric” \nCust \u0003 \n“Jane” \nLoc \u0003\n“A”\nLoc \u0003\n“B”\nLoc \u0003\n“C”\nCust \u0003\n“Alex”\nAccount 2\nAccount 3\nAccount 4\n FIGURE 6.21 \n A DAG That Drives Multigranularity Locking. This extends the graphs of  Figure 6.19 , to allow each row to have more than \none parent, which in this case are key ranges. \n\n\n To avoid this problem, we modify the multigranularity locking protocol for write locks. We require that \nto set a write lock or iw lock on an object  x , a transaction must have an iw lock on  every parent of  x . In the \nexample, this means that T 1 needs an iw lock on the two key ranges that are parents of Account 1, namely, \nCustomer  \u0003  “ Eric ” and Location  \u0003  “ A. ” The iw lock on Location  \u0003  “ A ” would conﬂ ict with T 2 ’s read lock on \nLocation  \u0003  “ A. ” So only one of them can lock the range, thereby avoiding the situation where T 1 and T 2 own \nconﬂ icting locks on Account 1. \n Typically , key range locks are implemented by setting locks on physical index entries. This assumes that \neach lockable key corresponds to an indexed column. For example, to set a lock on Customer  \u0003  “ Eric, ” there \nwould need to be an index on the Customer column of the Accounts table. The procedure to set the lock searches \nfor  “ Eric ” in the index and sets the appropriate lock on the index record for Customer  \u0003  “ Eric. ” A procedure to \nﬁ nd the account record for  “ Eric ” needs to look up  “ Eric ” in the index anyway. \n 6.11  LOCKING NESTED TRANSACTIONS \n In this section we discuss locking behavior that is needed to support the nested transaction model described in \nSection 2.2. Recall that nested transactions behave as follows: \n 1.  If a program is already executing inside a transaction T and issues a Start command, then Start creates \na subtransaction S of T. If the program is executing inside a subtransaction S, then Start creates a sub-\ntransaction of S. Thus, there is a  “ nesting hierarchy ” among transactions, which can be of any depth. \n 2.  If a program is not already executing inside a transaction and issues a Start command, then Start creates \na new, independent top-level transaction, which is not a subtransaction of another transaction. \n 3.  If a subtransaction S aborts, then all of S’s operations are undone, including all its subtransactions. \nHowever, this does not cause S’s parent P to abort. It simply notiﬁ es P that S aborted. \n 4.  If a subtransaction S commits, S no longer can issue operations. S’s parent is notiﬁ ed of S’s commit. \n 5.  While a subtransaction S is executing, data items that it has updated are isolated and hence not visible \nto other transactions and subtransactions (just like the ﬂ at transaction model). \n Rule (5) is a requirement on the isolation behavior of nested transactions. If two-phase locking is the mech-\nanism used to obtain isolation, then it needs to be modiﬁ ed slightly in order to satisfy rule (5). \n \n i.  Top-level transactions set locks in the same way as they do in a non-nested transaction  model. \n \n ii.  When a subtransaction S commits or aborts, its locks are inherited by S’s parent, which is either a top-\nlevel transaction or another subtransaction one level higher in the nesting hierarchy. \n \n iii.  A request to lock a data item  x on behalf of a subtransaction S is granted if the only conﬂ icting locks on \n x , if any, are held by ancestors of S in the nesting hierarchy. \n The effect of (ii) and (iii) is that subtransactions of the same parent are two-phase locked with respect to \neach other and hence are serializable with respect to each other. Therefore, even though subtransactions may \nexecute concurrently with much interleaving of their operations, in the end one can think of subtransactions of \nthe same parent as isolated operations. \n In Chapter 2, we presented nested transactions as a user-oriented execution model, one that is visible to \nthe application programmer. Nested transactions are also a useful implementation tool when building a data \nmanager. We encountered an example of this in Section 6.9,  B-Tree Locking , which addressed the problem of \nimplementing operations on a B \u0005 tree index, such as Get Data Item  x with Location  \u0003  “ B. ” The parent trans-\naction that invokes the operation views it as isolated with respect to other operations it invokes. However, the \n6.11 Locking Nested Transactions  181\n\n\n182  CHAPTER 6 Locking\n internal execution of the operation has multiple steps that traverse a B \u0005 tree — reading its pages and interpret-\ning their content. The locking protocol that ensures this internal execution is isolated with respect to other B \u0005 \ntree operations is not two-phase locking. Rather, it’s a lock coupling protocol that uses knowledge of the B \u0005 \ntree structure to enable more concurrency than two-phase locking would allow. However, the goal is the same \nas nested two-phase locking, namely, ensuring isolation of operations within the same parent. \n Another common case where nested transactions arise in a data manager is implementing record-oriented \noperations on a page-oriented ﬁ le store. Each page consists of multiple records. An implementation of read \nand write operations on records involves reading and writing pages and interpreting their contents. We will see \nan example of nested locking protocols to support this scenario in the next chapter on database recovery. 7 \n 6.12  SUMMARY \n Locking is the most popular mechanism to achieve transaction isolation, that is, to ensure that every execution \nof a set of  transactions is serializable. Each transaction sets read and write locks on data items that it reads and \nwrites, respectively. And it follows the two-phase rule, meaning that it obtains all its locks before releasing any \nof them. Locks are generally set and released automatically by data managers and therefore are hidden from \nthe application programmer. \n A write lock conﬂ icts with a read or write lock on the same data item. Two transactions cannot concurrently \nhold conﬂ icting locks on the same data item. If a transaction requests a lock that conﬂ icts with one owned by \nanother transaction, it is delayed. This leads to two problems: deadlock and thrashing. \n A deadlock occurs when a set of transactions are waiting for each other to release locks. Deadlocks usually \nare handled automatically by a detection mechanism. The system can use timeouts to identify a transaction that \nhas been waiting too long and is suspected of being in a deadlock. Or it explicitly maintains a waits-for graph \nand periodically checks for cycles. The system breaks a deadlock by aborting one of the transactions involved \nin the deadlock. \n The main application design problem created by locking is performance delays created by lock conﬂ icts. \nIf too many transactions request conﬂ icting locks, transaction throughput decreases. This is called lock thrash-\ning. To solve it in a running system, the number of active transactions must be decreased by aborting them. \nAlternatively, one can modify the application, database, or system design to reduce the number of conﬂ icts. \nThe latter is a design activity that involves adjusting the locking granularity or using special locking techniques \nthat reduce the level of conﬂ ict, such as the following: \n ■  Use ﬁ ner grained locks, thereby increasing concurrency, at the expense of more locking overhead, since \nmore locks must be set. \n ■  Reduce the time that locks are held by shortening transaction execution time or delaying lock requests \nuntil later in the transaction. \n ■  Use a hot spot technique, such as delaying operations until commit time, using operations that don’t con-\nﬂ ict, and keeping hot data in main memory to shorten transaction execution time. \n ■  Use a weaker degree of isolation, such as read committed isolation, allowing inconsistent reads by releas-\ning each read lock immediately after reading. \n ■  Use multiversion data, so that queries can access old versions of data and thereby avoid setting locks that \nconﬂ ict with update transactions. \n 7 See the discussion of latches at the end of Section 7.4. Latches ensure that write-record operations are isolated from each other. \nRecord locks ensure transactions are isolated from each other (i.e., are serializable). \n\n\n ■  Use lock coupling or the B-link method to reduce lock contention in B \u0005 tree indexes. \n ■  Use multigranularity locking so that each transaction sets locks at the appropriate granularity for the \noperation it is performing. \n Insert and delete operations require special techniques, such as key-range locking, to avoid phantom updates \nand thereby ensure serializable executions. Nested transactions require special techniques too, for lock inheri-\ntance, to ensure subtransactions of the same parent are isolated from each other. \n 6.13  APPENDIX: BASIC SERIALIZABILITY THEORY \n Serializability theory is one of the standard techniques for arguing the correctness of concurrency control algo-\nrithms, such as two-phase locking. In this section, we present the basics — enough to prove that two-phase \nlocking produces serializable executions. \n Equivalence of Histories \n When we design a concurrency control algorithm, we need to show that every execution of transactions that is \npermitted by the algorithm has the same effect as a serial execution. So to start, we need a formal model of an \nexecution of transactions. As in Section 6.1, we model an execution as a  history , which is a sequence of the \nread, write, and commit operations issued by different transactions. To simplify matters, we do not consider \naborted transactions in this analysis, although they can be included with some modest additional complexity to \nthe theory. For clarity, we do include commit operations, denoted by c i for transaction T i . \n We formalize the concept of  “ has the same effect as ” by the concept of equivalence between two histories. \nInformally, we say that two histories are equivalent if each transaction reads the same input in both histories and the \nﬁ nal value of each data item is the same in both histories. Formally, we say that two histories are  equivalent if they \nhave the same operations and conﬂ icting operations are in the same order in both histories. This captures the infor-\nmal notion of  “ has the same effect as ” because changing the relative order of conﬂ icting operations is the only way \nto affect the result of two histories that have the same operations. For example, the following histories are equivalent: \n \nH\nr [ ] r [ ] w [ ] c  w [ ] c\nH\nr [ ] r [ ] w [ ] c  w\n1\n1\n2\n1\n1\n2\n2\n2\n2\n1\n1\n1\n2\n\u0003\n\u0003\nx\nx\nx\ny\nx\nx\nx\n[ ] c\nH\nr [ ] r [ ] w [ ] c  w [ ] c\nH\nr [ ] w [ ] c  r\ny\nx\nx\nx\nx\ny\n2\n3\n2\n1\n2\n2\n1\n1\n4\n2\n2\n2\n\u0003\n\u0003\ny\n1\n1\n1\n[ ] w [ ] c\nx\nx\n \n But none of them are equivalent to \n H\nr [ ] w [ ] c  r [ ] w [ ] c\n5\n1\n1\n1\n2\n2\n2\n\u0003\nx\nx\nx\ny\n \n The reason is that r 2 [ x ] and w 1 [ x ] conﬂ ict and r 2 [ x ] precedes w 1 [ x ] in H 1  – H 4 , but r 2 [ x ] follows w 1 [ x ] in H 5 . \n We model a serial execution as a  serial history , which is a history where the operations of different trans-\nactions are not interleaved. For example, H 4 and H 5 are serial histories, but H 1  – H 3 are not. \n The Serializability Theorem \n One standard way to prove serializability is using a directed graph that describes a history, called a  serialization \ngraph . It has one node for each transaction. For each pair of conﬂ icting operations by different transactions, it \n6.13 Appendix: Basic Serializability Theory  183\n\n\n184  CHAPTER 6 Locking\n has an edge from the earlier transaction to the later one. For example, in the history in  Figure 6.23 , r 2 [ x ] con-\nﬂ icts with and precedes w 1 [ x ], so there is an edge from T 2 to T 1 in the serialization graph. Two conﬂ icts can lead \nto the same edge. For example, r 2 [ x ] conﬂ icts with and precedes w 1 [ x ], and w 2 [ y ] conﬂ icts with and precedes \nw 1 [ y ], both of which produce the same edge from T 2 to T 1 . \n A  cycle in a directed graph is a sequence of edges from a node back to itself. An  acyclic directed graph \nis a directed graph with no cycles. The fundamental theorem of serializability theory is that a history is serial-\nizable if its serialization graph is acyclic. For example, the history in  Figure 6.23 has an acyclic serialization \ngraph, so it’s serializable. In fact, it is equivalent to the following serial history: \n r [ ] w [ ] c  r [ ] w [ ] w [ ] c  r [ ] w [ ] c\n2\n2\n2\n1\n1\n1\n1\n3\n3\n3\nx\ny\nx\ny\nx\nx\nx\n \n To prove the fundamental theorem, we need to show that if a given history’s serialization graph is acyclic, \nthen it is equivalent to a serial history. Let’s start by constructing a serial history over the same transactions \nas the given history where the transactions are in an order that is consistent with the serialization graph. It is \nsurely possible to construct such a serial history because the graph is acyclic. Now observe that each pair of \nconﬂ icting operations in the given history is in the same order as in the serial history, because the pair cor-\nresponds to an edge in the graph. Since all conﬂ icting operations are in the same order, the given history is \nequivalent to the serial history. Therefore, the given history is serializable, which proves the theorem. \n The Two-Phase Locking Theorem \n Given this fundamental theorem, we can prove that two-phase locking produces serializable executions by \nshowing that any execution it produces has an acyclic serialization graph. So, consider the serialization graph \nof a two-phase locked execution, and examine one edge in this graph, say T i → T j . This means there were two \nconﬂ icting operations, o i from T i and o j from T j . T i and T j each set locks for o i and o j , and since the operations \nconﬂ ict, the locks must conﬂ ict. (For example, o i might have been a read and o j a write on the same data item.) \nBefore o j executed, its lock was set, and o i ’s lock must have been released before then (since it conﬂ icts). So, \nin summary, given that T i → T j , T i released a lock before T j set a lock. \n Now , suppose there is a sequence of edges T i → T j and T j → T k . From the previous paragraph, we know \nthat T i released a lock before T j set a lock, and T j released a lock before T k set a lock. (They may be different \nlocks.) Moreover, since T j is two-phase locked, it set all its locks before it released any of them. Therefore, T i \nreleased a lock before T k set a lock. Avoiding the rigor of an induction argument, it is easy to see that we can \nrepeat this argument for sequences of edges of any length. Therefore, for any sequence of edges T i → … → T m , \nT i released a lock before T m set a lock. \n To prove that the two-phase locked execution is serializable, we need to show that its serialization graph \nis acyclic. So, by way of contradiction, suppose there  is a cycle in the serialization graph T i → … → T i . From \nthe previous paragraph, we can conclude that T i released a lock before T i set a lock. But this implies T i was \n not two-phase locked, contradicting our assumption that all transactions were two-phase locked. Therefore the \ncycle cannot exist and, by the fundamental theorem of serializability, the execution is serializable. \nr1[x] r2[x] w1[x] r3[x] w2[y] c2 w1[y] c1 w3[x] c3\nT2\nT3\nT1\n FIGURE 6.23 \n An Execution and Its Serialization Graph. The execution on the left is modeled by the serialization graph on the right. \n\n\n 7.1  CAUSES OF SYSTEM FAILURE \n A critical requirement for most TP systems is that they be up all the time; in other words, highly available. Such \nsystems often are called  “ 24 by 7 ” (or 24  \u0004  7), since they are intended to run 24 hours per day, 7 days per week. \nDeﬁ ning this concept more carefully, we say that a system is  available if it is running correctly and yielding the \nexpected results. The  availability of a system is deﬁ ned as the fraction of time that the system is available. Thus, \na highly available system is one that, most of the time, is running correctly and yielding expected results. \n Availability is reduced by two factors. One is the rate at which the system fails. By  fails , we mean the system \ngives the wrong answer or no answer. Other things being equal, if it fails frequently, it is less available. The sec-\nond factor is recovery time. Other things being equal, the longer it takes to ﬁ x the system after it fails, the less it \nis available. These concepts are captured in two technical terms: mean time between failures and mean time to \nrecovery. The  mean time between failures , or  MTBF , is the average time the system runs before it fails. MTBF \nis a measure of system  reliability . The  mean time to repair , or  MTTR , is how long it takes to ﬁ x the system \nafter it does fail. Using these two measures, we can deﬁ ne availability precisely as MTBF/(MTBF  \u0005  MTTR), \nwhich is the fraction of time the system is running. Thus, availability improves when reliability (MTBF) \nincreases and when repair time (MTTR) decreases. \n In many practical settings, the system is designed to meet a  service level agreement (SLA) , which is typi-\ncally a combination of availability, response time, and throughput. That is, it is not enough that the system is \navailable. It must also have satisfactory performance. Of course, poor performance may arise from many sources, \nsuch as the database system, network, or operating system. Performance problems are sometimes TP-speciﬁ c, \nsuch as the cases of locking performance discussed in Chapter 6. More often, they are speciﬁ c to other compo-\nnent technologies. These problems are important, but since they are not speciﬁ c to the TP aspects of the system, \nwe will not consider them here. Instead, we focus entirely on failures and how to recover from them. \n Failures come from a variety of sources. We can categorize them as follows: \n ■  The environment: Effects on the physical environment that surrounds the computer system, such as power, \ncommunication, air conditioning, ﬁ re, and ﬂ ood. \n ■  System management: What people do to manage the system, including vendors doing preventative main-\ntenance and system operators taking care of the system. \n ■  Hardware: All hardware devices including processors, memory, I/O controllers, storage devices, etc. \n ■  Software: The operating system, communication systems, database systems, transactional middleware, other \nsystem software, and application software. \n Let ’s look at each category of failures and see how we can reduce their frequency. \n System Recovery \n 7 \nCHAPTER\n",
      "page_number": 190
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 204-214)",
      "start_page": 204,
      "end_page": 214,
      "detection_method": "topic_boundary",
      "content": "186  CHAPTER 7 System Recovery\n Hardening the Environment \n One part of the environment is communications systems that are not under the control of the people building \nthe computer system, such as long distance communication provided by a telecommunications company. As a \ncustomer of communication services, sometimes one can improve communications reliability by paying more \nto buy more reliable lines. Otherwise, about all one can do is lease more communication lines than are needed \nto meet functional and performance goals. For example, if one communication line is needed, lease two inde-\npendent lines instead, so if one fails, the other one will probably still be operating. \n A second aspect of the environment is power. Given its failure rate, it’s often appropriate to have battery backup \nfor the computer system. In the event of power failure, battery backup can at least keep main memory alive, so the \nsystem can restart immediately after power is restored without rebooting the operating system, thereby reducing \nMTTR. Batteries may be able to run the system for a short period, either to provide useful service (thereby increas-\ning MTBF) or to hibernate the system by saving main memory to a persistent storage device (which can improve \navailability if recovering from hibernation is faster than rebooting). To keep running during longer outages, an \nuninterruptible power supply (UPS) is needed. A full UPS generally includes a gas or diesel powered generator, \nwhich can run the system much longer than batteries. Batteries are still used to keep the system running for a few \nminutes until the generator can take over. \n A third environmental issue is air conditioning. An air conditioning failure can bring down the computer \nsystem, so when a computer system requires an air conditioned environment, a redundant air conditioning \nsystem is often advisable. \n Systems can fail due to natural disasters , such as ﬁ re, ﬂ ood, and earthquake, or due to other extraordinary \nexternal events, such as war and vandalism. There are things one can do to defend against some of these events: \nbuild buildings that are less susceptible to ﬁ re, that are able to withstand strong earthquakes, and that are secured \nagainst unauthorized entry. How far one goes depends on the cost of the defense, the beneﬁ t to availability, and \nthe cost of downtime to the enterprise. When the system is truly  “ mission critical, ” as in certain military, ﬁ nan-\ncial, and transportation applications, an enterprise will go to extraordinary lengths to reduce the probability of \nsuch failures. One airline system is housed in an underground bunker. \n After hardening the environment, the next step is to replicate the system, ideally in a geographically distant \nlocation whose environmental disasters are unlikely to be correlated to those at other replicas. For example, \nmany years ago one California bank built an extra computer facility east of the San Andreas Fault , so they could \nstill operate if their Los Angeles or San Francisco facility were destroyed by an earthquake. More recently, geo-\ngraphical replication has become common practice for large-scale Internet sites. Since a system replica is use-\nful only if it has the data necessary to take over processing for a failed system, data replication is an important \nenabling technology. Data replication is the subject of Chapter 9. \n System Management \n System management is another cause of failures. People are part of the system. Everybody has an off day or \nan occasional lapse of attention. It’s only a matter of time before even the best system operator does something \nthat causes the system to fail. \n There are several ways to mitigate the problem. One is simply to design the system so that it doesn’t \nrequire maintenance, such as using automated procedures for functions that normally would require opera-\ntor intervention. Even preventative maintenance, which is done to increase availability by avoiding failures \nlater on, may be a source of downtime. Such procedures should be designed to be done while the system is \noperating. \n\n\n Simplifying maintenance procedures also helps, if maintenance can’t be eliminated entirely. So does building \nredundancy into maintenance procedures, so an operator has to make at least two mistakes to cause the system to \nmalfunction. Training is another factor. This is especially important for maintenance procedures that are needed \ninfrequently. It’s like having a ﬁ re drill, where people train for rare events, so when the events do happen, people \nknow what actions to take. \n Software installation is often a source of planned failures. The installation of many software products requires \nrebooting the operating system. Developing installation procedures that don’t require rebooting is a way to \nimprove system reliability. \n Many operation errors involve reconﬁ guring the system. Sometimes adding new machines to a rack or chang-\ning the tuning parameters on a database system causes the system to malfunction. Even if it only degrades perfor-\nmance, rather than causing the system to crash, the effect may be the same from the end user’s perspective. One can \navoid unpleasant surprises by using conﬁ guration management tools that simulate a new conﬁ guration and demon-\nstrate that it will behave as predicted, or to have test procedures on a test system that can prove that a changed con-\nﬁ guration will perform as predicted. Moreover, it is valuable to have reconﬁ guration procedures that can be quickly \nundone, so that when a mistake is made, one can revert to the previous working conﬁ guration quickly. \n If a system is not required to be 24  \u0004  7, then scheduled downtime can be used to handle many of these \nproblems, such as preventative maintenance, installing software that requires a reboot, or reconﬁ guring a sys-\ntem. However, from a vendor’s viewpoint, offering products that require such scheduled downtime limits their \nmarket only to customers that don’t need 24  \u0004  7. \n Hardware \n The third cause of failures is hardware problems. To discuss hardware failures precisely, we need a few techni-\ncal terms. A  fault is an event inside the system that is believed to have caused a failure. A fault can be either \ntransient or permanent. A  transient fault is one that does not reoccur if you retry the operation. A  permanent \nfault is not transient; it is repeatable. \n The vast majority of hardware faults are transient. If the hardware fails, simply retry the operation; there’s \na very good chance it will succeed. For this reason, operating systems have many built-in recovery procedures \nto handle transient hardware faults. For example, if the operating system issues an I/O operation to a disk or \na communications device and gets an error signal back, it normally retries that operation many times before it \nactually reports an error back to the caller. \n Of course, some hardware faults are permanent. The most serious ones cause the operating system to fail, \nmaking the whole system unavailable. In this case, rebooting the operating system may get the system back into \na working state. The reboot procedure will detect malfunctioning hardware and try to reconﬁ gure around it. If \nthe reboot fails or the system fails shortly after reboot, then the next step is usually to reimage the disk with a \nfresh copy of the software, in case it became corrupted. If that doesn’t ﬁ x the problem, then repairing the hard-\nware is usually the only option. \n Software \n This brings us to software failures. The most serious type of software failure is an operating system crash, \nsince it stops the entire computer system. Since many software problems are transient, a reboot often repairs \nthe problem. This involves rebooting the operating system, running software that repairs disk state that might \nhave become inconsistent due to the failure, recovering communications sessions with other systems in a dis-\ntributed system, and restarting all the application programs. These steps all increase the MTTR and therefore \n7.1 Causes of System Failure  187\n\n\n188  CHAPTER 7 System Recovery\n reduce availability. So they should be made as fast as possible. The requirement for faster recovery inspired \noperating systems vendors in the 1990s to incorporate fast ﬁ le system recovery procedures, which was a major \ncomponent of operating system boot time. Some operating systems are carefully engineered for fast boot. For \nexample, highly available communication systems have operating systems that reboot in under a minute, worst \ncase. Taking this goal to the extreme, if the repair time were zero, then failures wouldn’t matter, since the sys-\ntem would recover instantaneously, and the user would never know the difference. Clearly reducing the repair \ntime can have a big impact on availability. \n Some software failures only degrade a system’s capabilities, not cause it to fail. For example, consider an \napplication that offers functions that require access to a remote service. When the remote service is unavail-\nable, those functions stop working. However, through careful application design, other application functions \ncan still be operational. That is, the system degrades gracefully when parts of it stop working. A real example \nwe know of is an application that used a TP database and a data warehouse, where the latter was nice to have \nbut not mission-critical . The application was not designed to degrade gracefully, so when the data warehouse \nfailed, the entire application became unavailable, which caused a large and unnecessary loss of revenue. \n When an application process or database system does fail, the failure must be detected and the application \nor database system process must be recovered. This is where TP-speciﬁ c techniques become relevant. \n 7.2  A MODEL FOR SYSTEM RECOVERY \n In this section, we will discuss how to cope with the failure and recovery of processes that are running applica-\ntion code. We will look at the failure and recovery of resource managers, notably database systems, starting in \nSection 7.3. \n Detecting Process Failures \n Operating system processes are a ﬁ rewall between the operating system and the application. An application \nfailure may cause the application’s process to fail. However, the operating system can continue, so only the \nprocess needs to be restarted. This reduces MTTR compared to a system where the application failure causes \nan operating system reboot. Therefore, most TP systems are built from multiple processes. \n We would like each process to be as reliable as possible. But of course, no matter how reliable it is, there are \ntimes when it will fail. When it does fail, some agent outside of the process has to observe that fact and ask to \nrecreate the process. Usually that’s done by the operating system, database system, or transactional middleware. \n The transactional middleware or database system usually has one or more monitoring processes that track \nwhen application or database processes fail. There are several ways that are commonly used to detect failures: \n ■  Each process could periodically send an  “ I’m alive ” message to the monitoring process (see  Figure 7.1 ); \nthe absence of such a message warns the monitoring process of a possible failure. \n ■  The monitoring process could poll the other processes with  “ Are you alive? ” messages. \n ■  Each process could own an operating system lock that the monitoring process is waiting to acquire; if the \nprocess fails, the operating system releases the process ’ s lock, which causes the monitoring process to be \ngranted the lock and hence to be alerted of the failure. \n Whichever approach is taken, it is important to optimize the time it takes for a monitoring process to detect \nthe failure, since that time contributes to the MTTR and therefore to unavailability. \n In all these cases, the symptom provides a good reason to suspect that the process failed, but it is not an \nironclad guarantee that the process actually did fail. In the ﬁ rst two cases, the process might just be slow to \n\n\n respond. In the third case, it might have released the lock yet still be operational. The suspicion of a failure \nis more likely to be true if the detector is executing under the same operating system instance as the process \nbeing monitored; that is, on the same machine or virtual machine, though even here it is not a guarantee. This \nis the scenario we focus on in this chapter, and we will assume that failure detection is accurate. \n In a distributed system where the monitor is running on a different machine than the process being moni-\ntored, there is a greater chance that the failure symptom is due to a communication failure rather than a process \nfailure. We will explore this issue in Chapters 8 and 9. \n A process could fail by returning incorrect values. That is, it could fail to satisfy its speciﬁ cation. For \nexample, the data it returns could have been corrupted by faulty memory, a faulty communication line, or an \napplication bug. We do not consider such errors here. We assume the ﬁ rst two are prevented by suitable error-\ndetecting codes. We do not consider application bugs because we cannot eliminate them by using generic sys-\ntem mechanisms. They are addressed by software engineering technology and methodology, which are outside \nthe scope of this book. \n When a process failure is detected, some agent needs to recreate the failed process. The operating system \ngenerally is designed only to recreate processes that are needed to keep the system running at all, such as the \nﬁ le system (if it runs as a process) and system monitor processes. The operating system generally does not \nautomatically recreate application processes, except those managed by the operating system’s process control \nsystem. Therefore, transactional middleware and database systems must step in to detect the failure of applica-\ntion and database system processes, and when they do fail, to recreate them. \n Client Recovery \n In this discussion of recovery, we assume a basic client – server model: a client process communicates with a \nserver process and the server process uses underlying resources, such as a disk or communications line (see \n Figure 7.2 ). A common conﬁ guration is to have the client running on a desktop machine and the server on a \nlarger shared machine. Whatever the conﬁ guration, the possible technical approaches for system recovery remain \nthe same. We are therefore deliberately vague about the type of machine on which the client and server run. \n There are several points of failure in this system: the client, the client-server connection, the server, the \nserver-resource connection, and the resources. If the client fails and later recovers, it needs to reconnect to \nthe server and can start calling it again. Or, if the client loses communication with the server, either because the \ncommunication line or server failed, the failure will eventually be repaired and the client will later re-establish \nFault detection\nmonitor\n“I'm alive”\n“I'm alive”\n“I'm alive”\nProcess 1\nProcess 2\nProcess N\n FIGURE 7.1 \n A Fault Detection Monitor. The monitor detects process failures, in this case by listening for  “ I’m alive ” messages. When \nit doesn’t hear one within its timeout period, it assumes the process has failed. \n7.2 A Model for System Recovery  189\n\n\n190  CHAPTER 7 System Recovery\n that communication and resume calling the server. In either case, at recovery time, the main issue for the client \nis to re-establish its state relative to the server. \n The state of the client relative to the server consists of the set of its outstanding calls to the server. Therefore, \nto recover its state, it needs to determine the following: \n ■  What calls were outstanding at the time it failed or lost connectivity with the server? \n ■  What happened to those calls while it was down or not communicating with the server? \n ■  What does it have to do to ﬁ nish those calls properly before proceeding with new calls? \n These are exactly the issues we discussed in Chapter 4,  “ Queued Transaction Processing. ” If there is a per-\nsistent queue between the client and server, then the client can ﬁ nd out the state of all outstanding calls (called \n “ requests ” in Chapter 4) by examining the queue. If not, then it has to use an application-speciﬁ c technique, such \nas looking at the database state on the server to determine if the client’s previous calls completed, or reissuing \nin-doubt calls with the same serial number and relying on the server to discard duplicate calls. These techniques \ntoo were discussed in Chapter 4. \n The remaining issues all focus on server availability, which is the subject of the rest of this section. \n Server Recovery \n After a server has been recreated, it runs its recovery procedure to reconstruct its state before starting to pro-\ncess new calls. If this is the ﬁ rst time the server has ever run, then the recovery procedure is trivial — the server \njust initializes its state. If not, then it has some work to do. \n To explore how a server reconstructs its state, let’s begin from ﬁ rst principles. Suppose the server is a sequen-\ntial processor of calls and there are no transactions in the picture. The server just receives a call from a client, \ndoes what is requested, and returns a result. At the time it failed, the server might have been in the middle of \nprocessing such a call. \n As we discussed in the previous section on Client Recovery, it is up to the client to determine the state of its \noutstanding calls. It’s always possible that a server (or communications) failure causes a call to get lost, so the \nclient must be able to cope with that fact. Since the client has to be able to deal with lost calls, it would seem \nthat a recovering server could just ignore whatever call it was working on at the time it failed and start afresh. \nIt’s up to the client to ﬁ gure out what to do. \nResources\nServer\nClient\n FIGURE 7.2 \n Basic Client-Server Model. A client process communicates with a server process and the server process uses underlying \nresources, such as a disk or communication line. \n\n\n Unfortunately , this doesn’t always work, because the server may have performed a non-idempotent  opera-\ntion while it was processing its last call before the failure. For example, it may have printed a check, transferred \nmoney, credited a bank account, dispensed cash, or shipped a product. If the client concludes that the server \ndid not execute the call, it will reissue it, thereby causing the server to redo the work. Therefore, if the server \nperformed a non-idempotent  operation on behalf of the call it was processing at the time of failure, it must not \nre-execute the call. Rather, it must complete the call and return a result. \n The details of recovering a partially-executed  call are complex and are not commonly used in systems that \nsupport transactions. However, to appreciate how much easier things are when transactions are available, let us \nbrieﬂ y examine what the server would have to do if it could not rely on transactions. \n Checkpoint-Based Recovery \n Suppose the server partially executed a client’s call and then failed. Suppose all the operations that the server \nexecuted for that partially-executed  call were idempotent. In that case, at recovery time the server can simply \nreprocess the call from the beginning. Re-executing operations that it executed before the failure does no harm, \nbecause all those operations are idempotent. \n Suppose the server did perform non-idempotent  operations for the last call. Then it must recover itself to \na state that came after the last non-idempotent  operation it executed before the failure. So, for example, if the \nserver printed a check before the failure, then it must be recovered to a state after the time that it printed the \ncheck. If the server continued processing from a state before it printed the check then it would repeat that oper-\nation (i.e., print the check again), which is exactly what should not happen. Recreating this state requires some \ncareful bookkeeping before the failure, so the recovering server can look up what was going on at the time of \nfailure, to ﬁ gure out what it should do. \n One general way to prepare for this type of recovery is to have a server save its memory state on nonvolatile \nstorage (e.g., a disk) before it executes a non-idempotent  operation. That way, when it recovers, it can recreate \nthat state (see  Figure 7.3 ). Saving memory state is an example of checkpointing. In general,  checkpointing is \nany activity that is done during normal processing to reduce the amount of work to redo after a recovery. Saving \nmemory state is a kind of checkpointing, because it ensures that when the server recovers, it won’t have to redo \nany work that it did before saving its state. \n Saving the state of the server’s memory is not cheap, especially if it has to be done every time a non-\nidempotent  operation is performed. As we’ll see in a moment, transactions help reduce this cost. \n To recover from a failure, the server restores the last checkpoint state it successfully saved (see  Figure 7.4 ). \nIt must then check if the non-idempotent  operation that followed its last checkpoint actually ran. For example, \na. Normal Operation\nb. Server Recovery\nDisk\nServer\nClient\nWrite\ncheckpoints.\nServer\nClient\nRead last\ncheckpoint.\nDisk\n FIGURE 7.3 \n Server Checkpointing. During normal operation, the server periodically writes a checkpoint. After a failure, it uses its last \ncheckpointed state to recover. \n7.2 A Model for System Recovery  191\n\n\n192  CHAPTER 7 System Recovery\n if the server checkpoints its state right before printing a check, then at recovery time reconstituting the server \nstate requires determining whether or not the check was printed. This is the same question we asked in the ear-\nlier section on Client Recovery and in Section 4.4,  Handling Non-Undoable  Operations . That is, in this situa-\ntion, the server is in the role of a client in Section 4.4 that may have called a non-idempotent  operation before \nit failed. Therefore, when the server recovers, it must determine whether that non-idempotent  operation ran, \nand if so it can skip over it. \n To summarize: If a server performs non-idempotent operations, then it reconstitutes its state at recovery \ntime to one that comes after the last non-idempotent operation that it performed before the failure. The idea is \nto start running the process from that state, so that non-idempotent operations it does from that point on don’t \ncause a problem. \n Transaction-Based Server Recovery \n Transactions simplify server recovery by focusing clients ’ and servers ’ attention on the transactions executed \nby each server, rather than on individual calls within a transaction. That is, the server does all its work within \ntransactions. The client tells the server to start a transaction, the client makes some calls to the server within \nthat transaction, and then the client tells the server to commit the transaction. \n If a server that supports transactions fails and subsequently recovers, its state includes the effects of all \ntransactions that committed before the failure and no effects of transactions that aborted before the failure or \nwere active at the time of the failure. Comparing this behavior to a nontransactional server, it is as if the trans-\nactional server performs a checkpoint every time it commits a transaction, and its recovery procedure discards \nall effects of aborted or incomplete transactions. Thus, when a transactional server recovers, it ignores which \n calls were executing when it failed and focuses instead on which  transactions were executing when it failed. \nSo instead of recovering to a state as of the last partially-executed  call (as in checkpoint-based recovery), it \nrecovers to a state containing all the results of all committed transactions and no others. \n For this to work, the server must be able to undo all of a transaction’s operations when it aborts. This effec-\ntively makes the operations redoable when the transaction is re-executed . That is, if an operation was undone, \nthen there’s no harm in redoing it later, even if it is non-idempotent. This avoids a problem that was faced in \ncheckpoint-based recovery — the problem of returning to a state after the last non-idempotent operation. This \nisn’t necessary because every non-idempotent operation was either part of a committed transaction (and hence \nwon’t be redone) or was undone (and hence can be redone). \nServer Program\n     . . .\n     Checkpoint;\n     // Recovery procedure branches to next line\n     If RestartFlag\n     { RestartFlag \u0003 0;\n       If(check wasn’t printed before the failure) print check;\n     }\n     else print check\n     . . .\nServer Recovery Procedure:\n    RestartFlag \u0003 1;\n    Find last checkpoint on disk;\n    Restore checkpoint’s memory state;\n    Go to next server statement after Checkpoint\n FIGURE 7.4 \n Checkpoint-Based Recovery Procedure. The server program checkpoints before its non-idempotent  “ print check ” \noperation. The server recovery procedure recovers the last checkpoint state and branches to the line after the statement \nthat created the checkpoint. The server program then executes the non-idempotent operation  “ print check ” only if it \nwasn’t done before the failure. \n\n\n If all operations in a transaction must be redoable, then the transaction must not include the non-idempotent \noperations we encountered in the earlier section,  Server Recovery , such as printing a check or transferring \nmoney. To cope with such a non-idempotent operation, the transaction should enqueue a message that con-\ntains the operation. It’s safe for the transaction to contain the enqueue operation, because it is undoable. The \nprogram that processes the message and performs the non-idempotent operation should use the reply handling \ntechniques in Section 4.4 to get exactly-once execution of the actual operation (printing the check or sending a \nmoney-transfer message). \n Transactions not only simplify server recovery, they also speed it up. A memory checkpoint is expensive, \nbut transaction commitment is relatively cheap. The trick is that the transactional server is carefully maintain-\ning all its state on disk, incrementally, by writing small amounts to a log ﬁ le, thereby avoiding a bulk copy of \nits memory state. It is designed to suffer failures at arbitrary points in time, and to reconstruct its memory state \nfrom disk using the log, with relatively modest effort. The algorithms to reconstruct its state in this way are \nwhat gives transactions their all-or-nothing and durability properties. Either all of a transaction executes or none \nof it does. And all of its results are durably saved in stable storage, even if the system fails momentarily after the \ntransaction commits. These algorithms are the main subject of the rest of this chapter. \n Stateless Servers \n When transactions are used, servers usually are split into two types: application processes and resource managers \n(see  Figure 7.5 ). An application process receives a client request, starts a transaction, performs application logic, \nand sends messages to transactional resource managers. It does not directly access transactional resources, such \nas a database. Resource managers handle the state being shared by transactions — databases, recoverable queues, \nand so on. \n A resource manager behaves just like a transactional server described in the previous section,  Transaction-\nBased Server Recovery . That is, it executes all calls within a transaction. And its recovery procedure returns its \nstate to one that includes the effects of all committed transactions and no others. \nApplication\nProcess\nResource\nManager\nClient\nResources\n FIGURE 7.5 \n Stateless Servers. An application process stores all its state in resource managers, and is therefore stateless. \n7.2 A Model for System Recovery  193\n\n\n194  CHAPTER 7 System Recovery\n An application process can use a simpler recovery procedure than resource managers, because it is state-\nless. That is, it doesn’t have any state that might be needed after recovery. It receives a request to run a transac-\ntion (from its client), starts a transaction, executes operations that manipulate local memory or call a database \nsystem or another application process, commits the transaction, and sends a reply back to the client. At this \npoint, it has no state worth remembering. It simply processes the next request that it receives as if it had been \ninitialized from scratch. \n A stateless server doesn’t have to do very much to recover from a failure. It just reinitializes its state and starts \nrunning transactions again, completely oblivious to whatever it was doing before the failure. Since it maintains \nall its state in transactional resource managers, it is really up to the resource managers to reconstitute their states \nafter a failure. The resource managers recover to a state that includes all the committed transactions and none of \nthe aborted ones, up to the time of the failure. Now the application process can start processing requests again. \n The application processes controlled by transactional middleware usually are designed to be stateless serv-\ners so they do not need any recovery code. The only ambiguity is about the state of the last request that a client \nissued to the application process before the failure (e.g., that a front-end program issued to a request control-\nler). That is, the client is not stateless, since it needs to know the state of that last request. This is where queued \nrequest processing comes in — to ﬁ gure out the state of that last request and thereby determine whether it has \nto be rerun. For the application process that was actually executing the request, there’s no ambiguity at all. It \nrestarts in a clean state, as if it were initialized for the ﬁ rst time. \n 7.3  INTRODUCTION TO DATABASE RECOVERY \n Now that we understand how to recover application processes, it’s time to turn our attention to recovering \nresource managers. As in Chapter 6,  “ Locking, ” we will use the term data manager instead of the more generic \nterm resource manager. The most popular type of data manager is a database system. However, the principles \napply to any kind of transactional resource manager, such as queue managers and transactional ﬁ le systems. \n To recover from a failure, a data manager needs to quickly return its database to a state that includes the \nresults of all transactions that committed before the failure and no results of transactions that aborted before \nthe failure or were active at the time of failure. Most data managers do an excellent job of this type of recovery. \nThe application programmer doesn’t get involved at all. \n The mechanisms used to recover from these failures can have a signiﬁ cant effect on performance. However, \nif a data manager uses a recovery approach that leads to mediocre transaction performance, there is not too \nmuch that the application programmer can do about it. This is rather different than locking, where application \nprogramming and database design can have a big effect. In view of the lack of control that an application pro-\ngrammer has on the situation, there is no strong requirement that he or she have a deep understanding of how a \ndata manager does recovery. \n Still , there are a few ways, though not many, that database and system administrators can work together \nto improve performance, fault tolerance, and the performance of recovery. For example, they can improve the \nfault tolerance of a system by altering the conﬁ guration of logs, disk devices, and the like. To reason about per-\nformance and fault tolerance implications of application and system design, it helps a great deal to understand \nthe main concepts behind database recovery algorithms. We describe these concepts in the rest of this chapter \nand their implications for application programming. \n Types of Failure \n Many failures are due to incorrectly programmed transactions and to data entry errors that lead to incorrect \nparameters to transactions. Unfortunately, these failures undermine the assumption that a transaction’s execution \n\n\n preserves the consistency of the database (the  “ C ” in ACID). They can be dealt with by applying software engi-\nneering techniques to the programming and testing of transactions, by validating input before feeding it to a trans-\naction, and by semantic integrity mechanisms built into the data manager. However they’re dealt with, they are \nintrinsically outside the range of problems that transaction recovery mechanisms can automatically handle. Since \nwe’re interested in problems that transaction recovery mechanisms  can handle, we will assume that transactions \ndo indeed preserve database consistency. \n There are three types of failures that are most important to a TP system: transaction failures, system fail-\nures, and media failures. A  transaction failure occurs when a transaction aborts. A  system failure occurs \nwhen the contents of volatile storage, namely main memory, is corrupted. For example, this can happen to \nsemiconductor memory when the power fails. It also happens when the operating system fails. Although an \noperating system failure may not corrupt all of main memory, it is usually too difﬁ cult to determine which \nparts were actually corrupted by the failure. So one generally assumes the worst and reinitializes all of main \nmemory. Given the possibility of system failures, the database itself must be kept on a stable storage medium, \nsuch as disk. (Of course, other considerations, such as size, may also force us to store the database on stable \nmass storage media.) By deﬁ nition,  stable (or  nonvolatile )  storage withstands system failures. A  media fail-\nure occurs when any part of the stable storage is destroyed. For instance, this happens if some sectors of a disk \nbecome damaged. \n In this chapter we assume that each transaction accesses and updates data at exactly one data manager. This \nallows us to focus our attention on recovery strategies for a single data manager. In the next chapter we’ll con-\nsider additional problems that arise when a transaction can update data at more than one data manager. \n Recovery Strategies \n The main strategy for recovering from failures is quite simple: \n ■  Transaction failure: If a transaction aborts, the data manager restores the previous values of all data items \nthat the transaction wrote. \n ■  System failure: To recover from the failure, the data manager aborts any transactions that were active \n(i.e., uncommitted) at the time of the failure, and it ensures that each transaction that did commit before \nthe failure actually installed its updates in the database. \n ■  Media failure: The recovery strategy is nearly the same as for system failures, since the goal is to \nreturn the database to a state where it contains the results of all committed transactions and no aborted \ntransactions. \n We will concentrate on recovery from transaction and system failures for most of the chapter. Recovery \nfrom media failures is quite similar to recovery from system failures, so we’ll postpone discussing it until the \nend of the chapter, after we have a complete picture of system recovery mechanisms. \n It ’s easy to see why system and media recovery are so similar. Each recovery mechanism considers a cer-\ntain part of storage to be unreliable: main memory, in the case of system failures; a portion of stable storage, in \nthe case of media failures. To safeguard against the loss of data in unreliable storage, the recovery mechanism \nmaintains another copy of the data, possibly in a different representation. This redundant copy is kept in another \npart of storage that it deems reliable: stable storage, in the case of system failures, or another piece of stable \nstorage, such as a second disk or tape, in the case of media failures. Of course, the different physical character-\nistics of storage in the two cases may require the use of different strategies. But the principles are the same. \n The most popular technique for recovering from system and media failures is logging. The log is that \nsecond, redundant copy of the data that is used to cope with failures. To understand how a log is used, why it \nworks, and how it affects performance, we need to start with a simpliﬁ ed model of data manager internals, so \nwe have a framework in which to discuss the issues. \n7.3 Introduction to Database Recovery  195\n\n\n196  CHAPTER 7 System Recovery\n 7.4  THE SYSTEM MODEL \n Locking Assumptions \n From the viewpoint of transactions, the recovery system is part of the storage subsystem that processes read, write, \ncommit, and abort operations. The recovery system makes few assumptions about the transactions that use its ser-\nvices. The main one is that the transaction is responsible for setting locks before issuing read and write operations \nto the storage system, and that it holds onto its write locks until after the transaction commits or aborts. \n Since a transaction holds a write lock on any data it updates until after it commits or aborts, no other trans-\naction can read or write that data until then. This avoids three messy recovery situations. \n The ﬁ rst messy situation is guaranteeing recoverability. Suppose a transaction is allowed to release write locks \nbefore it commits or aborts. Consider a transaction T 2 that reads a data item that was last updated by an active \ntransaction T 1 , and T 2 commits while T 1 is still active. If T 1 subsequently aborts, the execution looks like this: \n E\nw [ ] r [ ] commit  abort\n1\n2\n\u0003\nx\nx\n2\n1  \n The data manager is now stuck. It should abort T 2 , because T 2 has read data that is now invalid; but it can’t, \nbecause T 2 already committed. That is, the data manager is in a state from which it can’t recover. It’s therefore \nessential that a transaction not commit if it read any data that was last updated by a transaction that is still \nactive. That is, a transaction T’s commit operation must follow the commit of every transaction from which T \nread. An execution that obeys this rule is called  recoverable . Holding write locks until after a transaction com-\nmits or aborts solves this problem with a sledgehammer; a transaction can’t read data that was last updated by \na transaction that is still active, because the latter holds a write lock on that data. \n The second messy situation is cascading abort. Consider the same situation as in the previous paragraph, \nwhere T 2 read data that was last updated by an active transaction T 1 . But this time, suppose T 1 aborts while T 2 \nis still active. That is, the execution looks like this: \n E\nw [ ] r [ ] abort\n1\n\u0002 \u0003\nx\nx\n2\n1  \n Then , as before, T 2 would have to abort too, since its input would be invalid. This is called  cascading abort , \nsince the abort of one transaction (T 1 ) cascades to the abort of another transaction (T 2 ). We’re certainly better off in \nthis situation than in the previous paragraph, since at least it’s legal to abort T 2 (because T 2 is still active). But the \nsystem still needs to keep track of which transactions depend on which other transactions — nontrivial bookkeep-\ning. We can avoid this bookkeeping by requiring that a transaction only reads data that was last updated by a trans-\naction that has committed. An execution that obeys this rule is said to  avoid cascading aborts . A data manager \ncan avoid cascading aborts by ensuring that every transaction holds its write locks until after it commits or aborts. \n The third messy situation is being unable to abort a transaction simply by restoring the previous values of \ndata it wrote. This arises if a transaction can overwrite another transaction’s uncommitted writes. For example, \nif T 1 does not hold its write locks until after it commits or aborts, then another transaction can overwrite data \nwritten by T 1 . The effect is rather nasty, as illustrated by the following execution: \n E\nw [ ] w [ ] abort  abort\n1\n\t \u0003\nx\nx\n2\n1\n2  \n In execution E \t , when transaction T 1 aborts, the system cannot simply restore the value  x had before w 1 [ x ], \nsince that would wipe out the result of T 2 ’s write operation, w 2 [ x ]. At this point, the system doesn’t know \nwhether T 2 will commit or abort. If T 2 later commits, its update to  x would be lost. So, the right thing for the \ndata manager to do when T 1 aborts is nothing. Now, when T 2 aborts, the system cannot restore the value  x had \n",
      "page_number": 204
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 215-222)",
      "start_page": 215,
      "end_page": 222,
      "detection_method": "topic_boundary",
      "content": " before w 2 [ x ], since that would reinstall the value written by T 1 , which just aborted. So, the right thing for the \nsystem to do when T 2 aborts is to restore the value  x had before w 1 [ x ]. This is a pretty complicated analysis \nfor the recovery mechanism to do, and this is just for two updates by two transactions. If multiple transactions \nwere involved, the analysis would be very tricky indeed. All systems we know of avoid it by allowing a trans-\naction to write a data item only if the previous transaction that updated the data item already committed. Such \nexecutions are called  strict . This is usually implemented by requiring that write locks are held until after the \ntransaction commits or aborts. This ensures that the data manager can abort a transaction simply by restoring \nthe previous values of data that the transaction wrote. \n In summary, a lot of recovery problems become much simpler if the recovery system can assume that a \ntransaction holds its write locks until after it commits or aborts. All systems we know of rely on this assumption. \n Page Granularity Operations \n Locking granularity is another aspect of locking that affects the complexity of recovery mechanisms. Recovery \nalgorithms are a lot simpler when page granularity locking is used. Here’s why. \n The only truly reliable operation that a data manager has available is writing one page to a disk. Disk hard-\nware is careful to make this an atomic (i.e., all-or-nothing) operation with respect to system failures. That is, if \nthe system fails, then recovers, and then a program reads a page P from disk, the content of P reﬂ ects the last \ncomplete write to P before the system failed. \n Although the hardware is designed to make disk writes atomic, errors are still possible. For example, if \na disk malfunctions, it might partially execute a write operation on page P. In that case, the next operation to \nread P may detect the error, for example, as an erroneous checksum on the page. This is a media failure. \n Depending on the hardware, some media failures may not be detectable. For example, consider a disk mal-\nfunction where it executes a write operation completely, but stores the data in the wrong location. That is, an \noperation was issued to write page P, but the disk wrote it to a different location, Q. In this case, when an appli-\ncation reads page P, the value it reads may appear to be correct. However, due to the previous erroneous write, \nthe value of P does not reﬂ ect the last write operation to P, but an earlier one. Moreover, the next read of page Q \nwill return a value that appears to be correct (since it reﬂ ects a complete write operation), but it too is incorrect \nbecause it contains the last value written to page P, not page Q. The latter error can be detected if the checksum \non Q is a function of both the address of Q and its content. \n We assume that all this complexity is hidden by the hardware and software I/O system that implements read \nand write operations. That is, each write operation either overwrites the intended page or does nothing. And each \nread operation returns a complete disk page or an error indicating that the page is corrupted. Recovery algo-\nrithms for system failure make heavy use of this property of disks, that page operations are atomic. So if trans-\nactions read and write complete pages, the atomicity of page writes offers a clean model we can use to reason \nabout the state of the database after a failure. \n Suppose a page can hold multiple records, transactions write records not pages, and the data manager uses \nrecord-level locks. In that case, multiple transactions can lock and update different records within a single page. \nIf they do, then at recovery time a page may contain records that were recently updated by different transac-\ntions, only some of which have committed. Depending on the state of the page, some of the committed updates \nmay need to be reapplied, while others need to be undone. The bookkeeping to sort this out is quite challenging. \nThis complexity is a problem worth solving, but for pedagogical reasons, it’s one we’ll postpone for awhile. \nInstead, to keep things simple, we will use page granularity for everything: \n ■  The database consists of a set of pages. \n ■  Each update by a transaction applies to only one page. \n7.4 The System Model  197\n\n\n198  CHAPTER 7 System Recovery\n ■  Each update by a transaction writes a whole page (not just part of the page). \n ■  Locks are set on pages. \n Page granularity simpliﬁ es the discussion, but it is too inefﬁ cient for high performance systems. After we \ndescribe recovery using this assumption, we’ll show what happens when we allow ﬁ ner grained updates and \nlocks on records. \n Storage Model \n We model storage as two areas: stable storage (usually disk) and volatile storage (usually main memory) (see \n Figure 7.6 ). Stable storage contains the  stable database , which has one copy of each database page. It also \ncontains the log, which we’ll discuss in a moment. \n Volatile storage contains the database  cache . The cache contains copies of some of the database pages, \nusually ones that were recently accessed or updated by transactions. Using a cache is a big performance win, \nbecause it helps transactions avoid the high cost of disk accesses for popular pages. \n For recovery purposes, it really doesn’t matter which pages are in cache, only that there are some. Pages \nin cache may contain updates that have not yet been written to stable storage. Such pages are called  dirty . \nCorrectly handling dirty pages is an important responsibility of the recovery system during normal operation. \n The  cache manager keeps track of what is in cache. It is part of the page-oriented ﬁ le system layer of a \ndata manager, as shown in Figure 6.4. It divides the cache into  slots , each of which can hold one database page. \nIt uses a table to keep track of what is in each slot. Each row of the table contains a  cache descriptor , which \nidentiﬁ es the database page that is in the cache slot, the main memory address of the cache slot, a bit to indicate \nwhether the page is dirty, and a pin count (explained below; see  Figure 7.7 ). The cache manager supports ﬁ ve \nbasic operations: \n ■  Fetch(P): P is the address of a database page. This reads P into a cache slot (if it isn’t already there) and \nreturns the address of the cache slot. \nStable database\nFetch, Flush\nPin, Unpin\nDeallocate\nCache\nRead, Write\nRead, Write\nLog\nCache manager\n FIGURE 7.6 \n The Storage Model. The cache manager controls the movement of pages between stable storage (the stable database \nand log) and volatile storage (the cache). \n\n\n ■  Pin(P): This makes page P’s cache slot unavailable for ﬂ ushing (it is  “ pinned down ” ). Usually, a caller \npins P immediately after fetching it. \n ■  Unpin(P): Releases the caller’s previous pin. The cache manager maintains a  pin count for each page, \nwhich is incremented by each Pin operation and decremented by each Unpin. If the pin count is zero, the \npage is available for ﬂ ushing or deallocation. \n ■  Flush(P): If database page P is in a cache slot and is dirty, then this operation writes it to the disk. It does \nnot return until after the disk acknowledges that the write operation is done. That is, a ﬂ ush is a synchro-\nnous write. \n ■  Deallocate(P): Deallocates P so its cache slot can be reused by another page. Does not ﬂ ush the page, \neven if the cache slot is dirty. It is up to the cache manager’s clients to ﬂ ush a page (if appropriate) \nbefore deallocating it. \n Everything else that happens to pages is up to the transactions. If a transaction has fetched and pinned a \npage, it can do what it wants to the content of that page, as far as the cache manager is concerned. Of course, \nwe know the transaction will have an appropriate lock to read or write the page, but this is at a higher layer than \nthe cache manager, which doesn’t know anything about these locks. \n The cache manager is heavily used by data manager components that read and write the database. This is \nusually the record management layer of the data manager (i.e., the Access Method layer in Figure 6.3), which \nreads and writes records and provides indexed access to data. To read or write data on a page P, this component \nissues Fetch(P) followed by Pin(P). When it’s done reading or updating the page, it calls Unpin(P). It does not \ncall Flush(P). \n It is up to two other data manager components to call Flush(P). One is the cache manager’s page replace-\nment algorithm. Its job is to make the best use of cache by keeping only those pages that transactions are likely \nto need in the near future. If a page P hasn’t been referenced in awhile, it deallocates P from its page slot. If P \nis dirty, then it calls Flush(P) before Deallocate(P), so that recent updates to P aren’t lost. \n The other component that uses Flush(P) is the recovery manager, which is described in the next section. \n The Log \n The  log is a sequential ﬁ le, usually kept on disk, that contains a sequence of records that describes updates that \nwere applied to the database. The record that describes an update includes \n ■  The address of the page that was updated \n ■  The identiﬁ er of the transaction that performed the update \nPage\nDirty Bit\nCache Address\nPin Count\nP4\n1\n104\n1\nP16\n0\n376\n1\nP5\n1\n400\n0\n FIGURE 7.7 \n Cache Descriptor Table. Each page in a cache slot is described by a row in this table. \n7.4 The System Model  199\n\n\n200  CHAPTER 7 System Recovery\n ■  The value of the page that was written, called its  after-image \n ■  The value of the page before it was written, called its  before-image \n As described here, each log record is over two pages long, which is much too inefﬁ cient. Like our other \npage granularity assumptions, we’ll weaken it later on. \n This log record is written by the same component that writes to the cache. That is, whenever it updates a \ncache page, and before it unpins that page, it writes a log record that describes the update. That way, the log is \nalways consistent with the contents of the cache. \n The log also contains records that report when a transaction commits or aborts. Such records just contain \nthe identiﬁ er of the transaction and an indication whether the transaction committed or aborted. \n It is crucial that the log accurately reﬂ ects the order in which conﬂ icting operations really executed. That is, \nif one update precedes and conﬂ icts with another update in the log, then the updates must really have executed \nin that order. The reason is that after a failure, the recovery system will replay some of the work that happened \nbefore the failure. It will assume that the order of operations in the log is the order it should replay work. Note \nthat it is not necessary that the log accurately reﬂ ect the ordering of  all updates, only the conﬂ icting ones, \nwhich are the only ones whose relative order makes a difference. Some systems exploit this distinction by log-\nging nonconﬂ icting updates in parallel in  “ sublogs ” and merging those sublogs later, when conﬂ icting updates \noccur. \n Page -level locking ensures this ordering is enforced. If ﬁ ner granularity locking is used, then two transac-\ntions can update a page concurrently, so the database system must ensure that it updates the page and writes \nthe log record on behalf of one transaction before it performs these two actions on behalf of the other. This is \ndone by setting a short-term exclusive lock on the page, called a  latch , which can simply be a bit in the cache \ndescriptor. The latch brackets the activities of updating the page and logging the update (see  Figure 7.8 ). The \nlatch ensures that if another transaction was concurrently attempting the same sequence, then its update and log \noperations would either precede or follow those of T. \n Setting and releasing latches is done more frequently than setting and releasing locks. It therefore must be \nvery fast — just a few instructions. Thus, in most systems, no deadlock detection is done based on latches. So \nlots of care is needed to ensure that such deadlocks cannot occur. \n Whereas most systems store before-images and after-images in the same log, some use separate logs. \nThis is done because before-images are not needed after a transaction commits and usually are not needed \nfor media recovery. They can therefore be deleted relatively quickly, unlike after-images, which are needed \nfor very long periods. However, this can also lead to extra log writes, since there are now two logs to deal \nwith. \nFetch (P)                        /* read P into cache */\nPin (P)                            /* ensure P isn’t flushed */\nwrite lock P                    /* for two-phase locking */\nlatch P                            /* get exclusive access to P */\nupdate P                         /* update it in the cache */\nlog the update to P \n \n/* append it to the log */\nunlatch P                        /* release exclusive access */\nUnpin (P)                        /* allow P to be flushed */\n FIGURE 7.8 \n Using Latches. Obtaining a latch on P ensures that the ordering of log records is consistent with the order of updates to \neach page. \n\n\n 7.5  DATABASE RECOVERY MANAGER \n The recovery manager is the component that is responsible for processing commit and abort operations. It is \nalso responsible for the restart operation, which initiates recovery from a system failure, to bring the database \nback into a consistent state where it can process transactions again. In summary, the operations should have the \nfollowing effects (see  Figure 7.9 ): \n ■  Commit(T i ): Permanently installs T i ’s updated pages into the stable database. Its effect must be atomic, \nthat is, all-or-nothing, even in the event of a system failure. Also, its effect is irrevocable; once the trans-\naction is committed, it cannot subsequently be aborted. \n ■  Abort(T i ): Restores all the data that T i updated to the values it had before T i executed. Like Commit, its \neffect is irrevocable: once the transaction is aborted, it cannot subsequently be committed. \n ■  Restart: Aborts all transactions that were active at the time of the system failure. Also, any updates by \ncommitted transactions that were not installed in the stable database before the failure are installed now. \n(They may have been written only to the log and may not have made it to the stable database before the \nfailure.) The result should be that the database contains all committed updates and no aborted ones. \n To implement these operations, the recovery manager must follow certain rules. The essence of these rules \nis in controlling when dirty data is ﬂ ushed to disk. \n Implementing Abort \n Consider the operation Abort(T i ). Suppose T i wrote page P and no other transaction wrote P since P was last \nread from stable storage. If P was not transferred to stable storage after the time that T i ﬁ rst wrote P, then the \nrecovery manager can simply deallocate P. Otherwise, it has to write P’s before-image to the stable database; \nCommit, Abort\nRestart\nTransactions\nProgramming interface\nto low-level storage and\nrecovery subsystem\nRecovery manager\nCache\nRead, Write\nRead, Write\nFetch\n   Pin\n     Unpin\nFlush\nDeallocate\nT2\nCache manager\nT1\nTn\n FIGURE 7.9 \n Recovery Manager Model. The recovery manager calls the cache manager to help it implement the commit, abort, and \nrestart operations. \n7.5 Database Recovery Manager  201\n\n\n202  CHAPTER 7 System Recovery\n that is, it must restore P’s value to what it was before T i executed. Ordinarily, this is straightforward, since \nT i logged its update to P and the log record contains P’s before-image. However, what if the abort is being \nexecuted to help recover from a system failure? That is, T i was executing at the time of the system failure and \nthe restart procedure is executing Abort(T i ) to clean things up. It is conceivable that T i ’s update to P was trans-\nferred to the stable database before the failure, but its update to the log was not transferred to stable storage \nbefore the failure (see  Figure 7.10 ). In this case, T i ’s update to P cannot be undone, because the before-image \nhas been lost. This unacceptable situation must be prevented by enforcing the following rule: \n The Write-Ahead Log Protocol: Do not ﬂ ush an uncommitted update to the stable database until the log \nrecord containing its before-image has been ﬂ ushed to the log. \n There is a simple way to avoid the bookkeeping required to enforce this rule, namely, never ﬂ ush an uncom-\nmitted update to the stable database. Just ﬂ ush it to the log. This is sometimes called a  no-steal approach, \nbecause a cache slot occupied by an updated page is never  “ stolen ” so it can be used to store another page that \nis read in. After the transaction has committed, then ﬂ ush the page containing the update to the stable database. \nThat way, you never have to worry whether the before-image is in the log, because it will never be necessary to \nundo an uncommitted update in the stable database. That is, undo will never be required. For this reason, it is \nsometimes called a  no-undo strategy. \n Some systems avoid the bookkeeping by maintaining multiple versions of each page, as discussed in \nSection 6.6, on query-update problems. Instead of overwriting a page, they create a new version of the page. \nPeriodically, old versions that are no longer needed are purged. By keeping old versions in the database itself, \nbefore-images need not be logged, so the write-ahead log protocol is automatically satisﬁ ed. \n Implementing Commit \n Now let’s consider the operation Commit(T i ), and suppose T i wrote page P. Since a transaction’s results must \nbe durable and Commit is atomic, all of T i ’s updates must be in stable storage before the Commit — in the log \n1. Update P\nCache\n2. Update P\nSystem crashes after (2),\nso (3) never executes\n3. Write P’s before-image\nTi\nStable\ndatabase\nLog\nP\n FIGURE 7.10 \n Why We Need the Write-Ahead Log Protocol. If T i is active when the system fails, then it can’t be aborted after recovery, \nbecause P’s before-image was lost. \n\n\n or in the stable database. In particular, the after-image of T i ’s update to P (that is, the value that T i wrote to P) \nmust be there. This means that the recovery manager must enforce another rule: \n The Force-at-Commit Rule: Do not commit a transaction until the after-images of all its updated pages are \nin stable storage (in the log or the stable database). \n A simple way to implement the force-at-commit rule is to ﬂ ush a transaction’s updates to the stable database \nbefore it commits. This is sometimes called a  force approach, because all of a transaction’s updates are forced \nto the stable database before commit. This avoids any bookkeeping required to know which updates are not in \nthe stable database and therefore have to be ﬂ ushed in the log before commit. It also avoids any redo of commit-\nted updates, because they are always in the database before they are committed. For this reason, it is sometimes \ncalled a  no-redo strategy. However, it is inefﬁ cient for hot pages; that is, those that are frequently updated. As \nwe will see, the best logging algorithms avoid this inefﬁ ciency, although it requires some complex bookkeeping. \n Notice that the no-steal approach for enforcing the write-ahead log protocol and the force approach for \nenforcing force-at-commit rule are contradictory (see  Figure 7.11 ). Whichever approach is taken, it would \nseem that some undo or redo will be required. Although logging algorithms do indeed perform some undo \nand/or  redo, there are techniques that avoid both, which are described in the next section. \n The third operation of the recovery manager is restart. Restart requires a fair bit of bookkeeping. It needs to \nknow which transactions were active at the time of the failure, so it can abort them, and which updates of com-\nmitted transactions were not written to the stable database, so it can redo them. Moreover, restart must be fault-\ntolerant in the sense that if the system fails when restart is running, it must be possible to re-execute  restart. \nThat is, restart must be idempotent. This means that restart must be careful that, at all times, the system is in a \nstate from which restart can correctly execute (which is exactly the same requirement that normal executions \nhave). This requires carefully ordering updates to stable storage. \n Given all these rules, we are ready to look at algorithms that implement a recovery manager. A good recov-\nery manager algorithm should add little overhead to the normal processing of transactions. The principal ways \nit can contribute overhead is by ﬂ ushing pages too often (creating excess disk trafﬁ c) and by logging too much \ndata. A second goal is to recover quickly from a failure, so the system is only down for a short period. The \nshorter the downtime, the higher the availability. If the system could recover instantly from a failure, then it \ncould fail very often and no one would care (as long as it can commit some transactions!). \n 7.6  SHADOW-PAGING ALGORITHM \n Shadow paging is a simple way to implement a recovery manager. It is one of the easiest recovery algorithms \nto implement because it does not require a log manager, which is a relatively complex component. It is not \nwidely used in commercial products because it does not scale up to high transaction rates as well as logging. \nHowever, since it’s simple, we’ll describe it ﬁ rst. \nFlush all of Ti’s updates before\ncommit to avoid redo\nTi:      Start      . . .      Write(P)      . . .      Commit\nFlush all of Ti’s updates only\nafter commit to avoid undo\n FIGURE 7.11 \n Avoiding Undo or Redo. Depending on when a transaction’s updates are ﬂ ushed, undo or redo can be avoided. \n7.6 Shadow-Paging Algorithm  203\n\n\n204  CHAPTER 7 System Recovery\n The main idea is to store all of a transaction’s updates in a shadow copy of the database. There is also a \nmaster copy of the database, whose state represents the execution of all committed transactions and no aborted \nones. When the transaction commits, the shadow copy is swapped with the master copy of the database, thereby \ninstalling the updates. \n To enable this strategy, the master database is structured as a tree of pages. Let’s assume that the database \nconsists of a set of ﬁ les, where each ﬁ le is a sequence of pages. In this case, the root page of the master database \ncontains pointers to the root page of each ﬁ le. The root page of a ﬁ le is a page table that contains a sequence \nof pointers to the pages of the ﬁ le. To keep things simple, let’s assume that ﬁ les are small enough that pointers \nto all of the pages of a ﬁ le can ﬁ t in the ﬁ le’s root page. For example, in  Figure 7.12 the database has two ﬁ les, \nnamed A and B. File A has a page table identiﬁ ed by A Pt,m , where  “ m ” means  “ master. ” The ﬁ gure shows point-\ners to the ﬁ rst two pages of the ﬁ le, A 1 and A 2 . \n To keep this description simple, let’s assume that transactions execute serially. Thus, at most one transac-\ntion is active at any given time. \n In main memory each transaction has a cached copy of the page table of each ﬁ le it reads or writes. For \nexample, the cached page tables for transaction T i are shown in  Figure 7.12 . Initially, the contents of these \ncached page tables is the same as their content in stable storage. As the transaction executes, pages are fetched \ninto main memory. The transaction updates some of those pages. When one of those dirty pages is ﬂ ushed, it is \nwritten to an unused location of stable storage. That is, the previous copy of the page is not overwritten. Then, \nthe copy of the page table in main memory is updated to point to the updated page in stable storage, and the \nupdated page table entry is marked as  “ updated. ” For example,  Figure 7.13 shows the result of ﬂ ushing a new \nversion of page A 2 , where A 2,old is the original copy of the page before transaction T i performed its update and \nA 2,new is the version of the page that includes the update. \n To commit a transaction, do the following: \n 1.  For each page P that the transaction updated, if P is dirty in cache, then ﬂ ush it as described earlier. \n 2.  Initialize a list called UpdatedFiles to include the name of every ﬁ le updated by the transaction. \nA1\nA2\nStable Storage\nB1\nB2\nB3\nMain Memory\nDatabase\nRoot\nA\nB\nAPt,i\nBPt,i\n1\n1\n2\n3\n...\n2\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\n FIGURE 7.12 \n Tree-structured Database for Shadow Paging. There are two ﬁ les, A and B. A Pt,m is the master copy of ﬁ le A’s page table \nthat points to the pages of ﬁ le A, such as A 1 and A 2 . \n",
      "page_number": 215
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 223-235)",
      "start_page": 223,
      "end_page": 235,
      "detection_method": "topic_boundary",
      "content": " 3.  For each ﬁ le F in UpdatedFiles, do the following: \n ■  Set a write lock on F’s root page. Let L be its location in stable storage. \n ■  Read F’s root page into cache. Call this the shadow copy of F’s page table. \n ■  For each page of F that is marked as updated in F’s cached page table, copy that page’s entry from \nF’s cached page table into its shadow page table. \n ■  Write the shadow copy of F’s page table to an unused location L \u0002 of stable storage. \n ■  Replace L by L \u0002 in the entry for F in UpdatedFiles. \n For example, if a transaction updated page A 2 of ﬁ le A, and B 1 of ﬁ le B, then at the end of this procedure, \nthe state of main memory and stable storage would be as shown in  Figure 7.14 . \n When this is done, we repeat essentially the same process for the root page of the database, as follows: \n 1.  Set a write lock on the root page of the database. \n 2.  Read the root page of the database into cache. Call this the shadow copy of the database’s page table. \n 3.  For each ﬁ le F in UpdatedFiles, copy the associated pointer (to F’s shadow page table in stable storage) \ninto F’s entry in the database’s shadow page table. \n 4.  Overwrite the database’s root page in stable storage with the shadow copy of the database’s root page. \nThis write operation of a single page causes all the transaction’s updated pages to become part of the \nmaster database. \n 5.  Release all the locks that the transaction obtained on data pages, ﬁ le page tables, and the database’s root \npage. Discard the UpdatedFiles list and the transaction’s cached copies of page tables. \n As a result of step 4 (shown in  Figure 7.15 ) the shadow page tables of  Figure 7.14 are now master page \ntables. The former master page tables are now garbage and hence are labeled  “ g ” in the ﬁ gure (A Pt,g and B Pt,g ). \nThe old versions of pages updated by the transaction are also garbage, that is, pages A 2,old and B 1,old . \n To abort a transaction, simply discard all its updated pages in stable storage and cache. Since the database \nroot page and the page tables it points to are unchanged, none of the pages updated by the aborted transaction \nare part of the master database. Therefore, there is nothing to undo. \nA1\nA2,old\nA2,new\nStable Storage\nB1\nB2\nB3\nMain Memory\nDatabase\nRoot\nAPt,i\nBPt,i\n1\n1\n2\n3\n...\n2\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\nA\nB\nC\n...\nupdated bit\n FIGURE 7.13 \n The Result of Flushing a Dirty Page. An updated version of page A 2 has been ﬂ ushed to stable storage into an unused \nlocation. The main memory page table is updated to point to it and is marked as updated. \n7.6 Shadow-Paging Algorithm  205\n\n\n206  CHAPTER 7 System Recovery\n One loose end in this story is how to manage available space in stable storage. One approach is to use a \nlist of available space, call it Avail, and treat it as another ﬁ le. For example, Avail could be a bit map, a binary \narray where each bit Avail[ j ] indicates whether page  j of stable storage is available. \n Suppose Avail ﬁ ts in one page, and a pointer to Avail is stored in the database’s root page. When a transac-\ntion ﬂ ushes a page P for the ﬁ rst time, it needs to allocate a page in stable storage to hold the shadow copy of \nP. To do this, it reads a copy of Avail into cache (if it is not already there), identiﬁ es a page  k that is available, \nclears the bit in Avail, marks Avail[ k ] as updated, and stores the shadow copy of P in location  k . When the \nA1\nA\nB\nA2,old\nA2,new\nB1,new\nStable Storage\nB1,old\nB2\nB3\nMain Memory\nDatabase\nRoot\nAPt,i\nBPt,i\n1\n1\n2\n3\n...\n2\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\nA\nB\nC\n...\nupdated bit\nUpdated\nfiles\nAPt,s\nBPt,s\n1\n1\n2\n3\n...\n2\n...\n FIGURE 7.14 \n System State after Partial Commit. Transaction T i updated pages A 2 and B 1 . In the ﬁ rst part of the commit procedure, \nshadow page tables A Pt,s and B Pt,s are constructed and ﬂ ushed, and UpdatedFiles points to them. \nA1\nA2,old\nA2,new\nB1,new\nStable Storage\nB1,old\nB2\nB3\nMain Memory\nDatabase\nRoot\nAPt,g\nBPt,g\n1\n1\n2\n3\n...\n2\n...\nA\nB\nC\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\n FIGURE 7.15 \n System State after Commit. The shadow page tables of  Figure 7.14 are now master page tables. The former master page \ntables are now garbage. The UpdatedFiles list and transaction’s cached page tables have been deallocated. \n\n\n transaction commits, the updated entries in the cached copy of Avail are copied into the shadow copy of its \npage table, which is written to stable storage. \n Another loose end is how to allow two or more transactions to execute concurrently. In this case, each trans-\naction has a private copy of the page table of each ﬁ le it updates. This allows each transaction to keep track of \nthe pages it updated. In addition, to ensure that each transaction reads the last committed value of each page it \naccesses, a global copy of the master page table is also maintained in cache. When a transaction reads a page \nfor the ﬁ rst time, it uses the pointer in the global cached master page table, not the one in its transaction-local \ncached page table. To see why, suppose there are two active transactions, T 1 and T 2 , and the following sequence \nof operations executes: \n 1.  T 1 updates page A 1 of ﬁ le A. \n 2.  T 2 updates page A 2 of ﬁ le A. \n 3.  T 2 commits. \n 4.  T 1 reads page A 2 of ﬁ le A. \n In step (4), T 1 should read the value of A 2 produced by T 2 . However, after T 2 commits, T 1 ’s page table still \nhas a pointer to the original value of A 2 , not the one written by T 2 . Therefore, when T 1 reads A 2 , it needs to use \nthe pointer to A 2 in the master page table. \n We began this section by commenting that shadow paging is not used often in commercial products because \nit does not scale up to high transaction rates. The reason is step one of the commit procedure, which requires \nthat all pages updated by the transaction be written to the stable database. This is a lot of random I/O, which is \nrelatively expensive. \n Due to the force-at-commit rule, we cannot avoid writing all the transaction’s updates to stable storage \nbefore the transaction commits. However, we can do it more efﬁ ciently than in shadow paging by appending \nthose updates to a log, which is a sequential ﬁ le. Sequential writes to disk can be done about 100 times faster \nthan random writes to disk, because they avoid disk head movement and rotational latency. Therefore, a system \ncan reach a much higher transaction rate by writing sequentially to a log than writing randomly to the stable \ndatabase. Eventually, all updated pages need to be written back to the stable database. However, this can be \ndone lazily, so the rate of random writes has a smaller effect on transaction throughput. The details of making \nthis work are the subject of the next two sections. \n 7.7  LOG-BASED DATABASE RECOVERY ALGORITHMS \n Logging is the most popular technique for implementing a recovery manager. As we described earlier, the log \ncontains a record for each write, commit, and abort operation. \n Implementing Commit \n To process a commit operation, the recovery manager adds a commit record to the end of the log and ﬂ ushes \nthe log. The log manager is designed so that it doesn’t acknowledge the ﬂ ush operation until all the log pages \nin memory, up to and including the one being ﬂ ushed, have been written to disk and the disk has acknowl-\nedged that the disk writes completed successfully. At this point, the transaction has been committed and the \nrecovery manager can acknowledge this fact to its caller. \n Since all the transaction’s update records precede the commit record in the log, by writing the commit \nrecord and then ﬂ ushing the log, the recovery manager ensures that all the transaction’s updates are in stable \n7.7 Log-Based Database Recovery Algorithms  207\n\n\n208  CHAPTER 7 System Recovery\n storage. That is, it ensures that the force-at-commit rule has been satisﬁ ed. It doesn’t matter whether any of the \nupdated pages have been ﬂ ushed to the stable database. The updates are in the log, and the log is in stable stor-\nage, which is enough to satisfy the rule. \n Flushing the log to commit a transaction is a potential bottleneck. If the disk that holds the log can do  K \nsequential disk-writes per second, then  K is the maximum number of transactions per second for the whole \nsystem. This is too small a number for high performance systems. This is especially annoying because the \nlog page normally isn’t full when the ﬂ ush is invoked, so the full bandwidth of the disk isn’t being used. This \nobservation creates an opportunity to improve performance. \n A popular way to relieve this bottleneck is an optimization called  group commit . After adding a commit \nrecord to the log, the recovery manager introduces a small artiﬁ cial delay before ﬂ ushing the log page, some-\nthing on the order of  1 / K ; that is, a few milliseconds. During that period, if there are other transactions running, \nthey can add records to the end of the log — update records, commit records, and abort records. If the system \nis busy, then the chances are that the log page will ﬁ ll up during this period, and when the recovery manager \nreaches the end of the delay period, it will end up ﬂ ushing a full page. Thus, each ﬂ ush operation on the log \ncan commit many transactions, and the recovery manager is getting the full value of the disk bandwidth. If the \nsystem is not busy, then it doesn’t matter that a partially ﬁ lled log page is ﬂ ushed to disk, since not all the disk \nbandwidth is needed to support the transaction load. \n The group commit optimization is an example of a general-purpose technique called  boxcarring . When \nthere is a high ﬁ xed overhead per write operation, it pays to pack a lot of data in each operation. Another \nplace this arises is communication systems that have a high ﬁ xed cost to send a message independent of the \nmessage’s size. The term boxcar is a metaphor for the boxcar in a train, which has a high ﬁ xed cost to transport \nindependent of how full it is. \n Implementing Abort \n To process an abort operation, the recovery manager has to undo the updates of any database pages that were \nupdated by the transaction. It does this by tracing through the transaction’s log records, starting from the last \none, and installing the before-image of each page that was updated by the transaction. \n Sequentially searching the log for the transaction’s update records is rather inefﬁ cient. To avoid this \nsequential scan, the recovery manager maintains a linked list of all the transaction’s update records in the log. \nThe list header is a  transaction descriptor , which is a data structure that describes each transaction that it \nknows about (see  Figure 7.16 ). The descriptor includes a pointer to the last log record that was written by each \ntransaction. Each update record in the log contains a pointer to the previous update record written by the same \ntransaction. So, starting from the transaction descriptor, all the transaction’s update records can be scanned. \n Maintaining the list is easy. When a transaction writes an update record to the log, it includes a backpointer \nto the previous log record for that transaction. Then it updates the transaction descriptor to point to the new \nupdate record, which is now the last one for the transaction. \n There is still the matter of the write-ahead log protocol to consider. The system needs to ensure that it doesn’t \nﬂ ush a dirty page from the cache to the stable database unless all the update records that describe updates to that \npage by uncommitted transactions have already been ﬂ ushed to the log. To do this, it needs a little help from the \ncache manager. \n We need to add a ﬁ eld to the cache descriptor of each cache slot. This ﬁ eld points to the log page that we \nneed to worry about to enforce the write-ahead log protocol. That is, it contains the address of the log page that \ncontains the update record describing the last update to this cache slot’s page (see  Figure 7.17 ). Let’s call this \nthe  dependent log page address (there’s no standard term for this). Every time a database page P is updated, \nthe dependent log page address of P’s cache slot is also updated to point to the page containing the update’s \n\n\n log record. Before the cache manager ﬂ ushes a cache slot, it must check that the dependent log page is not in \ncache and dirty. If it is, then the dependent log page must be ﬂ ushed ﬁ rst, to ensure the write-ahead log proto-\ncol is satisﬁ ed. \n Although the cache manager has to check the dependent log page address every time it ﬂ ushes a page from \ncache, this rarely generates an extra cache ﬂ ush of the log page. The reason is this: The log is a sequential ﬁ le. \nAs soon as a log page ﬁ lls up, the log manager tells the cache manager to ﬂ ush it. By the time the cache man-\nager decides to ﬂ ush a database page, the chances are that the database page has been sitting around in cache \nfor awhile since it was last updated. For example, the cache replacement algorithm notices that the page hasn’t \nbeen accessed recently and therefore decides to replace it. Since the page hasn’t been accessed recently, the \nchances are that the dependent log page has already been ﬂ ushed. \n As we will see in a moment, even hot pages must eventually be ﬂ ushed. Since a hot page is updated \nfrequently, it may have update records in the tail of the log. So ﬂ ushing a hot page may be delayed until its \ndependent log page has been ﬂ ushed. \nTransaction Descriptors\nStart of log\nEnd of log\nT7\nBackpointer\n\u0003\u0003Null\nrest of log\nrecord\nT7\nBackpointer\nrest of log\nrecord\nTransaction\nPointer to last\nlog record\nT7\nT7’s first log record \nT7’s second log record \nLog records from \nother transactions\nLog records from \nother transactions\n FIGURE 7.16 \n Data Structure Supporting Abort Processing. Starting from the transaction descriptor, all the transaction’s update records \ncan be scanned. \nPage\nDirty Bit\nCache Address\nPin Count\nDependent Log\nPage Address\nP4\n1\n104\n1\nP16\n0\n376\n1\nP5\n1\n400\n0\n1218\nnull\n1332\n FIGURE 7.17 \n Dependent Log Page Address. Before ﬂ ushing a page, the cache manager must check that the dependent log page is not \nin cache and dirty. \n7.7 Log-Based Database Recovery Algorithms  209\n\n\n210  CHAPTER 7 System Recovery\n Implementing Restart \n To implement restart, the recovery manager scans the log to ﬁ gure out which transactions need to be aborted \nand which committed updates need to be redone. As many algorithms of different complexities are in use, \nwe’ll start with a simple one and optimize it as we go. \n All restart algorithms depend on the recovery manager to perform checkpoint operations periodically, which \nsynchronize the state of the log with the state of the stable database. The simplest checkpoint algorithm does the \nfollowing: \n 1.  It stops accepting any new update, commit, and abort operations. It waits until all active update, com-\nmit, and abort operations have ﬁ nished. \n 2.  It makes a list of all active transactions along with each transaction’s pointer to its last log record. \n 3.  It ﬂ ushes all the dirty pages in cache. \n 4.  It writes a  checkpoint record to the log, which includes the list of active transactions and log pointers. \n 5.  It resumes accepting new update, commit, and abort operations again. \n At this point, the stable database state is exactly consistent with the state of the log. We’ll explain a more \nefﬁ cient checkpointing algorithm in a moment, but for now, let’s assume we’re using this one. \n The restart algorithm scans the log forward and fully processes each log record before proceeding to the \nnext. Its goal is ﬁ rst to redo all updates that executed after the last checkpoint and then to undo the ones that \ndid not commit. It starts at the last checkpoint record. There is no point in looking at log records before the last \ncheckpoint record, because their effects have been fully recorded in the stable database (see  Figure 7.18 ). The \nrestart algorithm maintains lists of committed and aborted transactions, which are initially empty; and a list of \nactive transactions, which is initialized from the last checkpoint record. When the restart algorithm encounters \na new log record, it does the following: \n ■  If the log record is an update record, then it writes the after-image of the update to the cache, and it adds the \ntransaction’s identiﬁ er to the active list if it isn’t already there. Notice that even if the update is already in \nthe stable database, there is no harm in writing the after-image, because the after-image contains an entire \npage image. (Remember our simplifying assumption that each update writes a whole page.) So at worst, it’s \njust redoing work needlessly. \n ■  If the log record is a commit record, it adds the transaction to its commit list and removes it from the \nactive list. \n ■  If the log record is an abort record, it undoes all of the transaction’s updates in the same way as it nor-\nmally processes an abort. Also, it adds the transaction to its abort list and removes it from the active list. \nLast checkpoint\nAll updates preceding the last\ncheckpoint are in the stable database.\nStart of Log\nEnd of Log\nCheckpoint\nPrefix of the log \n FIGURE 7.18 \n Basic Checkpointing. All dirty pages are ﬂ ushed before a checkpoint record is written. \n\n\n When it reaches the end of the log, it has redone all the updates of committed and active transactions, and \nwiped out the effects of any aborted transactions. At this point, the active list contains any transactions that \nstarted running before the failure but did not commit or abort before the failure. (Notice that since the active \nlist was initialized from the last checkpoint record, this includes transactions that were active at the last check-\npoint but did not subsequently commit or abort.) These transactions cannot continue running, since they lost \ntheir memory state during the system failure, so the restart algorithm aborts them too. Now the system is ready \nto process new transactions, since the combined state of the cache and stable database includes all committed \nupdates and no aborted ones. \n As long as the restart algorithm is running, users are unable to run transactions. Therefore, it’s important to \noptimize it to minimize its running time and therefore maximize the system’s availability. These optimizations \nare the subject of the next section. \n 7.8  OPTIMIZING RESTART IN LOG-BASED ALGORITHMS \n Fuzzy Checkpointing \n Checkpoints are an important way of speeding up the restart algorithm. The more frequently the system runs a \ncheckpoint, the less log that the restart algorithm will have to process, and therefore, the less time it will take \nto run restart. However, checkpointing isn’t free. The checkpointing algorithm described earlier does quite a lot \nof work and causes the system to stop processing new requests for awhile, until it has ﬁ nished ﬂ ushing all the \ndirty pages in cache. We need a cheaper way to checkpoint, so we can afford to checkpoint often and thereby \nspeed up the restart algorithm. \n The solution is called  fuzzy checkpointing . To do a checkpoint, the recovery manager does the following: \n 1.  It stops accepting any new update, commit, and abort operations. \n 2.  It scans the cache to make a list of all the dirty pages in the cache. \n 3.  It makes a list of all active transactions along with each transaction’s pointer to its last log record. \n 4.  It writes a checkpoint record to the log, which includes the list of active transactions and log pointers, \nand it allows normal operation to resume. \n 5.  It resumes accepting new update, commit, and abort operations. \n 6.  In parallel with running new update, commit and abort operations, it issues ﬂ ush operations to write to \nthe stable database all the dirty pages on the list it gathered in step (2). These are low priority operations \nthat the cache manager should do only when it has spare capacity. It may take awhile. \n The recovery manager is allowed to do another checkpoint operation only after step (6) completes; that is, \nonly after those dirty old pages have been ﬂ ushed. Thus, by the time the next checkpoint record is written, all \nthe updates that preceded the previous checkpoint record must be in the stable database. \n Let ’s revisit the restart algorithm with this fuzzy checkpointing algorithm in mind. Notice that it’s the \nsecond-to-last (i.e., penultimate) checkpoint record that has the property we’re looking for (see  Figure 7.19 ). \nAll the updates in the log that precede the penultimate checkpoint record must be in the stable database. The \ncheckpointing algorithm would not have written the last checkpoint record until it knew this was true. So, the \nrestart algorithm should start with the penultimate checkpoint record. By contrast, in the simple checkpointing \nalgorithm of the previous section, all updates before the last checkpoint record were in the stable database, so \nit started with the last checkpoint record, not the penultimate one. \n Notice that fuzzy checkpointing is a relatively fast activity. It needs to stop processing momentarily, to \nexamine the cache and write a checkpoint record. It then writes out dirty pages in parallel with normal operation. \n7.8 Optimizing Restart in Log-Based Algorithms  211\n\n\n212  CHAPTER 7 System Recovery\n If possible, these writes should run at low priority so they don’t block reads by active transactions. Assuming \nthere is enough disk bandwidth to process these reads and writes (which is needed in any case), these random \nwrites have very little impact on the performance of active transactions. Thus, checkpointing can be run fre-\nquently, to minimize the amount of work that restart has to do. \n The fuzzy checkpointing algorithm is so important to transaction performance and restart speed, it is worth \noptimizing it heavily. Commercial implementations use many optimizations of the algorithm described here. \n Operation Logging \n It is very inefﬁ cient to write the entire before-image and after-image of a page every time a transaction does \nan update, since most updates modify only a small portion of a page. Worse yet, it does not work correctly if \nthe database system does record-granularity locking. For example, suppose the system logs before-images and \nafter-images of pages, records  x and  y are on the same page P, and we have the following execution: \n E\nw [ ] w [ ] abort  commit\n1\n2\n\u0003\nx\ny\n2\n1\n \n When transaction T 1 aborts, we cannot install its before-image of P, since this would wipe out T 2 ’s update \nto  y . This is essentially the same problem we ran into at the beginning of Section 7.4, on Locking Assumptions, \nwhere we argued for holding write locks until after the transaction commits. \n A solution is to have each update record include only the before-image and after-image of the record that it \nactually updates on a page. This kills two birds with one stone. It greatly reduces the amount of logging, and \nit allows us to support record-level locking. It does have one unfortunate side-effect, though. The restart algo-\nrithm has to read the page from disk before applying the update. This wasn’t needed with page-level logging, \nbecause the log contained a complete copy of the page. Since logging is a much more frequent operation than \nrestart, this is a net win, but it does create another activity that needs to be optimized by the restart algorithm. \n We can reduce the amount of logging even further by recording only a  description of the change that was \nmade rather than the entire record. The description must have enough information that we can undo or redo the \nchange, but no more than that. That is, it doesn’t necessarily have to include the entire before-image and after-\nimage of the record. For example, if the update modiﬁ es only one ﬁ eld of a record, the update record needs \nto contain only the identity of the record (e.g., its key), the identity of the ﬁ eld (e.g., its byte range within \nthe record), and the before-image and after-image of the modiﬁ ed ﬁ eld, plus the name of the operation being \nperformed (e.g.,  “ update-ﬁ eld ” ), so the restart algorithm will know how to interpret the log record later. As \nanother example, the update record might describe the insertion of a record, in which case it needs to log only \nthe after-image of the record, since there is no before-image. \nLast checkpoint\nAll updates preceding the second-to-last\ncheckpoint are in the stable database.\nStart of Log\nEnd of Log\nCheckpoint\nCheckpoint\nPrefix of the log\nSecond-to-last checkpoint\n FIGURE 7.19 \n Fuzzy Checkpointing. After a checkpoint record is written, all dirty cache pages are ﬂ ushed. The ﬂ ushes must be \ncompleted before the next checkpoint record is written. \n\n\n By reducing the amount of logging this way, we have complicated the restart algorithm. It can no longer \nsimply start at the penultimate checkpoint record and redo update records, because the redo operations might \nnot be applicable to the stable database page in its current state. For example, it would be wrong to insert a \nrecord on a page if that record is already there, because that would put two copies of the record on the page. \nThe reason that the insert is not applicable is because it already executed and it is not idempotent. \n The restart algorithm has to know whether an update record is applicable to a page before redoing the \nupdate. To do this, each page is given a header that includes the log address of the last log record that was \napplied to the page (see  Figure 7.20 ). This is called the  log sequence number ( LSN ). After an update is per-\nformed on the page and the log record is written to the log, the LSN is written to the page header before releas-\ning the latch on the page. This allows the restart algorithm to tell whether a page includes an update before \nredoing it: If LSN(database-page)  \n  LSN(log-record), then the log-record’s update is already on the page and \nshould not be redone (see  Figure 7.21 ). \n This LSN idea is useful, but it complicates undo operations. When the restart algorithm undoes an update \nto abort a transaction, T 1 , there is no LSN that accurately describes the state of the page relative to the log. To \nvisualize the problem, consider the example in  Figure 7.22 . Transactions T 1 and T 2 update different records R 1 \nand R 2 , respectively, on the same page, P. T 2 writes to P (at LSN 222) after T 1 and then T 2 commits (at LSN \n223). When T 1 aborts (at LSN 224), what LSN should it write in P? It cannot use the LSN of the last update to \nP that preceded its update (219), since that would say that T 2 ’s update did not execute, which is wrong. It cannot \nuse the LSN of T 2 ’s update either (222), since that says T 1 ’s update was done but not undone. \nLog record describing\nlatest update to P\nEnd of Log\nLSN \u0003 4275\nUpdate(P)\nLSN \u0003 4275\nPage P\n FIGURE 7.20 \n Storing Log Sequence Numbers (LSNs) in Pages. When updating a page, include the LSN of the log record describing the \nupdate. \nLog record describing\nan update to P\nDuring redo recovery, apply\na log record to P if and only if\nLSN(P) \u000b x.\nEnd of Log\nLSN \u0003 x\nUpdate(P)\nLSN(P)\nPage P\n FIGURE 7.21 \n Interpreting LSNs during Recovery. Redo an update if and only if the page’s LSN indicates that the update isn’t already \nthere. \n7.8 Optimizing Restart in Log-Based Algorithms  213\n\n\n214  CHAPTER 7 System Recovery\n A good solution to this problem is to log undo operations. That is, when T 1 aborts, each time it undoes an \nupdate operation, say on page P, it writes a log record that describes that undo and it uses the LSN of that log \nrecord in P’s page header. This is called an  undo record or  compensation log record . Now the LSN of the \nundo record accurately describes the state of the page relative to the log. See  Figure 7.23 . \n Logging undo’s has an interesting side effect: Committed and aborted transactions look exactly the same \nin the log. They both have a sequence of update operations followed by an operation that says the transaction \nis done (committed or aborted). The restart algorithm processes both kinds of transactions in the same way, \nnamely, it redoes their updates. For aborted transactions, some of those redo operations are applied to undo \nrecords, but the restart algorithm doesn’t care. It redoes them just like ordinary update records. The only trans-\nactions that the restart algorithm actually has to abort by scanning the log backward are those that were active \nat the time of the failure. \n Suppose a transaction T is in the midst of aborting when the system fails. That is, T may have written undo \nrecords for some but not all of its update records. When the system recovers, the restart algorithm sees that \nLSN 224\naccurately\ndescribes the\nstate of P.\nLSN \u0003 219\nupdate0(R2)\nLSN \u0003 218\nupdate0(R1)\nPage P\nPage P\nPage P\nPage P\nPage P\nLSN \u0003 220\nCommit0\nLSN \u0003 221\nupdate1(R1)\nLSN \u0003 222\nupdate2(R2)\nLSN \u0003 223\nCommit2\nLSN \u0003 224\nundo(update1(R1))\nLSN \u0003 225\nAbort1\nLSN \u0003 222\nLSN \u0003 224\nNew R2\nOld R1\nNew R2\nNew R1\nLSN \u0003 221\nOld R2\nNew R1\nLSN \u0003 219\nOld R2\nOld R1\nLSN \u0003 218\nOld R1\n FIGURE 7.23 \n Using an Undo Log Record. If the undo operation is logged, its LSN can be installed on page P to record the fact that the \nupdate was undone. \nWhat LSN should\nbe written in P?\n(See text.)\nLSN \u0003 219\nupdate0(R2)\nLSN \u0003 218\nupdate0(R1)\nLSN \u0003 220\nCommit0\nLSN \u0003 221\nupdate1(R1)\nLSN \u0003 222\nupdate2(R2)\nLSN \u0003 223\nCommit2\nLSN \u0003 224\nAbort1\nLSN \u0003 218\nOld R1\nPage P\nLSN \u0003 219\nOld R1\nOld R2\nPage P\nPage P\nLSN \u0003 221\nNew R1\nOld R2\nNew R1\nNew R2\nPage P\nLSN \u0003 222\nLSN \u0003 ?\nOld R1\nNew R2\nPage P\n FIGURE 7.22 \n Installing an LSN during Undo. The state of page P is shown after logging each update. When aborting T 1 , there is no \nLSN to store in P that accurately describes P’s state. \n\n\n T was active at the time of the failure. Therefore, it undoes all of T’s updates, not just the update records for \nT but also the undo records. For example, in  Figure 7.24 transaction T 1 was aborting at the time the system \nfailed. Before the failure, it performed the undo for LSN 112 and recorded that fact in the undo record with \nLSN 113. However, it didn’t complete the abort before the system crashed. After recovery, the restart algo-\nrithm sees that T 1 was active when the system crashed, so it performs undo operations for LSN 113, 112, and \n111, in that order, thereby writing undo records with LSNs 114, 115, and 116, respectively. \n This activity of undoing undo records is redundant. It can be avoided by splicing undo records out of the \nchain of transaction backpointers, as shown in  Figure 7.25 . To do this, each undo record points to the next \nupdate record to be undone. For example, in the ﬁ gure the undo record with LSN 113 points to the update \nrecord at LSN 111. To ﬁ nish aborting T 1 during restart, the restart algorithm starts with the last log record for \nT 1 , which is at LSN 113, and follows its backpointer to the next update to be undone, in this case the update at \nLSN 111. \n Another useful optimization is to avoid unnecessary page fetches by recording ﬂ ush operations in the log. \nThat is, after the cache manager ﬂ ushes a page and before it allows any further updates to the page, it adds a \n ﬂ ush record to the log, which includes the address of the page that was ﬂ ushed. This record tells the restart \nalgorithm that all updates to that page that precede the ﬂ ush record are already on disk and therefore do not \nneed to be redone. In effect, it is a per-page checkpoint record. \nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nCrash!\nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nLSN \u0003 114\nundo(undo(update1(R2)))\nLSN \u0003 115\nundo(update1(R2))\nLSN \u0003 116\nundo(update1(R1))\nLSN \u0003 117\nabort1\nBefore system fails\nAfter Restart aborts T1\n FIGURE 7.24 \n Undoing Undo Records. During Restart, T 1 ’s undo record at LSN 113 needs to be undone, as does the update at LSN \n112, again. \nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nCrash!\nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nLSN \u0003 114\nundo(update1(R1))\nLSN \u0003 115\nabort1\nBefore system fails\nAfter Restart aborts T1\n FIGURE 7.25 \n Splicing Out Undo Records. Each undo record points to the next update record that needs to be undone. \n7.8 Optimizing Restart in Log-Based Algorithms  215\n\n\n216  CHAPTER 7 System Recovery\n A good way to use ﬂ ush records during recovery is to pre-analyze  the log before the redo phase. To enable \nthis process, in each checkpoint record, each page in the list of dirty pages is augmented with the oldest LSN \nthat must be redone to that page. This requires some additional bookkeeping by the cache manager, which needs \nto associate that oldest LSN with each cache slot, assign it when a clean page is ﬁ rst updated, and clear it when \nthe page is ﬂ ushed. This list of dirty pages with their oldest LSNs to redo is called a  dirty page table . \n The pre-analysis  phase of the restart algorithm does a preliminary log scan starting at the penultimate check-\npoint and moving forward toward the end of the log. The goal is to create a dirty-page table that, to the extent \npossible, describes the state of the cache at the time of failure. To initialize the undo phase of restart, it also \nbuilds a list of active transactions that includes the last LSN of each transaction. During this scan, there are four \ntypes of log records of interest: update, ﬂ ush, commit, and abort. \n ■  Update i (P): If page P is not in the dirty-page table, then add it and set its oldest LSN to be the LSN of \nthis update record. If transaction T i is not already on the transaction list, then add it. Set T i ’s last LSN to \nbe the LSN of this update record. \n ■  Flush(P): Delete P from the dirty-page table. \n ■  Commit i or Abort i : Delete T i from the transaction list. \n At the end of this pre-analysis  phase, for each page in the dirty-page table there is at least one update record \nin the log after the last ﬂ ush record for the page. Therefore, the page needs to be updated during the redo phase. \nSaying this in reverse: The preanalysis phase avoids redoing any update records for page P if the last update \nrecord for P precedes the last ﬂ ush record for P. Normally, one would expect many update records to satisfy this \nproperty, so this preanalysis phase avoids useless page fetches during redo and hence speeds up restart. \n The dirty-page table also gives guidance on when a page needs to be fetched. Every page in the dirty-page \ntable needs to be read during restart, since there is at least one update record in the log that follows the last \nﬂ ush record for the page. Since the dirty page table includes the LSN of the oldest update to each page, the \nrestart algorithm can prefetch pages in increasing order of oldest LSN, so the pages will arrive in cache in the \norder they will be needed by redo scan, which further improves its performance. \n The restart algorithm described in this section is called ARIES, and was developed by C. Mohan and his \ncolleagues at IBM. The most important insight is the value of replaying history from the penultimate check-\npoint, so that at the end of the redo scan the log and database are mutually consistent. This makes it easy to see \nthat the restart algorithm is correct and enables complex reasoning leading to optimizations like splicing out \nundo records and using a dirty page table to reduce page fetches during restart. ARIES includes other optimi-\nzations not described here, such as taking checkpoints during restart, handling nested transactions and nested \ntop-level actions, and updating index structures. (See the Bibliographic Notes for references.) \n Many other tricky problems arise in implementing recovery algorithms, such as redundantly storing point-\ners to the checkpoint record (so the restart algorithm can ﬁ nd it even if there is a media failure), ﬁ nding the end \nof the log (it’s too expensive to update a disk-resident pointer to end-of-log every time the log is updated), and \nhandling multipage update records (what if only one of the pages is written before a failure?). These details \nare of interest mainly to people building recovery algorithms, and are therefore beyond the scope of this book. \n(See the Bibliographic Notes for further readings.) \n User Techniques \n Although most optimizations of system recovery are only available to database system implementers, there are \na few things that a user can do to speed up restart and thereby improve availability, such as the following: \n ■  If the checkpointing frequency can be adjusted by the system administrator, then increasing it will reduce \nthe amount of work needed at restart. Running a benchmark with different checkpointing frequencies \n\n\n will help determine the expense of using frequent checkpoints to improve recovery time. Depending on \nthe overhead of the checkpointing algorithm used, this might require buying extra hardware, to ensure \nsatisfactory transaction performance while checkpointing is being done. \n ■  Partition the database across more disks. The restart algorithm is often I/O-bound. Although it reads the \nlog sequentially (which is fast), it accesses the database randomly. Spreading the database over more \ndisks increases the effective disk bandwidth and can reduce restart time. \n ■  Increase the system resources available to the restart program. After the operating system recovers from \na failure, it runs recovery scripts that include calling the database restart algorithm. It may not allocate \nmain memory resources optimally, if left to its own defaults. The restart algorithm beneﬁ ts from a huge \ncache, to reduce its I/O. If memory allocation can be controlled, tuning it can help reduce restart time. \n In general, one should benchmark the performance of restart to determine its sensitivity to a variety of con-\nditions and thereby be able to tune it to balance restart running time against checkpointing overhead. \n 7.9  MEDIA RECOVERY \n A media failure is the loss of a portion of stable storage. This usually is detected when an attempt is made to \nread a portion of the stable database, and the disk responds with an error condition. Failure rates of stable stor-\nage devices are sensitive to many factors, and they change over time with changing technologies. That said, a \ntypical failure rate for magnetic disks is 2% to 8% per year, meaning that a system with 100 disks experiences \ntwo to eight irreparable disk failures per year. This is a sufﬁ ciently frequent occurrence that engineered solutions \nare needed to shield the system from the effect of a media failure and to enable recovery when a media failure \ndoes occur. The latter is similar to recovering from a system failure: Load a usable state of the stable database \nfrom some backup device, such as tape or another disk, and then use the log to bring that state up to date. \n Mirrored Disks \n Media failures are a fairly serious problem, since as we will see, it can take a signiﬁ cant amount of time to \nrecover from one. To avoid it, most TP systems use  mirrored (or  shadowed )  disks . This means they use two \nphysical disks for each logical disk that they need, so each disk has an up-to-date backup that can substitute for \nit if it fails. The mirroring is usually done in hardware, though operating systems also offer the feature in soft-\nware. In either case, each write operation is sent to both physical disks, so the disks are always identical. Thus, \na read can be serviced from either disk. If one disk fails, the other disk is still there to continue running until a \nnew disk can be brought in to replace the failed one. This greatly reduces the chances of a media failure. \n After one disk of a mirrored pair fails, a new disk must be initialized while the good disk is still function-\ning. Like mirroring itself, this is usually done in the hardware controller. The algorithm that accomplishes it \nusually works as follows: The algorithm scans the good disk and copies tracks, one by one, to the new disk. \nIt has a temporary variable that identiﬁ es the track currently being copied. While it is copying that track, no \nupdates are allowed to the track. Updates to tracks that already have been copied are written to both disks, \nsince these tracks are already identical on both disks. Updates to tracks that have not yet been copied are writ-\nten only to the good disk, since writing them to the new disk would be useless. This copying algorithm can run \nin the background while the good disk is handling the normal processing load. \n Like restart, it is important that this mirror recovery procedure be as fast as possible. While it is going on, \nthe good disk is a single point of failure. If it dies, then a media failure has occurred, at which point the only \nhope is to load an old copy of the database and use a redo log to bring it up to date. \n7.9 Media Recovery  217\n",
      "page_number": 223
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 236-261)",
      "start_page": 236,
      "end_page": 261,
      "detection_method": "topic_boundary",
      "content": "218  CHAPTER 7 System Recovery\n Even a fast mirror recovery procedure is intrusive. Mirror recovery does sequential I/O, whereas normal \noperation performs random I/O. So normal operation slows down mirror recovery and vice versa. Thus, the \nsystem needs enough spare disk bandwidth to do mirror recovery while giving satisfactory performance to \nusers. \n The failure of a log disk is especially problematic, since it affects all update transactions. There are many \ncreative ways to minimize the effect of mirror recovery on writes to the log. For example, advanced disk-\nmanagement software lets you set a low priority for repairing that mirror, but then mirror recovery is running \nmuch longer, during which time a second log disk failure would be a disaster. Another approach is to populate \nonly a small fraction of the mirrored log disk, say 10%. This cuts the rebuild time and increases the random I/O \nrate during that rebuild. Or one can build a triple mirror; if a disk fails, wait until a slack time to rebuild the third \ndrive of the mirror. Experienced database administrators build a synthetic load with peak log-write throughput \nand kill their log mirror to see if the system will continue to support the required service level agreement. \n The choice of disk conﬁ guration will be greatly affected by the increasing availability of affordable solid \nstate disks (SSDs). These disks perform sequential and random I/O at about the same speed. Therefore, ran-\ndom I/O is less disruptive to mirror recovery than with magnetic disks. However, the cost per gigabyte of SSDs \nis considerably higher than for magnetic disks, and this gap is expected to continue going forward. It may \ntherefore be desirable to use conﬁ gurations that contain both SSDs and magnetic disks. It is too early to pre-\ndict how the cost and performance tradeoffs will play out. However, it seems likely that it will continue to be \nchallenging to design a storage conﬁ guration that meets a system’s service level agreement at the lowest cost. \n A related technology is  RAID — redundant arrays of inexpensive disks. In RAID, an array of identical disks \nis built to function like one high-bandwidth disk (see  Figure 7.26 ). A  stripe is the set of disk blocks consisting \nof the  i th block from each disk, where  i is an integer between one and the number of blocks on a disk. If the \ndisk block size is  s and there are  d disks in the RAID, then a stripe is, in effect, a logical block of size  d   \u0004   s . \nA RAID is high-bandwidth because the disks are read and written in parallel. That is, it reads or writes a stripe \nin about the same amount of time that one disk can read or write a single block. \nComputer sees the RAID as one\nhigh-bandwidth highly reliable disk.\nA RAID system\nComputer\nDatabase\n. . .\n. . .\nError correction bits\n FIGURE 7.26 \n A Redundant Array of Inexpensive Disks (RAID). An array of disks built to function as one high-bandwidth disk. Using \nextra disks for error correction bits increases reliability. \n\n\n Some RAID systems use extra disks in the array to store error correction bits, so they can tolerate the fail-\nure of one of the disks in the array without losing data. For example, an array of ﬁ ve disks could store data \non four disks and parity bits on the ﬁ fth disk. Thus, the RAID can tolerate the loss of one disk without losing \ndata. A write to any of disks 1 through 4 implies a write to disk 5. To avoid having disk 5 be a bottleneck, par-\nity blocks can be distributed across the disks. For example, stripes 1, 6, and 11 store their parity block on disk \n1; stripes 2, 7, and 12 store their parity block on disk 2; and so on. \n The different RAID conﬁ gurations are identiﬁ ed by numbers. Striped disks without parity are called RAID \n0. Mirroring is called RAID 1 and can use more than two disk replicas. RAID 2 through 6 use parity in different \nconﬁ gurations. RAID 10 is a RAID 0 conﬁ guration where each disk is actually a mirrored pair (i.e., RAID 1). \nThis is called nested RAID, since it nests RAID 1 disks into a RAID 0 conﬁ guration. \n Even if it is judged to be uneconomical to use mirrored disks or a RAID for the stable database, one should \nat least use them for the log. Losing a portion of the log could be a disaster.  Disaster is a technical term for an \nunrecoverable failure. There are two ways that a media failure of the log can be unrecoverable: \n ■  After writing an uncommitted update to the stable database, the log may be the only place that has the \nbefore-image of that update, which is needed if the transaction aborts. If the tail of the log gets corrupted, \nit may be impossible to abort the transaction, ever. \n ■  After committing a transaction, some of its after-images may be only in the log and not yet in the stable \ndatabase. If the tail of the log gets corrupted and the system fails (losing the cache), then the committed \nafter-image is lost forever. \n In both cases, manual intervention and guesswork may be needed to recover from the failure. Therefore, \nit’s a good idea to put the log on a separate device and mirror it. \n Even with mirrored disks, it is possible that both disks fail before the ﬁ rst failed disk is replaced. When \nconﬁ guring a system, there are some things one can do to reduce this possibility. First, one can try to minimize \nthe amount of shared hardware between two mirrored disks. For example, if the disks share a single control-\nler, and that controller starts scribbling garbage, both disks will be destroyed. Second, one can keep the disks \nin separate rooms or buildings, so that physical damage, such as a ﬁ re, does not destroy both disks. How far to \ngo down these design paths depends on the cost of downtime if data becomes unavailable for awhile due to a \nmedia failure. \n The general principle here is that protection against media failure requires redundancy. We need two copies \nof the log to ensure restart can run correctly if one log disk fails. We use mirrored disks or a RAID system that \nhas built-in error correction to avoid requiring media recovery when a database disk fails. If the stable database \nis not mirrored and a disk fails, or if both mirrors fail, then yet another copy of the stable database — an archive \ncopy — is needed in order to run media recovery. \n Archiving \n Media recovery requires the system to have an archive (i.e., backup) copy of the stable database that it can use \nas a starting point. It also needs a copy of the log that includes all committed updates that executed after the \narchive copy was created. The media recovery algorithm can therefore load the latest archive copy and redo \nthe corresponding log. \n To create an archive copy, one can simply copy the entire  stable database. If this is done when the system \nis not processing transactions, it will produce a snapshot of the database that is consistent with the log. If \narchiving is done on-line, that is, if the system is processing transactions while the archive copy is being made, \nthen different parts of the archive copy will include updates from different transactions. That is, pages copied \n7.9 Media Recovery  219\n\n\n220  CHAPTER 7 System Recovery\n later will have updates from more transactions than those copied earlier. It seems like this would be hard to \nsort out when it is time to recover from a media failure. However, essentially the same old restart algorithm \nthat we described for system failures will work here too. \n This approach requires that the system keep an archive copy of the log. Therefore, even after a checkpoint \nhas made early parts of the log unnecessary for recovery from system failures, those early parts must still be \nsaved for media recovery. Usually, they are copied to a  media recovery log on a separate long-term storage \ndevice. \n To avoid disk head contention between on-line transactions writing to the end of the log and the media \nrecovery log archiver reading from the beginning of the log, it is worthwhile to have two pairs of mirrored log \ndisks. One pair contains the tail of the log for active transactions. The other contains the early part of the log for \narchiving to the media recovery log. By the time the active transaction log is out of space, the media recovery \nlog archiver should have ﬁ nished reading the other pair of log disks. So the latter can immediately be reused for \nthe active transaction log and the archiver can turn its attention to the other pair of log disks. \n Suppose the recovery manager uses the optimization in  Operation Logging , in Section 7.8, where it stores \non each page the log address of the last update applied to it (i.e., the LSN). This information will be in the \narchive copy too. So the media recovery manager knows the exact state of the page to recover, in the same way \nas the restart algorithm. \n As for system failures, recovery time for media failures affects availability, so checkpointing frequently is \ndesirable for reducing recovery time. Making an archive copy of the entire stable database is slow. One can \nspeed up archiving by only copying pages that have changed since the last time the archiving algorithm ran. \nA simple way to do this is to keep an  update-bit in each page header that indicates whether the page has been \nupdated since it was last archived. This bit is set every time the page is updated. The archive algorithm clears the \nbit each time it copies the page to the archive. The archive algorithm still needs to read the entire stable database, \nto look at all the update bits, but it only needs to copy a fraction of those pages to the archive. We can speed \nthings up even further by keeping the update bits in a separate location, so the archiving algorithm needs to read \nonly pages that were recently updated, not all pages. \n To recover from the media failure of a disk, one needs to load the most recent archive copy of the disk \nand process the log that includes all updates that were done since the archive copy was made. This means the \narchive algorithm should write a checkpoint record to the log, indicating when it started running, and another \ncheckpoint record when it is done. When it is done, all database updates that preceded the ﬁ rst checkpoint \nrecord are deﬁ nitely in the archive (and some later updates too, but we can’t tell which ones by looking at the \nlog). So the latter checkpoint record indicates that only updates occurring after the former checkpoint record \nneed to be considered during media recovery. \n A useful optimization to reduce the amount of log needed for media recovery is to avoid keeping undo \ninformation in the media recovery log, such as before-images. If the archiving procedure archives pages only \nwhen their entire contents is committed, then undo information will not be needed at archive recovery time. \nTherefore, the archiving procedure should write-lock each page before it copies it to the archive, thereby ensur-\ning there are no active transactions writing to the page at the time it does the copy operation. A postprocessing \nstep on the log can strip out all undo information before setting it aside for future use during media recovery. \n It is common that a media failure only corrupts a small portion of a disk, such as a few tracks. Depending on \nhow the media recovery algorithm is organized, it may or may not be necessary to recover the entire disk in this \ncase. A distinguishing feature of database systems is whether they can recover from such failures efﬁ ciently. \nFor example, instead of reconstructing the entire disk, a database system could offer the ability to recover just \nthe damaged portions of the disk and write them to an empty area of the same disk. Moreover, it could have \nutilities to postprocess logs, to partition them based on regions of the disk, so that the media recovery algorithm \nonly needs to process a log containing records that are relevant to the damaged portion of the disk. \n\n\n Not all media failures are permanent failures, where the damaged page is physically destroyed. Some failures \nare transient, where the content of the page is wrong but it can be repaired simply by rewriting it. For example, \na disk may not have written a page atomically (i.e., written out only part of its contents), because the disk arm \nstrayed a bit during the write. Some disks can detect this error immediately and retry the write. However, if the \ncorrupt page is discovered much later when the page is read, then it needs to be recovered. In this case, it is \nworthwhile to reconstruct the page in place, rather than replacing the disk or relocating the damaged page. \n 7.10  SUMMARY \n TP systems often are expected to be available 24 hours per day, 7 days per week, to support around-the-clock \nbusiness operations. Two factors affect availability: the mean time between failures (MTBF) and the mean time \nto repair (MTTR). Improving availability requires increasing MTBF, decreasing MTTR, or both. \n Computer failures occur because of: \n ■  Environmental factors (power, air conditioning, communication lines, natural disasters , etc.) \n ■  System management (operations staff errors, software upgrades, preventive maintenance, etc.) \n ■  Hardware (failure of any component, such as memory, disk, network controller, etc.) \n ■  Software (crash of operating system, database system, transactional middleware, or application program) \n If the operating system fails, then just reboot it. For other types of software failure, the transactional mid-\ndleware or database system must detect the failure of a process and recreate it. The recreated process must then \nrun a recovery procedure to reconstruct its state. \n When a client recovers it needs to reconnect to its servers. It then should determine which calls were out-\nstanding when it failed, and what it needs to do to complete those calls. This is exactly the problem addressed \nin Chapter 4,  “ Queued Transaction Processing. ” \n When a server recovers, it needs to reconstruct a state that is consistent with the last calls that it processed \nbefore the failure. This requires taking checkpoints periodically during normal operation, so it can reload the \ncheckpointed state at recovery time. Executing from that recovered state, the server must avoid redoing any \nnon-redoable  actions (such as printing a check). \n Transactions simplify recovery by allowing a server to focus on restoring its state to contain only the results \nof committed transactions, rather than recovering to a state that is consistent with the last operations it ran. \nTransactional servers often are split into two types, resource managers that maintain state and stateless appli-\ncation servers. The latter store all their state in the resource managers and therefore can recover simply by \nreinitializing. \n A database system must be able to recover from several kinds of failure. It recovers from a transaction failure \n(where a transaction aborts) by undoing all the transaction’s updates. It recovers from a system failure (where \nmain memory is lost) or a media failure (where some stable storage is lost) by restoring the database to contain \nexactly the set of committed updates. \n All of today’s recovery mechanisms require every transaction to hold its write locks until it commits, to \navoid cascading aborts and to ensure that undo can be implemented simply by restoring an update’s before-\nimage. For satisfactory performance, locks usually are held at record granularity, though recovery can be sim-\npliﬁ ed considerably if page-granularity locking is used. \n The recovery manager uses a cache manager to fetch pages from disk and later ﬂ ush them. In addition to \nprocessing commit and abort operations, it implements a recovery algorithm to recover from system failures. \nThe most popular recovery algorithms use a log, which contains a history of all updates, commits, and aborts. \n7.10 Summary  221\n\n\n222  CHAPTER 7 System Recovery\n The recovery manager must carefully control when updates are ﬂ ushed to ensure the database is always \nrecoverable. In particular, it must enforce two rules: \n ■  The Write-Ahead Log Protocol: Do not ﬂ ush an uncommitted update to the stable database until the log \nrecord containing its before-image has been ﬂ ushed to the log. \n ■  The Force-at-Commit Rule: Do not commit a transaction until the after-images of all of its updated pages \nare in stable storage (in the log or the stable database). \n The recovery manager tells the cache manager about dependencies between dirty database pages and log \npages so the cache manager can enforce the write-ahead log protocol. To implement commit, the recovery \nmanager appends a commit record to the log and ﬂ ushes it. Since all updates are logged, this implements the \nforce-at-commit rule. To implement abort, the recovery manager follows a linked list of the transaction’s log \nrecords, undoing each update along the way. \n To minimize the amount of log to process at recovery time, the recovery manager periodically does a \ncheckpoint, which synchronizes the state of the log with the stable database. To recover from a system failure, \nit scans the log from the last or penultimate checkpoint record (depending on the checkpointing algorithm) and \nredoes updates as required. It can tell whether a log record should be redone by comparing the log record’s \naddress (LSN) with the LSN stored in the corresponding database page, since each database page’s LSN is \nupdated whenever the page itself is updated. Using LSNs in this way allows the recovery manager to log oper-\nation descriptions, rather than before- and after-images, since it redoes an operation only if the page is in the \nsame state as when the operation originally ran. \n Recovery time should be short, to maximize availability. Therefore, there are numerous optimizations to \nreduce checkpoint overhead so it can be done more frequently, and thereby reduce recovery time. For the same \nreason, there are also many optimizations to speed up the recovery algorithm itself. \n To cope with media failures, some redundant storage is required. Mirrored disks or RAID systems commonly \nare used for the database and for the log. Still, to cope with media failures of the stable database, it’s important \nto periodically make an archive copy of the database plus an archive copy of the log that includes all committed \nupdates that executed after creating the archive database copy. The recovery algorithm for media failures loads \nthe archive copy and redoes committed updates in the log, just like the recovery algorithm for system failures. \nAs for system failures, checkpointing should be frequent and the recovery algorithm should be optimized to run \nfast, to maximize availability. \n \n\n\n 8.1  INTRODUCTION \n The previous chapter showed how to use logging to ensure that a transaction is atomic with respect to failures, \nprovided that the transaction updates data only in one resource manager. If two or more resource managers \nprocess updates for a transaction, then another technique is needed to ensure that the transaction commits at all \nresource managers or at none of them. This is called the  two-phase commit protocol. Chapter 1 brieﬂ y intro-\nduced the protocol. This chapter develops it in more detail. \n The main goal of the protocol is to ensure that a transaction either commits at all the resource managers \nthat it accessed or aborts at all of them. The undesirable outcome that the protocol avoids is that the transaction \ncommits at one resource manager and aborts at another. \n Two -phase commit arises whenever the resource managers that processed a transaction’s updates can com-\nmit the transaction independently. This surely arises if the resource managers execute on different machines. It \nalso arises when the resource managers execute on the same machine but use separate logs. However, when the \nresource managers use a shared log, they can commit a transaction simultaneously by appending a single com-\nmit record to the log. In that case, the resource managers do not independently commit the transaction, so two-\nphase commit is not required. \n At ﬁ rst, it may seem that committing at multiple resource managers is no more difﬁ cult than committing at \none resource manager: Just send a message telling each resource manager to commit or abort. In the absence of \nfailures, this would work. But failures can make it much harder to commit or abort everywhere. For example, \nwhat should be done while committing transaction T in each of the following situations? \n ■  A resource manager that processed some of T’s updates fails after T has committed at another resource \nmanager. \n ■  A resource manager that failed while T was committing has now recovered and wants to ﬁ nd out whether \nT committed or recovered. How does it know who to ask? What should it do if none of the other resource \nmanagers that processed T’s operations are up and running? \n ■  What if a resource manager R is not responding to messages? Should other resource managers assume \nR is down, and therefore its active transactions will abort; or that communications is down and R is still \noperational? \n A complete solution must deal with these and all other failure situations that can arise. \n Two-Phase Commit \n 8 \nCHAPTER\n\n\n224  CHAPTER 8 Two-Phase Commit\n In this chapter, we return to using the terms  “ resource manager ” and  “ resource, ” instead of the terms  “ data \nmanager ” and  “ data item ” that we used in Chapters 6 and 7. When discussing two-phase commit, it is common \npractice to talk about resource managers, rather than data managers or database systems. The reason is that \nwhen a transaction commits, all the transactional resources it accesses need to get involved in the commitment \nactivity, not just databases. Non-database transactional resources include recoverable scratchpad areas, queues, \nand other messaging systems. \n As in resource manager recovery, application programmers usually do not get involved in two-phase commit. \nMost database systems and transactional middleware support it and make it transparent to the application. However, \nif an application needs to directly manage a transactional resource as well as use other resource managers, then the \napplication needs to participate in the two-phase commit protocol. The application programmer needs to know \nwhat to do in this case. Some error scenarios require operator intervention. The application needs to expose these \nsituations to the operator in a comprehensible way so the operator can determine the best course of action. \n System architects who conﬁ gure a TP system have a more pressing need to consider the effects of two-\nphase commit. When conﬁ guring a system consisting of different resource managers, such as different database \nsystems supplied by different vendors, one needs to ensure that the two-phase commit implementations of the \nresource managers interoperate properly. This requires some understanding of how two-phase commit protocols \nare implemented. Moreover, such multidatabase conﬁ gurations lead to additional communication overhead for \ntwo-phase commit, which can dramatically affect transaction performance. In some cases, that overhead makes \nit advisable to avoid a multidatabase conﬁ guration. For all these reasons, a solid understanding of two-phase \ncommit is needed to build robust TP applications. \n 8.2  THE TWO-PHASE COMMIT PROTOCOL \n Assumptions \n The protocol makes the following assumptions about each transaction T: \n 1.  Transaction T accesses resources from time to time. If it experiences a serious error at any time, such as \na deadlock or illegal operation, it issues an abort operation. If it terminates normally without any errors, \nit issues a commit. In response to the commit, the system runs the two-phase commit protocol. \n 2.  Each resource manager can commit or abort its part of T; that is, permanently install or undo T’s opera-\ntions that involve this resource manager. This essentially says that each resource manager has a transac-\ntional recovery system, as described in the previous chapter. \n 3.  One and only one program issues the commit operation on T. That is, one program decides when to start \ncommitting T by running the two-phase commit protocol, and no other program will later start running \nthe protocol on T independently. In some cases, a second attempt to run two-phase commit while the ﬁ rst \nattempt is still running will cause the protocol to break; that is, cause it to commit at one resource man-\nager and abort at another. The protocol can be programmed to cope with concurrent attempts to run two-\nphase commit, but we will not investigate this type of error here. We will just assume it does not happen. \n 4.  Transaction T has terminated executing at all resource managers before issuing the commit operation. If \nthe transaction does all of its communication using RPC, then this is easy to arrange. T can ensure it has \nﬁ nished processing at all resource managers by waiting for all of its RPCs to return, provided that each \nresource manager ﬁ nishes all the work it was asked to do before returning from the call. This assump-\ntion avoids our having to deal with the complexity of transaction termination here. \n\n\n In general, termination can be hard to arrange if T uses communications paradigms other than RPC. \nFor example, if the transaction uses peer-to-peer messaging, where each communicating party can send \nmessages to and receive messages from other parties in an application-deﬁ ned order, then the transaction \nmay need an application-speciﬁ c protocol to ensure it has terminated. A general-purpose peer-to-peer \nprotocol that ensures termination is IBM’s LU6.2, which was described in Section 3.4 of the ﬁ rst edition \nof this book. \n 5.  Every system and resource manager fails by stopping. That is, the protocol does not make mistakes when \na system or a resource manager malfunctions. It either does exactly what the protocol says it should do, \nor it stops running. It is possible for a failure to cause the protocol to do something that is inconsistent \nwith its speciﬁ cation, such as sending bogus messages. These are called Byzantine failures. There are \nways to cope with limited numbers of  Byzantine failures , but they are quite expensive in terms of the \nnumber of messages exchanged and are not used in current TP systems, so they are not discussed here. \n In the remainder of this section, we will use the term  coordinator as the name of the component that runs \nthe two-phase commit protocol on behalf of one transaction. That is, the coordinator is the component that \nreceives the commit or abort request from the application program and drives the execution of the protocol. \n In our description of the protocol, the resource managers that did work on behalf of the transaction (by \nreading and updating resources) are called  participants . The goal is to ensure that the coordinator and all par-\nticipants commit the transaction or the coordinator and all participants abort the transaction. \n “ Coordinator ” and  “ participant ” are abstract concepts that don’t map exactly to real components of a TP sys-\ntem. In Section 8.5, we will look at how the system is organized into components, including the transaction man-\nager component that actually runs two-phase commit. We will explore how the transaction manager organizes its \nwork, communicates with resource and transaction managers, and interacts with the communication system itself. \n Being Prepared \n A participant P is said to be  prepared if all of transaction T’s after-images at P are in stable storage. It is essen-\ntial that T does not commit at  any participant until  all participants are prepared. The reason is the force-at-com-\nmit rule, which says not to commit a transaction until the after-images of all of its updates are in stable storage. \nSuppose the rule is violated by having one participant, P 1 , commit T before another participant, P 2 , is prepared. \nIf P 2  subsequently fails, before it is prepared and after P 1  commits, then T will not be atomic. T already has com-\nmitted at P 1 , and it cannot commit at P 2  because P 2  may have lost some of T’s updates when it failed. On the \nother hand, if P 2  is prepared  before P 1  commits, then it is still possible for T to be atomic after P 2  fails. When P 2  \nrecovers, it still has T’s updates in stable storage (because it was prepared before it failed). After it recovers and \nﬁ nds out that T committed, it too can ﬁ nish committing T. \n Ensuring that all participants are prepared before any of them commits is the essence of two-phase com-\nmit. Phase one is when all participants become prepared. Phase two is when they commit. No participant enters \nphase two until all participants have completed phase one; that is, until all participants are prepared. \n The Protocol \n The protocol proceeds as follows (see  Figure 8.1 ): \n Begin Phase 1: \n 1.  To commit the transaction, the coordinator starts by sending a  REQUEST-TO-PREPARE message to each \nparticipant. \n8.2 The Two-Phase Commit Protocol  225\n\n\n226  CHAPTER 8 Two-Phase Commit\n 2.  The coordinator waits for all participants to  “ vote ” on the request. \n 3.  In response to receiving a  REQUEST-TO-PREPARE message, each participant votes by sending a mes-\nsage back to the coordinator, as follows: \n ■  It votes  PREPARED if it is prepared to commit. \n ■  It may vote  NO for any reason, usually because it cannot prepare the transaction due to a local failure. \n ■  It may delay voting indeﬁ nitely, for example, because its system is overburdened with other work or \nbecause it failed. \n Begin Phase 2: \n 1.  If the coordinator receives  PREPARED messages from  all participants, it decides to commit. The trans-\naction is now ofﬁ cially committed. Otherwise, it either received a  NO message or gave up waiting for \nsome participant, so it decides to abort. \n 2.  The coordinator sends its decision to all participants (i.e.,  COMMIT or  ABORT ). \n 3.  Participants acknowledge receipt of the commit or abort by replying  DONE . \n 4.  After receiving  DONE from all participants, the coordinator can  forget the transaction, meaning that it \ncan deallocate any memory it was using to keep track of information about the transaction. \n Performance \n The performance of two-phase commit is measured by counting the number of messages required to commit the \ntransaction. There are four rounds of messages to or from all participants, as can easily be seen in  Figure 8.1 : \n REQUEST-TO-PREPARE, PREPARED ; or  NO ,  COMMIT or  ABORT , and  DONE . \n The transaction actually is committed before all these messages are sent. After the second round, when the \ncoordinator decides to commit, the transaction actually is committed and the coordinator can tell the user that this \nis true. Of course, there is still another round of messages, the  COMMIT messages, before the participants ﬁ nd out \nthat the transaction is committed, at which point they can release their locks. The ﬁ nal round of messages, the \na.  The transaction commits\nHorizontal arrows indicate messages between the coordinator and participant.\nTime is moving down the page, so the first message in both cases is REQUEST-TO-PREPARE.\nb.  The transaction aborts\nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nMessages\nCoordinator\nParticipant\nREQUEST-TO-PREPARE\nNO\nABORT\nDONE\nMessages\nCoordinator\nParticipant\nTime\n FIGURE 8.1 \n The Two-Phase Commit Protocol. The messages that are shown are exchanged between the coordinator and each \nparticipant. \n\n\n DONE messages, is not performance sensitive, since this just tells the coordinator that it can clean up whatever \ncontrol structures it has used for the transaction. In fact, a participant can avoid an extra message by holding onto \nthe  DONE message until it has another message for the coordinator on which it can piggyback the  DONE message, \nsuch as a  PREPARED message for a later transaction. \n Blocking \n Before a participant votes, it can abort unilaterally, any time it wants. Once it sends  PREPARED , and until it \nreceives a message containing the coordinator’s decision, it is unable to commit or abort. If it did, it might \nmake a decision opposite to the coordinator’s, producing an inconsistent result. During this period, it is said to \nbe  uncertain 1 (see  Figure 8.2 ). \n The coordinator is never uncertain, because it gets to decide. Until it decides, it can abort whenever it wants. \nAnd after it decides, it is obviously not uncertain. So, only participants are uncertain. \n Uncertainty is a bad property of two-phase commit. If the coordinator fails while a participant is uncertain, \nthe participant is  blocked ; it can neither commit nor abort. The coordinator could be down for a long time. This \nis a bad situation for the participant, since it is holding locks on data that the transaction accessed. Since the \nwhole point of two-phase commit is to cope with failures (otherwise, one-phase commit would work ﬁ ne), it is \nbad news that when a failure does happen, a participant could become blocked. \n This leads one to wonder whether two-phase commit is a good protocol after all. Are there other protocols \none could adopt that avoid blocking? Unfortunately, the answer is no, as stated in the following theorem. \n Theorem 1: For every possible commit protocol (not just two-phase commit), a communications failure can \ncause a participant to become blocked. \n There is a related problem, essentially the recovery-time version of blocking. If a participant fails while it is \nuncertain, and subsequently recovers, it is possible that when it recovers the coordinator is down. In this case, \nit is still uncertain and therefore cannot completely recover, since it doesn’t know whether to commit or abort \nthe transaction. That is, the participant cannot  independently recover . Like blocking, this too is unavoidable. \n 1 This is called  “ in doubt ” in Gray and Reuter (1992). \nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nCoordinator\nParticipant\nUncertainty\nPeriod\n FIGURE 8.2 \n The Uncertainty Period in Two-Phase Commit. From the time a participant replies PREPARED until it receives the \ndecision from the coordinator, it is uncertain. \n8.2 The Two-Phase Commit Protocol  227\n\n\n228  CHAPTER 8 Two-Phase Commit\n Theorem 2: No commit protocol can guarantee independent recovery of failed participants. \n We may be unhappy about the blocking problem in two-phase commit, but there is no avoiding it. Any \nother protocol that atomically commits a transaction that accesses multiple resource managers must have the \nsame problem. \n Nevertheless , there have been many attempts at circumventing these theorems. One technique for handling \nblocking situations is to make a  heuristic decision , which is simply to guess the outcome. The guess may be \nwrong, but at least the transaction can terminate and release locks. Another is to attempt to ﬁ nd out the deci-\nsion from other participants, called the cooperative termination protocol, which is described in Section 8.4. Yet \nanother technique is three-phase commit, which avoids blocking if the system has no communications failures. \nThis protocol is much more complex than two-phase commit and still leads to blocking if a communication fail-\nure occurs (for details, see Bernstein, Hadzilacos, and Goodman, 1987; Section 7.5). Currently, three-phase com-\nmit is not widely used in practice. \n 8.3  FAILURE HANDLING \n The purpose of two-phase commit is to cope with the various failures that can arise. To complete the descrip-\ntion of the protocol we need to explain what happens in every possible failure situation. \n We assume that all failures of messages and processes are detected by timeout. That is, a caller sets a timer \nwhen it sends a message to another process and assumes that a failure has occurred if the timer expires before \nit receives the reply it was expecting. The length of the timer is called the  timeout period . The timeout period \nshould be long enough to cover cases where the callee or the communications network is a little slow due to \na backlog of work. But it should not be too long, since that will mean that failures are not detected promptly, \nwhich would be annoying to users. Notice that if a process detects a timeout, it cannot tell whether the process \nfailed or the communications failed. All it knows is that something has gone wrong. \n It is very realistic to assume that all failures are detected by timeout. In most distributed systems, messages \nare exchanged asynchronously (that is, whenever processes have something to say, rather than synchronously \nat ﬁ xed time intervals). So the only information that a process has about other processes is what it learns from \nmessages it receives from them. If a failure occurs, the only hint it gets about the failure is that a message it \nwas expecting has not arrived. \n Sometimes the underlying communication system provides failure detection. A process can ask the com-\nmunication system to establish a session. Later, if one of the processes or systems stops responding to mes-\nsages, the communication system tells the other process that the session has failed. In this case, the failure was \nstill detected by timeout, but by the underlying communication system rather than by the process itself. \n The coordinator or a participant can fail in two ways. Either it stops running (assumption 5 in Section 8.2) \nor it times out waiting for a message it was expecting. The latter may happen either because the sender fails \nor because the communication system isn’t functioning properly. The symptom is the same in both cases — the \nreceiver does not get the message. \n To analyze the failure cases, let’s walk through the protocol from both the coordinator’s and participant’s \nviewpoint and explain what happens in each case where a message was expected but does not arrive. Then we \nwill talk about what the coordinator and participant do if they fail and subsequently recover. \n Coordinator ’s view: \n 1.  Send  REQUEST-TO-PREPARE messages to all the participants. \n Error handling: None, since it is not expecting any messages in this step. \n\n\n 2.  Receive  PREPARED messages from all participants, or receive a  NO message from at least one participant. \n Error handling: It is waiting for  PREPARED or  NO messages. If it does not receive all of them within its \ntimeout period, it can simply abort the transaction, just as if one of the participants had voted  NO . \n 3.  Depending on the messages received, decide to commit or abort. \n Error handling: None, since it is not expecting any messages in this step. \n 4.  Send  COMMIT or  ABORT messages to all participants (depending on the decision). \n Error handling: None, since it is not expecting any messages in this step. \n 5.  Receive  DONE messages from all participants. \n Error handling: It is waiting for  DONE messages. Nothing important depends on when these messages \narrive, so it waits indeﬁ nitely for them. If its timeout period expires, it can send reminder messages to \nthe participants to resolicit the  DONE messages. \n 6.  Forget the transaction. \n Error handling: None, since it is not expecting any messages in this step. \n Participant ’s view: \n 1.  Receive a  REQUEST-TO-PREPARE message from the coordinator. \n Error handling: After ﬁ nishing its work for the transaction, if it does not receive a  REQUEST-TO-\nPREPARE within its timeout period, it can unilaterally abort the transaction. If it later receives a \n REQUEST-TO-PREPARE from the coordinator, it votes  NO (or ignores the message, since a nonvote \nhas the same effect as  NO ). \n 2.  Prepare the transaction. \n Error handling: None, since it is not expecting any messages in this step. \n 3.  If (2) succeeds, then send a  PREPARED message to the coordinator, otherwise send  NO to the coordinator. \n Error handling: None, since it is not expecting any messages in this step. \n 4.  Receive a decision message,  COMMIT or  ABORT . \n Error handling: If it does not receive a decision message within its timeout period, it is blocked. It is in \nits uncertainty period, so there is nothing it can do without risking a mistake. \n 5.  Send a  DONE message. \n Error handling: None, since it is not expecting any messages in this step. \n If the coordinator or participant fails and subsequently recovers, then at recovery time it can only use infor-\nmation in stable storage to guide its recovery. This is the same assumption we used for recovering from system \nfailures in the previous chapter. So to ensure that recovery is possible, we need to ensure that the coordinator \nand participant log information that they may need during the recovery activity. \n We say that writing a log record is  eager (sometimes called forced or synchronous) if it must complete \nbefore the corresponding message is sent. Otherwise, it is  lazy (or asynchronous). Eager log writes have a big-\nger performance impact than lazy ones, because they must be completed before the protocol can continue and \nthey therefore add to the transaction’s response time. \n The coordinator needs to write three log records (see  Figure 8.3 ). \n ■  Before it sends a  REQUEST-TO-PREPARE , it should log a  start-two-phase-commit record , which \nincludes a list of the participants. This writing is eager; that is, the coordinator must wait until this record \nis in the stable log before sending a  REQUEST-TO-PREPARE to any participant. Otherwise, if it failed \nafter sending the  REQUEST-TO-PREPARE and before the log record was stable, it would not know which \nparticipants to notify about the decision. \n ■  Before sending a commit decision, it should log a  commit record . Indeed, writing the commit record to \nthe log is what actually commits the transaction. This too is eager. Otherwise, if the coordinator failed \n8.3 Failure Handling  229\n\n\n230  CHAPTER 8 Two-Phase Commit\n after sending the  COMMIT message and before ﬂ ushing the commit record to the log, and it subsequently \nrecovered, it would abort the transaction during its recovery procedure, which produces an inconsistent \noutcome if the participant that received the  COMMIT message committed. \n ■  After it receives the  DONE messages it writes a  done record , which records the fact that the transaction is \nﬁ nished. This is lazy. \n The participant writes two log records (see  Figure 8.3 ). \n ■  When it gets a  REQUEST-TO-PREPARE from the coordinator, it writes a  prepared record to the log. \nThis is eager; that is, it waits until the prepared record is in the stable log before sending  PREPARED to \nthe coordinator. Otherwise, if it failed after sending  PREPARED and before ﬂ ushing the prepared record \nto the log, and it subsequently recovered, it would abort the transaction during its recovery procedure \n(since there is no prepared or commit record in the log). But since it sent  PREPARED , it gave permission \nto the coordinator to commit the transaction, which would produce an inconsistent outcome. \n ■  It writes a  commit record or  abort record , after it receives the decision message. This too is eager, \nsince once it sends  DONE , it gives permission to the coordinator to forget the transaction. If it fails after \nsending  DONE and before the decision message is stable, then at recovery time it might not be able to ﬁ nd \nout what the decision was. Moreover it holds locks for the transaction until after it commits or aborts, so \nthe sooner it logs the decision, the sooner it can release locks. \n We will see ways of turning some of the eager log writes into lazy ones in the next section, on optimizations. \n Now that we know what information they log, we can look at how the coordinator and participant recover \nfrom failures. First, consider the coordinator. When it recovers it can be in one of four states (see numbered \nboxes on left side of  Figure 8.4 ): \n 1.  It has no start-two-phase-commit log record for the transaction. It did not start two-phase commit before \nthe failure. So no participant could have received a  REQUEST-TO-PREPARE message and therefore all \nof them either aborted unilaterally while the coordinator was down, or will abort on their own later (if \nthe coordinator was down only brieﬂ y). \nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nCoordinator\nParticipant\nLog a start-two-phase-commit\nrecord (eager)\nLog a commit record (eager)\nLog a done record (lazy)\nLog a prepared record (eager)\nLog a committed record (eager)\n FIGURE 8.3 \n Log Operations in Two-Phase Commit (the commit case). Each of the eager log writes must be completed before sending \nthe next message, so the process can correctly handle failures that occur after the message is sent (see text). \n\n\n 2.  It has a start-two-phase-commit record only, so it did not reach a decision before the failure. It aborts \nthe transaction. It is possible that participants are waiting for this decision, so it sends an abort decision \nmessage to all of them. Some of them may ignore the message, because they never got a  REQUEST-TO-\nPREPARE message and therefore unilaterally aborted, but there is no harm in sending the abort decision \nmessage. \n 3.  It has a commit or abort record in the log, but no done record. Again, it is possible that participants are \nwaiting for this decision, so it sends a decision message to all of them. \n 4.  It has a done record in the log. All participants acknowledged receiving the decision, so there is nothing \nto do. \n Now , consider a participant. When it recovers it can be in one of three states (see numbered boxes on right \nside of  Figure 8.4 ): \n 1.  It did not log a prepared record. The transaction could not have committed, so the participant unilater-\nally aborts the transaction. \n 2.  It logged a prepared record, but did not log a committed or aborted record. This is the bad case, where \nthe participant is blocked. It should run a termination protocol, which will be explained in a moment. \n 3.  It logged the decision, commit, or abort. It can either send another  DONE message, or it can wait until \nthe coordinator sends it a reminder message, reminding it of the decision, at which time it sends a  DONE \nmessage. \n A  termination protocol is what a participant does to try to resolve a blocked transaction when the partici-\npant recovers from a failure. The simplest termination protocol is to wait until it re-establishes  communication \nwith the coordinator and to resend its vote. If the coordinator sees a redundant vote message, this must mean \nthat the participant hasn’t yet received the decision, so it resends the decision. \n If communication cannot be re-established  in an acceptably short time, then a human operator may need \nto intervene and guess whether the transaction committed or aborted (perhaps making a telephone call to the \noperator of the other system to ﬁ nd out the decision). The protocol should log this  heuristic decision , so that \nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nCoordinator\nParticipant\nLog a start-two-phase-commit\nrecord (eager)\nLog a prepared record (eager)\nLog a committed record (eager)\n1\n2\n3\n1\n2\n3\n4\nLog a done record (lazy)\nLog a commit record (eager)\n FIGURE 8.4 \n Possible States from Which a Coordinator or Participant Must Recover. See text for a description of recovery actions for \nthe state labeled by each numbered box. \n8.3 Failure Handling  231\n\n\n232  CHAPTER 8 Two-Phase Commit\n when communication between the two systems is re-established, the systems can detect whether a consistent \nor inconsistent decision was made. In the latter case, the system can notify an operator that corrective action is \nneeded. \n Repairing an inconsistent decision can be difﬁ cult. The transaction that incorrectly committed or aborted \nleft some incorrect data in the database. That incorrect data may have been read by later transactions which \nthemselves wrote some data. In this way, the inconsistency may have spread beyond the data that was directly \nupdated by the transaction that terminated inconsistently. Taking corrective action therefore could require some \ncareful analysis of the database and transaction log. \n This covers all the failure scenarios — timing out waiting for a message and recovering from a failure. So \nwe now have a complete and correct two-phase commit protocol. \n 8.4  OPTIMIZATIONS AND VARIATIONS \n There are many variations of two-phase commit to handle special transaction communications patterns. We dis-\ncuss three of them here: reinfection, where a transaction revisits a resource manager after the two-phase commit \nprotocol has started; transfer of coordination, to allow one resource manager to execute one-phase-commit; and \nphase zero, where a transaction delays sending updates to some resource managers until after it has ﬁ nished \nexecuting. \n There are also many optimizations of two-phase commit to save messages and reduce the number of eager \nlog writes. The most obvious is to avoid two-phase commit altogether when there is only one resource man-\nager in a transaction, and run one-phase commit instead. This is a fairly important optimization since many \ntransactions access only one resource manager. If a transaction issues Start and Commit but never accesses a \nresource manager, then it can run no-phase commit. That is, the coordinator can commit immediately without \nsending a message to any outside agent. Several other optimizations are described later: presumed abort, to \nreduce the amount of logging for transactions that abort; reducing a round of messages for read-only resources; \nand the cooperative termination protocol, to increase the chance that a blocked resource manager can become \nunblocked. \n Reinfection \n If the coordinator starts two-phase commit before all the participants have fully completed (thereby violating \nassumption 4 in Section 8.2), then it’s possible that a participant will prepare and later be asked to do work for \nthe same transaction. This is called  reinfection . \n Reinfection can arise if participants want to postpone certain work until after the transaction has completed \nits regular work, for example, with database triggers that should execute at the end of the transaction. Since the \ncoordinator waits until the transaction completes its normal work before sending  REQUEST-TO-PREPARE mes-\nsages, participant P might use the arrival of a  REQUEST-TO-PREPARE message to tell it to execute an end-of-\ntransaction trigger. But the trigger could update data at another participant Q that has already prepared, thereby \nreinfecting Q. So Q has to prepare again. \n This complicates matters. The coordinator already may have received Q’s  PREPARED message. If the coor-\ndinator receives P’s acknowledgment of its  REQUEST-TO-PREPARE before Q prepares again, it could commit \nbefore Q is prepared. To avoid this bad outcome, if Q is reinfected by a call from P, it should not reply to P \nuntil it has processed P’s request  and has prepared again by ensuring all updates it made due to the reinfection \nare in stable storage (see  Figure 8.5 ). That way, when P sends  PREPARED to the coordinator, it knows that Q is \nalso prepared (again) and it’s safe for the coordinator to commit. \n\n\n Transfer of Coordination \n If there is only one participant, then two-phase commit can be done with only three rounds of communication \ninstead of four. The trick is for the coordinator to transfer its  “ coordinator role ” to the participant, which then \nbecomes the coordinator. The optimized protocol works as follows (see  Figure 8.6 ): \n ■  The coordinator prepares and then sends a message to the participant that asks it to prepare  and to \nbecome the coordinator. \nREQUEST-TO-PREPARE\nPREPARED\nREQUEST-TO-PREPARE\nUPDATE DATA\nPREPARED\nCOMMIT\nDONE\nCOMMIT\nDONE\nParticipant P\nCoordinator\nParticipant Q\nAccess data at \nparticipant Q\nDo the requested\nwork and prepare\nagain\nReply and acknowledge prepared\n FIGURE 8.5 \n Reinfection. Participant P reinfects Participant Q after Q prepared. P waits for Q to prepare again and reply to P before P \nsends PREPARED to the coordinator, thereby ensuring Q is prepared before the coordinator commits. \nREQUEST-TO-PREPARE-AND\nTRANSFER COORDINATION\nCOMMIT\nDONE\nCoordinator\nParticipant\nLog a prepared record (eager)\nLog a commit record (eager)\nLog a committed record (eager)\nLog a done record (lazy)\n FIGURE 8.6 \n Transfer of Coordination Optimization. The coordinator prepares and then tells the participant to prepare and commit, \nand thereby become the coordinator. This saves a message over standard two-phase commit. \n8.4 Optimizations and Variations  233\n\n\n234  CHAPTER 8 Two-Phase Commit\n ■  The participant (which is now the coordinator) prepares, commits, and sends a  COMMIT message to the \nformer coordinator. \n ■  The coordinator commits and sends  DONE to the participant. \n Notice that the participant does not need a prepare phase in this case. However, since the participant is now \nperforming the coordinator’s role, it must remember the decision until it receives the  DONE message from the \nformer coordinator. This covers the case where the  COMMIT message is lost, and the former coordinator must \nlater ask the participant what the decision was. \n Using this observation, we can run two-phase commit in a system that uses a resource manager that does not \nsupport a separate prepare phase and can only commit or abort, as long as there is only one such resource manager \nin any transaction. To do this, the coordinator goes through the usual ﬁ rst phase of two-phase commit. After all the \nother participants have acknowledged that they’re prepared, the coordinator prepares and transfers coordination to \nthe resource manager that does not support two-phase commit. When the resource manager acknowledges that it \ncommitted, the coordinator can ﬁ nish the job by sending  COMMIT messages to the remaining participants. \n This can work with only one resource manager that doesn’t support the prepare phase. If there were two, then \nthe coordinator would have to tell them both to commit without asking them to prepare. If one committed and \nthe other didn’t, the result would be inconsistent, the very situation that two-phase commit is designed to avoid. \n Phase Zero \n Many systems use a mid-tier or client cache that holds copies of a transaction’s updates until the transaction \nhas terminated and is ready to commit. In this case, the cache manager needs to ﬂ ush the transaction’s updates \nto the appropriate resource manager before the two-phase commit protocol starts to ensure that the resource \nmanager stores a stable copy of the transaction’s updates during phase one. \n Suppose a participant P is caching transaction updates that P needs to send to a resource manager R before \nT commits. To ensure that R has all of T’s updates, P must send T’s updates to R after T invokes Commit (to \nensure it has  all the updates that will perform at R) and before R prepares (to ensure the updates are made \nstable during phase one). Thus, we need an extra phase, before phase one. \n A solution is to allow some participants to enlist for  phase zero of a transaction. For example, a mid-tier \ncache manager would enlist for phase zero of transaction T when the cache manager receives the ﬁ rst write on \nbehalf of T. When the transaction manager receives a transaction’s request to commit, the transaction manager \nsends a message to all of the transaction’s participants that enlisted for phase zero. A participant who receives \nsuch a message can ﬂ ush its cache or perform any other actions that need to be completed before phase one of \ntwo-phase commit begins. The transaction manager waits for all phase zero participants to reply to its phase \nzero request message before it starts executing phase one of two-phase commit. If it doesn’t receive one of \nthose replies within its timeout period, then it aborts the transaction. \n Presumed Abort \n Ordinarily , the coordinator does an eager write of the start-two-phase-commit log record (see  Figure 8.3 ). By \na slight modiﬁ cation of the protocol, the coordinator can avoid logging this record at all — at recovery time, if \nthere is no record of a transaction in the coordinator’s log, then the coordinator assumes the transaction must \nhave aborted. This assumption has several implications: \n ■  If a participant asks the coordinator about a transaction, and the coordinator has no information, then the \ncoordinator presumes the transaction aborted. This is more than a presumption; according to this revised \nprotocol, the transaction  must have aborted. \n\n\n ■  If the transaction aborts, a participant can do a  lazy log write of an abort decision and need not send \n DONE to the coordinator. \n ■  If the transaction aborts, the coordinator need not log a done record. \n To see why this works, suppose a participant is blocked at recovery time and sends a message to the coor-\ndinator. If the transaction aborted, there are two cases to consider: (1) the coordinator has an abort record in \nthe log (it aborted the transaction but failed before sending the  ABORT messages), in which case it replies with \nan abort decision; (2) it has no record at all — it didn’t abort the transaction (fully) before the failure — in which \ncase it again replies with an abort decision (the  “ presumed abort ” for the no-information case; see  Figure 8.7 ). \nIf the transaction committed (see  Figure 8.8 ), the coordinator must have a commit record in the log, since it \nis still obligated to remember commit decisions until all participants have replied  DONE (i.e., the two-phase \ncommit protocol is unchanged for the commit case, except that the coordinator doesn’t log a start-two-phase-\ncommit record). \n Presumed abort is a popular optimization, used by most implementations of two-phase commit. \n Read-Only Transactions \n If a participant reads but does not write data on behalf of the transaction, then it does not care what the deci-\nsion is. Whether the transaction commits or aborts, the participant does the same thing, namely, it releases the \ntransaction’s read locks. In fact, it need not wait to ﬁ nd out whether the transaction commits or aborts. It can \nrelease read locks as soon as it receives a  REQUEST-TO-PREPARE , since that signals that the transaction has \nterminated, at which point it is safe to release read locks, as far as two-phase locking is concerned. Therefore, \nin response to a  REQUEST-TO-PREPARE , it replies  PREPARED-READ-ONLY , which tells the coordinator not to \nbother sending a decision message (see  Figure 8.9 ). \n Although this optimization looks very appealing and intuitive, it often cannot be used in practice, because some \nparticipants may have more work to do after they receive a  REQUEST-TO-PREPARE (again violating assumption \n4 in Section 8.2). For example, they may need to execute SQL triggers or integrity constraints, which can involve \nacquiring more locks. We saw this kind of situation in the section on reinfection. If a read-only participant releases \nREQUEST-TO-PREPARE\nPREPARED\nDECISION-REQUEST\nABORT\nCoordinator\nParticipant\nStart two-phase-commit\nwithout logging a record\n                  Crash!\n                 Recover\nCoordinator responds Abort,\nsince it has no information\nLog a prepared record (eager)\nParticipant times out waiting\nfor a decision message, so it\nasks the coordinator\n FIGURE 8.7 \n Presumed Abort Optimization (the Abort Case). The coordinator need not log a start-two-phase-commit record. If it fails \nbefore it commits, it has no information about the transaction. In this case, it responds abort to requests for the decision. \n8.4 Optimizations and Variations  235\n\n\n236  CHAPTER 8 Two-Phase Commit\n a lock after receiving a  REQUEST-TO-PREPARE , and another participant acquires a lock later on while evaluating \na trigger, the transaction has broken the two-phase locking protocol and the result may not be serializable. \n If the application knows that a transaction is read-only, then it can get the same effect as the read-only opti-\nmization without any help from the transaction manager or resource managers. After the transaction has done \nits work, it issues an abort instead of a commit. The beneﬁ t of aborting is that the coordinator only does one \nround of messages to abort. And in this case, because the transaction is read-only, an abort has the same effect \nas a commit; namely, it tells each resource manager to release the transaction’s locks. However, notice that \nthis optimization is applicable only if the entire transaction is read-only. This is more restrictive than the read-\nonly optimization, which is applicable as long as the transaction is read-only at one resource manager. Also \nREQUEST-TO-PREPARE\nPREPARED-READ-ONLY\nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nParticipant P\nCoordinator\nParticipant Q\n FIGURE 8.9 \n Read-Only Optimization. Since Participant Q is read-only, it can release locks and ﬁ nish the transaction when it receives \na  REQUEST-TO-PREPARE , and the coordinator does not have to send it a  COMMIT . \nREQUEST-TO-PREPARE\nPREPARED\nDECISION-REQUEST\nCOMMIT\nCoordinator\nParticipant\nStart two-phase-commit\nwithout logging a record\nLog a commit record (eager)\n                  Crash!\n                 Recover\nCoordinator responds Commit,\nsince it has a commit record\nin its log\nLog a prepared record (eager)\nParticipant times out waiting\nfor a decision message, so it\nasks the coordinator\n FIGURE 8.8 \n Presumed Abort Optimization (the Commit Case). The coordinator does not log a start-two-phase-commit record. Since it \nfails after it commits, it responds commit to the request for the decision, exactly as if the optimization were not used. \n\n\n notice that this optimization is the responsibility of the application program, not the transaction manager and \nresource managers. It can be used only if the application program knows that the transaction did not perform \nany updates. If application does an RPC to a server whose internal behavior is unknown, then it has to assume \nthe worst and commit, not abort. \n Cooperative Termination Protocol \n Recall that the bad case when a participant recovers from a failure is that the participant logged a prepared \nrecord, but did not log a committed or aborted record. This means the participant is blocked and must run a ter-\nmination protocol. The participant can ﬁ nd out the decision from the coordinator, if it is alive. If not, it can avoid \nwaiting for the coordinator to recover by using the  cooperative termination protocol , which asks for help from \nother participants. \n The cooperative termination protocol requires that each participant knows the addresses of the other par-\nticipants, so that it can contact them if it is blocked during recovery. It therefore needs to get this information \nfrom the coordinator in the  REQUEST-TO-PREPARE message. At recovery time, it then proceeds as follows \n(see  Figure 8.10 ): \n 1.  The participant P sends a  DECISION-REQUEST message to the other participants. \n 2.  When a participant Q receives a  DECISION-REQUEST , it responds as follows: \n ■  If it knows what the decision was (i.e., it got a  COMMIT or  ABORT from the coordinator), then it \nreplies with the decision ( COMMIT or  ABORT ). \nREQUEST-TO-PREPARE\n(includes list of other\nparticipants)\nPREPARED\n(COMMIT/ABORT)\nDECISION-REQUEST\nDECISION-REPLY\nParticipant P\nCoordinator\nParticipant Q\nCrash!\nCrash!\n. . .\nRecover\nParticipant P sends this message only\nif Participant Q sent UNCERTAIN as its\nDECISION-REPLY.\nDecision\n FIGURE 8.10 \n Cooperative Termination Protocol. When Participant P recovers, the coordinator is down. So Participant P asks other \nparticipants what the decision was (via  DECISION-REQUEST ). Other participants, such as Participant Q, reply with \na  DECISION-REPLY containing  COMMIT ,  ABORT , or  UNCERTAIN . If Participant P learns the decision from some \nparticipant, then it sends a decision message to each participant that replied  UNCERTAIN in the previous round. \n8.4 Optimizations and Variations  237\n\n\n238  CHAPTER 8 Two-Phase Commit\n ■  If it did not prepare the transaction, it replies  ABORT . The transaction could not have committed, \nsince this participant did not send a  PREPARE to the coordinator. Since another participant is blocked, \nthere is no point in waiting for the decision from the coordinator, since the coordinator is apparently \ndown or not communicating with some participants. \n ■  If it prepared, but does not know what the decision was, then it replies  UNCERTAIN . This is the bad \ncase that doesn’t help participant  P . \n 3.  If any participant replies with a decision, then P acts on the decision and sends the decision to every \nparticipant that replied  UNCERTAIN , since they want to know the decision too. \n If participants are allowed to run the cooperative termination protocol, then it may not be a good idea for \nthem to forget the decision shortly after they receive it from the coordinator, because some other participant \nmay later ask for it when it runs the cooperative termination protocol. Since a participant could fail and be \ndown for a long time, there is no bound on how long participants should remember the decision. There are two \nways to handle this problem. First, each participant can simply hold on to each decision for some ﬁ xed amount \nof time, such as one minute, before discarding it. If asked later than that about the decision, it has to reply \n UNCERTAIN . Second, we could add a ﬁ fth round of messages from the coordinator to the participants, after the \ncoordinator receives  DONE from all the participants. This ﬁ nal message from the coordinator tells the partici-\npants that they can forget the decision, since all other participants know the decision and will not need to run \nthe cooperative termination protocol after a failure. Like  DONE messages, these ﬁ nal messages are not urgent \nand can be piggybacked on other messages from the coordinator to the participants. \n 8.5  PROCESS STRUCTURING \n Independent Transaction Managers \n Now that we have studied two-phase commit from a single transaction’s viewpoint, it is time to see how a sys-\ntem can manage two-phase commit on behalf of many transactions and resource managers. The usual approach \nis to have one module, the  transaction manager , be responsible for running the two-phase commit protocol, \nperforming both the coordinator and participant functions for a group of transactions. The transaction manager \nusually is packaged with another product, such as the operating system (as in Microsoft Windows and HP’s \nOpenVMS) or transactional middleware (as in IBM’s Websphere or Oracle’s WebLogic). \n One possibility is to have the transaction manager be part of the database system. This works ﬁ ne for trans-\nactions that access multiple copies of one particular database system. But it generally does not work with other \ndatabase systems, because each database system uses its own two-phase commit protocol, with its own mes-\nsage formats and optimizations. A different approach is needed for transactions to interoperate across different \ndatabase systems. \n The standard solution to this problem is to have the transaction manager be an independent component. \nIt runs two-phase commit for all transactions that execute on its machine. To do this, it communicates with \nresource managers on its own machine and with transaction managers on other machines. \n Although one transaction manager per machine is the standard conﬁ guration, it is not the only one. A trans-\naction manager may support multiple machines, or a machine may have multiple transaction managers. In a \nclustered environment where two or more machines share disks and other resources, there may be one trans-\naction manager for the cluster rather than one per machine. In this case, if the transaction manager’s machine \nfails, then the cluster manager needs to recreate the transaction manager on another machine in the cluster that \n\n\n has access to the transaction manager’s log. Conversely, a machine that runs heterogeneous software may have \nmultiple transaction managers. For example, it may run transactional middleware that has its own transaction \nmanager while executing on a machine whose operating system and database system have transaction manag-\ners. This is usually inefﬁ cient, due to the logging and communication that each transaction manager requires. \nBut it is unavoidable if the application depends on those heterogeneous components. \n This system model of having an independent transaction manager has been standardized by X/Open (now \npart of The Open Group), which also has deﬁ ned the interface between transaction managers and resource man-\nagers, so that transaction and resource managers from different vendors can be hooked up (see  Figure 8.11 ). \nNotice that this model deﬁ nes the transaction bracketing interface (TX) but not the interfaces to resource man-\nagers (which are covered by other standards, notably SQL). The application programming interface may also \ninclude other operations, which are not shown in the model. Although the X/Open model is widely supported, \nmany transaction managers offer proprietary interfaces too. Section 10.6 describes other transaction manage-\nment standards, such as the Object Transaction Service and the Java Transaction API. \n Enlisting in a Transaction \n In this architecture, each transaction manager can be the coordinator of a transaction; its participants are local \nresource managers accessed by the transaction and, when a transaction is propagated to a remote machine, \nremote transaction managers on those remote machines. Or, a transaction manager can be a participant, being \ncoordinated by transaction managers on other machines. As we’ll see, a transaction manager can be both, even \nfor the same transaction. Since each transaction accesses different resource managers at different machines \nof the network, the transaction manager must dynamically ﬁ gure out the coordinator-participant relationships \nfor each transaction. To dynamically manage transactions in this way, each resource manager and transaction \nmanager must  join or  enlist in a transaction when it is ﬁ rst accessed on behalf of the transaction. \n When the application calls a local resource manager, R, for the ﬁ rst time on behalf of a transaction T, R calls its \nlocal transaction manager with Enlist(T), which  “ enlists R in T. ” This tells the transaction manager that R needs to \nbe notiﬁ ed about commit and abort operations later (see  Figure 8.12 ). When the transaction manager later receives \na commit or abort operation for T, it runs two-phase commit with the local resource managers that enlisted in T. \nApplication program\nTransaction manager\nResource manager operations\nsuch as Read and Write\nTX interface \u0003 Start Transaction, \nCommit, Roll Back (i.e.,  Abort)\nApplication\nprogramming\ninterface\nResource manager\nXA interface \u0003 Enlist and\ntwo-phase commit operations\n FIGURE 8.11 \n X/Open Transaction Model. The transaction manager runs two-phase commit for all transactions at its machine and \ncommunicates with local resource managers. \n8.5 Process Structuring  239\n\n\n240  CHAPTER 8 Two-Phase Commit\n Similarly , when the application calls an application or resource manager at a remote machine M for the \nﬁ rst time, the application’s local transaction manager and machine M’s transaction manager must be notiﬁ ed \nthat the transaction has moved, thereby starting a new  branch of the transaction at M. This is done by the \ncomponent that performs remote transactional communications, usually called the  communication manager . \nLike the transaction manager, it may be part of the transactional middleware, operating system, or resource \nmanager (for remote resource manager calls). \n For example in  Figure 8.13 , application AP 1 running transaction T at machine M calls application AP 2 at \nmachine N. In addition to sending the message and calling the remote application, the communication manager \ncreates a branch of T at N. This is needed so that M’s transaction manager knows to send two-phase commit \nmessages to N’s transaction manager. It also tells N’s transaction manager to expect Enlist operations on this \nApplication program,  AP1\nApplication program,  AP2\nTransaction manager\nlocal to AP1\nTransaction manager\nlocal to AP2\n1. Call(AP2, T)\n2. AddBranch(N, T)\nMachine M\nMachine N\n3. Send \n“Call(AP2, T)”\n5. Call(AP2, T)\n4. StartBranch(T)\nApplication\nprogramming\ninterface\nCommunication manager\nlocal to AP1\nCommunication manager\nlocal to AP2\n FIGURE 8.13 \n A Remote Call That Starts a Branch Transaction. Application AP 1  calls application AP 2  at a remote machine N, thereby \ncreating a branch transaction at N. The communication manager tells the transaction managers at machines M and N \nabout the new branch by the AddBranch and StartBranch calls, respectively. \nApplication program\nTransaction manager\n2.  Write(X, T)\n1. Start transaction\n(returns transaction ID T)\n3.  Enlist(T)\nApplication\nprogramming\ninterface\nResource manager\n FIGURE 8.12 \n A Resource Manager Enlists for a Transaction. When an application program executing a transaction ﬁ rst accesses a \nresource manager, the resource manager enlists with its local transaction manager. This tells the transaction manager to \nnotify the resource manager about this transaction’s commit or abort operation later. \n\n\n transaction from N’s resource managers and to expect two-phase commit operations from M’s transaction man-\nager. In some systems, M’s transaction manager establishes communications with N’s transaction manager (if it \nhasn’t already done so) and sends an enlistment message. This tells N’s transaction manager where to send the \ntwo-phase commit messages later. \n It requires a high degree of trust for a transaction manager on one machine to agree to communicate with \na transaction manager on another machine. Each transaction manager needs to know that the other transaction \nmanager will make timely and correct progress toward completing the transaction. In particular, if a trans-\naction manager acting as coordinator stops communicating with the other transaction acting as participant, \nthen the participant could become blocked. Each transaction manager needs to believe this is a very unlikely \nevent before agreeing to communicate. This trust relationship is hard to establish between different enterprises, \nsince their systems are autonomous and independently managed. For this reason, two-phase commit rarely is \nexecuted between systems in different enterprises. It may even be problematic between systems with a single \nlarge enterprise. It is more commonly used between machines that support different parts of the same applica-\ntion, which are controlled by the same system manager. \n The Tree-of-Processes Model \n A transaction can migrate from machine to machine many times during its execution. This leads to a tree-\nstructured set of transaction managers and resource managers involved in the transaction, called the  tree-of-\nprocesses model of transaction execution. For example, a transaction could migrate as follows (see  Figure 8.14 ): \n ■  It started at machine 1 and accessed resource manager RM 1 . \n ■  From machine 1, it made a remote call to machine 2, where it accessed resource managers RM 2a and RM 2b . \n ■  From machine 1, it made a remote call to machine 3, where it accessed resource manager RM 3 . \n ■  From machine 3, it made a remote call to machine 4, where it accessed resource manager RM 4 . \nTM1\nTM3\nRM1\nTM2\nRM2b\nRM2a\nRM3\nTM4\nRM4\nLegend: \n• RM \u0003 Resource manager\n• TM \u0003 Transaction manager\n• Dashed lines indicate machine boundaries.\n• Arrows are from a coordinator to its \n  participants.\n FIGURE 8.14 \n Tree-of-Processes Model. By migrating from machine to machine and accessing resource managers, a transaction \ncreates a tree of coordinators and participants that will run two-phase commit. A particular execution that leads to this \ntree is described in the text. \n8.5 Process Structuring  241\n\n\n242  CHAPTER 8 Two-Phase Commit\n In the tree of processes model, the root transaction manager is the coordinator, and its children are partici-\npants. So in  Figure 8.14 , TM 1 is the overall coordinator, and TM 2 , TM 3 , and RM 1 are its participants. TM 2 is, \nin turn, the coordinator of RM 2a and RM 2b , and TM 3 is the coordinator of RM 3 and TM 4 . So TM 2 and TM 3 play \nthe roles of both participant (with respect to TM 1 ) and coordinator (with respect to their children). Similarly, \nTM 4 is a participant (with respect to TM 3 ) and coordinator (with respect to RM 4 ). \n In  Figure 8.14 , suppose the transaction executing on machine 4 calls an application on machine 1. This attempt \nto execute StartBranch on machine 1 returns a warning that the transaction already is executing on machine 1. \nThis just means that TM 1 does not become a participant with respect to TM 4 . This is not an error, so the call to \nthe application at machine 1 succeeds. That application’s operations on machine 1’s resource managers, such as \nRM 1 , are part of the transaction and are committed or aborted whenever TM 1 tells its local resource managers to \ncommit or abort. \n When a transaction manager is both a participant and a coordinator, it must prepare its subtree before it \nreplies prepared to a  REQUEST-TO-PREPARE message. For example, in  Figure 8.14 : \n ■  After TM 3  receives  REQUEST-TO-PREPARE from TM 1 , it should send a  REQUEST-TO-PREPARE to RM 3  \nand TM 4 . \n ■  TM 4  then sends a  REQUEST-TO-PREPARE to RM 4 . \n ■  After RM 4  replies  PREPARED , TM 4  can reply  PREPARED to TM 3 . \n ■  After TM 4  and RM 3  reply  PREPARED , TM 3  can reply  PREPARED to TM 1 . \n A tree-of-processes adds delay to two-phase commit because of the daisy-chain of communication, such as \nfrom TM 1 , to TM 3 , to TM 4  in the example. This delay can be reduced by ﬂ attening the tree, so that all transac-\ntion managers communicate with the root coordinator. For example, if TM 1  knew about TM 4 , it could com-\nmunicate with TM 4  directly and in parallel with its communication wit h TM 2  and TM 3 . This short-circuiting \nof communications is called  ﬂ attening the tree. It can be done by passing knowledge of new branches back up \nthe tree during normal execution. For example, when the transaction migrates from TM 3  to TM 4 , TM 3  could \ntell TM 1  about the migration, so TM 1  can later communicate with TM 4  directly (see  Figure 8.15 ). Although \nthis ﬂ attening is usually desirable, it is not always possible, because some pairs of machines may not be able to \ncommunicate directly. \nTM1\nTM3\nRM1\nTM2\nRM2b\nRM2a\nRM3\nTM4\nRM4\n FIGURE 8.15 \n Flattening the Tree-of-Processes. If TM 3  tells TM 1  about TM 4 , then TM 1  can communicate with TM 4  directly. This ﬂ attens \nthe tree of  Figure 8.14 , thereby reducing communication delay from TM 1  to TM 4 . \n\n\n 8.6  USER CHECKLIST \n There are several aspects of a two-phase commit implementation that are of direct interest to users of TP \nproducts. The most obvious is whether two-phase commit is appropriate at all. The communication required \nfor two-phase commit increases transaction execution time and hence lock holding time. This can increase \nthe lock conﬂ ict rate and hence reduce throughput. In addition, if the communication connections between \nresource managers are  not extremely reliable, then the probability of blocked transactions may be unaccept-\nably high. In these cases, there are two possible solutions: ensure that each transaction can do its work with \njust one resource manager, or split the transaction into a multistep business process where each step is a trans-\naction that accesses only one resource manager. Both approaches require extra application development effort. \nThe beneﬁ ts are better performance or availability. \n If transactions do indeed need to perform updates at multiple resource managers, one needs to check \nwhether each resource manager product supports two-phase commit at all. Today, most popular database sys-\ntems and transactional middleware support it. However, not all combinations of database systems and trans-\nactional middleware work correctly together; that is, they don’t all  interoperate . Even if a database system \nsupports the X/Open interfaces, there is still the question of whether it has been tested with a given transac-\ntional middleware product and whether it exploits any proprietary optimizations that a given transaction man-\nager offers. Such optimizations can have a big effect on transaction performance. \n Although there is increasing support for standard two-phase commit protocols, there is enough variation \nthat this doesn’t always guarantee compatibility. Moreover, some transaction manager vendors use their own \ntwo-phase commit protocol. In a system that uses transaction managers from different vendors, a transaction \nmight need to access applications or resource managers that use these different transaction managers. To get \nall-or-nothing behavior, the transaction managers need to interoperate. That is, one of the transaction managers \nmust be willing to communicate using the other transaction manager’s two-phase commit protocol. \n For the most part, two-phase commit is transparent to system operators. However, when a transaction is \nblocked due to a failure, an operator may need to get involved. Although this event occurs rarely, when there \nis a failure, there is a good chance that  some transaction will be blocked. Therefore, support for heuristic deci-\nsions is valuable, along with notiﬁ cation of inconsistent decisions when they are made. \n Two -phase commit should be transparent to application programmers. If it isn’t, then the vendor’s imple-\nmentation is incomplete. However, if a nonstandard or home-grown database system is used in an application, \nthen it is unlikely to be supported by the TP system’s built-in two-phase commit implementation. In this case, \nit is important that the resource manager interface to the transaction manager be exposed. This interface allows \nthe user to integrate the nonstandard resource manager with the transaction manager, so the resource manager’s \noperations can be included in distributed transactions. \n 8.7  SUMMARY \n The two-phase commit protocol ensures that a transaction either commits at all the resource managers that \nit accessed or aborts at all of them. It avoids the undesirable outcome that the transaction commits at one \nresource manager and aborts at another. The protocol is driven by a coordinator, which communicates with \nparticipants, which together include all the resource managers accessed by the transaction. \n Since failures are unavoidable, the protocol must ensure that if a failure occurs, the transaction can reach \na consistent outcome after the failed component recovers. It therefore requires that, during phase one, every \nresource manager prepares the transaction by recording all the transaction’s updates on stable storage. After \n8.7 Summary  243\n",
      "page_number": 236
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 262-279)",
      "start_page": 262,
      "end_page": 279,
      "detection_method": "topic_boundary",
      "content": "244  CHAPTER 8 Two-Phase Commit\n all resource managers have acknowledged to the coordinator that they  “ prepared ” in phase one, the coordinator \nstarts phase two by committing the transaction and then notifying the participants of this commit decision. If \nany participant fails to acknowledge phase one, or votes  “ no, ”  then the coordinator aborts the transaction and \nnotiﬁ es the participants of this decision. \n The complexity of two-phase commit comes from all the failure scenarios that can arise. The most annoy-\ning failure happens after a participant has acknowledged prepared and before it receives the decision, such as \na failure of the coordinator or of participant-coordinator communications. This leaves the participant blocked. \nIt can’t commit or abort, since the coordinator may have decided the opposite and the participant can’t ﬁ nd out \nthe decision. This problem is inherent in any commit protocol when communication failures are possible and \nnot a special weakness of two-phase commit in particular. \n The coordinator and participant must log certain changes in their state, so if either of them fails and subse-\nquently recovers, it can tell what it was doing at the time of failure and take appropriate action. In particular, \nthe coordinator must write a log record before beginning the protocol and before sending its decision, and each \nparticipant must log a prepared record before acknowledging prepared. Each participant should log the decision \nwhen it ﬁ nds out what it was. Finally, the coordinator should write a log record when it gets all acknowledgments \nof its decision, so it knows it can forget the transaction. One then must go through a careful analysis to determine \nwhat the coordinator and each participant should do in every possible failure situation that can arise. \n There are variations of two-phase commit to handle special transaction communications patterns. Three \npopular ones are reinfection, to handle a transaction that revisits a resource manager after the two-phase com-\nmit protocol has started; transfer of coordination, to enable one participant to use one-phase commit; and phase \nzero, when a mid-tier cache needs to ﬂ ush its updates before phase one. There are also many optimizations of \ntwo-phase commit to reduce the number of log writes and messages. The most popular one is presumed abort, \nwhich avoids requiring that the coordinator write a log record before beginning of the protocol and before \naborting a transaction. \n Two -phase commit is implemented by the transaction manager component, which communicates with local \nresource managers and remote transaction managers. It plays the role of coordinator or participant, depending \non whether the transaction started at its machine or elsewhere. It needs to be notiﬁ ed when a transaction has ﬁ rst \naccessed a resource manager or moved to another machine, so it will know with whom to communicate when \nit comes time to run two-phase commit. X/Open has standardized the transaction manager’s interfaces with \nresource managers, called XA. This standard is widely supported, but most systems also have more efﬁ cient \nnonstandard interfaces too. Most transaction managers support a unique proprietary protocol. \n \n\n\n 9.1  INTRODUCTION \n Replication is the technique of using multiple copies of a server or a resource for better availability and per-\nformance. Each copy is called a  replica . \n The main goal of replication is to improve availability, since a service is available even if some of its repli-\ncas are not. This helps mission critical services, such as many ﬁ nancial systems or reservation systems, where \neven a short outage can be very disruptive and expensive. It helps when communications is not always avail-\nable, such as a laptop computer that contains a database replica and is connected to the network only intermit-\ntently. It is also useful for making a cluster of unreliable servers into a highly-availabl e system, by replicating \ndata on multiple servers. \n Replication can also be used to improve performance by creating copies of databases, such as data ware-\nhouses, which are snapshots of TP databases that are used for decision support. Queries on the replicas can be \nprocessed without interfering with updates to the primary database server. If applied to the primary server, such \nqueries would degrade performance, as discussed in Section 6.6,  Query-Update Problems in two-phase locking. \n In each of these cases, replication can also improve response time. The overall capacity of a set of repli-\ncated servers can be greater than the capacity of a single server. Moreover, replicas can be distributed over a \nwide area network, ensuring that some replica is near each user, thereby reducing communications delay. \n 9.2  REPLICATED SERVERS \n The Primary-Backup Model \n To maximize a server’s availability, we should try to maximize its mean time between failures (MTBF) and \nminimize its mean time to repair (MTTR). After doing the best we can at this, we can still expect periods of \nunavailability. To improve availability further requires that we introduce some redundant processing capability \nby conﬁ guring each server as two server processes : a primary server that is doing the real work, and a backup \nserver that is standing by, ready to take over immediately after the primary fails (see  Figure 9.1 ). The goal is \nto reduce MTTR: If the primary server fails, then we do not need to wait for a new server to be created. As \nsoon as the failure is detected, the backup server can immediately become the primary and start recovering to \nthe state the former primary had after executing its last non-redoable  operation, such as sending a message to \n Replication \n 9 \nCHAPTER\n\n\n246  CHAPTER 9 Replication\nan ATM to dispense money. If it recovered to an earlier state, it would end up redoing the operation, which \nwould be incorrect. Since we are interested primarily in transactional servers, this means recovering to a state \nthat includes the effects of all transactions that committed at the former primary and no other transactions. \nFor higher availability, more backup servers can be used to guard against the possibility that the primary and \nbackup fail. \n This technique is applicable to resource managers and to servers that run ordinary applications, such as \nrequest controllers and transaction servers. When a server of either type fails, it needs to be recreated. Having \na backup server avoids having to create the backup server at recovery time. \n If there are many clients and some are connected by slow communication lines, then it can take a long time \nto recreate sessions with the backup server. To avoid doing this at recovery time, each client connected to the \nprimary server should also have a backup communication session with the backup server. This further decreases \n(i.e., improves) MTTR. \n In general, the degree of readiness of the backup server is a critical factor in determining MTTR. If a \nbackup server is kept up to date so that it is always ready to take over when the primary fails with practically \nno delay, then it is called a  hot backup . If it has done some preparation to reduce MTTR but still has a signiﬁ -\ncant amount of work to do before it is ready to take over from the primary, then it is called a  warm backup . If \nit has done no preparation, then it is called a  cold backup . \n As in the case of a server that has no backup, when the primary server fails, some external agent, such as a \nmonitoring process, has to detect the failure and then cause the backup server to become the primary. The delay \nin detecting failures contributes to MTTR, so fast failure detection is important for high availability. \n Once the backup server has taken over for the failed primary, it may be worthwhile to create a backup for the \nnew primary. An alternative is to wait until the former primary recovers, at which time it can become the backup. \nThen, if desired, the former backup (which is the new primary) could be told to fail, so that the original primary \nbecomes primary again and the backup is restarted as the backup again. This restores the system to its original \nconﬁ guration, which was tuned to work well. The cost is a brief period of downtime while the secondary and \nprimary switch roles. \n When telling a backup to become the primary, some care is needed to avoid ending up with two servers \nbelieving they’re the primary. For example, if the monitor process gets no response from the primary, it may con-\nclude that the primary is dead. But the primary may actually be operating. It may just be slow because its system \nis overloaded (e.g., a network storm is swamping its operating system), and it therefore hasn’t sent an  “ I’m alive ” \nmessage in a long time, which the monitor interprets as a failure of the primary. If the monitor then tells the \nbackup to become the primary, then two processes will be operating as primary. If both primaries perform opera-\ntions against the same resource, they may conﬂ ict with each other and corrupt that resource. For example, if the \nPrimary\nServer\nBackup\nServer\nClient\n FIGURE 9.1 \n Primary-Backup Model. The primary server does the real work. The backup server is standing by, ready to take over after \nthe primary fails. \n\n\nresource is a disk they might overwrite each other, or if the resource is a communications line they may send \nconﬂ icting messages. \n One way to avoid ending up with two primaries is to require the primary to obtain a lock that only one pro-\ncess can hold. This lock could be implemented in hardware as part of the resource. For example, some network-\ning techniques, such as reﬂ ective memory, and most disk systems, such as SCSI and Fiber Channel (as it runs \nover SCSI), allow a lock on a resource over their shared bus. Or it could be implemented in software using a \nglobal lock manager, which is supported by some operating systems that are designed for multiserver clusters and \nas independent components in some distributed systems. Another solution is to use a third  “ watchdog ” process, \nwhich is described in Section 9.4,  Primary Recovery with One Secondary . \n Replicating the Resource \n A server usually depends on a resource, typically a database. When replicating a server, an important consid-\neration is whether to replicate the server’s resource too. The most widely-used  approach to replication is to \nreplicate the resource (i.e., the database) in addition to the server that manages it (see  Figure 9.2 ). This has two \nbeneﬁ ts. First, it enables the system to recover from a failure of a resource replica as well as a failure of a server \nprocess. And second, by increasing the number of copies of the resource, it offers performance beneﬁ ts when \naccess to the resource is the bottleneck. For example, the backup can do real work, such as process queries, and \nnot just maintain the backup replica so it can take over when there is a failure. \n The main technical challenge in implementing this approach to replication is to synchronize updates \nwith queries and each other when these operations execute on different replicas. This approach of replicating \nresources, and its associated technical challenges, is the main subject of this chapter, covered in Sections 9.3 \nthrough 9.6. \n Replicating the Server with a Shared Resource \n Another approach is to replicate the server without replicating the resource, so that all copies of the server \nshare the same copy of the resource (see  Figure 9.3 ). This is useful in a conﬁ guration where processors share \nPrimary\nServer\nBackup\nServer\nClient\nResource\nReplicas\nResource\nReplicas\n FIGURE 9.2 \n Replicating a Server and Its Resource. Both the server and the resource are replicated, which enables recovery from a \nresource failure. \n9.2 Replicated Servers  247\n\n\n248  CHAPTER 9 Replication\nstorage, such as a storage area network. In a primary-backup conﬁ guration, if the primary fails and the resource \nis still available, the backup server on another processor can continue to provide service (see  Figure 9.3a ). \n This primary-backup approach improves availability, but not performance. If the server is the bottleneck and \nnot the resource, then performance can be improved by allowing multiple servers to access the resource concur-\nrently, as shown in  Figure 9.3b . This approach, often called  data sharing , introduces the problem of conﬂ icts \nbetween transactions that execute in different servers and read and write the same data item in the resource. One \nsolution is to partition the resource and assign each partition to one server. That way, each server can treat the \npartition as a private resource and therefore use standard locking and recovery algorithms. If a server fails, its par-\ntition is assigned to another server, like in the primary-backup approach. Another solution is to allow more than \none server to access the same data item. This solution requires synchronization between servers and is discussed \nin Section 9.7. \n 9.3  SYNCHRONIZING UPDATES TO REPLICATED DATA \n One-Copy Serializability \n On possible goal of replication is to have replicas behave functionally like nonreplicated servers. This goal can \nbe stated precisely by the concept of one-copy serializability, which extends the concept of serializability to a \nsystem where multiple replicas are present. An execution is  one-copy serializable if it has the same effect as \na serial execution on a one-copy database. We would like a system to ensure that its executions are one-copy \nserializable. In such a system, the user is unaware that data is replicated. \n In a system that produces serializable executions, what can go wrong that would cause it to violate one-\ncopy serializability? The answer is simple, though perhaps not obvious: a transaction might read a copy of a \ndata item, say  x , that was not written by the last transaction that wrote other copies of  x . For example, consider \na system that has two copies of  x , stored at locations A and B, denoted  x A and  x B . Suppose we express execu-\ntion histories using the notation of Section 6.1, where  r ,  w , and  c represent read, write, and commit operations, \nrespectively, and subscripts are transaction identiﬁ ers. Consider the following execution history: \n H\nr [\n] w [\n] w [\n] c  r [\n] w [\n] c  r [\n] w [\n] w\nA\nA\nB\nB\nB\nA\nA\n\u0003\n1\n1\n1\n1\n2\n2\n2\n3\n3\nx\nx\nx\nx\nx\nx\nx\n3\n3\n[\n] c  \nB\nx\n \nPrimary\nServer\nBackup\nServer\nClient\nResource\na. Primary and backup share the resource\nb. Many servers concurrently share the resource\nServer1\nServern\nServer2\nClient\nResource\n FIGURE 9.3 \n Replicated Server with Shared Resource. In (a), the primary and backup server share the resource, but only one of them \nuses the resource at any given time. In (b), many servers share the resource and can concurrently process requests \nthat require access to the resource. \n\n\n This is a serial execution. Each transaction reads just one copy of  x ; since the copies are supposed to be iden-\ntical, any copy will do. The only difﬁ culty with it is that transaction T 2 did not write into copy  x A . This might \nhave happened because copy  x A was unavailable when T 2 executed. Rather than delaying the execution of T 2 \nuntil after  x A recovered, the system allowed T 2 to ﬁ nish and commit. Since we see r 3 [ x A ] executed after c 2 , appar-\nently  x A recovered before T 3 started. However, r 3 [ x A ] read a stale value of  x A , the one written by T 1 , not T 2 . \n When  x A recovered, it should have been refreshed with the newly updated value of  x that is stored in  x B . \nHowever, we do not see a write operation into  x A after T 2 committed and before r 3 [ x A ] executed. We therefore \nconclude that when r 3 [ x A ] executed,  x A still had the value that T 1 wrote. \n Clearly , the behavior of H is not what we would expect in a one-copy database. In a one-copy database, T 3 \nwould read the value of  x written by T 2 , not T 1 . There is no other serial execution of T 1 , T 2 , and T 3 that has the \nsame effect as H. Therefore, H does not have the same effect as any serial execution on a one-copy database. \nThus, it is not one-copy serializable. \n One obvious implication of one-copy serializability is that each transaction that writes into a data item  x \nshould write into all copies of  x . However, when replication is used for improved availability, this isn’t always \npossible. The whole point is to be able to continue to operate even when some copies are unavailable. Therefore, \nthe not-so-obvious implication of one-copy serializability is that each transaction that reads a data item  x must \nread a copy of  x that was written by the most recent transaction before it that wrote into any copy of  x . This \nsometimes requires careful synchronization. \n Still , during normal operation, each transaction’s updates should be applied to all replicas. There are two ways \nto arrange this: replicate update operations or replicate requests. In the ﬁ rst case, each request causes one transac-\ntion to execute. That transaction generates update operations, each of which is applied to all replicas. In the sec-\nond case, the request message is sent to all replicas and causes a separate transaction to execute at each replica. \nWe discuss each case, in turn. \n Replicating Updates \n There are two approaches to sending a transaction’s updates to replicas: synchronous and asynchronous. In the \n synchronous approach, when a transaction updates a data item, say  x , the update is sent to all replicas of  x . \nThese updates of the replicas execute within the context of the transaction. This is called synchronous because \nall replicas are, in effect, updated at the same time (see  Figure 9.4a ). Although sometimes this is feasible, often \nX1\nX2\nX3\nX1\nX2\nX3\nT:  Start\n \n…\n \nWrite(x1)\n \nWrite(x2)\n \nWrite(x3)\n \n…\n \nCommit\nT:  Start\n \n…\n \nWrite(x1)\n \n…\n \nCommit\nSometime later:\n \nWrite(x2)\n \nWrite(x3)\na. Synchronous replication\nb. Asynchronous replication\n FIGURE 9.4 \n Synchronous vs. Asynchronous Replication. In synchronous replication, each transaction updates all copies at the same \ntime. In asynchronous replication, a transaction updates only one replica immediately. Its updates are propagated to the \nother replicas later. \n9.3 Synchronizing Updates to Replicated Data  249\n\n\n250  CHAPTER 9 Replication\nit is not, because it produces a heavy distributed transaction load. In particular, it implies that all transactions \nthat update replicated data have to use two-phase commit, which entails signiﬁ cant communications cost. \n Fortunately , looser synchronization can be used, which allows replicas to be updated independently. This is \ncalled  asynchronous replication, where a transaction directly updates one replica and the update is propagated \nto other replicas later (see  Figure 9.4b ). \n Asynchronous updates from different transactions can conﬂ ict. If they are applied to replicas in arbitrary \norders, then the replicas will not be identical. For example, suppose transactions T 1 and T 2 update  x , which has \ncopies  x A and  x B . If T 1 updates  x A before T 2 , but T 1 updates  x B after T 2 , then  x A and  x B end up with different val-\nues. The usual way to avoid this problem is to ensure that the updates are applied in the same order to all replicas. \nBy executing updates in the same order, all replicas go through the same sequence of states. Thus, each query (i.e., \nread-only transaction) at any replica sees a state that could have been seen at any other replica. And if new updates \nwere shut off and all in-ﬂ ight updates were applied to all replicas, the replicas  would be identical. Therefore, users \nworking with one replica see the same behavior that they would see with any other replica. In this sense, all repli-\ncas behave exactly the same way. \n Applying updates in the same order to all replicas requires some synchronization. This synchronization can \ndegrade performance, because some operations are delayed until other operations have time to complete. Much \nof the complexity in replication comes from clever synchronization techniques that minimize this performance \ndegradation. \n Whether synchronous or asynchronous replication is used, applying updates to all replicas is sometimes \nimpossible, because some replicas are down. The system could stop accepting updates when this happens, but \nthis is rarely acceptable since it decreases availability. If some replicas do continue processing updates while \nother replicas are down, then when the down replicas recover, some additional work is needed to recover the \nfailed replicas to a satisfactory state. Some of the complexity in replication comes from ways of coping with \nunavailable servers and handling their recovery. \n Replicas can be down either because a system has failed or because communication has failed (see  Figure \n9.5 ). The latter is more dangerous, because it may lead to two or more independently functioning partitions \nof the network, each of which allows updates to the replicas it knows about. If a resource has replicas in both \nReplica 1\nReplica 2\nReplica 3\na. Replica 3 fails\nReplica 1\nReplica 2\nReplica 3\nb. Network connection\n \nto Replica 3 fails\n FIGURE 9.5 \n Node and Communications Failures. Replica 1, Replica 2, and Replica 3 are connected by a network. In (a), Replica 3 \nfails. In (b), the connection to Replica 3 fails. Replica 1 and Replica 2 cannot distinguish these two situations, yet the \nsystem’s behavior is quite different. \n\n\npartitions, those replicas can be independently updated. When the partitions are reunited, they may discover \nthey have processed incompatible updates. For example, they might both have sold the last item from inven-\ntory. Such executions are not one-copy serializable, since it could not be the result of a serial execution on a \none-copy database. There are two solutions to this problem. One is to ensure that if a partition occurs, only one \npartition is allowed to process updates. The other is to allow multiple partitions to process updates and to rec-\noncile the inconsistencies after the partitions are reunited — something that often requires human intervention. \n Circumventing these performance and availability problems usually involves compromises. To conﬁ gure a \nsystem with replicated servers, one must understand the behavior of the algorithms used for update propaga-\ntion and synchronization. These algorithms are the main subject of this chapter. \n Replicating Requests \n An alternative to sending updates to all replicas is to send the  requests to run the original transactions to all \nreplicas (see  Figure 9.6 ). To ensure that all the replicas end up as exact copies of each other, the transactions \nshould execute in the same order at all replicas. Depending on the approach selected, this is either slow or \ntricky. A slow approach is to run the requests serially at one replica and then force the requests to run in the \nsame order as the other replicas. This ensures they run in the same order at all replicas, but it allows no concur-\nrency at each replica and therefore would be an inefﬁ cient use of each replica’s resources. \n The trickier approach is to allow concurrency within each replica and use some fancy synchronization \nacross replicas to ensure that timing differences at the different replicas don’t lead to different execution orders \nat different replicas. For example, in HP’s Reliable Transaction Router (RTR), a replicated request can be exe-\ncuted at two or more replicas concurrently as a single distributed transaction. Since it runs as a transaction, it is \nserialized with respect to other replicated requests (which also run as transactions). It therefore can execute con-\ncurrently with other requests. Transaction synchronization (e.g., locking) ensures that the requests are processed \nin the same order at all replicas. As usual, transaction termination is synchronized using two-phase commit. \nHowever, unlike ordinary two-phase commit, if one of the replicas fails while a transaction is being committed, \nPrimary\nServer\nBackup\nServer\nRequest\nReplicator\nRequest\nRequest\nResource\nReplica\nResource\nReplica\n FIGURE 9.6 \n Replicating Requests. Each transaction runs independently against each replica. In both cases, conﬂ icting updates must \nbe applied in the same order against all replicas. \n9.3 Synchronizing Updates to Replicated Data  251\n\n\n252  CHAPTER 9 Replication\nthe other continues running and commits the transaction. This is useful in certain applications, such as securi-\nties trading (e.g., stock markets), where the legal deﬁ nition of fairness dictates that transactions must execute in \nthe order they were submitted, so it is undesirable to abort a transaction due to the failure of a replica. \n Replicating updates is a more popular approach than replicating requests, by far. Therefore, we will focus \non that approach for the rest of this chapter. \n 9.4  SINGLE-MASTER PRIMARY-COPY REPLICATION \n Normal Operation \n The most straightforward, and often pragmatic, approach to replication is to designate one replica as the pri-\nmary copy and to allow update transactions to read and write only that replica. This is the primary-backup \ntechnique illustrated in  Figure 9.1 . Updates on the primary are distributed to other replicas, called  secondaries , \nin the order in which they executed at the primary and are applied to secondaries in that order (see  Figure 9.7 ). \nThus, all replicas process the same stream of updates in the same order. In between any two update transactions, \na replica can process a local query. \n One way to propagate updates is by synchronous replication. For example, in a relational database sys-\ntem, one could deﬁ ne an SQL trigger on the primary table that remotely updates secondary copies of the table \nwithin the context of the user’s update transaction. This implies that updates are propagated right away, which \nmay delay the completion of the transaction. It also means that administrators cannot control when updates \nare applied to replicas. For example, in some decision support systems, it is desirable to apply updates at ﬁ xed \ntimes, so the database remains unchanged when certain analysis work is in progress. \n Currently , the more popular approach is asynchronous replication, where updates to the primary gener-\nate a stream of updates to the secondaries, which is processed after transactions on the primary commit. For \ndatabase systems, the stream of updates is often a log. The log reﬂ ects the exact order of the updates that were \nperformed at the primary, so the updates can be applied directly to each secondary as they arrive. \n One application of primary-copy replication is  database mirroring , where there are only two replicas, one \nprimary and one secondary. This is a hot backup technique for high availability. Among the ﬁ rst general-purpose \nSecondary\nT1\nT2\nTn\nSecondary\nSecondary\nPrimary\nReplica\nUpdate\nTransactions\nUpdate Logs\n FIGURE 9.7 \n Propagating Updates from Primary to Secondaries. Transactions update data only at the primary replica. The primary \npropagates updates to the secondary replicas. The secondaries can process local queries. \n\n\nsystems to do this were IBM’s IMS/XRF and Tandem’s (now HP’s) Non-Stop SQL database systems. Now most \ndatabase systems offer a database mirroring feature. \n With database mirroring, the primary sends its database log to the secondary. The secondary continually runs \nlog-based recovery, so that its database state is very close to that of the primary. If the primary fails, the second-\nary just needs to ﬁ nish processing the tail of the log it received before the primary failed, after which it can take \nover as primary. If synchronous replication is used, then no transactions are lost in this failover. With asynchro-\nnous replication, the secondary may not have received the last few updates from the primary. This problem can \nbe mitigated if the primary and secondary are colocated and the secondary can be given access to the primary \ncopy’s disk log. In that case, after the secondary is given control, it can read the disk log to pick up the last few \nlog records that it did not receive before the primary failed. \n Another application of primary-copy replication is to produce queryable copies of parts of a database. This \nis a functionally-rich  feature that is offered by most relational database products. In this case, there is no real-\ntime requirement to move the log records immediately to the secondary copy, so there is time to postprocess \nupdates from the primary copy in various ways. \n Some relational database systems capture updates to each primary table in a log table that is colocated with \nthe primary table (see  Figure 9.8b ). One approach is to have the system deﬁ ne an SQL trigger on each primary \ntable that translates each update into an insert on the log table. Periodically, the primary creates a new log table \nto capture updates and sends the previous log table to each secondary where it is applied to the replica. This \napproach to capturing updates can slow down normal processing of transactions, due to the extra work introduced \nby the trigger. \n Another approach is to postprocess the database log to create the stream of updates to the replicas. If this is done \non-line while the log is still in main memory, then it avoids slowing down normal processing of transactions as \ncompared to the trigger approach. In fact, the log can be sent to a different server, where the postprocessing is done. \n Since the log can be quite large, one reason to postprocess the log is to reduce its size if possible. One \ntechnique is to ﬁ lter out aborted transactions, since they do not need to be applied to replicas (see  Figure 9.8a ). \nDatabase\nsystem’s\nlog\nDatabase\nsystem’s\nlog\nData\nTrigger\nDatabase\nLog\ntable\nFilter aborted\ntransactions\nto \nreplicas\nRead log\ntable\nDatabase\nDatabase system\nTransaction\nupdates\nDatabase system\na. Propagating updates from the\n   database system’s log\nb. Propagating updates from a log \n    table generated by database triggers\nto \nreplicas\nTransaction\nupdates\n FIGURE 9.8 \n Generating Update Streams for Replicas. An update stream for replicas can be produced from (a) the database system’s \nlog or (b) a log table produced by triggers. \n9.4 Single-Master Primary-Copy Replication  253\n\n\n254  CHAPTER 9 Replication\nThis reduces the amount of data transmission and the cost of processing updates at the replica. However, it \nrequires that the primary not send a log record until it knows that the transaction that wrote the record has com-\nmitted. This introduces additional processing time at the primary and delay in updating the secondary, which \nare the main costs of reducing the data transmission. Another technique is to send only the ﬁ nest granularity \ndata that has changed, e.g., ﬁ elds of records, rather than coarser-grain units of data, such as entire records. \n Another reason to postprocess the log is to group together the updates of each transaction. This is beneﬁ -\ncial because it enables transactions to be applied to secondaries serially. After each transaction is applied, the \nsecondary database is in a consistent state. Therefore a query can read a consistent database state without using \nread locks. If updates were not grouped by transaction, then in order for queries to read a consistent state, \nupdates would have to set write locks and queries would have to set read locks. \n Some systems allow different parts of the database to be replicated to different locations. For example, the \nprimary might contain a table describing customers and other tables describing orders. These tables are colo-\ncated at the primary, since many transactions require access to all of these tables. However, the customer table \nmay be replicated at different servers than the order tables. To enable this, the log postprocessing splits each \ntransaction’s updates into two transactions, one for the customer table and one for the order tables, and adds \nthem to separate streams, one for the customer replicas and one for the order replicas. If there is also a replica \nthat contains all the customer and orders information, then the log postprocessor would generate a third stream \nfor that replica, with all the updates of each transaction packaged in a single transaction in the stream. \n Given this complex ﬁ ltering and transaction splitting, often a  “ buffer database ” is used to store updates that \nﬂ ow from the primary to secondaries. Updates that are destined for different replicas are stored in different \nareas of the buffer database. This allows them to be applied to replicas according to different schedules. \n Some systems allow application-speciﬁ c logic to be used to apply changes to replicas. For example, the \napplication could add a timestamp that tells exactly when the update was applied to the replica. \n Although primary-copy replication normally does not allow transactions to update a secondary before updating \nthe primary, there are situations where it can be made to work. For example, consider an update transaction that \nreads and writes a replica using two-phase locking. Suppose it keeps a copy of all the values that it read, which \nincludes all the data items that the transaction wrote. When it is ready to commit, it sends the values of data items \nthat it read along with values that it wrote to the primary. Executing within the context of the same transaction, the \nprimary reads the same data items that the transaction read at the secondary, setting locks as in normal two-phase \nlocking. If the values of the data items that it reads at the primary are the same as those that the transaction read at \nthe secondary, then the transaction applies its updates to the primary too, and commits. If not, then it aborts. This \nis essentially an application of the optimistic concurrency control technique described in Section 6.8. \n Most database systems offer considerable ﬂ exibility in conﬁ guring replication. Subsets of tables can be inde-\npendently replicated, possibly at different locations. For example, a central ofﬁ ce’s Accounts table can be split by \nbranch, and the accounts for each branch are replicated at the system at that branch. As the number of replicated \ntables grows, it can be rather daunting to keep track of which pieces of which tables are replicated at which sys-\ntems. To simplify management tasks, systems offer tools for displaying, querying, and editing the conﬁ guration \nof replicas. \n The replication services of most database systems work by constructing a log stream or log table of updates \nand sending it to secondary servers. This approach was introduced in Tandem’s (now HP’s) Non-Stop SQL and \nin Digital’s VAX Data Distributor in the 1980s. Similar approaches currently are offered by IBM, Informix (now \nIBM), Microsoft (SQL Server), MySQL, Oracle, and Sybase. Within this general approach, products vary in \nthe speciﬁ c features they offer: the granularity of data that can be replicated (a database, a table, a portion of a \ntable); the ﬂ exibility of selecting primaries and secondaries (a server can be a primary server for some data and \na secondary for others); how dynamically the conﬁ guration of primaries and secondaries can be changed; the \noptions for ﬁ ltering updates and splitting transactions; and facilities to simplify managing a large set of replicas. \n\n\n Failures and Recoveries \n This primary-copy approach works well as long as the primary and secondaries are alive. How do we handle \nfailures? Let us work through the cases. \n Secondary Recovery \n If a secondary replica fails, the rest of the system continues to run as before. When the secondary recovers, it \nneeds to catch up processing the stream of updates from the primary. This is not much different than the process-\ning it would have done if it had not failed; it’s just processing the updates later. The main new problem is that \nit must determine which updates it processed before it failed, so it doesn’t incorrectly reapply non-idempotent \n updates. This is the same problem as log-based database recovery that we studied in Chapter 7. \n If a secondary is down for too long, it may be more efﬁ cient to get a whole new copy of the database rather \nthan processing an update stream. In this case, while the database is being copied from the primary to the \nrecovering secondary, more updates are generated at the primary. So after the database has been copied, to ﬁ n-\nish up, the secondary needs to process that last stream of updates coming from the primary. This is similar to \nmedia recovery, as described in Chapter 7. \n Primary Recovery with One Secondary \n If the primary fails, recovery can be more challenging. One could simply disallow updates until the primary \nrecovers. This is a satisfactory approach when the main goal of replication is better performance for queries. In \nfact, it may be hard to avoid this approach if complex ﬁ ltering and partitioning of updates is supported. Since \ndifferent secondaries receive a different subset of the changes that were applied to the primary, secondaries are \noften not complete copies of the primary. Therefore, it would be difﬁ cult to determine which secondaries should \ntake over as primary for which parts of the primary’s data. \n If a goal of replication is improved availability for updates, then it is usually not satisfactory to wait for the \nprimary to recover, since the primary could be down for awhile. So if it is important to keep the system running, \nsome secondary must take over as primary. This leads to two technical problems. First, all replicas must agree \non the selection of the new primary, since the system cannot tolerate having two primaries — this would lead to \ntotal confusion and incorrect results. Second, the last few updates from the failed primary may not have reached \nall replicas. If a replica starts processing updates from the new primary before it has received all updates from \nthe failed primary, it will end up in a different state than other replicas that did receive all the failed primary’s \nupdates. \n We ﬁ rst explore these problems in a simple case of two replicas, one primary and one secondary. Suppose \nthe secondary detects that the primary has failed. This failure detection must be based on timeouts. For exam-\nple, the secondary is no longer receiving log records from the primary. And when the secondary sends  “ are \nyou there? ” messages to the primary, the secondary receives no reply from the primary. However, these time-\nouts may be due to a communications failure between the primary and secondary, similar to the one shown in \n Figure 9.7 , and the primary may still be operating. \n To distinguish between a primary failure and a primary-secondary communications failure, an external agent \nis needed to decide which replica should be primary. A typical approach is to add a  “ watchdog ” process, pref-\nerably on a different machine than the primary and secondary. The watchdog sends periodic  “ are you there? ” \nmessages to both the primary and secondary. There are four cases to consider (see  Figure 9.9 ): \n 1.  If the watchdog can communicate with the primary and not with the secondary, then it tells the primary \nof this fact. If the primary can communicate with the secondary, then no action is needed. If not, then \nthe primary creates another secondary, if possible. \n9.4 Single-Master Primary-Copy Replication  255\n\n\n256  CHAPTER 9 Replication\n 2.  If the watchdog can communicate with both the primary and secondary, but they cannot communicate \nwith each other, then they notify the watchdog of this fact. The watchdog then tells the secondary to fail, \nsince it can no longer function as a replica. It also tells the primary to create another secondary, if possible. \n 3.  If the watchdog can communicate only with the secondary, then it tells the secondary that it believes the \nprimary is down. If the secondary can communicate with the primary, then no action is needed. If not, \nthen it can take over as primary. In this case, if the primary is still operational but is simply unable to com-\nmunicate with the watchdog, then the primary must self-destruct. Otherwise, the old primary and the new \nprimary (which was formerly the secondary) are both operating as primary. It may therefore be advisable \nthat the watchdog send a message to tell the primary to self-destruct, in case the primary is able to receive \nmessages from the watchdog but its replies are not getting through. In summary, if the secondary loses \ncommunications with the primary, then whichever replica can still communicate with the watchdog is \nnow the primary. \n 4.  If neither replica can communicate with the watchdog or with each other, then neither replica can operate \nas the primary. This is called a  total failure . \n Suppose that the primary did indeed fail and the secondary has been designated to be the new primary. Now \nwe face the second problem: the new primary may not have received all the committed updates performed by \nthe former primary before the former primary failed. One solution to this problem is to have the primary delay \ncommitting a transaction’s updates until it knows that the secondary received those updates. The primary could \nwait until the secondary has stored those updates in stable storage, or it could wait only until the secondary has \nreceived the updates in main memory. If the system that stores the secondary has battery backup, then the latter \nmight be reliable enough. In either case, we’re back to synchronous replication, where the updates to the replica \nare included as part of the transaction. This extra round of commit-time messages between the primary and sec-\nondary is essentially a simple two-phase commit protocol. The performance degradation from these messages \ncan be signiﬁ cant. The choice between performance (asynchronous replication) and reliability (synchronous \nreplication) depends on the application and system conﬁ guration. Therefore, database products that offer data-\nbase mirroring usually offer both options, so the user can choose on a case-by-case basis. \n Primary Recovery with Multiple Secondaries \n Now let’s look at the more general case where there are multiple secondaries and a secondary detects the failure \nof a primary. There are two ways this could happen. The primary might indeed be down. Or, much worse, there \ncould be a communication failure that partitions the network into independent sets of functioning replicas. \nLegend: \n     W \u0003 watchdog      P \u0003 primary   S \u0003 secondary\n     X  \u0003 broken link    ?  \u0003 possibly broken link       \nP\nS\nW\nP\nS\nW\nP\nS\nW\nP\nS\nW\n?\nX\n?\nCase 4\nCase 3\nCase 2\nCase 1\nX\n FIGURE 9.9 \n Failure Cases with a Watchdog. A watchdog process can help sort out failure cases between a primary and secondary. \n\n\nIn the latter case the primary could still be operational, so the set of replicas that doesn’t include the primary \nmust not promote one of the secondaries to be a primary. The same problem can arise even in the ﬁ rst case \nwhere the primary is down. In this case, we do want to promote one of the secondaries to become primary. But \nif there are two independent sets of replicas that are operating, each set might independently promote a second-\nary to be the primary, a situation that we want to avoid. \n To solve this problem, we need a decision criterion by which at most one set of replicas has an operational pri-\nmary. We need an algorithm by which replicas can reach this decision. And after the replicas have chosen a new \nprimary, we need an algorithm by which they can recover to the latest state before accepting new transactions. \nThe next three sections treat each of these problems in turn. \n Majority and Quorum Consensus \n One simple way to ensure that only one primary exists is to statically declare one replica to be the primary. If \nthe network partitions, the partition that has the primary is the one that can process updates. This is a feasible \napproach, but it is useless if the goal is high availability. If the primary is down, each partition has to assume \nthe worst, which is that the primary really is running but not communicating with this partition. Thus, neither \npartition promotes a secondary to become primary. \n A more ﬂ exible algorithm for determining which partition can have the primary is called  majority consensus : \na set of replicas is allowed to have a primary if and only if the set includes a majority of the replicas (see  Figure \n9.10 ). Since a majority is more than half, only one set of replicas can have a majority. Moreover, each partition \ncan independently ﬁ gure out if it has a majority. These are the two critical properties of majorities that make the \ntechnique work. \n Majority consensus is a generalization of the watchdog technique we described for database mirroring. The \nwatchdog adds a third process to the mix. Two communicating processes comprise a majority. Thus, whichever \npartition has at least two communicating processes is allowed to have the primary: either the existing primary \nand secondary if the watchdog is down; or the watchdog plus whichever replica(s) it can communicate with. \nBy convention, if the watchdog can communicate with the primary and secondary but the latter cannot com-\nmunicate with each other, then the secondary is told to fail. \n Majority consensus does have one annoying problem: it does not work well when there is an even number \nof copies. In particular, it is useless when there are just two replicas, since the only majority of two is two; that \nis, it can operate only when both replicas are available. When there are four replicas, a majority needs at least \nthree, so if the network splits into two groups of two copies, neither group can have a primary. \nReplica\nReplica\nReplica\nReplica\nReplica\nReplica\nPartition 1\nPartition 2\n FIGURE 9.10 \n Majority Consensus. Partition 1 has a majority of the replicas and therefore is allowed to process updates. Partition 2 \nmay not process updates. \n9.4 Single-Master Primary-Copy Replication  257\n\n\n258  CHAPTER 9 Replication\n A fancier approach is the  quorum consensus algorithm. It gives a  weight to each replica and looks for a \nset of replicas with a majority of the weight, called a  quorum (see  Figure 9.11 ). For example, with two repli-\ncas, we could give a weight of two to the more reliable replica and a weight of one to the other. That way, the \nreplica with a weight of two can be primary even if the other replica is unavailable. Giving a weight of two to \nthe most reliable replica helps whenever there is an even number of replicas. If the network partitions into two \ngroups with the same number of copies, the group with the replica of weight two still has a quorum. \n Reaching Consensus \n During normal operation, the set of operational replicas must agree on which replicas are up and which are \ndown or unreachable. If a replica loses communication with one or more other replicas, then the operational \nreplicas need to reassess whether they still have a majority. (For the purpose of this discussion, we’ll assume \nmajority consensus, not quorum consensus.) In fact, the nonoperational replicas that are up also need to do this \nwhen they reestablish communications with a replica, since this replica may be the one they need to reach a \nmajority. After some group of replicas is established as having a majority, that group can choose a primary and \nensure that all replicas in the group have the most up-to-date state. \n To discuss the details, we need some terminology: The  replica set is the set of all replicas, including those \nthat are up and down; the  current conﬁ guration is the set of operational replicas that are able to communicate \nwith each other and comprise a majority. \n An algorithm that enables a set of processes to reach a common decision is called a  consensus algorithm . \nIn this case, that common decision is agreement on the current conﬁ guration by a set of operational repli-\ncas. Given our problem context, we’ll call the participants replicas instead of processes. But the algorithm we \ndescribe works for general consensus, not just for deciding on the current conﬁ guration. \n One problem with such consensus algorithms is that multiple replicas may be trying to drive a common deci-\nsion at the same time. It’s important that different replicas don’t drive the replicas toward different decisions. \n Another problem is that the system may be unstable, with replicas and communications links failing and \nrecovering while replicas are trying to reach consensus. There’s not much hope in reaching consensus during \nsuch unstable periods. However, once the system stabilizes, we do want the algorithm to reach consensus quickly. \nReplica\nweight \u0003 2\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nPartition 1\nPartition 2\n FIGURE 9.11 \n Quorum Consensus. Partition 1 has a total weight of 4, which is more than half of the total weight of 7. It therefore \nconstitutes a quorum and is allowed to process updates. \n\n\n There are several variations of algorithms to reach consensus, but they all have a common theme, namely, \nthat there’s a unique identiﬁ er associated with the consensus, that these identiﬁ ers are totally ordered, and that \nthe highest unique identiﬁ er wins. We will call that identiﬁ er an  epoch number . It identiﬁ es a period of time, \ncalled an  epoch , during which a set of replicas have agreed on the current conﬁ guration, called an  epoch set . An \nepoch number can be constructed by concatenating a counter value with the unique replica identiﬁ er of the rep-\nlica that generated the epoch number. Each replica keeps track of the current epoch number  e in stable storage. \n During stable periods, the epoch set with largest epoch number is the current conﬁ guration. During unsta-\nble periods, the actual current conﬁ guration may differ from the current epoch set. The goal of the consensus \nalgorithm is to reach agreement on a new epoch set with associated epoch number that accurately describes the \ncurrent conﬁ guration. \n Suppose a replica R is part of the current conﬁ guration, which has epoch number  e 1 . If R detects that the \ncurrent conﬁ guration is no longer valid (because R has detected a failure or recovery), R becomes the leader of \na new execution of the consensus algorithm, which proceeds as follows: \n 1.  R generates a new epoch number  e 2 that is bigger than  e 1 . For example, it increments the counter value \npart of  e 1 by one and concatenates it with R’s replica identiﬁ er. \n 2.  R sends an  invitation message containing the value  e 2 to all replicas in the replica set. \n 3.  When a replica R \u0002 receives the invitation, it replies to R with an  accept message if R \u0002 has not accepted \nanother invitation with an epoch number bigger than  e 2 . R \u0002 includes its current epoch number in the \naccept message. Moreover, if R \u0002 was the leader of another instance of the consensus algorithm (which \nis using a smaller epoch number), it stops that execution. Otherwise, if R \u0002 has accepted an invitation \nwith an epoch number bigger than  e 2 , it sends a  reject message to R. As a courtesy, it may return the \nlargest epoch number of any invitation it has previously accepted. \n 4.  R waits for its timeout period to expire, to ensure it receives as many replies as possible. \n a.  If R receives accept messages from at least one less than a majority of replicas in the replica set, \nthen it has established a majority (including itself) and therefore has reached consensus. It therefore \nsends a  new epoch message to all the accepting replicas and stops. The new epoch message con-\ntains the new epoch number and epoch set. When a replica receives a new epoch message, it updates \nits epoch number and the associated list of replicas in the epoch set and writes it to stable storage. \n b.  Otherwise, R has failed to reach a majority and stops. \n Let ’s consider the execution of this algorithm under several scenarios. First, assume that only one leader R \nis running this algorithm. Then it will either receive enough accept messages to establish a majority and hence \na new epoch set, or it will fail to reach a majority. \n Suppose a leader R 1 fails to establish an epoch set. One reason this could happen is that R 1 may be unable \nto communicate with enough replicas to establish a majority. In this case, R 1 periodically could attempt to re-\nexecute  the algorithm, in case a replica or communication link has silently recovered and thereby made it pos-\nsible for R 1 to form a majority. \n A second reason that R 1 may fail to establish an epoch set is that another replica R 2 is concurrently trying to \ncreate a new epoch set using a higher epoch number. In this case, it is important that R 1 not rerun the algorithm \nright away with a larger epoch number, since this might kill R 2 ’s chance of getting a majority of acceptances. \nThat is, it might turn into an  “ arms race, ” where each replica reruns the algorithm with successively higher epoch \nnumbers and thereby causes the other replica’s consensus algorithm to fail. \n The arms race problem notwithstanding, if R 1 fails to establish an epoch set and, after waiting awhile, \nreceives no other invitations to join an epoch set with higher epoch number, then it may choose to start another \n9.4 Single-Master Primary-Copy Replication  259\n\n\n260  CHAPTER 9 Replication\nround of the consensus algorithm. In the previous round, if it received a reject message with a higher epoch \nnumber  e 3 , then it can increase its chances of reaching consensus by using an epoch number even higher than \n e 3 . This ensures that any replica that is still waiting for the result of the execution with epoch number  e 3 will \nabandon waiting and choose the new, higher epoch number instead. \n Establishing the Latest State \n After the current conﬁ guration has been established as the epoch set, the primary needs to be selected and all \nthe replicas in the current conﬁ guration have to be brought up to date. The ﬁ rst step is to determine if the new \nepoch set includes the primary from the previous epoch. To do this, ﬁ rst observe that since every epoch set has \na majority, it overlaps every earlier epoch set. Therefore, there is at least one replica in the new epoch set from \nthe previous epoch set and it has the largest epoch number less than the new epoch number. If one of the rep-\nlicas with the largest previous epoch number was the primary of that epoch set, then we can simplify recovery \nby reusing it as the primary of the new epoch set. \n Unfortunately , this may not be right, because the last epoch may not have stabilized before it lost its major-\nity and had to reconﬁ gure. If that happened, then the primary of the previous epoch set may not have the latest \nstate. That is, the previous epoch set may have elected the primary but not yet refreshed the new primary’s state \nto be the latest state known to all replicas in the epoch set. To avoid this outcome, the new epoch set needs to \nidentify the last  stable epoch set. This can be done by having each epoch use a state bit that it sets after it has \nstabilized and ensured that every replica in the replica set has the latest state. Only then can the epoch set accept \nnew work. \n Therefore , the new epoch set should determine if it includes the primary of the last stable epoch set. If so, \nthen it knows that this primary has the most up-to-date state. So to resume normal processing, the primary \nneeds to ensure the secondaries are up to date by determining the state of each secondary and sending it what-\never updates it is missing. It then sets the epoch’s state bit to stable and broadcasts that to all secondaries. \n If the epoch set does not include the primary from the previous epoch, then a new primary must be selected. \nThe choice of primary may be based on the amount of spare capacity on its machine (since a primary con-\nsumes more resources than a secondary) and on whether it was a member of the most recent epoch set and thus \nhas the latest or a very recent state (so that it can recover quickly and start accepting new requests). \n The latest state of the secondaries that are still alive can be determined by comparing the sequence numbers \nof the last message received by each secondary from the previous primary. The one with highest sequence num-\nber has the latest state and can forward the tail of its update sequence to other secondaries that need it. After a \nreplica receives that state, it acknowledges that fact to the primary. After the new primary receives acknowledg-\nments from all replicas in the epoch set, it can set the epoch’s state to stable and start processing new transac-\ntions. The new primary should then start off with a message sequence number greater than that of the largest \nreceived by any secondary in the previous epoch. \n Does the new epoch set actually have the latest state? To answer this question, let C be the set of replicas that \nwere in both the previous epoch and the new one. Since each epoch set has a majority of the replicas, C must \ninclude at least one replica. The replicas in C are the only ones that might know the latest state. However, as in \nthe case of database mirroring, it’s possible that none of them actually do know the latest state, due to the delay in \npropagating updates from the primary to the replicas. For example, suppose the epoch set for epoch 1 had repli-\ncas P, S 1 , and S 2 , with P as the primary. Suppose the last transaction was committed by P and S 1 , but not S 2 . Then \nthey all died, and epoch set 2 was formed, consisting of replicas S 2 , S 3 , and S 4 . Epoch sets 1 and 2 overlap by one \nreplica, S 2 , but S 2 doesn’t have the latest state. \n We encountered this problem when considering secondary recovery for database mirroring. The solution \nwe offered was to propagate updates synchronously. In that case, two-phase commit is needed. This ensures \n\n\nthat every replica in C has all the committed updates. However, the last few updates might be in their uncer-\ntainty periods and hence blocked. Thus, while synchronous replication reduces the number of transactions that \nmight be lost when a secondary takes over as primary, it doesn’t close the gap entirely. \n Consistency, Availability, and Partition-Tolerance \n In distributed systems, there is an inherent tradeoff between data consistency, system availability, and tolerance \nto network partitions. A system can offer any two of these three properties, but not all three of them. This is \nknown as the  CAP conjecture . \n The primary-copy approach with synchronous replication ensures data consistency and partition-tolerance, \nand therefore gives up on availability in some cases. It attains data consistency by writing updates to replicas \nas part of the transaction that performed the write and using two-phase commit for transaction atomicity. It \nattains partition-tolerance by using quorum consensus to ensure that there are not two partitions that are both \nable to run transactions. This leads to a loss of availability in the case where the network partitions, because \nsome operational replicas are not part of the quorum. Therefore, even though they are up and running, they are \nnot available. \n Suppose the network partitions and the partition that has a quorum of replicas does not include the former \nprimary. Although the system can ensure the updates are permitted only on the quorum of copies, it cannot guar-\nantee consistency because the last few transactions that executed at the former primary may not have arrived at \nany of the replicas in the quorum before the network partition occurred. Thus, a decision to allow updates to the \nquorum of replicas is trading off consistency for availability. A decision to disallow updates to the quorum of \nreplicas is making the opposite tradeoff, namely, trading off availability in order to ensure consistency. \n Another aspect of this tradeoff is eventual consistency versus instantaneous consistency. Asynchronous \nreplication ensures eventual consistency but gives up on instantaneous consistency, since there may be a long \ndelay before updates are propagated to some replicas. The weaker level of consistency improves performance \nby avoiding two-phase commit. It may also improve availability, by allowing a user to be redirected from one \nreplica to another in a slightly different state. \n For example, suppose an on-line shopper has started populating her shopping basket and the shopping bas-\nket is replicated using primary-copy replication. Suppose the primary fails and is not present in the quorum. To \nmaximize availability, the system could service read requests using another replica while the replicas are being \nbrought up to date. Thus, during this period, the shopper might be given an older state of his or her shopping \ncart. This may occur even if the last update to the cart is known to the quorum, because the shopper’s reads are \nbeing serviced by a slightly out-of-date replica. This may be confusing, especially since the shopping cart will \nreturn to the latest state after the replicas are brought up to date. However, if the probability of this occurrence \nis sufﬁ ciently low, this loss of consistency may be regarded as a better tradeoff than having the shopping cart \nbe unavailable while the replicas are being brought up to date. \n A different set of tradeoffs between consistency, availability, and partition-tolerance is offered by multi-\nmaster replication. We will consider these tradeoffs at the end of the next section. \n 9.5  MULTIMASTER REPLICATION \n Partitioned Operation Can Be Useful \n Rather than being the result of a communication failure, a partition is sometimes a planned event that happens \nfrequently. For example, a laptop computer might be connected to the network only periodically. It could contain \n9.5 Multimaster Replication  261\n",
      "page_number": 262
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 280-292)",
      "start_page": 280,
      "end_page": 292,
      "detection_method": "topic_boundary",
      "content": "262  CHAPTER 9 Replication\na replica of a database, whose primary resides on a reliable server. When the laptop computer is disconnected, \nit might still be important that it process updates. For example, consider a laptop that contains a sales database \nand is used by a sales person. Its database might have a customer table (rarely updated), an orders table (insert-\nmostly), and a sales-call table (append-only). Even when the laptop is disconnected from the network, the sales \nperson must be able to create an order and change basic customer information, such as address and phone num-\nber. In this case, it is not satisfactory to require that only the partition with a quorum of replicas be operative. \nIndeed, if there are many sales people, there probably is no partition with a quorum of replicas, yet all sales \npeople need to be allowed to update their replicas. \n Update Propagation with Multiple Masters \n Despite the partition, we could try using the same primary-copy scheme as in the previous section, but allow update \ntransactions to execute at any replica. Each replica logs its updates, as if it were a primary copy. When a replica R \nreconnects to the network, it sends its logged updates to the real primary that resides on a reliable server, which can \nprocess the updates and forward them to other replicas. R can also ask the primary for updates that occurred while \nit was disconnected. \n One problem with this scheme is conﬂ icting updates that originate at different replicas. For example, in \n Figure 9.12 , each transaction executes at a replica. Its updates are applied ﬁ rst to the replica where it executes: \ntransaction T 1 updates  x at replica R 1 and T 2 updates  x at replica R 2 . Each replica sends its update to the pri-\nmary, which forwards it to the other replica. In the end, these conﬂ icting updates are applied in different orders \nby different replicas, so the resulting replicas are not identical. \n One way to avoid this problem is to design the applications so that most updates do not conﬂ ict. Such updates \ncan be applied in different orders by different replicas and still produce the same ﬁ nal state at all replicas. For \nexample, in the sales database, a sales person appends a row to the sales-call table every time the sales person \ninteracts with a customer. This row is unique for each such interaction, so two rows generated by different sales \npeople cannot conﬂ ict; they may refer to the same customer, but they describe different interactions. The orders \ntable is also insert-mostly. Each insertion of a new order produces a new row in the order table. With careful \nReplica R1\nInitially, x\u00030\nT1: x\u00031\nSend (x\u00031)\nReceive (x\u00032)\nx\u00032\nPrimary\nInitially, x\u00030\nReplica R2\nInitially, x\u00030\nT2: x\u00032\nSend (x\u00032)\nReceive (x\u00031)\nx\u00031\nReceive (x\u00032)\nx\u00032\nSend (x\u00032)\nReceive (x\u00031)\nx\u00031\nSend (x\u00031)\n FIGURE 9.12 \n Conﬂ icting Updates Originating at Different Replicas. The updates to  x are applied in different orders by replicas R 1 and \nR 2 , so the resulting replicas are not identical. \n\n\ndesign, these insertions do not conﬂ ict. For example, to ensure insertions do not conﬂ ict, the insertion of a new \norder must not require reading previous orders; for example, to check that the new order is not a duplicate. \n If conﬂ icts can occur, then there are several problems to be solved: (1) detecting the conﬂ icts, (2) resolving \nthe conﬂ icts in the same way at all replicas, and (3) ensuring that replicas eventually converge to be identi-\ncal. One approach to these problems is to tag each update with a unique timestamp. Unique timestamps can \nbe constructed by concatenating the replica’s local clock time with its unique replica identiﬁ er, so timestamps \ngenerated at different replicas cannot be identical. Each data item at a replica also is tagged with a timestamp. \nUpdates are applied using  Thomas ’ Write Rule as follows [Thomas 79] (see  Figure 9.13 ): If an update to \ndata item  x arrives at a replica, and the update’s timestamp is larger than  x ’s timestamp at the replica, then the \nupdate is applied and  x ’ s timestamp is replaced by the update’s timestamp. Otherwise, the update is discarded. \n Thomas ’ Write Rule addresses these three problems. It detects a conﬂ ict when an update to a data item \narrives at a replica with an update timestamp lower than the replica’s timestamp on that data item. It resolves \nthe conﬂ ict by retaining the value that has the larger timestamp . And eventually, each data item  x has the same \nvalue at all replicas, because at every replica, the update to  x with the largest timestamp is the last one that \nactually was applied. \n The deletion of a data item needs to be handled like any other update, to ensure it is not reinserted by an \nupdate with a smaller timestamp that arrives after the deletion was processed. That is, a deleted data item must \nstill be known to the replica and have a timestamp that was written by the delete operation, but its value is \n “ deleted. ” This value is usually called a  tombstone . \n Thomas ’ Write Rule does not require that clocks be exactly synchronized. However, if the clock at one rep-\nlica is fast, then its updates will have larger timestamps than updates concurrently generated by other replicas. In \nconﬂ ict situations, the update with the larger timestamp wins, so the replica with a fast clock has an unfair advan-\ntage. For this reason, it is beneﬁ cial to keep the clocks nearly synchronized when using Thomas ’ Write Rule. \n Nonblind Updates \n Thomas ’ Write Rule works ﬁ ne for  blind updates , which are updates that replace the value of a data item with \na new value that does not depend on any data that the transaction previously read. We just saw two examples: \nrecording a sales call and inserting a new order. Another example is storing a customer’s phone number. In this \nupdate x, timestamp =\n128976, value = “ghi” \na. The update has smaller timestamp\n \nthan the database’s timestamp of x,\n \nso it should not be applied\nb. The update has larger timestamp\n \nthan the database’s timestamp of x,\n \nso it should be applied\nX\nTimestamp\nValue\n128965\n“abc”\nTimestamp\nValue\n128965\n“abc”\nX\nupdate x, timestamp =\n128944, value = “def”\n FIGURE 9.13 \n Thomas ’ Write Rule. An update to a data item  x is applied only if its timestamp is larger than the one in the database. \n9.5 Multimaster Replication  263\n\n\n264  CHAPTER 9 Replication\ncase, two updates by different transactions that store a new phone number for the same customer conﬂ ict, and \nif they write different phone numbers then the execution order certainly matters. However, since the updates \nwere submitted concurrently, either execution order is satisfactory as long as all replicas reﬂ ect the same exe-\ncution order. Thomas ’ Write Rule solves this problem by ensuring that the ﬁ nal value at all replicas is the one \nwritten by the update with the higher timestamp. \n If the updates are not blind, then Thomas ’ Write Rule isn’t a completely satisfactory solution, because it \ndoesn’t diagnose that one update depends on another one. For example, consider  Figure 9.14 , which is similar \nto  Figure 9.12 except that the transactions increment  x instead of performing blind updates to  x , and they use \nThomas ’ Write Rule. Each value of  x is represented by a [value, timestamp] pair. Initially,  x  \u0003  0 at the primary \nand replicas and the associated timestamp (ts) is 5. Since transaction timestamps are guaranteed to be unique, \nT 1 and T 2 update  x with different timestamps, namely 6 and 7, respectively. The updates are concurrent in the \nsense that neither T 1 nor T 2 reads the value of  x written by the other. Since T 2 has the larger timestamp, its \nvalue is the one that sticks at all three copies. However, the increment operation by T 1 is lost, which is prob-\nably not what is desired. The execution is not one-copy serializable, since a serial execution of the two transac-\ntions (in either order) on a one-copy database would produce a ﬁ nal value of  x  \u0003  3. The problem is that the \nnature of the conﬂ ict between T 1 and T 2 was not diagnosed. The system simply retained the update with larger \ntimestamp as if both updates were blind, which they were not. \n With multimaster replication, situations like  Figure 9.14 are unavoidable. That is, in general it’s possible \nfor two conﬂ icting transactions to update different copies of the same data item independently at different rep-\nlicas, such that neither transaction reads the other transaction’s updated value. \n The way multimaster replication is used can greatly affect the probability of such conﬂ icts. For example, \nwhen multimaster replication is used to support disconnected operation, such as laptops that are intermittently \nconnected to the network, replicas can run for long periods without exchanging updates. The longer a replica \nexecutes transactions without exchanging its updates with other replicas, the greater the chance that reconcilia-\ntion will be needed. That is, if updates are exchanged frequently, then the chances are better that an update will \nbe propagated to all replicas before a transaction with a conﬂ icting update executes, thereby avoiding the need \nfor reconciliation. \nReplica R1\nInitially, x \u0003 [0, ts\u00035]\nT1: x \u0003 x \u0005 1(ts\u00036)\nSend (x \u0003 [1, ts\u00036])\nReceive (x \u0003 [2, ts\u00037])\nx \u0003 [2, ts\u00037]\nReplica R2\nInitially, x \u0003 [0, ts\u00035]\nT2: x \u0003 x \u0005 2 (ts\u00037)\nSend (x \u0003 [2, ts\u00037])\nReceive (x \u0003 [1, ts\u00036])\nThomas’ Write Rule says\ndon’t update x,\nso x is still [2, ts\u00037]\nPrimary\nInitially, x \u0003 [0, ts\u00035]\nReceive (x \u0003 [1, ts\u00036])\nx \u0003 [1, ts\u00036]\nSend (x \u0003 [1, ts\u00036])\nReceive (x \u0003 [2, ts\u00037])\nx \u0003 [2, ts\u00037]\nSend (x \u0003 [2, ts\u00037])\n FIGURE 9.14 \n Conﬂ icting Nonblind Updates. Thomas ’ Write Rule ensures that  x  \u0003  2 at all replicas, but T 1 ’s update is lost (ts is an \nabbreviation for timestamp). \n\n\n When such a conﬂ ict occurs, Thomas ’ Write Rule makes a rather arbitrary choice by applying the one with \nlarger timestamp and discarding the other one. In a variation of the rule, instead of discarding the one with \nsmaller timestamp, the system can save it. The saved update can then be examined later by a person who deter-\nmines whether it needs to be reconsidered or merged into the primary somehow. \n Detecting Replication Conﬂ icts Using Version Vectors \n Instead of requiring manual reconsideration of the saved update in all cases, we want to distinguish between \nreal conﬂ icts where reconciliation is required and fake conﬂ icts where a value really should be overwritten by \na later update. We can do this using a technique called version vectors. \n To explain the use of version vectors, we need the concept of version that was introduced in Section 6.6. \nRecall that a  version of a data item  x is the value of  x written by a particular transaction. That is, each transac-\ntion that updates  x produces a new version of  x . We introduced this notion in the context of multiversion data-\nbases, where the database retains all or most of the versions produced by different transactions. Here, we will \ntypically retain only one version of a data item. However, we nevertheless need to refer to different versions of \na data item because after a data item is updated, different replicas will store different versions during the period \nthat the update is being propagated between replicas. \n To distinguish between real and fake conﬂ icts, we need precise deﬁ nitions of them. Given two versions  x i \nand  x k of  x , we say that  x i  precedes  x k (written  x i  →  x k ) if there is a sequence of transactions, each of which \nupdates  x , such that \n ■  The ﬁ rst transaction in the sequence reads and overwrites  x i . \n ■  Starting with the second transaction in the sequence, each transaction reads and overwrites the version of \n x produced by the previous transaction in the sequence. \n ■  The last transaction in the sequence produces version  x k . \n If  x i does not precede  x k and  x k does not precede  x i then we say that  x i and  x k have a  replication conﬂ ict \n(i.e., a  “ real ” conﬂ ict). If the database started with one version of  x , then the presence of a replication conﬂ ict \nimplies there is some version of  x that was overwritten independently by two transactions that did not see each \nother’s output. This is the essence of the kind of conﬂ ict exhibited by transactions T 1 and T 2 in  Figure 9.14 . \nIf two versions of  x are related by the precedes relation, then it’s a fake conﬂ ict, since the later version clearly \nshould replace the earlier one. \n The version vector technique enables us to detect replication conﬂ icts between versions. It requires that \neach replica maintain an update count. When a transaction updates a data item  x for the ﬁ rst time, it associates \nits local replica ID and current update count with this new version of  x , and the update count for the replica \nis incremented by one. The pair [replica id, update count] uniquely identiﬁ es the version and is called a  ver-\nsion ID . For example, if the current update count for replica R is 8 and the replica runs a transaction T that \nﬁ rst updates data item  x and then updates  y , then T associates version ID [R, 8] with  x and [R, 9] with  y . If T \nupdates  x or  y a second time, the version IDs of  x and  y associated with T needn’t be changed. Since each rep-\nlica has a unique replica ID, each version ID is unique too. By convention, we use the version ID of a data item \nto uniquely identify the ﬁ nal value (not any intermediate values) written by a transaction into that data item. \n To track which versions each replica R has received, R maintains an array of version IDs, called a  version \nvector , with one entry in the array for each replica. Each entry in the version vector tells which updates R has \nreceived and processed from every other replica. Entry [R i , c] in the version vector says that R has received all \nupdates generated by R i with version IDs [R i , 1], [R i , 2],  … , [R i , c]. R’s version vector includes an entry for its \nown latest version ID. \n9.5 Multimaster Replication  265\n\n\n266  CHAPTER 9 Replication\n In addition to maintaining a version vector for each replica, we also maintain a version ID and version vec-\ntor for each data item at the replica. This per-data-item information is used to detect replication conﬂ icts. The \nversion ID and version vector for a data item  x is updated when a transaction executing at replica R updates  x . \nAfter a transaction T executing at R updates a data item  x for the ﬁ rst time, it replaces  x ’s version ID by R’s \nversion ID, it replaces R’s position in  x ’s version vector by R’s current version ID, and R increments its version \nID. This records the fact that T generated a new version of  x at replica R. For example, if T executes at replica \nR 1 , R 1 ’s current update count is 14, and T updates  x , then T replaces  x ’s version ID with [R 1 , 14], T replaces the \nversion ID formerly in  x ’s version vector, say [R 1 , c], by [R 1 , 14], and R increments its update count. It must be \nthat c  \u000b 14, because [R 1 , 14] is the largest version ID that R 1 has generated so far. \n When replica S (the sender) sends its updated version v of  x to another replica R (the receiver), it includes \nthe version ID and version vector along with the value. The version vector tells R which updates were applied \nto  x before v was generated. This gives R enough information to determine whether R’s own version of  x has a \nreplication conﬂ ict with v, and hence whether it should replace its own version by v. \n To see how conﬂ ict detection works, suppose that the updated version of  x that S sends to R has version ID \n[S, 10] and version vector [[S,10], [R, 4]]. Suppose that when R receives the updated version, its value of  x has \nversion ID [R, 5] and version vector [[S, 9], [R, 5]]. In this case, we have a replication conﬂ ict. How can R tell? \nThe version vector [[S,10], [R, 4]] sent by S tells R that S did not receive R’s updated version [R, 5] before S exe-\ncuted the update that wrote version [S, 10]. On the other hand, R’s version vector [[S, 9], [R, 5]] for  x tells R that \nR did not receive S’s updated version [S, 10] before it executed update [R, 5]. Since neither S nor R saw the other \nreplica’s updated version of  x before it executed its latest update, R deduces that there is a replication conﬂ ict. \n We will explain some general approaches to detecting replication conﬂ icts shortly. But ﬁ rst, we describe two \nother mechanisms that are needed in a complete system, namely, conﬂ ict resolution and update propagation. \n Conﬂ ict Resolution \n In the previous example, a simple way for R to deal with the conﬂ ict is for it to retain both values of  x — the \none it already has and the one it just received from S, with the associated version IDs and version vectors. \nA later conﬂ ict resolution process can determine how to reconcile these two values. This is necessarily an \napplication-speciﬁ c process because it depends on knowing (or assuming) something about the semantics of \nthe transactions that conﬂ icted. For example, if the conﬂ ict resolver knows that transactions originating at R \nincrement  x by one as opposed to doing a blind write of  x , then it can add one to the value of  x produced by the \nother transaction to generate a new ﬁ nal value. \n The replication system can help a little bit by allowing an application to register one or more merge pro-\ncedures for each data item, which can then be invoked automatically when multiple values are stored for that \nitem. Alternatively, the two versions of  x can be retained and given to the next transaction that reads  x , which \nthen has to determine the correct value of  x . In any case, the solution is a matter of application programming. \n If the resolution executes as a transaction, then its result propagates to other replicas as a normal updated \nversion. If it propagates fast enough, this avoids the need to execute the resolution procedure at other replicas. \n Maintaining the Version Vector \n Now let us see how to propagate recently written versions and maintain the per-replica version vector. Suppose \nthat when a replica S sends updated versions to a replica R, S sends all updated versions of all data items that \nit hasn’t previously sent to R. In that case, at the end of the update transfer from S to R, if R has received an \nupdated version with version ID [S, 10] from S, then R knows it has received all updated versions from S with \nversion ID [S, c] for c  \u0006 10. \n\n\n S needs to send to R not only the updated versions from transactions that S executed since the last time \nit synchronized with R, but also updated versions that S received from other replicas, such as R \u0002 . R may not \nhave received those updated versions and indeed may never have the opportunity to synchronize with R \u0002 . For \nexample, S may be a server that is always on the network, and R and R \u0002 are portable machines on different \ncontinents that are rarely if ever connected to the network at the same time. \n This logic about S’s version IDs sent by S to R applies to R \u0002 too. That is, if S sends an updated version to \nR with version ID [R \u0002 , 5], then at the end of the transfer from S to R, R must also have received all of R \u0002 ’ s \nupdated versions with version IDs less than 5. This observation holds even if S received R \u0002 ’ s updated versions \nindirectly via other replicas, because every replica along the path from R \u0002 to S sent all the updated versions it \nreceived earlier from other replicas. That is, R \u0002 sent all of its updated versions with version IDs less than or \nequal to [R \u0002 , 5] to replica R \t , which sent them to R \u0002 \u0002 \u0002 , and so on, until they reached S, which in turn sent them \nto R. We can summarize this argument as the following invariant. \n Version ID invariant : If replica R received an updated version with version ID [R i , c] and there are no \ntransfers to R in progress, then R received all updated versions generated by R i with version ID [R i , c \u0002 ] for \nall c \u0002  \u0006 c. \n The version ID invariant implies that R can use a single version ID to summarize which updates it has \nreceived from each replica. For example, R can use version ID [R \u0002 , 5] to summarize the fact that R has received \nall updated versions generated by replica R \u0002 with version IDs [R \u0002 , 1] through [R \u0002 , 5]. By doing this for all repli-\ncas, R is maintaining a version vector. \n Therefore , after R has processed all the updates it received from S, R should merge S’s version vector with \nits own, thereby reﬂ ecting the fact that R’s state now includes all updates that are known to S. This involves \nusing the maximum count for each entry in the two version vectors. For example, if the R i entry in the version \nvectors for S and R are [R i , c] and [R i , c \u0002 ], respectively, then R should replace c \u0002 by the maximum of c and c \u0002 . \n S need not send updated versions that it knows were overwritten. For example, if S executed two or more \ntransactions that updated data item  x , S needs to send to R only its last updated version of  x . There is no point in \nsending the earlier updated versions to R because they will be overwritten by later updated versions to  x sent by \nS to R. \n Given this observation, we have to modify our earlier explanation of the meaning of version vectors. We \nsaid that an entry [R i , c] in the version vector for replica R means that R has received all updates generated by \nR i with version IDs [R i , 1], [R i , 2],  … , [R i , c]. However, this isn’t true if overwritten versions are not propa-\ngated. Hence, we have to weaken the statement to say that entry [R i , c] in R’s version vector is the largest ver-\nsion ID of any update that was generated by R i and received by R. Moreover, R’s state is the same as if it had \nreceived all the versions in the sequence [R i , 1],  … , [R i , c]. \n When two replicas decide to exchange updates, each one needs to ﬁ gure out which updates to send to the \nother replica. Version ID’s are helpful for this purpose. When replica R wants to receive recent updates from \nreplica S, R sends its current version vector to S. Now S runs a query against its local database that retrieves \nevery version whose version ID is greater than the corresponding version ID in R’s version vector and sends \nthese updates to R. For example, if R’s version vector has an entry [R 1 , 10], then S should send all data items \nwhose version ID is [R 1 , b] where b  \f  10. \n Version Vector Update Rules \n As a prelude to presenting update rules based on version vectors, we need a few more deﬁ nitions. To simplify \nthings a bit, let us assume that there are  n replicas named R 1 through R n . This enables us to represent a version \n9.5 Multimaster Replication  267\n\n\n268  CHAPTER 9 Replication\nvector by a sequence of  n integers, where entry  i in the vector is the count for replica R i . For example, a version \nvector [[R 1 , 7], [R 2 , 3], [R 3 , 10], [R 4 , 7]] would be represented by [7, 3, 10, 7]. \n We say that a version vector V  dominates another version vector V \u0002 if the elements of V and V \u0002 cover the \nsame set of replica ID’s and for every index position  i , V[ i ]  \n V \u0002 [ i ]. For example, if there are three replicas, \nthen version vector [3, 4, 4] dominates [2, 4, 3] and [3, 4, 3]. If V  \u0002 V \u0002 and neither dominates the other, then we \nsay V and V \u0002 are  incomparable . For example, version vector [3, 4, 4] is incomparable to [2, 4, 5] and [2, 4]. \n Now that we have the complete picture, let’s look at the rules for applying updates, which we call the  version \nvector-based update rules . First, let us recall the rule for running a transaction: \n VV1. Suppose a transaction T executes at replica R, which has update counter value c, and T updates data item \n x . Then T replaces  x ’s version ID by [R, c], it sets the R position in  x ’s version vector to c, and it incre-\nments R’s update counter by 1. \n Suppose a version of  x moves from replica S to replica R. More precisely, suppose R receives an updated \nversion  x s of some data item  x from replica S, where \n ■  The updated version  x s has version ID [R i , c] and version vector V S  \u0003  [s 1 ,  … , s n ], and \n ■  R’s stored version  x r of  x has version ID [R k , d] and version vector V R  \u0003  [r 1 ,  … , r n ]. \n Note that R i and R k may be different from both R and S. R processes the update from S as follows: \n VV2. If V R dominates V S , then R discards the updated version  x s sent by S. In effect, this says that  x r should \noverwrite  x s , but since  x r arrived at R before  x s , R simply discards  x s . \n VV3. If V S dominates V R , then R replaces its version  x r by  x s , along with version ID [R i , c] and version vector \n[s 1 ,  … , s n ]. \n VV4. If V R and V S are incomparable, then there’s a conﬂ ict and conﬂ ict resolution is needed. If R resolves the \nconﬂ ict, then the version that R generates by its conﬂ ict resolution procedure has a version vector that’s the \nmerge of the version vectors of the conﬂ icting versions (i.e., taking the maximum count for each entry in \nthe two version vectors), except for the position corresponding to R, which has the version ID of the new \nversion generated by R. \n As explained in the previous section, after R has processed all the updates it received from S, R should \nmerge S’s version vector with its own. \n The goal of the rules is to ensure that if a version  x 2 overwrites another version  x 1 , then  x 1  →  x 2 . Clearly, if \na transaction executes according to VV1 or VV4 and overwrites  x 1 by  x 2 , then  x 1  →  x 2 . The more interesting \ncases are VV2 and VV3. \n In VV2 and VV3, the decisions are governed by version vector dominance. Consider VV2. If V R domi-\nnates V S , then every vector position of V R is greater than or equal to the corresponding position of V S . The \nonly way to create a version vector is to execute a transaction using VV1 or VV4. Each transaction modiﬁ es a \nversion vector by increasing one of the elements in the vector. Therefore, the only way that V R can come into \nexistence is that starting with V S , there must be a sequence of transactions that generates successive version \nvectors where each one updates the version of  x generated by the previous one and where the last transaction \nin the sequence generates V R . By deﬁ nition of replication conﬂ ict, there are no replication conﬂ icts in this \nsequence. Therefore, if V R dominates V S , then  x s  →  x r , so  x r should be retained and  x s should be discarded. \nThis is exactly what rule VV2 does. A symmetric argument holds for VV3. \n The remaining possibility is VV4, namely that V R does not dominate V S and V S does not dominate V R . In \nthat case V R and V S are incomparable. Thus, there must be elements r a , r b in V R and s a , s b in V S such that r a  \f  s a \nand s b  \f  r b . Since r a  \f  s a , the transaction that produced version [R a , r a ] was in the sequence of transactions that \n\n\nproduced V R but not in the sequence that produced V S , so  x r does not precede  x s . Similarly, since s b  \f  r b , the \ntransaction that produced version [R b , r b ] was in the sequence of transactions that produced V S but was not in \nthe sequence that produced V R , so  x s does not precede  x r . Thus the versions tagged by V R and V S exhibit a repli-\ncation conﬂ ict. \n Simpliﬁ ed Version Vector Update Rules \n Instead of comparing version vectors, it is actually enough to compare version IDs of data items to version \nvectors of replicas, rather than comparing version vectors for dominance. That is, the rules VV2 and VV3 are \nmodiﬁ ed to the following: \n VI2. If r i  \n c, then R discards S’s updated version. \n VI3. If s k  \n d, then R replaces its version of  x by the one sent by S, along with version ID [R i , c] and version \nvector [s 1 ,  … , s n ]. \n As in the previous section, the goal of these rules is to ensure that if a version  x 2 overwrites another version \n x 1 then  x 1  →  x 2 . Since VV1 and VV4 are unchanged, they ensure this goal as before. \n The simplest correctness argument we know of that covers rules VI2 and VI3 involves some fairly subtle \nreasoning. We provide a proof here. However, you can skip the rest of this section without loss of continuity in \nunderstanding the rest of the chapter. \n We say that a version ID v  \u0003  [R i , c]  is in a version vector V if the R i position of V is greater than or equal \nto c. Notice that the test in VI2 of r i  \n c is testing whether version ID [R i , c] is in version vector [r 1 ,  … , r n ]. \nSimilarly, the test in VI3 of s k  \n d is testing whether version ID [R k , d] is in version vector [s 1 ,  … , s n ]. \n Suppose we are given two versions  x 1 and  x 2 of  x that have version IDs v 1 and v 2 and version vectors V 1 \nand V 2 , respectively. We want to show that if VI2 or VI3 overwrites  x 1 with  x 2 , then  x 1  →  x 2 . By the observa-\ntion of the previous paragraph, this is equivalent to showing that if v 1 is in V 2 , then  x 1  →  x 2 . \n First , we restate the deﬁ nition of  → recursively as follows: Given versions  x 1 and  x 2 of  x ,  x 1  →  x 2 if and \nonly if either there exists a transaction T that overwrote version  x 1 with  x 2 or there exists a transaction T and a \nversion  x 3 such that  x 1 →  x 3 and T overwrote  x 3 with  x 2 . \n We say that a version  x i is  made by the replica that executed the transaction that created  x i . We say that  x i is \n made from the version  x j that was held by the replica when it executed the transaction that created  x i . When a rep-\nlica R receives a version  x i from replica S and R replaces its version of  x by  x i , we say that  x i  moved from S to R. \n Now we deﬁ ne a total ordering over the versions. For any version held by a replica R, deﬁ ne its  age to be \nthe number of make and move steps that it took to arrive at this state. For conﬂ ict-resolving makes (according \nto VV4), let its age be one greater than the maximum age over all conﬂ icting versions it is resolving. Our proof \nis by induction on version age, but we will have to strengthen the statement to be proved to make the induction \nstep work: \n For every version  x 2 with version ID v 2 , version vector V 2 , and age c held by replica R, and for every version \n x 1  \u0002  x 2 with version ID v 1 : \n 1.  If v 1 is in V 2 then  x 1 →  x 2 . \n 2.  If  x 1 was made by replica R,  x 1 has age c 1 , and c 1 \u000b c, then  x 1  →  x 2 . In other words, every version made \nby a given replica precedes every version that is later held by that replica. \n Basis step: If age  \u0003  1,  x 2 must have been created from  x 1 by a make step, that is, VV1 or VV4. Clearly, these \nsteps ensure  x 1  →  x 2 , so both (1) and (2) hold. \n9.5 Multimaster Replication  269\n\n\n270  CHAPTER 9 Replication\n Induction step: Suppose  x 2 is held by replica R k and has age c k and v 2  \u0003  [R n , c n ]. Version  x 2 was made from \nsome version  x 3 , possibly resolving a set of conﬂ icting versions, Con. As in the basis step,  x 3  →  x 2 and for \nall versions  x c in Con,  x c  →  x 2 . Observe that V 2 is the merge of the version vector of  x 3 and those of Con, \nplus with c n in n th  position. \n To prove (1), there are two cases: \n a.  x 1 was not made by R n . The transaction that made v 2 only updated position  n of its version vector. \nTherefore, if v 1 is in V 2 , it must be that v 1 is in the version vector of  x 3 or of one of the versions  x c of \nCon. Since all of these versions are younger than  x 2 , by part (1) of the induction hypothesis,  x 1  →  x 3 or \n x 1  →  x c . Since  x 3  →  x 2 and for all versions  x c in Con,  x c  →  x 2 , by transitivity  x 1  →  x 2 . \n b.  x 1 itself was made by R n with an age smaller than c n . Thus, by induction hypothesis part (2),  x 1  →  x 3 , \nand by transitivity  x 1  →  x 2 . \n To prove (2), observe that there are two cases: \n c.  x 2 was made by R k  (in other words, R k   \u0003  R n ). In that case,  x 3  was held by R n  before it made  x 2 , and so \nby induction hypothesis part (2),  x 1   →  x 3 , and we are done by transitivity. \n d.  x 2  moved to R k , overwriting what R k was holding, say  x 4 with version ID v 4 . In this case, according to \nVV 1  and VI 2 , v 4 is in V 2 . Before  x 2 moved, it was younger than it currently is, so we apply part (1) of \nthe induction hypothesis to conclude that  x 4  →  x 2 . But by induction hypothesis part (2),  x 1  →  x 4 , and so \nwe are done by transitivity. \n Example Revisited \n Using these rules, let’s revisit the example of  Figure 9.14 using version vectors instead of timestamps. The result \nis shown in  Figure 9.15 . We rename the primary to be replica R 3 , so we can use the more compact version v ector \nReplica R1\nInitially, x \u0003 [0, [R3,1], [1, 1, 1]]\nT1: x \u0003 x \u0005 1 \nx \u0003 [1, [R1,2], [2, 1, 1]]\nSend (x \u0003 [1, [R1,2], [2, 1, 1]])\nReceive (x \u0003 [2, [R2,2], [1, 2, 1]])\n       x \u0003 {[1, [R1,2], [2, 1, 1]]\n               [2, [R2,2], [1, 2, 1]]}\nReplica R3\nInitially, x \u0003 [0, [R3,1], [1, 1, 1]]\nReceive (x \u0003 [1, [R1,2], [2, 1, 1]])\nx \u0003 [1, [R1,2], [2, 1, 1]]\n Send (x \u0003 [1, [R1,2], [2, 1, 1]])\n Receive (x \u0003 [2, [R2,2], [1, 2, 1]])\n       x \u0003 {[1, [R1,2], [2, 1, 1]]\n                [2, [R2,2], [1, 2, 1]]}\nSend (x \u0003 [2, [R2,2], [1, 2, 1]])\nReplica R2\nInitially, x \u0003 [0, [R3,1], [1, 1, 1]]\nT2: x \u0003 x \u0005 2 \nx \u0003 [2, [R2,2], [1, 2, 1]]\n Send (x \u0003 [2, [R2,2], [1, 2, 1]])\n \n Receive (x \u0003 [1, [R1,2], [2, 1, 1]])\n        x \u0003 {[1, [R1,2], [2, 1, 1]]\n                 [2, [R2,2], [1, 2, 1]]}\n FIGURE 9.15 \n Using Version Vectors to Reconcile Updates. Initially,  x has value 0, produced by version [R 3 ,1] in the state characterized \nby version vector [1, 1, 1]. Since T 1 and T 2 produce incomparable version IDs and version vectors, their updated \nversions conﬂ ict and are retained at all replicas. \n\n\nnotation. The version of  x is now a triple, comprised of a value, a version ID, and a version vector. Initially,  x is \n0 at the three replicas. It was last written by a transaction running at replica R 3 that generated version ID [R 3 , 1] \nafter which its state is summarized by the version vector [1, 1, 1]. The sequence of actions is exactly as before. \nThe interesting cases are when each site receives the second updated version. In each case, the recipient rec-\nognizes that the second updated version’s version ID and version vector are incomparable to the ones it has \nstored, so it detects a replication conﬂ ict and ends in a state containing both conﬂ icting updates. For example, \nconsider replica R 2 when it receives R 1 ’s updated version [1, [R 1 , 2], [2, 1, 1]] from R 3 . R 2 ’s local version of  x \nis [2, [R 2 , 2], [1, 2, 1]]. These versions of  x satisfy VV4, which means there is a replication conﬂ ict: R 2 ’s local \nversion [R 2 , 2] was written without having seen version [R 1 , 2], and the version [R 1 , 2] sent by R 1 was written \nwithout having seen version [R 2 , 2]. \n In this example, it seems like the use of version vectors has only helped a little bit in handling concurrent \nupdates of different replicas of the same data item. It correctly diagnosed the replication conﬂ ict but did not \nfully resolve it. However, there are other cases where the use of version vectors fully resolves the situation. \n For example, consider  Figure 9.16 , which is a variation of the scenario in  Figure 9.15 where R 1 sends its \nupdate by T 1 directly to R 2 in addition to sending it to R 3 . If R 1 ’s updated version arrives at R 2 before R 2 executes \nT 2 , then T 2 will overwrite R 1 ’s updated version of  x . R 3 will recognize this fact when it receives R 2 ’s updated ver-\nsion of  x from R 2 and will replace R 1 ’s version of  x by R 2 ’s updated version. On the other hand, if R 1 ’s updated \nversion arrives at R 2  after R 2 executes T 2 , then T 2 will not overwrite R 1 ’s updated version of  x . R 2 will still send \nthe updated version to R 3 , but in this case R 3 will recognize it as a conﬂ ict. Notice that timestamps alone cannot \nmake this distinction. For example, if T 2 is assigned a larger timestamp than T 1 , then it will always overwrite T 1 ’s \nupdated version at all replicas, whether or not T 2 saw T 1 ’s updated version of  x at the time it executed. \n Although version vectors do identify replication conﬂ icts, they do not ensure one-copy serializability because \nthey detect conﬂ icts only on a single data item, not across two or more data items. For example, suppose the \ndatabase has data items  x and  y that are stored at replicas R 1 and R 2 . Initially,  x has the version [3, [R 1 , 1], [1, 2]] \nand  y has the version [5, [R 2 , 2], [1, 2]] at both replicas. Suppose transaction T 1 at R 1 adds  x and  y and stores the \nresult, 8, into  x with version ID [R 1 , 2]. Suppose transaction T 2 does the same thing, but stores the result, 8, into \n y with version ID [R 2 , 3]. Each of them propagates their updated version to the other replica. According to the \nversion ID-based update rules, each replica will apply the updated version that it receives from the other replica. \nSo the ﬁ nal state at both replicas will have  x  \u0003  [8, [R 1 , 2], [2, 2]] and  y  \u0003  [8, [R 2 , 2], [1, 3]]. However, if the \ntransactions ran on a one-copy database, either the resulting value of  x would be 11 or the resulting value of  y \nwould be 13. So the result is not one-copy serializable. \nR1\nR2\nR3\nT1’s update \nT1’s \nupdate \nT2’s \nupdate \nT1 runs\nat R1\nT2 runs\nat R2\n FIGURE 9.16 \n Diagnosing a Replication Conﬂ ict. Using version vectors, when R 3 receives T 2 ’s update, it can tell whether that update \nran before or after R 2 received T 1 ’s update. \n9.5 Multimaster Replication  271\n\n\n272  CHAPTER 9 Replication\n Consistency, Availability, and Partition-Tolerance Revisited \n At the end of Section 9.4 we introduced the tradeoff between data consistency, system availability, and parti-\ntion-tolerance. We saw that the primary-copy approach with synchronous replication offers data consistency \nand partition-tolerance at the cost of system availability when a partition occurs. With asynchronous replica-\ntion, it improves availability in some cases at the cost of data consistency. \n The multimaster approach with asynchronous replication offers further improvement of availability and \npartition-tolerance but with decreased data consistency. If a replica R is up and running, then R can be read or \nwritten. R need not be part of a quorum of replicas. In fact, even if R is partitioned from the rest of the network, \nit is available. However, there is a cost in data consistency. First, since there is delay in propagating updates to \nreplicas, the system is only eventually consistent, not instantaneously consistent. And second, since transactions \ncan update other replicas concurrently with transactions that update R, there may be replication conﬂ icts. Such \nconﬂ icts represent a loss of data consistency. \n As we saw, these conﬂ icts can be detected in certain cases, at which point an application-speciﬁ c conﬂ ict \nresolution procedure can try to return the data to a consistent state. Still, a conﬂ ict resolution procedure may \nnot be able to make the data perfectly consistent, in the sense that it makes the execution one-copy serializ-\nable. For example, if replicas are used for ﬂ ight reservations, and two replicas ran transactions that sold the last \nseat on a ﬂ ight, then the best that the conﬂ ict resolution procedure can do is run a compensation for one of the \nticket holders. This is not a result that would occur in a one-copy system. \n Microsoft Sync Framework \n As an example of a multimaster replication system that uses version vectors, we consider Microsoft Sync \nFramework, which was introduced in 2007. Like the approach described in this section, it generates a version ID \nfor each update and maintains a version vector for each replica. Like most multimaster implementations, it uses \na number of variations of the basic techniques outlined in this section. We highlight two of them here. First, in \nmost cases it does not attach a version vector to each data item. Instead, it detects replication conﬂ icts using the \nreplica’s version vector (not the data item’s version vector) and modiﬁ ed version ID-based update rules. Second, \nit allows a transfer of updates from one replica to another to be interrupted and resumed at another time. This \nrequires additional modiﬁ cations to the maintenance and use of version vectors. \n Like before, suppose that replica R receives from replica S an updated version of some data item  x with \nversion ID [R i , c] and that R’s version of  x has version ID [R k , d]. At the time R receives the updated version, \nits current version vector is [r 1 ,  … , r n ] and replica S’s current version vector is [s 1 ,  … , s n ]. Then R decides how \nto process the update using the following  modiﬁ ed version ID-based update rules : \n MVI1. If r i  \n c, then discard S’s update. \n MVI2. If s k  \n d, then replace the value of  x at R by the one sent by S, along with version ID [R i , c]. \n MVI3. Otherwise, there is a conﬂ ict and conﬂ ict resolution is needed. \n In the case of MVI3, both values of  x are retained. The value sent by S is stored with its version ID and \nwith S’s version vector [s 1 ,  … , s n ]. Thus, some data items have per-data-item version vectors. But these are \npresumably a small fraction of the data items at the replica. In an application where they are a large fraction \nof the data items, there is a large number of unresolved replication conﬂ icts, which casts doubt on the value of \nusing multimaster replication in this application. \n If a later updated version arrives at R for  x , then when deciding whether to overwrite the stored version, R \nuses the version vector associated with  x rather than R’s version vector. Similarly, if R forwards this updated \nversion of  x to another replica R \u0002 , R forwards it with the version vector associated with  x and R \u0002 uses that ver-\nsion vector when applying the modiﬁ ed version ID-based update rules, not R’s version vector. \n\n\n The surprising fact about the modiﬁ ed version ID-based update rules is that they have the same effect as \nthe original version ID-based rules. \n The second feature of the Microsoft Sync Framework that we discuss is that it allows the transfer of \nupdated versions from replica S to R to be interrupted. Ordinarily, that would cause a problem for R, since \nit may have received an updated version of some data item  x but not some updates on which the version \ndepended. It avoids this problem through a technique similar to conﬂ ict detection. \n To be more precise, if R receives an updated version with version ID [R i , c] for data item  x and the modiﬁ ed \nversion vector-based update rule says to apply the updated version (either overwriting  x or adding a conﬂ icting \nversion of  x ), then R’s state for  x is more up to date for  x than for other data items. If the transfer is interrupted, \nR needs to know that S’s version vector characterizes the state of updates from S that R has applied. These are \ncalled exceptions. Eventually, possibly after several lengthy interruptions, S completes its transfer of updates to \nR. Now R knows that it is not missing any information earlier than S’s version vector. Therefore, any exceptions \nthat it accumulated due to updates it received from R and that are not replication conﬂ icts can be dropped. At \nthat point, S’s version vector can be merged with R’s version vector, as in the normal case. \n Suppose there is a total order over data items; for example, by name or storage address. Then to minimize \nthe number of the exceptions at R, S can send the updated versions to R in data item order. If the transfer is \ninterrupted after R has received items in (say) the range 1 to  m , it can summarize its exceptions by the range \nexception [1, m] and S’s version vector. Clearly, this is a much denser representation than enumerating excep-\ntions for each updated data item that was transferred. \n Given these techniques, a replica has several sources of knowledge about past updates: a per-replica version \nvector and per-data-item version vectors for replication conﬂ icts and for exceptions. When a replica R requests \nrecent changes from another replica S, R sends all this knowledge of its current state to S, so that S can avoid \nsending updates that R already knows about. \n There are several other special techniques used in this system; for example, to garbage collect tombstones, \nto enable replicas to join and leave a system, and to allow different conﬂ ict handlers at different replicas. See \nthe bibliographic notes for articles that describe these and other features. \n 9.6  OTHER REPLICATION TECHNIQUES \n Replication algorithms have been an active area of database research for over three decades. Many algorithms \nhave been published beyond those described here, which are the ones that are primarily used in today’s data-\nbase systems. Some interesting other approaches include: \n ■  Nontransactional replication, based on timestamped updates. That is, each original update executes as an \natomic action outside the context of any transaction. These algorithms often are used for distributed sys-\ntem services, such as a directory service, where multimaster replication is needed but not transactions. \n ■  Quorum consensus applied to every transaction. Each transaction reads a quorum of copies of each data \nitem it accesses, and uses the most up-to-date value among those copies as input. This approach avoids \nelections and other reconﬁ guration algorithms, at the cost of more work for each transaction. It is also \none of the ﬁ rst correct replication algorithms published. \n ■  Read-one-write-all-available, where instead of using a primary copy, each transaction writes to all avail-\nable copies of every data item it updates. One well-known algorithm, called Virtual Partitions, uses this \napproach along with quorum consensus, to ensure a data item is updatable only if the set of connected \nsites have a quorum of copies of that item. \n See the Bibliographic Notes for further reading. \n9.6 Other Replication Techniques  273\n\n\n274  CHAPTER 9 Replication\n 9.7  DATA SHARING SYSTEMS \n A  data sharing system is one where two data manager processes can both access the same database. This is \na case where the server is replicated but not the resource. Data sharing arises in systems where two or more \nmachines have access to the same stable storage devices. In this case, the data managers executing on indepen-\ndent machines have to synchronize their access to shared pages. This usage scenario was made popular in the \n1980s in clustered systems, such as VMScluster. Currently, it arises when multiple machines can access the same \nstorage using a storage area network, such as in Oracle Real Application Clusters and IBM DB2 Data Sharing. \n Another rather different scenario where data sharing arises is mid-tier caching, where two or more mid-\ntier machines cache data that is stored on the same backend data manager. Often, the mid-tier machines cache \nonly static data, in which case there are no special concurrency control or recovery problems. However, if the \nmid-tier machines can update data, then concurrency control problems occur that are similar to those of shared \nstable storage. \n In a data sharing system, it is no longer satisfactory to have the lock manager be local to the data manager, \nbecause a lock that is set by one data manager would not be visible to another server that accesses the same \ndatabase. This changes the locking architecture quite a bit and has some effect on the recovery algorithm. \n Locking \n In a data sharing system, when a data manager process obtains a lock on a data item it must be sure that no other \ndata manager has a conﬂ icting lock. This usually entails the use of a global lock manager that lives outside of the \ndata manager processes that access it. Thus, invocations of lock and unlock operations are usually more expen-\nsive than with an in-process lock manager, due to the expense of a context switch and a message if the lock man-\nager is remote. This expense affects the design of concurrency control algorithms for data sharing. Some systems \ntry to reduce the expense with special hardware or operating system support. Others try to reduce the frequency \nof calls to the global lock manager. \n One way to reduce the number of calls to the global lock manager is to combine it with a local (i.e., in-p rocess) \nlock manager. When a transaction T accesses a data item  x , its data manager S sets a lock at the global lock \nmanager and, if it succeeds, then T sets a lock in the local lock manager. When T commits or aborts, it releases \nits lock on  x at the local lock manager. However, S retains its lock on  x at the global lock manager. This allows \nlater transactions running in S to lock  x using only the local lock manager. \n If a transaction T \u0002 running in another data manager accesses  x , its data manager S \u0002 must lock  x at the global \nlock manager. However, it will be unable to do so if S holds a conﬂ icting lock on  x . There needs to be a proto-\ncol that ensures S will release its lock on  x . One way to do this is via a  call-back from the global lock manager \nto S. That is, if the global lock manager receives a request by S \u0002 to lock  x at a time when S holds a conﬂ icting \nlock, the global lock manager sends a call-back message to S asking it to release the lock. If there is no active \ntransaction in S that is using  x (i.e., that has a local lock on  x ), then S releases the lock on  x at the global lock \nmanager. If there is such a transaction, then S waits until that transaction has completed before releasing its \nlock on  x . If S has other transactions waiting in its local lock manager for the lock on  x , then it’s a policy ques-\ntion as to whether S releases the lock right away at the global lock manager or waits until there are no active \ntransactions in S that are waiting for the lock. \n Caching \n In a data sharing system two data manager processes can have a cached copy of the same data item. So they \nnot only need to synchronize access using locks, but they also need to ensure they see each other’s cached \n",
      "page_number": 280
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 293-301)",
      "start_page": 293,
      "end_page": 301,
      "detection_method": "topic_boundary",
      "content": "updates. For example, in  Figure 9.17 data managers S and S \u0002 both have a cached copy of page P whose per-\nsistent copy resides in a shared database. S sets a lock on P at the global lock manager, executes a transaction \nT 1 that updates record r 1 on page P, and then releases its lock on P. Now S \u0002 sets a lock on P at the global lock \nmanager so that it can run a transaction T 2 that updates a different record r 2 on page P. To ensure that T 1 ’s \nupdate to r 1 does not get lost, it’s essential that T 2 reads the copy of P that was updated by T 1 . This will work \nﬁ ne if S writes P to the shared database on behalf of T 1 before T 1 releases its lock on P. \n Since a transaction needs to be durable, it would seem to be obvious that S must write P to the database \nbefore T 1 commits. However, as we saw in Section 7.8, often this is not done. Instead, T 1 ’s update to r 1 might \nbe written only to a log, without writing P itself to the database. In this case, S does not need to write P on \nbehalf of each transaction, because later transactions that execute in S will access the cached copy of P and \ntherefore are not in danger of losing earlier transactions ’ updates. However, before S releases its lock on P \nat the global lock manager, it needs to ensure that, if another data manager process locks P at the global lock \nmanager, it will access the latest copy of P in the shared database. For example, before releasing its lock on P, \nS can write P to the shared database. An alternative is for S to set a ﬂ ag in the global lock for P that indicates \nit has the latest version of P in cache. When another data manager sets a lock on P, it sees that it should get the \nlatest copy of P from S, not from stable storage. \n Continuing the example, let’s suppose S writes P to the stable database and releases its global lock on P. Data \nmanager S \u0002 gets the global lock on P, reads P from the shared database, runs one or more transactions that update \nP, and eventually writes P back to the shared database and releases its global lock on P. Now, suppose S has \nanother transaction that wants to access page P. So S sets a global lock on P. However, notice that S might still \nhave a copy of P in its cache. If so, it will use its cached copy rather than reading it from the shared database. \nObviously, this would be a mistake since S would ignore the updated value of P that was produced by transac-\ntions running in process S \u0002 . Therefore, even though S has a cached copy of P, it should invalidate this copy and \nreread P from the shared database. \n What if no other process updated page P between the time S released its global lock on P and the time it \nset the lock again? In that case, it’s safe for S to use its cached copy of P. A simple bookkeeping technique can \nenable S to recognize this case. Each page header includes a version number. (An LSN could be used for this \npurpose; see Chapter 7.) The ﬁ rst time that a data manager updates a page P, it increments the version number. \nP\nr1\nData Manager S\nData Manager S\u0002\nP\nP\nShared\nDatabase\nr2\n FIGURE 9.17 \n A Data Sharing System. Page P is stored on disk. Processes S and S \u0002 cache P in their private main memory. \n9.7 Data Sharing Systems  275\n\n\n276  CHAPTER 9 Replication\nWhen it releases the global lock on P, it tells the lock manager the version number of the page. Although the \nlock has been released, the global lock manager retains the lock in its lock table with the associated version \nnumber. When a data manager sets a global lock on the page, the lock manager returns the page’s version num-\nber to the data manager. If the data manager has a cached copy of the page, it can compare this version number \nto that of its cached copy. If they’re the same, then it doesn’t need to reread the page from the shared database. \n Using this version number technique, locks will remain in the lock manager even if no transaction is hold-\ning them. How does a lock disappear from the global lock manager, to avoid having the lock manager become \ncluttered with locks that are no longer being used? This could be done implicitly by a timer. If a lock is not \nowned by any data manager and has been unused for a period of time, then the lock can be deallocated. The \ntime period should be long enough that any page that was unused in a data manager’s cache for that long is \nlikely to have been deallocated. If the lock manager deallocates a lock too soon, then a data manager may \nrequest that lock while it still has the corresponding page in cache. In that case, since the lock manager is \nunable to tell the data manager the version number of the latest version of the page, the data manager needs to \ninvalidate the cached copy of the page and reread it from stable storage. \n Another approach to lock deallocation is to explicitly maintain a reference count of the number of data \nmanagers that have a cached copy of the page corresponding to each lock. When a data manager invalidates a \ncached page, it tells the lock manager to decrement the reference count. There is no urgency to have the lock \nmanager do this decrement, so the data manager could save such calls in a batch and send them to the lock \nmanager periodically. \n Synchronizing shared pages between the caches of different data managers is one of the major costs in a \ndata sharing system. One way to reduce this cost is to reduce the chance that a page needs to be accessed by \ntwo or more data managers. To take an extreme case, the database could be partitioned so that each data man-\nager has exclusive access to one partition and each transaction only accesses data in one partition. Thus, each \ntransaction uses the data manager that manages the partition needed by the transaction. Two data managers \nnever need the same page, so cache synchronization doesn’t arise. \n Of course, if all databases and transaction loads could be partitioned in this way, then the mechanism for \ndynamic cache synchronization would have little value, since each data manager can be assigned a partition \nstatically. However, even if a perfect partitioning isn’t possible, an approximate partitioning may be within \nreach and serve the purpose. That is, each data manager is assigned a partition of the database, but it is allowed \nto access the rest of the database for the occasional transaction that needs data outside the partition. Similarly, \ntransaction types are partitioned so that each transaction gets most, usually all, of its data from one data man-\nager’s partition. Thus, cache synchronization is required only occasionally, since it is relatively unlikely that \ntransactions running in different partitions happen to access the same data page. \n For example, consider the debit-credit transaction workload of TPC-B, discussed in Section 1.5. The data-\nbase could be partitioned by bank branch, so that each branch balance is accessed by at most one data manager. \nBy the nature of the application, tellers are partitioned by bank branch and each account has a home branch. \nSo account records could be organized so that each page has account records with the same home branch. \nEach request takes an account ID, branch ID, and teller ID as input parameters. The branch ID parameter is \nused to send the request to that branch’s data manager. So the branch balance and teller balance for that branch \nare guaranteed to be in that data manager’s cache. Usually this branch ID for the request is the home branch of \nthe account ID, since people do most of their banking at their home branch. In this case, the account informa-\ntion is very unlikely to be in the cache of any other data manager. Occasionally, the account ID is not for the \nhome branch. In this case, the data manager for the branch is accessing a page of accounts all of which are for \nanother branch. There is a nonnegligible probability that this page is in the cache of the data manager of those \naccounts ’ home branch. But it’s still a relatively low probability. Therefore, although cache synchronization for \nsuch cases does happen, it is relatively rare. \n\n\n Logging \n When logging is used for database recovery, there is one log for each database. The log describes the sequence \nof updates that was applied to the database. The recovery algorithm uses this sequence to reconstruct the cor-\nrect database state after a failure, as discussed in Chapter 7. \n In a data sharing system, multiple data managers are updating the database and therefore are writing \nrecords to the end of the same log. One way to implement this log is to have data managers send  “ append-log-\nrecord ” operations to a shared log server process. The append-log-record operation appends the given record \nto the log and returns the LSN (i.e., log address) of the log record being appended. The append operation \nhas a parameter indicating whether the append must be forced to stable storage before returning to the caller. \nSince the log is often a bottleneck that limits transaction throughput, it’s important that the log server be able \nto process append operations at a high rate. Therefore, it may be worthwhile for each data manager to send \na sequence of append operations in each call to the log server, to amortize the cost of calling the log server \nacross multiple operations. \n Another way to implement the log is to allow data mangers to write log pages directly into a shared log \nﬁ le (rather than log records to a shared log server). This is possible because a data sharing system has shared \npersistent storage, some of which can be used for a shared log ﬁ le that is directly accessible to all data manag-\ners. To ensure that the data managers don’t overwrite each others ’ data at the end of the log, a log space server \ncan be used to allocate log space to each data manager. The log space server supports the  “ allocate ” operation, \nwhich returns a range of physical log pages and a range of LSNs that are reserved for the caller. This range of \npages may be written only by the data manager to which they were allocated. So the data manager can write \ninto those log pages directly. It can use a local buffer to collect updates to the log and periodically write that \nbuffer to the log pages that are allocated for it. To simplify the following discussion, we assume that the log \nspace server allocates one log page in response to each call to the allocate operation. \n In the log server approach, a data manager needs to receive the LSN from the log server to complete each \nupdate. By contrast, in this direct writing approach, the data manager has a private pool of LSNs it can use, so \nit can process updates locally. This helps reduce the amount of communications required for interacting with \nthe log and therefore speeds up the processing of writes. \n In both approaches, some care is needed to enforce the write-ahead log protocol. In the log server approach, \neach data manager needs to be told periodically the LSN of the last log record that was written to disk. This \ncan be one of the return values of every append operation. In the direct writing approach, a data manager \nuses the same technique as in a system that does not use data sharing.  That is, before it ﬂ ushes a data page, it \nensures that the log page containing the last update record to that data page has already been ﬂ ushed. \n To commit a transaction, a commit record is written and the tail of the log is forced to stable storage, pos-\nsibly after a short delay for group commit. In the direct writing approach, each log page is written by only one \ndata manager. Hence, there may be more partially ﬁ lled log pages than with the log server approach, where log \nrecords from different data managers can be written to the same log page. \n The ﬁ rst step of a recovery procedure is to ﬁ nd the end of the log. This is a bit more complicated for the \ndirect writing approach than for the log server approach. Using the direct writing approach, the order in which \ndata managers write their log pages may be different than the order in which those pages were allocated. \nTherefore, there may be holes in the sequence at the end of the stable log. For example, if pages  n-1 and  n were \nthe last two log pages that were allocated (to different data managers), it is possible that page  n was written \nbefore the failure but page  n-1 was not. This does not add any cost to the algorithm for ﬁ nding the end of the \nlog, but it does add some algorithmic complexity. \n The ﬁ nal issue relates to transactions that execute in different data managers and update the same data item. \nSome synchronization is needed to ensure that log records for conﬂ icting updates are written to the log in the \n9.7 Data Sharing Systems  277\n\n\n278  CHAPTER 9 Replication\nsame order that the updates themselves executed. With the log server approach, this is automatic, since a data \nmanager does not release a page for use by other data managers until after it has sent its last update record for \nthat page to the log manager. \n By contrast, in the direct writing approach it is possible that the update records can appear out of order. \nFor example, suppose a data manager D writes into page P and appends an update record to its log page, say \npage  n . It ﬂ ushes that log page and then ﬂ ushes P and releases its lock on P, thereby making P available to \nother data managers. The next data manager D \u0002 that updates P might be using a log page that precedes  n and \nhence has smaller LSNs than the LSN written by D. If D \u0002 wrote a smaller LSN on P than the one written by D, \nthat would suggest that the update from D \u0002 had been applied to P but the one from D had not, which is incor-\nrect. Thus, the recovery algorithm could no longer use LSNs to determine which updates had or had not been \napplied to a page before the last failure. \n A simple solution is that when D \u0002 updates P, if it sees that P’s LSN is larger than the largest LSN currently \nallocated to D \u0002 , then it ﬂ ushes the remainder of its allocated log and gets new log pages from the log space \nserver. This incurs an extra log ﬂ ush and increases the likelihood of partially-ﬁ lled  log pages. However, if the \ndatabase is partially partitioned as described at the end of the previous subsection on  Caching , then this type of \nsynchronization will be relatively rare. \n 9.8  SUMMARY \n The main goal of replication is to improve availability, since a service is available even if some of its replicas \nare not. Replication can also improve response time, since the capacity of a set of replicated servers can be \ngreater than the capacity of a single server. \n The most widely-used  approach to replication is to replicate the resource (i.e., the database) in addition to \nthe server that manages it. This requires synchronizing updates with queries and each other when these opera-\ntions execute on different replicas, so that the effects are indistinguishable from a nonreplicated system. The \nsynchronization mechanism must allow for replicas or communications between replicas to be down for long \nperiods. Communication failures are especially troublesome, since noncommunicating replicas may process \nconﬂ icting updates that they are unable to synchronize until after they reconnect. \n One popular approach to replication is to designate one replica as the primary copy and to allow update \ntransactions to originate only at that replica. Updates on the primary are distributed and applied to other repli-\ncas, called secondaries, in the order in which they executed at the primary. Since all replicas process the same \nupdates in the same order, the replicas converge toward the same state as the primary. \n The stream of updates sent from the primary can be quite large, so it is worth minimizing its size by only \nincluding data items that are modiﬁ ed and by ﬁ ltering out aborted transactions. The stream can be generated \nby processing the resource manager’s log or by using triggers to generate the update stream directly from \nupdates on the primary copy. \n An alternative to propagating updates is to send the requests to run the original transactions to all second-\naries and ensure that the transactions execute in the same order at all secondaries and the primary, either by \nphysically running them in that order, which is slow, or synchronizing their execution between primary and \nsecondaries, which can be tricky. \n In any case, when a secondary fails and subsequently recovers, it must catch up processing the updates \nproduced by the primary while it was down. If the primary fails, the remaining secondaries must elect a new \nprimary and ensure it has the most up-to-date view of the updates that executed before the primary failed. \n When a primary or secondary fails, the remaining replicas must check that they have a majority or quorum \nof copies, to ensure that they are the only group of communicating replicas. For if there were two partitions of \n\n\nreplicas that could communicate within the partition but not between partitions, then the two partitions could \nprocess conﬂ icting updates that would be hard to reconcile after the groups were reunited. \n Sometimes partitioning is a planned and frequent event, as with laptop computers that contain replicas but \nare only periodically connected to the network. This requires that every partition be allowed to process updates, \nallowing for multiple masters, not just one primary. Some variation of Thomas ’ write rule often is used for \nthese situations: each data item is tagged by the timestamp of the latest update to it. An update is applied only if \nits timestamp is larger than the data item’s tag in the database. That way, updates can arrive in different orders, \nsometimes with long delays, yet the replicas will all eventually have the same value, namely the one produced \nby using the update with the largest timestamp.  \n The problem with this approach is that an update can be lost if it’s overwritten by another update with larger \ntimestamp that didn’t see the output of the earlier update. One way to avoid this problem is to use version vec-\ntors in place of timestamps. Each version vector tells which updates were received by the replica before pro-\nducing the current version of the data item. This enables more accurate conﬂ ict detection at the cost of more \ninformation attached to each data item. An optimization used in Microsoft Sync Framework avoids this per-\ndata-item version vector in most cases, but still requires version vectors for data items involved in a conﬂ ict or \nreceived out of order. \n The CAP conjecture says that a system can offer at most two of the following three properties: data consis-\ntency, system availability, and tolerance to network partitions. The primary-copy approach with synchronous \nreplication ensures data consistency and partition-tolerance. It gives up on the availability of replicas that are \noutside the quorum. Asynchronous replication gives up on instantaneous consistency, ensuring eventual con-\nsistency instead, which improves availability further in some cases. Multimaster replication offers availability \nand partition-tolerance at the cost of data consistency. \n The primary copy and multimaster algorithms described here are the ones used most widely in practice. \nHowever, since replication has been much studied by database researchers, there are many other published \nalgorithms beyond the ones in this chapter. \n Another form of replication is data sharing, where data manager replicas share access to a common resource, \nsuch as a database. Since two data managers can access the same page of the database, some synchronization \nis needed between the data managers. This is usually done with a global lock manager that is accessible to all \ndata managers. A data manager sets a global lock before operating on a page. If it updates a page, then it ﬂ ushes \nthe page to stable storage before releasing the lock. This ensures the next data manager that reads the page will \nsee the latest version. Synchronization is also needed to enable all the data managers to write to the shared \nlog. This can be done with a global log server. Data managers call the log server to append records to the log. \nAlternatively, a log space server can be used to allocate log pages to each data manager, which can then write to \nthose log pages without further synchronization. \n \n9.8 Summary  279\n\n\nThis page intentionally left blank\n\n\n 10.1  INTRODUCTION \n In this chapter, we’ll survey some popular transactional middleware products and standards, including: \n ■  Current products from Microsoft and Java vendors \n ■  Popular persistence abstractions mechanisms that simplify database access \n ■  Legacy TP monitors, including information on how each product can be reused in a modern system, such \nas a Service Oriented Architecture (SOA)-based application \n ■  Widely-adopted  TP standards \n Trends in Transactional Middleware \n Over the past 20 years, we have seen a continual repackaging of transactional middleware functionality, both \nthe aggregation of components into transactional middleware packages and the decomposition of packages into \nindependently conﬁ gurable components. For example, transaction management is a basic capability in most \ndatabase management systems. It is also offered in enterprise service buses and other products designed for use \nwith an SOA-based application. Some features and functions of front-end programs, request controllers, and \ntransaction servers have migrated from integrated TP monitors and application servers to separate products. \nOthers are migrating into operating systems, such as distributed transaction management. The innovations of \nlarge web sites such as Amazon.com, Google, and eBay have also been inﬂ uential, such as the use of custom \ntransactional middleware components for replicated state management and simple scalable data management. \n The goal of this chapter is to give you a feeling for the state of the art of transactional middleware products \nand some conﬁ dence that the technical issues discussed in this book do give you the necessary background to \nunderstand transactional middleware. A secondary goal is to help you think about which technology is most \nappropriate for your speciﬁ c requirements. \n It is not a goal of this chapter to provide sufﬁ ciently detailed feature comparisons to help you select the \nexact products that best suit your needs. Product features change with each succeeding product release, so we \nrecommend that you evaluate the latest information from a product’s vendor when making such a decision. It is \nalso not a goal to explain each product in enough detail to enable you to use it. In particular, example programs \nare meant only to illustrate each product’s approach, not to be used as a template for developing applications. \n For the most part, when describing each product or technology, we use this book’s terminology rather than \nthat of the product or technology. If you know a given product well, it may seem strange to see it described using \n Transactional Middleware Products \nand Standards \n 10 \nCHAPTER\n\n\n282  CHAPTER 10 Transactional Middleware Products and Standards\n unfamiliar terms. However, for a reader learning about the product for the ﬁ rst time, we hope this approach \nmakes it easier to gain a basic understanding of how the product is structured and what features it offers. \n Transactional Middleware Programming Models \n Today ’s transactional middleware products provide a conﬁ gurable deployment container for application objects. \nThe goal of the container is to reduce complexity by packaging together system capabilities such as transaction \ncontrol, threading, and persistence, and enabling a developer to customize them using conﬁ guration properties. \nDeployment of a transactional object into a container requires a conﬁ guration step to set its properties. This is \nthe approach described in Section 2.2,  Transaction Bracketing in Object-Oriented Programming . Both the .NET \nFramework and Java-based products recommend using container-managed transactions for most applications. \n Container -managed transactions are called the  implicit programming model because an application devel-\noper creates TP programs that incorporate the business logic without describing transactional behavior. This \nsimpliﬁ es programming by not requiring the developer to think about which parts of the code need to run as \ntransactions. It also helps address the transaction composition problem by enabling programs to be composed \nin different combinations without being rewritten. \n In this model, transactional behavior is deﬁ ned in another step, perhaps by another person, using conﬁ gura-\ntion properties. Conﬁ guration properties can be deﬁ ned in a separate ﬁ le associated with the program, as attri-\nbutes embedded within a program and its interface, or as a combination of the two. Sometimes the separate \nconﬁ guration ﬁ le is generated from the embedded attributes. Some technologies allow attributes in a conﬁ gu-\nration ﬁ le to override embedded attributes. Others do not. \n The implicit model is increasingly popular, but there are cases where developers want the ﬂ exibility to \nexpress transactional behavior in the business logic. To meet this need, both the Java-based and .NET-based \ntransactional middleware systems also offer  explicit programming control of transactions. In this model, devel-\nopers use transaction management APIs to explicitly start and end transactions within their objects. \n The explicit programming model adds ﬂ exibility, but usually at the cost of more difﬁ culty in creating and \nmaintaining complex systems. However, whether developers use explicit or implicit transaction control, the \nbehavior of the underlying transactional system remains the same because the execution of the transaction \ncontrol operations relies on the same transactional infrastructure. \n Java EE and the .NET Framework \n Currently , the two primary transactional middleware environments are Java Enterprise Edition-based applica-\ntion servers and Microsoft’s .NET Framework. Both environments provide comprehensive capabilities for creating \nand deploying TP applications. \n In keeping with the ongoing trend to repackage transactional middleware functionality, some TP envi-\nronments use only parts of the Java Enterprise Edition (EE) and .NET Frameworks. Sometimes these parts \nare combined with legacy TP monitors, for example, to modernize an existing application or to enable new \napplications to interoperate with older ones. \n Comparing the Java EE and .NET Framework environments, one obvious difference is platform coverage. \nFor example, Microsoft’s .NET Framework offers a comprehensive and full-featured programming model for \ndeveloping and deploying TP applications, but it is available only on Windows operating systems. A second sig-\nniﬁ cant difference between products is their set of programming interfaces and communication paradigms. For \nexample, .NET Framework APIs differ from Java EE APIs. Although the APIs share many common features, \nthey each offer some unique ones. A third difference is standards conformance. Products typically conform to \nvarious TP standards, but not necessarily to the same ones. \n\n\n We describe the details of the .NET Framework and Java EE in Sections 10.3 and 10.4, respectively. But \nﬁ rst, we discuss technologies for developing front-end programs using web browsers, since they are largely \ncommon to both environments. \n 10.2  WEB BROWSER FRONT-END PROGRAMS \n As described in Chapter 3, a web browser is a common front-end program for TP applications. Most TP applica-\ntions support them directly or can be adapted to support them, so we’ll cover them as a general topic applicable \nto any transactional middleware. \n A web browser requires a web server to handle HTTP requests and replies. In the multitier architecture the \nweb server may directly interact with the database or with one or more intermediate tiers created using transac-\ntional middleware components, as illustrated in  Figure 10.1 . In some cases the database system can function as \na web server. Intermediate tiers typically introduce mechanisms for scalability and availability, such as partition-\ning, replication, caching, and request routing. HTTP load balancers can be used to scale up browser access to \nthe web server itself. Typical web servers include Microsoft’s Internet Information Server (IIS) and the Apache \nHTTP Server. \n One popular type of web browser programming environment is AJAX (Asynchronous JavaScript and XML). \nAJAX enables browser-based forms and menus to be highly efﬁ cient and interactive. Compared to browsers \nusing plain HTML or XML, AJAX introduces three major beneﬁ ts for TP applications: using AJAX the browser \nneeds to exchange only the changed information with the web server, instead of the entire page, thereby reduc-\ning communication expense and improving response time; AJAX allows asynchronous interaction with the web \nserver, which does not block the user’s interaction with forms and menus; and AJAX allows the browser to \nofﬂ oad the web server by absorbing more of the application processing load. \n A simple AJAX program typically involves the exchange of an XML document with a web server and map-\nping the data into and out of the ﬁ elds in the menus and forms that users interact with. A more complex AJAX \nprogram might handle a REST-style interaction or a Web Service invocation. Java Script Object Notation \n(JSON) is another popular supported data format for AJAX. \n Figure 10.2 illustrates a simpliﬁ ed browser-based form for a money transfer operation. The form obtains \naccount numbers from the user along with the amount to be transferred. This data is sent to the server where \nWeb Browser \nDatabase/\nWeb Server \nWeb Browser \nWeb Server \nDatabase \nWeb Browser \nWeb Server\nDatabase \nTransactional\nMiddleware \n FIGURE 10.1 \n Web Browsers and Multitier TP Architecture. Web browsers work with TP applications in a variety of ways, including \ndirect database access and multitier architectures using transactional middleware. \n10.2 Web Browser Front-End Programs  283\n",
      "page_number": 293
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 302-315)",
      "start_page": 302,
      "end_page": 315,
      "detection_method": "topic_boundary",
      "content": "284  CHAPTER 10 Transactional Middleware Products and Standards\n the accounts are updated and the resulting balances for the two accounts are returned to the browser. While this \nexchange is taking place the user does not leave the form. \n Figure 10.3 shows an AJAX program snippet that works for both Microsoft’s Internet Explorer and other \nbrowsers. Internet Explorer implements AJAX using an ActiveX control ( XMLHTTP ), which is a mechanism \nspeciﬁ c to Windows, whereas other browsers typically use the standard  XMLHttpRequest class. AJAX sup-\nport also is included in the .NET Framework Active Server Pages (ASP) .NET library, including integration \nbetween AJAX and server-side ASP.NET. \n In either case, the  XMLHttpRequest class interacts with the web server asynchronously. It provides \nm ethods for exchanging data in various formats with the web server, including SOAP, XML, and JSON. \nSince AJAX is also a popular technology for developing Web Service clients, an AJAX library is available \nfor g enerating and handling Web Services, called  ws.js . Apache CXF provides an option for generating \nc lient-side JavaScript from a server-side Web Service deﬁ nition. In ASP.NET, an AJAX script can be used to \ncall either an ASP.NET Web Service (.asmx) or a Windows Communication Foundation (WCF)-based Web \nService (.svc). \n Typically , an HTTP  GET operation is performed ﬁ rst to display an HTML form. The modiﬁ ed ﬁ elds are \nsent to the server as XML elements in an HTTP  POST operation, returned in the response message, and dis-\nplayed on the form. In the example a  POST operation sends the URL of the server along with the data from \nthe form (in this case to and from account numbers and the transfer amount). The  true parameter in the open \nmethod indicates that the HTTP operation is to be performed asynchronously. The  onreadystatechange \nmethod is used to detect a state change in the data and trigger the data exchange with the server. \n Like any other front-end program, the AJAX script creates a request to run a transaction. The subsequent \ncontrol ﬂ ow depends on whether the application uses one resource manager, many resource managers, or \nmultiple tiers. Some applications simply connect the web tier to the database tier, so no independent transac-\ntion manager is needed. Others introduce tiers in between, some of which may need to control transactions. \nStill others may introduce a business process layer, which also controls transactions. Each of these back-end \ndesigns requires transactional middleware functionality to glue it together. This can be implemented using the \n.NET Framework and/or  Java-EE-based transactional middleware products, which are the subjects of the next \ntwo sections. \nTransfer\nFrom Account\nTo Account\nTransfer Amount\nFrom Balance\nTo Balance\nCustomer ID\n FIGURE 10.2 \n Simple Web Browser Form. The left boxes are labels. The user types the customer ID, transfer accounts, and transfer \namount as input and receives the updated account balances in the shaded boxes as output. \n\n\n 10.3  .NET FRAMEWORK \n Microsoft ’s .NET Framework provides a complete environment for developing and deploying multitier TP \napplications, including: \n ■  Windows Presentation Foundation (WPF), ASP.NET, and Silverlight for developing PC-based or \nbrowser-based front-end programs. \n<script type=“text/javascript”>\nvar fep = null;\nif(navigator.appName == “Microsoft Internet Explorer”) {\n  fep = new ActiveXObject(“Microsoft.XMLHTTP”);\n} else {\n  fep = new XMLHttpRequest();\n}\nfunction transfer(Customer) {\n fep.open(“POST”, “document”+CustomerID, FromAccountNo, ToAccountNo, \n          TransferAmt, true);\n fep.onreadystatechange=function() {\n   if(fep.readyState == 4) {\n      document.getElementById(‘account1Balance’).innerHTML = fep.responseText1\n      document.getElementById(‘account2Balance’).innerHTML = fep.responseText2;    \n}\n  }\nfep.send(document);\n}\n</script>\n<h1>Transfer</h1>\n<form>\n  <input type=“text” />\n  <div id=“Customer”>\n  </div>\n  <input type=“int” />\n  <div id=“FromAccountNo”>\n  </div>\n  <input type=“int” />\n  <div id=“ToAccountNo”>\n  </div>\n  <input type=“int” />\n  <div id=“TransferAmt”>\n  </div>\n  <input type=“int” />\n  <div id=“FromAccountBalance”>\n  </div>\n  <input type=“int” />\n  <div id=“ToAccountBalance”>\n  </div>\n</form>\n FIGURE 10.3 \n Sample AJAX Program for Browser-Based Funds Transfer Operation. The AJAX program is divided between its related \nJavaScript and HTML elements. After it detects the user input, it obtains the changed information from the form, sends \nit asynchronously to the web server, and then displays the results. \n10.3 .NET Framework  285\n\n\n286  CHAPTER 10 Transactional Middleware Products and Standards\n ■  Windows Communication Foundation (WCF) and the Internet Information Server (IIS) for developing \nand deploying request controllers and transaction servers. \n ■  Host Integration Server (HIS) and BizTalk Server adapters for integration with legacy environments. \nIn some instances of the multitier architecture, the transaction server and/or  resource manager can be \nhosted within a legacy environment. Interoperability tools such as these can include them into the .NET \nFramework environment. \n ■  Windows Workﬂ ow Foundation (WF) and WS-BPEL support in BizTalk Server for creating and execut-\ning business processes, including those that combine multiple services. \n Except for HIS and BizTalk Server, these components are bundled into Windows operating systems, start-\ning with the Vista release. Most components are also available as downloads for prior versions of Windows. \n Figure 10.4 shows that a front-end program can be written to run in a web browser and connect to a web \nserver acting as a request controller. Or it can connect directly to the database acting as a web server (not shown) \nor transaction server. \n A native PC program created using WPF can also connect to a web server. Or it can communicate directly \nwith either a request controller or a transaction server. Similarly, a Web Services client can communicate \ndirectly with an application process or the database (not shown in the ﬁ gure). \n A request controller can be developed to run in a web server or as an application process using WCF. A \ntransaction server can be implemented to run as an application process using WCF or as a stored procedure in \na database system. \n An application developed using the .NET Framework transactional middleware components can therefore \nimplement a two-tier, three-tier, or multitier architecture to meet scalability, availability, and other TP applica-\ntion requirements. \n Any server-side component or combination of components can use the transaction management capabilities \nof the platform through either the implicit or explicit programming models, either with or without using WCF. \n A variety of deployment functions also are supported to meet TP application requirements for scalabil-\nity, availability, and reliability. These include Windows operating system services, IIS application spaces, and \nWindows Server clusters. \nBrowser\nFront-End\nProgram:\nSilverlight,\nASP.NET or\nAJAX    \nPC\nFront-End\nProgram:\nWPF,\nSilverlight, or\nWeb services\nWeb Server\nRequest\nController\nProgram \nStored\nprocedures\nacting as\ntransaction\nserver\nPersistence\nTier\nApplication\nProcess\nRequest Controller\nand Transaction\nServer Programs:\nWCF\nADO.NET\nEntities \nDatabase \n FIGURE 10.4 \n .NET Framework Multitier Transactional Middleware Architecture. The components of the .NET Framework multitier \narchitecture provide multiple options for developing and deploying front-end programs, request controllers, and \ntransaction servers. \n\n\n A WCF program can use Web Services standards to interoperate with a legacy TP monitor or Java-based \nproduct, such as a Java-EE-compliant application server. \n Developing Front-End Programs \n In the .NET Framework the technologies used for front-end programs include: \n ■  Windows Presentation Foundation for PC- or browser-based GUIs \n ■  ASP.NET and Silverlight for web browser-based GUIs \n The Windows Presentation Foundation (WPF) provides a comprehensive environment for developing front-\nend programs that implement menus and forms with high levels of interactivity, control, and graphical capabil-\nity. WPF is intended to consolidate and replace prior generations of Windows-based graphical user interface \n(GUI) frameworks. WPF also can be used to create a GUI that runs in a web browser. \n ASP .NET provides a complete development and deployment environment for web-based applications. A sec-\nond option, Silverlight, provides a subset of WPF and .NET for cross-platform use; that is, for multiple operating \nsystems and web browsers. \n Windows Presentation Foundation \n WPF uses  XAML ( Extensible Application Markup Language , pronounced  “ zammel ” ), which is an XML \nsyntax for initializing structured values. In WPF, these structured values deﬁ ne components of a GUI. WPF \ncommands are expressed using XAML, or alternatively using a CLR-based programming language such as C# \nor Visual Basic (VB). \n Front -end programs developed using XAML commands can be deployed in a browser or in a native PC \nenvironment, which Microsoft calls a standalone application. A standalone application can be hosted in its \nown window or in a special window provided by WPF that offers basic navigation features. WPF can directly \naccess data in a database or other resource. The .NET Framework provides several options for this, including \nADO.NET, LINQ (Language-Integrated Query), and various mechanisms to execute a stored procedure in SQL \nServer (see Section 10.5 for further information). WPF also can be used in combination with WCF to connect \nto request controllers and transaction servers in a multitier architecture. \n A complete front-end program requires a combination of a XAML markup ﬁ le to deﬁ ne the display char-\nacteristics, a CLR-based program for the execution logic, and a conﬁ guration ﬁ le to bind the display charac-\nteristics to the program. The conﬁ guration ﬁ le generates an executable ﬁ le for deployment in the target hosting \nenvironment (Visual Studio, standalone, or web browser). \n Figure 10.5 illustrates a simple front-end program snippet deﬁ ned using WPF. XAML commands exist \nwithin the XAML namespace. The XAML commands are contained within a top-level structure called a  page , \n<Page \n  xmlns=“http://schemas.microsoft.com/winfx/2006/xaml/presentation”\n  xmlns:x=“http://schemas.microsoft.com/winfx/2006/xaml”\n  x:Class=“Transfer.HomePage”\n  WindowTitle=“Transfer Funds”\n  Title=“Transfer - Home” \n  WindowWidth=“550” WindowHeight=“380”>\n</Page>\n FIGURE 10.5 \n Simple XAML Commands for WPF. These sample XAML commands deﬁ ne a form title and the form’s position on the screen. \n10.3 .NET Framework  287\n\n\n288  CHAPTER 10 Transactional Middleware Products and Standards\n which is similar to an operating system window or a web page. The top-level page is called a  home page , \nwhich in the example is the  Transfer page. A single front-end program can have multiple pages correspond-\ning to multiple display panels for additional menus and forms. \n The display panel deﬁ ned by the home page in the example is given the title  “ Transfer Funds. ” The \n Transfer class is set as the namespace for all subpages and programs associated with this display. The dis-\nplay width and height are speciﬁ ed in pixels. Additional controls typically are added to deﬁ ne ﬁ elds and but-\ntons and to map data into and out of the page. For example, input ﬁ elds could be added in C# to capture the \nuser’s bank account numbers and transfer amount for an update operation. \n The C# snippet in  Figure 10.6 illustrates a program associated with the  Transfer home page. Additional \nC# logic typically is added to handle GUI events, such as what steps to perform on a button click or pressing \nEnter. In WPF terminology this is called a  code behind ﬁ le to handle events deﬁ ned in the XAML ﬁ le. The code \nbehind ﬁ le is merged with the code generated by processing the XAML deﬁ nitions. For example, the XAML \nsteps would obtain from the user the account number and amount to transfer between bank accounts and the C# \ncode would execute the actual transfer operation. A build step combines any XAML ﬁ les and associated C# ﬁ les \ninto an executable that can be run from a command line or within Visual Studio for testing and debugging. \n The .NET Framework environment supports the use of multiple approaches for front-end program con-\nstruction. In particular, a front-end program developed independently of .NET can use standard HTTP, the \nREST/HTTP protocol, or another Web Service invocation mechanism compatible with WCF to invoke a .NET \nFramework request controller or transaction server. \n ASP.NET and Silverlight \n ASP .NET supports the development and deployment of web-based applications, including components to cre-\nate a GUI for a web browser and a hosting environment in the IIS web server for processing requests. ASP.\nNET applications can be developed using any CLR-based language and can use any of the classes in the .NET \nFramework, including capabilities for security, transactions, and system administration. ASP.NET also sup-\nports Web Services development and deployment. \nusing System;\nusing System.Windows;\nusing System.Windows.Controls;\nusing System.Windows.Navigation;\nnamespace Transfer\n{\n    public partial class HomePage : Page\n    {\n        public HomePage()\n        {\n            InitializeComponent();\n            void Button(object sender, FormInput e)\n        }\n    }    \n}\n FIGURE 10.6 \n Sample C# Class Associated with a WPF Page. The C# code is merged with code generated from the corresponding \nXAML ﬁ le, for example to implement a button object that submits form input data. \n\n\n Silverlight is used similarly to WPF to develop front-end programs that can be used natively on Windows \nor with any web browser. Silverlight programs can be included within static HTML ﬁ les and server-generated \npages (e.g., using PHP, Python, or Ruby scripts). Like WPF, Silverlight programs include XAML ﬁ les and \ncode in the form of class ﬁ les that are associated with the XAML ﬁ les. \n Silverlight supports a JavaScript/AJAX programming model and a cross-platform, cross-browser version of \nthe .NET Framework. This allows developers of front-end programs to write Silverlight applications using any \n.NET language (including VB, C#, JavaScript, IronPython, and IronRuby) and deploy it on a range of operating \nsystems and web browsers. Silverlight supports REST, Web Services, XML over HTTP, RDF Site Summary \n(RSS), and standard HTTP communication protocols for interaction with web servers and WCF services. \n Developing Request Controllers and Transaction Servers \n WCF provides a set of capabilities that can be used to connect a front-end program to a request controller or \ntransaction server developed using the .NET Framework. WCF implements a service-oriented interaction model \nthat can be conﬁ gured for CLR objects created using Visual Basic .NET and C#. Many of the WCF libraries \nare also available to programs created using C \u0005 \u0005 , J#, and JScript. WCF supports both implicit and explicit \ntransaction programming models and works with all Microsoft SQL Server versions and ADO.NET compliant \nresource managers. WCF also includes .NET libraries that work with COM and COM \u0005 components. \n For communications WCF supports a variety of conﬁ gurable messaging models and data formats, includ-\ning native remote procedure call (RPC), Web Services, and asynchronous queuing (using Microsoft Message \nQueuing). WCF also supports custom-developed protocols and formats. \n A WCF service requires an explicit  contract , which is an interface to a .NET Framework object. The inter-\nface must be associated with an executable class ﬁ le that contains the program logic. It must also be associated \nwith a binding that speciﬁ es the data format, communication protocol, and additional characteristics of the com-\nmunication session (such as reliability, security, or transaction propagation) for the operations in the interface. \n A WCF interface describes a service that can be invoked remotely and deﬁ nes any additional distrib-\nuted computing characteristics for each method. For example, the interface shown in  Figure 10.7 is called \n[ServiceContract]\nInterface ITransfer\n{\n     [OperationContract]\n      void AccountBalance (decimal AccountNumber, decimal);\n     [OperationContract]\n      void WithdrawAccount (decimal AccountNumber, decimal Amount);\n     [OperationContract]\n      void DepositAccount (decimal AccountNumber, decimal Amount);\n     [OperationContract]\n      void Transfer(decimal FromAccountNumber, decimal ToAccountNumber, \n                   decimal Amount);\n}\n FIGURE 10.7 \n WCF Interface Deﬁ nition. An interface that exposes a service remotely is a core feature of WCF. Multiple bindings can be \nconﬁ gured for an interface, including Web Services and native. \n10.3 .NET Framework  289\n\n\n290  CHAPTER 10 Transactional Middleware Products and Standards\n ITransfer and includes four methods:  AccountBalance ,  WithdrawAccount ,  DepositAccount , and \n Transfer . The interface is marked as a service using  [ServiceContract] , and each method in the ser-\nvice is marked as being remotely accessible using  [OperationContract] . Not all methods have to be made \navailable remotely, but when they are they must be tagged with the  [OperationContract] attribute. \n Transactions \n Three main attributes affect the transaction behavior of a method: \n ■  TransactionFlowOption is speciﬁ ed on the interface to the method and tells whether the method will \naccept a transaction context propagated from its caller. \n ■  TransactionScopeRequired property of the  OperationBehavior attribute is speciﬁ ed on an \nimplementation of the method and tells whether the method must execute within a transaction. \n ■  TransactionFlow is speciﬁ ed on the binding that the caller uses to invoke the method and tells \nwhether the caller’s transaction context can ﬂ ow across the binding. \n The  [TransactionFlow] attribute on an interface has three possible values:  Mandatory ,  Allowed , and \n NotAllowed . The  Mandatory attribute shown in  Figure 10.8 indicates that the  WithdrawAccount operation \nmust receive a transaction context when invoked by another method.  Allowed means that the service accepts \na transaction context if one is received with the message, but it does not require the message to contain one. \n NotAllowed is the default and means that the service ignores a propagated transaction context. \n An annotated class implements a WCF interface deﬁ nition. The class deﬁ nes the execution logic for each of \nthe methods listed in the service, such as methods that access a database, do computation, or invoke other ser-\nvices. The  TransactionScopeRequired attribute on each method is set to  true or  false , indicating whether \nor not the operation must be executed within a transaction. For example, in  Figure 10.9 the  WithdrawAccount \n[OperationContract]\n     [TransactionFlow(TransactionFlowOption.Mandatory)]\n      void WithdrawAccount(int AccountNumber,int Amount);\n FIGURE 10.8 \n Using the TransactionFlow Attribute to Require Propagation. Adding attributes to the WCF interface controls transaction \npropagation. \nclass TransferService : Transfer\n{\n    [OperationBehavior(TransactionScopeRequired = true)]\n     public void WithdrawAccount (int accountNumber, decimal amount)\n} \n{\n    [OperationBehavior(TransactionScopeRequired = true)]\n     public void DepositAccount (int accountNumber, decimal amount)\n      ...\n}\n FIGURE 10.9 \n Deﬁ ning the Object Class for the Interface. Each operation in a WCF interface has a method in a corresponding object \nclass for its implementation. \n\n\n and  DepositAccount methods have a  TransactionScopeRequired attribute of  true , so they must always \nexecute in the context of a transaction. \n Suppose the binding between the caller and the service indicates that the caller’s transaction context can ﬂ ow \nacross the binding (details are in the next section). The combination of values for  TransactionFlowOption \nand  TransactionScopeRequired lead to a variety of possible behaviors. For example: \n ■  If the caller is executing a transaction, the  TransactionFlowOption on the method is  Mandatory \nor  Allowed , and  TransactionScopeRequired is  true , then the method executes in the caller’s \ntransaction. \n ■  If the caller is executing a transaction, the  TransactionFlowOption is  NotAllowed , and \n TransactionScopeRequired is  true , then the method executes in a new transaction. \n ■  If the caller is  not executing a transaction and  TransactionScopeRequired is  true , then the method \nexecutes in a new transaction, no matter what value is speciﬁ ed for  TransactionFlowOption . \n Transaction termination depends on the successful completion of each method executed within the transac-\ntion. That is, a transactional object is considered a participant in the transaction and must provide a comple-\ntion vote for the transaction to commit. If the  TransactionAutoComplete attribute is  true (which is the \ndefault), then the transaction is completed automatically if it exits without throwing an unhandled exception. \nSuch an exception means the transactional object will vote to abort. \n A one-way ﬂ ow (i.e., a one-way asynchronous message exchange) is not allowed to propagate a transaction \ncontext, although a correlated request/reply message exchange using an asynchronous communication protocol \nis allowed to propagate a context. \n So far nothing has indicated which wire format is used. The type of transaction context is speciﬁ ed in the \nWCF binding. \n Bindings \n Internally , WCF is based on the  chain of responsibility architecture, in which a series of  handlers (some-\ntimes called  interceptors ) are inserted into the call chain between client and server, including a handler that \npropagates transaction context for a remote service. The chain of responsibility pattern can be implemented as \nan extension to the RPC mechanism. When the proxies and stubs are generated from the interface, the code for \nthe handlers is inserted into the call chain to implement any additional characteristics associated with the inter-\nface deﬁ ned using conﬁ guration metadata. Handlers are inserted into the call chain in a predetermined order, \naccording to the type of functionality they provide. For example, a message serialization handler must execute \nbefore a handler that dispatches the serialized message onto the communications protocol. \n The call chain handlers in WCF are called  channels and are visible to developers in collections called \n bindings . A binding is basically a collection of related channels designed to fulﬁ ll a speciﬁ c task, such as \ntransmit a Web Services request using HTTP. A binding contains an ordered collection of  binding elements , \nsuch as the  TransactionFlowBindingElement in a transaction propagation channel. The various commu-\nnication and transaction propagation capabilities offered by WCF therefore are expressed in the collection of \navailable channels. Custom bindings can also be deﬁ ned. A local optimization of a WCF binding is used when \nservices are deployed into the same address space. \n An extended HTTP binding,  WSHttpBinding , shown in  Figure 10.10 , is used for messages that need bind-\ning elements for SOAP headers deﬁ ned in extended Web Services speciﬁ cations such as WS-Security for mes-\nsage-based security, WS-ReliableMessaging for reliable message exchange, and WS-AtomicTransaction for \ntransaction context propagation. A simpler HTTP binding,  BasicHttpBinding , which is aimed at WS-I Basic \nProﬁ le conformance, is used to transmit a basic SOAP-formatted message over HTTP. In the simpler binding, \nHTTP security is used for basic encryption, authentication, and authorization, and transactions are not supported. \n10.3 .NET Framework  291\n\n\n292  CHAPTER 10 Transactional Middleware Products and Standards\n The example in  Figure 10.11 illustrates a conﬁ guration for the  Transfer service. The executable service \nlogic, interface contract, and communications binding are combined in an  endpoint deﬁ nition. The endpoint \nidentiﬁ es the executable ﬁ le for the service as  TransferService.svc and gives its network address as a URL. \nThe service uses the  WSHttpBinding for the interface contract  ITransfer , and a  TransactionalHTTP bind-\ning conﬁ guration, which will propagate the transaction context using WS-AtomicTransaction. \n WCF also offers a binding, called  NetTcpBinding, for directly sending a binary message over TCP/IP. The \nmessage format is optimized for internal communications and available for use only among WCF services. The \n NetTcpBinding supports transaction propagation and a conﬁ gurable selection of formats for the transaction con-\ntext. The format choices include OLE Transactions, WS-AtomicTransaction 2004, or WS-AtomicTransaction 1.1. \n A WCF service can be conﬁ gured to support multiple bindings and thus multiple communication protocols \nand data formats. For example, a developer may want to publish a service over  NetTcpBinding for optimized \nWCF-WCF communications and over  WSHttpBinding to allow access from external Web Services clients. \nThis simply requires specifying multiple bindings for the service in its associated endpoint conﬁ guration ﬁ le. \nTo propagate transaction context, however, it’s always necessary to choose a transactional binding; that is, one \nthat can include a  TransactionFlowBindingElement . \n The code in  Figure 10.12 illustrates a WCF service endpoint that uses two bindings,  TransactionalTCP \nand  TransactionalHTTP . This makes  TransferService available over each protocol on a different port \nnumber (8001 and 8002, respectively). In the binding deﬁ nitions for  NetTCPBinding and  WsHttpBinding , \nthe  transactionFlow attribute is set to  true (the default is  false ). In this case both bindings are transaction-\naware and the ﬂ ow attribute requires transaction context to propagate. In other words, the  TransferService is \nconﬁ gured to accept a transactional service invocation over both TCP and HTTP. The TCP channel will receive \nOLE-Transactions context and the HTTP channel will receive WS-Transaction ’ s WS-AT context. \nTCP/IP \nWCF\nService\nRequester \nWCF\nService\nProvider\nChannel (WS-\nAtomic Transaction)\nChannel (SOAP) \nChannel (HTTP) \nChannel (WS-\nAtomic Transaction)\nChannel (SOAP) \nChannel (HTTP) \nWSHttpBinding \nWSHttpBinding \n FIGURE 10.10 \n WCF Bindings Consist of a Collection of Channels. The  WSHttpBinding combines channels for Web Service \ntransaction context propagation, message formatting, and transport. \n<endpoint \n    address  = “http://localhost:8002/TransferService.svc”\n               bindingConfiguration = “TransactionalHTTP”\n               binding  = “wsHttpBinding”\n               contract = “ITransfer”/>\n FIGURE 10.11 \n Endpoint Deﬁ nition for a WCF Service. The endpoint deﬁ nition maps an interface to one or more bindings, such as \n WSHttpBinding for transactional Web Services. \n\n\n Discussion \n The implicit programming model was ﬁ rst implemented in .NET as a single attribute associated with an inter-\nface that applied to all methods of the interface. The attribute deﬁ ned both how the method would handle a \ntransaction context when invoked, and whether or not the method would create a new transaction if it did not \nreceive a context on the invocation. That is, a single setting controlled whether or not a method would accept \na transaction context propagation and whether or not the called method would create a new transaction if it \ndidn’t receive one. This is still the model use in Java EE. \n This changed in WCF. First, attributes are associated with individual methods, not the entire interface. \nSecond, WCF uses separate attributes to demarcate a transaction and to control the propagation of transaction \ncontext. This allows a potential separation of roles between a developer and system integrator. A developer \nwants to require that his method executes in a transaction because it accesses transactional resources. But he \nwants to allow the method to be called by another method that is already operating inside a transaction. He \ndoes not necessarily want to deﬁ ne an exception handler, because the exception handler’s behavior may be dif-\nferent depending on whether the transaction is demarcated by his method or a method that invokes his method. \n<?xml version = “1.0” encoding = “utf-8” ?>\n<configuration>\n   <system.serviceModel>\n      <services>\n         <service name = “TransferService”>\n            <endpoint\n               address = “net.tcp://localhost:8001/TransferService/”\n               bindingConfiguration = “TransactionalTCP”\n               binding  = “netTcpBinding”\n               contract = “ITransfer”\n            />\n            <endpoint\n               address  = “http://localhost:8002/TransferService/”\n               bindingConfiguration = “TransactionalHTTP”\n               binding  = “wsHttpBinding”\n               contract = “ITransfer”\n            />\n         </service>\n      <bindings>\n         <NetTcpBinding>\n            <binding name = “TransactionalTCP”\n               transactionFlow = “true”\n            />\n         </NetTcpBinding>\n         <WsHttpBinding>\n            <binding name = “TransactionalHTTP”\n               transactionFlow = “true”\n            />\n         </WsHttpBinding>\n      </bindings>\n   </system.serviceModel>\n</configuration>\n FIGURE 10.12 \n Conﬁ guration File Example for WCF Services. Transactional bindings for both binary and HTTP-based protocols can be \nconﬁ gured for the same service, using different port numbers. \n10.3 .NET Framework  293\n\n\n294  CHAPTER 10 Transactional Middleware Products and Standards\n Consider a system integrator who is reusing an existing transactional method  M in a larger application. He or \nshe may need to control whether  M executes in the context of the caller’s transaction. For example, if  M logs a \nsecurity violation, it needs to run as a transaction, which the developer of  M can specify. The system integrator \nneeds to control whether or not the security violation will be logged even if the caller’s transaction aborts. He or \nshe can do this by deciding whether or not the caller’s transaction context is propagated to  M . If so, then  M will \nrun in the caller’s transaction. If not, then  M will run as a top-level transaction and commit independently of the \ncaller. The system integrator can conﬁ gure two different callers so that one propagates transaction context and the \nother doesn’t. \n In the earlier model, the decisions of transaction demarcation and context propagation were linked. That is, \na single attribute controlled whether  M executes as a transaction and whether it executes in the context of the \ncaller’s transaction. In WCF, these decisions are made separately. \n REST/HTTP Support \n REST /HTTP support in NET is provided using enhancements to WCF, including templates for constructing \nand using URLs with HTTP verbs, and attributes for deﬁ ning REST-based operations in a WCF interface. \nWCF provides a nontransactional binding for REST/HTTP style services called  WebHttpBinding . \n WCF Deployment Options \n WCF supports several hosting options, including IIS running on Windows Server clusters for scalability and \navailability. For production, one option is to use a Windows hosted  “ service ” (not to be confused with a WCF \nservice). WCF programs can also be hosted using IIS worker processes. Or they can be included in ASP.NET \napplications. \n Initially , the IIS hosting environment was available only for HTTP-based communications. As of the Windows \nVista release, the application hosting environment portion of IIS is packaged separately, so it can now accept \nincoming requests over any communication protocol that WCF supports. \n In a Windows Server cluster environment, it’s possible to conﬁ gure the transaction manager to manage trans-\nactions centrally or per machine. When conﬁ gured per machine, if one machine fails, then a transaction manager \non another machine can assume responsibility for coordinating transactions for the failed machine’s transaction \nmanager. A clustered transactional application must use a cluster-aware transaction manager to ensure correct \nresults and meet availability requirements. In general, performance is improved by colocating the transaction \nmanager in a cluster with the resource manager(s) being coordinated. \n Transaction Management Using  System.Transactions \n The runtime infrastructure for creating transactional services and objects in the .NET Framework is delivered \nin the  System.Transactions API. The API supports both implicit and explicit transaction programming \nmodels, either for .NET programs running on their own or for those deﬁ ned within WCF. The .NET transaction \nmanagement infrastructure uses a context called an  ambient transaction , which is created for any Windows \noperating system thread that runs transactional code. If an ambient transaction already exists when an object \nneeds a transaction context, then the existing ambient transaction is used. If not, then a new one is created. \n Two transaction managers are used in .NET. The general-purpose transaction manager for transactions that \nuse multiple resource managers (RMs) is the Microsoft Distributed Transaction Coordinator (DTC). There is \nalso the Lightweight Transaction Manager (LTM), which can handle any number of volatile resources and at \nmost one persistent resource. LTM is cheaper than DTC because it doesn’t require a log. \n\n\n To minimize transaction overhead,  System.Transactions optimizes transaction coordination by attempting \nto use the LTM when possible. A transaction starts out being managed by LTM. If the transaction only accesses \nvolatile resources, then LTM coordinates the transaction. If the transaction accesses a persistent resource, such as \nSQL Server or the transactional NT File System (TxF), then an optimization strategy called  Promotable Single \nPhase Enlistment (PSPE) comes into play. It transparently promotes the lightweight in-memory transaction to \na persistent single-phase transaction. To coordinate the transaction, LTM commits the volatile resources and then \ntransfers commit coordination responsibility to the durable RM. If the transaction accesses a second durable RM, \npropagates the transaction to another process, or takes other actions that are beyond LTM’s ability to manage, \nthen LTM delegates the transaction coordination to DTC. \n SQL Server version 2005 and higher are compatible with PSPE and can therefore handle the delegation or \npromotion of control when a transaction is started by  System.Transactions . DTC supports any XA-compliant \nRM, such as Oracle Database and IBM’s DB2, and can include them within a DTC managed transaction. \n The Explicit Programming Model \n The explicit model in  System.Transactions incorporates transaction management APIs directly into appli-\ncation code. Developers use the methods in the  Transaction class to manage transactional behavior. Similar \nto the implicit programming model, the explicit programming model can be used in any .NET programming \nlanguage, within or outside of WCF. \n A typical approach to manage transactions explicitly is to set a transaction scope on a  using or  try block. \nAll operations on data within the block execute within the scope of the transaction. This includes any methods \ncalled from within the block, unless explicitly excluded. \n An example is shown in  Figure 10.13 . The  TransactionScope() object is instantiated within a  using \nblock, and the  AccountDeposit operation within the block is contained within the transaction. Instantiating \na  TransactionScope() object starts a new transaction or joins an ambient transaction, if one exists. The \ndefault  TransactionScopeOption is  Required . In the explicit model, the transaction is completed using \nthe  complete method instead of using the  Autocomplete attribute. However, the result is the same — the \ntransaction is committed if all participants vote complete and the execution of all methods is successful (i.e., \nno unhandled exceptions are thrown). \n The  System.Transactions explicit model API also can be used to bracket multiple SQL connections. \nIn  Figure 10.14 a new transaction scope is created explicitly. The ﬁ rst  using block creates an initial SQL \nusing (TransactionScope tx = new TransactionScope())\n{\n  //...\n  AccountCredit = 100.00M;\n  AccountID = 77392;\n  AccountDeposit(AccountID, AccountCredit);\n  //...  \n  \n  tx.Complete();\n}\n FIGURE 10.13 \n Explicit Transaction Management Using  TransactionScope() . The  TransactionScope() class code snippet \nshown picks up an existing ambient transaction or initiates a new transaction and votes to successfully complete the \ntransaction if no exception is thrown. \n10.3 .NET Framework  295\n\n\n296  CHAPTER 10 Transactional Middleware Products and Standards\n connection that executes an  insert command. A second  using block creates a second SQL connection that \nexecutes an  update command. After both SQL commands complete successfully, the  scope.complete() \noperation indicates the work of this method is done, and the method is prepared for the transaction to be com-\nmitted. For simplicity, exception handling logic that typically is added to the  using blocks has been omitted. \n The  TransactionScopeOption  choices are: \n ■  Required : Join the existing ambient transaction, or create a new one if one does not exist. \n ■  RequiresNew : Create a new transaction whether or not an ambient transaction was present. \n ■  Suppress : Execute outside the scope of a transaction, that is, suppress the ambient transaction. \n A transaction context is associated with a scope object created when a transaction is initiated. The decision \nto create a new transaction depends on the  TransactionScopeOption attribute deﬁ ned for the object. \n The explicit programming model offered by  System.Transactions allows a developer to control trans-\naction bracketing without decomposing transactions into separate methods. It also offers more control over the \ndetails of transaction management, such as getting and manipulating the transaction context and logging trans-\naction IDs. For example, a program can obtain a reference to the ambient transaction context as follows: \n Transaction ambientTransaction  \u0003 Transaction.Current; \n This enables a program to pass its ambient transaction to another party. The ambient transaction can be \nchanged by setting  Transaction.Current , which enables a program to control its transaction context explicitly. \nusing (TransactionScope scope =\n    \n  new TransactionScope(TransactionScopeOption.Required))\n{\n    using (SqlConnection connection =\n        new SqlConnection(connectionString))\n    {\n        SqlCommand command = connection.CreateCommand();\n        command.CommandText = “Insert....”;\n        \n        connection.Open();\n        command.ExecuteNonQuery();\n        connection.Close();\n \n using (SqlConnection connection2 = \n          new SqlConnection (connectionString)\n       {\n         SqlCommand command2 = connection2.CreateCommand();\n         command2.CommandText = “Update....”;\n         connection.Open();\n         \n         command2.ExecuteNonQuery(); \n       }\n    }\n    scope.Complete();\n}\n FIGURE 10.14 \n Bracketing Multiple SQL Connections. In this example, nested  using blocks are deﬁ ned to connect to two SQL \ndatabases and coordinate a transaction across both. \n\n\n Integration with Legacy TP Monitors \n The .NET Framework includes the Microsoft Host Integration Server to access CICS and IMS transactions \nand DB2 databases. BizTalk Server Adapters for Host Systems can be used to integrate with other existing \nsystems and legacy TP monitors. The Line of Business adapter toolkit in WCF and BizTalk Server can be used \nto develop a custom adapter where no packaged adapter exists. \n Transactional integration with existing systems and legacy TP monitors is offered speciﬁ cally for CICS and \nIMS using a two-phase commit bridge between DTC and mainframe transaction managers using the LU6.2 \nprotocol in the Host Integration Server product. Transactional integration also is offered generically via Web \nServices transactions in WCF and XA support in DTC, both of which can also be used with BizTalk Server. \nExisting systems also can be wrapped using Web Services and accessed via WCF, either standalone or together \nwith BizTalk Server. \n Host Integration Server offers a direct connection to DB2 databases from the .NET Framework. Programs \nthat access mainframe transactions from the .NET Framework can be developed using Visual Studio, includ-\ning the ability to import metadata from legacy environments in the form of COBOL Copy Books and RPG \ndata deﬁ nitions. A data access tool provides a mapping to the DB2 data sources. It’s also possible to manage \ndatabase connections to mainframe databases from the .NET Framework environment and integrate them with \nconnections to SQL Server data sources. \n Host Integration Server also supports an option for using IBM 3270 terminal communications protocol \nover TCP/IP. \n 10.4  JAVA ENTERPRISE EDITION \n Java Enterprise Edition (Java EE) refers to an umbrella speciﬁ cation that groups 79 API speciﬁ cations (as of \nJava EE 5) designed for enterprise computing applications such as transaction processing. Java EE API features \nwork together to provide a complete environment for developing and deploying TP applications, including: \n ■  The Swing Library, Servlets, Java Server Pages, and Java Server Faces for developing front-end programs, \nincluding interactive menu and forms capabilities for web browsers and native PC and UNIX programs \n ■  Enterprise Java Beans (EJBs), a distributed computing component model for developing request control-\nlers and transaction servers that support a variety of front-end programs \n ■  The Java Persistence API (JPA), a lightweight object-relational mapping integrated with EJBs to interact \nwith persistent entities stored in a relational database \n ■  The Java Connector Architecture (JCA) API, a programming environment for integration with legacy \nsystems that includes a standard client and adapter toolkit \n ■  The Java Transaction API (JTA), an infrastructure and programming environment for transaction man-\nagement, used in both the implicit and explicit programming models for Java EE \n ■  A WS-BPEL engine for business process management, which is also provided by most Java EE vendors \n Java EE is deﬁ ned through the Java Community Process, a consortium of Java vendors chaired by Sun \nMicrosystems. Java EE originally was released in December 1999, and has gone through several iterations since \nthen. Its original name was Java 2 Enterprise Edition, or J2EE, which was changed to Java EE as of its fourth \nrelease, called Java EE 5. A major difference between the enterprise edition and the standard edition of Java is \nthe addition of EJBs. The current version, EJB3, represents a signiﬁ cant change from earlier versions of EJB \n(1.1 through 2.1), with a lighter weight container, JPA in place of entity beans, and the use of Java 5 annotations \nfor transaction demarcation and other EJB functions. \n10.4 Java Enterprise Edition  297\n",
      "page_number": 302
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 316-330)",
      "start_page": 316,
      "end_page": 330,
      "detection_method": "topic_boundary",
      "content": "298  CHAPTER 10 Transactional Middleware Products and Standards\n Java EE APIs are delivered in Java-EE-compliant application server products from IBM, Oracle, Red Hat, \nand others. Java-EE-compliant vendors must pass a set of conformance tests to receive a certiﬁ cation from the \nJava Community Process, which indicates that the vendor has successfully implemented each of the required \nAPIs. Examples of certiﬁ ed products include IBM’s WebSphere Application Server, Oracle’s WebLogic \nApplication Server, and Red Hat’s JBoss Application Server. These products are available on UNIX, Windows, \nand zOS operating systems. Java-EE-compliant application servers typically include vendor-speciﬁ c mecha-\nnisms for server clustering and failover, sometimes including state caching and replication. However, these \nfeatures are not included in the Java EE APIs and are therefore beyond the scope of this book. \n In contrast to the Microsoft transactional middleware, which runs only on Windows operating systems, Java-\nbased transactional middleware runs on virtually any operating system. But operating system portability has its \ncosts. In particular, .NET Framework components are generally better integrated with the operating system than \nJava-based components. As might be expected, the speciﬁ c details of how to create and deploy transactional \nprograms with Java EE and the .NET Framework are different, even though the technologies and underlying \nconcepts are very similar. \n Figure 10.15 illustrates the relationships among the transactional middleware components of the Java \nEE architecture. It includes two types of front-end programs, those designed to run in a web browser and \nthose designed to run on a desktop PC or UNIX system. The Java EE architecture is very similar to the .NET \nFramework in this respect, but a signiﬁ cant difference is the presence of EJBs, which are programs and associ-\nated containers that were speciﬁ cally designed for use in TP applications. \n Typically , a browser-based front-end program communicates with the web tier, which in turn calls the EJB \ntier. The EJB tier then invokes one or more JPA entities at the persistence tier. An EJB may also use JCA to \ninvoke a back-end system, such as a legacy TP monitor, or may directly access a database using SQL com-\nmands through Java Database Connectivity (JDBC). \n The standard protocol for remote communication between the web tier and the EJB tier is the Java Remote \nMethod Invocation over the CORBA Internet Inter-Orb Protocol (RMI/IIOP). Other communication protocols \ncan also be used. SOAP over HTTP is supported from a Web Services client to the EJB tier. Java EE vendors \ntypically offer proprietary communications protocols and data formats speciﬁ cally tuned for their individual \nproducts. It is also fairly common practice for the web tier to communicate locally with the EJB tier. \nBrowser\nFront-end\nprogram\nwith Java\nServer\nPages \nPC\nFront-end\nprogram\nusing Swing\nor Web\nServices\nWeb Tier\nServlets, Java\nServer\nFaces\nStored\nprocedures\nacting as\ntransaction\nserver\nPersistence\nTier\nEJB Tier\nSession Beans \nJPA Entities\nDatabase \n FIGURE 10.15 \n Java EE Multitier Transactional Middleware Architecture. The components of the Java EE environment provide several \noptions for developing and deploying front-end programs, request controllers, and transaction servers. \n\n\n An application developed using Java-EE-compliant transactional middleware components can therefore \nimplement a two-tier, three-tier, or multitier architecture to meet scalability, availability, and other TP applica-\ntion requirements. For example: \n ■  When a web browser is used for the front-end program, a web server can function as the request control-\nler by including an EJB that routes the request to a transaction server program. \n ■  When a PC- or UNIX-based front-end program is used, the EJB tier can be used to fulﬁ ll the request \ncontroller function on its own, without a web server. \n ■  When multiple tiers are needed, EJBs can be used to fulﬁ ll both the request controller and transaction \nserver functions (including the persistence tier). \n ■  Stored procedures can also fulﬁ ll the transaction server function for web server hosted or plain EJB-\nbased request controllers. \n As in the .NET environment, both implicit and explicit transaction programming models are supported, and \nthe implicit model is recommended for most applications. \n Developing Front-End Programs \n In Java EE the technologies used for front-end programs include: \n ■  The Swing Library for PC- and UNIX-based GUIs \n ■  Servlets, Java Server Pages (JSP), and Java Server Faces (JSF) for web browser-based GUIs \n Swing is the name of a collection of libraries and functions used to develop highly interactive PC- and UNIX-\nbased front-end programs. The Swing Library is comparable to the .NET Framework’s WPF and Silverlight. \nLibrary functions deﬁ ne a screen’s area and layout, menus, scroll bars, tabs, buttons, sliders, tables, frames, tool-\nbars, and so on. The example in  Figure 10.16 uses the Swing libraries to display a table of information. As shown \nin the ﬁ gure, Swing classes can be used to construct a variety of GUI features. In this case the  JTable class is \nused to create a table of a customer’s accounts. Although the main program thread exits at the end of the example, \nSwing supplies a second thread that continues processing in the background to handle GUI components. \n A Java  servlet extends the capability of a standard web server to support dynamic content generation. The Java \nServlet API is an alternative to web server callout mechanisms such as Common Gateway Interface (CGI) scripts \nand web server APIs such as Apache API or ISAPI (IIS). Servlets handle HTTP sessions and route requests to Java \nobjects, EJBs, or databases. Servlets also handle REST and Web Services communications. The server can use any \ntechnique to maintain session state, typically using cookies or URL rewriting. All Java-EE-based application server \nproducts include a servlet engine. Apache Tomcat is an example of a popular standalone servlet engine. \n Java Server Pages (JSP) layer on servlets and replace static HTML and XML pages with dynamic content \ngenerated using JSP tags embedded in HTML or XML pages. The tags access and generate content that is then \nformatted into HTML or XML. When the page request is executed, a JSP is converted to a servlet for handling \nthe content to be displayed in the browser. \n The example in  Figure 10.17 illustrates the use of JSP tags to generate information within an HTML bulleted \nlist. When executed, the JSP tags dynamically generate the content for the bank name, the account balance, and \nthe current date of the web server access.  Java Server Faces (JSF) components are server-side controllers of \nbrowser-based menu and form components such as buttons, tables, and graphics. JSF and JSP technologies can \nwork together, for example when JSFs are used to create JSPs, and JSPs generate content for JSF-deﬁ ned menu \nand form elements. JSPs and JSFs can work in combination to drive server-side and client-side user interaction \nscenarios. For example, the JSF custom library can be used by the JSP to generate content and GUI elements for \nthe browser. \n10.4 Java Enterprise Edition  299\n\n\n300  CHAPTER 10 Transactional Middleware Products and Standards\n The example in  Figure 10.18 illustrates a simple form deﬁ ned using JSF tag libraries. The JSF component \nclasses maintain the component’s state and the rendering tags deﬁ ne how to render the content for the user. \nFor example, the  commandButton tag is rendered as a button. The example also illustrates a validation func-\ntion to check a username when the button is clicked. When a JSP is created using JSF, a tree of components is \nmapped into memory from which a response to a browser request is generated. \n REST Support \n REST support in Java EE environments is provided by the Java API for Restful Web Services (JAX-RS). JAX-\nRS deﬁ nes a set of annotations and interfaces that can be used in Java objects to expose them as RESTful web \nresources. JAX-RS objects can be deployed to either a standalone servlet engine or a servlet engine within a \nJava EE application server. JAX-RS enables front-end programs to call the objects using HTTP as the network \nprotocol, using HTTP content types to deﬁ ne the data formats. \nimport java.awt.*;\n       import javax.swing.*;\n  \npublic class SimpleTable extends JFrame {\n \n  \npublic SimpleTable() {\n \n \n  \nsuper(“Transfer”);\n \n \n  \nsetSize(300, 200);\n \n \n        setDefaultCloseOperation(EXIT_ON_CLOSE);\n                       JTable jt = new JTable(\n                         new String[][] { \n                         {“John Smith”, “Savings”, “100.0”} }, \n                         new String[] { “Customer”, “Account”, “Balance”} \n                       );\n \n \n \nJScrollPane scp = new JScrollPane(jt);\n \n \n \ngetContentPane().add(scp, BorderLayout.CENTER);\n \n        }\n \n \npublic  static void main(String args[]) {\n \n \n \nSimpleTable st = new SimpleTable();\n \n \n \nst.setVisible(true);\n \n        }\n}\n FIGURE 10.16 \n Code for a Java Swing-Based Table. The Swing client displays a list of accounts and balances for a customer. \n<UL>   \n  <LI> Web Bank name: ${account.bankName}   \n  <LI> Current Balance: ${account.balance} \n  <LI><B> JSP 1.2 expression: </B><BR>       \n   Current date: <%= new java.util.Date()%> \n</UL> \n FIGURE 10.17 \n JSP Tags Generate Content for an HTML List. JSP 2.0 tags inside an HTML list include an expression that ﬁ nds the web \nbank’s name, an account balance, and a directive that gets and displays the current date. \n\n\n Developing Request Controllers and Transaction Servers \n An  Enterprise Java Bean (EJB) refers both to a type of Java program designed for TP applications and to a \ncontainer within which such a program is deployed. An EJB abstracts transactional middleware functionality, \nsuch as threading, transaction control, and security. EJBs originally were designed for compatibility with legacy \nTP monitors, although the most popular implementations of EJBs have been written from scratch. EJBs have \nevolved signiﬁ cantly from their initial deﬁ nition. Compared to EJB2, EJB3 beans feature a lighter weight con-\ntainer, dependency injection, and Java 5 attributes for expressing conﬁ guration properties. \n In Java EE, a request controller can be developed for the web tier or the EJB tier. When developed for the \nweb tier, the request controller typically is implemented using a servlet engine running inside a web server, \nwhich routes the request to an EJB. The EJB can execute in the web server or in a separate process. \n EJB types include: \n ■  Session beans: Designed for hosting an interactive session with the front-end program. A session bean \ncan be stateless or stateful and can manage transactions. \n ■  Message-driven beans: Designed for interacting with asynchronous messaging systems that conform to \nthe Java Messaging Service (JMS) API. \n EJB2 deﬁ ned a third EJB type, an entity bean. Entity beans are preserved in EJB3 for compatibility with \nEJB2 applications. In EJB3, entity beans are replaced by JPA entities (covered next and in Section 10.6). \n An EJB can manage transactions and participate in transactional compositions. A message-driven bean can \nalso manage transactions, but cannot be composed into a transaction started by another bean. \n A session bean is allocated to a single instance of a front-end program and is terminated when the front-end \nprogram terminates. A stateful session bean maintains the state of its instance variables for the duration of its \ninteraction with the front-end program; a stateless session bean does not. \n Stateful session bean state is volatile and not transactional. For a web browser front-end program, ses-\nsion state management also can be provided by the  HttpSession object. For PC- or UNIX-based Swing cli-\nents stateful session beans are the only mechanism available to preserve in-memory conversational state across \nmultiple interactions between the front-end program and the request controller. \n As with any stateless design, the advantage of a stateless session bean is that the application server can maintain \na reusable pool of stateless session beans, allocate them to any request on demand, and deallocate them once a bean \nﬁ nishes executing the request. With a stateful bean the application server has to direct a subsequent call by a given \nfront-end program to the same bean instance so that it has access to the state of its conversation with the front end. \n<%@ taglib uri=“http://java.sun.com/jsf/html” prefix=“h” %>\n    <%@ taglib uri=“http://java.sun.com/jsf/core” prefix=“f” %>\n    <body bgcolor=“white”>\n    <f:view>\n    <h:form id=“Sign In Form”>\n    <h2>Username:</h2>\n   \n<h:inputText id=“username” value=“#{UserNameBean.userName}”\n            validator=“#{UserNameBean.validate}”/>\n   \n<h:commandButton id=“submit” action=“success” value=“Submit”/>\n    </h:form>\n    </f:view>\n FIGURE 10.18 \n JSF Components Prompt for a Username and Create a Submit Button. This JSF component prompts the user for his or her \nname and checks it with the server-side username validation program. \n10.4 Java Enterprise Edition  301\n\n\n302  CHAPTER 10 Transactional Middleware Products and Standards\n A stateless session bean can have a Web Service interface, allowing a Web Service client to invoke an EJB \nmethod. Web Services support is included in the Java EE speciﬁ cations through the inclusion of the Java API \nfor XML-Based Web Services (JAX-WS) speciﬁ cation. Therefore, all Java-EE-complaint application server \nproducts offer toolkits that generate a Web Service interface from an EJB interface. \n A session bean can query and update a relational database by using one or more JPA entities. The data \nmembers of a JPA entity are transactionally persistent, and a session bean can access that state by issuing oper-\nations on the JPA  EntityManager . Like a web server, however, a session bean also has the option to access \na database directly to execute embedded SQL or to invoke a stored procedure using JDBC. Direct database \naccess is commonly used in practice. \n A  bean implementation class is an ordinary Java class ﬁ le that contains the method implementations for \nthe EJB. An implementation class exposes a  business interface for remote and local access to business logic \nmethods. Restrictions on the Java class and methods used for an EJB ensure that everything works correctly \nwhen deployed within a container, such that they must be public, cannot be ﬁ nal, and cannot be abstract. \n A bean implementation class becomes an EJB by importing one or more EJB libraries and either including \none or more EJB annotations or declaring it an EJB in an associated descriptor ﬁ le (see  Figure 10.24 ). EJB anno-\ntations control the abstractions of the container and generate deployment metadata. As of EJB3 the embedded \nannotations can be used to generate the descriptor ﬁ le. As with entity beans, a manually coded descriptor ﬁ le \n(i.e., created without using annotations) is supported for backward compatibility with EJB2. In EJB3, the embed-\nded annotations typically are used to generate the deployment metadata, including any vendor-speciﬁ c variations. \n The EJB type annotations are: \n ■  @javax.ejb.Stateless \n ■  @javax.ejb.Stateful \n ■  @javax.ejb.MessageDriven \n The ﬁ rst two deﬁ ne a session bean as being either stateless or stateful. The third deﬁ nes a message-driven \nbean (i.e., one that interacts with JMS message queues). The  Stateless annotation is more commonly used \nthan  Stateful . In EJB3, the  @javax.ejb.entity annotation is used only to include an EJB 2.1 entity bean \ninto an EJB3-compliant application server. \n Other annotations specify transaction control, security, and how to handle messages and resources. Each of \nthe annotations other than the EJB type has a default value if not speciﬁ ed. For example, if a transaction con-\ntrol annotation is not speciﬁ ed, the default is to require a transaction for each method in a class. \n The example in  Figure 10.19 illustrates a stateless session bean for a group of methods that can perform \nseveral operations for a ﬁ ctitious bank account management application. A session bean typically is invoked by \nthe servlet engine, although it can also be invoked using a Web Service, another EJB, or a Swing client. Since \nno  @TransactionAttribute annotation is included, the bean uses default of container-managed transac-\ntions with a transaction required for the execution of each method. Thus, if a method is called from another \nmethod, the calling method’s transaction will be used. Otherwise a new transaction will be created. \n An EJB  reference is needed to invoke a bean, with the exception of a Web Service invocation of a stateless \nsession bean method. The EJB reference can be injected or retrieved using a directory lookup. A typical direc-\ntory service for a Java EE-based application server is the Java Naming and Directory Interface (JNDI).  Figure \n10.20 shows an example of a client with an EJB reference injected using the  @EJB annotation to provide the \nreference that can be used to invoke the  Transfer EJB. The  @Resource annotation also can be used to inject \na variety of other external information, such an environment variable, an EJB context, a JMS destination, a \nconnection factory, or a data source. \n The default for accessing an interface is local access; that is, from an EJB client running in the same address \nspace. A remotely accessible interface needs to be explicitly identiﬁ ed using the  @javax.ejb.Remote annota-\ntion. The  @javax.ejb.Local annotation explicitly restricts an interface to local access. \n\n\n The  @TransactionManagement annotation deﬁ nes whether the implicit or explicit programming model \nis used for a bean. Valid values for this attribute are: \n ■  TransactionManagementType.CONTAINER \n ■  TransactionManagementType.BEAN \nimport javax.ejb.Stateless;\n@Stateless\npublic class AccountOperationBean implements AccountOperation {\n    public double balance(int accountNumber) {\n        Account acct = this.getAccount(accountNumber);\n        return acct.getBalance();\n    }\n    public void deposit(int accountNumber, double amount) {\n        Account acct = this.getAccount(accountNumber);\n        acct.setBalance(acct.getBalance() + amount);\n    }\n    public void withdraw(int accountNumber, double amount) {\n        Account acct = this.getAccount(accountNumber);\n        if (acct.getBalance() < amount) {\n            throw new InsufficientFundsException();\n        }\n        acct.setBalance(acct.getBalance() - amount);\n    }\n    private Account getAccount(int accountNumber) {\n        // Code to retrieve the Account balance\n    }\n}\n FIGURE 10.19 \n Stateless Session Bean. This stateless EJB implements the operations of the  AccountOperation interface to check a \ncustomer’s account balance and to withdraw or deposit funds. \nimport javax.naming.Context;\nimport javax.naming.InitialContext;\npublic class TransferClient \n{\npublic static void main(String [] args)\n  {\n    @EJB Transfer myTransfer; \n    myTransfer.transfer(123, 456, 100.00);\n }\n}\n FIGURE 10.20 \n Sample EJB Reference for Transfer Class. An EJB reference can be injected to allow a front-end program or request \ncontroller to invoke an EJB. \n10.4 Java Enterprise Edition  303\n\n\n304  CHAPTER 10 Transactional Middleware Products and Standards\n When the value is  CONTAINER the implicit programming model is used, which is called  container man-\naged in EJB terminology. When it’s  BEAN , the explicit programming model is used, called  bean managed . \n The  @javax.ejb.ApplicationException annotation marks an application exception that can be thrown by \na method in a bean managed transaction. The exception is reported directly to the EJB client when it occurs. The \nrollback attribute of the annotation can be used to deﬁ ne whether the exception automatically causes a rollback. \n The  @TransactionAttribute is used to control the operations of the implicit programming model, such \nas whether or not the container is required to start a new transaction before executing each method in the class. \nThe next section lists the valid values for this attribute. \n A  JPA entity can be deﬁ ned within an EJB to map its data to a relational database, using an object-relational \nmapping. The  @javax.persistence.Entity annotation deﬁ nes a Java class as a JPA entity. A JPA entity \ncan be used from within a session bean or a plain Java class. \n In previous versions of EJB this functionality was called bean-managed or container-managed persistence. \nJPA is lighter weight, easier to use, and more efﬁ cient than the previous EJB approach. A JPA entity maps the \ndata items and attributes of a Java class to one or more rows in one or more database tables. Optional attributes \ncan be used to specify ﬁ ne-grained control over which data items are persisted. \n The example in  Figure 10.21 shows a stateless session bean that uses a JPA  EntityManager to create a new \naccount record. Bean methods access and update the persistent resource. Operations to create or update an entity \nshould execute in the context of a transaction, which is why the  @TransactionAttribute annotation is set to \n REQUIRED . It creates a new  Account record based on parameters passed to the  createAccount method, and \nthen calls the  em.persist method to add a row to the database table. When used in an EJB, a JPA entity partici-\npates in the global transaction managed by the Java Transaction API (JTA; described later in this section). When \nused outside of an EJB, a JPA entity can use a JDBC managed transaction or a global transaction managed by JTA. \n Transaction Management in Java \n Java developers creating TP applications may choose to use a persistence abstraction from a plain Java object \nor from within an EJB. If using a plain Java object, a session can be established with a single resource manager \nimport javax.ejb.Stateless;\nimport javax.ejb.TransactionManagement;\nimport javax.persistence.PersistenceContext;\nimport javax.persistence.EntityManager;\n...\n@Stateless\n@TransactionAttribute(REQUIRED)\npublic class AccountCreationBean implements AccountCreation {\n    @PersistenceContext(unitName=“AccountSystem”)\n    private EntityManager em;\n    public void createAccount(String customerName, int accountNumber, \n                              double initialDeposit) {\n        Account acct = new Account(accountNumber);\n        acct.setCustomerName(customerName);\n        acct.setBalance(initialDeposit);\n        em.persist(acct);\n    }\n}\n FIGURE 10.21 \n Using a JPA Entity to Create an Account Record. A JPA entity manager retrieves and updates persistent items in a database. \n\n\n to directly control its transactions. If using a persistence abstraction within an EJB, JTA is used to control the \ntransaction. \n An EJB does not have an equivalent mechanism to the .NET Framework  set.complete() method because \nan EJB is not treated as a transaction participant. Nor does the EJB speciﬁ cation include a concept directly com-\nparable to an ambient transaction; that is, one that exists independently of the lifecycle of an object for which a \ntransaction is started. However, Java EE does offer the  setRollbackOnly command for a subobject to tell the \ntop-level object to abort. \n The Implicit Programming Model \n In the implicit programming model the EJB container automatically starts and terminates a transaction when a \ntransactional EJB method is invoked. Successful completion commits the transaction and an exception can be \nset to cause an automatic abort. \n By default, the EJB container automatically invokes a business method within a transaction context and \nautomatically decides whether to commit or abort the transaction, depending on whether the method completes \nsuccessfully or not. A transaction annotation can be speciﬁ ed on the entire bean class, or on individual methods \nto override the default behavior. An annotation at the method level overrides an annotation at the class level, if \nboth are speciﬁ ed. \n Valid values for the  @TransactionAttribute annotation are: \n ■  REQUIRES_NEW \n ■  REQUIRED \n ■  SUPPORTS \n ■  NOT_SUPPORTED \n ■  MANDATORY \n ■  NEVER \n The transaction attribute values instruct the container to perform the following operations: \n ■  REQUIRES_NEW . Every invocation of the method starts executing in a new transaction, whether or not \nthe caller was already executing in a transaction. \n ■  REQUIRED . If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method starts executing in a new transaction. \n ■  SUPPORTS . If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method does not execute within a transaction. \n ■  NOT_SUPPORTED . The called method does not execute within a transaction, even if the caller is running \nwithin a transaction. \n ■  MANDATORY . If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, an exception is raised. \n ■  NEVER . If the caller is already running within a transaction, an exception is raised. \n If the transaction attribute of a message-driven bean is  REQUIRED , then the bean executes as a top-level \ntransaction. The transaction includes its operations on the message queue and on any other transactional \nresources. Operations in a message-driven bean cannot join the transactional operations of any other bean. When \nthe transaction attribute is  NOT_SUPPORTED , the message-driven bean’s operations do not execute in the context \nof a transaction. A container-managed transaction is required to coordinate operations on message queues with \noperations on other persistent resources. \n An EJB always uses JTA unless the  NOT_SUPPORTED attribute is speciﬁ ed. JTA implementations use a \none-phase commit optimization whenever there’s a single resource manager. This optimization is sufﬁ cient for \n10.4 Java Enterprise Edition  305\n\n\n306  CHAPTER 10 Transactional Middleware Products and Standards\n most applications. However, unlike the PSPE optimization in .NET’s  System.Transactions , it still involves \nthe application server’s transaction manager. There are workarounds, but they involve the EJB doing explicit \ntransaction control with the RM. \n Figure 10.22 illustrates a session bean that uses the  REQUIRED attribute to invoke two methods within the \nsame transaction. The  REQUIRED attribute means that if the caller is executing in a transaction, then any called \nmethods also execute within the caller’s transaction. If the caller is not executing a transaction, the method \nexecutes in a new top-level transaction. \n An exception class can be deﬁ ned so that when the execution of a transaction throws an exception, the \napplication can catch it in the exception handler and throw an application-speciﬁ c exception. In the example \nin  Figure 10.23 the  @ApplicationException annotation sets the  rollback attribute to  true , meaning that \nwhen the exception handler catches an exception of the deﬁ ned type, a  TransferException is raised, and a \nrollback is signaled for the transaction. \npublic class TransferBean implements Transfer {\n    @EJB AccountOperation op;\n   ...\n    @TransactionAttribute(REQUIRED)\n    public void transfer(int acct1, int acct2, double amount) {\n        op.withdraw(acct1, amount);\n        op.deposit(acct2, amount);\n    }\n}\n FIGURE 10.22 \n Transactional Session Bean Invoking Two Methods. Both the  Withdraw and  Deposit methods are invoked within the \nsame transaction. \n>>> Exception class:\nimport javax.ejb.ApplicationException;\n@ApplicationException(rollback = true)\npublic class TransferException extends RuntimeException {}\n>>> Session bean class:\nimport javax.ejb.*;\n@Stateless\n@TransactionManagement(TransactionManagementType.CONTAINER) \npublic class TransferBean implements Transfer {\n  @TransactionAttribute(TransactionAttributeType.REQUIRES_NEW)\n  public void transfer(int acct1, int acct2, double amount) {\n    try {\n        <<do transfer>>\n    } catch (Exception e1) {\n        <<log>>\n        throw new TransferException(e1);\n    }\n  }\n}\n FIGURE 10.23 \n Using a Try Block to Catch an Exception. The  try block allows an exception to be caught and transferred for the transaction. \n\n\n Transaction control attributes can be speciﬁ ed either as embedded annotations and attributes in EJB3 or in a \ndeployment descriptor ﬁ le, which is illustrated in  Figure 10.24 . A descriptor ﬁ le can be either hand-coded or gen-\nerated from annotations and attributes. For each EJB listed in the example ﬁ le, the implicit programming model \nis speciﬁ ed ( transaction-type is  container ) and a transaction control attribute is associated with either all \nmethods of a class (using an asterisk) or with a particular method of the class (for example,  transfer ). \n The Explicit Programming Model \n In the Java EE environment, explicit transaction programming directly uses the Java Transaction API (JTA) in \na bean-managed transaction. JTA has three major functional areas: \n ■  Simple transaction demarcation: javax.transaction.UserTransaction \n ■  Transaction manger control: javax.transaction.TransactionManager \n ■  A Java mapping of the XA API for resource integration: javax.transaction.xa.XAResource \n<ejb-jar>\n  ...\n  <session>\n    <ejb-name>AccountOperationBean</ejb-name>\n    ...\n    <transaction-type>Container</transaction-type>\n  </session>\n  <session>\n    <ejb-name>TransferBean</ejb-name>\n    ...\n    <transaction-type>Container</transaction-type>\n  </session>\n  <assembly-descriptor>\n      ...\n    <container-transaction>\n      <method>\n        <ejb-name>AccountOperationBean</ejb-name>\n        <method-name>*</method-name>\n      </method>\n      <trans-attribute>Required</trans-attribute>\n    </container-transaction>\n   \n    <container-transaction>\n      <method>\n        <ejb-name>TransferBean</ejb-name>\n        <method-name>transfer</method-name>\n      </method>\n      <trans-attribute>RequiresNew</trans-attribute>\n    </container-transaction>\n  </assembly-descriptor>\n</ejb-jar>\n FIGURE 10.24 \n Using an EJB Deployment Descriptor to Specify Transaction Control Attributes. The EJB descriptor ﬁ le associates EJB \nmethod names with attributes that deﬁ ne whether the program in the bean uses the explicit or implicit programming \nmodel, and whether or not a transaction context is required to invoke the method. \n10.4 Java Enterprise Edition  307\n\n\n308  CHAPTER 10 Transactional Middleware Products and Standards\n The  UserTransaction part of the API is used for bean managed transactions; that is, for explicit trans-\naction programming in an EJB. The  TransactionManager part of the API typically is used by applica-\ntion server vendors to access and control the functions of an independent transaction manager, such as a Java \nTransaction Service (JTS) compliant transaction manager. Some application server products explicitly prohibit \nits use. The  XAResource portion of the API is a Java mapping of the standard XA interface that the applica-\ntion server uses to include XA-compliant resource managers into JTA-managed transactions. \n The underlying implementation of JTA isn’t explicitly deﬁ ned and may vary from vendor to vendor. JTS \nspeciﬁ es one implementation, using the Object Management Group’s Object Transaction Service (OTS, \ndescribed in Section 10.8) and General Inter-ORB Protocol (IIOP). Vendors typically use a combination of \nJTS and XA-compliant libraries. Transaction interoperability between transactional Java EE application serv-\ners is optional, but if supported it must use JTS/OTS. \n JTA can be used in a Java EE environment. It can also be used outside a Java EE environment when an \nindependent implementation of JTA is available, such as Atomikos or the JBoss Transaction Manager. \n Figure 10.25 illustrates the use of explicit transaction management within a stateless session bean. The \n UserTransaction part of the JTA API is used in a stateless EJB to start ( utx.begin() ) and terminate \n( utx.commit() ) a transaction. A transaction has to be started and completed in the same method, although \nthe transaction context (as in the implicit model) can be propagated to other methods. As shown in the exam-\nple, an exception handler can be deﬁ ned to issue the  utx.rollback() command and throw an exception to \nthe client if there’s a problem. \n Integration with Legacy TP Monitors \n The Java Connector Architecture (JCA) deﬁ nes a standard way for Java-EE-compliant transactional middleware \nto connect to legacy TP monitors and other existing systems such as packaged applications. JCA provides a set \nof APIs and system programming interfaces for developing and deploying connections and adapters to existing \n@Stateless\n@TransactionManagement(TransactionManagementType.BEAN) \npublic class TransferBean implements Transfer {\n@Resource private UserTransaction utx;\npublic void transfer(int acct1, int acct2, double amount) {\n    try {\n        utx.begin();\n        <<do transfer>>\n        utx.commit();\n    } catch (Exception e1) {\n        try { utx.rollback(); } catch (Exception e2) {}\n        <<log>>\n        throw new TransferException(e1);\n    }\n}\n FIGURE 10.25 \n Explicit Transaction Control in a Stateless Session Bean. A stateless session bean can explicitly manage a transaction \nthat includes updates to multiple resource managers. \n\n\n systems. JCA can propagate a transaction context from an EJB to a legacy TP monitor, depending on the \ncompatibility of the application server’s and legacy TP monitor’s transaction protocols. \n JCA deﬁ nes a set of system-level contracts between a Java EE application server and an existing system. \nThey include contracts for communications, security, and transaction management. JCA deﬁ nes a common \nclient interface that allows an EJB to call an adapter written for an existing technology’s external client or a \ncustom-developed adapter. It can propagate application server features using one or more connection contracts, \nsuch as one that propagates transaction context. JCA calls such a contract a  resource adapter . A resource \nadapter plugs into the application server as a protocol and functional bridge between an application server and \nan existing system. \n Transaction management is integrated with JTA and is based on wrapping each existing transactional envi-\nronment as an XA resource so it can be coordinated using the application server’s transaction manager. JCA \noffers the application server the option to delegate transaction management to the local resource when a single \nresource manager is involved in the transaction, saving the overhead of two-phase commit coordination when \nit isn’t needed. Transaction propagation works with both the implicit and explicit programming models. \n Existing systems such as legacy TP monitors typically support external clients, for example ECI for CICS \nand TP Web Connector for ACMS. Vendors also have the option of providing their own JCA-compliant adapter. \nJCA adapters are capable of bidirectional communication, including transactions, between existing systems and \napplication servers. \n Spring Transactions \n The Spring Framework is a popular open source programming model for developing enterprise applications, \nsuch as TP applications, using plain old Java objects (POJOs) and EJBs. Spring objects, called Spring Beans, \ncan be deployed into Java-EE-compliant application servers, standalone servlet engines that don’t support \nEJBs, or OSGi Frameworks such as Eclipse Equinox and Apache Felix. \n The Spring Framework offers a widely-adopted lightweight alternative to EJBs, including transactional mid-\ndleware functions. Spring works with popular EJB containers and standalone JTA-compliant transaction manag-\ners such as the JBoss Transaction Manager, the Atomikos transaction manager, or the Java Open Transaction \nManager (JOTM) from the OW2 Consortium. The Spring Framework extends transaction processing applica-\ntions outside of the Java-EE-compliant application server environment and offers a lightweight alternative for \nsingle resource transactions. \n Spring supports two models for transaction management: \n ■  Local: Delegates transaction management to the persistence abstraction mechanism (e.g., JDBC or JPA) \n ■  JTA: Uses the JTA API from within the Spring Platform Transaction Manager API explicitly to initiate \nand terminate transactions \n Spring supports both implicit and explicit programming models for either the local or JTA transaction man-\nagement models. The implicit and explicit models are called  declarative and  programmatic demarcation , \nrespectively. Declarative demarcation uses embedded annotations whereas programmatic demarcation uses the \nJTA API. Spring Beans using transactions can be deployed within an EJB container or independently of an \nEJB container as long as the requisite transaction management infrastructure is available (i.e., a transactional \npersistence abstraction mechanism and/or a standalone JTA implementation). \n Spring transaction management uses the Spring Platform Transaction Manager API to abstract the transac-\ntion management and programming models. The local and JTA transaction management models are  strategies . \nA transaction management strategy is deﬁ ned or altered using a conﬁ guration ﬁ le associated with a Spring \n10.4 Java Enterprise Edition  309\n\n\n310  CHAPTER 10 Transactional Middleware Products and Standards\n Bean. The Spring Framework focuses primarily on local transaction management as the most common use of \ntwo-phase commit; that is, coordinating transactional resources that reside on the same machine. \n The Spring Framework supports local propagation of transaction context across method invocations using \neither strategy. Remote propagation of transaction context uses a JTA-aware communication protocol (e.g., \nRMI and RMI/IIOP) and requires explicit JTA programming. \n The Spring Framework allows TP application developers to deﬁ ne which exceptions will cause a rollback, \na capability that is also available in EJB3. \n As shown in  Figure 10.26 , the Spring Framework uses the  PlatformTransactionManager interface to \nimplement the transaction strategy declared for a Spring Bean. The strategy can choose a transaction manager \nthat provides a JTA API, or it can use the transaction management capabilities of a JDBC connection. However, \nit is also possible for a Java programmer to use this interface directly from a Spring Bean to programmatically \nset the strategy. \n In  Figure 10.27 the  PROPAGATION_REQUIRED attribute is set to ensure that the method is invoked within a \ntransaction context. Note that remote context propagation requires the use of the explicit programming model. \nThe example also illustrates the way in which the Spring Framework allows a rollback to be associated with an \napplication deﬁ ned exception, such as  MyException . \npublic interface PlatformTransactionManager {\n    TransactionStatus getTransaction(TransactionDefinition definition)\n        throws TransactionException;\n   void commit(TransactionStatus status) throws TransactionException;\n   void rollback(TransactionStatus status) throws TransactionException;\n}\n FIGURE 10.26 \n The Spring Framework Abstract Interface for Transaction Management. The interface is used internally by the Spring \nFramework to set the transaction strategy, which is deﬁ ned in an associated conﬁ guration ﬁ le. It can also be used \nexplicitly by developers to control the transaction strategy programmatically. \nDefaultTransactionDefinition def = new DefaultTransactionDefinition();\n  def.setName(“Transfer”);\n  def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED);\n  TransactionStatus status = txManager.getTransaction(def);\n    try {\n      //execute your business logic here\n    }\n    catch (MyException ex) {\n      txManager.rollback(status);\n      throw ex;\n    }\n  txManager.commit(status);\n FIGURE 10.27 \n Using the Spring Framework for Explicit Transaction Management. A new transaction is deﬁ ned for the  Transfer \nmethod along with its propagation behavior. The transaction is initiated and completed within the  try block, which also \ncan throw the rollback exception. \n\n\n The implicit model implements declarative demarcation using Spring’s  @Transactional annotation. This \nworks similarly to EJB’s annotation system. Spring supports the EJB  @TransactionAttribute values and \nextends them for deﬁ ning a custom isolation level or a read-only transaction, or to control cache ﬂ ushing. \n In the example in  Figure 10.28 , the  @Transactional annotation indicates using the  Propagation.\nREQUIRES_NEW property that a new transaction must be started before executing the  withdrawFunds method, \neven when a transaction context is propagated on the method invocation. Spring supports EJB propagation \noptions and adds a  NESTED option to support nested transactions. This can be used by persistence abstraction \nmechanisms that support savepoints, such as a JDBC3 driver or Apache OpenJPA. \n Switching the transaction management strategy from local to JTA is accomplished using a conﬁ guration \nchange. For example, the ﬁ rst part of  Figure 10.29 conﬁ gures the local Spring transaction management strat-\negy to use a JDBC driver and the second part conﬁ gures a JTA strategy. A conﬁ guration change to a JTA strat-\negy may be necessary when a Spring Bean accesses multiple resource managers within the same transaction, \nor needs to propagate transaction context remotely. \n 10.5  SERVICE-ORIENTED ARCHITECTURE \n The SOA style of design provides many beneﬁ ts, including functional reuse across multiple applications, \nimproved ﬂ exibility in developing new applications, and interoperability across disparate software systems, \nsuch as .NET, Java EE, and legacy TP monitors. SOA-based applications can include services created from \nJava EE or .NET Framework objects, legacy TP monitor procedures, asynchronous message queues, or data-\nbases. SOA products create and manage services for these and other environments. They also combine services \ninto business process ﬂ ows. Interoperability across disparate software systems enhances the beneﬁ ts of SOA \nfor reuse and ﬂ exibility, but presents additional challenges for transaction management. \n@Transactional(propagation=Propagation.REQUIRES_NEW)\n  public void withdrawFunds(Account Amount) {\n    ...\n  }\n FIGURE 10.28 \n Spring Transactions Implicit Model. Spring uses the  @Transactional annotation to declaratively specify transaction \ncontrol for a method (method code not shown). \n<tx:annotation-driven/>\n<bean id=“transactionManager”\n class=“org.springframework.jdbc.datasource.DataSourceTransactionManager”>\n   <property name=“dataSource” ref=“myTargetDataSourceBean”/>\n</bean>\n <tx:annotation-driven/>\n<bean id=“transactionManager”\n class=“org.springframework.transaction.jta.JtaTransactionManager”/>\n FIGURE 10.29 \n Switching Transaction Strategies. Spring transactions use conﬁ guration to switch transaction management strategies. \n10.5 Service-Oriented Architecture  311\n\n\n312  CHAPTER 10 Transactional Middleware Products and Standards\n Applications based on the Service-Oriented Architecture (SOA) style of design began to appear in the \nlate 1990s and early 2000s using products such as Progress Software’s CORBA-compliant Orbix and IBM’s \nWebSphere MQ. Some applications based on the SOA design use both, such as the well-documented Credit \nSuisse Information Bus. \n More recently, Web Services have become a popular technology for SOA. As mentioned in the .NET \nFramework and Java EE sections, both of those technology suites support Web Services. They also support \nREST/HTTP, another popular technology for SOA. We will discuss both technologies for SOA. \n Products and services speciﬁ cally designed for use with SOA are offered by HP, IBM, Microsoft, Oracle, \nProgress Software, Red Hat, Software AG, TIBCO Software, and others. Most SOA products support a two-\nphase commit protocol for services that execute as a transaction. Some products also include a compensation-\nbased protocol for services that execute as a business process. SOA-based applications often include both kinds \nof services, sometimes in the same application. Sometimes these two types of services are called ﬁ ne-grained \nand coarse-grained, or tightly-coupled and loosely-coupled, respectively. \n The exact characteristics and details of the SOA products vary, but they tend to fall into these general \ncategories: \n ■  Service enablement: Create Web Service interfaces and REST/HTTP access to existing and new pro-\ngrams, objects, databases, and message queues. \n ■  Business process management: Compose and execute ﬂ ows of sequences of services. \n ■  Governance: Store and retrieve service metadata, including development lifecycle support. \n ■  Management: Monitor runtime service execution and enforce policy contracts such as security and \navailability. \n In a typical SOA-based application, a request type can invoke a transaction that uses cooperating services \nwithin a single application environment, or a business process that invokes multiple services in sequence. In \nthe ﬁ rst case, any transaction protocol can be used, such as a native two-phase commit or the WS-AT protocol \nfrom WS-Transactions. For a business process, however, a compensation-based protocol is more likely to be \nrequired, such as the WS-BusinessActivity protocol from WS-Transactions. \n Several factors apply to the choice of Web Services or REST/HTTP based technologies for an SOA-based \napplication. In general, requirements for RPC communications and for wrapping existing systems favor the \nuse of Web Services, and requirements for hosting applications on the Web favors the use of REST/HTTP. \nOther factors include whether the application is a purely web-based application, or whether the application is a \nmixture of web components and transactional middleware components. Web Services are readily available for \ntransactional middleware environments, including legacy TP monitors. However, given the success of the Web, \ndevelopers would do well to prepare for a web-based architecture whenever possible. \n Web Services-Based SOA \n Web Services use SOAP as the message format, with parameters expressed in XML and interfaces expressed \nin Web Services Deﬁ nition Language (WSDL). Some implementations allow a SOAP message to contain a \nsingle XML document instead of RPC-style arguments. Optional headers are added to SOAP messages to \nexpress requirements for system functions such as security, reliability, and transaction propagation. \n One popular application of Web Services is interoperability between native RPC protocols, such as Java \nEE’s RMI and the Microsoft RPC. This is done by programs that understand both formats, translating native \nRPC messages into and out of the SOAP format. \n In  Figure 10.30 , the SOAP message is created using a C# object linked with a proxy generated from a \nWCF interface that uses a Web Services binding. The SOAP processor in the WCF environment obtains the \n",
      "page_number": 316
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 331-340)",
      "start_page": 331,
      "end_page": 340,
      "detection_method": "topic_boundary",
      "content": "WSDL  interface from the remote service, perhaps using a registry, and marshals the C# data types into XSD \ndata types using the message deﬁ nition in the remote service’s WSDL ﬁ le. The caller uses the Web Services \naddress, or obtains the address of the remote service from the WSDL ﬁ le as well as the transport to be used, \ntypically HTTP. The WSDL ﬁ le may also include a WS-Policy assertion that requires a transaction context \nto invoke the remote service. In that case the WCF SOAP processor includes in the SOAP message header a \ntransaction context conforming to the policy assertion. \n When the remote Java service receives the request message, its SOAP processor unmarshals the XSD data \ntypes into Java data types (perhaps using the Java Architecture for XML Binding (JAXB)). The SOAP proces-\nsor checks whether any SOAP headers need to be interpreted, such as a transactional context, and then uses \nthe service name in the interface to dispatch the request to a local Java object for processing. When a transac-\ntion context header is received, the SOAP processor calls a transaction manager to enroll the local transaction \nin a transaction initiated by the service requester and propagated on the request. Results are returned in the \nresponse message, following this path in reverse. If an exception occurs, it is passed back to the calling service \nusing a SOAP Fault message. The WS-Transactions standard deﬁ nes how the transaction context is propagated \nand how the commitment protocol is executed. \n The style of Web Services illustrated in this example focuses on their use within the .NET Framework \nand Java EE-based application server environment. However, SOA vendors also provide products that do not \ndepend upon either of these transactional middleware systems. Instead, they use a  mediator to process a SOAP \nmessage and submit requests to programs, queues, and databases. A mediator is software that sits between the \nservice requester and the service provider. It is also typically responsible for processing any optional SOAP \nheaders for security, reliability, or transactions. \n Another popular application of Web Services is to encapsulate a series of ﬁ ne-grained services inside a busi-\nness process, exposed using a coarse-grained service. A coarse-grained service may not need the RPC-oriented \nmechanisms described in the previous example. Instead, an XML payload may be consumed directly. However, \nthe message can still carry optional SOAP headers such as a WS-Security or WS-Transactions context. \n The transaction context for the ﬁ ne-grained services shown in  Figure 10.31 executes within a business pro-\ncess and uses a compensation-based protocol such as WS-Transactions ’ WS-BA to undo the results of transac-\ntions executed within the steps of the business process. A compensation-based protocol can also be used for \nRM \nSOAP\nProcessor \nSOAP Message\nSOAP\nProcessor\nC#\nService\nJava\nService\nOptional Transaction\nContext Header\nTM \nTM \nRM \n FIGURE 10.30 \n Web Services Interoperability. Two different execution environments can interoperate using SOAP, potentially including a \ntransaction context. \n10.5 Service-Oriented Architecture  313\n\n\n314  CHAPTER 10 Transactional Middleware Products and Standards\n recovery from failures in interactions among coarse-grained services, especially those using asynchronous com-\nmunication protocols. \n REST/HTTP-Based SOA \n In the REST/HTTP approach to SOA, interfaces such as WSDL are not used. Nor are message headers such \nas those deﬁ ned for SOAP. Instead, HTTP headers are used and resource representations are exchanged \nand processed. Resource representations typically use XML or JavaScript Object Notation (JSON) formats. \nInformation contained within the resources tells the client what it’s allowed to do. The server accepts HTTP \nverb requests (GET, PUT, DELETE) or interprets information it receives from the client on a POST request. \nTherefore, typical RPC artifacts aren’t necessary, such as an interface compiler, proxies and stubs, and mar-\nshaled parameters in the form of method arguments. \n Instead , REST/HTTP assigns a URI to a resource and exchanges representations of the resource using \nHTTP verbs. For example, the resource could be a database and the exchanged representation could be an \nXML representation of rows retrieved from or to be stored in a database table. \n Unlike Web Services, transaction propagation for REST/HTTP isn’t deﬁ ned. However, transactions can be \nsupported by representing each transaction as a unique resource with which HTTP verbs interact. To start a trans-\naction T, the server creates a resource R T that represents the transaction. All of T’s operations on (other) trans-\nactional resources R \u0002 (such as rows of database tables) are sent to R T , so that it can keep track of before- and \nafter-images of R \u0002 . T ﬁ nishes by sending a commit or abort operation to R T , which does the corresponding action \nand then deletes R T . \n The reason for representing the transaction as a resource is that REST/HTTP doesn’t support shared ses-\nsion state. Since there is no session on which to propagate the transaction context, the resource is used to hold \nthat context. Indeed, it holds the entire transaction state. The client maintains its application state and drives \nthe state changes of the server resource that represents the transaction. \n REST /HTTP is often a good choice for communication between companies, in which the cost of pro-\ncessing a self-describing XML message isn’t justiﬁ ed due to the relatively small volume of such messages. \nThe REST/HTTP approach is also simpler than the RPC style of interaction more commonly used with Web \nServices, and thus is easier to use. A multistep REST/HTTP-based exchange between two companies can use \na compensation-based transaction protocol. \nService A\ncan be a business\nprocess that invokes\nfine-grained services\nS1, S2, S3   \nService Requester\ninvokes coarse-\ngrained service A \nS3\nS2\nS1\nTransaction\nContext \nCompensation\nSteps  \n FIGURE 10.31 \n Encapsulating Fine-Grained Services in a Business Process. In an SOA environment, the service requester may invoke \na coarse-grained service that encapsulates and invokes a series of ﬁ ne-grained services within a compensation-based \ntransaction context. \n\n\n Figure 10.32 illustrates clients that understand REST/HTTP, such as Silverlight, WCF, Java EE (through the \nJAX-RS API), and Java Script. These interact with the web server via HTTP verbs. The web server typically \ndispatches the document received via REST/HTTP to a program on the server side, such as a .NET Framework \nor Java EE object to interact with the resource, such as a database. \n REST /HTTP architectures typically use reliable messaging to capture and process messages after they are \nreceived. Large web businesses also typically deploy redundant hardware and software systems to ensure reli-\nable request capture and processing. For example, a REST/HTTP request message may be durably stored before \nsending it to the transaction server and processing it against the database. Reliable schemes also include the \nability to detect and ﬁ lter duplicate messages, or to design messages as idempotent. \n An SOA project initially should deﬁ ne a blueprint or style of design before identifying a particular technol-\nogy or how to apply it. The examples in this section illustrate some possible implementations, highlighting the \nrelationship between transaction management and SOA designs using popular technologies. However, many \nmore approaches are possible. \n 10.6  PERSISTENCE ABSTRACTION MECHANISMS \n Much of the application code in a TP system makes direct use of database functionality. Some of this function-\nality is closely related to transactional middleware, namely, database sessions and stored procedures. Therefore, \neven though database APIs are beyond the scope of this book, this chapter on transactional middleware prod-\nucts and standards would be incomplete without some discussion of these closely-related  topics. \n Early database systems for enterprise computing executed in the same address space as the application and \ntherefore could be invoked directly as a runtime library. With the advent of client-server architectures in the \n1980s, these database systems were redesigned to execute in a separate process, that is, as a database server. \nThis enables the database system to run on a separate machine from the applications that use the database. In \nthis architecture, the application and database system need to communicate using messages. This communica-\ntion requires that a fair bit of context is shared between the application and database system, such as the identity \nof the database that the application is using (since a database server may have access to multiple databases), \nthe security credentials of the application for access control, and the transaction ID of the transaction that the \napplication is currently executing. It would be expensive and cumbersome to pass this context information back \nand forth between the application and database system with every message. To avoid this, a session is needed to \nmaintain the shared context between the application and database server. \nHTTP Get  \nHTTP Post  \nRM\nTransaction\nContext\n.NET or\nJava\nprogram \nWeb\nServer\nJavaScript\nSilverlight\nWCF\nJAX-RS \n FIGURE 10.32 \n REST/HTTP Architecture for SOA. A program capable of using HTTP verbs constructs a document to exchange as a \nrepresentation of a server-side resource. The service requester receives a hypermedia document representing a resource, \nwhich can direct the requester with URIs and forms to POST information back to the resource to effect changes. \n10.6 Persistence Abstraction Mechanisms  315\n\n\n316  CHAPTER 10 Transactional Middleware Products and Standards\n A database session API has two main kinds of operations: operations to create, destroy, and update the ses-\nsion; and operations to send and receive database commands and data over the session. In addition, there are \nprovider interfaces that enable vendors to plug in drivers that enable the session API to be used with different \ndatabase server products. \n When it became clear that the session API would be a part of every database application, various efforts \nwere undertaken to standardize it, notably the SQL Access Group (originally an independent consortium whose \nactivities were transferred to the Open Group). To make it easy for PCs to access database servers, Microsoft \ndeveloped the Open Database Connectivity (ODBC) speciﬁ cation in conjunction with the SQL Access Group, \npublishing the ﬁ rst version in September 1992. The corresponding Java Database Connectivity (JDBC) \nstandard for Java objects, modeled on ODBC, was ﬁ rst published in 1997. \n Since then, there has been a steady stream of new APIs introduced, some of which include an ODBC or \nJDBC session. Many of the new APIs make it easier to access data from an object-oriented programming lan-\nguage and add support for a wider range of data types. Some also support access to other types of resources \nin addition to SQL databases. Examples include the Java Persistence API (JPA), OASIS Service Data Objects \n(SDO), Microsoft’s OLE DB (Object Linking and Embedding, Database), and Microsoft’s ActiveX Data \nObjects (ADO). There are also APIs that support more ﬂ exible mappings between the application’s view of the \ndatabase schema and the schema supported by the underlying database system, such as Red Hat’s Hibernate, \nOracle’s TopLink, and Microsoft’s ADO.NET Entity Framework and Language Integrated Query (LINQ). \n These APIs can be used independently of, or in conjunction with, transactional middleware. In either case, \ntheir use has to be considered as part of a multitier TP architecture. The following sections brieﬂ y describe \nODBC and JDBC and the use of stored procedures as transaction servers. \n ODBC and JDBC \n The architecture used for ODBC and JDBC deﬁ nes a client-side driver for use by the application program. The \nclient-side driver exposes a standard interface on top of the store-speciﬁ c functions and protocols. These func-\ntions and protocols receive and execute application commands against the database on behalf of the client. The \nclient and server usually run in different address spaces. The use of ODBC and JDBC drivers allows client-\nside SQL statements to be created dynamically and passed to the server for execution. ODBC can be used by a \nvariety of programming languages. JDBC is intended for use by Java applications. \n ODBC and JDBC provide a common architecture for accessing database products, ensuring some level \nof application portability and application interoperation with different database systems. ODBC clients and \ndrivers ship with every version of the Windows operating system and most versions of Linux. ODBC and \nJDBC drivers are supported by most database products, including Microsoft SQL Server, IBM’s DB2, Oracle \nDatabase, MySQL, and PostgreSQL. Bridges are also available to layer JDBC on ODBC and vice versa. \n ODBC access starts by deﬁ ning a data source, as follows: \n DSN  \u0003  mydsn;attribute1  \u0003  value;attribute2  \u0003  value;attributeN  \u0003  value; \n The data source deﬁ nition includes a data source name (DSN) and attributes of the connection, such as \nsecurity requirements, server address, and isolation level. JDBC uses a very similar format. \n Given a data source deﬁ nition, an application starts by opening a data source connection and then creates \nSQL statements to send to the connection. For example, a Java object using JDBC instantiates a driver man-\nager object to connect to the database and execute SQL statements against it. Once ODBC or JDBC establishes \na connection object to the database the application executes methods on the connection object. \n For example, the code fragment in  Figure 10.33 starts by instantiating a connection using the \n DriverManager object, thereby logging into the database. Then it instantiates a  Statement object in the \ncontext of the connection and uses it to execute a SQL statement. The result of the query is assigned to a \n\n\n ResultSet object, which in general can contain many rows. The program executes a simple  while loop to \nretrieve results from those rows. \n ODBC and JDBC features include transaction control. An ODBC or JDBC connection is created in \n AutoCommit mode by default, meaning that each SQL statement automatically is committed after it is com-\npleted. Turning off  AutoCommit allows two or more SQL statements to be grouped into the same transaction \nand committed using the  commit() method on the connection object. Similarly, the  rollback() method \naborts all SQL statements that executed after the last  commit() or  rollback() on the connection object. \nJDBC and ODBC both support savepoints for partial rollback. \n In  Figure 10.34 ,  AutoCommit mode is disabled for the connection, allowing the two statements, \n DepositAccount and  WithdrawAccount , to commit their updates together when the  commit() method is \ncalled. The question marks in the SQL statements act as a placeholder for the substituted amount, which in the \nexample is simply hardcoded for convenience. \n A popular function for an ODBC/JDBC driver is to execute a stored procedure, as in the following example. \n CallableStatement proc  \u0003 conn.prepareCall(“ { ?  \u0003 call TransferFunds(?, ?)  } ”); \n Executing the  proc command in the client causes the driver program to request the execution of the \n TransferFunds stored procedure. The application program assigns values to the second and third question-\nmark parameters before executing the statement and gets the value of the ﬁ rst question mark parameter after the \nstatement executes. \nConnection con = DriverManager.getConnection\n           (“jdbc:myDriver:Wombat”, “Login”,“Password”);\n \nStatement stmt = con.createStatement();\nResultSet rs = stmt.executeQuery(“SELECT a, b, c FROM Table1”);\nwhile (rs.next()) {\n \nint x = rs.getInt(“a”);\n \nString s = rs.getString(“b”);\n \nfloat f = rs.getFloat(“c”);\n \n}\n FIGURE 10.33 \n JDBC Connection and SQL Statement Execution. JDBC (and ODBC, not shown) establishes a connection by providing a \nlogin username and password and then sends SQL statements to the connection. \ncon.setAutoCommit(false);\nPreparedStatement DepositAccount = con.prepareStatement(\n    “UPDATE ACCOUNT SET Balance = Balance + ?”);\nDepositAccount.setInt(1, 100);\nDepositAccount.executeUpdate();\nPreparedStatement WithdrawAccount = con.prepareStatement(\n    “UPDATE ACCOUNT SET Balance = Balance - ?”);\nWithdrawAccount.setInt(1, 100);\nWithdrawAccount.executeUpdate();\ncon.commit();\n FIGURE 10.34 \n Disabling Auto Commit for a JDBC Connection. When  AutoCommit is disabled, it’s possible to group multiple operations \ninto the same transaction, such as these statements that execute withdrawal and deposit operations. \n10.6 Persistence Abstraction Mechanisms  317\n\n\n318  CHAPTER 10 Transactional Middleware Products and Standards\n Object -relational mapping solutions generate mappings from classes and their members to tables and col-\numns of a relational database. For example, the Java Persistence API (JPA), which is part of Java EE, maps \nJava objects to rows in a relational database system. The ADO.NET Entity Framework provides similar func-\ntionality for the .NET Framework. Other APIs support data item mappings to other types of resource managers \nand allow multiple resource managers to be combined in a single program access. \n Stored Procedures \n Most relational database systems support stored procedures, which can be used to implement a transaction server. \nStored procedures can be called directly from application code from any tier in a multitier TP architecture. \n Database system products typically offer a stored procedure language derived from SQL. Often it’s a pro-\nprietary one because the SQL/PSM standard is not widely implemented. The Oracle Database calls its stored \nprocedure language PL/SQL, SQL Server calls it Transact-SQL, and IBM’s DB2 calls it the SQL procedure \nlanguage. Database systems typically also support stored procedures written using standard programming lan-\nguages such as Java or a CLR-based language from the .NET Framework, such as C#. \n As with proprietary language stored procedures, the rules vary by product as to how much of the Java and \n.NET languages are supported, and how to deploy Java or .NET classes into the database. For example, in \nOracle Java methods must be public and static. The  LoadJava command is used to prepare a Java class for \nloading. Rules for deploying Java in DB2 include  “ fencing ” the Java code (i.e., restricting its capabilities), \nconﬁ guring it, and determining the argument types to be supported. For example, no user-deﬁ ned signal han-\ndlers are permitted in DB2. \n The inclusion of Java and CLR-based language procedures in the database provides the ability to run all \nor part of the transaction server code within the database process. This gives developers the ﬂ exibility to write \ntransaction server code before deciding how much of it to run as stored procedures and how much to deploy in \nanother address space, whether on the same machine or on a remote machine (see  Figure 10.35 ). Parts of the \nApplication Code\n[SQL]\nDatabase \nApplication Code\n[Call SQL]\nDatabase with\nSQL Stored\nProcedure\nApplication Code\n[Call procedure]\nDatabase with\nJava or .NET\nApplication Code \n FIGURE 10.35 \n Options for Using a SQL in Application Code or as a Stored Procedure. Stored procedures offer an application the choice \nof executing SQL statements inside the database instead of in the application code, using a proprietary SQL stored \nprocedure language, Java, or a .NET language. \n\n\n application that frequently invoke SQL statements should execute in a stored procedure, to minimize context \nswitching overhead. Parts of the application that are processor-intensive and make infrequent calls to SQL \nshould execute outside the stored procedure, so they can run on a different machine and not limit the scalabil-\nity of the database server, which is often a bottleneck. \n SQL Server Stored Procedure Examples \n We show some examples of stored procedures using Microsoft SQL Server. Stored procedures in other data-\nbase products work similarly. The example in  Figure 10.36 illustrates the native SQL Server stored procedure \nlanguage, Transact-SQL. This could be accessed from a web server or application process using an ODBC \nconnection by executing the  @Transfer command. In SQL Server, the stored procedure can also be invoked \nusing a Web Service. The procedure allocates variables using the @-sign preﬁ x and executes SQL statements \nsuch as  SELECT and  SET . A stored procedure is created using the database  CREATE command and can accept \ninput arguments and return output arguments. \n Figure 10.37 illustrates the use of SQL commands in a stored procedure written in C#. The stored proce-\ndure needs to include the partial class  StoredProcedures and manages the connection to SQL server as it \nwould in a WCF service. In either case, transaction control can group multiple operations on data. Transaction \nbracketing operations are the same for proprietary SQL and CLR-based or Java-based stored procedures. \nHowever, nested transactions and savepoints are supported only by proprietary SQL stored procedures. \n Using the .NET Framework’s ambient transaction feature, it’s possible to delegate transaction control from \nthe middleware to the stored procedure, and to include multiple resource managers in the same transaction, \nwhether control is deﬁ ned in the middleware or the stored procedure. \n Java Persistence API \n The Java Persistence API (JPA) deﬁ nes a standard for object-relational mapping between Java objects and rela-\ntional databases. JPA can be used independently from an EJB in a plain Java object and also can be used within \na stateless or stateful session bean. JPA was developed as part of the EJB3 speciﬁ cation as a replacement for \nEJB2 entity beans, which were used in EJB2’s container-managed persistence and bean-managed persistence \nobject-relational mappings. EJB2 entity beans continue to be supported in EJB3 for backward compatibility. \n The JPA speciﬁ cation is intended to unify multiple object-relational mechanisms for Java, such as \nJDO, Hibernate, and entity beans. In doing so JPA abandoned the heavyweight EJB2 persistence model that \nintegrated container-managed transactions, security, and concurrency within a single entity bean. JPA is based \non the lightweight persistent model made popular by products such as Red Hat’s Hibernate and Oracle’s \nTopLink. \nCREATE PROCEDURE Transfer (@fromAccount int, @toAccount int, @amount int) \nBEGIN TRAN  \n  UPDATE Account SET Balance = Balance - @amount WHERE AccountID = @fromAccount\n  UPDATE Account SET Balance = Balance + @amount WHERE AccountID = @toAccount\nCOMMIT TRAN\nEND\n FIGURE 10.36 \n Transact-SQL Stored Procedure for Transfer Operation. Execution of the stored procedure, whether directly from within \nobject code or using an ODBC or JDBC connection, results in the transfer of the given amount from one of the customer’s \naccounts to the other. \n10.6 Persistence Abstraction Mechanisms  319\n\n\n320  CHAPTER 10 Transactional Middleware Products and Standards\n JPA uses Java 5 annotations and XML descriptors to map the data items and attributes of a Java class to \nrelational database tables. JPA also includes a runtime  EntityManager API for processing queries and updates \nagainst the objects mapped to the database, using an object-level query language called Java Persistence Query \nLanguage (JPQL). \n Each JPA entity maps to a particular row in one or more tables and is uniquely identiﬁ ed by one or more \nﬁ elds or properties that comprise an identiﬁ er. The identiﬁ er of each entity is unique within the scope of an \ninheritance hierarchy for that entity. It can be used both by clients for querying and by the implementation for \nmaintaining instance identity throughout the transactional or persistence context. \n An implementation of JPA is called a  JPA provider . Examples of JPA providers include Oracle’s Kodo, \nRed Hat’s Hibernate, the Eclipse Foundation’s EclipseLink, and Apache OpenJPA. The JPA speciﬁ cation also \ndeﬁ nes a service provider interface that describes how an EJB container hosts a JPA entity, using such mecha-\nnisms as  EntityManager injection, propagation of persistence contexts, and Java classloading. Through these \nmechanisms, any EJB3-compliant application server can plug in any JPA provider and run it within the host \ncontainer. The Spring Framework’s container is also capable of hosting a JPA provider. \n JPA can be used outside of an EJB in a plain Java environment. In plain Java, the  EntityManager API is \nused directly to initiate and terminate transactions, which are always local to the  EntityManager that cre-\nated them (see  Figure 10.38 ). JPA transactions in a plain Java environment are simple JDBC-level single-RM \ntransactions. \nusing System;\nusing System.Data;\nusing System.Data.Sql;\nusing System.Data.SqlTypes;\nusing Microsoft.SqlServer.Server;\npublic partial class StoredProcedures\n{\n    [Microsoft.SqlServer.Server.SqlProcedure]\n     public static void Transfer()\n     {\n       SqlConnection conn = new SqlConnection();\n       conn.ConnectionString = “Context Connection=true”;\n       SqlCommand cmd = new SqlCommand();\n       cmd.Connection = conn;\n       cmd.CommandText = @“SELECT ToAccount, [Number] \n                         FROM Account ;”\n       conn.Open();\n       SqlDataReader rdr = cmd.ExecuteReader();\n       SqlContext.Pipe.Send(rdr);\n       rdr.Close();\n       conn.Close();    \n     }\n};\n FIGURE 10.37 \n Stored Procedure Written in C#. This stored procedure retrieves all matching account numbers. \n\n\n When running in an EJB the  EntityManager transaction joins the global transaction managed by JTA \n(see  Figure 10.39 ). Updates to JPA entities can then be coordinated with updates to any other transactional \nresources enlisted in the same transaction for the EJB. \n A JPA entity can be used in any stateful or stateless session bean with either the implicit or explicit pro-\ngramming models. \nEntityManager em = emf.getEntityManager();\nEntityTransaction tx = em.getTransaction();\ntry\n{\n    tx.begin();\n      {user code to persist objects}\n    tx.commit();\n}\ndone\n{\n    if (tx.isActive())\n    {\n        tx.rollback();\n    }\n}\nem.close();\n FIGURE 10.38 \n JPA Uses Locally Managed Transactions in Plain Java. An  EntityManager API transaction is associated with a local \nJDBC transaction when used outside of an EJB. \n@Stateless \n@TransactionManagement(TransactionManagementType.BEAN)\npublic class TransferBean implements Transfer {\n    @PersistenceContext EntityManager em;\n    @Resource UserTransaction tx;\n    public boolean transfer(int sourceAcct, int destAcct, int amount) {\n        Account src = em.find(Account.class, sourceAcct);\n        Account dest = em.find(Account.class, destAcct);\n        if (src == null || dest == null) return false;\n        try {\n            tx.begin();\n            src.setBalance(src.getBalance() – amt);\n            dest.setBalance(dest.getBalance() + amt);\n            tx.commit();\n        } catch  (Exception ex) {\n            try { tx.rollback(); } catch (Exception e) {}\n            return false;\n        }\n        return true;\n}\n FIGURE 10.39 \n JPA Transactions Enlist with a JTA Managed Transaction When Used within an EJB. The example illustrates a bean-\nmanaged transaction using JPA with JTA to update two account records. \n10.6 Persistence Abstraction Mechanisms  321\n\n\n322  CHAPTER 10 Transactional Middleware Products and Standards\n ADO.NET and the ADO.NET Entity Framework \n ADO .NET provides a consistent abstraction for .NET programs to access data resources, such as SQL Server \ndatabases, XML ﬁ les, and other resources accessible through OLE DB or ODBC. It offers generic classes for \naccessing the data, such as  DataTableCollection to access the tables in a database and  DataTable to \naccess the schema and rows of a table. A client program can directly retrieve data, update data, or run a stored \nprocedure. A client can also retrieve data into a  DataSet object, which is an in-memory relational database. \nData that is modiﬁ ed in the  DataSet object can optionally be transferred back to the data source. \n ADO .NET connects to a resource manager through an adaptor called a  data provider . There are built-in \ndata providers for SQL Server, Oracle, OLE DB, and ODBC. Various database vendors also offer ADO.NET \ndata providers. \n In addition to ADO.NET, there is a newer data-access API called the ADO.NET Entity Framework, which \noffers access to data expressed in a new data model called the  entity data model (EDM) . EDM is based on \nthe extended entity-relationship model commonly used for database design. It has constructs for inheritance, \nassociations (i.e., relationships), and complex types. The Entity Framework simpliﬁ es programmatic access \nto relational data by mapping a conceptual schema expressed in EDM into an underlying relational database, \nwhich is connected to the Entity Framework using an ADO.NET data provider. \n The Entity Framework differs from an object-relational mapping because an EDM schema represents an \nabstract deﬁ nition of data separate from either the programming object or the relational database. Relationships \namong entities are explicitly deﬁ ned within the model, eliminating the need to join relational tables using for-\neign keys. Multiple different EDM schemas can be mapped to the same physical database. \n The Entity Framework offers four ways to access data. First, data can be accessed as entities using Entity SQL, \nwhich is an extension of SQL that can manipulate data that conforms to an EDM schema. This enables access \nusing standard database interfaces, such as query builders and report writers. Second, the Entity Framework can \ngenerate an object-oriented interface that corresponds to the EDM schema. This provides strongly-typed  read \nand write access through object-oriented programming languages, such as C# and VB. Third, queries against this \nobject-oriented representation can be expressed in the language-integrated query (LINQ) mechanism of the .NET \nFramework. LINQ enables compile-time checking of queries against the schema. Finally, data can be represented \nas web resources that are addressed by URIs and accessed using HTTP commands. \n For example, consider an EDM schema  BankDB that has two entity sets,  Customers and  Accounts , and \na relationship between them called  CustomerAccounts . The entity type  Accounts has a role  Customer that \nrelates each account to the customer that owns it.  Figure 10.40 illustrates an Entity SQL statement that ﬁ nds the \nbalance for a given customer account. In this case,  acct.Customer.CustomerName  navigates the relationship \nbetween the  Customers and  Accounts sets to retrieve the  CustomerName from the appropriate entity. \n ADO .NET Data Services offers REST-style access to EDM data, returning data in the format of ATOM/XML \nor JSON. ADO.NET Data Services are implemented using a specialized version of a WCF service to which \ninstructions are sent via URL parameters. For example, the following URI accesses  Customers of  BankDB : \n http://www.BankDB.com/transfer.svc/Customers \nSELECT acct.Customer.CustomerName, acct.Balance\nFROM BankDB.Accounts AS acct\nWHERE acct.AccountNumber = @acctNum\n FIGURE 10.40 \n Entity SQL Example. The Entity Framework’s Entity SQL is similar to SQL but abstracts data access mechanics to use a \nmapping layer called an entity provider. \n",
      "page_number": 331
    },
    {
      "number": 33,
      "title": "Segment 33 (pages 341-349)",
      "start_page": 341,
      "end_page": 349,
      "detection_method": "topic_boundary",
      "content": " If customer number is the key of  Customers , then a query to return  CustomerName of customer number \n345 could be expressed like this: \n http://www.BankDB.com/transfer.svc/Customers(345)/CustomerName \n An EDM schema is deﬁ ned in a separate schema ﬁ le, expressed as an XML document. A mapping from \na conceptual EDM schema into a relational database schema is expressed in a similar format. These ﬁ les can \nbe generated by a graphical schema and mapping editor or created manually. The mapping is compiled into an \ninternal form that the runtime layer uses to translate operations on the conceptual schema into operations on \nthe relational database. \n If an application accesses an EDM database as a set of objects, then the Entity Framework generates a class \nfor the EDM database derived from the class  ObjectContext . This class includes a connection to the data-\nbase, metadata that describes the EDM schema, and the state of objects in the client cache. It tracks each object \nhanded out through a query, notes any objects that change, and generates the required statements for implic-\nitly updating the objects when they are returned to the entity provider. The Entity Framework uses a form of \noptimistic concurrency control in which the user optionally speciﬁ es a subset of properties to be used to track \nchanges (for example, a timestamp or version property), along with the identity properties of any entities to \nbe updated. During update operations, if the values on the server no longer match the values obtained by the \noriginal query, the update fails and the framework throws an exception. The application then decides whether \nto refresh the client objects with the values on the server or commit the changes made on the client. An appli-\ncation can explicitly issue an update using the  SaveChanges() command.  Figure 10.41 shows an example of \na transaction that updates two accounts, very similar to the JPA example in  Figure 10.39 . \npublic class TransferClass implements Transfer {\n  public bool transfer(int sourceAcct, int destAcct, int amount) {\n     // Connection string for BankDB is specified in a configuration file\n     BankDB db = new BankDB();\n     var src = from a in db.Accounts\n               where a.AccountNumber = sourceAcct\n               select a;\n     var dest = from a in db.Accounts\n                where a.AccountNumber = destAcct\n                select a;\n     try {\n         src.FirstOrDefault().Balance = src.FirstOrDefault().Balance – amt);\n         dest.FirstOrDefault().Balance = dest.FirstOrDefault().Balance + amt);\n         db.SaveChanges();\n     } catch  (OptimisticConcurrencyException) {\n         try {\n             db.Refresh(src, RefreshMode.StoreWins); \n             db.Refresh(dest, RefreshMode.StoreWins); }\n         catch (Exception) {}\n         return false;\n     } catch  (NullReferenceException) {\n         return false;\n     }\n     return true;\n  }\n}\n FIGURE 10.41 \n A Transaction in the ADO.NET Entity Framework. This example illustrates a transaction that updates two accounts. The \nqueries assigned to  src and  dest are expressed in LINQ. \n10.6 Persistence Abstraction Mechanisms  323\n\n\n324  CHAPTER 10 Transactional Middleware Products and Standards\n 10.7  LEGACY TP MONITORS \n Transactional middleware products began with the development and deployment of dedicated hardware and \nsoftware systems, designed speciﬁ cally for use in processing transactions. The ﬁ rst such system, called SABRE, \nwas developed by IBM and American Airlines in the late 1950s and early 1960s as an automated way of reserv-\ning seats on airplanes. Later it was adapted for use by other airlines. The operating system layer became an IBM \nproduct called ACP (Airline Control Program) with PARS (Programmed Airline Reservation System) as one of \nthe applications. An offshoot named PARS-Financial was used in the ﬁ nance industry. The product introduced \nmany useful innovations, such as system performance modeling prior to system construction, replicated writes, \nfast restart (at most 5 seconds), intelligent terminal controller, client failover, and workload migration. However, \nin one respect, it was quite bare-bones by today’s standards: ACID transaction semantics was implemented \nby the application. Many years later, acknowledging its use outside the airline industry, IBM renamed it TPF \n(Transaction Processing Facility). TPF is still used for airline reservations some 40 years later, and by several \nﬁ nancial institutions, for example to process credit card payments. \n In the late 1960s, IBM released two TP monitor products with much more functionality, IMS (Information \nManagement System) and CICS (Customer Information Control System). CICS was developed before IMS, \nby IBM’s ﬁ eld engineering group, initially for one speciﬁ c customer, but was not released as a product until \nafter IMS. All of these TP monitors were designed for the mainframe environment and typically were used on \nmachines dedicated to a single application. \n During the minicomputer area, roughly from 1980 to 2000, a new generation of distributed TP monitors \nemerged. Operating systems for these machines were designed to work well with many more processes than \nmainframe systems. So these TP monitors make heavier use of processes, which enable them to scale up an \napplication by moving processes onto more machines. This is in contrast to earlier mainframe TP monitors, \nwhere scaling up usually involves buying a larger mainframe machine. \n Legacy TP monitors typically include a lot of product-speciﬁ c components. They are part of the TP moni-\ntor because they’re essential for the construction and deployment of TP applications but were not part of the \nunderlying platform at the time the TP monitor product was developed. Examples include specialized resource \nmanagers such as database management systems, indexed ﬁ les, and queues; specialized presentation technol-\nogy for vendor-speciﬁ c terminals; program development tools; and system management environments. Today, \nmany of these components are available as general-purpose technology, such as general-purpose system man-\nagement tools, display devices, and database systems. \n Many applications still exist that are based on legacy TP monitors, because the applications work well and \nthe cost of rewriting the application exceeds the expected savings in moving to commodity technologies. This \nsection describes some of these products — ones that you may still encounter, for example in the context of a \nlegacy modernization, interoperability, or SOA project. \n One challenge with modernization, interoperability, and SOA projects is ﬁ nding a good point of entry for \nan external call into the legacy application. Many older applications are not very modular, due to poor initial \ndesign, tight integration of components to meet stringent performance requirements, or many changes made to \nthe application over the years. Sometimes this means that the applications themselves have to be modiﬁ ed to \ncomplete the project, and it can be difﬁ cult ﬁ nding programmers who are qualiﬁ ed to work in the legacy com-\nputing environment. \n The legacy TP monitors described in this section all are popular enough that interfaces to modern TP environ-\nments have been built for them, such as Web Services wrappers, Java EE connectors, CORBA interfaces, and mes-\nsage queue adapters. In some cases capabilities such as these have been added directly into the legacy TP monitors \nthemselves. And as we have already seen, both the .NET Framework and Java EE transactional middleware envi-\nronments include capabilities speciﬁ cally designed for integration with these (and other) legacy environments. \n\n\n CICS Transaction Server \n CICS is IBM’s most popular legacy TP monitor. It pioneered many of the technologies and approaches found \nin modern transactional middleware products, including two-phase commit and transactional RPC. \n Developed in 1968 to improve the efﬁ ciency of mainframe operating system environments, CICS is now \na family of products running on the VSE and z/OS operating systems. A version of the CICS product called \nTX Series runs on the UNIX and Windows operating systems. Although there is some variation of features \nbetween the different implementations, the products all support essentially the same  “ command level ” API. \n Commands are embedded using the preﬁ x  EXEC CICS in any of the supported languages: COBOL, PL/I, \nAssembler, C/C \u0005 \u0005 , and Java. The commands are translated by a precompiler into CICS function calls to carry \nout the requested operations. For example, the following are commands to send a form to a terminal, receive a \nform from a terminal, and link to another CICS program: \n EXEC CICS SEND… \n EXEC CICS RECEIVE… \n EXEC CICS LINK… \n IBM and various third-party vendors offer toolkits for enabling Web Service access of CICS applications, \nallowing them to participate in SOA-based applications. These convert existing COBOL data types to XML \nand generate SOAP messages and WSDL interfaces from the COBOL metadata (often called the Copy Book \nor  COMMAREA ). CICS supports HTTP as a transport, which allows SOAP and plain XML messages to be \nexchanged with CICS transactions. \n Other approaches to legacy integration employ an intermediate node, such as a UNIX or Windows system \nrunning the TX Series version of CICS. The intermediate node runs Web Services or other formats and pro-\ntocols, which are converted into legacy formats and protocols. Deploying the integration solution on an inter-\nmediate machine can avoid having to modify the mainframe CICS application or install additional integration \nsoftware on the mainframe. \n Most CICS remote communication today uses TCP/IP and HTTP. LU6.2 gateways are still in use but IIOP, \nRMI, and WebSphere MQ protocols are more typical. IBM also has ported WebSphere Application Server to \nthe mainframe, which can invoke EJB Session Beans hosted in CICS. \n System Architecture \n CICS offers a process-like abstraction called a  region . A region is an address space that can execute mul-\ntiple threads. CICS implements its own middleware-level threading abstraction (see Section 2.3). A region can \nown resources, such as terminals, programs, communications, and databases. The failure of an application is \nscoped to a region; that is, when a failure occurs, it affects only the region. The unit of distribution likewise is \na region. \n Each CICS resource type is described by a table, whose entries list resources of that type (see  Figure \n10.42 ). In early mainframe versions of CICS, it was common practice to have all resources of a TP application \nbe owned by a single region. Early communications mechanisms were limited and had high overhead, so this \nwas the most efﬁ cient structure. It amounts to running all tiers of a TP application in a single process. Today, \ncommunications capabilities are much improved, so the recommended practice is to partition an application \ninto three regions that correspond roughly to the multitier transactional middleware model: a terminal region \n(the front-end program), an application region (request controller), and a data region (transaction server). \n A CICS region can communicate with another region and with an external application using a dynamic pro-\ngram link (DPL), an RPC-style mechanism speciﬁ c to CICS. Inter-region  communication points offer good \nopportunities for integration with applications based on other technologies, including through an external client. \n10.7 Legacy TP Monitors  325\n\n\n326  CHAPTER 10 Transactional Middleware Products and Standards\n In a terminal region, the terminal table identiﬁ es the terminals attached to the region. When a user logs in, \nthe user is authenticated via a password; later accesses to data resources are controlled via an access control \nlist external to CICS. The region can support geographical entitlement by optionally checking that the user is \nauthorized to operate from the given terminal within a given time period and to fulﬁ ll a given role (such as the \nmaster terminal operator). \n “ Transaction ” is the CICS term for a request. Each request entered by a user includes a four-character \ntransaction code. Using the region’s transaction table, the request can be sent to a region that can process it. In \nCICS, this is called  transaction routing . In our model, it corresponds to using a request controller to route a \nrequest from a front-end program to a transaction server. \n Requests that arrive at a region are classiﬁ ed based on request type, user, and terminal ID. Once the request \nis scheduled, the program table checks whether or not this request type can be processed locally, and whether \nthe user and terminal are authorized to run this request. It then loads the application program if it’s not already \nloaded. (Multiple users can share the same copy of a transaction program.) Then CICS creates a  task , which \nis the execution of a transaction program for a given user and request, assigns it an execution thread, and auto-\nmatically starts a transaction using the chained transaction model. Each execution thread is reclaimed for use \nby another program when the reply message is sent. \n Front-End Program \n Before the widespread adoption of PCs, most CICS systems were accessed by IBM 3270 block-mode termi-\nnals, which send and receive a screen of data at a time. This is still a popular mode of access, sometimes with \n3270 emulation software running on the PC or other displays that conform to the 3270’s data stream communi-\ncations protocol. Thus, one way for an external system to communicate with a CICS application is to emulate a \n3270 terminal and communicate using the 3270 protocol. A function called the external programming interface \n(EPI) provides this support. EPI is also used to connect a variety of external clients. \n CICS has a built-in forms manager, called Basic Mapping Services (BMS), which maps between a device-\noriented view of the data and program-oriented data structures. BMS can be used to interact with 3270 terminals and \nTransaction\nprogram\nlibrary\nOther CICS regions\nand non-CICS\napplications\nDisplays\nCICS region\nCommunications\nlinks\nTerminal and user tables\nTransaction program table\nCommunications\ntable\nResource\ntable\nLoaded programs\nCommands for display access,\nresource access, communications,\nand transaction control\nData\nresources\n FIGURE 10.42 \n A CICS Region. A region provides multithreading and controls application resources, including devices, transaction \nprograms, data resources, and communications links. \n\n\n other types of devices. Typical Web Service enablement and other interoperability tools support COMMAREA \ndirect calls (DPL style), 3270 emulation, and BMS emulation. \n TP Communications \n CICS offers applications a variety of ways to call remote programs. We have already encountered EPI. Some \nothers are: \n ■  Distributed Program Link (DPL), which is a programming model similar to a remote procedure call. \nDPL is synchronous, that is, the application waits for the results (see  Figure 10.43 ). \n ■  Multiregion Operation (MRO) and Inter-Systems Communication (ISC), which are available on CICS \nVSE and zOS, are transport mechanisms that enable communications between regions running on the \nsame mainframe (i.e., transaction routing and DPL can be implemented using MRO or ISC). \n ■  Distributed Transaction Processing (DTP), which is the interface to a peer-to-peer communications \ntransport. It uses the LU6.2 protocol, which is a session-based protocol that associates a transaction with \neach session using the chained transaction model. It propagates transaction context across send-message \noperations and includes a two-phase commit protocol. LU6.2 is part of IBM’s proprietary network archi-\ntecture called SNA (System Network Architecture). \n The COMMAREA is the standard place in main memory to put information to pass via inter-region com-\nmunications facilities such as DPL. Web Services toolkits for CICS also use the COMMAREA to obtain mes-\nsage deﬁ nitions. COMMAREA data types typically are converted to XML data types for use in Web Services. \n The CICS Universal Client product from IBM includes programming libraries for Visual Basic, C/C \u0005 \u0005 , \nand COBOL, and supports both TCP/IP and SNA-based communication protocols. \n Database Access \n CICS initially was implemented on mainframe operating systems that did not support efﬁ cient multithread-\ning. Thus, multithreading was implemented by CICS. Recall from Section 2.3 that such an implementation \nmust not allow application programs to issue blocking operations, since they would delay all the threads in the \nCICS server (z/OS  VSE, UNIX) \nDPL\nECI/ESI\nEPI\nHTTP\nCICS region\nTX series or native\nWindows/Unix\nCICS terminal table\nCICS program\nOther CICS\nregions\nProgram table\nCICS universal\nclient\nWeb service\nDesktop/GUI\napplication\n FIGURE 10.43 \n Communications from CICS Clients and External Interfaces. CICS provides multiple communications options for \ndistributed processing and interoperability with external platforms, including the integration of browsers, PCs, and UNIX \nServers. \n10.7 Legacy TP Monitors  327\n\n\n328  CHAPTER 10 Transactional Middleware Products and Standards\n process. Therefore, applications issued all of their database operations to CICS, which could thereby switch \nthreads if a database operation would ordinarily cause the process to be blocked. \n Early versions of CICS did most of their database processing through COBOL indexed ﬁ les, accessing the \nVSAM (Virtual Sequential Access Method) ﬁ le store. CICS and VSAM include services for buffer manage-\nment, block management, indexed access, and optional logging for rollback. CICS was among the ﬁ rst TP \nsystems to offer remote data access, using a facility called  function shipping , which allows an application to \naccess a remote VSAM ﬁ le. \n Later , support was added for IMS databases via the DL/I interface and, more recently, for relational data-\nbases including IBM’s DB2 family via the SQL interface. Implementations of all continue to be found in \nproduction. \n IMS \n IMS (Information Management System) is another popular TP monitor product from IBM. IMS was designed \nwith Rockwell and Caterpillar for the Apollo space program. IMS’s challenge was to inventory the very large \nbill-of-materials for the Saturn V moon rocket and Apollo space vehicle. Thus, its design originally centered \naround its powerful hierarchical database. \n IMS was released in 1968 for IBM mainframes. It was among the ﬁ rst products to offer online database and \ntransaction processing at a time when nearly all data processing was done in batch. IMS runs in both online \nand batch modes, allowing the incremental conversion of an application from batch to online. Like many TP \napplications, most IMS applications still contain a large portion of batch programming. \n IMS consists of both a TP monitor called IMS Transaction Manager (TM) and a hierarchical-style database \nsystem called IMS Database Manager (DB). The TP monitor and database systems are independent and can \nbe conﬁ gured separately, which allows considerable ﬂ exibility. For example, the IMS DB can be used with the \nCICS TP monitor, or IMS TM can be used with DB2, IBM’s relational database product. Multiple IMS sys-\ntems can be conﬁ gured for distributed processing environments and as standby systems for high availability. In \naddition, IMS supports multiple optimizations for fast performance. \n IMS TM is among the ﬁ rst queued messaging systems dedicated to TP. Like CICS, IMS TM can be accessed \nfrom devices, PCs, and UNIX systems outside the mainframe environment. It has speciﬁ c external access points \nfor XML, Web Services, Java EE, and BPEL. A variety of third-party products provide support for Web Service \nenablement and interoperability with IMS, such as Orbix, WebSphere MQ, and WebSphere Application Server. \nIMS DB includes support for XML data mapping, JDBC drivers, and XML Query. \n Basic System Architecture \n Applications run in a  system , which contains the application program itself and the facilities required to sup-\nport the application. In contrast to CICS, which manages its own address space, an IMS application runs in \nan operating system process and accesses TP monitor services such as threading, dispatching, and program \nloading through a call interface to a system library (instead of using an embedded command style language). \nAn example appears in  Figure 10.44 . Multiple applications can run in separate processes to take advantage of \nzSeries symmetric multiprocessing. \n The basic IMS TM model is queued. An end user inputs some data on a device (see  Figure 10.45 ). IMS \nextracts the data, adds a transaction ID, formats the input into a request message, and enqueues it on the input \nqueue. IMS then loads the program associated with the transaction, if it is not already running. Then IMS \ndequeues the input message (starting the transaction), translates the transaction ID into the transaction program \nname, and routes the message to the application, which executes the transaction program using the input data. \nDequeuing a message starts a transaction. When the transaction program completes, the application enqueues \n\n\n a reply message to the output queue associated with the input device or program. There are options to enqueue \nthe reply message to a different device, another application, or a speciﬁ c user, instead of or in addition to the \ninput device. \n IMS TM also offers an optimization called Fast Path, which essentially allows the application to bypass \nthe queuing system (i.e., request controller) and send simple request messages directly from the device to the \ntransaction program, using a predeﬁ ned mapping that is kept resident in main memory. Requests identify the \nfast path transaction programs, which are preloaded and ready to process the requests. The fast path can also \nuse a special main memory database, with advanced concurrency control features, as described in Section 6.5 \non Hot Spot locking. \n An interface called the Open Transaction Manager Access (OTMA), allows multiple communications man-\nagers to connect to IMS. Using OTMA, IMS receives transaction requests from any source on the network and \nroutes responses back. \nPROCEDURE DIVISION.\nENTRY-LINKAGE.\n     ENTRY ‘DLITCBL’ USING I-O-PCB DB-PCB.\nMAIN PROGRAM.\n     PERFORM GET-MSG-ROUTINE THRU GET-MESSAGE-ROUTINE-EXIT\n                    UNITL I-O-STATUS-CODE EQUAL NO-MORE-MESSAGES.\n    GO BACK\n FIGURE 10.44 \n IMS COBOL Example. The PROCEDURE DIVISION starts with a loop that executes until no more messages are found on \nthe queue. The ﬁ rst time a request is issued for this program, IMS loads it and keeps it loaded until all requests for the \nprogram are completed. \nWeb services\nJava EE\nAPPC/IMS \nInput\nQueue\nOutput\nQueue\nDevice\nIMS System\nExternal Subsystem\nApplication\nProgram\nMQI\nSQL\nIMS/DB\nDB2\nMSC\nISC\n FIGURE 10.45 \n Basic IMS System Architecture. Request and reply messages move between a device and an application via queues. \nVarious gateways connect IMS to external communications systems and resource managers. \n10.7 Legacy TP Monitors  329\n\n\n330  CHAPTER 10 Transactional Middleware Products and Standards\n Security options include device security (which controls the entry of IMS commands), password security, \nand access control on transactions, commands, control regions, and application programs. \n Front-End Program \n IMS TM includes a built-in forms manager, called Message Format Service (MFS), and an optional Screen \nDeﬁ nition Facility (SDF) that deﬁ nes and formats IBM 3270 terminal screens and collects the input data and \ntransaction ID for the request message. \n TP Communications \n IMS TM is based on a queued TP model, rather than a direct TP model such as RPC. This has enhanced recov-\nery compared to most TP monitors, at the cost of extra transactions and I/O, as described in Chapter 4. \n Applications access the input and output queues using calls to retrieve input messages, to return output \nmessages to the sending device, and to send output messages to other application programs and devices. MFS \nassists in translating messages between device format (originally the terminal format) and the application pro-\ngram format. \n Extensions to IMS allow it to accept a remote call from a PC or workstation, access an IMS database via SQL, \nuse APPC for LU6.2 conversational communications with CICS, access the message queue interface (MQI) to \ninteroperate with WebSphere MQ, and accept calls from a CORBA wrapper, EJB, or Web Service. IMS also \nsupports TCP/IP sockets for LU6.2-style conversations. And IMS supports IBM’s Intersystem Communication \n(ISC), which allows communication among multiple IMS systems or between an IMS system and a CICS region; \nand Multiple Systems Coupling (MSC), which allows communication among multiple IMS systems. \n Database Access \n The native database system that comes with IMS is based on a hierarchical model, which preceded the devel-\nopment of relational database systems. The higher performance of the hierarchical model is one of the rea-\nsons IMS-based applications are still in production. Today’s IMS applications can also use DB2, in addition \nto or in place of the IMS DB database. The database access runs using the application’s thread. A data propa-\ngation utility is available that moves data updates from IMS DB to DB2, or vice versa, automatically. Java \nlibrary support allows IMS DB to invoke stored procedures hosted in DB2. Other tools allow data to be moved \nbetween IMS and non-IBM relational databases. \n Tuxedo \n Tuxedo is a legacy TP monitor from Oracle. Tuxedo runs on a variety of UNIX and Windows platforms. Oracle \nowns the rights for Tuxedo, as do a few resellers who customize the product for their own platforms (e.g., \nUNISYS and Bull). AT & T’s Bell Laboratories created Tuxedo in 1984, primarily to service telecommunication \napplications, which remains its largest market. The Tuxedo design is based on IMS, and originally was intended \nto replace IMS at the US telephone companies (who are large IMS users). \n Tuxedo supports several options for interoperability with external systems, including Java EE, Web Services, \nand CORBA. \n Tuxedo was the basis for many of the X/Open DTP standards, including the DTP model itself, XA, TX, \nand XATMI. Tuxedo also implements OTS via its CORBA API. \n\n\n System Architecture \n Tuxedo provides two main APIs. One is called the  Application Transaction Monitor Interface (ATMI) , \nwhich is a collection of runtime services that are called directly by a C, C \u0005 \u0005 , or COBOL application. The \nother is the CORBA C \u0005 \u0005 API. Tuxedo runtime services provide support for communications, distributed \ntransactions, and system management. In contrast to the full-featured CICS API, ATMI relies heavily on UNIX \nsystem libraries and external database system services for ﬁ lling some TP application requirements. \n The ATMI function  tpcall() invokes a Tuxedo service. A typical  tpcall is shown in the following \nexample: \n tpcall (  “ TRANS ” , (char *)reqfb, 0, (char **) & reqfb, (long *) & reqlen, ); \n Tuxedo services can be developed using C, C \u0005 \u0005 , or COBOL. Native Tuxedo API clients can be developed \nusing C, C \u0005 \u0005 , COBOL, and Java. Tuxedo services can be written using Java when they are hosted on the \nOracle WebLogic Server using its domain gateway feature. And CORBA-compliant Tuxedo API clients and \nservers can be developed using C \u0005 \u0005 . \n Tuxedo ’s services are implemented using a shared memory area called the  bulletin board , which con-\ntains conﬁ guration information (similar to CICS tables) that supports many TP monitor functions (see  Figure \n10.46 ). For example, it contains transaction service names, a mapping of transaction service names to transac-\ntion server addresses, parameter-based routing information, and conﬁ guration options for transaction services \nand servers. \n In a distributed environment, one system at a time is designated as having the master bulletin board. \nThe bulletin board at each node is loaded into shared memory from a conﬁ guration ﬁ le when Tuxedo boots. \nChanges to the master bulletin board are written to the conﬁ guration ﬁ le, which is propagated at boot time if \nit has changed since the last boot. The master copy of the bulletin board is propagated at the boot of a new \nmachine. Other nodes reload the ﬁ le to see the updated state. Servers and services can be added, modiﬁ ed, or \nremoved dynamically. \nClient\nClient\nBulletin Board\nBulletin Board\nNode A\nNode B\nServer\nServer\nBridge\nBridge\n FIGURE 10.46 \n Tuxedo Client/Server Architecture. Requests are routed to the correct server process using the bulletin board, whether \non a local or remote node. \n10.7 Legacy TP Monitors  331\n",
      "page_number": 341
    },
    {
      "number": 34,
      "title": "Segment 34 (pages 350-358)",
      "start_page": 350,
      "end_page": 358,
      "detection_method": "topic_boundary",
      "content": "332  CHAPTER 10 Transactional Middleware Products and Standards\n A Tuxedo system consists of client and server processes. Clients typically provide presentation services to \nusers. That is, they interact with devices that issue requests and do not access transactional resource manag-\ners. Unlike CICS and IMS, a Tuxedo client is allowed to issue a Start operation, which may optionally be for-\nwarded to the server (request controller or transaction server) to actually start the transaction. \n Tuxedo systems are conﬁ gured in a  domain , which deﬁ nes the scope of computers in the network that par-\nticipate in a given application. The domain concept essentially represents an administrative boundary around \nparticipating client and server processes in a network and represents the scope of shared access to bulletin \nboard metadata. A domain also can be federated with other domains to increase the scalability of large Tuxedo \ninstallations. \n Although the bulletin board typically is used for the request controller, a Tuxedo server can perform the \nfunctions of request controller, transaction server, or both. This ﬂ exibility allows an application to be struc-\ntured into a multitier architecture, but doesn’t require it. \n In Tuxedo, a  service is the name of a server interface. When a client calls a service, the bulletin board for-\nwards the call to a server that supports the service, similar to how IMS routes a queued message to a transaction \nprogram. The server might be on a different node than the client, in which case the bulletin board routes the \nrequest via a bridge to the other node. When a service becomes available, the server advertises the service by \nposting the service name to the bulletin board. Each server process has a main memory queue that is used for \nincoming messages (see  Figure 10.47 ). A call to a service causes a message to be put into its queue. As in IMS, \nthe server dequeues messages sent by the client and does the requested work, optionally in priority order. When \nit’s done, the server sends a reply message to a message queue associated with the client, which includes a status \nthat tells whether the call completed successfully or resulted in an error. The client dequeues the message and \nprocesses the reply. \n The Tuxedo API offers programmers explicit transaction control primitives — for example,  tpbegin , \n tpcommit , and  tpabort . \n Flags can be set in the client program and in the conﬁ guration ﬁ le to place the execution of transaction \np rograms in automatic, or implicit, transaction mode. In implicit transaction mode, a transaction is started \nautomatically when the transaction program receives control from the front-end program (or client program, \nin Tuxedo terminology), and is automatically committed if the execution of the server program is successful. \nServer\nClient\nQueues\nService\nTPCALL\n FIGURE 10.47 \n Tuxedo Request Message Flow. Requests are routed between client and server processes using input and output queues. \n\n\n If the client program starts a transaction, automatic transaction mode detects the existing transaction and \nincludes the called transaction program in the same transaction. An execution error (that is, a return of bad \nstatus) results in an automatic transaction abort. This is similar to the way CICS handles transactions for DPL-\ninvoked programs. \n An explicit programming model option is asynchronous commit processing, where an application can con-\ntinue without waiting for the second phase to complete in a two-phase commit operation. \n Error handling is at the application level. The program examines a global variable to get an error message, \nand checks this error status after every call, as in IMS programming. \n Front-End Program \n Some legacy applications still use Tuxedo’s Data Entry System forms package, originally designed for use on \ncharacter cell terminals. The input on such a form contains the desired transaction type’s service name and a typed \nbuffer that contains the input data. It also includes ﬂ ags that select various options, such as automatically starting a \ntransaction for the server being called and automatically retrying after an operating system interrupt signal. \n Native communication messages are constructed using Tuxedo’s Field Manipulation Language (FML). \nThis creates typed buffers, which are similar to the CICS COMMAREA. \n Tuxedo offers several options for external client access, including the /WS package for UNIX and PC cli-\nents, web browser and Web Services clients, CORBA clients, and a Java client for use with Oracle’s WebLogic \napplication server. Tuxedo also supports interoperability with JMS-based message queues. \n TP Communications \n Processes using the ATMI protocol can communicate using a choice of peer-to-peer message passing, remote \nprocedure calls, or an event posting mechanism. An RPC can be synchronous (i.e., the application waits for \nthe results) or asynchronous (i.e., the application asks sometime later for the results). Using peer-to-peer mes-\nsage passing, the programmer can establish a conversational session between the front-end program and the \ntransaction server and exchange messages in an application-deﬁ ned order, rather than in the strict request-reply \nstyle of RPC. A subscription service puts events on the bulletin board, and an event posting mechanism allows \na server to raise an event, which sends an unsolicited message to one or more clients (in the case of multiple \nclients this represents a type of broadcast facility). \n Servers developed using the CORBA API can communicate using the RMI/IIOP protocol. Tuxedo serv-\ners can interact bidirectionally with an HTTP Web Service through Tuxedo’s SALT (Services Architecture \nLeveraging Tuxedo) gateway. Tuxedo also includes a variety of mainframe connectivity options, including \nTCP/IP, SNA, and OSI TP-based protocols with speciﬁ c support for invoking CICS and IMS transactions. \n When a server calls another server, the caller can specify whether the callee runs in the same transaction or \noutside of the transaction context. \n Database Access \n TUXEDO has a built-in transaction manager that supports two-phase commit. It can use any XA-compliant \nresource manager, such as Oracle, Sybase, DB2, or SQL Server. \n ACMS \n ACMS (Application Control and Management System) is a legacy TP monitor from HP. ACMS was developed \nby Digital Equipment Corporation in the early 1980s as part of an effort to gain market share in commercial \n10.7 Legacy TP Monitors  333\n\n\n334  CHAPTER 10 Transactional Middleware Products and Standards\n applications. (Digital’s initial strength was in scientiﬁ c computing.) ACMS runs on the HP OpenVMS operating \nsystem. \n ACMS was originally released in 1984 as part of the integrated VAX Information Architecture product set \nalong with Rdb (relational database system), DBMS (CODASYL database system), TDMS (original forms \nsystem), DECforms (a newer forms system), CDD (Common Data Dictionary), and Datatrieve (query and \nreport writer for record-oriented ﬁ les and databases). ACMS pioneered many transactional RPC and abstrac-\ntion concepts, and remains a popular TP monitor for the HP OpenVMS environment. \n System Architecture \n ACMS uses a three-process TP monitor model in which each of the three tiers is mapped to a different operat-\ning system process, very similar to our multitier architecture: front-end program, request controller, and trans-\naction server (see  Figure 10.48 ). The processes communicate via a proprietary RPC. \n ACMS applications accept a request for the execution of a transaction from a terminal or other display \ndevice connected to the process running the front-end program, called the  Command Process . It is multi-\nthreaded to handle multiple devices concurrently. The front-end program sends a request message to the \nrequest controller process, called the  Task Server . (A  task is a program in a request controller that controls \na request.) The request controller is also multithreaded to handle multiple requests concurrently. The request \ncontroller calls a procedure running in the transaction server, which ACMS calls the  Procedure Server . Since \nthe transaction server is single-threaded, it is typically deployed as a server class consisting of multiple server \nprocesses. ACMS monitors the workload on transaction servers to determine whether enough server process \ninstances are active to handle the application workload. If there are too few, it automatically starts another \nserver instance. If a server is idle for too long, ACMS automatically deletes it to conserve system resources. \nDECforms:\nlogin,\nmenus and\nforms  \nSI: External\ndisplay and\ndevice\naccess\nTDL: Task\nflow and\ntransaction\ncontrol \nTDL:\nException\nhandling,\nthreading,\nRPC stubs\nand proxies \nStandard\nprocedures\n& SQL:\ndatabase\nand file\naccess\nCommuni-\ncations\ngateways\nRPC \nRPC\nResource\nmanagers\nOther TP\nMonitors\nCommand\nProcess\nExecution\nController\nProcedure\nServer\n FIGURE 10.48 \n ACMS Three-Process Model. Remote procedure calls communicate among predeﬁ ned processes tuned for speciﬁ c \ntypes of application work. The Task Deﬁ nition Language deﬁ nes the workﬂ ow and controls transactions. \n\n\n In contrast to CICS, IMS, and Tuxedo, ACMS has a specialized compiled language, the Task Deﬁ nition \nLanguage (TDL), for specifying request control. It supports features that were required by the ACMS model \nbut not present in traditional imperative languages in the early 1980s when ACMS was designed, such as RPC, \nmultithreading, transaction control, and structured exception handling. TDL is designed to work in conjunc-\ntion with TDMS and DECforms for menu and forms handling and with any OpenVMS language for transac-\ntion server development. It was standardized by X/Open as the Structured Transaction Deﬁ nition Language \n(STDL). ACMS was also the basis of the X/Open Transactional RPC speciﬁ cation (TxRPC).  Figure 10.49 \ncontains an example of TDL calls to transaction server procedures. \n When an exception occurs, control is passed to the ACTION portion of the task. Certain exceptions auto-\nmatically abort the transaction before branching to the exception handler, as in CICS or automatic transaction \nmode of Tuxedo. A single resource transaction can be started in the procedure server. \n ACMS offers an open, call-level interface to its RPC, called the Systems Interface (SI) API, for connecting \nspecialized devices such as ATMs, gas pumps, and telecom switches. The SI also has been used to create cli-\nents external to ACMS, such as .NET clients, web browsers, and Java EE clients. \n TP Communications \n All process-to-process communication is via a proprietary RPC protocol, including calling a procedure in \nanother process on the same machine. It is possible to change a local call (i.e., in the same process) to a remote \ncall via a conﬁ guration change. \n REPLACE TASK TRANSFER \n \n WORKSPACES ARE CUSTOMER_WKSP, \n                ACCOUNTS_WKSP; \n TASK ARGUMENTS ARE CUSTOMER_WKSP WITH ACCESS READ,\n                    ACCOUNTS_WKSP WITH ACCESS MODIFY; \n BLOCK\n    ...\n        BLOCK WORK WITH TRANSACTION IS \n  \n           PROCESSING WORK IS  \n           CALL WITHDRAW_PROC USING CUSTOMER_WKSP, ACCOUNT_WKSP; \n           CALL DEPOSIT_PROC USING CUSTOMER_WKSP, ACCOUNT_WKSP; \n                                                     \n           EXCHANGE WORK IS  ...\n           ACTION IS  ...\n \n        END BLOCK WORK; \n \n END BLOCK; \n END DEFINITION;\n FIGURE 10.49 \n ACMS TDL Example for the Transfer Task. The ACMS task deﬁ nition declares the data to be passed to a procedure using \nrecord deﬁ nitions and can call multiple procedures within the same transaction block. \n10.7 Legacy TP Monitors  335\n\n\n336  CHAPTER 10 Transactional Middleware Products and Standards\n TDL includes an interface deﬁ nition language called the  task group . The TDL compiler uses the task group \ninformation to generate proxy and stub programs to be linked with the RPC caller and callee. The callee typically \nwould be a procedure server developed using any of the OpenVMS supported languages, such as COBOL, C, \nFORTRAN, Basic, Pascal, and Ada. This allows callers to use standard procedure call syntax, rather than explic-\nitly constructing a specially-formatted  buffer and then passing it in the call (as in CICS and Tuxedo). Information \nabout the request, such as the security context and display identiﬁ er, is automatically placed in hidden arguments \nand is forwarded transparently to the server, where it becomes part of the server’s context. \n ACMS uses OpenVMS cluster technology to support high availability for applications, by automati-\ncally redirecting an RPC from a failed node to a surviving node. It uses the OpenVMS transaction manager, \nDECdtm, for two-phase commit. It also uses the OpenVMS database, Rdb (now owned by Oracle Corp), for \nautomatic failover in an OpenVMS cluster. That is, the database is available from multiple nodes in the cluster, \nand the application can fail over automatically from a database connection on one machine to a database con-\nnection on another machine, using the OpenVMS lock manager. Using these mechanisms, ACMS is able to \nachieve very high levels of availability. \n ACMS has been extended using a product called TP Ware that includes support for .NET Framework cli-\nents, Java clients, web browsers, and Web Services clients running on the Windows operating system. A product \ncalled the Web Services Integration Toolkit, running on OpenVMS, exposes ACMS tasks as EJBs and Web \nServices. ACMS server procedures can include HP’s APPC/LU6.2 gateway for interoperability with CICS-based \napplications. TP Ware basically replaces the command process in the three-tier architecture with web browser, \n.NET, and Java clients, providing libraries and an API to directly invoke a task in the task server, bypassing the \nCommand Process. \n Database Access \n Transaction server programs directly access any database or resource manager. Certain specialized databases \nare directly accessible from TDL. ACMS includes a queue manager for durable request queue operations. \n If a transaction is bracketed within a TDL program (in a request controller), then ACMS controls the com-\nmitment activity using DECdtm. If it is bracketed within the transaction server, then ACMS is uninvolved in \nthe commitment process. This is useful for database systems that are not integrated with DECdtm, or that offer \nspecialized options that can only be set in the transaction bracket statements. \n Pathway TS/MP \n Pathway with NonStop Transaction Services (TS/MP) is another legacy TP monitor from HP. It was developed \noriginally by Tandem Computers and released in the mid-1980s as a TP development platform for Tandem’s \nGuardian operating system running on their fault-tolerant platform. \n Tandem later teased apart its operating system into a kernel portion, the NonStop Kernel (NSK), with two \nlayers on top: one that supports the Guardian API, and one that supports a POSIX (UNIX) API, called Open \nSystem Services (OSS). OSS supports a native port of Tuxedo and a nonnative port of a Java EE application \nserver (Oracle’s WebLogic). Pathway and Tandem in general, was a pioneer of high availability, fault toler-\nance, and data replication technologies. \n Pathway is based on a client/server process structure and a transaction abstraction. NonStop TS/MP pro-\nvides server process management (e.g., load balancing and automatic server restart). Transaction management \nis implemented using infrastructure called the NonStop Transaction Management Facility (TMF). This TP \ninfrastructure supports all application environments, including Pathway, NonStop Tuxedo, NonStop CORBA, \nNonStop JSP, NonStop SOAP, and NonStop Web Server. TS/MP recently has been completely rearchitected \n\n\n using a new component called Application Cluster Services that extends server management and load balanc-\ning capabilities to the new generation of HP Integrity NonStop processors. \n System Architecture \n Pathway uses a two-process model to implement its client/server architecture, which is called requester/server \n(see  Figure 10.50 ). The client is a multithreaded Terminal Control Program (TCP), which handles multiple \nsimultaneous interactions with end users. It supports both front-end program and request controller functions. \nThe TCP interpretively executes programs written in Tandem’s COBOL dialect, SCREEN COBOL, which \nincludes features for terminal handling and communication with single-threaded transaction servers. An exam-\nple of SCREEN COBOL is in  Figure 10.51 . Enhancements to the NonStop environment have allowed the devel-\nopment of multithreaded transaction servers. Similarly to ACMS, transaction servers execute compiled object \ncode written in a standard language with embedded SQL and run in server classes. Supported languages include \nC/C \u0005 \u0005 , COBOL, Java, and TAL (Transaction Application Language, which is proprietary to HP NonStop). \n The TCP interprets a SCREEN COBOL application program to display menus, paint and read a screen, \nvalidate the input data, and format a request message with the name of the target server class. The application \nprogram then starts a transaction and executes a SEND command to issue an RPC to a transaction server in the \nserver class named by the request. \n The RPC mechanism establishes a new link to a server in the requested server class, if it doesn’t already \nhave one or if all existing links are busy processing other requests. The server accepts the message and does \nthe work of the request, accessing a database if appropriate. When the server program completes, it sends a \nreply message to the TCP. The TCP’s application program can invoke many such RPCs before forwarding the \nreply to the terminal and committing the transaction. Finally, the reply message is displayed. \n The Guardian operating system implements software fault-tolerance through  process pairs , a mechanism \nby which a given operating system process has a second, shadow process as a backup to each primary process. \n}\nTerminal Control\nPrograms (TCP)\nSCREEN COBOL\nProcess\nPair\nRPCs\nAda, C, C++, COBOL,\nFORTRAN,  TAL\nCheckpoints\nTerminal\nServer Class\nServer\nServer\nServer\nNonStop SQL\nEnscribe\n FIGURE 10.50 \n Pathway Monitor Two-Process Model. The Terminal Control Program interprets SCREEN COBOL programs to interact \nwith the display and format requests, and to call servers via RPC. The servers access the Tandem resource managers. \nTCPs are implemented using process pairs for fault-tolerance. \n10.7 Legacy TP Monitors  337\n\n\n338  CHAPTER 10 Transactional Middleware Products and Standards\n A conﬁ guration option tells Pathway to run each TCP as a process pair. A server monitoring feature called \nPathmon, which is also implemented as a process pair, monitors Pathway servers and restarts them in the event \nof a process or processor failure. The primary and backup processes in a process pair conﬁ guration run on dif-\nferent processors so that at least one of them will survive any processor failure. \n At the beginning of each transaction, Pathway checkpoints the display context (essentially, the request), \nwhich means that it copies this state from the primary process to its backup process. It checkpoints again just \nbefore commit (essentially, the reply). If the primary fails during the transaction execution, the transaction \naborts and the backup can re-execute  the transaction using the checkpointed display context, without asking \nthe user to re-enter  the data. If the transaction executes without any failures and commits, then the precommit \ncheckpoint replaces the start-of-transaction checkpoint, and can be sent to the display. The checkpoints play \na similar role to queue elements in queued TP. The NonStop process pair and checkpoint/restart capability is \nunique in the TP industry. \n Servers are typically stateless, which allows successive calls to a server class within the same transaction to \nbe handled by different servers. Servers are automatically restarted in the event of process or processor failure. \n Transactions are managed by the TMF. Updates to data are logged to an audit ﬁ le, from which TMF man-\nages various types of recovery. There is one log per node. TMF provides a system logging service for both \nitself (as a transaction manager), and for the NonStop resource managers (NonStop SQL and Enscribe). All \nupdates by a transaction are written as a single log write, no matter how many resource managers are involved, \nthereby minimizing the number I/Os per transaction to improve performance and scalability. \n NonStop resource managers provide fault tolerance through disk mirroring and hot backup, and provide \nupward scalability through data partitioning and parallel processing. System server processes typically run as \nprocess pairs to ensure high availability. \n Front-End Program \n Pathway was introduced in the days of low-function terminals. So its front-end program, TCP, supports ter-\nminal devices via a multithreaded process, where each thread maintains a context for a terminal and initiates \na request on behalf of the user. Later on, the TCP interface was opened up for access from PCs, workstations, \nand other devices, such as ATMs, gas pumps, and bar code readers. \n External client support has been added for web browsers, Web Services, .NET, CORBA, JMS, and Tuxedo \nusing a set of special gateway processes that replace the TCP for modern display devices and interoperability \nPROCEDURE DIVISION.\n000-BEGIN SECTION.\nACCEPT INPUT-MSG.\n  BEGIN-TRANSACTION.\n  MOVE ACCOUNT-ID OF INPUT-MSG TO ACCOUNT-ID OF DBCR-MSG.\n  MOVE AMOUNT OF INPUT-MSG TO AMOUNT OF DBCR-MSG.\n  SEND MESSAGE DBCR-MSG TO /LOCAL\n      REPLY CODE STATUS.\n  MOVE BALANCE OF DBCR-MSG TO BALANCE1 OF CONFIRM-MSG.\n  SEND MESSAGE DBCR-MSG TO /REMOTE\n      REPLY CODE STATUS.\n  END-TRANSACTION.\n FIGURE 10.51 \n SCREEN COBOL Example. The program accepts input from the display, begins a transaction, and sends messages to two \nservers, one locally for the debit operation and the other to a remote node for the credit operation. \n\n\n solutions. A Web Services toolkit is available to generate a WSDL interface from a Pathway interface so that a \nstandard Web Services client can access a Pathway server. Similarly, the NonStop JSP product, together with \nthe NonStop Web Server product, supports direct access to Pathway servers from standard HTTP clients. \n TP Communications \n A NonStop system (or node) is a loosely-coupled  cluster of processors, connected by a high-speed bus called \nServerNet. Processors do not share memory, but this architecture is supported by the common operating sys-\ntem environment that provides high performance, availability, and scalability. \n The NonStop operating system uses a transactional interprocess communications mechanism based on the \nNonStop messaging system, between processes both on the same node and on remote nodes. The communica-\ntion mechanism is accessed using the PathSend API. \n Database Access \n The NonStop environment includes an SQL-compliant resource manager called NonStop SQL and a trans-\nactional ﬁ le system called Enscribe. Both resource managers support parallel processing and distributed pro-\ncessing features of the NonStop platform. When it was released in the mid-1980s, NonStop SQL was the ﬁ rst \ndistributed, parallel relational database system product. \n Mirrored disks are supported for local backup, and the Remote Database Facility (RDF) supports a remote \nhot backup. RDF uses the process pair architecture to forward log records from the primary database to the \nremote replica, where another process pair applies the log records to the database replica. \n Multiple processors can execute separate SQL requests simultaneously or divide a large single request for \nparallel processing on multiple processors. The resource managers support the standard locking and logging \napproaches described in Chapters 6 and 7, including record locking, relaxed isolation levels for improved read \nperformance, and logs for undo-redo recovery. Online reconﬁ guration is supported for such things as moving a \npartition or splitting an index. \n 10.8  TP STANDARDS \n Historically , standardization has been very challenging for TP technologies, due to the broad variety of imple-\nmentation architectures, programming models, communications protocols, and integration points among mod-\nern and legacy products. The main goals of TP standardization are: \n ■  Portability: Allowing the same transaction program to run on different transactional middleware products \n ■  Interoperability: Allowing multiple transactional middleware products to exchange data or control infor-\nmation while executing within the same transaction \n ■  Integration: Allowing components from multiple transactional middleware products that perform differ-\nent functions to work in combination \n We will focus primarily on standards pertinent to the .NET Framework and Java EE transactional middle-\nware and touch only brieﬂ y on other related standardization efforts. The primary standard for transactional \ninteroperability is deﬁ ned by the Web Services transactions set of speciﬁ cations. We describe the following \nstandards: \n ■  The Web Services Transactions (WS-Transactions) set of speciﬁ cations from OASIS \n ■  The XA protocol from the Open Group \n10.8 TP Standards  339\n\n\n340  CHAPTER 10 Transactional Middleware Products and Standards\n ■  The Object Transaction Service (OTS) from the Object Management Group \n ■  The Java Transaction API (JTA) from the Java Community Process \n These last three standards are related. The XA protocol is incorporated into OTS, and both XA and OTS \nare incorporated into JTA. The XA protocol is perhaps the most successful TP standard. Most transactional \nresource managers support it for two-phase commit, including relational database systems and asynchronous \nmessage queues. \n We also brieﬂ y mention the emerging Service Component Architecture (SCA), OSGi enterprise edition, \nand Advanced Message Queuing Protocol (AMQP) speciﬁ cations since they support transactions. \n WS-Transactions \n WS -Transactions is  a set of transactional interoperability speciﬁ cations standardized by OASIS. It extends \nbasic Web Services (i.e., SOAP and WSDL) by including a transaction context in a SOAP header and deﬁ ning \na protocol for transactional interoperability across Web Services. Both vendor and open source products imple-\nment it, including Microsoft’s Windows Communications Framework, IBM’s WebSphere Application Server, \nRed Hat’s JBoss Application Server, Progress Software’s Artix ESB, Sun’s Metro, and Apache’s Kandula2. \n WS -Transactions includes three speciﬁ cations: \n ■  WS-Coordination (WS-C) is the core speciﬁ cation, deﬁ ning a generic state machine coordinator that \nsupports pluggable protocols for various transaction models, such as WS-AT and WS-BA. \n ■  WS-AtomicTransactions (WS-AT) deﬁ nes a durable and volatile variation of the classic two-phase com-\nmit protocol that plug into WS-C. \n ■  WS-BusinessActivity (WS-BA) deﬁ nes an  “ open nested ” transaction protocol with compensation actions \nthat plugs into WS-C. It can be used with long running transaction ﬂ ows such as those deﬁ ned using \nWS-BPEL. \n An implementation of WS-C is a prerequisite for WS-AT and/or WS-BA. However, it is also possible to \nimplement WS-C without implementing either WS-AT or WS-BA, for example by deﬁ ning a new protocol to \nplug into WS-C, such as a notiﬁ cation, publish/subscribe, consensus, or three-phase commit protocol. \n The WS-C speciﬁ cation deﬁ nes how a Web Service implementation interacts with a transaction coordinator \nto obtain and manage the context for a given transaction type. The WS-AT and WS-BA speciﬁ cations deﬁ ne \nspeciﬁ c context formats for WS-C to manage. The context is obtained from WS-C and passed from a Web \nService requester to a Web Service provider using SOAP headers. A WS-Policy assertion can be attached to \nthe Web Service’s WSDL interface to advertise its transactional requirements. \n For example, in  Figure 10.52 the .NET client obtains a WSDL interface from the Java EE application \nserver that includes a policy requiring WS-AT. It therefore knows it has to start a transaction and obtain a \nWS-AT context for propagation to the remote service. The context is included in the header of the SOAP \nmessage that invokes the remote EJB server. When the service provider receives the SOAP header it recognizes \nthe WS-AT context and registers the transaction with a WS-C coordinator — either a local coordinator that con-\ntacts the remote coordinator on its behalf, or directly with the remote coordinator. \n Figure 10.53 shows an example of the context structure for WS-AT. It includes URIs that identify the coordi-\nnation (i.e., context) type, the coordinator, and the address of the coordinator with which to register the context. \n The two-phase commit protocol includes volatile and durable variations. The open nested model deﬁ ned in \nWS-BA allows a nested transaction to commit without requiring the top-level or root transaction to commit. \nHowever, if the top-level transaction aborts, a compensation action must be applied to any subtransaction that \npreviously committed. WS-BA includes two variations: one for participant completion and the other for coor-\ndinator completion. \n",
      "page_number": 350
    },
    {
      "number": 35,
      "title": "Segment 35 (pages 359-367)",
      "start_page": 359,
      "end_page": 367,
      "detection_method": "topic_boundary",
      "content": " WS -Transactions uses the Web Services Policy (WS-Policy) Framework as the format for the policies it \ndeﬁ nes for association with a WSDL interface. In WS-Policy the policy items, called  assertions , are used \nto advertise the transactional capabilities of a Web Service. For example, an assertion can tell the service \nrequester whether or not a transaction context is required in order to invoke the service. Each WSDL operation \ncan have its own policies. \n5. Register\ntransaction\n4. SOAP call with WS-AT header \n3. Get WS-AT\ncontext   \n2. Receive WSDL with WS-AT policy \nWS-C \nWS-C \n1. Request WSDL \n6. SOAP response \n.NET\nFramework \nWCF\nJava EE\nApplication\nServer EJB \n FIGURE 10.52 \n The .NET Client Obtains a WSDL Interface Requiring WS-AT. The example illustrates a transactional Web Service \ninvocation that coordinates Java EE and NET Framework resources. \n<SOAP11:Envelope xmlns:S11=“http://www.w3.org/2003/05/soap-envelope”>\n    <SOAP11:Header>\n        ...\n        <wscoor:CoordinationContext \n           ... \n            <wscoor:Identifier>\n                 uuid:1234567890\n            </wscoor:Identifier>\n           ...\n           <wscoor:CoordinationType>\n               http://docs.oasis-open.org/ws-tx/wsat/2006/06\n           </wscoor:CoordinationType>\n           <wscoor:RegistrationService>\n                <wsa:Address>\n                 http://WWW.MyLargeBank.com/CoordinationService/registration\n                </wsa:Address>\n           </wscoor:RegistrationService>\n    </SOAP11:Header>\n    ...\n</SOAP11:Envelope>\n FIGURE 10.53 \n WS-Transactions Context for WS-Atomic Transactions. The context type for WS-AT is included in the SOAP header along \nwith the URL for the coordinator. \n10.8 TP Standards  341\n\n\n342  CHAPTER 10 Transactional Middleware Products and Standards\n For example,  Figure 10.54 deﬁ nes the transacted policy for the  Transfer operation. It indicates that a \ntransaction context, such as the WS-AT context, is required in order to request this service. If a SOAP message \narrives for the  Transfer operation without a transaction context an exception will be generated. \n The XA Interface \n The XA speciﬁ cation originally was developed by X/Open in 1991 as part of a family of speciﬁ cations deﬁ n-\ning a complete distributed transaction processing environment. XA is supported by most relational database \nproducts, including Oracle, Sybase, IBM’s DB2, Microsoft’s SQL Server, and Sun’s MySQL. XA is also sup-\nported by most asynchronous message queuing products, including IBM’s WebSphere MQ, TIBCO Software’s \nEnterprise Message Service, Progress Software’s SonicMQ, and the Apache Foundation’s ActiveMQ. \n X /Open was established to deﬁ ne portability and interoperability standards for UNIX. X/Open is now \npart of The Open Group, Inc., which was formed in 1994 by combining X/Open with the Open Software \nFoundation. X/Open’s original goal was to promote application portability through the development of API \nstandards for UNIX. In fact, The Open Group owns the UNIX brand. \n Although the complete family of X/Open speciﬁ cations failed to gain adoption, the X/Open Distributed \nTransaction Processing (DTP) model remains a good framework for identifying both the components involved \nin a distributed transaction and the appropriate areas for standardization (see  Figure 10.55 ). It divides a distrib-\nuted TP system into three major components — transaction manager, resource manager, and application — and \ndeﬁ nes the interfaces between them. \n Within the X/Open DTP model, the XA speciﬁ cation deﬁ nes a bidirectional interface between the transac-\ntion manager (TM) and the resource manager (RM). Today it’s common to think of the .NET Framework or \nJava EE deﬁ ning the transaction demarcation API instead of the TX API. SQL is the most widely-used  API \nfor RM access, but there are others for access to queues and other nonrelational resources. XA is intended pri-\nmarily for transactions that span multiple resource managers. For example, a common application of XA is to \ncoordinate a transaction that includes a database and a message queue. \n The XA speciﬁ cation deﬁ nes the protocol to allow the transactional work of an RM to be externally coor-\ndinated by a TM in a distributed transaction. XA is a presumed-abort, two-phase commit protocol with opti-\nmizations that enable a TM to chose a one-phase commit when there is only a single RM involved in the \ntransaction. When an application starts a transaction the TM creates a new transaction and assigns it a global \ntransaction ID (which XA calls an  XID ). When the application calls the RM (for example, using an SQL state-\nment), the runtime hosting the application passes the ID it obtained from the TM to the RM. The RM’s trans-\naction manager recognizes the ID as coming from an independent TM (i.e., it’s not a transaction that the RM \n<wsdl:operation name=“Transfer”>\n   <wsp:PolicyReference URI-“#TransactedPolicy” wsdl:required=“true” />\n   <!-- omitted elements -->\n</wsdl:operation>\n<wsp:Policy wsu:Id=“TransactedPolicy” >\n    <wsat:ATAssertion/>\n</wsp:Policy>\n FIGURE 10.54 \n Policy Assertion Requiring a Transaction for the  Transfer Operation. The Transfer operation has a reference to a  wsp:\nPolicy element that contains a  wsat:ATAssertion indicating that a transaction context is required for this operation. \n\n\n initiated) and enlists its transaction with the TM’s transaction using the address of the TM, which is passed \nas part of the transaction context. At termination, the TM notiﬁ es all registered participants of the transaction \noutcome. \n Object Transaction Service \n The Object Transaction Service (OTS) was deﬁ ned in 1994 by the Object Management Group (OMG), an \nindustry consortium. OMG was founded to develop the Common Object Request Broker Architecture (or \nCORBA) speciﬁ cations and now is responsible for a variety of standards, including the well-known Uniﬁ ed \nModeling Language (UML). OTS is one of the CORBA services that extend the core interfacing and interop-\nerability technology for use in enterprise applications such as transaction processing. \n OTS is incorporated into Java EE as the interoperable format for transaction context propagation on remote \nEJB requests. JTA provides the local Java interfaces in Java EE for TX and XA protocols. Implementations of \nCORBA and OTS include Progress Software’s Orbix, Borland Software’s VisiBroker, Oracle’s Tuxedo, HP’s \nNonStop Kernel, and Hitachi’s TP Broker. OTS often is mapped to Java Transaction Service (JTS) implemen-\ntations. And the WS-Transactions approach is derived from the OMG’s  Additional Structuring Mechanisms \nfor the OTS Speciﬁ cation , which ﬁ rst included the concept of separating the coordinator from the transaction \nprotocol. \n The OTS model (as of V1.4) includes a transactional server and recoverable server, which correspond to \nthe request controller and transaction server in our multitier model (see  Figure 10.56 ). \n Objects in the transactional clients and servers communicate with each other using the ORB. They also \naccess the transaction service to initiate and terminate a transaction and to register resources for a transaction. \nThe transactional server does not directly interact with persistent resources, but calls one or more objects in the \nrecoverable server to do so. \n In XA terms, the transactional client, transactional server, and recoverable server comprise the application \n(AP) and the transaction service implements the transaction manager (TM). The RM is the same as in XA and, \nin fact, interacts with the TM using the XA protocol. \n OTS supports both implicit and explicit programming models. The implicit programming model uses an \nobject called  current to associate a context with the execution thread. The  begin command initializes the \ncurrent context. Once a context is associated with the execution thread, it can be automatically propagated to \nany other transactional object invoked from that thread, depending on the transactional policy associated with \nResource Manager (RM) \nApplication Program (AP) \nTransaction Manager (TM) \nSQL\nXA\nTX\n FIGURE 10.55 \n X/Open DTP Model. In the X/Open DTP model an application program typically uses the TX API to access transaction \nmanagement services and SQL to access a resource manager. The XA standard allows different vendors ’ transactional \nmiddleware and resource managers to interoperate. \n10.8 TP Standards  343\n\n\n344  CHAPTER 10 Transactional Middleware Products and Standards\n the target object. The scope of a transaction is determined by the extent of the context sharing among objects, \nwhether explicit or implicit. \n The following properties can be associated with an object’s interoperable object reference (IOR) to deﬁ ne \nwhether or not it will accept implicit context propagation: \n ■  REQUIRES: A transaction context must be present when the object is invoked. \n ■  FORBIDS: A transaction context must not be present when the object is invoked. \n ■  ADAPTS: The object can be invoked whether or not a transaction context is present. \n Properties cannot be set on individual methods in an object. A transactional object can perform both trans-\nactional and nontransactional work. \n The explicit programming model uses the complete set of methods on the current object to explicitly start a \ntransaction, get a context object, control the transaction through the methods on the object, and propagate the \ncontext to other transactional objects. \n Transaction semantics in OTS are compatible with XA, and transactions can be exported and imported \nbetween the two environments. OTS supports subtransactions but they are not widely implemented in resource \nmanagers. \n An OTS coordinator can become a resource to another coordinator. This is called  interposition , in which \na coordinator acts as a resource to the root coordinator. Interposition was designed for network efﬁ ciency. \nWhen multiple remote resources are included in the transaction, it’s more efﬁ cient for the root coordinator \nto exchange remote messages with an interposed coordinator than it would be with all the remote resources \nindividually. The interposed coordinator receives messages from the root coordinator and passes them along to \nthe local resources enrolled with it. An interposed coordinator can also reduce the number of sessions a given \nresource manager has to support, and can help enforce security for a given domain. This is essentially the tree-\nof-processes model discussed in Section 8.5. \n JTA \n The Java Transaction API (JTA) deﬁ nes the Java interfaces for the TX and XA protocols. JTA originally was \ndeﬁ ned in 1999 and joins OTS and XA within a common Java programming environment. JTA is used in JCA, \nXA\nRegisters\nresources, full\nparticipant\nCan only\nforce rollback \nInitiate and\nterminate\ntransactions \nObject Request Broker (ORB)\nRM\nRM\nSQL\nSQL\nTransaction Service\nTransactional\nClient \nTransactional\nServer\nRecoverable\nServer\n FIGURE 10.56 \n Object Transaction Service Architecture. The ORB provides the communication among objects participating in an OTS \ntransaction while the transaction service provides transaction coordination. \n\n\n JDBC, and JMS, and is included in any Java-EE-compliant application server product. See Section 10.4,  The \nExplicit Programming Model for additional examples. \n JTA consists of three main parts: \n ■  An interface that allows an application to explicitly initiate, propagate, and terminate a transaction \n ■  A Java language mapping of the XA interface (XAResource) \n ■  An interface between the TM and other application server components such as containers and cache \nmanagers to support enlistment of durable and volatile resources (XAResources and Synchronizations). \n The  javax.transaction.UserTransaction interface deﬁ nes an explicit transaction programming \nmodel that can be used by Java clients and EJBs. \n The  javax.transaction.TransactionManager interface deﬁ nes a programming model for the appli-\ncation server vendor to control transactions that use the implicit programming model. When an EJB container \nmanages the transaction state for a transactional EJB, the container uses the  TransactionManager interface \nto create, manage, and propagate a transaction context for a given thread of execution. \n The  javax.transaction.xa.XAResource interface is a Java mapping of the industry standard XA \ninterface. As of JTA 1.1, the  javax.transaction.TransactionSynchronizationRegistry interface \ndeﬁ nes a distinct set of operations for components such as persistence managers that typically would not have \naccess to the full  TransactionManager interface. \n Service Component Architecture \n The OASIS Service Component Architecture (SCA) deﬁ nes a set of metadata for identifying services for an \nSOA, mapping them into a component model for deployment, and assembling them into various applications. \nSCA also includes a mechanism for attaching policies to the components and identiﬁ es a way in which Java \nprograms can include SCA metadata as annotations. \n Transactions are incorporated into SCA components using extended policy information incorporating \nthe WS-Policy speciﬁ cation from W3C. For example, when deploying an SCA component or assembly of \ncomponents into a Java EE runtime environment, the transaction policies attached to the SCA components \nare translated into Java EE transaction attributes. See the Section 10.4,  The Implicit Programming Model , for \ninformation on Java EE transaction attributes. When SCA components are deployed onto other runtimes, the \npolicies are mapped into WS-Policy elements as deﬁ ned in the WS-TX set of speciﬁ cations, described earlier \nin this section. \n OSGi Alliance \n The OSGi Alliance creates and maintains the OSGi speciﬁ cations, which deﬁ ne a core framework for Java \nmodularization and an associated set of framework services for discovery, security, logging, and so on. The \nOSGi Alliance was created as the Open Server Gateway initiative in 1998 based on Java Speciﬁ cation Request \n8. Its original goal was to modularize Java for embedded devices, such as those intended for home automation, \nallowing the dynamic loading and unloading of selected sets of Java libraries needed to support the device’s \nresource constraints and capability requirements. OSGi technology had mixed early adoption in various \nembedded applications, including automotive and mobile telephone application. \n Following the adoption of the OSGi platform by the Eclipse Foundation in 2004, the OSGi framework \nbecame popular as a deployment mechanism for Java-based products such as IBM’s WebSphere Application \nServer, Oracle’s WebLogic, Red Hat’s JBoss, Spring Source’s dm Server, and the Apache Foundation’s \nServiceMix, among others. \n10.8 TP Standards  345\n\n\n346  CHAPTER 10 Transactional Middleware Products and Standards\n The OSGi framework deﬁ nes a dynamic component model for Java, and addresses other shortcomings of \nthe standalone Java virtual machine environment, such as improved classloading, versioning, and lifecycle \ncontrol. Applications can be deﬁ ned as a set of cooperating components that can be remotely installed, started, \nstopped, updated, and uninstalled dynamically (i.e., without requiring application reboot). A service registry \nallows modules to detect the addition of new services or the removal of services, and to adapt dynamically, \nincluding the automatic installation of new components as required by the application. \n The enterprise release of the OSGi speciﬁ cations, R 4.2, extends the OSGi framework to meet the require-\nment of enterprise Java applications, including components for distributed computing, extensions to the com-\nponent model itself (based on the Spring Framework’s component model), and a mapping of various Java EE \ncomponents such as JTA, JDBC, JPA, JNDI, and Web applications. The Java EE and other enterprise compo-\nnents are accessible from application code using the OSGi service model. That means web applications, trans-\naction, persistence abstractions, and other enterprise components are available as dynamically-loadable  services \nfor OSGi-compliant applications. \n Advanced Message Queuing Protocol \n The Advanced Message Queuing Protocol (AMQP) is an open standard originally deﬁ ned by JP Morgan Chase \nand then submitted to an independent consortium, which maintains and improves it. AMQP focused initially \non deﬁ ning a wire format interoperability standard for asynchronous messaging systems, such as JMS-based \nmessage queues. \n JMS deﬁ nes a standard API for message queuing, but it does not deﬁ ne a data format. Among the goals of \nthe AMQP Working Group is achieving interoperability across multiple asynchronous message queuing tech-\nnologies and products. AMQP supports XA transactions for coordinating queue operations with operations \non another resource. Current implementations include Red Hat’s Enterprise MRG, Apache Qpid, iMatix’s \nOpenAMQ, and Cohesive FT and LShift’s RabbitMQ. \n Members of the AMQP Working Group consortium include Cisco Systems; Credit Suisse; Deutsche Borse \nSystems; Envoy Technologies; Goldman Sachs; iMatix Corporation; JP Morgan Chase Bank  & Co.; Microsoft \nCorporation; Novell; Progress Software; Rabbit Technologies (a joint venture of CohesiveFT and LShift); Red \nHat, Inc.; Twist Process Innovations; WSO2, Inc.; and 29West, Inc. \n 10.9  SUMMARY \n Transactional middleware products meet the requirements of multitier TP applications. Twenty years ago, \ntransactional middleware was delivered to market as a single product category, the TP (or OLTP) monitor. \nMany of these products are still in production, but the most popular transactional middleware environments are \nnow delivered in the Java EE and .NET Framework environments. \n As the new environments have gained popularity, components of the original monolithic TP monitors now \nare sold as independent products. Examples include forms products, database management systems, system \nmanagement consoles, distributed computing communications systems, and application development environ-\nments. Modern TP applications often include server components of legacy TP monitors, general purpose prod-\nucts, and components from the .NET Framework, Java EE-compliant application servers, or both. We expect \nthe trend toward componentization to continue. Yet the features and functions of transactional middleware \nremain unchanged — to help scale up, improve performance, reliability, security, manageability, maintenance, \ntransaction control, recovery, and availability. \n\n\n TP applications typically consist of two or more tiers that provide the functions of the front-end program, \nrequest controller, and transaction server. In their simplest and most direct design, a front-end program might \ndirectly access the transaction server in a database. However, since connections between front-end programs \nand databases can be expensive to maintain, one or more middle tiers often are introduced to improve scalabil-\nity and performance. Transactions can be controlled by the resource manager or the transactional middleware. \nDifferent transactional middleware systems provide different options for composing multiple resources into \nlocal and distributed transactions. \n Most transactional middleware systems also support the use of web servers as request controllers, and rich \nInternet applications such as AJAX deliver desktop-like levels of interactivity and features to the web browser. \nAll transactional middleware, including legacy TP monitors, supports access from web browsers either directly \nor through an intermediary. \n Transactional middleware products typically support both an implicit and explicit programming model for \ntransaction control. The implicit model uses conﬁ guration properties of abstract runtime containers to automat-\nically begin, propagate, and terminate a transaction. The explicit model relies on APIs incorporated directly \ninto programs. The tradeoffs are generally between ease of use of the implicit model and ﬂ exibility of control \nof the explicit model. \n Legacy TP monitors such as CICS, IMS, ACMS, Tuxedo, and Pathway continue to be used in many pro-\nduction environments. They now include support for modern front ends such as .NET, Java, and Web Services, \nfor integration with newer applications and SOA-based designs. \n Microsoft ’s .NET Framework includes multiple technologies for creating front-end programs, such as \nWPF, Silverlight, and ASP.NET. WCF can be used to develop request controllers and transaction servers. SQL \nServer can run stored procedures, which functions as a complete transaction server in some environments. \n Transaction management in the .NET Framework uses the  System.Transactions API set. It underlies the \nimplicit programming model in WCF and can also be accessed explicitly from .NET Framework objects. When \nused with WCF, attributes embedded within .NET objects cause them to execute as transactions. Annotations \ncan also be embedded in programs and interfaces to automatically complete and propagate a transaction. \n The Java EE environment includes multiple technologies for creating front-end programs, such as Swing, \nJSP, JSF, and servlets. EJBs can be used to develop request controllers and transaction servers, and can include \nJPA beans for object-relational persistence. SQL database systems run stored procedures, which can function \nas transaction servers. \n Transaction management in the Java EE environment uses the Java Transaction API (JTA), which underlies \nthe implicit programming model in EJBs, and can also be accessed directly from Java objects. As in WCF, \nannotations embedded in EJBs control transaction initiation, termination, and propagation. In the Java world, \nthe Spring Framework is emerging as an alternative for TP application development. It includes a transaction \nmanagement abstraction API that’s conﬁ gurable for either JDBC- or JTA-managed transactions. \n In Java EE the same set of annotations is used for transaction control and propagation, whereas these func-\ntions can be controlled separately in the .NET Framework. Another difference between the environments \nis that the .NET Framework automatically promotes a single resource transaction to a multiresource trans-\naction when it detects an application accessing a second resource manager.  System.Transactions can \nautomatically reassign coordination responsibility from the resource manager’s transaction manager to an \nindependent transaction manager (i.e., DTC). In the Java EE environment, such a change has to be explicitly \nprogrammed. \n SOA -based designs are gaining adoption for TP applications using various technologies, such as Web \nServices and REST/HTTP. The transactional models differ for these two approaches. In Web Services, trans-\nactional RPC and compensation protocols are formalized in the WS-Transactions speciﬁ cations, which make \nmapping transactional capabilities fairly straightforward. With REST/HTTP, a transaction can be modeled as \n10.9 Summary  347\n\n\n348  CHAPTER 10 Transactional Middleware Products and Standards\n a resource. The server maintains the state of the resource and the front-end program maintains the application \nstate separately. Representations of state changes are exchanged using HTTP verbs. \n Persistence abstractions enable easier access to resource managers, especially relational databases. The ini-\ntial abstraction was designed to improve the use of remote database connections, and was formalized in ODBC \nand JDBC, which are still widely used. Newer abstractions include object-relational mappings such as JPA and \nentity data models such as ADO.NET Entity Framework. The abstraction mechanisms typically include trans-\naction management capabilities. \n TP standards help promote interoperability of TP environments and portability of applications. The most \nwidely adopted is the XA protocol, which deﬁ nes the relationship between a resource manager and an inde-\npendent transaction manager, so resource managers and transaction managers from different vendors can eas-\nily integrate. Other widely-adopted  standards include the Object Transaction Service from OMG, which is \nincluded in Java EE’s JTA, JTA itself, and WS-Transactions for Web services transactions. Emerging standards \ngaining adoption include SCA, OSGi’s enterprise edition, and AMQP. \n\n\n 11.1  INTRODUCTION \n Although the principles of transaction processing change very slowly, the technology that implements those \nprinciples changes all the time. Some of these changes involve repackaging well-known mechanisms to ﬁ t into \nnew software architectures. For example, over the years we have seen transactional RPC appear in TP moni-\ntors, client-server database systems, object request brokers, application servers, and web services. Other changes \nare driven by cost reductions in hardware and communications that put additional applications within reach. For \nexample, airline reservation systems evolved from simply keeping track of the number of available seats to add-\ning applications for frequent ﬂ yer programs, special meals, seat assignments, complex fares, and notiﬁ cations via \ne-mail and text messaging. Banking and stock brokerage systems have undergone a similar evolution. We are now \nseeing a growing use of mobile devices to access TP applications, such as managing a doctor’s appointments. \n A third driver of changes are web-based enterprises with large TP sites. When off-the-shelf technology \nfails to meet their needs, they often roll their own. Forty years ago, early corporate on-line TP application \ndevelopers rolled their own middleware. Later, transactional middleware products, such as TP monitors, came \nalong with general-purpose implementations of the same functionality. We expect to see this trend continue, \nwith custom solutions for the largest e-commerce sites migrating into transactional middleware and database \nsystem products. \n This chapter highlights four areas where we expect that technological changes will have a major effect on \nthe design of TP systems and products: cloud computing, scalable distributed computing, ﬂ ash memory, and \nstream processing. Since these areas are changing rapidly, anything we say about the technology is likely to \nbecome quickly outdated. So we will focus on overall trends, not on technical detail. \n 11.2  CLOUD COMPUTING \n Cloud computing is a computing service offered over the Internet. That is, a customer plugs into the  “ network \ncloud ” and uses computing capabilities owned and operated by another company called the  service provider . \nThe service provider may be a large company with many data centers containing hundreds of thousands of \nmachines, such as Microsoft, Google, Yahoo!, Amazon.com, IBM, or  Salesforce.com . \n Roughly speaking, a computing service can be an application-speciﬁ c service or a generic service. An \napplication-speciﬁ c service offers a particular application, such as e-mail, search, enterprise resource planning \n Future Trends \n 11 \nCHAPTER\n",
      "page_number": 359
    },
    {
      "number": 36,
      "title": "Segment 36 (pages 368-377)",
      "start_page": 368,
      "end_page": 377,
      "detection_method": "topic_boundary",
      "content": "350  CHAPTER 11 Future Trends\n (ERP), customer relationship management (CRM), or social networking. An application-speciﬁ c service usu-\nally is offered both as a web site that can be accessed from a browser and as a web service that can be invoked \nby other applications. The application is usually customizable and extensible. \n A generic service offers a general-purpose computing service, such as raw storage, record-oriented data \nstorage, data warehousing, or raw processing power. The latter often is provided in the form of a virtual \nmachine (VM) into which the customer can load any kind of software. \n An application-speciﬁ c service may be combined with generic services. For example, a social networking \napplication may run in one cloud service but store large media ﬁ les on another service provider’s cloud service. \n The customer may use the generic service as extra data center capacity, for processing, storage, or both. \nFor example, a company could use cloud computing services to test new functionality or to handle temporary \nworkload spikes. Or the customer may use the service as its primary computing infrastructure. Sometimes, the \ncustomer starts using it as extra capacity and, after gaining conﬁ dence in the service, evolves into using it as its \nprimary computing facility. \n One of the attractions of most cloud computing services is that they gracefully scale up or down to meet \nthe current workload. That is, the customer pays only for the capacity that’s needed at any given moment. For \nexample, if a company is suddenly front-page news and hence gets a huge burst of trafﬁ c, the cloud computing \nservice can quickly respond by scaling up the company’s application to run on triple the number of machines \nto handle the load. \n A set of generic services can be packaged together, much like system software components that are pack-\naged into transactional middleware. For example, a service may offer a combination of computing, storage, \nand database management. A customer writes his or her application to the service’s API in much the same way \nhe or she would write it to a transactional middleware API. The service provider ensures that any application \nwritten to their API will scale up. Usually, this requires that the API restricts functionality in certain ways; for \nexample, to minimize or avoid the use of two-phase commit or database queries that span many machines. \nThese restrictions are designed to ensure that data and computation can be partitioned efﬁ ciently across many \nmachines, and that the partitioning automatically adjusts to changing the load by dynamically repartitioning \nacross more machines and balancing the load among them. \n Another attraction of cloud computing services is that the customer beneﬁ ts from the economies of scale \nthat are available to the service provider. A large-scale service provider can invest in complex system manage-\nment software to minimize the staff required to run the service, something that is beyond the reach of most \ncustomers today. They can buy communications bandwidth at wholesale rates. They can design custom hard-\nware with lower power requirements. And they can reduce the need for expensive backup electrical power by \ngeo-replicating applications, so if a data center goes off-line another can immediately pick up the load. These \ncost savings can be shared with the customer, so that both customer and service provider beneﬁ t. \n Today , to obtain economies of scale, a generic service typically runs a ﬁ xed small set of components of \neach type, often just one. For example, it may support only one message queuing system and two database \nsystem products. Thus, by choosing a generic service, customers are choosing the software platform on which \ntheir applications will run. Over time, service providers may compete by the range of platforms they offer. \n Multitenant Systems \n This book is about the technology for building application-speciﬁ c services for TP applications. However, we \nhave not covered one important aspect of such applications that arise in cloud computing, that of supporting \nindependent enterprises using the same service provider’s computing infrastructure. This is called  multitenant \nsupport. Consider a CRM service that supports many enterprise customers. When an enterprise signs up as a \ncustomer of the service, the service provider needs to  provision the system; that is, assign resources that are \n\n\n required to serve the customer. For example, it might need to allocate storage space, adjust the conﬁ guration so \nthat requests from this customer are serviced by server machines that have access to the customer’s database, \nand update the network name service with a customer-speciﬁ c URL that is directed to the service provider’s \nnetwork address. \n The service provider faces architectural decisions about how to isolate customers from each other. For \nexample, it could create a separate database for each customer. This ensures that data from different custom-\ners isn’t accidentally comingled. However, this doesn’t scale very well if the service provider supports a large \nnumber of small customers, due to the ﬁ xed overhead of each separate database. An alternative is to have one \ndatabase that serves all customers, where the customer ID is a ﬁ eld of every table in the database. In this case, \nthe service provider’s application needs to be very careful to give each customer access only to those database \nrecords that have that customer’s ID. \n Virtual machine technology can also be used to isolate customers from each other. A virtual machine can \nbe conﬁ gured for each customer with all the customer’s required resources. Since an application has access \nonly to the resources assigned to its virtual machine, this approach reduces the chance that one customer’s data \nleaks to another customer. \n 11.3  SCALABLE DISTRIBUTED COMPUTING \n With a corporate TP application, the users are known — usually, they are the employees of the company. The \nload is fairly predictable, especially for back-ofﬁ ce applications and customer-facing applications whose load \nis bounded by physical constraints, such as the number of cash registers or gas pumps where a customer can be \nserved. And downtime for upgrades and maintenance can be scheduled since the application is running inside \nof the business. \n By contrast, the web environment is less predictable and controllable. Large web sites have to be prepared \nto react immediately to huge spikes in application load, to maintain higher levels of availability, and to upgrade \ntheir systems without taking them out of service. \n Many of these requirements are not easily met by traditional transactional middleware products, since \nthey were designed to meet the requirements of internal systems. Still, the mechanisms required to meet these \nrequirements are well known. Indeed, many of them were covered in this book. What changes is how the mech-\nanisms are assembled into a complete system that has satisfactory availability, performance, scalability, secu-\nrity, manageability, and so on. By looking at the largest e-commerce web sites, many trends can be identiﬁ ed: \n ■  More use of caching: While browsing, a user expects instant response time. To do this in a cost-effective \nway, systems exploit skewed access patterns by caching frequently accessed information. This is done at \nevery layer of the multitier architecture — in HTTP proxy servers, web servers, application servers, and \ndatabase servers. Ordinarily, the system refreshes its cache frequently, especially for items that change \nrapidly. During workload spikes, the system may use fewer of its resources to refresh its cache, thereby \ngiving good response time to more users but offering more stale results. Cache management has become \nso important that it has become a separate product category. \n ■  More use of updatable caches: Not all cached data is static. When cached data is updated, the update must \nﬂ ow to all the caches that store it. We described the approaches in Chapter 9: primary copy, where the \nupdate is ﬁ rst applied to the master and then propagated to the caches; and multimaster, where an update \ncan be directly applied to any cache and then propagated lazily to the other caches. In either case, the rep-\nlication model is one of eventual consistency, not instantaneous consistency. In many cases, this weaker \nmodel offers acceptable behavior to end users, while yielding better availability and partition tolerance. \n11.3 Scalable Distributed Computing  351\n\n\n352  CHAPTER 11 Future Trends\n ■  More use of queued transactions: After a user has ﬁ nished browsing and is ready to take action, such \nas placing an order, it is usually enough that the system captures the request reliably and quickly. It is \nusually not necessary to process the request instantly. Thus, if there is a burst of trafﬁ c the system can \ngive a good customer experience as long as the queuing system can handle the load. When combined \nwith caching, this sometimes leads to rejected requests, because the user issued the request based on \ninformation that turned out to be too stale, such as quantity on hand or highest bid. In effect, rejecting \nsuch requests is a form of optimistic concurrency control. This occasional undesirable result usually is \nregarded as an acceptable compromise in return for better scalability. \n ■  More use of business processes: This is a natural consequence of increased use of queued transactions. \nSince an instant response isn’t required, it is not critical that the entire request run as a single transaction. \nTherefore, for all the reasons discussed in Chapter 5, it makes sense to break up the request into multiple \nsteps, which often execute on different systems. This is a form of partitioning, which makes the system \nmore scalable. Also, the system can be made more available by continuing to offer some level of service \neven when some subsystems are down. This leads to more application programming for compensating \ntransactions and more system support to automate their invocation. \n ■  More use of dynamic partitioning: When a server becomes overloaded, its workload needs to be spread \nover more servers. This entails installing the application on those servers and often partitioning the database \nacross those servers. Some systems have made this an automated process, thereby enabling graceful growth. \n ■  More physical componentization of applications: With the use of service-oriented architecture and \nobject-oriented design, applications are more componentized and reusable in multiple contexts. For eas-\nier manageability, it is beneﬁ cial to partition these application components on different systems. This iso-\nlates their workload for easier performance management and enables them to be independently upgraded \nwithout affecting other applications on the web site. \n ■  More exploitation of user requirements: Some technology problems can be addressed by trading off cus-\ntomer requirements. For example, users have learned to accept communication errors as a fact of life, since \nthey can occur for a broader set of reasons and are largely outside their control. Therefore, following a \ncommunication error, customers may prefer fast resubmission of requests rather than ensuring reliable cap-\nture of all input. Another example of a tradeoff is relaxing immediate consistency of some data to ensure \nonly eventual consistency, but gaining performance and availability in the face of network partitions. \n ■  More use of cloud computing: A TP system needs to be conﬁ gured for its peak workload. If the work-\nload increases rapidly, a common occurrence when an Internet site becomes popular, a  “ success disaster ” \ncan occur where the system is unable to grow fast enough to handle the increasing load. As a result, \ncustomers leave in frustration. Instead of each system paying for spare capacity that it probably will not \nneed, a cloud-based service can be conﬁ gured with enough headroom to handle load spikes from a few \nof its many tenants. The cost of the headroom is therefore spread across many more applications, reduc-\ning the system cost for all of them. \n The current generation of transactional middleware and database systems is not ﬂ exible enough to enable \nthe cost-effective construction of the largest web sites, such as those managed by Amazon, Google, eBay, and \nMicrosoft. These companies have therefore invested heavily in building out their own solutions. The older \ntechnologies are often in the mix, but play designated roles rather than serving as the primary infrastructure. \n We expect the system architecture for assembling such sites to stabilize, at which point we expect to see a new \ngeneration of transactional middleware products modeled on that architecture. These may be packaged products, \nlike classical transactional middleware, or cloud-based platforms that are made available to application tenants. \nWhatever form they take, we expect them to borrow heavily from the solutions adopted by today’s largest web sites. \n\n\n 11.4  MEMORY TECHNOLOGY \n Magnetic disks were one of the main technologies that enabled the development of the ﬁ rst TP systems in the \n1960s. Until very recently, it has remained the only nonvolatile storage medium for on-line random access to \nlarge databases. We are now beginning to see nonvolatile solid state devices that are viable alternatives to disk, \nparticularly those based on ﬂ ash memory. Given the high demand for ﬂ ash memory for use in digital cameras, \nmusic players, and cell phones, manufacturers have been able to ramp up production to very high volumes. As \na consequence, the cost and capacity of ﬂ ash memory has been dropping rapidly. \n There are three main performance metrics for nonvolatile storage: \n ■  Capacity: The number of gigabytes it can store \n ■  Bandwidth: The rate at which data can be streamed onto or off of the device \n ■  Latency: The time required for a random read or write \n Although the capacity of magnetic disks has improved dramatically, their bandwidth and latency have \nimproved much more slowly. There are physical limits to how fast the disk can spin, which along with bit den-\nsity determine disk bandwidth. And there are limits to how quickly a head can seek to a new cylinder, which \ndetermines disk latency. \n Semiconductor devices offer much shorter latency than magnetic disks, roughly two orders of magnitude \nshorter. However, until recently, they were too expensive per gigabyte to offer a meaningful alternative to mag-\nnetic disk. This is now changing due to the availability of higher-density ﬂ ash memory chips, which reduce \nthe cost per gigabyte. Solid state disk devices are now available that use ﬂ ash memory, have the capacity of a \nsmall magnetic disk drive, and are competitively priced. Given that fast random access to nonvolatile storage is \na major determinant of TP performance, it is likely that these solid state storage devices will become a popular \nalternative to magnetic disks for TP systems. \n Other solid state memory technologies are under development, which have characteristics that make them \npotentially competitive with dynamic RAM (DRAM) and ﬂ ash memory. Current examples are magnetoresis-\ntive RAM (MRAM), memristors, and phase-change memory (PCM or PRAM). It is too soon to tell whether \nany of these technologies will reach commodity status and hence be candidates to dislodge today’s market \ndominance of DRAM and ﬂ ash. However, they are sufﬁ ciently promising to be worth tracking as a possible \nsource of disruptive change to the storage device market. \n 11.5  STREAMS AND EVENT PROCESSING \n One source of inputs for a TP system are real-time devices that detect events in the physical world. Example \napplications include processing streams of price changes in ﬁ nancial markets, monitoring events in a computer \nnetwork, tracking packages using RFID tags, and monitoring automobile movement for trafﬁ c control. \n Such applications take as input streams of messages — essentially requests in our terminology. In many \nof these applications it is inappropriate or infeasible to store messages in a persistent database before taking \naction based on that data. It may be inappropriate because it introduces too much delay before the input event \nis processed. It may be infeasible because the incoming data rate is too high. This breaks the classical TP \nparadigm, where the message causes a transaction to execute, the transaction stores the data in a database, and \nusers query that data later. \n Instead , the messages need to be processed while they pass through main memory on their way to persistent \nstorage (if they are stored at all). This processing usually involves a query that ﬁ lters the data for events that \ndetermine whether the data is of special interest and, if so, what action to take. The query may need to access \n11.5 Streams and Event Processing  353\n\n\n354  CHAPTER 11 Future Trends\n a persistent database to compare the new message to past behavior, for example, to identify an unusual price \nchange for electronic trading or an unusual purchase for fraud detection. It may also need to access a range of \nrecent messages, to determine a trend or a break in a trend in a ﬁ nancial market. It may need to deal with errone-\nous and out-of-order messages, which requires retracting query results , much like a compensating transaction. \n This style of application is reminiscent of messaging applications that are supported by message-oriented \nmiddleware, as described in Chapter 5. What makes them different are primarily the performance requirements: \nresponse time, throughput, and scalability. These requirements create challenges for conventional transactional \nmiddleware and database systems, where data must be stored before it can be processed. This has led to the \ndevelopment of specialized database systems for stream processing. \n Stream processing functionality is already becoming an important capability of database systems. It is impor-\ntant for TP as well, and this importance is likely to continue growing for some time. Contributing factors include \nthe decreasing cost and increasing function of sensor devices, the growth and declining cost of wireless networks, \nand the desire to monitor more events of the physical world in real time. \n 11.6  SUMMARY \n Businesses continually adapt to changing technology capabilities and pricing. Although transaction processing \nprinciples have remained fairly constant during the past 20 years or so, the technologies that implement the \nprinciples have been evolving. Recent changes starting to impact transactional middleware products include \ncloud computing, highly scalable computing designs, solid state memory, and streaming event processing. \nThese changes are too recent for us to predict with any certainty what impact they’ll have on the next genera-\ntion of transactional middleware, but we can at least identify the trends to watch. \n Cloud computing is a computing service offered over the Internet. A service provider may offer a complete \napplication, such as e-mail, search, enterprise resource planning (ERP), customer relationship management \n(CRM), or social networking. Or they may offer generic infrastructure services such as providing processing and \nstorage capacity on demand. Some cloud computing systems provide a combination of these capabilities. Usually, \nthe service can scale up quickly when the workload increases, and the customer pays only for the capacity that \nactually is used. \n The largest web sites are innovating in the use of custom designs for scalable computing. This customiza-\ntion is needed to cope with the unpredictability of workloads and the need to optimize fast response times for a \ngood customer experience. Such customization is reminiscent of the early years of transaction processing tech-\nnologies, where companies developed middleware for their internal applications. Among the techniques now \nbeing employed are additional caching at every level of the multitier TP architecture to improve performance \nand ensure good response time, increased use of queued transactions and business processes, and more dynamic \napplication partitioning. \n The evolution of nonvolatile solid state memory as an alternative to magnetic disk is another trend inﬂ u-\nencing TP system design. Flash memory is now being used for solid state disks. Its capacity is continually \nincreasing, while its cost is decreasing. Its latency is much smaller than that of magnetic disk, making it very \nattractive for TP applications. Solid state memory is also likely to have a signiﬁ cant impact on mid-tier cach-\ning solutions for scalability. \n Finally , the growing importance of processing data and event streams is another trend likely to affect trans-\nactional middleware products. Stream processing technology enables data to be processed in real time, while \nit is in ﬂ ight — that is, before it is persisted. This is similar to message processing, but with higher performance \nand throughput. \n\n\n The following acronyms are used in this book. If an acronym is speciﬁ c to a company, organization, or product, the company, \norganization, or product name is appended. \n 2PC \n two-phase commit \n 3270 \n block-mode terminal — IBM \n 4GL \n fourth-generation language \n ACID \n atomicity, consistency, isolation, durability (properties of a transaction) \n ACMS \n Application Control and Management System — HP \n ACP \n Airline Control Program — IBM \n ADO \n ActiveX Data Objects — Microsoft \n AJAX \n Asynchronous JavaScript And XML \n AMD \n Advanced Micro Devices \n ANSI \n American National Standards Institute \n AP \n application program \n API \n application programming interface \n APPC \n Advanced Program to Program Communication — IBM \n AQ \n Advanced Queuing — Oracle \n ARM \n Advanced RISC Machine  – ARM Holdings \n ASP \n Active Server Pages — Microsoft \n ATM \n automated teller machine \n ATMI \n Application Transaction Manager Interface — Oracle \n BMS \n Basic Mapping Services — IBM \n BPM \n business process management \n BPMN \n Business Process Modeling Notation — OMG \n CAP \n consistency, availability, and partition-tolerance \n CCI \n Common Client Interface (part of JCA) — JCP \n CDR \n Common Data Representation — OMG \n CGI \n Common Gateway Interface — W3C \n CICS \n Customer Information and Control System — IBM \n CLR \n Common Language Runtime — Microsoft \n COM \n Component Object Model — Microsoft \n COM \u0005 \n Component Object Model plus — Microsoft \n CORBA \n Common Object Request Broker Architecture — OMG \n CRM \n customer relationship management \n DAG \n directed acyclic graph \n DB \n database manager \n DBA \n database administrator \n DL/I \n Data Language/I — IBM \n DM \n data manager \n DNS \n Domain Name System — IETF \n DPL \n Distributed Program Link — IBM \n DRAM \n dynamic random access memory \n DSN \n data source name \n DTC \n Distributed Transaction Coordinator — Microsoft \n DTP \n distributed transaction processing \n ECI \n external call interface (part of CICS) — IBM \n EDI \n Electronic Data Interchange — UN/EDIFACT \n EDM \n entity data model \n EAI \n enterprise application integration \n Glossary of Acronyms \n\n\n356  Glossary of Acronyms\n EJB \n Enterprise Java Beans — Java Enterprise Edition \n EPI \n external programming interface (part of CICS) — IBM \n ERP \n enterprise resource planning \n ESB \n enterprise service bus \n FML \n Field Manipulation Language — Oracle \n GUI \n graphical user interface \n HIS \n Host Integration Server — Microsoft \n HTML \n Hypertext Markup Language — W3C \n HTTP \n Hypertext Transfer Protocol — IETF \n HTTPS \n HTTP/TLS — IETF \n ID \n identiﬁ er \n IDE \n interactive development environment \n IDL \n interface deﬁ nition language \n IETF \n Internet Engineering Task Force \n IIOP \n Internet Inter-Orb Protocol — OMG \n IIS \n Internet Information Server — Microsoft \n IMS \n Information Management System — IBM \n I/O \n input/output \n ISAPI \n Internet Server Application Programming Interface — Microsoft \n ISC \n Intersystem Communication — IBM \n Java EE \n Java Enterprise Edition — JCP \n Javax \n Java extensions — JCP \n JAXB \n Java Architecture for XML Binding — JCP \n JAX-RS \n Java API for Restful Web Services — JCP \n JAX-WS \n Java API for XML Web Services — JCP \n JCA \n Java Connector Architecture — JCP \n JCP \n Java Community Process \n JDBC \n Java Database Connectivity — JCP \n JMS \n Java Messaging Service — JCP \n JNDI \n Java Naming and Directory Interface — JCP \n JPA \n Java Persistence Architecture — JCP \n JSON \n JavaScript Object Notation — JSON.org \n JSF \n Java Server Faces — JCP \n JSP \n Java Server Pages — JCP \n JTA \n Java Transaction API — JCP \n JTS \n Java Transaction Service — JCP \n LAN \n Local Area Network \n LINQ \n Language-Integrated Query — Microsoft \n LOB \n Line of Business adapter — Microsoft \n LSN \n log sequence number \n LTM \n Lightweight Transaction Manager — Microsoft \n LU6.2 \n Logical Unit 6.2 protocol — IBM \n MFS \n Message Format Service — IBM \n MQ \n message queue \n MQI \n Message Queue Interface — IBM \n MRAM \n magnetoresistive random access memory \n MRO \n Multiregion Operation — IBM \n MSC \n Multiple Systems Coupling — IBM \n MSMQ \n Microsoft Message Queue — Microsoft \n MTBF \n mean time between failures \n MTTR \n mean time to repair \n MVI \n modiﬁ ed version ID \n NSAPI \n Netscape Server API — Sun \n NSK \n NonStop Kernel — HP \n OASIS \n Organization for the Advancement of Structured Information Standards \n\n\nGlossary of Acronyms  357\n ODBC \n Open Database Connectivity — SQL Access Group \n OLE \n Object Linking and Embedding — Microsoft \n OLE DB \n Object Linking and Embedding, Database — Microsoft \n OLTP \n on-line transaction processing \n OMG \n Object Management Group \n OpenVMS \n Open Virtual Management System — HP \n OO \n object-oriented \n OSI TP \n Open Software Interconnect Transaction Processing — ISO \n OSS \n Open System Services — HP \n OTMA \n Open Transaction Manager Access — IBM \n OTS \n Object Transaction Service — OMG \n PARS \n Programmed Airline Reservation System — IBM \n PC \n personal computer \n PCM \n phase change memory \n PL/SQL \n Procedural Language/Structured Query Language — Oracle \n POJO \n plain old Java object \n POWER \n Performance Optimization With Enhanced RISC — IBM \n PowerPC \n Power Performance Computing — Apple, IBM, and Motorola \n PRAM \n parameter random access memory \n PSPE \n Promotable Single Phase Enlistment — Microsoft \n RAID \n redundant array of inexpensive disks \n RAM \n random access memory \n RCP \n Rich Client Platform — Eclipse \n RDF \n Remote Database Facility — HP \n REST \n representational state transfer \n RFID \n radio frequency identiﬁ cation \n RM \n resource manager \n RMI \n Remote Method Invocation — JCP \n RMI/IIOP \n RMI over IIOP — JCP \n RPC \n remote procedure call \n RSS \n RDF Site Summary — RSS-DEV Working Group \n RTR \n Reliable Transaction Router — HP \n SABRE \n Semi-Automated Business Research Environment — Sabre Holdings \n SALT \n Services Architecture Leveraging Tuxedo — Oracle \n SCA \n Service Component Architecture — OASIS \n SCSI \n Small Computer System Interface — ANSI \n SDF \n Screen Deﬁ nition Facility — IBM \n SDO \n Service Data Objects — OASIS \n SI \n Systems Interface — HP \n SLA \n service level agreement \n SMP \n symmetric multiprocessor \n SNA \n System Network Architecture — IBM \n SOA \n service-oriented architecture \n SPARC \n Scalable Processor Architecture — Sun \n SPI \n system programming interface \n SQL \n Structured Query Language — ISO \n SQL/PSM \n Structured Query Language/Persistent Stored Modules — ANSI \n SSL \n Secure Socket Layer — IETF \n STDL \n Structured Transaction Deﬁ nition Language — The Open Group (formerly X/Open) \n TAL \n Transaction Application Language — HP \n TCP \n Terminal Control Program — HP \n TCP/IP \n Transmission Control Protocol/Internet Protocol — IETF \n TDL \n Task Deﬁ nition Language — HP \n TLS \n Transport Layer Security — IETF \n TM \n transaction manager \n\n\n358  Glossary of Acronyms\n TMF \n Transaction Management Facility — HP \n TP \n transaction processing \n TPC \n Transaction Processing Performance Council \n TPC-A, -B, -C, -E, -H \n Transaction Processing Performance Council benchmarks A, B, C, E, and H \n TPF \n Transaction Processing Facility — IBM \n tpm \n transactions per minute \n tpmC \n transactions per minute — TPC-C \n tps \n transactions per second \n tpsE \n transactions per second — TPC-E \n $/tpsE \n cost per transaction per second — TPC-E \n TX \n Transaction Demarcation API — The Open Group (formerly X/Open) \n TxF \n Transactional NT File System — Microsoft \n TxRPC \n Transactional Remote Procedure Call — The Open Group (formerly X/Open) \n UDDI \n Universal Description, Discovery, and Integration  – OASIS \n UML \n Uniﬁ ed Modeling Language — OMG \n UN/EDIFACT \n United Nations/ Electronic Data Interchange For Administration, Commerce, and Transport \n URI \n Uniform Resource Identiﬁ er — W3C \n URL \n Uniform Resource Locator — W3C \n VAX \n Virtual Address Extension — HP \n VB \n Visual Basic — Microsoft \n VM \n virtual machine \n VSAM \n Virtual Sequential Access Method — IBM \n VSE \n Virtual Storage Extended \n W3C \n World Wide Web Consortium \n WAN \n wide area network \n WCF \n Windows Communication Foundation — Microsoft \n WF \n Windows Workﬂ ow Foundation — Microsoft \n WPF \n Windows Presentation Foundation — Microsoft \n WSDL \n Web Services Description Language — W3C \n WS-AT \n Web Services Atomic Transaction — OASIS \n WS-BA \n Web Services Business Activity — OASIS \n WS-BPEL \n Web Services Business Process Execution Language — OASIS \n WS-C \n Web Services Coordination — OASIS \n WS-I \n Web Services Interoperability Organization \n WWW \n World Wide Web \n WYSIWYG \n What you see is what you get \n XA \n Interface between TM and RM — The Open Group (formerly X/Open) \n XAML \n Extensible Application Markup Language — Microsoft \n XATMI \n X/Open Application Transaction Manager Interface — The Open Group (formerly X/Open) \n XDR \n External Data Representation — IETF \n XHTML \n Extensible Hypertext Markup Language — W3C \n XID \n X/Open transaction ID — The Open Group (formerly X/Open) \n XML \n Extensible Markup Language — W3C \n XPath \n XML Path Language — W3C \n XRF \n extended recovery facility — IBM \n XSD \n XML Schema Deﬁ nition language — W3C \n XSL \n Extensible Stylesheet Language — W3C \n XSLT \n XSL Transformations — W3C \n \n\n\n The goal of these bibliographic notes is to provide some historical context and offer places to ﬁ nd additional material on each \ntopic. It is not intended to be a comprehensive bibliography. \n The deﬁ nitive work on TP technology is  Transaction Processing: Concepts and Techniques , by Jim Gray and Andreas Reuter \n(1992). Most of the topics in this book are covered there in more detail, usually from the viewpoint of someone developing a data-\nbase system or transactional middleware. For the reader who wants to dig deeper into TP technology, this is an excellent place to \nlook. However, it is no longer the last word on some topics, since there has been technical progress since it was published. For a \nmore up-to-date view on any particular topic, see the following bibliographic notes. \n Most articles on advanced transaction processing technology are published in the database research ﬁ eld. A very complete \nbibliography search engine called DBLP is available at  http://www.sigmod.org/dblp/db/index.html . Most of the relevant confer-\nence proceedings can be obtained from the ACM SIGMOD Anthology ( http://www.sigmod.org/sigmod/anthology/index.htm ) and \nthe ACM Digital Library ( http://portal.acm.org/dl.cfm ). \n More extensive bibliographic notes for Chapters 6 through 9 can be found in Bernstein et al. (1987) and for Chapters 6 \nthrough 8 in Weikum and Vossen (2002). These are academic-style textbooks that cover the material in more depth. Other books \non transaction processing are Claybrook (1992) and Lewis et al. (2002). \n CHAPTER 1 INTRODUCTION \n The concepts of transaction and TP monitor appeared in the early 1970s. There is a rich literature on the theory of transactions, \nstarting from the mid 1970s (see Bernstein, Hadzilacos, and Goodman, 1987, for references), and on their implementation (ﬁ rst \nsummarized in Gray, 1978, and later in Gray and Reuter, 1992). SOA and Web Services are described in Newcomer and Lomow \n(2004). REST is described in Richardson and Ruby (2007). For references on transactional middleware, see the Bibliographic \nNotes for Chapter 3. \n An early inﬂ uential paper on the transaction concept was Eswaran et al. (1976), which includes some earlier references. The \nacronym ACID was coined in H ä rder and Reuter (1983). For references on the two-phase commit protocol, see the Bibliographic \nNotes for Chapter 7. \n The most up-to-date information on TPC benchmarks can be found at the Transaction Processing Performance Council web site, \n http://www.tpc.org . A description of the evolution of TPC-A/B into TPC-C is in Levine et al. (1993). Articles about many database \nand TP benchmarks can be found in Gray (1993). Much of Section 1.6 on availability is from Gray (1986). \n CHAPTER 2 TRANSACTION PROCESSING ABSTRACTIONS \n The material on transaction bracketing is mostly from the authors ’ experience in designing and using transaction APIs. \nDescriptions of the use of transaction attributes in object-oriented programming in .NET can be found at the Microsoft web site, \n http://msdn.microsoft.com . For Java EE, see  http://java.sun.com/javaee . The nested transaction model described here is from Moss \n(1985); see also Lynch et al. (1993) for a mathematical treatment and Liskov (1988) for a language that embodies the model. \nDetails about threads can be found in any modern operating systems textbook, such as Silberschatz et al. (2008). The core mate-\nrial on RPC is from Birrell and Nelson (1984), the classic research paper on this topic. \n CHAPTER 3 TRANSACTION PROCESSING APPLICATION ARCHITECTURE \n The three-tier TP application architecture model is from Bernstein (1990) and Bernstein et al. (1991). See also Gray and Edwards \n(1995) and Chapter 5 of Gray and Reuter (1992). The more up-to-date view of multitier TP application architecture is based on the \nauthors ’ knowledge of current products. The REST architectural pattern was introduced in Chapter 5 of Fielding (2000). Details of the \nSecure Socket Layer can be found in Rescorla (2001). Kaufman et al. (2002) give a general treatment of network security. Howard and \nLeBlanc (2003) give a more prescriptive view of how to ensure code is secure. See the Bibliographic Notes for Chapter 10 for speciﬁ c \nproduct references. \n Bibliographic Notes \n",
      "page_number": 368
    },
    {
      "number": 37,
      "title": "Segment 37 (pages 378-388)",
      "start_page": 378,
      "end_page": 388,
      "detection_method": "topic_boundary",
      "content": "360  Bibliographic Notes\n CHAPTER 4 QUEUED TRANSACTION PROCESSING \n Much of this chapter evolved from Bernstein et al. (1990), which in turn was inﬂ uenced by many sources, such as Gray (1978) and \nPausch (1988). A good place to ﬁ nd more details about the publish-subscribe paradigm is in books about the Java Messaging Service \nor at  http://java.sun.com/products/jms/ . Further information on Websphere MQ and Oracle Streams AQ can be found at  http://www.\nibm.com and  http://www.oracle.com , respectively. The Advanced Message Queue Protocol is described at  www.amqp.org . \n CHAPTER 5 BUSINESS PROCESS MANAGEMENT \n Jajodia and Kerschberg (1997) is an anthology of business process models, written by many top researchers working in that ﬁ eld. \nLeymann and Roller (2000) present a broad overview of business process technology from requirements and design through run-\ntime deployment. The WS-BPEL standard and associated documents are at  http://www.oasis-open.org/ . Wolter (2006) explains the \ntechnology of SQL Server Service Broker and how to use it. Documents about the Business Process Modeling Notation are at  http://\nwww.omg.org . WS-BPEL is described at  http://www.oasis-open.org/committees/tc_home.php?wg_abbrev=wsbpel . Other relevant \nmaterial about business processes can be found at the web site of the Workﬂ ow Management Coalition ( http://www.wfmc.org ). \n CHAPTER 6 LOCKING \n Two -phase locking was introduced in Eswaran et al. (1976). The deadlock discussion is from Chapter 3 of Bernstein et al. (1987). \nThe description of lock managers is from Gray (1978). The view of locking performance is from Tay (1987) and Thomasian (1996, \n1998); for further reading, see Shasha and Bonnet (2002). Most of the hot spot methods originated in IMS Fast Path (Gawlick and \nKinkade 1985). Degrees of isolation originated in Gray et al. (1976); see Berenson et al. (1995) for an updated presentation. \nChan et al. (1982) describes an early implementation of multiversion data. The phantom problem was introduced in Eswaran \net al. (1976). The use of index locking to avoid phantoms appears in Lomet (1993). Optimistic concurrency control was introduced \nin Kung and Robinson (1981). \n B -trees were introduced in Bayer and McCreight (1972). There are many papers on B-tree variations and optimizations. An \nearly survey is Comer (1979). The preﬁ x B-tree optimization is in Bayer and Unterauer (1977). The lock coupling protocol is from \nBayer and Schkolnick (1977) and Kedem and Silberschatz (1980). The B-link optimization is by Lehman and Yao (1981). \n Multigranularity locking was introduced in Gray et al. (1975, 1976). The nested transaction model was introduced in Reed \n(1978). The locking protocol for nested transactions is from Moss (1985). \n Timestamp ordering and serialization graph testing are described in Chapter 4 of Bernstein et al. (1987). Commit ordering is \npresented in Raz (1992). \n CHAPTER 7 SYSTEM RECOVERY \n The introduction that summarizes causes of failure was inspired by Gray (1986). The explanation of recovery and checkpoint-\ning techniques in Section 7.2 was developed for this book, but was heavily inﬂ uenced by ideas in early products from Tandem \nComputers. The model of recovery management in Sections 7.4 and 7.5 is an expanded version of material in Chapter 6 of \nBernstein et al. (1987), which was in turn heavily inﬂ uenced by Gray (1978) and H ä rder and Reuter (1983). The shadow-paging \nalgorithm in Section 7.6 is from Lorie (1977). \n Many logging algorithms have been published, going back at least to Gray (1978). The use of LSNs in pages are discussed in \nLindsay (1980). The ARIES algorithm is described in Mohan et al. (1992). Mohan (1999) gives a retrospective of ARIES and its vari-\nations with an extensive bibliography. Other details about logging can be found in Gray and Reuter (1992), Lomet (1992), Lomet and \nTuttle (2003), and Weikum and Vossen (2002). Kumar and Hsu (1998) is an anthology that includes many of these articles and others. \n Disk failure rates are presented in Gray and Van Ingen (2005) and Pinheiro et al. (2007). RAID was introduced in Patterson et al. \n(1988). \n CHAPTER 8 TWO-PHASE COMMIT \n The two-phase commit protocol was ﬁ rst published in Lampson and Sturgis (1976) and explained further in Gray (1978) and \nLampson (1981). The tree of processes model is from Lindsay et al. (1984) and the presumed abort optimization is from Mohan \net al. (1986). This particular description borrows heavily from Chapter 7 of Bernstein et al. (1987). \n\n\nBibliographic Notes  361\n The X/Open model is published in The Open Group (1992). For descriptions of particular products, see Laing et al. (1991) for \nDigital’s VMS transaction manager, and Microsoft (2000) for Microsoft’s Distributed Transaction Coordinator. \n CHAPTER 9 REPLICATION \n One -copy serializability was introduced in Attar et al. (1984). The primary copy approach was ﬁ rst published in Stonebraker \n(1979). Majority consensus comes from Thomas (1979), and was extended in Gifford (1979) to quorum consensus. The behavior \nof timestamps is explained in Lamport (1978). \n There are many articles on how to reach consensus, not limited to the problem of deciding which replicas are alive and which \nis primary. An early such algorithm for data replication is the Virtual Partitions algorithm in El Abbadi et al. (1985) and El Abbadi \nand Toueg (1989). The algorithm for reaching consensus near the end of Section 9.4 is a variation of the Paxos algorithm in Oki and \nLiskov (1988) and Lamport (1998). An implementation is described in Chandra et al. (2007). \n The CAP conjecture was posed in Brewer (2000). It was proved in Gilbert and Lynch (2002). \n The multimaster implementation of Lotus Notes is described in Kawell et al. (1988). Early use of version vectors for rep-\nlication are Fischer and Michael (1982) and Parker et al. (1983). A later algorithm is described in Ladin et al. (1992) with an \nextensive bibliography. The algorithms described here are based on Microsoft’s WinFS and Sync Framework, described in Novik \net al. (2006) and Malkhi et al. (2007). Terry (2008) presents an excellent survey of replication techniques for mobile computing. \nDeCandia et al. (2007) describes multimaster techniques used by  Amazon.com . \n The description of data sharing was modeled on Oracle’s Rdb/VMS, described in Lomet et al. (1992). Data sharing in IBM DB2 is \ndescribed in Josten et al. (1997). Concurrency control for data sharing is also discussed in Mohan and Narang (1991) and Rahm (1993). \n CHAPTER 10 TRANSACTIONAL MIDDLEWARE PRODUCTS AND STANDARDS \n Primary sources were used for most of the information in this chapter. The most signiﬁ cant web references are listed next. MSDN \nwas our source of most of the information about the .NET Framework. An excellent source of general information on Java EE and \nEJB3 is Burke and Monson-Haefel (2006). Java Swing is described in Loy et al. (2003). Further information about Java TP tech-\nnologies, standards, and programming techniques are in Little et al. (2004). \n SOA design principles and concepts, with case studies and a detailed description of the Credit Suisse SOA-based application, \nis in Krafzig et al. (2004). Richardson and Ruby (2007) explore how to use REST/HTTP for web services and SOA. Another view \nof RESTful services is in Vinoski (2008a,b). \n Alonso et al. (2004) give an overview of Web Services. Detailed descriptions of Web Services standards and their relation-\nships is in Werrawarana et al. (2005). \n The following books were used for the ﬁ rst edition as source material on legacy TP monitors, and much of the information \nremains relevant: Andrade et al. (1996), for Tuxedo; LeBert (1989), for CICS; UNIX International (1992), for Tuxedo and CICS; \nand Willis (1994), for OpenVMS. \n Other general sources of product and standards information are  http://www.infoq.com/ ,  http://www.theserverside.com/ , and of \ncourse  http://www.wikipedia.org/ . \n Apache \n General:  http://www.apache.org/ \n Apache HTTP Server:  http://httpd.apache.org/ \n Apache CXF:  http://cxf.apache.org/ \n Apache OpenJPA:  http://openjpa.apache.org/ \n Apache Tomcat:  http://tomcat.apache.org/ \n Apache ActiveMQ:  http://activemq.apache.org/ \n Eclipse \n General:  http://www.eclipse.org/ \n SOA Tools Platform Project BPMN Editor Screenshot examples:  http://www.eclipse.org/projects/\nproject_summary.php?projectid  \u0003  stp.bpmn http://www.eclipse.org/bpmn/images/screenshots/ \n\n\n362  Bibliographic Notes\n HP \n ACMS:  http://h71000.www7.hp.com/commercial/acms/index.html \n NonStop Software/Pathway:  http://h20219.www2.hp.com/NonStopComputing/cache/76380-0-0-230-470.html \n IBM \n IMS:  http://www.ibm.com/software/data/ims/ \n CICS:  http://www.ibm.com/software/htp/cics/ \n DB2:  http://www.ibm.com/software/data/db2/ \n WebSphere:  http://www.ibm.com/software/websphere/ \n Java Enterprise Edition (Java EE) \n General:  http://java.sun.com/javaee/ \n Enterprise Java Beans:  http://java.sun.com/products/ejb/ \n J2EE Connector Architecture:  http://java.sun.com/j2ee/connector/ \n Java Message Service:  http://java.sun.com/products/jms/ \n Java Persistence API:  http://java.sun.com/javaee/technologies/persistence.jsp \n Java Server Faces:  http://java.sun.com/javaee/javaserverfaces/ \n Java Server Pages:  http://java.sun.com/products/jsp/ \n Java Servlets:  http://java.sun.com/products/servlet/index.jsp \n Java Swing:  http://java.sun.com/javase/6/docs/technotes/guides/swing/ \n Java Transaction API:  http://java.sun.com/javaee/technologies/jta/ \n JDBC:  http://java.sun.com/products/jdbc/overview.html \n REST- JAX-RS:  http://jcp.org/aboutJava/communityprocess/ﬁ nal/jsr311/index.html \n Web services- JAX-WS:  http://jcp.org/en/jsr/detail?id \u0003 224 \n Microsoft \n NET Framework Overview:  http://msdn.microsoft.com/en-us/netframework/default.aspx \n ADO.NET:  http://msdn.microsoft.com/en-us/data/default.aspx \n BizTalk Server:  http://www.microsoft.com/biztalk/en/us/default.aspx \n Host Integration Server:  http://www.microsoft.com/hiserver/default.mspx \n Internet Information Services:  http://msdn.microsoft.com/en-us/library/aa737439.aspx \n Open Database Connectivity (ODBC):  http://msdn.microsoft.com/en-us/library/ms710252(VS.85).aspx \n Silverlight:  http://silverlight.net/ \n SQL Server:  http://www.microsoft.com/sqlserver/2008/en/us/default.aspx \n System.Transactions:  http://msdn.microsoft.com/en-us/library/system.transactions.aspx \n Visual Studio:  http://msdn.microsoft.com/en-us/vstudio/default.aspx \n Windows Communication Foundation:  http://msdn.microsoft.com/en-us/library/ms735119.aspx \n Windows Presentation Foundation:  http://msdn.microsoft.com/en-us/netframework/aa663326.aspx \n Windows Workﬂ ow Foundation:  http://msdn.microsoft.com/en-us/netframework/aa663328.aspx \n Oracle \n Database:  http://www.oracle.com/database/index.html \n Tuxedo:  http://www.oracle.com/products/middleware/tuxedo/tuxedo.html \n WebLogic Server:  http://www.oracle.com/appserver/weblogic/enterprise-edition.html \n\n\nBibliographic Notes  363\n Red Hat \n JBoss:  http://www.jboss.com/ \n Object Management Group (OMG) \n General:  http://www.omg.org/ \n Object Transaction Service:  http://www.omg.org/technology/documents/formal/transaction_service.htm \n The Open Group \n General:  http://www.opengroup.org/ \n DTP Model:  http://www.opengroup.org/pubs/catalog/c193.htm \n XA:  http://www.opengroup.org/onlinepubs/009680699/toc.pdf \n Organization for the Advancement of Structured Information Standards (OASIS) \n General:  http://www.oasis-open.org/home/index.php \n WS-Transactions:  http://www.oasis-open.org/committees/tc_home.php?wg_abbrev \u0003 ws-tx \n OSGi Alliance \n General:  http://www.osgi.org/ \n Service Composition Architecture (SCA) \n General:  http://www.oasis-opencsa.org/sca \n The Web Services Interoperability Organization (WS-I) \n General:  http://www.ws-i.org/ \n World Wide Web Consortium (W3C) \n General:  http://www.w3.org/ \n Web Services Activity:  http://www.w3.org/2002/ws/ \n\n\nThis page intentionally left blank\n\n\n Alonso ,  G. ,  Casati ,  F. ,  Kuno ,  H. ,  Machiraju ,  V. ,  2004 .  Web Services .  Springer-Verlag ,  Berlin .  \n Andrade ,  J.M. ,  Carges ,  M.T. ,  Dwyer ,  T.J. ,  Felts ,  S.D. ,  1996 .  The TUXEDO System, Software for Constructing and Managing \nDistributed Business Applications .  Addison Wesley ,  Reading, MA .  \n Attar ,  R. ,  Bernstein ,  P.A. ,  Goodman ,  N. ,  1984 .  Site initialization, recovery, and backup in a distributed database system .  IEEE \nTrans. Software Eng.  10 ( 6 ) ,  645 – 650 .  \n Bayer ,  R. ,  McCreight ,  E.M. ,  1972 .  Organization and maintenance of large ordered indices .  Acta Inform.  1 ,  173 – 189 .  \n Bayer ,  R. ,  Schkolnick ,  M. ,  1977 .  Concurrency of operations on B-trees .  Acta Inform.  9 ( 1 ) ,  1 – 21 .  \n Bayer ,  R. ,  Unterauer ,  K. ,  1977 .  Preﬁ x B-Trees .  ACM Trans. Database Syst.  2 ( 1 ) ,  11 – 26 .  \n Berenson, H., Bernstein, P.A., Gray, J.N., Melton, J., O’Neil, E., O’Neil, P., 1995. Levels of isolation. In: Proceedings of the 1995 \nACM SIGMOD Conference on Management of Data, pp. 1 – 10. \n Bernstein ,  P.A. ,  1990 .  Transaction processing monitors .  Commun. ACM  33 ( 11 ) ,  75 – 86 .  \n Bernstein ,  P.A. ,  Emberton ,  W. ,  Trehan ,  V. ,  1991 .  DECdta: digital’s distributed transaction processing architecture .  Digital Tech. J. \n 3 ( 1 ) ,  10 – 17 .  \n Bernstein ,  P.A. ,  Hadzilacos ,  V. ,  Goodman ,  N. ,  1987 .  Concurrency Control and Recovery in Database Systems .  Addison-Wesley , \n Reading, MA.  Freely downloadable at:  http://research.microsoft.com/~philbe .  \n Bernstein, P.A., Hsu, M., Mann, B., 1990. Implementing recoverable requests using queues. In: Proceedings of the 1990 ACM \nSIGMOD Conference on Management of Data, pp. 112 – 122. \n Bernstein ,  P.A. ,  Shipman ,  D.W. ,  Wong ,  W.S. ,  1979 .  Formal aspects of serializability in database concurrency control .  IEEE Trans. \nSoftware Eng.  SE-5 ( 3 ) ,  203 – 215 .  \n Birrell ,  A.D. ,  Nelson ,  B.J. ,  1984 .  Implementing remote procedure calls .  ACM Trans. Comput. Syst.  2 ( 1 ) ,  39 – 59 .  \n Brewer, E.A., 2000. Towards robust distributed systems (abstract). In: Proceedings of the Nineteenth Annual ACM Symposium on \nPrinciples of Distributed Computing, p. 7. \n Burke ,  B. ,  Monson-Haefel ,  R. ,  2006 .  Enterprise Java Beans ,  ﬁ fth ed.  O’Reilly Media ,  Sebastopol, CA .  \n Chan, A., Fox, S., Lin, W.T.K., Nori, A., Ries, D.R., 1982. The implementation of an integrated concurrency control and recovery \nscheme. In: Proceedings of the 1982 ACM SIGMOD Conference on Management of Data, pp. 184 – 191. \n Chandra, T.D., Griesemer, R., Redstone, J., 2007. Paxos made live: an engineering perspective. In: Proceedings of the 1988 ACM \nConference on Principles of Distributed Computing, pp. 398 – 407. \n Claybrook ,  B.J. ,  1992 .  OLTP — Online Transaction Processing Systems .  J. Wiley  & Sons ,  New York .  \n Comer ,  D. ,  1979 .  The ubiquitous B-Tree .  ACM Comput. Surv.  11 ( 2 ) ,  121 – 137 .  \n DeCandia, G., Hastorun, D., Jampani, M., Kakulapati, G., Lakshman, A., Pilchin, A., Sivasubramanian, S., Vosshall, P., Vogels, \nW., 2007. Dynamo: amazon’s highly available key-value store. In: Proceedings of the 21st ACM Symposium on Operating \nSystems Principles, pp. 205 – 220. \n El Abbadi, A., Skeen, D., Cristian, F., 1985. An efﬁ cient, fault-tolerant protocol for replicated data management. In: Proceedings \nof the 1985 Symposium on Principles of Database Systems, pp. 215 – 229. \n El Abbadi ,  A. ,  Toueg ,  S. ,  1989 .  Maintaining availability in partitioned replicated databases .  ACM Trans. Database Syst.  14 ( 2 ) , \n 264 – 290 .  \n Bibliography \n\n\n366  Bibliography\n Eswaran ,  K.P. ,  Gray ,  J.N. ,  Lorie ,  R.A. ,  Traiger ,  I.L. ,  1976 .  The notions of consistency and predicate locks in a database system . \n Commun. ACM  19 ( 11 ) ,  624 – 633 .  \n Fielding ,  R.T. ,  2000 .  Architectural Styles and the Design of Network-based Software Architectures .  University of California , \n Irvine,  http://www.ics.uci.edu/~ﬁ elding/pubs/dissertation/top.htm .  \n Fischer, M.J., Michael, A., 1982. Sacriﬁ cing serializability to attain high availability of data in an unreliable network. In: Proceedings \nof the 1982 Symposium on Principles of Database Systems, pp. 70 – 75. \n Gawlick ,  D. ,  Kinkade ,  D. ,  1985 .  Varieties of concurrency control in IMS/VS fastpath .  IEEE Database Eng.  8 ( 2 ) ,  3 – 10 .  \n Gifford, D.K., 1979. Weighted voting for replicated data. In: 7th ACM SIGOPS Symposium on Operating System Principles, \npp. 150 – 159. \n Gilbert ,  S. ,  Lynch ,  N. ,  2002 .  Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services .  ACM \nSIGACT News  33 ( 2 ) ,  51 – 59 .  \n Gray ,  J.N. ,  1978 .  Notes on database operating systems .  In:  Operating Systems: An Advanced Course, Springer-Verlag Lecture \nNotes in Computer Science ,  vol. 60 .  Springer-Verlag ,  New York .   \n Gray, J.N., 1981. The transaction concept: virtues and limitations (Invited Paper). In: Proceedings of the 7th International \nConference on Very Large Data Bases. IEEE Press, pp. 144 – 154. \n Gray, J.N., 1986. Why do computers stop and what can we do about it. In: 5th Symposium on Reliability in Distributed Soft-\nware and Database Systems. IEEE Computer Society Press, pp. 3 – 12. Early version available at:  http://research.microsoft.\ncom/~gray/papers/TandemTR85.7_WhyDoComputersStop.pdf . \n Gray ,  J.N. (Ed.),  1993 .  The Benchmark Handbook for Database and Transaction Processing Systems ,  second ed.  Morgan Kaufmann \nPublishers ,  San Francisco . Online at:  http://research.microsoft.com/users/gray/BenchmarkHandbook/TOC.htm. \n Gray ,  J.N. ,  Edwards ,  J. ,  1994 .  Scale up with TP monitors .  Byte Mag.  April .  \n Gray ,  J.N. ,  Lorie ,  R.A. ,  Putzolu ,  G.R. ,  Traiger ,  I.L. ,  1976 .  Granularity of locks and degrees of consistency in a shared database . \n In:  Modeling in Data Base Management Systems .  Elsevier ,  Amsterdam .  \n Gray, J.N., Lorie, R.A., Traiger, I.L., 1975. Granularity of locks in a shared data base. In: Proceedings of 1975 International Con-\nference on Very Large Data Bases, pp. 428 – 451. \n Gray ,  J.N. ,  Reuter ,  A. ,  1992 .  Transaction Processing: Concepts and Techniques .  Morgan Kaufmann ,  San Francisco .  \n Gray, J.N., Van Ingen, C., 2005. Empirical measurements of disk failure rates and error rates. In: Microsoft Research Technical \nReport MSR-TR-2005-166.  http://research.microsoft.com/research/pubs . \n H ä rder ,  T. ,  Reuter ,  A. ,  1983 .  Principles of transaction-oriented database recovery .  ACM Comput. Surv.  15 ( 4 ) ,  287 – 317 .  \n Howard ,  M. ,  LeBlanc ,  D. ,  2003 .  Writing Secure Code .  Microsoft Press ,  Redmond, WA .  \n Jajodia ,  S. ,  Kerschberg ,  L. (Eds.) ,  1997 .  Advanced Transaction Models and Architecture .  Springer-Verlag ,  Berlin . \n Josten ,  J.W. ,  Mohan ,  C. ,  Narang ,  I. ,  Teng ,  J.Z. ,  1997 .  DB2’s use of the coupling facility for data sharing .  IBM Sys. J.  36 ( 2 ) , \n 327 – 351 .  \n Kaufman ,  C. ,  Perlman ,  R. ,  Speciner ,  M. ,  2002 .  Network Security – PRIVATE Communication in a PUBLIC World .  Prentice Hall \nPTR ,  Upper Saddle River, NJ .  \n Kawell Jr. L., Beckhardt, S., Halvorsen, T., Ozzie, R., Greif, I., 1988. Replicated document management in a group communica-\ntion system. In: Proceedings of the 1988 ACM Conference on Computer-Supported Cooperative Work. Online at the ACM \nDigital Library. \n Kedem, Z.M., Silberschatz, A., 1980. Non-two-phase locking protocols with shared and exclusive locks. In: Proceedings of 1980 \nInternational Conference on Very Large Data Bases, pp. 309 – 317. \n Krafzig ,  D. ,  Banke ,  K. ,  Slama ,  D. ,  2004 .  Enterprise SOA: Service-Oriented Architecture Best Practices (Coad Series) .  Prentice \nHall PTR ,  Upper Saddle River, NJ .  \n\n\nBibliography  367\n Kumar ,  V. ,  Hsu ,  M. ,  1998 .  Recovery Mechanisms in Database Systems .  Prentice Hall PTR ,  Upper Saddle River, NJ .  \n Kung ,  H.T. ,  Robinson ,  J.T. ,  1982 .  On optimistic methods for concurrency control .  ACM Trans. Database Syst.  6 ( 2 ) ,  213 – 226 .  \n Ladin ,  R. ,  Liskov ,  B. ,  Shrira ,  L. ,  Ghemawat ,  S. ,  November 1992 .  Providing high availability using lazy replication .  ACM Trans. \nComput. Syst.  10 ( 4 ) ,  360 .  \n Laing ,  W.A. ,  Johnson ,  J.E. ,  Landau ,  R.V. ,  1991 .  Transaction management support in the VMS operating system kernel .  Digital \nTech. J.  3 ( 1 ) ,  33 – 44 .  \n Lamport ,  L. ,  1978 .  Time, clocks, and the ordering of events in a distributed system .  Commun. ACM  21 ( 7 ) ,  558 – 565 .  \n Lamport ,  L. ,  1998 .  The part-time parliament .  ACM Trans. Comput. Syst.  16 ( 2 ) ,  133 – 169 .  \n Lampson ,  B.W. ,  1981 .  Atomic transactions .  In:  Goos ,  G. ,  Hartmanis ,  J. (Eds.) ,  Distributed Systems — Architecture and Imple-\nmentation: An Advanced Course. LNCS 105 .  Springer Verlag ,  Berlin , pp.  246 – 265 .  \n Lampson, B.W., Sturgis, H., 1976. Crash recovery in a distributed data storage system. In: Technical Report, Computer Science \nLaboratory, Xerox Palo Alto Research Center, Palo Alto, CA. \n LeBert ,  J.J. ,  1989 .  CICS for microcomputers .  McGraw Hill ,  New York .  \n Lehman ,  P.L. ,  Yao ,  S.B. ,  1981 .  Efﬁ cient locking for concurrent operations on B-trees .  ACM Trans. Database Syst.  6 ( 4 ) ,  550 – 670 . \n Levine, C., Gray, J.N., Kiss, S., Kohler, W., 1993. The Evolution of TPC Benchmarks: Why TPC-A and TPC-B are Obsolete. \nTandem Technical Report 93.1, Tandem Computers. Online at:  http://www.hpl.hp.com/techreports/tandem/TR-93.1.pdf . \n Lewis ,  P.M. ,  Bernstein ,  A. ,  Kifer ,  M. ,  2002 .  Databases and Transaction Processing, An Application-Oriented Approach .  Addison-Wesley , \n Boston .  \n Leymann ,  F. ,  Roller ,  D. ,  2000 .  Production Workﬂ ow, Concepts and Techniques .  Prentice Hall PTR ,  Upper Saddle River, NJ .  \n Lindsay ,  B.G. ,  Haas ,  L.M. ,  Mohan ,  C. ,  Wilms ,  P.F. ,  Yost ,  R.A. ,  1984 .  Computation and communication in R*: a distributed data-\nbase manager .  ACM Trans. Comput. Syst.  2 ( 1 ) ,  24 – 38 .  \n Liskov ,  B. ,  1988 .  Distributed programming in Argus .  Commun. ACM  31 ( 3 ) ,  300 – 312 .  \n Little ,  M. ,  Maron ,  J. ,  Pavlik ,  G. ,  2004 .  Java Transaction Processing .  Prentice Hall PTR ,  Upper Saddle River, NJ .  \n Lomet, D.B., 1992. MLR: A recovery method for multi-level systems. In: Proceedings of the 1992 ACM SIGMOD Conference on \nManagement of Data, pp. 185 – 194. \n Lomet, D.B., 1993. Key range locking strategies for improved concurrency. In: Proceedings of the 1993 International Conference \non Very Large Data Bases, pp. 655 – 664. \n Lomet, D.B., Anderson, R., Rengarajan, T.K., Spiro, P., 1992. How the Rdb/VMS data sharing system became fast. In: Technical \nReport CRL 92/4, Digital Equipment Corp., Cambridge Research Lab.  http://www.hpl.hp.com/techreports/Compaq-DEC/\nCRL-92-4.pdf . \n Lomet, D.B., Tuttle, M.R., 2003. A theory of redo recovery. In: Proceedings of the 2003 ACM SIGMOD Conference on Manage-\nment of Data, pp. 397 – 406. \n Lomet, D.B., Weikum, G., 1998. Efﬁ cient and transparent application recovery in client-server information systems. In: Proceed-\nings of the 1995 ACM SIGMOD Conference on Management of Data, pp. 460 – 471. \n Lorie ,  R.A. ,  1977 .  Physical integrity in a large segmented database .  ACM Trans. Database Syst.  2 ( 1 ) ,  91 – 104 .  \n Loy ,  M. ,  Eckstein ,  R. ,  Wood ,  D. ,  Elliot ,  J. ,  Cole ,  B. ,  2003 .  Java Swing ,  second ed.  O’Reilly Media  Examples:  http://examples.\noreilly.com/jswing2/code/ .  \n Lynch ,  N. ,  Merritt ,  M. ,  Weihl ,  W.E. ,  Fekete ,  A. ,  1993 .  Atomic Transactions in Concurrent and Distributed Systems .  Morgan \nKaufmann Publishers ,  San Francisco .  \n Malkhi ,  D. ,  Novik ,  L. ,  Purcell ,  C. ,  2007 .  P2P replica synchronization with vector sets .  Operating Syst. Rev.  41 ( 2 ) ,  68 – 74 .  \n\n\n368  Bibliography\n Microsoft Corporation ,   2000 .  COM  \u0005  Developer’s Reference Library .  Microsoft Press ,  Redmond, WA .  \n Mohan, C., 1999. Repeating history beyond ARIES. In: Proceedings of the 1999 International Conference on Very Large Data \nBases, pp. 1 – 17. \n Mohan ,  C. ,  Haderle ,  D. ,  Lindsay ,  B. ,  Pirahesh ,  H. ,  Schwarz ,  P. ,  1992 .  ARIES: a transaction recovery method supporting ﬁ ne-\ngranularity locking and partial rollback using write-ahead logging .  ACM Trans. Database Syst.  17 ( 1 ) ,  94 – 162 .  \n Mohan ,  C. ,  Lindsay ,  B.G. ,  Obermarck ,  R. ,  1986 .  Transaction management in the R* distributed database management system . \n ACM Trans. Database Syst.  11 ( 4 ) ,  378 – 396 .  \n Mohan, C., Narang, I., 1991. Recovery and coherency-control protocols for fast intersystem page transfer and ﬁ ne-granularity \nlocking in a shared disks transaction environment. In: Proceedings of the 1991 International Conference on Very Large Data-\nbases, pp. 193 – 207. \n Moss ,  E. ,  1985 .  Nested Transactions: An Approach to Reliable Distributed Computing .  MIT Press ,  Boston .  \n Newcomer ,  E. ,  Lomow ,  G. ,  2004 .  Understanding SOA with Web Services .  Addison-Wesley ,  Upper Saddle River, NJ .  \n Novik, L., Hudis, I., Terry, D.B., Anand, S., Jhaveri, V., Shah, A., Wu, Y., 2006. Peer-to-peer replication in WinFS. In: Microsoft \nResearch Technical Report MSR-TR-2006-78. \n Oki, B.M., Liskov, B., 1988. View stamped replication: a general primary copy. In: Proceedings of the 1988 ACM Symposium on \nPrinciples of Distributed Computing, pp. 8 – 17. \n Parker   Jr. ,  D.S. ,  Popek ,  G.J. ,  Rudisin ,  G. ,  Stoughton ,  A. ,  Walker ,  B.J. ,  Walton ,  E. ,  Chow ,  J.M. ,  Edwards ,  D. ,  Kiser ,  S. ,  Kline ,  C. , \n 1983 .  Detection of mutual inconsistency in distributed systems .  IEEE Trans. Software Eng.  9 ( 3 ) ,  240 – 247 .  \n Patterson, D.A., Gibson, G., Katz, R.H., 1988. A case for redundant arrays of inexpensive disks (RAID). In: Proceedings of the \n1988 ACM SIGMOD Conference on Management of Data, pp. 109 – 116. \n Pausch, R., 1988. Adding input and output to the transaction model. Ph.D. Thesis, Computer Science Dept., Carnegie Mellon \nUniversity, August (CMU-CS-88-171). \n Pinheiro, E., Weber, W.-D., Barroso, L.A., 2007. Failure trends in large disk drive populations. In: Proceedings of the 5th USENIX \nConference on File and Storage Technologies (FAST  ’ 07), pp. 17 – 28. \n Rahm ,  E. ,  1993 .  Empirical performance evaluation of concurrency and coherency control protocols for database sharing systems . \n ACM Trans. Database Syst.  18 ( 2 ) ,  333 – 377 .  \n Raz, Y., 1992. The principle of commitment ordering, or guaranteeing serializability in a heterogeneous environment of multiple \nautonomous resource managers using atomic commitment. In: Proceedings of the 1992 International Conference on Very \nLarge Data Bases, pp. 292 – 312. \n Reed, D.P., 1978. Naming and synchronization in a decentralized computer system. Ph.D. Dssertation, Department of Electrical \nEngineering and Computer Science, MIT., Cambridge, MA. Technical Report TR-205, Laboratory for Computer Science, \nCambridge, MA. \n Rescorla ,  E. ,  2001 .  SSL and TLS — Designing and Building Secure Systems .  Addison-Wesley ,  Upper Saddle River, NJ .  \n Richardson ,  L. ,  Ruby ,  S. ,  2007 .  RESTful Web Services .  O’Reilly Media ,  Sebastopol, CA .  \n Shasha ,  D. ,  Bonnet ,  P. ,  2002 .  Database Tuning: Principles, Experiments, and Troubleshooting Techniques .  Morgan Kaufmann \nPublishers ,  San Francisco .  \n Silberschatz ,  A. ,  Galvin ,  P.B. ,  Gagne ,  G. ,  2008 .  Operating System Concepts ,  seventh ed.  Wiley ,  Hoboken, NJ .  \n Stonebraker ,  M. ,  1979 .  Concurrency control and consistency of multiple copies of data in distributed INGRES .  IEEE Trans. Soft-\nware Eng.  3 ( 3 ) ,  188 – 194 .  \n Tay ,  Y.C. ,  1987 .  Locking Performance in Centralized Databases .  Academic Press ,  Orlando, FL .  \n Terry, D.B., 2008. Replicated data management for mobile computing. In: Synthesis Lectures on Mobile and Pervasive Computing \n#5, Morgan  & Claypool Publishers. \n\n\nBibliography  369\n The Open Group, 1992. Distributed TP: The XA Speciﬁ cation.  http://www.opengroup.org/bookstore/catalog/c193.htm . \n Thomas ,  R. ,  1979 .  A majority consensus approach to concurrency control for multiple copy databases .  ACM Trans. Database \nSyst.  4 ( 2 ) ,  180 – 209 .  \n Thomasian ,  A. ,  1996 .  Database Concurrency Control: Methods, Performance, and Analysis .  Kluwer Academic Publishers ,  \nBoston .  \n Thomasian ,  A. ,  1998 .  Concurrency control: methods, performance, and analysis .  ACM Comput. Surv.  30 ( 1 ) ,  70 – 119 .  \n UNIX International, 1992. Open Enterprise Transaction Processing: Integrating the TUXEDO System with Mainframe CICS. \n Vinoski ,  S. ,  2008 a .  RPC and REST — dilemma, disruption, and displacement .  IEEE Internet Comput.  September/October ,  92 – 95 , \n Toward Integration Column .  \n Vinoski ,  S. ,  2008 b .  RESTful web services development checklist .  IEEE Internet Comput.  November/December ,  94 – 96,  Toward \nIntegration Column .  \n Weerawarana ,  S. ,  Curbera ,  F. ,  Leymann ,  F. ,  Storey ,  T. ,  Ferguson ,  D. ,  2005 .  Web Services Platform Architecture: SOAP, WSDL, \nWS-Policy, WS-Addressing, WS-BPEL, WS-Reliable Messaging, and More .  Prentice-Hall ,  Upper Saddle River, NJ .  \n Weikum ,  G. ,  Vossen ,  G. ,  2002 .  Transactional Information Systems — Theory, Algorithms, and the Practice of Concurrency Control \nand Recovery .  Morgan Kaufmann Publishers ,  San Francisco .  \n Willis ,  J.M. ,  1994 .  TP Software Development for OpenVMS .  CBM Books ,  Horsham, PA .  \n Wolter ,  R. ,  2006 .  The Rational Guide to SQL Server 2005 Service Broker .  Rational Press ,  Rollinsford, NH .  \n\n\nThis page intentionally left blank\n",
      "page_number": 378
    },
    {
      "number": 38,
      "title": "Segment 38 (pages 389-396)",
      "start_page": 389,
      "end_page": 396,
      "detection_method": "topic_boundary",
      "content": " Page numbers followed by  “ f ” indicate ﬁ gures \n Index \n A \n Abort cascading  196 \n Abort operation  208 – 209 ,  234 – 235 \n Abort record  230 \n Abstract process  137 \n Abstractions  see  Persistence abstraction \nmechanisms; Transaction \nprocessing abstractions \n Accept message  259 \n ACID properties  10 \n Activities  136 \n Acyclic directed graphs  184 \n Address space  41 – 42 \n ADO.NET/ADO.NET entity framework \n 322 – 323 \n Advanced Message Queueing Protocol \n(AMQP)  115 ,  346 \n After-image log  200 \n AJAX (Asynchronous JavaScript and \nXML)  283 \n All-or-nothing behavior  10 ,  12f \n Ambient transaction  294 \n Apache  361 \n Application Control and Management System \n(ACMS) (HP)  333 – 336 \n Application programming interface (API) \n ADO.NET/ADO.NET entity framework \n 322 – 323 \n deﬁ nition of  31 \n front-end programs and the  79 \n Java Persistence API (JPA)  319 – 321 \n ODBC and JDBC  316 – 318 \n transactional middleware and  93 \n Tuxedo (Oracle)  331 – 333 \n Applications \n stateful and stateless  60 – 61 \n transaction processing  3 \n Archiving  219 – 221 \n ARIES restart algorithm  216 \n ASP.Net  285 ,  288 – 289 \n Assertions  341 \n Atomicity \n in business process management  127 – 128 \n deﬁ nition  10 \n ensuring with two-phase commit  15 \n introduction to  10 – 13 \n real-time systems  26 \n subtransactions  38 \n TP monitors \n legacy, integrating \n in .NET Framework  297 \n in Java  308 – 309 \n on-line TP (OLTP)  6 \n Attributes  35 – 36 \n Authentication  86 – 88 \n Automated teller machine (ATM) \nexample  10 – 11 ,  12f \n Automatic reconﬁ guration \npartitioning  67 \n Availability \n 2PC  272 \n deﬁ nition of  185 \n introduction to  22 – 24 \n B \n Backups, hot/warm/cold  246 \n Batch processing systems  24 – 25 \n Batching to relieve hot spots  162 \n Bean implementation class  302 \n Bean managed  304 \n Before-image log  200 \n Benchmarks \n TPC-A/B  18 – 19 \n TPC-C  19 – 21 \n TPC-E  21 – 22 \n for vendors, deﬁ ning  17 \n Bindings  291 – 292 \n BizTalk Server adapters  286 \n Blind updates  263 – 264 \n B-link optimization  176 – 178 \n Blocking, 2PC systems  227 – 228 \n Boxcarring  208 \n Bracketing  32 – 34 ,  35 – 37 ,  69 – 70 ,  89 \n Branch transaction  240 \n Broken requests  40 \n Broker-based architecture  113 – 114 \n B-tree indexing \n B \u0005 trees  172 – 174 \n B-links  176 \n locking  175 – 176 \n sidewise pointers  177f \n tree insertion  174 – 175 \n Bus-based architecture  114 – 115 \n Business activity monitoring  126 \n Business interface  302 \n Business objects  77 – 78 \n Business process \n deﬁ nition of  39 ,  121 \n examples of  121 – 122 \n partially automated  122 ,  123 – 124 \n Business process deﬁ nition  123 – 124 \n Business process execution  124 – 126 \n Business process management \n bibliographic notes  360 \n conﬁ guration management \nsystems  135 \n interactions involving people  \n122 ,  123 – 124 ,  124 \n introduction to  121 – 123 \n products and standards  135 – 138 \n scientiﬁ c workﬂ ow model  134 – 135 \n special purpose runtime  129 – 130 \n state management  62 ,  124 – 126 \n summary  139 \n techniques for maintaining durability \n 129 – 134 \n transactional properties  126 – 129 \n using queued requests  130 – 131 \n Business Processing Modeling Notation \n(BPMN)  136 \n Business rules  78 \n Business transaction  121 \n Byzantine failures  225 – 226 \n C \n Cache afﬁ nity  69 \n Cache invalidation  64 \n Cache manager  198 – 199 \n Caching  64 ,  274 – 276 \n Callbacks  52 \n Call-backs  274 \n CAP conjecture  261 \n\n\n372  Index\n Chain of responsibility architecture  291 \n Chained transactions  35 ,  39 \n Channels  291 \n Checkpoint record  198 – 199 \n Checkpointing \n basic  210 \n fuzzy  211 \n Choreography  121 \n CICS (IBM)  35 ,  325 – 328 \n Client-server binding  48 – 52 \n Client-server communications \n direct TP  99 \n queued TP  104 – 106 \n Client-server systems  27 \n Cloud computing  349 – 351 \n Code behind ﬁ le  288 \n Cold backup  246 \n Cold ﬁ elds  156 \n Command Process  334 \n Commit  10 ,  11f \n Commit list  166 \n Commit operation  207 – 208 \n Commit ordering  145 \n Commit record  229 – 230 ,  230 \n Communication \n ACMS (HP)  335 – 336 \n CICS  327 \n client-server \n in direct aTP  99 \n in queued TP  104 – 106 \n IMS TM  330 \n Pathway TS/MP  339 \n publish-subscribe  112 – 113 \n transaction handshakes  144 – 145 \n Tuxedo (Oracle)  333 \n see also  RPC (remote procedure call) \nsystems, queued transaction \nprocessing \n Communication binding  50 – 51 ,  99 – 100 \n Communication manager  240 \n Communication session  58 – 60 \n Compensating transaction  12 ,  128 \n Compensation log record  214 \n Composability problem  33 ,  38 \n Conﬁ guration management systems  135 \n Conﬁ guration management, Transaction \nProcessing systems  28 \n Conﬂ ict in operations  141 \n Consensus, majority and quorum  257 – 258 \n Consensus algorithm  258 \n Conservative locking  157 \n Consistency \n 2PC  261 ,  272 \n deﬁ nition of  13 \n Container  93 \n Container managed  304 \n Context handle  52 \n Contract  289 \n Control thread  41 – 42 \n Conversation  137 \n Conversation group  138 \n Cookie  63 \n Cooperative termination protocol  237 – 238 \n Coordinator  225 \n Correctness and the two-phase rule \n 142 – 143 \n Correlation set  137 \n Cost of ownership  18 \n Crabbing  175 \n Cursor  164 \n Cursor stability  164 – 165 \n Cycles in directed graphs  184 \n Cyclic restart  152 \n D \n Data manager  145 ,  224 \n Data provider  322 \n Data sharing systems \n caching  274 – 276 \n deﬁ nition of  274 – 278 \n locking  274 \n Data warehouse systems  26 ,  163 – 164 \n Database access \n ACMS (HP)  336 \n CICS  327 – 328 \n IMS  330 \n Pathway TS/MP  339 \n persistence abstraction mechanisms \n 315 – 323 \n Tuxedo (Oracle)  333 \n Database cache  198 \n Database log  199 – 200 \n Database mirroring  252 – 253 \n Database recovery \n implementing abort  201 – 202 \n implementing commit  202 – 203 \n introduction  194 – 195 \n log-based  207 – 211 \n Database recovery manager  201 – 203 \n Database servers vs. transactional \nmiddleware  96 – 97 \n Database system  5 \n Database(s) \n TPC-A/B  18 \n TPC-C  19 \n TPC-E  21 \n Deadlock \n deﬁ nition of  150 – 154 \n detection  151 – 152 \n prevention  150 – 151 \n victim selection  152 – 153 \n Decision, heuristic  228 \n Declarative demarcation  309 \n Degree 1 isolation  165 \n Degree 2 isolation  164 \n Degree 3 isolation  165 \n Degrees of isolation  164 – 166 \n Delivery transactions  20 \n Dependent log page address  208 – 209 \n Direct transaction processing \n limitations  99 \n queued TP vs.  99 \n Dirty page table  216 \n Dirty read isolation  165 \n Disaster  219 \n Dispatching  51 ,  112 \n Distributed deadlock detection  153 – 154 \n Document-oriented application  125 \n Domain  332 \n Dominant version vector  266 \n Done record  230 \n Downtime  see  availability \n Durability \n business process management  129 \n deﬁ nition of  14 – 15 \n real-time systems  26 \n subtransactions  38 \n Durability, techniques for maintaining \n logging  133 – 134 \n pseudo-conversations  131 – 132 \n queued requests  130 – 131 \n special-purpose runtime system  129 – 130 \n E \n Eager log writers  229 \n Eclipse  361 \n Efﬁ ciency  1 \n Electronic Data Interchange (EDI)  125 \n Encryption  86 – 88 \n End user  5 \n Endpoint deﬁ nition  292 \n Enlisting in a transaction  239 – 241 \n Enterprise application integration (EAI) \n 113 \n Enterprise Java Bean (EJB)  36 ,  301 \n Enterprise Java Bean (EJB) reference  302 \n Enterprise service buses (ESBs)  113 \n Entity data model (EDM)  322 \n Epoch  259 \n Epoch number  259 \n Epoch set  259 \n Eswaran, K.P., et al.  143 \n Event processing  353 – 354 \n Exception handling  38 – 39 \n Exclusive (X) locks  141 \n\n\nIndex  373\n Explicit programming model \n .NET  295 – 296 \n Java EE  307 – 308 \n F \n Failure \n Byzantine  225 \n replication systems  255 – 256 \n total  256 \n see also  Software failures ;  System \nrecovery \n Failure, reducing \n environment  186 \n hardware  187 \n software  187 – 188 \n system management  186 – 187 \n Failure handling in 2PC \n coordinator’s view  228 – 229 \n participant’s view  229 \n termination protocol  231 \n timeout period  228 \n Fault tolerance, RPC systems  54 – 55 \n Filtering  110 \n Flash memory  353 \n Flattening, tree-of-process  242 \n Flow  137 \n Flush log record  215 \n Forms and menus  79 – 82 \n Front-end program layers  78 – 79 \n Front-end programs \n application architecture  78 – 88 \n CICS  326 – 327 \n deﬁ nition of  5 ,  74 \n developing in Java EE  299 – 300 \n developing in .NET Framework  285 – 297 \n IMS TM  330 \n Pathway TS/MP  338 – 339 \n Tuxedo (Oracle)  333 \n use of term client vs.  100 \n web browsers  283 – 284 \n web servers  83 – 84 \n Full disclosure report  17 – 18 \n Function shipping  328 \n Fuzzy checkpointing  211 – 212 \n G \n Geographical entitlement  87 – 88 \n Granularity  148 – 149 \n Graph-based detection  151 \n Graphs \n acyclic directed  184 \n lock instance  178 \n lock type  178 \n serialization  145 ,  183 – 184 \n waits-for  151 \n Gray, Jim  359 \n Group commit  208 \n H \n Handlers  291 \n Handshakes  144 – 145 \n Hardware architecture  9 \n Hardware failure  187 \n Hash partitioning  67 \n Heuristic decision  228 \n Home page  288 \n Host Integration Server (HIS)  286 \n Hot backup  246 \n Hot ﬁ elds  156 \n Hot spots, locking  159 – 163 \n HP \n Application Control and Management \nSystem (HP)  333 – 336 \n bibliographic notes  362 \n Pathway TS/MP  336 – 339 \n Hypertext Transfer Protocol (HTTP)  8 \n I \n IBM \n bibliographic notes  362 \n CICS  35 ,  325 – 328 \n IMS  328 – 330 \n Websphere MQ  115 – 117 \n Identiﬁ ers  16 ,  34 – 35 \n Incomparable version vectors  266 \n Independent recovery  227 – 228 \n Information Management System (IMS) \n(IBM)  328 – 330 \n Integration \n example  47 \n legacy TP monitors \n in .NET Framework  297 \n in Java  308 – 309 \n message-oriented middleware  113 – 115 \n Intention locks  149 ,  178 \n Intention read  178 \n Intention-to-write/intention-to-read lock \ntypes  178 \n Interceptors  291 \n Interface deﬁ nitions  49 \n Internet, computing services over the \n 349 – 351 \n Internet Information Server (IIS)  286 \n Internet websites, response times  18 \n Interoperability \n 2PC systems  243 \n deﬁ nition of  8 ,  94 \n RPC systems  55 – 56 \n Interposition  344 \n Invalidation, cache  64 \n Invitation message  259 \n Isolation \n ANSI SQL terminology  166f \n business process management  127 \n deﬁ nition of  13 – 14 \n Degree 1  165 \n Degree 2  164 \n Degree 3  165 \n read committed  164 \n read uncommitted  165 \n serializable  165 \n snapshot  167 \n speciﬁ cation of scopes and  137 \n subtransactions  38 \n two-phase  164 \n see also  Locking \n Isolation levels  164 – 166 \n J \n Java Database Connectivity (JDBC) \n 316 – 318 \n Java Enterprise Edition (Java EE)  36 , \n 282 – 283 ,  297 – 311 ,  362 \n Java Persistence API (JPA)  319 – 321 \n Java Server Faces (JSF)  299 \n Java Server Pages (JSP)  299 \n Java Transaction API (JTA)  307 ,  344 – 345 \n Joining a transaction  239 \n Journaling  110 \n JPA entity  304 \n L \n Latch  200 \n Lazy log writers  229 \n Leaf pages  172 \n Least-recently-used algorithm  64 \n Legacy TP monitors \n ACMS  333 – 336 \n background  324 – 339 \n CICS transaction server  325 – 328 \n Information Management System (IMS) \n(IBM)  328 – 330 \n integration \n in .NET Framework  297 \n in Java  308 – 309 \n Pathway TS/MP  336 – 339 \n Tuxedo  330 – 333 \n Load balancing  99 – 100 ,  101 \n Lock \n conﬂ ict  141 \n contention, tuning to reduce  156 \n conversions  154 – 155 \n coupling  175 \n deﬁ nition of  141 \n escalation  149 \n\n\n374  Index\nLock (Continued)\n intention  149 ,  178 \n intention-to-write/intention-to-read  178 \n read locks  141 \n read-with-intention-to-write  179 – 180 \n setting and releasing  147 – 148 \n Lock instance graph  178 \n Lock managers  146 – 147 \n Lock table  146 \n Lock thrashing  155 – 158 \n Lock type compatability  179f \n Lock type graph  178 \n Locking \n automated  145 \n batch update  162 \n bibliographic notes  360 \n B-tree  172 – 178 \n conservative  157 \n correctness and the two-phase rule \n 142 – 143 \n in data sharing systems  274 \n deadlocks  150 – 154 \n hot spots  159 – 163 \n implementation  145 – 150 \n introduction to  141 – 145 \n optimistic  160 – 162 \n optimistic concurrency control  171 – 172 \n performance  145 – 146 ,  154 – 159 , \n 158 – 159 ,  170 – 171 \n phantom avoidance  169 – 171 \n query-update problems  163 – 168 \n reducing contention  156 – 158 \n summary  182 – 183 \n transaction handshakes  144 – 145 \n transactions interactions  143 \n tree/B-tree  172 – 178 \n Locking granularity  148 – 149 ,  178 – 181 , \n 179f ,  180f \n Locking nested transactions  181 – 182 \n Log sequence number (LSN)  213 ,  277 \n Log writers, eager or lazy  229 \n Log-based recovery algorithms \n deﬁ nition of  207 – 211 \n implementing abort  207 – 208 \n implementing commit  208 – 209 \n implementing restart  210 – 211 \n Logging  83 ,  133 – 134 ,  277 – 278 \n M \n Machine  9 \n Majority consensus  257 – 258 \n Manufacturing, product data management \nsystem  135 \n Marshaling  49 \n Mean time between failures (MTBF)  185 \n Mean time to repair (MTTR)  185 \n Media failure  195 \n Media recovery \n archiving  219 – 221 \n deﬁ nition of  217 – 221 \n mirrored disks  217 – 219 \n RAID  218 \n Media recovery log  220 \n Mediator  313 \n Memory technology  353 \n Message context  116 \n Message ordering  109 – 110 \n Message-oriented applications  125 \n Message-oriented middleware \n broker-based architecture  113 – 114 \n bus-based architecture  114 – 115 \n Messages, invitation, accept and reject  259 \n Messages, poisoned  109 \n Messaging, queued TP  109 \n Methods  77 – 78 \n Microsoft \n .Net Enterprise Services  36 \n .NET Framework  282 – 283 ,  285 – 297 \n bibliographic notes  362 \n Com  \u0005   36 \n Open Database Connectivity (ODBC) \n 316 – 318 \n SQL Server Service Broker  137 – 138 \n Sync Framework  272 – 273 \n Transaction Server  36 \n Windows Communication Foundation \n(WCF)  286 \n Windows Presentation Foundation (WPF) \n 285 ,  287 – 288 \n Windows Workﬂ ow Foundation (WF)  286 \n Microsoft Windows Communication \nFoundation  36 \n Middleware threads  43 – 46 \n Mirrored database  252 – 253 \n Mirrored disks  217 \n Mission critical services  22 \n Multigranularity locking  149 – 150 , \n 178 – 181 ,  179f ,  180f \n Multistep business processes  12 – 13 \n Multitenant systems  350 – 351 \n Multithreading  51 ,  44 – 45 ,  90 \n Multitier architecture  74 ,  75 – 76 ,  283, 285 – 297 \n Multiversion data  166 – 168 \n N \n Nested transactions \n locking  181 – 182 \n programming model  37 – 38 \n savepoints for supporting  40 – 41 \n New-order transactions  20 \n Node  9 \n Nonblind updates  263 – 265 \n Nonrepeatable reads  164 \n Nontransactional replication  273 \n Nonvolatile storage  14 \n O \n OASIS Service Component Architecture \n(SCA)  345 ,  363 \n Object Management Group (OMG)  \n36 ,  363 \n Object Transaction Service (OTS)  \n343 – 344 \n Object-oriented (OO) paradigm  7 \n Object-oriented design  77 – 78 \n Object-oriented RPC  51 – 52 \n Off-line  3 \n On-line TP (OLTP) monitors  6 \n On-line transaction  2 \n Open Database Connectivity (ODBC) \n(Microsoft)  316 – 318 \n Operating system threads  44 – 45 \n Operation logging  212 – 216 \n Operations, real-world  10 – 11 ,  12f \n Optimistic concurrency control  162 , \n 171 – 172 \n Optimistic locking  160 – 162 \n Oracle \n bibliographic notes  362 \n Tuxedo  330 – 333 \n Oracle Streams AQ  117 – 118 \n Orchestration  121 \n Order-status transactions  20 \n Organization for the Advancement of \nStructured Information Standards \n(OASIS)  340 ,  363 \n OSGi Alliance  345 – 346 ,  363 \n P \n Page granularity operations  197 \n Pages  287 \n Parameter-based routing  66 \n Participants, 2PC  225 \n Partitioning \n 2PC systems  261 – 273 \n automatic reconﬁ guration  67 \n basics of  65 – 67 \n hash  67 \n queued TP  111 \n range  66 \n to relieve hot spots  163 \n table-lookup  67 \n Partitioning sessions  67 – 68 ,  90 \n Partition-tolerance  261 ,  272 \n Partner link/partner link type  136 \n\n\nIndex  375\n Path length  149 – 150 \n Pathway TS/MP (HP)  336 – 339 \n Payment transactions  20 \n Performance \n 2PC systems  226 – 227 \n batch processing systems  24 – 25 \n locking  145 – 146 ,  154 – 159 ,  158 – 159 , \n 170 – 171 \n queued TP  103 – 104 \n RPC systems  56 \n transaction processing  17 – 22 \n Persistence abstraction mechanisms \n 315 – 323 \n Persistent storage  14 \n Phantoms in locking  169 – 171 \n Phase zero  234 \n Pick (in BPEL)  137 \n Platforms  94 \n Portability  94 \n Prepared record  230 \n Prepared to commit  16 \n Presentation independence  78 – 79 \n Presumed abort  234 – 235 \n Priority-based scheduling  100 ,  109 – 110 \n Procedure Server  334 \n Processor context  41 – 42 \n Product data management system  135 \n Programmatic demarcation  309 \n Promotable Single Phase Enlistment \n(PSPE)  295 \n Provenance  134 \n Provisioning  350 – 351 \n Pseudo-conversations  131 – 132 \n Publish-subscribe communication  112 – 113 \n Pure restart policy  157 \n Q \n Queue manager  108 – 112 ,  115 \n Queued requests, business process \nmanagement  130 – 131 \n Queued transaction processing \n bibliographic notes  360 \n client recovery  104 – 106 \n client’s viewpoint  103 – 104 \n message-oriented middleware  113 – 115 \n non-undoable operations, handling \n 107 – 108 \n products and standards  115 – 118 \n publish-subscribe  112 – 113 \n queue manager  108 – 112 \n reasons for using  99 – 102 \n server’s viewpoint  102 \n summary  118 – 119 \n Queued transaction processing model \n broker-based  113 – 114 \n Queued transaction processing model \n bus-based  114 – 115 \n database servers vs. middleware  94 – 96 \n Queued transaction processing model \n deﬁ nition of  102 \n Quorum consensus  257 – 258 ,  273 \n R \n RAID (redundant arrays of inexpensive \ndisks)  218 \n Range partitioning  66 \n Read committed isolation  164 \n Read locks  141 \n Read stability  171 \n Read uncommitted isolation  165 \n Read-one-write-all available replication \n 273 \n Read-only transactions  235 – 237 \n Reads \n nonrepeatable  164 \n repeatable  165 ,  171 \n Read-with-intention-to-write locks \n 179 – 180 \n Real-time systems  25 – 26 \n Records of transactions  2 \n Recoverable execution  196 \n Recovery \n 2PC  255 – 256 \n database  194 – 195 ,  207 – 211 \n independent  227 – 228 \n media  217 – 221 \n queued transaction processing  104 – 106 \n strategies  195 \n see also  System recovery \n Recovery log  220 \n Recovery manager  201 – 203 \n Red Hat  363 \n Redundant arrays of inexpensive disks \n(RAID)  218 \n Region  325 \n Registry service  50 – 51 \n Reinfection  232 \n Reject message  259 \n Reliability  185 \n Remote procedure call (RPC)  46 – 57 , \n 70 – 71 \n Repeatable reads  165 ,  171 \n Replacement algorithm  64 \n Replica conﬁ guration  258 \n Replica consensus \n deﬁ nition of  258 \n epoch number and set  259 \n establishing state for  260 – 261 \n messages, invitation, accept and \nreject  259 \n Replica set  258 \n Replicas \n deﬁ nition of  245 \n update streams for  253f \n weighting  258 \n Replicated data \n one-copy serialization  258 – 260 \n replicating requests  251 \n replicating updates  249 – 251 \n synchronizing updates to  248 – 252 \n Replicated servers \n 2PC systems  245 – 248 \n cold backup  246 \n hot backup  246 \n primary backup  245 \n resource management  247 \n warm backup  246 \n Replication \n bibliographic notes  361 \n data sharing systems  274 – 278 \n to distribute workload  68 – 69 \n failure and recovery  255 – 256 \n introduction to  245 \n multimaster \n conﬂ icting resolution  266 \n conﬂ icting updates  262f ,  266 \n deﬁ nition of  261 – 273 \n detecting conﬂ icts  263 – 265 \n Thomas ’ Write Rule  247 \n tombstone  248 \n update propagation  262 \n version vectors  265 – 266 \n nontransactional  273 \n single-master primary-copy  252 – 261 \n summary  278 – 279 \n synchronizing updates to data  248 – 252 \n synchronous vs. asynchronous  \n249 – 251 \n total failure  256 \n Replication conﬂ icts, detecting  265 – 266 \n Representational State Transfer (REST)  8 \n Request controller \n deﬁ nition of  5 ,  75 ,  88 – 89 \n developing in Java EE  301 – 304 \n developing in .NET  289 – 294 \n Enterprise Java Bean (EJB)  301 – 304 \n purpose of  88 – 90 \n Request identiﬁ er  82 – 83 \n Request integrity  89 – 90 \n Request message  3 ,  82 – 83 \n Resource manager  145 ,  224 \n Resource pooling  65 \n Resource replication  247 \n Resources  126 \n REST (representational state transfer)  300 \n\n\n376  Index\n REST (representational state transfer) \narchitectural pattern  8, 85, 300 \n REST/HTTP  8 ,  21 – 22 ,  85 ,  294 \n REST/HTTP-based SOA  314 – 315 \n Reuter, Andreas  359 \n Routing \n parameter-based  66 ,  111 \n queued TP  111 \n RPC (remote procedure call) systems \n comparing  56 – 57 \n fault tolerance  54 – 55 \n interoperability  55 – 56 \n object-oriented  51 – 52 \n performance  56 \n programmer’s view  51 \n security  54 \n summary  70 – 71 \n system management  55 \n transactional  48 \n walkthrough  52 \n S \n SABRE system  3 \n Saga  128 \n Savepoints  39 – 40 ,  40 – 41 \n Scalability  2 ,  17 ,  85 \n Scalability techniques  63 – 69 ,  71 \n Scalable distributed computing  351 – 352 \n Scale-out  65 – 69 ,  111 \n Scheduling priority  100 \n Scientiﬁ c workﬂ ow business model \n 134 – 135 \n Secure sockets layer (SSL)  86 \n Security \n authentication and encryption  86 – 88 \n RPC systems  54 \n user/process authorization  91 \n Serializability \n deﬁ nition of  13 \n one-copy  248 – 252 \n real-time systems  26 \n two-phase locking and  143 ,  183 \n see also  Locking \n Serializability Theorem  183 – 184 \n Serializable isolation  165 \n Serialization graphs  145 ,  183 – 184 \n Server classes  45 – 46 \n Server interface  332 \n Server machine  9 \n Server process  9 \n Server recovery  190 – 191 \n Servers \n database vs. transactional middleware \n 96 – 97 \n replicating with a shared resource  247 – 248 \n scaling up  64 \n stateless  60 – 61 ,  84 – 86 \n Service Component Architecture (SCA) \n 345 ,  363 \n Service level agreement (SLA)  185 \n Service Oriented Architecture (SOA)  7 , \n 76 – 77 ,  311 – 315 \n Service provider  349 \n Servlet  299 \n Session structure, communication  90 \n Shadow paging  204 \n Shadowed disks  217 \n Shared (S) locks  141 \n Shared state systems  57 – 63 ,  71 \n Silverlight  285 ,  288 – 289 \n Simple requests  78 \n Snapshot isolation  167 \n Snapshot mode  166 – 167 \n Software failures \n categories of  23 \n direct TP  99 \n queued TP  104 – 106 \n Special-purpose runtime systems  129 – 130 \n Spraying  68 \n Spring Framework  297 \n SQL database architecture  148f \n SQL Server Service Broker  137 \n Stable storage  14 \n State management  62 \n Stateful applications  61 \n Stateless servers  60 – 61 ,  84 – 86 \n Stock-level transactions  20 \n Storage, stable  14 \n Stored procedure  76, 318 – 319 \n Streams and event processing  353 – 354 \n Stripe  218 \n Subtransactions  37 \n Swing  299 \n Switch  137 \n Syncpoint  35 \n System engineering  24 \n System failure  185 ,  286 \n System management, RPC systems  55 \n System model  196 – 200 \n System recovery \n bibliographic notes  360 \n checkpoint based  191 – 192 \n client recovery  189 – 190 \n detecting process failures for  188 – 189 \n failure causes  185 – 188 \n model  188 – 194 \n server recovery  190 – 191 \n shadow-paging algorithm  203 – 207 \n stateless servers  193 – 194 \n transaction based  192 – 193 \n user techniques for  216 – 217 \n see also  Recovery \n System resources, queued TP  104 ,  111 \n Systems \n deﬁ nition of  9 \n scalability of  2 ,  17 \n styles of  24 \n TP  5 \n T \n Table-lookup partitioning  67 \n Task  334 \n Task group  336 \n Task Server  334 \n Termination protocol  231 ,  237 – 238 \n Testable state  107 \n Thick/thin client architecture  80 \n Thomas ’ Write Rule  247 \n Threads  41 – 46 ,  70 \n Thread-safe applications  51 \n Three-tier architecture  74 \n Timeout period  228 \n Timeout-based detection  151 \n Timeouts, queued TP  109 \n Timesharing systems  26 – 27 ,  42 \n Timestamp ordering  145 \n Tombstone  263 \n Top-level transaction  36 ,  37 \n Total failure  256 \n TPC-A/B benchmarks  18 – 19 \n TPC-C benchmark  19 – 21 \n TPC-E benchmark  21 – 22 \n Transaction abstraction  31 – 41 \n Transaction Handshake Theorem  144 \n Transaction processing \n abstractions \n bibliographic notes  359 \n processes and threads  41 – 46 ,  70 \n remote procedure calls  46 – 57 , \n 70 – 71 \n scalability  63 – 69 ,  71 \n shared state  57 – 63 ,  71 \n summary  69 – 71 \n transaction bracketing  32 – 34 ,  \n69 – 70 \n transactions  31 – 41 \n application architecture \n bibliographic notes  359 \n front-end programs  78 – 88 \n functional components  74 \n introduction to  73 – 74 \n middleware  92 – 94 \n multitier  75 – 76 ,  285 – 297 \n object-oriented design  77 – 78 \n request controllers  88 – 90 \n\n\nIndex  377\n service-oriented (SOA)  7 ,  76 – 77 , \n 311 – 315 \n summary  96 – 97 \n transaction servers  91 – 92 \n applications  3 – 4 ,  4f ,  99 – 102 \n basics of  1 – 4 \n critical properties of  9 – 15 \n deﬁ nition of  1 – 2 ,  2 \n further resources  359 \n future trends \n cloud computing  349 – 351 \n introduction to  349 \n memory technology  353 \n multitenant systems  350 – 351 \n scalable distributed computing \n 351 – 352 \n streams and event processing  353 – 354 \n summary  354 \n history  359 \n requirements of  1 – 2 \n standards \n Advanced Message Queueing \nProtocol (AMQP)  346 \n bibliographic notes  361 \n introduction to  339 – 346 \n Java Transaction API (JTA)  344 – 345 \n Object Transaction Service (OTS) \n 343 – 344 \n OSGi Alliance  345 – 346 \n Service Component Architecture \n(SCA)  345 \n WS-Transactions  340 – 342 \n XA interface  342 – 343 \n summary  29 \n systems \n availability  22 – 24 \n database servers vs. middleware \n 94 – 96 \n distributed  2 \n hardware architecture  9 \n performance  17 – 22 \n personalizing  2 \n scaling up  2 \n styles of  24 – 28 \n system architecture  5 – 9 \n two-phase commit  15 – 17 \n Transaction Processing (Gray and Reuter) \n 359 \n Transaction Processing Performance \nCouncil (TPC)  17 – 18 \n Transaction program  3 ,  4 ,  6 \n Transaction rate metric (tpmC)  20 \n Transactional middleware \n basics of  92 – 94 \n database servers vs.  94 – 96 \n deﬁ nition of  6 \n message-oriented  113 – 115 \n persistence abstraction mechanisms and \n 315 – 323 \n products \n ASP.Net  288 – 289 \n bibliographic notes  361 \n future trends  351 – 352 \n Java Enterprise Edition  36 ,  282 – 283 , \n 297 – 311 \n legacy TP monitors  324 – 339 \n Microsoft’s .NET Framework \n 282 – 283 ,  285 – 297 \n Silverlight  288 – 289 \n Spring Framework  309 – 311 \n summary  346 – 348 \n web browser front-end programs \n 83 – 84 ,  283 – 284 \n programming models  282 \n trends in  281 – 282 \n see also  application programming \ninterface (API) \n Transactional RPC  48 \n Transaction(s) \n acknowledgement of  2 \n ambient  294 \n application parts  5f \n attributes \n .NET  290 – 291 \n deﬁ nition of  35 – 36 \n Java EE  303 ,  305 – 307 \n bracketing  32 – 34 ,  35 – 37 ,  69 – 70 ,  89 \n business  1 – 2 \n composability problem  33 \n critical properties of  9 \n deﬁ nition of  2 – 3 \n descriptor  208 \n failure  195 \n handshakes  144 – 145 \n identiﬁ er  16 ,  34 – 35 \n load  155 \n management \n in .NET Framework  294 – 295 \n in Java EE  293 – 294 \n Java EE and .NET discussion  293 \n manager  15 ,  238 – 242 \n on-line  2 \n path length  142 \n per second (tps)/per minute (tpm)  18 \n routing  326 \n servers \n basics of  91 – 92 \n deﬁ nition of  5 ,  75 \n developing  289 – 294 \n Enterprise Java Bean (EJB)  301 – 304 \n types of TPC-C  20 \n types of TPC-E  21t \n uncontrolled concurrent  1 \n Transport Layer Security (TLS)  86 \n Tree locking  172 – 178 \n Tree-of-processes model  241 – 242 \n Tuxedo (Oracle)  330 – 333 \n Two-phase commit (2PC) \n basics of  15 – 17 \n bibliographic notes  360 \n failure handling  228 – 232 \n introduction to  223 – 224 \n optimizations and variations  \n232 – 238 \n process structuring  238 – 242 \n summary  243 – 244 \n user checklist  243 \n Two-phase commit (2PC) protocol \n 224 – 228 \n Two-Phase Locking Theorem  143 , \n 143 – 144 ,  184 \n Two-phase rule in locking  145 ,  164 , \n 142 – 143 \n U \n Ullman, J. D.  143 ,  183 \n Uncertainty  227 \n Unchained transactions  35 ,  39 \n Undo log record  214 \n Unsolicited abort  38 \n Update lock  142 \n Update-bit  220 \n URL rewriting  63 \n User authentication  86 – 88 \n V \n Version ID  265 \n Version ID invariant  267 \n Version ID update rules  272 \n Version vector update rules  267 – 269 \n Version vectors  265 – 266 \n Victim selection, deadlock  152 – 153 \n W \n Waits-for graph  151 \n Warm backup  246 \n Web browsers \n cookies  63 \n front-end programs  283 – 284 \n in multitier TP architecture  283f \n Web servers \n front-end programs  83 – 84 \n state management  84 – 86 \n use of term client vs.  100 \n Web Services  6 ,  8 \n\n\n378  Index\n Web Services Business Process Execution \nLanguage (WS-BPEL) standard \n 136 – 137 ,  286 \n The Web Services Interoperability \nOrganization (WS-I)  363 \n Web Services-based SOA  312 – 314 \n Websphere MQ (IBM)  115 – 117 \n Weighting replicas  258 \n Workﬂ ow  39 ,  121 \n World Wide Web Consortium \n(W3C)  363 \n Write locks  141 \n Write-through/write-back cache  65 \n WS-Transactions  340 – 342 \n X \n X locks  141 \n XA interface  342 – 343 \n X/Open transaction model (XA)  16f ,  237f , \n 343f  \n",
      "page_number": 389
    },
    {
      "number": 39,
      "title": "Segment 39 (pages 397-397)",
      "start_page": 397,
      "end_page": 397,
      "detection_method": "topic_boundary",
      "content": "",
      "page_number": 397
    }
  ],
  "pages": [
    {
      "page_number": 2,
      "content": " Principles of \nTransaction Processing \n \n",
      "content_length": 42,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 3,
      "content": " The Morgan Kaufmann Series in Data Management Systems (Selected Titles) \n Information Modeling and Relational Databases, \n2nd Edition \n Terry Halpin, Tony Morgan \n Joe Celko’s Thinking in Sets \n Joe Celko \n Business Metadata \n Bill Inmon, Bonnie O’Neil, Lowell Fryman \n Unleashing Web 2.0 \n Gottfried Vossen, Stephan Hagemann \n Enterprise Knowledge Management \n David Loshin \n Business Process Change, 2nd Edition \n Paul Harmon \n IT Manager’s Handbook, 2nd Edition \n Bill Holtsnider  & Brian Jaffe \n Joe Celko’s Puzzles and Answers, 2nd Edition \n Joe Celko \n Making Shoes for the Cobbler’s Children \n Charles Betz \n Joe Celko’s Analytics and OLAP in SQL \n Joe Celko \n Data Preparation for Data Mining Using SAS \n Mamdouh Refaat \n Querying XML: XQuery, XPath, and SQL/XML \nin Context \n Jim Melton and Stephen Buxton \n Data Mining: Concepts and Techniques, 2nd \nEdition \n Jiawei Han and Micheline Kamber \n Database Modeling and Design: Logical Design, \n4th Edition \n Toby J, Teorey, Sam S. Lightstone, Thomas P. \nNadeau \n Foundations of Multidimensional and Metric \nData Structures \n Hanan Samet \n Joe Celko’s SQL for Smarties: Advanced SQL \nProgramming, 3rd Edition \n Joe Celko \n Moving Objects Databases \n Ralf Hartmut G ü ting and Markus Schneider \n Joe Celko’s SQL Programming Style \n Joe Celko \n Data Mining, Second Edition: Concepts and \nTechniques \n Ian Witten and Eibe Frank \n Fuzzy Modeling and Genetic Algorithms for Data \nMining and Exploration \n Earl Cox \n Data Modeling Essentials, 3rd Edition \n Graeme C. Simsion and Graham C. Witt \n Location -Based Services \n Jochen Schiller and Agn è s Voisard \n Database Modeling with Microsoft ® Visio for \nEnterprise Architects \n Terry Halpin, Ken Evans, Patrick Hallock, Bill \nMaclean \n Designing Data-Intensive Web Applications \n Stephano Ceri, Piero Fraternali, Aldo Bongio, \nMarco Brambilla, Sara Comai, Maristella Matera \n Mining the Web: Discovering Knowledge from \nHypertext Data \n Soumen Chakrabarti \n Advanced SQL: 1999 — Understanding Object-\nRelational and Other Advanced Features \n Jim Melton \n Database Tuning: Principles, Experiments, and \nTroubleshooting Techniques \n Dennis Shasha, Philippe Bonnet \n SQL :1999 — Understanding Relational Language \nComponents \n Jim Melton, Alan R. Simon \n Information Visualization in Data Mining and \nKnowledge Discovery \n Edited by Usama Fayyad, Georges G. Grinstein, \nAndreas Wierse \n Transactional Information Systems \n Gerhard Weikum and Gottfried Vossen \n Spatial Databases \n Philippe Rigaux, Michel Scholl, and Agnes \nVoisard \n Managing Reference Data in Enterprise \nDatabase \n Malcolm Chisholm \n Understanding SQL and Java Together \n Jim Melton and Andrew Eisenberg \n Database : Principles, Programming, and \nPerformance, 2nd Edition \n Patrick and Elizabeth O’Neil \n The Object Data Standard \n Edited by R. G. G. Cattell, Douglas Barry \n Data on the Web: From Relations to \nSemistructured Data and XML \n Serge Abiteboul, Peter Buneman, Dan Suciu \n Data Mining: Practical Machine Learning Tools \nand Techniques with Java Implementations \n Ian Witten, Eibe Frank \n Joe Celko’s Data and Databases: Concepts in \nPractice \n Joe Celko \n Developing Time-Oriented Database Applications \nin SQL \n Richard T. Snodgrass \n Web Farming for the Data Warehouse \n Richard D. Hackathorn \n Management of Heterogeneous and Autonomous \nDatabase Systems \n Edited by Ahmed Elmagarmid, Marek \nRusinkiewicz, Amit Sheth \n Object -Relational DBMSs, 2nd Edition \n Michael Stonebraker and Paul Brown, with \nDorothy Moore \n Universal Database Management: A Guide to \nObject/Relational Technology \n Cynthia Maro Saracco \n Readings in Database Systems, 3rd Edition \n Edited by Michael Stonebraker, Joseph M. \nHellerstein \n Understanding SQL’s Stored Procedures: \nA Complete Guide to SQL/PSM \n Jim Melton \n Principles of Multimedia Database Systems \n V . S. Subrahmanian \n Principles of Database Query Processing for \nAdvanced Applications \n Clement T. Yu, Weiyi Meng \n Advanced Database Systems \n Carlo Zaniolo, Stefano Ceri, Christos Faloutsos, \nRichard T. Snodgrass, V. S. Subrahmanian, \nRoberto Zicari \n Principles of Transaction Processing, 2nd Edition \n Philip A. Bernstein, Eric Newcomer \n Using the New DB2: IBMs Object-Relational \nDatabase System \n Don Chamberlin \n Distributed Algorithms \n Nancy A. Lynch \n Active Database Systems: Triggers and Rules for \nAdvanced Database Processing \n Edited by Jennifer Widom, Stefano Ceri \n Migrating Legacy Systems: Gateways, Interfaces, \n & the Incremental Approach \n Michael L. Brodie, Michael Stonebraker \n Atomic Transactions \n Nancy Lynch, Michael Merritt, William Weihl, \nAlan Fekete \n Query Processing for Advanced Database \nSystems \n Edited by Johann Christoph Freytag, David \nMaier, Gottfried Vossen \n Transaction Processing \n Jim Gray, Andreas Reuter \n Database Transaction Models for Advanced \nApplications \n Edited by Ahmed K. Elmagarmid \n A Guide to Developing Client/Server SQL \nApplications \n Setrag Khoshaﬁ an, Arvola Chan, Anna Wong, \nHarry K. T. Wong \n",
      "content_length": 4994,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 4,
      "content": " Principles of \nTransaction Processing \n Second Edition \n Philip A. Bernstein \n Eric Newcomer \n \n \nAMSTERDAM • BOSTON • HEIDELBERG • LONDON  \nNEW YORK • OXFORD • PARIS • SAN DIEGO  \nSAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO\nMorgan Kaufmann Publishers is an imprint of Elsevier\n",
      "content_length": 278,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 5,
      "content": "  Morgan Kaufmann Publishers is an imprint of Elsevier \n 30 Corporate Drive, Suite 400, Burlington, MA 01803, USA \n Copyright © 2009 by Elsevier Inc. All rights reserved. \n Designations used by companies to distinguish their products are often claimed as trademarks or \nregistered trademarks. In all instances in which Morgan Kaufmann Publishers is aware of a claim, \nthe product names appear in initial capital or all capital letters. All trademarks that appear or are \notherwise referred to in this work belong to their respective owners. Neither Morgan Kaufmann \nPublishers nor the authors and other contributors of this work have any relationship or afﬁ liation \nwith such trademark owners nor do such trademark owners conﬁ rm, endorse or approve the contents \nof this work. Readers, however, should contact the appropriate companies for more information \nregarding trademarks and any related registrations. \n No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any \nform or by any means — electronic, mechanical, photocopying, scanning, or otherwise — without \nprior written permission of the publisher. \n Permissions may be sought directly from Elsevier’s Science  & Technology Rights Department \nin Oxford, UK: phone: ( \u0002 44) 1865 843830, fax: ( \u0002 44) 1865 853333, E-mail:  mail to:\npermissions@elsevier.com . You may also complete your request online via the Elsevier \nhomepage ( http://www.elsevier.com ), by selecting  “ Support  & Contact ” then  “ Copyright and \nPermission ” and then  “ Obtaining Permissions. ” \n Library of Congress Cataloging-in-Publication Data \n Bernstein, Philip A.\nPrinciples of transaction processing/Philip A. Bernstein, Eric Newcomer.—2nd ed.\n p. cm. — (The Morgan Kaufmann series in data management systems)\nIncludes bibliographical references and index.\nISBN 978-1-55860-623-4 (pbk.)\n1. Transaction systems (Computer systems) I. Newcomer, Eric. II. Title.\nQA76.545.B47 2009\n005.74 \u0003 5–dc22\n2009003605 \n For information on all Morgan Kaufmann publications, \n visit our Web site at  www.mkp.com or  www.elsevierdirect.com \n Printed in the United States of America \n 09 10 11 12 13  5 4 3 2 1 \n \n",
      "content_length": 2177,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 6,
      "content": "  For Jim Gray, wherever he may be \n",
      "content_length": 36,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 7,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 8,
      "content": " Preface  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\n Trademarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xvii\n CHAPTER 1  Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n  1.1 The Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1\n  1.2 TP System Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5\n  1.3 Atomicity, Consistency, Isolation, and Durability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\n  1.4 Two-Phase Commit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .15\n  1.5 Transaction Processing Performance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .17\n  1.6 Availability  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .22\n  1.7 Styles of Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24\n  1.8 TP System Conﬁ gurations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .28\n  1.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .29\n CHAPTER 2  Transaction Processing Abstractions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n  2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\n  2.2 Transactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\n  2.3 Processes and Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .41\n  2.4 Remote Procedure Call . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .46\n  2.5 Shared State . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .57\n  2.6 Scalability  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n  2.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n CHAPTER 3 Transaction Processing Application Architecture  . . . . . . . . . . . . . . . . . . . . 73\n  3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .73\n  3.2 Application Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\n  3.3 Front-End Program . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78\n  3.4 Request Controller  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .88\n  3.5 Transaction Servers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .91\n  3.6 Transactional Middleware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .92\n  3.7 Database Servers Versus Transactional Middleware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .94\n  3.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .96\n CHAPTER 4 Queued Transaction Processing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n   4.1 Why Use Queues? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\n   4.2 The Queued Transaction Processing Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .102\n  4.3 Client Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .104\n  4.4 Handling Non-Undoable  Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .107\n  4.5 The Queue Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .108\n  4.6 Publish-Subscribe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .112\n  4.7 Other Message-Oriented Middleware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .113\n Contents  \n",
      "content_length": 5140,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 9,
      "content": "viii  Contents\n  4.8 Queuing Products and Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .115\n  4.9 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\n CHAPTER 5 Business Process Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n  5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .121\n  5.2 Business Process Deﬁ nition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123\n  5.3 Business Process Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .124\n  5.4 Transactional Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\n  5.5 Making Process State Durable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .129\n  5.6 Other Models of Business Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\n  5.7 Products and Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\n  5.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\n CHAPTER 6 Locking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n  6.1 Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .141\n  6.2 Implementation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .145\n  6.3 Deadlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .150\n  6.4 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .154\n  6.5 Hot Spots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n  6.6 Query-Update Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .163\n  6.7 Avoiding Phantoms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .169\n  6.8 Optimistic Concurrency Control  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .171\n  6.9 B-Tree Locking  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172\n  6.10 Multigranularity Locking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .178\n  6.11 Locking Nested Transactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .181\n  6.12 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\n  6.13 Appendix: Basic Serializability Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .183\n CHAPTER 7 System Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n  7.1 Causes of System Failure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .185\n  7.2 A Model for System Recovery  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .188\n  7.3 Introduction to Database Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .194\n  7.4 The System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .196\n  7.5 Database Recovery Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\n  7.6 Shadow-Paging Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .203\n  7.7 Log-Based Database Recovery Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .207\n  7.8 Optimizing Restart in Log-Based Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .211\n  7.9 Media Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .217\n  7.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\n CHAPTER 8 Two-Phase Commit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\n  8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .223\n  8.2 The Two-Phase Commit Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .224\n  8.3 Failure Handling  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .228\n  8.4 Optimizations and Variations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .232\n",
      "content_length": 5619,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 10,
      "content": "Contents  ix\n  8.5 Process Structuring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .238\n  8.6 User Checklist . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\n  8.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\n CHAPTER 9 Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n  9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245\n  9.2 Replicated Servers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245\n  9.3 Synchronizing Updates to Replicated Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\n  9.4 Single-Master Primary-Copy Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .252\n  9.5 Multimaster Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\n  9.6 Other Replication Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .273\n  9.7 Data Sharing Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .274\n  9.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .278\n CHAPTER 10 Transactional Middleware Products and Standards . . . . . . . . . . . . . . . . . 281\n  10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .281\n  10.2 Web Browser Front-End Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .283\n  10.3 .NET Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .285\n  10.4 Java Enterprise Edition  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .297\n  10.5 Service-Oriented Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .311\n  10.6 Persistence Abstraction Mechanisms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .315\n  10.7 Legacy TP Monitors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .324\n  10.8 TP Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .339\n  10.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .346\n CHAPTER 11 Future Trends . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\n  11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .349\n  11.2 Cloud Computing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .349\n  11.3 Scalable Distributed Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .351\n  11.4 Memory Technology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .353\n  11.5 Streams and Event Processing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .353\n  11.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\n Glossary of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355\n Bibliographic Notes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359\n Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\n Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371 \n",
      "content_length": 4475,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 11,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 12,
      "content": " WHY READ THIS BOOK? \n Transaction processing has been an important software technology for 40 years. Large enterprises in transpor-\ntation, ﬁ nance, retail, telecommunications, manufacturing, government, and the military are utterly dependent \non transaction processing applications for electronic reservations, banking, stock exchanges, order processing, \nmusic and video services, shipment tracking, government services, telephone switching, inventory control, and \ncommand and control. Many large hardware and software vendors receive much of their revenue from compo-\nnents of transaction processing systems, such as IBM, HP, Oracle, Microsoft, Dell, Red Hat, and EMC. The \nmarket for transaction processing products and services is many tens of billions of dollars per year. As con-\nsumers, we all use this technology every day to withdraw cash, buy gas, rent movies, and make purchases on \nthe Internet. \n How exactly do these transaction processing systems work? This question was once of interest only to com-\nputer professionals in the commercial data processing ﬁ eld. Now, given the widespread use of transaction pro-\ncessing in today’s economy, it is of interest to a much broader engineering audience. Despite this interest, there is \nlittle written for a system professional to get a readable, technically solid introduction to this complex technology. \nThis book ﬁ lls the gap. \n The software environment of most large-scale transaction processing systems is based on transactional mid-\ndleware, which helps knit together many software components. These components include front-end applications \nto drive web browsers and other devices, middle-tier applications to route requests to the server that can run \nthem, and server applications that execute business logic. Examples of transactional middleware include IBM’s \nCICS; Microsoft’s .NET Enterprise Services; and Java Enterprise Edition products, such as IBM WebSphere \nApplication Server, Oracle’s WebLogic Server, and Red Hat’s JBoss Application Server. The ﬁ rst half of this \nbook focuses on transactional middleware technology. \n For many software engineers, transactional middleware is obscure technology — strange software glue that \nseems to be needed beyond operating systems, database systems, communication systems, and application pro-\ngramming languages. This book demystiﬁ es transactional middleware by explaining how it contributes to the \nperformance, security, scalability, availability, manageability, and ease-of-use of transaction processing systems. \nThe ﬁ rst half of the book explains transactional middleware outside and in — the features it offers to application \nprogrammers and how it is constructed to offer these features. \n The transaction abstraction itself is largely implemented by database systems. They ensure that each trans-\naction executes in its entirety, is isolated from interference by other transactions, and generates results that will \nsurvive hardware and software failures. This behavior is implemented by locking, logging, communication \nprotocols, and replication. These technologies are the subject of the second half of this book. \n This book is an introduction to transaction processing, intended to meet the needs of a broad audience, \nincluding: \n ■  Application programmers with an interest in building transaction processing applications \n ■  Database administrators who manage database systems used for transaction processing \n ■  Application analysts who design applications for deployment on transaction processing systems \n ■  Product developers in related areas, such as database systems, operating systems, and communications \n Preface \n",
      "content_length": 3671,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 13,
      "content": "xii  Preface\n ■  Marketing and technical support engineers for both systems and application products \n ■  Computer science undergraduates and graduate students looking for an introduction to this topic \n Our focus is on the principles of transaction processing, not on a prescription for how to build a transaction \nprocessing application — “ how come? ” not  “ how to. ” We include examples from many products, to illustrate \nhow the principles have been applied and where ideas originated. But we do not dwell heavily on any one \nproduct. We present technology that is practical and used in products and pay only modest attention to good \nideas that are not commonly used in practice. \n We do not assume any special prerequisites, other than  “ system sophistication. ” We expect most readers \nwill have some familiarity with SQL and database systems, but this background isn’t necessary. \n After ﬁ nishing the book, you will understand how transactional middleware works and when to use it, and \nhow transactional middleware and database systems work together to support reliable distributed transaction \nprocessing applications. You will be able to learn quickly how to use any transactional middleware product or \ndatabase system to support the development and management of transaction processing applications. \n WHAT’S NEW IN THIS SECOND EDITION? \n The short answer is  “ a lot. ” There are several new chapters and rewritten chapters, and many new and revised \nsections of the rest. \n Two main goals drove these changes. Our ﬁ rst goal was to present the new and revised transaction archi-\ntectures and technologies that have appeared since we published the ﬁ rst edition twelve years ago. Back then, \nInternet-based electronic commerce was just beginning. Now, it is established as a major segment of many \nbusiness-to-consumer and business-to-business markets. The growth of this segment, along with the com-\nmoditization of server hardware and operating systems, has led to major changes in transaction processing \nproducts. Web browsers are now a dominant technology for interacting with transaction processing systems. \nTransactional middleware has evolved from on-line transaction processing monitors to many new product cat-\negories that are designed to work well over the Internet, such as application servers, object request brokers, \nmessage-oriented middleware, and workﬂ ow systems. Object-oriented programming and service-oriented \narchitecture have become mainstream. And database systems have become more complete transaction process-\ning environments. These changes are all reﬂ ected in this second edition. \n Our second main goal was to add coverage and depth of classical transaction processing topics, to make the \nbook more complete. In part, this is based on the ﬁ rst author’s experience in using the book as a textbook for a \ngraduate computer science course for professional masters ’ students at the University of Washington. It is also \nin response to technological improvements, where formerly exotic technologies are now widely used. \n Concretely , the major changes are as follows: The three chapters on transactional middleware have been \nentirely rewritten — two on principles and a long one on example products and standards, including details of \nJava Enterprise Edition and Microsoft .NET. There is a new chapter on business process management. The \nchapter on locking has new sections on optimistic concurrency control, B-tree locking, multigranularity locking,\nand nested transactions. There are new sections on the TPC-E benchmark, state management, scalability, \nshadow-paging, data sharing systems, consensus algorithms, log-based replication, and multimaster replica-\ntion. Concepts of service-oriented architecture (SOA), REST, and Web Services are sprinkled throughout the \nbook. There are numerous smaller additions of technical detail in many sections. Signiﬁ cant changes can be \nfound in every chapter. \n Supplementary material will be available on the publisher’s web page for this book. Initially, it will include \na selection of problems, grouped by chapter. We will add other technical material over time. \n",
      "content_length": 4165,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 14,
      "content": "Preface  xiii\n SUMMARY OF TOPICS \n The enterprise that pays for a transaction processing system wants it to give fast service, be inexpensive to \nbuy and operate, and be scalable as usage grows and new applications are added. Application programmers \nwant to be insulated from the complexity of the many different kinds of technologies required to run a transac-\ntion processing system, such as transaction protocols, message protocols, transactional remote procedure calls, \npersistent queues, multithreaded processes, resource pooling, session management, and replication protocols. \nAn application programmer’s job is to understand what the business wants the transaction to do and to write a \nprogram that does it. The system software should make it possible to run that program on a system that is fast, \nefﬁ cient, scalable, and reliable. This is what transactional middleware does, which is the main subject of the \nﬁ rst half of this book, Chapters 1 through 5. Today’s products and standards for transactional middleware are \ndescribed in Chapter 10. \n Users of a transaction processing system want to think of it as a sequential processor of transactions, one \nthat’s inﬁ nitely reliable, gives them its full and undivided attention while it executes their transaction, exe-\ncutes the whole transaction (not just part of it), and saves the result of their transaction forever. This is a tall \norder and doesn’t at all describe what’s really going on inside the system: The system executes many transac-\ntions concurrently; it fails from time to time due to software and hardware errors, often at the worst possible \nmoment (when it’s running  your transaction); and it has limited storage capacity. Yet, through a combination \nof software techniques, the system approximates the behavior that users want. Those techniques are the main \nsubject of Chapters 6 through 9. \n As computing technology evolves, transaction processing technology will evolve to support it. We discuss \nsome major trends in Chapter 11: cloud computing, scalable distributed computing, ﬂ ash storage, and streams \nand event processing. \n Here is a summary of what you’ll ﬁ nd in each chapter: \n Chapter 1, Introduction: Gives a broad-brush overview of transaction processing application and system \nstructure. It describes service-oriented computing, the ACID properties of transactions, the two-phase \ncommit protocol, the industry-standard TPC performance benchmarks, high availability requirements, and \nthe relationship of transaction processing to batch processing, real-time, and data warehousing systems. \n Chapter 2, Transaction Processing Abstractions: Describes the main software abstractions found in transac-\ntion processing systems: transactions; processes and threads; remote procedure call; techniques for man-\naging shared state, such as transaction context, sessions, and cookies; and scalability techniques, such as \ncaching, resource pooling, partitioning, and replication. \n Chapter 3, Transaction Processing Application Architecture: Explains the value of multitier application \narchitecture and then delves into each tier in detail: front ends that use forms and web servers to com-\nmunicate with end-user devices; request controllers that bracket transactions; and transaction servers that \nexecute transactions. It also explains how transactional middleware and database servers structure these \nactivities. \n Chapter 4, Queued Transaction Processing: Shows how a persistent message queue adds reliability. It gives \ndetailed walk-throughs of recovery scenarios and shows how queues drive publish-subscribe, broker-based \nand bus-based message-oriented middleware. It also explains the internals of queue managers, with IBM’s \nWebsphere MQ and Oracle’s Stream AQ as examples. \n Chapter 5, Business Process Management: Describes mechanisms to support the creation, management, and \nmonitoring of business processes that execute as multiple related transactions. It explains how to obtain \n",
      "content_length": 3995,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 15,
      "content": "xiv  Preface\n suitable atomicity, isolation, and durability of multitransaction requests. It summarizes the business process \nexecution language (BPEL) standard and, as an example, business process mechanisms in Microsoft SQL \nService Broker. \n Chapter 6, Locking: Shows how and why two-phase locking works and how application programmers affect \nits correctness and performance. It describes lock manager implementation and deadlock handling. It then \nexplains in detail how performance can be controlled by lock granularity, optimistic methods, batching, \navoiding hot spots, avoiding phantoms, and supporting query-update workloads using lower degrees of iso-\nlation and multiversion methods. Finally, it covers B-tree locking and multigranularity locking used in SQL \ndatabase systems, and nested transaction locking. \n Chapter 7, System Recovery: Identiﬁ es what causes failures, and how transactions help mask their effects. It \ndiscusses checkpoint-based application recovery, using stateless servers to simplify recovery, and warm and \nhot standby systems that use process pairs to reduce recovery time. It then explains how database systems \nuse logging to recover from transaction failures, system failures, and media failures. It explains the undo \nand redo paradigm, how and why logging algorithms work, log checkpointing, recovery algorithms, shadow \npaging, some fancy popular logging optimizations (including the ARIES algorithm), and archive recovery. \n Chapter 8, Two-Phase Commit: Explains the two-phase commit protocol in detail. It carefully walks through \nrecovery situations and shows where and why the user must get involved. It presents popular optimiza-\ntions such as presumed abort, phase zero, and transfer of coordination. And it explains how database sys-\ntems and transaction managers interoperate using the XA interface of the X/Open transaction management \narchitecture. \n Chapter 9, Replication: Describes the tradeoffs of replicating servers versus replicating resources and shows \nhow the correctness criterion, one-copy serializability, applies to each of them. It presents the two most \npopular approaches to replication: primary-copy replication, where updates to a primary are propagated \nto secondaries; and multimaster replication, where updates are applied to any copy and then propagate to \nother copies. It also explains synchronization of replicated caches that connect to a shared database. It cov-\ners algorithms for electing a primary, quorum consensus, establishing the latest state, and replica recovery. \n Chapter 10, Transactional Middleware Products and Standards: Describes popular products and standards \nfor transactional middleware, such as Java Enterprise Edition, Microsoft’s .NET Enterprise Services, legacy \ntransaction processing monitors (CICS, IMS, Tuxedo, ACMS, and Pathway), and other service-oriented \nmiddleware. Component technologies include Windows Communications Foundation, Enterprise Java \nBeans, Java Database Connectors, Java Transaction API, and the Spring Framework , which appear in prod-\nucts from IBM, Oracle, Progress, and in open source software. It also describes transaction standards from \nOMG and X/Open, and Web Services standards from OASIS. \n Chapter 11, Future Trends: Discusses major directions where transaction processing technology is headed: \ncloud computing platforms, composing scalable systems using distributed computing components, the use \nof ﬂ ash storage to replace disks, and data and event streams from sensor devices as a source of transaction \nrequests. \n GUIDANCE FOR INSTRUCTORS \n The ﬁ rst author has taught transaction processing courses several dozen times over the past 25 years. Details \nof his most recent offerings are on the web site of the Department of Computer Science and Engineering at \n",
      "content_length": 3810,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 16,
      "content": "Preface  xv\n the University of Washington,  http://www.cs.washington.edu/education/courses/csep545/ , where you’ll ﬁ nd \nassignments, projects, and video-recorded lectures. \n The syllabus that has worked best for a formal university course is to use the ﬁ rst half of the course to \ncover Chapter 1 of this book followed by principles of concurrency control (Sections 6.1 – 6.4 of Chapter 6) \nand recovery (Chapter 7). These topics immerse students in challenging technical details that are best learned \nthrough structured homework assignments and are amenable to a conventional exam. This gets students to the \npoint where they can work on a course project. \n Transaction processing is a systems engineering problem, with many interacting parts. We have tried three \ndifferent kinds of course projects to help students deepen their understanding of how the parts ﬁ t together: case \nstudies of applications; building an application using commercial products (such as Microsoft .NET or Java \nEnterprise Edition); and building a transactional middleware system for running distributed transactions. The \nlast of these projects has been the most effective by far, from both the students ’ and instructor’s viewpoint. So \nin recent offerings, we require that all students do this project. \n The project involves building a skeleton of a travel reservation system for ﬂ ights, hotel rooms, and rental \ncars. This requires them to build a resource manager with locking and recovery, a two-phase commit proto-\ncol, and transactional middleware to move requests around. We found this was too much work for a 10-week \nquarter, even for graduate students who are full-time professional programmers. So we give them some of the \ncomponents to start with. The software is downloadable from the course web site. \n ACKNOWLEDGMENTS \n This book began over 20 years ago as course notes developed by the ﬁ rst author. Over the years, the course has \nbeen presented to over a thousand people at Digital Equipment Corp., the Wang Institute of Graduate Studies \n(gone, but not forgotten), Microsoft Corp., and University of Washington. The  “ students, ” most of them prac-\nticing engineers, suggested countless ideas that have become part of this book. We thank them all for the rich \ndetail they provided. \n Many people gave generously of their time to review selected chapters. They corrected our blunders, pointed \nout holes, and often ﬁ lled them in. We are very grateful to Brian Milnes, who reviewed the entire book in detail \nand added much from his experience in running large Internet TP systems. We greatly appreciate the help we \nreceived on various chapters from John Apps, Darach Ennis, Mike Keith, David Kubelka, Mark Little, Peter \nNiblett, Betty O’Neil, Pat O’Neil, Gera Shegalov, Tony Storey, Satish Thatte, Roger Wolter, and especially Lev \nNovik, who was a partner in developing the new section on multimaster replication. \n It was a major challenge to include many examples of products, applications, and benchmarks, and to get \nthem right. We could never have done it without the substantial assistance of the engineers who work on those \nartifacts. They reviewed several iterations, to help us think through every detail. While we take full responsibility\nfor any errors that slipped through, we are pleased to share the credit with Keith Evans, Max Feingold, Tom \nFreund, Jonathan Halliday, Jeurgen Hoeller, Rajkumar Irudayaraj, Jim Johnson, Ed Lassettre, Charles Levine, \nAnne Thomas Manes, Miko Matsumura, Laurence Melloul, Dean Meltz, Geoff Nichols, Greg Pavlik, Mike \nPizzo, Ian Robinson, Adrian Trenaman, Steve Vinoski, John Wells, and Jesse Yurkovich. \n Although much of this edition is new, much is not. In writing the ﬁ rst edition, we beneﬁ ted enormously \nfrom the help of Jim Gray and Joe Twomey. We also appreciate the help we received from Mario Bocca, Dexter \nBradshaw, Ian Carrie, Ed Cobb, Gagan Chopra, Dick Dievendorff, Keith Evans, Wayne Duquaine, Terry Dwyer, \nKo Fujimura, Per Gyllstrom, Vassos Hadzilacos, Brad Hammond, Pat Helland, Greg Hope, Larry Jacobs, Roger \nKing, Walt Kohler, Barbara Klein, Dave Lomet, Susan Malaika, Michael C. Morrison, M. Tamer Ozsu, Wes Saeger, \nDavid Schorow, Randy Smerik, Alex Thomasian, Karen Watterson, and Tom Wimberg. \n",
      "content_length": 4281,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 17,
      "content": "xvi  Preface\n We thank Vassos Hadzilacos, Nat Goodman, and the Addison-Wesley Publishing Company for permis-\nsion to republish excerpts from  Concurrency Control and Recovery in Database Systems , by P. Bernstein, \nV. Hadzilacos, and N. Goodman, primarily in Chapter 8. \n We thank our editors, Rick Adams, Diane Cerra, and Denise Penrose for their encouragement, ﬂ exibility, \nand good advice, as well as the production staff at Elsevier, and especially Jeff Freeland, for their efﬁ ciency and \ncareful attention in the production of the book. \n Finally , we thank our families and friends for indulging our moaning, keeping us happy, and accepting our \nlimited companionship without complaint, while all our discretionary time was consumed by this writing. It’s \nover  … for awhile    . \n \n",
      "content_length": 791,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 18,
      "content": " Trademarks  \n \n The following trademarks or registered trademarks are the property of the following organizations: \n Dreamweaver is a trademark or registered trademark of Adobe Systems Incorporated. \n AMD is a trademark or registered trademark of Advanced Micro Devices, Inc. \n Amazon.com is a trademark or registered trademark of Amazon.com, Inc. \n Netscape is a trademark or registered trademark of AOL, LLC. \n Apache, Apache API, Apache ActiveMQ, Apache CXF, Apache HTTP Server, Apache Kandula2, Apache \nTomcat,  Apache OpenJPA, Apache Qpid, and Apache ServiceMix are trademarks or registered trademarks \nof The Apache Software Foundation. \n ARM is a trademark or registered trademark of ARM Limited. \n Atomikos is a trademark or registered trademark of Atomikos BVBA. \n Raima RDM is a trademark or registered trademark of Birdstep Technology ASA. \n VisiBroker is a trademark or registered trademark of Borland Software Corporation. \n SiteMinder and Unicenter are trademarks or registered trademarks of CA. \n RabbitMQ is a trademark or registered trademark of Cohesive Flexible Technologies Corporation and Lshift \nLtd. \n Eclipse, SOA Tools Platform Project, Rich Client Platform, and Higgins are trademarks or registered trade-\nmarks of The Eclipse Foundation. \n Delphi is a trademark or registered trademark of Embarcadero Technologies, Inc. \n Google is a trademark or registered trademark of Google, Inc. \n ACMS, DATATRIEVE, DECforms, DECdtm, Guardian, HP, Non-Stop, OpenView, OpenVMS, Pathway, \nReliable Transaction Router, TDMS, TP Ware, TP Web Connector, VAX, VMSCluster, and Web Services \nIntegration Toolkit are trademarks or registered trademarks of Hewlett-Packard Development Company. \n TPBroker is a trademark or registered trademark of Hitachi Computer Products, Inc. \n OpenAMQ is a trademark or registered trademark of iMatix Corporation. \n Intel is a trademark or registered trademark of Intel Corporation. \n i5/OS, AIX, CICS, DB2, IBM, IMS, Informix, OS/400, Power PC, Tivoli, Tx Series VSE, UDB, WebSphere, \nand zOS are trademarks or registered trademarks of International Business Machines Corporation. \n Linux is a trademark or registered trademark of the Linux Mark Institute. \n eXtremeDB and McObject are trademarks or registered trademarks of McObject LLC. \n Active Directory, BizTalk, Expression, Microsoft, SQL Server, Visual Basic, Visual C#, Visual J#, Visual \nStudio, Windows, Windows Cardspace, Windows Server, Windows Vista, and Xbox are trademarks or reg-\nistered trademarks of Microsoft Corporation. \n",
      "content_length": 2536,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 19,
      "content": "xviii  Trademarks\n Motorola is a trademark or registered trademark of Motorola, Inc. \n BPMN, CORBA, IIOP, Object Management Group, OMG, UML, and Uniﬁ ed Modeling Language are trade-\nmarks or registered trademarks of the Object Management Group. \n UNIX and X/Open are trademarks or registered trademarks of The Open Group. \n CDD, Coherence, Oracle, Rdb, Streams, TimesTen, TopLink, Tuxedo, and WebLogic are trademarks or regis-\ntered trademarks of Oracle Corporation. \n OW2 is a trademark or registered trademark of OW2 Consortium. \n Artix, Orbix, Sonic, Sonic ESB, and SonicMQ are trademarks or registered trademarks of Progress Software \nCorporation. \n Python is a trademark or registered trademark of The Python Software Foundation. \n Enterprise MRG, Hibernate, JBoss, and Red Hat are trademarks or registered trademarks of Red Hat, Inc. \n SABRE, Sabre Holdings, and Travelocity are trademarks or registered trademarks of an afﬁ liate of Sabre \nHoldings Corporation. \n Salesforce is a trademark or registered trademark of Salesforce.com, Inc. \n SPARC is a trademark or registered trademark of SPARC International. \n Spring Framework and SpringSource dm Server are trademarks or registered trademarks of SpringSource. \n MySQL, NetBeans, and all trademarks and logos that contain Java, Solaris, or Sun, are trademarks or regis-\ntered trademarks of Sun Microsystems, Inc. \n PowerBuilder and Sybase are trademarks or registered trademarks of Sybase, Inc. \n TIBCO and TIBCO Enterprise Message Service are trademarks or registered trademarks of Tibco Software, \nInc. \n TPC, TPC-A, TPC-B, TPC-C, TPC-E, and TPC-H are trademarks or registered trademarks of the Transaction \nProcessing Performance Council. \n Web Services Interoperability Organization and WS-I are trademarks or registered trademarks of the Web \nServices Interoperability Organization. \n Yahoo! is a trademark or registered trademark of Yahoo! Inc. \n FastCGI is © Copyright 1996 – 2008 by Open Market, Rob Saccoccio, and others. \n PostgreSQL is Copyright © 1996 – 2008 by the PostgreSQL Global Development Group. \n \n",
      "content_length": 2076,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 20,
      "content": " 1.1  THE BASICS \n The Problem \n A  business transaction is an interaction in the real world, usually between an enterprise and a person or \nanother enterprise, where something is exchanged. For example, it could involve exchanging money, products, \ninformation, or service requests. Usually some bookkeeping is required to record what happened. Often this \nbookkeeping is done by a computer, for better scalability, reliability, and cost. Communications between the \nparties involved in the business transaction is often done over a computer network, such as the Internet. This is \n transaction processing (TP) — the processing of business transactions by computers connected by computer \nnetworks. There are many requirements on computer-based transaction processing, such as the following: \n ■  A business transaction requires the execution of multiple operations. For example, consider the purchase \nof an item from an on-line catalog. One operation records the payment and another operation records \nthe commitment to ship the item to the customer. It is easy to imagine a simple program that would do \nthis work. However, when scalability, reliability, and cost enter the picture, things can quickly get very \ncomplicated. \n ■  Transaction volume and database size adds complexity and undermines efﬁ ciency. We’ve all had the expe-\nrience of being delayed because a sales person is waiting for a cash register terminal to respond or because \nit takes too long to download a web page. Yet companies want to serve their customers quickly and with \nthe least cost. \n ■  To scale up a system for high performance, transactions must execute concurrently. Uncontrolled con-\ncurrent transactions can generate wrong answers. At a rock concert, when dozens of operations are com-\npeting to reserve the same remaining seats, it’s important that only one customer is assigned to each seat. \nFairness is also an issue. For example, Amazon.com spent considerable effort to ensure that when its \nﬁ rst thousand Xboxes went on sale, each of the 50,000 customers who were vying for an Xbox had a fair \nchance to get one. \n ■  If a transaction runs, it must run in its entirety. In a retail sale, the item should either be exchanged for \nmoney or not sold at all. When failures occur, as they inevitably do, it’s important to avoid partially com-\npleted work, such as accepting payment and not shipping the item, or vice versa. This would make the \ncustomer or the business very unhappy. \n Introduction \n 1 \nCHAPTER\n",
      "content_length": 2505,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 21,
      "content": "2  CHAPTER 1 Introduction\n ■  Each transaction should either return an acknowledgment that it executed or return a negative acknowl-\nedgment that it did not execute. Those acknowledgments are important. If no acknowledgment arrives, \nthe user doesn’t know whether to resubmit a request to run the transaction again. \n ■  The system should be incrementally scalable. When a business grows, it must increase its capacity for run-\nning transactions, preferably by making an incremental purchase — not by replacing its current machine by \na bigger one or, worse yet, by rebuilding the application to handle the increased workload. \n ■  When an electronic commerce (e-commerce) web site stops working, the retail enterprise is closed for \nbusiness. Systems that run transactions are often  “ mission critical ” to the business activity they support. \nThey should hardly ever be down. \n ■  Records of transactions, once completed, must be permanent and authoritative. This is often a legal \nrequirement, as in ﬁ nancial transactions. Transactions must never be lost. \n ■  The system must be able to operate well in a geographically distributed environment. Often, this implies \nthat the system itself is distributed, with machines at multiple locations. Sometimes, this is due to a legal \nrequirement that the system must operate in the country where the business is performed. Other times, dis-\ntributed processing is used to meet technical requirements, such as efﬁ ciency, incremental scalability, and \nresistance to failures (using backup systems). \n ■  The system should be able to personalize each user’s on-line experience based on past usage patterns. \nFor a retail customer, it should identify relevant discounts and advertisements and offer products custom-\nized to that user. \n ■  The system must be able to scale up predictably and inexpensively to handle Internet loads of millions of \npotential users. There is no way to control how many users log in at the same time or which transactions \nthey may choose to access. \n ■  The system should be easy to manage. Otherwise, the system management staff required to operate a \nlarge-scale system can become too large and hence too costly. Complex system management also increases \nthe chance of errors and hence downtime, which in turn causes human costs such as increased stress and \nunscheduled nighttime work. \n In summary, transaction processing systems have to handle high volumes efﬁ ciently, avoid errors due to \nconcurrent operation, avoid producing partial results, grow incrementally, avoid downtime, never lose results, \noffer geographical distribution, be customizable, scale up gracefully, and be easy to manage. It’s a tall order. \nThis book describes how it’s done. It explains the underlying principles of automating business transactions, \nboth for traditional businesses and over the Internet; explores the complexities of fundamental technologies, \nsuch as logging and locking; and surveys today’s commercial transactional middleware products that provide \nfeatures necessary for building TP applications. \n What Is a Transaction? \n An  on-line transaction is the execution of a program that performs an administrative function by accessing a \nshared database, usually on behalf of an on-line user. Like many system deﬁ nitions, this one is impressionistic \nand not meant to be exact in all its details. One detail is important: A transaction is always the  execution of a \nprogram. The program contains the steps involved in the business transaction — for example, recording the sale \nof a book and reserving the item from inventory. \n",
      "content_length": 3608,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 22,
      "content": " We ’ll use the words  transaction program to mean the program whose execution is the transaction. \nSometimes the word  “ transaction ” is used to describe the message sent to a computer system to request the exe-\ncution of a transaction, but we’ll use different words for that: a  request message . So a transaction always means \nthe execution of a program. \n We say that a transaction performs an administrative function, although that isn’t always the case. For \nexample, it could be a real-time function, such as making a call in a telephone switching system or controlling \na machine tool in a factory process-control system. But usually there’s money involved, such as selling a ticket \nor transferring money from one account to another. \n Most transaction programs access shared data, but not all of them do. Some perform a pure communications \nfunction, such as forwarding a message from one system to another. Some perform a system administration \nfunction, such as resetting a device. An application in which no programs access shared data is not considered \ntrue transaction processing, because such an application does not require many of the special mechanisms that \na TP system offers. \n There is usually an on-line user, such as a home user at a web browser or a ticket agent at a ticketing device. \nBut some systems have no user involved, such as a system recording messages from a satellite. Some transac-\ntion programs operate  off-line , or in batch mode, which means that the multiple steps involved may take longer \nthan a user is able to wait for the program’s results to be returned — more than, say, ten seconds. For example, \nmost of the work to sell you a product on-line happens after you’ve entered your order: a person or robot gets \nyour order, picks it from a shelf, deletes it from inventory, prints a shipping label, packs it, and hands it off to \nthe shipping company. \n Transaction Processing Applications \n A  transaction processing application is a collection of transaction programs designed to do the functions \nnecessary to automate a given business activity. The ﬁ rst on-line transaction processing application to receive \nwidespread use was an airline reservation system: the SABRE system developed in the early 1960s as a joint \nventure between IBM and American Airlines. SABRE was one of the biggest computer system efforts under-\ntaken by anyone at that time, and still is a very large TP system. SABRE was spun off from American Airlines \nand is now managed by a separate company, Sabre Holdings Corporation, which provides services to more \nthan 200 airlines and thousands of travel agencies, and which runs the Travelocity web site. It can handle a \nlarge number of ﬂ ights, allow passengers to reserve seats and order special meals months in advance, offer \nbonuses for frequent ﬂ yers, and schedule aircraft maintenance and other operational activities for airlines. Its \npeak performance has surpassed 20,000 messages per second. \n Today , there are many other types of TP applications and new ones are emerging all the time. We sum-\nmarize some of them in  Figure 1.1 . As the cost of running transactions and of managing large databases \ndecreases, more types of administrative functions will be worth automating as TP applications, both to reduce \nthe cost of administration and to generate revenue as a service to customers. \n In its early years, the TP application market was driven primarily by large companies needing to support \nadministrative functions for large numbers of customers. Such systems often involve thousands of terminals, \ndozens of disk drives, and many large processors, and can run hundreds of thousands of transactions per day. \nLarge TP systems are becoming even more important due to the popularity of on-line services on the Internet. \nHowever, with the downsizing of systems has come the need for small TP applications too, ones with just a \nfew browsers connected to a small server machine, to handle orders for a small catalog business, course reg-\nistrations for a school, or patient visits to a dental ofﬁ ce. All these applications — large and small — rely on the \nsame underlying system structure and software abstractions. \n1.1 The Basics  3\n",
      "content_length": 4232,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 23,
      "content": "4  CHAPTER 1 Introduction\n TP systems also are being offered as services to other companies. For example, Amazon.com hosts other \ncompanies ’ web storefronts. Some airlines develop and operate reservation services for other airlines. Some \nvendors of packaged applications are now offering their application as a service that can be invoked by a third \nparty’s application over the Internet, which in turn helps the third party offer other TP services to their custom-\ners. Given the expense, expertise, and management attention required to build and run a high-quality TP sys-\ntem, this trend toward out-sourcing TP applications is likely to grow. \n A Transaction Program’s Main Functions \n A transaction program generally does three things: \n 1.  Gets input from a web browser or other kind of device, such as a bar-code reader or robot sensor. \n 2.  Does the real work being requested. \n 3.  Produces a response and, possibly, sends it back to the browser or device that provided the input. \n Each invocation of the transaction program results in an independent unit of work that executes exactly \nonce and produces permanent results. We’ll have more to say about these properties of a transaction program \nshortly. \n Most TP applications include some code that does not execute as a transaction. This other code executes \nas an ordinary program, not necessarily as an independent unit of work that executes exactly once and pro-\nduces permanent results. We use the term TP application in this larger sense. It includes transaction programs, \nprograms that gather input for transactions, and maintenance functions, such as deleting obsolete inventory \nrecords, reconﬁ guring the runtime system, and updating validation tables used for error-checking. \nApplication\nExample Transaction\nBanking\nWithdraw money from an account\nSecurities trading\nPurchase 100 shares of stock\nInsurance\nPay an insurance premium\nInventory control\nRecord the fulfillment of an order\nManufacturing\nLog a step of an assembly process\nRetail point-of-sale\nRecord a sale\nGovernment\nRegister an automobile\nOnline shopping\nPlace an order using an on-line catalog\nTransportation\nTrack a shipment\nTelecommunications\nConnect a telephone call\nMilitary Command and Control\nFire a missile\nMedia\nGrant permission to download a video\n FIGURE 1.1 \n Transaction Processing Applications. Transaction processing covers most sectors of the economy. \n",
      "content_length": 2409,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 24,
      "content": " 1.2  TP SYSTEM ARCHITECTURE \n A  TP system is the computer system — both hardware and software — that hosts the transaction programs. The \nsoftware parts of a TP system usually are structured in a special way. As you can see from  Figure 1.2 , the TP \nsystem has several main components. Different parts of the application execute in each of these components. \n 1.  End-user device: An  end user is someone who requests the execution of transactions, such as a customer \nof a bank or of an Internet retailer. An end-user device could be a physical device, such as a cash register \nor gasoline pump. Or it could be a web browser running on a desktop device, such as a personal computer \n(PC). If it is a dumb device, it simply displays data that is sent to it and sends data that the user types in. \nIf it is a smart device, then it executes application code that is the front-end program. \n 2.  Front-end program: A  front-end program is an application code that interacts with the end-user device. \nUsually it sends and receives menus and forms, to offer the user a selection of transactions to run and \nto collect the user’s input. Often, the device is a web browser and the front-end program is an applica-\ntion managed by a web server that communicates with the browser via HTTP. The front-end program \nvalidates the user’s input and then sends a request message to another part of the system whose job is to \nactually execute the transaction. \n 3.  Request controller: A  request controller is responsible for receiving messages from front-end programs \nand turning each message into one or more calls to the proper transaction programs. In a centralized \nsystem, this is simply a matter of calling a local program. In a distributed TP system, it requires sending \nthe message to a system where the program exists and can execute. If more than one program is needed, \nit tracks the state of the request as it moves between programs. \n 4.  Transaction server: A  transaction server is a process that runs the parts of the transaction program that \nperform the work the user requested, typically by reading and writing a shared database, possibly call-\ning other programs, and possibly returning a reply that is routed back to the device that provided the \ninput for the request. \n 5.  Database system: A  database system manages shared data that is needed by the application to do its job. \nIf Buy-a-Book\n  {call  A}; \nIf Find-Order\n  {call  B}; \nIf Cancel-Order\n  {call C};\nTransaction\nServer A \nRequest\nController\nEnd-user\nDevice \nDatabase\nFront-end\nProgram\nSend Form\nReceive Form\nBuy-a-Book \nBook: \nAmount:\nBuy-a-Book \nBook: TP\n$50\nAmount:\n FIGURE 1.2 \n Transaction Application Parts. A transaction application gathers input, routes the input to a program that can execute the \nrequest, and then executes the appropriate transaction program. \n1.2 TP System Architecture  5\n",
      "content_length": 2881,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 25,
      "content": "6  CHAPTER 1 Introduction\n For example, in an Internet-based order processing application, a user submits orders via a web browser. \nThe front-end program is managed by a web server, which reads and writes forms and menus and perhaps \nmaintains a shopping cart. A request controller routes requests from the web server to the transaction server \nthat can process the order the user requested. The transaction server processes the order, which requires access-\ning the database that keeps track of orders, catalog information, and warehouse inventory, and perhaps contacts \nanother transaction server to bill a credit card for the order. \n The transaction programs that run in the server are of a limited number of types that match operational busi-\nness procedures, such as shipping an order or transferring funds. Typically there are a few dozen and usually no \nmore than a few hundred. When applications become larger than this, usually they are partitioned into indepen-\ndent applications of smaller size. Each one of these programs generally does a small amount of work. There’s \nno standard concept of an average size of a transaction program, because they all differ based on the applica-\ntion. But a typical transaction might have between zero and 30 disk accesses, a few thousand up to a few million \ninstructions, and at least two messages, but often many more depending on how distributed it is. It may be dis-\ntributed because different application services are needed to process it or because multiple machines are needed \nto handle the application load. The program generally is expected to execute within a second or two, so that the \nuser can get a quick response. Later on we’ll see another, more technical reason for keeping transactions short, \nhaving to do with locking conﬂ icts. \n Database systems play a big role in supporting transaction programs, often a bigger role than the applica-\ntion programs themselves. Although the database can be small enough to ﬁ t in main memory, it is often much \nlarger than that. Some databases for TP require a large number of nonvolatile storage devices, such as mag-\nnetic or solid state disks, pushing both storage and database system software technology to the limit. To scale \neven larger, the database may be replicated or partitioned onto multiple machines. \n Another major category of TP software products is  transactional middleware , which is a layer of software \ncomponents between TP applications and lower level components such as the operating system, database sys-\ntem, and system management tools. These components perform a variety of functions. They can help the appli-\ncation make the most efﬁ cient use of operating system processes, database connections, and communications \nsessions, to enable an application to scale up. For example, they may provide functions that client applications \ncan use to route requests to the right server applications. They can integrate the transaction abstraction with the \napplication, operating system, and database system, for example, to enable the execution of distributed transac-\ntions, sometimes across heterogeneous environments. They can integrate system management tools to simplify \napplication management, for example, so that system managers can balance the load across multiple servers in \na distributed system. And they may offer a programming interface and/or  conﬁ gurable properties that simplify \nthe use of related services that originate in the operating system and database system. \n Transactional middleware product categories have evolved rapidly over the past ﬁ fteen years. Before the advent \nof the World Wide Web (WWW), transactional middleware products were called TP monitors or on-line TP (OLTP) \nmonitors. During the mid 1990s, application server products were introduced to help application developers cope \nwith new problems introduced by the Web, such as integrating with web servers and web browsers. Initially, appli-\ncation servers formed a bridge between existing commercial systems managed by TP monitors and the Internet. In \na relatively short time, the functionality of application servers and TP monitors converged. During the same period, \nmessage-oriented transactional middleware and object request brokers became popular. Message-oriented middle-\nware became the foundation of a product category called enterprise application integration systems. The adoption \nof standard Internet-based protocols for application communication, called Web Services, has led to the enterprise \nservice bus, another transactional middleware product. And ﬁ nally, workﬂ ow products have become popular to \nhelp users deﬁ ne and manage long-running business processes. Although transactional middleware products usu-\nally are marketed as a complete environment for developing and executing TP applications, customers sometimes \nuse components from multiple transactional middleware products to assemble their TP environments. \n",
      "content_length": 4967,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 26,
      "content": " Service Oriented Computing \n Service Oriented Architecture (SOA) is a style of design in which applications are composed in whole or in \npart of reusable services. SOA aligns information systems technology well with business objectives by mod-\neling an application as a composition of reusable services. In contrast to the object-oriented (OO) paradigm, \nservices are designed to model functions rather than things. They are a natural abstraction of the concept of \nbusiness services; that is, services that a business provides to its customers and partners. A service can be \nimplemented using an object, but it need not be. For example, it may be implemented using a procedure, stored \nprocedure, asynchronous message queue, or script. Services are characterized by the messages they exchange \nand by the interface contracts deﬁ ned between the service requester and provider, rather than by the programs \nthat are used to implement them. \n Service orientation has been around for a long time as a concept. However, only recently has it become \nmainstream, with many large-scale web sites for web search, social networking, and e-commerce now offer-\ning service-oriented access to their functions. In part, this wide availability is due to the advent of standard \nWeb Services protocols. Web Services is an implementation technology that enables independent programs \nto invoke one another reliably and securely over a network, especially the Internet. Many vendors now sup-\nport Web Services protocols. This enables one to implement SOA in a multivendor environment, which is a \nrequirement for most enterprises. \n A TP system that is created in whole or in part using the SOA approach may include multiple reusable \nservices offered by a single transaction program or by multiple distributed services. An SOA-based TP system \nmay include both synchronous and asynchronous communications mechanisms, depending on the message \nexchange patterns that a given service supports and the execution environment in which it runs. SOA-based TP \nsystems may be assembled using a combination of services from a variety of applications and using a variety \nof operating systems, middleware platforms, and programming languages. \n Figure 1.3 illustrates the components of a service-oriented architecture. They include a service provider that \noffers a service, a requester that invokes a service, and a registry (sometimes called a repository) that publishes \nservice descriptions. The service descriptions typically include the service interface, the name and format of \ndata to be exchanged, the communications protocol to be used, and the quality of service that the interaction is \nrequired to support (such as its security and reliability characteristics and its transaction behavior). \n A caller communicates with a service by sending messages, guided by a message exchange pattern. The \nbasic pattern is a one-way asynchronous request message, where a caller sends a request message to the ser-\nvice provider and the service provider receives the message and executes the requested service. Other common \npatterns are request-response and publish-subscribe. \nRegistry \nService\nRequester\nService\nProvider\nPublish (WSDL)\nFind (UDDI) \nInvoke (SOAP)\n FIGURE 1.3 \n Basic Architecture of Service Orientation. A service provider publishes its interface in the registry. A service requester \nuses the registry to ﬁ nd a service provider and invokes it. The corresponding Web Service technologies are WSDL, \nUDDI, and SOAP. \n1.2 TP System Architecture  7\n",
      "content_length": 3544,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 27,
      "content": "8  CHAPTER 1 Introduction\n The registry is an optional component because the requester can obtain service description information in \nother ways. For example, a developer who writes the requester can ﬁ nd the service description on a web site or \nbe given the service description by the service’s owner. \n One mechanism to implement SOA is Web Services, where a service requester invokes a service provider \nusing the protocol SOAP. 1 The service interface offered by the service provider is deﬁ ned in the Web Services \nDescription Language (WSDL). The service provider makes this interface known by publishing it in a regis-\ntry. The registry offers access to service descriptions via the Universal Description, Discovery, and Integration \n(UDDI) protocol. A service requester and provider can be running in different execution environments, such as \nJava Enterprise Edition or Microsoft. NET. \n Web Service interfaces are available for virtually all information technology product categories: application \nservers, object request brokers, message oriented middleware systems, database management systems, and pack-\naged applications. Thus, they provide  interoperability , meaning that applications running on disparate software \nsystems can communicate with each other. Web Services support transaction interoperability too, as deﬁ ned in \nthe Web Services Transactions speciﬁ cations (discussed in Section 10.8). \n Services simplify the assembly of new applications from existing ones by combining services. Tools and \ntechniques are emerging to simplify the assembly of services, such as the Service Component Architecture for \nJava and the Windows Communication Foundation for Windows. \n A TP application may exist as a combination of reusable services. The use of reusable services doesn’t change \nthe functions of the front-end program, request controller, or transaction server. However, it may affect the way \nthe functions are designed, modeled, and implemented. For example, in  Figure 1.2 , the decision to build the \nrequest controller as a reusable Web Service may affect the choice of implementation technologies, such as deﬁ n-\ning the interface to the request controller using WSDL and invoking it using SOAP. That decision may also affect \nthe design by enabling an end-user device such as a web browser to call the request controller service(s) directly, \nbypassing the front-end program. We’ll talk a lot more about TP software architecture in Chapter 3. \n Representational State Transfer (REST) is another approach to SOA, rather different than that of Web \nServices. The term REST is used in two distinct but related ways: to denote the protocol infrastructure used for \nthe World Wide Web, namely the Hypertext Transfer Protocol (HTTP); and to denote a software architectural \npattern that can be implemented by web protocols. We use it here in the former sense, which we call REST/\nHTTP. We will discuss the REST architectural pattern in Section 3.3. \n REST /HTTP focuses on the reuse of resources using a small set of generic HTTP operations, notably GET \n(i.e., read), PUT (i.e., update), POST (i.e., insert), and DELETE. This is in contrast to Web Services, which uses \nservices that are customized for a particular application. Each HTTP operation is applied to a resource identi-\nﬁ ed by a Uniform Resource Identiﬁ er (URI). A registry function, as shown in  Figure 1.3 , is needed to translate \neach URI into a network address where the resource can be found. On the Internet, this is implemented by the \nDomain Name System, which translates domain names such as  www.mydomain.com into IP addresses. \n In REST, generic HTTP operations are used to perform application-speciﬁ c functions. For example, instead of \ninvoking a Web Service AddCustomer, you could use REST to invoke the POST operation with a URI that makes \nit clear that a customer is being inserted, such as  www.company-xyz.com/customers . In general, the application-\nspeciﬁ c information that identiﬁ es the function and its parameters must be embodied in the representation of the \nresource. This is why this style of communication is called representational state transfer. In practice, the represen-\ntation that is transferred is often in a standard, stylized form, such as JavaScript Object Notation (JSON). \n The format of the representation is speciﬁ ed in the HTTP header; the  content-type and  accept ﬁ elds \nspecify the format of the input and output, respectively. Thus, instead of specifying data types in a service’s \n 1 Originally, SOAP was an acronym for Simple Object Access Protocol. However, the SOAP 1.2 speciﬁ cation explicitly says it should \nno longer be treated as an acronym. \n",
      "content_length": 4699,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 28,
      "content": " interface deﬁ nition, the caller speciﬁ es the data types it would like to receive. This ﬂ exibility makes it easier \nfor diverse kinds of callers to invoke the service. \n REST /HTTP is popular for its speed and simplicity. Web Services require parameters in SOAP messages to \nbe represented in XML, which is expensive to parse. XML is self-describing and highly interoperable, but these \nbeneﬁ ts are not always important, for example, for simple services. A very simple interface makes it easier and \nfaster to manipulate in limited languages such as JavaScript. \n Hardware Architecture \n The computers that run these programs have a range of processing power. A display device could be a character-\nat-a-time terminal, a handheld device, a low-end PC, or a powerful workstation. Front-end programs, request \ncontrollers, transaction servers, and database systems could run on any kind of server machine, ranging from a \nlow-end server machine, to a high-end multiprocessor mainframe, to a distributed system. A distributed system \ncould consist of many computers, localized within a machine room or campus or geographically dispersed in a \nregion or worldwide. \n Some of these systems are quite small, such as a few display devices connected to a small machine on a PC \nLocal Area Network (LAN). Big TP systems tend to be enterprise- wide or Internet-wide, such as airline and \nﬁ nancial systems, Internet retailers, and auction sites. The big airline systems have on the order of 100,000 dis-\nplay devices (terminals, ticket printers, and boarding-pass printers) and thousands of disk drives, and execute \nthousands of transactions per second at their peak load. The biggest Internet systems have hundreds of millions \nof users, with tens of millions of them actively using the system at any one time. \n Given this range of capabilities of computers that are used for TP, we need some terminology to distinguish \namong them. We use standard words for them, but in some cases with narrower meanings than is common in \nother contexts. \n We deﬁ ne a  machine to be a computer that is running a single operating system image. It could use a single-\ncore or multicore processor, or it could be a shared-memory multiprocessor. Or it might be a virtual machine \nthat is sharing the underlying hardware with other virtual machines. A  server machine is a machine that exe-\ncutes programs on behalf of client programs that typically execute on other computers. A  system is a set of one \nor more machines that work together to perform some function. For example, a  TP system is a system that sup-\nports one or more TP applications. A  node (of a network) is a system that is accessed by other machines as if it \n were one machine. It may consist of several machines, each with its own network address. However, the system \nas a whole also has a network address, which is usually how other machines access it. \n A  server process is an operating system process,  P , that executes programs on behalf of client programs exe-\ncuting in other processes on the same or different machines as the one where  P is running. We often use the word \n “ server ” instead of  “ server machine ” or  “ server process ” when the meaning is obvious from context. \n 1.3  ATOMICITY, CONSISTENCY, ISOLATION, AND DURABILITY \n There are four critical properties of transactions that we need to understand at the outset: \n ■  Atomicity: The transaction executes completely or not at all. \n ■  Consistency: The transaction preserves the internal consistency of the database. \n ■  Isolation: The transaction executes as if it were running alone, with no other transactions. \n ■  Durability: The transaction’s results will not be lost in a failure. \n1.3 Atomicity, Consistency, Isolation, and Durability  9\n",
      "content_length": 3778,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 29,
      "content": "10  CHAPTER 1 Introduction\n This leads to an entertaining acronym, ACID. People often say that a TP system executes ACID transac-\ntions, in which case the TP system has  “ passed the ACID test. ” Let’s look at each of these properties in turn and \nexamine how they relate to each other. \n Atomicity \n First , a transaction needs to be  atomic (or  all-or-nothing ), meaning that it executes completely or not at all. \nThere must not be any possibility that only part of a transaction program is executed. \n For example, suppose we have a transaction program that moves $100 from account A to account B. It takes \n$100 out of account A and adds it to account B. When this runs as a transaction, it has to be atomic — either both \nor neither of the updates execute. It must not be possible for it to execute one of the updates and not the other. \n The TP system guarantees atomicity through database mechanisms that track the execution of the transac-\ntion. If the transaction program should fail for some reason before it completes its work, the TP system will \nundo the effects of any updates that the transaction program has already done. Only if it gets to the very end and \nperforms all of its updates will the TP system allow the updates to become a permanent part of the database. \n If the TP system fails, then as part of its recovery actions it undoes the effects of all updates by all transac-\ntions that were executing at the time of the failure. This ensures the database is returned to a known state fol-\nlowing a failure, reducing the requirement for manual intervention during restart. \n By using the atomicity property, we can write a transaction program that emulates an atomic business trans-\naction, such as a bank account withdrawal, a ﬂ ight reservation, or a sale of stock shares. Each of these business \nactions requires updating multiple data items. By implementing the business action by a transaction, we ensure \nthat either all the updates are performed or none are. \n The successful completion of a transaction is called  commit . The failure of a transaction is called  abort . \n Handling Real-World Operations \n During its execution, a transaction may produce output that is displayed back to the user. However, since the \ntransaction program is all-or-nothing, until the transaction actually commits, any results that the transaction \nmight display to the user should not be taken seriously, because it’s still possible that the transaction will abort. \nAnything displayed on the display device could be wiped out in the database on abort. \n Thus , any value that the transaction displays may be used by the end-user only if the transaction commits \nand not if the transaction aborts. This requires some care on the part of users (see  Figure 1.4 ). If the system \nactually displays some of the results of a transaction before the transaction commits, and if the user utilizes \nany of these results as input to another transaction, then we have a problem. If the ﬁ rst transaction aborts and \nthe second transaction commits, then the all-or-nothing property has been broken. That is, some of the results \nof the ﬁ rst transaction will be reﬂ ected in the results of the second transaction. But other results of the ﬁ rst \ntransaction, such as its database updates, were not performed because the transaction aborted. \n Some systems solve this problem simply by not displaying the result of a transaction until after the transac-\ntion commits, so the user can’t inadvertently make use of the transaction’s output and then have it subsequently \nabort. But this too has its problems (see  Figure 1.5 ): If the transaction commits before displaying any of its \nresults, and the system crashes before the transaction actually displays any of the results, then the user won’t \nget a chance to see the output. Again, the transaction is not all-or-nothing; it executed all its database updates \nbefore it committed, but did not display its output. \n We can make the problem more concrete by looking at it in the context of an automated teller machine \n(ATM) (see  Figure 1.6 ). The output, for example, may be an operation that dispenses $100 from the ATM. If \nthe system dispenses the $100 before the transaction commits, and the transaction ends up aborting, then the \n",
      "content_length": 4292,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 30,
      "content": " bank gives up the money but does not record that fact in the database. If the transaction commits and the sys-\ntem fails before it dispenses the $100, then the database says the $100 was given to the customer, but in fact \nthe customer never got the money. In both cases, the transaction’s behavior is not all-or-nothing. \n A closely-related problem is that of ensuring that each transaction executes exactly once. To do this, the \ntransaction needs to send an acknowledgment to its caller, such as sending a message to the ATM to dispense \nmoney, if and only if it commits. However, sending this acknowledgment is not enough to guarantee exactly-\nonce behavior because the caller cannot be sure how to interpret the absence of an acknowledgment. If the caller \nfails to receive an acknowledgment, it might be because the transaction aborted, in which case the caller needs to \nresubmit a request to run a transaction (to ensure the transaction executes once). Or it might be that the transac-\ntion committed but the acknowledgment got lost, in which case the caller must not resubmit a request to run the \ntransaction because that would cause the transaction to execute twice. So if the caller wants exactly-once behav-\nior, it needs to be sure that a transaction did not and will not commit before it’s safe to resubmit the request to \nrun the transaction. \n Although these seem like unsolvable problems, they can actually be solved using persistent queues, which \nwe’ll describe in some detail in Chapter 4. \nT1: Start\n \n read/write database\n \n . . .\n \n display results\n \n . . .\n \n error detected\n    If error then Abort\nT2: Start\n     display form\n     . . .\n     get input from display\n     . . .\n   Commit\nUser sees results\nUser provides input\n FIGURE 1.4 \n Reading Uncommitted Results. The user read the uncommitted results of transaction T 1  and fed them as input to \ntransaction T2. Since T1 aborts, the input to T2 is incorrect. \nT1: Start\n \n . . .\n    Commit\nDisplay results\nSystem crashes, so user \nnever sees the results.\n FIGURE 1.5 \n Displaying Results after Commits. This solves the problem of  Figure 1.4 , but if the transaction crashes before displaying \nthe results, the results are lost forever. \n1.3 Atomicity, Consistency, Isolation, and Durability  11\n",
      "content_length": 2278,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 31,
      "content": "12  CHAPTER 1 Introduction\n Compensating Transactions \n Commitment is an irrevocable action. Once a transaction is committed, it can no longer be aborted. People \ndo make mistakes, of course. So it may turn out later that it was a mistake to have executed a transaction that \ncommitted. At this point, the only course of action is to run another transaction that reverses the effect of the \none that committed. This is called a  compensating transaction . For example, if a deposit transaction was in \nerror, then one can later run a withdrawal transaction that reverses its effect. \n Sometimes , a perfect compensation is impossible, because the transaction performed some irreversible act. \nFor example, it may have caused a paint gun to spray-paint a part the wrong color, and the part is long gone \nfrom the paint gun’s work area when the error is detected. In this case, the compensating transaction may be to \nrecord the error in a database and send an e-mail message to someone who can take appropriate action. \n Virtually any transaction can be executed incorrectly. So a well-designed TP application should include a \ncompensating transaction type for every type of transaction. \n Multistep Business Processes \n Some business activities do not execute as a single transaction. For example, the activity of recording an order \ntypically executes in a separate transaction from the one that processes the order. Since recording an order is \nrelatively simple, the system can give excellent response time to the person who entered the order. The process-\ning of the order usually requires several time-consuming activities that may require multiple transactions, such \nas checking the customer’s credit, forwarding the order to a warehouse that has the requested goods in stock, \nand fulﬁ lling the order by picking, packing, and shipping it. \n Even though the business process executes as multiple transactions, the user may still want atomicity. Since \nmultiple transactions are involved, this often requires compensating transactions. For example, if an order is \naccepted by the system in one transaction, but later on another transaction determines that the order can’t be ful-\nﬁ lled, then a compensating transaction is needed to reverse the effect of the transaction that accepted the order. \nTo avoid an unhappy customer, this often involves the universal compensating transaction, namely, an apology \nand a free gift certiﬁ cate. It might also involve offering the customer a choice of either cancelling or telling the \nretailer to hold the order until the requested items have been restocked. \nStart\n     Record withdrawal\n     Dispense money\nCommit\nStart\n     Record withdrawal\nCommit\nDispense money\nTeller Machine \nTransaction 1\nSystem crashes and\ntransaction aborts,\nbut money is dispensed.\n(Bank is unhappy.)\nTransaction commits,\nthen the system crashes,\nso the money is not dispensed.\n(Customer is unhappy.)\nTeller Machine \nTransaction 2\n FIGURE 1.6 \n The Problem of Getting All-or-Nothing Behavior with Real-World Operations. Whether the program dispenses money before \nor after it commits, it’s possible that only one of the operations executes: dispense the money or record the withdrawal. \n",
      "content_length": 3215,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 32,
      "content": " Transactional middleware can help manage the execution of multistep business processes. For example, it \ncan keep track of the state of a multistep process, so if the process is unable to complete then the middleware \ncan invoke compensating transactions for the steps that have already executed. These functions and others are \ndiscussed in Chapter 5,  Business Process Management . \n Consistency \n A second property of transactions is consistency — a transaction program should maintain the consistency of \nthe database. That is, if you execute the transaction all by itself on a database that’s initially consistent, then \nwhen the transaction ﬁ nishes executing the database is again consistent. \n By consistent, we mean  “ internally consistent. ” In database terms, this means that the database at least satis-\nﬁ es all its integrity constraints. There are several kinds of integrity constraints that database systems can typically \nmaintain: \n ■  All primary key values are unique (e.g., no two employee records have the same employee number). \n ■  The database has referential integrity, meaning that records reference only objects that exist (e.g., the Part \nrecord and Customer record that are referenced by an Order record really exist). \n ■  Certain data values are in a particular range (e.g., age is less than 120 and social security number is not null). \n There are other kinds of integrity constraints that database systems typically cannot maintain but may nev-\nertheless be important, such as the following: \n ■  The sum of expenses in each department is less than or equal to the department’s budget. \n ■  The salary of an employee is bounded by the salary range of the employee’s job level. \n ■  The salary of an employee cannot decrease unless the employee is demoted to a lower job level. \n Ensuring that transactions maintain the consistency of the database is good programming practice. However, \nunlike atomicity, isolation, and durability, consistency is a responsibility shared between transaction programs \nand the TP system that executes those programs. That is, a TP system ensures that transactions are atomic, \nisolated, and durable, whether or not they are programmed to preserve consistency. Thus, strictly speaking, the \nACID test for transaction systems is a bit too strong, because the TP system does its part for the C in ACID \nonly by guaranteeing AID. It’s the application programmer’s responsibility to ensure the transaction program \npreserves consistency. \n There are consistency issues that reach out past the TP system and into the physical world that the TP \napplication describes. An example is the constraint that the number of physical items in inventory equals the \nnumber of items on the warehouse shelf. This constraint depends on actions in the physical world, such as cor-\nrectly reporting the restocking and shipment of items in the warehouse. Ultimately, this is what the enterprise \nregards as consistency. \n Isolation \n The third property of a transaction is called  isolation . We say that a set of transactions is isolated if the effect \nof the system running them is the same as if the system ran them one at a time. The technical deﬁ nition of iso-\nlation is serializability. An execution is  serializable (meaning isolated) if its effect is the same as running the \ntransactions serially, one after the next, in sequence, with no overlap in executing any two of them. This has \nthe same effect as running the transactions one at a time. \n A classic example of a non-isolated  execution is a banking system, where two transactions each try to with-\ndraw the last $100 in an account. If both transactions read the account balance before either of them updates it, \n1.3 Atomicity, Consistency, Isolation, and Durability  13\n",
      "content_length": 3785,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 33,
      "content": "14  CHAPTER 1 Introduction\n then both transactions will determine there’s enough money to satisfy their requests, and both will withdraw the \nlast $100. Clearly, this is the wrong result. Moreover, it isn’t a serializable result. In a serial execution, only the \nﬁ rst transaction to execute would be able to withdraw the last $100. The second one would ﬁ nd an empty account. \n Notice that isolation is different from atomicity. In the example, both transactions executed completely, so \nthey were atomic. However, they were not isolated and therefore produced undesirable behavior. \n If the execution is serializable, then from the point of view of an end-user who submits a request to run a \ntransaction, the system looks like a standalone system that’s running that transaction all by itself. Between the \ntime he or she runs two transactions, other transactions from other users may run. But during the period that the \nsystem is processing that one user’s transaction, the user has the illusion that the system is doing no other work. \nThis is only an illusion. It’s too inefﬁ cient for the system to actually run transactions serially, because there is a \nlot of internal parallelism in the system that must be exploited by running transactions concurrently. \n If each transaction preserves consistency, then any serial execution (i.e., sequence) of such transactions pre-\nserves consistency. Since each serializable execution is equivalent to a serial execution, a serializable execution \nof the transactions will preserve database consistency too. It is the combination of transaction consistency and \nisolation that ensures that the execution of a set of transactions preserves database consistency. \n The database typically sets locks on data accessed by each transaction. The effect of setting the locks is to \nmake the execution appear to be serial. In fact, internally, the system is running transactions in parallel, but \nthrough this locking mechanism the system gives the illusion that the transactions are running serially, one after \nthe next. In Chapter 6, we will describe those mechanisms in more detail and present the rather subtle argument \nwhy locking actually produces serializable executions. \n A common misconception is that serializability isn’t important because the database system will maintain \nconsistency by enforcing integrity constraints. However, as we saw in the previous section on consistency, there \nare many consistency constraints that database systems can’t enforce. Moreover, sometimes users don’t tell the \ndatabase system to enforce certain constraints because they degrade performance. The last line of defense is \nthat the transaction program itself maintains consistency and that the system guarantees serializability. \n Durability \n The fourth property of a transaction is durability.  Durability means that when a transaction completes execut-\ning, all its updates are stored in  stable storage ; that is, storage that will survive the failure of power or the \noperating system. Today, stable storage (also called  nonvolatile or  persistent storage ) typically consists of \nmagnetic disk drives, though solid-state disks that use ﬂ ash memory are making inroads as a viable alternative. \nEven if the transaction program fails, or the operating system fails, once the transaction has committed, its \nresults are durably stored on stable storage and can be found there after the system recovers from the failure. \n Durability is important because each transaction usually is providing a service to the user that amounts \nto a contract between the user and the enterprise that is providing the service. For example, if you’re moving \nmoney from one account to another, once you get a reply from the transaction saying that it executed, you \nexpect that the result is permanent. It’s a legal agreement between the user and the system that the money has \nbeen moved between these two accounts. So it’s essential that the transaction actually makes sure that the \nupdates are stored on some stable storage device, to ensure that the updates cannot possibly be lost after the \ntransaction ﬁ nishes executing. Moreover, the durability of the result must be maintained for a long period, until \nit is explicitly overwritten or deleted by a later transaction. For example, even if a checking account is unused \nfor several years, the owner expects to ﬁ nd her money there the next time she accesses it. \n The durability property usually is obtained by having the TP system append a copy of all the transaction’s \nupdates to a log ﬁ le while the transaction program is running. When the transaction program issues the com-\nmit operation, the system ﬁ rst ensures that all the records written to the log ﬁ le are out on stable storage, and then \n",
      "content_length": 4789,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 34,
      "content": " returns to the transaction program, indicating that the transaction has indeed committed and that the results are \ndurable. The updates may be written to the database right away, or they may be written a little later. However, if the \nsystem fails after the transaction commits and before the updates go to the database, then after the system recovers \nfrom the failure it must repair the database. To do this, it reads the log and checks that each update by a commit-\nted transaction actually made it to the database. If not, it reapplies the update to the database. When this recovery \nactivity is complete, the system resumes normal operation. Thus, after the system recovers, any new transaction \nwill read a database state that includes all the updates of transactions that committed before the failure (as well as \nthose that committed after the recovery). We describe log-based recovery algorithms in Chapter 7. \n 1.4  TWO-PHASE COMMIT \n When a transaction updates data on two or more database systems, we still have to ensure the atomicity property, \nnamely, that either both database systems durably install the updates or neither does. This is challenging, because \nthe database systems can independently fail and recover. This is certainly a problem when the database systems \nreside on different nodes of a distributed system. But it can even be a problem on a single machine if the database \nsystems run as server processes with private storage since the processes can fail independently. The solution is a \nprotocol called  two-phase commit ( 2PC ), which is executed by a module called the  transaction manager . \n The crux of the problem is that a transaction can commit its updates on one database system, but a second \ndatabase system can fail before the transaction commits there too. In this case, when the failed system recov-\ners, it must be able to commit the transaction. To commit the transaction, the recovering system must have a \ncopy of the transaction’s updates that executed there. Since a system can lose the contents of main memory \nwhen it fails, it must store a durable copy of the transaction’s updates before it fails, so it will have them after \nit recovers. This line of reasoning leads to the essence of two-phase commit: Each database system accessed \nby a transaction must durably store its portion of the transaction’s updates before the transaction commits any-\nwhere. That way, if a system  S fails after the transaction commits at another system  S \u0003 but before the transac-\ntion commits at  S , then the transaction can commit at  S after  S recovers (see  Figure 1.7 ). \nNew York System\nUpdate X\nCommit\na.  Without two-phase commit.  The \n  transaction updates X and Y, but\n   the failure causes the update to \n   Y to be lost.\nb.  With two-phase commit.  The London\n   system durably saved the update to Y,\n   so it can commit after it recovers.\nLondon System\nUpdate Y\nSystem fails\n. . .\nSystem recovers\nThe system lost the update to\nY when it failed, so it can’t\ncommit the transaction after\nit recovers.\nSince the system saved the\nupdate to disk before it failed,\nit can commit the transaction\nafter it recovers.\nNew York System\nUpdate X\nWrite X to disk\nCommit\nLondon System\nUpdate Y\nWrite Y to disk\nSystem fails\n. . .\nSystem recovers\n FIGURE 1.7 \n How Two-Phase Commit Ensures Atomicity. With two-phase commit, each system durably stores its updates before the \ntransaction commits, so it can commit the transaction when it recovers. \n1.4 Two-Phase Commit  15\n",
      "content_length": 3513,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 35,
      "content": "16  CHAPTER 1 Introduction\n To understand two-phase commit, it helps to visualize the overall architecture in which the transaction \nmanager operates. The standard model, shown in  Figure 1.8 , was introduced by IBM’s CICS and popularized \nby Oracle’s Tuxedo and X/Open (now part of The Open Group, see Chapter 10). In this model, the transaction \nmanager talks to applications, resource managers, and other transaction managers. The concept of  “ resource ” \nincludes databases, queues, ﬁ les, messages, and other shared objects that can be accessed within a transaction. \nEach resource manager offers operations that must execute only if the transaction that called the operations \ncommits. \n The transaction manager processes the basic transaction operations for applications: Start, Commit, and \nAbort. An application calls Start to begin executing a new transaction. It calls Commit to ask the transaction \nmanager to commit the transaction. It calls Abort to tell the transaction manager to abort the transaction. \n The transaction manager is primarily a bookkeeper that keeps track of transactions in order to ensure ato-\nmicity when more than one resource is involved. Typically, there’s one transaction manager on each node of a \ndistributed computer system. When an application issues a Start operation, the transaction manager dispenses a \nunique ID for the transaction called a  transaction identiﬁ er . During the execution of the transaction, it keeps \ntrack of all the resource managers that the transaction accesses. This requires some cooperation with the appli-\ncation, resource managers, and communication system. Whenever the transaction accesses a new resource \nmanager, somebody has to tell the transaction manager. This is important because when it comes time to com-\nmit the transaction, the transaction manager has to know all the resource managers to talk to in order to execute \nthe two-phase commit protocol. \n When a transaction program ﬁ nishes execution and issues the commit operation, that commit operation \ngoes to the transaction manager, which processes the operation by executing the two-phase commit protocol. \nSimilarly, if the transaction manager receives an abort operation, it tells the resource managers to undo all the \ntransaction’s updates; that is, to abort the transaction at each resource manager. Thus, each resource manager \nmust understand the concept of transaction, in the sense that it undoes or permanently installs the transaction’s \nupdates depending on whether the transaction aborts or commits. \n When running two-phase commit, the transaction manager sends out two rounds of messages — one for each \nphase of the commitment activity. In the ﬁ rst round of messages it tells all the resource managers to prepare to \ncommit by writing a copy of the results of the transaction to stable storage, but not actually to commit the trans-\naction. At this point, the resource managers are said to be  prepared to commit . When the transaction manager \ngets acknowledgments back from all the resource managers, it knows that the whole transaction has been pre-\npared. That is, it knows that all resource managers stored a durable copy of the transaction’s updates but none \nof them have committed the transaction. So it sends a second round of messages to tell the resource managers \nto actually commit.  Figure 1.9 gives an example execution of two-phase commit with two resource managers \ninvolved. \nApplication Program\nResource Manager\nTransaction Manager\n FIGURE 1.8 \n X/Open Transaction Model (XA). The transaction manager processes Start, Commit, and Abort. It talks to resource \nmanagers to run two-phase commit. \n",
      "content_length": 3672,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 36,
      "content": " Two -phase commit avoids the problem in  Figure 1.7(a) because all resource managers have a durable copy \nof the transaction’s updates before any of them commit. Therefore, even if a system fails during the commitment \nactivity, as the London system did in the ﬁ gure, it can commit the transaction after it recovers. However, to make \nthis all work, the protocol must handle every possible failure and recovery scenario. For example, in  Figure \n1.7(b) , it must tell the London system to commit the transaction. The details of how two-phase commit handles \nall these scenarios is described in Chapter 8. \n Two -phase commit is required whenever a transaction accesses two or more resource managers. Thus, one \nkey question that designers of TP applications must answer is whether or not to distribute their transaction \nprograms among multiple resources. Using two-phase commit adds overhead (due to two-phase commit mes-\nsages), but the option to distribute can provide better scalability (adding more systems to increase capacity) \nand availability (since one system can fail while others remain operational). \n 1.5  TRANSACTION PROCESSING PERFORMANCE \n Performance is a critical aspect of TP systems. No one likes waiting more than a few seconds for an automated \nteller machine to dispense cash or for a hotel web site to accept a reservation request. So response time to end-users \nis one important measure of TP system performance. Companies that rely on TP systems, such as banks, airlines, \nand commercial web sites, also want to get the most transaction throughput for the money they invest in a TP sys-\ntem. They also care about system scalability; that is, how much they can grow their system as their business grows. \n It ’s very challenging to conﬁ gure a TP system to meet response time and throughput requirements at mini-\nmum cost. It requires choosing the number of systems, how much storage capacity they’ll have, which process-\ning and database functions are assigned to each system, and how the systems are connected to displays and to \neach other. Even if you know the performance of the component products being assembled, it’s hard to predict \nhow the overall system will perform. Therefore, users and vendors implement benchmarks to obtain guidance \non how to conﬁ gure systems and to compare competing products. \n Vendor benchmarks are deﬁ ned by an independent consortium called the Transaction Processing Performance \nCouncil (TPC;  www.tpc.org ). The benchmarks enable apples-to-apples comparisons of different vendors ’ hardware \nResource Manager\nin New York\nResource Manager\nin London\nResource Manager\nin New York\nResource Manager\nin London\nTransaction Manager\n1. Prepare\n2. I am prepared\n1. Prepare\n2. I am prepared\n3. Commit\n4. OK\n3. Commit\n4. OK\nTransaction Manager\nPhase one\nPhase two\n FIGURE 1.9 \n The Two-Phase Commit Protocol. In Phase One, every resource manager durably saves the transaction’s updates before \nreplying  “ I am Prepared. ” Thus, all resource managers have durably stored the transaction’s updates before any of \nthem commits in phase two. \n1.5 Transaction Processing Performance  17\n",
      "content_length": 3141,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 37,
      "content": "18  CHAPTER 1 Introduction\n and software products. Each TPC benchmark deﬁ nes standard transaction programs and characterizes a system’s \nperformance by the throughput that the system can process under certain workload conditions, database size, \nresponse time guarantees, and so on. Published results must be accompanied by a  full disclosure report , which \nallows other vendors to review benchmark compliance and gives users more detailed performance information \nbeyond the summary performance measures. \n The benchmarks use two main measures of a system’s performance, throughput, and cost-per-through-\nput-unit. Throughput is the maximum throughput it can attain, measured in  transactions per second (tps) or \n transactions per minute (tpm) . Each benchmark deﬁ nes a response time requirement for each transaction \ntype (typically 1 – 5 seconds). The throughput can be measured only when 90% of the transactions meet their \nresponse time requirements and when the average of all transaction response times is less than their response \ntime requirement. The latter ensures that all transactions execute within an acceptable period of time. \n As an aside, Internet web sites usually measure 90% and 99% response times. Even if the average perfor-\nmance is fast, it’s bad if one in a hundred transactions is too slow. Since customers often run multiple trans-\nactions, that translates into several percent of customers receiving poor service. Many such customers don’t \nreturn. \n The benchmarks ’ cost-per-throughput-unit is measured in dollars per tps or tpm. The cost is calculated as \nthe list purchase price of the hardware and software, plus three years ’ vendor-supplied maintenance on that \nhardware and software (called the  cost of ownership ). \n The deﬁ nitions of TPC benchmarks are worth understanding to enable one to interpret TPC performance \nreports. Each of these reports, published on the TPC web site, is the result of a system benchmark evaluation \nperformed by a system vendor and subsequently validated by an independent auditor. Although their main pur-\npose is to allow customers to compare TP system products, these reports are also worth browsing for educa-\ntional reasons, to give one a feel for the performance range of state-of-the-art systems. They are also useful as \nguidance for the design and presentation of a custom benchmark study for a particular user application. \n The TPC-A and TPC-B Benchmarks \n The ﬁ rst two benchmarks promoted by TPC, called TPC-A and TPC-B, model an ATM application that debits \nor credits a checking account. When TPC-A/B were introduced, around 1989, they were carefully crafted to \nexercise the main bottlenecks customers were experiencing in TP systems. The benchmark was so successful \nin encouraging vendors to eliminate these bottlenecks that within a few years nearly all database systems per-\nformed very well on TPC-A/B. Therefore, the benchmarks were retired and replaced by TPC-C in 1995. Still, \nit’s instructive to look at the bottlenecks the benchmarks were designed to exercise, since these bottlenecks can \nstill arise today on a poorly designed system or application. \n Both benchmarks run the same transaction program. The only difference is that TPC-A includes terminals \nand a network in the overall system, while TPC-B does not. In both cases, the transaction program performs \nthe sequence of operations shown in  Figure 1.10 (except that TPC-B does not perform the read/write terminal \noperations). \n In TPC-A/B, the database consists of: \n ■  Account records, one record for each customer’s account (total of 100,000 accounts) \n ■  A teller record for each teller, which stores the amount of money in the teller’s cash drawer (total of \n10 tellers) \n ■  One record for each bank branch (one branch minimum), which contains the sum of all the accounts at \nthat branch \n ■  A history ﬁ le, which records a description of each transaction that actually executes \n",
      "content_length": 3953,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 38,
      "content": " The transaction reads a 100-byte input message, including the account number and amount of money to \nwithdraw or deposit. The transaction uses that input to ﬁ nd the account record and update it appropriately. \nIt updates the history ﬁ le to indicate that this transaction has executed. It updates the teller and bank branch \nrecords to indicate the amount of money deposited or withdrawn at that teller and bank branch, respectively. \nFinally, for TPC-A, it sends a message back to the display device to conﬁ rm the completion of the transaction. \n The benchmark exercises several potential bottlenecks on a TP system: \n ■  There’s a large number of account records. The system must have 100,000 account records for each trans-\naction per second it can perform. To randomly access so many records, the database must be indexed. \n ■  The end of the history ﬁ le can be a bottleneck, because every transaction has to write to it and therefore \nto lock and synchronize against it. This synchronization can delay transactions. \n ■  Similarly, the branch record can be a bottleneck, because all of the tellers at each branch are reading and \nwriting it. However, TPC-A/B minimizes this effect by requiring a teller to execute a transaction only \nevery 10 seconds. \n Given a ﬁ xed conﬁ guration, the performance and price/performance of any TP application depends on the \namount of computer resources needed to execute it: the number of processor instructions, I/Os to stable storage, \nand communications messages. Thus, an important step in understanding the performance of any TP application \nis to count the resources required for each transaction. In TPC-A/B, for each transaction a high performance \nimplementation uses a few hundred thousand instructions, two or three I/Os to stable storage, and two interac-\ntions with the display. When running these benchmarks, a typical system spends more than half of the processor \ninstructions inside the database system and maybe another third of the instructions in message communications \nbetween the parts of the application. Only a small fraction of the processor directly executes the transaction pro-\ngram. This isn’t very surprising, because the transaction program mostly just sends messages and initiates data-\nbase operations. The transaction program itself does very little, which is typical of many TP applications. \n The TPC-C Benchmark \n The TPC-C benchmark was introduced in 1992. It is based on an order-entry application for a wholesale sup-\nplier. Compared to TPC-A/B, it includes a wider variety of transactions, some  “ heavy weight ” transactions \n(which do a lot of work), and a more complex database. \n The database centers around a  warehouse , which tracks the  stock of  items that it  supplies to  customers \nwithin a sales  district , and tracks those customers ’  orders , which consist of  order-lines . The database size is \nproportional to the number of warehouses (see  Table 1.1 ). \nStart\n  Read message from terminal (100 bytes)\n  Read and write account record (random access)\n  Write history record (sequential access)\n  Read and write teller record (random access)\n  Read and write branch record (random access)\n  Write message to terminal (200 bytes)\nCommit       \n FIGURE 1.10 \n TPC-A/B Transaction Program. The program models a debit/credit transaction for a bank. \n1.5 Transaction Processing Performance  19\n",
      "content_length": 3393,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 39,
      "content": "20  CHAPTER 1 Introduction\n There are ﬁ ve types of transactions: \n ■  New-Order: To enter a new order, ﬁ rst retrieve the records describing the given warehouse, customer, \nand district, and then update the district (increment the next available order number). Insert a record in \nthe Order and New-Order tables. For each of the 5 to 15 (average 10) items ordered, retrieve the item \nrecord (abort if it doesn’t exist), retrieve and update the stock record, and insert an order-line record. \n ■  Payment: To enter a payment, ﬁ rst retrieve and update the records describing the given warehouse, dis-\ntrict, and customer, and then insert a history record. If the customer is identiﬁ ed by name, rather than id \nnumber, then additional customer records (average of two) must be retrieved to ﬁ nd the right customer. \n ■  Order-Status: To determine the status of a given customer’s latest order, retrieve the given customer \nrecord (or records, if identiﬁ ed by name, as in Payment), and retrieve the customer’s latest order and cor-\nresponding order-lines. \n ■  Delivery: To process a new order for each of a warehouse’s 10 districts, get the oldest new-order record \nin each district, delete it, retrieve and update the corresponding customer record, order record, and the \norder’s corresponding order-line records. This can be done as one transaction or 10 transactions. \n ■  Stock-Level: To determine, in a warehouse’s district, the number of recently sold items whose stock \nlevel is below a given threshold, retrieve the record describing the given district (which has the next \norder number). Retrieve order lines for the previous 20 orders in that district, and for each item ordered, \ndetermine if the given threshold exceeds the amount in stock. \n The transaction rate metric is the number of New-Order transactions per minute, denoted  tpmC , given that \nall the other constraints are met. The New-Order, Payment, and Order-Status transactions have a response time \nrequirement of ﬁ ve seconds. The Stock-Level transaction has a response time of 20 seconds and has relaxed \nconsistency requirements. The Delivery transaction runs as a periodic batch. The workload requires executing \nan equal number of New-Order and Payment transactions, and one Order-Status, Delivery, and Stock-Level \ntransaction for every 10 New-Orders. \n Table 1.1  Database for the TPC-C Benchmark. The database consists of the tables in the left column, which \nsupport an order-entry application \n Table Name \n Number of Rows per \nWarehouse \n Bytes-per-Row \n Size of Table (in bytes) \nper Warehouse \n Warehouse \n  1 \n 89 \n .089  K \n District \n 10 \n 95 \n .95  K \n Customer \n 30  K \n 655 \n 19.65  K \n History \n 30  K \n 46 \n 1.38  K \n Order \n 30  K \n 24 \n 720  K \n New-Order \n  9  K \n 8 \n 72  K \n Order-Line \n 300  K \n 54 \n 16.2  M \n Stock \n 100  K \n 306 \n 306  M \n Item \n 100  K \n 82 \n 8.2  M \n",
      "content_length": 2875,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 40,
      "content": " The TPC-C workload is many times heavier per transaction than TPC-A/B and exhibits higher contention \nfor shared data. Moreover, it exercises a wider variety of performance-sensitive functions, such as deferred \ntransaction execution, access via secondary keys, and transaction aborts. It is regarded as a more realistic \nworkload than TPC-A/B, which is why it replaced TPC-A/B as the standard TP systems benchmark. \n The TPC-E Benchmark \n The TPC-E benchmark was introduced in 2007. Compared to TPC-C, it represents larger and more complex \ndatabases and transaction workloads that are more representative of current TP applications. And it uses a stor-\nage conﬁ guration that is less expensive to test and run. It is based on a stock trading application for a broker-\nage ﬁ rm where transactions are related to stock trades, customer inquiries, activity feeds from markets, and \nmarket analysis by brokers. Unlike previous benchmarks, TPC-E does not include transactional middleware \ncomponents and solely measures database performance. \n TPC -E includes 10 transaction types, summarized in  Table 1.2 , which are a mix of read-only and read-\nwrite transactions. For each type, the table shows the percentage of transactions of that type and the number of \ndatabase tables it accesses, which give a feeling for the execution cost of the type. \n There are various parameters that introduce variation into the workload. For example, trade requests are \nsplit 50-50 between buy and sell and 60-40 between market order and limit order. In addition, customers are \nassigned to one of three tiers, depending on how often they trade securities — the higher the tier, the more \naccounts per customer and trades per customer. \n The database schema has 33 tables divided into four sets: market data (11 tables), customer data (9 tables), \nbroker data (9 tables), and static reference data (4 tables). Most tables have fewer than six columns and less \nthan 100 bytes per row. At the extremes, the Customer table has 23 columns, and several tables store text \ninformation with hundreds of bytes per row (or even more for the News Item table). \n Table 1.2  TPC-E Transaction Types \n Transaction \nType \n Percent of \nTransactions \n Database \nTables \nAccessed \n Description \n Trade Order \n 10.1% \n 17 \n Buy or sell a security \n Trade Result \n 10% \n 15 \n Complete the execution of a buy or sell order \n Trade Status \n 19% \n 6 \n Get the status of an order \n Trade Update \n 2% \n 6 \n Make corrections to a set of trades \n Customer Position \n 13% \n 7 \n Get the value of a customer’s assets \n Market Feed \n 1% \n 2 \n Process an update of current market activity (e.g., ticker tape) \n Market Watch \n 18% \n 4 \n Track market trends (e.g., for a customer’s  “ watch list ” ) \n Security Detail \n 14% \n 12 \n Get a detailed data about a security \n Trade Lookup \n 8% \n 6 \n Get information about a set of trades \n Broker Volume \n 4.9% \n 6 \n Get a summary of the volume and value of pending orders of a \nset of brokers \n1.5 Transaction Processing Performance  21\n",
      "content_length": 3033,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 41,
      "content": "22  CHAPTER 1 Introduction\n A driver program generates the transactions and their inputs, submits them to a test system, and measures \nthe rate of completed transactions. The result is the  measured transactions per second (tpsE), which is the \nnumber of Trade Result transactions executed per second, given the mix of the other transaction types. Each \ntransaction type has a response time limit of one to three seconds, depending on transaction type. In contrast to \nTPC-C, application functions related to front-end programs are excluded. Thus, the results measure the server-\nside database management system. Like previous TPC benchmarks, TPC-E includes a measure for the cost per \ntransaction per second ($/tpsE). \n TPC -E provides data generation code to initialize the database with the result of 300 days of initial trading, \ndaily market closing price information for ﬁ ve years, and quarterly company report data for ﬁ ve years. Beyond \nthat, the database size scales up as a function of the  nominal tpsE, which is the transaction rate the benchmark \nsponsor is aiming for . The measured tpsE must be within 80 to 102% of the nominal tpsE. The database must \nhave 500 customers for each nominal tpsE. Other database tables scale relative to the number of customer \nrows. For example, for each 1000 Customers, there must be 685 Securities and 500 Companies. Some tables \ninclude a row describing each trade and therefore grow quite large for a given run. \n Compared to TPC-C, TPC-E is a more complex workload. It makes heavier use of SQL database features, \nsuch as referential integrity and transaction isolation levels (to be discussed in Chapter 6). It uses a more com-\nplex SQL schema. Transactions execute more complex SQL statements and several of them have to make mul-\ntiple calls to the database, which cannot be batched in one round-trip. And there is no trivial partitioning of the \ndatabase that will enable scalability (to be discussed in Section 2.6). Despite all this newly introduced complex-\nity, the benchmark generates a much lower I/O load than TPC-C for a comparable transaction rate. This makes \nthe benchmark cheaper to run, which is important to vendors when they run high-end scalability tests where \nlarge machine conﬁ gurations are needed. \n In addition to its TP benchmarks, the TPC publishes a widely used benchmark for decision support systems, \nTPC-H. It also periodically considers new TP benchmark proposals. Consult the TPC web site,  www.tpc.org , \nfor current details. \n 1.6  AVAILABILITY \n Availability is the fraction of time a TP system is up and running and able to do useful work — that is, it isn’t \ndown due to hardware or software failures, operator errors, preventative maintenance, power failures, or the \nlike. Availability is an important measure of the capability of a TP system because the TP application usually \nis offering a service that’s  “ mission critical, ” one that’s essential to the operation of the enterprise, such as air-\nline reservations, managing checking accounts in a bank, processing stock transactions in a stock exchange, or \noffering a retail storefront on the Internet. Obviously, if this type of system is unavailable, the business stops \noperating. Therefore, the system  must operate nearly all the time. \n Just how highly available does a system have to be? We see from the table in  Figure 1.11 that if the system \nis available 96% of the time, that means it’s down nearly an hour a day. That’s too much time for many types \nof businesses, which would consider 96% availability to be unacceptable. \n An availability of 99% means that the system is down about 100 minutes per week (i.e., 7 days/week  \u0004  24 \nhours/day  \u0004  60 minutes/hour  \u0004  1/100). Many TP applications would ﬁ nd this unacceptable if it came in one \n100-minute period of unavailability. It might be tolerable, provided that it comes in short outages of just a few \nminutes at a time. But in many cases, even this may not be tolerable, for example in the operation of a stock \nexchange where short periods of downtime can produce big ﬁ nancial losses. \n An availability of 99.9% means that the system is down for about an hour per month, or under two min-\nutes per day. Further, 99.999% availability means that the system is down ﬁ ve minutes a year. That number \n",
      "content_length": 4320,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 42,
      "content": " may seem incredibly ambitious, but it  is attainable; telephone systems typically have that level of availability. \nPeople sometimes talk about availability in terms of the number of 9s that are attained; for example,  “ ﬁ ve 9s ” \nmeans 99.999% available. \n Some systems need to operate for only part of the day, such as 9  AM to 5  PM on weekdays. In that case, avail-\nability usually is measured relative to the hours when the system is expected to be operational. Thus, 99.9% avail-\nability means that it is down at most 2.4 minutes per week (i.e., 40 hours/week  \u0004  60 minutes/hour  \u0004  1/1000). \n Today ’s TP system customers typically expect availability levels of at least 99%, although it certainly depends \non how much money they’re willing to spend. Generally, attaining high availability requires attention to four \nfactors: \n ■  The environment — making the physical environment more robust to avoid failures of power, communi-\ncations, air conditioning, and the like \n ■  System management — avoiding failures due to operational errors by system managers and vendors ’ ﬁ eld \nservice \n ■  Hardware — having redundant hardware, so that if some component fails, the system can immediately \nand automatically replace it with another component that’s ready to take over \n ■  Software — improving the reliability of software and ensuring it can automatically and quickly recover \nafter a failure \n This book is about software, and regrettably, of the four factors, software is the major contributor to avail-\nability problems. Software failures can be divided into three categories: application failures, database system \nfailures, and operating system failures. \n Because we’re using transactions, when an application fails, any uncommitted transaction it was executing \naborts automatically. Its updates are backed out, because of the atomicity property. There’s really nothing that \nthe system has to do other than re-execute  the transaction after the application is running again. \n When the database system fails, all the uncommitted transactions that were accessing the database system \nat that time have to abort, because their updates may be lost during the database system failure. A system man-\nagement component of the operating system, database system, or transactional middleware has to detect the \nfailure of the database system and tell the database system to reinitialize itself. During the reinitialization pro-\ncess, the database system backs out the updates of all the transactions that were active at the time of the failure, \nthereby getting the database into a clean state, where it contains the results only of committed transactions. \n A failure of the operating system requires it to reboot. All programs, applications, and database systems exe-\ncuting at the time of failure are now dead. Everything has to be reinitialized after the operating system reboots. \nOn an ordinary computer system all this normally takes between several minutes and an hour, depending on \nhow big the system is, how many transactions were active at the time of failure, how long it takes to back out the \nuncommitted transactions, how efﬁ cient the initialization program is, and so on. Very high availability systems, \nsuch as those intended to be available in excess of 99%, typically are designed for very fast recovery. Even when \nDowntime\nAvailability (%)\n1 hour/day\n95.8\n1 hour/week\n99.41\n1 hour/month\n99.86\n1 hour/year\n99.9886\n1 hour/20 years\n99.99942\n FIGURE 1.11 \n Downtime at Different Availability Level. The number of nines after the decimal point is of practical signiﬁ cance. \n1.6 Availability  23\n",
      "content_length": 3626,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 43,
      "content": "24  CHAPTER 1 Introduction\n they fail, they are down only for a very short time. They usually use some form of replicated processing to get \nthis fast recovery. When one component fails, they quickly delegate processing work to a copy of the component \nthat is ready and waiting to pick up the load. \n The transaction abstraction helps the programmer quite a bit in attaining high availability, because the sys-\ntem is able to recover into a clean state by aborting transactions. And it can continue from where it left off by \nrerunning transactions that aborted as a result of the failure. Without the transaction abstraction, the recovery \nprogram would have to be application-speciﬁ c. It would have to analyze the state of the database at the time \nof the failure to ﬁ gure out what work to undo and what to rerun. We discuss high availability issues and tech-\nniques in more detail in Chapter 7, and replication technology in Chapter 9. \n In addition to application, database system, and operating system failures, operator errors are a major con-\ntributor to unplanned downtime. Many of these errors can be attributed to system management software that is \nhard to understand and use. If the software is difﬁ cult to tune, upgrade, or operate, then operators make mis-\ntakes. The ideal system management software is fully automated and requires no human intervention for such \nroutine activities. \n 1.7  STYLES OF SYSTEMS \n We ’ve been talking about TP as a style of  application , one that runs short transaction programs that access \na shared database. TP is also a style of  system , a way of conﬁ guring software components to do the type of \nwork required by a TP application. It’s useful to compare this style of system with other styles that you may be \nfamiliar with, to see where the differences are and why TP systems are constructed differently from the others. \nThere are several other kinds of systems that we can look at here: \n ■  Batch processing systems, where you submit a job and later receive output in the form of a ﬁ le \n ■  Real-time systems, where you submit requests to do a small amount of work that has to be done before \nsome very early deadline \n ■  Data warehouse systems, where reporting programs and  ad hoc queries access data that is integrated \nfrom multiple data sources \n Designing a system to perform one of these types of processing is called  system engineering . Rather than \nengineering a speciﬁ c component, such as an operating system or a database system, you engineer an inte-\ngrated system by combining different kinds of components to perform a certain type of work. Often, systems \nare engineered to handle multiple styles, but for the purposes of comparing and contrasting the different styles, \nwe’ll discuss them as if each type of system were running in a separately engineered environment. Let’s look \nat requirements for each of these styles of computing and see how they compare to a TP system. \n Batch Processing Systems \n A batch is a set of requests that are processed together, often long after the requests were submitted. Data \nprocessing systems of the 1960s and early 1970s were primarily batch processing systems. Today, batch work-\nloads are still with us. But instead of running them on systems dedicated for batch processing, they often exe-\ncute on systems that also run a TP workload. TP systems can execute the batches during nonpeak periods, \nsince the batch workload has ﬂ exible response-time requirements. To make the comparison between TP and \nbatch clear, we will compare a TP system running a pure TP workload against a classical batch system running \na pure batch workload, even though mixtures of the two are now commonplace. \n",
      "content_length": 3713,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 44,
      "content": " A batch processing system executes each batch as a sequence of transactions, one transaction at a time. \nSince transactions execute serially there’s no problem with serializability. By contrast, in a TP system many \ntransactions can execute at the same time, and so the system has extra work to ensure serializability. \n For example, computing the value of a stock market portfolio could be done as a batch application, running \nonce a day after the close of ﬁ nancial markets. Computing a monthly bill for telephone customers could be a \nbatch application, running daily for a different subset of the customer base each day. Generating tax reporting \ndocuments could be a batch application executed once per quarter or once per year. \n The main performance measure of batch processing is throughput, that is, the amount of work done per unit \nof time. Response time is less important. A batch could take minutes, hours, or even days to execute. By con-\ntrast, TP systems have important response time requirements, because generally there’s a user waiting at a dis-\nplay for the transaction’s output. \n A classical batch processing application takes its input as a record-oriented ﬁ le whose records represent \na sequence of request messages. Its output is also normally stored in a ﬁ le. By contrast, TP systems typically \nhave large networks of display devices for capturing requests and displaying results. \n Batch processing can be optimized by ordering the input requests consistently with the order of the data in \nthe database. For example, if the requests correspond to giving airline mileage credit for recent ﬂ ights to mileage \naward customers, the records of customer ﬂ ights can be ordered by mileage award account number. That way, \nit’s easy and efﬁ cient to process the records by a merge procedure that reads the mileage award account database \nin account number order. By contrast, TP requests come in a random order. Because of the fast response time \nrequirement, the system can’t spend time sorting the input in an order consistent with the database. It has to be \nable to access the data randomly, in the order in which the data is requested. \n Classical batch processing takes the request message ﬁ le and existing database ﬁ le(s) as input and produces \na new master output database as a result of running transactions for the requests. If the batch processing pro-\ngram should fail, there’s no harm done because the input ﬁ le and input database are unmodiﬁ ed — simply throw \nout the output ﬁ le and run the batch program again. By contrast, a TP system updates its database on-line as \nrequests arrive. So a failure may leave the database in an inconsistent state, because it contains the results of \nuncompleted transactions. This atomicity problem for transactions in a TP environment doesn’t exist in a batch \nenvironment. \n Finally , in batch the load on the system is ﬁ xed and predictable, so the system can be engineered for that load. \nFor example, you can schedule the system to run the batch at a given time and set aside sufﬁ cient capacity to do \nit, because you know exactly what the load is going to be. By contrast, a TP load generally varies during the day. \nThere are peak periods when there’s a lot of activity and slow periods when there’s very little. The system has to \nbe sized to handle the peak load and also designed to make use of extra capacity during slack periods. \n Real-Time Systems \n TP systems are similar to real-time systems, such as a system collecting input from a satellite or controlling \na factory’s shop ﬂ oor equipment. TP essentially is a kind of real-time system, with a real-time response time \ndemand of 1 to 2 seconds. It responds to a real-world process consisting of end-users interacting with display \ndevices, which communicate with application programs accessing a shared database. So not surprisingly, there \nare many similarities between the two kinds of systems. \n Real -time systems and TP systems both have predictable loads with periodic peaks. Real-time systems usu-\nally emphasize gathering input rather than processing it, whereas TP systems generally do both. \n Due to the variety of real-world processes they control, real-time systems generally have to deal with more \nspecialized devices than TP, such as laboratory equipment, factory shop ﬂ oor equipment, or sensors and con-\ntrol systems in an automobile or airplane. \n1.7 Styles of Systems  25\n",
      "content_length": 4440,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 45,
      "content": "26  CHAPTER 1 Introduction\n Real -time systems generally don’t need or use special mechanisms for atomicity and durability. They sim-\nply process the input as quickly as they can. If they lose some of that input, they ignore the loss and keep on \nrunning. To see why, consider the example of a system that collects input from a monitoring satellite. It’s not \ngood if the system misses some of the data coming in. But the system certainly can’t stop operating to go back \nto ﬁ x things up like a TP system would do — the data keeps coming in and the system must do its best to con-\ntinue processing it. By contrast, a TP environment can generally stop accepting input for a short time or can \nbuffer the input for awhile. If there is a failure, it can stop collecting input, run a recovery procedure, and then \nresume processing input. Thus, the fault-tolerance requirements between the two types of systems are rather \ndifferent. \n Real -time systems are generally not concerned with serializability. In most real-time applications, processing \nof input messages involves no access to shared data. Since the processing of two different inputs does not affect \neach other, even if they’re processed concurrently, they’ll behave like a serial execution. No special mechanisms, \nsuch as locking, are needed. When processing real-time inputs to shared data, the notion of serializability is as \nrelevant as it is to TP. However, in this case, real-time applications generally make direct use of low-level syn-\nchronization primitives for mutual exclusion, rather than relying on a general-purpose synchronization mecha-\nnism that is hidden behind the transaction abstraction. \n Data Warehouse Systems \n TP systems process the data in its raw state as it arrives.  Data warehouse systems integrate data from multiple \nsources into a database suitable for querying. \n For example, a distribution company decides each year how to allocate its marketing and advertising budget. \nIt uses a TP system to process sales orders that includes the type and value of each order. The customer database \ntells each customer’s location, annual revenue, and growth rate. The ﬁ nance database includes cost and income \ninformation, and tells which product lines are most proﬁ table. The company pulls data from these three data \nsources into a data warehouse. Business analysts can query the data warehouse to determine how best to allocate \npromotional resources. \n Data warehouse systems execute two kinds of workloads: a batch workload to extract data from the sources, \ncleaning the data to reconcile discrepancies between them, transforming the data into a common shape that’s \nconvenient for querying, and loading it into the warehouse; and queries against the warehouse, which can range \nfrom short interactive requests to complex analyses that generate large reports. Both of these workloads are \nquite different than TP, which consists of short updates and queries. Also unlike TP, a data warehouse’s content \ncan be somewhat out-of-date, since users are looking for trends that are not much affected by the very latest\nupdates. In fact, sometimes it’s important to run on a static database copy, so that the results of successive \nqueries are comparable. Running queries on a data warehouse rather than a TP database is also helpful for per-\nformance reasons, since data warehouse queries would slow down update transactions, a topic we’ll discuss in \nsome detail in Chapter 6. Our comparison of system styles so far is summarized in  Figure 1.12 . \n Other System Types \n Two other system types that are related to TP are timesharing and client-server. \n Timesharing \n In a timesharing system, a display device is connected to an operating system process, and within that pro-\ncess the user can invoke programs that interact frequently with the display. Before the widespread use of PCs, \nwhen timesharing systems were popular, TP systems often were confused with timesharing, because they both \n",
      "content_length": 3986,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 46,
      "content": " involve managing lots of display devices connected to a common server. But they’re really quite different in \nterms of load, performance requirements, and availability requirements: \n ■  A timesharing system has a highly unpredictable load, since users continually make different demands \non the system. By comparison, a TP load is very regular, running similar load patterns every day. \n ■  Timesharing systems have less stringent availability and atomicity requirements than TP systems. The \nTP concept of ACID execution doesn’t apply. \n ■  Timesharing applications are not mission-critical to the same degree as TP applications and therefore \nhave weaker availability requirements. \n ■  Timesharing system performance is measured in terms of system capacity, such as instructions per sec-\nond and number of on-line users. Unlike TP, there are no generally accepted benchmarks that accurately \nrepresent the behavior of a wide range of timesharing applications. \n Client-Server \n In a client-server system, a large number of personal computers communicate with shared servers on a local area \nnetwork. This kind of system is very similar to a TP environment, where a large number of display devices con-\nnect to shared servers that run transactions. In some sense, TP systems were the original client-server systems \nwith very simple desktop devices, namely, dumb terminals. As desktop devices have become more powerful, TP \nsystems and personal computer systems have been converging into a single type of computing environment with \ndifferent kinds of servers, such as ﬁ le servers, communication servers, and TP servers. \n There are many more system types than we have space to include here. Some examples are embedded systems, \ncomputer-aided design systems, data streaming systems, electronic switching systems, and trafﬁ c control systems. \nIsolation\nserializable, multi-\nprogrammed execution\nserial, uni-\nprogrammed\nexecution\nno transaction\nconcept\nno transaction\nconcept\nWorkload\nhigh variance\npredictable\npredictability\ndepends on the\napplication\npredictable loading,\nhigh variance queries\nPerformance\nmetric \nresponse time and\nthroughput  \nthroughput\nresponse time,\nthroughput, missed\ndeadlines\nthroughput for\nloading, response\ntime for queries\nInput\nnetwork of display\ndevices submitting\nrequests\nrecord-oriented file\nnetwork of devices\nsubmitting data and\noperations \nnetwork of display\ndevices submitting\nqueries\nData Access\nrandom access\naccesses sorted to be\nconsistent with\ndatabase order\nunconstrained\npossibly sorted\nfor loading,\nunconstrained for\nqueries\nRecovery\nafter failure, ensure\ndatabase has committed\nupdates and no others\nafter failure, rerun\nthe batch to produce\na new master file\napplication’s\nresponsibility\napplication’s\nresponsibility\nTransaction\nProcessing\nBatch\nReal-time\nData Warehouse\n FIGURE 1.12 \n Comparison of System Types. Transaction processing has different characteristics than the other styles, and therefore \nrequires systems that are specially engineered to the purpose. \n1.7 Styles of Systems  27\n",
      "content_length": 3048,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 47,
      "content": "28  CHAPTER 1 Introduction\n Why Engineer a TP System? \n Each system type that we looked at is designed for certain usage patterns. Although it is engineered for that \nusage pattern, it actually can be used in other ways. For example, people have used timesharing systems to run \nTP applications. These applications typically do not scale very well or use operating system resources very \nefﬁ ciently, but it can be done. For example, people have built special-purpose TP systems using real-time sys-\ntems, and batch systems to run on a timesharing system. \n TP has enough special requirements that it’s worth engineering the system for that purpose. The amount of \nmoney businesses spend on TP systems justiﬁ es the additional engineering work vendors do to tailor their sys-\ntem products for TP — for better performance, reliability, and ease-of-use. \n 1.8  TP SYSTEM CONFIGURATIONS \n When learning the principles of transaction processing, it is helpful to have a feel for the range of systems \nwhere these principles are applied. We already saw some examples in Section 1.5 on TP benchmarks. Although \nthose benchmark applications have limited functionality, they nevertheless are meant to be representative of \nthe kind of functionality that is implemented for complete practical applications. \n In any given price range, including the very high end, the capabilities of TP applications and systems con-\ntinually grow, in large part due to the steadily declining cost of computing and communication. These growing \ncapabilities enable businesses to increase the functionality of classical TP applications, such as travel reserva-\ntions and banking. In addition, every few years, these capabilities enable entirely new categories of businesses. \nIn the past decade, examples include large-scale Internet retailers and social networking web sites. \n There is no such thing as an average TP application or system. Rather, systems that implement TP applications \ncome in a wide range of sizes, from single servers to data centers with thousands of machines. And the applica-\ntions themselves exhibit a wide range of complexity, from a single database with few dozen transaction types to \nthousands of databases running hundreds of millions of lines of code. Therefore, whatever one might say about \ntypical TP installations will apply only to a small fraction of them and will likely be outdated within a few years. \n A low-end system could be a departmental application supporting a small number of users who perform \na common function. Such an application might run comfortably on a single server machine. For example, the \nsales and marketing team of a small company might use a TP application to capture sales orders, record cus-\ntomer responses to sales campaigns, alert sales people when product support agreements need to be renewed, \nand track the steps in resolving customer complaints. Even though the load on the system is rather light, the \napplication might require hundreds of transaction types to support many different business functions. \n By contrast, the workload of a large Internet service might require thousands of server machines. This is \ntypical for large-scale on-line shopping, ﬁ nancial services, travel services, multimedia services (e.g., sharing \nof music, photos, and videos), and social networking. To ensure the service is available 24 hours a day, 7 days \na week (a.k.a. 24  \u0004  7), it often is supported by multiple geographically distributed data centers. Thus if one \ndata center fails, others can pick up its load. \n Like hardware conﬁ guration, software conﬁ gurations cover a wide range. The system software used to \noperate a TP system may be proprietary or open source. It may use the latest system software products or \nones that were introduced decades ago. It may only include a SQL database system and web server, or it may \ninclude several layers of transactional middleware and specialized database software. \n The range of technical issues that need to be addressed is largely independent of the hardware or software \nconﬁ guration that is chosen. These issues include selecting a programming model; ensuring the ACID properties; \nand maximizing availability, scalability, manageability, and performance. These issues are the main subject of \nthis book. \n",
      "content_length": 4305,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 48,
      "content": " 1.9  SUMMARY \n A  transaction is the execution of a program that performs an administrative function by accessing a shared data-\nbase. Transactions can execute on-line, while a user is waiting, or off-line (in batch mode) if the execution takes \nlonger than a user can wait for results. The end-user requests the execution of a transaction program by sending a \nrequest message. \n A transaction processing application is a collection of transaction programs designed to automate a given \nbusiness activity. A TP application consists of a relatively small number of predeﬁ ned types of transaction pro-\ngrams. TP applications can run on a wide range of computer sizes and may be centralized or distributed, running \non local area or wide area networks. TP applications are mapped to a specially engineered hardware and soft-\nware environment called a TP system. \n The three parts of a TP application correspond to the three major functions of a TP system: \n 1.  Obtain input from a display or special device and construct a request. \n 2.  Accept a request message and call the correct transaction program. \n 3.  Execute the transaction program to complete the work required by the request. \n Database management plays a signiﬁ cant role in a TP system. Transactional middleware components sup-\nply functions to help get the best price/performance out of a TP system and provide a structure in which TP \napplications execute. \n There are four critical properties of a transaction: atomicity, consistency, isolation, and durability. Consistency \nis the responsibility of the program. The remaining three properties are the responsibility of the TP system. \n ■  Atomicity: Each transaction performs all its operations or none of them. Successful transactions commit; \nfailed transactions abort. Commit makes database changes permanent; abort undoes or erases database \nchanges. \n ■  Consistency: Each transaction is programmed to preserve database consistency. \n ■  Isolation: Each transaction executes as if it were running alone. That is, the effect of running a set of \ntransactions is the same as running them one at a time. This behavior is called serializability and usually is \nimplemented by locking. \n ■  Durability: The result of a committed transaction is guaranteed to be on stable storage, that is, one that \nsurvives power failures and operating system failures, such as a magnetic or solid-state disk. \n If a transaction updates multiple databases or resource managers, then the two - phase commit protocol is \nrequired. In phase one, it ensures all resource managers have saved the transaction’s updates to stable storage. If \nphase one succeeds, then phase two tells all resource managers to commit. This ensures atomicity, that is, that \nthe transaction commits at all resource managers or aborts at all of them. Two-phase commit usually is imple-\nmented by a transaction manager, which tracks which resource managers are accessed by each transaction and \nruns the two-phase commit protocol. \n Performance is a critical aspect of TP. A TP system must scale up to run many transactions per time unit, \nwhile giving one- or two-second response time. The standard measures  of performance are the TPC bench-\nmarks, which compare TP systems based on their maximum transaction rate and price per transaction for a stan-\ndardized application workload. \n A TP system is often critical to proper functioning of the enterprise that uses it. Therefore, another important \nproperty of TP systems is availability; that is, the fraction of time the system is running and able to do work. \nAvailability is determined by how frequently a TP system fails and how quickly it can recover from failures. \n TP systems have rather different characteristics than batch, real-time, and data warehouse systems. They \ntherefore require specialized implementations that are tuned to the purpose. These techniques are the main \nsubject of this book. \n \n1.9 Summary  29\n",
      "content_length": 3957,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 49,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 50,
      "content": " 2.1  INTRODUCTION \n This chapter discusses ﬁ ve software abstractions that are used heavily in TP systems: \n ■  Transactions \n ■  Processes and threads \n ■  Remote procedure calls \n ■  Transaction context, sessions, and other techniques for managing shared state \n ■  Caching, resource pooling, partitioning, and replication \n These abstractions involve both the application programming interface and mechanisms to support it. \nUnderstanding them is fundamental to developing and engineering a TP system. \n We start with the transaction abstraction, where we focus on the semantics of the programming model. We \npresent pseudocode that illustrates how a transaction is delimited and thus establishes the relationship between a \nprogram and the TP infrastructure. This sets the stage to discuss the signiﬁ cant abstractions relevant to that infra-\nstructure — processes, threads, and remote procedure call — where the focus shifts from the programming model to \nhow the mechanisms work. Then we present the main abstractions involved in state management, which are at the \ncore of the leading programming and deployment models used in transactional middleware. Finally, we talk about \nabstractions that are used to enhance the performance and scalability of TP applications: caching of state; pooling \nof sessions, threads, and other resources; and partitioning and replication of databases and server processes. \n 2.2  TRANSACTIONS \n The transaction abstraction affects three aspects of a TP system: \n ■  The programming model; that is, the style in which application programs are written \n ■  The application programming interface (API); that is, the commands available to the application programmer \n ■  Components of the system software that support TP applications \n It is up to the application programmer to bracket the set of operations that should be executed as part of the same \ntransaction. This section focuses on the semantics that is  implied by the transaction brackets. For the most part, we \nuse pseudocode to express this bracketing explicitly, because it is easy to understand and exposes the semantic \n Transaction Processing Abstractions  2 \nCHAPTER\n",
      "content_length": 2171,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 51,
      "content": "32  CHAPTER 2 Transaction Processing Abstractions\n issues that are at stake. Other styles of programming are described later in this section. Product-speciﬁ c program-\nming models and APIs for transaction bracketing are presented in Chapter 10. System software components that \nsupport TP applications are discussed in Chapter 3. \n Transaction Bracketing \n Transaction bracketing offers the application programmer commands to Start, Commit, and Abort a transaction. \nThese are expressed explicitly in some programming models and implicitly in others, but in either case these are \nthe commands whose execution begins and terminates a transaction. \n The commands to bracket a transaction are used to identify which operations execute in the scope of a trans-\naction. The Start command creates a new transaction. After an application invokes a Start command, all of its \noperations execute within that transaction until the application invokes Commit or Abort. In particular, if the \napplication calls a procedure, that procedure ordinarily executes within the same transaction as its caller. After \ninvoking Commit or Abort, the application is no longer executing a transaction until it invokes Start again. \n Sometimes , a procedure is designed to be executed either as an independent transaction or as a step within \na larger transaction. For example, consider the following two procedures: \n ■  DebitChecking(acct, amt) . Withdraw a given amount of money ( amt ) from a given checking account \n( acct ). \n ■  PayLoan(loan,  amt) . Pay back a given amount of money ( amt ) on a given loan ( loan ). \n Each of these procedures could execute as an independent ACID transaction. In that case, you would expect \nto see Start at the beginning of the body of each of the procedures and Commit at the end. Example procedures \nfor  DebitChecking and  PayLoan are shown in  Figure 2.1 . \nBoolean DebitChecking(acct, amt) {\n \nint acct, amt;\n \nStart;\n \nBoolean success = true;\n \n// Code to perform the withdrawal goes here.\n \n// Set “success = false” if the withdrawal fails,\n \n// e.g., due to insufficient funds\n \nif success Commit else Abort;\n \nreturn success;\n}\nBoolean PayLoan(loan, amt) {\n \nint loan, amt;\n \nStart;\n \nBoolean success = true;\n \n// Code to perform the payment goes here.\n \n// Set “success = false” if the payment fails,\n \n// e.g., because the loan has already been paid\n \nif success Commit else Abort;\n \nreturn success;\n}       \n FIGURE 2.1 \n Explicit Transaction Brackets. The DebitChecking and PayLoan procedures explicitly bracket their transactions with \na Start command and a Commit or Abort command. \n",
      "content_length": 2616,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 52,
      "content": " As long as a transaction executes a single procedure, it is quite straightforward to bracket the transaction \nusing Start, Commit, and Abort. Things get more complicated if a procedure that is running a transaction calls \nanother procedure to do part of the work of the transaction. For example, suppose there is a procedure  PayLoan\nFromChecking(acct, loan, amt) that calls the  DebitChecking and  PayLoan procedures to withdraw \nmoney from a checking account to pay back part of a loan, as shown in  Figure 2.2 . \n We would like the  PayLoanFromChecking procedure to execute as an ACID transaction. We therefore \nbracket the body of the procedure with calls to Start and Commit. This  PayLoanFromChecking transaction \nincludes its calls to the  DebitChecking and  PayLoan procedures. However, there is a potential problem with \nthis, namely, that  DebitChecking and  PayLoan also invoke the Start and Commit commands. Thus, as they’re \ncurrently written,  DebitChecking and  PayLoan would execute separate transactions that commit indepen-\ndently of  PayLoanFromChecking , which is not what we want. That is, we cannot compose  DebitChecking \nand  PayLoan into a larger transaction. We call this the  transaction composability problem . \n One solution is to have the system ignore invocations of the Start command when it is executed by a program \nthat is already running within a transaction. In this approach, when the  PayLoanFromChecking procedure calls \nthe  DebitChecking procedure, the Start command in the  DebitChecking procedure in  Figure 2.1 would not \ncause a new transaction to be created. However, the system cannot completely ignore this second Start com-\nmand. It must remember that this second Start command was invoked, so it will know that it should ignore \nthe execution of the corresponding Commit command in  DebitChecking . That is, the Commit command in \n Figure 2.1 should not commit the  “ outer ” transaction created by  PayLoanFromChecking . More generally, the \nsystem maintains a start-count for each executing application, which is initialized to zero. Each execution of the \nStart command increments the start-count and each Commit decrements it. Only the last Commit, which decre-\nments the count back to zero, causes the transaction to commit. \n What if the  DebitChecking procedure issues the Abort command? One possible interpretation is that if an \ninner procedure calls Abort, then the transaction that the procedure is executing really does need to abort. Thus, \nunlike the Commit command, the Abort command in the  DebitChecking procedure causes an abort of the outer \ntransaction created by  PayLoanFromChecking . In some systems, it is simply an error for a procedure that has \nexecuted a second Start command to subsequently invoke an Abort command. In others, the invocation of Abort \nis ignored. Another possible interpretation is that it is an attempt to abort only the work that was performed since \nthe last Start command executed. This semantics is  discussed in the later subsection,  Nested Transactions . \n Another solution to the transaction composability problem is to remove the Start and Commit com-\nmands from  DebitChecking and  PayLoan , so they can be invoked within the transaction bracketed by the \n PayLoanFromChecking procedure. Using this approach, the  DebitChecking procedure would be replaced \nby the one in  Figure 2.3 . To enable  DebitChecking to execute as an independent transaction, one can write \nBoolean PayLoanFromChecking(acct, loan, amt) {\n \nint  acct, loan, amt;\n \nStart;\n \nif ¬DebitChecking(acct, amt) {Abort; return false;};\n \nif ¬PayLoan(loan, amt) {Abort; return false;};\n \nCommit;\n \nreturn true;\n}  \n FIGURE 2.2 \n A Composite Transaction. The transaction  PayLoanFromChecking is written by composing the  DebitChecking \nand  PayLoan procedures. \n2.2 Transactions  33\n",
      "content_length": 3856,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 53,
      "content": "34  CHAPTER 2 Transaction Processing Abstractions\n a  “ wrapper ” procedure  CallDebitChecking that includes the transaction brackets, also shown in  Figure 2.3 . \nThis approach avoids the need to rewrite application code when existing procedures are composed in new ways. \nAnother programming model that realizes this beneﬁ t is described in a later subsection entitled,  Transaction \nBracketing in Object-Oriented Programming . \n The impact of the transaction composability problem is something that needs to be evaluated and under-\nstood in the context of whichever programming model or models you are using. \n Transaction Identiﬁ ers \n As we explained in Chapter 1, each transaction has a unique transaction identiﬁ er (transaction ID), which is \nassigned when the transaction is started. The transaction ID is assigned by whichever component is responsible \nfor creating the transaction in response to the Start command. That component could be a transaction manager \n(see Section 1.4) or a transactional resource manager such as a database system, ﬁ le system, or queue manager. \n There are two major types of transaction IDs: global and local. The transaction manager assigns a global \nID, which is needed when more than one transactional resource participates in a transaction. If the transac-\ntional resource managers also assign transaction IDs, then these are local IDs that are correlated with the \nglobal transaction ID since they all refer to the same transaction. \n Whenever a transaction accesses a transactional resource, it needs to supply its transaction ID, to tell the \nresource’s manager on which transaction’s behalf the access is being made. The resource manager needs this \ninformation to enforce the ACID properties. In particular, it needs it for write accesses, so that it knows which \nwrite operations to permanently install or undo when the transaction commits or aborts. \n When an application program invokes Commit or Abort, it needs to pass the transaction ID as a parameter. \nThis tells the transaction manager which transaction it is supposed to commit or abort. \n Since the application needs to supply its transaction ID to resource managers and the transaction manager, \nit needs to manage its transaction ID. It could do this explicitly. That is, the Start operation could return a \nBoolean DebitChecking(acct, amt) {\n \nint acct, amt;\n \nBoolean success = true;\n \n// Code to perform the withdrawal goes here.\n \n// Set “success = false” if the withdrawal fails,\n \n// e.g., due to insufficient funds\n \nreturn success;\n}\nBoolean CallDebitChecking(acct, amt) {\n \nint acct, amt;\n \nStart;\n \nBoolean success = DebitChecking(acct, amt);\n \nif success Commit else Abort;\n \nreturn success;\n}        \n FIGURE 2.3 \n Enabling Composability. The Start, Commit, and Abort commands are removed in this revised version of the \n DebitChecking procedure ( Figure 2.1 ), so it can be invoked in a larger transaction, such as  PayLoanFromChecking \n( Figure 2.2 ). A wrapper procedure  CallDebitChecking is added, which includes the transaction brackets needed to \nexecute  DebitChecking as an independent transaction. \n",
      "content_length": 3134,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 54,
      "content": " transaction ID explicitly to the application, and the application could pass that transaction ID to every resource \nit accesses. \n Most systems hide this complexity from the application programmer. Instead of returning the transaction ID to \nthe program P that invokes Start, the system typically makes the transaction ID part of a hidden  context , which is \ndata that is associated with P but is manipulated only by the system, not by P. In particular, using the context the \nsystem transparently attaches the transaction ID to all database operations and Commit and Abort operations. This \nis more convenient for application programmers — it’s one less piece of bookkeeping for them to deal with. It also \navoids errors, because if the application passes the wrong transaction identiﬁ er, the system could malfunction. \n Typically , the hidden context is associated with a thread, which is a sequential ﬂ ow of control through a pro-\ngram. A thread can have only one transaction ID in its context, so there is no ambiguity about which transaction \nshould be associated with each database operation and Commit or Abort. Threads are discussed in detail in the \nnext section. \n Notice that there are no transaction IDs in  Figure 2.1 through  Figure 2.3 . The transaction ID is simply part \nof the hidden program context. Throughout this chapter, we will assume that transaction IDs are hidden in this \nway, although as we will see some programming models allow access to this transaction context. \n Chained Transactions \n In some programming models, an application is assumed to be always executing within a transaction, so there is \nno need for the developer to start a transaction explicitly. Instead, an application simply speciﬁ es the boundary \nbetween each pair of transactions. This  “ boundary operation ” commits one transaction and immediately starts \nanother transaction, thereby ensuring that the program is always executing a transaction. In IBM’s CICS product,\nthe verb called  syncpoint works in this way. Microsoft SQL Server offers an implicit transaction mode that \nworks this way too. \n This programming style is called  chained transactions , because the sequence of transactions executed by a \nprogram forms a chain, one transaction after the next, with no gaps in between. The alternative is an  unchained \nmodel, where after a program ﬁ nishes one transaction, it need not start the execution of another transaction right \naway. For example, this can be done using the Start and Commit commands for explicit transaction bracketing. \nMost of today’s programming models use the unchained model, requiring that the developer explicitly deﬁ nes \nthe start of each new transaction. \n On the face of it, the unchained model sounds more ﬂ exible, since there may be times when you would \nwant an application to do work outside of a transaction. However, in fact there is really very little purpose in it. \nThe only beneﬁ t is in systems where a transaction has signiﬁ cant overhead even if it doesn’t access recoverable \ndata. In that case, the unchained model avoids this overhead. \n On the other hand, the unchained model has two signiﬁ cant disadvantages. First, if the code that executes \noutside a transaction updates any transactional resources, then each of those updates in effect executes as a \nseparate transaction. This is usually more expensive than grouping sets of updates into a single transaction. \nThat is, it is sometimes important to group together updates into a single transaction for performance rea-\nsons. Second, the unchained model gives the programmer an opportunity to break the consistency property of \ntransactions by accidentally executing a set of updates outside of a transaction. For these reasons, the chained \nmodel usually is considered preferable to the unchained model. \n Transaction Bracketing in Object-Oriented Programming \n With the advent of object-oriented programming for TP applications, a richer style of chained transaction \nmodel has become popular. In this approach each method is tagged with a  transaction attribute that indicates \n2.2 Transactions  35\n",
      "content_length": 4123,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 55,
      "content": "36  CHAPTER 2 Transaction Processing Abstractions\n its transactional behavior, thereby avoiding explicit transaction bracketing in the application code itself. The \ntransaction attribute can have one of the following values: \n ■  Requires New: Every invocation of the method starts executing in a new transaction, whether or not the \ncaller is already executing in a transaction. \n ■  Required: If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method starts executing in a new transaction. \n ■  Supported: If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method does not execute within a transaction. \n ■  Not Supported: The called method does not execute within a transaction, even if the program that created \nthe object is running within a transaction. 1 \n This style of programming was introduced in the mid-1990s in Microsoft Transaction Server, which evolved \nlater into COM \u0002 in Microsoft’s .NET Enterprise Services. In that system, a transaction attribute is attached to \na component, which is a set of classes, and applies to all classes in the component. In its intended usage, the \ncaller creates an object of the class (rather than calling a method of an existing object), at which time the trans-\naction attribute is interpreted to decide whether it is part of the caller’s transaction, is part of a new transaction, \nis not part of any transaction, or throws an exception. The called object is destroyed when the transaction ends. \n The concept of transaction attribute was adopted and extended by OMG’s CORBA standard and Enterprise \nJava Beans (EJB, now part of Java Enterprise Edition (Java EE)). It is now widely used in transactional mid-\ndleware products, as well as in Web Services. In EJB, the attributes tag each method and apply per method \ncall, not just when the called object is created. A class can be tagged with a transaction attribute, in which case \nit applies to all untagged methods. EJB also adds attributes to cover some other transaction options, in par-\nticular, Mandatory, where the called method runs in the caller’s transaction if it exists and otherwise throws an \nexception. \n Microsoft introduced per-method transaction attributes in Windows Communication Foundation in .NET \n3.0. It uses separate attributes to specify whether the method executes as a transaction and whether the caller’s \ntransaction context propagates to the called method (i.e., the difference between Required and Requires New). \n Let us call a method invocation  top-level if it caused a new transaction to be started. That is, it is top-level \nif it is tagged with Requires New or is tagged with Required and its caller was not executing in a transaction. \nGenerally speaking, a transaction commits when its top-level method terminates without an error. If it throws \nan exception during its execution, then its transaction aborts. \n A top-level method can call other methods whose transaction attribute is Required, Mandatory, or Supported. \nThis submethod executes in the same transaction as the top-level method. If the submethod terminates without \nerror, the top-level method can assume that it is ﬁ ne to commit the transaction. However, the top-level method \nis not obligated to commit, for example, if it encounters an error later in the execution of another submethod. In \nsome execution models, a submethod can continue to execute after announcing that the transaction can be com-\nmitted as far as it is concerned. \n If the submethod throws an exception, then the top-level method must abort the transaction. In some execu-\ntion models, the exception immediately causes the transaction to abort, as if the submethod had issued the \nAbort command. In other models, it is left to the top-level method to cause the abort to happen. \n Instead of having a method automatically vote to commit or abort depending on whether it terminates nor-\nmally or throws an exception, an option is available to give the developer more explicit control. For example, \n 1 Microsoft supports an additional value, Disabled, which has the same transaction behavior as Not Supported. A newly created object \nuses the  “ context ” of its caller, whereas for Not Supported the newly created object is given a fresh context of its own. Contexts are \nexplained in Section 2.5. \n",
      "content_length": 4453,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 56,
      "content": " in the .NET Framework, a program can do this by calling SetComplete and SetAbort. Java EE is similar, offer-\ning the setRollbackOnly command for a subobject to tell the top-level object to abort. \n The approach of using transaction attributes is declarative in that the attributes are attached to interface def-\ninitions or method implementations. Microsoft’s .NET framework also offers a runtime layer, exposed through \nthe class TransactionScope, that allows a program to invoke the functionality of the transaction  bracketing \nattributes shown previously. A program deﬁ nes a transaction bracket by creating a TransactionScope object \nwith one of the following options: \n ■  Requires New: The program starts executing within a new transaction, whether or not it was previously \nexecuting in the context of a transaction. \n ■  Required: If the program was executing in the context of a transaction, then it continues doing so. \nOtherwise, it starts a new transaction. \n ■  Suppress: The program is now executing outside of a transaction. \n In the case of Requires New and Suppress, if the program was running within a transaction  T when it created \nthe new transaction scope  S , then  T remains alive but has no activity until  S exits. \n Additional details of these approaches to transaction bracketing appear in Section 10.3 for .NET and \nSection 10.4 for Java EE. \n Nested Transactions \n The  nested transaction programming model addresses the transaction composability problem by capturing \nthe program-subprogram structure of an application within the transaction structure itself. In nested transac-\ntions, each transaction can have subtransactions. For example, the  PayLoanFromChecking transaction can \nhave two subtransactions  DebitChecking and  PayLoan . \n Like ordinary  “ ﬂ at ” (i.e., non-nested) transactions, subtransactions are bracketed by the Start, Commit, and \nAbort operations. In fact, the programs of  Figure 2.1 and  Figure 2.2 could be a nested transaction. What is dif-\nferent about nested transactions is not the bracketing operations — it’s their semantics. They behave as follows: \n 1.  If a program is already executing inside a transaction and issues a Start command, then Start creates a \n subtransaction of its parent transaction, rather than creating a new, independent transaction. For exam-\nple, if  DebitChecking is called from  PayLoanFromChecking , the Start in  DebitChecking starts a \nsubtransaction. \n 2.  If a program is  not already executing inside a transaction and issues a Start command, then Start creates \na new, independent transaction, called a  top-level transaction, which is not a subtransaction of another \ntransaction. For example, Start in  PayLoanFromChecking creates a top-level transaction. \n 3.  The Commit and Abort operations executed by a top-level transaction have their usual seman-\ntics. That is, Commit permanently installs the transaction’s updates and allows them to be read by \nother transactions. Abort undoes all the transaction’s updates. For example, Commit and Abort in \n PayLoanFromChecking have these effects. \n 4.  If a subtransaction  S aborts, then all the operations of  S are undone. This includes all the subtransac-\ntions of  S . However, the abort does not cause the abort of  S ’s parent. The parent is simply notiﬁ ed that \nits child subtransaction aborted. For example, Abort in  DebitChecking aborts the subtransaction, but \nnot its parent transaction that was started by  PayLoanFromChecking . \n 5.  While a subtransaction is executing, data items that it has updated are isolated and hence not vis-\nible to other transactions and subtransactions (just like the ﬂ at transaction model). For example, if \n2.2 Transactions  37\n",
      "content_length": 3724,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 57,
      "content": "38  CHAPTER 2 Transaction Processing Abstractions\n PayLoanFromChecking executed its subtransactions  DebitChecking and  PayLoan concurrently \nand those subtransactions read and wrote some shared data (which they don’t in this example), then \n DebitChecking would not see  PayLoan ’s updates until after  PayLoan commits, and  PayLoan would \nnot see  DebitChecking ’s updates until after  DebitChecking commits. \n 6.  When a subtransaction commits, the data items it has updated are made visible to other subtransactions. \nFor example, after  PayLoan commits, any data it has updated would be visible to  DebitChecking (if \nthey shared data). \n Consider the properties of subtransactions relative to the ACID properties. Rule (4) means that a subtrans-\naction is atomic (i.e., all-or-nothing) relative to other subtransactions of the same parent. Rule (5) means that \na subtransaction is isolated relative to other transactions and subtransactions. However, a subtransaction is not \ndurable. Rule (6) implies that its results become visible once it commits, but by rule (3) the results become \npermanent only when the top-level transaction that contains it commits. \n The nested transaction model provides a nice solution to the transaction composability problem. In our \nexample,  DebitChecking and  PayLoan in  Figure 2.1 can execute as subtransactions within a top-level trans-\naction executed by  PayLoanFromChecking or as independent top-level transactions, without writing an arti-\nﬁ cial wrapper transaction like  CallDebitChecking in  Figure 2.3 . \n Although nested transactions are appealing from an application programming perspective, they are not sup-\nported in many commercial products. \n Exception Handling \n An application program that brackets a transaction must say what to do if the transaction fails and therefore \naborts. For example, suppose the program divides by zero, or one of the underlying database systems deadlocks \nand aborts the transaction. The result would be an  unsolicited abort — one that the application did not cause \ndirectly by calling the Abort command. Alternatively, the whole computer system could go down. For example, \nthe operating system might crash, in which case all the transactions that were running at the time of the crash \nare affected. Thus, an application program that brackets a transaction must provide error handling for two types \nof exceptions — transaction failures and system failures. \n For each type of exception, the application should specify an  exception handler , which is a program that \nexecutes after the system recovers from the error. To write an exception handler, a programmer needs to know \nexactly what state information is available to the exception handler; that is, the reason for the error and what \nstate was lost due to the error. Two other issues are how the exception handler is called and whether it is run-\nning in a transaction. \n Information about the cause of the abort should be available to the exception handler, usually as a status \nvariable that the exception handler can read. If the abort was caused by the execution of a program statement, \nthen the program needs to know both the exception that caused the statement to malfunction and the reason for \nthe abort — they might not be the same. For example, it’s possible that there was some error in the assignment \nstatement due to an overﬂ ow in some variable, but the real reason for the abort was an unavailable database \nsystem. The exception handler must be able to tell the difference between these two kinds of exceptions. \n When a transaction aborts, all the transactional resources it accessed are restored to the state they had \nbefore the transaction started. This is what an abort means, undo all the transaction’s effects. Nontransactional \nresources — such as a local variable in the application program, or a communications message sent to another \nprogram — are completely unaffected by the abort. In other words, actions on nontransactional resources are \nnot undone as a result of the abort. \n",
      "content_length": 4061,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 58,
      "content": " It ’s generally best if a transaction failure automatically causes the program to branch to an exception han-\ndler. Otherwise the application program needs an explicit test, such as an  IF -statement, after each and every \nstatement, which checks the status returned by the previous statement and calls the appropriate exception han-\ndler in the event of a transaction abort. \n In the chained model, the exception handler is automatically part of a new transaction, because the previous \ntransaction aborted and, by deﬁ nition, the chained model is always executing inside of some transaction. In the \nunchained model, the exception handler is responsible for demarcating a transaction in which the exception \nhandling logic executes. It  could execute the handler code outside of a transaction, although as we said earlier \nthis is usually undesirable. \n If the whole system goes down, all the transactions that were active at the time of the failure abort. Since \na system failure causes the contents of main memory to be lost, transactions cannot resume execution when \nthe system recovers. So the recovery procedure for transaction programs needs to apply to the application as a \nwhole, not to individual transactions. The only state that the recovery procedure can rely on is information that \nwas saved in a database or some other stable storage area before the system failed. A popular way to do this is \nto save request messages on persistent queues. The technology to do this is described in Chapter 4. \n Some applications execute several transactions in response to a user request. This is called a  business pro-\ncess or  workﬂ ow . If the system fails while a business process is executing, then it may be that some but not all \nof the transactions involved in the business process committed. In this case, the application’s exception handler \nmay execute compensating transactions for the business process ’ transactions that already committed. Business \nprocess engines typically include this type of functionality. More details appear in Chapter 5. \n Savepoints \n If a transaction periodically saves its state, then at recovery time the exception handler can restore that state \ninstead of undoing all the transaction’s effects. This idea leads to an abstraction called savepoints. \n A  savepoint is a point in a program where the application saves all its state, generally by issuing a  save-\npoint command . The savepoint command tells the database system and other resource managers to mark this \npoint in their execution, so they can return their resources to this state later, if asked to do so. This is useful for \nhandling exceptions that only require undoing part of the work of the transaction, as in  Figure 2.4 . \nvoid Application\n     {  Start;\n        do some work;\n        . . .\n        Savepoint (“A”);\n        do some more work;\n        . . .\n        if (error)       \n           { Restore (“A”);\n             take corrective action;\n             Commit;\n           }\n        else Commit;\n     }      \n FIGURE 2.4 \n Using Savepoints. The program saves its state at savepoint  “ A. ” It can restore the state later if there’s an error. \n2.2 Transactions  39\n",
      "content_length": 3190,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 59,
      "content": "40  CHAPTER 2 Transaction Processing Abstractions\n A savepoint can be used to handle broken input requests. Suppose a transaction issues a savepoint imme-\ndiately after receiving an input request, as in the program  Application in  Figure 2.5 . If the system needs \nto spontaneously abort the transaction, it need not actually abort, but instead can roll back the transaction to \nits ﬁ rst savepoint, as in  ExceptionHandlerForApplication in  Figure 2.5 . This undoes all the transac-\ntion’s updates to transactional resources, but it leaves the exception handler with the opportunity to generate a \ndiagnostic and then commit the transaction. This is useful if the transaction needs to abort because there was \nincorrect data in the request. If the whole transaction had aborted, then the get-input-request operation would \nbe undone, which implies that the request will be re-executed . Since the request was incorrect, it is better to \ngenerate the diagnostic and commit. Among other things, this avoids having the request re-execute  incorrectly \nover and over, forever. \n Unfortunately , in some execution models the exception handler of a transactional application must abort \nthe transaction. In this case, a mechanism outside the transaction needs to recognize that the broken request \nshould not be re-executed  time after time. Queuing systems usually offer this function, which is described in \nChapter 4. \n Some database systems support the savepoint feature. Since the SQL standard requires that each SQL \noperation be atomic, the database system does its own internal savepoint before executing each SQL update \noperation. That way, if the SQL operation fails, it can return to its state before executing that operation. Since \nthe database system supports savepoints anyway, only modest additional work is needed to have it make save-\npoints available to applications. \n In general, savepoints seem like a good idea, especially for transactions that execute for a long time, so that \nnot all their work is lost in the event of a failure. Although it’s available in some systems, it’s a feature that \nreportedly is not widely used by application programmers. \n Using Savepoints to Support Nested Transactions \n Since a savepoint can be used to undo part of a transaction but not all of it, it has some of the characteristics of \nnested transactions. In fact, if a transaction executes a sequential program, then it can use savepoints to obtain \nthe behavior of nested transactions if the system adheres to the following rules: \n 1.  When a subtransaction ﬁ rst accesses a resource manager, it issues a savepoint operation. \n 2.  When a subtransaction aborts, the system restores the savepoint that the subtransaction previously \nestablished at each resource manager that the subtransaction accessed. \n 3.  To commit a subtransaction, no special action is required by the resource managers. However, future \naccesses to resource managers are now done on behalf of the subtransaction’s parent. \nVoid Application\n     {  Start;\n        get-input-request;\n        Savepoint (“B”);\n        do some more work;\n        Commit;\n      }\nVoid ExceptionHandlerForApplication\n     {  Restore (“B”);\n        generate diagnostic;\n        Commit;\n      }\n FIGURE 2.5 \n Using Savepoints for Broken Requests. The application’s savepoint after getting the request enables its exception handler \nto generate a diagnostic and then commit. If the transaction were to abort, the get-input-request would be undone, so \nthe broken request would be re-executed. \n",
      "content_length": 3552,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 60,
      "content": " This implementation works only if the transaction program is sequential. If it has internal concurrency, then \nit can have concurrently executing subtransactions, each of which can independently commit or abort. Since a \nsavepoint applies to the state of the top-level transaction, there will not always be a savepoint state that can \nselectively undo only those updates of one of the concurrently executing subtransactions. \n Consider the example in  Figure 2.6 , where  functionX starts a transaction and then calls  functionY \nand  functionZ concurrently, indicated by the  “ concurrent block ” bracketed by  cobegin and  coend . Both \n functionY and  functionZ access a resource manager RM_A that supports savepoints. Each of them has \ntransaction brackets and therefore should run as a subtransaction. Since  functionY and  functionZ are exe-\ncuting concurrently, their operations can be interleaved in any order. Consider the following steps : \n 1.  functionY accesses RM_A, and since this is its ﬁ rst access it issues a savepoint at RM_A (rule 1, in \nthe previous list ) . \n 2.  functionZ accesses RM_A, and therefore also issues a savepoint at RM_A (rule 1 in the previous list). \n 3.  functionY performs an update at RM_A. \n 4.  functionZ performs an update at RM_A. \n 5.  functionZ commits its subtransaction. \n 6.  functionY aborts its subtransaction. \n According to rule 2 (in the previous list),  in step 6 the system should restore the savepoint created on behalf of \n functionY . However, this will undo the update performed by  functionZ , which is incorrect, since  functionZ \ncommits in step 5. \n 2.3  PROCESSES AND THREADS \n Why We Need Threads \n A processor has a state, called the  processor context , that consists of a control thread and an address space. \nThe  control thread consists of the values stored in the processor’s registers, such as the instruction counter, \nvoid functionX;\n{ Start;\n  cobegin;\n    functionZ;\n    functionY;\n  coend;\n  Commit; }\n}\nvoid functionY;\n{ Start;\n   Access RM_A;\n   Update RM_A;\n   . . .\n   if (b) Commit\n   Else Abort;\n}  \n1\n3\n6\nvoid functionZ;\n{ Start;\n   Access RM_A;\n   Update RM_A;\n   . . .\n   if (b) Commit\n   Else Abort;\n}  \n2\n4\n5\nRM_A\n FIGURE 2.6 \n Savepoints Aren’t Enough for Concurrent Subtransactions. If  functionZ commits and  functionY aborts, there is no \nsavepoint in RM_A that produces the right state. \n2.3 Processes and Threads  41\n",
      "content_length": 2415,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 61,
      "content": "42  CHAPTER 2 Transaction Processing Abstractions\n the stack pointer, and data registers. It also includes certain memory areas that are assigned to the processor but \nare not directly addressable by the program running on the processor, such as a processor stack. An  address \nspace is a mapping of the processor’s view of memory to the physical memory, typically represented in regis-\nters that point to page tables. \n In a multiprogrammed system, every active program has an associated processor state. For a program that’s \ncurrently executing, it is the state of the physical processor on which it’s running. For programs that were exe-\ncuting and are temporarily idle, the state is saved in main memory and will be reloaded into a processor when \nthe program resumes execution. \n The architecture of a TP system is affected by whether components share an address space, whether that \naddress space has one thread or multiple threads executing, and whether there are hardware, operating system, \nor language mechanisms to protect programs that share an address space from inappropriately modifying each \nother’s memory. For example, traditional timesharing systems, such as early UNIX operating systems, were \nstructured so that each display device had its own process, each process had exactly one thread executing, and \nall programs that ran on behalf of that display device executed in that one process. As we’ll see, TP systems \ndon’t work this way. \n In the timesharing model one could implement a TP system by combining all three TP application functions \ninto one big sequential program, rather than splitting them across front-end, middle-tier, and back-end servers. \nThe TP application would simply be a sequential program that consists of an inﬁ nite loop that gets an input \nmessage from a display device, starts a transaction, calls the appropriate transaction server program to run the \nrequest, commits or aborts that transaction, and returns to the top of the loop to do it again. Each display device \nwould be connected to a process that runs this program, thereby executing transactions on behalf of that display. \n There are many disadvantages, however, of using this execution model. The most important is that there \nare just too many processes. A system with tens or hundreds of thousands of display devices would have tens \nor hundreds of thousands of processes, because it needs one process for every display device. Most operating \nsystems do not work well with such a large number of processes, for many reasons: \n ■  Some operating system functions sequentially scan lists of processes. If the list is too long, it takes too \nlong to perform these operating system functions. \n ■  There is a lot of context switching between these processes, which involves swapping out register values \nof one process and loading those of another process, including invalidating and reloading the processor’s \ncache memory. \n ■  There’s usually a certain amount of memory for each process that has to remain in physical main memory \nand can’t be paged at all. Given this high memory consumption, many processes may have some of their \nvirtual memory out on disk, which has to be paged in when the transaction is invoked, adding extra delay. \n ■  Distributing transactions on multiple nodes require even more processes, because each display device \nneeds a process running on every system doing work on behalf of that display. \n ■  It is difﬁ cult to control the load on such a system. The only knob you can turn is to reduce the number of \nactive processes. Since each process is associated with a display device, shutting down a process effec-\ntively turns off a display — bad news for the person using that display. It would be better to shut down only \ncertain low-priority types of transactions, but this is hard to control because those transaction types are \nburied in the application. It would require some application programming to control the load in this way. \n ■  With a large number of processes, the complexity of sharing data structures between processes is sig-\nniﬁ cantly higher and requires more costly synchronization. Additionally, resources shared between pro-\ncesses can become orphaned under certain failure scenarios. \n",
      "content_length": 4258,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 62,
      "content": " Due to all these disadvantages, from a very early stage in the history of TP systems, transactional middle-\nware started supporting multithreaded processes. Like all abstractions supported by transactional middleware, \nthis threading abstraction is made available in a uniform way across all the operating systems that the transaction \nmiddleware supports. \n A multithreaded process supports many control threads in a single address space. Each thread is an inde-\npendent path of execution through the process. All the threads in the process execute the same program and \nuse the same process memory. But each of them has a save area for register values and private variables (e.g., \nthe process stack). See  Figure 2.7 . Thus, a multithreaded process has many executions of its program running \nconcurrently, one for each of its threads. \n Threads save memory, since the process ’ memory is shared by many threads. It avoids some of the expense \nof context switching, since a processor can switch between threads without switching address spaces. And it \nreduces the number of processes, since threads can be used instead of processes and there can be many threads \nper process. \n In a system with dedicated display devices, a single multithreaded process can manage multiple displays. \nIn this case, a thread can be used to execute a program on behalf of a display. When the process switches atten-\ntion between display devices, it switches to a different thread. Compared to a process-per-display, this reduces \nthe number of processes and the number of context switches. \n Initially , threads were dynamically allocated to display devices when the display was actively executing a \nrequest. Later, as the cost of processors and memory declined, a thread was statically allocated to each display \ndevice. \n Implementing Threads \n Threads can be implemented by middleware or by the operating system. There are beneﬁ ts to each approach. \n Middleware Threads \n If threads are implemented by transactional middleware, then the operating system doesn’t know about the \nthreads. It’s just running an ordinary process. Basically the transactional middleware is fooling the operating \nsystem by turning the process’s attention to different display devices by itself. However, this may produce \ninterference between these two levels of scheduling. Since the operating system is scheduling processes and the \ntransactional middleware is scheduling threads within the process, they may end up working at cross-purposes. \n There is one technical difﬁ culty with having the transactional middleware implement threads. If a transac-\ntion server, executing in a multithreaded process, tries to read data from disk or tries to read a communications \nThread 1\nsave area\n• registers\n• stack\nProcess’ program area\nProcess’ data area\nThread 2\nsave area\n• registers\n• stack\nThread 3\nsave area\n• registers\n• stack\nThread n\nsave area\n• registers\n• stack\nMemory shared\nby all threads\n FIGURE 2.7 \n Memory Structure of a Multithreaded Process. In addition to the usual program and data areas, there is a save area for \neach thread, instead of one save area for the whole process as in a single-threaded process. \n2.3 Processes and Threads  43\n",
      "content_length": 3223,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 63,
      "content": "44  CHAPTER 2 Transaction Processing Abstractions\n message, and the data that it needs is not yet available, then the operating system ordinarily will put the process \nto sleep. If there’s only one thread running, this is the right thing to do — put the process to sleep until it has \nsome work to do. But if there are multiple threads running inside the process, then all the threads, and therefore \nall the displays, end up getting delayed. This is bad, because some of those other displays could do useful work \nwhile the ﬁ rst display’s I/O operation is in progress. \n For this reason, the transactional middleware has to trap any of those synchronous I/O operations (generally \nreads) to avoid putting the process to sleep. Instead, it sends an asynchronous message to the disk, database \nsystem, or communications system, and asks to get a software interrupt back when the operation is complete. \nAfter the message is sent, the transactional middleware can continue operating by calling another thread that \nhas useful work to do. When the I/O operation that corresponds to the message has ﬁ nished, it will send a soft-\nware interrupt to the transactional middleware, which then wakes up the thread that was waiting for that result. \nThe cost of this approach to multithreading is that all the calls to I/O operations have to be intercepted by the \ntransactional middleware. \n For example, the mainframe version of IBM’s CICS transactional middleware product has worked this way \nstarting from its earliest implementations. It offers I/O operations that can be invoked from ordinary appli-\ncation programs, such as COBOL and C. Some transactional middleware products trap all synchronous I/O \noperations. \n Operating System Threads \n If the operating system supports multithreading, it keeps track of all the threads on its own. For example, since \nthe mid-1990s, Windows and UNIX operating systems support this. When a thread issues a synchronous I/O \noperation, the operating system puts that thread to sleep. But it recognizes when there are other active threads \nthat it can call and calls another thread that’s ready to execute (in that process), rather than putting the whole \nprocess to sleep. This avoids unnecessary context switching. Another beneﬁ t of operating system multithread-\ning is that if the process is running on a shared memory (i.e., symmetric) multiprocessor (SMP) or a multicore \nprocessor, it can assign the threads of the same process to different processors in the machine and thereby get \nparallelism among the threads of the process. \n A difﬁ culty of operating system multithreading, however, is performance overhead. Since it is the operat-\ning system that is involved in switching threads, this involves system calls. These are generally more expensive \nthan thread operations executed at the user level, which is where the transactional middleware is operating. \n There is a second disadvantage of multithreading, which is a problem whether it is implemented by the \nmiddleware or the operating system. Since there are multiple threads running inside the same process, there’s \nlittle or no memory protection between them. An error in the execution of one thread could potentially damage \nmemory for the entire process, thereby causing all the threads to malfunction. This could also lead to a security \nleak, if one thread reads memory that is private to another thread. With operating system threads, this prob-\nlem can be somewhat mitigated by providing a protected memory area for special subsystems, such as transac-\ntional middleware functions, which can be protected from user level code. It can also be mitigated by the use of \nstrongly-typed  programming languages, such as Java and C#, which can make fairly strong guarantees that an \nexecuting program will access only memory dedicated to its use. \n A third disadvantage of multithreading is that a multithreaded process cannot use a single-threaded process \nthat retains context information for only one thread. The canonical example of this is early database system \nproducts. Until the mid-1980s, most database systems were single-threaded and could execute only one trans-\naction at a time. The database system executed as a runtime library in each single-threaded application process. \nThus, if a multithreaded process invoked a database system, all threads in the process would have to be run-\nning the same transaction, which is obviously not what is intended when using multithreaded applications for \n",
      "content_length": 4512,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 64,
      "content": " TP. This problem was solved by the database system vendors who re-engineered their products to run as inde-\npendent multithreaded processes, where each thread could run a different transaction. This enables each thread \nof a multithreaded application process to have an independent connection to a database system and have the \ndatabase system execute that connection in a thread (and hence in a transaction) that’s private to the connec-\ntion. Most database systems today work this way, though there is still a market for database systems that run in \nthe application process (e.g., for embedded systems). We will have more to say about multithreaded database \nservers in Section 3.7. \n In summary, multithreading offers signiﬁ cant efﬁ ciency improvements, but must be used carefully to avoid \nblocking during I/O operations, interference between transactional middleware and operating system schedul-\ning, performance overhead in thread context switching, and corruption of unprotected memory. Overall, for \nmost applications, operating system multithreading is superior to transactional middleware multithreading, \nsince it avoids the ﬁ rst two of these problems and can beneﬁ t from multicore and SMP conﬁ gurations. For this \nreason, operating system multithreading has become ubiquitous in current TP products. The use of transac-\ntional middleware multithreading is now mostly limited to older products. \n Server Classes \n When multithreaded operating system processes are not available, a good alternative is to use a set of pro-\ncesses to emulate a pool of threads. That is, instead of having one multithreaded process, the system uses a set \nof single-threaded processes, all of which are running the same program (see  Figure 2.8 ). This often is called a \n server class . In this case, for each server program, there is a set of server processes that runs it. \n Server classes have a number of nice features. Most of them stem from the fact that each process in the \nserver class is an ordinary single-threaded process and therefore avoids the disadvantages of multithreading, \nsuch as the following: \n ■  Since the process is single-threaded, there’s no harm in putting it to sleep if it is blocked during a syn-\nchronous I/O operation. Therefore, there is no need for the transactional middleware to trap synchronous \nI/O; the normal blocking behavior of the operating system is just ﬁ ne. \n ■  There’s no possible conﬂ ict between process and thread scheduling and no possible memory corruption \nproblems from threads in the same process. \n ■  Processes in a server class fail independently. That is, a server class is largely unaffected by the failure of \nany individual process in the server class, since other processes continue to run. This is in contrast to a \nT\nh\nr\ne\na\nd \n1\nT\nh\nr\ne\na\nd \n2\nT\nh\nr\ne\na\nd \nn\nMultithreaded\nServer Process\nServer Class (many single-threaded processes)\nServer\nProcess\n1\nServer\nProcess\n2\nServer\nProcess\nn\n FIGURE 2.8 \n Multithreaded Process vs. Server Class. In both cases, there is one server program and many threads executing it. The \ndifference is whether the threads execute in one process (multithreaded server) or many processes (server class). \n2.3 Processes and Threads  45\n",
      "content_length": 3232,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 65,
      "content": "46  CHAPTER 2 Transaction Processing Abstractions\n multithreaded process, where the failure of one thread can bring down the whole process, especially if it \ncorrupts the memory of other threads. \n ■  Each process in a server class can use single-threaded services, such as a single-threaded database sys-\ntem that executes as a runtime library. This was an important beneﬁ t before the advent of multithreaded \ndatabase systems. \n For these reasons, and to avoid the expense of implementing multithreading, server classes were quite pop-\nular in transactional middleware products before the advent of multithreaded operating systems, as in the case \nof HP’s ACMS and Pathway legacy TP monitors. \n However , server classes do have disadvantages. One is that there is a process per thread. As we explained \nearlier, operating systems don’t work well with too many processes. So server classes can be used only when \nthe number of required server threads is relatively small. \n Another disadvantage of server classes is that they require an additional mechanism to dispatch calls to \nthe server class to a particular server process. The problem is how to balance the load across the servers in the \nserver class. The caller could randomize its selection of server, thereby balancing the load across multiple serv-\ners, on the average. Or, the processes in the server class could share a queue of unprocessed requests. If a busy \nprocess receives a call, it simply adds it to the queue, where another process can pick it up. Or, the server class \ncould have a single process that receives all requests and routes each one to an idle process. The latter is easy \nto implement, but costs an extra context switch, since each call has to invoke the server class’s router process \nbefore going to a server. We will have more to say about load balancing in Section 2.6. \n 2.4  REMOTE PROCEDURE CALL \n Remote procedure call (RPC) is a programming mechanism that enables a program in one process to invoke \na program in another process using an ordinary procedure call, as if the two programs were executing in the \nsame process (or more precisely, in the same address space). \n There are several beneﬁ ts to programming in the RPC style. First, the programmer can still write and reason \nabout a program as if all the program’s procedures were linked together in a single process. Therefore, the pro-\ngrammer can focus on correctly modularizing the program and ignore the underlying communications mecha-\nnism. In particular, the programmer can ignore that the program is really distributed, which would add signiﬁ cant \ncomplexity to the programming task if it were made visible. \n Second , the RPC style avoids certain programming errors because of the simple request-response message \nprotocol that it implies. Using RPC, a program receives a return for every call. Either the caller receives a return \nmessage from the called procedure, or the system returns a suitable exception to the caller so it can take appro-\npriate action. By contrast, using asynchronous message passing, a program has explicit statements to send and \nreceive messages. These send and receive operations issued by communicating programs deﬁ ne a communica-\ntion protocol. This requires the programmer to handle the message sequences and errors directly. For example, \neach program must be ready to receive a message after the message is sent to it. Programs have to cope with \ncertain error conditions, such as waiting for a message that never arrives, or giving up waiting for a message and \ncoping with that message if it does eventually arrive later. In RPC, these problems are dealt with by the RPC \nimplementation rather than by the application program. \n Third , RPC implementations can hide the differences in parameter format between the programming lan-\nguages in which the client’s and server’s program are written. RPC implementations also can hide differences \namong processors such as Intel x86, AMD, PowerPC, and SPARC and the differences among operating sys-\ntems such as Windows and Linux. \n",
      "content_length": 4076,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 66,
      "content": " To understand how RPC works, consider the example in  Figure 2.9 . This program consists of three procedures: \n ■  PayCreditCard , which pays a credit card bill \n ■  DebitChecking , which subtracts money from a checking account \n ■  PayBill , which calls  PayCreditCard and  DebitChecking to pay a credit card bill from a checking \naccount \n Let us assume that these three procedures execute in separate processes, possibly on different nodes of a net-\nwork. Therefore, the invocations of  PayCreditCard and  DebitChecking by  PayBill are remote procedure \ncalls. \nBoolean Procedure PayBill (acct#, card#)\n{ int     acct#, card#;\n  long    amount;\n  Boolean ok;\n  Start;  /* start a transaction */\n  amount = PayCreditCard(card#);\n  ok = DebitChecking(acct#, amount);\n  if (!ok) Abort else Commit;\n  return (ok);\n}\nlong Procedure PayCreditCard (card#);\n{ int  card#;\n  long amount;\n  /* get the credit card balance owed */\n  Exec SQL Select AMOUNT\n           Into :amount\n           From CREDIT_CARD\n           Where (ACCT_NO = :card#);\n  /* set the balance owed to zero */\n  Exec SQL Update CREDIT_CARD\n           Set AMOUNT = 0\n           Where (ACCT_NO = :card#);\n  return (amount);\n}\nBoolean Procedure DebitChecking (acct#, amount);\n{ int  acct#;\n  long amount;\n  /* debit amount from checking balance if balance is sufficient */\n  Exec SQL Update ACCOUNTS\n           Set BALANCE = BALANCE - :amount\n           Where (ACCT_NO = :acct# and BALANCE ≥ amount);\n  /* SQL Code = 0 if previous statement succeeds */\n  return (SQLCODE == 0);\n}\n FIGURE 2.9 \n Credit Card Payment Example.  PayBill brackets the transaction and calls two subprograms,  PayCreditCard and \n DebitChecking , which it calls by RPC. \n2.4 Remote Procedure Call  47\n",
      "content_length": 1737,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 67,
      "content": "48  CHAPTER 2 Transaction Processing Abstractions\n PayCreditCard  takes a credit card account number as input, returns the amount of money owed on that \naccount, and zeroes out the amount owed. The ﬁ rst SQL statement selects the amount of money from the credit \ncard table, which contains the amount of money owed on each account number. The second statement zeroes \nout that amount (i.e., the entire balance is paid off) and returns the amount actually owed for the account. \n DebitChecking  subtracts a given amount of money from a given account. In the SQL statement, if the \nbalance in that account is greater than or equal to the amount of money to be debited, then it subtracts the \namount of money to be debited from the account balance. In this case, the SQL statement succeeds and there-\nfore sets SQLCODE to zero, so  DebitChecking returns true. On the other hand, if the balance in that account \nis less than the amount of money to be debited, then the SQL statement does not update the account balance. \nSince the SQL statement failed, SQLCODE is not set to zero and  DebitChecking returns false. \n Each of these programs is useful by itself. The  PayCreditCard program can be used to process credit card \nbills. The  DebitChecking program can be used to process debits and credits against a checking account from \nan ATM. Using these two programs, we can easily write a  PayBill program that implements a  bill-paying \ns ervice by paying a customer’s credit card bill out of his or her checking account. \n The  PayBill program takes a checking account number and credit card number and tries to pay the credit \ncard bill out of the checking account. The program starts a transaction, pays the credit card bill (which returns the \namount of money owed), and tries to debit that money from the checking account. If the  DebitChecking program \nreturns true — meaning that there was enough money to pay the bill — the program commits. If it returns false, then \nthere wasn’t enough money to pay the bill and the transaction aborts. In both cases the  PayCreditCard program \nupdates the credit card table. But if the  PayBill program aborts the transaction, the abort automatically undoes \nthat update, thereby leaving the bill for that credit card account unpaid. (If  DebitChecking returns false, its SQL \nupdate failed and has no effect on the  ACCOUNTS table.) \n Transactional RPC \n The RPC runtime system has some extra work to do to allow a transaction to invoke an RPC. It has to pass the \ntransaction context from the caller to the callee (which may be hidden, as in  Figure 2.9 and earlier examples) \nand must throw transaction-related exceptions back to the caller. In addition to the transaction ID, the context \nmay include security credentials, the identity of the system that started the transaction, and other system infor-\nmation that is required by the callee to continue operating within the same transaction. An RPC mechanism \nthat does this additional work is called a  transactional RPC . \n A transactional RPC system may also need to do some work to support two-phase commit. For example, \nas part of making an RPC call, it may need to call the transaction manager on the caller’s and callee’s systems \nto notify them that the transaction has now moved to a new system. This information is needed later when the \ntwo-phase commit protocol is initiated, so the transaction managers know which systems are participants in \nthe transaction. We’ll discuss these issues at length in Chapter 8. \n Sometimes , the RPC mechanism itself is used to transmit the two-phase commit messages. This is an imple-\nmentation strategy for the vendor of the two-phase commit implementation. It is a sensible one, but has no effect \non the functionality available to application developers. This is  not what is meant by the term  “ transactional RPC. ” \n Binding Clients and Servers \n The programs shown in  Figure 2.9 are incomplete in that they don’t show how the caller and callee procedures \ndiscover each other’s interfaces and establish connections that enable them to communicate. First of all, to \nmake remote procedure call worthwhile in this situation, the  PayBill program would probably be running in \na different process, possibly on a different system, than the  PayCreditCard or  DebitChecking programs. \n",
      "content_length": 4331,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 68,
      "content": " To compile and run the programs on these different systems,  PayBill needs to reference the external proce-\ndures  PayCreditCard and  DebitChecking . This is done by writing an  interface deﬁ nition for each pro-\ngram to be called — in this case  PayCreditCard and  DebitChecking . \n Interface Deﬁ nitions \n An interface deﬁ nition speciﬁ es the name and type of the program and its parameters. It is processed by the \n interface compiler or  stub compiler , which may be part of the programming language compiler if the latter \nhas built-in RPC functionality. The interface compiler produces several outputs, one of which is a header ﬁ le \n(consisting of data structures) for the caller to use. In this case the interface compiler would produce header ﬁ les \nfor  PayCreditCard and  DebitChecking that could be included with the  PayBill program so that it can be \ncompiled. The interface compiler also produces  proxy and  stub procedures, which are the programs that inter-\nface the  PayBill caller to the  PayCreditCard and  DebitChecking servers via the network. The caller’s \nprogram is linked with a proxy and the server’s program is linked with a stub. The interface compiler produces \nboth the header ﬁ les and the proxy and stub procedures.  Figure 2.10 illustrates the interface compiler operation. \n Marshaling \n Another function of the proxy and stub procedures is to lay out the procedure name and parameters into a \nstream, which can be sent in a message. This is called  marshaling . \n Some care is needed to avoid marshaling too much information, such as repeatedly copying and sending \nthe same object class information. In addition, it is sometimes hard to maintain identity when sending items of \na type. For example, Java enumerations don’t maintain identity over RPC. \n As part of marshaling parameters, the proxy can translate them between the format of the caller and the cal-\nlee. In the previous examples, all the programs were written using the same language, but that needn’t be the \ncase. The  PayCreditCard and  DebitChecking programs might have been written some time ago in one lan-\nguage, whereas the  PayBill program was added later to introduce the new service and was written in a different \nlanguage. In this case the client proxy translates the parameters into a standard format that the callee can under-\nstand, and the server stub translates that into the appropriate format for the procedures called  PayCreditCard \nand  DebitChecking . \nInterface Definition\nHeader Files\nProxy\nStub\nCompiler\n FIGURE 2.10 \n Interface Compiler Operation. The interface compiler produces header ﬁ les for the caller and callee to use, and proxy \nand stub procedures that provide an interface between the caller and callee and the underlying network. \n2.4 Remote Procedure Call  49\n",
      "content_length": 2804,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 69,
      "content": "50  CHAPTER 2 Transaction Processing Abstractions\n Communication Binding \n Besides linking in the proxy and stub, there is the issue of creating a communication binding between these \nprograms so they can communicate over the network. The runtime system has to know where each server \nprocess exists (e.g.,  PayCreditCard and  DebitChecking ), so it can create bindings to each server process \nwhen asked (e.g., by  PayBill ). Two activities are involved: \n ■  Each server program must  export or publish its interface, to tell all the systems on the network that it \nsupports this interface. It must also tell where on the network it can be found. \n ■  When the  PayBill program wants to connect to the server, it must create a communications connection \nusing that information exported by the server. \n These activities are ordinarily supported by a  registry service . For a Web Service, its interface is typically \ncontained within a Web Services Description Language (WSDL) ﬁ le that can be retrieved from a registry. A reg-\nistry is used to store and retrieve the interface information and is accessible from any computer in the distributed \nsystem. For example, when the  PayCreditCard program is initialized in a process, its location can be written \nto the registry service (step 1 in  Figure 2.11 ). This location could be  “ process 17315 ” of network node 32.143, \nURL  www.xyz.net (which is deﬁ ned in the WSDL ﬁ le). When the  PayBill program asks to connect to the \n PayCreditCard program, it calls the registry service (one of the RPC runtime calls mentioned earlier) to ﬁ nd out \nwhere  PayCreditCard is located (step 2). The registry service returns the instances of  PayCreditCard it knows \nabout (in this case, there is one). If there are any running,  PayBill may connect to any one of them (step 3). \nSome implementations of communication bindings automate server selection to balance the load across multiple \nidentical servers. Having received the network address of the server process number (in this case 32.143.17315), \nthe  PayBill process can now communicate with the server, so it can issue RPCs to  PayCreditCard . \n Mapping interface or server names into network addresses has to be a dynamic function, to support peri-\nodic reconﬁ guration. For example, if a server on one system fails, and the system manager recreates that server \non another system, the mapping needs to be updated to reﬂ ect the new location of the server. The system man-\nager may also want to move servers around to rebalance the load across servers, for example due to changing \ninput patterns. \n The registry that supports the binding activity needs to be accessible from all machines in the distributed sys-\ntem. This functionality ordinarily is supported by a network directory service, usually by replicating its c ontents \n3. Create a communication binding\nfor a given network address.\n1. Store server’s name\n \nand network address.\n2. Get network address\n \nfor a given server name.\nServer\nClient\nRegistry Service\n FIGURE 2.11 \n Using a Registry Service. When it’s initialized, the server stores its name and address in the registry service. Later, the \nclient gets the server’s address and uses it to create a communication binding. \n",
      "content_length": 3245,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 70,
      "content": " on many servers. For this reason, registries are often implemented on top of a network directory. For good per-\nformance, the network directory provides a client layer that caches recently accessed information. The client \nusually has connections to multiple directory services, so it can quickly switch between them if one fails. \n Instead of using a replicated repository, a simpler primary-copy approach may be supported. In this approach, \na central copy of the repository is maintained, and each system keeps a cached copy that is periodically refreshed. \nThis arrangement gives fast access to the cached mapping during normal operation. When a reconﬁ guration \nrequires that the central copy be updated, the central copy must notify the other systems to refresh their caches. \n Much of this work is done by the RPC runtime system, but some may be exposed to the application. For \nexample, the application may have to issue calls to get the network address and create a communications bind-\ning. Most systems hide this. A distinguishing feature among different implementations of RPC is how much of \nthis complexity the application programmer has to cope with. \n Dispatching \n When an RPC call arrives at the target system, the RPC runtime library needs to invoke the designated server \nprocess. If the multithreaded process or server pool doesn’t exist, then the runtime creates it. If the server is \na multithreaded process, then the runtime needs to assign the call to a thread. It can create a new thread to \nprocess the call, assign the call to an existing thread, or put the call packet on a queue (e.g., if the process is \nalready executing its maximum allowable number of active threads). If a server pool is used, then it assigns the \ncall to a server process, or if all server processes are busy it enqueues the request. \n Application Programmer’s View \n Although the RPC style does simplify some aspects of application programming, it may also introduce some \nnew complexities. First, to write these programs, one may have to write interface deﬁ nitions for the servers. \nThis is a new programming task that isn’t needed in the single-process case. \n Second , to support synchronous waiting by the caller, one needs a multithreaded client so that blocking \na caller doesn’t stall the client process. Programmers ﬁ nd it challenging to write  thread-safe applications \nfor multithreaded servers. Program-level locking problems slow throughput, consume processor cycles, or \nworse — a single memory corruption can stop many threads. As the number of available processor cores is pro-\njected to increase dramatically in the coming years, ﬁ nding ways to simplify thread-safe programming is a hot \nresearch topic in computer science. \n Third , the client and server programs need startup code to connect up or  bind the programs together before \nthey ﬁ rst communicate. This includes importing and exporting interfaces, deﬁ ning security characteristics, set-\nting up communication sessions, and so on. Although much of this can be hidden, sometimes a lot of it isn’t. \nFinally, communication failures generate some new kinds of exceptions, such as a return message that never \nshows up because of a communications or server failure. Such exceptions don’t arise in the sequential case \nwhen the programs are running inside of the same process. \n Object-Oriented RPC \n In an object-oriented programming model, procedures are deﬁ ned as methods of classes. There are two types \nof methods,  class methods and  object methods . A class method is invoked on the class itself, such as the \nmethod  new , which creates an object (i.e., instance) of the class. Most methods are object methods, which \nare invoked on an object of the class, not the class itself. For example, the procedures in  Figure 2.9 could be \ndeﬁ ned as object methods of three classes:  PayBill as a method of the Billing class,  PayCreditCard as a \nmethod of the CreditCard class, and  DebitChecking as a method of the CheckingAccount class. (Class deﬁ -\nnitions are not shown in  Figure 2.9 .) \n2.4 Remote Procedure Call  51\n",
      "content_length": 4106,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 71,
      "content": "52  CHAPTER 2 Transaction Processing Abstractions\n To invoke an object method, the caller uses a reference (i.e., a binding) to the object. This could be created \nby the caller when it invokes the method  new . If the class is remote, then this invocation of  new is itself an \nRPC, which returns a reference to a new object of the remote class. The object lives in the remote class, while \nthe reference is local to the caller. The reference is thus a local  surrogate for the remote object. The caller can \nnow invoke an object method on the surrogate, which the caller’s runtime system recognizes as an RPC to the \nreal object that resides in the remote class. \n As an optimization, the invocation of the method  new usually is executed locally in the caller’s process \nby creating the surrogate and not yet calling the method  new on the remote class. When the caller invokes an \nobject method on the newly created object for the ﬁ rst time, the caller’s runtime system sends both the invoca-\ntion of the method  new and the object method in a single message to the remote class. This saves a message \nround-trip between the caller and the remote class. Since the only thing that the caller can do with the newly \ncreated object is to invoke methods on the object, there’s no loss of functionality in grouping the remote invo-\ncation of the method  new with the ﬁ rst invocation of a method on it. \n A remote object may need to live across multiple object method calls, so that the object can retain state \ninformation that is accessible to later invocations of the object’s methods. For example, the ﬁ rst invocation of \nan object could invoke an ExecuteQuery method, which executes an SQL query. Later invocations of the object \ncould invoke a GetNext method, each of which returns the next few rows that are in the result of that query. \nOther examples of retained state are discussed in Section 2.5. \n Callbacks \n A callback enables the callee of an RPC to invoke the caller. The caller of the RPC includes a so-called  con-\ntext handle as a parameter to the RPC. The callee can use the context handle to call back to the caller. One use \nof callbacks is to pass along a large parameter from caller to callee a-chunk-at-a-time. That is, instead of send-\ning the large parameter in the original RPC to the callee, the caller sends a context handle. The callee can use \nthis context handle to call back to the caller to get a chunk of the parameter. It executes multiple callbacks until \nit has received the entire large parameter. \n The context handle passed in a callback could be an object. In a sense, a callback is an object-oriented RPC \nin reverse; it is the RPC callee that holds a reference to the caller, rather than having the caller hold a reference \nto the callee. \n An RPC Walkthrough \n Now that we have explained the main components of an RPC system, let’s walk through an example to see \nwhat happens, beginning-to-end. In  Figure 2.12 , the client application calls the server application. The client \napplication could be the  PayBill program, for example, and the server application could be  PayCreditCard . \nAs we discussed, there are proxy and stub programs and a runtime system along the path. \n The client application issues a call to the server, say  PayCreditCard . This  “ Call  PayCreditCard ” state-\nment actually calls the client’s  PayCreditCard proxy (1). The proxy is a procedure with the same interface \nas the server application; it looks exactly like  PayCreditCard to the client. Of course the  PayCreditCard \nproxy doesn’t actually do the work. All it does is send a message to the server. \n The  PayCreditCard proxy marshals the parameters of  PayCreditCard into a packet (2). It then calls \nthe communications runtime for the RPC, which sends the packet as a message to the server process (3). \n The RPC runtime creates a communications binding between the processes and adds it as a parameter to \nsubsequent send and receive operations. The client’s RPC runtime sends each message to the server’s RPC run-\ntime. The server’s RPC runtime contains a binding of message types to processes and procedures within them \nand uses it to direct each message to the right procedure. \n",
      "content_length": 4221,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 72,
      "content": " The server process’s RPC runtime system receives the message (4). It looks at the packet’s header and sees \nthat this is a call to the  PayCreditCard program, so it calls the  PayCreditCard server stub. The server stub \nunmarshals the arguments and performs an ordinary local procedure call to the  PayCreditCard program (5). \nThe  PayCreditCard program takes the call and runs just as if it had been called by a local caller instead of a \nremote caller (6). \n When  PayCreditCard completes, the whole mechanism runs in reverse:  PayCreditCard does a return \noperation to the program that called it. From  PayCreditCard ’s viewpoint, that’s the server stub. When it returns \nto the server stub, it passes a return value and perhaps some output parameters. The server stub marshals those \nvalues into a packet and passes them back to the RPC runtime system, which sends a message back to the caller. \n The caller’s system receives the packet and hands it to the correct process. The process’s RPC runtime \nreturns to the correct proxy for this call, which unmarshals the results and passes them back as part of its return \nstatement to the original  PayCreditCard call, the client’s call. \n5.  The server stub \nunpacks the arguments \nand calls the server \nprogram.\nClient’s System\n1.  The client\ncalls the local\nproxy.\n3.  The client runtime\nsystem sends the call\npacket (arguments\nand procedure name).\n2.  The client proxy\nmarshals arguments to\nPayCreditCard. \nClient\nApplication\nCall\nPayCreditCard\nPay-\nCreditCard\nReturn to\nPayBill\nPACK\nARGUMENT\nPACK\nRETURN\nUNPACK\nARGUMENT\nUNPACK\nRESULT\nRECEIVE\nRECEIVE\nWAIT\nWORK\nSEND\nSEND\nRETURN\nPACKET\nCALL\nPACKET\nClient\nProxy\nRPC\nRuntime\nRPC\nRuntime\nServer’s System\nServer\nStub\nServer\nApplication\n4.  The server runtime\nreceives the message\nand calls the right stub.\n6.  The PayCreditCard program \nruns as if it were called locally. Its \nresults flow back to the caller by \nreversing the procedure that \nexecuted the call, this time going \nfrom server to client.\n FIGURE 2.12 \n RPC Implementation. The numbers indicate the sequence of actions to process a call from the client to the \n PayCreditCard server program. \n2.4 Remote Procedure Call  53\n",
      "content_length": 2186,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 73,
      "content": "54  CHAPTER 2 Transaction Processing Abstractions\n System Characteristics of RPC \n An RPC system needs to be engineered for security, fault tolerance, performance, and manageability. Some \nRPC systems are engineered speciﬁ cally for interoperability across multiple programming languages, data for-\nmats, and operating systems. We discuss these system issues in the following subsections. \n Security of RPC \n When a client binds to a server, the client ﬁ rst calls the runtime system to ﬁ nd the server’s address and to cre-\nate a communications binding to the server. A secure gatekeeper is needed to control the creation of these \nbindings, since not all clients should be able to connect to any server for any purpose. As an extreme example, \nit shouldn’t be possible for any workstation to declare itself the network-wide  electronic mail server, since it \nwould allow the workstation to eavesdrop on everyone’s mail. \n In general, when a client connects to a server, it wants to know who it is actually talking to — that the server \nis who it says it is. Moreover, the server wants to authenticate the client, to be sure the client is who it claims to \nbe. This requires  authentication ; that is, a secure way to establish the identity of a system, a user, a machine, \nand so forth. Thus, when binding takes place, the runtime system should authenticate the names of the client \nand the server (see  Figure 2.13 ). This ensures, for example, that the server can prove that it really is the mail \nserver, and the client can prove that it’s really a client that’s allowed to connect to this server. \n Having authenticated the client, the server still needs to exercise  access control ; that is, to check whether a \nclient is authorized to use the procedure. Access control is entirely up to the server. The server’s transactional \nmiddleware or operating system may help by offering operations to maintain a list of authorized clients, called an \n access control list . But it’s up to the server to check the access control list before doing work on behalf of a client. \n Fault Tolerance in RPC \n A common fault tolerance problem is determining what a program should do if it issues an operation but \ndoesn’t get a reply that tells whether the operation executed correctly. We saw an example of this in Section \n1.3,  Handling Real-World Operations , in dealing with a missing reply to a request to dispense $100 from an \nATM. This problem also arises in RPC when a client issues a call and does not receive a reply. The key ques-\ntion is whether it is safe to retry the operation. \n Suppose a client calls a server that processes the call by updating a database, such as the  DebitChecking \nprogram in  Figure 2.9 . If the client does not receive a return message, it’s not safe to try the call again, since \nit’s possible that the original call executed, but the return message got lost. Calling  DebitChecking again \nwould debit the account a second time, which is not the desired outcome. \n The property that says it is safe to retry is called idempotence. An operation is  idempotent if any number of \nexecutions of the operation has the same effect as one execution. In general, queries are idempotent — it doesn’t \nClient\nServer\nAccess\nControl\nList\n1  Create a communication binding, passing\n \nin the authenticated client identity.\n2   Acknowledge the communication binding,\n \npassing back the authenticated server identity.\n3  RPC to the server, which checks that the\n \nclient is authorized to make this particular call.\n1\n2\n3\n FIGURE 2.13 \n RPC Security. The communication system authenticates the client and server when it creates a communication binding \nbetween them (in 1 and 2). The server checks the client’s authorization on subsequent calls for service (in 3). \n",
      "content_length": 3784,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 74,
      "content": " matter how many times you call, you always get back the same answer (if there are no intervening updates) \nand there are no side effects. Most update operations are not idempotent. For example,  DebitChecking is not \nidempotent because executing it twice has a different effect than executing it just once. \n A server is idempotent if all the operations it supports are idempotent. It is useful if a server declares that \nit is idempotent (e.g., its operations are all queries). The RPC runtime system learns that fact when it creates a \nbinding to the server. In this case, if the client RPC runtime sends a call but does not receive a reply, it can try \nto call again and hope that the second call gets through. If the server is not idempotent, however, it’s not safe to \nretry the call. In this case, the client could send a control message that says  “ Are you there? ” or  “ Have you pro-\ncessed my previous message? ” but it can’t actually send the call a second time, since it might end up executing \nthe call twice. \n Even if it resends calls (to an idempotent server) or it sends many  “ Are you there? ” messages (to a non-idem-\npotent server), the caller might never receive a reply. Eventually, the RPC runtime will give up waiting and return \nan exception to the caller. The caller cannot tell whether the call executed or not. It just knows that it didn’t receive \na reply from the server. It’s possible that a server will reply later, after the RPC runtime returns an exception. At \nthis point, it’s too late to do anything useful with the reply message, so the RPC runtime simply discards it. \n Looking at the issue a bit more abstractly, the goal is to execute an idempotent operation  at least once  and \nto execute a non-idempotent  operation  at most once . Often, the goal is to execute the operation  exactly once . \nTransactions can help. A call executes exactly once if the server is declared non-idempotent  and the RPC exe-\ncutes within a transaction that ultimately commits. We will explore exactly-once behavior further in Chapter 4. \n System Management \n We ’ve discussed RPC assuming that both the client and server process are already up and running, but of course \nsomebody has to make all this happen to begin with. These are system management activities: to create cli-\nent and server processes and communications sessions to support RPC bindings. Sometimes these are dynamic \nfunctions that are part of the RPC system. In TP systems, they are usually static functions that are part of initial-\nizing the application, done in the transactional middleware. \n The system manager also has to track the behavior of the system. This requires software to monitor all the \nlow-level system components and make them visible with abstractions that are intelligible to the system man-\nager. For example, if someone calls the Help Desk saying,  “ I can’t run transactions from my PC, ” the system \nmanager has to check, among other things, whether the PC is communicating with the server, whether the server \nprocesses are running, whether the client and server are running compatible versions of the proxy and stub, and \nso on. Similarly, if there are performance problems, the system manager has to track the message load for each \nof the systems, determine whether the server has enough threads to run all the incoming calls, and so on. \n Interoperability of RPC \n In the example, suppose that the client and server applications use different programming languages with dif-\nferent data formats. In that case, the client proxy and the server stub need to translate the parameters between \nthe client’s and server’s format. There are two ways to do this: \n ■  Put the parameters into a standard, canonical format that every server knows how to interpret. \n ■  Ensure that the server’s stub can interpret the client’s format, known as  receiver-makes-it-right . \n Canonical forms include XML Schema, CDR (used in RMI/IIOP), and XDR (used in the Sun RPC). When \nusing a canonical format, the client proxy translates the parameters into the standard format, the server trans-\nlates them out of standard format, and likewise for the return parameters — the server stub puts them into stan-\ndard format and the client proxy puts them back into client format. \n2.4 Remote Procedure Call  55\n",
      "content_length": 4311,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 75,
      "content": "56  CHAPTER 2 Transaction Processing Abstractions\n This is ﬁ ne if the client and server are running different languages, but what if they’re running the same \nlanguage? For example, suppose they’re both using Java or C#. The client proxy is going through all the extra \nwork of taking the data out of Java format and putting it into standard format, and then the server is taking it out \nof standard format and putting it back into Java format. For this reason, the receiver-makes-it-right technique \noften is used. The client proxy marshals the parameters in the client’s format, not in a standard format, and \ntags them with the name of the format it’s using. When the receiver gets the parameters, if it sees that they’re in \nthe same format that the server is using, it just passes them unmodiﬁ ed to the server. However, if they’re not \nin the right format, it does the translation, either via a standard format or directly into the target format. This \nsaves the translation expense in many calls, but requires the server to support format translations for every \nformat it might see as input. \n Even when the client and server are running the same language in the same execution environment, some \nmachine-dependent translation may be required. This arises because there are two different ways of laying out \nbytes in words in computer memory, sometimes called little-endian and big-endian. The difference is whether \nthe bytes are laid out in increasing addresses starting with the least-signiﬁ cant byte (little-endian) or most-\nsigniﬁ cant byte (big-endian) within the word. In other words, is the low-order bit in the ﬁ rst or last position of \nthe word. (Intel and compatible processors use little-endian. Motorola, PowerPC, SPARC, and Java wire for-\nmat use big-endian. ARM and some PowerPC and SPARC processors are switchable.) When moving packets \nbetween systems, it may be necessary to translate between little-endian and big-endian format, even if both \nsystems are running the same implementation of the same language. Again this can be hidden by the proxies \nand stubs using one of the parameter translation mechanisms. \n Performance of RPC \n RPC is a heavily used mechanism when a TP system is distributed. Each transaction that’s split between two \nTP systems, such as between a client PC and a server back-end, needs at least one RPC to send the request and \nreturn the reply. It’s very important that this executes quickly. If it isn’t very fast, people will avoid using it, \nwhich completely defeats its purpose. \n There are basically three parts to the execution, which were illustrated in  Figure 2.12 . One is the proxy \nand stub programs that marshal and unmarshal parameters. The second is the RPC runtime and communica-\ntions software, which passes packets between the stub and the network hardware. And then there’s the network \ntransfer itself, which physically passes the messages through the communications hardware and over the wire \nto the other system. \n In most RPC systems, the time spent performing a call is evenly split among these three activities, all of \nwhich are somewhat slow. In a local area network, the overall performance is typically in the range of about \n10,000 to 15,000 machine-language instructions per remote procedure call, which is several hundred times \nslower than a local procedure call. So it’s very important to optimize this. There are lower-functionality research \nimplementations in the 1500 to 2000 instruction range. For web services that rely on text-based data formats, \nsuch as XML, performance is typically even slower. Techniques to make the system run faster include avoid-\ning extra acknowledgment messages, using the receiver-makes-it-right technique to make the proxies and stubs \nfaster, optimizing for the case where all the parameters ﬁ t in one packet to avoid extra control information and \nextra packets, optimizing the case where client and server processes are on the same machine to avoid the full \ncost of a context switch, and speeding up the network protocol. \n How to Compare RPC Systems \n RPC has become a standard feature of distributed computing systems, whether or not those systems run trans-\nactions. For example, Microsoft’s Windows operating systems and Linux support RPC as a built-in function. \n",
      "content_length": 4300,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 76,
      "content": " To get RPC integrated with transactions often requires using some transactional middleware. Many operating \nsystems have some of this integration built in. This appeared ﬁ rst in Tandem’s Guardian operating system and \nthen in Digital’s OpenVMS (both now part of HP). \n When shopping for a transactional middleware product, simply knowing that it supports RPC, or even RPC \nwith transactions, is not enough. You really have to go to the next layer of detail to understand the exact pro-\ngramming model and how difﬁ cult it is to write programs. Some of these interfaces are low-level and hard to \nprogram, whereas others are high-level and relatively easy to program. \n One thing to look for when evaluating RPC systems is which languages and data types are supported. For \nexample, some systems support only a generic proxy and stub procedure, which require application program-\nming to marshal parameters. Most proxies and stubs are unable to translate complex data structures such as an \narray. Or they may handle it as a parameter, but only for a certain language. Bulk data transfer is difﬁ cult using \nsome RPC systems, for example scrolling through a long table a portion at a time. \n Another issue is whether transactional RPC is supported. If so, what types of context are transparently \npropagated and what types are the application programmer’s responsibility? The types of context might include \nuser context, device context, security context, ﬁ le or database context, and of course transaction context. \n Popular RPC implementations include the Remote Method Invocation (RMI) in Java, the Internet Inter-ORB \nProtocol (IIOP) from CORBA , and the Microsoft RPC on Windows. RMI, IIOP, and Microsoft RPC closely \nfollow the concepts and implement the mechanisms described in the previous sections. \n 2.5  SHARED STATE \n There are many situations in which components of a TP system need to share state information about users, \nactivities, and the components themselves. Some examples of state information are the following: \n ■  Transaction — the transaction ID of the programs executing a transaction \n ■  Users — a user’s authenticated identity or the address of the user’s device \n ■  Activities — the identity or contents of the last message that one component sent to another, or temporary \ninformation shared between a client and the system, such as the contents of a shopping cart \n ■  Components — the identity of transaction managers that need to participate in committing a transaction, \nor the identity of processes that can handle a certain kind of request \n The rest of this section explores these kinds of state and mechanisms to share it. \n The kind of shared state we are interested in here is usually short-lived. That is, it is a state that can be dis-\ncarded after a few seconds, minutes, or hours, though in some cases it may be much longer than that. Often it \nis information that describes a current activity of limited duration, such as a transaction or a shopping session. \nIt is usually shared mostly for convenience or performance, to avoid having to send it repeatedly when compo-\nnents communicate. If this shared state is lost due to a failure, it can be reconstructed in the same way it was \ncreated in the ﬁ rst place — a nuisance and an expense, but not a catastrophe. \n Of course, a TP system also needs to manage long-lived, permanent state. Examples of such state are data-\nbases that contain information about accounts, loans, and customers in a bank; or information about products, \nwarehouses, and shipments in a retail business. In a sense, this information describes the state of the enterprise. \nThis is the information that transactions are keeping track of. Unlike the short-lived state, it must not be lost in \nthe event of a failure. This kind of long-lived state information is a very important part of TP systems, but it is \n not the kind of state that is the subject of this section. \n2.5 Shared State  57\n",
      "content_length": 3966,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 77,
      "content": "58  CHAPTER 2 Transaction Processing Abstractions\n Transaction Context \n Earlier in this chapter, we saw that each transaction has a transaction ID, and that each program that executes a \ntransaction has context information that includes its transaction ID. Thus, the transaction ID is state shared by \nthe programs executing a transaction. \n There are two design issues for any kind of shared state: how to establish the shared state and how to stop \nsharing and release the state. For transaction IDs, the ﬁ rst issue is addressed by native transactional RPC and \nWS-Transactions for SOAP. They propagate transaction context from caller to callee, to ensure that all pro-\ngrams executing the transaction have the same transaction context. \n The second issue is addressed in different ways, depending on whether the program is a resource manager \nthat needs to participate in two-phase commit. If so, then it retains the transaction context until after it pro-\ncesses the Commit operation in the second phase of two-phase commit. If not, and if it does not need to retain \ntransaction state across calls, then it can release its transaction state when it returns from the transactional RPC \nthat called it. If it does need to retain transaction state across calls, then it retains the transaction state until \nsome later time, determined either by two-phase commit or by the program itself. \n For example, in .NET, a program can release its transaction context by calling  SetComplete or  SetAbort \nbefore returning from a call. As we explained earlier, these operations tell the system that the transaction may \nor may not be committed (respectively) insofar as the caller is concerned. To retain the transaction context, the \nprogram calls  EnableCommit or  DisableCommit . These operations tell the system that the transaction may or \nmay not be committed (respectively) insofar as the caller is concerned, but unlike  SetComplete and  SetAbort , \nthey do not release the transaction context. These two situations — releasing or retaining transaction context — are \nspecial cases of stateless and stateful servers, which are discussed in more detail later in this section. \n In Java EE, context is managed using a context object that is created when the transaction is \nstarted. The Java APIs to release context are  javax.transaction.UserTransaction.commit and \n rollback — there’s no equivalent for  SetComplete but for  SetAbor t the Java extensions (Javax) API pro-\nvides  setRollbackOnly . \n Sessions \n A  communication session is a lasting connection between two system components, typically two processes, \nthat want to share state. The main reason to establish a session is to avoid having the components send the \nshared state information in each message. This saves not only the transmission cost, but also the sender’s cost \nof obtaining the state information when composing the message and the receiver’s cost of validating and sav-\ning the state information when receiving the message. The following are some examples of state information \nthat might be shared by a session: \n ■  The network address of both components, so they do not need to incur costly address lookups every time \nthey send a message to each other \n ■  Access control information, so each party knows that the other one is authorized to be sending it mes-\nsages, thereby avoiding some security checks on each message \n ■  A cryptographic key, so the components can encrypt information that they exchange in later messages \n ■  The identity of the last message each component sent and received, so they can resynchronize in case a \nmessage is not delivered correctly \n ■  The transaction ID of the transaction that both components are currently executing \n A session is created between two components by exchanging messages that contain the state to be shared. \nFor example, a component C 1 can send a message  REQUEST-SESSION(id, x) to component C 2 , which asks it to \n",
      "content_length": 3957,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 78,
      "content": " become a party to a new session that is identiﬁ ed by id and whose initial state is x. C 2 replies with a message \n ACCEPT-SESSION(id) , which tells C 1 that C 2 received the  REQUEST-SESSION message, agrees to be a party to the \nsession, and has retained the initial session state x. Usually, this is enough to establish the session. However, \nsometimes C 2 needs to be sure that C 1 received its  ACCEPT-SESSION message before it sends C 1 another message. \nIn that case it should require that C 1 acknowledge C 2 ’s  ACCEPT-SESSION message by sending a message  CONFIRM-\nSESSION(id) . In the latter case, the protocol to establish the session is called a  three-way handshake (see \n Figure 2.14 ). \n Sometimes a session is established as a side-effect of another message. For example, it might be a side-\neffect of the ﬁ rst RPC call from a client to a server, and it stays around until it times out. \n Each component that is involved in a session needs to allocate some memory that holds the shared state \nassociated with the session. This is usually a modest cost per session. However, the memory cost can be signif-\nicant if a component is communicating with a large number of other components, such as server with sessions \nto a million clients over the Internet. This is one good reason why HTTP is not a session-oriented protocol. \n Most sessions are transient. This means that if one of the components that is involved in a session fails, then \nthe session disappears. Continuing with our example, suppose component C 2 fails and loses the contents of its \nmain memory. Then it loses the state information that comprises the session. The other component C 1 involved \nin the session may still be operating normally, but it will eventually time out waiting for a message from C 2 , \nat which point it discards the session. If C 2 recovers quickly, before C 1 times out, then C 2 might reply to C 1 ’s \nattempt to re-establish contact. However, since C 2 lost the session due to its failure, it no longer has the shared \nstate of the session when it recovers. Therefore, it should reply to C 1 ’s message with a negative acknowledg-\nment, thereby telling C 1 to discard the session. If C 1 and C 2 want to re-establish their session after C 2 has recov-\nered, then they have to recreate the session from scratch. \n If C 2 had sessions with only a few other components at the time it failed, then re-establishing the sessions \ndoes not cost very much. However, if it had a large number of sessions at the time it failed, then re-establishing \nthem all at recovery time can be very time-consuming. During that time, C 2 is still unavailable. If one of the \ncomponents with which C 2 is re-establishing a session is slow to respond to the  REQUEST-SESSION or, even worse, \nis unavailable, then C 2 ’s availability may be seriously degraded waiting for that session to be established. \n A given pair of components may have more than one session between them. For example, they may have a \ntransport session for the network connection, a session for the application state, and a session for end user infor-\nmation. Although in principle these sessions could be bundled into a single session between the components, \nin practice they are usually maintained independently, because they have different characteristics. For example, \nthey may be established in different ways, use different recovery strategies, and have different lifetimes. \n To summarize, the beneﬁ t of using sessions is to avoid resending and reprocessing the same information \nover and over again in every message exchange between a pair of components. The costs are the time to estab-\nlish the session and to recover it after a failure, which in turn negatively affects availability. \n1.  REQUEST-SESSION(id, x) \n2.   ACCEPT-SESSION(id)\n3.  CONFIRM-SESSION(id)\nComponent\nC2\nComponent\nC1\n FIGURE 2.14 \n Three-Way Handshake to Create a Session. Component C 1  initiates the protocol by requesting to establish a session. C 2 \nagrees to be a party to the session. Finally, C 1 acknowledges receipt of that agreement. \n2.5 Shared State  59\n",
      "content_length": 4109,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 79,
      "content": "60  CHAPTER 2 Transaction Processing Abstractions\n One common use of sessions in TP is to connect an application component to a database system. The session \nstate typically includes a database name, an authenticated user ID, and the transaction ID of the current trans-\naction being executed by the application component. When the application component creates the session via \n REQUEST-SESSION , it includes the user ID and password as parameters. They are validated by the database system \nbefore it replies with  ACCEPT-SESSION . The database system executes all the operations it receives from the applica-\ntion component on behalf of the session’s user. Thus, operations only succeed if the session’s user has privileges \nfor them. All the operations execute within the session’s transaction. After the application commits the transac-\ntion, the session either automatically starts a new transaction (i.e., if it uses the chained transaction model) or it no \nlonger is operating in the context of a transaction (i.e., if it uses the unchained transaction model). \n Another common use of sessions in TP is to connect transaction managers that participate in the two-phase \ncommit protocol for a given transaction. The protocol for establishing sessions between these participants is a \nmajor part of a two-phase commit implementation and is discussed in Chapter 8. \n Stateless Servers \n Consider a session between a client process and a server process, where the client calls the server using RPC \nin the context of the session, so both the client and server can use the session’s shared state. There are three \nproblems that arise in this arrangement: \n 1.  The session ties the client to a particular server process. In a distributed system with multiple server pro-\ncesses that are running the same application, it is desirable for a given client to be able to send different \nrequests to different server processes; for example, to use the most lightly loaded one. However, if the \nclient is relying on the server to retain state information about their past interactions, then it does not have \nthe freedom to send different requests to different servers. All its requests have to go to the same server, \nnamely, the one that is keeping track of their shared state. \n 2.  If the server fails, then the session is lost. Since the client was depending on the server to remember the \nstate of the session, the server needs to rebuild that state after it recovers. The server can do this either \nby having the client resend that state or by recovering the state from persistent storage, which in turn \nrequires that the server saved the state in persistent storage before it failed. \n 3.  If the server is servicing requests from a large number of clients, then it costs a lot of memory for it to \nretain a shared state. Moreover, the problem of rebuilding sessions after a failure becomes more acute. \n For these three reasons, it is sometimes recommended that server processes be  stateless . That is, there is no \nsession between the client and server processes, and the server retains no application state after it services and \nreplies to a client’s request. Thus, it processes each request message from a clean state. Let us reconsider the \npreceding three problems for stateless server processes. First, if there are multiple server processes running the \nsame application, then successive calls from a client can go to any of the server processes since none of them \nretain any state from the client’s previous calls. Second, if a stateless server process fails, then it has no applica-\ntion state that it needs to recover. And third, a stateless server process does not incur the memory cost of retain-\ning shared state. \n The recommendation that servers be stateless applies mainly to communication between middle-tier serv-\ners and front-end processes associated with an end-user (i.e., clients), such as a browser or other presenta-\ntion manager on a desktop device. This is a case where these three problems are likely to appear: (1) a client \nmay want to send different requests to different servers, depending on server load; (2) re-establishing client-\nserver sessions may be problematic, because clients can shut down unexpectedly for long periods and because \n",
      "content_length": 4284,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 80,
      "content": " a server would need a large number of these sessions since there is typically a large number of clients; and \n(3) the server would need to dedicate a lot of memory to retain shared state. \n By contrast, this recommendation usually does not apply to communication between a middle-tier server \nand a back-end server, which are often database systems. As mentioned earlier, there usually  are sessions \nbetween a middle-tier server and each back-end database system it invokes. Therefore, the back-end server \nis stateful with respect to the middle-tier servers that call it. Thus, the preceding three problems need to be \naddressed. We will discuss solutions in the next section. \n It may sound a little strange to hear about stateless middle-tier server processes, because of course a TP \napplication needs to store a lot of application state in databases. The point is that this database state is the only \nstate that the stateless server process depends on. The server process itself does not retain state. Thus, if the \nserver fails and subsequently recovers, it doesn’t need to rebuild its internal state, because all the state that it \nneeds is ready and waiting in the databases it can access. \n A well-known example of a stateless middle-tier process is the use of a web server for HTTP requests \nfor static web pages. All the state needed by the web server is stored in ﬁ les. After servicing a request, a web \nserver does not need to retain any state about the request or response. Since such web servers are stateless, if \nthere are multiple web server processes, then each request can be serviced by a different web server. And if a \nweb server fails and is then restarted, it has no state that needs to be recovered. \n Stateful Applications \n Having just explored reasons why stateless applications are beneﬁ cial, let us now examine cases where a middle-\ntier application needs to retain state information across multiple front-end requests. Here are four examples: \n 1.  A user request requires the execution of several transactions, and the output of one transaction may \nneed to be retained as input to the next. \n 2.  A middle-tier server wants to retain information about a user’s past interactions, which it will use for \ncustomizing the information it displays on later interactions. \n 3.  A front end establishes a secure connection with a server using authentication information, which \nrequires it to cache a token. \n 4.  A user wants to accumulate a shopping cart full of merchandise before actually making the purchase. \n In each of these scenarios, the state that is retained across client requests has to be stored somewhere. There \nare several places to put it, such as the following: \n ■  Save it in persistent storage, such as a database system. The operation that stores the state should be part \nof the transaction that produces the state, so that the state is retained if and only if the transaction that \nproduces it commits. \n ■  Save it in shared persistent storage, but not within a transaction. \n ■  Store it in volatile memory or in a database that is local to one server process. This makes the server \nstateful. Whether or not there is a communication session, future requests from the same client need to \nbe processed by the server that has the shared state. \n ■  Return it to the caller that requested the transaction execution. It is then the caller’s responsibility to save \nthe state and pass it back to the server on its next invocation of that server. \n Wherever the state is stored, it must be labeled with the identity of the client and/or server, so that both client \nand server can ﬁ nd the state when they need it. \n2.5 Shared State  61\n",
      "content_length": 3692,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 81,
      "content": "62  CHAPTER 2 Transaction Processing Abstractions\n Let us explore these ways of managing state and client-server identities in examples (1) to (4) in the  pre-\nvious list. The ﬁ rst scenario is a business process, that is, a user request that requires the execution of mul-\ntiple transactions. A variety of state information is accumulated during a business process execution. This state \nincludes a list of the business process steps whose transactions have committed and those that have yet to be \nexecuted. It may also include results that were returned by the transactions that committed, since these results \nmay be needed to construct input to other transactions in the business process (see  Figure 2.15 ). For example, \nif a travel reservation executes as a business process, then the arrival time of the ﬂ ight that is returned by the \nﬂ ight reservation transaction may be needed to construct the input to a car rental reservation transaction, since \nthat input requires a pick-up time. This information also needs to be saved so it can be returned to the client \nwhen the business process has ﬁ nished executing. \n Like any transaction, each transaction that executes as part of a business process should execute at most \nonce. Therefore, the business process state must be maintained in persistent storage. If it were stored in volatile \nmemory instead of persistent storage, and the contents of that memory were lost due to a failure, then it could \nnot be reconstructed by executing the business process ’ transactions again (because transactions should execute \nat most once). For the same reason, the state must be updated by each transaction that executes as part of the \nbusiness process. Suppose the application is written so that the result of the transaction is stored in the business \nprocess state after the transaction committed. If a failure occurs between the time the transaction commits and \nthe time its results are supposed to be written to the business process state, then those results would be lost. \n In scenario (2) the server keeps track of a user’s interactions over a long period of time. For example, it \nmay remember all the user’s past orders and past window-shopping. It may use this information to suggest \nnew products that are likely to be of interest based on that past behavior. In this case, the shared state needs to \nbe identiﬁ ed by a long-lived name. The user’s e-mail address commonly is used for this purpose. But in some \ncases it might not be good enough, since the user may access the server both from home and the ofﬁ ce, and \nmay switch e-mail providers from time to time. The user’s full name and address might be better, although this \ntoo has problems due to variations in spelling and typos. Thus, depending on the requirements, selecting and \nusing long-lived names can be a nontrivial design problem. \n In scenario (3) a client browser establishes a secure connection with a server by exchanging authentication \ninformation. The connection establishes trust between the client and server so that the authentication informa-\ntion does not have to be passed on each subsequent call. The server caches the authentication token and identi-\nﬁ es it with the connection to the browser. This is handy because then the user does not have to log in again and \ncan submit multiple requests during the same session to the same resource. Since the connection is established \nas secure, the user’s credentials do not have to be presented on each request. \n Scenario (4) concerns creating and maintaining a shopping cart. Each item that a user selects to buy is put \ninto the user’s shopping cart. Since a user may be shopping for awhile, the shopping cart may be stored in a \nT1\nPersistent\nResource \nSave output\nT2\nT3\nT4\n FIGURE 2.15 \n Retaining State in a Business Process. Each transaction in a business process saves the process state for use by the \nnext transaction in the sequence. \n",
      "content_length": 3941,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 82,
      "content": " database or other persistent storage, to avoid the expense of using main memory for information that is infre-\nquently accessed. This need not be written in the context of a transaction. However, the shopping cart is not \nthe permanent state. The server system retains the shopping cart until either the user checks out and purchases \nthe items in the cart, or until a time-out has occurred after which the server disposes of the shopping cart. The \nshopping cart is the shared state between the user and the system. So is the user ID that the system needs to \nknow in order to ﬁ nd the user’s shopping cart while processing each of the user’s operations. \n What user ID should be associated with the shopping cart? If the server is stateful, the session ID can be \nused to identify the user and hence the shopping cart. If the session goes away before the customer purchases \nthe contents of the shopping cart, then the shopping cart can be deleted. If the server is stateless, and the user \nhas not identiﬁ ed herself to the server, then the system must generate a user ID. Since the server is stateless, \nthat user ID must accompany every call by that user to the server. One way to do this is to ensure that all calls \nfrom the client to the server, and all return messages, include the server-generated user ID. Since this is rather \ninconvenient, a different mechanism has been adopted for web browsers, called cookies. \n A  cookie is a small amount of information sent by a server to a web browser that the web browser then \nstores persistently and returns to the same server on subsequent calls. For example, when an anonymous user \nplaces his or her ﬁ rst item in a shopping cart, the server that performs the action could generate a user ID for \nthat user and return it in a cookie. The user’s subsequent requests to that server would contain the cookie and \ntherefore would tell the server which shopping cart is relevant to those subsequent requests. Thus, the cookie is \nthe shared state between the web browser and the server. \n A cookie has a name, domain, and path, which together identify the cookie. It also has a value, which is \nthe content of the cookie, such as a server-generated user ID for the shopping cart. For privacy reasons, the \nbrowser should send the cookie with HTTP requests only to the cookie’s domain (e.g., books.elsevier.com). \nSince cookies are easily sniffed, they are also usually encrypted. Each cookie also has an expiration date, after \nwhich the browser should dispose of the cookie. \n Cookies are sometimes not available, for example, because a user disabled them in the browser. In this \ncase, the server can use a different technique, called  URL rewriting . Before the server sends an HTML page \nback to the browser, it rewrites all the URLs on the page to include the user’s session ID. For example, it could \nappend  “ ;jsessionid \u0005 1234 ” to every URL on the page. That way, any action that the user takes on that page \ncauses the session ID to be sent back to the server. \n URL rewriting is less secure than an encrypted cookie, since it can be seen by others. Moreover, an unsus-\npecting user might copy the rewritten URL into an e-mail to send to a friend, who might thereby have access \nto the sender’s private session information. \n In summary, maintaining the state across multiple requests requires a fair bit of design effort to choose \nwhere and how the state is identiﬁ ed and maintained. For this reason, it is worthwhile to design an application \nto limit the use of shared state whenever possible. \n 2.6  SCALABILITY \n Scaling up a TP system to handle high load involves two activities. First, one can tune and grow each indi-\nvidual server system to handle the maximum possible load. And second, one can distribute the load across \nmultiple interconnected server systems. The decision of which approach to take depends on cost-performance \nas well as other goals, such as availability, security, and manageability. In this section we focus on the mecha-\nnisms that enable scaling up system performance. \n2.6 Scalability  63\n",
      "content_length": 4092,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 83,
      "content": "64  CHAPTER 2 Transaction Processing Abstractions\n Scaling up a Server \n The throughput of a server system is ultimately dependent on its hardware conﬁ guration; that is, on the speed \nof its processors, on the size and speed of main memory and secondary storage, and on the bandwidth and \nlatency of its interconnects. Software too plays a major role. For a given hardware conﬁ guration, there are \ntwo techniques that are commonly used to get the most beneﬁ t from that conﬁ guration: caching and resource \npooling. \n Caching \n A cache is an area of memory containing data whose permanent home is elsewhere, such as in secondary stor-\nage or on a remote server system. Ideally, the cache contains data that frequently is accessed by programs run-\nning on the system containing the cache and that is much cheaper to access than its permanent home. Thus, the \nexpense of retrieving the data from its permanent home is amortized across a large number of accesses. This \ngreatly improves performance over a system in which every access to the data requires accessing the data’s \npermanent home. \n Since many components of a TP system need to access data that is not local to the component, caches are \nheavily used in TP. A web browser may cache pages of frequently accessed web sites, to avoid having to go \nto the web site every time those pages are requested. A web server may cache information that is needed to \nservice popular requests, such as the information displayed in response to a client’s initial request to access \nthe web site. A proxy server, which sits between the network and the web server, also offers this caching func-\ntionality. Some large data items, such as images, may be cached at a third-party’s web site that is closer to the \nend user and can therefore offer higher speed access to the information. A server running a TP application may \ncache popular data whose permanent home is a remote database system. And the database system itself may \ncache data whose permanent home is secondary storage. \n The ofﬁ cial copy of a data item in its permanent home may be updated shortly after that copy was read and put \ninto a cache. Therefore, once data has been put into a cache (somewhere other than its permanent home), it poten-\ntially is no longer up to date. Thus, a cache is most appropriate for data that is infrequently updated. For example, \nin a TP system, it is probably useful to cache catalog information, since its content changes slowly. But it may not \nbe useful to cache the latest bid in an auction that will close shortly, since it may be updated very frequently. \n The implementation of a cache requires a fast way to look up entries. This usually is done using a hash \nalgorithm that maps the identiﬁ er of a data item to its memory location in the cache. It also requires a  replace-\nment algorithm , which selects an item to remove from the cache to make room for a new item that has to be \ninserted. A commonly used replacement algorithm is  least-recently-used , which replaces the item whose last \naccess was longest in the past among all items in the cache. There is a large repertoire of cache replacement \nalgorithms used in practice. However, coverage of these algorithms is beyond the scope of this book. \n Sometimes , items in the cache are  invalidated before they need to be replaced. Invalidation is done if it \nis known that the item is unlikely to be fresh enough to be used. When a server stores an item in its cache, \nit may include an invalidation time that the cache manager enforces. For example, a web server may add an \ninvalidation time 10 minutes in the future when it caches a copy of a headline news banner, thereby ensuring it \nrefreshes the headline from the news server at least that often. \n Alternatively , the server that is the data’s permanent home may keep track of which caches have a copy \nof that data. After the server processes an update for that data, it can issue an  invalidation message to every \ncache that has a copy, which tells the cache to invalidate its copy of that data. This helps to ensure that the \ncaches are  coherent ; that is, that a data item has the same value in all caches that currently hold the data item. \nClearly, there are limits to cache coherence due to variance in the time it takes for each cache to receive an \ninvalidation message and process it. \n",
      "content_length": 4366,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 84,
      "content": " A cache may be updatable. Each update to a data item in the cache must be propagated back to the data item’s \npermanent home. Sometimes, this must be done explicitly by the client of the cache. That is, it stores the updated \ndata item in both the cache and the data item’s permanent home. If the cache manager knows how to map each \ncached data item to its permanent home, then the client may only need to update the cache and the cache man-\nager propagates the update to the data item’s permanent home. If the cache manager propagates the update imme-\ndiately as part of the operation to update the cache, then the cache is called  write-through . If it propagates the \nupdate lazily, potentially long after the cache was updated, then the cache is called  write-back . \n Clearly , cache coherence is affected by the way that updates to the cache are propagated. For example, if \nthe data item’s server uses invalidation messages to notify caches when the item has changed, then a write-\nthrough cache will yield better cache coherence than a write-back cache. But this better coherence has a cost. \nUsually, the cost of the write-back cache is lower, since multiple updates to the same cached data item within \na short time period incur only one write-back, and a write-back can batch multiple updates in a single message \nto the data’s permanent home. \n Since caching mechanisms are complex and important, they are built into many types of products, notably \ntransactional middleware and database systems. There are main memory database systems that are intended \nto be used for cached data. Some operate as a conventional transactional resource manager, such as Oracle’s \nTimesTen, McObject’s eXtremeDB, and Raima’s RDM. Others are designed speciﬁ cally for caching, for exam-\nple, by offering the application explicit control of when to invalidate cached data or write-back updated cached \ndata to its home location. Examples include Danga Interative’s memcached, Oracle’s Coherence and Microsoft’s \nproject codenamed  “ Velocity. ” \n Resource Pooling \n Another case where caching can improve performance is when a resource is costly to create and relatively inex-\npensive to access. Sessions are one such resource. Consider an application that requires the use of a database \nsystem. The server process that runs this application needs a session with a database system for each transac-\ntion currently running. However, each transaction typically needs the session only for a fraction of a second. \nTherefore, the server process can maintain a pool (i.e., cache) of sessions. Each transaction is given exclusive \nuse of one of the sessions while it is running. After it commits or aborts, the session is returned to the pool. \nThus, sessions are  serially reused by different transactions. \n Process threads are another example of resources that can be pooled and serially reused. The process has a \nﬁ xed number of threads. When it receives an RPC, the RPC is assigned to a thread in which to execute. After \nthe RPC ﬁ nishes executing and returns to its caller, the thread is returned to the thread pool. \n A third example is server classes, which avoid the overhead of frequent process creation. Like threads, each \nprocess receives a call. After the call completes, the process is available for reuse by another call. \n Scaling Out a System \n One way to scale up a system is to add more machines. This is called  scale-out . There are two approaches \nto scale-out, partitioning and replication, which offer different ways of distributing the workload across the \nmachines. \n Partitioning \n One way to distribute the workload is to  partition the application and its data into different types of work and \nassign each type to a different machine. For example, in a bank, one might assign the credit card application \nto one system, the loan application to a second system, and the checking account application to a third system. \n2.6 Scalability  65\n",
      "content_length": 3961,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 85,
      "content": "66  CHAPTER 2 Transaction Processing Abstractions\n When a request arrives, it is directed to the system that supports the relevant application. This can be done by \nstoring the mapping between applications and servers in a registry service and looking up the mapping for \neach request, as was described in Section 2.4. \n Partitioning by application type is an effective technique. However, it is an incomplete solution if an appli-\ncation needs to scale up beyond the capabilities of a single machine. Then the application itself needs to be \npartitioned. A common way to do this is  range partitioning , where different copies of the server handle dif-\nferent ranges of an input parameter. For example, a debit-credit application dealing with retail banking might \nbe split into ﬁ ve servers, each of which handles a range of account numbers (see  Figure 2.16 ). The database \nthat supports each of these servers can be local to the system that supports those account numbers. So the \nﬁ rst group of account numbers is stored on the same computer as the application program that supports those \naccount numbers, and so on. \n When the system is organized in this way, a routing function needs to forward each request to the correct \nserver based not only on the identiﬁ er of the request type, but also on one or more of the input parameters. In \nthe example, it would be the account number. This is called  parameter-based routing . \n Range partitioning can be implemented directly by the application, by having the application support the \nrouting function. Many systems provide built-in support. For example, range partitioning and parameter-based \nrouting are supported by many high-function database systems and some transaction middleware products. \n Partitioning schemes all suffer from the problem of load balancing, especially when servers are partitioned \nstatically. Usually, the workload varies over time. For example, in the system shown in  Figure 2.16 there may \nbe a burst of activity for accounts in the 20,000 to 39,999 range, thereby overloading the second server. This \nproblem may arise frequently if the load is correlated with value ranges. For example, if account numbers are \ncorrelated with geographical regions, then a peak period in one time zone will cause its partition’s servers to be \nmore heavily loaded than those of other partitions. An overloaded partition will perform poorly. It doesn’t help \nthat other servers may be less heavily loaded, because they don’t have the data required to service requests in \nthe 20,000 to 39,999 range. \nRouter\nApplication\nAccounts\nin the range\n0–19,999\nAccounts\nin the range\n20,000–39,999\nAccounts\nin the range\n40,000–59,999\nAccounts\nin the range\n60,000–79,999\nAccounts\nin the range\n80,000–99,999\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\nDebit-Credit\nApplication\nServer\n FIGURE 2.16 \n Parameter-based Routing. The router application forwards each request to the appropriate server based on the account \nnumber parameter in the request. \n",
      "content_length": 3094,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 86,
      "content": " One way to reduce the frequency of such overload situations is to use  hash partitioning , where a hash \nfunction is used to map each parameter value to a server partition. A well-designed hash function will, with \nvery high probability, spread the load evenly across servers. It therefore is less likely to exhibit load-balancing \nproblems than range partitioning. Hash partitioning commonly is used not only for partitioning a database but \nalso for partitioning a large-scale cache that is spread across many servers. \n One solution to load balancing is  automatic reconﬁ guration . That is, when a partition becomes over-\nloaded, it automatically is split into two partitions and the routing function is updated accordingly. The deci-\nsion to split a partition should be based on workload trends, not a short-term spike in load. If a partition is split \nbased on a temporary load spike, the split partitions will be underutilized after the spike dissipates. \n Another solution to load balancing is to use  table-lookup partitioning , where a mapping table explicitly \nmaps each input parameter value to a particular server. There is a signiﬁ cant cost to maintaining all this mapping \ninformation when a lot of parameter values are present, though this can be mitigated with the use of some net-\nwork switches, such as Layer 7 switches. This partitioning approach offers some signiﬁ cant beneﬁ ts over range \nand hash partitioning. One beneﬁ t is ﬁ ne-grained control over reconﬁ guration. When a server overﬂ ows, a new \nserver can be allocated and newly added parameter values can be assigned to the new server. Another beneﬁ t \nis that different parameter values can be explicitly assigned levels of service. For example, a bank may offer \ntwo levels of service to checking accounts, depending on their minimum monthly balance. This account-type \ninformation can be stored in the mapping table and the account stored at a server that supports the appropriate \nlevel of service. A third beneﬁ t is that users can be upgraded to a new release of an application one by one. By \ncontrast, with range or hash partitioning, the application would not know whether to access a user’s data in the \npartition using the old or new format. Thus, all the parameter values (e.g., accounts) in a partition would be inac-\ncessible while the upgrade was in progress. \n Whatever partitioning scheme is used, conﬁ guring a system with the right amount of server capacity is \nimportant. Servers need to be conﬁ gured for peak load, not average load, to ensure that they can offer good \nresponse time even in periods of high load. The more extra capacity (or  headroom ) that each system offers \nrelative to its expected peak load, the less likely it will become overloaded. \n Partitioning Sessions \n Partitioning also helps scale-out when communication sessions are required. In a two-tier architecture, if there \nare many clients and each client requires a session with every server, the result is a polynomial explosion in the \nnumber of sessions. For example, if there are 100,000 clients and each one has to connect to all 500 servers, \nthen each server would have 100,000 sessions, resulting in 50,000,000 sessions overall (see  Figure 2.17 ). Each \nsession consumes some main memory and requires some setup time. When there are too many sessions, this \nsession overhead can be troublesome. It can limit the ability of the server system to scale out by adding more \nservers. \n The total number of sessions can be greatly reduced by inserting a routing layer between the clients and \nservers that partitions the set of clients. Each router process connects to a subset of the clients and to all the \nservers. Thus, each client can still send messages to all servers, at the cost of an extra message hop through a \nrouter. See  Figure 2.18 . \n Now say you have 10 routers between the clients and servers, and each client is connected to one router. \nEach of the 10 routers would have 10,000 sessions to their clients and 500 sessions to all the servers, result-\ning in 10,500 sessions per router, or 105,000 sessions overall — a huge reduction from the 50,000,000 sessions \nrequired without the routing layer. \n Grouping clients by routers can be based on geographical considerations. For example, all the clients on \na given local area network might be serviced by the same router. More complex groupings may be needed \n2.6 Scalability  67\n",
      "content_length": 4432,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 87,
      "content": "68  CHAPTER 2 Transaction Processing Abstractions\n for fault tolerance reasons. For example, the ATMs at a bank branch may be split across two routers over two \nseparate communication lines, so the failure of one router still leaves half of the ATMs operating. \n Replication \n Another way to distribute workload is to replicate server processes and assign the replicas to different systems. \nThe replicas are identical, in the sense that they can all process the same kinds of requests. This works espe-\ncially well if the processes are stateless. In that case, each request can be assigned to any of the replicas, even \nif a previous request from the same client was processed by a different replica. \n As in the partitioning approach, it is desirable to balance the load across the replicated servers. This can be \ndone by having each request randomly choose a server to process the request, sometimes called  spraying the \nrequests across the servers. It can be done by the client that issues the request, or it can be done in a server sys-\ntem. For example, a network router that connects a server system to the Internet might have built-in load bal-\nancing functionality to forward messages based on round robin, least number of active connections, or fastest\nresponse time. \n Even if each client sends the same number of requests to each server, the load may not be distributed evenly, \nbecause one server may receive requests that require more time to service than those received by another server. \nTo avoid this unbalanced load, each client can put requests into a queue that is shared by all servers, and each \nClient\nClient\nClient\nServer\nServer\nServer\n FIGURE 2.17 \n Polynomial Explosion in Two-Tier Model. If there are f front-end programs and t transaction servers, then there are f  \u0004  t \nsessions. \nClient\nClient\nClient\nClient\nRouter\nRouter\nServer\nServer\nServer\n FIGURE 2.18 \n Multilevel Routing. By introducing routers in between clients and servers, the overall number of sessions is greatly \nreduced, compared to the two-tier model of  Figure 2.17 . \n",
      "content_length": 2069,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 88,
      "content": " server dequeues a request whenever it is idle. Thus, each server obtains new work if and only if it has additional \ncapacity to process it. The main disadvantage of this approach is the overhead of managing the queue. It needs \nto be accessible to all the servers, and clients and servers need to synchronize their accesses to the shared queue. \nWe will have a lot more to say about queuing mechanisms in Chapter 4. \n Replication interacts with caching. Suppose a server is replicated and a client process  C issues a request  r \nthat accesses one of those server replicas,  S . To process  r ,  S may access remote data, which  S saves in a cache. \nFor example,  C may be a web browser running on a desktop machine and  S may be a web server at a site that \nhas a large number of web servers running. The request may access a web page, which is cached by  S . A given \nclient often issues many similar requests. If  C issues a request  r \u0003 that is similar to  r and hence accesses the \nsame data as  r , then it would be cheaper to process  r \u0003 at  S rather than at a different server replica that has not \ncached the data required by  r \u0003 . In this case, we say that  C has  cache afﬁ nity for  S . Although  C can still access \nany of the server replicas, it performs better when accessing  S than any of the other server replicas. \n A more extreme example of afﬁ nity occurs when a server replica  S is maintaining shared state with respect \nto a client  C . In this case, it is essential that all requests from  C be serviced by  S , so the request has access to \nthe shared state. Notice that this problem does not arise if  C maintains the shared state. That is, if  C includes \nthe shared state with every request, then any server replica can process a request, because the server replicas \nare stateless with respect to  C . \n When replicas contain updatable data, updates must be propagated to all replicas to keep them identical. \nA common conﬁ guration is to require that all updates be applied to a primary replica, which forwards those \nupdates to the other read-only replicas. This offers simpler synchronization than immediately broadcasting \nupdates to all replicas, but introduces delay by passing all updates through the primary replica. Synchronization \nalgorithms for replicated data are covered in Chapter 9. \n Replication is a common feature of database systems. It can also be used to implement cache coherence. If \na replicated cache is updatable, then a replication mechanism can be used to propagate updates from one cache \nto all the others. \n Replication also is used to improve availability. If one replica is unavailable, then its workload can be han-\ndled by other replicas. Techniques for using replicas in this way are also covered in Chapter 9. \n 2.7  SUMMARY \n This chapter covered major software abstractions needed to make it easy to build reliable TP applications with good \nperformance: transaction bracketing, threads, remote procedure calls, state management, and scalability techniques. \n Transaction Bracketing \n Transaction bracketing offers the programmer commands to start, commit, and abort a transaction. The opera-\ntions on data that execute after the Start command and before the Commit or Abort are part of the transaction. \nIn the chained model, a new transaction begins immediately after a Commit or Abort, so all operations are part \nof some transaction. \n The transaction composability problem arises when a program running a transaction calls another program. \nThere is a choice of bracketing semantics, depending on whether the callee should or should not execute within \nthe caller’s transaction. If so, the caller’s transaction ID must be passed to the callee. \n In the nested transaction model, the callee executes in a subtransaction. A subtransaction abort undoes its \nactions, but leaves its parent transaction intact. It is up to the top-level transaction to decide whether to commit \n2.7 Summary  69\n",
      "content_length": 3967,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 89,
      "content": "70  CHAPTER 2 Transaction Processing Abstractions\n all its committed subtransactions ’ work, thereby making its results durable. Savepoints are a related technol-\nogy that enable single-threaded transactions to back up to a previous state, much like subtransaction abort. \n Another approach to transaction bracketing is to tag each component with an attribute that indicates \nwhether an invocation of the component should run in a new transaction, in the caller’s transaction, or in no \ntransaction. This approach commonly is used in object-oriented transactional middleware products, instead of \nexplicit commands to start, commit, and abort. \n A transaction program needs to provide compensation steps and exception handling code for transaction \nfailures and system failures. The programming model needs a way to expose the reason for the exception, the \nstate that is available if the exception handler executes after an abort or recovery from a system failure, and \nwhether the handler itself executes within a transaction. \n Processes and Threads \n Each program executing in a processor has an address space and control thread, called its processor state. In a \nmultiprogrammed computer system, each program’s processor state can be temporarily stored in main memory \nor on disk and reloaded when the program resumes execution. A TP system architecture must take into account \nwhether its related programs are running in the same or different address spaces, since this can affect perfor-\nmance and management. \n The behavior of a TP system is affected by whether the components of the system share an address space \nand control thread. Although it is possible to deploy all components of the TP system in a single-threaded \nprocess, it leads to a system with a large number of processes, typically at least one per executing transac-\ntion. Better performance and scalability usually is obtained with multithreaded processes, due to reduced main \nmemory requirements, fewer context switching operations, and ﬁ ner grained tuning opportunities. If middle-\nware implements the multithreading, then it must intercept synchronous I/O to avoid blocking the entire pro-\ncess during such operations. The more popular approach is to use threads supported by the operating system. \n When multithreading is unavailable, an alternative is server classes, where multiple copies of a TP compo-\nnent are replicated in multiple single-threaded servers. Executing the same code in a pool of single threaded \nprocesses can produce similar beneﬁ ts to executing the same code in multiple threads of the same process. \n Remote Procedure Calls \n A remote procedure call (RPC) mechanism provides a programming model and runtime environment that \nallows a program to invoke a program in another address space as if it were a local call within the same address \nspace. With an RPC, the programmer either receives a return from the call or an error indicating that the pro-\ngram didn’t run, just as if the call were performed locally. \n An RPC mechanism uses an interface deﬁ nition language to produce a proxy linked to the local program \nand a stub linked to the program in the remote address space. Proxies and stubs abstract distributed comput-\ning details such as data marshaling and the communications protocol from the programs involved in the call. \nIn an object-oriented RPC, the proxy may use a local object as a surrogate for the remote object being called. \nA transactional RPC uses the proxies and stubs to propagate the transaction context, including the transaction ID,\nfrom the caller to the callee. \n Before performing an RPC, a client needs to create a binding to the server, for example, by looking up the \nserver’s network address in a registry service. To perform an RPC securely, the client and server need to be \nauthenticated and the server needs to check that the client is authorized to do the call. The runtime needs to \nmonitor each call to ensure it succeeds. If the client runtime does not receive an acknowledgment, then it can \neither repeat the call or ping the server, depending on whether the server is idempotent. The runtime might also \ntranslate parameters between different machine formats to enable interoperability. \n",
      "content_length": 4240,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 90,
      "content": " All this functionality has a price. RPCs are much slower than local procedure calls and simple message \npassing. But since RPC functionality usually is needed, the only alternative is to move the burden to the appli-\ncation programmer, which makes application programming more time-consuming. Hence, transactional RPC \nis a popular feature of transactional middleware and underlying platforms. \n Shared State \n To process transaction requests correctly, components of a TP system need to share state information about \nusers, security tokens, transaction IDs, and the locations and characteristics of other system components. When \nall the components are deployed within a single address space, they can easily share this state. When the com-\nponents are distributed across multiple address spaces, this sharing becomes more challenging. \n This problem can be circumvented by using stateless servers, which do not share state with the client that \ncalls them. Instead of sharing state, each client request includes all state information that the server needs for \nprocessing the request. For example, a browser can retain a cookie, which is the server state that is stored at the \nclient and passed by the client to the server in each request. \n One important type of shared state is a transaction ID, which identiﬁ es a transaction context and is shared \nacross programs that participate in the same transactional unit of work. A transaction context typically is asso-\nciated with a thread of execution and can be propagated from one program to another, for example when using \nan RPC. \n A communication session is a way of sharing state between processes on different machines. Typical session \nstate includes transaction context and security information. By creating a shared session, two processes avoid \nhaving to pass state information on every interaction. However, sessions require messages to set up and memory \nto store their state. Thus, they are primarily useful when information is shared for a relatively long period. \n Scalability Techniques \n Several abstractions are needed to help a TP system scale up and scale out to handle large loads efﬁ ciently, \nincluding caching, resource pooling, and data partitioning and replication. Using these abstractions improves \nthe ability of a TP system to share access to data. \n Caching is a technique that stores a copy of persistent data in shared memory for faster access. The major \nbeneﬁ t of caching is faster access to data. If the true value of the data in its permanent home needs to be \nupdated, then synchronization is required to keep the cache values acceptably up to date. \n Resource pooling is a mechanism that reuses a resource for many client programs, rather than creating \na new resource for each program that needs the resource. For example database connections can be pooled. \nA database connection is allocated to a program when it needs to use the database and returned to the pool when a\nprogram’s task is completed. \n Partitioning is a technique for improving scalability by segmenting resources into related groups that can \nbe assigned to different processors. When a resource type is partitioned, the TP system routes requests for the \nresource to the partition that contains it. For example, if a database is partitioned, an access to a data item is \nrouted to the database partition that contains the data item. \n Replication is a technique for improving scalability by spreading the workload across multiple identical \nservers. Clients can either push their work onto particular servers or enqueue the work and have the servers \npull from the queues. A client may have afﬁ nity for a server that has cached data that it frequently accesses, in \nwhich case it prefers sending its workload to that server. Replication can also be used to improve availability \nby using backup replicas to handle the load of a failed replica. One major challenge of replication is to keep \nupdatable replicas mutually consistent at an affordable cost. \n2.7 Summary  71\n",
      "content_length": 4037,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 91,
      "content": " \nThis page intentionally left blank\n",
      "content_length": 37,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 92,
      "content": " 3.1  INTRODUCTION \n From the end user’s point of view, a transaction processing (TP) application is a serial processor of requests. \nIt is a server that appears to execute an inﬁ nite loop whose body is an ACID transaction, such as the following \npseudo-program: \n Do Forever \n    /* the body of this loop is a transaction */ \n    receive a request \n    do the requested work \n    send a reply (optional) \n End \n However , as we saw in Chapter 1, the behind-the-scenes reality is more complex. Usually, the user is execut-\ning on a front-end machine that is remote from the server machine that executes the transactions. Often the \nserver is itself a distributed system, primarily so that it can scale up to handle a large number of requests. \n To process a request, the actual control ﬂ ow within a TP application is more like this: \n ■  The front-end program captures the user’s request using a combination of forms and menu selections, \ntypically executing in a web browser or more specialized input device, such as an ATM or gas pump. \n ■  The front-end program translates the input into a request message and sends it to a server. \n ■  A middle-tier or back-end server examines the request message to determine what type of transaction is \nbeing requested and which application program  P should process the request. \n ■  The server starts a transaction and invokes  P . Typically  P invokes a database system to do some of its work. \n ■  If the transaction terminates successfully, the server commits the transaction. Otherwise, it aborts the \ntransaction. \n ■  The server sends some output back to the source of the request, such as a web browser or other input \ndevice, to ﬁ nish processing the user’s request. \n TP applications that have the preceding structure require a diverse set of runtime functions. They include \nthe functions described in Chapter 2, plus many others such as presentation services, message routing, secu-\nrity, and system management. These functions are typically not all packaged together in one product. Some are \nin the operating system. Others are in the database system. Some are in independent middleware components. \n Transaction Processing Application \nArchitecture \n 3 \nCHAPTER\n",
      "content_length": 2221,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 93,
      "content": "74  CHAPTER 3 Transaction Processing Application Architecture\n This is a fairly complicated picture: many different services, supported by a variety of products, distributed \nacross different systems in a network. It can be a challenging environment in which to develop an applica-\ntion and to manage it while it is running. This chapter will try to simplify the challenge by explaining how the \npieces of the environment are meant to be used together to build and operate a TP application. \n 3.2  APPLICATION ARCHITECTURE \n There are three interrelated ways to decompose a TP system: by functional components, by hardware subsys-\ntems, and by operating system processes. The decomposition by functional components is shown in  Figure 3.1 . \nIt consists of front-end programs, request controllers, transaction servers, and database systems. In the past, this \nwas called a  three-tier architecture , consisting of the front-end program as the ﬁ rst tier, the database system \nas the third tier, and everything in between as the middle tier. As systems have become more layered, it is no \nlonger clear how many tiers are present. We therefore call it a  multitier architecture . \n The display device, shown in the upper left, interacts with a component that we call the  front-end program , \nwhich is responsible for gathering input and displaying output. It captures input from forms, menu selections, \nand the like; validates the input; and translates it into a request message. \n The front-end program communicates with the device in a device-speciﬁ c format. The types of display \ndevices change frequently based in large part on the cost of hardware to implement them. Today, a web browser \nrunning on a PC is a common device. In this case, the front-end program is a web browser connected to a web \nserver that uses the HTTP protocol and some variant of hypertext markup language (HTML) plus some scripting. \nFront-end Program\nRequest Controller\nQueues\nTransaction\nServer\nTransaction\nServer\nTransaction\nServer\nNetwork\nRequests flow on\nthese connections\nMessage\ninputs\nDatabase System\nDatabase\nDatabase System\nDatabase\nShared by two\ntransaction\nServers\nPrivate to one\ntransaction\nServer \n FIGURE 3.1 \n Multitier TP Application Architecture. The front-end program manages the user’s display and outputs requests. The \nrequest controller processes a request by calling transaction servers, which access databases and other transactional \nresources. \n",
      "content_length": 2452,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 94,
      "content": " The front-end program may respond to some requests itself. It sends other requests to the next stage of the \nsystem, either by storing them on a disk in a queue or forwarding them directly for processing by the applica-\ntion, in a component that we call the  request controller . \n The request controller component guides the execution of requests. It determines the steps required to exe-\ncute the request. It then executes those steps by invoking transaction servers. The application executing in this \ncomponent usually runs as part of an ACID transaction. \n Transaction servers are processes that run application programs that do the actual work of the request. They \nalmost always execute within a transaction. The transaction server usually communicates with one or more data-\nbase systems, which may be private to a particular transaction server or may be shared by several of them. \n Like any program, a TP application usually is constructed by composing simple components into more complex \nones. Simple transaction server applications can be composed into a compound application using local procedure \ncalls, such as composing  DebitChecking and  PayLoan into  PayLoanFromChecking as we saw in Section 2.2. \nTo compose distributed components, a distributed communications mechanism is needed, such as a remote proce-\ndure call or asynchronous message queue. Service-oriented components and workﬂ ow mechanisms can also play a \npart in this composition. Compound applications can then be composed into even higher level functions. This com-\nposition of components can have several levels, which sometimes makes the distinction between request controller \nand transaction server programs rather fuzzy. In such situations, a program may perform both request controller \nand transaction server functions. \n This multitier TP application architecture means that the TP application itself must be split into different \nparts that perform these different functions: front end, request controller, and transaction server. Most of this \nchapter is devoted to the details of what each of the components needs to do. \n Multitier Architectures \n TP systems usually have two kinds of hardware subsystems, front-end systems that sit close to the display devices, \nand back-end systems that sit close to the databases. In a simple conﬁ guration, each front-end system may be a \nPC running a web browser connected to the Internet, and the back-end system may be a single machine such as a \nshared memory multiprocessor running a web server and a database management system. In complex conﬁ gura-\ntions, both the front-end and back-end systems may contain many machines. For example, a front-end system \nmay have multiple machines that support a large number of devices in a retail store. A back-end system may be a \nlarge server farm that supports hundreds of stores, with different machines running different applications, such as \nﬁ nance, order processing, shipping, and human resources. \n A major architectural issue in TP systems is how to map the functional components of  Figure 3.1 into processes \non front-end and back-end systems. One natural way is to have each function run in a separate kind of process: \n ■  The front-end program runs in a separate process, typically either a web browser or custom software to con-\ntrol relatively low-function end-user devices. On large systems, separate front-end machines are dedicated \nto front-end programs. On small systems, they run on the same back-end machine as other components. \n ■  Each request controller runs in a separate process and communicates with the front-end programs via \nmessages. It usually runs on a back-end system. \n ■  Each transaction server runs as a process on a back-end system, preferably colocated on the same \nmachine or local area network as the database system that it most frequently accesses. It communicates \nwith request controllers and other transaction servers via messages. \n ■  Each database system runs as a process on a back-end system. \n3.2 Application Architecture  75\n",
      "content_length": 4063,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 95,
      "content": "76  CHAPTER 3 Transaction Processing Application Architecture\n Most modern TP applications are structured in this multitier architecture to get the following beneﬁ ts in a \ndistributed computing environment: \n ■  Flexible distribution: Functions can be moved around in the distributed system without modifying appli-\ncation programs, because the different functions already are separated into independent processes that \ncommunicate by exchanging messages. \n ■  Flexible conﬁ guration: Processes can be located to optimize performance, availability, manageability, \nand so on. \n ■  Easier scale-out: The distribution and conﬁ guration ﬂ exibility makes it easier to scale out a system by \nadding more server boxes and moving processes to them. \n ■  Flexible control: Each functional component can be independently controlled. For example, one can con-\ntrol the relative speeds of transaction servers by varying the number of threads in those servers without \naffecting the front-end program or request controller functions, which are running in separate processes. \n ■  Easier operations: In a large system, only a few people are expert at each tier’s applications. Having \nthem isolated makes them easier to debug and independently upgradable. \n ■  Fault isolation: Since the different functions are running in different processes, errors in one function \ncannot corrupt the memory of other functions, which are running in separate processes. \n The main disadvantage of this multitier architecture is its impact on performance. The functional compo-\nnents are communicating via messages between processes, instead of local procedure calls within a single pro-\ncess. The former are at least two orders-of-magnitude slower than the latter. Since even the simplest transaction \nrequires a round-trip between a front-end program and request controller and between a request controller and \ntransaction server, there is quite a lot of message overhead in this approach. \n There are other disadvantages of the multitier architecture due to its large number of moving parts. This \nleads to complexity of the design, deployment, conﬁ guration, and management of the multitier system. To miti-\ngate these problems, vendors have been steadily improving their tools for development and system management. \nBut there is still much room for improvement. \n Due to communications overhead, it is common to combine functions in a single process. For example, most \ndatabase systems support  stored procedures , which are application programs that execute within the database \nserver process. One can use this mechanism to run transaction server programs as stored procedures, thereby \neliminating a layer of processes between request controllers and the database system and hence eliminating \ncommunication overhead. Of course, this reduces the degrees of ﬂ exibility of the multitier architecture, since it \nprevents transaction server programs from being distributed independently of the database server processes in \nwhich they run. \n Taking this approach to the extreme, one can run all the functional components of the multitier architec-\nture in a database server process. This reduces the multitier architecture to a two-tier architecture. This was a \npopular approach in the early days of client – server computing in the 1980s, but fell out of favor for large-scale \nsystems due to its limited ability to scale out. However, as database servers are becoming more functional, it is \nlooking more appealing. We will discuss this trend later, in Section 3.7. \n Service-Oriented Architecture \n In addition to the multitier application architecture, application design methodologies play a role in the structure \nof TP applications. Service-oriented architecture (SOA) is one such design methodology, which was discussed \n",
      "content_length": 3811,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 96,
      "content": " in Chapter 1. In SOA, the designer identiﬁ es a service that a business provides for its customers and partners. The \ndesigner maps this business service to a software service, which is an operation. Typically, a set of related opera-\ntions are grouped together in a service interface. Each operation in a service interface is implemented as a soft-\nware component that can be invoked over a network by sending it a message. In SOA, operations are intended \nto be relatively independent of each other, so they can be assembled into applications in different combinations, \nconnected by different message patterns. \n In a TP system, a service can implement a transaction or a step within a transaction. That is, it can play the \nrole of a request controller or transaction server. In either case, it is invoked by sending a message to the ser-\nvice. In this sense, the notion of a service is nicely aligned with multitier TP system architecture. \n This alignment between SOA and TP depends only on the fact that SOA decomposes applications into \nindependent services. It does not depend on the particular technology that is used to deﬁ ne service interfaces \nor to communicate between services, such as RPC or Web Service standards. \n Object-Oriented Design \n Another popular application design methodology that plays a role in the structure of TP applications is object-\noriented design. Object-oriented design offers a different perspective than SOA, focusing on modeling things \nrather than functions. \n Object -oriented design maps nicely onto the TP application architecture of  Figure 3.1 as shown in  Figure 3.2 . \nIn this style of design, one starts by deﬁ ning  business objects , which are the elementary types of entities used by \nthe business. In programming terms, each business object corresponds to a class in an object-oriented program-\nming language, such as C \u0002 \u0002 , Java, C#, or Visual Basic. It encapsulates the elementary operations on that type of \nentity, called  methods . Typically, these methods change slowly, because they correspond to types of real-world \nobjects whose behavior has been well-established for a long time. For example, the following could be deﬁ ned as \nbusiness objects: \n ■  Customer: It supports methods to create a new customer, change address, change phone number, and \nreturn customer information in several different formats. \na. Multitier TP\n    application architecture\nb. Object-oriented\n    application architecture \nMenu item and form\nto open an account\nOpen an account\nCustomer\nobject \nAccount\nobject\nFront-end program\nRequest controller\n\u0005 business rules \nTransaction server\n\u0005 business objects\n FIGURE 3.2 \n Mapping Object-Oriented Application Architecture to a Multitier Model. Business objects, such as  “ Customer, ”  “ Credit \nHistory, ” and  “ Account ” run in transaction servers, and business rules such as  “ Open an Account ” run in request \ncontrollers. \n3.2 Application Architecture  77\n",
      "content_length": 2955,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 97,
      "content": "78  CHAPTER 3 Transaction Processing Application Architecture\n ■  Loan Account: It supports methods to create a new loan account, increase the amount owed, credit the \namount paid, and associate the loan account with a different customer. \n ■  Credit History: It supports methods to create a credit history for a given customer, add a credit event \n(such as a loan or loan payment), and return all its credit events for a given time period. \n After deﬁ ning the business objects in an application, one deﬁ nes  business rules , which are actions that \nthe business performs in response to things that happen in the real world. For example, the business rule for \nopening a new loan might involve creating a new customer object (if this is a new customer), checking the cus-\ntomer’s credit history, and if the credit history is satisfactory, then creating an account. Business rules change \nmore frequently than business objects, because they reﬂ ect changes in the way the business operates in the real \nworld. It is therefore useful to program business rules in modules that are separate from business objects. \n One can map this object-oriented application design onto TP application architecture by running business \nobjects as transaction servers and business rules as request controller programs. This is an efﬁ cient architecture, \nsince business objects make frequent access to the database that stores the object’s state and can be colocated \nwith the database. It is also a ﬂ exible structure, since business rules can be changed within request controllers \nwithout affecting the business objects (i.e., transaction servers) that they call. \n Applications created using objects can be service-enabled to participate in an SOA. Externally callable \nmethods of an object-oriented application are good candidates for services. Services might expose only por-\ntions of the functionality of the objects through the service interface. \n Simple Requests \n In this chapter, we’ll focus on simple requests. A  simple request accepts one input message from its input \ndevice (a display device or specialized device such as an ATM), executes the transaction, and sends one mes-\nsage back to the input device. Examples are making a bank account deposit, placing an order, or logging a \nshipment. Each simple request is independent of every other simple request. \n A given user interaction may actually require a sequence of related requests. For example, a user might want \nto arrange a trip, which requires reserving airline seats, reserving a car, and reserving a hotel room. A travel \nweb site may offer this as one request, even though it may actually run as three separate requests. We’ll look at \nmulti-request interactions in Chapter 5. In this chapter, we’ll assume that all requests are simple — one message \nin and one message out. \n The next three sections, Sections 3.3 through 3.5, cover the main components of TP application architec-\nture: front-end programs, request controllers, and transaction servers. They look at both the application’s func-\ntions and issues related to building the underlying component. Section 3.6 looks at transactional middleware \nthat provides support for these components. Section 3.7 revisits the two-tier versus three-tier system models, \nexploring in more detail the decision to group front-end programs, request controllers, and transaction servers \ninto the database server process. \n 3.3  FRONT-END PROGRAM \n Front-End Program Layers \n A front-end program gathers input from a user and sends it as a request message to the request controller. From \nthat point on, the TP application deals with only request messages. It doesn’t need to know any details of the \nvarious devices, forms managers, or web services that capture input for the request or that interpret the output \n",
      "content_length": 3822,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 98,
      "content": " of the transaction that runs the request. Only the front-end program deals with that. We call this  presentation \nindependence , because the front-end program makes the rest of the application independent of the other soft-\nware and hardware that’s interacting with the user. \n Typically the request controller offers a ﬁ xed application programming interface (API) for use by the front-\nend program. That is, the API doesn’t depend on the type of front-end device or program. This enables a single \nTP application to interact concurrently with diverse front-end devices and programs. It also makes it easy to \nadd new front-end devices and programs without modifying the rest of the TP application. \n The front-end program has two main functions (see  Figure 3.3 ): one that interacts with the user to gather \ninput and display output; and one that deals with constructing request messages and interpreting replies. We’ll \ndescribe each function in turn. \n Gathering Input Using Forms and Menus \n Form and Menu Concepts \n The front-end program gathers from a display device the input required to generate a request message. If the \ndisplay device is a terminal, PC, or workstation, the front-end program generally interacts with the user via \nmenus and forms, often executing inside a web browser. The user selects a menu item — perhaps by clicking on \nan icon or a command button, or by highlighting an entry on a pull-down menu — to identify the type of trans-\naction he or she wants to run. Then the front-end program displays a form or series of forms in which the user \nenters the input data needed for the type of request. Anyone who has made a retail purchase over the Internet \nusing a web browser recognizes this style of interaction. \n Application programmers write the programs that direct the front end’s menu management, forms manage-\nment, and data validation functions. One or more presentation technologies offers application programmers the \nability to do the following: \n ■  Deﬁ ne menus and how to navigate between them. \n ■  Deﬁ ne the ﬁ elds of each form and how they are laid out on the screen. \n ■  Identify the data validation routine to be called for each ﬁ eld on the form to ensure that the input makes \nsense. \n The system functions available to interact with forms and menus have changed a lot over the years, due \nto the evolution of desktop devices and graphical user interfaces. However, the required capabilities of forms \nand menus have not changed very much. We ﬁ rst explain the principles and then discuss how they have been \nembodied in various kinds of technology. \n The front-end program usually performs some data validation of the input form, to ensure that the input \nvalues make sense. This validation is done for each ﬁ eld, either one-by-one as each ﬁ eld is entered, or altogether\nGather Input & Display Output\nConstruct Requests\nRequests\n FIGURE 3.3 \n Layers of a Front-End Program. The front-end program gathers input by communicating with the display, then translates \nthat input into a request message. \n3.3 Front-End Program  79\n",
      "content_length": 3083,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 99,
      "content": "80  CHAPTER 3 Transaction Processing Application Architecture\n after the entire form has been ﬁ lled in. The goal of the validation is to minimize the chance of attempting to \nexecute the request with incorrect input. This would result in having the error detected downstream by a request \ncontroller, transaction server, or database system, thereby wasting system resources and increasing the delay in \nnotifying the user of the error. \n Data validation can sometimes be circumvented by offering a pick-list, such as a drop-down menu, that con-\ntains only the valid values for that ﬁ eld (e.g., a state or province in an address). Other checks require a cached \ncopy of valid data values that are compared to values that the user enters in the form. For example, when request-\ning a ﬂ ight reservation, the user needs to enter a valid city name or airport code. \n When validating ﬁ elds, it is usually a bad idea to compare the values entered by the end-user directly with \ndata in the back-end database. If this were done as each input ﬁ eld is entered, it would generate a high load \non the communication path between the user display and the database and on the database itself. This would \ndegrade the response time to the user and the throughput of the back end. However, using a cached copy also \nhas disadvantages. The cached copy is refreshed from the live database only periodically, so it usually isn’t com-\npletely accurate. This is satisfactory for ﬁ elds that don’t change frequently, such as department names and prod-\nuct codes, but not for frequently changing ﬁ elds, such as the number of items left in inventory for a popular \nproduct. Those ﬁ elds can be validated only by executing the transaction itself in the transaction server, which \nhas direct access to the database. \n One problem with validation logic is that it resides on the front end but is closely associated with the \nback end, where the validated input is interpreted. Thus, changes in transaction server behavior can affect the \ndata validation behavior that’s required. This affects the process for developing, deploying, and managing \napplications. \n The use of cached and potentially out-of-date data for data validation is an example of the general design \nprinciple presented in Section 2.6 for scaling up. By limiting the application’s need for accurate and consistent \ndata, the application can be replicated to scale up to a large number of web servers and browsers. If accurate \ndata were required, then it would be more costly to keep the replicas up to date. \n Form and Menu Technology \n Before the advent of the PC, terminals were the dominant device for an end-user to communicate with a TP \nsystem. Terminal devices evolved from teletype terminals, to character-at-a-time cathode-ray tube terminals, to \nblock-mode screen-at-a-time terminals. In all the cases, forms management software was used to write front-end \nprograms to communicate with such devices. In the 1970s, this functionality was built into early TP monitor \nproducts. In the 1980s, independent forms manager products became popular. They offered a What-You-See-Is-\nWhat-You-Get (WYSIWYG) forms designer and callout functions to a standard programming language. \n In the early 1990s, PCs became popular as display devices for communicating with TP applications. Early \nforms products were replaced by fourth generation languages (4GLs) and visual programming products, such \nas Microsoft’s Visual Basic, Powersoft’s (now Sybase’s) PowerBuilder, and Borland’s Delphi. The forms and \nmenus compile into programs that run on a PC, rather than on a server as had been the case for low-function \ndisplay devices. They typically use an RPC to communicate with the back-end server. This style of front-end \nprogram often is called a  thick client , because it runs in a general-purpose operating system environment. \n As web browsers became popular in the late 1990s, the  thin client architecture emerged, where the menus \nand forms are hosted in a browser.  Figure 3.4 illustrates the thick and thin client alternatives. \n The thin client architecture gets its name from the more limited functionality of the browser environment \ncompared to a general-purpose programming language and operating system. The basic interaction pattern is \nthat the browser receives and displays HTML ﬁ les and their embedded links, the user enters data (usually via \nHTML forms), and the browser returns the user’s data to the web server as a query-string in an HTTP GET or \nas the content of an HTTP POST, which the web server then processes. The same pattern is used for XHTML, \nwhich uses XML syntax to express HTML. The web server is then responsible for invoking the back-end server. \n",
      "content_length": 4733,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 100,
      "content": " In the thin client architecture, some of the browser controls may be used instead of or in addition to the \nforms logic, such as the browser navigation buttons. Browser-based front-end programs also may have to com-\npensate for browser-based navigations; for example, compensating for the case when the browser’s  “ back ” but-\nton is pushed before the form is completed. \n From a TP system designer’s perspective, one beneﬁ t of browsers is that there are a relatively small num-\nber of popular ones and hence a relatively small number of interfaces to support. However, early browsers did \nnot support a very expressive programming environment. The browser has become less of a thin client over \ntime with the development of more powerful programming constructs that can run in the browser, such as \ninteractive plug-ins and scripting languages. Other programming models for active content include Dynamic \nHTML, which adds client-side scripting, cascading style sheets, and the document object model to HTML; \nAJAX (Asynchronous JavaScript And XML), which enables updating of small portions of a web page instead \nof reloading the entire page; and multimedia environments such as Adobe Flash and Microsoft Silverlight. \nNew, more powerful browser-based technologies appear every year. \n Desktop systems are much less expensive than back-end TP systems and are usually paid for by users, not \nby the enterprise owning the TP system. Therefore, TP system designers want to ofﬂ oad as much processing as \npossible to the front end. However, given the power of a web browser to display complex multipart pages and \nto execute code, some care is needed to avoid overloading a page with too much functionality and thereby neg-\natively affecting performance. For example, displaying too many objects, with images assembled from several \nsources, can be a source of delay. Objects embedded in the browser also have the capability to directly invoke \na transaction server, but this can introduce scalability problems such as those discussed in Chapter 2. \n Forms Development \n Forms and menus usually are designed graphically, by creating the form on the screen. Actions may be associ-\nated with each ﬁ eld and menu item to validate as the form is ﬁ lled in, or there may be a single action to accept \nall the user input and package it in a request message. \nVisual Studio\nEclipse-based IDE\nNetBeans\nHTML Forms\nXHTML\nDynamic HTML\nAJAX\nThick Client\nWeb Server\nRequest\nController\nHTML/XML\nForms Editor\nDreamWeaver\nExpression Web\nThin Client\nEnd-user’s\ndevice\nDesign time\nRun time\nVisual Basic, C#\nJava\nEclipse RCP\n FIGURE 3.4 \n Sample Forms Tools. In a thick client, a general-purpose program on the user’s PC communicates with the back-end \nserver. A thin client uses a browser to display forms and gather input. \n3.3 Front-End Program  81\n",
      "content_length": 2834,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 101,
      "content": "82  CHAPTER 3 Transaction Processing Application Architecture\n Some development environments provide extensive function libraries to help build the form and process \nthe input to it, including validation. If using HTML or a variation of it, the development environment may have \nfewer built-in functions, so more processing may be needed at the request controller to compensate for the lack \nof functionality in the front-end program environment. \n Constructing Requests \n A request message from a front-end program can take the form of a remote procedure call or asynchronous \nmessage. Its format usually includes the following (see  Figure 3.5 ): \n ■  The identiﬁ er of the user; that is, the name of the user who is operating the device and is entering the \nrequest (if a human is doing this work) or of the software component that is authorized to issue the request. \nFor HTTP, this often is captured in a cookie and is omitted for some types of requests. \n ■  A device identiﬁ er of the device that’s producing the input. For example, this could be the network address \nof the device or an operating system socket that is bound to a TCP session with the device. The device’s \ntype might be available through the message protocol (e.g., in HTTP) or it may be supplied by the commu-\nnications system. For example, the device type could be a particular version of a web browser or a particular \nasynchronous terminal device. \n ■  A request type, which is the identiﬁ er of the type of transaction that the request is asking to execute. \n ■  Input parameters; each request type generally requires a certain number of parameters as input. The rest \nof the message contains those parameters, which are different for each type of request. \n There are many message format standards that deﬁ ne ﬁ elds for some of the above information. For example, \nHTTP provides a default mechanism for constructing a request using a URL. Other standard formats include \nSOAP headers and some Web Services standards, such as WS-Addressing and WS-Security. Application-\nspeciﬁ c formats also are used. For example, some ﬁ elds could be expressed in the data type part of the Web \nService Description Language. They may simply be part of an XML payload that is passed in an asynchronous \nmessage, deﬁ ned using XML Schema. Or they may be deﬁ ned by a transactional middleware product that \noffers request management functions. \n Ideally , a TP application uses one format for all its transaction types. However, an enterprise system often \nhas heterogeneous components that use different request formats. In this case, a request controller may need to \ntransform or reformat some requests into and out of different formats. This is a common function of message-\noriented middleware, which is described in Chapter 4. \n A request should also include a  request identiﬁ er , which is unique relative to other request identiﬁ ers from \nthe same client and is made visible to the user or application program that issued the request. There are two \noperations that should be offered to users and that need this identiﬁ er, Status and Cancel. The Status operation is \nissued by a user who has timed out waiting for a reply to the request. It returns the state of the request, such as \nUser ID\nDevice ID\nRequest Type\nRequest-Specific Parameters\n FIGURE 3.5 \n Typical Request Contents. It contains the ID of the user entering the request, the user’s device, the type of transaction \nbeing requested, and parameters to the request. \n",
      "content_length": 3503,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 102,
      "content": " whether the request has been received, has been processed and committed, or has been processed and aborted. \nThe Cancel operation attempts to kill the request before it executes. This operation cannot be guaranteed to \nsucceed. If the request has already executed and committed at the time the cancel operation is received by the \nsystem, it’s too late, because once a transaction is committed, its results are permanent (except by running a \ncompensating transaction). If the front-end program is allowed to have many requests outstanding, then the \nrequest identiﬁ er has a third use: to match each reply to the corresponding request, either by the front-end pro-\ngram or request controller. \n After the front-end program has gathered the user’s input, it sends a request message to the request control-\nler. This is typically an RPC or HTTP operation. Before RPC was widely available, transactional middleware \nproducts often implemented a custom protocol to send a request message and receive a reply. These protocols \nare still available in many of the older products, primarily for backward compatibility. Modern SOA or web-\nbased systems may also offer an asynchronous messaging capability. \n When a front-end program is tightly integrated with a transactional middleware product, the request may \nbe constructed by the middleware product with little application programming. By setting certain properties of \nthe menu item and by tagging forms ﬁ elds with the names of parameters required by the transaction program, \nthe application programmer can give the front-end program what it needs to translate that menu item and form \ndata into a request message. \n Logging \n Some front-end programs are able to keep a record of all the work going on at the front-end by logging messages. \nSometimes the display devices themselves do this. For example, some ATMs print a record of each transaction on \na paper log inside the machine, to settle later disputes. For less functional devices, the front-end program may do \nthe message logging itself and provide an interface where system managers can go back and look at that log to \nreconcile any errors that might appear later. Transactional middleware often has built-in message logging func-\ntionality to help, such as that in the Java Enterprise Edition (Java EE) and the .NET Framework. We discuss such \nreconciliation problems further in Sections 4.4 and 5.5. \n Web Servers \n Although web servers reside on back-end systems, their primary purpose is to capture input from web browsers \nand display output in the form of static or dynamically- generated content. Since they are so closely linked to the \nbehavior of web browsers, we usually regard them as part of the front-end layer of the multitier architecture. \n Web servers are designed not only to interact with a display by sending pages to web browsers, but also to \nprocess simple requests. For example, a web server can process a request for relatively static information, such \nas the root page of a web site or the table of contents of a catalog. Answering this kind of request in the web \nserver offers faster response time than forwarding the request to other middle-tier or back-end components \nfor processing. Moreover, since the requested information is static, it can be cached in the web server, further \nimproving efﬁ ciency. Over time, we expect web servers to continually grow in their capacity to handle not only \nsimple requests efﬁ ciently, but also more and more complex requests. \n Some simple requests require the invocation of an application program. One of the ﬁ rst mechanisms intro-\nduced for a web server to invoke application code was the Common Gateway Interface (CGI). A CGI program \ncan be written in any language supported by the system on which the web server is running. A speciﬁ c location \nis deﬁ ned for the CGI programs (e.g.,  http://www.example.com/wiki.cgi ). Whenever a request to a matching \nURL is received (e.g.,  http://en.wikipedia.org/wiki/URL ), the corresponding program is called, together with \n3.3 Front-End Program  83\n",
      "content_length": 4083,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 103,
      "content": "84  CHAPTER 3 Transaction Processing Application Architecture\n any data that the client sent as input. Output from the program is collected by the web server, augmented with \nappropriate headers, and sent back to the client. \n Each call from the web server to execute a request through CGI causes a new process to be created. The \nnew process executes the application program required to process the request. In particular, that application \nprogram could be a request controller. This is the 1970s ’ time-sharing model of executing commands, namely, \nfor every call create a process and run the called program in that process. The approach is simple, but expen-\nsive, and therefore has limited scalability. Techniques have been developed to improve the performance of \nCGI scripts, including the ability to execute compiled programs and an optimized version of the CGI protocol \ncalled FastCGI. FastCGI creates a limited pool of processes (i.e., a server class) that runs CGI programs with \ncommunications connections to the web server. These processes can be reused by multiple CGI calls, instead \nof creating a process per call. \n To avoid the overhead of process creation altogether, web servers have interfaces to execute applica-\ntion code within the web server that invokes the application, such as Microsoft’s Internet Server Application \nProgramming Interface (ISAPI) and the Apache API. This is more efﬁ cient. But the APIs are relatively low-\nlevel, which makes applications that use these APIs somewhat complex. Moreover, applications running in a \nweb server process are not as well protected from each other as they would be running in separate processes, \nas in CGI. A higher level and more portable alternative is the Java Servlet API. HTTP requests and responses \nare mapped to Servlet threads, which invoke Java objects to dynamically generate content and access resources \nexternal to the web server. \n Higher level programming environments also have been developed that simplify application programming. \nInitially, a scripting language was allowed to be embedded in web pages, such as Active Server Pages (ASP) \nand Java Server Pages (JSP). When the web server receives a URL for such a page, it loads the page and \nthen interprets the embedded script, which results in a page containing only HTML (for example), which is \nreturned to the browser that requested the page. This programming model has been quite popular and therefore \nhas been steadily improved to allow more powerful language features, more prepackaged controls, compilation \nof pages, and invocation of code outside pages using an RPC. \n Another trend is offering more modern programming languages, such as Java and C#, which have garbage \ncollection and type safety for higher programmer productivity and increased reliability. However, garbage col-\nlection hides from the user the amount of memory being used, so the equivalent of a memory leak may go \nundetected while the memory footprint increases forever. Although garbage collection often reduces application \nexecution time, even with concurrent multithreaded garbage collectors the system must sometimes stop and \ncollect garbage, thereby introducing latency. To avoid unacceptable response time, TP system implementers \nneed to watch out for these issues and minimize their effects. \n The functionality of web servers, and of front-end programs in general, changes relatively rapidly. These \nchanges are driven by several factors: the continual increase in the power of end-user devices and speed of \nnetworks that connect the front-end program to that device; the desire to offer more appealing interfaces for \nhuman – computer interaction; and the demand to improve programmer productivity when developing applica-\ntions for presentation services. We expect all these trends to continue indeﬁ nitely. \n State Management for Web Servers \n Applications running in a web server usually are designed to be stateless with respect to a browser instance. This \nis partly because browsers communicate with web servers using the HTTP protocol, which is stateless. Thus, dif-\nferent requests sent by a browser to a given back-end system may be processed by different web servers in that \nsystem. Clearly, this creates a problem if there is a state that needs to be maintained across multiple interactions \nbetween the browser and web servers. One approach is to carry along the state as application-managed parameters \n",
      "content_length": 4459,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 104,
      "content": " or cookies in each call. A second approach is to store that state on the back end by replicating it across multiple \nweb servers. A third approach is to store it on the back end in a location that is accessible to all the web servers \nthat can receive requests that may need that state. In the latter two approaches, the URL or a cookie needs to iden-\ntify that state so the web server knows how to ﬁ nd it. \n One reason that stateless web servers are popular is that they simplify scalability. Since web servers do not \nretain state, the dispatcher of HTTP requests can spray those requests randomly across all the web servers, thereby \nbalancing the load. Moreover, there is no state management needed to scale up a back-end system comprised of \nweb servers. One can simply add server machines, create web servers to run on the machines, and make the exis-\ntence of the web servers known to the HTTP dispatcher. \n Stateless web servers also simplify recovery. A web server may fail unexpectedly or be deliberately brought \ndown for maintenance or an upgrade. Since a web server does not retain state from one request to the next, the \nfailure of a web server affects only the speciﬁ c requests it was processing at the time it failed. If a user times out \nwaiting for a reply from a failed web server, he or she can simply reissue the request. The back-end system will \ndispatch the retry to an available web server, which is equally well prepared to process the request. Moreover, \nwhen the failed web server recovers, it can immediately start processing new requests, since it has no state that \nneeds to be recovered ﬁ rst. \n The use of stateless web servers is part of the software architectural pattern called REST (representational \nstate transfer). An example of the architectural pattern is the REST/HTTP protocol infrastructure, which we \ndiscussed in Section 1.2. The REST architectural pattern is characterized by the following set of constraints on \nservice-oriented systems: \n ■  Servers are stateless. \n ■  Operations are generic (e.g., GET and POST), so the application-speciﬁ c nature of an operation must be \ncaptured in the name and content of the resource being accessed (e.g., the URL). \n ■  The resource’s (e.g., web page’s) representation captures the name and parameters of operations being \ninvoked. \n ■  Caching is transparent, so the invocation of an operation can be answered from a cached result if it is \navailable, such as a cached copy of a static web page being requested by a GET operation. \n Together , these constraints enable scalability of clients and servers. To invoke a service, a client needs to \nknow only the name of the resource being invoked. It does not need to know the names of operations because \nthey are generic. Thus, a client can invoke a server as long as it has access to a service that can translate \nresource names into network addresses (e.g., the Internet Domain Name System (DNS)). Since servers are \nstateless, they scale out easily and more cheaply. And the use of caching helps avoid expensive communication \nand accesses to databases or ﬁ les, further improving scalability. \n The downside is that the REST architectural pattern, and stateless servers in general, can cause worse per-\nformance when interacting with shared data, because sometimes it leads to transferring more state than would \nbe needed with stateful servers. For example, since a stateless server cannot cache database records, it may \nsend a large set of records to a client, even though often only the ﬁ rst few are used. A stateful server  S can \nsolve this problem by maintaining a record cache. Or  S can use a database session with a database server-side \ncursor, which caches a large query result and returns a small set of records on each fetch operation by  S . \n In practice many web sites do not follow all the constraints of REST, making it more like an ideal architec-\nture against which to measure implementations of web technologies than a concrete programming model. The \nwidespread use of cookies is a good example, since they create resources that don’t have a URL, introduce \nstate management into a stateless protocol, and can become inconsistent when a web browser’s BACK button \nis pressed. Other common violations of REST are including parameters and methods in URLs, using POST \n3.3 Front-End Program  85\n",
      "content_length": 4365,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 105,
      "content": "86  CHAPTER 3 Transaction Processing Application Architecture\n for every operation instead of using GET, and misapplications of caching such that a system cannot determine \nwhich representation of a resource is authoritative or expired. \n Authentication and Encryption \n Another function performed by the front-end program is authentication, which is the activity of determining \nthe identity of the user (see  Figure 3.6 ). For example, this is required when a user accesses a bank or broker-\nage account. Not all applications require authentication. For example, retail businesses often allow users to \nmake purchases simply by providing billing and shipping information, without logging in. For applications \nthat require it, authentication usually is done by having the user enter a username and password, the results of \nwhich are visible to the application as an authentication token. \n Whenever the front-end program sends a request message to the request controller, the results of the user \nauthentication process are included. This proves to the rest of the application that the message came from a \ncertain person and allows authorization to be performed by the server. \n The user also wants to be sure that she is communicating with the correct server, not a rogue server that is \nspooﬁ ng — that is, masquerading as the server the user really wants. This requires that the server authenticate \nitself to the user. \n An additional level of security can be provided if the wire that connects the device to the system is encrypted, \nwhich reduces the threat of wiretapping. A good encryption algorithm makes it unlikely that a wiretapper would \nbe able either to decrypt messages or to spoof the system by trying to convince the system that it’s actually a \nqualiﬁ ed user. \n When the client system is communicating with the server over the Internet, server authentication and \nencryption usually is obtained using Transport Layer Security (TLS) (the successor to Secure Socket Layer \n(SSL)) on TCP/IP. This is a protocol by which the client and server exchange enough information to estab-\nlish a secure information channel, over which they exchange encrypted information that only each other can \ndecipher. \n In TLS, the client obtains from the server a certiﬁ cate, which includes the server’s public key. The server \ncertiﬁ cate is issued by a trusted certiﬁ cate authority and signed using the authority’s private key. A client can \nvalidate the certiﬁ cate using the authority’s public key. Thus, the certiﬁ cate can be used to authenticate the \nserver to the client web browser, so the latter is sure that it is talking to the intended server. The client and \nserver then exchange encryption keys and message authentication codes, which enable the client and server \nto exchange encrypted information. Often TLS is implemented by a site’s network switch, and lighter weight \nencryption is used within the site. \nUser\nBack-end\nserver\nEncryption to avoid wiretapping\nUser’s\ndevice\nWeb server\nauthenticates user\nBack end authenticates\nweb server and user\nWeb server\n FIGURE 3.6 \n Authentication and Security. Web servers and back-end servers authenticate the identity of users that communicate with \nthem. Additional security is provided by encrypting messages. \n",
      "content_length": 3277,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 106,
      "content": " There are many ways to arrange secure communications between the front-end program and web server, \ndepending on the desired level of security and the amount of effort devoted to performance optimization. The \nfollowing is a typical scenario: \n ■  Suppose that Alice is browsing a retail web site. She gets an encrypted cookie that identiﬁ es her as a \nuser, whether or not she’s logged in. Her browser sends the cookie back and forth over HTTP. The web \nserver of the web site can quickly decrypt basic information about Alice and her session. \n ■  After some browsing, Alice decides to buy what’s in her shopping basket. She goes to the checkout page, \nwhich uses HTTPS (i.e., TLS). All pages in the checkout process use HTTPS and hence communication \nis encrypted to protect Alice’s password, credit card number, and other personal information such as her \naddress. The HTTPS connection setup is expensive as it uses public key encryption of certiﬁ cates to give \nAlice some assurance that she’s talking to the right web site. After the certiﬁ cate is checked the HTTPS \nconnection may switch to a symmetric and cheaper connection. \n ■  The web site asks her to log in. It authenticates Alice’s login information and creates an encrypted \ncookie, which holds a key for the session information that’s stored on the back end. The web site also \nlooks up any relevant personal information it has on ﬁ le for her, such as billing and shipping address, \npreferred type of shipping, and credit card number. The web server caches the information in a local \nnondurable in-memory database and stores it as session state in a separate database that’s available to all \nweb servers. \n ■  The web site then asks Alice to ﬁ ll in or validate that personal information. It takes multiple interactions \nfor Alice to enter all this information. Since the web site uses a layer 7 network switch, which can route \nmessages by content, the switch will continue to direct her to the same server unless the server slows \ndown or crashes. If one of her interactions moves to another web server, the web server uses her cookie \nto ﬁ nd her session state in the session state database. \n ■  On the ﬁ nal web page, if Alice agrees to the purchase, the web site validates her credit card with a bank \nover another TLS connection, runs the transaction, and replies to Alice with a receipt. After that, she’s \nback to normal HTTP for more shopping. As HTTPS is more costly than HTTP, when Alice returns \nto web pages that anyone can see, the web site will switch back to unencrypted HTTP connections to \nsave cost. \n Some TP applications manage their own authentication and authorization information, whereas others use \nan external security service, such as the operating system’s security service, or an independent security service \nsuch as those provided by CA’s SiteMinder, Microsoft’s Windows Active Directory, or IBM’s Tivoli. If the \nsecurity service is made available to all back-end components, then the system can offer users a single set of \ncredentials across all applications. It might also offer a single sign-on for users, where they receive a ticket-\ngranting ticket  that can be used by multiple applications to authenticate the user. When an external security \nservice is used, the application has to be able to understand the external format, access the external service, \nand potentially federate security tokens (when more than one is used). \n In some TP applications, it’s quite important to know that a message arrived from a particular device, not \njust from any device at which a particular user logged in. This is called  geographical entitlement , because one \nis entitled to provide input based on one’s geographic location. An example would be in the securities trading \nroom of a brokerage house. When the traders show up for work, they have to display their photo identiﬁ cation \ncards to a guard before entering the trading room. They then sit down at their display devices and provide pass-\nwords to prove to the TP application that they are who they say they are. For this extra level of security to work, \nthe system must know that the request actually came from a device in the secured trading room. If someone \n3.3 Front-End Program  87\n",
      "content_length": 4252,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 107,
      "content": "88  CHAPTER 3 Transaction Processing Application Architecture\n connects from another location, device authentication will tell the system which device entered the request, so \nthe system can determine that the device is not entitled to enter requests, even if that someone knows the pass-\nword of an authorized user. \n Specifying the security of the TP system and monitoring the front-end program’s behavior creates require-\nments for a variety of system management functions within the front end. The front end has to allow a system \nmanager to deﬁ ne information needed to authenticate devices and users, such as passwords and valid network \naddresses. For example, the front-end program might allow the system manager to set up a default password that \nthe device owner or the user can change after logging in. The system manager may also specify that a user is \nallowed to enter only certain types of requests at certain times of day. Since there may be many users of the sys-\ntem, the complexity of this speciﬁ cation can be reduced by introducing the abstraction of a  role . Each role has a \nset of privileges, such as allowable requests and usage times, and a set of users that have those privileges. Instead \nof specifying privileges for each user, the system manager simply assigns and removes individual users from \nroles. The system manager needs to specify privileges for each role, but there are many fewer roles than users \nand the privileges for roles change less frequently than for users. Identity-based security is starting to emerge as \na way to achieve more ﬁ ne-grained authorization, such as Microsoft’s CardSpace and Eclipse’s Higgins. \n Security is a major consideration when developing and deploying TP applications and is a subject for a \nbook in itself. In-depth discussions about security mechanisms are beyond the scope of this book. \n 3.4  REQUEST CONTROLLER \n The purpose of a request controller is to execute requests by calling the transaction server programs that can \nperform the request. If the execution of the request produces output, the request controller routes the response \nback to the front-end program that sent the request. Usually the request controller brackets transactions; that \nis, it issues the Start, Commit, and Abort operations. Within a transaction, there may be calls to one or more \ntransaction servers. \n Specifying Request Controller Functions \n A request may require the execution of many transaction server programs and possibly of many transactions. \nAn application-speciﬁ c program in the request controller decides which transaction servers to call and in which \norder. On the face of it, there’s nothing special about it. It simply accepts a call that contains a request and calls \nsubroutines (transaction servers) to do most of its work. For requests that execute as a single transaction, the \napplication really is quite simple. When multiple transactions are required to process the request, there are \ncomplications, but we’ll defer those until Chapter 5. \n Most transactional middleware products allow the same language to be used both for request controller \nand transaction server functions. So it’s the application designer’s job to split the request-processing function \nbetween the request controller and the transaction server, but it is not something that is forced on the devel-\noper. Nevertheless, this split is desirable for the reasons discussed in the subsection  Multitier Architectures in \nSection 3.2. \n Some transactional middleware products support a special programming language in which to express the \nrequest controller logic. Some of these languages were introduced in the 1980s to ensure request controller appli-\ncations cannot do synchronous I/O, thereby enabling the implementation of multithreading in middleware (see \nSection 2.3). Examples are Task Deﬁ nition Language used in HP’s ACMS (originally from Digital Equipment \nCorporation) and Screen COBOL used in HP’s Pathway TP monitor (originally from Tandem Computers). \n",
      "content_length": 4025,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 108,
      "content": " Other languages are designed to simplify programming multi-transaction requests, such as the Web Services \nBusiness Process Execution Language. This is discussed further in Chapter 5. \n Modern transactional middleware systems handle these functions using a combination of container abstrac-\ntions, APIs, attributes, and conﬁ guration properties. \n Transaction Bracketing \n No matter what language is used to express it, the request controller generally brackets the transaction before it \nactually calls the program to do the work for the request — that is, it issues a Start operation to begin a transac-\ntion before it calls any transaction server programs. After all the transaction servers that execute on behalf of the \nrequest have returned, it issues a Commit operation to indicate that the transaction is done and should be com-\nmitted. The Start and Commit operations are issued by the system when using an implicit programming model. \n Some discipline may be required in choosing which programs issue the transaction bracketing operations \nStart, Commit, and Abort. For example, suppose the transactional middleware or underlying platform does \nnot offer a solution to the transaction composability problem, e.g., by properly handling calls to Start issued \nwithin a transaction or by using transaction attributes attached to object-oriented components (as in .NET and \nJava EE). Then the transaction server programs should not contain the Start, Commit, and Abort operations, \nbut rather should be pure objects. The request controller that calls the transaction server program should be the \none that actually starts the transaction and commits or aborts it. That way the callee can be called from several \ndifferent applications that use the same procedure in different ways, as described in the subsection  Transaction \nBracketing in Section 2.2. All the other issues related to the transaction abstraction in Section 2.2 apply here \ntoo, such as exception handing, savepoints, and chained versus unchained transaction models. \n Request Integrity \n One major complication related to transaction bracketing is ensuring the integrity of each transaction’s request \nmessage. If a transaction aborts, its request may be lost, making it impossible to re-execute  the transaction, \nwhich is very undesirable. The application should catch the abort exception and return a comprehensible mes-\nsage to the user. If it doesn’t, the user might get back an inscrutable error message (e.g.,  “ transaction aborted ” \nor  “ HTTP 500: Internal Server Error ” ), or in some bad cases no response at all. \n To avoid lost requests, the transaction that performs the request should include the operation that gets a request \nas input, say  Get-input-request as shown in  Figure 3.7 . Usually, it’s the ﬁ rst operation executed by the transaction. \nThe system should make the Get-input-request operation recoverable. That is, if the transaction aborts, then the \nGet-input-request operation is undone, just like any other recoverable transaction operation. Thus, the request \nmessage is again available as input and will cause another transaction to execute later, as desired. \n// Example A\nGet-input-request;\nStart;\n   . . .\nCommit;\n// Example B\nStart;\n   Get-input-request;\n   . . .\nCommit;\n FIGURE 3.7 \n Ensuring the Integrity of Requests. In (A), the Get-input-request operation executes before the transaction, so if the \ntransaction aborts, the request is lost. In (B), Get-input-request executes within the transaction, so if the transaction \naborts, the Get-input-request operation is undone and the request is restored. \n3.4 Request Controller  89\n",
      "content_length": 3651,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 109,
      "content": "90  CHAPTER 3 Transaction Processing Application Architecture\n A limit on the number of retries is needed to avoid looping forever on badly formed requests. If a request \nis determined to be badly formed, then a transaction should execute Get-input-request, report the error, and \ncommit, thereby ensuring the request doesn’t execute anymore. As discussed in Section 2.2, savepoints can be \nhelpful in structuring this activity. \n Using the explicit Get-input-request operation, the program waits until a front-end program has an input \nrequest to offer. This is common practice with dumb display devices, which was the usual situation before the \nadvent of PCs. \n The advent of client-server computing and widespread availability of RPC has made it popular for the cli-\nent to invoke the server. That is, the front-end program calls the request controller program, rather than having \nthe request controller call a Get-input-request operation. In this case, the operation that receives the client’s \ncall is the invocation of the called procedure. To avoid the request integrity problem, this  “ receive-the-client’s-\ncall ” operation must be made explicit, so it can be invoked within the context of a transaction and undone if \nthe transaction aborts. The details of how to recover a request if the transaction aborts are sufﬁ ciently complex \nso that we devote an entire chapter to them, Chapter 4, and therefore do not discuss them further here. \n Process Structure \n The request controller typically runs in a multithreaded process. The process may be dedicated to request con-\ntroller functions. Or it may be combined with front-end program functions or transaction server functions, to \nsave context switching overhead. For example, we saw how to combine web server functions with a request \ncontroller in Section 3.3,  Web Servers . Combining request controller functions in the same process as transac-\ntion server functions is usually straightforward. Since a request controller usually invokes transaction servers \nusing RPC, it is simply a matter of replacing remote procedure calls by local procedure calls. \n Since the request controller application executes within a transaction, it needs to have a transaction context \nand to pass that context to transaction servers that it invokes. If the request controller and transaction server \nrun in separate processes, then this is usually done with a transactional RPC. If they run in the same process, \nthen they automatically share thread context and hence transaction context. \n Usually , only a modest amount of processing time is required in the request controller to handle each request. \nNevertheless, this processing time is not zero, so even a multithreaded request controller has limited capacity. If \nthe system is required to handle a maximum request controller workload that exceeds the processing capacity of \na single machine, then it may be necessary to partition or replicate the request controller. For example, a request \ncontroller could be partitioned by request type, and each partition assigned to run on a different machine. As \nwith any scale-out scheme, if request controllers are replicated or partitioned, then it is desirable to have them be \nstateless with respect to their request sources, to avoid the complexity of having to route requests to the particu-\nlar copy of a request controller that has the request source’s state. \n Session Structure \n One traditional function of request controllers is to reduce the number of communication sessions by parti-\ntioning the sessions that would otherwise be required to connect front ends to transaction servers. This helps \nthe session scale-out problem that is described in Section 2.6,  Partitioning Sessions . For example, front ends \nexecuting in the same geographical location could be serviced by the same request controller. \n More complex groupings of connections between front ends and request controllers may be needed for \nfault tolerance reasons. For example, the ATMs at a bank branch may be split across two request controllers \nover two independent communication lines, so the failure of one controller or communication line still leaves \nhalf of the ATMs operating. \n",
      "content_length": 4220,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 110,
      "content": " Security \n If the request controller is receiving requests from untrusted front ends, then requests are a potential source of \nsecurity threats. The request controller therefore should not trust that the data it receives is well formed. For \nexample, it should not assume that a buffer it receives is null terminated or that ﬁ eld  A of a message really is the \nsize for ﬁ eld  B . The bottom line is that secure coding practices are essential when developing TP applications. \n We assume that the request controller is part of the trusted computing base. In particular, it is safe to have \nit be responsible for checking user authorization. To do this, it needs to know about the authenticated user that \nissued the request. For example, it may need to check that the user is authorized to execute the request’s request \ntype. It also needs to pass the authenticated user ID to transaction servers, since some access control can be per-\nformed only when accessing the database. For example, permission to withdraw from a bank account should be \ngiven only to users who own that account. \n In addition to user authorization, process authorization may be required. For example, a transaction server \nmay be accessible only from request controller processes that are known to have done preliminary user autho-\nrization checks and therefore are trusted. This avoids the need for the transaction server to duplicate the request \ncontroller’s check that the user is authorized to execute the request. Process authorization can be done by asso-\nciating the request controller process with an authenticated application administrator, who creates the request \ncontroller process to execute on his or her behalf. Transaction servers are then conﬁ gured to accept calls only \nfrom request controller processes executing on behalf of this application administrator. \n A session may be established between the request controller and transaction server whose session state \nincludes the authenticated application administrator information. This avoids requiring the transaction server \nto perform this security check on every access. Since the authorization state is the same for all requests, these \nsessions can be pooled, to avoid creating a new one for every request. \n It can be time consuming for a system manager to maintain all this security information. It can also be time \nconsuming for the transactional middleware to check all this security information at runtime. Simplicity of secu-\nrity management and efﬁ ciency of runtime security checking are features of transactional middleware products. \n 3.5  TRANSACTION SERVERS \n A  transaction server is the application program that does the real work of running the request. Part of that \nwork usually involves reading and writing shared databases. It always executes in the context of a transaction, \noften created by the request controller that called it. \n It can be a self-contained program or it might call other programs to do its work. Those other programs \nmight execute on the same system as the transaction server that calls it or on a remote system that requires a \ncommunications message to go from the caller to the callee. The communications must be transactional, so \nthat the transaction context ﬂ ows along with the messages. This typically is done using transactional RPC, as \ndiscussed in Section 2.4. \n For application portability, it’s desirable that the transaction servers be written using a popular program-\nming language such as COBOL, C \u0002 \u0002 , C#, FORTRAN, or Java. It is also desirable that they express database \naccesses in a widely used data manipulation language, such as SQL. This ensures that the transaction server \npart of the application can be ported to different transactional middleware environments. \n From the viewpoint of the application programmer, transaction servers are ordinary data access programs. \nThe application programmer needs to ensure the program preserves database integrity, doesn’t take too long to \nexecute and thereby create a resource bottleneck, uses timeouts to detect database server failures, returns com-\nprehensible error messages, copes with distributed databases, and so on. These are complex issues that arise \n3.5 Transaction Servers  91\n",
      "content_length": 4257,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 111,
      "content": "92  CHAPTER 3 Transaction Processing Application Architecture\n for any data access program. There is little that the programmer needs to do differently to run the program in a \ntransaction server process. \n Process and Session Structure \n From the viewpoint of process structure, transaction servers have several special considerations, which are \nrelated to their need to scale to high request rates and to support transaction-based communications. \n For scale-out, a transaction server  S needs to have enough threads to handle the system’s maximum required \nload. Although ﬁ guring out the right number of threads is really an experimental science, the following back-\nof-the-envelope calculation shows which factors are at stake. Suppose each transaction requires  t seconds of \nelapsed time to be processed by the transaction server. If the transaction server has one thread, then it can pro-\ncess 1 /t transactions per second. Thus, if the system needs to handle a peak load of  n transactions per second of \nthe transaction types implemented by  S , then  t  \u0004 n threads are required. Actually, somewhat more are required, \ndue to variance in elapsed processing time. The latter is dependent in large part on the time it takes to process \nits database operations, which is usually where most of the time is spent. This varies based on database server \nload, which may include database operations from other transaction servers. \n To access a database system, every active transaction in a transaction server process needs a database ses-\nsion with the database system. Thus, the number of database sessions required is comparable to the number of \nthreads in the transaction server. Since it is relatively expensive to create a database session, it is desirable that \nthey be pooled and reused. \n The use of database sessions has security implications, because part of the database session is the ID of a data-\nbase user, which usually cannot be changed after the session is created. The database system uses that ID to do an \nauthorization check of each operation executed on that session. Usually, the user ID of the database session is that \nof a dedicated account with sufﬁ cient privileges to access the data needed by the transaction server. This allows \nsessions to be reused for different requests and hence pooled. By contrast, if the user ID were that of the end user \nwho is issuing the request, then a new session would have to be created on that user’s behalf, unless the user hap-\npens to have executed another request in the very recent past and therefore already has a database session set up. \nAlso, if the user ID were that of an end user, then a database administrator would have to create a database user \naccount for every end user who can access the database. This is not feasible for TP applications that are accessed \nby a large number of end users only occasionally, a few times a year, such as a retail e-commerce site. \n The dedicated account usually is given read-write authorization on all parts of the database that may be \naccessed by the given transaction server. That is, the database system treats the transaction server as a trusted \nuser. Thus, it is up to the transaction server to check that a given end-user request is authorized to perform the \ndatabase operations required. \n 3.6  TRANSACTIONAL MIDDLEWARE \n Software vendors have developed transactional middleware products that make it easier to create, execute, and \nmanage TP applications by integrating diverse runtime functions. The main product category for this market \ntoday is the application server. Before the advent of the World Wide Web, the main product category was the \nTP monitor or On-Line TP (OLTP) monitor. Descriptions of transactional middleware products are presented \nin Chapter 10. \n The main job of transactional middleware is to provide an environment that takes applications that are writ-\nten to process a single request and scale them up to run efﬁ ciently on large, often distributed systems with many \nactive users submitting requests and many servers processing requests. By enabling this scale-up, transactional\n",
      "content_length": 4144,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 112,
      "content": " middleware increases the capacity and lowers the per-transaction cost of the application. From a business \nperspective, it lowers the cost of retail sales, ticket reservations, funds transfers, and such. \n Transactional middleware typically includes software in four major functional areas: \n ■  An application programming interface that offers the type of runtime functions described in earlier sec-\ntions of this chapter. It integrates these functions, thereby simplifying the environment in which appli-\ncations are programmed. Some of these functions may be directly implemented by the transactional \nmiddleware. Others may be offered by lower-level products, which the application server passes through \neither as functions in its integrated API or directly through system-level APIs. Some functions may be \ndeﬁ ned using attributes embedded in class deﬁ nitions, or as policies and conﬁ guration attributes of the \napplication execution environment. \n ■  Program development tools for building transaction programs, such as program templates for the main \napplication components, and smooth integration of its API into a particular programming language and \ndevelopment environment. \n ■  A system management interface and accompanying runtime functions to conﬁ gure a TP application for a \ndistributed system, deploy it, and then monitor and control its execution. \n ■  Integration with popular database management systems and front-end programs. \n Transactional middleware is a software framework or application execution environment in which applica-\ntion programs run and in which users interact with the computer system. The execution environment often is \ncalled a  container . The container ties together the underlying system components that are needed by all TP \napplications — multithreading, user interface services, communications system, operating system, and the data-\nbase system. It also may offer components of its own. For example, it may add transactional capability to the \nbuilt-in RPC mechanism or it may add two-phase commit, if these are absent from the operating system and/or \n database system. \n The container provides a single, smooth interface, so that developers and end users don’t need to deal with \neach of these components independently or learn multiple low-level APIs (see  Figure 3.8 ). Instead of writing \napplication programs that talk independently to the forms system, web server, operating system, communication \nRequest control\nfunctions\nTransactional\ncommunications\nTwo-phase\ncommit\nTransactional middleware API\nOther\ncommunication\nservices\nDatabase\nsystem\nservices \nOperating\nsystem\nabstractions\nSecurity\nservices \nUser\ninterface\nservices\nPolicy and\nconfiguration\nmetadata\n FIGURE 3.8 \n Transactional Middleware Container. The transactional middleware container provides services, such as request \nmanagement, transactional communications, and two-phase commit. Its container provides a single abstraction to \napplication programmers and system managers. \n3.6 Transactional Middleware  93\n",
      "content_length": 3040,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 113,
      "content": "94  CHAPTER 3 Transaction Processing Application Architecture\n system, and so on, the programmer writes an application using a single interface that talks to the transactional \nmiddleware. \n Some transactional middleware systems integrate their runtime functions with a particular programming \nlanguage. A notable example of this is Java EE, which consists of Java classes that encapsulate the applica-\ntion server’s functionality. Older examples of the language-speciﬁ c approach developed in the 1980s are HP’s \nScreen COBOL and Task Deﬁ nition Language (see also Section 3.4). \n Other transactional middleware products offer language-independent runtime functions. IBM’s CICS is \none example of this approach, introduced in the late 1960s and still widely used. A more recent example is \nMicrosoft’s .NET Framework, where runtime functions are available in all .NET languages. There is a trend \ntoward exposing transactional middleware features as extensions to the normal development experience, rather \nthan making them available only in a closed development environment. \n Java EE-based application servers are  portable in the sense that they run on a variety of  platforms , or \noperating systems (e.g., Windows, IBM mainframes, and many ﬂ avors of UNIX); they support the same APIs \non these platforms; and they integrate with multiple database systems and front-end programs. Thus, TP appli-\ncations can usually be ported from one Java EE application server to another with moderate effort. \n Interoperability is the ability of programs to participate as part of the same application. Programs may \nﬁ nd it hard to interoperate because they were independently developed in different languages, with incompat-\nible interfaces, and using incompatible data types. Or interoperations may be difﬁ cult because they run on dif-\nferent machines with different underlying platforms. This latter issue requires that there are implementations \nof the same protocols on the machines for communication, two-phase commit, and other shared functions. \n Interoperability can be achieved by running instances of the same application server on different machines \nthat run different platforms or by using application servers that support the same protocol. For example, \ntwo RPC protocols that are in common use by different application servers are RMI/IIOP and SOAP/HTTP. \nSometimes, interoperability is sacriﬁ ced by offering custom features, by disabling features of an interoperability \nstandard, or by using nonstandard protocols for better performance. For example, some platforms implement a \ncustom two-phase commit protocol that has special features and better performance than standard protocols. \n System management functions include load balancing, fault monitoring and repair, performance monitor-\ning and tuning, and the ability to change the conﬁ guration by creating and destroying processes, creating and \ndestroying communication sessions, and so on. For example, the transactional middleware may store a descrip-\ntion of which server processes are running on which machines. Instead of just telling the system manager that \nan operating system process has failed, the transactional middleware might say that the bank’s loan server pro-\ncess has failed, thereby giving the system manager a better idea of where the problem is and what to do about \nit. It may also automate recovery by creating a new copy of the failed process on another machine that has spare \ncapacity. System management functions also are required to set up and maintain security information to protect \naccess to displays and to ensure that only authorized users can access sensitive transaction control programs. \nThese kinds of system management functions often are provided for TP applications by generic system man-\nagement tools, such as CA’s Unicenter, IBM’s Tivoli, and HP’s OpenView. \n The transactional middleware also provides some application development tools to make it easier to write \nthe code for each of the components of a multitier architecture. We’ll describe examples of program develop-\nment in Chapter 10. \n 3.7  DATABASE SERVERS VERSUS TRANSACTIONAL MIDDLEWARE \n A database server is a relational database system that runs as a multithreaded server. It supports stored proce-\ndures that can be invoked by an RPC-like protocol. And, of course, it supports transactions. It therefore offers \n",
      "content_length": 4396,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 114,
      "content": " many of the main features of transactional middleware. It’s interesting to compare database servers to transac-\ntional middleware, to see where these two technologies are similar and different. \n Stored procedures are written in either a proprietary version of SQL or a general-purpose programming \nlanguage, and can issue SQL requests to the database system, just like a transaction server running in an appli-\ncation server. Thus, a request controller can directly call stored procedures, instead of ﬁ rst calling a transaction \nserver, which in turn calls a database server. Said differently, the transaction server application can be written \nas a stored procedure. In fact, the request controller application can be written as a stored procedure too. \n Figure 3.9 shows the process structure of transactional middleware and database servers. Most relational \ndatabase systems today offer this database server structure, including those from IBM, Oracle, Sybase, and \nMicrosoft. So why might one buy a transactional middleware product if the database server supports most of \nthe facilities that we’ve been discussing in this chapter? \n One reason is scalability. In a multitier system running under transactional middleware, if a machine becomes \noverloaded, one can simply reassign request controller and transaction server processes to another machine. \nToday, this isn’t very easy with most database servers, because the application runs in the same process and \ntherefore on the same machine as the database server. Spreading the workload across multiple database servers \nrequires a request controller outside the database servers to distribute the load and to multiplex sessions across \na large number of users (see Section 2.6,  Scaling Out a System ). We expect this scalability advantage of trans-\nactional middleware will decrease over time as database servers add more functionality to support partitioning \nand scalable data sharing. The capabilities of web servers also are growing, however, and are increasingly being \nused to route requests directly to a database on behalf of a web browser client. \n Like scalability, the issues that distinguish transactional middleware from database servers are changing with \neach new product release, so any list of feature distinctions we give here would be quickly outdated. However, \nwe can identify general areas where functionality differences often are found. The main ones are as follows: \n ■  Choice of programming language: Some database servers offer a more limited set of programming \nlanguages for stored procedures than application servers offer for transaction servers. And even when \nFront-end\nprogram\nRequest\nController\nTransaction\nServer\nRelational\nDBMS\nClient\nDatabase Server\nTransactional\nMiddleware\nConfiguration\nDatabase Server\nConfiguration\nRelational\nDBMS\nStored\nprocedures\n FIGURE 3.9 \n Transactional Middleware and Database Server Conﬁ gurations. The database server architecture eliminates the request \ncontroller layer of the transactional middleware. \n3.7 Database Servers Versus Transactional Middleware  95\n",
      "content_length": 3096,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 115,
      "content": "96  CHAPTER 3 Transaction Processing Application Architecture\n database servers support standard languages, they impose restrictions to ensure compatibility with the \ndatabase software. \n ■  Implicit transaction bracketing: Many database servers require explicit bracketing of transactions using \nStart, Commit, and Abort, rather than allowing components to be tagged with transaction attributes, such \nas Requires New, Required, and Supported. The explicit bracketing of transactions makes it more difﬁ -\ncult to compose them. \n ■  Transports: A TP system can offer both secure and reliable transport (written to a journal) between client \nand server. Most database systems don’t offer this. \n ■  Debugging: Some database servers offer weaker debugging and development tools than are available in \na general-purpose program development environment. The latter are usually fully available when using a \ntransaction server. \n ■  Interoperable distributed transactions: Most database servers offer distributed transactions with two-\nphase commit. However, they often do not offer distributed transactions across database servers from dif-\nferent vendors and other transactional resource managers, such as record-oriented ﬁ le systems and queue \nmanagers. This usually requires a two-phase commit protocol implemented by transactional middleware \nor the underlying platform. \n ■  Communications efﬁ ciency: Some database server protocols are more efﬁ cient for pipelined transfer of \nlarge data sets than transactional middleware protocols. \n ■  Protocol support: Application processes running with transactional middleware can use all platform-\nsupported protocols. By contrast, some database servers have limited protocol support. For example, \nthey may not support HTTP, so remote requests to a database server need to pass through an application \nprocess, such as a web server. \n ■  Multitransaction workﬂ ow: Some transactional middleware products have more functionality than data-\nbase servers in support of multitransaction workﬂ ows, such as the ability to conﬁ gure resource depen-\ndencies and transactional compositions. \n ■  System management: Some transactional middleware products offer a richer system management envi-\nronment than a database server offers. For example, it may allow prioritization of applications, applica-\ntion-based load control, remote name resolution, geographical entitlement, or application-based security. \n Over the past decade, the functionality gap between database servers and transactional middleware has been \ngetting smaller. Only time will tell whether this trend will continue or transactional middleware will add func-\ntionality fast enough to stay ahead of database servers for decades to come. \n 3.8  SUMMARY \n The processing of simple requests involves receiving a request, routing it to the appropriate application pro-\ngram, and then executing it. This activity usually is distributed across components of a multitier architecture, \nconsisting of the following: \n ■  Front-end programs, for interaction with an end user or special device \n ■  Request controllers, for routing a request to the correct transaction program \n ■  Transaction servers, to do the work necessary to fulﬁ ll the request, usually involving accesses to transac-\ntional resources, such as databases, and typically returning results to the caller \n",
      "content_length": 3371,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 116,
      "content": " This architecture is aligned with service-oriented architecture, by mapping services to transaction servers, and \nwith object-oriented design, by mapping business objects to transaction servers. \n The front-end program is responsible for interacting with the end user via menus and forms, gathering \ninput for the transaction request and the name of the transaction to be executed. After gathering input, the \nfront-end program constructs the request message and sends it to the request controller. The front-end program \nneeds a suitably secure connection to the request controller, optionally using geographical entitlement to check \nthat the user is authorized for the speciﬁ c device. Currently, the most popular technology for these functions is \nthe web browser running on the end user’s device, communicating with a web server that executes many of the \nfront-end program’s functions. When money or personally identiﬁ able information is involved, the connection \nbetween web browser and web server often is enabled by use of Transport Layer Security. \n The main goal of the request controller is routing. It decodes the request message, determines the location of \nthe transaction program to be called, and makes the call. The request controller brackets the transaction that exe-\ncutes the request. Its application code is structured to solve the transaction composability problem using what-\never mechanisms are available from the underlying middleware or platform. It ensures that each request is not \nlost if its corresponding transaction aborts. It typically runs in a multithreaded process, often partitioning front-\nend sessions by request controller for scalability. It also bridges the per-user security model of the front ends \nwith the process-oriented authorization model that usually is needed for communication with back ends. \n The transaction server executes program logic to fulﬁ ll the request, such as retrieve data from a database \nor update data with new values provided by the request. It usually is implemented as a multithreaded process, \nwhich in turn communicates with multithreaded database servers using pooled database sessions. \n Transactional middleware products provide APIs, development tools, system management tools, and integra-\ntion with popular database systems and front-end programs. Transactional middleware products typically pro-\nvide an abstraction called a container that helps TP application developers handle the complexities of transaction \nmanagement and low-level operating system functions such as multithreading, communications, and security. \n Many functions previously performed only by transactional middleware products are now features of data-\nbase servers. Transactional middleware products still provide features that database servers don’t yet have, such \nas request routing, server classes, transactions distributed across multiple types of resource managers, compos-\nable transactions by setting transaction attributes, and certain system management and administrative functions \nfor TP applications programs and systems. However, database servers are suitable for many applications and \ntheir range of applicability is growing. \n \n3.8 Summary  97\n",
      "content_length": 3219,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 117,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 118,
      "content": " 4.1  WHY USE QUEUES? \n In direct transaction processing, a client sends a request to a server and synchronously waits for the server to \nrun the transaction and reply. For example, using RPC, the client sends a request to the system as an RPC, \nwhich returns with a reply indicating whether or not the transaction ran. \n Even though this direct TP model is widely used in practice, it has some limitations (see  Figure 4.1 ). The \nﬁ rst problem is dealing with the failure of a server or of client-server communications, which prevents a client \nfrom communicating with the server. If a client sends a request to this server, it immediately receives an error \ntelling it that the server is down or disconnected and therefore is unable to receive the request message. At this \npoint, either the client is blocked, waiting for a server to become available, or the user has to return later and \nresubmit the request to the client. A desirable alternative, which is not possible in direct TP, is simply to ask that \nthe request be sent as soon as the server is available, without the user or client being required to wait on-line for \nthe server to do so. For example, the user might want to log off and come back later to get the reply. \n The second problem is the inverse of the ﬁ rst. The client may successfully send the request to the server. \nBut the server, after executing the transaction, may be unable to send a reply to the client, because the client \nfailed, client-server communications failed, or the server failed after completing the transaction and before \nsending the reply. In each of these failure cases, the server’s reply may be lost. So even after the failed com-\nponent has recovered, the client still may not receive a reply. It therefore doesn’t know whether its last request \nactually ran, and hence whether it should resubmit the request. \n The ﬁ rst or second problem could occur due to failed communications between the client and server. \nSuppose the client sends the request to the server and does not receive an immediate error. What does it do if \nit does not receive a reply in a timely manner? It cannot tell whether the original request failed to be delivered \nto the server due to a communication failure or server failure, or the request was delivered to the server but the \nreply failed to be delivered back to the client. Under the circumstances, it is hard to imagine how the system \ncould be programmed to execute each request exactly once, which is usually the behavior that’s desired. \n A third issue is load balancing. In direct TP, if there is a pool of servers that can handle a client’s request, \nthen the mechanism for binding a client to a server must select one of the servers from the pool. As discussed \nin Section 2.3,  Server Classes , one approach is to randomize the selection of a server, so on average, the same \nnumber of clients are connected to each server. However, this randomization is just a guess. At any given \nmoment, the actual load may not be equally balanced among the servers. That is, one server could receive \nmany requests requiring a lot of work and thereby become overloaded. At the same time, other servers may not \n Queued Transaction Processing \n 4 \nCHAPTER\n",
      "content_length": 3237,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 119,
      "content": "100  CHAPTER 4 Queued Transaction Processing\n be receiving any requests at all. When the variance in workload is high, this type of situation is rather likely, \nleading to poor response time for some clients some of the time. \n Finally , this whole model is based on ﬁ rst-come, ﬁ rst-served scheduling of requests. There’s no sense of \npriority in the system in which high priority requests are processed early and low priority requests are delayed \nuntil later. \n We are using the term  “ client ” here because it’s more architecturally neutral than front-end program or web \nserver. The issues of interest apply to any program that is outside the TP system and submitting requests to run \ntransactions, rather than being a participant in the transaction itself. \n Queues as the Solution \n These problems are solved by using a queue as a buffer for requests and replies between the client and \nthe server (see  Figure 4.2 ). Instead of sending a request directly to the server, a client sends it to a queue. And the \nserver receives those requests from the queue, instead of receiving them directly from the client. Similarly, the \nserver sends replies to a queue, and the client receives replies from the queue. \na. Server down\nb. Client down\nc. Unbalanced Load\nServer\nRequest\nRequest\nUrgent\nRequest\nRequest\nServer2\nServer3\nRequest\nRequest\nRequest\nServer1\nRequest\nRequest\nRequest\nRequest\nd. First-come first-served\nServer\ndown\nRequest\nClient\nClient\nReply\ndown\nServer\n FIGURE 4.1 \n Problems with Direct TP. (a) Sending a request to a down server. (b) Sending a reply to a down client. (c) Balancing the \nrequest load across many servers. (d) Scheduling requests. \nClient\nEnqueue\nDequeue\nServer\nQueue\n FIGURE 4.2 \n Queued Transaction Model. In queued TP, clients send requests to queues, and servers receive requests from queues. \nThis is in contrast to direct TP, where clients send requests to servers. \n",
      "content_length": 1907,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 120,
      "content": " The queue is a transactional resource. So operations on the queue are made permanent or undone, depend-\ning on whether the transaction that issued the operations commits or aborts. Usually, the queue is persistent \nand is stored on disk or some other nonvolatile storage device. \n This queued TP model solves the problems that we just listed. First, a client can send a request even if it \nis targeted for a server that is busy, down, or disconnected, as long as the queue is available. The client simply \nstores the request in the queue. If the server is available, it can execute the request right away. Otherwise, when \nthe server becomes available, it can check the queue and run requests that were submitted while it was down. \n Second , a server can send a reply to a client even if the client is down or disconnected, as long as the client’s \nreply queue is available. The server simply sends the reply to the queue. When the client recovers or is recon-\nnected to the system, it checks the queue to ﬁ nd any reply messages that are waiting. \n By using queues to capture requests and replies, we can implement exactly-once execution of requests. \nFor each request that a client submits, the client can tell whether the request is waiting to be processed (in the \nrequest queue), executing (absent from both queues), or processed (in the reply queue). There are some corner \ncases that need attention, but with queues an implementation of exactly-once execution seems within reach. \nWe will work out the details in Sections 4.2 and 4.3. \n Third , as shown in  Figure 4.3 , many servers can be receiving requests from the same queue, thereby balanc-\ning the load across many servers. This load balancing is fully dynamic. As soon as a server ﬁ nishes processing \none request, it can take another request from the queue. There is never a time when one server is overloaded \nwhile another is idle. \n Fourth , queues can be used for priority-based scheduling. Each request can be tagged with a priority, which \nis used to guide the scheduling strategy. For example, each server can dequeue requests highest-priority-ﬁ rst. \nAlternatively, to ensure low priority requests are given some service, one server can be given the job of servic-\ning low-priority requests while all other servers use highest-priority-ﬁ rst. Or each request’s priority could be \nset to be its deadline, and requests are processed in deadline order. Requests can also be scheduled manually, \nby collecting them in a queue and running them under operator control. Once there is a queue in the picture, \nthere is great ﬂ exibility in controlling the order in which requests are processed. \n A queue is also useful as an intermediary between a back-end system and a remote service, for many rea-\nsons. It can buffer the effect of network delays. It can be used to localize credentials for accessing the remote \nservice. It can be a protocol bridge by supporting different protocols for remote and local access. And it is a \nconvenient place for auditing and performance measurement of the remote service. \n This is a long list of beneﬁ ts for such a relatively simple mechanism. For this reason most transactional mid-\ndleware products and even some database systems support queues as one way of moving requests and replies \nClient\nEnqueue\nDequeue\nServer\nServer\nQueue\nClient\n•\n•\n•\n•\n•\n•\n FIGURE 4.3 \n Load Balancing Using Multiple Servers. When a server ﬁ nishes processing one request, it takes another request from the \nqueue. This dynamically balances the load across all servers. \n4.1 Why Use Queues?  101\n",
      "content_length": 3583,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 121,
      "content": "102  CHAPTER 4 Queued Transaction Processing\n between clients and servers. Usually, queues sit between the front-end program and the request controller, as \nshown in Figure 3.1. Since queues can be used in other parts of a system, in the rest of this chapter we will use \nthe more general client-server terminology, instead of front-end program and request controller terminology. \nHowever, to be concrete, you can think about it in the latter setting without being misled. \n 4.2  THE QUEUED TRANSACTION PROCESSING MODEL \n Server’s View of Queuing \n Let ’s look at how the queued TP model works in the context of a transaction from a server’s perspective. As in \nour description of direct TP in previous chapters, we will assume that each request is asking for just one trans-\naction to be executed. In the queued TP model, the server program starts a transaction and dequeues the next \nrequest from the request queue (see  Figure 4.4 ). The server then does the work that the request is asking for, \nenqueues the reply to the reply queue, and commits. \n Since these queues are transactional resources, if the transaction aborts, the dequeue operation that receives \nthe request is undone, thereby returning the input request to the request queue. If the abort happens at the very \nend, then the enqueue operation to the reply queue also is undone, thereby wiping out the reply from the reply \nqueue. Therefore, whenever the client checks the queues, either the request is in the request queue, the reply is \nin the reply queue, or the request can’t be checked because it is currently being processed. In any case, there’s \nnever any ambiguity as to the request’s state. It either has not yet been processed, is in the midst of being pro-\ncessed, or has been completed. \nStart\n    Dequeue (Request queue)\nprocess request\n    Enqueue (Reply queue)\nCommit\nRequest queue\nReply queue\n FIGURE 4.4 \n Managing a Queued Request within a Transaction. The request is dequeued and the reply enqueued within a transaction. \nIf the transaction aborts, the request isn’t lost. \n",
      "content_length": 2064,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 122,
      "content": " Client’s View of Queuing \n In  Figure 4.4 we looked at the queues from the server’s viewpoint. Now let’s look at the entire path from the \nclient to the server in the queued TP model. In this model, each request executes three transaction programs (see \n Figure 4.5 ). Transaction 1 (Submit Request) receives input from the user, constructs a request, enqueues that \nrequest onto the request queue, and then commits. Then Transaction 2 (Execute Request) runs, just as described \nin  Figure 4.4 : It starts a transaction, dequeues the request, processes the request, enqueues the reply, and com-\nmits. At this point, the request is gone from the request queue, and the reply is sitting in the reply queue. Now, \nTransaction 3 (Process Reply) runs: It starts a transaction, dequeues the reply from the reply queue, translates \nthe reply into the proper output format, delivers that output, and commits, thereby wiping out the reply from the \nreply queue. \n For example, to run a debit transaction, the client runs a transaction that enqueues a request on the request \nqueue. The debit server runs a transaction that dequeues the request, debits the account, and enqueues a reply \nthat conﬁ rms the debit. Later, the client runs a transaction to dequeue the reply and print a receipt. By contrast, \nif direct TP were used, the client would send the request directly to the server, and the server would send the \nreply directly to the client, all within one transaction and without any queues in between. \n In  Figure 4.5 the client pushes a request to the queue while the server pulls it from the queue. If desired, \nthe server (Transaction 2) can be turned into a push model by adding a dispatcher component that starts a \ntransaction, dequeues the request, calls the rest of the Transaction 2 code (i.e., starting with  “ process request ” \nin  Figure 4.5 ), and, after the latter ﬁ nishes, commits. \n Because the queues are now under transaction control, they have to be managed by a database system or \nsome other resource manager that supports transaction semantics. To optimize performance, TP systems often \nTransaction 1: //submit request\nStart\nget input\nconstruct request\n   Enqueue (request queue)\nCommit\nTransaction 3: //process reply\nStart\nDequeue (reply queue)\nDecode reply\nprocess output\nCommit\nClient\nTransaction 2: //execute request\nStart\nDequeue (request queue)\nprocess request\n   Enqueue (reply queue)\nCommit\nServer\nRequest\nqueue\nReply\nqueue\n FIGURE 4.5 \n Running a Request as Three Transactions. The client submits a request (Transaction 1), the server processes the request \nand returns a reply (Transaction 2), and the client processes the reply (Transaction 3). \n4.2 The Queued Transaction Processing Model  103\n",
      "content_length": 2732,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 123,
      "content": "104  CHAPTER 4 Queued Transaction Processing\n use a specialized queue manager that is tuned for the purpose. Today’s transactional middleware products typi-\ncally provide an API to an external queued messaging system that supports transaction semantics. \n Notice that to run even a single request, the system executes three transactions. The client transactions may \nbe rather lightweight, as transactions go. For example, in the simple case of  Figure 4.5 , they each do one access \nto a transactional resource, that is, a queue. But even so, queued TP uses more system resources than an ordinary \ndirect TP system in which each request runs as a single transaction. Not only are there two client transactions, \nbut the server transaction has two additional accesses to transactional resources — the request and reply queues. \nIn return for this extra overhead, the system offers the beneﬁ ts that we talked about previously; that is, communi-\ncation with unavailable servers and clients, load balancing across servers, and priority-based scheduling. \n 4.3  CLIENT RECOVERY \n An important reason to use queuing instead of direct TP is to address certain client and server failure situa-\ntions. In this section, we systematically explore the various failure situations that can arise. We do this from a \nclient’s perspective, to determine what a client should do in each case. \n We will assume the request-reply model of  Figure 4.5 . That is, a client runs Transaction 1 to construct and \nsubmit a request, and later runs Transaction 3 to receive and process the reply. Its goal is to get exactly-once \nbehavior; that is, that Transaction 2 executes exactly once and its reply is processed in Transaction 3 exactly once. \n Let us assume that there is no failure of the client, the communications between the client and the queues, \nor the queues themselves. In this case, the client’s behavior is pretty straightforward. It submits a request. Since \nthere are no failures between the client and the request queue, the client receives an acknowledgment that the \nrequest is successfully enqueued. The client then waits for a reply. If it is waiting too long, then there is presum-\nably a problem with the server — it is down, disconnected, or busy — and the client can take appropriate action, \nsuch as sending a message to a system administrator. The important point is that there is no ambiguity about the \nstate of the request. It’s either in the request queue, in the reply queue, or being processed. \n Suppose the client fails or loses connectivity to the queues, or the queues fail. This could happen for a vari-\nety of reasons, such as the failure of the client application or machine, the failure of the machine that stores the \nqueues, a network failure, or a burst of trafﬁ c that causes one of these components to be overloaded and there-\nfore unresponsive due to processing delays. At some point, the failed or unresponsive components recover and \nare running normally again, so the client can communicate with the queues. At this point the client needs to run \nrecovery actions to resynchronize with the queues. What exactly should it do? \n To keep things simple, let’s assume that the client processes one request at a time. That is, it processes the \nreply to each request before it submits another request, so it has at most one request outstanding. In that case, at \nthe time the client recovers, there are four possible states of the last request it submitted: \n A.  Transaction 1 did not run and commit. Either it didn’t run at all, or it aborted. Either way, the request was \nnot submitted. The client should resubmit the request (if possible) or else continue with a new request. \n B.  Transaction 1 committed but Transaction 2 did not. So the request was submitted, but it hasn’t executed \nyet. The client must wait until the reply is produced and then process it. \n C.  Transaction 2 committed but Transaction 3 did not. The request was submitted and executed, but the \nclient hasn’t processed the reply yet. The client can process the reply right away. \n D.  Transaction 3 committed. The request was submitted and executed, and the client already processed the \nreply. So the client’s last request is done, and the client can continue with a new request. \n To determine what recovery action to take, the client needs to ﬁ gure out which of the four states it is in. \n",
      "content_length": 4391,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 124,
      "content": " If each client has a private reply queue, it can make some headway in this analysis. Since the client pro-\ncesses one request at a time, the reply queue either is empty or has one reply in it. So, if the reply queue is \nnonempty, then the system must be in state C, and the client should go ahead and process the reply. If not, it \ncould be in states A, B, or D. \n To disambiguate these states, some additional state information needs to be stored somewhere. If the client \nhas access to persistent storage that supports transaction semantics, it can use that storage for state informa-\ntion. The client marks each request with a globally-unique identiﬁ er (ID) and stores the request in persistent \nstorage before enqueuing it in the request queue (see LastRequest in Transaction 0 in  Figure 4.6 ). In persistent \nstorage the client also keeps the IDs of the last request it enqueued and the last reply it dequeued, denoted \nLastEnqueuedID and LastDequeuedID, respectively. It updates these IDs as part of transactions 1 and 3 that \nenqueue a request and dequeue a reply, as shown in  Figure 4.6 . In that ﬁ gure, the expression R.ID denotes the \nID of request R. \n At recovery time, the client reads LastRequest, LastEnqueuedID, and LastDequeuedID from persistent \nstorage. It uses them to analyze the state of LastRequest as follows: \n ■  If LastRequest.ID  \u0002 LastEnqueuedID, then the system must be in state A. That is, the last request that the \nclient constructed was not successfully submitted to the request queue. Either the client failed before run-\nning Transaction 1, or Transaction 1 aborted because of the client failure or some other error. The client\ncan either resubmit the request or delete it, depending on the behavior expected by the end user. \n   Dequeue (Request queue)\n   process request\n   Enqueue (Reply queue)\nCommit\nTransaction 2: //Execute Request\nStart\nR \u0005 Dequeue (Reply queue)\ndecode reply\nprocess output\nCommit\nTransaction 3: //Process Reply\nStart\nLastDequeuedID \u0005 R.ID\nTransaction 1: //Submit Request\nStart\nR \u0005 LastRequest\nEnqueue (Request queue, R)\nCommit\nLastEnqueuedID \u0005 R.ID\nget input\nTransaction 0: //Create Request\nStart\nconstruct request R\nCommit\nLastRequest \u0005 R\nRequest queue\nReply queue\nClient\nServer\n FIGURE 4.6 \n Client Maintains Request State . The client stores the ID of the last request it enqueued and the last reply it dequeued, in \nTransactions 1 and 3, respectively. \n4.3 Client Recovery  105\n",
      "content_length": 2448,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 125,
      "content": "106  CHAPTER 4 Queued Transaction Processing\n ■  If LastRequest.ID  \u0005  LastDequeuedID, then the client dequeued (and presumably processed) the reply \nto the last request the client submitted, so the system is in state D. In this case, the request ID has helped \nthe client match up the last request with its reply, in addition to helping it ﬁ gure out which state it is in. \n ■  If the reply queue is nonempty, the client should dequeue the reply and process it (i.e., state C). Notice \nthat in this case, LastRequest.ID  \u0005  LastEnqueuedID and LastRequest.ID  \u0002 LastDequeuedID, so the \nprevious two cases do not apply. \n ■  Otherwise, the client should wait until the reply appears before dequeuing it (i.e., state B). \n This recovery procedure assumes that the client uses a persistent storage system that supports transaction \nsemantics. This is a fairly strong assumption. The client may not have such storage available. Even if the client \ndoes have it, the application developer may want to avoid using it for performance reasons. That is, since the \nqueue manager and persistent storage are independent resource managers, the two-phase commit protocol is \nneeded for Transactions 1 and 3, which incurs some cost. \n This cost can be avoided by storing the state information in the queue manager itself. For example, the \nclient could store LastEnqueuedID and LastDequeuedID in a separate queue dedicated for this purpose. \nAlternatively, the queue manager could maintain LastEnqueuedID and LastDequeuedID as the state of a persis-\ntent session between the client and the queue manager. The client signs up with the queue manager by opening \na session. The session information is recorded in the queue manager’s persistent storage, so the queue manager \ncan remember that the client is connected. If the client loses connectivity with the server and later reconnects, \nthe queue manager remembers that it already has a session with the client, because it is maintaining that infor-\nmation in persistent storage. So when the client attempts to reconnect, the system re-establishes the existing \nsession. Since the session state includes the request and reply IDs, the client can ask for them as input to its \nrecovery activity. \n The recovery scenario that we just described is based on the assumption that the client waits for a reply to \neach request before submitting another one. That is, the client never has more than one request outstanding. \nWhat if this assumption doesn’t hold? In that case, it is not enough for the system to maintain the ID of the last \nrequest enqueued and the last reply dequeued. Rather, it needs to remember enough information to help the cli-\nent resolve the state of all outstanding requests. For example, it could retain the ID of every request that has not \nbeen processed and the ID of the last  n replies the client has dequeued. Periodically, the client can tell the queue \nmanager the IDs of recently dequeued replies for which it has a persistent record, thereby freeing the queue \nmanager from maintaining that information. Many variations of this type of scheme are possible. \n This scenario assumes that after a client processes a reply, it no longer needs to know anything about that \nrequest’s state. For example, suppose a client runs two requests. It submits Request 1 , the server processes \nRequest 1 and sends Reply 1 , and the client processes Reply 1 . Then the client submits Request 2 , the server pro-\ncesses Request 2 and sends Reply 2 , and the client processes Reply 2 . At this point, the client can ﬁ nd out about \nthe state of Request 2 , but not about Request 1 , at least not using the recovery procedure just described. \n Finding out the state of old requests is clearly desirable functionality. Indeed, it’s functionality that we often \ndepend on in our everyday lives, such as ﬁ nding out whether we paid for a shipment that hasn’t arrived or \nwhether we were credited for mileage on an old ﬂ ight. However, this functionality usually is not offered by a \nqueuing system or queued transaction protocols like the ones we have been discussing. Rather, if it is offered, \nit needs to be supported by the application as another transaction type — a lookup function for old requests. \nTo support this type of lookup function, the application needs to maintain a record of requests that it already \nprocessed. In ﬁ nancial systems, these records are needed in any case, to support the auditability required by \naccounting rules. However, even when they’re not required, they’re often maintained as a convenience to \ncustomers. \n",
      "content_length": 4593,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 126,
      "content": " 4.4  HANDLING NON-UNDOABLE OPERATIONS \n Although the analysis of the previous section appears to cover all the cases, it still leaves one problem open if \nthe system is in state C, namely how to handle the statement  “ process output ” in Transaction 3 if Transaction \n3 aborts. There are three cases to consider, depending on whether the process-output statement is undoable, is \nidempotent, or has neither of these properties. \n If the process-output statement is an undoable operation, then there is no problem. If Transaction 3 aborts, \nthen process-output is undone, just like any database operation. For example, this would be the behavior if pro-\ncess-output involves only recording the execution of the request in transactional persistent storage. \n If the process-output statement is idempotent, then again there is no problem. The operation does not need \nto be undone by an abort of Transaction 3. When Transaction 3 re-executes, it re-executes the process-output \nstatement, which is safe to do if the statement is idempotent. For example, this would be the case if process-\noutput involves printing a receipt that has a unique identiﬁ cation number that is linked to the request. There is \nno harm in executing it twice, since it would generate two identical receipts. It would be a bit confusing to the \nrecipient, but it might be acceptable since there is enough information to recognize the two receipts as dupli-\ncates of each other. \n Often , the process-output statement is neither undoable nor idempotent. For example, this typically arises \nwhen processing the output involves asking a physical device to perform some action in the real world, such \nas dispensing money. As we observed in Chapter 1, it isn’t clear whether this operation should be done before \nor after the transaction commits. If the operation is done before the transaction commits, but the transaction \nactually aborts, then the operation can’t be undone, as it should be. And it is unsafe to run the operation again \nwhen Transaction 3 re-executes, because the operation is not idempotent. On the other hand, if the operation is \ndone after the transaction commits, but a failure happens after the transaction commits and before the opera-\ntion executes, then the operation is lost. \n To solve this problem, the process-output statement must be operating on a device that has  testable state . \nThis means that it must be possible for Transaction 3 to read the state of the physical device, and the physical \ndevice must change its state as a result of performing the operation required by the process-output statement. \nThat way, the transaction can record the device’s state before it performs the operation and can determine if \nthe operation ran by comparing the device’s current state to the value it recorded. For example, the transaction \nmight read the check number that is to be printed next. After printing the check, the transaction would read a \ndifferent number for the new check sitting under the print head. If it reads the same number for the check, then \nit knows the printing operation did not execute. \n Given that this device state is available, the transaction that processes replies should follow the process-a-\nreply transaction shown in  Figure 4.7 . To see why this works, suppose the client is recovering from a failure \nand through the previous analysis determines that it is in state C. It should therefore process the reply by run-\nning the process-a-reply transaction. If this is its ﬁ rst attempt at processing the reply, then there is no earlier \nlogged device state for this reply, so the transaction performs the device operation and commits. Otherwise, \nin step (3) it determines whether it’s safe to rerun the device operation associated with this reply. If the state \nof the device has changed since the previous attempt to run the transaction, then the device operation for this \nreply appears to have executed, so it is  not safe. At this point, the operator must get involved to determine what \nreally happened. For example, did the check really get printed, or was it destroyed by the device, which caused \nthe previous execution of the reply-processing transaction to abort after logging the device’s state in step (4)? \nIn the latter case, the operator has to tell the current execution of the process-a-reply transaction whether it’s \nsafe to reprint the check. \n A clever technique for logging the device’s state is to read the device state  before dequeuing the reply (i.e., \nbefore step (2) in  Figure 4.7 ) and to attach the device state to the log record for the dequeue operation. Since \n4.4 Handling Non-Undoable Operations  107\n",
      "content_length": 4673,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 127,
      "content": "108  CHAPTER 4 Queued Transaction Processing\n the queue manager has to log the dequeue operation anyway (since it might have to undo it), it can log the \ndevice state at the same time and thereby do one write to the log, instead of two. \n There is one case where step (3) is not needed — if the device’s operation is idempotent. For example, sup-\npose the operation causes a robot arm to move to a certain position, or suppose it sends a mail message describ-\ning the transaction. In these cases, there may be no harm in executing the operation a second time. That is, the \noperation is idempotent. So there is no reason to log the state of the device and recheck it in steps (3) and (4). \n Sometime , an operation that is not normally idempotent can be made idempotent. This is important when it isn’t \npossible to read the current state of the device. For example, sending a mail message that says  “ you just bought \n100 shares of IBM ” is not idempotent. If you issued one request to buy 100 shares and got back two acknowl-\nedgment messages like this, you would be worried whether your request executed once or twice. Moreover, at \nrecovery time, there is no device state that the client can read to tell if the message was sent. However, if the mail \nmessage says,  “ your request, with conﬁ rmation number 12345, to buy 100 shares of IBM, has executed, ” there’s \nno harm in sending it twice. You would recognize the second message as a duplicate and ignore it. \n 4.5  THE QUEUE MANAGER \n To support a queuing model, the system needs a  queue manager that stores and manages queues. A queue \nmanager is a lot like a database system. It supports the storage abstraction of a queue store. The queue store \ncan be a conventional relational database system or a custom storage system designed speciﬁ cally for queue \nmanagement. Within a queue store, the queue manager supports operations to create and destroy queues and \nmodify a queue’s attributes (e.g., owner, maximum size, queue name, user privileges). Most importantly, it \nsupports operations on messages in queues. \n Operations on Queued Messages \n The main operations on messages are enqueue and dequeue. The queue manager should also support opera-\ntions to examine a queue, such as to determine if it’s empty, and to scan a queue’s messages one by one without \nTo Process a Reply:\n1.   Start a transaction\n2.   Dequeue the reply\n3.   If there is an earlier logged device state for this reply\n      and it differs from the current device state\n      then ask the operator whether to abort this transaction\n4.   Log the current device state on persistent storage along\n      with the reply’s ID. This operation must be performed\n     whether or not the transaction commits\n5.   Perform the operation on the physical device\n6.   Commit\nReply queue\nread\nwrite\nread\nread\nwrite\nLog\n FIGURE 4.7 \n Client Procedure for Reply Processing. Step (3) determines if the reply has already been processed. Step (4) logs the \ndevice state, in case this transaction aborts and restarts, so it can run step (3) the next time around. \n",
      "content_length": 3080,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 128,
      "content": " dequeuing them. It might also support random access to messages in a queue; for example, to read or dequeue \nthe third message in the queue or a message with a speciﬁ c ID. \n Usually , the dequeue operation offers two options in dealing with an empty queue. If called with the non-\nblocking option, it returns with an exception that says the queue is empty. For example, this is useful if a \nserver is polling several queues and does not want to be blocked on an empty queue since another one may be \nnonempty. If called with the blocking option, the dequeue operation remains blocked until a message can be \nreturned. The latter is useful, for example, to dequeue a reply when it arrives. \n Generalized Messaging \n We have focused on using queued messages for the reliable processing of requests and replies. However, queu-\ning can be used for other kinds of messages too. That is, the enqueue and dequeue operations can be used to \nsend and receive arbitrary messages. This is a peer-to-peer messaging scenario, where the communicating par-\nties can exchange messages in a general application-deﬁ ned pattern, not just matched request-reply pairs. \n In this scenario, it is sometimes useful to use volatile queues. That is, the content of the queues do not sur-\nvive system failures. Volatile queues still offer many of the beneﬁ ts discussed in Section 4.1, such as load bal-\nancing, priority scheduling, and the ability to communicate with an unavailable server. \n Timeouts \n If a message remains in a queue for too long without being processed, it may need special attention. It is there-\nfore useful to be able to attach a timeout to a message. If the timeout expires before the message has been \ndequeued, then a timeout action is invoked, such as discarding the message or enqueuing the message on another \nqueue (e.g., an error queue) with a tag that explains the timeout. \n Handling Poisoned Messages \n Suppose a message has faulty content that causes an abort of the transaction that dequeues it. The abort will cause \nthe dequeued message to be returned to the queue. To avoid repeating this problem forever, a queue may have \na user-conﬁ gurable threshold of the maximum number of times a message can be dequeued. To avoid rejecting \na message due to a transient system problem, the queue may offer control over the minimum time between the \nretries. If the retry threshold is exceeded, the message is moved to an error queue for manual reconciliation. This \nmay be done by the application, queue manager, or dispatcher, depending on the implementation. \n Message Ordering \n The message in a queue may be ordered in a variety of ways, such as ﬁ rst-come, ﬁ rst-served, in which case an \nenqueue operation places the new message at the end of the queue, or highest-priority-ﬁ rst, in which case an \nenqueue operation places the new message before the ﬁ rst message in the queue of lower priority. \n Whatever the priority mechanism, the ordering is normally made fuzzy by the possible abort of a transac-\ntion that does a dequeue. For example, suppose transaction T 1 dequeues the ﬁ rst message M 1 from the queue \nand then T 2 dequeues the next message M 2 (see  Figure 4.8 ). If T 1 aborts, then its dequeue operation is undone, \nso M 1 is returned to the queue. However, T 2 might commit, in which case M 2 ends up being processed before \nM 1 , even though it should have been processed  after M 1 . \n To avoid this anomaly, T 2 should not be allowed to dequeue M 2 until after T 1 commits. For example, the \nqueue may be set to disallow concurrent dequeues. Unfortunately, this eliminates concurrency among transac-\ntions that dequeue from the same queue, in this case T 1 and T 2 , and therefore degrades performance. Since \nthis reduction in concurrency is only to prevent the relatively infrequent out-of-order dequeuing that results \nfrom an abort, most systems allow concurrent dequeue operations and ignore the occasional out-of-order \n4.5 The Queue Manager  109\n",
      "content_length": 3985,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 129,
      "content": "110  CHAPTER 4 Queued Transaction Processing\n dequeuing. However, in some applications, out-of-order processing is unacceptable, for example, for legal rea-\nsons. For example, in a stock trading system, orders submitted at the same price (to buy or sell) may be legally \nrequired to be processed in strict arrival order. To obey this rule and get satisfactory concurrency, trading sys-\ntems exploit the speciﬁ c semantics of the trading transactions themselves, for example, by batching up a set of \ntrades and committing them as a group (even though they were submitted separately). \n Filter Criteria \n Some queue managers offer clients the ability to dequeue messages based on their content. That is, rather than \nsimply dequeuing the oldest message, the client can dequeue the oldest message that has a particular value in \none of its content ﬁ elds. For example, the client might ﬁ rst dequeue a message with a ﬁ eld  “ importance ” equal \nto the value  “ high. ” If there are no such messages, then it could revert to dequeuing the oldest one. \n Nontransactional Queuing \n Most clients of the queue manager execute queue operations within a transaction. However, it is sometimes \ndesirable to execute operations as independent transactions, so the result is recorded whether or not the sur-\nrounding transaction aborts. A classic example is a security violation. Suppose a running transaction discovers \nthat the request it is executing is illegal — for example, it includes an illegal password. It is often important to \nrecord such violations, so they can be analyzed later to ﬁ nd patterns of security break-in attempts. The transac-\ntion can do this by enqueuing a security violation message on a special queue. Even if the transaction aborts, the \nsecurity violation should still be persistently recorded. Therefore, the operation to enqueue the security violation \nmessage should run as a separate transaction, which commits even if the transaction that called it aborts. \n Journaling \n Queued messages can provide a history of all the transactions that were executed by a TP system. Therefore, \nsome queue managers offer an option to save a description of all operations on messages in a journal. The \njournal may be useful for ﬁ nding lost messages or for auditing purposes; for example, to prove that certain \nmessages were submitted and/or processed, or to comply with government regulations, such as the Sarbanes-\nOxley Act. \n Queue Management \n A queue manager usually supports operations to start and stop a queue. Stopping a queue disables enqueue and \ndequeue operations. While the queue is stopped, these operations return an exception. This is a way of taking \na queue off-line, for example, if the server that processes its messages is down. It is also useful to enable and \nT1 dequeues M1\nT2 dequeues M2\nT2 commits\nT1 aborts (which returns M1 to the queue)\nT3 dequeues M1\nM1\nM2\n FIGURE 4.8 \n An Abort Destroys Priority Ordering. Although M 1  is dequeued before M 2 , since T 1  aborts, M 2  is processed before M 1 . \n",
      "content_length": 3043,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 130,
      "content": " disable enqueue and dequeue operations independently. For example, if a queue is full, enqueue operations can \nbe disabled so the queue will not accept any new work. \n Routing \n A queue manager usually supports ﬂ exible routing. For example, it may support queue forwarding, to move mes-\nsages from one queue to another. This is useful to reroute a client system’s input queue to another server system \nwhen the server is overloaded or down. It can also be used to save communications by batching up requests on \none system and sending them later in bulk to another system, rather than sending them one by one. Queue for-\nwarding involves reading one or more messages from one queue, moving them to the other queue, storing them \non disk, and then committing, thereby removing the messages from one queue and installing them on the other \nqueue as one transaction. \n A typical conﬁ guration that exploits queue forwarding is shown in  Figure 4.9 . The client can reliably enqueue \nrequests locally, whether or not the server system is available. Requests on the local queue can subsequently be \nforwarded to the server’s queue. The queue manager might offer an option to send an acknowledgment to the \nclient when the message reaches its ﬁ nal destination, in this case on System B, or when the transaction that \ndequeues the message has committed. \n The transaction to forward a request adds a fourth transaction to the three-transaction model and a ﬁ fth if \na reply is needed. Alternatively, a client could enqueue its requests directly to a server queue, without using a \nlocal queue as an intermediary. This saves the fourth transaction to forward the request and a ﬁ fth to return a \nreply. However, the client is unable to submit transactions when the remote queue is unavailable. Some prod-\nucts offer both queue forwarding and remote queuing. This allows a hybrid scheme, where the client enqueues \nto the remote server queue when it’s available, otherwise it uses a local queue. \n Of course, for a client to support a local queue, it needs a queue store. This requires additional hardware \nresources and system administration — the price to be paid for the additional availability. \n A queue manager may also support parameter-based routing, as was described in Section 2.6. This allows \na queue to be partitioned onto multiple systems for scale-out. It may also enable more ﬂ exible reconﬁ guration \noptions. For example, if a queue is overloaded, messages with certain parameter values can be directed to a more \nlightly loaded queue simply by changing the mapping of parameter values to queue names. \nEnqueue\nDequeue\nQueue\nQueue\nClient\nSystem A\nSystem B\nServer\n FIGURE 4.9 \n Forwarding with Local Enqueuing. The client enqueues requests to its local queue. Those requests are transparently \nforwarded to the server’s queue, where the server dequeues them locally. \n4.5 The Queue Manager  111\n",
      "content_length": 2906,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 131,
      "content": "112  CHAPTER 4 Queued Transaction Processing\n Dispatcher \n A queue manager usually includes a dispatcher, to support a push model as mentioned near the end of Section \n4.2. Instead of requiring an application to call the queue manager to dequeue a message, the dispatcher calls the \napplication when a new message appears on the queue. Many scheduling options are possible: It may do this \n(1) every time a new message arrives, (2) only if a new message arrives when the application is not currently \nrunning, (3) when the queue reaches a certain length, or (4) at ﬁ xed time intervals provided the queue is non-\nempty. The dispatcher may also include load control, to limit the number of application threads it can invoke. \nThat is, if the maximum number of application threads are already executing, then a new message that appears \non the queue must wait there until a thread ﬁ nishes executing its current request. \n 4.6  PUBLISH-SUBSCRIBE \n Using queued communication, each message has a single recipient — the process that dequeued the message. \nBy contrast, some applications need to send a message to multiple recipients. For example, this arises with a \nnotiﬁ cation service that broadcasts an alert when an important event occurs, such as a major change of a stock \nprice. If the sender knows the identities of all the recipients, it can broadcast the message by sending the mes-\nsage to each of them. However, this is inconvenient if there is a large number of recipients. And it may not \neven be feasible if the sender doesn’t know the identities of all the recipients. \n To handle the latter case, a different communication paradigm can be used instead, called publish-subscribe. \nIn the  publish-subscribe paradigm, a publisher sends a message to a broker that is responsible for forwarding \nthe message to many subscribers. Typically, the publisher tags each message by its type. Each subscriber regis-\nters interest in certain message types. After receiving a message from a publisher, the publish-subscribe broker \nsends the message to all subscribers that have registered an interest in that message’s type. \n The publish-subscribe paradigm is like queuing in three ways. First, the sender and receiver are decoupled, \nin the sense that they don’t communicate directly with each other. Instead, they each communicate with the mes-\nsage broker. In fact, if one equates the notion of message type with that of queue, then the similarity is even more \npronounced; in effect, senders enqueue messages to a queue for the message type and receivers dequeue them. \n Second , messages can be sent or received in the context of a transaction. In that case, the operations to send \nor receive a message are undone in the event of an abort. \n Third , subscribers can use either a pull or push model. In the pull model the subscriber can explicitly poll \nfor new messages that satisfy its subscription. In the push model when a message arrives a dispatcher forwards \nthe message to all subscribers whose subscriptions include that message. \n Given these similarities between queuing and publish-subscribe systems, the two communications para-\ndigms often are supported by a common queue management implementation. This has become especially \ncommon since the development of the Java Message Service (JMS) standard, which includes a program-\nming interface for both point-to-point messaging and publish-subscribe. Other standard interfaces that offer \npublish-subscribe capability are the CORBA-Notiﬁ cation service and WS-Eventing or WS-Notiﬁ cation for \nWeb Services. \n In the simplest version, the message type is simply a name, sometimes called a topic. In more advanced \nversions, types can be grouped into a hierarchical namespace. So a type could be a path in the namespace, such \nas  “ Equity-exchange/NY-stock-exchange/IBM ” rather than simply  “ IBM. ” \n Some publish-subscribe systems allow subscribers to identify messages using predicates that refer to the \nmessages ’ content. For example, one could subscribe to (type  \u0005  “ IBM ” ) and (price  \u0006  100) where price is a \nﬁ eld in the message content. \n",
      "content_length": 4121,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 132,
      "content": " Publish -subscribe systems usually offer the option of having a subscription be persistent or volatile. If it is \npersistent, then each message is delivered to all registered recipients. If a recipient is unavailable when the mes-\nsage arrives, then the message broker retains the message and resends it when the recipient becomes available. \nIf the subscription is volatile, then when each message arrives, the message broker forwards it to all registered \nrecipients. If a recipient isn’t available, then it simply doesn’t receive the message; the message broker does not \nattempt redelivery when the recipient becomes available. \n 4.7  OTHER MESSAGE-ORIENTED MIDDLEWARE \n Many TP systems are used in conjunction with other TP systems that offer related application functionality. \nWe saw a simple example of this in Section 2.4, which described the integration of TP applications that sup-\nport checking accounts and credit card accounts. To be used together, the systems need to be integrated. \n Integration is hard because independent TP applications are usually heterogeneous in three ways. They \nsupport different communications protocols, different application functions, and different message formats. To \nintegrate the applications, all three of these differences must be reconciled. \n There are two main architectures for performing this reconciliation:  broker-based and  bus-based . Broker-\nbased products, sometimes called  enterprise application integration (EAI) systems, use a broker as interme-\ndiary between client and server to perform the integration. Bus-based products, sometimes called enterprise \nservice buses (ESBs), enable clients to communicate directly with servers. However, the technical distinction \nbetween EAI and ESB products is not always this sharp. For example, both product categories are moving \ntoward incorporating business process management capabilities, which will be discussed in the next chapter. \nAs we noted in Chapter 1, the terminology for transactional middleware product categories has been evolving \nover the past 15 years, an evolution that seems likely to continue. \n Broker-Based Architecture \n In a broker-based architecture a message server provides a bridge between the heterogeneous applications (see \n Figure 4.10 ). Instead of communicating directly with the applications, a client communicates with the broker, \nwhich forwards the message to the desired application. The client can be one of the applications being inte-\ngrated or an external program such as an end-user device. \n The broker provides three functions, which correspond to the three differences to be reconciled. First, it sup-\nports all the communication protocols required to communicate with the applications. A client sends a message \nTP Application\nTP System\nProtocol Adaptor\nProtocol Adaptor\nUniform\nFunction\nInterface\nParameter\nTranslation\nTP Application\nClient\nMessage Broker\nTP System\n FIGURE 4.10 \n Broker-Based Application Integration. The Message Broker mediates message transfer from clients to TP applications. \n4.7 Other Message-Oriented Middleware  113\n",
      "content_length": 3100,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 133,
      "content": "114  CHAPTER 4 Queued Transaction Processing\n to the broker using any of the supported protocols. The broker can forward that message to the desired applica-\ntion using the protocol supported by that application. \n Second , the broker supports the union of all the functions offered by the applications being integrated. \nUsually, the broker offers a uniform interface to these functions, such as a canonical message format deﬁ ned \nby the broker. Thus, a client can call these functions using that uniform interface, independent of the message \nprotocol, programming language, or other technologies used by the application that implements the function. \nInternally the broker stores a mapping that tells it how to translate each function into the form required by the \napplication that implements the function. This mapping often is implemented as a set of protocol adaptors, one \nfor each of the application environments being integrated. Some brokers can also support clients that use their \nown protocols and formats and don’t enforce the use of a single uniform interface \n Third , it offers tools for translating between different parameter and message formats. The translation may \nbe based on a calculation (such as translating between date formats), a table (such as translating between coun-\ntry codes), or a lookup from an external source (such as an exchange rate server to translate a money ﬁ eld \nbetween currencies). Some applications import or export structured documents (e.g., in XML), rather than indi-\nvidual parameters. In this case document translation is used, such as an XSLT program that translates one XML \ndocument into another XML document having a different format. \n Some brokers also offer routing functions. A message may be routed based on the contents of a request or \nby requirements that are set by the client or the server. Other broker functions include logging, auditing, per-\nformance monitors, and other system management functions. \n Bus-Based Architecture \n In a bus-based architecture all TP applications are invoked using the same communications protocol, which is \nconﬁ gurable for some products (such as Microsoft’s WCF and Progress Software’s Artix). For example, they \nmay all support the Web Service protocols. If a TP system does not support the common protocol, then it needs \nto have a protocol translator that translates from the bus’s common protocol to the system-speciﬁ c technology \nfor calling the TP system’s applications (see  Figure 4.11 ). \n Since all TP systems can be invoked using the same protocol, the TP application interfaces are naturally \nexposed using the same interface deﬁ nition technology, namely, the one supported by the protocol. For exam-\nple, if Web Services are used, then interfaces are deﬁ ned using WSDL and are made available to callers using \nUDDI. \nClient\nProtocol Adaptor\nTP Application\nTP System\nProtocol Adaptor\nTP Application\nTP System\nBus\n FIGURE 4.11 \n Bus-Based Application Integration. The client talks directly to TP applications using a standard wire protocol. \n",
      "content_length": 3061,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 134,
      "content": " Since there is no broker between the client and the TP system it calls, the client is usually responsible for \ntranslating between formats for parameters and messages. This can be done using a shared library of transla-\ntion functions that can be bound into the client’s applications. Or it can be implemented as a service that the \nclient invokes to translate parameters before invoking the target application. \n Comparing Brokers and Buses \n The main difference between broker-based and bus-based architectures is whether messages from client to TP \nsystem pass through an intermediate message server. If so, then it’s a broker-based architecture, in which case \nthe protocol translation usually takes place in the message server. If not, then it’s a bus-based architecture, in \nwhich case the protocol translation usually takes place in the TP systems running the applications to be inte-\ngrated. However, this distinction gets muddy when a bus-based architecture offers a queuing subsystem. It’s in \nthe eye of the beholder to regard the queue subsystem as another server on the bus or as a broker that mediates \naccesses between the client and the TP system. \n The broker-based and bus-based approaches are even more similar in their approaches to the uniform deﬁ -\nnition of application functions and parameter format translation. Both architectures require a directory service \nto expose the interface deﬁ nitions of the TP applications being integrated. For parameter translation, the main \ndifference seems to be in choosing where the functionality is implemented: in the client, in a broker or transla-\ntion service, or in the TP system. \n 4.8  QUEUING PRODUCTS AND STANDARDS \n A variety of queue manager products are available. One of the original implementations was in IBM’s IMS TP \nmonitor, where queued TP was the default behavior. Queuing is integrated with many other transactional mid-\ndleware products, such as Oracle’s WebLogic and JBoss Messaging. It is also integrated in Oracle Database, \ncalled Oracle Streams AQ, and in Windows, called Microsoft Message Queue (MSMQ). Some vendors offer \nqueuing in independent products, such as TIBCO’s Enterprise Message Service, Progress ’ SonicMQ, Apache \nActiveMQ, and IBM’s Websphere MQ (MQ  \u0005  Message Queuing). A consortium sponsored by JP Morgan \nChase has proposed a messaging standard, called Advanced Message Queuing Protocol. We brieﬂ y describe \nWebSphere MQ and Oracle Streams AQ here as two examples of such products. \n IBM’s WebSphere MQ \n IBM promotes WebSphere MQ 1 as an integration solution among its various operating system and TP environ-\nments and those of other vendors. It has a proprietary API, called Message Queuing Interface (MQI), a Java \nMessaging Service (JMS) API, and a non-Java equivalent of JMS. It can be used by applications running under \nIBM’s transactional middleware such as WebSphere Application Server and CICS Transaction Server, and on \nany operating system supported by WebSphere MQ, including IBM AIX, i5/OS, OS/400, and z/OS, as well as \nHP-UX, Linux, Sun Solaris, and Microsoft Windows. \n The WebSphere MQ  queue manager accepts input from an application via the JMS API or MQI verbs. \nThe main verbs are MQPUT to enqueue a message and MQGET to dequeue a message. A named queue can \nsupport multiple concurrent enqueuers and dequeuers. \n 1 The information in this section is based on WebSphere MQ V6.0. \n4.8 Queuing Products and Standards  115\n",
      "content_length": 3455,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 135,
      "content": "116  CHAPTER 4 Queued Transaction Processing\n To process an MQPUT, the queue manager starts a transaction if the application is not already executing one \nand places the message in the queue. The operation is committed along with the rest of the transaction (which can \nbe the normal exit from the application) or can optionally run in its own transaction as described in the subsection \non nontransactional queuing in this section. The enqueued message consists of application data and the  message \ncontext , including a variety of parameters, such as a system-generated message ID, a ﬂ ag indicating whether the \nmessage is persistent, a message priority, the name of the destination queue when forwarding, the name of the \nreply queue (if any), message type (datagram, request, reply, report), correlation id (to link a reply to a request), \npriority, expiry time, application-deﬁ ned format type, code page identiﬁ ers (for language localization), context \ninformation (to identify the user and application that generated the message), and report options — whether the \nrecipient should conﬁ rm on arrival (when it’s enqueued), on delivery (when it’s dequeued), on expiration (if \nthe expiry time is exceeded), on positive action (the application successfully serviced it), on negative action \n(the application was unable to service it), or on exception. \n A message that is oversized for the queue manager or application can be decomposed into smaller segments. \nMoreover, several messages can be assigned to a group, which allows the application to correlate independent \nmessages, such as those that arrive from different sources but must be processed by the same application. \n An application can request that MQI operations participate in a transaction. Otherwise, by default, each \nindividual MQPUT or MQGET executes outside a transaction, meaning that the operation completes immedi-\nately whether or not the application is executing a transaction. \n WebSphere MQ offers several transaction management options for applications that are running within a \ntransaction. If the only transactional operations are MQI operations, then the transaction can be managed as a \nlocal transaction by MQ. If the transaction needs to access other transactional resources, then MQ can play the \nrole of a resource manager under an external transaction manager, such as the Java Transaction API in Java EE. \nIf no external transaction manager is present, then on non-mainframe platforms MQ’s XA-capable transaction \nmanager can coordinate the transactions across MQ and databases. \n Like many queuing products, WebSphere MQ offers the ability to enqueue persistent and nonpersistent \nmessages in the same queue. Nonpersistent messages are more efﬁ cient but less reliable. They do not incur \nlogging overhead and normally are handled in main memory, without being written to disk. Both types of \nmessages obey transaction semantics. However, a persistent message is delivered exactly once, whereas a non-\npersistent message is delivered at most once; that is, once (in the absence of failures) or not at all (if there is a \nfailure). \n Queue forwarding is handled by another component, which is much like an ordinary client that does \nMQGET from one queue manager and MQPUT to another, though it does have special access to the log for its \nsequence number management. So if MQPUT has a destination queue name that maps to a remote queue, this \ncomponent forwards the message asynchronously and transactionally, using an intermediate node if necessary, \nto the system on which the remote queue exists (see  Figure 4.12 ). The queue forwarding component uses a \ntransaction that’s internal to MQ to coordinate updates to the source and target queues. \n An application issues an MQGET to dequeue a message. The queue manager starts a transaction upon \nreceipt of an MQGET verb, dequeues the message from the message queue, and upon the commit from the \napplication, physically removes the message from the queue. If the transaction aborts, the queue manager \nreturns the message to the queue. MQGET supports a blocking option, which blocks the caller if the queue \nis empty and awakens it when a message is available or a timeout expires. It also supports a signaling option, \nwhere the caller can continue executing and is notiﬁ ed when the desired message arrives. Messages can be \nretrieved in order or by searching for a given ID or key. The queue can also be browsed, to examine the mes-\nsages of the queue without deleting them. WebSphere MQ also includes a dispatcher that triggers the execu-\ntion of an application when the ﬁ rst message arrives on a queue, whenever a new message arrives, or when the \nqueue length reaches a predeﬁ ned threshold. \n",
      "content_length": 4750,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 136,
      "content": " WebSphere MQ supports multiple named queues per queue manager. Each queue manager has the follow-\ning components: a connection manager for managing the connections between the application and the queues; \na message manager for remote communications; a data manager to manage the physical storage of the linked \nlists comprising the queue; a lock manager for locking queues and messages; a buffer manager for caching \ndata, ordering writes, and ﬂ ushing data to disk; a recovery manager for keeping track of active transactions in \nthe event of a failure/restart; and a log manager for handling the recovery log. The component names differ \nslightly in different products. \n Features of most message queuing systems that support JMS are similar to WebSphereMQ. \n Oracle Streams AQ \n Unlike most queue management products, which are independent middleware components, Oracle Streams AQ is \na queuing facility that is built into Oracle Database. 2 It is built on top of Oracle Streams, which enables the prop-\nagation and management of information in data streams, either within a database or from one database to another. \nAQ can be accessed from most popular programming languages via APIs for PL/SQL, Oracle Call Interface, \nOracle Objects for OLE, and extended versions of JDBC and JMS that provide access to Oracle-speciﬁ c features \nsuch as those in AQ. It also offers web-based access via SOAP through the AQ XML Servlet. \n In Oracle Streams AQ queues are mapped to a table that can be accessed using the standard types of queu-\ning operations, such as enqueue and dequeue. Since queued messages are stored in a table, they can also be \naccessed by SQL queries. \n Oracle Streams AQ is a complete queuing system offering most of the capabilities described in Section 4.5. \nThe enqueue operation takes a queue name, payload, message properties, and enqueue options as input and \nreturns a message ID. Message properties and enqueue options control the behavior of the enqueue operation. \nFor example, using message properties, the sender can control the earliest time when a message is consumed, \nQueue\nz/OS\nAIX\nOS/400\nQueue\nQueue\nEnqueuing\nApplication\n(MQPUT)\nQueue\nManager\nQueue\nManager\nQueue\nManager\nDequeuing\nApplication\n(MQGET)\n FIGURE 4.12 \n WebSphere MQ Architecture. Messages can be forwarded transparently between queue managers running on different \nplatforms. \n 2 The information in this section is based on Oracle 11  g. \n4.8 Queuing Products and Standards  117\n",
      "content_length": 2477,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 137,
      "content": "118  CHAPTER 4 Queued Transaction Processing\n whether a message is volatile or persistent, the retry threshold after which a poison message is added to an \nexception queue, whether the operation is transactional, and priority ordering. \n The entire history of information about a message is maintained along with the message itself. This serves as \nproof of the sending and receipt of messages and can be used for nonrepudiation of the sender and receiver. The \nhistory includes the name of the agent and database that performed the enqueue or dequeue operation and the \ntime and transaction ID of the operation. After the message is propagated to the destination queue, it still includes \nthe message ID of the source message so that the source and destination messages and their histories can be \ncorrelated. Stronger nonrepudiation can be achieved by storing the digital signature of the sender and receiver. \n The following are some additional features worth highlighting: \n ■  A message can be enqueued with an explicit set of recipients, which overrides the list of subscribers to \nthe queue. \n ■  A caller can batch multiple items in an enqueue or dequeue operation, which is less expensive than \nenqueuing or dequeuing the items one by one. \n ■  A consumer can dequeue a message without deleting it from the queue based on the queue’s retention \npolicy. The ﬁ rst dequeue runs as a select query, which returns a snapshot of the messages to be dequeued. \nSubsequent dequeues within the same transaction are performed on the same snapshot without issuing a \nnew select. \n ■  A sender can split a complex message into a message group, which the consumer can process atomically. \n ■  A caller can listen to multiple queues, waiting for a message to arrive. If the listen operation returns suc-\ncessfully, then the caller must issue a dequeue to retrieve the message. \n ■  A caller can dequeue a message without retrieving the message’s content. This is useful for deleting a \nlarge message whose content is irrelevant. \n 4.9  SUMMARY \n Queued TP is an alternative to direct TP that uses a persistent queue between client and server programs. The \nclient enqueues requests and dequeues replies. The server dequeues a request, processes the request, enqueues \na reply, and commits; if the transaction aborts, the request is replaced in the queue and can be retried. \n The main beneﬁ ts of queued TP are: \n ■  A client can submit a request even when the server is down (by enqueuing the request). \n ■  A server can reply to the client even when the client is down (by enqueuing the reply). \n ■  Communication failures do not result in lost replies or uncertain results. \n ■  Balancing the load among multiple servers is easier. \n ■  Priority can be given to some requests relative to others. \n The cost of these beneﬁ ts is the additional transactions to enqueue requests and dequeue replies. \n Clients can determine whether or not a request executed by examining its queues. An unexecuted request \nis still in the client’s request queue. An executed request has a reply in the client’s reply queue. If the queue \nmanager remembers the unique ID of the last request enqueued and reply dequeued by a client, then the client \ncan recover from a failure by synchronizing its state with the state known to the queue manager. To cope with \nfailures that make the result of nonredoable operations (such as printing a check) ambiguous, the client should \nread the state of the device and compare it to the state it logged before operating on the device. \n",
      "content_length": 3549,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 138,
      "content": " A queue manager is needed to support the queued communication model. It may be an independent product \nor an integral component of a transactional middleware product. It provides operations for the storage abstrac-\ntion of queues, including: \n ■  Operations on queued messages, such as enqueue, dequeue, scan a queue, and keyed access \n ■  Creating and destroying queues \n ■  Modifying a queue’s attributes (e.g., queue owner, size, queue name, privileges) \n ■  Starting and stopping a queue. \n A queue manager may support routing, either by enqueuing to a remote server, or by enqueuing locally and \nforwarding messages to a remote server. This is useful to reroute requests to another server when a primary \nserver is overloaded or down, or to batch requests that are processed only periodically. When forwarding is \ndone transactionally, it adds a fourth transaction to the model. \n Publish -subscribe is a messaging style where a publisher sends a message to a broker that is responsible for \nforwarding the message to many subscribers. Subscribers register interest in certain message types and receive \nall published messages of that type. Publish-subscribe systems usually are based on queued messaging, where \npublished messages are distributed to subscribers via queues. \n Other types of message-oriented middleware are available to integrate independent TP applications that sup-\nport different communications protocols, different application functions, and different message formats. The two \nmain architectures for performing this reconciliation are broker-based products, often called enterprise appli-\ncation integration (EAI) systems, and bus-based products, often called enterprise service buses (ESBs). They \ninclude functions for bridging different protocols, routing messages to the desired application, and translating \nbetween different message formats. \n4.9 Summary  119\n",
      "content_length": 1894,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 139,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 140,
      "content": " 5.1  INTRODUCTION \n A  business process is a set of related tasks that lead to a particular goal. Some business processes automate the \nexecution or tracking of tasks using software. Such processes can be modeled as a partially ordered set of steps. \nEach step may be a transaction, an execution of a program that is not a transaction, an activity performed by \na person or machine, or another multistep business process. Business processes are not limited to businesses. \nThey arise in government, academia, science, and many other complex organizations. \n The term  workﬂ ow is a commonly used synonym for the concept of a business process. The term  busi-\nness transaction is sometimes used as a synonym for a business process or a step within a business process. \n Business process management is the activity of creating, managing, adapting, and monitoring business pro-\ncesses. Sometimes a distinction is made between  orchestration and  choreography , which are essentially busi-\nness process management within an enterprise and between enterprises, respectively. \n Much of the work of business process management is comprised of traditional operational activities per-\nformed by business managers. This includes deﬁ ning and organizing the activities of an enterprise, hiring and \ntraining people to do the work, developing accounting procedures to measure cost and productivity, and identi-\nfying ways of simplifying or automating the work to reduce cost, improve quality, improve customer satisfac-\ntion, and so on. These activities are essential ingredients for successful business process management, but they \nare not our main interest here. Rather, this chapter focuses on aspects of business process management that \nrelate to the choice and use of software. \n The operation of a large enterprise usually involves hundreds or thousands of business processes. Many of \nthem offer a product or service to a customer of the enterprise, often interoperating with multiple businesses. \nThe following are a few examples: \n ■  Process an order for retail goods: Check the customer’s credit, reserve the required material from stock, \nschedule the shipment, give commission credit to the salesperson, submit a request for payment from a \ncredit card company, perform the shipment, and then validate that the order was delivered. \n ■  Transfer money: The source bank approves the transfer and sends a message to the target bank. The tar-\nget bank records the transfer, bills the account for the transfer fee, and sends an acknowledgment to the \nsource bank. The source bank bills the account for the transfer fee and sends a written acknowledgment \nto the customer. \n ■  Reserve a trip: Arrange a trip at a travel web site by reserving ﬂ ights, car rentals, and hotel rooms. \n Business Process Management \n 5 \nCHAPTER\n",
      "content_length": 2824,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 141,
      "content": "122  CHAPTER 5 Business Process Management\n ■  Process an order for a new computer: Analyze the conﬁ guration for feasibility. Manufacture the computer. \nShip the computer. Debit the credit card. E-mail an acknowledgment to the customer. The manufacturing \nstep is, in turn, a nested business process: identify the required components; group the components by \nsupplier; send an order to each supplier; when all the components have arrived, issue a build order; when \nthe computer is completed, send a notiﬁ cation to the parent process. \n Many business processes are internal to an organization and only indirectly in support of a product or service, \nsuch as the following: \n ■  Report a bug: A tester reports a bug in a software product. A test engineer diagnoses the problem and \nassigns it to the relevant design engineer. The design engineer ﬁ xes the problem. The test engineer \nchecks that the repaired program indeed solves the problem. The test engineer adds a test to the product’s \nregression test suite, to detect if the product exhibits the bug in a later version. \n ■  Process a shipping request: Print the shipping order. Get the products to be shipped. Package the prod-\nucts. Print a shipping label and afﬁ x it to the package. Add the postage label. Record the shipment in the \ndatabase. Place the package in the outbox. \n This chapter focuses on business processes that are at least partially automated using software, especially \nusing TP technology, such as those just listed. Partially automated business processes have steps that include \nhuman interaction, such as the following: \n ■  Adjust an insurance claim: When someone submits a claim, preliminary data must be captured. Later there \nis an inspection of the damage, which is recorded. Then the claim is approved (or not). After the damage is \nrepaired, receipts are submitted for reimbursement. Then a reimbursement check is issued. \n ■  Plan a new product version: A product manager collects ideas for new product features from customers, engi-\nneers, and sales people. The engineering group estimates the feasibility, design time, and manufacturing cost \nof each new feature. The product manager ranks the features based on cost and incremental sales expected \ndue to each feature. A business manager decides which features to include based on available engineering \nresources and on the expected increase of proﬁ t and customer satisfaction compared to other product invest-\nments being considered. The engineering manager develops a schedule to design the approved features. \n ■  Buy a piece of real estate: Find the right property. Make an offer. If the offer is accepted, have it inspected. \nIf the inspection reveals problems, renegotiate the offer. Arrange ﬁ nancing. Arrange insurance. Do the \nclosing. \n ■  Evaluate a book proposal: The editor receives a book proposal from an author. The editor negotiates changes \nto the proposal with the author. The editor sends the proposal to reviewers. The editor sends reviews to the \nauthor. The author revises the proposal. The editor either rejects the revised proposal or offers a publishing \ncontract. The author reviews and revises the contract. The editor and author sign the contract. \n Even when all steps of a business process involve human interaction, the process can beneﬁ t from software \nassistance from TP applications; for example, to track progress in a system for document management or case \nmanagement. Many business processes are a hybrid of human and automated steps where the latter execute \nas transactions, such as customer relationship management. There are packaged software products for each of \nthese applications. \n Following the traditional waterfall model of software development, business process management involves \nthe usual application development activities: specifying the business process, implementing it, deploying it, \nand monitoring and managing its execution. A lot of attention has focused on the speciﬁ cation of business \n",
      "content_length": 4003,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 142,
      "content": " processes, especially on software tools to visually display a process speciﬁ cation and to simulate it, thereby \nenabling business users to evaluate the appropriateness of the speciﬁ cation. Although this is an important aspect \nof business process management, it is more closely related to software design methodology and tools than to \nTP, so we will not be delving into it here. \n 5.2  BUSINESS PROCESS DEFINITION \n A business process deﬁ nition speciﬁ es the steps of the business process, the work performed by each step, the \norder in which the steps execute, and how steps communicate with each other. That is, it deﬁ nes the control \nﬂ ow and data ﬂ ow between steps. It also speciﬁ es the components of the state of the business process and how \nthey relate to each other. \n A business process deﬁ nition can be distributed among the steps of the process. For example, consider a travel \nreimbursement request. The step that captures the request from the user can include logic to send a message to the \nappropriate manager for approval. The step that captures the manager’s approval can either forward a request-for-\npayment to the accounting department (if approved) or return the original request to the employee (if rejected). \n Alternatively , the business process deﬁ nition can be expressed as a single program. In this case it is usually \na relatively simple script-like program, not a complex algorithm with complex data structures. For the travel \nreimbursement example, this program would ﬁ rst receive the request input from the user and then send a mes-\nsage to the manager for approval. Based on the manager’s reply, it would either send a request-for-payment \nmessage to the accounting department or send the rejected request to the employee. \n Independent of how the business process is deﬁ ned, it is best to encapsulate each step of the business pro-\ncess separately. This allows the business process deﬁ nition to focus on the ﬂ ow of control and data between \nsteps without being cluttered by the application logic of each step. It also is consistent with the goal of reus-\ning services in a service-oriented architecture. Each encapsulated step can be deﬁ ned as a service that can be \ninvoked in multiple business processes. \n Systems that support the execution of business processes usually offer a special-purpose programming lan-\nguage for specifying business processes. For the most part, these are ordinary languages with local variables and \nthe usual control ﬂ ow constructs, such as if-then-else, do-while, RPCs, one-way messages, parallel execution of \na set of statements, and exception handlers. In addition, there are a few constructs that are somewhat specialized \nfor business processes. One construct is to wait for the arrival of one or all of a set of messages and events (such \nas timeouts). Another is to send a message to a particular instance of another business process, thereby enabling \nbusiness processes on two systems to coordinate their activities by passing messages back and forth. \n Business processes typically are driven by events that reﬂ ect actions in the outside world: a house purchaser \nreceives a mortgage approval, an investor receives a trade conﬁ rmation, a programmer receives a bug report, or \n an author receives a draft publishing contract. It is therefore natural to specify a business process as a ﬁ nite state \nmachine. Such a machine has a ﬁ nite set of states. For each state, it speciﬁ es the set of events that can occur. Each \nevent causes the machine to perform an action and move into a different state. An example state machine appears \nin  Figure 5.1 . A ﬁ nite state machine is a convenient way to specify a business process when at each point in time \nthere are several possible events that cause the process to act, and those events can arrive in any order. This typi-\ncally arises when events correspond to actions performed by people, which can happen in arbitrary orders. \n One limitation of the ﬁ nite state machine model is the difﬁ culty of specifying transaction boundaries and \ncompensating transactions. A procedural speciﬁ cation is often more natural for capturing these aspects of a \nbusiness process deﬁ nition. \n A step of a business process may need to interact with a person. For example, a person may be needed \nto review a special order or approve a travel request. In a large organization, it is important that the business \n5.2 Business Process Deﬁ nition  123\n",
      "content_length": 4475,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 143,
      "content": "124  CHAPTER 5 Business Process Management\n process identify these people by their roles and not by their names. This allows multiple people to serve the \nsame role, such as using multiple expediters to handle nonstandard orders. It also allows people to change roles \ndynamically, such as enabling a manager to approve travel requests for one of her subordinates when the subor-\ndinate is on vacation. The mapping of roles to people is explicitly stored and used by the runtime environment \nto assign a step of a given business process to the right person. \n 5.3  BUSINESS PROCESS EXECUTION \n Many systems that support the execution of business processes offer a special-purpose runtime system. This \nsection summarizes the main capabilities one would expect from such a runtime system. \n First , the system needs to offer a way of installing business process deﬁ nitions so they can subsequently be \ninvoked. For the most part, this is no different than installing any service. One needs to store the executable, \nmake its interface deﬁ nition known to programs that will call it, and add its name to a registry so that a caller \ncan ﬁ nd the service to invoke it. \n Routing a request to create a business process is easy enough, since it can be guided by a registry entry. \nMessages that arrive for running business processes are more challenging. Each message, which corresponds to \nan event, needs to be routed to the proper instance of the business process. For example, when a message arrives \nthat says a particular computer has left manufacturing, the message needs to be routed to the business process \ninstance that is responsible for that order. This involves matching parameters in the message with process state. \nThis matching needs to be fast, even when there is a large number of active business processes. \n Many business processes that include steps performed by people need to allow people to modify the process \ndynamically. That is, a person performing a step might want to add a new step, skip a certain step, or reorder \nsome steps. For example, in a mortgage application process, if an underwriter ﬁ nds the customer has an unusual \ncredit history, she may add another step for a second opinion by a more experienced loan ofﬁ cer. Like other pro-\ncess behavior, these modiﬁ cations of the process should be logged so they are made available to later queries. \n State Management \n The runtime system needs to manage the state of a running process. For each process, it needs to know which \nsteps have executed, the step(s) that should execute next, the business process’s local variables, and other context \nMortgageInProcess\nreceiveAppraisal\nreceiveCreditCheck\nreceiveCancellation\ndenyApplication\napproveApplication\nMortgageApproved\nMortgageNotApproved\ntransition\nLegend\nstate\nevent\nmyEvent\nReceiveMortgageApplication\n FIGURE 5.1 \n Finite State Machine. A mortgage approval process speciﬁ ed as a ﬁ nite state machine. \n",
      "content_length": 2945,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 144,
      "content": " information needed for it to run. Much of the work in managing business process execution involves managing \nthe business process state. \n The runtime system should make process state available to applications. Applications need this capability \nso they can tell the user about the state of his or her partially executed business process, which is important \nbecause business processes may take a long time to execute. For example, if a user places an order and doesn’t \nreceive an acknowledgment within a few days, then the user wants to be able to investigate the state of the order. \nA general-purpose mechanism to save the state of a business process and to query that state makes it easier for \napplications to offer this kind of functionality. \n To maintain the state of a running process, the runtime needs to log all the interesting events that occur in a \nprocess, since the fact that those events occurred is part of the process’s state. For example, for each active pro-\ncess, it should log when the process starts, who invoked it, and when it ends. Also, the runtime should log when \neach step starts and ends, perhaps including its input parameters and other information about the context in which \nit runs. This information should be stored in a form that makes it easy to process queries about an individual pro-\ncess or a large number of processes. The former is needed for answering customer questions, such as the question \nearlier, to investigate the state of an order. The latter is needed by system managers to monitor performance and \nidentify slow or otherwise unhealthy processes that need attention. Aggregate information may also be useful to \nbusiness process analysts, to determine the average performance of business processes (e.g., response time for \ncertain kinds of orders), to optimize processes (e.g., certain kinds of processes that are taking too long), and to \nidentify poorly automated processes (e.g., ones that require too many manual steps for exception handling). \n A business process may execute over a long period, such as days or even months. Although a business pro-\ncess is long-running, it spends most of its time in an inactive state, waiting for an event to arrive to wake it up. It \nwould be inefﬁ cient and unreliable for the process to reside in main memory throughout its execution. It would \nbe inefﬁ cient because the process has long periods of inactivity during which its state might as well reside on \nless expensive persistent storage. It would be unreliable because main memory is volatile, so the business pro-\ncess’s state would be lost in a system failure. This is a much more serious problem than the loss of a short trans-\naction, which can simply abort and re-execute . Therefore, for safety’s sake, the business process should save its \nstate at the end of each step, as we saw in Figure 2.15. \n There are two styles of process execution that relate to process state management,  document-oriented and \n message-oriented . A document-oriented application takes a document as input, associates it with a business \nprocess, and passes the document along from one step of the business process to the next. Each step knows \nwhere to look in the document for the information that it needs for that step. Each step updates the state of the \nprocess in the document itself and saves it persistently before passing it on to the next step. Applications that \nevolved from the Electronic Data Interchange (EDI) standard typically work this way, as are many newer ones \nthat use XML documents for business-to-business e-commerce. \n By contrast, a message-oriented application looks more like a sequence of events, where each event arrives \nas a message with explicit parameters that tell the next step what to do, rather than relying on the step to ﬁ nd \nits input in a document. The state of the business process is stored in one or more databases, not in the message \nlike in a document-oriented application. \n Although most applications follow one of these two styles, there are hybrid cases that don’t fall neatly into one \nstyle or the other. That is, some process state information may be retained in messages that are passed between \nsteps, while other state information resides in databases. And document-oriented processing often invokes RPCs \nto execute one or more of the steps. \n The system needs to offer functions for saving and restoring the state of a business process. The functions \nfor saving a business process’s state might be invoked by the business process itself or by an agent that looks \nfor business processes that have been idle for a long time and should be moved out of main memory. The func-\ntion for restoring the state of a business process could be invoked by the runtime environment when a step of \n5.3 Business Process Execution  125\n",
      "content_length": 4829,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 145,
      "content": "126  CHAPTER 5 Business Process Management\n the process is ready to execute. We will see other uses for state management in the next section for handling \nsystem failure and recovery. \n Business process state can be used to help understand the relationships between different types of enterprise \ninformation. It is often the only place where related data entities are correlated and managed. For instance, the \nrelationship between a sales opportunity, a sales quote, a sales order, and a contract for sales is hard to main-\ntain. If these activities were reﬂ ected as entities and were coordinated by a single opportunity-to-contract pro-\ncess, then each instance of the process would have an ID that would correlate the IDs of these related activity \nentities as part of the business process state. In this sense business process state is central to creating integrated \nviews of business data. \n Given the importance of business process state, tools to analyze this state have become a recognized busi-\nness process management capability, called  business activity monitoring . This involves emitting business \nprocess state, such as event streams that populate a database. The database can be used by data mining and \nother business intelligence tools to provide visibility into every aspect of the workings of real business pro-\ncesses, including human-driven ones. \n 5.4  TRANSACTIONAL PROPERTIES \n Although it is tempting to execute all the steps of a business process within one transaction, the vast majority \nof business processes require the execution of more than one transaction. There are many reasons for this, such \nas the following: \n ■  Resource availability: At the time the request to execute the business process is taken as input, only some \nof the people or systems that are necessary to execute the request may be available. For example, when \na customer submits an order, it is immediately stored in the order processing database. But if the request \narrives after normal business hours, there may be no one to process it until the next business day. As \nanother example, one step in processing an expense claim may be getting a manager’s approval, but the \nmanager only sets aside time to approve claims twice a week. \n ■  Real-world constraints: Processing an automobile insurance claim may require the customer to bring in \nthe car for damage inspection and get two estimates for the cost of the repair. This could take weeks. \n ■  System constraints: When executing a money transfer between two banking systems (e.g., to automati-\ncally pay a credit card bill from a checking account), the two systems might not run compatible transac-\ntion protocols, such as two-phase commit, or be available at the same time. The transfer therefore has to \nrun as multiple independent transactions on each system. \n ■  Function encapsulation: Different business functions are managed independently by different depart-\nments. For example, in order processing, inventory management is done in manufacturing, scheduling a \nshipment is done by the ﬁ eld service group, commission reporting is done in the sales system, and credit \napproval is done by the ﬁ nance department. Decomposing a workﬂ ow request into steps that are pro-\ncessed by these separate systems or by separate reusable services in an SOA is more intellectually and \norganizationally manageable than designing it to run as one big transaction. \n ■  Resource contention: A long-running transaction usually holds resources, such as a lock on data or a com-\nmunications device. Contention for the resource thereby slows down other transactions trying to use the \nresource. What starts as a performance problem, due to resource contention, may turn into an availability \nproblem, since whole groups of transactions may be unable to run until the long-running transaction gives \n",
      "content_length": 3855,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 146,
      "content": " up its resources. For example, a money transfer between two banks could take a long time to run, because \nthe banks are connected by slow or intermittent communication. For this reason, the operation normally \nruns as (at least) two transactions: one on the source system, to debit the money from the source account; \nand then some time later, a second one on the target system to credit the money to the target account. \n So far in this book, we have assumed that each user request can be satisﬁ ed by the execution of a single \ntransaction. When queuing is used for better availability and load balancing, we added transactions that read \nfrom and write to queues to move the request around. However, even in this case, only one transaction did the \napplication-oriented work that was requested. \n This assumption breaks down for multistep business processes. One of the most important runtime require-\nments of business processes is that they do not have to execute as a single transaction. Once you split the \nexecution of a request into multiple transactions, you no longer necessarily get the beneﬁ ts of a single transac-\ntion: atomicity, isolation, and durability. Let’s look at how these properties might break and what can be done \nabout it. \n Isolation \n Consider a money transfer operation as an example, debiting $100 from account  A and then crediting that $100 \nto account  B at another bank. If these run as separate transactions, then the money transfer request is not iso-\nlated from other transactions. For example, somebody could perform an audit of the two banks while the money \nis in ﬂ ight, that is, after it is debited from account  A and before it is credited to account  B . If an auditor reads \nthose accounts, it would look like $100 had disappeared. Thus, if the audit and money transfer are considered \nto be  “ transactions, ” they are not serializable; no serial execution of the audit and money transfer could result in \nthe audit seeing the partial result of a transfer. \n Of course, running the money transfer as one transaction would eliminate the problem. But as explained \nearlier, there are many reasons why this may not be possible or desirable. Therefore, in contrast to single-\ntransaction requests, multitransaction business processes require special attention to the isolation problem. \n The isolation problem of a multitransaction business process usually requires application-speciﬁ c solu-\ntions. For example, the bank audit program must have logic that can deal with in-ﬂ ight money transfers. An \nalternative general-purpose solution is to lock data for the duration of the business process. However, for long-\nrunning business processes, this creates major resource contention, which is usually unacceptable. \n Atomicity \n In the money transfer example earlier, suppose there is a failure after committing the ﬁ rst transaction that deb-\nits account  A . This could be a failure of the business process’s application code or of the system that is running \nthat code. In either case, as a result of this failure, the ﬁ rst bank’s message to tell the second bank to credit \naccount  B may have been lost. If this occurs, then the second transaction to credit account  B will never exe-\ncute. Thus, the money transfer is not all-or-nothing. \n Any automated solution to this problem must include maintaining the state of the business process, that is, \nwhich steps of the business process did and did not execute. The mechanism will need this state after the recov-\nery from the failure that caused the business process to stop prematurely. Therefore, as we noted earlier, this \nstate should be kept in persistent storage, such as a disk. If the state is maintained in persistent storage, then it \nwill be available after recovery from the failure even if the failure was caused by a system failure in which the \ncontent of main memory was lost. \n5.4 Transactional Properties  127\n",
      "content_length": 3929,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 147,
      "content": "128  CHAPTER 5 Business Process Management\n Given that the state of each business process is maintained persistently, a recovery mechanism can address \nthe atomicity problem by periodically polling that state to determine whether to initiate recovery. If the recovery \nmechanism ﬁ nds a business process that has remained in the same state for longer than the process’s predeﬁ ned \ntimeout period, then it can initiate recovery. \n One way that a recovery mechanism can repair a stalled business process is to run a compensating transaction \nfor each of the steps of the business process that have already executed. This approach requires that for every \nstep of a business process, the application programmer writes code for a compensating transaction that reverses \nthe effect of the forward execution of the step. So in the money transfer example, the ﬁ rst transaction, which \ndebits $100 from account  A , has an associated compensating transaction that puts the money back into account \n A . If the system is unable to run the second transaction, which credits account  B , it can run a compensation for \nthe ﬁ rst transaction that debited account  A . A compensating transaction may not be needed for the last step if the \nsuccessful completion of that step ensures that the entire business process has completed successfully. \n Some systems include a general-purpose recovery mechanism to implement this approach, for example \nas part of the transactional middleware. For each active business process, the transactional middleware keeps \ntrack of the sequence of transactions that have run. During its forward execution, each transaction saves all the \ninformation that is needed to allow its compensating transaction to be invoked at recovery time. For example, \nit might save the name of the program that implements the compensating transaction and the parameter values \nthat should be used to invoke that program. If the recovery mechanism detects that the business process is \nunable to ﬁ nish, then it runs compensations for all the transactions that committed and thereby brings the sys-\ntem back to its initial state (see  Figure 5.2 ). Thus, it automates the execution of those compensations. This is \ncalled a  saga : a sequence of transactions that either runs to completion or that runs a compensating transaction \nfor every committed transaction in the sequence. \n In a saga, how does the system keep track of these multiple transaction steps to ensure that at any given time \nit can run the compensations if the saga terminates prematurely? One possibility is to store the saga’s state in \nqueue elements. Each transaction in the saga creates a queue element, which is a request that incorporates or ref-\nerences the history of the steps that have run so far. If at any point the saga can’t run the next step in the request, \nthe system can look at that history and invoke the compensating transaction for each of the steps in the history. \nBecause the queue elements are persistent, they can’t get lost. Even if one of the steps is aborted many times, \neventually the system will recognize the fact that the saga has not completed and will run the compensating \ntransactions for the steps in the saga that executed. \nStep 1\nCompensation 1\nCompensation 2\nCompensation 3\nStep 2\nStep 3\nFailure\nStep 4\nStep 5\n FIGURE 5.2 \n A Saga. This saga has ﬁ ve steps, each of which is a transaction. Each step’s program includes a compensating \ntransaction. Since this execution of the saga cannot proceed past step 3, it runs compensations for the three steps \nthat did execute. \n",
      "content_length": 3587,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 148,
      "content": " Durability \n The use of a multistep business process to implement a request does not affect the durability guarantee. The \ndurability of a business process’s updates is ensured by the durability property of the transactions that execute \nthose updates. If all of a business process’s updates to durable transactional resources execute in the context of \ntransactions, then the result of those updates is durable. \n As we saw in this section and the last, it is also important to maintain a durable copy of the intermediate \nstate of a business process. This is not a requirement for transactions. The reason is that a transaction is atomic; \nthat is, all-or-nothing. However, a multistep business process may not be atomic. To make it atomic, we need a \ndurable copy of its intermediate states. \n 5.5  MAKING PROCESS STATE DURABLE \n We have seen several reasons why business process state needs to be maintained durably. This section dis-\ncusses several techniques for doing so: \n ■  A special-purpose runtime system for business processes \n ■  Persistent queues \n ■  Pseudo-conversations \n ■  Message logging \n Using a Special-Purpose Runtime System \n Consider a system that uses a special-purpose runtime system to support business process management. Suppose \nthe runtime supports a function SaveState that stores the current state of a business process in persistent storage. \nSuppose the business process calls SaveState and then executes another step as a transaction, T. In general, exe-\ncuting a transaction is not an idempotent operation. So if the system fails and, after recovering, resumes execut-\ning the business process, it is important that the business process doesn’t execute T a second time. This problem \nis reminiscent of the problem of handling non-undoable and non-idempotent operations in Section 4.4, where \nwe wanted to process the output of a transaction (e.g., print a check) exactly once. In this case, we want to run \nT in the business process exactly once. It is essentially the same problem, except in this case the non-undoable \noperation is a transaction. \n The way we solved this problem in Section 4.4 was the equivalent of invoking SaveState immediately \nbefore running T, as illustrated in  Figure 5.3 . Then, before invoking T, check that it didn’t run once before. This \nassumes that T produces some testable state; that is, some persistent state that proves whether it did or did not \nrun. This can be arranged if the invocation of the step that corresponds to T is done via a special function in the \nbusiness process’s runtime. That function can perform the required update of persistent storage that, if needed, \ncan be checked later to determine if T ran. \n Since T is a transaction, another possible solution is to have the business process’s state be a transactional \nresource and make SaveState the last operation of the transaction. That way, the business process’s state is saved \nin persistent storage if and only if T commits. If the system fails before T commits, then at recovery time the \nbusiness process will continue executing with the last state that was saved before the execution of T. So T will \nexecute again, which is what we want since T ’s ﬁ rst execution aborted as a result of the failure. If the system \nfails after T commits, then at recovery time the business process will continue executing with the statement that \nfollows the SaveState operation. We would like this to be the statement that follows the execution of the commit \noperation for T. So we would like the SaveState operation to save the state that the transaction committed. \n5.5 Making Process State Durable  129\n",
      "content_length": 3650,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 149,
      "content": "130  CHAPTER 5 Business Process Management\n Notice that it is not satisfactory to invoke the SaveState operation immediately after T commits, instead \nof invoking it as part of T. The reason is that the system might fail after T commits and before executing the \nSaveState operation that follows the commit. That would result in having T execute again at recovery time, which \nis one of the outcomes we want to avoid. \n Using Queued Requests \n Another way to manage the state of a business process is to use persistent queues. The business process can be \ninitiated by a request that is stored in a queue. Each step of the business process executes as a transaction and \nproduces requests for the succeeding steps of the business process if and only if the step commits. Thus, the \nstate of the process is stored in the queue elements holding the active requests of the business process. \n Since the steps are separated in time, some requests in a business process may stay in a queue for a long \ntime. However, since the queue is persistent, the request cannot be lost. Moreover, no special recovery proce-\ndure is required. If the system fails and then recovers, the recovery procedure will restart the conﬁ guration of \nthe server processes, which includes the dispatchers associated with its queues. These dispatchers will then \nstart dequeuing requests and invoking the appropriate programs to run them. \n In this approach, there may be no one program that encapsulates the control ﬂ ow of the business process. \nInstead, that logic could be distributed among the steps of the process. Each step of the process has an associ-\nated program that performs the work of that step, which includes deﬁ ning what happens next by virtue of the \nrequests that it produces. Since no one program deﬁ nes the business process, the process has no local variables \nthat need to be stored persistently. If step S produces any information that is needed by subsequent steps, then \nS needs either to pass that information along in the requests it produces or to store it in a shared database that \nis accessible to subsequent steps. \n Instead of distributing the logic of business process steps, the business process could be encapsulated in a \nsingle program. The program executes each step as a transaction that dequeues the expected request, executes \nit, and enqueues output requests for the next steps. Since queue elements are persistent, the process can save its \nstate there instead of saving it periodically in a separate transactional resource. However, it still needs to save \nits control state periodically in a well-known location, as we described in the previous subsection, so that at \nrecovery time the business process can be resurrected and resume execution at the point where it left off. \nS3\nPersistent Resource \nSave\nState\nS1\nT\nS2\n FIGURE 5.3 \n The SaveState Operation Runs Before Transaction  T . Saving the state of the business process in step S 1  allows the state to \nbe tested before running step S 2  to prevent re-execution  of T in the event of a recovery from failure. \n",
      "content_length": 3088,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 150,
      "content": " The top-level request that initiates a business process often requires a reply that tells the user when the \nbusiness process is completed. For example, the reply might include the itinerary for a trip, the reimbursement \nof an insurance claim, or the acknowledgment of a money transfer. However, intermediate steps of the work-\nﬂ ow often do not need to reply to the originator of the step’s request. Rather than sending a reply to the previ-\nous step of the business process, each intermediate step feeds a request to perform the next step of the business \nprocess. Each intermediate step might also send an e-mail or other form of notiﬁ cation to the end-user of the \nlatest step that was performed (e.g., the order was received or the order was shipped), but it does not expect a \nreply to such notiﬁ cations. \n For example, consider the problem of moving orders from one ofﬁ ce to another in a global enterprise. The \nTokyo ofﬁ ce runs a transaction to enqueue an order request (see  Figure 5.4 ). The server recognizes the request \nas one that requires remote processing, so it runs a transaction that dequeues the order from the queue in Tokyo \nand enqueues it to another queue in New York. Now a server in New York dequeues the order, processes the \norder, and enqueues a shipping request. When the order ships, a transaction records that fact, enqueues a mes-\nsage containing an invoice and an acknowledgment that the order was ﬁ lled, and perhaps sends a shipping notiﬁ -\ncation to the end user. A transaction forwards the reply from the queue in New York back to the queue in Tokyo. \nThe Tokyo server prints the invoice and acknowledgment and mails it to the customer. That ﬁ nal step in Tokyo \nis effectively a reply to the original order request. The intermediate steps are a chain of steps where each step \nsends a request to perform the next step. \n Pseudo-Conversations \n Another type of business process arises from an interactive request; that is, one that interacts with a display \ndevice. As before, due to resource contention and availability, it is wise to break up the execution into several \ntransactions, one for each point of interaction. \n5.5 Making Process State Durable  131\nEnqueue\norder request.\nPrint invoice and\nacknowledgment.\nForward\norder to\nNew York.\nTokyo\nForward\nreply to\nTokyo.\nProcess\norder.\nShip\norder.\nNew York\n FIGURE 5.4 \n A Multitransaction Business Process. Each boxed action runs as a transaction. An order is entered in Tokyo, forwarded to \nNew York for processing, processed, and shipped, and a reply is forwarded to Tokyo, which prints an invoice for the order. \n",
      "content_length": 2615,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 151,
      "content": "132  CHAPTER 5 Business Process Management\n For example, consider an airline reservation transaction that gets a ﬂ ight number as input from a display, \nreads the number of seats available on that ﬂ ight from the database, and then displays that number and asks the \nticket agent how many seats the customer wants to reserve (see  Figure 5.5 ). After the customer says how many \nseats to reserve, this number is entered as input, the number of available seats is decremented, and the transac-\ntion commits. To make such transactions serializable, the system ordinarily holds a lock on that ﬂ ight record for \nthe duration of the transaction. This blocks other customers from making reservations on that ﬂ ight. The block-\ning delay could be signiﬁ cant, while the customer is deciding how many seats to reserve. For this reason, deter-\nmining the number of available seats usually runs as a separate transaction from reserving the seats. That way, \nthe ﬂ ight record isn’t locked while the customer is deciding how many seats to reserve. Of course, this means \nthat the number of available seats can change while the customer is deciding. That’s why the ticket agent often \nreserves seats on the ﬂ ight you inquire about, to make sure the seats don’t go away while you’re deciding; if you \ndecide not to reserve them, the agent cancels the reservation. \n In most ways, making this airline reservation is an ordinary multistep request, consisting of two transac-\ntions. The ﬁ rst displays the number of available seats and the second makes a reservation. Like other multistep \nrequests, one could implement it as a business process; for example, by moving requests between client and \nserver queues. However, these sorts of interactive situations arise often enough that some systems have a spe-\ncial mechanism, called  pseudo-conversations , where the request is shuttled back and forth between client and \nserver. \n With pseudo-conversations, each time the server processes a request message, it saves some information \nthat was gathered from that transaction step in the message that it returns to the client device (essentially a \nqueued reply). Some of this information may be displayed to the user (e.g., number of available seats). Other \ninformation may be there just as context that can be sent back from the client to the next transaction step (e.g., \nan identiﬁ er for a partially-completed reservation record). The message is saved in persistent storage on the \nclient and the server. But since there’s only one message ever in transit between them, the system doesn’t need a \nmechanism as elaborate as queues. It just needs a block of persistent storage reserved for each client. In a sense, \nthe pseudo-conversation is a session with the message containing the state being shared by the client and server. \nThus, any technique for managing persistent session state could be used. For example, the client state could be \nstored in a cookie in the web browser. \n This way of exchanging messages is called a pseudo-conversation because it looks as if it’s a conversational \ntransaction; that is, it looks interactive. In fact, it’s just a sequence of noninteractive requests, each of which has \none input and one output. \nDatabase\nInteractive Transaction\nGet flight number.\nRead flight information.\nDisplay number of available seats.\n/* possibly long delay\nGet number of seats desired.\nReserve the seats.\n FIGURE 5.5 \n An Interactive Transaction. During the delay while the user is deciding how many seats to reserve, the ﬂ ight information \nis locked, preventing other users from accessing it. \n",
      "content_length": 3606,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 152,
      "content": " Using Logging \n Logging is another way to make interactive requests reliable, without a pseudo-conversation or queuing. In this \napproach, the system runs the interactive request as one transaction (not a sequence of transactions) and logs \nall the transaction’s input/output operations to the display or the communications system. \n If the transaction aborts and restarts, then the system executes the restarted transaction in  “ restart mode. ” In \nthis mode the system uses the log to service the transaction’s input requests. That is, instead of reading from \nthe display, the restarted transaction reads the values produced during the previous execution, which are in the \nlog (see  Figure 5.6 ). If there are no more logged input values to read, then the system resumes processing the \nrestarted transaction’s input operations in  “ normal mode, ” by reading from the display or communication system. \n While in restart mode the system processes each of the restarted transaction’s output operations by compar-\ning it to the output that was recorded in the log during the original execution. These two outputs might differ \nbecause the restarted transaction read a different value from the database than the original transaction read. If \nso, then the system aborts the transaction and restarts it, but this time executing it in normal mode. If not, then \nthe restarted transaction continues executing in restart mode. If there are no more logged output values to com-\npare it to, then the system resumes processing the restarted transaction’s output operations in  “ normal mode, ” by \nwriting to the display or communication system.  \n The implementation of this approach can get quite complicated. There are many ways a transaction can per-\nform input and output. Each type of input and output must be logged during the original execution. And for each \ntype of operation the system must be able to reproduce the logged behavior and to detect when the restarted \ntransaction has exhibited different behavior. \nLog\nMessages\na. During normal operation, log all messages\nTransaction\nLog\nb. Use the log to recover from a transaction failure\nResume normal operation\nNo\nYes\nContinue\n3. Output\nMessage\n3. Output\nMessage\n1. Input\nMessage\n2. Transaction\n\u0005?\n FIGURE 5.6 \n Message Log for Transaction Recovery. During recovery, the transaction replays by (1) getting its input messages from \nthe log, (2) executing until it produces output, and (3) comparing its output messages to the result of the previous \nexecution. If the output is the same as its previous execution it continues the replay. \n5.5 Making Process State Durable  133\n",
      "content_length": 2636,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 153,
      "content": "134  CHAPTER 5 Business Process Management\n The execution of a business process can use this message logging technique to attain a similar level of \nfault tolerance as it would have using any of the techniques described earlier in this section, namely, a special-\npurpose runtime, queuing, or pseudo-conversations. However, unlike those earlier approaches, in this case the \nbusiness process must execute as one transaction and not be decomposed into multiple transactions. Therefore, \nthis technique by itself does not avoid the problems of resource contention and availability, which are two \nother reasons why it may be undesirable to execute a business process as one transaction. Thus, it’s suitable \nonly when they are not critical problems. \n 5.6  OTHER MODELS OF BUSINESS PROCESSES \n The term  “ business process ” has a strong connotation of applying the technology to business procedures in \nsupport of large enterprises. However, long-running processes also occur in science and engineering, which \nalso have developed some degree of automation support. Since their capabilities are very similar to those we \ndescribed for business processes, we summarize them only brieﬂ y. \n Scientiﬁ c Workﬂ ow \n Software systems that support scientiﬁ c experimentation need to deal with long-running processes. Scientists call \nthese workﬂ ows rather than business processes, but the concept is the same. A typical scenario is to use a pipe-\nline of tools that takes raw data from a physical scientiﬁ c experiment and transforms it into a meaningful inter-\npretation of the result of the experiment. For example, in bioinformatics, an experiment might involve putting the \nliquid result of a wet-lab experiment into a scientiﬁ c instrument, such as a mass spectrometer or micro-array. The \noutput of the instrument is a ﬁ le. That ﬁ le is then pipelined through a sequence of data analysis tools, ultimately \nproducing results that can be interpreted by a scientist. The analysis may be run thousands of times on different \nsamples. \n There are several ways in which automation of workﬂ ows can help scientists, such as the following: \n ■  A scientist can write a workﬂ ow deﬁ nition that drives the execution of the multistep experiment. The \nworkﬂ ow management system maps the computational steps onto a multiprocessor computing facility \nand monitors and manages their execution. \n ■  A scientist can review the history of workﬂ ow executions. This history, which scientists usually call \n provenance , can give the exact steps that were executed to produce a particular output. The ability to run \nqueries to ﬁ nd the provenance of certain experiments helps enable the reproducibility of experiments. \nThis is especially valuable when the process has manual steps and different executions of the workﬂ ow \nhave different manual steps. \n ■  A workﬂ ow system can capture the sequence of steps of a process so that it can be replayed many times. \nInitial experiments may involve many manual steps. But as the process is perfected, the same steps are \nexecuted in each replay. It is therefore helpful if the workﬂ ow system can transform an execution history \ninto a script that can be re-executed  many times. \n As of this writing, scientists have their own workﬂ ow management systems, which are different from those \nused for business processes. However, there is a growing awareness of the strong similarities of these two tech-\nnologies. It therefore seems likely that more technology sharing between these two communities will develop. \n",
      "content_length": 3543,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 154,
      "content": " Conﬁ guration Management Systems \n Conﬁ guration management systems help engineers manage shared designs. A similar kind of system, called \na product data management system, is used for discrete manufacturing. In these systems, design information \ntypically is stored in ﬁ les, which are grouped into conﬁ gurations, each of which corresponds to some com-\nponent being designed. The system offers check-out – check-in functionality. A user checks out the ﬁ les he or \nshe needs to work on. After the work is completed, the user checks them back in. The work that was done \nbetween the check-out and check-in can be thought of as a step in the design process. A design tool may be \ninvoked to evaluate the result of that step. If the result passes the test, it has to be recorded in the project man-\nagement system where the change request originated. If not, it has to be returned to the engineer to redo the \ndesign step. \n For the most part, the steps of such a conﬁ guration management process are manual. However, they \noften follow a well-deﬁ ned engineering process that could be codiﬁ ed as a business process deﬁ nition. Thus, \nthey can beneﬁ t from some degree of software automation to track the state of each process and to review \nits history long after it executed. Currently, this type of functionality usually is built as a special function \nin a conﬁ guration management product, rather than using general-purpose business process management \ntools. \n Conﬁ guration management also is used to manage complex computer systems. This is more of an opera-\ntional activity than a design activity. However, the business process functionality is largely the same. The steps \nrequired to perform certain system management functions are speciﬁ ed as a business process, such as steps to \nadd a new user to the system or to add a new server to the network. Thus, some degree of automation to track \nprocess state is valuable here too. \n One interesting aspect of conﬁ guration management compared to normal TP systems is that the steps of a \nconﬁ guration management process require application-speciﬁ c logic to make them serializable, due to concur-\nrent checkout steps. For example, suppose Alice checks out ﬁ le  F and then Bob checks out  F too. Alice modiﬁ es \n F , thereby creating  F \u0003 , and checks in  F \u0003 . Then Bob modiﬁ es his copy of  F , thereby creating  F  \u0007 , and checks in \n F  \u0007 . At check-in time, the conﬁ guration management system knows that Bob’s initial state of  F was overwrit-\nten by Alice. It therefore knows that it would be incorrect to overwrite Alice’s version  F \u0003 by Bob’s version  F  \u0007 . \nInstead, a conﬁ guration management system would ask that Bob’s changes to  F be merged into  F \u0003 . The system \nmight help by ﬁ nding the differences between  F and  F  \u0007 , and then helping Bob add those changes to  F \u0003 . Or it \nmight ﬁ nd the differences between  F and  F \u0003 and the differences between  F and  F  \u0007 , merge those changes, and \nthen apply the merged changes to  F . In both solutions, the intent is to make it appear that Bob actually made his \nmodiﬁ cations to  F \u0003 , not to  F ; that is, to make it appear that Alice’s and Bob’s modiﬁ cations ran serially. We will \nsee that this is an instance of a general problem that arises in TP when independent transactions modify different \ncopies of the same data, in this case different copies of  F . We discuss a variety of general-purpose solutions to \nthe problem in Section 9.5,  Multimaster Replication . Those solutions don’t solve the problem for conﬁ guration \nmanagement  per se , but they have the same property of identifying independent and hence conﬂ icting changes \nand requiring that they be merged together in an application-speciﬁ c way. \n 5.7  PRODUCTS AND STANDARDS \n This section offers two concrete examples to illustrate the concepts of business process management: the Web \nServices Business Process Execution Language (WS-BPEL) standard and the Service Broker component of \nMicrosoft SQL Server. \n5.7 Products and Standards  135\n",
      "content_length": 4048,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 155,
      "content": "136  CHAPTER 5 Business Process Management\n Web Services Business Process Execution Language \n WS -BPEL is a standard from the Organization for the Advancement of Structured Information Standards \n(OASIS), which is responsible for some of the Web Services standards. It speciﬁ es an XML syntax and execu-\ntion semantics for business processes. A business process runtime system is WS-BPEL compliant if it can exe-\ncute business processes that are expressed in WS-BPEL. \n The WS-BPEL standard does not specify a graphical notation or a programming language syntax for \nexpressing processes. Thus, a business process speciﬁ cation tool is WS-BPEL compliant as long as it compiles \nbusiness process deﬁ nitions into WS-BPEL — it can offer any notation or language syntax it wants to people \nwho design business processes. There are dozens of such notations and languages. One popular notation is \nthe Business Process Modeling Notation (BPMN), which is a graphical notation standardized by the Object \nManagement Group and supported by many tool vendors. An example is shown in  Figure 5.7 . 1 BPMN has been \nmapped successfully to WS-BPEL. \n In WS-BPEL, the steps of a business process are called  activities . WS-BPEL assumes that all activities are per-\nformed by Web Services. A process deﬁ ned in WS-BPEL describes the interfaces between a business process and \nthe Web Services with which it interacts. A WS-BPEL business process can itself be exposed as a Web Service. In \naddition, a business process describes the control ﬂ ow of the activities, state management, and exception handling. \n A variable in WS-BPEL contains a WSDL message type or an XML Schema (XSD) simple type or element \ntype. For example, a process can use a variable to store a document or message that it receives from one service \nand that it intends to send later to another service. Or it can use a variable to record state information about a \nprocess, as discussed in Section 5.3. A rich expression language is available to assign a value to a variable. In \nparticular, components of a variable can be identiﬁ ed using XPath, which is an expression language for referenc-\ning a portion of an XML document. \n Each process is itself a service. Each interaction of a process is described by a  partner link , which connects \nthe process to a partner service. Each partner link has a  partner link type , which speciﬁ es the name of the role \nof each participant in the link type and the port type over which each participant communicates. Port types are \nabstract connection points to a service, which are later made concrete through a port deﬁ nition that includes \nnetwork information. A partner link speciﬁ es the partner link type of which it is an instance and the role that the \nprocess and its partner play. In RPC terminology, the partner link type and partner link deﬁ ne a service contract \nover which service invocations can take place. \nPrepareInput\nwsInput\nCallStore\nStartRecipientList\nCallSupplier\nCallLogistic\nRetrieveldOrder\nEndRecipientList\nEnd\nStart\nwsOutput\n FIGURE 5.7 \n Sample BPMN Diagram for Order Processing Flow. The rounded rectangles denote steps, the rectangles with folded right \ncorners denote data, and the diamonds with plus signs denote fork and join. \n 1 Example screenshot from the Eclipse SOA Tools Platform Project BPMN Modeler:  http://www.eclipse.org/bpmn/images/screenshots/ \n",
      "content_length": 3394,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 156,
      "content": " A process communicates with another service by invoking it via a partner link, either as a one-way or \nrequest-reply operation (i.e., an RPC). Since a process is a service, it can also receive such a call from a part-\nner and, if the call is a request-reply operation, the process can subsequently send a reply to the partner. \n A process can communicate with a particular instance of a service. To do this, it identiﬁ es a set of variables \nthat are input parameters to service calls as a  correlation set . Messages to a service that have the same values \nof a correlation set will go to the same instance of that service. That is, the value of the correlation set identi-\nﬁ es the instance of the partner service. \n A process has the usual control ﬂ ow structures available, such as a sequential execution of activities, a \nparallel execution of activities (called a  ﬂ ow ), if-then-else, a case statement to select among activities (called \na  switch ), a wait activity to wait for a duration or for a deadline, and looping constructs (while, repeat-until, \nfor-each). It also offers an event block (called a  pick ) that identiﬁ es a set of event-activity pairs, where the ﬁ rst \nevent to ﬁ re causes the associated activity to execute. \n Each activity deﬁ nes a scope. Larger scopes consisting of multiple activities can be explicitly deﬁ ned. Each \nscope can have an associated fault handler and compensation handler. For example, a compensation handler \ncan be deﬁ ned using the WS-BusinessActivity protocol of WS-Transactions. There is considerable ﬂ exibility \nin deﬁ ning the behavior of these handlers to override the default. For example, suppose an employee makes a \npurchase, which is then billed to his or her department. To cancel this sequence and compensate for it, it may \nbe necessary to cancel the purchase ﬁ rst, to determine if there are cancellation fees that need to be deducted \nfrom the credit to the department. This is the opposite order of the default, which is to run compensations for \ntransactions in the reverse order that they executed. \n Scopes can also be used to control serializability. If two concurrent scopes are speciﬁ ed as  isolated , then \ntheir execution must be serializable relative to their shared variables and partner links. That is, the effect of read \nand write operations on shared variables and partner links must be the same as those effects in a serial execution \nof the two scopes. \n A process may be partially speciﬁ ed as an  abstract process , which leaves out certain details that are needed \nto execute the process. An abstract process may be useful as a description to business partners who should not \nsee all details of the process or as a stable description that is unaffected by subsequent changes to implementa-\ntion details. \n At the time of this writing, the latest release of the WS-BPEL standard is version 2.0. There are many runtime \nengines that support some version of the standard. \n SQL Server Service Broker \n Microsoft SQL Server 2005 includes a queue-based system for managing business processes, called Service \nBroker. It offers functionality to allow multiple services to cooperate in the execution of a step of a business \nprocess and to enable the step to retain persistent state of the business process to be used by later steps. It also \nreliably and transactionally delivers events and messages to a business process so that the business process can \nreliably recover from failures without missing or repeating steps. \n An application in Service Broker consists of a set of steps, which are implemented by services. Each ser-\nvice is implemented by a program bound to a queue. The program can be a stored procedure or a program \nexternal to SQL Server. To invoke a service, a program ﬁ rst creates a session with the service, called a  conver-\nsation , by calling Begin Dialog Conversation. It then sends a message over the conversation, which causes a \nmessage to be placed in the service’s queue. In the simplest case, the service starts a transaction, receives (i.e., \ndequeues) the message, does the requested work, and sends a reply message over the same conversation and \ncommits. This causes the reply to be enqueued on the caller’s queue. This is essentially the model of queued \nmessaging that we explored in Chapter 4. \n5.7 Products and Standards  137\n",
      "content_length": 4356,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 157,
      "content": "138  CHAPTER 5 Business Process Management\n Messages within a conversation are processed in the exact order they were placed on the queue. This order-\ning is maintained even in highly scalable multithreaded and multiprocess services. \n Service Broker expands this simple queuing model in a number of ways to support multistep business pro-\ncesses. First, it has an abstraction called  conversation group . Roughly speaking, a conversation group cor-\nresponds to a business process. It has a unique ID, which is meant to be used to identify persistent state that \nthe application associates with the business process. To invoke the ﬁ rst step of a business process, a program \ncreates a conversation without specifying a conversation group, which tells Service Broker to create a new \none. If this ﬁ rst step is part of a multistep business process, then the service that executes this step should \ninsert a row into a database table whose key is the conversation group ID. This row is used by this step and \nsubsequent steps to maintain the state of the business process. For each subsequent step, the program invok-\ning the steps should create a conversation (to the service that will perform the step) in the context of the busi-\nness process’s conversation group, so the service can access the business process’s state. For example, if the \nﬁ rst step S1 invokes two other steps, S2 and S3, then S1 should create a conversation to the services for S2 \nand S3 in the context of S1’s conversation group, thereby causing the services for S2 and S3 to execute in S1’s \nbusiness process. \n It is possible that there are several messages in a queue that pertain to the same conversation group. In the \nprevious example, this could happen if S2 and S3 do their work and reply before S1’s service is able to receive \neither reply. If S1’s service is multithreaded, then when it does get around to receiving S2’s and S3’s replies, \nit could end up with two separate threads processing those replies. To relieve the application developer from \nthe synchronization that would be required between these two threads, Service Broker has a built-in locking \nprotocol. \n Service Broker locks the conversation group for the duration of any transaction that processes a message in \nthe conversation group to ensure that this is the only service invocation (i.e., thread) that can process messages \nfor this conversation group. The service invocation should receive and process the messages for this conversa-\ntion group one by one. Following this protocol in the example would cause S1’s service to process the replies \nfrom S2 and S3 in the same transaction with no risk of another service invocation interfering with it. \n A service can become idle when there are no messages in its queue. To enable this functionality, Service \nBroker allows a service to be started in the following ways: (1) when a message arrives in its queue; (2) when \nan event is received; (3) at a scheduled time (e.g., every night at 11  PM ); or (4) when SQL Server starts up. In the \nﬁ rst three cases, the service becomes idle after it has processed all the items on its queue. In case (4), the service \nremains active indeﬁ nitely and hence consumes resources even when idle. \n To ensure that a service is sent only messages it knows how to process, Service Broker offers some message \ntype management. An application can deﬁ ne message types, each of which includes the name of the message \ntype and a validation criterion. The validation criterion can be none (no criterion), empty (requires the mes-\nsage body to be empty), XML (requires the body to be well-formed XML), or validate with schema collection \n(requires the body to conform to a given XSD schema). The validation criterion speciﬁ es what validation work \nwill be done by the recipient service at runtime for each message of this type that it receives. \n When starting a conversation, one can specify a contract that says which message types can be exchanged \nbetween the initiator (which is starting the conversation) and the target (the other party to the conversation). \nTo do this, the developer ﬁ rst speciﬁ es the contract. For each message type in the contract, it says whether the \ninitiator, target, or both can receive messages of that type. A contract does not constrain the order in which \nthese messages can be sent or whether they can be duplicated; that is up to the services that participate in the \nconversation. \n Service Broker offers a message retention option. This tells Service Broker to maintain a permanent record \nof the exact sequence of messages that were processed by a conversation; for example, to undo the steps of a \nbusiness process. \n",
      "content_length": 4700,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 158,
      "content": " 5.8  SUMMARY \n Many types of requests need to be executed as a multistep business process, not just as one transaction. Examples \ninclude processing an order, arranging a trip, or processing an insurance claim. Business process management is \nthe activity of creating, managing, adapting, and monitoring business processes. \n Like any application program, a business process needs to be speciﬁ ed in a formal language. This can be an \nimperative language with the usual control ﬂ ow constructs, a ﬁ nite state machine, or a graphical notation suit-\nable for a visual programming tool. \n Usually a business process is supported by a special-purpose runtime system. Since a business process may \nrun for a long time, days or even months, it must be possible for users to interrogate the process’s state. Hence, \nthe business process runtime needs to log all the interesting events that occur in a process that affect the pro-\ncess’s state. The runtime system needs to offer functions for saving the state of a business process, if the pro-\ncess is idle or in anticipation of a failure, and for restoring the state when the process becomes active again or \nrecovers from a failure. \n Breaking up a request into a multitransaction business process loses the beneﬁ ts of isolation and atomicity. \nTherefore, a business process needs to pay special attention to maintaining state in a way that avoids inter-\npreting the result of a partially executed process (and thereby break isolation) and that can interpret that state \nwhen invoking compensating transactions to cope with the failure of a partially executed process (to ensure \natomicity). \n There are several ways to maintain process state. There are special-purpose runtime systems that explicitly \nstore state information while the process executes. Some systems use persistent queues to maintain process \nstate. For business processes that engage in back-and-forth communication with a client, the client and busi-\nness process server can use a pseudo-conversation, which maintains  the state of the communication along with \nsome state information in the message. A related technique to cope with interactive transactions is to log its \nI/O, so if it fails in mid-stream, its I/O can be replayed at recovery time. \n \n5.8 Summary  139\n",
      "content_length": 2289,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 159,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 160,
      "content": " 6.1  INTRODUCTION \n An important property of transactions is that they are isolated. Technically, this means that the execution of \ntransactions has the same effect as running the transactions serially, one after another, in sequence, with no over-\nlap in executing any two of them. Such an execution is called  serializable , meaning that it has  the same effect as \na serial execution. A serializable execution gives each user the easy-to-understand illusion that while the system \nis processing his or her transaction, it is doing no other work. \n The most popular mechanism used to attain serializability is locking. The concept is simple: \n ■  Each transaction reserves access to the data it uses. This reservation is called a  lock . \n ■  There are  read locks and  write locks . 1 \n ■  Before reading a piece of data, a transaction sets a read lock. Before writing the data, it sets a write lock. \n ■  Read locks conﬂ ict with write locks, and write locks conﬂ ict with both read and write locks. \n ■  A transaction can obtain a lock only if no other transaction has a conﬂ icting lock on the same data item. \nThus, it can obtain a read lock on a data item  x only if no transaction has a write lock on  x . It can obtain \na write lock on  x only if no transaction has a read lock or write lock on  x . \n We say that two operations  conﬂ ict if they operate on the same data and at least one of them is a write. The \nintuition is that the execution order of conﬂ icting operations makes a difference, because it changes either the \nvalue read by a transaction (since a read operation reads a different value depending on whether it executes \nbefore or after a write operation) or the ﬁ nal value of a data item (since changing the order of two write opera-\ntions on the same data changes the ﬁ nal value of the data). Since their execution order matters, it’s important \nto control that order. \n The intuition behind locking is that it avoids interference between transactions by using conﬂ icting locks to \nsynchronize the execution order of conﬂ icting operations. If a transaction is holding a read lock, then another \ntransaction cannot set a write lock, which avoids the concurrent execution of a conﬂ icting write operation. This \nworks similarly for write locks. \n Although the concept of locking is simple, its effects on performance and correctness can be complex, \ncounterintuitive, and hard to predict. Building robust TP applications requires a solid understanding of locking. \n Locking \n 6 \nCHAPTER\n 1 Many systems call them  “ shared (or S) ” and  “ exclusive (or X) ” locks, instead of  “ read ” and  “ write ” locks. However, as a reminder \nthat there is perfect symmetry between operations and lock types, we use the operation names  “ read ” and  “ write ” instead. \n",
      "content_length": 2793,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 161,
      "content": "142  CHAPTER 6 Locking\n Locking affects performance. When a transaction sets a lock, it delays other transactions that need to set \na conﬂ icting lock. Everything else being equal, the more transactions that are running concurrently, the more \nlikely that such delays will happen. The frequency and length of such delays can also be affected by transac-\ntion design, database layout, and transaction and database distribution. To understand how to minimize this \nperformance impact, one must understand locking mechanisms and how they are used, and how these mecha-\nnisms and usage scenarios affect performance. \n Locking also affects correctness. Although locking usually strikes people as intuitively correct, not all uses of \nlocking lead to correct results. For example, reserving access to data before actually doing the access would seem \nto eliminate the possibility that transactions could interfere with each other. However, if serializability is the goal, \nthen simply locking data before accessing it is not quite enough: The timing of unlock operations also matters. \n Correctness and the Two-Phase Rule \n To see how unlock operations affect correctness, consider two transactions, T 1 and T 2 , which access two shared \ndata items,  x and  y . T 1 reads  x and later writes  y , and T 2 reads  y and later writes  x . 2 For example,  x and  y could be \nrecords that describe ﬁ nancial and personnel aspects of a department. T 1 reads budget information in  x and updates \nthe number of open requisitions in  y . T 2 reads the current head count and updates the committed salary budget. \n To describe executions of these transactions succinctly, we’ll use r 1 [ x ] to denote T 1 ’s read of  x , w 1 [ y ] to \ndenote T 1 ’s write of  y , and similarly for T 2 . We’ll denote lock operations in a similar way — rl 1 [ x ] to denote \nthat T 1 sets a read lock on  x , and ru 1 [ x ] to denote that T 1 unlocks  x . Given this notation, consider the following \nexecution E of T 1 and T 2 : \n \n In execution E , each transaction locks each data item before accessing it. (You should check this for each \noperation.) Yet the execution isn’t serializable. We can show this by stripping off the lock and unlock opera-\ntions, producing the following execution (see  Figure 6.1 ): \n E\nr [ ] r [ ] w [ ] w [ ]\n\u0002 \u0003 1\n2\n2\n1\nx\ny\nx\ny  \n Since execution E has the same read and write operations as execution E \u0002 and the operations are in the same \norder, E and E \u0002 have the same effect on the database (the only difference between them is the lock operations). \nTo show that E \u0002 isn’t serializable, let’s compare it to the two possible serial executions of T 1 and T 2 , namely \nT 1 T 2 and T 2 T 1 , and show that neither of them could produce the same result as E \u0002 : \n ■  In the serial execution T 1 T 2  \u0003  r 1 [ x ] w 1 [ y ] r 2 [ y ] w 2 [ x ], T 2 reads the value of  y written by T 1 . This isn’t \nwhat actually happened in E \u0002 so this doesn’t produce the same effect as E \u0002 . \n ■  In the serial execution T 2 T 1  \u0003  r 2 [ y ] w 2 [ x ] r 1 [ x ] w 1 [ y ], T 1 reads the value of  x written by T 2 . This isn’t \nwhat actually happened in E \u0002 so this too doesn’t produce the same effect as E \u0002 . \n Since T 1 T 2 and T 2 T 1 are the only possible serial executions of T 1 and T 2 , and E \u0002 doesn’t have the same effect \nas either of them, E \u0002 isn’t serializable. Since E has the same effect as E \u0002 , E isn’t serializable either. \nE\nrl\nr\nru\nT reads \nrl\nr\n\u0003\n1\n1\n1\n1\n2\n2\nx\nx\nx\nx\ny\ny\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\n⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\nwl\nw\nru\nwu\nT reads\nand writes \n2\n2\n2\n2\n2\nx\nx\ny\nx\ny\nx\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0002\n\u0003\n\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\nwl\nw\nwu\nT writes \n1\n1\n1\n1\ny\ny\ny\nx\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\nE\nrl\nr\nru\nT reads \nrl\nr\n\u0003\n1\n1\n1\n1\n2\n2\nx\nx\nx\nx\ny\ny\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\n⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\nwl\nw\nru\nwu\nT reads\nand writes \n2\n2\n2\n2\n2\nx\nx\ny\nx\ny\nx\n\u0002\n\u0003\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n\u0002\n\u0003\n\u0004\u0004\u0004\n\u0005\n\u0004\u0004\u0004\nwl\nw\nwu\nT writes \n1\n1\n1\n1\ny\ny\ny\nx\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n⎡⎢⎤⎥\n 2 The example is a bit contrived, in that each transaction updates a data item it didn’t previously read. The example is designed to illus-\ntrate a variety of concurrency control concepts throughout the chapter. \n",
      "content_length": 4150,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 162,
      "content": " Each transaction in E got a lock before accessing the corresponding data item. So what went wrong? The \nproblem is the timing of T 1 ’s unlock operation on  x . It executed too soon. By releasing its lock on  x before get-\nting its lock on  y , T 1 created a window of opportunity for T 2 to ruin the execution. T 2 wrote  x after T 1 read it \n(making it appear that T 2 followed T 1 ) and it read  y before T 1 wrote it (making it appear that T 2 preceded T 1 ). \nSince T 2 can’t both precede and follow T 1 in a serial execution, the result was not serializable. \n The locking rule that guarantees serializable executions in all cases is called  two-phase locking . It says that \na transaction must obtain all its locks before releasing any of them. Or equivalently, a transaction cannot release \na lock and subsequently get a lock, as T 1 did in E. When a transaction obeys this rule, it has two phases (hence \nthe name): a growing phase during which it acquires locks, and a shrinking phase during which it releases them. \nThe operation that separates the two phases is the transaction’s ﬁ rst unlock operation, which is the ﬁ rst operation \nof the second phase. \n Two-Phase Locking Theorem: If all transactions in an execution are two-phase locked, then the execu-\ntion is serializable. \n Despite the simple intuition behind locking, there are no simple proofs of the Two-Phase Locking Theorem. \nThe original proof by Eswaran et al. appeared in 1976 and was several pages long. The simplest proof we \nknow of is by J. D. Ullman and is presented in the appendix at the end of this chapter. \n Transactions Interact Only Via Reads and Writes \n Whether or not you take the time to understand the proof, it is important to understand one assumption on \nwhich the proof is based, namely,  transactions interact only via read and write operations . This assumption \nensures that the only way that transactions can affect each other’s execution is through operations that are syn-\nchronized by locking. \n One way to break this assumption is to allow transactions to exchange messages through the communication \nsystem, as ordinary messages over a communication channel or in main memory, not via transactional queues. \nFor example, consider the following execution: send 3 [ msg ] receive 4 [ msg ] w 4 [ x ] r 3 [ x ] where  msg is a message \nsent by T 3 to T 4 . This execution is not serializable: T 4 received  msg that was sent by T 3 , making it appear that T 4 \nexecuted after T 3 ; but T 3 read the value of  x written by T 4 , making it appear that T 3 executed after T 4 . Obviously, \nin a serial execution T 3 cannot run both before and after T 4 , so the execution is not equivalent to a serial execu-\ntion and hence is not serializable. Yet two-phase locking would allow this execution to occur, which can be seen \nby adding locking operations to the execution: send 3 [ msg ] receive 4 [ msg ] wl 4 [ x ] w 4 [ x ] wu 4 [ x ] rl 3 [ x ] r 3 [ x ] ru 3 [ x ]. \nx\ny\n1. Read\n4. Write\nT1\nT2\n3. Write\n2. Read\n FIGURE 6.1 \n A Nonserializable Execution, E \u0002 , That Uses Locking. The numbers 1 – 4 indicate the order in which operations execute. \n6.1 Introduction  143\n",
      "content_length": 3173,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 163,
      "content": "144  CHAPTER 6 Locking\n Since  w 4 [ x ] is the last operation of T 4 , it is safe for T 4 to unlock  x , thereby allowing T 3 to read  x . So, we have \nan execution that is two-phase locked but is not serializable, which seems to contradict the Two-Phase Locking \nTheorem. \n The problem is not that the theorem is wrong, but rather that the execution broke an assumption on which \nthe theorem is based, namely, that transactions interact only via reads and writes. T 3 and T 4 interacted via \nmessage passing, and those message passing operations were not locked. Either T 3 and T 4 should not have \nexchanged messages, or those messages should have been exchanged via a write operation (to send  msg ) and a \nread operation (to receive  msg ), which would have been synchronized by locks. \n Another way of stating the assumption is that  “ all operations by which transactions can interact must be pro-\ntected by locks. ” In other words, it is all right for transactions to issue send[ msg ] and receive[ msg ], provided that \nlocks are set for these operations in a two-phase manner. Later in the chapter, we will see examples of other opera-\ntions besides read and write that are protected by locks. However, until then, for simplicity, we will assume that \nreads and writes are the only operations by which transactions can interact and therefore are the only ones that \nneed to be locked. \n Preserving Transaction Handshakes \n A more subtle way for transactions to communicate is via a human operator. For example, suppose a user reads \nthe output displayed by a transaction T 5 and uses it as input to transaction T 6 . The effect here is the same as if \nT 5 sent a message to T 6 . We discussed this example brieﬂ y in Figure 1.4. In terms of our example here, Figure \n1.4 was concerned that T 5 might abort after the user copied its output into T 6 . We therefore recommended that \na user wait until a transaction (e.g., T 5 ) has committed before using that transaction’s output as input to another \ntransaction (e.g., T 6 ). This is called a  transaction handshake . This solves the problem of a transaction reading \ninput that later is undone by an abort. However, is it safe, in view of the assumption that transactions commu-\nnicate only via reads and writes? After all, even if the user waits for T 5 to commit before using T 5 ’s output as \ninput to T 6 , a message is still effectively ﬂ owing from T 5 to T 6 . \n The following theorem tells us that it is indeed safe. \n Transaction Handshake Theorem 3 : For every two-phase locked execution, there is an equivalent serial exe-\ncution that preserves all transaction handshakes. \n In other words, it’s all right for a user to wait for T 5 to ﬁ nish before starting T 6 so that he or she can use T 5 ’s \noutput as input to T 6 . It is true that the user is breaking the assumption that transactions only interact via reads \nand writes. However, this cannot break serializability, because the direction of information transfer, from T 5 to \nT 6 , is consistent with the effective serial order in which the transactions executed. \n The Transaction Handshake Theorem seems obvious. To see that it is not, consider the following execution: \nr 1 [ x ] w 2 [ x ] r 3 [ y ] w 1 [ y ]. In this execution, the user may have seen output that was displayed by transaction T 2 and \nused it as part of the input he or she provided to transaction T 3 . The user was careful to use a transaction hand-\nshake, to make sure that T 2 committed before providing input to T 3 . This execution is serializable, in the order \nT 3 T 1 T 2 . In fact, T 3 T 1 T 2 is the only serial ordering of transactions that is equivalent to the given execution. \nHowever, this serial ordering does not preserve transaction handshakes. In the original execution, transaction \nT 2 (consisting of the single operation w 2 [ x ]) ﬁ nished before T 3 (consisting of the single operation r 3 [ y ]) started. \nThis is a transaction handshake. But in the only equivalent serial ordering, T 3  precedes T 2 . This is a problem if \nthe user transferred some of the output of T 2 into T 3 . \n 3 The proof is from Bernstein et al. (1979). \n",
      "content_length": 4157,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 164,
      "content": " The Transaction Handshake Theorem says that this kind of thing cannot happen when you use two-phase \nlocking. Therefore, the execution r 1 [ x ] w 2 [ x ] r 3 [ y ] w 1 [ y ] must not be obtainable via two-phase locking. To \ncheck that this is so, let’s try to add lock operations to the execution. We start by locking  x for r 1 [ x ]: rl 1 [ x ] r 1 [ x ] \nw 2 [ x ] r 3 [ y ] w 1 [ y ]. Now we need to lock  x for w 2 [ x ], but we can’t do this unless we ﬁ rst release rl 1 [ x ]. Since T 1 \nis two-phase locked, it must get its write lock on  y before it releases its read lock on  x . Thus, we have rl 1 [ x ] \nr 1 [ x ] wl 1 [ y ] ru 1 [ x ] wl 2 [ x ] w 2 [ x ] wu 2 [ y ] r 3 [ y ] w 1 [ y ]. Next, r 3 [ y ] must get a read lock on  y , but it can’t because \nT 1 still has its write lock on  y and it can’t give it up until after w 1 [ y ] executes. So there is no way r 3 [ y ] can run \nat this point in the execution, which shows that the execution could not have happened if all transactions were \ntwo-phase locked. \n Automating Locking \n An important feature of locking is that it can be hidden from the application programmer. Here’s how. \n When a transaction issues a read or write operation, the data manager that processes the operation ﬁ rst sets \na read or write lock on the data to be read or written. This is done without any special hints from the transaction \nprogram, besides the read or write operation itself. \n To ensure the two-phase rule, the data manager holds all locks until the transaction issues the Commit or \nAbort operation, at which point the data manager can release the transaction’s locks since it knows the transac-\ntion is done. This is later than the rule requires, but it’s the ﬁ rst time the data manager can be sure the transaction \nwon’t issue any more reads or writes, which would require it to set another lock. That is, if the data manager \nreleases one of the transaction’s locks before the transaction terminates, and the transaction subsequently issues \na read or write, the system would have to set a lock and thereby break the two-phase rule. \n Thus , a transaction program only needs to bracket its transactions. The data manager does the rest. Although \na data manager can hide locking from the application programmer, it often gives some control over when locks \nare set and released. This offers the programmer a measure of performance tuning, often at the expense of cor-\nrectness. We’ll discuss this in more detail later in the chapter. \n Notice that we used the term  data manager here, instead of the more generic term  “ resource manager ” that \nwe use elsewhere in this book. Since there is such a strong connotation that locking is used by database sys-\ntems, we ﬁ nd it more intuitive to use the terms data manager and data item in this chapter, rather than resource \nmanager and resource. But this is just a matter of taste. We use the terms data manager and resource manager as \nsynonyms, to mean a database system, ﬁ le system, queue manager, and so on — any system that manages access \nto transactional resources. \n Not all concurrency control algorithms use locks. One popular example is optimistic concurrency control, \nwhich is discussed in Sections 6.5 and 6.8. Three other techniques are timestamp ordering, serialization graph \ntesting, and commit ordering.  Timestamp ordering assigns each transaction a timestamp and ensures that con-\nﬂ icting operations execute in timestamp order.  Serialization graph testing tracks conﬂ icts and ensures the \nresulting serialization graph is acyclic.  Commit ordering ensures that conﬂ icting operations are consistent with \nthe relative order in which their transactions commit, which can enable interoperability of systems using dif-\nferent concurrency control mechanisms. These techniques are rarely used in practice, so we don’t discuss them \nhere. See the bibliographic notes for references. \n 6.2  IMPLEMENTATION \n Although an application programmer never has to deal directly with locks, it helps to know how locking is \nimplemented, for two reasons. First, locking can have a dramatic effect on the performance of a TP system. \n6.2 Implementation  145\n",
      "content_length": 4179,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 165,
      "content": "146  CHAPTER 6 Locking\n Most systems offer tuning mechanisms to optimize performance. To use these mechanisms, it’s valuable to \nunderstand their effect on the system’s internal behavior. Second, some of those optimizations can affect cor-\nrectness. Understanding locking implementation helps to understand when such optimizations are acceptable \nand what alternatives are possible. \n An implementation of locking in a data manager has three aspects: implementing a lock manager, setting \nand releasing locks, and handling deadlocks, which we discuss in turn next. \n Lock Managers \n A lock manager is a component that services the operations: \n ■  Lock(transaction-id, data-item, lock-mode): Set a lock with mode  lock-mode on behalf of transaction \n transaction-id on  data-item . \n ■  Unlock(transaction-id, data-item): Release transaction  transaction-id’s lock on  data-item . \n ■  Unlock(transaction-id): Release all transaction  transaction-id’s locks. \n Most implementations store locks in a  lock table . This is a low-level data structure in main memory, much \nlike a control table in an operating system (i.e., not like a SQL table). Lock and unlock operations cause locks \nto be inserted into and deleted from the lock table, respectively. \n Each entry in the lock table describes the locks on a data item. It contains a list of all the locks held on that \ndata item and all pending lock requests that cannot be granted yet. \n To execute a Lock operation, the lock manager sets the lock if no conﬂ icting lock is held by another transac-\ntion. Consider the lock table state shown in  Figure 6.2 . In this state the lock manager would grant a request by T 2 \nfor a read lock on  z , and would therefore add [trid 2 , read] to the list of locks being held on  z , where trid 2 is T 2 ’s \ntransaction ID. If it received a request by T 2 for a write lock on  v , it would add an entry in the lock table for data \nitem  v and then add [trid 2 , write] to the list of locks being held on  v . \n If the lock manager receives a lock request for which a conﬂ icting lock is being held, the lock manager \nadds a request for that lock, which it will grant after conﬂ icting locks are released. In this case, the transaction \nthat requires the lock is blocked until its lock request is granted. For example, a request by T 2 for a write lock \non  z would cause [trid 2 , write] to be added to  z ’s list of lock requests and T 2 to be blocked. \n The strategy for granting blocked requests requires some care to avoid indeﬁ nite postponement. For exam-\nple, in  Figure 6.2 suppose T 5 requests a read lock on  x . In principle, this request could be granted because the \nonly locks on  x are read locks. However, following this strategy, a steady stream of requests for read locks on \n x could indeﬁ nitely postpone T 3 ’s request for a write lock, since there might never be a time when there are no \nread locks on  x . Therefore, a safer approach is to add T 5 ’s request for a read lock to the end of the list of lock \nrequests, after T 3 ’s request. \n Data item identiﬁ ers usually are required to be a ﬁ xed length, say 32 bytes. The lock manager does not \nknow what each of these identiﬁ ers represents. It could be a table, page, row, or other object. It is up to the \nList of Locks Being Held \nData Item\nList of Lock Requests \n[trid1, read], [trid2, read]\n[trid3, write] \n[trid2, write]\n[trid4, read] [trid1, read] \n[trid1, read]\nx\ny\nz\n FIGURE 6.2 \n A Lock Table. Each entry in a list of locks held or requested is of the form [transaction-id, lock-mode]. \n",
      "content_length": 3563,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 166,
      "content": " caller of the lock manager to compress the name of the object to be locked into a data item identiﬁ er of the \nlength supported by the lock manager. \n Any data item in a database can be locked, but only a small fraction of them are locked at any one time, \nbecause only a small fraction of them are accessed at any one time by a transaction that’s actively executing. \nTherefore, instead of allocating a row in the lock table for every possible data item identiﬁ er value, the lock \ntable is implemented as a hash table, whose size is somewhat larger than the maximal number of locks that are \nheld by active transactions. The hash key is the data item identiﬁ er. \n Lock operations on each data item must be atomic relative to each other. That is, each lock operation must \ncomplete before the next one starts. Otherwise, two conﬂ icting lock requests might incorrectly be granted at the \nsame time. For example, if two requests to set a write lock on  v execute concurrently, they might both detect \nthat  v is unlocked before either of them set the lock. Therefore, both of them might set the lock. To avoid this \nbad behavior, the lock manager executes each lock or unlock operation on a data item completely before start-\ning the next one on that data item. That is, it executes lock and unlock operations on each data item atomically \nwith respect to each other. Note that lock operations on different data items can safely execute concurrently. \n The lock manager could become a bottleneck if it takes too long for a lock to be set or released. Since lock \nand unlock operations are very frequent, they could consume a lot of processor time. And since lock opera-\ntions on a data item are atomic, lock requests on popular data items might be delayed because another lock \noperation is in progress. For these reasons, lock and unlock operations must be very fast, ideally on the order \nof a few hundred machine language instructions. \n Although most systems implement locking using a lock table, this is not the only possible design. An alter-\nnative implementation is to store each object’s lock with the object itself. For example, a page lock could be \nstored in the page. \n Rather than exposing lock operations to programs that invoke read and write, locks could be set by the data \naccess operations themselves. For example, in an object-oriented system, consider a class C whose instances \n(i.e., objects) are data items. C could inherit from a generic lock manager class. Each method to access an \nobject of C could be given the responsibility to set the appropriate lock on itself. For example, a get method \ncould set a read lock and a put method could set a write lock. The lock manager class could automatically \nrelease all locks when the transaction commits, thereby relieving the object itself from invoking unlock opera-\ntions. Whether the object’s locks are stored in the object’s representation or in a lock table is an independent \nimplementation decision. \n Setting and Releasing Locks \n To understand how higher levels of the data manager choose which data items to lock, we need to know a little \nbit about data manager architecture. A typical example is a database system that supports the SQL language. \nSuch a system usually is implemented in the following layers (see  Figure 6.3 ): \n ■  Page-oriented ﬁ les: This is the lowest layer of the system, which communicates directly with the per-\nsistent storage device, such as a disk. It offers operations to read and write pages in a ﬁ le. It also imple-\nments a buffer pool that caches recently used pages. \n ■  Access methods: This layer implements record-oriented ﬁ les by formatting each page as a set of records, \neach of which can be accessed by a  logical address. It also implements indexes, to allow records to \nbe accessed based on ﬁ eld value. Typical operations are GetRecord(logical address), which returns the \nrecord with that address; OpenScan(ﬁ eld value), which returns a cursor that points to the ﬁ rst record \nwith that ﬁ eld value; and GetNextRecord(cursor), which returns the record identiﬁ ed by the cursor and \nadvances the cursor to the next record with the ﬁ eld value associated with the cursor. \n6.2 Implementation  147\n",
      "content_length": 4227,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 167,
      "content": "148  CHAPTER 6 Locking\n ■  Query executor: This layer implements the basic relational database operators, such as project, select, join, \nupdate, insert, and delete. It takes as input an expression consisting of one or more of these operations and, \nin the case of retrieval expressions, returns a set of records. Typically, each table is implemented as a ﬁ le at \nthe access method layer and each row is implemented as a record. So we treat the following as synonyms \nin the rest of this chapter: tables and ﬁ les, columns and ﬁ elds, and rows and records. \n ■  Query optimizer: This layer takes a SQL statement as input, parses it, and translates it into an optimized \nexpression of relational database operators that is passed to the query executor. \n Locks can be set by any or all layers of a data manager that conforms to this SQL database architecture. \nFor example, the page-oriented ﬁ le layer could set locks on pages, the record-oriented layer could set locks \non individual records, and the query executor or query optimizer layer could set locks on tables or columns of \ntables. The choice is a tradeoff between the amount of concurrency needed, the overhead of locking operations, \nand the software complexity arising from the combination of locks that are used. We will explore this choice in \nsome detail throughout the chapter. But ﬁ rst, let’s take a high level view of the main tradeoff: concurrency ver-\nsus locking overhead. \n Granularity \n The size of data items that the data manager locks is called the  locking granularity . The data manager could \nlock at a coarse granularity such as ﬁ les, at a ﬁ ne granularity such as records or ﬁ elds, or at an intermediate \ngranularity such as pages. Each approach has its beneﬁ ts and liabilities. \n If it locks at a coarse granularity, the data manager doesn’t have to set many locks, because each lock covers \nso much data. Thus, the overhead of setting and releasing locks is low. However, by locking large chunks of \ndata, the data manager usually is locking more data than a transaction needs to access. For example, with ﬁ le \ngranularity locking, even if a transaction T accesses only a few records of a ﬁ le, the data manager will lock the \nwhole ﬁ le, thereby preventing other transactions from locking any other records of the ﬁ le, most of which are \nnot accessed by transaction T. This reduces the number of transactions that can run concurrently, which both \nreduces the throughput and increases the response time of transactions. \nDatabase\nTransaction 1 \nTransaction N\nAccess Method\n(record-oriented files)  \nRecord-oriented\noperations\nPage-oriented\noperations\nSQL operations\nRelational operations\nDatabase\nSystem \nQuery Optimizer \nQuery Executor \nPage-oriented files \nSQL Operations,\nStart, Commit,  Abort\n FIGURE 6.3 \n SQL Database Architecture. A SQL operation issued by a transaction is translated through a series of layers, each of \nwhich has the option to set locks. \n",
      "content_length": 2956,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 168,
      "content": " If it locks at a ﬁ ne granularity, the data manager locks only the speciﬁ c data actually accessed by a trans-\naction. These locks don’t artiﬁ cially interfere with other transactions, as coarse grain locks do. However, the \ndata manager must now lock every piece of data accessed by a transaction, which can generate a lot of locking \noverhead. For example, if a transaction issues an SQL query that accesses tens of thousands of records, a data \nmanager that does record granularity locking would set tens of thousands of locks, which can be quite costly. In \naddition to the record locks, locks on associated indexes also are needed, which compounds the problem. \n There is a fundamental tradeoff between amount of concurrency and locking overhead, depending on the \ngranularity of locking. Coarse-grained locking has low overhead but low concurrency. Fine-grained locking \nhas high concurrency but high overhead. \n One compromise is to lock at the ﬁ le and page granularity. This gives a moderate degree of concurrency \nwith a moderate amount of locking overhead. It works well in systems that don’t need to run at high transaction \nrates and hence are unaffected by the reduced concurrency. It also works well in systems where transactions \nfrequently access many records per page (such as engineering design applications), so that page locks are not \nartiﬁ cially locking more data than transactions actually access. Another beneﬁ t is that it simpliﬁ es the recovery \nalgorithms for Commit and Abort, as we’ll see in Chapter 7. However, for high performance TP, record locking \nis needed, because there are too many cases where concurrent transactions need to lock different records on the \nsame page. \n Multigranularity Locking \n Most data managers need to lock data at different granularities, such as ﬁ le and page granularity; or database, \nﬁ le, and record granularity. For transactions that access a large amount of data, the data manager locks coarse \ngrain units, such as ﬁ les or tables. For transactions that access a small amount of data, it locks ﬁ ne grain units, \nsuch as pages or records. \n The trick to this approach is in detecting conﬂ icts between transactions that set conﬂ icting locks at differ-\nent granularity, such as one transaction that locks a ﬁ le and another transaction that locks pages in the ﬁ le. This \nrequires special treatment, because the lock manager has no idea that locks at different granularities might con-\nﬂ ict. For example, it treats a lock on a ﬁ le and a lock on a page in that ﬁ le as two completely independent locks \nand therefore would grant write locks on them by two different transactions. The lock manager doesn’t recog-\nnize that these locks  “ logically ” conﬂ ict. \n The technique used for coping with different locking granularities is called  multigranularity locking . In \nthis approach, transactions set ordinary locks at a ﬁ ne granularity and  intention locks at coarse granularity. \nFor example, before read-locking a page, a transaction sets an intention-read lock on the ﬁ le that contains the \npage. Each coarse grain intention lock warns other transactions that lock at coarse granularity about potential \nconﬂ icts with ﬁ ne grain locks. For example, an intention-read lock on the ﬁ le warns other transactions not to \nwrite-lock the ﬁ le, because some transaction has a read lock on a page in the ﬁ le. Details of this approach are \ndescribed in Section 6.10. \n There is some guesswork involved in choosing the right locking granularity for a transaction. For example, \na data manager may start locking individual records accessed by a transaction, but after the transaction has \naccessed hundreds of records, the data manager may conclude that a coarser granularity would work better. \nThis is called lock  escalation and is commonly supported by database systems. An alternative to lock escala-\ntion is program analysis, where the query language compiler estimates how much data will be accessed by a \ntransaction. If it estimates that a lot of data will be accessed, then it generates a hint to lock at coarse granular-\nity. Otherwise, it generates a hint to lock at ﬁ ne granularity. \n Some data managers give the transactions the option of overriding the mechanism that automatically deter-\nmines lock granularity. For example, in Microsoft SQL Server, a transaction can use the keyword PAGLOCK to \n6.2 Implementation  149\n",
      "content_length": 4409,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 169,
      "content": "150  CHAPTER 6 Locking\ninsist that the system use a page lock when it would otherwise use a table lock. Similarly, it can use TABLOCK \nor TABLOCKX to insist that the system use a read or write lock, respectively, on a table. Similarly, in IBM \nDB2 UDB, you can use the LOCK TABLE statement to set a read or write lock on the entire table. Such over-\nrides are useful when tuning an application whose performance is lacking due to inappropriate automatic selec-\ntion of lock granularity by the system. \n 6.3  DEADLOCKS \n When two or more transactions are competing for the same lock in conﬂ icting modes, some of them will \nbecome blocked and have to wait for others to free their locks. Sometimes, a set of transactions are all waiting \nfor each other; each of them is blocked and in turn is blocking other transactions. In this case, if none of the \ntransactions can proceed unless the system intervenes, we say the transactions are  deadlocked . \n For example, reconsider transactions T 1 and T 2 that we discussed earlier in execution E \u0002  \u0003  r 1 [ x ] r 2 [ y ] w 2 [ x ] \nw 1 [ y ] (see  Figure 6.4 ). Suppose T 1 gets a read lock on  x ( Figure 6.4a ) and then T 2 gets a read lock on  y ( Figure \n6.4b ). Now, when T 2 requests a write lock on  x , it’s blocked, waiting for T 1 to release its read lock ( Figure 6.4c ). \nWhen T 1 requests a write lock on  y , it too is blocked, waiting for T 2 to release  its read lock ( Figure 6.4d ). Since each \ntransaction is waiting for the other one, neither transaction can make progress, so the transactions are deadlocked. \n Deadlock is how two-phase locking detects nonserializable executions. At the time deadlock occurs, there \nis no possible execution order of the remaining operations that will lead to a serializable execution. In the pre-\nvious example, after T 1 and T 2 have obtained their read locks, we have the partial execution r 1 [ x ] r 2 [ y ]. There \nare only two ways to complete the execution, r 1 [ x ] r 2 [ y ] w 1 [ y ] w 2 [ x ] or r 1 [ x ] r 2 [ y ] w 2 [ x ] w 1 [ y ], both of which \nare nonserializable. \n Once a deadlock occurs, the only way for the deadlocked transactions to make progress is for at least one of \nthem to give up its lock that is blocking another transaction. Once a transaction releases a lock, the two-phase \nlocking rule says that it can’t obtain any more locks. But since each transaction in a deadlock  must obtain at least \none lock (otherwise it wouldn’t be blocked), by giving up a lock it is bound to break the two-phase locking rule. \nSo there’s no point in having a transaction release just one lock. The data manager might as well abort the transac-\ntion entirely. That is, the only way to break a deadlock is to abort one of the transactions involved in the deadlock. \n Deadlock Prevention \n In some areas of software, such as operating systems, it is appropriate to prevent deadlocks by never granting \na lock request that can lead to a deadlock. For transaction processing, this is too restrictive, because it would \nr1[x]\nr1[x] r2[y]\nr1[x] r2[y] wl2[x]-{blocked}\nr1[x] r2[y] wl2[x]-{blocked} wl1[y]-{blocked}\nData\nItem\nLocks\nHeld\nLocks\nRequested\nData\nItem\nLocks\nHeld\nLocks\nRequested\nData\nItem\nLocks\nHeld\nLocks\nRequested\nData\nItem\nLocks\nHeld\nLocks\nRequested\nx\nx\nT1,read\nT1,read\nT2,read\ny\ny\nx\nT1,read\nx\nT1,read\nT2,read\nT2,write\nT2,write\nT1,write\nT2,read\ny\ny\na.\nb.\nc.\nd.\n FIGURE 6.4 \n Execution Leading to a Deadlock. Each step of the execution is illustrated by the operations executed so far, with the \ncorresponding state of the lock table below it. \n",
      "content_length": 3568,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 170,
      "content": " overly limit concurrency. The reason is that transaction behavior is unpredictable. For example, in the execu-\ntion in  Figure 6.4b , once the system grants T 1 ’s request for a read lock on  x and T 2 ’s request for a read lock on \n y , deadlock is unavoidable; it doesn’t matter in which order T 1 and T 2 request their second lock. The only way \nto avoid deadlock is to delay granting T 2 ’s request to read lock  y . This is  very restrictive. It amounts to requir-\ning that T 1 and T 2 run serially; T 1 must get all of its locks before T 2 gets any of its locks. In this case, a serial \nexecution of T 1 and T 2 is the only serializable execution. But usually, transactions can be interleaved a fair bit \nand still produce a serializable execution. \n The only way to prevent deadlocks and still allow some concurrency is to exploit prior knowledge of trans-\naction access patterns. All operating system techniques to prevent deadlock have this property. In general-\npurpose TP, it is inappropriate to exploit prior knowledge. It either overly restricts the way transactions are \nprogrammed (e.g., by requiring that data be accessed in a predeﬁ ned order) or overly restricts concurrency \n(e.g., by requiring a transaction to get all of its locks before it runs). For this reason, all commercial TP prod-\nucts that use locking allow deadlocks to occur. That is, they allow transactions to get locks incrementally by \ngranting each lock request as long as it doesn’t conﬂ ict with an existing lock, and they detect deadlocks when \nthey occur. \n Deadlock Detection \n There are two techniques that are commonly used to detect deadlocks: timeout-based detection and graph-based \ndetection.  Timeout-based detection guesses that a deadlock has occurred whenever a transaction has been \nblocked for too long. It uses a timeout period that is much larger than most transactions ’ execution time (e.g., \n15 seconds) and aborts any transaction that is blocked longer than this amount of time. The main advantages of \nthis approach are that it is simple and hence easy to implement, and it works in a distributed environment with \nno added complexity or overhead. However, it does have two disadvantages. First, it may abort transactions that \naren’t really deadlocked. This mistake adds delay to the transaction that is unnecessarily aborted, since it now \nhas to restart from scratch. This sounds undesirable, but as we’ll see later when we discuss locking performance, \nthis may not be a disadvantage. Second, it may allow a deadlock to persist for too long. For example, a deadlock \nthat occurs after one second of transaction execution will be undetected until the timeout period expires. \n The alternative approach, called  graph-based detection , explicitly tracks waiting situations and periodically \nchecks them for deadlock. This is done by building a  waits-for graph, whose nodes model transactions and \nwhose edges model waiting situations. That is, if transaction T 1 is unable to get a lock because a conﬂ icting \nlock is held by transaction T 2 , then there is an edge T 1 → T 2 , meaning T 1  is waiting for T 2 . In general, the data \nmanager creates an edge T i → T k whenever transaction T i is blocked for a lock owned by transaction T k . It deletes \nthe edge when T i becomes unblocked. There is a deadlock whenever the deadlock graph has a cycle, that is, a \nsequence of edges that loops back on itself, such as T 1 → T 2 → T 1 (see  Figure 6.5 ), or T 1 → T 7 → T 4 → T 2 → T 1 . \nT1\nT1 waits-for T2’s lock on y\nT2 waits-for T1’s lock on x\nr1[x] r2[y] wl2[x]-{blocked} wl1[y]-{blocked} \nT2\n FIGURE 6.5 \n A Waits-For Graph. The graph on the left represents the waiting situations in the execution on the right (see also Figure \n6.4). Since there is a cycle involving T 1  and T 2 , they are deadlocked. \n6.3 Deadlocks  151\n",
      "content_length": 3843,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 171,
      "content": "152  CHAPTER 6 Locking\n Any newly added edge in the waits-for graph could cause a cycle. So it would seem that the data manager \nshould check for cycles (deadlocks) whenever it adds an edge. While this is certainly correct, it is also possible \nto check for deadlocks less frequently, such as every few seconds. A deadlock won’t disappear spontaneously, \nso there is no harm in checking only periodically; the deadlock will still be there whenever the deadlock detec-\ntor gets around to look for it. By only checking periodically, the system reduces deadlock detection cost. Like \ntimeout-based detection, it allows some deadlocks to go undetected longer than necessary. But unlike timeout, \nall detected deadlocks are real deadlocks. \n Victim Selection \n After a deadlock has been detected using graph-based detection, one of the transactions in the cycle must be \naborted. This is called the  victim . Like all transactions in the deadlock cycle, the victim is blocked. It ﬁ nds out \nthat it is the victim by receiving an error return code from the operation that was blocked, which says  “ you have \nbeen aborted. ” It’s now up to the application that issued the operation to decide what to do next. Usually, it just \nrestarts the transaction from the beginning, possibly after a short artiﬁ cial delay to give the other transactions in \nthe cycle time to ﬁ nish, so they don’t all deadlock again. \n There are many victim selection criteria that the deadlock detector can use. It could choose the one in the \ndeadlock cycle that: \n 1.  Closed the deadlock cycle: This may be the easiest to identify and is fair in the sense that it is the trans-\naction that actually caused the deadlock. \n 2.  Has the fewest number of locks: This is a measure of how much work the transaction did. Choose the \ntransaction that did the least amount of work. \n 3.  Generated the least amount of log records: Since a transaction generates a log record for each update it \nperforms (to be discussed at length in Chapter 7), this transaction is probably the cheapest to abort. \n 4.  Has the fewest number of write locks: This is another way of selecting the transaction that is probably \ncheapest to abort. \n Instead of the deadlock detector choosing a victim, the application itself can choose one . For example, \nOracle Database backs out the statement that caused the deadlock to be detected and returns an error, thereby \nleaving it up to the application to choose whether to abort this transaction or another one. 4 \n Some systems allow the transaction to inﬂ uence victim selection. For example, in Microsoft SQL Server, a \ntransaction can say  “ SET DEADLOCK_PRIORITY LOW ” or  “ SET DEADLOCK_PRIORITY NORMAL. ” If \none or more transactions in a deadlock cycle have priority LOW, one of them will be selected as victim. Among \nthose whose priority makes them eligible to be the victim, the system selects the one that is cheapest to abort. \n One consideration in victim selection is to avoid  cyclic restart , where transactions are continually restarted \ndue to deadlocks and thereby prevented from completing. One way this could happen is if the oldest transac-\ntion is always selected as victim. For example, suppose T 1 starts running, then T 2 starts, then T 1 and T 2 dead-\nlock. Since T 1 is older, it’s the victim. It aborts and restarts. Shortly thereafter, T 1 and T 2 deadlock again, but \nthis time T 2 is older (since T 1 restarted after T 2 ), so T 2 is the victim. T 2 aborts and restarts and subsequently \ndeadlocks again with T 1 . And so on. \n One way to avoid cyclic restart is to select the youngest transaction as victim. This ensures that the oldest \ntransaction in the system is never restarted due to deadlock. A transaction might still be repeatedly restarted \ndue to bad luck — if it’s always the youngest transaction in the cycle — but this is very unlikely. \n 4 In  Oracle Database Concepts ,11g Release 1 (11.1), Part Number B28318-05, Chapter 13,  “ Data Concurrency and Consistency. ” \n",
      "content_length": 4005,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 172,
      "content": " The problem can be avoided entirely if the transaction is given the same start time each time it is restarted, \nso that it will eventually be the oldest in the system. But this requires that the data manager accept the start-\ntime as an input parameter to the Start operation, which few data managers support. \n In the end, the application or transactional middleware usually provides the solution by tracking the num-\nber of times a transaction is restarted. An application error is reported if a transaction is restarted too many \ntimes, whether for deadlock or other reasons, at which point it is an application debugging or tuning problem \nto determine why the transaction is deadlocking so often. \n Distributed Deadlock Detection \n In practice many systems use multiple databases. They are introduced for many reasons, for example, to scale \nup the system, to separate data belonging to different applications, to simplify debugging and maintenance, or \nto add an application that requires a different data manager product. A system that uses multiple databases is \nlikely to need distributed transactions. \n In a distributed system, there are multiple data managers on different nodes of the network. A transaction \nmay access data at more than one data manager. Data managers set locks in the usual way, as if the transaction \nwere not distributed. That is, when a transaction accesses a data item at a data manager, the data manager sets \nthe appropriate lock before performing the access. \n As in the nondistributed case, sometimes a lock request becomes blocked. These blocking situations can \nexist at multiple data managers, which can lead to a deadlock that spans data managers yet is not detectable by \nany one data manager by itself. For example, let’s reconsider our favorite transactions T 1 and T 2 , and suppose \n x and  y are stored at different data managers, DM x and DM y (see  Figure 6.6 ). T 1 reads  x at DM x , setting a read \nlock, and T 2 reads  y at DM y , setting a read lock. Now, as before, T 1 tries to set a write lock on  y at DM y but is \nblocked waiting for T 2 , and T 2 tries to set a write lock  x at DM x but is blocked waiting for T 1 . This is the same \ndeadlock we observed in  Figure 6.4 and  Figure 6.5 ; T 1 is waiting for T 2 at DM y and T 2 is waiting for T 1 at \nDM x . However, neither DM x nor DM y alone can see the deadlock. They each just see one waiting situation. \n Dozens of algorithms to detect distributed deadlocks have been published by database researchers over \nthe years, but only a few are used in practice. One simple technique is to designate one data manager  D as the \ndistributed deadlock detector and have every other data manager periodically send its waits-for graph to  D. \nD has a complete view of waits-for situations across all nodes and can therefore detect distributed deadlocks. \nThis can work well for a set of data managers from a single vendor that are executing on machines that have \na high speed interconnect. However, in a more heterogeneous system, this requires more cooperation between \ndata managers than one can reasonably expect. And if communication speeds are slow, frequent exchange of \ndeadlock graphs may be impractical. \nrl1[x]\nwl2[x] {blocked}\nrl2[y]\nwl1[y] {blocked}\nDMx\nDMy\n FIGURE 6.6 \n A Distributed Deadlock. DM x and DM y are independent data managers, perhaps at different nodes of the network. At DM x , \nT 2 is waiting for T 1 , which is waiting for T 2 at DM y . The transactions are deadlocked, but neither DM x nor DM y alone can \nrecognize this fact. \n6.3 Deadlocks  153\n",
      "content_length": 3587,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 173,
      "content": "154  CHAPTER 6 Locking\n The most popular approach for detecting distributed deadlocks is even simpler, namely, timeout-based detec-\ntion. The implementation is trivial, it works in heterogeneous systems, and it is unaffected by slow communica-\ntions (except to select an appropriate timeout period). Moreover, it performs surprisingly well. We will see why \nin the next section. \n 6.4  PERFORMANCE \n Locking performance is almost exclusively affected by delays due to blocking, not due to deadlocks. Deadlocks \nare rare. Typically, fewer than 1% of transactions are involved in a deadlock. \n One practical reason why deadlocks are rare is that they can have very bad consequences, so database \nadministrators (DBAs) work hard to avoid them. In a poorly constructed system, a deadlock can cause a user’s \njob to sit there for minutes. If too many deadlocks occur, an entire database can be rendered unusable. So \nDBAs quickly ﬁ nd out about common deadlocks and minimize their frequency of occurrence. \n Lock Conversions \n One situation that can lead to many deadlocks is lock conversions.  A lock conversion is a request to upgrade a \nread lock to a write lock. This occurs when a transaction reads a data item, say  x , and later decides to write it, a \nrather common situation. If two transactions do this concurrently, they will deadlock; each holds a read lock on \n x and requests a conversion to a write lock, which can’t be granted. Notice that it is not safe for a transaction to \nrelease its read lock before upgrading it to a write lock, since that would break two-phase locking. \n This problem can be prevented if each transaction gets a write lock to begin with and then downgrades it \nto a read lock if the transaction decides not to write the item. This can be done, provided that the transaction \nis programmed in a relatively high-level language, such as SQL. To see how, consider a SQL Update state-\nment, which updates the subset of rows in a table that satisﬁ es the predicate in the statement’s WHERE clause. \nA na ï ve implementation would scan all the rows of the table. For each row, it sets a read lock, checks whether \nthe row satisﬁ es the WHERE clause, and if so, converts the read lock to a write lock and updates the row. To \navoid the possible lock conversion deadlock in the last step, it could instead work as follows: For each row, it \nsets a write lock, checks whether the row satisﬁ es the WHERE clause; if so, it updates the row and if not, it \nconverts the write lock to a read lock. \n Downgrading the write lock to a read lock looks like it might be breaking two-phase locking, since reduc-\ning the strength of the lock is much like releasing the lock. Ordinarily, two-phase locking would disallow this, \nbut here, since the transaction only reads the row, it’s safe: The transaction ﬁ rst sets a write lock, in case it \nneeds that lock later to avoid a deadlock. Once it realizes it will not write the row, it knows that it only needed \na read lock, so it downgrades to a read lock. \n The approach can be approximated even if the transaction is programmed in a lower level language, where \nupdates are performed by ﬁ rst reading a data item and then later issuing a write operation. However, in this case, \nthe transaction needs to give an explicit hint in the read operation that a write lock is required. Downgrading the \nlock to a read lock would require another hint; or it may not be done, at the expense of reduced concurrency. \n Although getting write locks early can reduce concurrency, the overall performance effect is beneﬁ cial \nsince it prevents a likely deadlock. Therefore, many commercial SQL data managers use this approach. \n One can improve concurrency somewhat by adding an  update lock mode . An update lock conﬂ icts with \nupdate locks and write locks, but not with read locks. In this approach, when a transaction accesses a data item \nthat it may later update, it sets an update lock instead of a write lock. If it decides to update the data item, it \n",
      "content_length": 4014,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 174,
      "content": " c onverts the update lock to a write lock. This lock conversion can’t lead to a lock conversion deadlock, because \nat most one transaction can have an update lock on the data item. (Two transactions must try to convert the lock \nat the same time to create a lock conversion deadlock.) On the other hand, the beneﬁ t of this approach is that an \nupdate lock does not block other transactions that read without expecting to update later on. The weakness is that \nthe request to convert the update lock to a write lock may be delayed by other read locks. If a large number of data \nitems are read and only a few of them are updated, the tradeoff is worthwhile. This approach is used in Microsoft \nSQL Server. SQL Server also allows update locks to be obtained in a SELECT (i.e., read) statement, but in this \ncase, it will not downgrade the update locks to read locks, since it doesn’t know when it is safe to do so. \n Lock Thrashing \n By reducing the frequency of lock conversion deadlocks, we have dispensed with deadlock as a major perfor-\nmance consideration, so we are left with blocking situations. Blocking affects performance in a rather dramatic \nway. Until lock usage reaches a saturation point, it introduces only modest delays — signiﬁ cant, but not a seri-\nous problem. At some point, when too many transactions request locks, a large number of transactions sud-\ndenly become blocked, and few transactions can make progress. Thus, transaction throughput stops growing. \nSurprisingly, if enough transactions are initiated, throughput actually decreases. This is called  lock thrashing \n(see  Figure 6.7 ). The main issue in locking performance is to maximize throughput without reaching the point \nwhere thrashing occurs. \n One way to understand lock thrashing is to consider the effect of slowly increasing the  transaction load , \nwhich is measured by the number of active transactions. When the system is idle, the ﬁ rst transaction to run \ncannot block due to locks, because it’s the only one requesting locks. As the number of active transactions \ngrows, each successive transaction has a higher probability of becoming blocked due to transactions already \nrunning. When the number of active transactions is high enough, the next transaction to be started has virtually \nno chance of running to completion without blocking for some lock. Worse, it probably will get some locks \nbefore encountering one that blocks it, and these locks contribute to the likelihood that other active transac-\ntions will become blocked. So, not only does it not contribute to increased throughput, but by getting some \nlocks that block other transactions, it actually reduces throughput. This leads to thrashing, where increasing \nthe workload decreases the throughput. \nThroughput\nHigh\nHigh\nNumber of Active\nTransactions\nLow\nLow\nThrashing\nRegion\n FIGURE 6.7 \n Lock Thrashing. When the number of active transactions gets too high, many transactions suddenly become blocked, \nand few transactions can make progress. \n6.4 Performance  155\n",
      "content_length": 3032,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 175,
      "content": "156  CHAPTER 6 Locking\n There are many techniques open to designers of data managers, databases, and applications to minimize \nblocking. However, even when all the best techniques are applied, if the transaction load is pushed high enough, \nlock thrashing can occur, provided other system bottlenecks (such as disk or communications bandwidth) don’t \nappear ﬁ rst. \n Tuning to Reduce Lock Contention \n Suppose a transaction holds a write-lock  L for  t seconds. Then the maximum transaction rate for transactions \nthat set  L is 1/ t (i.e., one transaction per  t seconds). To increase the transaction rate, we need to make  t smaller. \nThus, most techniques for minimizing blocking attempt to reduce the time a transaction holds its locks. \n One approach is to set lock  L later in the transaction’s execution, by accessing  L ’s data later. Since a trans-\naction releases its locks when it completes, the later in its execution that it sets a lock, the less time it holds \nthe lock. This may require rearranging application logic, such as storing an update in a local variable and only \napplying it to the database just before committing the transaction. \n A second approach is to reduce the transaction’s execution time. If a transaction executes faster, it com-\npletes sooner, and therefore holds its locks for a shorter period. There are several ways to reduce transaction \nexecution time: \n ■  Reduce the number of instructions it executes, called its  path length . \n ■  Buffer data effectively, so a transaction rarely has to read from disk. If data must be read from disk, do \nthe disk I/O before setting the lock, to reduce the lock holding time. \n ■  Optimize the use of other resources, such as communications, to reduce transaction execution time. \n A third approach is to split the transaction into two or more shorter transactions. This reduces lock holding \ntime, but it also loses the all-or-nothing property of the transaction, thereby requiring one of the techniques for \nmultitransaction business processes discussed in Chapter 5. This can complicate the application design, but it’s \nthe price to be paid for reduced lock contention. For example, instead of one all-or-nothing transaction, there \nare now two transactions; there needs to be recovery code for the case where the ﬁ rst one succeeds and the sec-\nond one doesn’t, something that wasn’t required when there was just one transaction. \n Recall that lock granularity affects locking performance. One can reduce conﬂ icts by moving to ﬁ ner granu-\nlarity locks. Usually, one relies on the data manager to do this, but there are cases where a database or application \ndesigner can affect granularity. For example, suppose a data manager uses record granularity locking. Consider \na ﬁ le that has some frequently updated ﬁ elds, called  hot ﬁ elds, and other infrequently updated ones, called  cold \nﬁ elds. In this case, it may be worth splitting the ﬁ le  “ vertically ” into two ﬁ les, where each record is split in half, \nwith its hot ﬁ elds in one ﬁ le and its cold ﬁ elds in the other. For example, the ﬁ le may contain information about \ncustomer accounts, and we split it with customer number, name, and balance (the hot ﬁ eld) in one ﬁ le, and cus-\ntomer number, address, and phone number (the cold ﬁ elds) in the other (see  Figure 6.8 ). Note that customer num-\nber, the key, must appear in both ﬁ les to link the two halves of each record. 5 Before splitting the ﬁ le, transactions \nthat used the cold ﬁ elds but not the hot one were delayed by locks held by transactions accessing the hot ﬁ eld. \nAfter splitting the ﬁ le, such conﬂ icts do not arise. \n In this example, even though the name ﬁ eld is not frequently updated, it is included with the hot ﬁ eld bal-\nance because in this hypothetical application name and balance are usually accessed together by the same trans-\naction. If name were included with the cold ﬁ elds address and phone number, then a transaction that updates a \nbalance would have to set a read lock on the cold half of the record, which would increase locking overhead and \ndata access cost. \n 5 In a relational database system, you could make the original table available as a view of the partitioned tables. This avoids rewriting \nexisting programs and offers more convenient access to a transaction that requires both hot and cold ﬁ elds. \n",
      "content_length": 4360,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 176,
      "content": " When a running system is on the verge of thrashing due to too much blocking, the main way to control the \nproblem is to reduce the transaction load. This is relatively straightforward to do: reduce the maximum number \nof threads allowed by each data manager. One good measure for determining that the system is close to thrash-\ning is the fraction of active transactions that are blocked. Various studies have shown that a value of about 30% \nis the point at which thrashing starts to occur. This fraction is available in most systems, which expose the \nnumber of active and blocked transactions. \n Recall that detecting deadlocks by timeout can make mistakes by aborting transactions that are not really \ndeadlocked. However, if a transaction is blocked for a long time, this suggests that the transaction load is too \nhigh, so aborting blocked transactions may be good to do. Of course, to get the full beneﬁ t of this load reduc-\ntion, the aborted transaction should not be immediately restarted, which would keep the transaction load at too \nhigh a level. But even if it is restarted immediately, aborting it may have a positive effect by unblocking some \ntransactions that are waiting for the aborted transaction’s locks. \n Some impractical locking policies are useful to understand, because they provide insight on how locking \nperformance is affected by certain factors. One such policy is  conservative locking : after a transaction exe-\ncutes the Start operation, it waits until it can set all the locks it needs, at which point it sets all the locks at \nonce. Since blocked transactions hold no locks, this increases the transaction load that can be handled, which \nis good. However, the approach is impractical for two reasons: First, a transaction must know exactly which \nlocks it needs before it starts. Since it ordinarily does not know this, it would be compelled to set all the locks \nthat it  might need, typically a much larger set than the exact set it  does need, which thereby increases lock con-\ntention. Second, a transaction may have to try to acquire all its locks many times before it gets all of them, so \neach attempt to get all its locks must be practically free, which it is not. \n Another interesting impractical locking approach is the  pure restart policy . In this approach, transactions \nnever wait. Rather, if a transaction requests a lock that conﬂ icts with one that is already set, it aborts and waits \nuntil the conﬂ icting lock is released before it restarts. If aborts are cheap and there is no contention for other \nresources (besides locks), a pure restart policy can sustain a higher transaction load than a standard blocking \npolicy (where transactions wait for conﬂ icting locks to be released). Of course, aborts do have a cost and often \nother resources are in limited supply, which is why the blocking policy is normally used in practice. However, \nas we’ll see in Section 6.8, there is a practical case where a pure restart policy is preferable. \nb. Partitioning into two files, with hot ﬁelds on the left and cold ﬁelds on the right\na. Original file\nCustomer\nNumber\nName\nAddress\nBalance\nPhone\nNumber\nName\nBalance\nAddress\nPhone\nNumber\nCustomer\nNumber\nCustomer\nNumber\n FIGURE 6.8 \n Splitting Hot and Cold Fields to Avoid Contention. By moving the cold ﬁ elds, Address and Phone Number, into a separate \nﬁ le, accesses to those ﬁ elds aren’t delayed by locks on the hot ﬁ elds, Name and Balance, which are now in a separate ﬁ le. \n6.4 Performance  157\n",
      "content_length": 3503,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 177,
      "content": "158  CHAPTER 6 Locking\n Several other practical approaches to improving locking performance are described in later sections of \nthis chapter: Section 6.5, on hot spot techniques; Section 6.6, on techniques for mixed loads of queries and \nupdates, such as weaker degrees of isolation and multiversion data; and Section 6.8, on optimistic concurrency \ncontrol. \n A Mathematical Model of Locking Performance \n Some fairly deep mathematics has been applied to locking performance. Although it isn’t necessary to under-\nstand the math to know how to reduce lock contention, the math does produce formulas that help explain \nthe observed phenomena. Some of the key formulas can be explained using a fairly simple model, which we \ndescribe here. The model can be used to estimate the probability of conﬂ icts and deadlock when designing \ntransactions. Using it in a ﬁ ve-minute calculation can save you a lot of trouble. \n In the model each transaction issues requests for  K write locks with an average time  t between lock \nrequests. The overall database has  D data items that can be locked, and there are  N transactions running at any \ngiven time (see  Figure 6.9 ). \n Since each transaction requests  K write locks, at any given time each running transaction has  K /2 write \nlocks on average. Therefore, on average there are  NK /2 locks held by the system at any given time. When a \ntransaction requests a new lock, if it makes a random selection among the  D lockable data items, then the prob-\nability it conﬂ icts with an existing lock is ( NK /2)/ D , or  NK /2 D . Since each transaction makes  K lock requests, \nthe probability it encounters a conﬂ ict sometime during its execution is  K times the probability of a conﬂ ict, \nwhich is  K  \u0004  NK /2 D , or  NK 2 /2 D . \n The probability that two transactions deadlock is the probability that a transaction T 1 is blocked (i.e., \n NK 2 /2 D ) times the probability that another transaction T 2 is blocked waiting for T 1 . Since there are  N transac-\ntions in the system and T 2 is equally likely to conﬂ ict with any of them, the probability that T 2 is blocked wait-\ning for T 1 is the probability that T 2 is blocked (i.e.,  NK 2 /2 D ) divided by  N  – 1. To simplify the formula, we’ll \nassume  N is large enough that we can use  N instead of  N  – 1. So the probability of a deadlock involving two \ntransactions is: \n \n (\n/\n)\n(\n/\n)/\n(\n/4\n)/N\n/\nNK\nD\nNK\nD N\nN K\nD\nNK\nD\n2\n2\n2\n4\n2\n4\n2\n2\n2\n4\n\u0004\n\u0003\n\u0003\n \n \nStart\nTransaction Model\n• K lock requests per transaction\n• t seconds average time between lock requests\nSystem Model\n• N transactions accessing the database\n• D data items in the database\nRequest\nlock1\nx1\nxD\nRequest\nlock2\nRequest\nlockK\n  Commit\nT1\nT2\nTN\n. . .\n. . .\n. . .\nt\nt\nt\n FIGURE 6.9 \n Mathematical Model of Transactions and System. Using this model, formulas can be derived for probability of conﬂ ict \nand deadlock, and for throughput. \n",
      "content_length": 2905,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 178,
      "content": " The probability of deadlock cycles that involve three or more transactions is so much smaller than for two \ntransactions that it can be ignored without losing much accuracy. Therefore, dropping the constants, we can \nsummarize the preceding analysis as follows: \n ■  The probability of a conﬂ ict is proportional to  K 2 N/D \n ■  The probability of a deadlock is proportional to  K 4 N/D 2 \n Since a typical application might have a  K of 20 (for an average transaction) and a  D of one million, you \ncan see from the previous two formulas why deadlock is so rare relative to conﬂ ict — a deadlock is  K 2 / D as \nlikely as a conﬂ ict, or only 0.0004 as likely. \n Now let’s look at transaction throughput. If transactions were never blocked, then the throughput would \nbe  N /( t  \u0004  ( K  \u0005  1)), where  t  \u0004  ( K  \u0005  1) is the transaction’s execution time. For example, if  N is 50 and each \ntransaction executes for 0.5 seconds, then the throughput would be 100 transactions per second. However, at \nany given time some fraction of transactions are blocked and therefore are not contributing to system through-\nput. We can estimate that fraction by the probability that a transaction encounters a conﬂ ict ( K 2 N /2 D ) times the \nfraction of its total execution time (including blocked time) that it spends waiting if it encounters a conﬂ ict. \nLet’s use  A to denote the latter. Thus, we have the following: \n The throughput is proportional to ( N / tt )  \u0004  (1  –  AK 2 N /2 D ), where \n ■  tt  \u0003  t  \u0004  ( K  \u0005  1) is the transaction’s execution time assuming it is never blocked \n ■  A  \u0003  fraction of total transaction execution time (including blocked time) that a transaction spends wait-\ning given that it encounters a conﬂ ict, typically 1/3 to 1/2 \n Looking at throughput, we see that using ﬁ ner grain locks increases  D , which decreases  K 2 N/D , thereby \nincreasing throughput (assuming that transactions are really accessing ﬁ ne-grained data, so that K is unaffected \nby decreasing lock granularity). Shortening transaction execution time decreases  tt , which increases  N/tt , and \nhence increases throughput. \n 6.5  HOT SPOTS \n Even when a system locks ﬁ ne-grained data items, some of those data items are so frequently updated that they \nbecome locking bottlenecks. Such data items are called  hot spots (i.e., they are so frequently accessed that the \ndata metaphorically  “ gets hot ” ). Some common kinds of hot spots are: \n ■  Summary information, such as the amount of money in a bank branch, since every debit and credit trans-\naction needs to update that value \n ■  The end-of-ﬁ le marker in a ﬁ le being used primarily for data entry, since each insert operation moves \n(i.e., updates) the end-of-ﬁ le marker and therefore needs to lock it \n ■  The next serial number to be sequentially assigned, such as order number or transaction number, since \nmany transaction types need to assign such serial numbers \n In these cases, the hot spot is already a ﬁ ne-grained data item, so moving to a ﬁ ner granularity to relieve the \nbottleneck is not an option. Other techniques are needed. \n There are four main techniques to relieve hot spot bottlenecks: \n 1.  Keep the hot data in main memory. Since accesses to main memory are fast, the transaction accessing \nthe hot data will hopefully execute quickly and therefore not hold onto its lock for too long. \n6.5 Hot Spots  159\n",
      "content_length": 3403,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 179,
      "content": "160  CHAPTER 6 Locking\n 2.  Delay operations on the hot spot until just before the transaction commits. That way, the transaction \nholds its lock on the hot data for the minimum amount of time. \n 3.  Replace read operations by veriﬁ cation operations that can be delayed until just before the transaction \ncommits. \n 4.  Group operations into private batches and apply the batch to the hot spot data only periodically. \n Often , these techniques are used in combination. \n The ﬁ rst technique is relatively automatic. Since the data is hot, the data manager’s cache management \nalgorithm will probably keep the data in main memory without any special attention. Still, some systems \nmake a special point of nailing down hot data in main memory, so it can’t be paged out even if it hasn’t been \naccessed in awhile. \n Delaying Operations Until Commit \n The second technique can be implemented by carefully programming a transaction so that its updates come \nat the end. One can automate this approach. Instead of executing operations on data items when they occur, \nthe data manager simply writes a description of each operation in a log. 6 After the transaction is ﬁ nished and \nready to start committing, the data manager actually executes the operations in the transaction’s log. The data \nmanager gets locks for the operations only during this actual execution. Since this execution is at the very end \nof the transaction, the lock holding time will be quite short. \n For example, consider a data entry application that is adding records to the end of a ﬁ le. Each transaction \nmust lock the end-of-ﬁ le marker from the time it starts its insertion until after it commits. Since every transac-\ntion is adding a record, the end-of-ﬁ le marker is likely to be a lock bottleneck. One can avoid this problem by \ndelaying record insertions until the transaction is ready to commit, thereby reducing the lock holding time on \nthe end-of-ﬁ le marker. This technique is used in IBM’s IMS Fast Path system for data that is declared to be a \nData Entry database. \n One problem with this technique is read operations. A transaction program usually cannot delay read oper-\nations until the end, because the values it reads affect its execution — it affects the values it writes and it affects \nits control ﬂ ow via if-statements and the like. For any read operation that must be executed when it is issued \n(and not delayed until the end of the transaction’s execution), the data manager must set a read lock. This is a \nproblem if the read lock is set on a hot spot. \n Optimistic Methods \n One way to circumvent this problem of read operations is to build reads into higher level operations that don’t \nreturn data item values to the calling program. For example, consider an operation Decrement( x ), which sub-\ntracts one from data item  x . To decrement  x , the operation needs to read the current value of  x , but it need not \nreturn that value to the caller. It therefore can be deferred until the transaction is ready to commit. However, \nsuppose instead that Decrement( x ) subtracts one from  x only if  x is positive, and it returns True or False to \nindicate whether or not it actually subtracted one from  x . Since Decrement returns a value to its caller, it can-\nnot be deferred. Unfortunately, like the second version of Decrement, many hot spot operations need to return \na value and therefore cannot be deferred. \n To circumvent the problem of deferring operations that return a value, we need to be a little more devious. \nInstead of simply deferring the operation until commit, the data manager executes the operation twice: ﬁ rst, \n 6 This log is local to the transaction. It is unrelated to the shared recovery log to be discussed at length in Chapter 7. \n",
      "content_length": 3769,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 180,
      "content": " when it is initially issued by the application and second, as a deferred operation at commit time (see  Figure \n6.10 ). During the operation’s ﬁ rst execution, the data manager logs the value returned by the operation along \nwith the operation itself, discards any updates that the operation performs, and releases its lock at the end of \nthe operation. At commit time, the data manager reacquires the necessary lock, executes the logged operation \nagain, but this time it allows the updates to be installed and holds the lock until the transaction is done. In addi-\ntion, it checks that the operation returns the same value  v at commit time as it did initially, by comparing the \nlogged value to  v ; if they’re not the same, it aborts the transaction. \n Let ’s apply this technique to the previous example. If Decrement( x ) returns True during the ﬁ rst execution \nof the operation, then its update is thrown out and True is logged, but no lock is held on  x . (In terms of the \nprevious paragraph  v  \u0003  True.) When Decrement( x ) is re-executed  at commit time, it sets and holds a lock, its \nupdate (if it makes one) is allowed to be installed, and the value returned by Decrement at commit time is com-\npared to the logged value True. If they are different, the transaction is aborted. The reason they could be dif-\nferent is that other transactions decremented  x between this transaction’s two Decrement operations. The ﬁ rst \nDecrement executed when  x is greater than zero, but by the time the second Decrement executes  x equals zero. \n To see why this works, consider what happens if the data manager actually sets a lock on the data during \nthe ﬁ rst execution. Then of course the operation would return the same value during the initial and deferred \nexecutions, since the data that the operation is reading couldn’t change during that period. Instead of setting a \nlock, the data manager simply checks at commit time that the operation returns the same value, which effec-\ntively checks that the execution behaves as if the lock were held. \n The reason why this helps is that it allows concurrent conﬂ icting operations on the hot spot data since the data \nisn’t locked during its initial execution. That is, for a given transaction, the value of the data read by the operation \ncan change between its two executions of Decrement, as long as that change doesn’t affect the value returned by \nthe operation. For example, suppose a transaction T 1 issues Decrement( x ) and that when Decrement( x ) executes \nthe ﬁ rst time,  x  \u0003  2, so it returns True. Suppose that before T 1 commits, another transaction T 2 decrements  x and \ncommits. Therefore, when T 1 issues its commit operation,  x  \u0003  1. But that’s all right. At commit time, T 1 ’s re-\nexecution  of Decrement( x ) decrements  x to zero and returns True, which is the same value that it returned during \nits ﬁ rst execution. Notice that T 1 and T 2 executed concurrently, even though they both updated  x . If they had used \nordinary locking, one of them would have been delayed until the other one committed and released its lock. \n To illustrate a case where an abort occurs, suppose that initially  x  \u0003  1 instead of  x  \u0003  2. So T 1 executes \nDecrement( x ) and returns True. Then T 2 decrements  x and commits (before T 1 commits). Then when T 1 re-executes \nvoid OptimisticTransaction;\n  { Start;\n     .\n     .\n     .\n     b = Decrement(x)\n     .\n     .\n     .\n    Commit;\n  \n  }\nSystem logs  “Decrement(x)” and the value returned\nSystem replays the log. If  “Decrement(x)” returns a different\nvalue than was previously logged, then abort else commit\n FIGURE 6.10 \n Using a Decrement Operation with Optimistic Locking. No locks are set when Decrement( x ) ﬁ rst executes. During the \nreplay of Decrement( x ), the system sets locks, but aborts if the result Decrement( x ) changed since the original execution. \n6.5 Hot Spots  161\n",
      "content_length": 3916,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 181,
      "content": "162  CHAPTER 6 Locking\n Decrement( x ) at commit time,  x  \u0003  0, so it returns False, which is different than what it returned during its ﬁ rst \nexecution, so T 1 aborts and needs to be restarted. When T 1 is re-executed , it ﬁ nds  x  \u0003  0 during its ﬁ rst execution \nof Decrement( x ) and takes appropriate action. For example, if  x represents the number of available reservations, it \nwould report that there are no more reservations available. \n This technique can be effective even for operations that don’t do any updates. For example, consider an \noperation Verify( f ), where  f is a predicate formula that references data items and evaluates to True or False. Like \nDecrement( x ), this operation can be deferred until the end of the transaction by logging not only the operation, \nbut also the value it returns (i.e., True or False). When the operation is replayed at commit time, it locks any \ndata items it accesses, and if it evaluates to a different value than it did during normal execution, its transaction \naborts. \n This Verify operation can be used with a deferred Decrement that does not return a value. For example, \nconsider an inventory application that keeps track of the number of items in stock. It can accept orders for an \nitem until there are none in stock. So, suppose that for each inventory item  i , it stores the quantity in stock, \nQuantity( i ). A transaction that processes an order for item  i should decrement Quantity( i ) provided that it \ndoesn’t make Quantity( i ) negative. It can do this by executing: \n EnoughAvailable\nVerify Quantity\n \n=\n≥\n(\n( )\n)\ni\n1  \n If EnoughAvailable then Decrement(Quantity( )) else Print(\ni\n“\n”\nInsufficient stock. ) \n The semantics here is surprisingly subtle. For example, this example works only if Decrement is deferred. This \nmethod, using a restricted form of the Verify operation, is used in IMS Fast Path in its Main Storage Databases \nfeature. \n This idea of executing an operation without setting locks, and checking that the operation is still valid at \ncommit time, is called  optimistic concurrency control . It is called optimistic because you have to be opti-\nmistic that the check at commit time is usually OK. If it fails, the penalty is rather high — you have to abort the \nwhole transaction. In the previous inventory application, for example, the technique would work well only if \nmost items are usually in stock, which is the expected case in most businesses. By contrast, two-phase locking \nis pessimistic, in that a transaction sets locks in anticipation of conﬂ icts that may never arise. Other scenarios \nwhere optimistic concurrency control is useful are presented in Section 6.8. \n Batching \n Another technique that is used to relieve hot spots is batching. Instead of having each transaction update the \nhot data when it needs it, it batches its effect across a set of transactions. For example, in a data entry applica-\ntion, instead of appending records to the shared ﬁ le in each transaction, each transaction appends the record to \na local batch (one batch for each thread of executing transactions). Since each thread has a private batch, there \nis no lock contention for the batch. Periodically, the batch is appended to the shared ﬁ le. As another example, \nconsider the problem of assigning serial numbers. Instead of reading the latest serial number within each trans-\naction, a batch of serial numbers is periodically set aside for each thread. The thread assigns serial numbers \nfrom its private batch until it runs out, at which time it gets another batch. \n Batching is effective at relieving hot spots, but it has one disadvantage — failure handling requires extra \nwork. For example, after a failure, the private batches of appended records must be gathered up and appended \nto the ﬁ le. Similarly, if it’s important that all serial numbers actually be used, then after a failure, unused serial \nnumbers have to be collected and reassigned to threads. Sometimes, the application can allow the failure han-\ndling to be ignored, for example, if lost serial numbers are not important. \n",
      "content_length": 4100,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 182,
      "content": " Partitioning \n The load on a hot data item can be reduced by partitioning it. For example, if  x represents the number of avail-\nable reservations and is hot, it can be partitioned into  x 1 ,  x 2 , and  x 3 , where the values of  x 1 ,  x 2 , and  x 3 are approx-\nimately equal and  x 1  \u0005  x 2  \u0005  x 3  \u0003  x . Each transaction that decrements  x randomly selects one of the partitions \nto use. Thus, instead of applying 100% of the transaction load to  x , one third of the load is applied to each parti-\ntion. The number of partitions is selected to be large enough so that the load on each partition doesn’t create a \nhot spot bottleneck. \n The main problem with partitioning is balancing the load among the partitions. In the previous example, \nwe balanced the load by randomizing each transaction’s selection of a partition. However, it’s still possible that \nmore transactions are applied to one partition than another. Therefore, it’s possible that one partition will run \nout of available reservations while other partitions still have some reservations left. To ensure that a transaction \nis denied a reservation only if all partitions have been exhausted, the application would have to try all three \npartitions. So, once two of the partitions are empty, all transactions are applied to the nonexhausted partition, \nmaking it a hot spot. It therefore may be better to deny a reservation immediately, if the partition it selected is \nempty. \n Partitioning  x also has the effect of making the value of  x more expensive to obtain. To read  x , a transac-\ntion has to read  x 1 ,  x 2 , and  x 3 and calculate their sum. This isn’t very burdensome, unless this value is required \nfrequently. In that case, the read locks on  x 1 ,  x 2 , and  x 3 obtained by each transaction that reads  x may cause a \nlocking bottleneck with respect to the transactions that update each partition. It may be satisfactory to read the \nvalues of  x 1 ,  x 2 , and  x 3 in separate transactions, which would relieve the bottleneck at the expense of getting an \naccurate value of  x . If not, then one of the techniques described in the next section is needed. \n 6.6  QUERY-UPDATE PROBLEMS \n Another major source of concurrency bottlenecks is queries; that is, read-only requests for decision support \nand reporting. Queries typically run much longer than update transactions and they access a lot of data. So, if \nthey run using two-phase locking, they often set many locks and hold those locks for a long time. This creates \nlong, often intolerably long, delays of update transactions. There are three popular approaches to circumvent-\ning this problem: data warehousing, weaker consistency guarantees, and multiversion databases. \n Data Warehousing \n A simple way to avoid lock conﬂ icts between queries and updates is to run them against different databases. \nTo do this, one creates a  data warehouse , which is a snapshot of data that is extracted from TP databases. \nQueries run against the data warehouse and updates run against the TP databases. Periodically, the contents of \nthe data warehouse is refreshed, either by reloading it from scratch or by extracting only those values from the \nTP database that have changed since the last time the data warehouse was refreshed. \n There are several reasons why it makes sense to use a data warehouse, in addition to relieving lock con-\ntention between queries and updates. First, when doing data analysis, it’s often important that the data not be \nchanging in between queries. For example, suppose you are trying to understand trends in customer behavior. \nIf the database contents changes after every query you run, then you’re never quite sure whether the differences \nyou’re seeing are due to changes in the query or changes in the underlying data. \n Second , it’s often important to run queries against data that is extracted from multiple databases. For example, \nyou may be interested in cross-correlating information in the purchase order, inventory, and sales applications. \n6.6 Query-Update Problems  163\n",
      "content_length": 4062,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 183,
      "content": "164  CHAPTER 6 Locking\n Often, such applications are developed independently over a long period of time, which leads to discrepancies \nbetween the data in their databases. For example, they may use different ways to encode the same information. \nAlso, since the applications run independently, there may be operational errors that cause their databases to dif-\nfer. For example, when a shipment arrives, the shipping clerk sometimes types the wrong corresponding pur-\nchase order number. For these reasons, it is common practice to transform and  “ scrub ” TP data before putting it \nin the data warehouse, so that queries see a  “ clean ” database. If queries were run against the TP data, they would \nsee data that is untransformed and partially inconsistent, making the results less useful. \n Third , it’s important that a TP system has excellent, predictable response time, even under heavy load. For \nexample, if an Internet retail store becomes a bit sluggish, the customer is likely to try a web search to ﬁ nd \nanother store. However, when data analysis queries are running, excellent response time is hard to guarantee, \nbecause such queries can put a virtually unbounded load on the data manager. This scenario is avoided by running \nqueries on a data warehouse system, where queries can slow down other queries, but not on-line transactions. \n For these reasons, data warehousing is a very popular architecture. Still, there are times when queries need \nto run against the same database as update transactions, for example, to get an up-to-the-second view of the \ndatabase. In these situations, solutions to the query-update problem are needed. \n Degrees of Isolation \n To avoid the query-update problem, many applications just give up on serializability for queries by using weaker \nlocking rules. These rules, sometimes called  degrees of isolation or  isolation levels , are codiﬁ ed in the SQL \nstandard and are therefore offered by most SQL database products. \n One such rule is called  read committed (sometimes called  Degree 2 )  isolation . If a query executes with \nread committed isolation, then the data manager holds a read lock on a data item only while the query is actu-\nally reading the data. As soon as the data is read, it releases the lock. \n The beneﬁ t of read committed isolation is performance. Some simulation studies of mixed workloads have \nshown throughput improves by a factor of three over two-phase locking. For some workloads, the performance \nimprovement is even larger. \n Read committed isolation is weaker than two-phase locking, which requires the transaction to hold read \nlocks until it has obtained all its locks. Read committed isolation does ensure that the query only reads data that \nwas produced by transactions that committed. That is, if an active update transaction is currently modifying \na data item, the query will not be able to lock it until that  updater (i.e., update transaction) has committed or \naborted. However, it does not ensure serializability. For example, if the query reads data items  x and  y , and an \nupdater is updating those data items, one possible scenario is the following: \n ■  The query reads  x and then releases its lock on  x . \n ■  Then the updater updates  x and  y , commits, and releases its locks. \n ■  Then the query reads  y . \n The query looks like it executed before the updater on  x but after the updater on  y , a result that would be \nimpossible in a serial execution. \n Under read committed isolation, a transaction that reads the same data item twice might read different val-\nues for each of the read operations. This can happen because another transaction can update the data in between \nthe two reads. For this reason, we say that read committed isolation allows  nonrepeatable reads . It’s a bit of a \nmisnomer, since the transaction is allowed to repeat a read; it’s just that it may get different values each time it \nexecutes the read. \n A slightly stronger version of read committed isolation, called  cursor stability , is offered by some SQL data-\nbase systems. In SQL, the result of a query is a set of rows that is returned to a program as a  cursor . A program \n",
      "content_length": 4180,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 184,
      "content": " can scan the result of the query by iterating over the cursor, one row at a time. Using read committed isolation, \na program would obtain a read lock on the row before reading it and release the lock immediately thereafter. \nUsing cursor stability, the program holds the read lock a little longer, until it asks to move to the next row using \nthe SQL fetch operation. At that point, the database system ﬁ rst releases the lock on the current row and then \nacquires the lock on the next row. Thus, the row that the cursor currently identiﬁ es is stable (i.e., read locked) \nwhile the program is looking at it — hence the term, cursor stability. \n Using cursor stability, a program can update the current row of the cursor without risking a race condition. \nSince it is holding a read lock on the row when it issues the update, the data manager can convert the read \nlock to a write lock. By contrast, if the program used read committed isolation, it would release its read lock \non the row immediately after executing its read operation and before issuing its write operation. Thus, two \nprograms could do this concurrently. They each read the record, then they each release their read lock, and \nthen they each update the record, which causes one program to overwrite the other. Cursor stability avoids this \noutcome. \n Given the performance beneﬁ ts of read committed isolation, many SQL database products make it the default \nisolation level, so that an application must add special keywords to obtain serializable (i.e., two-phase locked) \nbehavior. Even though the answers could be incorrect, customers don’t seem to mind very much. There is no \nsatisfactory technical explanation for this, though there is an intuitive explanation that might be true, at least for \nqueries: Queries often produce summary results about a database. If the database is being updated frequently, \nthen it doesn’t matter that there are small discrepancies based on serializability errors, because the query result is \nsomewhat outdated anyway, almost immediately after being presented to the user. Moreover, since this is only a \nsummary for decision support purposes, it doesn’t matter that the data isn’t exactly right. \n One can run queries in an even weaker locking mode, where it holds no locks at all. This is called  read \nuncommitted (or  dirty read or  Degree 1 )  isolation . In this case, a query can perform  dirty reads , where it \nreads uncommitted data — that is, data that may be wiped out when a transaction aborts. This will delay queries \neven less than read committed, at the cost of further inconsistencies in the values that are read. \n Notice that even if queries use either read committed or read uncommitted isolation, update transactions \ncan still use two-phase locking and can therefore be serializable with respect to each other. In this case, the \ndatabase state is still consistent in the sense that it is the result of a serializable execution of transactions. It’s \njust that queries might read inconsistent versions of that state. \n Most SQL database systems offer the option of running update transactions using read committed or even \nread uncommitted isolation, by executing a statement to set the isolation level. Running a transaction at one of \nthese lower isolation levels violates two-phase locking and can produce a non-serializable  execution. The per-\nformance may be better, but the result may be incorrect. For example, if two transactions each read and write  x \n(e.g., to increment  x ), then read committed isolation would allow both of them to read  x before either of them \nwrite  x . This is a non-serializable  execution and is almost certainly unsatisfactory to users since it causes one \nof the updates to be lost. \n When using degrees-of-isolation terminology, serializability often is characterized as Degree 3. This is \nsometimes called  repeatable reads , because unlike cursor stability, reading a data item multiple times returns \nthe same value since read locks are held throughout a transaction. The strongest level of isolation is called  seri-\nalizable , and it means just that: the execution of transactions must be equivalent to a serial execution. A sum-\nmary of the levels is in  Figure 6.11 . The degree-of-isolation terminology is used inconsistently in the literature. \nWe’ve glossed over many of the ﬁ ner points here. A more thorough discussion of the various terms and their \nsubtle differences appears in Berenson et al. (1995). \n Most database systems allow a database administrator to set the degree of isolation per database. Database \nsystems and transactional middleware also usually allow an application developer to override the database’s \ndegree of isolation for particular transaction programs. Some database systems allow a transaction to issue an \n6.6 Query-Update Problems  165\n",
      "content_length": 4852,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 185,
      "content": "166  CHAPTER 6 Locking\n operation that changes its degree of isolation after it has partially executed. Some systems allow the applica-\ntion to discover the degree of isolation, such as .NET ’ s System.Transactions. \n Many database systems offer degrees of isolation that are less than serializable but that don’t ﬁ t neatly into \none of the terms of the ANSI SQL standard. For example, Microsoft SQL Server offers a locking option called \nREADPAST. If a transaction is using read committed isolation and speciﬁ es the READPAST option in a SQL \nstatement, then the statement will ignore write-locked rows, rather than waiting for those locks to be released. \nThe intuition is that since the application is using read committed isolation, it isn’t expecting exact results any-\nway. So, in some cases, it is worth avoiding the delay of waiting for write locks to be released by simply skip-\nping over write-locked rows. \n We will see other examples of weaker degrees of isolation later in the chapter. \n Multiversion Data \n One good technique for ensuring that queries read consistent data without slowing down the execution of \nupdaters is  multiversion data . With multiversion data, updates do not overwrite existing copies of data items. \nInstead, when an updater modiﬁ es an existing data item, it creates a new copy of that data item, called a new \n version . So, each data item consists of a sequence of versions, one version corresponding to each update that \nwas applied to it. For example, in  Figure 6.12 a data item is a row of the table, so each version is a separate \nrow. There are three versions of employee 3, one of employee 43, and two of employee 19. \n To distinguish between different versions of the same data item, each version is tagged by the unique iden-\ntiﬁ er of the transaction that wrote it. Each version of a data item points to the previous version of that data item \n(the  “ previous transaction ” ﬁ eld in  Figure 6.12 ), so each data item has a chain of versions beginning with the \nmost recent and going back in time. In addition, the data manager maintains a list of transaction IDs of trans-\nactions that have committed, called the  commit list . \n Update transactions use two-phase locking and ignore old versions. They therefore behave as if the data-\nbase has only one version of each data item. That is, when an updater reads a data item  x , it sets a read lock on \n x and reads the latest version of  x . When it writes  x for the ﬁ rst time, it sets a write lock on  x and adds a new \nversion of  x . If it writes  x again, it simply overwrites the new version that it previously created. Commit and \nabort work in the usual way. Since update transactions use two-phase locking, they are serializable. \n The interesting capability of multiversion data is  snapshot mode , which allows a query to avoid setting \nlocks and thereby avoid locking delays. When a query executes in snapshot mode, the data manager starts \nby reading the current state of the commit list and associating it with the query for the query’s whole execu-\ntion. Whenever the query asks to read a data item, say  x , the data manager selects the latest version of  x that is \nDegree of \nIsolation\nANSI SQL Term\nBehavior\n1\nRead uncommitted\n2\nRead committed\n3\nSerializable\nDon’t set read locks\nOnly read committed data\nSerializability\n FIGURE 6.11 \n Degrees of Isolation. Degrees 1 and 2 provide less than serializable behavior, but better performance. \n",
      "content_length": 3465,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 186,
      "content": " tagged by a transaction ID on the query’s commit list. This is the last version of  x that was committed before \nthe query started executing. There is no need to lock this data because it can’t change. An updater will only \ncreate new versions and never modify an existing version. \n When a query executes in snapshot mode, it is effectively reading the state of the database that existed at \nthe time it started running. Thus, it reads a consistent database state. Any updates that execute after the query \nstarted running are issued by transactions that are not on the query’s commit list. These updates will be ignored \nby the data manager when it executes reads on behalf of the query. So although the query reads a consistent \ndatabase state, that state becomes increasingly out-of-date while it is running. \n A popular variation of this technique is  snapshot isolation , where an update transaction does not use two-\nphase locking. Instead, it executes reads using snapshot mode and executes writes without setting locks. When \nan update transaction T commits, the data manager checks that T’s updates are still valid. To do this, it checks \nwhether any data that T updated was also updated by another transaction T \u0002 that committed while T was run-\nning. If so, then T aborts, otherwise it commits. For example, suppose T updated  x and while T was running T \u0002 \nalso updated  x . This is a problem because neither T nor T \u0002 read the other transaction’s update to  x . When T tries \nto commit, the data manager checks T’s updates. If it sees that T \u0002 also updated  x and already committed, then \nthe data manager aborts T. This is sometimes called  “ ﬁ rst committer wins, ” because if two concurrent transac-\ntions try to write the same data, then the ﬁ rst one that ﬁ nishes commits while the second one aborts. \n Snapshot isolation provides stronger synchronization than read committed isolation. For example, it pre-\nvents a race condition where two transactions try to increment  x and both read  x before either of them writes  x . \nHowever, it is not serializable. For example, suppose transaction T 1 copies the value of  x into  y , so it reads  x and \nthen writes  y . Transaction T 2 does the opposite. To copy the value of  y into  x , it reads  y and then writes  x . If T 1 \nand T 2 execute concurrently using snapshot isolation, they will swap the values of  x and  y , which is not equiva-\nlent to a serial execution of T 1 and T 2 . Snapshot isolation is offered in Oracle Database, Microsoft SQL Server, \nand PostgreSQL. \n In principle, multiversion data can be used to offer read committed isolation. When a transaction reads a \ndata item, if the latest version of that data item currently is locked by an update transaction, then the transac-\ntion reads the previous version. The latter was surely written by a committed transaction, so this ensures read \ncommitted isolation. \nTransaction\nIdentiﬁer \nPrevious\nTransaction \nEmployee\nNumber \nName\nDepartment\nSalary\n174\nnull\n3\nTom\nHat\n$20,000\n21156\n174\n3\nTom\nToy\n$20,000\n21159\n21156\n3\nTom\nToy\n$24,000\n21687\nnull\n43\nDick\nFinance\n$40,000\n10899\nnull\n19\nHarry\nAppliance\n$27,000\n21687\n10899\n19\nHarry\nComputer\n$42,000\n FIGURE 6.12 \n An Example Multiversion Database. Each transaction creates a new version of each row that it updates. \n6.6 Query-Update Problems  167\n",
      "content_length": 3336,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 187,
      "content": "168  CHAPTER 6 Locking\n There is obviously some cost in maintaining old versions of data items. However, some of that cost is \nunavoidable, because recently overwritten old versions are needed to undo updates when a transaction aborts. \nIn a sense, multiversion data is making use of those old versions that are needed anyway for aborting transac-\ntions. Implementation details of transaction abort appear in the section on Database Recovery in Chapter 7. \n Multiversion Implementation Details \n There are two technicalities in making this type of mechanism run efﬁ ciently. A user of the mechanism need \nnot be aware of these issues, but for completeness, we describe them here. \n First , it is too inefﬁ cient to represent the entire commit list as a list of transaction IDs. We can keep the \ncommit list short by assigning transaction IDs sequentially (e.g., using a counter to generate them) and peri-\nodically discarding a preﬁ x of the commit list. To do this, we exploit the following observations: \n 1.  If all active transactions have a transaction ID greater than some value, say T-Oldest, and \n 2.  No new transaction will be assigned a transaction ID smaller than T-Oldest, and \n 3.  For every transaction that had a transaction ID  \u0006  T-Oldest and aborted, its updates are wiped out from \nthe database, \n 4.  Then queries don’t need to know about transaction IDs smaller than T-Oldest. \n Therefore , the commit list needs to contain only transaction IDs greater than T-Oldest. To see why, suppose \nthe data manager processes a read operation for a query on data item  x . As usual, the data manager looks for \nthe latest version of  x that is tagged by a transaction ID on the query’s commit list. If it ﬁ nds such a version, it \nreturns it, which is the standard behavior of snapshot mode. If not, then it returns the latest version  v of  x with \ntransaction ID  \u0006  T-Oldest. This is the correct version to return because none of the versions later than T-Oldest \nare on the query’s commit list, by (1) and (2) there will not be any other versions of  x with transaction ID \nbetween that of  v and T-Oldest, and by (3) version  v must be committed. To keep the list short, the data manager \nshould frequently truncate the small transaction IDs from the commit list based on the previous rule. \n One can avoid using a commit list altogether by assigning sequence numbers to transactions, where the \nsequence numbers are consistent with the effective order in which the transactions executed. This can be done by \ngetting a new sequence number when a transaction starts to commit, thereby ensuring that the sequence number \nis larger than the sequence number of every committed transaction that it conﬂ icts with. Each version is tagged \nby the sequence number of the transaction that produced it. When a query starts executing in snapshot mode, \ninstead of reading the commit list, it reads the value of the last transaction sequence number that was assigned, \nwhich becomes the sequence number for the query. When it reads a data item, it reads the version of that data \nitem with the largest sequence number tag that is less than or equal to the query’s sequence number. This type of \ntechnique is used in Oracle Database and in Microsoft SQL Server when snapshot isolation is enabled. \n A second problem is that the database can become cluttered with old versions that are useless, because no \nquery will ever read them. A version of data item  x is useless if (1) it is not the latest version of  x , and (2) all \nactive queries have a commit list that contains the transaction ID of a later version of  x , either explicitly or \nbecause its T-Oldest value exceeds the transaction ID of some later version of  x . \n In this case, no active query will read a useless version of  x ; they’ll only read later ones. No new query will \nlook at this version of  x either, because it will use an even more up-to-date commit list, which won’t include \nsmaller transaction IDs than currently running queries. So this version of  x can be discarded. \n Since useless versions are harmless, they can be discarded lazily. In some implementations, old versions of \na data item are collocated. In this case, when a data item is read, all its versions are brought into main memory. \nTherefore, when the data manager services the read operation, it can ask a background thread to scan the list of \nversions to determine if any of them are useless and, if so, delete them. \n",
      "content_length": 4474,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 188,
      "content": " 6.7  AVOIDING PHANTOMS \n In the standard locking model that we have been using in this chapter, insert and delete operations are modeled \nas write operations. We don’t treat them specially. However, inside the system, the data manager must be par-\nticularly careful with these operations to avoid nonserializable results. \n To see the potential problem, consider the database in  Figure 6.13 . The Accounts table has a row for each \naccount, including the account number, branch location, and balance in that account. The Assets table has the \ntotal balance for all accounts at each branch location. Now, suppose we execute the following sequence of \noperations by transactions T 1 and T 2 : \n 1.  T 1 : Read Accounts 1, 2, 3. \n 2.  T 1 : Identify the Accounts rows where Location  \u0003  B (i.e., 2 and 3) and calculate the sum of their bal-\nances ( \u0003 150). \n 3.  T 2 : Insert a new Accounts row [4, B, 100]. \n 4.  T 2 : Read the total balance for location B in Assets (returns 150). \n 5.  T 2 : Write Assets [B, 250]. \n 6.  T 2 : Commit. \n 7.  T 1 : Read Assets for location B (returns 250). \n 8.  T 1 : Commit. \n Transaction T 1 is auditing the accounts in location B. It ﬁ rst reads all the accounts in the Accounts table \n(step 1), adds up the balances in location B (step 2), and then looks up the Assets for location B (step 7) to \nmake sure they match. They don’t, because T 1 didn’t see the Accounts row inserted by T 2 , even though it did \nsee the updated value in the Assets table for location B, which included the result of T 2 ’s insertion. \nAccounts\nAssets\nAccount Number\nLocation\nBalance\n1\nA\n2\nB\n3\nB\n50\n50\n100\nLocation\nTotal\nA\nB\n50\n150\n FIGURE 6.13 \n Accounts Database to Illustrate Phantoms. \n6.7 Avoiding Phantoms  169\n",
      "content_length": 1735,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 189,
      "content": "170  CHAPTER 6 Locking\n This execution is not serializable. If T 1 and T 2 had executed serially, T 1 either would have seen T 2 ’s updates \nto both the Accounts table and the Assets table, or it would have seen neither of them. However, in this execu-\ntion, it saw T 2 ’s update to Assets but not its update to Accounts. \n The problem is the Accounts row [4, B, 100] that T 2 inserts. T 1 didn’t see this row when it read the Accounts \ntable, but did see T 2 ’s effect on Assets that added 100 to B’s total balance. The Accounts row [4, B, 100] is called \na  phantom , because it’s invisible during part of T 1 ’s execution but not all of it. \n The strange thing about this execution is that it appears to be allowed by two-phase locking. In the follow-\ning, we add the lock operations required by two-phase locking: \n 1.  T 1 : Lock rows 1, 2, and 3 in Accounts. Read Accounts 1, 2, 3. \n 2.  T 1 : Identify the Accounts rows where Location  \u0003  B (i.e., 2 and 3) and calculate the sum of their bal-\nances ( \u0003 150). \n 3.  T 2 : Insert a new Accounts row [4, B, 100] and lock it. \n 4.  T 2 : Lock location B’s row in Assets. Read the total balance for location B (returns 150). \n 5.  T 2 : Write Assets [B, 250]. \n 6.  T 2 : Commit and unlock location B’s row in Assets and row [4, B, 100] in Accounts. \n 7.  T 1 : Lock location B’s row in Assets. Read Assets for location B (returns 250). \n 8.  T 1 : Commit and unlock location B’s row in Assets and rows 1, 2, and 3 in Accounts. \n Is it really true that two-phase locking doesn’t guarantee serializability when there are insertion operations? \nFortunately not. There is some hidden behavior here that would cause an extra lock to be set and that isn’t shown \nin the execution. It all hinges on how T 1 knew there were exactly three rows in the Accounts table. There must \nhave been a data structure of some kind to tell it: an end-of-ﬁ le marker, a count of the number of rows in the ﬁ le, \na list of pointers to the rows in the ﬁ le, or something. Since it read that data structure to determine that it should \nread exactly rows 1, 2, and 3, it had to set a read lock on that data structure. Moreover, since T 2 added a row to the \nAccounts table, it had to lock that data structure too, in write mode, so it could update it. It would be prevented \nfrom doing so by T 1 ’s read lock on that data structure, and thus the previous execution could not occur. \n So , the phantom problem is not a problem, provided that the data manager sets locks on all shared data it \ntouches, including system structures that it uses internally on behalf of a transaction’s operation. \n Performance Implications \n This example brings up yet another common scenario that leads to performance problems, one that’s closely \nrelated to the query-update problems we saw in the previous section. The example has one transaction, T 1 , that \nscans a ﬁ le (essentially a query), and another transaction, T 2 , that inserts a row and therefore is blocked by the \nscan operation. Since T 1 needs to compare the values it reads in the Accounts table to the values it reads in the \nAssets table, it must run in a serializable way. Read committed locking isn’t good enough. This means that T 1 \nmust lock the entire table in read mode, which delays any update transaction that wants to write an existing \nrow or insert a new one. This reduction in concurrency is bound to cause some transaction delays. \n Database systems that support SQL reduce this problem somewhat by locking ranges of key values. In the \nexample, since T 1 only wants to read rows in location B, the system would set a key-range lock on rows with \n “ Location  \u0003  B. ” Transaction T 2 would have to get a key-range lock on  “ Location  \u0003  B ” to insert its new row, \nso it would be blocked as before. But other update transactions that operate on rows in other locations would \nbe permitted to run, because they would get key-range locks on other key ranges. That is, a key-range lock on \n “ Location  \u0003  B ” does not conﬂ ict with one on  “ Location  \u0003  A. ” \n Key -range locking works well in SQL because the WHERE clause in SQL has clauses like \n “ Accounts.Location  \u0003  B, ” which gives the system a strong hint about which lock to set. In an indexed ﬁ le \n",
      "content_length": 4253,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 190,
      "content": " system, such as COBOL ISAM implementations, it is much harder to do, since the operations issued by the \nprogram don’t give such strong hints to the ﬁ le system to ﬁ gure out which key-range locks to set. For this \nreason, key-range locking is widely supported in SQL database systems, but not in many other kinds. \n Although key-range locking is effective and relatively inexpensive, it is not free. Therefore, some systems \noffer a degree of isolation that guarantees serializability except for phantoms. Thus, it is in between read com-\nmitted and serializable. This is called  repeatable read in Microsoft SQL Server and in the ANSI SQL 92 stan-\ndard, and  read stability in IBM DB2 UDB. \n 6.8  OPTIMISTIC CONCURRENCY CONTROL \n In addition to the hot spot technique described in Section 6.5, optimistic concurrency control is useful in situ-\nations where data is cached outside the data manager. For example, a client or middle-tier server may cache \ndata that it retrieves from a data manager that resides on a remote server. In such cases, the cached data may \nbe updated in the data manager at the remote server (e.g., by other clients) without the cache being told about \nit. Therefore, any transaction that reads the cached data is at risk to use out-of-date data that can lead to a non-\nserializable  execution. As in the hot spot method, the solution is to check at commit time whether the cached \ndata has changed in the data manager in a way that invalidates the transaction’s earlier reads. If so, the transac-\ntion must abort. \n One scenario where this comes up is interactive transactions, where a user is involved in looking at data \nbefore deciding whether or how to update it. Since the user may look at the data for several minutes before \ndeciding, it is impractical to lock the data between the time it’s read and the time it’s updated. Therefore, the \napplication that interacts with the user executes one transaction to read the data and later runs a second trans-\naction to perform the user’s updates. In between the two transactions, the user decides which updates to per-\nform. Since the data isn’t locked between the reads and writes, an optimistic approach can be used. Namely, \nthe update transaction includes the values of the data items that were read earlier and on which the update \ndepends. The update transaction checks that the values that were read still have the same values in the data \nmanager. If so, then the transaction can perform its updates. \n The effect is as if the transaction had set read locks on the data during the ﬁ rst read-only transaction and held \nthem until the update transaction ran. Of course, since it didn’t hold the read locks that long, the update transac-\ntion may ﬁ nd that some of the data items that were read have changed, and therefore the transaction must abort. \nIn that case, the application needs to get involved by rereading the data that it read during the ﬁ rst transaction, \ndisplaying those new values to the user and asking the user if her previous updates are still what she wants. \n For example, suppose a building contractor is accessing an on-line supplier from a web browser over the \nInternet. The contractor wants 20 windows of a certain size, for delivery within two weeks. He issues a request \nfor catalog information on the appropriate type of windows. He shows the windows to his customer and, after \nsome discussion, they select a particular window. That purchase request should include not only the part num-\nber of the window to be purchased but also the delivery date. The update transaction that runs on the supplier’s \nserver rereads the promised delivery date and compares it to the one in the request; this is to validate the earlier \noptimistic read of the delivery date. If the delivery date can no longer be met, the application returns an error, \nelse it completes the purchase as requested. \n Notice that it’s up to the application to ﬁ gure out the data items that were read earlier and on which the \nupdate depends. In the previous example, the application needs to know that the update only depends on the \ndelivery date, not on all the other catalog information that is displayed to the contractor. \n Still , under certain assumptions, it’s possible for the application to ﬁ gure out what data items to validate \nwithout any hints from the application. For example, in Microsoft SQL Server, a cursor (which contains the \n6.8 Optimistic Concurrency Control  171\n",
      "content_length": 4473,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 191,
      "content": "172  CHAPTER 6 Locking\n result of a SQL query) can be declared as  Optimistic With Values . In this case, the database rows that are \nreturned in the cursor are not read-locked. Instead, if an application updates a row in the cursor, both the old \nand new value of the row are sent to the database system. The system processes the update by setting a lock on \nthe row and then checking whether the current value of the row equals the old value that was included with the \nupdate. If so, then the new value of the row is installed. If not, then the update is rejected and an exception is \nreturned. A similar option called  Optimistic With Versions is available, where each row is tagged by a \ntimestamp, which is updated every time the row is modiﬁ ed. So, instead of sending the old value of the row with \nthe update, only the old timestamp needs to be sent. If the timestamp has changed, then the update is rejected. \n Note that this SQL Server mechanism implicitly assumes that the update to the row depends only on the \nprevious value of the same row. If the update depended on the previous value of some other rows, then another \nconcurrency control technique would need to be used on those other rows. For example, those rows could be \nread using the serializable isolation level or the application could reread those rows using serializable isolation \nlevel at the time it does the update and check that their values didn’t change. \n 6.9  B-TREE LOCKING \n All database systems use some form of index to speed up content-based retrieval of records. An index is a \nmapping from key values to physical location. For example, in a relational database system an index maps col-\numn values to rows; in  Figure 6.13 an index on Location values in the Accounts table would map the column \nvalue  “ A ” to the ﬁ rst row and  “ B ” to the second and third rows. When a user submits a query to retrieve rows \nthat have a given ﬁ eld value, such as Location  \u0003  “ B, ” the database system can use the index to access exactly \nthe desired rows, instead of having to scan all rows of the table to ﬁ nd the desired ones. \n First , we explain how indexes work. Then we discuss techniques to avoid the special locking bottlenecks \nthat can arise when accessing indexes. \n B \u0003  Trees \n The most popular data structure used for implementing an index in a database system is the B-tree. A  B-tree \nconsists of a set of pages organized as a tree. The  leaf pages (i.e., those that don’t point to other pages in the \ntree) contain the data being indexed, such as rows of a table. The remaining pages, called  internal nodes , are \ndirectories of key values that are used to guide a search. \n If the internal nodes contain the data that is associated with the keys, then the tree is called a B-tree. On the \nother hand, if the internal nodes contain  only key values and not the associated data, then it is called a  B \u0005  tree . \nFor the most part, our discussion applies to both B-trees and B \u0005 trees. However, we will use B \u0005 trees in all of \nour examples since they are more commonly used in practice. \n Each page contains a sorted sequence of key values, which subdivides the range of possible key values into \nsubranges. So, a sequence of  n key values [ k 1 ,  k 2 ,  … ,  k n ] creates  n  \u0005  1 subranges: one subrange for key values \nless than  k 1 , one for key values from  k 1 to  k 2 ,  … , one for key values from  k n  \u0007 1 to  k n , and one for key values \ngreater than or equal to  k n . Associated with each subrange is a pointer to the root of a subtree that contains all \nthe keys in that subrange. \n For example, the B \u0005 tree in  Figure 6.14 has key values that are non-negative integers. The root page, P 0 , \ncontains the sorted sequence of key values 125, 490. (In the terminology of the previous paragraph,  n  \u0003  2.) \nThe pointer before 125 points to the root page of a subtree that contains all the keys in the range [0, 125) (i.e., \nzero up to but not including 125). Similarly, the pointer between 125 and 490 points to a subtree containing the \nrange [125, 490), and the pointer after 490 points to a subtree containing the range [490,  \b ). (Only the subtree \n",
      "content_length": 4173,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 192,
      "content": " for the range [125, 490) is shown explicitly.) Thus, the root page partitions the set of all key values into three \nranges: [0, 125), [125, 490), and [490,  \b ). \n Below the root, each page subdivides its key range, which is deﬁ ned by its parent. Looking again at the ﬁ g-\nure, we see that page P 1 subdivides the range [125, 490), which is deﬁ ned by its parent, P 0 . The subranges con-\nsist of [125, 213), [213, 352), and [352, 490). Notice that P 1 ’s ﬁ rst subrange is [125, 213), not [0, 213), because \nP 1 subdivides the range [125, 490), not [0, 490). Similarly, the last subrange is [352, 490), not [352,  \b ). The \nleaves of the tree contain the actual key values, such as 125, 145, and 199 in the leaf P 2 . These key values may \ninclude the data records themselves (such as rows in the Accounts table) or pointers to those records. \n To search for a given key value  k , you start by examining the root page and ﬁ nding the key range that con-\ntains  k . You then follow the pointer associated with that key range to another page. Then repeat the process, \nmoving down the tree. For example, to search for key value 145, you search the root and discover that range \n[125, 490) contains 145. So you follow the pointer to P 1 . In P 1 , you ﬁ nd that key range [125, 213) contains \n145, so you follow the pointer to P 2 . Searching page P 2 , you ﬁ nd key 145. To search for key 146, you would \nfollow the same sequence of pages. However, in that case, when reaching P 2 , you would ﬁ nd that the page \ndoesn’t contain 146. Since this is a leaf page, there is nowhere else to look, so you would conclude that 146 \nis not contained in the index. Notice that in all cases, the number of pages that are read equals the number of \nlevels of the tree, that is, one more than the number of pointers that need to be followed to get from the root to \na leaf. \n The B \u0005 tree effectively sorts the keys, as you can see in the leaves P 2 , P 3 , and P 4 in the ﬁ gure. You can \ntherefore get all the keys in a given range by searching for the key at the low end of the range and then scan-\nning the leaves in order until you reach the high end of the range. For example, to ﬁ nd all keys in the range \n160 to 360, you search for key 160, which takes you to page P 2 . Then you scan pages P 2 , P 3 , and P 4 . When you \nreach key value 487 on P 4 , which is the ﬁ rst key value greater than 360, you know you have found all keys in \nthe desired range. \n The B \u0005 tree in  Figure 6.14 is artiﬁ cially small, so it can ﬁ t on a printed page. In practice, each B \u0005 tree \npage is the size of a disk page and therefore can hold hundreds of keys. For example, if a page is 8  K bytes, a \nkey is 8 bytes, and a pointer is 2 bytes, then a page can hold up to 819 keys; therefore, a three-level B \u0005 tree \ncan have up to 820 2  \u0003  672,400 leaves. If each leaf holds up to 80 records, that’s over 5.3 million records in all. \nIf the tree has four levels, then it can hold up to about 4.4 billion records. As you can see from these numbers, \nit’s very rare for a B \u0005 tree to have more than four levels. \nsubtree\nwith keys\n<125 \nsubtree\nwith keys\n ≥490 \nP1\nP2\nP3\nP4\n125\n213\n217\n320\n352\n487\n145\n199\nP0\n125\n490\n213\n352\n FIGURE 6.14 \n A B \u0003 Tree. Page P 0 is the root and P 2 , P 3 , and P 4 are leaves. Each of the two triangular subtrees is an abbreviation for a \ncombination of pages like P 1  – P 4 . \n6.9 B-Tree Locking  173\n",
      "content_length": 3414,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 193,
      "content": "174  CHAPTER 6 Locking\n B \u0005 trees are intended to live on disk with a portion of them buffered in main memory. The root is always \ncached in main memory and usually the level below the root is cached too. Levels 3 and 4 are more problem-\natic. How much of them are cached depends on how much memory is available and how frequently the pages \nare accessed; that is, whether it’s worth caching them. However, even if levels 3 and 4 are not cached at all, to \nsearch for a key, only two disk pages need to be accessed. It’s pretty amazing, if you think about it — you can \nsearch for a key in a ﬁ le of 4 billion records and are guaranteed to ﬁ nd it in two disk accesses. \n This great performance of a B \u0005 tree depends on the tree being wide and ﬂ at. If the tree were thin and deep —\n that is, if it had many levels — then the performance would be worse. You would have to read many more pages \nto search from the root to a leaf. The main trick that makes the B \u0005 tree structure so attractive is that its update \nalgorithms are able to keep the tree wide and ﬂ at. \n B \u0003 Tree Insertions \n To insert a key value into a B \u0005 tree, you simply search for that key value. The search procedure identiﬁ es the \npage where that key value should be stored, so that’s where you store it. For example, to insert key value 353 \nin  Figure 6.14 , the search would take you to page P 4 , so you add the new record to that page. \n Inserting 353 was straightforward because there was extra space on that page. What if the desired page is \nalready full? For example, suppose each leaf can hold at most three records and you want to insert key value \n225. The search procedure takes you to page P 3 , which is full. In this case, you split the page in half. That is, you \nallocate another page, say P 5 , from free space and distribute the keys of P 3 plus 225 evenly between P 3 and P 5 , as \nshown in  Figure 6.15 . By adding page P 5 , you have effectively split the range [213, 352) into two ranges: [213, \n225) and [225, 352). This splitting of range [213, 353) must be recorded in P 3 ’s parent, P 1 , which is shown in \n Figure 6.15 . \n The split shown in  Figure 6.15 assumes that there is space in P 1 to store the extra range. If there isn’t enough \nspace, then since it’s full, P 1 would need to be split, just like P 3 was. The result is shown in  Figure 6.16 . In this \ncase, P 1 is split into P 1 and P 6 . This causes another key range to be propagated up to the root, P 0 . But since the \nroot is full, it too must be split into P 0 and P 7 . Thus, a new root, P 8 , needs to be added, which divides the total \nkey range between P 0 and P 7 . \n Notice that the tree stays wide and ﬂ at as it grows. The technical term is  “ balanced. ” It’s balanced in the \nsense that all leaves are the same distance from the root. \nsubtree\nwith keys\n<125 \nsubtree\nwith keys\n ≥490 \nP1\n225\n352\nP2\nP3\nP5\nP4\n125\n213 217\n225 320\n352 487\n145 199\nP0\n125\n490\n213\n FIGURE 6.15 \n A B \u0003 Tree After a Split. This shows the B \u0005 tree of  Figure 6.14 after inserting key 225, assuming P 1 can hold 3 keys and \nP 3 can hold 3 records. \n",
      "content_length": 3102,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 194,
      "content": " There are many variations of B-trees in the technical literature. The bibliographic notes provide entry \npoints for the interested reader. \n Tree Locking \n Suppose a transaction is executing a search for key value  k 1 in a B \u0005 tree. The search starts by reading the root \npage and scanning it to ﬁ nd the key range that contains  k 1 . Since it is reading all of the root, it needs to set a \nread lock on the entire root page. Similarly, it needs to lock the other pages that it searches, as it travels down \nthe tree toward the leaf that contains  k 1 . These read locks prevent any updates to the locked pages. If several \nactive transactions are using the B \u0005 tree, then large portions of the tree are read locked, which potentially \nblocks many update transactions. \n This locking bottleneck can be avoided by exploiting the fact that all transactions traverse the B \u0005 tree from \nroot to leaf. Consider a simple tree consisting of a page P (the parent), child C of P, and a child G of C (G is the \ngrandchild of P). Instead of holding read locks on all pages it touches, it is actually safe for a transaction T i to \nrelease its read lock on P after it has set a read lock C, where C covers the key range of interest. This seems more \nthan a little strange, since we have made such a big point in this chapter of being two-phase locked. If T i contin-\nues searching down the tree to lock G, then T i has broken two-phase locking — it unlocked P and later obtained a \nlock on G. However, in this special case of traversing a tree, breaking two-phase locking in this way is safe. \n The important point is that T i acquired its lock on C  before releasing its lock on P. It descends through the \ntree much like climbing down a ladder, placing one foot ﬁ rmly on the next lower rung before lifting the other \nfoot from the higher rung. This is called  lock coupling , or  crabbing (by analogy to the way a crab walks). \nThe effect is that no transaction that is obtaining conﬂ icting locks can pass T i on the way down, because T i is \nalways holding a lock on some page on the path to its ﬁ nal destination. \n A bad case would be that some transaction T k got a write lock on page P after T i released its read lock on P, \nbut got a write lock on G before T i got its read lock on G. That would violate serializability because it would \nsubtree\nwith keys\n<125 \nsubtree\nwith keys\n ≥490 \nP1\nP6\nP7\nP0\nP2\nP3\nP5\nP4\n125\n213\n213\n125\n490\n352\n217\n225 320\n352 487\n145 199\nP8\n225\n FIGURE 6.16 \n A B \u0003 Tree After a Recursive Split. This shows the B \u0005 tree of  Figure 6.15 , after inserting key 225, assuming internal nodes \ncan hold at most two keys. Thus, P 1 must split into P 1 and P 6 , which in turn causes P 0 to split into P 0 and P 7 , which causes \na new root P 8 to be created. \n6.9 B-Tree Locking  175\n",
      "content_length": 2804,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 195,
      "content": "176  CHAPTER 6 Locking\n appear that T k came after T i with respect to P and before T i with respect to G. But this can’t happen. If T k gets \na conﬂ icting lock on P after T i releases its lock on P, then lock coupling ensures that T k will follow T i on the \nentire path that T i takes down the tree. \n The correctness argument earlier assumes that each transaction gets the same kind of lock on all pages. If it \nswitches between two types of locks, then the argument breaks down. For example, if T k sets a write lock on P, \na read lock on C, and a write lock on G, then a non-serializable  execution could arise as follows: \n 1.  T i read locks P, T i read locks C, T i unlocks P. (At this point, T i has a read lock on C.) \n 2.  T k write locks P. (So T k follows T i at P.) \n 3.  T k read locks C. (T i and T k both have read locks on C.) \n 4.  T k unlocks P, T k write locks G, T k unlocks C, T k unlocks G. (T k arrived ﬁ rst at G, then ﬁ nishes up.) \n 5.  T i read locks G. (T i follows T k at G.) \n Since T k follows T i at P (step 2) and T i follows T k at G (step 5), the result isn’t serializable. In this case, \nwhere a transaction switches between lock types, lock coupling isn’t enough. A commonly used solution is to \ndisallow transactions from getting a weaker lock when traversing down the tree. \n After T i locks the leaf page L that it’s looking for, it can release its lock on L’s parent. At this point, it is \nholding a lock on only one page, L. In terms of locking performance, this is much better than before, where T i \nwould have held a lock on every page on the path from the root to L. Since T i is only locking L, update trans-\nactions can run concurrently as long as they aren’t trying to update a key on L. \n Insertions cause a problem for lock coupling, due to page splits. Suppose a transaction executes an insert \nof key value  k 2 into the B \u0005 tree. The insert begins by searching down the tree for the leaf that should contain \n k 2 , setting read locks on pages, just like a B \u0005 tree search. When it ﬁ nds the leaf L, it sets a write lock on it, \nso that it can insert  k 2 . If L is full, then it must be split, which requires that a new key be added to L’s parent. \nHowever, at this point, the transaction doesn’t own a lock on L’s parent. Reacquiring the lock would break the \nlock coupling protocol and thereby allow a non-serializable  execution to occur. \n One solution is to require that the insert procedure obtain write locks as it traverses down the tree. Assume \nit holds a lock on page P and has just acquired a lock on P’s child C. At this point, it checks whether C is full. \nIf not, then it releases its lock on P. If so, then it retains the lock on P because it may have to split C, in which \ncase it will need to update P. This solution is rather expensive, because the insert needs to set write locks from \nthe beginning of its search, including the root, an obvious bottleneck. An alternative solution is to search down \nthe tree using read locks only, keeping track of which pages are full. If the desired leaf turns out to be full, then \nrelease its lock and start traversing down from the root again. This time, the insert procedure holds write locks \non all the pages that need to be updated, which include the leaf L and its parent P, plus P’s parent if P is full, \nplus P’s grandparent if P’s parent is full, and so on. \n The B-Link Optimization \n Lock coupling is a signiﬁ cant performance boost over two-phase locking for B \u0005 trees. However, we can do \neven better by adding to the B \u0005 tree structure a sideways link from each page to the next page at the same \nlevel in key-sequence order. For example, the sideways links in  Figure 6.17 are shown as horizontal dashed \nlines. Notice that links are not only between siblings; that is, between pages that have a common parent. Links \nmay also connect cousins, such as the pointer from P 7 to P 2 . Thus, only the last page on each level has no side-\nways link; in the ﬁ gure, that’s P 4 on level 3, P 1 on level 2, and P 0 on level 1. \n These sideways links, called  B-links , enable the search and insert procedures to hold only one page lock \nat a time, which improves concurrency over lock coupling. The optimization exploits our knowledge about the \nkinds of updates to a B \u0005 tree that can alter its structure, namely page splits. \n",
      "content_length": 4352,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 196,
      "content": " When searching down a B \u0005 tree, the search procedure only holds a lock on one page at a time. So, for example, \nsuppose T 1 executes a search for key 94. The search procedure begins by locking P 0 , selecting the range [0, 125) as \nthe one that contains 94, getting the associated pointer to P 5 , and releasing its lock on P 0 . At this point, it holds no \nlocks. It repeats the process on P 5 by locking P 5 , selecting the range [56, 125), getting the associated pointer to P 7 , \nand releasing its lock on P 5 . Finally, it locks P 7 , ﬁ nds the record with key 94, and releases its lock. \n This search procedure looks rather dangerous, because at certain points in its execution, it is holding a \npointer to a page that isn’t locked. For example, after unlocking P 5 , it’s holding a pointer to P 7 , which is not \nlocked. What if another transaction somehow makes that pointer to P 7 invalid before the search procedure fol-\nlows the pointer? \n Here is where our knowledge of B \u0005 tree behavior comes in. Assume that B \u0005 tree pages are never deleted, \nwhich is a common practice since databases rarely shrink signiﬁ cantly. In that case, the only way that P 7 can \nchange in a way that affects the search is if another transaction splits P 7 . For example, suppose that when T 1 ’s \nsearch holds a pointer to P 7 but no locks, another transaction T 2 inserts key 60 on P 7 causing P 7 to split, yield-\ning the tree in  Figure 6.18 . Let’s look at the split of P 7 in more detail: T 2 write locks P 7 , allocates a new page \nP 8 , copies P 7 ’s link (to P 2 ) into P 8 (so P 8 points to P 2 ), moves records 94 and 108 from P 7 to P 8 , inserts record \n60 in P 7 , updates P 7 ’s link to point to P 8 , and unlocks P 7 . At this point, P 5 is inconsistent with P 7 and P 8 , so T 2 \nmust update P 5 to add key 94 and a pointer to P 8 . However, this update of P 5 has no effect on T 1 , which already \nread P 5 and is holding a pointer to P 7 . So, now that T 2 has unlocked P 7 , T 1 can push ahead and lock P 7 and read \n56\n213\n352\n125\nP4\nP3\nP2\nP7\nP6\nP5\nP1\nP0\n352 487\n213 217 320\n125 145 199\n56\n94 108\n6\n14\n55\n FIGURE 6.17 \n A B \u0003 Tree with Sideways Pointers. Each page points to the next page at the same level in key sequence order. \n56\n94\n213\n352\n125\nP3\nP2\nP8\nP7\nP6\nP5\nP1\nP0\n213 217 320\nP4\n352 487\n125 145 199\n94 108\n56\n60\n6\n14\n55\n FIGURE 6.18 \n The B \u0003 Tree of Figure 6.17 After Inserting 60 . Page P 7 is split into P 7 and a new page P 8 , links are updated, and the \nboundary key 94 is inserted in page P 5 . \n6.9 B-Tree Locking  177\n",
      "content_length": 2548,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 197,
      "content": "178  CHAPTER 6 Locking\n it. Of course, record 94, which T 1 is looking for, isn’t in P 7 anymore. Fortunately, T 1 can ﬁ gure this out. It sees \nthat the largest key in P 7 is 60. So it’s possible that record 94 got moved during a split and can be found on the \nnext higher page. This is where the link is used. Instead of giving up after failing to ﬁ nd 94 in P 7 , T 1 follows \nthe link to the next higher page, looks there for key 94, and ﬁ nds it. \n Suppose that T 1 was looking for key 95 instead of 94. When it follows the link to P 8 , and fails to ﬁ nd 95 \non P 8 , it looks for the largest key on P 8 , which in this case is 108. Since 108 is larger than 95, T 1 knows that \nthere’s no point in following P 8 ’s link to P 2 , since all keys in P 2 are larger than 108. \n 6.10  MULTIGRANULARITY LOCKING \n At the end of Section 6.2, we brieﬂ y explained how a data manager can set locks at different granularities, such \nas database, ﬁ le, and record granularity. In this section, we expand on the details. Knowledge of these details \ncan be helpful in understanding the performance characteristics of locking in data managers that use it. \n As we explained earlier, the main problem in locking at different granularities is determining when locks \nat different granularities conﬂ ict. For example, if transaction T 1 owns a write lock on ﬁ le  F , we would like T 2 \nto be prevented from setting a read lock on record  R in  F . However, as far as the lock manager is concerned, \nlocks on  F and  R are completely independent, so the lock manager would allow them both to be set. \n The trick in multigranularity locking is to require that before setting a ﬁ ne grain lock on a data item  x , a \ntransaction must ﬁ rst set a weak lock, called an  intention lock , on every coarse grain data item that contains  x . \nIntention locks conﬂ ict with read and write locks. In the previous example, since  F contains  R , T 2 would need \nto set an  intention read lock on  F before it tried to set a read lock on  R . The intention read lock on  F conﬂ icts \nwith T 1 ’s write lock on  F , so the lock manager recognizes the conﬂ ict and T 2 is delayed, as desired. \n To know which intention locks to set for a given data item  x , a data manager must know which data items \ncontain  x . This knowledge is captured in a containment hierarchy, called a  lock type graph . For example, a \nsimple lock type graph for a SQL database system is shown in  Figure 6.19a . This graph says that each row is \ncontained in a table, and each table is contained in a database. So, to set a lock on a row  R , the data manager \nneeds to set an intention lock on the table and database that contain  R . \n Locks must be set in root-to-leaf order, as deﬁ ned by the lock type graph. For example, consider the  lock \ninstance graph in  Figure 6.19b , which represents a database that conforms to the lock type graph in  Figure 6.19a . \nTo set a lock on record R 3 , a transaction T 1 ﬁ rst would have to set an intention lock on database DB A , then set an \nintention lock on table Tbl S2 . If T 1 disobeyed the root-to-leaf order and set a lock on R 3 before setting those inten-\ntion locks, it might ﬁ nd that another transaction T 2 already owns a lock on Tbl S2 that prevents T 1 from setting the \nintention lock. Thus, T 1 would have a lock on R 3 and T 2 would have a lock on the table Tbl S2 that contains R 3 , \nwhich is exactly the situation we’re trying to avoid. Locking from root to leaf prevents this bad outcome. \n Note that the hierarchy is only conceptual. It need not be physically stored. That is, the data manager \ndoesn’t need a data structure that represents the lock type graph. Rather, the data manager can rely on hard-\ncoded knowledge of the graph to decide which locks to set. \n Each lock type has a corresponding intention lock type. That is, there are  intention-to-write ( iw ) and  intention-\nto-read ( ir ) lock types, which correspond to the write and read lock types, respectively. Before setting a read lock \non a data item  x , a transaction must ﬁ rst set an ir lock on  x ’s ancestors; similarly, for setting a write lock. \n The lock conﬂ ict rules for intention locks are shown in  Figure 6.20 . To understand their meaning, consider \na data item  x (e.g., a table) and data items  y and  z that are contained by  x (e.g., two rows in table  x ): \n ■  r is compatible with ir, because it’s alright if T 1 owns a read lock on  x while T 2 owns an ir lock on  x and \na read lock on, say,  y . \n",
      "content_length": 4513,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 198,
      "content": " ■  r is incompatible with iw, because if T 1 owns a read lock on  x , then T 2 should not be allowed to own a \nwrite lock on  y . T 2 ’s attempt to get an iw lock on  x (before locking  y ) will conﬂ ict with T 1 ’s read lock. \n ■  w is incompatible with ir or iw, because if T 1 owns a write lock on  x , then T 2 should not be allowed to \nown a read or write lock on  y . \n ■  ir and iw locks are compatible with each other, because they indicate only that ﬁ ner grain locks are being \nheld, possibly on different data items. Suppose T 1 and T 2 own an ir and iw lock on  x , respectively. This \nmeans T 1 plans to own a read lock on some  y contained in  x and T 2 plans to own a write lock on some \n z contained in  x . This is a problem only if  y  \u0003  z . But in that case T 1 and T 2 will conﬂ ict when they both \ntry to lock  y . It would be premature to disallow T 1 and T 2 from owning their intention locks on  x since in \nmost cases they will lock different ﬁ ne grained items within  x . \n The lock type  read-with-intention-to-write ( riw ) is designed for transactions that are scanning a large \nnumber of data items but updating only some of them, such as executing a SQL Update statement. Such a \ntransaction would have to own both an r and iw lock on the same data item, such as a SQL table. It simpliﬁ es \nthe lock manager if each transaction is allowed to hold at most one lock on each data item. Therefore, the two \nDatabase\nTable\nRow\na. A lock type graph\nDBA\nTblS1\nTblS2\nR1\nR2\nR3\nR4\nR5\nb. A lock instance graph\n FIGURE 6.19 \n Graph That Drives Multigranularity Locking. The lock type graph describes the hierarchy of granularity of object types \nthat can be locked. The lock instance graph shows instances of those types. \ny\ny\ny\nn\nn\nn\nn\nn\nn\ny\nr\nw\nir\niw\nriw\nn\nn\ny\nn\nn\nn\ny\ny\nn\nn\nn\ny\nn\nn\ny\nLock Type Requested\nr\nw\nir\niw\nriw\nLock Type Held\n FIGURE 6.20 \n Lock Type Compatibility Matrix. Each entry says whether the lock type requested can be granted given that another \ntransaction holds the lock type held. \n6.10 Multigranularity Locking  179\n",
      "content_length": 2062,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 199,
      "content": "180  CHAPTER 6 Locking\n lock types, r and iw, are combined into one, riw. Notice that the riw lock type is compatible with another lock \ntype  lt if and only if both r and iw are compatible with  lt . In  Figure 6.20 only lock type ir has this property. \n So far, we have treated lock instance graphs that are trees. Trees have the nice property that each data item \n(except the root) has exactly one parent. Often, we need to handle lock instance graphs that are directed acyclic \ngraphs (DAGs), where a data item may be contained by two or more parents. This requires modifying the rules \nfor setting intention locks, because setting an intention lock on a parent of a data item  x does not prevent other \ntransactions from setting a conﬂ icting coarse grain lock on a different parent of  x . \n Let ’s look at the most common place where this arises, namely key-range locking, which we used in Section \n6.7 to avoid phantoms. In key-range locking, key-range is another type of object that can be locked, as shown \nin the lock type graph in  Figure 6.21a . If a table uses multiple keys, then each row is in multiple key ranges. For \nexample, in  Figure 6.22 suppose the Customer and Location columns are used as keys in the Accounts table. \nThen each row is contained in two different key ranges, one for each key. For example, Account 1 is in the \nCustomer key range for  “ Eric ” and the Location key range for  “ A. ” Suppose that transaction T 1 sets an iw lock \non DB A , Accounts, and the key range Customer  \u0003  “ Eric ” and then sets a write lock on Account 1. This does not \nprevent another transaction T 2 from setting an ir lock on DB A and Accounts and setting a read lock on the key \nrange Location  \u0003  “ A. ” Since the key range Location  \u0003  “ A ” covers the row for Account 1, this means that T 2 \nimplicitly has a read lock on Account 1, which conﬂ icts with T 1 ’s explicit write lock on Account 1. This is an \nexample of the problem described in the previous paragraph: a transaction holds an intention lock on one parent \nof  x (i.e., on key range Customer  \u0003  “ Eric, ” which is a parent Account 1), but another transaction holds a con-\nﬂ icting lock on a different parent of  x (i.e., key range Location  \u0003  “ A ” ). \nAccount Number\nCustomer\nLocation\nBalance\nEric\nEric\nJane\nAlex\n1\n2\n3\n4\nA\nB\nB\nC\n50\n50\n100\n75\n FIGURE 6.22 \n Example Database. This database corresponds to the lock instance graph of  Figure 6.21b . \nDBA\nAccounts\nAccount 1 \nb. A lock instance graph\na. A lock type graph\nDatabase\nTable\nKeyRange\nRow \nCust \u0003\n“Eric” \nCust \u0003 \n“Jane” \nLoc \u0003\n“A”\nLoc \u0003\n“B”\nLoc \u0003\n“C”\nCust \u0003\n“Alex”\nAccount 2\nAccount 3\nAccount 4\n FIGURE 6.21 \n A DAG That Drives Multigranularity Locking. This extends the graphs of  Figure 6.19 , to allow each row to have more than \none parent, which in this case are key ranges. \n",
      "content_length": 2827,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 200,
      "content": " To avoid this problem, we modify the multigranularity locking protocol for write locks. We require that \nto set a write lock or iw lock on an object  x , a transaction must have an iw lock on  every parent of  x . In the \nexample, this means that T 1 needs an iw lock on the two key ranges that are parents of Account 1, namely, \nCustomer  \u0003  “ Eric ” and Location  \u0003  “ A. ” The iw lock on Location  \u0003  “ A ” would conﬂ ict with T 2 ’s read lock on \nLocation  \u0003  “ A. ” So only one of them can lock the range, thereby avoiding the situation where T 1 and T 2 own \nconﬂ icting locks on Account 1. \n Typically , key range locks are implemented by setting locks on physical index entries. This assumes that \neach lockable key corresponds to an indexed column. For example, to set a lock on Customer  \u0003  “ Eric, ” there \nwould need to be an index on the Customer column of the Accounts table. The procedure to set the lock searches \nfor  “ Eric ” in the index and sets the appropriate lock on the index record for Customer  \u0003  “ Eric. ” A procedure to \nﬁ nd the account record for  “ Eric ” needs to look up  “ Eric ” in the index anyway. \n 6.11  LOCKING NESTED TRANSACTIONS \n In this section we discuss locking behavior that is needed to support the nested transaction model described in \nSection 2.2. Recall that nested transactions behave as follows: \n 1.  If a program is already executing inside a transaction T and issues a Start command, then Start creates \na subtransaction S of T. If the program is executing inside a subtransaction S, then Start creates a sub-\ntransaction of S. Thus, there is a  “ nesting hierarchy ” among transactions, which can be of any depth. \n 2.  If a program is not already executing inside a transaction and issues a Start command, then Start creates \na new, independent top-level transaction, which is not a subtransaction of another transaction. \n 3.  If a subtransaction S aborts, then all of S’s operations are undone, including all its subtransactions. \nHowever, this does not cause S’s parent P to abort. It simply notiﬁ es P that S aborted. \n 4.  If a subtransaction S commits, S no longer can issue operations. S’s parent is notiﬁ ed of S’s commit. \n 5.  While a subtransaction S is executing, data items that it has updated are isolated and hence not visible \nto other transactions and subtransactions (just like the ﬂ at transaction model). \n Rule (5) is a requirement on the isolation behavior of nested transactions. If two-phase locking is the mech-\nanism used to obtain isolation, then it needs to be modiﬁ ed slightly in order to satisfy rule (5). \n \n i.  Top-level transactions set locks in the same way as they do in a non-nested transaction  model. \n \n ii.  When a subtransaction S commits or aborts, its locks are inherited by S’s parent, which is either a top-\nlevel transaction or another subtransaction one level higher in the nesting hierarchy. \n \n iii.  A request to lock a data item  x on behalf of a subtransaction S is granted if the only conﬂ icting locks on \n x , if any, are held by ancestors of S in the nesting hierarchy. \n The effect of (ii) and (iii) is that subtransactions of the same parent are two-phase locked with respect to \neach other and hence are serializable with respect to each other. Therefore, even though subtransactions may \nexecute concurrently with much interleaving of their operations, in the end one can think of subtransactions of \nthe same parent as isolated operations. \n In Chapter 2, we presented nested transactions as a user-oriented execution model, one that is visible to \nthe application programmer. Nested transactions are also a useful implementation tool when building a data \nmanager. We encountered an example of this in Section 6.9,  B-Tree Locking , which addressed the problem of \nimplementing operations on a B \u0005 tree index, such as Get Data Item  x with Location  \u0003  “ B. ” The parent trans-\naction that invokes the operation views it as isolated with respect to other operations it invokes. However, the \n6.11 Locking Nested Transactions  181\n",
      "content_length": 4055,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 201,
      "content": "182  CHAPTER 6 Locking\n internal execution of the operation has multiple steps that traverse a B \u0005 tree — reading its pages and interpret-\ning their content. The locking protocol that ensures this internal execution is isolated with respect to other B \u0005 \ntree operations is not two-phase locking. Rather, it’s a lock coupling protocol that uses knowledge of the B \u0005 \ntree structure to enable more concurrency than two-phase locking would allow. However, the goal is the same \nas nested two-phase locking, namely, ensuring isolation of operations within the same parent. \n Another common case where nested transactions arise in a data manager is implementing record-oriented \noperations on a page-oriented ﬁ le store. Each page consists of multiple records. An implementation of read \nand write operations on records involves reading and writing pages and interpreting their contents. We will see \nan example of nested locking protocols to support this scenario in the next chapter on database recovery. 7 \n 6.12  SUMMARY \n Locking is the most popular mechanism to achieve transaction isolation, that is, to ensure that every execution \nof a set of  transactions is serializable. Each transaction sets read and write locks on data items that it reads and \nwrites, respectively. And it follows the two-phase rule, meaning that it obtains all its locks before releasing any \nof them. Locks are generally set and released automatically by data managers and therefore are hidden from \nthe application programmer. \n A write lock conﬂ icts with a read or write lock on the same data item. Two transactions cannot concurrently \nhold conﬂ icting locks on the same data item. If a transaction requests a lock that conﬂ icts with one owned by \nanother transaction, it is delayed. This leads to two problems: deadlock and thrashing. \n A deadlock occurs when a set of transactions are waiting for each other to release locks. Deadlocks usually \nare handled automatically by a detection mechanism. The system can use timeouts to identify a transaction that \nhas been waiting too long and is suspected of being in a deadlock. Or it explicitly maintains a waits-for graph \nand periodically checks for cycles. The system breaks a deadlock by aborting one of the transactions involved \nin the deadlock. \n The main application design problem created by locking is performance delays created by lock conﬂ icts. \nIf too many transactions request conﬂ icting locks, transaction throughput decreases. This is called lock thrash-\ning. To solve it in a running system, the number of active transactions must be decreased by aborting them. \nAlternatively, one can modify the application, database, or system design to reduce the number of conﬂ icts. \nThe latter is a design activity that involves adjusting the locking granularity or using special locking techniques \nthat reduce the level of conﬂ ict, such as the following: \n ■  Use ﬁ ner grained locks, thereby increasing concurrency, at the expense of more locking overhead, since \nmore locks must be set. \n ■  Reduce the time that locks are held by shortening transaction execution time or delaying lock requests \nuntil later in the transaction. \n ■  Use a hot spot technique, such as delaying operations until commit time, using operations that don’t con-\nﬂ ict, and keeping hot data in main memory to shorten transaction execution time. \n ■  Use a weaker degree of isolation, such as read committed isolation, allowing inconsistent reads by releas-\ning each read lock immediately after reading. \n ■  Use multiversion data, so that queries can access old versions of data and thereby avoid setting locks that \nconﬂ ict with update transactions. \n 7 See the discussion of latches at the end of Section 7.4. Latches ensure that write-record operations are isolated from each other. \nRecord locks ensure transactions are isolated from each other (i.e., are serializable). \n",
      "content_length": 3900,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 202,
      "content": " ■  Use lock coupling or the B-link method to reduce lock contention in B \u0005 tree indexes. \n ■  Use multigranularity locking so that each transaction sets locks at the appropriate granularity for the \noperation it is performing. \n Insert and delete operations require special techniques, such as key-range locking, to avoid phantom updates \nand thereby ensure serializable executions. Nested transactions require special techniques too, for lock inheri-\ntance, to ensure subtransactions of the same parent are isolated from each other. \n 6.13  APPENDIX: BASIC SERIALIZABILITY THEORY \n Serializability theory is one of the standard techniques for arguing the correctness of concurrency control algo-\nrithms, such as two-phase locking. In this section, we present the basics — enough to prove that two-phase \nlocking produces serializable executions. \n Equivalence of Histories \n When we design a concurrency control algorithm, we need to show that every execution of transactions that is \npermitted by the algorithm has the same effect as a serial execution. So to start, we need a formal model of an \nexecution of transactions. As in Section 6.1, we model an execution as a  history , which is a sequence of the \nread, write, and commit operations issued by different transactions. To simplify matters, we do not consider \naborted transactions in this analysis, although they can be included with some modest additional complexity to \nthe theory. For clarity, we do include commit operations, denoted by c i for transaction T i . \n We formalize the concept of  “ has the same effect as ” by the concept of equivalence between two histories. \nInformally, we say that two histories are equivalent if each transaction reads the same input in both histories and the \nﬁ nal value of each data item is the same in both histories. Formally, we say that two histories are  equivalent if they \nhave the same operations and conﬂ icting operations are in the same order in both histories. This captures the infor-\nmal notion of  “ has the same effect as ” because changing the relative order of conﬂ icting operations is the only way \nto affect the result of two histories that have the same operations. For example, the following histories are equivalent: \n \nH\nr [ ] r [ ] w [ ] c  w [ ] c\nH\nr [ ] r [ ] w [ ] c  w\n1\n1\n2\n1\n1\n2\n2\n2\n2\n1\n1\n1\n2\n\u0003\n\u0003\nx\nx\nx\ny\nx\nx\nx\n[ ] c\nH\nr [ ] r [ ] w [ ] c  w [ ] c\nH\nr [ ] w [ ] c  r\ny\nx\nx\nx\nx\ny\n2\n3\n2\n1\n2\n2\n1\n1\n4\n2\n2\n2\n\u0003\n\u0003\ny\n1\n1\n1\n[ ] w [ ] c\nx\nx\n \n But none of them are equivalent to \n H\nr [ ] w [ ] c  r [ ] w [ ] c\n5\n1\n1\n1\n2\n2\n2\n\u0003\nx\nx\nx\ny\n \n The reason is that r 2 [ x ] and w 1 [ x ] conﬂ ict and r 2 [ x ] precedes w 1 [ x ] in H 1  – H 4 , but r 2 [ x ] follows w 1 [ x ] in H 5 . \n We model a serial execution as a  serial history , which is a history where the operations of different trans-\nactions are not interleaved. For example, H 4 and H 5 are serial histories, but H 1  – H 3 are not. \n The Serializability Theorem \n One standard way to prove serializability is using a directed graph that describes a history, called a  serialization \ngraph . It has one node for each transaction. For each pair of conﬂ icting operations by different transactions, it \n6.13 Appendix: Basic Serializability Theory  183\n",
      "content_length": 3238,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 203,
      "content": "184  CHAPTER 6 Locking\n has an edge from the earlier transaction to the later one. For example, in the history in  Figure 6.23 , r 2 [ x ] con-\nﬂ icts with and precedes w 1 [ x ], so there is an edge from T 2 to T 1 in the serialization graph. Two conﬂ icts can lead \nto the same edge. For example, r 2 [ x ] conﬂ icts with and precedes w 1 [ x ], and w 2 [ y ] conﬂ icts with and precedes \nw 1 [ y ], both of which produce the same edge from T 2 to T 1 . \n A  cycle in a directed graph is a sequence of edges from a node back to itself. An  acyclic directed graph \nis a directed graph with no cycles. The fundamental theorem of serializability theory is that a history is serial-\nizable if its serialization graph is acyclic. For example, the history in  Figure 6.23 has an acyclic serialization \ngraph, so it’s serializable. In fact, it is equivalent to the following serial history: \n r [ ] w [ ] c  r [ ] w [ ] w [ ] c  r [ ] w [ ] c\n2\n2\n2\n1\n1\n1\n1\n3\n3\n3\nx\ny\nx\ny\nx\nx\nx\n \n To prove the fundamental theorem, we need to show that if a given history’s serialization graph is acyclic, \nthen it is equivalent to a serial history. Let’s start by constructing a serial history over the same transactions \nas the given history where the transactions are in an order that is consistent with the serialization graph. It is \nsurely possible to construct such a serial history because the graph is acyclic. Now observe that each pair of \nconﬂ icting operations in the given history is in the same order as in the serial history, because the pair cor-\nresponds to an edge in the graph. Since all conﬂ icting operations are in the same order, the given history is \nequivalent to the serial history. Therefore, the given history is serializable, which proves the theorem. \n The Two-Phase Locking Theorem \n Given this fundamental theorem, we can prove that two-phase locking produces serializable executions by \nshowing that any execution it produces has an acyclic serialization graph. So, consider the serialization graph \nof a two-phase locked execution, and examine one edge in this graph, say T i → T j . This means there were two \nconﬂ icting operations, o i from T i and o j from T j . T i and T j each set locks for o i and o j , and since the operations \nconﬂ ict, the locks must conﬂ ict. (For example, o i might have been a read and o j a write on the same data item.) \nBefore o j executed, its lock was set, and o i ’s lock must have been released before then (since it conﬂ icts). So, \nin summary, given that T i → T j , T i released a lock before T j set a lock. \n Now , suppose there is a sequence of edges T i → T j and T j → T k . From the previous paragraph, we know \nthat T i released a lock before T j set a lock, and T j released a lock before T k set a lock. (They may be different \nlocks.) Moreover, since T j is two-phase locked, it set all its locks before it released any of them. Therefore, T i \nreleased a lock before T k set a lock. Avoiding the rigor of an induction argument, it is easy to see that we can \nrepeat this argument for sequences of edges of any length. Therefore, for any sequence of edges T i → … → T m , \nT i released a lock before T m set a lock. \n To prove that the two-phase locked execution is serializable, we need to show that its serialization graph \nis acyclic. So, by way of contradiction, suppose there  is a cycle in the serialization graph T i → … → T i . From \nthe previous paragraph, we can conclude that T i released a lock before T i set a lock. But this implies T i was \n not two-phase locked, contradicting our assumption that all transactions were two-phase locked. Therefore the \ncycle cannot exist and, by the fundamental theorem of serializability, the execution is serializable. \nr1[x] r2[x] w1[x] r3[x] w2[y] c2 w1[y] c1 w3[x] c3\nT2\nT3\nT1\n FIGURE 6.23 \n An Execution and Its Serialization Graph. The execution on the left is modeled by the serialization graph on the right. \n",
      "content_length": 3931,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 204,
      "content": " 7.1  CAUSES OF SYSTEM FAILURE \n A critical requirement for most TP systems is that they be up all the time; in other words, highly available. Such \nsystems often are called  “ 24 by 7 ” (or 24  \u0004  7), since they are intended to run 24 hours per day, 7 days per week. \nDeﬁ ning this concept more carefully, we say that a system is  available if it is running correctly and yielding the \nexpected results. The  availability of a system is deﬁ ned as the fraction of time that the system is available. Thus, \na highly available system is one that, most of the time, is running correctly and yielding expected results. \n Availability is reduced by two factors. One is the rate at which the system fails. By  fails , we mean the system \ngives the wrong answer or no answer. Other things being equal, if it fails frequently, it is less available. The sec-\nond factor is recovery time. Other things being equal, the longer it takes to ﬁ x the system after it fails, the less it \nis available. These concepts are captured in two technical terms: mean time between failures and mean time to \nrecovery. The  mean time between failures , or  MTBF , is the average time the system runs before it fails. MTBF \nis a measure of system  reliability . The  mean time to repair , or  MTTR , is how long it takes to ﬁ x the system \nafter it does fail. Using these two measures, we can deﬁ ne availability precisely as MTBF/(MTBF  \u0005  MTTR), \nwhich is the fraction of time the system is running. Thus, availability improves when reliability (MTBF) \nincreases and when repair time (MTTR) decreases. \n In many practical settings, the system is designed to meet a  service level agreement (SLA) , which is typi-\ncally a combination of availability, response time, and throughput. That is, it is not enough that the system is \navailable. It must also have satisfactory performance. Of course, poor performance may arise from many sources, \nsuch as the database system, network, or operating system. Performance problems are sometimes TP-speciﬁ c, \nsuch as the cases of locking performance discussed in Chapter 6. More often, they are speciﬁ c to other compo-\nnent technologies. These problems are important, but since they are not speciﬁ c to the TP aspects of the system, \nwe will not consider them here. Instead, we focus entirely on failures and how to recover from them. \n Failures come from a variety of sources. We can categorize them as follows: \n ■  The environment: Effects on the physical environment that surrounds the computer system, such as power, \ncommunication, air conditioning, ﬁ re, and ﬂ ood. \n ■  System management: What people do to manage the system, including vendors doing preventative main-\ntenance and system operators taking care of the system. \n ■  Hardware: All hardware devices including processors, memory, I/O controllers, storage devices, etc. \n ■  Software: The operating system, communication systems, database systems, transactional middleware, other \nsystem software, and application software. \n Let ’s look at each category of failures and see how we can reduce their frequency. \n System Recovery \n 7 \nCHAPTER\n",
      "content_length": 3125,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 205,
      "content": "186  CHAPTER 7 System Recovery\n Hardening the Environment \n One part of the environment is communications systems that are not under the control of the people building \nthe computer system, such as long distance communication provided by a telecommunications company. As a \ncustomer of communication services, sometimes one can improve communications reliability by paying more \nto buy more reliable lines. Otherwise, about all one can do is lease more communication lines than are needed \nto meet functional and performance goals. For example, if one communication line is needed, lease two inde-\npendent lines instead, so if one fails, the other one will probably still be operating. \n A second aspect of the environment is power. Given its failure rate, it’s often appropriate to have battery backup \nfor the computer system. In the event of power failure, battery backup can at least keep main memory alive, so the \nsystem can restart immediately after power is restored without rebooting the operating system, thereby reducing \nMTTR. Batteries may be able to run the system for a short period, either to provide useful service (thereby increas-\ning MTBF) or to hibernate the system by saving main memory to a persistent storage device (which can improve \navailability if recovering from hibernation is faster than rebooting). To keep running during longer outages, an \nuninterruptible power supply (UPS) is needed. A full UPS generally includes a gas or diesel powered generator, \nwhich can run the system much longer than batteries. Batteries are still used to keep the system running for a few \nminutes until the generator can take over. \n A third environmental issue is air conditioning. An air conditioning failure can bring down the computer \nsystem, so when a computer system requires an air conditioned environment, a redundant air conditioning \nsystem is often advisable. \n Systems can fail due to natural disasters , such as ﬁ re, ﬂ ood, and earthquake, or due to other extraordinary \nexternal events, such as war and vandalism. There are things one can do to defend against some of these events: \nbuild buildings that are less susceptible to ﬁ re, that are able to withstand strong earthquakes, and that are secured \nagainst unauthorized entry. How far one goes depends on the cost of the defense, the beneﬁ t to availability, and \nthe cost of downtime to the enterprise. When the system is truly  “ mission critical, ” as in certain military, ﬁ nan-\ncial, and transportation applications, an enterprise will go to extraordinary lengths to reduce the probability of \nsuch failures. One airline system is housed in an underground bunker. \n After hardening the environment, the next step is to replicate the system, ideally in a geographically distant \nlocation whose environmental disasters are unlikely to be correlated to those at other replicas. For example, \nmany years ago one California bank built an extra computer facility east of the San Andreas Fault , so they could \nstill operate if their Los Angeles or San Francisco facility were destroyed by an earthquake. More recently, geo-\ngraphical replication has become common practice for large-scale Internet sites. Since a system replica is use-\nful only if it has the data necessary to take over processing for a failed system, data replication is an important \nenabling technology. Data replication is the subject of Chapter 9. \n System Management \n System management is another cause of failures. People are part of the system. Everybody has an off day or \nan occasional lapse of attention. It’s only a matter of time before even the best system operator does something \nthat causes the system to fail. \n There are several ways to mitigate the problem. One is simply to design the system so that it doesn’t \nrequire maintenance, such as using automated procedures for functions that normally would require opera-\ntor intervention. Even preventative maintenance, which is done to increase availability by avoiding failures \nlater on, may be a source of downtime. Such procedures should be designed to be done while the system is \noperating. \n",
      "content_length": 4116,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 206,
      "content": " Simplifying maintenance procedures also helps, if maintenance can’t be eliminated entirely. So does building \nredundancy into maintenance procedures, so an operator has to make at least two mistakes to cause the system to \nmalfunction. Training is another factor. This is especially important for maintenance procedures that are needed \ninfrequently. It’s like having a ﬁ re drill, where people train for rare events, so when the events do happen, people \nknow what actions to take. \n Software installation is often a source of planned failures. The installation of many software products requires \nrebooting the operating system. Developing installation procedures that don’t require rebooting is a way to \nimprove system reliability. \n Many operation errors involve reconﬁ guring the system. Sometimes adding new machines to a rack or chang-\ning the tuning parameters on a database system causes the system to malfunction. Even if it only degrades perfor-\nmance, rather than causing the system to crash, the effect may be the same from the end user’s perspective. One can \navoid unpleasant surprises by using conﬁ guration management tools that simulate a new conﬁ guration and demon-\nstrate that it will behave as predicted, or to have test procedures on a test system that can prove that a changed con-\nﬁ guration will perform as predicted. Moreover, it is valuable to have reconﬁ guration procedures that can be quickly \nundone, so that when a mistake is made, one can revert to the previous working conﬁ guration quickly. \n If a system is not required to be 24  \u0004  7, then scheduled downtime can be used to handle many of these \nproblems, such as preventative maintenance, installing software that requires a reboot, or reconﬁ guring a sys-\ntem. However, from a vendor’s viewpoint, offering products that require such scheduled downtime limits their \nmarket only to customers that don’t need 24  \u0004  7. \n Hardware \n The third cause of failures is hardware problems. To discuss hardware failures precisely, we need a few techni-\ncal terms. A  fault is an event inside the system that is believed to have caused a failure. A fault can be either \ntransient or permanent. A  transient fault is one that does not reoccur if you retry the operation. A  permanent \nfault is not transient; it is repeatable. \n The vast majority of hardware faults are transient. If the hardware fails, simply retry the operation; there’s \na very good chance it will succeed. For this reason, operating systems have many built-in recovery procedures \nto handle transient hardware faults. For example, if the operating system issues an I/O operation to a disk or \na communications device and gets an error signal back, it normally retries that operation many times before it \nactually reports an error back to the caller. \n Of course, some hardware faults are permanent. The most serious ones cause the operating system to fail, \nmaking the whole system unavailable. In this case, rebooting the operating system may get the system back into \na working state. The reboot procedure will detect malfunctioning hardware and try to reconﬁ gure around it. If \nthe reboot fails or the system fails shortly after reboot, then the next step is usually to reimage the disk with a \nfresh copy of the software, in case it became corrupted. If that doesn’t ﬁ x the problem, then repairing the hard-\nware is usually the only option. \n Software \n This brings us to software failures. The most serious type of software failure is an operating system crash, \nsince it stops the entire computer system. Since many software problems are transient, a reboot often repairs \nthe problem. This involves rebooting the operating system, running software that repairs disk state that might \nhave become inconsistent due to the failure, recovering communications sessions with other systems in a dis-\ntributed system, and restarting all the application programs. These steps all increase the MTTR and therefore \n7.1 Causes of System Failure  187\n",
      "content_length": 3998,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 207,
      "content": "188  CHAPTER 7 System Recovery\n reduce availability. So they should be made as fast as possible. The requirement for faster recovery inspired \noperating systems vendors in the 1990s to incorporate fast ﬁ le system recovery procedures, which was a major \ncomponent of operating system boot time. Some operating systems are carefully engineered for fast boot. For \nexample, highly available communication systems have operating systems that reboot in under a minute, worst \ncase. Taking this goal to the extreme, if the repair time were zero, then failures wouldn’t matter, since the sys-\ntem would recover instantaneously, and the user would never know the difference. Clearly reducing the repair \ntime can have a big impact on availability. \n Some software failures only degrade a system’s capabilities, not cause it to fail. For example, consider an \napplication that offers functions that require access to a remote service. When the remote service is unavail-\nable, those functions stop working. However, through careful application design, other application functions \ncan still be operational. That is, the system degrades gracefully when parts of it stop working. A real example \nwe know of is an application that used a TP database and a data warehouse, where the latter was nice to have \nbut not mission-critical . The application was not designed to degrade gracefully, so when the data warehouse \nfailed, the entire application became unavailable, which caused a large and unnecessary loss of revenue. \n When an application process or database system does fail, the failure must be detected and the application \nor database system process must be recovered. This is where TP-speciﬁ c techniques become relevant. \n 7.2  A MODEL FOR SYSTEM RECOVERY \n In this section, we will discuss how to cope with the failure and recovery of processes that are running applica-\ntion code. We will look at the failure and recovery of resource managers, notably database systems, starting in \nSection 7.3. \n Detecting Process Failures \n Operating system processes are a ﬁ rewall between the operating system and the application. An application \nfailure may cause the application’s process to fail. However, the operating system can continue, so only the \nprocess needs to be restarted. This reduces MTTR compared to a system where the application failure causes \nan operating system reboot. Therefore, most TP systems are built from multiple processes. \n We would like each process to be as reliable as possible. But of course, no matter how reliable it is, there are \ntimes when it will fail. When it does fail, some agent outside of the process has to observe that fact and ask to \nrecreate the process. Usually that’s done by the operating system, database system, or transactional middleware. \n The transactional middleware or database system usually has one or more monitoring processes that track \nwhen application or database processes fail. There are several ways that are commonly used to detect failures: \n ■  Each process could periodically send an  “ I’m alive ” message to the monitoring process (see  Figure 7.1 ); \nthe absence of such a message warns the monitoring process of a possible failure. \n ■  The monitoring process could poll the other processes with  “ Are you alive? ” messages. \n ■  Each process could own an operating system lock that the monitoring process is waiting to acquire; if the \nprocess fails, the operating system releases the process ’ s lock, which causes the monitoring process to be \ngranted the lock and hence to be alerted of the failure. \n Whichever approach is taken, it is important to optimize the time it takes for a monitoring process to detect \nthe failure, since that time contributes to the MTTR and therefore to unavailability. \n In all these cases, the symptom provides a good reason to suspect that the process failed, but it is not an \nironclad guarantee that the process actually did fail. In the ﬁ rst two cases, the process might just be slow to \n",
      "content_length": 4002,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 208,
      "content": " respond. In the third case, it might have released the lock yet still be operational. The suspicion of a failure \nis more likely to be true if the detector is executing under the same operating system instance as the process \nbeing monitored; that is, on the same machine or virtual machine, though even here it is not a guarantee. This \nis the scenario we focus on in this chapter, and we will assume that failure detection is accurate. \n In a distributed system where the monitor is running on a different machine than the process being moni-\ntored, there is a greater chance that the failure symptom is due to a communication failure rather than a process \nfailure. We will explore this issue in Chapters 8 and 9. \n A process could fail by returning incorrect values. That is, it could fail to satisfy its speciﬁ cation. For \nexample, the data it returns could have been corrupted by faulty memory, a faulty communication line, or an \napplication bug. We do not consider such errors here. We assume the ﬁ rst two are prevented by suitable error-\ndetecting codes. We do not consider application bugs because we cannot eliminate them by using generic sys-\ntem mechanisms. They are addressed by software engineering technology and methodology, which are outside \nthe scope of this book. \n When a process failure is detected, some agent needs to recreate the failed process. The operating system \ngenerally is designed only to recreate processes that are needed to keep the system running at all, such as the \nﬁ le system (if it runs as a process) and system monitor processes. The operating system generally does not \nautomatically recreate application processes, except those managed by the operating system’s process control \nsystem. Therefore, transactional middleware and database systems must step in to detect the failure of applica-\ntion and database system processes, and when they do fail, to recreate them. \n Client Recovery \n In this discussion of recovery, we assume a basic client – server model: a client process communicates with a \nserver process and the server process uses underlying resources, such as a disk or communications line (see \n Figure 7.2 ). A common conﬁ guration is to have the client running on a desktop machine and the server on a \nlarger shared machine. Whatever the conﬁ guration, the possible technical approaches for system recovery remain \nthe same. We are therefore deliberately vague about the type of machine on which the client and server run. \n There are several points of failure in this system: the client, the client-server connection, the server, the \nserver-resource connection, and the resources. If the client fails and later recovers, it needs to reconnect to \nthe server and can start calling it again. Or, if the client loses communication with the server, either because the \ncommunication line or server failed, the failure will eventually be repaired and the client will later re-establish \nFault detection\nmonitor\n“I'm alive”\n“I'm alive”\n“I'm alive”\nProcess 1\nProcess 2\nProcess N\n FIGURE 7.1 \n A Fault Detection Monitor. The monitor detects process failures, in this case by listening for  “ I’m alive ” messages. When \nit doesn’t hear one within its timeout period, it assumes the process has failed. \n7.2 A Model for System Recovery  189\n",
      "content_length": 3300,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 209,
      "content": "190  CHAPTER 7 System Recovery\n that communication and resume calling the server. In either case, at recovery time, the main issue for the client \nis to re-establish its state relative to the server. \n The state of the client relative to the server consists of the set of its outstanding calls to the server. Therefore, \nto recover its state, it needs to determine the following: \n ■  What calls were outstanding at the time it failed or lost connectivity with the server? \n ■  What happened to those calls while it was down or not communicating with the server? \n ■  What does it have to do to ﬁ nish those calls properly before proceeding with new calls? \n These are exactly the issues we discussed in Chapter 4,  “ Queued Transaction Processing. ” If there is a per-\nsistent queue between the client and server, then the client can ﬁ nd out the state of all outstanding calls (called \n “ requests ” in Chapter 4) by examining the queue. If not, then it has to use an application-speciﬁ c technique, such \nas looking at the database state on the server to determine if the client’s previous calls completed, or reissuing \nin-doubt calls with the same serial number and relying on the server to discard duplicate calls. These techniques \ntoo were discussed in Chapter 4. \n The remaining issues all focus on server availability, which is the subject of the rest of this section. \n Server Recovery \n After a server has been recreated, it runs its recovery procedure to reconstruct its state before starting to pro-\ncess new calls. If this is the ﬁ rst time the server has ever run, then the recovery procedure is trivial — the server \njust initializes its state. If not, then it has some work to do. \n To explore how a server reconstructs its state, let’s begin from ﬁ rst principles. Suppose the server is a sequen-\ntial processor of calls and there are no transactions in the picture. The server just receives a call from a client, \ndoes what is requested, and returns a result. At the time it failed, the server might have been in the middle of \nprocessing such a call. \n As we discussed in the previous section on Client Recovery, it is up to the client to determine the state of its \noutstanding calls. It’s always possible that a server (or communications) failure causes a call to get lost, so the \nclient must be able to cope with that fact. Since the client has to be able to deal with lost calls, it would seem \nthat a recovering server could just ignore whatever call it was working on at the time it failed and start afresh. \nIt’s up to the client to ﬁ gure out what to do. \nResources\nServer\nClient\n FIGURE 7.2 \n Basic Client-Server Model. A client process communicates with a server process and the server process uses underlying \nresources, such as a disk or communication line. \n",
      "content_length": 2793,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 210,
      "content": " Unfortunately , this doesn’t always work, because the server may have performed a non-idempotent  opera-\ntion while it was processing its last call before the failure. For example, it may have printed a check, transferred \nmoney, credited a bank account, dispensed cash, or shipped a product. If the client concludes that the server \ndid not execute the call, it will reissue it, thereby causing the server to redo the work. Therefore, if the server \nperformed a non-idempotent  operation on behalf of the call it was processing at the time of failure, it must not \nre-execute the call. Rather, it must complete the call and return a result. \n The details of recovering a partially-executed  call are complex and are not commonly used in systems that \nsupport transactions. However, to appreciate how much easier things are when transactions are available, let us \nbrieﬂ y examine what the server would have to do if it could not rely on transactions. \n Checkpoint-Based Recovery \n Suppose the server partially executed a client’s call and then failed. Suppose all the operations that the server \nexecuted for that partially-executed  call were idempotent. In that case, at recovery time the server can simply \nreprocess the call from the beginning. Re-executing operations that it executed before the failure does no harm, \nbecause all those operations are idempotent. \n Suppose the server did perform non-idempotent  operations for the last call. Then it must recover itself to \na state that came after the last non-idempotent  operation it executed before the failure. So, for example, if the \nserver printed a check before the failure, then it must be recovered to a state after the time that it printed the \ncheck. If the server continued processing from a state before it printed the check then it would repeat that oper-\nation (i.e., print the check again), which is exactly what should not happen. Recreating this state requires some \ncareful bookkeeping before the failure, so the recovering server can look up what was going on at the time of \nfailure, to ﬁ gure out what it should do. \n One general way to prepare for this type of recovery is to have a server save its memory state on nonvolatile \nstorage (e.g., a disk) before it executes a non-idempotent  operation. That way, when it recovers, it can recreate \nthat state (see  Figure 7.3 ). Saving memory state is an example of checkpointing. In general,  checkpointing is \nany activity that is done during normal processing to reduce the amount of work to redo after a recovery. Saving \nmemory state is a kind of checkpointing, because it ensures that when the server recovers, it won’t have to redo \nany work that it did before saving its state. \n Saving the state of the server’s memory is not cheap, especially if it has to be done every time a non-\nidempotent  operation is performed. As we’ll see in a moment, transactions help reduce this cost. \n To recover from a failure, the server restores the last checkpoint state it successfully saved (see  Figure 7.4 ). \nIt must then check if the non-idempotent  operation that followed its last checkpoint actually ran. For example, \na. Normal Operation\nb. Server Recovery\nDisk\nServer\nClient\nWrite\ncheckpoints.\nServer\nClient\nRead last\ncheckpoint.\nDisk\n FIGURE 7.3 \n Server Checkpointing. During normal operation, the server periodically writes a checkpoint. After a failure, it uses its last \ncheckpointed state to recover. \n7.2 A Model for System Recovery  191\n",
      "content_length": 3478,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 211,
      "content": "192  CHAPTER 7 System Recovery\n if the server checkpoints its state right before printing a check, then at recovery time reconstituting the server \nstate requires determining whether or not the check was printed. This is the same question we asked in the ear-\nlier section on Client Recovery and in Section 4.4,  Handling Non-Undoable  Operations . That is, in this situa-\ntion, the server is in the role of a client in Section 4.4 that may have called a non-idempotent  operation before \nit failed. Therefore, when the server recovers, it must determine whether that non-idempotent  operation ran, \nand if so it can skip over it. \n To summarize: If a server performs non-idempotent operations, then it reconstitutes its state at recovery \ntime to one that comes after the last non-idempotent operation that it performed before the failure. The idea is \nto start running the process from that state, so that non-idempotent operations it does from that point on don’t \ncause a problem. \n Transaction-Based Server Recovery \n Transactions simplify server recovery by focusing clients ’ and servers ’ attention on the transactions executed \nby each server, rather than on individual calls within a transaction. That is, the server does all its work within \ntransactions. The client tells the server to start a transaction, the client makes some calls to the server within \nthat transaction, and then the client tells the server to commit the transaction. \n If a server that supports transactions fails and subsequently recovers, its state includes the effects of all \ntransactions that committed before the failure and no effects of transactions that aborted before the failure or \nwere active at the time of the failure. Comparing this behavior to a nontransactional server, it is as if the trans-\nactional server performs a checkpoint every time it commits a transaction, and its recovery procedure discards \nall effects of aborted or incomplete transactions. Thus, when a transactional server recovers, it ignores which \n calls were executing when it failed and focuses instead on which  transactions were executing when it failed. \nSo instead of recovering to a state as of the last partially-executed  call (as in checkpoint-based recovery), it \nrecovers to a state containing all the results of all committed transactions and no others. \n For this to work, the server must be able to undo all of a transaction’s operations when it aborts. This effec-\ntively makes the operations redoable when the transaction is re-executed . That is, if an operation was undone, \nthen there’s no harm in redoing it later, even if it is non-idempotent. This avoids a problem that was faced in \ncheckpoint-based recovery — the problem of returning to a state after the last non-idempotent operation. This \nisn’t necessary because every non-idempotent operation was either part of a committed transaction (and hence \nwon’t be redone) or was undone (and hence can be redone). \nServer Program\n     . . .\n     Checkpoint;\n     // Recovery procedure branches to next line\n     If RestartFlag\n     { RestartFlag \u0003 0;\n       If(check wasn’t printed before the failure) print check;\n     }\n     else print check\n     . . .\nServer Recovery Procedure:\n    RestartFlag \u0003 1;\n    Find last checkpoint on disk;\n    Restore checkpoint’s memory state;\n    Go to next server statement after Checkpoint\n FIGURE 7.4 \n Checkpoint-Based Recovery Procedure. The server program checkpoints before its non-idempotent  “ print check ” \noperation. The server recovery procedure recovers the last checkpoint state and branches to the line after the statement \nthat created the checkpoint. The server program then executes the non-idempotent operation  “ print check ” only if it \nwasn’t done before the failure. \n",
      "content_length": 3770,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 212,
      "content": " If all operations in a transaction must be redoable, then the transaction must not include the non-idempotent \noperations we encountered in the earlier section,  Server Recovery , such as printing a check or transferring \nmoney. To cope with such a non-idempotent operation, the transaction should enqueue a message that con-\ntains the operation. It’s safe for the transaction to contain the enqueue operation, because it is undoable. The \nprogram that processes the message and performs the non-idempotent operation should use the reply handling \ntechniques in Section 4.4 to get exactly-once execution of the actual operation (printing the check or sending a \nmoney-transfer message). \n Transactions not only simplify server recovery, they also speed it up. A memory checkpoint is expensive, \nbut transaction commitment is relatively cheap. The trick is that the transactional server is carefully maintain-\ning all its state on disk, incrementally, by writing small amounts to a log ﬁ le, thereby avoiding a bulk copy of \nits memory state. It is designed to suffer failures at arbitrary points in time, and to reconstruct its memory state \nfrom disk using the log, with relatively modest effort. The algorithms to reconstruct its state in this way are \nwhat gives transactions their all-or-nothing and durability properties. Either all of a transaction executes or none \nof it does. And all of its results are durably saved in stable storage, even if the system fails momentarily after the \ntransaction commits. These algorithms are the main subject of the rest of this chapter. \n Stateless Servers \n When transactions are used, servers usually are split into two types: application processes and resource managers \n(see  Figure 7.5 ). An application process receives a client request, starts a transaction, performs application logic, \nand sends messages to transactional resource managers. It does not directly access transactional resources, such \nas a database. Resource managers handle the state being shared by transactions — databases, recoverable queues, \nand so on. \n A resource manager behaves just like a transactional server described in the previous section,  Transaction-\nBased Server Recovery . That is, it executes all calls within a transaction. And its recovery procedure returns its \nstate to one that includes the effects of all committed transactions and no others. \nApplication\nProcess\nResource\nManager\nClient\nResources\n FIGURE 7.5 \n Stateless Servers. An application process stores all its state in resource managers, and is therefore stateless. \n7.2 A Model for System Recovery  193\n",
      "content_length": 2610,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 213,
      "content": "194  CHAPTER 7 System Recovery\n An application process can use a simpler recovery procedure than resource managers, because it is state-\nless. That is, it doesn’t have any state that might be needed after recovery. It receives a request to run a transac-\ntion (from its client), starts a transaction, executes operations that manipulate local memory or call a database \nsystem or another application process, commits the transaction, and sends a reply back to the client. At this \npoint, it has no state worth remembering. It simply processes the next request that it receives as if it had been \ninitialized from scratch. \n A stateless server doesn’t have to do very much to recover from a failure. It just reinitializes its state and starts \nrunning transactions again, completely oblivious to whatever it was doing before the failure. Since it maintains \nall its state in transactional resource managers, it is really up to the resource managers to reconstitute their states \nafter a failure. The resource managers recover to a state that includes all the committed transactions and none of \nthe aborted ones, up to the time of the failure. Now the application process can start processing requests again. \n The application processes controlled by transactional middleware usually are designed to be stateless serv-\ners so they do not need any recovery code. The only ambiguity is about the state of the last request that a client \nissued to the application process before the failure (e.g., that a front-end program issued to a request control-\nler). That is, the client is not stateless, since it needs to know the state of that last request. This is where queued \nrequest processing comes in — to ﬁ gure out the state of that last request and thereby determine whether it has \nto be rerun. For the application process that was actually executing the request, there’s no ambiguity at all. It \nrestarts in a clean state, as if it were initialized for the ﬁ rst time. \n 7.3  INTRODUCTION TO DATABASE RECOVERY \n Now that we understand how to recover application processes, it’s time to turn our attention to recovering \nresource managers. As in Chapter 6,  “ Locking, ” we will use the term data manager instead of the more generic \nterm resource manager. The most popular type of data manager is a database system. However, the principles \napply to any kind of transactional resource manager, such as queue managers and transactional ﬁ le systems. \n To recover from a failure, a data manager needs to quickly return its database to a state that includes the \nresults of all transactions that committed before the failure and no results of transactions that aborted before \nthe failure or were active at the time of failure. Most data managers do an excellent job of this type of recovery. \nThe application programmer doesn’t get involved at all. \n The mechanisms used to recover from these failures can have a signiﬁ cant effect on performance. However, \nif a data manager uses a recovery approach that leads to mediocre transaction performance, there is not too \nmuch that the application programmer can do about it. This is rather different than locking, where application \nprogramming and database design can have a big effect. In view of the lack of control that an application pro-\ngrammer has on the situation, there is no strong requirement that he or she have a deep understanding of how a \ndata manager does recovery. \n Still , there are a few ways, though not many, that database and system administrators can work together \nto improve performance, fault tolerance, and the performance of recovery. For example, they can improve the \nfault tolerance of a system by altering the conﬁ guration of logs, disk devices, and the like. To reason about per-\nformance and fault tolerance implications of application and system design, it helps a great deal to understand \nthe main concepts behind database recovery algorithms. We describe these concepts in the rest of this chapter \nand their implications for application programming. \n Types of Failure \n Many failures are due to incorrectly programmed transactions and to data entry errors that lead to incorrect \nparameters to transactions. Unfortunately, these failures undermine the assumption that a transaction’s execution \n",
      "content_length": 4284,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 214,
      "content": " preserves the consistency of the database (the  “ C ” in ACID). They can be dealt with by applying software engi-\nneering techniques to the programming and testing of transactions, by validating input before feeding it to a trans-\naction, and by semantic integrity mechanisms built into the data manager. However they’re dealt with, they are \nintrinsically outside the range of problems that transaction recovery mechanisms can automatically handle. Since \nwe’re interested in problems that transaction recovery mechanisms  can handle, we will assume that transactions \ndo indeed preserve database consistency. \n There are three types of failures that are most important to a TP system: transaction failures, system fail-\nures, and media failures. A  transaction failure occurs when a transaction aborts. A  system failure occurs \nwhen the contents of volatile storage, namely main memory, is corrupted. For example, this can happen to \nsemiconductor memory when the power fails. It also happens when the operating system fails. Although an \noperating system failure may not corrupt all of main memory, it is usually too difﬁ cult to determine which \nparts were actually corrupted by the failure. So one generally assumes the worst and reinitializes all of main \nmemory. Given the possibility of system failures, the database itself must be kept on a stable storage medium, \nsuch as disk. (Of course, other considerations, such as size, may also force us to store the database on stable \nmass storage media.) By deﬁ nition,  stable (or  nonvolatile )  storage withstands system failures. A  media fail-\nure occurs when any part of the stable storage is destroyed. For instance, this happens if some sectors of a disk \nbecome damaged. \n In this chapter we assume that each transaction accesses and updates data at exactly one data manager. This \nallows us to focus our attention on recovery strategies for a single data manager. In the next chapter we’ll con-\nsider additional problems that arise when a transaction can update data at more than one data manager. \n Recovery Strategies \n The main strategy for recovering from failures is quite simple: \n ■  Transaction failure: If a transaction aborts, the data manager restores the previous values of all data items \nthat the transaction wrote. \n ■  System failure: To recover from the failure, the data manager aborts any transactions that were active \n(i.e., uncommitted) at the time of the failure, and it ensures that each transaction that did commit before \nthe failure actually installed its updates in the database. \n ■  Media failure: The recovery strategy is nearly the same as for system failures, since the goal is to \nreturn the database to a state where it contains the results of all committed transactions and no aborted \ntransactions. \n We will concentrate on recovery from transaction and system failures for most of the chapter. Recovery \nfrom media failures is quite similar to recovery from system failures, so we’ll postpone discussing it until the \nend of the chapter, after we have a complete picture of system recovery mechanisms. \n It ’s easy to see why system and media recovery are so similar. Each recovery mechanism considers a cer-\ntain part of storage to be unreliable: main memory, in the case of system failures; a portion of stable storage, in \nthe case of media failures. To safeguard against the loss of data in unreliable storage, the recovery mechanism \nmaintains another copy of the data, possibly in a different representation. This redundant copy is kept in another \npart of storage that it deems reliable: stable storage, in the case of system failures, or another piece of stable \nstorage, such as a second disk or tape, in the case of media failures. Of course, the different physical character-\nistics of storage in the two cases may require the use of different strategies. But the principles are the same. \n The most popular technique for recovering from system and media failures is logging. The log is that \nsecond, redundant copy of the data that is used to cope with failures. To understand how a log is used, why it \nworks, and how it affects performance, we need to start with a simpliﬁ ed model of data manager internals, so \nwe have a framework in which to discuss the issues. \n7.3 Introduction to Database Recovery  195\n",
      "content_length": 4326,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 215,
      "content": "196  CHAPTER 7 System Recovery\n 7.4  THE SYSTEM MODEL \n Locking Assumptions \n From the viewpoint of transactions, the recovery system is part of the storage subsystem that processes read, write, \ncommit, and abort operations. The recovery system makes few assumptions about the transactions that use its ser-\nvices. The main one is that the transaction is responsible for setting locks before issuing read and write operations \nto the storage system, and that it holds onto its write locks until after the transaction commits or aborts. \n Since a transaction holds a write lock on any data it updates until after it commits or aborts, no other trans-\naction can read or write that data until then. This avoids three messy recovery situations. \n The ﬁ rst messy situation is guaranteeing recoverability. Suppose a transaction is allowed to release write locks \nbefore it commits or aborts. Consider a transaction T 2 that reads a data item that was last updated by an active \ntransaction T 1 , and T 2 commits while T 1 is still active. If T 1 subsequently aborts, the execution looks like this: \n E\nw [ ] r [ ] commit  abort\n1\n2\n\u0003\nx\nx\n2\n1  \n The data manager is now stuck. It should abort T 2 , because T 2 has read data that is now invalid; but it can’t, \nbecause T 2 already committed. That is, the data manager is in a state from which it can’t recover. It’s therefore \nessential that a transaction not commit if it read any data that was last updated by a transaction that is still \nactive. That is, a transaction T’s commit operation must follow the commit of every transaction from which T \nread. An execution that obeys this rule is called  recoverable . Holding write locks until after a transaction com-\nmits or aborts solves this problem with a sledgehammer; a transaction can’t read data that was last updated by \na transaction that is still active, because the latter holds a write lock on that data. \n The second messy situation is cascading abort. Consider the same situation as in the previous paragraph, \nwhere T 2 read data that was last updated by an active transaction T 1 . But this time, suppose T 1 aborts while T 2 \nis still active. That is, the execution looks like this: \n E\nw [ ] r [ ] abort\n1\n\u0002 \u0003\nx\nx\n2\n1  \n Then , as before, T 2 would have to abort too, since its input would be invalid. This is called  cascading abort , \nsince the abort of one transaction (T 1 ) cascades to the abort of another transaction (T 2 ). We’re certainly better off in \nthis situation than in the previous paragraph, since at least it’s legal to abort T 2 (because T 2 is still active). But the \nsystem still needs to keep track of which transactions depend on which other transactions — nontrivial bookkeep-\ning. We can avoid this bookkeeping by requiring that a transaction only reads data that was last updated by a trans-\naction that has committed. An execution that obeys this rule is said to  avoid cascading aborts . A data manager \ncan avoid cascading aborts by ensuring that every transaction holds its write locks until after it commits or aborts. \n The third messy situation is being unable to abort a transaction simply by restoring the previous values of \ndata it wrote. This arises if a transaction can overwrite another transaction’s uncommitted writes. For example, \nif T 1 does not hold its write locks until after it commits or aborts, then another transaction can overwrite data \nwritten by T 1 . The effect is rather nasty, as illustrated by the following execution: \n E\nw [ ] w [ ] abort  abort\n1\n\t \u0003\nx\nx\n2\n1\n2  \n In execution E \t , when transaction T 1 aborts, the system cannot simply restore the value  x had before w 1 [ x ], \nsince that would wipe out the result of T 2 ’s write operation, w 2 [ x ]. At this point, the system doesn’t know \nwhether T 2 will commit or abort. If T 2 later commits, its update to  x would be lost. So, the right thing for the \ndata manager to do when T 1 aborts is nothing. Now, when T 2 aborts, the system cannot restore the value  x had \n",
      "content_length": 4004,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 216,
      "content": " before w 2 [ x ], since that would reinstall the value written by T 1 , which just aborted. So, the right thing for the \nsystem to do when T 2 aborts is to restore the value  x had before w 1 [ x ]. This is a pretty complicated analysis \nfor the recovery mechanism to do, and this is just for two updates by two transactions. If multiple transactions \nwere involved, the analysis would be very tricky indeed. All systems we know of avoid it by allowing a trans-\naction to write a data item only if the previous transaction that updated the data item already committed. Such \nexecutions are called  strict . This is usually implemented by requiring that write locks are held until after the \ntransaction commits or aborts. This ensures that the data manager can abort a transaction simply by restoring \nthe previous values of data that the transaction wrote. \n In summary, a lot of recovery problems become much simpler if the recovery system can assume that a \ntransaction holds its write locks until after it commits or aborts. All systems we know of rely on this assumption. \n Page Granularity Operations \n Locking granularity is another aspect of locking that affects the complexity of recovery mechanisms. Recovery \nalgorithms are a lot simpler when page granularity locking is used. Here’s why. \n The only truly reliable operation that a data manager has available is writing one page to a disk. Disk hard-\nware is careful to make this an atomic (i.e., all-or-nothing) operation with respect to system failures. That is, if \nthe system fails, then recovers, and then a program reads a page P from disk, the content of P reﬂ ects the last \ncomplete write to P before the system failed. \n Although the hardware is designed to make disk writes atomic, errors are still possible. For example, if \na disk malfunctions, it might partially execute a write operation on page P. In that case, the next operation to \nread P may detect the error, for example, as an erroneous checksum on the page. This is a media failure. \n Depending on the hardware, some media failures may not be detectable. For example, consider a disk mal-\nfunction where it executes a write operation completely, but stores the data in the wrong location. That is, an \noperation was issued to write page P, but the disk wrote it to a different location, Q. In this case, when an appli-\ncation reads page P, the value it reads may appear to be correct. However, due to the previous erroneous write, \nthe value of P does not reﬂ ect the last write operation to P, but an earlier one. Moreover, the next read of page Q \nwill return a value that appears to be correct (since it reﬂ ects a complete write operation), but it too is incorrect \nbecause it contains the last value written to page P, not page Q. The latter error can be detected if the checksum \non Q is a function of both the address of Q and its content. \n We assume that all this complexity is hidden by the hardware and software I/O system that implements read \nand write operations. That is, each write operation either overwrites the intended page or does nothing. And each \nread operation returns a complete disk page or an error indicating that the page is corrupted. Recovery algo-\nrithms for system failure make heavy use of this property of disks, that page operations are atomic. So if trans-\nactions read and write complete pages, the atomicity of page writes offers a clean model we can use to reason \nabout the state of the database after a failure. \n Suppose a page can hold multiple records, transactions write records not pages, and the data manager uses \nrecord-level locks. In that case, multiple transactions can lock and update different records within a single page. \nIf they do, then at recovery time a page may contain records that were recently updated by different transac-\ntions, only some of which have committed. Depending on the state of the page, some of the committed updates \nmay need to be reapplied, while others need to be undone. The bookkeeping to sort this out is quite challenging. \nThis complexity is a problem worth solving, but for pedagogical reasons, it’s one we’ll postpone for awhile. \nInstead, to keep things simple, we will use page granularity for everything: \n ■  The database consists of a set of pages. \n ■  Each update by a transaction applies to only one page. \n7.4 The System Model  197\n",
      "content_length": 4369,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 217,
      "content": "198  CHAPTER 7 System Recovery\n ■  Each update by a transaction writes a whole page (not just part of the page). \n ■  Locks are set on pages. \n Page granularity simpliﬁ es the discussion, but it is too inefﬁ cient for high performance systems. After we \ndescribe recovery using this assumption, we’ll show what happens when we allow ﬁ ner grained updates and \nlocks on records. \n Storage Model \n We model storage as two areas: stable storage (usually disk) and volatile storage (usually main memory) (see \n Figure 7.6 ). Stable storage contains the  stable database , which has one copy of each database page. It also \ncontains the log, which we’ll discuss in a moment. \n Volatile storage contains the database  cache . The cache contains copies of some of the database pages, \nusually ones that were recently accessed or updated by transactions. Using a cache is a big performance win, \nbecause it helps transactions avoid the high cost of disk accesses for popular pages. \n For recovery purposes, it really doesn’t matter which pages are in cache, only that there are some. Pages \nin cache may contain updates that have not yet been written to stable storage. Such pages are called  dirty . \nCorrectly handling dirty pages is an important responsibility of the recovery system during normal operation. \n The  cache manager keeps track of what is in cache. It is part of the page-oriented ﬁ le system layer of a \ndata manager, as shown in Figure 6.4. It divides the cache into  slots , each of which can hold one database page. \nIt uses a table to keep track of what is in each slot. Each row of the table contains a  cache descriptor , which \nidentiﬁ es the database page that is in the cache slot, the main memory address of the cache slot, a bit to indicate \nwhether the page is dirty, and a pin count (explained below; see  Figure 7.7 ). The cache manager supports ﬁ ve \nbasic operations: \n ■  Fetch(P): P is the address of a database page. This reads P into a cache slot (if it isn’t already there) and \nreturns the address of the cache slot. \nStable database\nFetch, Flush\nPin, Unpin\nDeallocate\nCache\nRead, Write\nRead, Write\nLog\nCache manager\n FIGURE 7.6 \n The Storage Model. The cache manager controls the movement of pages between stable storage (the stable database \nand log) and volatile storage (the cache). \n",
      "content_length": 2320,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 218,
      "content": " ■  Pin(P): This makes page P’s cache slot unavailable for ﬂ ushing (it is  “ pinned down ” ). Usually, a caller \npins P immediately after fetching it. \n ■  Unpin(P): Releases the caller’s previous pin. The cache manager maintains a  pin count for each page, \nwhich is incremented by each Pin operation and decremented by each Unpin. If the pin count is zero, the \npage is available for ﬂ ushing or deallocation. \n ■  Flush(P): If database page P is in a cache slot and is dirty, then this operation writes it to the disk. It does \nnot return until after the disk acknowledges that the write operation is done. That is, a ﬂ ush is a synchro-\nnous write. \n ■  Deallocate(P): Deallocates P so its cache slot can be reused by another page. Does not ﬂ ush the page, \neven if the cache slot is dirty. It is up to the cache manager’s clients to ﬂ ush a page (if appropriate) \nbefore deallocating it. \n Everything else that happens to pages is up to the transactions. If a transaction has fetched and pinned a \npage, it can do what it wants to the content of that page, as far as the cache manager is concerned. Of course, \nwe know the transaction will have an appropriate lock to read or write the page, but this is at a higher layer than \nthe cache manager, which doesn’t know anything about these locks. \n The cache manager is heavily used by data manager components that read and write the database. This is \nusually the record management layer of the data manager (i.e., the Access Method layer in Figure 6.3), which \nreads and writes records and provides indexed access to data. To read or write data on a page P, this component \nissues Fetch(P) followed by Pin(P). When it’s done reading or updating the page, it calls Unpin(P). It does not \ncall Flush(P). \n It is up to two other data manager components to call Flush(P). One is the cache manager’s page replace-\nment algorithm. Its job is to make the best use of cache by keeping only those pages that transactions are likely \nto need in the near future. If a page P hasn’t been referenced in awhile, it deallocates P from its page slot. If P \nis dirty, then it calls Flush(P) before Deallocate(P), so that recent updates to P aren’t lost. \n The other component that uses Flush(P) is the recovery manager, which is described in the next section. \n The Log \n The  log is a sequential ﬁ le, usually kept on disk, that contains a sequence of records that describes updates that \nwere applied to the database. The record that describes an update includes \n ■  The address of the page that was updated \n ■  The identiﬁ er of the transaction that performed the update \nPage\nDirty Bit\nCache Address\nPin Count\nP4\n1\n104\n1\nP16\n0\n376\n1\nP5\n1\n400\n0\n FIGURE 7.7 \n Cache Descriptor Table. Each page in a cache slot is described by a row in this table. \n7.4 The System Model  199\n",
      "content_length": 2816,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 219,
      "content": "200  CHAPTER 7 System Recovery\n ■  The value of the page that was written, called its  after-image \n ■  The value of the page before it was written, called its  before-image \n As described here, each log record is over two pages long, which is much too inefﬁ cient. Like our other \npage granularity assumptions, we’ll weaken it later on. \n This log record is written by the same component that writes to the cache. That is, whenever it updates a \ncache page, and before it unpins that page, it writes a log record that describes the update. That way, the log is \nalways consistent with the contents of the cache. \n The log also contains records that report when a transaction commits or aborts. Such records just contain \nthe identiﬁ er of the transaction and an indication whether the transaction committed or aborted. \n It is crucial that the log accurately reﬂ ects the order in which conﬂ icting operations really executed. That is, \nif one update precedes and conﬂ icts with another update in the log, then the updates must really have executed \nin that order. The reason is that after a failure, the recovery system will replay some of the work that happened \nbefore the failure. It will assume that the order of operations in the log is the order it should replay work. Note \nthat it is not necessary that the log accurately reﬂ ect the ordering of  all updates, only the conﬂ icting ones, \nwhich are the only ones whose relative order makes a difference. Some systems exploit this distinction by log-\nging nonconﬂ icting updates in parallel in  “ sublogs ” and merging those sublogs later, when conﬂ icting updates \noccur. \n Page -level locking ensures this ordering is enforced. If ﬁ ner granularity locking is used, then two transac-\ntions can update a page concurrently, so the database system must ensure that it updates the page and writes \nthe log record on behalf of one transaction before it performs these two actions on behalf of the other. This is \ndone by setting a short-term exclusive lock on the page, called a  latch , which can simply be a bit in the cache \ndescriptor. The latch brackets the activities of updating the page and logging the update (see  Figure 7.8 ). The \nlatch ensures that if another transaction was concurrently attempting the same sequence, then its update and log \noperations would either precede or follow those of T. \n Setting and releasing latches is done more frequently than setting and releasing locks. It therefore must be \nvery fast — just a few instructions. Thus, in most systems, no deadlock detection is done based on latches. So \nlots of care is needed to ensure that such deadlocks cannot occur. \n Whereas most systems store before-images and after-images in the same log, some use separate logs. \nThis is done because before-images are not needed after a transaction commits and usually are not needed \nfor media recovery. They can therefore be deleted relatively quickly, unlike after-images, which are needed \nfor very long periods. However, this can also lead to extra log writes, since there are now two logs to deal \nwith. \nFetch (P)                        /* read P into cache */\nPin (P)                            /* ensure P isn’t flushed */\nwrite lock P                    /* for two-phase locking */\nlatch P                            /* get exclusive access to P */\nupdate P                         /* update it in the cache */\nlog the update to P \n \n/* append it to the log */\nunlatch P                        /* release exclusive access */\nUnpin (P)                        /* allow P to be flushed */\n FIGURE 7.8 \n Using Latches. Obtaining a latch on P ensures that the ordering of log records is consistent with the order of updates to \neach page. \n",
      "content_length": 3725,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 220,
      "content": " 7.5  DATABASE RECOVERY MANAGER \n The recovery manager is the component that is responsible for processing commit and abort operations. It is \nalso responsible for the restart operation, which initiates recovery from a system failure, to bring the database \nback into a consistent state where it can process transactions again. In summary, the operations should have the \nfollowing effects (see  Figure 7.9 ): \n ■  Commit(T i ): Permanently installs T i ’s updated pages into the stable database. Its effect must be atomic, \nthat is, all-or-nothing, even in the event of a system failure. Also, its effect is irrevocable; once the trans-\naction is committed, it cannot subsequently be aborted. \n ■  Abort(T i ): Restores all the data that T i updated to the values it had before T i executed. Like Commit, its \neffect is irrevocable: once the transaction is aborted, it cannot subsequently be committed. \n ■  Restart: Aborts all transactions that were active at the time of the system failure. Also, any updates by \ncommitted transactions that were not installed in the stable database before the failure are installed now. \n(They may have been written only to the log and may not have made it to the stable database before the \nfailure.) The result should be that the database contains all committed updates and no aborted ones. \n To implement these operations, the recovery manager must follow certain rules. The essence of these rules \nis in controlling when dirty data is ﬂ ushed to disk. \n Implementing Abort \n Consider the operation Abort(T i ). Suppose T i wrote page P and no other transaction wrote P since P was last \nread from stable storage. If P was not transferred to stable storage after the time that T i ﬁ rst wrote P, then the \nrecovery manager can simply deallocate P. Otherwise, it has to write P’s before-image to the stable database; \nCommit, Abort\nRestart\nTransactions\nProgramming interface\nto low-level storage and\nrecovery subsystem\nRecovery manager\nCache\nRead, Write\nRead, Write\nFetch\n   Pin\n     Unpin\nFlush\nDeallocate\nT2\nCache manager\nT1\nTn\n FIGURE 7.9 \n Recovery Manager Model. The recovery manager calls the cache manager to help it implement the commit, abort, and \nrestart operations. \n7.5 Database Recovery Manager  201\n",
      "content_length": 2253,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 221,
      "content": "202  CHAPTER 7 System Recovery\n that is, it must restore P’s value to what it was before T i executed. Ordinarily, this is straightforward, since \nT i logged its update to P and the log record contains P’s before-image. However, what if the abort is being \nexecuted to help recover from a system failure? That is, T i was executing at the time of the system failure and \nthe restart procedure is executing Abort(T i ) to clean things up. It is conceivable that T i ’s update to P was trans-\nferred to the stable database before the failure, but its update to the log was not transferred to stable storage \nbefore the failure (see  Figure 7.10 ). In this case, T i ’s update to P cannot be undone, because the before-image \nhas been lost. This unacceptable situation must be prevented by enforcing the following rule: \n The Write-Ahead Log Protocol: Do not ﬂ ush an uncommitted update to the stable database until the log \nrecord containing its before-image has been ﬂ ushed to the log. \n There is a simple way to avoid the bookkeeping required to enforce this rule, namely, never ﬂ ush an uncom-\nmitted update to the stable database. Just ﬂ ush it to the log. This is sometimes called a  no-steal approach, \nbecause a cache slot occupied by an updated page is never  “ stolen ” so it can be used to store another page that \nis read in. After the transaction has committed, then ﬂ ush the page containing the update to the stable database. \nThat way, you never have to worry whether the before-image is in the log, because it will never be necessary to \nundo an uncommitted update in the stable database. That is, undo will never be required. For this reason, it is \nsometimes called a  no-undo strategy. \n Some systems avoid the bookkeeping by maintaining multiple versions of each page, as discussed in \nSection 6.6, on query-update problems. Instead of overwriting a page, they create a new version of the page. \nPeriodically, old versions that are no longer needed are purged. By keeping old versions in the database itself, \nbefore-images need not be logged, so the write-ahead log protocol is automatically satisﬁ ed. \n Implementing Commit \n Now let’s consider the operation Commit(T i ), and suppose T i wrote page P. Since a transaction’s results must \nbe durable and Commit is atomic, all of T i ’s updates must be in stable storage before the Commit — in the log \n1. Update P\nCache\n2. Update P\nSystem crashes after (2),\nso (3) never executes\n3. Write P’s before-image\nTi\nStable\ndatabase\nLog\nP\n FIGURE 7.10 \n Why We Need the Write-Ahead Log Protocol. If T i is active when the system fails, then it can’t be aborted after recovery, \nbecause P’s before-image was lost. \n",
      "content_length": 2677,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 222,
      "content": " or in the stable database. In particular, the after-image of T i ’s update to P (that is, the value that T i wrote to P) \nmust be there. This means that the recovery manager must enforce another rule: \n The Force-at-Commit Rule: Do not commit a transaction until the after-images of all its updated pages are \nin stable storage (in the log or the stable database). \n A simple way to implement the force-at-commit rule is to ﬂ ush a transaction’s updates to the stable database \nbefore it commits. This is sometimes called a  force approach, because all of a transaction’s updates are forced \nto the stable database before commit. This avoids any bookkeeping required to know which updates are not in \nthe stable database and therefore have to be ﬂ ushed in the log before commit. It also avoids any redo of commit-\nted updates, because they are always in the database before they are committed. For this reason, it is sometimes \ncalled a  no-redo strategy. However, it is inefﬁ cient for hot pages; that is, those that are frequently updated. As \nwe will see, the best logging algorithms avoid this inefﬁ ciency, although it requires some complex bookkeeping. \n Notice that the no-steal approach for enforcing the write-ahead log protocol and the force approach for \nenforcing force-at-commit rule are contradictory (see  Figure 7.11 ). Whichever approach is taken, it would \nseem that some undo or redo will be required. Although logging algorithms do indeed perform some undo \nand/or  redo, there are techniques that avoid both, which are described in the next section. \n The third operation of the recovery manager is restart. Restart requires a fair bit of bookkeeping. It needs to \nknow which transactions were active at the time of the failure, so it can abort them, and which updates of com-\nmitted transactions were not written to the stable database, so it can redo them. Moreover, restart must be fault-\ntolerant in the sense that if the system fails when restart is running, it must be possible to re-execute  restart. \nThat is, restart must be idempotent. This means that restart must be careful that, at all times, the system is in a \nstate from which restart can correctly execute (which is exactly the same requirement that normal executions \nhave). This requires carefully ordering updates to stable storage. \n Given all these rules, we are ready to look at algorithms that implement a recovery manager. A good recov-\nery manager algorithm should add little overhead to the normal processing of transactions. The principal ways \nit can contribute overhead is by ﬂ ushing pages too often (creating excess disk trafﬁ c) and by logging too much \ndata. A second goal is to recover quickly from a failure, so the system is only down for a short period. The \nshorter the downtime, the higher the availability. If the system could recover instantly from a failure, then it \ncould fail very often and no one would care (as long as it can commit some transactions!). \n 7.6  SHADOW-PAGING ALGORITHM \n Shadow paging is a simple way to implement a recovery manager. It is one of the easiest recovery algorithms \nto implement because it does not require a log manager, which is a relatively complex component. It is not \nwidely used in commercial products because it does not scale up to high transaction rates as well as logging. \nHowever, since it’s simple, we’ll describe it ﬁ rst. \nFlush all of Ti’s updates before\ncommit to avoid redo\nTi:      Start      . . .      Write(P)      . . .      Commit\nFlush all of Ti’s updates only\nafter commit to avoid undo\n FIGURE 7.11 \n Avoiding Undo or Redo. Depending on when a transaction’s updates are ﬂ ushed, undo or redo can be avoided. \n7.6 Shadow-Paging Algorithm  203\n",
      "content_length": 3721,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 223,
      "content": "204  CHAPTER 7 System Recovery\n The main idea is to store all of a transaction’s updates in a shadow copy of the database. There is also a \nmaster copy of the database, whose state represents the execution of all committed transactions and no aborted \nones. When the transaction commits, the shadow copy is swapped with the master copy of the database, thereby \ninstalling the updates. \n To enable this strategy, the master database is structured as a tree of pages. Let’s assume that the database \nconsists of a set of ﬁ les, where each ﬁ le is a sequence of pages. In this case, the root page of the master database \ncontains pointers to the root page of each ﬁ le. The root page of a ﬁ le is a page table that contains a sequence \nof pointers to the pages of the ﬁ le. To keep things simple, let’s assume that ﬁ les are small enough that pointers \nto all of the pages of a ﬁ le can ﬁ t in the ﬁ le’s root page. For example, in  Figure 7.12 the database has two ﬁ les, \nnamed A and B. File A has a page table identiﬁ ed by A Pt,m , where  “ m ” means  “ master. ” The ﬁ gure shows point-\ners to the ﬁ rst two pages of the ﬁ le, A 1 and A 2 . \n To keep this description simple, let’s assume that transactions execute serially. Thus, at most one transac-\ntion is active at any given time. \n In main memory each transaction has a cached copy of the page table of each ﬁ le it reads or writes. For \nexample, the cached page tables for transaction T i are shown in  Figure 7.12 . Initially, the contents of these \ncached page tables is the same as their content in stable storage. As the transaction executes, pages are fetched \ninto main memory. The transaction updates some of those pages. When one of those dirty pages is ﬂ ushed, it is \nwritten to an unused location of stable storage. That is, the previous copy of the page is not overwritten. Then, \nthe copy of the page table in main memory is updated to point to the updated page in stable storage, and the \nupdated page table entry is marked as  “ updated. ” For example,  Figure 7.13 shows the result of ﬂ ushing a new \nversion of page A 2 , where A 2,old is the original copy of the page before transaction T i performed its update and \nA 2,new is the version of the page that includes the update. \n To commit a transaction, do the following: \n 1.  For each page P that the transaction updated, if P is dirty in cache, then ﬂ ush it as described earlier. \n 2.  Initialize a list called UpdatedFiles to include the name of every ﬁ le updated by the transaction. \nA1\nA2\nStable Storage\nB1\nB2\nB3\nMain Memory\nDatabase\nRoot\nA\nB\nAPt,i\nBPt,i\n1\n1\n2\n3\n...\n2\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\n FIGURE 7.12 \n Tree-structured Database for Shadow Paging. There are two ﬁ les, A and B. A Pt,m is the master copy of ﬁ le A’s page table \nthat points to the pages of ﬁ le A, such as A 1 and A 2 . \n",
      "content_length": 2838,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 224,
      "content": " 3.  For each ﬁ le F in UpdatedFiles, do the following: \n ■  Set a write lock on F’s root page. Let L be its location in stable storage. \n ■  Read F’s root page into cache. Call this the shadow copy of F’s page table. \n ■  For each page of F that is marked as updated in F’s cached page table, copy that page’s entry from \nF’s cached page table into its shadow page table. \n ■  Write the shadow copy of F’s page table to an unused location L \u0002 of stable storage. \n ■  Replace L by L \u0002 in the entry for F in UpdatedFiles. \n For example, if a transaction updated page A 2 of ﬁ le A, and B 1 of ﬁ le B, then at the end of this procedure, \nthe state of main memory and stable storage would be as shown in  Figure 7.14 . \n When this is done, we repeat essentially the same process for the root page of the database, as follows: \n 1.  Set a write lock on the root page of the database. \n 2.  Read the root page of the database into cache. Call this the shadow copy of the database’s page table. \n 3.  For each ﬁ le F in UpdatedFiles, copy the associated pointer (to F’s shadow page table in stable storage) \ninto F’s entry in the database’s shadow page table. \n 4.  Overwrite the database’s root page in stable storage with the shadow copy of the database’s root page. \nThis write operation of a single page causes all the transaction’s updated pages to become part of the \nmaster database. \n 5.  Release all the locks that the transaction obtained on data pages, ﬁ le page tables, and the database’s root \npage. Discard the UpdatedFiles list and the transaction’s cached copies of page tables. \n As a result of step 4 (shown in  Figure 7.15 ) the shadow page tables of  Figure 7.14 are now master page \ntables. The former master page tables are now garbage and hence are labeled  “ g ” in the ﬁ gure (A Pt,g and B Pt,g ). \nThe old versions of pages updated by the transaction are also garbage, that is, pages A 2,old and B 1,old . \n To abort a transaction, simply discard all its updated pages in stable storage and cache. Since the database \nroot page and the page tables it points to are unchanged, none of the pages updated by the aborted transaction \nare part of the master database. Therefore, there is nothing to undo. \nA1\nA2,old\nA2,new\nStable Storage\nB1\nB2\nB3\nMain Memory\nDatabase\nRoot\nAPt,i\nBPt,i\n1\n1\n2\n3\n...\n2\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\nA\nB\nC\n...\nupdated bit\n FIGURE 7.13 \n The Result of Flushing a Dirty Page. An updated version of page A 2 has been ﬂ ushed to stable storage into an unused \nlocation. The main memory page table is updated to point to it and is marked as updated. \n7.6 Shadow-Paging Algorithm  205\n",
      "content_length": 2627,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 225,
      "content": "206  CHAPTER 7 System Recovery\n One loose end in this story is how to manage available space in stable storage. One approach is to use a \nlist of available space, call it Avail, and treat it as another ﬁ le. For example, Avail could be a bit map, a binary \narray where each bit Avail[ j ] indicates whether page  j of stable storage is available. \n Suppose Avail ﬁ ts in one page, and a pointer to Avail is stored in the database’s root page. When a transac-\ntion ﬂ ushes a page P for the ﬁ rst time, it needs to allocate a page in stable storage to hold the shadow copy of \nP. To do this, it reads a copy of Avail into cache (if it is not already there), identiﬁ es a page  k that is available, \nclears the bit in Avail, marks Avail[ k ] as updated, and stores the shadow copy of P in location  k . When the \nA1\nA\nB\nA2,old\nA2,new\nB1,new\nStable Storage\nB1,old\nB2\nB3\nMain Memory\nDatabase\nRoot\nAPt,i\nBPt,i\n1\n1\n2\n3\n...\n2\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\nA\nB\nC\n...\nupdated bit\nUpdated\nfiles\nAPt,s\nBPt,s\n1\n1\n2\n3\n...\n2\n...\n FIGURE 7.14 \n System State after Partial Commit. Transaction T i updated pages A 2 and B 1 . In the ﬁ rst part of the commit procedure, \nshadow page tables A Pt,s and B Pt,s are constructed and ﬂ ushed, and UpdatedFiles points to them. \nA1\nA2,old\nA2,new\nB1,new\nStable Storage\nB1,old\nB2\nB3\nMain Memory\nDatabase\nRoot\nAPt,g\nBPt,g\n1\n1\n2\n3\n...\n2\n...\nA\nB\nC\n...\nAPt,m\nBPt,m\n1\n1\n2\n3\n...\n2\n...\n FIGURE 7.15 \n System State after Commit. The shadow page tables of  Figure 7.14 are now master page tables. The former master page \ntables are now garbage. The UpdatedFiles list and transaction’s cached page tables have been deallocated. \n",
      "content_length": 1644,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 226,
      "content": " transaction commits, the updated entries in the cached copy of Avail are copied into the shadow copy of its \npage table, which is written to stable storage. \n Another loose end is how to allow two or more transactions to execute concurrently. In this case, each trans-\naction has a private copy of the page table of each ﬁ le it updates. This allows each transaction to keep track of \nthe pages it updated. In addition, to ensure that each transaction reads the last committed value of each page it \naccesses, a global copy of the master page table is also maintained in cache. When a transaction reads a page \nfor the ﬁ rst time, it uses the pointer in the global cached master page table, not the one in its transaction-local \ncached page table. To see why, suppose there are two active transactions, T 1 and T 2 , and the following sequence \nof operations executes: \n 1.  T 1 updates page A 1 of ﬁ le A. \n 2.  T 2 updates page A 2 of ﬁ le A. \n 3.  T 2 commits. \n 4.  T 1 reads page A 2 of ﬁ le A. \n In step (4), T 1 should read the value of A 2 produced by T 2 . However, after T 2 commits, T 1 ’s page table still \nhas a pointer to the original value of A 2 , not the one written by T 2 . Therefore, when T 1 reads A 2 , it needs to use \nthe pointer to A 2 in the master page table. \n We began this section by commenting that shadow paging is not used often in commercial products because \nit does not scale up to high transaction rates. The reason is step one of the commit procedure, which requires \nthat all pages updated by the transaction be written to the stable database. This is a lot of random I/O, which is \nrelatively expensive. \n Due to the force-at-commit rule, we cannot avoid writing all the transaction’s updates to stable storage \nbefore the transaction commits. However, we can do it more efﬁ ciently than in shadow paging by appending \nthose updates to a log, which is a sequential ﬁ le. Sequential writes to disk can be done about 100 times faster \nthan random writes to disk, because they avoid disk head movement and rotational latency. Therefore, a system \ncan reach a much higher transaction rate by writing sequentially to a log than writing randomly to the stable \ndatabase. Eventually, all updated pages need to be written back to the stable database. However, this can be \ndone lazily, so the rate of random writes has a smaller effect on transaction throughput. The details of making \nthis work are the subject of the next two sections. \n 7.7  LOG-BASED DATABASE RECOVERY ALGORITHMS \n Logging is the most popular technique for implementing a recovery manager. As we described earlier, the log \ncontains a record for each write, commit, and abort operation. \n Implementing Commit \n To process a commit operation, the recovery manager adds a commit record to the end of the log and ﬂ ushes \nthe log. The log manager is designed so that it doesn’t acknowledge the ﬂ ush operation until all the log pages \nin memory, up to and including the one being ﬂ ushed, have been written to disk and the disk has acknowl-\nedged that the disk writes completed successfully. At this point, the transaction has been committed and the \nrecovery manager can acknowledge this fact to its caller. \n Since all the transaction’s update records precede the commit record in the log, by writing the commit \nrecord and then ﬂ ushing the log, the recovery manager ensures that all the transaction’s updates are in stable \n7.7 Log-Based Database Recovery Algorithms  207\n",
      "content_length": 3477,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 227,
      "content": "208  CHAPTER 7 System Recovery\n storage. That is, it ensures that the force-at-commit rule has been satisﬁ ed. It doesn’t matter whether any of the \nupdated pages have been ﬂ ushed to the stable database. The updates are in the log, and the log is in stable stor-\nage, which is enough to satisfy the rule. \n Flushing the log to commit a transaction is a potential bottleneck. If the disk that holds the log can do  K \nsequential disk-writes per second, then  K is the maximum number of transactions per second for the whole \nsystem. This is too small a number for high performance systems. This is especially annoying because the \nlog page normally isn’t full when the ﬂ ush is invoked, so the full bandwidth of the disk isn’t being used. This \nobservation creates an opportunity to improve performance. \n A popular way to relieve this bottleneck is an optimization called  group commit . After adding a commit \nrecord to the log, the recovery manager introduces a small artiﬁ cial delay before ﬂ ushing the log page, some-\nthing on the order of  1 / K ; that is, a few milliseconds. During that period, if there are other transactions running, \nthey can add records to the end of the log — update records, commit records, and abort records. If the system \nis busy, then the chances are that the log page will ﬁ ll up during this period, and when the recovery manager \nreaches the end of the delay period, it will end up ﬂ ushing a full page. Thus, each ﬂ ush operation on the log \ncan commit many transactions, and the recovery manager is getting the full value of the disk bandwidth. If the \nsystem is not busy, then it doesn’t matter that a partially ﬁ lled log page is ﬂ ushed to disk, since not all the disk \nbandwidth is needed to support the transaction load. \n The group commit optimization is an example of a general-purpose technique called  boxcarring . When \nthere is a high ﬁ xed overhead per write operation, it pays to pack a lot of data in each operation. Another \nplace this arises is communication systems that have a high ﬁ xed cost to send a message independent of the \nmessage’s size. The term boxcar is a metaphor for the boxcar in a train, which has a high ﬁ xed cost to transport \nindependent of how full it is. \n Implementing Abort \n To process an abort operation, the recovery manager has to undo the updates of any database pages that were \nupdated by the transaction. It does this by tracing through the transaction’s log records, starting from the last \none, and installing the before-image of each page that was updated by the transaction. \n Sequentially searching the log for the transaction’s update records is rather inefﬁ cient. To avoid this \nsequential scan, the recovery manager maintains a linked list of all the transaction’s update records in the log. \nThe list header is a  transaction descriptor , which is a data structure that describes each transaction that it \nknows about (see  Figure 7.16 ). The descriptor includes a pointer to the last log record that was written by each \ntransaction. Each update record in the log contains a pointer to the previous update record written by the same \ntransaction. So, starting from the transaction descriptor, all the transaction’s update records can be scanned. \n Maintaining the list is easy. When a transaction writes an update record to the log, it includes a backpointer \nto the previous log record for that transaction. Then it updates the transaction descriptor to point to the new \nupdate record, which is now the last one for the transaction. \n There is still the matter of the write-ahead log protocol to consider. The system needs to ensure that it doesn’t \nﬂ ush a dirty page from the cache to the stable database unless all the update records that describe updates to that \npage by uncommitted transactions have already been ﬂ ushed to the log. To do this, it needs a little help from the \ncache manager. \n We need to add a ﬁ eld to the cache descriptor of each cache slot. This ﬁ eld points to the log page that we \nneed to worry about to enforce the write-ahead log protocol. That is, it contains the address of the log page that \ncontains the update record describing the last update to this cache slot’s page (see  Figure 7.17 ). Let’s call this \nthe  dependent log page address (there’s no standard term for this). Every time a database page P is updated, \nthe dependent log page address of P’s cache slot is also updated to point to the page containing the update’s \n",
      "content_length": 4471,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 228,
      "content": " log record. Before the cache manager ﬂ ushes a cache slot, it must check that the dependent log page is not in \ncache and dirty. If it is, then the dependent log page must be ﬂ ushed ﬁ rst, to ensure the write-ahead log proto-\ncol is satisﬁ ed. \n Although the cache manager has to check the dependent log page address every time it ﬂ ushes a page from \ncache, this rarely generates an extra cache ﬂ ush of the log page. The reason is this: The log is a sequential ﬁ le. \nAs soon as a log page ﬁ lls up, the log manager tells the cache manager to ﬂ ush it. By the time the cache man-\nager decides to ﬂ ush a database page, the chances are that the database page has been sitting around in cache \nfor awhile since it was last updated. For example, the cache replacement algorithm notices that the page hasn’t \nbeen accessed recently and therefore decides to replace it. Since the page hasn’t been accessed recently, the \nchances are that the dependent log page has already been ﬂ ushed. \n As we will see in a moment, even hot pages must eventually be ﬂ ushed. Since a hot page is updated \nfrequently, it may have update records in the tail of the log. So ﬂ ushing a hot page may be delayed until its \ndependent log page has been ﬂ ushed. \nTransaction Descriptors\nStart of log\nEnd of log\nT7\nBackpointer\n\u0003\u0003Null\nrest of log\nrecord\nT7\nBackpointer\nrest of log\nrecord\nTransaction\nPointer to last\nlog record\nT7\nT7’s first log record \nT7’s second log record \nLog records from \nother transactions\nLog records from \nother transactions\n FIGURE 7.16 \n Data Structure Supporting Abort Processing. Starting from the transaction descriptor, all the transaction’s update records \ncan be scanned. \nPage\nDirty Bit\nCache Address\nPin Count\nDependent Log\nPage Address\nP4\n1\n104\n1\nP16\n0\n376\n1\nP5\n1\n400\n0\n1218\nnull\n1332\n FIGURE 7.17 \n Dependent Log Page Address. Before ﬂ ushing a page, the cache manager must check that the dependent log page is not \nin cache and dirty. \n7.7 Log-Based Database Recovery Algorithms  209\n",
      "content_length": 1996,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 229,
      "content": "210  CHAPTER 7 System Recovery\n Implementing Restart \n To implement restart, the recovery manager scans the log to ﬁ gure out which transactions need to be aborted \nand which committed updates need to be redone. As many algorithms of different complexities are in use, \nwe’ll start with a simple one and optimize it as we go. \n All restart algorithms depend on the recovery manager to perform checkpoint operations periodically, which \nsynchronize the state of the log with the state of the stable database. The simplest checkpoint algorithm does the \nfollowing: \n 1.  It stops accepting any new update, commit, and abort operations. It waits until all active update, com-\nmit, and abort operations have ﬁ nished. \n 2.  It makes a list of all active transactions along with each transaction’s pointer to its last log record. \n 3.  It ﬂ ushes all the dirty pages in cache. \n 4.  It writes a  checkpoint record to the log, which includes the list of active transactions and log pointers. \n 5.  It resumes accepting new update, commit, and abort operations again. \n At this point, the stable database state is exactly consistent with the state of the log. We’ll explain a more \nefﬁ cient checkpointing algorithm in a moment, but for now, let’s assume we’re using this one. \n The restart algorithm scans the log forward and fully processes each log record before proceeding to the \nnext. Its goal is ﬁ rst to redo all updates that executed after the last checkpoint and then to undo the ones that \ndid not commit. It starts at the last checkpoint record. There is no point in looking at log records before the last \ncheckpoint record, because their effects have been fully recorded in the stable database (see  Figure 7.18 ). The \nrestart algorithm maintains lists of committed and aborted transactions, which are initially empty; and a list of \nactive transactions, which is initialized from the last checkpoint record. When the restart algorithm encounters \na new log record, it does the following: \n ■  If the log record is an update record, then it writes the after-image of the update to the cache, and it adds the \ntransaction’s identiﬁ er to the active list if it isn’t already there. Notice that even if the update is already in \nthe stable database, there is no harm in writing the after-image, because the after-image contains an entire \npage image. (Remember our simplifying assumption that each update writes a whole page.) So at worst, it’s \njust redoing work needlessly. \n ■  If the log record is a commit record, it adds the transaction to its commit list and removes it from the \nactive list. \n ■  If the log record is an abort record, it undoes all of the transaction’s updates in the same way as it nor-\nmally processes an abort. Also, it adds the transaction to its abort list and removes it from the active list. \nLast checkpoint\nAll updates preceding the last\ncheckpoint are in the stable database.\nStart of Log\nEnd of Log\nCheckpoint\nPrefix of the log \n FIGURE 7.18 \n Basic Checkpointing. All dirty pages are ﬂ ushed before a checkpoint record is written. \n",
      "content_length": 3074,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 230,
      "content": " When it reaches the end of the log, it has redone all the updates of committed and active transactions, and \nwiped out the effects of any aborted transactions. At this point, the active list contains any transactions that \nstarted running before the failure but did not commit or abort before the failure. (Notice that since the active \nlist was initialized from the last checkpoint record, this includes transactions that were active at the last check-\npoint but did not subsequently commit or abort.) These transactions cannot continue running, since they lost \ntheir memory state during the system failure, so the restart algorithm aborts them too. Now the system is ready \nto process new transactions, since the combined state of the cache and stable database includes all committed \nupdates and no aborted ones. \n As long as the restart algorithm is running, users are unable to run transactions. Therefore, it’s important to \noptimize it to minimize its running time and therefore maximize the system’s availability. These optimizations \nare the subject of the next section. \n 7.8  OPTIMIZING RESTART IN LOG-BASED ALGORITHMS \n Fuzzy Checkpointing \n Checkpoints are an important way of speeding up the restart algorithm. The more frequently the system runs a \ncheckpoint, the less log that the restart algorithm will have to process, and therefore, the less time it will take \nto run restart. However, checkpointing isn’t free. The checkpointing algorithm described earlier does quite a lot \nof work and causes the system to stop processing new requests for awhile, until it has ﬁ nished ﬂ ushing all the \ndirty pages in cache. We need a cheaper way to checkpoint, so we can afford to checkpoint often and thereby \nspeed up the restart algorithm. \n The solution is called  fuzzy checkpointing . To do a checkpoint, the recovery manager does the following: \n 1.  It stops accepting any new update, commit, and abort operations. \n 2.  It scans the cache to make a list of all the dirty pages in the cache. \n 3.  It makes a list of all active transactions along with each transaction’s pointer to its last log record. \n 4.  It writes a checkpoint record to the log, which includes the list of active transactions and log pointers, \nand it allows normal operation to resume. \n 5.  It resumes accepting new update, commit, and abort operations. \n 6.  In parallel with running new update, commit and abort operations, it issues ﬂ ush operations to write to \nthe stable database all the dirty pages on the list it gathered in step (2). These are low priority operations \nthat the cache manager should do only when it has spare capacity. It may take awhile. \n The recovery manager is allowed to do another checkpoint operation only after step (6) completes; that is, \nonly after those dirty old pages have been ﬂ ushed. Thus, by the time the next checkpoint record is written, all \nthe updates that preceded the previous checkpoint record must be in the stable database. \n Let ’s revisit the restart algorithm with this fuzzy checkpointing algorithm in mind. Notice that it’s the \nsecond-to-last (i.e., penultimate) checkpoint record that has the property we’re looking for (see  Figure 7.19 ). \nAll the updates in the log that precede the penultimate checkpoint record must be in the stable database. The \ncheckpointing algorithm would not have written the last checkpoint record until it knew this was true. So, the \nrestart algorithm should start with the penultimate checkpoint record. By contrast, in the simple checkpointing \nalgorithm of the previous section, all updates before the last checkpoint record were in the stable database, so \nit started with the last checkpoint record, not the penultimate one. \n Notice that fuzzy checkpointing is a relatively fast activity. It needs to stop processing momentarily, to \nexamine the cache and write a checkpoint record. It then writes out dirty pages in parallel with normal operation. \n7.8 Optimizing Restart in Log-Based Algorithms  211\n",
      "content_length": 3991,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 231,
      "content": "212  CHAPTER 7 System Recovery\n If possible, these writes should run at low priority so they don’t block reads by active transactions. Assuming \nthere is enough disk bandwidth to process these reads and writes (which is needed in any case), these random \nwrites have very little impact on the performance of active transactions. Thus, checkpointing can be run fre-\nquently, to minimize the amount of work that restart has to do. \n The fuzzy checkpointing algorithm is so important to transaction performance and restart speed, it is worth \noptimizing it heavily. Commercial implementations use many optimizations of the algorithm described here. \n Operation Logging \n It is very inefﬁ cient to write the entire before-image and after-image of a page every time a transaction does \nan update, since most updates modify only a small portion of a page. Worse yet, it does not work correctly if \nthe database system does record-granularity locking. For example, suppose the system logs before-images and \nafter-images of pages, records  x and  y are on the same page P, and we have the following execution: \n E\nw [ ] w [ ] abort  commit\n1\n2\n\u0003\nx\ny\n2\n1\n \n When transaction T 1 aborts, we cannot install its before-image of P, since this would wipe out T 2 ’s update \nto  y . This is essentially the same problem we ran into at the beginning of Section 7.4, on Locking Assumptions, \nwhere we argued for holding write locks until after the transaction commits. \n A solution is to have each update record include only the before-image and after-image of the record that it \nactually updates on a page. This kills two birds with one stone. It greatly reduces the amount of logging, and \nit allows us to support record-level locking. It does have one unfortunate side-effect, though. The restart algo-\nrithm has to read the page from disk before applying the update. This wasn’t needed with page-level logging, \nbecause the log contained a complete copy of the page. Since logging is a much more frequent operation than \nrestart, this is a net win, but it does create another activity that needs to be optimized by the restart algorithm. \n We can reduce the amount of logging even further by recording only a  description of the change that was \nmade rather than the entire record. The description must have enough information that we can undo or redo the \nchange, but no more than that. That is, it doesn’t necessarily have to include the entire before-image and after-\nimage of the record. For example, if the update modiﬁ es only one ﬁ eld of a record, the update record needs \nto contain only the identity of the record (e.g., its key), the identity of the ﬁ eld (e.g., its byte range within \nthe record), and the before-image and after-image of the modiﬁ ed ﬁ eld, plus the name of the operation being \nperformed (e.g.,  “ update-ﬁ eld ” ), so the restart algorithm will know how to interpret the log record later. As \nanother example, the update record might describe the insertion of a record, in which case it needs to log only \nthe after-image of the record, since there is no before-image. \nLast checkpoint\nAll updates preceding the second-to-last\ncheckpoint are in the stable database.\nStart of Log\nEnd of Log\nCheckpoint\nCheckpoint\nPrefix of the log\nSecond-to-last checkpoint\n FIGURE 7.19 \n Fuzzy Checkpointing. After a checkpoint record is written, all dirty cache pages are ﬂ ushed. The ﬂ ushes must be \ncompleted before the next checkpoint record is written. \n",
      "content_length": 3463,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 232,
      "content": " By reducing the amount of logging this way, we have complicated the restart algorithm. It can no longer \nsimply start at the penultimate checkpoint record and redo update records, because the redo operations might \nnot be applicable to the stable database page in its current state. For example, it would be wrong to insert a \nrecord on a page if that record is already there, because that would put two copies of the record on the page. \nThe reason that the insert is not applicable is because it already executed and it is not idempotent. \n The restart algorithm has to know whether an update record is applicable to a page before redoing the \nupdate. To do this, each page is given a header that includes the log address of the last log record that was \napplied to the page (see  Figure 7.20 ). This is called the  log sequence number ( LSN ). After an update is per-\nformed on the page and the log record is written to the log, the LSN is written to the page header before releas-\ning the latch on the page. This allows the restart algorithm to tell whether a page includes an update before \nredoing it: If LSN(database-page)  \n  LSN(log-record), then the log-record’s update is already on the page and \nshould not be redone (see  Figure 7.21 ). \n This LSN idea is useful, but it complicates undo operations. When the restart algorithm undoes an update \nto abort a transaction, T 1 , there is no LSN that accurately describes the state of the page relative to the log. To \nvisualize the problem, consider the example in  Figure 7.22 . Transactions T 1 and T 2 update different records R 1 \nand R 2 , respectively, on the same page, P. T 2 writes to P (at LSN 222) after T 1 and then T 2 commits (at LSN \n223). When T 1 aborts (at LSN 224), what LSN should it write in P? It cannot use the LSN of the last update to \nP that preceded its update (219), since that would say that T 2 ’s update did not execute, which is wrong. It cannot \nuse the LSN of T 2 ’s update either (222), since that says T 1 ’s update was done but not undone. \nLog record describing\nlatest update to P\nEnd of Log\nLSN \u0003 4275\nUpdate(P)\nLSN \u0003 4275\nPage P\n FIGURE 7.20 \n Storing Log Sequence Numbers (LSNs) in Pages. When updating a page, include the LSN of the log record describing the \nupdate. \nLog record describing\nan update to P\nDuring redo recovery, apply\na log record to P if and only if\nLSN(P) \u000b x.\nEnd of Log\nLSN \u0003 x\nUpdate(P)\nLSN(P)\nPage P\n FIGURE 7.21 \n Interpreting LSNs during Recovery. Redo an update if and only if the page’s LSN indicates that the update isn’t already \nthere. \n7.8 Optimizing Restart in Log-Based Algorithms  213\n",
      "content_length": 2620,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 233,
      "content": "214  CHAPTER 7 System Recovery\n A good solution to this problem is to log undo operations. That is, when T 1 aborts, each time it undoes an \nupdate operation, say on page P, it writes a log record that describes that undo and it uses the LSN of that log \nrecord in P’s page header. This is called an  undo record or  compensation log record . Now the LSN of the \nundo record accurately describes the state of the page relative to the log. See  Figure 7.23 . \n Logging undo’s has an interesting side effect: Committed and aborted transactions look exactly the same \nin the log. They both have a sequence of update operations followed by an operation that says the transaction \nis done (committed or aborted). The restart algorithm processes both kinds of transactions in the same way, \nnamely, it redoes their updates. For aborted transactions, some of those redo operations are applied to undo \nrecords, but the restart algorithm doesn’t care. It redoes them just like ordinary update records. The only trans-\nactions that the restart algorithm actually has to abort by scanning the log backward are those that were active \nat the time of the failure. \n Suppose a transaction T is in the midst of aborting when the system fails. That is, T may have written undo \nrecords for some but not all of its update records. When the system recovers, the restart algorithm sees that \nLSN 224\naccurately\ndescribes the\nstate of P.\nLSN \u0003 219\nupdate0(R2)\nLSN \u0003 218\nupdate0(R1)\nPage P\nPage P\nPage P\nPage P\nPage P\nLSN \u0003 220\nCommit0\nLSN \u0003 221\nupdate1(R1)\nLSN \u0003 222\nupdate2(R2)\nLSN \u0003 223\nCommit2\nLSN \u0003 224\nundo(update1(R1))\nLSN \u0003 225\nAbort1\nLSN \u0003 222\nLSN \u0003 224\nNew R2\nOld R1\nNew R2\nNew R1\nLSN \u0003 221\nOld R2\nNew R1\nLSN \u0003 219\nOld R2\nOld R1\nLSN \u0003 218\nOld R1\n FIGURE 7.23 \n Using an Undo Log Record. If the undo operation is logged, its LSN can be installed on page P to record the fact that the \nupdate was undone. \nWhat LSN should\nbe written in P?\n(See text.)\nLSN \u0003 219\nupdate0(R2)\nLSN \u0003 218\nupdate0(R1)\nLSN \u0003 220\nCommit0\nLSN \u0003 221\nupdate1(R1)\nLSN \u0003 222\nupdate2(R2)\nLSN \u0003 223\nCommit2\nLSN \u0003 224\nAbort1\nLSN \u0003 218\nOld R1\nPage P\nLSN \u0003 219\nOld R1\nOld R2\nPage P\nPage P\nLSN \u0003 221\nNew R1\nOld R2\nNew R1\nNew R2\nPage P\nLSN \u0003 222\nLSN \u0003 ?\nOld R1\nNew R2\nPage P\n FIGURE 7.22 \n Installing an LSN during Undo. The state of page P is shown after logging each update. When aborting T 1 , there is no \nLSN to store in P that accurately describes P’s state. \n",
      "content_length": 2417,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 234,
      "content": " T was active at the time of the failure. Therefore, it undoes all of T’s updates, not just the update records for \nT but also the undo records. For example, in  Figure 7.24 transaction T 1 was aborting at the time the system \nfailed. Before the failure, it performed the undo for LSN 112 and recorded that fact in the undo record with \nLSN 113. However, it didn’t complete the abort before the system crashed. After recovery, the restart algo-\nrithm sees that T 1 was active when the system crashed, so it performs undo operations for LSN 113, 112, and \n111, in that order, thereby writing undo records with LSNs 114, 115, and 116, respectively. \n This activity of undoing undo records is redundant. It can be avoided by splicing undo records out of the \nchain of transaction backpointers, as shown in  Figure 7.25 . To do this, each undo record points to the next \nupdate record to be undone. For example, in the ﬁ gure the undo record with LSN 113 points to the update \nrecord at LSN 111. To ﬁ nish aborting T 1 during restart, the restart algorithm starts with the last log record for \nT 1 , which is at LSN 113, and follows its backpointer to the next update to be undone, in this case the update at \nLSN 111. \n Another useful optimization is to avoid unnecessary page fetches by recording ﬂ ush operations in the log. \nThat is, after the cache manager ﬂ ushes a page and before it allows any further updates to the page, it adds a \n ﬂ ush record to the log, which includes the address of the page that was ﬂ ushed. This record tells the restart \nalgorithm that all updates to that page that precede the ﬂ ush record are already on disk and therefore do not \nneed to be redone. In effect, it is a per-page checkpoint record. \nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nCrash!\nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nLSN \u0003 114\nundo(undo(update1(R2)))\nLSN \u0003 115\nundo(update1(R2))\nLSN \u0003 116\nundo(update1(R1))\nLSN \u0003 117\nabort1\nBefore system fails\nAfter Restart aborts T1\n FIGURE 7.24 \n Undoing Undo Records. During Restart, T 1 ’s undo record at LSN 113 needs to be undone, as does the update at LSN \n112, again. \nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nCrash!\nLSN \u0003 111\nupdate1(R1)\nLSN \u0003 112\nupdate1(R2)\nLSN \u0003 113\nundo(update1(R2))\nLSN \u0003 114\nundo(update1(R1))\nLSN \u0003 115\nabort1\nBefore system fails\nAfter Restart aborts T1\n FIGURE 7.25 \n Splicing Out Undo Records. Each undo record points to the next update record that needs to be undone. \n7.8 Optimizing Restart in Log-Based Algorithms  215\n",
      "content_length": 2586,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 235,
      "content": "216  CHAPTER 7 System Recovery\n A good way to use ﬂ ush records during recovery is to pre-analyze  the log before the redo phase. To enable \nthis process, in each checkpoint record, each page in the list of dirty pages is augmented with the oldest LSN \nthat must be redone to that page. This requires some additional bookkeeping by the cache manager, which needs \nto associate that oldest LSN with each cache slot, assign it when a clean page is ﬁ rst updated, and clear it when \nthe page is ﬂ ushed. This list of dirty pages with their oldest LSNs to redo is called a  dirty page table . \n The pre-analysis  phase of the restart algorithm does a preliminary log scan starting at the penultimate check-\npoint and moving forward toward the end of the log. The goal is to create a dirty-page table that, to the extent \npossible, describes the state of the cache at the time of failure. To initialize the undo phase of restart, it also \nbuilds a list of active transactions that includes the last LSN of each transaction. During this scan, there are four \ntypes of log records of interest: update, ﬂ ush, commit, and abort. \n ■  Update i (P): If page P is not in the dirty-page table, then add it and set its oldest LSN to be the LSN of \nthis update record. If transaction T i is not already on the transaction list, then add it. Set T i ’s last LSN to \nbe the LSN of this update record. \n ■  Flush(P): Delete P from the dirty-page table. \n ■  Commit i or Abort i : Delete T i from the transaction list. \n At the end of this pre-analysis  phase, for each page in the dirty-page table there is at least one update record \nin the log after the last ﬂ ush record for the page. Therefore, the page needs to be updated during the redo phase. \nSaying this in reverse: The preanalysis phase avoids redoing any update records for page P if the last update \nrecord for P precedes the last ﬂ ush record for P. Normally, one would expect many update records to satisfy this \nproperty, so this preanalysis phase avoids useless page fetches during redo and hence speeds up restart. \n The dirty-page table also gives guidance on when a page needs to be fetched. Every page in the dirty-page \ntable needs to be read during restart, since there is at least one update record in the log that follows the last \nﬂ ush record for the page. Since the dirty page table includes the LSN of the oldest update to each page, the \nrestart algorithm can prefetch pages in increasing order of oldest LSN, so the pages will arrive in cache in the \norder they will be needed by redo scan, which further improves its performance. \n The restart algorithm described in this section is called ARIES, and was developed by C. Mohan and his \ncolleagues at IBM. The most important insight is the value of replaying history from the penultimate check-\npoint, so that at the end of the redo scan the log and database are mutually consistent. This makes it easy to see \nthat the restart algorithm is correct and enables complex reasoning leading to optimizations like splicing out \nundo records and using a dirty page table to reduce page fetches during restart. ARIES includes other optimi-\nzations not described here, such as taking checkpoints during restart, handling nested transactions and nested \ntop-level actions, and updating index structures. (See the Bibliographic Notes for references.) \n Many other tricky problems arise in implementing recovery algorithms, such as redundantly storing point-\ners to the checkpoint record (so the restart algorithm can ﬁ nd it even if there is a media failure), ﬁ nding the end \nof the log (it’s too expensive to update a disk-resident pointer to end-of-log every time the log is updated), and \nhandling multipage update records (what if only one of the pages is written before a failure?). These details \nare of interest mainly to people building recovery algorithms, and are therefore beyond the scope of this book. \n(See the Bibliographic Notes for further readings.) \n User Techniques \n Although most optimizations of system recovery are only available to database system implementers, there are \na few things that a user can do to speed up restart and thereby improve availability, such as the following: \n ■  If the checkpointing frequency can be adjusted by the system administrator, then increasing it will reduce \nthe amount of work needed at restart. Running a benchmark with different checkpointing frequencies \n",
      "content_length": 4425,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 236,
      "content": " will help determine the expense of using frequent checkpoints to improve recovery time. Depending on \nthe overhead of the checkpointing algorithm used, this might require buying extra hardware, to ensure \nsatisfactory transaction performance while checkpointing is being done. \n ■  Partition the database across more disks. The restart algorithm is often I/O-bound. Although it reads the \nlog sequentially (which is fast), it accesses the database randomly. Spreading the database over more \ndisks increases the effective disk bandwidth and can reduce restart time. \n ■  Increase the system resources available to the restart program. After the operating system recovers from \na failure, it runs recovery scripts that include calling the database restart algorithm. It may not allocate \nmain memory resources optimally, if left to its own defaults. The restart algorithm beneﬁ ts from a huge \ncache, to reduce its I/O. If memory allocation can be controlled, tuning it can help reduce restart time. \n In general, one should benchmark the performance of restart to determine its sensitivity to a variety of con-\nditions and thereby be able to tune it to balance restart running time against checkpointing overhead. \n 7.9  MEDIA RECOVERY \n A media failure is the loss of a portion of stable storage. This usually is detected when an attempt is made to \nread a portion of the stable database, and the disk responds with an error condition. Failure rates of stable stor-\nage devices are sensitive to many factors, and they change over time with changing technologies. That said, a \ntypical failure rate for magnetic disks is 2% to 8% per year, meaning that a system with 100 disks experiences \ntwo to eight irreparable disk failures per year. This is a sufﬁ ciently frequent occurrence that engineered solutions \nare needed to shield the system from the effect of a media failure and to enable recovery when a media failure \ndoes occur. The latter is similar to recovering from a system failure: Load a usable state of the stable database \nfrom some backup device, such as tape or another disk, and then use the log to bring that state up to date. \n Mirrored Disks \n Media failures are a fairly serious problem, since as we will see, it can take a signiﬁ cant amount of time to \nrecover from one. To avoid it, most TP systems use  mirrored (or  shadowed )  disks . This means they use two \nphysical disks for each logical disk that they need, so each disk has an up-to-date backup that can substitute for \nit if it fails. The mirroring is usually done in hardware, though operating systems also offer the feature in soft-\nware. In either case, each write operation is sent to both physical disks, so the disks are always identical. Thus, \na read can be serviced from either disk. If one disk fails, the other disk is still there to continue running until a \nnew disk can be brought in to replace the failed one. This greatly reduces the chances of a media failure. \n After one disk of a mirrored pair fails, a new disk must be initialized while the good disk is still function-\ning. Like mirroring itself, this is usually done in the hardware controller. The algorithm that accomplishes it \nusually works as follows: The algorithm scans the good disk and copies tracks, one by one, to the new disk. \nIt has a temporary variable that identiﬁ es the track currently being copied. While it is copying that track, no \nupdates are allowed to the track. Updates to tracks that already have been copied are written to both disks, \nsince these tracks are already identical on both disks. Updates to tracks that have not yet been copied are writ-\nten only to the good disk, since writing them to the new disk would be useless. This copying algorithm can run \nin the background while the good disk is handling the normal processing load. \n Like restart, it is important that this mirror recovery procedure be as fast as possible. While it is going on, \nthe good disk is a single point of failure. If it dies, then a media failure has occurred, at which point the only \nhope is to load an old copy of the database and use a redo log to bring it up to date. \n7.9 Media Recovery  217\n",
      "content_length": 4168,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 237,
      "content": "218  CHAPTER 7 System Recovery\n Even a fast mirror recovery procedure is intrusive. Mirror recovery does sequential I/O, whereas normal \noperation performs random I/O. So normal operation slows down mirror recovery and vice versa. Thus, the \nsystem needs enough spare disk bandwidth to do mirror recovery while giving satisfactory performance to \nusers. \n The failure of a log disk is especially problematic, since it affects all update transactions. There are many \ncreative ways to minimize the effect of mirror recovery on writes to the log. For example, advanced disk-\nmanagement software lets you set a low priority for repairing that mirror, but then mirror recovery is running \nmuch longer, during which time a second log disk failure would be a disaster. Another approach is to populate \nonly a small fraction of the mirrored log disk, say 10%. This cuts the rebuild time and increases the random I/O \nrate during that rebuild. Or one can build a triple mirror; if a disk fails, wait until a slack time to rebuild the third \ndrive of the mirror. Experienced database administrators build a synthetic load with peak log-write throughput \nand kill their log mirror to see if the system will continue to support the required service level agreement. \n The choice of disk conﬁ guration will be greatly affected by the increasing availability of affordable solid \nstate disks (SSDs). These disks perform sequential and random I/O at about the same speed. Therefore, ran-\ndom I/O is less disruptive to mirror recovery than with magnetic disks. However, the cost per gigabyte of SSDs \nis considerably higher than for magnetic disks, and this gap is expected to continue going forward. It may \ntherefore be desirable to use conﬁ gurations that contain both SSDs and magnetic disks. It is too early to pre-\ndict how the cost and performance tradeoffs will play out. However, it seems likely that it will continue to be \nchallenging to design a storage conﬁ guration that meets a system’s service level agreement at the lowest cost. \n A related technology is  RAID — redundant arrays of inexpensive disks. In RAID, an array of identical disks \nis built to function like one high-bandwidth disk (see  Figure 7.26 ). A  stripe is the set of disk blocks consisting \nof the  i th block from each disk, where  i is an integer between one and the number of blocks on a disk. If the \ndisk block size is  s and there are  d disks in the RAID, then a stripe is, in effect, a logical block of size  d   \u0004   s . \nA RAID is high-bandwidth because the disks are read and written in parallel. That is, it reads or writes a stripe \nin about the same amount of time that one disk can read or write a single block. \nComputer sees the RAID as one\nhigh-bandwidth highly reliable disk.\nA RAID system\nComputer\nDatabase\n. . .\n. . .\nError correction bits\n FIGURE 7.26 \n A Redundant Array of Inexpensive Disks (RAID). An array of disks built to function as one high-bandwidth disk. Using \nextra disks for error correction bits increases reliability. \n",
      "content_length": 3025,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 238,
      "content": " Some RAID systems use extra disks in the array to store error correction bits, so they can tolerate the fail-\nure of one of the disks in the array without losing data. For example, an array of ﬁ ve disks could store data \non four disks and parity bits on the ﬁ fth disk. Thus, the RAID can tolerate the loss of one disk without losing \ndata. A write to any of disks 1 through 4 implies a write to disk 5. To avoid having disk 5 be a bottleneck, par-\nity blocks can be distributed across the disks. For example, stripes 1, 6, and 11 store their parity block on disk \n1; stripes 2, 7, and 12 store their parity block on disk 2; and so on. \n The different RAID conﬁ gurations are identiﬁ ed by numbers. Striped disks without parity are called RAID \n0. Mirroring is called RAID 1 and can use more than two disk replicas. RAID 2 through 6 use parity in different \nconﬁ gurations. RAID 10 is a RAID 0 conﬁ guration where each disk is actually a mirrored pair (i.e., RAID 1). \nThis is called nested RAID, since it nests RAID 1 disks into a RAID 0 conﬁ guration. \n Even if it is judged to be uneconomical to use mirrored disks or a RAID for the stable database, one should \nat least use them for the log. Losing a portion of the log could be a disaster.  Disaster is a technical term for an \nunrecoverable failure. There are two ways that a media failure of the log can be unrecoverable: \n ■  After writing an uncommitted update to the stable database, the log may be the only place that has the \nbefore-image of that update, which is needed if the transaction aborts. If the tail of the log gets corrupted, \nit may be impossible to abort the transaction, ever. \n ■  After committing a transaction, some of its after-images may be only in the log and not yet in the stable \ndatabase. If the tail of the log gets corrupted and the system fails (losing the cache), then the committed \nafter-image is lost forever. \n In both cases, manual intervention and guesswork may be needed to recover from the failure. Therefore, \nit’s a good idea to put the log on a separate device and mirror it. \n Even with mirrored disks, it is possible that both disks fail before the ﬁ rst failed disk is replaced. When \nconﬁ guring a system, there are some things one can do to reduce this possibility. First, one can try to minimize \nthe amount of shared hardware between two mirrored disks. For example, if the disks share a single control-\nler, and that controller starts scribbling garbage, both disks will be destroyed. Second, one can keep the disks \nin separate rooms or buildings, so that physical damage, such as a ﬁ re, does not destroy both disks. How far to \ngo down these design paths depends on the cost of downtime if data becomes unavailable for awhile due to a \nmedia failure. \n The general principle here is that protection against media failure requires redundancy. We need two copies \nof the log to ensure restart can run correctly if one log disk fails. We use mirrored disks or a RAID system that \nhas built-in error correction to avoid requiring media recovery when a database disk fails. If the stable database \nis not mirrored and a disk fails, or if both mirrors fail, then yet another copy of the stable database — an archive \ncopy — is needed in order to run media recovery. \n Archiving \n Media recovery requires the system to have an archive (i.e., backup) copy of the stable database that it can use \nas a starting point. It also needs a copy of the log that includes all committed updates that executed after the \narchive copy was created. The media recovery algorithm can therefore load the latest archive copy and redo \nthe corresponding log. \n To create an archive copy, one can simply copy the entire  stable database. If this is done when the system \nis not processing transactions, it will produce a snapshot of the database that is consistent with the log. If \narchiving is done on-line, that is, if the system is processing transactions while the archive copy is being made, \nthen different parts of the archive copy will include updates from different transactions. That is, pages copied \n7.9 Media Recovery  219\n",
      "content_length": 4124,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 239,
      "content": "220  CHAPTER 7 System Recovery\n later will have updates from more transactions than those copied earlier. It seems like this would be hard to \nsort out when it is time to recover from a media failure. However, essentially the same old restart algorithm \nthat we described for system failures will work here too. \n This approach requires that the system keep an archive copy of the log. Therefore, even after a checkpoint \nhas made early parts of the log unnecessary for recovery from system failures, those early parts must still be \nsaved for media recovery. Usually, they are copied to a  media recovery log on a separate long-term storage \ndevice. \n To avoid disk head contention between on-line transactions writing to the end of the log and the media \nrecovery log archiver reading from the beginning of the log, it is worthwhile to have two pairs of mirrored log \ndisks. One pair contains the tail of the log for active transactions. The other contains the early part of the log for \narchiving to the media recovery log. By the time the active transaction log is out of space, the media recovery \nlog archiver should have ﬁ nished reading the other pair of log disks. So the latter can immediately be reused for \nthe active transaction log and the archiver can turn its attention to the other pair of log disks. \n Suppose the recovery manager uses the optimization in  Operation Logging , in Section 7.8, where it stores \non each page the log address of the last update applied to it (i.e., the LSN). This information will be in the \narchive copy too. So the media recovery manager knows the exact state of the page to recover, in the same way \nas the restart algorithm. \n As for system failures, recovery time for media failures affects availability, so checkpointing frequently is \ndesirable for reducing recovery time. Making an archive copy of the entire stable database is slow. One can \nspeed up archiving by only copying pages that have changed since the last time the archiving algorithm ran. \nA simple way to do this is to keep an  update-bit in each page header that indicates whether the page has been \nupdated since it was last archived. This bit is set every time the page is updated. The archive algorithm clears the \nbit each time it copies the page to the archive. The archive algorithm still needs to read the entire stable database, \nto look at all the update bits, but it only needs to copy a fraction of those pages to the archive. We can speed \nthings up even further by keeping the update bits in a separate location, so the archiving algorithm needs to read \nonly pages that were recently updated, not all pages. \n To recover from the media failure of a disk, one needs to load the most recent archive copy of the disk \nand process the log that includes all updates that were done since the archive copy was made. This means the \narchive algorithm should write a checkpoint record to the log, indicating when it started running, and another \ncheckpoint record when it is done. When it is done, all database updates that preceded the ﬁ rst checkpoint \nrecord are deﬁ nitely in the archive (and some later updates too, but we can’t tell which ones by looking at the \nlog). So the latter checkpoint record indicates that only updates occurring after the former checkpoint record \nneed to be considered during media recovery. \n A useful optimization to reduce the amount of log needed for media recovery is to avoid keeping undo \ninformation in the media recovery log, such as before-images. If the archiving procedure archives pages only \nwhen their entire contents is committed, then undo information will not be needed at archive recovery time. \nTherefore, the archiving procedure should write-lock each page before it copies it to the archive, thereby ensur-\ning there are no active transactions writing to the page at the time it does the copy operation. A postprocessing \nstep on the log can strip out all undo information before setting it aside for future use during media recovery. \n It is common that a media failure only corrupts a small portion of a disk, such as a few tracks. Depending on \nhow the media recovery algorithm is organized, it may or may not be necessary to recover the entire disk in this \ncase. A distinguishing feature of database systems is whether they can recover from such failures efﬁ ciently. \nFor example, instead of reconstructing the entire disk, a database system could offer the ability to recover just \nthe damaged portions of the disk and write them to an empty area of the same disk. Moreover, it could have \nutilities to postprocess logs, to partition them based on regions of the disk, so that the media recovery algorithm \nonly needs to process a log containing records that are relevant to the damaged portion of the disk. \n",
      "content_length": 4797,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 240,
      "content": " Not all media failures are permanent failures, where the damaged page is physically destroyed. Some failures \nare transient, where the content of the page is wrong but it can be repaired simply by rewriting it. For example, \na disk may not have written a page atomically (i.e., written out only part of its contents), because the disk arm \nstrayed a bit during the write. Some disks can detect this error immediately and retry the write. However, if the \ncorrupt page is discovered much later when the page is read, then it needs to be recovered. In this case, it is \nworthwhile to reconstruct the page in place, rather than replacing the disk or relocating the damaged page. \n 7.10  SUMMARY \n TP systems often are expected to be available 24 hours per day, 7 days per week, to support around-the-clock \nbusiness operations. Two factors affect availability: the mean time between failures (MTBF) and the mean time \nto repair (MTTR). Improving availability requires increasing MTBF, decreasing MTTR, or both. \n Computer failures occur because of: \n ■  Environmental factors (power, air conditioning, communication lines, natural disasters , etc.) \n ■  System management (operations staff errors, software upgrades, preventive maintenance, etc.) \n ■  Hardware (failure of any component, such as memory, disk, network controller, etc.) \n ■  Software (crash of operating system, database system, transactional middleware, or application program) \n If the operating system fails, then just reboot it. For other types of software failure, the transactional mid-\ndleware or database system must detect the failure of a process and recreate it. The recreated process must then \nrun a recovery procedure to reconstruct its state. \n When a client recovers it needs to reconnect to its servers. It then should determine which calls were out-\nstanding when it failed, and what it needs to do to complete those calls. This is exactly the problem addressed \nin Chapter 4,  “ Queued Transaction Processing. ” \n When a server recovers, it needs to reconstruct a state that is consistent with the last calls that it processed \nbefore the failure. This requires taking checkpoints periodically during normal operation, so it can reload the \ncheckpointed state at recovery time. Executing from that recovered state, the server must avoid redoing any \nnon-redoable  actions (such as printing a check). \n Transactions simplify recovery by allowing a server to focus on restoring its state to contain only the results \nof committed transactions, rather than recovering to a state that is consistent with the last operations it ran. \nTransactional servers often are split into two types, resource managers that maintain state and stateless appli-\ncation servers. The latter store all their state in the resource managers and therefore can recover simply by \nreinitializing. \n A database system must be able to recover from several kinds of failure. It recovers from a transaction failure \n(where a transaction aborts) by undoing all the transaction’s updates. It recovers from a system failure (where \nmain memory is lost) or a media failure (where some stable storage is lost) by restoring the database to contain \nexactly the set of committed updates. \n All of today’s recovery mechanisms require every transaction to hold its write locks until it commits, to \navoid cascading aborts and to ensure that undo can be implemented simply by restoring an update’s before-\nimage. For satisfactory performance, locks usually are held at record granularity, though recovery can be sim-\npliﬁ ed considerably if page-granularity locking is used. \n The recovery manager uses a cache manager to fetch pages from disk and later ﬂ ush them. In addition to \nprocessing commit and abort operations, it implements a recovery algorithm to recover from system failures. \nThe most popular recovery algorithms use a log, which contains a history of all updates, commits, and aborts. \n7.10 Summary  221\n",
      "content_length": 3961,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 241,
      "content": "222  CHAPTER 7 System Recovery\n The recovery manager must carefully control when updates are ﬂ ushed to ensure the database is always \nrecoverable. In particular, it must enforce two rules: \n ■  The Write-Ahead Log Protocol: Do not ﬂ ush an uncommitted update to the stable database until the log \nrecord containing its before-image has been ﬂ ushed to the log. \n ■  The Force-at-Commit Rule: Do not commit a transaction until the after-images of all of its updated pages \nare in stable storage (in the log or the stable database). \n The recovery manager tells the cache manager about dependencies between dirty database pages and log \npages so the cache manager can enforce the write-ahead log protocol. To implement commit, the recovery \nmanager appends a commit record to the log and ﬂ ushes it. Since all updates are logged, this implements the \nforce-at-commit rule. To implement abort, the recovery manager follows a linked list of the transaction’s log \nrecords, undoing each update along the way. \n To minimize the amount of log to process at recovery time, the recovery manager periodically does a \ncheckpoint, which synchronizes the state of the log with the stable database. To recover from a system failure, \nit scans the log from the last or penultimate checkpoint record (depending on the checkpointing algorithm) and \nredoes updates as required. It can tell whether a log record should be redone by comparing the log record’s \naddress (LSN) with the LSN stored in the corresponding database page, since each database page’s LSN is \nupdated whenever the page itself is updated. Using LSNs in this way allows the recovery manager to log oper-\nation descriptions, rather than before- and after-images, since it redoes an operation only if the page is in the \nsame state as when the operation originally ran. \n Recovery time should be short, to maximize availability. Therefore, there are numerous optimizations to \nreduce checkpoint overhead so it can be done more frequently, and thereby reduce recovery time. For the same \nreason, there are also many optimizations to speed up the recovery algorithm itself. \n To cope with media failures, some redundant storage is required. Mirrored disks or RAID systems commonly \nare used for the database and for the log. Still, to cope with media failures of the stable database, it’s important \nto periodically make an archive copy of the database plus an archive copy of the log that includes all committed \nupdates that executed after creating the archive database copy. The recovery algorithm for media failures loads \nthe archive copy and redoes committed updates in the log, just like the recovery algorithm for system failures. \nAs for system failures, checkpointing should be frequent and the recovery algorithm should be optimized to run \nfast, to maximize availability. \n \n",
      "content_length": 2835,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 242,
      "content": " 8.1  INTRODUCTION \n The previous chapter showed how to use logging to ensure that a transaction is atomic with respect to failures, \nprovided that the transaction updates data only in one resource manager. If two or more resource managers \nprocess updates for a transaction, then another technique is needed to ensure that the transaction commits at all \nresource managers or at none of them. This is called the  two-phase commit protocol. Chapter 1 brieﬂ y intro-\nduced the protocol. This chapter develops it in more detail. \n The main goal of the protocol is to ensure that a transaction either commits at all the resource managers \nthat it accessed or aborts at all of them. The undesirable outcome that the protocol avoids is that the transaction \ncommits at one resource manager and aborts at another. \n Two -phase commit arises whenever the resource managers that processed a transaction’s updates can com-\nmit the transaction independently. This surely arises if the resource managers execute on different machines. It \nalso arises when the resource managers execute on the same machine but use separate logs. However, when the \nresource managers use a shared log, they can commit a transaction simultaneously by appending a single com-\nmit record to the log. In that case, the resource managers do not independently commit the transaction, so two-\nphase commit is not required. \n At ﬁ rst, it may seem that committing at multiple resource managers is no more difﬁ cult than committing at \none resource manager: Just send a message telling each resource manager to commit or abort. In the absence of \nfailures, this would work. But failures can make it much harder to commit or abort everywhere. For example, \nwhat should be done while committing transaction T in each of the following situations? \n ■  A resource manager that processed some of T’s updates fails after T has committed at another resource \nmanager. \n ■  A resource manager that failed while T was committing has now recovered and wants to ﬁ nd out whether \nT committed or recovered. How does it know who to ask? What should it do if none of the other resource \nmanagers that processed T’s operations are up and running? \n ■  What if a resource manager R is not responding to messages? Should other resource managers assume \nR is down, and therefore its active transactions will abort; or that communications is down and R is still \noperational? \n A complete solution must deal with these and all other failure situations that can arise. \n Two-Phase Commit \n 8 \nCHAPTER\n",
      "content_length": 2543,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 243,
      "content": "224  CHAPTER 8 Two-Phase Commit\n In this chapter, we return to using the terms  “ resource manager ” and  “ resource, ” instead of the terms  “ data \nmanager ” and  “ data item ” that we used in Chapters 6 and 7. When discussing two-phase commit, it is common \npractice to talk about resource managers, rather than data managers or database systems. The reason is that \nwhen a transaction commits, all the transactional resources it accesses need to get involved in the commitment \nactivity, not just databases. Non-database transactional resources include recoverable scratchpad areas, queues, \nand other messaging systems. \n As in resource manager recovery, application programmers usually do not get involved in two-phase commit. \nMost database systems and transactional middleware support it and make it transparent to the application. However, \nif an application needs to directly manage a transactional resource as well as use other resource managers, then the \napplication needs to participate in the two-phase commit protocol. The application programmer needs to know \nwhat to do in this case. Some error scenarios require operator intervention. The application needs to expose these \nsituations to the operator in a comprehensible way so the operator can determine the best course of action. \n System architects who conﬁ gure a TP system have a more pressing need to consider the effects of two-\nphase commit. When conﬁ guring a system consisting of different resource managers, such as different database \nsystems supplied by different vendors, one needs to ensure that the two-phase commit implementations of the \nresource managers interoperate properly. This requires some understanding of how two-phase commit protocols \nare implemented. Moreover, such multidatabase conﬁ gurations lead to additional communication overhead for \ntwo-phase commit, which can dramatically affect transaction performance. In some cases, that overhead makes \nit advisable to avoid a multidatabase conﬁ guration. For all these reasons, a solid understanding of two-phase \ncommit is needed to build robust TP applications. \n 8.2  THE TWO-PHASE COMMIT PROTOCOL \n Assumptions \n The protocol makes the following assumptions about each transaction T: \n 1.  Transaction T accesses resources from time to time. If it experiences a serious error at any time, such as \na deadlock or illegal operation, it issues an abort operation. If it terminates normally without any errors, \nit issues a commit. In response to the commit, the system runs the two-phase commit protocol. \n 2.  Each resource manager can commit or abort its part of T; that is, permanently install or undo T’s opera-\ntions that involve this resource manager. This essentially says that each resource manager has a transac-\ntional recovery system, as described in the previous chapter. \n 3.  One and only one program issues the commit operation on T. That is, one program decides when to start \ncommitting T by running the two-phase commit protocol, and no other program will later start running \nthe protocol on T independently. In some cases, a second attempt to run two-phase commit while the ﬁ rst \nattempt is still running will cause the protocol to break; that is, cause it to commit at one resource man-\nager and abort at another. The protocol can be programmed to cope with concurrent attempts to run two-\nphase commit, but we will not investigate this type of error here. We will just assume it does not happen. \n 4.  Transaction T has terminated executing at all resource managers before issuing the commit operation. If \nthe transaction does all of its communication using RPC, then this is easy to arrange. T can ensure it has \nﬁ nished processing at all resource managers by waiting for all of its RPCs to return, provided that each \nresource manager ﬁ nishes all the work it was asked to do before returning from the call. This assump-\ntion avoids our having to deal with the complexity of transaction termination here. \n",
      "content_length": 3983,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 244,
      "content": " In general, termination can be hard to arrange if T uses communications paradigms other than RPC. \nFor example, if the transaction uses peer-to-peer messaging, where each communicating party can send \nmessages to and receive messages from other parties in an application-deﬁ ned order, then the transaction \nmay need an application-speciﬁ c protocol to ensure it has terminated. A general-purpose peer-to-peer \nprotocol that ensures termination is IBM’s LU6.2, which was described in Section 3.4 of the ﬁ rst edition \nof this book. \n 5.  Every system and resource manager fails by stopping. That is, the protocol does not make mistakes when \na system or a resource manager malfunctions. It either does exactly what the protocol says it should do, \nor it stops running. It is possible for a failure to cause the protocol to do something that is inconsistent \nwith its speciﬁ cation, such as sending bogus messages. These are called Byzantine failures. There are \nways to cope with limited numbers of  Byzantine failures , but they are quite expensive in terms of the \nnumber of messages exchanged and are not used in current TP systems, so they are not discussed here. \n In the remainder of this section, we will use the term  coordinator as the name of the component that runs \nthe two-phase commit protocol on behalf of one transaction. That is, the coordinator is the component that \nreceives the commit or abort request from the application program and drives the execution of the protocol. \n In our description of the protocol, the resource managers that did work on behalf of the transaction (by \nreading and updating resources) are called  participants . The goal is to ensure that the coordinator and all par-\nticipants commit the transaction or the coordinator and all participants abort the transaction. \n “ Coordinator ” and  “ participant ” are abstract concepts that don’t map exactly to real components of a TP sys-\ntem. In Section 8.5, we will look at how the system is organized into components, including the transaction man-\nager component that actually runs two-phase commit. We will explore how the transaction manager organizes its \nwork, communicates with resource and transaction managers, and interacts with the communication system itself. \n Being Prepared \n A participant P is said to be  prepared if all of transaction T’s after-images at P are in stable storage. It is essen-\ntial that T does not commit at  any participant until  all participants are prepared. The reason is the force-at-com-\nmit rule, which says not to commit a transaction until the after-images of all of its updates are in stable storage. \nSuppose the rule is violated by having one participant, P 1 , commit T before another participant, P 2 , is prepared. \nIf P 2  subsequently fails, before it is prepared and after P 1  commits, then T will not be atomic. T already has com-\nmitted at P 1 , and it cannot commit at P 2  because P 2  may have lost some of T’s updates when it failed. On the \nother hand, if P 2  is prepared  before P 1  commits, then it is still possible for T to be atomic after P 2  fails. When P 2  \nrecovers, it still has T’s updates in stable storage (because it was prepared before it failed). After it recovers and \nﬁ nds out that T committed, it too can ﬁ nish committing T. \n Ensuring that all participants are prepared before any of them commits is the essence of two-phase com-\nmit. Phase one is when all participants become prepared. Phase two is when they commit. No participant enters \nphase two until all participants have completed phase one; that is, until all participants are prepared. \n The Protocol \n The protocol proceeds as follows (see  Figure 8.1 ): \n Begin Phase 1: \n 1.  To commit the transaction, the coordinator starts by sending a  REQUEST-TO-PREPARE message to each \nparticipant. \n8.2 The Two-Phase Commit Protocol  225\n",
      "content_length": 3871,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 245,
      "content": "226  CHAPTER 8 Two-Phase Commit\n 2.  The coordinator waits for all participants to  “ vote ” on the request. \n 3.  In response to receiving a  REQUEST-TO-PREPARE message, each participant votes by sending a mes-\nsage back to the coordinator, as follows: \n ■  It votes  PREPARED if it is prepared to commit. \n ■  It may vote  NO for any reason, usually because it cannot prepare the transaction due to a local failure. \n ■  It may delay voting indeﬁ nitely, for example, because its system is overburdened with other work or \nbecause it failed. \n Begin Phase 2: \n 1.  If the coordinator receives  PREPARED messages from  all participants, it decides to commit. The trans-\naction is now ofﬁ cially committed. Otherwise, it either received a  NO message or gave up waiting for \nsome participant, so it decides to abort. \n 2.  The coordinator sends its decision to all participants (i.e.,  COMMIT or  ABORT ). \n 3.  Participants acknowledge receipt of the commit or abort by replying  DONE . \n 4.  After receiving  DONE from all participants, the coordinator can  forget the transaction, meaning that it \ncan deallocate any memory it was using to keep track of information about the transaction. \n Performance \n The performance of two-phase commit is measured by counting the number of messages required to commit the \ntransaction. There are four rounds of messages to or from all participants, as can easily be seen in  Figure 8.1 : \n REQUEST-TO-PREPARE, PREPARED ; or  NO ,  COMMIT or  ABORT , and  DONE . \n The transaction actually is committed before all these messages are sent. After the second round, when the \ncoordinator decides to commit, the transaction actually is committed and the coordinator can tell the user that this \nis true. Of course, there is still another round of messages, the  COMMIT messages, before the participants ﬁ nd out \nthat the transaction is committed, at which point they can release their locks. The ﬁ nal round of messages, the \na.  The transaction commits\nHorizontal arrows indicate messages between the coordinator and participant.\nTime is moving down the page, so the first message in both cases is REQUEST-TO-PREPARE.\nb.  The transaction aborts\nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nMessages\nCoordinator\nParticipant\nREQUEST-TO-PREPARE\nNO\nABORT\nDONE\nMessages\nCoordinator\nParticipant\nTime\n FIGURE 8.1 \n The Two-Phase Commit Protocol. The messages that are shown are exchanged between the coordinator and each \nparticipant. \n",
      "content_length": 2463,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 246,
      "content": " DONE messages, is not performance sensitive, since this just tells the coordinator that it can clean up whatever \ncontrol structures it has used for the transaction. In fact, a participant can avoid an extra message by holding onto \nthe  DONE message until it has another message for the coordinator on which it can piggyback the  DONE message, \nsuch as a  PREPARED message for a later transaction. \n Blocking \n Before a participant votes, it can abort unilaterally, any time it wants. Once it sends  PREPARED , and until it \nreceives a message containing the coordinator’s decision, it is unable to commit or abort. If it did, it might \nmake a decision opposite to the coordinator’s, producing an inconsistent result. During this period, it is said to \nbe  uncertain 1 (see  Figure 8.2 ). \n The coordinator is never uncertain, because it gets to decide. Until it decides, it can abort whenever it wants. \nAnd after it decides, it is obviously not uncertain. So, only participants are uncertain. \n Uncertainty is a bad property of two-phase commit. If the coordinator fails while a participant is uncertain, \nthe participant is  blocked ; it can neither commit nor abort. The coordinator could be down for a long time. This \nis a bad situation for the participant, since it is holding locks on data that the transaction accessed. Since the \nwhole point of two-phase commit is to cope with failures (otherwise, one-phase commit would work ﬁ ne), it is \nbad news that when a failure does happen, a participant could become blocked. \n This leads one to wonder whether two-phase commit is a good protocol after all. Are there other protocols \none could adopt that avoid blocking? Unfortunately, the answer is no, as stated in the following theorem. \n Theorem 1: For every possible commit protocol (not just two-phase commit), a communications failure can \ncause a participant to become blocked. \n There is a related problem, essentially the recovery-time version of blocking. If a participant fails while it is \nuncertain, and subsequently recovers, it is possible that when it recovers the coordinator is down. In this case, \nit is still uncertain and therefore cannot completely recover, since it doesn’t know whether to commit or abort \nthe transaction. That is, the participant cannot  independently recover . Like blocking, this too is unavoidable. \n 1 This is called  “ in doubt ” in Gray and Reuter (1992). \nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nCoordinator\nParticipant\nUncertainty\nPeriod\n FIGURE 8.2 \n The Uncertainty Period in Two-Phase Commit. From the time a participant replies PREPARED until it receives the \ndecision from the coordinator, it is uncertain. \n8.2 The Two-Phase Commit Protocol  227\n",
      "content_length": 2709,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 247,
      "content": "228  CHAPTER 8 Two-Phase Commit\n Theorem 2: No commit protocol can guarantee independent recovery of failed participants. \n We may be unhappy about the blocking problem in two-phase commit, but there is no avoiding it. Any \nother protocol that atomically commits a transaction that accesses multiple resource managers must have the \nsame problem. \n Nevertheless , there have been many attempts at circumventing these theorems. One technique for handling \nblocking situations is to make a  heuristic decision , which is simply to guess the outcome. The guess may be \nwrong, but at least the transaction can terminate and release locks. Another is to attempt to ﬁ nd out the deci-\nsion from other participants, called the cooperative termination protocol, which is described in Section 8.4. Yet \nanother technique is three-phase commit, which avoids blocking if the system has no communications failures. \nThis protocol is much more complex than two-phase commit and still leads to blocking if a communication fail-\nure occurs (for details, see Bernstein, Hadzilacos, and Goodman, 1987; Section 7.5). Currently, three-phase com-\nmit is not widely used in practice. \n 8.3  FAILURE HANDLING \n The purpose of two-phase commit is to cope with the various failures that can arise. To complete the descrip-\ntion of the protocol we need to explain what happens in every possible failure situation. \n We assume that all failures of messages and processes are detected by timeout. That is, a caller sets a timer \nwhen it sends a message to another process and assumes that a failure has occurred if the timer expires before \nit receives the reply it was expecting. The length of the timer is called the  timeout period . The timeout period \nshould be long enough to cover cases where the callee or the communications network is a little slow due to \na backlog of work. But it should not be too long, since that will mean that failures are not detected promptly, \nwhich would be annoying to users. Notice that if a process detects a timeout, it cannot tell whether the process \nfailed or the communications failed. All it knows is that something has gone wrong. \n It is very realistic to assume that all failures are detected by timeout. In most distributed systems, messages \nare exchanged asynchronously (that is, whenever processes have something to say, rather than synchronously \nat ﬁ xed time intervals). So the only information that a process has about other processes is what it learns from \nmessages it receives from them. If a failure occurs, the only hint it gets about the failure is that a message it \nwas expecting has not arrived. \n Sometimes the underlying communication system provides failure detection. A process can ask the com-\nmunication system to establish a session. Later, if one of the processes or systems stops responding to mes-\nsages, the communication system tells the other process that the session has failed. In this case, the failure was \nstill detected by timeout, but by the underlying communication system rather than by the process itself. \n The coordinator or a participant can fail in two ways. Either it stops running (assumption 5 in Section 8.2) \nor it times out waiting for a message it was expecting. The latter may happen either because the sender fails \nor because the communication system isn’t functioning properly. The symptom is the same in both cases — the \nreceiver does not get the message. \n To analyze the failure cases, let’s walk through the protocol from both the coordinator’s and participant’s \nviewpoint and explain what happens in each case where a message was expected but does not arrive. Then we \nwill talk about what the coordinator and participant do if they fail and subsequently recover. \n Coordinator ’s view: \n 1.  Send  REQUEST-TO-PREPARE messages to all the participants. \n Error handling: None, since it is not expecting any messages in this step. \n",
      "content_length": 3913,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 248,
      "content": " 2.  Receive  PREPARED messages from all participants, or receive a  NO message from at least one participant. \n Error handling: It is waiting for  PREPARED or  NO messages. If it does not receive all of them within its \ntimeout period, it can simply abort the transaction, just as if one of the participants had voted  NO . \n 3.  Depending on the messages received, decide to commit or abort. \n Error handling: None, since it is not expecting any messages in this step. \n 4.  Send  COMMIT or  ABORT messages to all participants (depending on the decision). \n Error handling: None, since it is not expecting any messages in this step. \n 5.  Receive  DONE messages from all participants. \n Error handling: It is waiting for  DONE messages. Nothing important depends on when these messages \narrive, so it waits indeﬁ nitely for them. If its timeout period expires, it can send reminder messages to \nthe participants to resolicit the  DONE messages. \n 6.  Forget the transaction. \n Error handling: None, since it is not expecting any messages in this step. \n Participant ’s view: \n 1.  Receive a  REQUEST-TO-PREPARE message from the coordinator. \n Error handling: After ﬁ nishing its work for the transaction, if it does not receive a  REQUEST-TO-\nPREPARE within its timeout period, it can unilaterally abort the transaction. If it later receives a \n REQUEST-TO-PREPARE from the coordinator, it votes  NO (or ignores the message, since a nonvote \nhas the same effect as  NO ). \n 2.  Prepare the transaction. \n Error handling: None, since it is not expecting any messages in this step. \n 3.  If (2) succeeds, then send a  PREPARED message to the coordinator, otherwise send  NO to the coordinator. \n Error handling: None, since it is not expecting any messages in this step. \n 4.  Receive a decision message,  COMMIT or  ABORT . \n Error handling: If it does not receive a decision message within its timeout period, it is blocked. It is in \nits uncertainty period, so there is nothing it can do without risking a mistake. \n 5.  Send a  DONE message. \n Error handling: None, since it is not expecting any messages in this step. \n If the coordinator or participant fails and subsequently recovers, then at recovery time it can only use infor-\nmation in stable storage to guide its recovery. This is the same assumption we used for recovering from system \nfailures in the previous chapter. So to ensure that recovery is possible, we need to ensure that the coordinator \nand participant log information that they may need during the recovery activity. \n We say that writing a log record is  eager (sometimes called forced or synchronous) if it must complete \nbefore the corresponding message is sent. Otherwise, it is  lazy (or asynchronous). Eager log writes have a big-\nger performance impact than lazy ones, because they must be completed before the protocol can continue and \nthey therefore add to the transaction’s response time. \n The coordinator needs to write three log records (see  Figure 8.3 ). \n ■  Before it sends a  REQUEST-TO-PREPARE , it should log a  start-two-phase-commit record , which \nincludes a list of the participants. This writing is eager; that is, the coordinator must wait until this record \nis in the stable log before sending a  REQUEST-TO-PREPARE to any participant. Otherwise, if it failed \nafter sending the  REQUEST-TO-PREPARE and before the log record was stable, it would not know which \nparticipants to notify about the decision. \n ■  Before sending a commit decision, it should log a  commit record . Indeed, writing the commit record to \nthe log is what actually commits the transaction. This too is eager. Otherwise, if the coordinator failed \n8.3 Failure Handling  229\n",
      "content_length": 3703,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 249,
      "content": "230  CHAPTER 8 Two-Phase Commit\n after sending the  COMMIT message and before ﬂ ushing the commit record to the log, and it subsequently \nrecovered, it would abort the transaction during its recovery procedure, which produces an inconsistent \noutcome if the participant that received the  COMMIT message committed. \n ■  After it receives the  DONE messages it writes a  done record , which records the fact that the transaction is \nﬁ nished. This is lazy. \n The participant writes two log records (see  Figure 8.3 ). \n ■  When it gets a  REQUEST-TO-PREPARE from the coordinator, it writes a  prepared record to the log. \nThis is eager; that is, it waits until the prepared record is in the stable log before sending  PREPARED to \nthe coordinator. Otherwise, if it failed after sending  PREPARED and before ﬂ ushing the prepared record \nto the log, and it subsequently recovered, it would abort the transaction during its recovery procedure \n(since there is no prepared or commit record in the log). But since it sent  PREPARED , it gave permission \nto the coordinator to commit the transaction, which would produce an inconsistent outcome. \n ■  It writes a  commit record or  abort record , after it receives the decision message. This too is eager, \nsince once it sends  DONE , it gives permission to the coordinator to forget the transaction. If it fails after \nsending  DONE and before the decision message is stable, then at recovery time it might not be able to ﬁ nd \nout what the decision was. Moreover it holds locks for the transaction until after it commits or aborts, so \nthe sooner it logs the decision, the sooner it can release locks. \n We will see ways of turning some of the eager log writes into lazy ones in the next section, on optimizations. \n Now that we know what information they log, we can look at how the coordinator and participant recover \nfrom failures. First, consider the coordinator. When it recovers it can be in one of four states (see numbered \nboxes on left side of  Figure 8.4 ): \n 1.  It has no start-two-phase-commit log record for the transaction. It did not start two-phase commit before \nthe failure. So no participant could have received a  REQUEST-TO-PREPARE message and therefore all \nof them either aborted unilaterally while the coordinator was down, or will abort on their own later (if \nthe coordinator was down only brieﬂ y). \nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nCoordinator\nParticipant\nLog a start-two-phase-commit\nrecord (eager)\nLog a commit record (eager)\nLog a done record (lazy)\nLog a prepared record (eager)\nLog a committed record (eager)\n FIGURE 8.3 \n Log Operations in Two-Phase Commit (the commit case). Each of the eager log writes must be completed before sending \nthe next message, so the process can correctly handle failures that occur after the message is sent (see text). \n",
      "content_length": 2842,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 250,
      "content": " 2.  It has a start-two-phase-commit record only, so it did not reach a decision before the failure. It aborts \nthe transaction. It is possible that participants are waiting for this decision, so it sends an abort decision \nmessage to all of them. Some of them may ignore the message, because they never got a  REQUEST-TO-\nPREPARE message and therefore unilaterally aborted, but there is no harm in sending the abort decision \nmessage. \n 3.  It has a commit or abort record in the log, but no done record. Again, it is possible that participants are \nwaiting for this decision, so it sends a decision message to all of them. \n 4.  It has a done record in the log. All participants acknowledged receiving the decision, so there is nothing \nto do. \n Now , consider a participant. When it recovers it can be in one of three states (see numbered boxes on right \nside of  Figure 8.4 ): \n 1.  It did not log a prepared record. The transaction could not have committed, so the participant unilater-\nally aborts the transaction. \n 2.  It logged a prepared record, but did not log a committed or aborted record. This is the bad case, where \nthe participant is blocked. It should run a termination protocol, which will be explained in a moment. \n 3.  It logged the decision, commit, or abort. It can either send another  DONE message, or it can wait until \nthe coordinator sends it a reminder message, reminding it of the decision, at which time it sends a  DONE \nmessage. \n A  termination protocol is what a participant does to try to resolve a blocked transaction when the partici-\npant recovers from a failure. The simplest termination protocol is to wait until it re-establishes  communication \nwith the coordinator and to resend its vote. If the coordinator sees a redundant vote message, this must mean \nthat the participant hasn’t yet received the decision, so it resends the decision. \n If communication cannot be re-established  in an acceptably short time, then a human operator may need \nto intervene and guess whether the transaction committed or aborted (perhaps making a telephone call to the \noperator of the other system to ﬁ nd out the decision). The protocol should log this  heuristic decision , so that \nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nCoordinator\nParticipant\nLog a start-two-phase-commit\nrecord (eager)\nLog a prepared record (eager)\nLog a committed record (eager)\n1\n2\n3\n1\n2\n3\n4\nLog a done record (lazy)\nLog a commit record (eager)\n FIGURE 8.4 \n Possible States from Which a Coordinator or Participant Must Recover. See text for a description of recovery actions for \nthe state labeled by each numbered box. \n8.3 Failure Handling  231\n",
      "content_length": 2653,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 251,
      "content": "232  CHAPTER 8 Two-Phase Commit\n when communication between the two systems is re-established, the systems can detect whether a consistent \nor inconsistent decision was made. In the latter case, the system can notify an operator that corrective action is \nneeded. \n Repairing an inconsistent decision can be difﬁ cult. The transaction that incorrectly committed or aborted \nleft some incorrect data in the database. That incorrect data may have been read by later transactions which \nthemselves wrote some data. In this way, the inconsistency may have spread beyond the data that was directly \nupdated by the transaction that terminated inconsistently. Taking corrective action therefore could require some \ncareful analysis of the database and transaction log. \n This covers all the failure scenarios — timing out waiting for a message and recovering from a failure. So \nwe now have a complete and correct two-phase commit protocol. \n 8.4  OPTIMIZATIONS AND VARIATIONS \n There are many variations of two-phase commit to handle special transaction communications patterns. We dis-\ncuss three of them here: reinfection, where a transaction revisits a resource manager after the two-phase commit \nprotocol has started; transfer of coordination, to allow one resource manager to execute one-phase-commit; and \nphase zero, where a transaction delays sending updates to some resource managers until after it has ﬁ nished \nexecuting. \n There are also many optimizations of two-phase commit to save messages and reduce the number of eager \nlog writes. The most obvious is to avoid two-phase commit altogether when there is only one resource man-\nager in a transaction, and run one-phase commit instead. This is a fairly important optimization since many \ntransactions access only one resource manager. If a transaction issues Start and Commit but never accesses a \nresource manager, then it can run no-phase commit. That is, the coordinator can commit immediately without \nsending a message to any outside agent. Several other optimizations are described later: presumed abort, to \nreduce the amount of logging for transactions that abort; reducing a round of messages for read-only resources; \nand the cooperative termination protocol, to increase the chance that a blocked resource manager can become \nunblocked. \n Reinfection \n If the coordinator starts two-phase commit before all the participants have fully completed (thereby violating \nassumption 4 in Section 8.2), then it’s possible that a participant will prepare and later be asked to do work for \nthe same transaction. This is called  reinfection . \n Reinfection can arise if participants want to postpone certain work until after the transaction has completed \nits regular work, for example, with database triggers that should execute at the end of the transaction. Since the \ncoordinator waits until the transaction completes its normal work before sending  REQUEST-TO-PREPARE mes-\nsages, participant P might use the arrival of a  REQUEST-TO-PREPARE message to tell it to execute an end-of-\ntransaction trigger. But the trigger could update data at another participant Q that has already prepared, thereby \nreinfecting Q. So Q has to prepare again. \n This complicates matters. The coordinator already may have received Q’s  PREPARED message. If the coor-\ndinator receives P’s acknowledgment of its  REQUEST-TO-PREPARE before Q prepares again, it could commit \nbefore Q is prepared. To avoid this bad outcome, if Q is reinfected by a call from P, it should not reply to P \nuntil it has processed P’s request  and has prepared again by ensuring all updates it made due to the reinfection \nare in stable storage (see  Figure 8.5 ). That way, when P sends  PREPARED to the coordinator, it knows that Q is \nalso prepared (again) and it’s safe for the coordinator to commit. \n",
      "content_length": 3827,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 252,
      "content": " Transfer of Coordination \n If there is only one participant, then two-phase commit can be done with only three rounds of communication \ninstead of four. The trick is for the coordinator to transfer its  “ coordinator role ” to the participant, which then \nbecomes the coordinator. The optimized protocol works as follows (see  Figure 8.6 ): \n ■  The coordinator prepares and then sends a message to the participant that asks it to prepare  and to \nbecome the coordinator. \nREQUEST-TO-PREPARE\nPREPARED\nREQUEST-TO-PREPARE\nUPDATE DATA\nPREPARED\nCOMMIT\nDONE\nCOMMIT\nDONE\nParticipant P\nCoordinator\nParticipant Q\nAccess data at \nparticipant Q\nDo the requested\nwork and prepare\nagain\nReply and acknowledge prepared\n FIGURE 8.5 \n Reinfection. Participant P reinfects Participant Q after Q prepared. P waits for Q to prepare again and reply to P before P \nsends PREPARED to the coordinator, thereby ensuring Q is prepared before the coordinator commits. \nREQUEST-TO-PREPARE-AND\nTRANSFER COORDINATION\nCOMMIT\nDONE\nCoordinator\nParticipant\nLog a prepared record (eager)\nLog a commit record (eager)\nLog a committed record (eager)\nLog a done record (lazy)\n FIGURE 8.6 \n Transfer of Coordination Optimization. The coordinator prepares and then tells the participant to prepare and commit, \nand thereby become the coordinator. This saves a message over standard two-phase commit. \n8.4 Optimizations and Variations  233\n",
      "content_length": 1401,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 253,
      "content": "234  CHAPTER 8 Two-Phase Commit\n ■  The participant (which is now the coordinator) prepares, commits, and sends a  COMMIT message to the \nformer coordinator. \n ■  The coordinator commits and sends  DONE to the participant. \n Notice that the participant does not need a prepare phase in this case. However, since the participant is now \nperforming the coordinator’s role, it must remember the decision until it receives the  DONE message from the \nformer coordinator. This covers the case where the  COMMIT message is lost, and the former coordinator must \nlater ask the participant what the decision was. \n Using this observation, we can run two-phase commit in a system that uses a resource manager that does not \nsupport a separate prepare phase and can only commit or abort, as long as there is only one such resource manager \nin any transaction. To do this, the coordinator goes through the usual ﬁ rst phase of two-phase commit. After all the \nother participants have acknowledged that they’re prepared, the coordinator prepares and transfers coordination to \nthe resource manager that does not support two-phase commit. When the resource manager acknowledges that it \ncommitted, the coordinator can ﬁ nish the job by sending  COMMIT messages to the remaining participants. \n This can work with only one resource manager that doesn’t support the prepare phase. If there were two, then \nthe coordinator would have to tell them both to commit without asking them to prepare. If one committed and \nthe other didn’t, the result would be inconsistent, the very situation that two-phase commit is designed to avoid. \n Phase Zero \n Many systems use a mid-tier or client cache that holds copies of a transaction’s updates until the transaction \nhas terminated and is ready to commit. In this case, the cache manager needs to ﬂ ush the transaction’s updates \nto the appropriate resource manager before the two-phase commit protocol starts to ensure that the resource \nmanager stores a stable copy of the transaction’s updates during phase one. \n Suppose a participant P is caching transaction updates that P needs to send to a resource manager R before \nT commits. To ensure that R has all of T’s updates, P must send T’s updates to R after T invokes Commit (to \nensure it has  all the updates that will perform at R) and before R prepares (to ensure the updates are made \nstable during phase one). Thus, we need an extra phase, before phase one. \n A solution is to allow some participants to enlist for  phase zero of a transaction. For example, a mid-tier \ncache manager would enlist for phase zero of transaction T when the cache manager receives the ﬁ rst write on \nbehalf of T. When the transaction manager receives a transaction’s request to commit, the transaction manager \nsends a message to all of the transaction’s participants that enlisted for phase zero. A participant who receives \nsuch a message can ﬂ ush its cache or perform any other actions that need to be completed before phase one of \ntwo-phase commit begins. The transaction manager waits for all phase zero participants to reply to its phase \nzero request message before it starts executing phase one of two-phase commit. If it doesn’t receive one of \nthose replies within its timeout period, then it aborts the transaction. \n Presumed Abort \n Ordinarily , the coordinator does an eager write of the start-two-phase-commit log record (see  Figure 8.3 ). By \na slight modiﬁ cation of the protocol, the coordinator can avoid logging this record at all — at recovery time, if \nthere is no record of a transaction in the coordinator’s log, then the coordinator assumes the transaction must \nhave aborted. This assumption has several implications: \n ■  If a participant asks the coordinator about a transaction, and the coordinator has no information, then the \ncoordinator presumes the transaction aborted. This is more than a presumption; according to this revised \nprotocol, the transaction  must have aborted. \n",
      "content_length": 3980,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 254,
      "content": " ■  If the transaction aborts, a participant can do a  lazy log write of an abort decision and need not send \n DONE to the coordinator. \n ■  If the transaction aborts, the coordinator need not log a done record. \n To see why this works, suppose a participant is blocked at recovery time and sends a message to the coor-\ndinator. If the transaction aborted, there are two cases to consider: (1) the coordinator has an abort record in \nthe log (it aborted the transaction but failed before sending the  ABORT messages), in which case it replies with \nan abort decision; (2) it has no record at all — it didn’t abort the transaction (fully) before the failure — in which \ncase it again replies with an abort decision (the  “ presumed abort ” for the no-information case; see  Figure 8.7 ). \nIf the transaction committed (see  Figure 8.8 ), the coordinator must have a commit record in the log, since it \nis still obligated to remember commit decisions until all participants have replied  DONE (i.e., the two-phase \ncommit protocol is unchanged for the commit case, except that the coordinator doesn’t log a start-two-phase-\ncommit record). \n Presumed abort is a popular optimization, used by most implementations of two-phase commit. \n Read-Only Transactions \n If a participant reads but does not write data on behalf of the transaction, then it does not care what the deci-\nsion is. Whether the transaction commits or aborts, the participant does the same thing, namely, it releases the \ntransaction’s read locks. In fact, it need not wait to ﬁ nd out whether the transaction commits or aborts. It can \nrelease read locks as soon as it receives a  REQUEST-TO-PREPARE , since that signals that the transaction has \nterminated, at which point it is safe to release read locks, as far as two-phase locking is concerned. Therefore, \nin response to a  REQUEST-TO-PREPARE , it replies  PREPARED-READ-ONLY , which tells the coordinator not to \nbother sending a decision message (see  Figure 8.9 ). \n Although this optimization looks very appealing and intuitive, it often cannot be used in practice, because some \nparticipants may have more work to do after they receive a  REQUEST-TO-PREPARE (again violating assumption \n4 in Section 8.2). For example, they may need to execute SQL triggers or integrity constraints, which can involve \nacquiring more locks. We saw this kind of situation in the section on reinfection. If a read-only participant releases \nREQUEST-TO-PREPARE\nPREPARED\nDECISION-REQUEST\nABORT\nCoordinator\nParticipant\nStart two-phase-commit\nwithout logging a record\n                  Crash!\n                 Recover\nCoordinator responds Abort,\nsince it has no information\nLog a prepared record (eager)\nParticipant times out waiting\nfor a decision message, so it\nasks the coordinator\n FIGURE 8.7 \n Presumed Abort Optimization (the Abort Case). The coordinator need not log a start-two-phase-commit record. If it fails \nbefore it commits, it has no information about the transaction. In this case, it responds abort to requests for the decision. \n8.4 Optimizations and Variations  235\n",
      "content_length": 3089,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 255,
      "content": "236  CHAPTER 8 Two-Phase Commit\n a lock after receiving a  REQUEST-TO-PREPARE , and another participant acquires a lock later on while evaluating \na trigger, the transaction has broken the two-phase locking protocol and the result may not be serializable. \n If the application knows that a transaction is read-only, then it can get the same effect as the read-only opti-\nmization without any help from the transaction manager or resource managers. After the transaction has done \nits work, it issues an abort instead of a commit. The beneﬁ t of aborting is that the coordinator only does one \nround of messages to abort. And in this case, because the transaction is read-only, an abort has the same effect \nas a commit; namely, it tells each resource manager to release the transaction’s locks. However, notice that \nthis optimization is applicable only if the entire transaction is read-only. This is more restrictive than the read-\nonly optimization, which is applicable as long as the transaction is read-only at one resource manager. Also \nREQUEST-TO-PREPARE\nPREPARED-READ-ONLY\nREQUEST-TO-PREPARE\nPREPARED\nCOMMIT\nDONE\nParticipant P\nCoordinator\nParticipant Q\n FIGURE 8.9 \n Read-Only Optimization. Since Participant Q is read-only, it can release locks and ﬁ nish the transaction when it receives \na  REQUEST-TO-PREPARE , and the coordinator does not have to send it a  COMMIT . \nREQUEST-TO-PREPARE\nPREPARED\nDECISION-REQUEST\nCOMMIT\nCoordinator\nParticipant\nStart two-phase-commit\nwithout logging a record\nLog a commit record (eager)\n                  Crash!\n                 Recover\nCoordinator responds Commit,\nsince it has a commit record\nin its log\nLog a prepared record (eager)\nParticipant times out waiting\nfor a decision message, so it\nasks the coordinator\n FIGURE 8.8 \n Presumed Abort Optimization (the Commit Case). The coordinator does not log a start-two-phase-commit record. Since it \nfails after it commits, it responds commit to the request for the decision, exactly as if the optimization were not used. \n",
      "content_length": 2020,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 256,
      "content": " notice that this optimization is the responsibility of the application program, not the transaction manager and \nresource managers. It can be used only if the application program knows that the transaction did not perform \nany updates. If application does an RPC to a server whose internal behavior is unknown, then it has to assume \nthe worst and commit, not abort. \n Cooperative Termination Protocol \n Recall that the bad case when a participant recovers from a failure is that the participant logged a prepared \nrecord, but did not log a committed or aborted record. This means the participant is blocked and must run a ter-\nmination protocol. The participant can ﬁ nd out the decision from the coordinator, if it is alive. If not, it can avoid \nwaiting for the coordinator to recover by using the  cooperative termination protocol , which asks for help from \nother participants. \n The cooperative termination protocol requires that each participant knows the addresses of the other par-\nticipants, so that it can contact them if it is blocked during recovery. It therefore needs to get this information \nfrom the coordinator in the  REQUEST-TO-PREPARE message. At recovery time, it then proceeds as follows \n(see  Figure 8.10 ): \n 1.  The participant P sends a  DECISION-REQUEST message to the other participants. \n 2.  When a participant Q receives a  DECISION-REQUEST , it responds as follows: \n ■  If it knows what the decision was (i.e., it got a  COMMIT or  ABORT from the coordinator), then it \nreplies with the decision ( COMMIT or  ABORT ). \nREQUEST-TO-PREPARE\n(includes list of other\nparticipants)\nPREPARED\n(COMMIT/ABORT)\nDECISION-REQUEST\nDECISION-REPLY\nParticipant P\nCoordinator\nParticipant Q\nCrash!\nCrash!\n. . .\nRecover\nParticipant P sends this message only\nif Participant Q sent UNCERTAIN as its\nDECISION-REPLY.\nDecision\n FIGURE 8.10 \n Cooperative Termination Protocol. When Participant P recovers, the coordinator is down. So Participant P asks other \nparticipants what the decision was (via  DECISION-REQUEST ). Other participants, such as Participant Q, reply with \na  DECISION-REPLY containing  COMMIT ,  ABORT , or  UNCERTAIN . If Participant P learns the decision from some \nparticipant, then it sends a decision message to each participant that replied  UNCERTAIN in the previous round. \n8.4 Optimizations and Variations  237\n",
      "content_length": 2350,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 257,
      "content": "238  CHAPTER 8 Two-Phase Commit\n ■  If it did not prepare the transaction, it replies  ABORT . The transaction could not have committed, \nsince this participant did not send a  PREPARE to the coordinator. Since another participant is blocked, \nthere is no point in waiting for the decision from the coordinator, since the coordinator is apparently \ndown or not communicating with some participants. \n ■  If it prepared, but does not know what the decision was, then it replies  UNCERTAIN . This is the bad \ncase that doesn’t help participant  P . \n 3.  If any participant replies with a decision, then P acts on the decision and sends the decision to every \nparticipant that replied  UNCERTAIN , since they want to know the decision too. \n If participants are allowed to run the cooperative termination protocol, then it may not be a good idea for \nthem to forget the decision shortly after they receive it from the coordinator, because some other participant \nmay later ask for it when it runs the cooperative termination protocol. Since a participant could fail and be \ndown for a long time, there is no bound on how long participants should remember the decision. There are two \nways to handle this problem. First, each participant can simply hold on to each decision for some ﬁ xed amount \nof time, such as one minute, before discarding it. If asked later than that about the decision, it has to reply \n UNCERTAIN . Second, we could add a ﬁ fth round of messages from the coordinator to the participants, after the \ncoordinator receives  DONE from all the participants. This ﬁ nal message from the coordinator tells the partici-\npants that they can forget the decision, since all other participants know the decision and will not need to run \nthe cooperative termination protocol after a failure. Like  DONE messages, these ﬁ nal messages are not urgent \nand can be piggybacked on other messages from the coordinator to the participants. \n 8.5  PROCESS STRUCTURING \n Independent Transaction Managers \n Now that we have studied two-phase commit from a single transaction’s viewpoint, it is time to see how a sys-\ntem can manage two-phase commit on behalf of many transactions and resource managers. The usual approach \nis to have one module, the  transaction manager , be responsible for running the two-phase commit protocol, \nperforming both the coordinator and participant functions for a group of transactions. The transaction manager \nusually is packaged with another product, such as the operating system (as in Microsoft Windows and HP’s \nOpenVMS) or transactional middleware (as in IBM’s Websphere or Oracle’s WebLogic). \n One possibility is to have the transaction manager be part of the database system. This works ﬁ ne for trans-\nactions that access multiple copies of one particular database system. But it generally does not work with other \ndatabase systems, because each database system uses its own two-phase commit protocol, with its own mes-\nsage formats and optimizations. A different approach is needed for transactions to interoperate across different \ndatabase systems. \n The standard solution to this problem is to have the transaction manager be an independent component. \nIt runs two-phase commit for all transactions that execute on its machine. To do this, it communicates with \nresource managers on its own machine and with transaction managers on other machines. \n Although one transaction manager per machine is the standard conﬁ guration, it is not the only one. A trans-\naction manager may support multiple machines, or a machine may have multiple transaction managers. In a \nclustered environment where two or more machines share disks and other resources, there may be one trans-\naction manager for the cluster rather than one per machine. In this case, if the transaction manager’s machine \nfails, then the cluster manager needs to recreate the transaction manager on another machine in the cluster that \n",
      "content_length": 3943,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 258,
      "content": " has access to the transaction manager’s log. Conversely, a machine that runs heterogeneous software may have \nmultiple transaction managers. For example, it may run transactional middleware that has its own transaction \nmanager while executing on a machine whose operating system and database system have transaction manag-\ners. This is usually inefﬁ cient, due to the logging and communication that each transaction manager requires. \nBut it is unavoidable if the application depends on those heterogeneous components. \n This system model of having an independent transaction manager has been standardized by X/Open (now \npart of The Open Group), which also has deﬁ ned the interface between transaction managers and resource man-\nagers, so that transaction and resource managers from different vendors can be hooked up (see  Figure 8.11 ). \nNotice that this model deﬁ nes the transaction bracketing interface (TX) but not the interfaces to resource man-\nagers (which are covered by other standards, notably SQL). The application programming interface may also \ninclude other operations, which are not shown in the model. Although the X/Open model is widely supported, \nmany transaction managers offer proprietary interfaces too. Section 10.6 describes other transaction manage-\nment standards, such as the Object Transaction Service and the Java Transaction API. \n Enlisting in a Transaction \n In this architecture, each transaction manager can be the coordinator of a transaction; its participants are local \nresource managers accessed by the transaction and, when a transaction is propagated to a remote machine, \nremote transaction managers on those remote machines. Or, a transaction manager can be a participant, being \ncoordinated by transaction managers on other machines. As we’ll see, a transaction manager can be both, even \nfor the same transaction. Since each transaction accesses different resource managers at different machines \nof the network, the transaction manager must dynamically ﬁ gure out the coordinator-participant relationships \nfor each transaction. To dynamically manage transactions in this way, each resource manager and transaction \nmanager must  join or  enlist in a transaction when it is ﬁ rst accessed on behalf of the transaction. \n When the application calls a local resource manager, R, for the ﬁ rst time on behalf of a transaction T, R calls its \nlocal transaction manager with Enlist(T), which  “ enlists R in T. ” This tells the transaction manager that R needs to \nbe notiﬁ ed about commit and abort operations later (see  Figure 8.12 ). When the transaction manager later receives \na commit or abort operation for T, it runs two-phase commit with the local resource managers that enlisted in T. \nApplication program\nTransaction manager\nResource manager operations\nsuch as Read and Write\nTX interface \u0003 Start Transaction, \nCommit, Roll Back (i.e.,  Abort)\nApplication\nprogramming\ninterface\nResource manager\nXA interface \u0003 Enlist and\ntwo-phase commit operations\n FIGURE 8.11 \n X/Open Transaction Model. The transaction manager runs two-phase commit for all transactions at its machine and \ncommunicates with local resource managers. \n8.5 Process Structuring  239\n",
      "content_length": 3208,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 259,
      "content": "240  CHAPTER 8 Two-Phase Commit\n Similarly , when the application calls an application or resource manager at a remote machine M for the \nﬁ rst time, the application’s local transaction manager and machine M’s transaction manager must be notiﬁ ed \nthat the transaction has moved, thereby starting a new  branch of the transaction at M. This is done by the \ncomponent that performs remote transactional communications, usually called the  communication manager . \nLike the transaction manager, it may be part of the transactional middleware, operating system, or resource \nmanager (for remote resource manager calls). \n For example in  Figure 8.13 , application AP 1 running transaction T at machine M calls application AP 2 at \nmachine N. In addition to sending the message and calling the remote application, the communication manager \ncreates a branch of T at N. This is needed so that M’s transaction manager knows to send two-phase commit \nmessages to N’s transaction manager. It also tells N’s transaction manager to expect Enlist operations on this \nApplication program,  AP1\nApplication program,  AP2\nTransaction manager\nlocal to AP1\nTransaction manager\nlocal to AP2\n1. Call(AP2, T)\n2. AddBranch(N, T)\nMachine M\nMachine N\n3. Send \n“Call(AP2, T)”\n5. Call(AP2, T)\n4. StartBranch(T)\nApplication\nprogramming\ninterface\nCommunication manager\nlocal to AP1\nCommunication manager\nlocal to AP2\n FIGURE 8.13 \n A Remote Call That Starts a Branch Transaction. Application AP 1  calls application AP 2  at a remote machine N, thereby \ncreating a branch transaction at N. The communication manager tells the transaction managers at machines M and N \nabout the new branch by the AddBranch and StartBranch calls, respectively. \nApplication program\nTransaction manager\n2.  Write(X, T)\n1. Start transaction\n(returns transaction ID T)\n3.  Enlist(T)\nApplication\nprogramming\ninterface\nResource manager\n FIGURE 8.12 \n A Resource Manager Enlists for a Transaction. When an application program executing a transaction ﬁ rst accesses a \nresource manager, the resource manager enlists with its local transaction manager. This tells the transaction manager to \nnotify the resource manager about this transaction’s commit or abort operation later. \n",
      "content_length": 2227,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 260,
      "content": " transaction from N’s resource managers and to expect two-phase commit operations from M’s transaction man-\nager. In some systems, M’s transaction manager establishes communications with N’s transaction manager (if it \nhasn’t already done so) and sends an enlistment message. This tells N’s transaction manager where to send the \ntwo-phase commit messages later. \n It requires a high degree of trust for a transaction manager on one machine to agree to communicate with \na transaction manager on another machine. Each transaction manager needs to know that the other transaction \nmanager will make timely and correct progress toward completing the transaction. In particular, if a trans-\naction manager acting as coordinator stops communicating with the other transaction acting as participant, \nthen the participant could become blocked. Each transaction manager needs to believe this is a very unlikely \nevent before agreeing to communicate. This trust relationship is hard to establish between different enterprises, \nsince their systems are autonomous and independently managed. For this reason, two-phase commit rarely is \nexecuted between systems in different enterprises. It may even be problematic between systems with a single \nlarge enterprise. It is more commonly used between machines that support different parts of the same applica-\ntion, which are controlled by the same system manager. \n The Tree-of-Processes Model \n A transaction can migrate from machine to machine many times during its execution. This leads to a tree-\nstructured set of transaction managers and resource managers involved in the transaction, called the  tree-of-\nprocesses model of transaction execution. For example, a transaction could migrate as follows (see  Figure 8.14 ): \n ■  It started at machine 1 and accessed resource manager RM 1 . \n ■  From machine 1, it made a remote call to machine 2, where it accessed resource managers RM 2a and RM 2b . \n ■  From machine 1, it made a remote call to machine 3, where it accessed resource manager RM 3 . \n ■  From machine 3, it made a remote call to machine 4, where it accessed resource manager RM 4 . \nTM1\nTM3\nRM1\nTM2\nRM2b\nRM2a\nRM3\nTM4\nRM4\nLegend: \n• RM \u0003 Resource manager\n• TM \u0003 Transaction manager\n• Dashed lines indicate machine boundaries.\n• Arrows are from a coordinator to its \n  participants.\n FIGURE 8.14 \n Tree-of-Processes Model. By migrating from machine to machine and accessing resource managers, a transaction \ncreates a tree of coordinators and participants that will run two-phase commit. A particular execution that leads to this \ntree is described in the text. \n8.5 Process Structuring  241\n",
      "content_length": 2648,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 261,
      "content": "242  CHAPTER 8 Two-Phase Commit\n In the tree of processes model, the root transaction manager is the coordinator, and its children are partici-\npants. So in  Figure 8.14 , TM 1 is the overall coordinator, and TM 2 , TM 3 , and RM 1 are its participants. TM 2 is, \nin turn, the coordinator of RM 2a and RM 2b , and TM 3 is the coordinator of RM 3 and TM 4 . So TM 2 and TM 3 play \nthe roles of both participant (with respect to TM 1 ) and coordinator (with respect to their children). Similarly, \nTM 4 is a participant (with respect to TM 3 ) and coordinator (with respect to RM 4 ). \n In  Figure 8.14 , suppose the transaction executing on machine 4 calls an application on machine 1. This attempt \nto execute StartBranch on machine 1 returns a warning that the transaction already is executing on machine 1. \nThis just means that TM 1 does not become a participant with respect to TM 4 . This is not an error, so the call to \nthe application at machine 1 succeeds. That application’s operations on machine 1’s resource managers, such as \nRM 1 , are part of the transaction and are committed or aborted whenever TM 1 tells its local resource managers to \ncommit or abort. \n When a transaction manager is both a participant and a coordinator, it must prepare its subtree before it \nreplies prepared to a  REQUEST-TO-PREPARE message. For example, in  Figure 8.14 : \n ■  After TM 3  receives  REQUEST-TO-PREPARE from TM 1 , it should send a  REQUEST-TO-PREPARE to RM 3  \nand TM 4 . \n ■  TM 4  then sends a  REQUEST-TO-PREPARE to RM 4 . \n ■  After RM 4  replies  PREPARED , TM 4  can reply  PREPARED to TM 3 . \n ■  After TM 4  and RM 3  reply  PREPARED , TM 3  can reply  PREPARED to TM 1 . \n A tree-of-processes adds delay to two-phase commit because of the daisy-chain of communication, such as \nfrom TM 1 , to TM 3 , to TM 4  in the example. This delay can be reduced by ﬂ attening the tree, so that all transac-\ntion managers communicate with the root coordinator. For example, if TM 1  knew about TM 4 , it could com-\nmunicate with TM 4  directly and in parallel with its communication wit h TM 2  and TM 3 . This short-circuiting \nof communications is called  ﬂ attening the tree. It can be done by passing knowledge of new branches back up \nthe tree during normal execution. For example, when the transaction migrates from TM 3  to TM 4 , TM 3  could \ntell TM 1  about the migration, so TM 1  can later communicate with TM 4  directly (see  Figure 8.15 ). Although \nthis ﬂ attening is usually desirable, it is not always possible, because some pairs of machines may not be able to \ncommunicate directly. \nTM1\nTM3\nRM1\nTM2\nRM2b\nRM2a\nRM3\nTM4\nRM4\n FIGURE 8.15 \n Flattening the Tree-of-Processes. If TM 3  tells TM 1  about TM 4 , then TM 1  can communicate with TM 4  directly. This ﬂ attens \nthe tree of  Figure 8.14 , thereby reducing communication delay from TM 1  to TM 4 . \n",
      "content_length": 2878,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 262,
      "content": " 8.6  USER CHECKLIST \n There are several aspects of a two-phase commit implementation that are of direct interest to users of TP \nproducts. The most obvious is whether two-phase commit is appropriate at all. The communication required \nfor two-phase commit increases transaction execution time and hence lock holding time. This can increase \nthe lock conﬂ ict rate and hence reduce throughput. In addition, if the communication connections between \nresource managers are  not extremely reliable, then the probability of blocked transactions may be unaccept-\nably high. In these cases, there are two possible solutions: ensure that each transaction can do its work with \njust one resource manager, or split the transaction into a multistep business process where each step is a trans-\naction that accesses only one resource manager. Both approaches require extra application development effort. \nThe beneﬁ ts are better performance or availability. \n If transactions do indeed need to perform updates at multiple resource managers, one needs to check \nwhether each resource manager product supports two-phase commit at all. Today, most popular database sys-\ntems and transactional middleware support it. However, not all combinations of database systems and trans-\nactional middleware work correctly together; that is, they don’t all  interoperate . Even if a database system \nsupports the X/Open interfaces, there is still the question of whether it has been tested with a given transac-\ntional middleware product and whether it exploits any proprietary optimizations that a given transaction man-\nager offers. Such optimizations can have a big effect on transaction performance. \n Although there is increasing support for standard two-phase commit protocols, there is enough variation \nthat this doesn’t always guarantee compatibility. Moreover, some transaction manager vendors use their own \ntwo-phase commit protocol. In a system that uses transaction managers from different vendors, a transaction \nmight need to access applications or resource managers that use these different transaction managers. To get \nall-or-nothing behavior, the transaction managers need to interoperate. That is, one of the transaction managers \nmust be willing to communicate using the other transaction manager’s two-phase commit protocol. \n For the most part, two-phase commit is transparent to system operators. However, when a transaction is \nblocked due to a failure, an operator may need to get involved. Although this event occurs rarely, when there \nis a failure, there is a good chance that  some transaction will be blocked. Therefore, support for heuristic deci-\nsions is valuable, along with notiﬁ cation of inconsistent decisions when they are made. \n Two -phase commit should be transparent to application programmers. If it isn’t, then the vendor’s imple-\nmentation is incomplete. However, if a nonstandard or home-grown database system is used in an application, \nthen it is unlikely to be supported by the TP system’s built-in two-phase commit implementation. In this case, \nit is important that the resource manager interface to the transaction manager be exposed. This interface allows \nthe user to integrate the nonstandard resource manager with the transaction manager, so the resource manager’s \noperations can be included in distributed transactions. \n 8.7  SUMMARY \n The two-phase commit protocol ensures that a transaction either commits at all the resource managers that \nit accessed or aborts at all of them. It avoids the undesirable outcome that the transaction commits at one \nresource manager and aborts at another. The protocol is driven by a coordinator, which communicates with \nparticipants, which together include all the resource managers accessed by the transaction. \n Since failures are unavoidable, the protocol must ensure that if a failure occurs, the transaction can reach \na consistent outcome after the failed component recovers. It therefore requires that, during phase one, every \nresource manager prepares the transaction by recording all the transaction’s updates on stable storage. After \n8.7 Summary  243\n",
      "content_length": 4139,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 263,
      "content": "244  CHAPTER 8 Two-Phase Commit\n all resource managers have acknowledged to the coordinator that they  “ prepared ” in phase one, the coordinator \nstarts phase two by committing the transaction and then notifying the participants of this commit decision. If \nany participant fails to acknowledge phase one, or votes  “ no, ”  then the coordinator aborts the transaction and \nnotiﬁ es the participants of this decision. \n The complexity of two-phase commit comes from all the failure scenarios that can arise. The most annoy-\ning failure happens after a participant has acknowledged prepared and before it receives the decision, such as \na failure of the coordinator or of participant-coordinator communications. This leaves the participant blocked. \nIt can’t commit or abort, since the coordinator may have decided the opposite and the participant can’t ﬁ nd out \nthe decision. This problem is inherent in any commit protocol when communication failures are possible and \nnot a special weakness of two-phase commit in particular. \n The coordinator and participant must log certain changes in their state, so if either of them fails and subse-\nquently recovers, it can tell what it was doing at the time of failure and take appropriate action. In particular, \nthe coordinator must write a log record before beginning the protocol and before sending its decision, and each \nparticipant must log a prepared record before acknowledging prepared. Each participant should log the decision \nwhen it ﬁ nds out what it was. Finally, the coordinator should write a log record when it gets all acknowledgments \nof its decision, so it knows it can forget the transaction. One then must go through a careful analysis to determine \nwhat the coordinator and each participant should do in every possible failure situation that can arise. \n There are variations of two-phase commit to handle special transaction communications patterns. Three \npopular ones are reinfection, to handle a transaction that revisits a resource manager after the two-phase com-\nmit protocol has started; transfer of coordination, to enable one participant to use one-phase commit; and phase \nzero, when a mid-tier cache needs to ﬂ ush its updates before phase one. There are also many optimizations of \ntwo-phase commit to reduce the number of log writes and messages. The most popular one is presumed abort, \nwhich avoids requiring that the coordinator write a log record before beginning of the protocol and before \naborting a transaction. \n Two -phase commit is implemented by the transaction manager component, which communicates with local \nresource managers and remote transaction managers. It plays the role of coordinator or participant, depending \non whether the transaction started at its machine or elsewhere. It needs to be notiﬁ ed when a transaction has ﬁ rst \naccessed a resource manager or moved to another machine, so it will know with whom to communicate when \nit comes time to run two-phase commit. X/Open has standardized the transaction manager’s interfaces with \nresource managers, called XA. This standard is widely supported, but most systems also have more efﬁ cient \nnonstandard interfaces too. Most transaction managers support a unique proprietary protocol. \n \n",
      "content_length": 3250,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 264,
      "content": " 9.1  INTRODUCTION \n Replication is the technique of using multiple copies of a server or a resource for better availability and per-\nformance. Each copy is called a  replica . \n The main goal of replication is to improve availability, since a service is available even if some of its repli-\ncas are not. This helps mission critical services, such as many ﬁ nancial systems or reservation systems, where \neven a short outage can be very disruptive and expensive. It helps when communications is not always avail-\nable, such as a laptop computer that contains a database replica and is connected to the network only intermit-\ntently. It is also useful for making a cluster of unreliable servers into a highly-availabl e system, by replicating \ndata on multiple servers. \n Replication can also be used to improve performance by creating copies of databases, such as data ware-\nhouses, which are snapshots of TP databases that are used for decision support. Queries on the replicas can be \nprocessed without interfering with updates to the primary database server. If applied to the primary server, such \nqueries would degrade performance, as discussed in Section 6.6,  Query-Update Problems in two-phase locking. \n In each of these cases, replication can also improve response time. The overall capacity of a set of repli-\ncated servers can be greater than the capacity of a single server. Moreover, replicas can be distributed over a \nwide area network, ensuring that some replica is near each user, thereby reducing communications delay. \n 9.2  REPLICATED SERVERS \n The Primary-Backup Model \n To maximize a server’s availability, we should try to maximize its mean time between failures (MTBF) and \nminimize its mean time to repair (MTTR). After doing the best we can at this, we can still expect periods of \nunavailability. To improve availability further requires that we introduce some redundant processing capability \nby conﬁ guring each server as two server processes : a primary server that is doing the real work, and a backup \nserver that is standing by, ready to take over immediately after the primary fails (see  Figure 9.1 ). The goal is \nto reduce MTTR: If the primary server fails, then we do not need to wait for a new server to be created. As \nsoon as the failure is detected, the backup server can immediately become the primary and start recovering to \nthe state the former primary had after executing its last non-redoable  operation, such as sending a message to \n Replication \n 9 \nCHAPTER\n",
      "content_length": 2510,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 265,
      "content": "246  CHAPTER 9 Replication\nan ATM to dispense money. If it recovered to an earlier state, it would end up redoing the operation, which \nwould be incorrect. Since we are interested primarily in transactional servers, this means recovering to a state \nthat includes the effects of all transactions that committed at the former primary and no other transactions. \nFor higher availability, more backup servers can be used to guard against the possibility that the primary and \nbackup fail. \n This technique is applicable to resource managers and to servers that run ordinary applications, such as \nrequest controllers and transaction servers. When a server of either type fails, it needs to be recreated. Having \na backup server avoids having to create the backup server at recovery time. \n If there are many clients and some are connected by slow communication lines, then it can take a long time \nto recreate sessions with the backup server. To avoid doing this at recovery time, each client connected to the \nprimary server should also have a backup communication session with the backup server. This further decreases \n(i.e., improves) MTTR. \n In general, the degree of readiness of the backup server is a critical factor in determining MTTR. If a \nbackup server is kept up to date so that it is always ready to take over when the primary fails with practically \nno delay, then it is called a  hot backup . If it has done some preparation to reduce MTTR but still has a signiﬁ -\ncant amount of work to do before it is ready to take over from the primary, then it is called a  warm backup . If \nit has done no preparation, then it is called a  cold backup . \n As in the case of a server that has no backup, when the primary server fails, some external agent, such as a \nmonitoring process, has to detect the failure and then cause the backup server to become the primary. The delay \nin detecting failures contributes to MTTR, so fast failure detection is important for high availability. \n Once the backup server has taken over for the failed primary, it may be worthwhile to create a backup for the \nnew primary. An alternative is to wait until the former primary recovers, at which time it can become the backup. \nThen, if desired, the former backup (which is the new primary) could be told to fail, so that the original primary \nbecomes primary again and the backup is restarted as the backup again. This restores the system to its original \nconﬁ guration, which was tuned to work well. The cost is a brief period of downtime while the secondary and \nprimary switch roles. \n When telling a backup to become the primary, some care is needed to avoid ending up with two servers \nbelieving they’re the primary. For example, if the monitor process gets no response from the primary, it may con-\nclude that the primary is dead. But the primary may actually be operating. It may just be slow because its system \nis overloaded (e.g., a network storm is swamping its operating system), and it therefore hasn’t sent an  “ I’m alive ” \nmessage in a long time, which the monitor interprets as a failure of the primary. If the monitor then tells the \nbackup to become the primary, then two processes will be operating as primary. If both primaries perform opera-\ntions against the same resource, they may conﬂ ict with each other and corrupt that resource. For example, if the \nPrimary\nServer\nBackup\nServer\nClient\n FIGURE 9.1 \n Primary-Backup Model. The primary server does the real work. The backup server is standing by, ready to take over after \nthe primary fails. \n",
      "content_length": 3559,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 266,
      "content": "resource is a disk they might overwrite each other, or if the resource is a communications line they may send \nconﬂ icting messages. \n One way to avoid ending up with two primaries is to require the primary to obtain a lock that only one pro-\ncess can hold. This lock could be implemented in hardware as part of the resource. For example, some network-\ning techniques, such as reﬂ ective memory, and most disk systems, such as SCSI and Fiber Channel (as it runs \nover SCSI), allow a lock on a resource over their shared bus. Or it could be implemented in software using a \nglobal lock manager, which is supported by some operating systems that are designed for multiserver clusters and \nas independent components in some distributed systems. Another solution is to use a third  “ watchdog ” process, \nwhich is described in Section 9.4,  Primary Recovery with One Secondary . \n Replicating the Resource \n A server usually depends on a resource, typically a database. When replicating a server, an important consid-\neration is whether to replicate the server’s resource too. The most widely-used  approach to replication is to \nreplicate the resource (i.e., the database) in addition to the server that manages it (see  Figure 9.2 ). This has two \nbeneﬁ ts. First, it enables the system to recover from a failure of a resource replica as well as a failure of a server \nprocess. And second, by increasing the number of copies of the resource, it offers performance beneﬁ ts when \naccess to the resource is the bottleneck. For example, the backup can do real work, such as process queries, and \nnot just maintain the backup replica so it can take over when there is a failure. \n The main technical challenge in implementing this approach to replication is to synchronize updates \nwith queries and each other when these operations execute on different replicas. This approach of replicating \nresources, and its associated technical challenges, is the main subject of this chapter, covered in Sections 9.3 \nthrough 9.6. \n Replicating the Server with a Shared Resource \n Another approach is to replicate the server without replicating the resource, so that all copies of the server \nshare the same copy of the resource (see  Figure 9.3 ). This is useful in a conﬁ guration where processors share \nPrimary\nServer\nBackup\nServer\nClient\nResource\nReplicas\nResource\nReplicas\n FIGURE 9.2 \n Replicating a Server and Its Resource. Both the server and the resource are replicated, which enables recovery from a \nresource failure. \n9.2 Replicated Servers  247\n",
      "content_length": 2542,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 267,
      "content": "248  CHAPTER 9 Replication\nstorage, such as a storage area network. In a primary-backup conﬁ guration, if the primary fails and the resource \nis still available, the backup server on another processor can continue to provide service (see  Figure 9.3a ). \n This primary-backup approach improves availability, but not performance. If the server is the bottleneck and \nnot the resource, then performance can be improved by allowing multiple servers to access the resource concur-\nrently, as shown in  Figure 9.3b . This approach, often called  data sharing , introduces the problem of conﬂ icts \nbetween transactions that execute in different servers and read and write the same data item in the resource. One \nsolution is to partition the resource and assign each partition to one server. That way, each server can treat the \npartition as a private resource and therefore use standard locking and recovery algorithms. If a server fails, its par-\ntition is assigned to another server, like in the primary-backup approach. Another solution is to allow more than \none server to access the same data item. This solution requires synchronization between servers and is discussed \nin Section 9.7. \n 9.3  SYNCHRONIZING UPDATES TO REPLICATED DATA \n One-Copy Serializability \n On possible goal of replication is to have replicas behave functionally like nonreplicated servers. This goal can \nbe stated precisely by the concept of one-copy serializability, which extends the concept of serializability to a \nsystem where multiple replicas are present. An execution is  one-copy serializable if it has the same effect as \na serial execution on a one-copy database. We would like a system to ensure that its executions are one-copy \nserializable. In such a system, the user is unaware that data is replicated. \n In a system that produces serializable executions, what can go wrong that would cause it to violate one-\ncopy serializability? The answer is simple, though perhaps not obvious: a transaction might read a copy of a \ndata item, say  x , that was not written by the last transaction that wrote other copies of  x . For example, consider \na system that has two copies of  x , stored at locations A and B, denoted  x A and  x B . Suppose we express execu-\ntion histories using the notation of Section 6.1, where  r ,  w , and  c represent read, write, and commit operations, \nrespectively, and subscripts are transaction identiﬁ ers. Consider the following execution history: \n H\nr [\n] w [\n] w [\n] c  r [\n] w [\n] c  r [\n] w [\n] w\nA\nA\nB\nB\nB\nA\nA\n\u0003\n1\n1\n1\n1\n2\n2\n2\n3\n3\nx\nx\nx\nx\nx\nx\nx\n3\n3\n[\n] c  \nB\nx\n \nPrimary\nServer\nBackup\nServer\nClient\nResource\na. Primary and backup share the resource\nb. Many servers concurrently share the resource\nServer1\nServern\nServer2\nClient\nResource\n FIGURE 9.3 \n Replicated Server with Shared Resource. In (a), the primary and backup server share the resource, but only one of them \nuses the resource at any given time. In (b), many servers share the resource and can concurrently process requests \nthat require access to the resource. \n",
      "content_length": 3051,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 268,
      "content": " This is a serial execution. Each transaction reads just one copy of  x ; since the copies are supposed to be iden-\ntical, any copy will do. The only difﬁ culty with it is that transaction T 2 did not write into copy  x A . This might \nhave happened because copy  x A was unavailable when T 2 executed. Rather than delaying the execution of T 2 \nuntil after  x A recovered, the system allowed T 2 to ﬁ nish and commit. Since we see r 3 [ x A ] executed after c 2 , appar-\nently  x A recovered before T 3 started. However, r 3 [ x A ] read a stale value of  x A , the one written by T 1 , not T 2 . \n When  x A recovered, it should have been refreshed with the newly updated value of  x that is stored in  x B . \nHowever, we do not see a write operation into  x A after T 2 committed and before r 3 [ x A ] executed. We therefore \nconclude that when r 3 [ x A ] executed,  x A still had the value that T 1 wrote. \n Clearly , the behavior of H is not what we would expect in a one-copy database. In a one-copy database, T 3 \nwould read the value of  x written by T 2 , not T 1 . There is no other serial execution of T 1 , T 2 , and T 3 that has the \nsame effect as H. Therefore, H does not have the same effect as any serial execution on a one-copy database. \nThus, it is not one-copy serializable. \n One obvious implication of one-copy serializability is that each transaction that writes into a data item  x \nshould write into all copies of  x . However, when replication is used for improved availability, this isn’t always \npossible. The whole point is to be able to continue to operate even when some copies are unavailable. Therefore, \nthe not-so-obvious implication of one-copy serializability is that each transaction that reads a data item  x must \nread a copy of  x that was written by the most recent transaction before it that wrote into any copy of  x . This \nsometimes requires careful synchronization. \n Still , during normal operation, each transaction’s updates should be applied to all replicas. There are two ways \nto arrange this: replicate update operations or replicate requests. In the ﬁ rst case, each request causes one transac-\ntion to execute. That transaction generates update operations, each of which is applied to all replicas. In the sec-\nond case, the request message is sent to all replicas and causes a separate transaction to execute at each replica. \nWe discuss each case, in turn. \n Replicating Updates \n There are two approaches to sending a transaction’s updates to replicas: synchronous and asynchronous. In the \n synchronous approach, when a transaction updates a data item, say  x , the update is sent to all replicas of  x . \nThese updates of the replicas execute within the context of the transaction. This is called synchronous because \nall replicas are, in effect, updated at the same time (see  Figure 9.4a ). Although sometimes this is feasible, often \nX1\nX2\nX3\nX1\nX2\nX3\nT:  Start\n \n…\n \nWrite(x1)\n \nWrite(x2)\n \nWrite(x3)\n \n…\n \nCommit\nT:  Start\n \n…\n \nWrite(x1)\n \n…\n \nCommit\nSometime later:\n \nWrite(x2)\n \nWrite(x3)\na. Synchronous replication\nb. Asynchronous replication\n FIGURE 9.4 \n Synchronous vs. Asynchronous Replication. In synchronous replication, each transaction updates all copies at the same \ntime. In asynchronous replication, a transaction updates only one replica immediately. Its updates are propagated to the \nother replicas later. \n9.3 Synchronizing Updates to Replicated Data  249\n",
      "content_length": 3444,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 269,
      "content": "250  CHAPTER 9 Replication\nit is not, because it produces a heavy distributed transaction load. In particular, it implies that all transactions \nthat update replicated data have to use two-phase commit, which entails signiﬁ cant communications cost. \n Fortunately , looser synchronization can be used, which allows replicas to be updated independently. This is \ncalled  asynchronous replication, where a transaction directly updates one replica and the update is propagated \nto other replicas later (see  Figure 9.4b ). \n Asynchronous updates from different transactions can conﬂ ict. If they are applied to replicas in arbitrary \norders, then the replicas will not be identical. For example, suppose transactions T 1 and T 2 update  x , which has \ncopies  x A and  x B . If T 1 updates  x A before T 2 , but T 1 updates  x B after T 2 , then  x A and  x B end up with different val-\nues. The usual way to avoid this problem is to ensure that the updates are applied in the same order to all replicas. \nBy executing updates in the same order, all replicas go through the same sequence of states. Thus, each query (i.e., \nread-only transaction) at any replica sees a state that could have been seen at any other replica. And if new updates \nwere shut off and all in-ﬂ ight updates were applied to all replicas, the replicas  would be identical. Therefore, users \nworking with one replica see the same behavior that they would see with any other replica. In this sense, all repli-\ncas behave exactly the same way. \n Applying updates in the same order to all replicas requires some synchronization. This synchronization can \ndegrade performance, because some operations are delayed until other operations have time to complete. Much \nof the complexity in replication comes from clever synchronization techniques that minimize this performance \ndegradation. \n Whether synchronous or asynchronous replication is used, applying updates to all replicas is sometimes \nimpossible, because some replicas are down. The system could stop accepting updates when this happens, but \nthis is rarely acceptable since it decreases availability. If some replicas do continue processing updates while \nother replicas are down, then when the down replicas recover, some additional work is needed to recover the \nfailed replicas to a satisfactory state. Some of the complexity in replication comes from ways of coping with \nunavailable servers and handling their recovery. \n Replicas can be down either because a system has failed or because communication has failed (see  Figure \n9.5 ). The latter is more dangerous, because it may lead to two or more independently functioning partitions \nof the network, each of which allows updates to the replicas it knows about. If a resource has replicas in both \nReplica 1\nReplica 2\nReplica 3\na. Replica 3 fails\nReplica 1\nReplica 2\nReplica 3\nb. Network connection\n \nto Replica 3 fails\n FIGURE 9.5 \n Node and Communications Failures. Replica 1, Replica 2, and Replica 3 are connected by a network. In (a), Replica 3 \nfails. In (b), the connection to Replica 3 fails. Replica 1 and Replica 2 cannot distinguish these two situations, yet the \nsystem’s behavior is quite different. \n",
      "content_length": 3198,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 270,
      "content": "partitions, those replicas can be independently updated. When the partitions are reunited, they may discover \nthey have processed incompatible updates. For example, they might both have sold the last item from inven-\ntory. Such executions are not one-copy serializable, since it could not be the result of a serial execution on a \none-copy database. There are two solutions to this problem. One is to ensure that if a partition occurs, only one \npartition is allowed to process updates. The other is to allow multiple partitions to process updates and to rec-\noncile the inconsistencies after the partitions are reunited — something that often requires human intervention. \n Circumventing these performance and availability problems usually involves compromises. To conﬁ gure a \nsystem with replicated servers, one must understand the behavior of the algorithms used for update propaga-\ntion and synchronization. These algorithms are the main subject of this chapter. \n Replicating Requests \n An alternative to sending updates to all replicas is to send the  requests to run the original transactions to all \nreplicas (see  Figure 9.6 ). To ensure that all the replicas end up as exact copies of each other, the transactions \nshould execute in the same order at all replicas. Depending on the approach selected, this is either slow or \ntricky. A slow approach is to run the requests serially at one replica and then force the requests to run in the \nsame order as the other replicas. This ensures they run in the same order at all replicas, but it allows no concur-\nrency at each replica and therefore would be an inefﬁ cient use of each replica’s resources. \n The trickier approach is to allow concurrency within each replica and use some fancy synchronization \nacross replicas to ensure that timing differences at the different replicas don’t lead to different execution orders \nat different replicas. For example, in HP’s Reliable Transaction Router (RTR), a replicated request can be exe-\ncuted at two or more replicas concurrently as a single distributed transaction. Since it runs as a transaction, it is \nserialized with respect to other replicated requests (which also run as transactions). It therefore can execute con-\ncurrently with other requests. Transaction synchronization (e.g., locking) ensures that the requests are processed \nin the same order at all replicas. As usual, transaction termination is synchronized using two-phase commit. \nHowever, unlike ordinary two-phase commit, if one of the replicas fails while a transaction is being committed, \nPrimary\nServer\nBackup\nServer\nRequest\nReplicator\nRequest\nRequest\nResource\nReplica\nResource\nReplica\n FIGURE 9.6 \n Replicating Requests. Each transaction runs independently against each replica. In both cases, conﬂ icting updates must \nbe applied in the same order against all replicas. \n9.3 Synchronizing Updates to Replicated Data  251\n",
      "content_length": 2903,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 271,
      "content": "252  CHAPTER 9 Replication\nthe other continues running and commits the transaction. This is useful in certain applications, such as securi-\nties trading (e.g., stock markets), where the legal deﬁ nition of fairness dictates that transactions must execute in \nthe order they were submitted, so it is undesirable to abort a transaction due to the failure of a replica. \n Replicating updates is a more popular approach than replicating requests, by far. Therefore, we will focus \non that approach for the rest of this chapter. \n 9.4  SINGLE-MASTER PRIMARY-COPY REPLICATION \n Normal Operation \n The most straightforward, and often pragmatic, approach to replication is to designate one replica as the pri-\nmary copy and to allow update transactions to read and write only that replica. This is the primary-backup \ntechnique illustrated in  Figure 9.1 . Updates on the primary are distributed to other replicas, called  secondaries , \nin the order in which they executed at the primary and are applied to secondaries in that order (see  Figure 9.7 ). \nThus, all replicas process the same stream of updates in the same order. In between any two update transactions, \na replica can process a local query. \n One way to propagate updates is by synchronous replication. For example, in a relational database sys-\ntem, one could deﬁ ne an SQL trigger on the primary table that remotely updates secondary copies of the table \nwithin the context of the user’s update transaction. This implies that updates are propagated right away, which \nmay delay the completion of the transaction. It also means that administrators cannot control when updates \nare applied to replicas. For example, in some decision support systems, it is desirable to apply updates at ﬁ xed \ntimes, so the database remains unchanged when certain analysis work is in progress. \n Currently , the more popular approach is asynchronous replication, where updates to the primary gener-\nate a stream of updates to the secondaries, which is processed after transactions on the primary commit. For \ndatabase systems, the stream of updates is often a log. The log reﬂ ects the exact order of the updates that were \nperformed at the primary, so the updates can be applied directly to each secondary as they arrive. \n One application of primary-copy replication is  database mirroring , where there are only two replicas, one \nprimary and one secondary. This is a hot backup technique for high availability. Among the ﬁ rst general-purpose \nSecondary\nT1\nT2\nTn\nSecondary\nSecondary\nPrimary\nReplica\nUpdate\nTransactions\nUpdate Logs\n FIGURE 9.7 \n Propagating Updates from Primary to Secondaries. Transactions update data only at the primary replica. The primary \npropagates updates to the secondary replicas. The secondaries can process local queries. \n",
      "content_length": 2795,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 272,
      "content": "systems to do this were IBM’s IMS/XRF and Tandem’s (now HP’s) Non-Stop SQL database systems. Now most \ndatabase systems offer a database mirroring feature. \n With database mirroring, the primary sends its database log to the secondary. The secondary continually runs \nlog-based recovery, so that its database state is very close to that of the primary. If the primary fails, the second-\nary just needs to ﬁ nish processing the tail of the log it received before the primary failed, after which it can take \nover as primary. If synchronous replication is used, then no transactions are lost in this failover. With asynchro-\nnous replication, the secondary may not have received the last few updates from the primary. This problem can \nbe mitigated if the primary and secondary are colocated and the secondary can be given access to the primary \ncopy’s disk log. In that case, after the secondary is given control, it can read the disk log to pick up the last few \nlog records that it did not receive before the primary failed. \n Another application of primary-copy replication is to produce queryable copies of parts of a database. This \nis a functionally-rich  feature that is offered by most relational database products. In this case, there is no real-\ntime requirement to move the log records immediately to the secondary copy, so there is time to postprocess \nupdates from the primary copy in various ways. \n Some relational database systems capture updates to each primary table in a log table that is colocated with \nthe primary table (see  Figure 9.8b ). One approach is to have the system deﬁ ne an SQL trigger on each primary \ntable that translates each update into an insert on the log table. Periodically, the primary creates a new log table \nto capture updates and sends the previous log table to each secondary where it is applied to the replica. This \napproach to capturing updates can slow down normal processing of transactions, due to the extra work introduced \nby the trigger. \n Another approach is to postprocess the database log to create the stream of updates to the replicas. If this is done \non-line while the log is still in main memory, then it avoids slowing down normal processing of transactions as \ncompared to the trigger approach. In fact, the log can be sent to a different server, where the postprocessing is done. \n Since the log can be quite large, one reason to postprocess the log is to reduce its size if possible. One \ntechnique is to ﬁ lter out aborted transactions, since they do not need to be applied to replicas (see  Figure 9.8a ). \nDatabase\nsystem’s\nlog\nDatabase\nsystem’s\nlog\nData\nTrigger\nDatabase\nLog\ntable\nFilter aborted\ntransactions\nto \nreplicas\nRead log\ntable\nDatabase\nDatabase system\nTransaction\nupdates\nDatabase system\na. Propagating updates from the\n   database system’s log\nb. Propagating updates from a log \n    table generated by database triggers\nto \nreplicas\nTransaction\nupdates\n FIGURE 9.8 \n Generating Update Streams for Replicas. An update stream for replicas can be produced from (a) the database system’s \nlog or (b) a log table produced by triggers. \n9.4 Single-Master Primary-Copy Replication  253\n",
      "content_length": 3163,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 273,
      "content": "254  CHAPTER 9 Replication\nThis reduces the amount of data transmission and the cost of processing updates at the replica. However, it \nrequires that the primary not send a log record until it knows that the transaction that wrote the record has com-\nmitted. This introduces additional processing time at the primary and delay in updating the secondary, which \nare the main costs of reducing the data transmission. Another technique is to send only the ﬁ nest granularity \ndata that has changed, e.g., ﬁ elds of records, rather than coarser-grain units of data, such as entire records. \n Another reason to postprocess the log is to group together the updates of each transaction. This is beneﬁ -\ncial because it enables transactions to be applied to secondaries serially. After each transaction is applied, the \nsecondary database is in a consistent state. Therefore a query can read a consistent database state without using \nread locks. If updates were not grouped by transaction, then in order for queries to read a consistent state, \nupdates would have to set write locks and queries would have to set read locks. \n Some systems allow different parts of the database to be replicated to different locations. For example, the \nprimary might contain a table describing customers and other tables describing orders. These tables are colo-\ncated at the primary, since many transactions require access to all of these tables. However, the customer table \nmay be replicated at different servers than the order tables. To enable this, the log postprocessing splits each \ntransaction’s updates into two transactions, one for the customer table and one for the order tables, and adds \nthem to separate streams, one for the customer replicas and one for the order replicas. If there is also a replica \nthat contains all the customer and orders information, then the log postprocessor would generate a third stream \nfor that replica, with all the updates of each transaction packaged in a single transaction in the stream. \n Given this complex ﬁ ltering and transaction splitting, often a  “ buffer database ” is used to store updates that \nﬂ ow from the primary to secondaries. Updates that are destined for different replicas are stored in different \nareas of the buffer database. This allows them to be applied to replicas according to different schedules. \n Some systems allow application-speciﬁ c logic to be used to apply changes to replicas. For example, the \napplication could add a timestamp that tells exactly when the update was applied to the replica. \n Although primary-copy replication normally does not allow transactions to update a secondary before updating \nthe primary, there are situations where it can be made to work. For example, consider an update transaction that \nreads and writes a replica using two-phase locking. Suppose it keeps a copy of all the values that it read, which \nincludes all the data items that the transaction wrote. When it is ready to commit, it sends the values of data items \nthat it read along with values that it wrote to the primary. Executing within the context of the same transaction, the \nprimary reads the same data items that the transaction read at the secondary, setting locks as in normal two-phase \nlocking. If the values of the data items that it reads at the primary are the same as those that the transaction read at \nthe secondary, then the transaction applies its updates to the primary too, and commits. If not, then it aborts. This \nis essentially an application of the optimistic concurrency control technique described in Section 6.8. \n Most database systems offer considerable ﬂ exibility in conﬁ guring replication. Subsets of tables can be inde-\npendently replicated, possibly at different locations. For example, a central ofﬁ ce’s Accounts table can be split by \nbranch, and the accounts for each branch are replicated at the system at that branch. As the number of replicated \ntables grows, it can be rather daunting to keep track of which pieces of which tables are replicated at which sys-\ntems. To simplify management tasks, systems offer tools for displaying, querying, and editing the conﬁ guration \nof replicas. \n The replication services of most database systems work by constructing a log stream or log table of updates \nand sending it to secondary servers. This approach was introduced in Tandem’s (now HP’s) Non-Stop SQL and \nin Digital’s VAX Data Distributor in the 1980s. Similar approaches currently are offered by IBM, Informix (now \nIBM), Microsoft (SQL Server), MySQL, Oracle, and Sybase. Within this general approach, products vary in \nthe speciﬁ c features they offer: the granularity of data that can be replicated (a database, a table, a portion of a \ntable); the ﬂ exibility of selecting primaries and secondaries (a server can be a primary server for some data and \na secondary for others); how dynamically the conﬁ guration of primaries and secondaries can be changed; the \noptions for ﬁ ltering updates and splitting transactions; and facilities to simplify managing a large set of replicas. \n",
      "content_length": 5086,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 274,
      "content": " Failures and Recoveries \n This primary-copy approach works well as long as the primary and secondaries are alive. How do we handle \nfailures? Let us work through the cases. \n Secondary Recovery \n If a secondary replica fails, the rest of the system continues to run as before. When the secondary recovers, it \nneeds to catch up processing the stream of updates from the primary. This is not much different than the process-\ning it would have done if it had not failed; it’s just processing the updates later. The main new problem is that \nit must determine which updates it processed before it failed, so it doesn’t incorrectly reapply non-idempotent \n updates. This is the same problem as log-based database recovery that we studied in Chapter 7. \n If a secondary is down for too long, it may be more efﬁ cient to get a whole new copy of the database rather \nthan processing an update stream. In this case, while the database is being copied from the primary to the \nrecovering secondary, more updates are generated at the primary. So after the database has been copied, to ﬁ n-\nish up, the secondary needs to process that last stream of updates coming from the primary. This is similar to \nmedia recovery, as described in Chapter 7. \n Primary Recovery with One Secondary \n If the primary fails, recovery can be more challenging. One could simply disallow updates until the primary \nrecovers. This is a satisfactory approach when the main goal of replication is better performance for queries. In \nfact, it may be hard to avoid this approach if complex ﬁ ltering and partitioning of updates is supported. Since \ndifferent secondaries receive a different subset of the changes that were applied to the primary, secondaries are \noften not complete copies of the primary. Therefore, it would be difﬁ cult to determine which secondaries should \ntake over as primary for which parts of the primary’s data. \n If a goal of replication is improved availability for updates, then it is usually not satisfactory to wait for the \nprimary to recover, since the primary could be down for awhile. So if it is important to keep the system running, \nsome secondary must take over as primary. This leads to two technical problems. First, all replicas must agree \non the selection of the new primary, since the system cannot tolerate having two primaries — this would lead to \ntotal confusion and incorrect results. Second, the last few updates from the failed primary may not have reached \nall replicas. If a replica starts processing updates from the new primary before it has received all updates from \nthe failed primary, it will end up in a different state than other replicas that did receive all the failed primary’s \nupdates. \n We ﬁ rst explore these problems in a simple case of two replicas, one primary and one secondary. Suppose \nthe secondary detects that the primary has failed. This failure detection must be based on timeouts. For exam-\nple, the secondary is no longer receiving log records from the primary. And when the secondary sends  “ are \nyou there? ” messages to the primary, the secondary receives no reply from the primary. However, these time-\nouts may be due to a communications failure between the primary and secondary, similar to the one shown in \n Figure 9.7 , and the primary may still be operating. \n To distinguish between a primary failure and a primary-secondary communications failure, an external agent \nis needed to decide which replica should be primary. A typical approach is to add a  “ watchdog ” process, pref-\nerably on a different machine than the primary and secondary. The watchdog sends periodic  “ are you there? ” \nmessages to both the primary and secondary. There are four cases to consider (see  Figure 9.9 ): \n 1.  If the watchdog can communicate with the primary and not with the secondary, then it tells the primary \nof this fact. If the primary can communicate with the secondary, then no action is needed. If not, then \nthe primary creates another secondary, if possible. \n9.4 Single-Master Primary-Copy Replication  255\n",
      "content_length": 4064,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 275,
      "content": "256  CHAPTER 9 Replication\n 2.  If the watchdog can communicate with both the primary and secondary, but they cannot communicate \nwith each other, then they notify the watchdog of this fact. The watchdog then tells the secondary to fail, \nsince it can no longer function as a replica. It also tells the primary to create another secondary, if possible. \n 3.  If the watchdog can communicate only with the secondary, then it tells the secondary that it believes the \nprimary is down. If the secondary can communicate with the primary, then no action is needed. If not, \nthen it can take over as primary. In this case, if the primary is still operational but is simply unable to com-\nmunicate with the watchdog, then the primary must self-destruct. Otherwise, the old primary and the new \nprimary (which was formerly the secondary) are both operating as primary. It may therefore be advisable \nthat the watchdog send a message to tell the primary to self-destruct, in case the primary is able to receive \nmessages from the watchdog but its replies are not getting through. In summary, if the secondary loses \ncommunications with the primary, then whichever replica can still communicate with the watchdog is \nnow the primary. \n 4.  If neither replica can communicate with the watchdog or with each other, then neither replica can operate \nas the primary. This is called a  total failure . \n Suppose that the primary did indeed fail and the secondary has been designated to be the new primary. Now \nwe face the second problem: the new primary may not have received all the committed updates performed by \nthe former primary before the former primary failed. One solution to this problem is to have the primary delay \ncommitting a transaction’s updates until it knows that the secondary received those updates. The primary could \nwait until the secondary has stored those updates in stable storage, or it could wait only until the secondary has \nreceived the updates in main memory. If the system that stores the secondary has battery backup, then the latter \nmight be reliable enough. In either case, we’re back to synchronous replication, where the updates to the replica \nare included as part of the transaction. This extra round of commit-time messages between the primary and sec-\nondary is essentially a simple two-phase commit protocol. The performance degradation from these messages \ncan be signiﬁ cant. The choice between performance (asynchronous replication) and reliability (synchronous \nreplication) depends on the application and system conﬁ guration. Therefore, database products that offer data-\nbase mirroring usually offer both options, so the user can choose on a case-by-case basis. \n Primary Recovery with Multiple Secondaries \n Now let’s look at the more general case where there are multiple secondaries and a secondary detects the failure \nof a primary. There are two ways this could happen. The primary might indeed be down. Or, much worse, there \ncould be a communication failure that partitions the network into independent sets of functioning replicas. \nLegend: \n     W \u0003 watchdog      P \u0003 primary   S \u0003 secondary\n     X  \u0003 broken link    ?  \u0003 possibly broken link       \nP\nS\nW\nP\nS\nW\nP\nS\nW\nP\nS\nW\n?\nX\n?\nCase 4\nCase 3\nCase 2\nCase 1\nX\n FIGURE 9.9 \n Failure Cases with a Watchdog. A watchdog process can help sort out failure cases between a primary and secondary. \n",
      "content_length": 3387,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 276,
      "content": "In the latter case the primary could still be operational, so the set of replicas that doesn’t include the primary \nmust not promote one of the secondaries to be a primary. The same problem can arise even in the ﬁ rst case \nwhere the primary is down. In this case, we do want to promote one of the secondaries to become primary. But \nif there are two independent sets of replicas that are operating, each set might independently promote a second-\nary to be the primary, a situation that we want to avoid. \n To solve this problem, we need a decision criterion by which at most one set of replicas has an operational pri-\nmary. We need an algorithm by which replicas can reach this decision. And after the replicas have chosen a new \nprimary, we need an algorithm by which they can recover to the latest state before accepting new transactions. \nThe next three sections treat each of these problems in turn. \n Majority and Quorum Consensus \n One simple way to ensure that only one primary exists is to statically declare one replica to be the primary. If \nthe network partitions, the partition that has the primary is the one that can process updates. This is a feasible \napproach, but it is useless if the goal is high availability. If the primary is down, each partition has to assume \nthe worst, which is that the primary really is running but not communicating with this partition. Thus, neither \npartition promotes a secondary to become primary. \n A more ﬂ exible algorithm for determining which partition can have the primary is called  majority consensus : \na set of replicas is allowed to have a primary if and only if the set includes a majority of the replicas (see  Figure \n9.10 ). Since a majority is more than half, only one set of replicas can have a majority. Moreover, each partition \ncan independently ﬁ gure out if it has a majority. These are the two critical properties of majorities that make the \ntechnique work. \n Majority consensus is a generalization of the watchdog technique we described for database mirroring. The \nwatchdog adds a third process to the mix. Two communicating processes comprise a majority. Thus, whichever \npartition has at least two communicating processes is allowed to have the primary: either the existing primary \nand secondary if the watchdog is down; or the watchdog plus whichever replica(s) it can communicate with. \nBy convention, if the watchdog can communicate with the primary and secondary but the latter cannot com-\nmunicate with each other, then the secondary is told to fail. \n Majority consensus does have one annoying problem: it does not work well when there is an even number \nof copies. In particular, it is useless when there are just two replicas, since the only majority of two is two; that \nis, it can operate only when both replicas are available. When there are four replicas, a majority needs at least \nthree, so if the network splits into two groups of two copies, neither group can have a primary. \nReplica\nReplica\nReplica\nReplica\nReplica\nReplica\nPartition 1\nPartition 2\n FIGURE 9.10 \n Majority Consensus. Partition 1 has a majority of the replicas and therefore is allowed to process updates. Partition 2 \nmay not process updates. \n9.4 Single-Master Primary-Copy Replication  257\n",
      "content_length": 3255,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 277,
      "content": "258  CHAPTER 9 Replication\n A fancier approach is the  quorum consensus algorithm. It gives a  weight to each replica and looks for a \nset of replicas with a majority of the weight, called a  quorum (see  Figure 9.11 ). For example, with two repli-\ncas, we could give a weight of two to the more reliable replica and a weight of one to the other. That way, the \nreplica with a weight of two can be primary even if the other replica is unavailable. Giving a weight of two to \nthe most reliable replica helps whenever there is an even number of replicas. If the network partitions into two \ngroups with the same number of copies, the group with the replica of weight two still has a quorum. \n Reaching Consensus \n During normal operation, the set of operational replicas must agree on which replicas are up and which are \ndown or unreachable. If a replica loses communication with one or more other replicas, then the operational \nreplicas need to reassess whether they still have a majority. (For the purpose of this discussion, we’ll assume \nmajority consensus, not quorum consensus.) In fact, the nonoperational replicas that are up also need to do this \nwhen they reestablish communications with a replica, since this replica may be the one they need to reach a \nmajority. After some group of replicas is established as having a majority, that group can choose a primary and \nensure that all replicas in the group have the most up-to-date state. \n To discuss the details, we need some terminology: The  replica set is the set of all replicas, including those \nthat are up and down; the  current conﬁ guration is the set of operational replicas that are able to communicate \nwith each other and comprise a majority. \n An algorithm that enables a set of processes to reach a common decision is called a  consensus algorithm . \nIn this case, that common decision is agreement on the current conﬁ guration by a set of operational repli-\ncas. Given our problem context, we’ll call the participants replicas instead of processes. But the algorithm we \ndescribe works for general consensus, not just for deciding on the current conﬁ guration. \n One problem with such consensus algorithms is that multiple replicas may be trying to drive a common deci-\nsion at the same time. It’s important that different replicas don’t drive the replicas toward different decisions. \n Another problem is that the system may be unstable, with replicas and communications links failing and \nrecovering while replicas are trying to reach consensus. There’s not much hope in reaching consensus during \nsuch unstable periods. However, once the system stabilizes, we do want the algorithm to reach consensus quickly. \nReplica\nweight \u0003 2\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nReplica\nweight \u0003 1\nPartition 1\nPartition 2\n FIGURE 9.11 \n Quorum Consensus. Partition 1 has a total weight of 4, which is more than half of the total weight of 7. It therefore \nconstitutes a quorum and is allowed to process updates. \n",
      "content_length": 3020,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 278,
      "content": " There are several variations of algorithms to reach consensus, but they all have a common theme, namely, \nthat there’s a unique identiﬁ er associated with the consensus, that these identiﬁ ers are totally ordered, and that \nthe highest unique identiﬁ er wins. We will call that identiﬁ er an  epoch number . It identiﬁ es a period of time, \ncalled an  epoch , during which a set of replicas have agreed on the current conﬁ guration, called an  epoch set . An \nepoch number can be constructed by concatenating a counter value with the unique replica identiﬁ er of the rep-\nlica that generated the epoch number. Each replica keeps track of the current epoch number  e in stable storage. \n During stable periods, the epoch set with largest epoch number is the current conﬁ guration. During unsta-\nble periods, the actual current conﬁ guration may differ from the current epoch set. The goal of the consensus \nalgorithm is to reach agreement on a new epoch set with associated epoch number that accurately describes the \ncurrent conﬁ guration. \n Suppose a replica R is part of the current conﬁ guration, which has epoch number  e 1 . If R detects that the \ncurrent conﬁ guration is no longer valid (because R has detected a failure or recovery), R becomes the leader of \na new execution of the consensus algorithm, which proceeds as follows: \n 1.  R generates a new epoch number  e 2 that is bigger than  e 1 . For example, it increments the counter value \npart of  e 1 by one and concatenates it with R’s replica identiﬁ er. \n 2.  R sends an  invitation message containing the value  e 2 to all replicas in the replica set. \n 3.  When a replica R \u0002 receives the invitation, it replies to R with an  accept message if R \u0002 has not accepted \nanother invitation with an epoch number bigger than  e 2 . R \u0002 includes its current epoch number in the \naccept message. Moreover, if R \u0002 was the leader of another instance of the consensus algorithm (which \nis using a smaller epoch number), it stops that execution. Otherwise, if R \u0002 has accepted an invitation \nwith an epoch number bigger than  e 2 , it sends a  reject message to R. As a courtesy, it may return the \nlargest epoch number of any invitation it has previously accepted. \n 4.  R waits for its timeout period to expire, to ensure it receives as many replies as possible. \n a.  If R receives accept messages from at least one less than a majority of replicas in the replica set, \nthen it has established a majority (including itself) and therefore has reached consensus. It therefore \nsends a  new epoch message to all the accepting replicas and stops. The new epoch message con-\ntains the new epoch number and epoch set. When a replica receives a new epoch message, it updates \nits epoch number and the associated list of replicas in the epoch set and writes it to stable storage. \n b.  Otherwise, R has failed to reach a majority and stops. \n Let ’s consider the execution of this algorithm under several scenarios. First, assume that only one leader R \nis running this algorithm. Then it will either receive enough accept messages to establish a majority and hence \na new epoch set, or it will fail to reach a majority. \n Suppose a leader R 1 fails to establish an epoch set. One reason this could happen is that R 1 may be unable \nto communicate with enough replicas to establish a majority. In this case, R 1 periodically could attempt to re-\nexecute  the algorithm, in case a replica or communication link has silently recovered and thereby made it pos-\nsible for R 1 to form a majority. \n A second reason that R 1 may fail to establish an epoch set is that another replica R 2 is concurrently trying to \ncreate a new epoch set using a higher epoch number. In this case, it is important that R 1 not rerun the algorithm \nright away with a larger epoch number, since this might kill R 2 ’s chance of getting a majority of acceptances. \nThat is, it might turn into an  “ arms race, ” where each replica reruns the algorithm with successively higher epoch \nnumbers and thereby causes the other replica’s consensus algorithm to fail. \n The arms race problem notwithstanding, if R 1 fails to establish an epoch set and, after waiting awhile, \nreceives no other invitations to join an epoch set with higher epoch number, then it may choose to start another \n9.4 Single-Master Primary-Copy Replication  259\n",
      "content_length": 4357,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 279,
      "content": "260  CHAPTER 9 Replication\nround of the consensus algorithm. In the previous round, if it received a reject message with a higher epoch \nnumber  e 3 , then it can increase its chances of reaching consensus by using an epoch number even higher than \n e 3 . This ensures that any replica that is still waiting for the result of the execution with epoch number  e 3 will \nabandon waiting and choose the new, higher epoch number instead. \n Establishing the Latest State \n After the current conﬁ guration has been established as the epoch set, the primary needs to be selected and all \nthe replicas in the current conﬁ guration have to be brought up to date. The ﬁ rst step is to determine if the new \nepoch set includes the primary from the previous epoch. To do this, ﬁ rst observe that since every epoch set has \na majority, it overlaps every earlier epoch set. Therefore, there is at least one replica in the new epoch set from \nthe previous epoch set and it has the largest epoch number less than the new epoch number. If one of the rep-\nlicas with the largest previous epoch number was the primary of that epoch set, then we can simplify recovery \nby reusing it as the primary of the new epoch set. \n Unfortunately , this may not be right, because the last epoch may not have stabilized before it lost its major-\nity and had to reconﬁ gure. If that happened, then the primary of the previous epoch set may not have the latest \nstate. That is, the previous epoch set may have elected the primary but not yet refreshed the new primary’s state \nto be the latest state known to all replicas in the epoch set. To avoid this outcome, the new epoch set needs to \nidentify the last  stable epoch set. This can be done by having each epoch use a state bit that it sets after it has \nstabilized and ensured that every replica in the replica set has the latest state. Only then can the epoch set accept \nnew work. \n Therefore , the new epoch set should determine if it includes the primary of the last stable epoch set. If so, \nthen it knows that this primary has the most up-to-date state. So to resume normal processing, the primary \nneeds to ensure the secondaries are up to date by determining the state of each secondary and sending it what-\never updates it is missing. It then sets the epoch’s state bit to stable and broadcasts that to all secondaries. \n If the epoch set does not include the primary from the previous epoch, then a new primary must be selected. \nThe choice of primary may be based on the amount of spare capacity on its machine (since a primary con-\nsumes more resources than a secondary) and on whether it was a member of the most recent epoch set and thus \nhas the latest or a very recent state (so that it can recover quickly and start accepting new requests). \n The latest state of the secondaries that are still alive can be determined by comparing the sequence numbers \nof the last message received by each secondary from the previous primary. The one with highest sequence num-\nber has the latest state and can forward the tail of its update sequence to other secondaries that need it. After a \nreplica receives that state, it acknowledges that fact to the primary. After the new primary receives acknowledg-\nments from all replicas in the epoch set, it can set the epoch’s state to stable and start processing new transac-\ntions. The new primary should then start off with a message sequence number greater than that of the largest \nreceived by any secondary in the previous epoch. \n Does the new epoch set actually have the latest state? To answer this question, let C be the set of replicas that \nwere in both the previous epoch and the new one. Since each epoch set has a majority of the replicas, C must \ninclude at least one replica. The replicas in C are the only ones that might know the latest state. However, as in \nthe case of database mirroring, it’s possible that none of them actually do know the latest state, due to the delay in \npropagating updates from the primary to the replicas. For example, suppose the epoch set for epoch 1 had repli-\ncas P, S 1 , and S 2 , with P as the primary. Suppose the last transaction was committed by P and S 1 , but not S 2 . Then \nthey all died, and epoch set 2 was formed, consisting of replicas S 2 , S 3 , and S 4 . Epoch sets 1 and 2 overlap by one \nreplica, S 2 , but S 2 doesn’t have the latest state. \n We encountered this problem when considering secondary recovery for database mirroring. The solution \nwe offered was to propagate updates synchronously. In that case, two-phase commit is needed. This ensures \n",
      "content_length": 4592,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 280,
      "content": "that every replica in C has all the committed updates. However, the last few updates might be in their uncer-\ntainty periods and hence blocked. Thus, while synchronous replication reduces the number of transactions that \nmight be lost when a secondary takes over as primary, it doesn’t close the gap entirely. \n Consistency, Availability, and Partition-Tolerance \n In distributed systems, there is an inherent tradeoff between data consistency, system availability, and tolerance \nto network partitions. A system can offer any two of these three properties, but not all three of them. This is \nknown as the  CAP conjecture . \n The primary-copy approach with synchronous replication ensures data consistency and partition-tolerance, \nand therefore gives up on availability in some cases. It attains data consistency by writing updates to replicas \nas part of the transaction that performed the write and using two-phase commit for transaction atomicity. It \nattains partition-tolerance by using quorum consensus to ensure that there are not two partitions that are both \nable to run transactions. This leads to a loss of availability in the case where the network partitions, because \nsome operational replicas are not part of the quorum. Therefore, even though they are up and running, they are \nnot available. \n Suppose the network partitions and the partition that has a quorum of replicas does not include the former \nprimary. Although the system can ensure the updates are permitted only on the quorum of copies, it cannot guar-\nantee consistency because the last few transactions that executed at the former primary may not have arrived at \nany of the replicas in the quorum before the network partition occurred. Thus, a decision to allow updates to the \nquorum of replicas is trading off consistency for availability. A decision to disallow updates to the quorum of \nreplicas is making the opposite tradeoff, namely, trading off availability in order to ensure consistency. \n Another aspect of this tradeoff is eventual consistency versus instantaneous consistency. Asynchronous \nreplication ensures eventual consistency but gives up on instantaneous consistency, since there may be a long \ndelay before updates are propagated to some replicas. The weaker level of consistency improves performance \nby avoiding two-phase commit. It may also improve availability, by allowing a user to be redirected from one \nreplica to another in a slightly different state. \n For example, suppose an on-line shopper has started populating her shopping basket and the shopping bas-\nket is replicated using primary-copy replication. Suppose the primary fails and is not present in the quorum. To \nmaximize availability, the system could service read requests using another replica while the replicas are being \nbrought up to date. Thus, during this period, the shopper might be given an older state of his or her shopping \ncart. This may occur even if the last update to the cart is known to the quorum, because the shopper’s reads are \nbeing serviced by a slightly out-of-date replica. This may be confusing, especially since the shopping cart will \nreturn to the latest state after the replicas are brought up to date. However, if the probability of this occurrence \nis sufﬁ ciently low, this loss of consistency may be regarded as a better tradeoff than having the shopping cart \nbe unavailable while the replicas are being brought up to date. \n A different set of tradeoffs between consistency, availability, and partition-tolerance is offered by multi-\nmaster replication. We will consider these tradeoffs at the end of the next section. \n 9.5  MULTIMASTER REPLICATION \n Partitioned Operation Can Be Useful \n Rather than being the result of a communication failure, a partition is sometimes a planned event that happens \nfrequently. For example, a laptop computer might be connected to the network only periodically. It could contain \n9.5 Multimaster Replication  261\n",
      "content_length": 3963,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 281,
      "content": "262  CHAPTER 9 Replication\na replica of a database, whose primary resides on a reliable server. When the laptop computer is disconnected, \nit might still be important that it process updates. For example, consider a laptop that contains a sales database \nand is used by a sales person. Its database might have a customer table (rarely updated), an orders table (insert-\nmostly), and a sales-call table (append-only). Even when the laptop is disconnected from the network, the sales \nperson must be able to create an order and change basic customer information, such as address and phone num-\nber. In this case, it is not satisfactory to require that only the partition with a quorum of replicas be operative. \nIndeed, if there are many sales people, there probably is no partition with a quorum of replicas, yet all sales \npeople need to be allowed to update their replicas. \n Update Propagation with Multiple Masters \n Despite the partition, we could try using the same primary-copy scheme as in the previous section, but allow update \ntransactions to execute at any replica. Each replica logs its updates, as if it were a primary copy. When a replica R \nreconnects to the network, it sends its logged updates to the real primary that resides on a reliable server, which can \nprocess the updates and forward them to other replicas. R can also ask the primary for updates that occurred while \nit was disconnected. \n One problem with this scheme is conﬂ icting updates that originate at different replicas. For example, in \n Figure 9.12 , each transaction executes at a replica. Its updates are applied ﬁ rst to the replica where it executes: \ntransaction T 1 updates  x at replica R 1 and T 2 updates  x at replica R 2 . Each replica sends its update to the pri-\nmary, which forwards it to the other replica. In the end, these conﬂ icting updates are applied in different orders \nby different replicas, so the resulting replicas are not identical. \n One way to avoid this problem is to design the applications so that most updates do not conﬂ ict. Such updates \ncan be applied in different orders by different replicas and still produce the same ﬁ nal state at all replicas. For \nexample, in the sales database, a sales person appends a row to the sales-call table every time the sales person \ninteracts with a customer. This row is unique for each such interaction, so two rows generated by different sales \npeople cannot conﬂ ict; they may refer to the same customer, but they describe different interactions. The orders \ntable is also insert-mostly. Each insertion of a new order produces a new row in the order table. With careful \nReplica R1\nInitially, x\u00030\nT1: x\u00031\nSend (x\u00031)\nReceive (x\u00032)\nx\u00032\nPrimary\nInitially, x\u00030\nReplica R2\nInitially, x\u00030\nT2: x\u00032\nSend (x\u00032)\nReceive (x\u00031)\nx\u00031\nReceive (x\u00032)\nx\u00032\nSend (x\u00032)\nReceive (x\u00031)\nx\u00031\nSend (x\u00031)\n FIGURE 9.12 \n Conﬂ icting Updates Originating at Different Replicas. The updates to  x are applied in different orders by replicas R 1 and \nR 2 , so the resulting replicas are not identical. \n",
      "content_length": 3036,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 282,
      "content": "design, these insertions do not conﬂ ict. For example, to ensure insertions do not conﬂ ict, the insertion of a new \norder must not require reading previous orders; for example, to check that the new order is not a duplicate. \n If conﬂ icts can occur, then there are several problems to be solved: (1) detecting the conﬂ icts, (2) resolving \nthe conﬂ icts in the same way at all replicas, and (3) ensuring that replicas eventually converge to be identi-\ncal. One approach to these problems is to tag each update with a unique timestamp. Unique timestamps can \nbe constructed by concatenating the replica’s local clock time with its unique replica identiﬁ er, so timestamps \ngenerated at different replicas cannot be identical. Each data item at a replica also is tagged with a timestamp. \nUpdates are applied using  Thomas ’ Write Rule as follows [Thomas 79] (see  Figure 9.13 ): If an update to \ndata item  x arrives at a replica, and the update’s timestamp is larger than  x ’s timestamp at the replica, then the \nupdate is applied and  x ’ s timestamp is replaced by the update’s timestamp. Otherwise, the update is discarded. \n Thomas ’ Write Rule addresses these three problems. It detects a conﬂ ict when an update to a data item \narrives at a replica with an update timestamp lower than the replica’s timestamp on that data item. It resolves \nthe conﬂ ict by retaining the value that has the larger timestamp . And eventually, each data item  x has the same \nvalue at all replicas, because at every replica, the update to  x with the largest timestamp is the last one that \nactually was applied. \n The deletion of a data item needs to be handled like any other update, to ensure it is not reinserted by an \nupdate with a smaller timestamp that arrives after the deletion was processed. That is, a deleted data item must \nstill be known to the replica and have a timestamp that was written by the delete operation, but its value is \n “ deleted. ” This value is usually called a  tombstone . \n Thomas ’ Write Rule does not require that clocks be exactly synchronized. However, if the clock at one rep-\nlica is fast, then its updates will have larger timestamps than updates concurrently generated by other replicas. In \nconﬂ ict situations, the update with the larger timestamp wins, so the replica with a fast clock has an unfair advan-\ntage. For this reason, it is beneﬁ cial to keep the clocks nearly synchronized when using Thomas ’ Write Rule. \n Nonblind Updates \n Thomas ’ Write Rule works ﬁ ne for  blind updates , which are updates that replace the value of a data item with \na new value that does not depend on any data that the transaction previously read. We just saw two examples: \nrecording a sales call and inserting a new order. Another example is storing a customer’s phone number. In this \nupdate x, timestamp =\n128976, value = “ghi” \na. The update has smaller timestamp\n \nthan the database’s timestamp of x,\n \nso it should not be applied\nb. The update has larger timestamp\n \nthan the database’s timestamp of x,\n \nso it should be applied\nX\nTimestamp\nValue\n128965\n“abc”\nTimestamp\nValue\n128965\n“abc”\nX\nupdate x, timestamp =\n128944, value = “def”\n FIGURE 9.13 \n Thomas ’ Write Rule. An update to a data item  x is applied only if its timestamp is larger than the one in the database. \n9.5 Multimaster Replication  263\n",
      "content_length": 3337,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 283,
      "content": "264  CHAPTER 9 Replication\ncase, two updates by different transactions that store a new phone number for the same customer conﬂ ict, and \nif they write different phone numbers then the execution order certainly matters. However, since the updates \nwere submitted concurrently, either execution order is satisfactory as long as all replicas reﬂ ect the same exe-\ncution order. Thomas ’ Write Rule solves this problem by ensuring that the ﬁ nal value at all replicas is the one \nwritten by the update with the higher timestamp. \n If the updates are not blind, then Thomas ’ Write Rule isn’t a completely satisfactory solution, because it \ndoesn’t diagnose that one update depends on another one. For example, consider  Figure 9.14 , which is similar \nto  Figure 9.12 except that the transactions increment  x instead of performing blind updates to  x , and they use \nThomas ’ Write Rule. Each value of  x is represented by a [value, timestamp] pair. Initially,  x  \u0003  0 at the primary \nand replicas and the associated timestamp (ts) is 5. Since transaction timestamps are guaranteed to be unique, \nT 1 and T 2 update  x with different timestamps, namely 6 and 7, respectively. The updates are concurrent in the \nsense that neither T 1 nor T 2 reads the value of  x written by the other. Since T 2 has the larger timestamp, its \nvalue is the one that sticks at all three copies. However, the increment operation by T 1 is lost, which is prob-\nably not what is desired. The execution is not one-copy serializable, since a serial execution of the two transac-\ntions (in either order) on a one-copy database would produce a ﬁ nal value of  x  \u0003  3. The problem is that the \nnature of the conﬂ ict between T 1 and T 2 was not diagnosed. The system simply retained the update with larger \ntimestamp as if both updates were blind, which they were not. \n With multimaster replication, situations like  Figure 9.14 are unavoidable. That is, in general it’s possible \nfor two conﬂ icting transactions to update different copies of the same data item independently at different rep-\nlicas, such that neither transaction reads the other transaction’s updated value. \n The way multimaster replication is used can greatly affect the probability of such conﬂ icts. For example, \nwhen multimaster replication is used to support disconnected operation, such as laptops that are intermittently \nconnected to the network, replicas can run for long periods without exchanging updates. The longer a replica \nexecutes transactions without exchanging its updates with other replicas, the greater the chance that reconcilia-\ntion will be needed. That is, if updates are exchanged frequently, then the chances are better that an update will \nbe propagated to all replicas before a transaction with a conﬂ icting update executes, thereby avoiding the need \nfor reconciliation. \nReplica R1\nInitially, x \u0003 [0, ts\u00035]\nT1: x \u0003 x \u0005 1(ts\u00036)\nSend (x \u0003 [1, ts\u00036])\nReceive (x \u0003 [2, ts\u00037])\nx \u0003 [2, ts\u00037]\nReplica R2\nInitially, x \u0003 [0, ts\u00035]\nT2: x \u0003 x \u0005 2 (ts\u00037)\nSend (x \u0003 [2, ts\u00037])\nReceive (x \u0003 [1, ts\u00036])\nThomas’ Write Rule says\ndon’t update x,\nso x is still [2, ts\u00037]\nPrimary\nInitially, x \u0003 [0, ts\u00035]\nReceive (x \u0003 [1, ts\u00036])\nx \u0003 [1, ts\u00036]\nSend (x \u0003 [1, ts\u00036])\nReceive (x \u0003 [2, ts\u00037])\nx \u0003 [2, ts\u00037]\nSend (x \u0003 [2, ts\u00037])\n FIGURE 9.14 \n Conﬂ icting Nonblind Updates. Thomas ’ Write Rule ensures that  x  \u0003  2 at all replicas, but T 1 ’s update is lost (ts is an \nabbreviation for timestamp). \n",
      "content_length": 3453,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 284,
      "content": " When such a conﬂ ict occurs, Thomas ’ Write Rule makes a rather arbitrary choice by applying the one with \nlarger timestamp and discarding the other one. In a variation of the rule, instead of discarding the one with \nsmaller timestamp, the system can save it. The saved update can then be examined later by a person who deter-\nmines whether it needs to be reconsidered or merged into the primary somehow. \n Detecting Replication Conﬂ icts Using Version Vectors \n Instead of requiring manual reconsideration of the saved update in all cases, we want to distinguish between \nreal conﬂ icts where reconciliation is required and fake conﬂ icts where a value really should be overwritten by \na later update. We can do this using a technique called version vectors. \n To explain the use of version vectors, we need the concept of version that was introduced in Section 6.6. \nRecall that a  version of a data item  x is the value of  x written by a particular transaction. That is, each transac-\ntion that updates  x produces a new version of  x . We introduced this notion in the context of multiversion data-\nbases, where the database retains all or most of the versions produced by different transactions. Here, we will \ntypically retain only one version of a data item. However, we nevertheless need to refer to different versions of \na data item because after a data item is updated, different replicas will store different versions during the period \nthat the update is being propagated between replicas. \n To distinguish between real and fake conﬂ icts, we need precise deﬁ nitions of them. Given two versions  x i \nand  x k of  x , we say that  x i  precedes  x k (written  x i  →  x k ) if there is a sequence of transactions, each of which \nupdates  x , such that \n ■  The ﬁ rst transaction in the sequence reads and overwrites  x i . \n ■  Starting with the second transaction in the sequence, each transaction reads and overwrites the version of \n x produced by the previous transaction in the sequence. \n ■  The last transaction in the sequence produces version  x k . \n If  x i does not precede  x k and  x k does not precede  x i then we say that  x i and  x k have a  replication conﬂ ict \n(i.e., a  “ real ” conﬂ ict). If the database started with one version of  x , then the presence of a replication conﬂ ict \nimplies there is some version of  x that was overwritten independently by two transactions that did not see each \nother’s output. This is the essence of the kind of conﬂ ict exhibited by transactions T 1 and T 2 in  Figure 9.14 . \nIf two versions of  x are related by the precedes relation, then it’s a fake conﬂ ict, since the later version clearly \nshould replace the earlier one. \n The version vector technique enables us to detect replication conﬂ icts between versions. It requires that \neach replica maintain an update count. When a transaction updates a data item  x for the ﬁ rst time, it associates \nits local replica ID and current update count with this new version of  x , and the update count for the replica \nis incremented by one. The pair [replica id, update count] uniquely identiﬁ es the version and is called a  ver-\nsion ID . For example, if the current update count for replica R is 8 and the replica runs a transaction T that \nﬁ rst updates data item  x and then updates  y , then T associates version ID [R, 8] with  x and [R, 9] with  y . If T \nupdates  x or  y a second time, the version IDs of  x and  y associated with T needn’t be changed. Since each rep-\nlica has a unique replica ID, each version ID is unique too. By convention, we use the version ID of a data item \nto uniquely identify the ﬁ nal value (not any intermediate values) written by a transaction into that data item. \n To track which versions each replica R has received, R maintains an array of version IDs, called a  version \nvector , with one entry in the array for each replica. Each entry in the version vector tells which updates R has \nreceived and processed from every other replica. Entry [R i , c] in the version vector says that R has received all \nupdates generated by R i with version IDs [R i , 1], [R i , 2],  … , [R i , c]. R’s version vector includes an entry for its \nown latest version ID. \n9.5 Multimaster Replication  265\n",
      "content_length": 4261,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 285,
      "content": "266  CHAPTER 9 Replication\n In addition to maintaining a version vector for each replica, we also maintain a version ID and version vec-\ntor for each data item at the replica. This per-data-item information is used to detect replication conﬂ icts. The \nversion ID and version vector for a data item  x is updated when a transaction executing at replica R updates  x . \nAfter a transaction T executing at R updates a data item  x for the ﬁ rst time, it replaces  x ’s version ID by R’s \nversion ID, it replaces R’s position in  x ’s version vector by R’s current version ID, and R increments its version \nID. This records the fact that T generated a new version of  x at replica R. For example, if T executes at replica \nR 1 , R 1 ’s current update count is 14, and T updates  x , then T replaces  x ’s version ID with [R 1 , 14], T replaces the \nversion ID formerly in  x ’s version vector, say [R 1 , c], by [R 1 , 14], and R increments its update count. It must be \nthat c  \u000b 14, because [R 1 , 14] is the largest version ID that R 1 has generated so far. \n When replica S (the sender) sends its updated version v of  x to another replica R (the receiver), it includes \nthe version ID and version vector along with the value. The version vector tells R which updates were applied \nto  x before v was generated. This gives R enough information to determine whether R’s own version of  x has a \nreplication conﬂ ict with v, and hence whether it should replace its own version by v. \n To see how conﬂ ict detection works, suppose that the updated version of  x that S sends to R has version ID \n[S, 10] and version vector [[S,10], [R, 4]]. Suppose that when R receives the updated version, its value of  x has \nversion ID [R, 5] and version vector [[S, 9], [R, 5]]. In this case, we have a replication conﬂ ict. How can R tell? \nThe version vector [[S,10], [R, 4]] sent by S tells R that S did not receive R’s updated version [R, 5] before S exe-\ncuted the update that wrote version [S, 10]. On the other hand, R’s version vector [[S, 9], [R, 5]] for  x tells R that \nR did not receive S’s updated version [S, 10] before it executed update [R, 5]. Since neither S nor R saw the other \nreplica’s updated version of  x before it executed its latest update, R deduces that there is a replication conﬂ ict. \n We will explain some general approaches to detecting replication conﬂ icts shortly. But ﬁ rst, we describe two \nother mechanisms that are needed in a complete system, namely, conﬂ ict resolution and update propagation. \n Conﬂ ict Resolution \n In the previous example, a simple way for R to deal with the conﬂ ict is for it to retain both values of  x — the \none it already has and the one it just received from S, with the associated version IDs and version vectors. \nA later conﬂ ict resolution process can determine how to reconcile these two values. This is necessarily an \napplication-speciﬁ c process because it depends on knowing (or assuming) something about the semantics of \nthe transactions that conﬂ icted. For example, if the conﬂ ict resolver knows that transactions originating at R \nincrement  x by one as opposed to doing a blind write of  x , then it can add one to the value of  x produced by the \nother transaction to generate a new ﬁ nal value. \n The replication system can help a little bit by allowing an application to register one or more merge pro-\ncedures for each data item, which can then be invoked automatically when multiple values are stored for that \nitem. Alternatively, the two versions of  x can be retained and given to the next transaction that reads  x , which \nthen has to determine the correct value of  x . In any case, the solution is a matter of application programming. \n If the resolution executes as a transaction, then its result propagates to other replicas as a normal updated \nversion. If it propagates fast enough, this avoids the need to execute the resolution procedure at other replicas. \n Maintaining the Version Vector \n Now let us see how to propagate recently written versions and maintain the per-replica version vector. Suppose \nthat when a replica S sends updated versions to a replica R, S sends all updated versions of all data items that \nit hasn’t previously sent to R. In that case, at the end of the update transfer from S to R, if R has received an \nupdated version with version ID [S, 10] from S, then R knows it has received all updated versions from S with \nversion ID [S, c] for c  \u0006 10. \n",
      "content_length": 4466,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 286,
      "content": " S needs to send to R not only the updated versions from transactions that S executed since the last time \nit synchronized with R, but also updated versions that S received from other replicas, such as R \u0002 . R may not \nhave received those updated versions and indeed may never have the opportunity to synchronize with R \u0002 . For \nexample, S may be a server that is always on the network, and R and R \u0002 are portable machines on different \ncontinents that are rarely if ever connected to the network at the same time. \n This logic about S’s version IDs sent by S to R applies to R \u0002 too. That is, if S sends an updated version to \nR with version ID [R \u0002 , 5], then at the end of the transfer from S to R, R must also have received all of R \u0002 ’ s \nupdated versions with version IDs less than 5. This observation holds even if S received R \u0002 ’ s updated versions \nindirectly via other replicas, because every replica along the path from R \u0002 to S sent all the updated versions it \nreceived earlier from other replicas. That is, R \u0002 sent all of its updated versions with version IDs less than or \nequal to [R \u0002 , 5] to replica R \t , which sent them to R \u0002 \u0002 \u0002 , and so on, until they reached S, which in turn sent them \nto R. We can summarize this argument as the following invariant. \n Version ID invariant : If replica R received an updated version with version ID [R i , c] and there are no \ntransfers to R in progress, then R received all updated versions generated by R i with version ID [R i , c \u0002 ] for \nall c \u0002  \u0006 c. \n The version ID invariant implies that R can use a single version ID to summarize which updates it has \nreceived from each replica. For example, R can use version ID [R \u0002 , 5] to summarize the fact that R has received \nall updated versions generated by replica R \u0002 with version IDs [R \u0002 , 1] through [R \u0002 , 5]. By doing this for all repli-\ncas, R is maintaining a version vector. \n Therefore , after R has processed all the updates it received from S, R should merge S’s version vector with \nits own, thereby reﬂ ecting the fact that R’s state now includes all updates that are known to S. This involves \nusing the maximum count for each entry in the two version vectors. For example, if the R i entry in the version \nvectors for S and R are [R i , c] and [R i , c \u0002 ], respectively, then R should replace c \u0002 by the maximum of c and c \u0002 . \n S need not send updated versions that it knows were overwritten. For example, if S executed two or more \ntransactions that updated data item  x , S needs to send to R only its last updated version of  x . There is no point in \nsending the earlier updated versions to R because they will be overwritten by later updated versions to  x sent by \nS to R. \n Given this observation, we have to modify our earlier explanation of the meaning of version vectors. We \nsaid that an entry [R i , c] in the version vector for replica R means that R has received all updates generated by \nR i with version IDs [R i , 1], [R i , 2],  … , [R i , c]. However, this isn’t true if overwritten versions are not propa-\ngated. Hence, we have to weaken the statement to say that entry [R i , c] in R’s version vector is the largest ver-\nsion ID of any update that was generated by R i and received by R. Moreover, R’s state is the same as if it had \nreceived all the versions in the sequence [R i , 1],  … , [R i , c]. \n When two replicas decide to exchange updates, each one needs to ﬁ gure out which updates to send to the \nother replica. Version ID’s are helpful for this purpose. When replica R wants to receive recent updates from \nreplica S, R sends its current version vector to S. Now S runs a query against its local database that retrieves \nevery version whose version ID is greater than the corresponding version ID in R’s version vector and sends \nthese updates to R. For example, if R’s version vector has an entry [R 1 , 10], then S should send all data items \nwhose version ID is [R 1 , b] where b  \f  10. \n Version Vector Update Rules \n As a prelude to presenting update rules based on version vectors, we need a few more deﬁ nitions. To simplify \nthings a bit, let us assume that there are  n replicas named R 1 through R n . This enables us to represent a version \n9.5 Multimaster Replication  267\n",
      "content_length": 4254,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 287,
      "content": "268  CHAPTER 9 Replication\nvector by a sequence of  n integers, where entry  i in the vector is the count for replica R i . For example, a version \nvector [[R 1 , 7], [R 2 , 3], [R 3 , 10], [R 4 , 7]] would be represented by [7, 3, 10, 7]. \n We say that a version vector V  dominates another version vector V \u0002 if the elements of V and V \u0002 cover the \nsame set of replica ID’s and for every index position  i , V[ i ]  \n V \u0002 [ i ]. For example, if there are three replicas, \nthen version vector [3, 4, 4] dominates [2, 4, 3] and [3, 4, 3]. If V  \u0002 V \u0002 and neither dominates the other, then we \nsay V and V \u0002 are  incomparable . For example, version vector [3, 4, 4] is incomparable to [2, 4, 5] and [2, 4]. \n Now that we have the complete picture, let’s look at the rules for applying updates, which we call the  version \nvector-based update rules . First, let us recall the rule for running a transaction: \n VV1. Suppose a transaction T executes at replica R, which has update counter value c, and T updates data item \n x . Then T replaces  x ’s version ID by [R, c], it sets the R position in  x ’s version vector to c, and it incre-\nments R’s update counter by 1. \n Suppose a version of  x moves from replica S to replica R. More precisely, suppose R receives an updated \nversion  x s of some data item  x from replica S, where \n ■  The updated version  x s has version ID [R i , c] and version vector V S  \u0003  [s 1 ,  … , s n ], and \n ■  R’s stored version  x r of  x has version ID [R k , d] and version vector V R  \u0003  [r 1 ,  … , r n ]. \n Note that R i and R k may be different from both R and S. R processes the update from S as follows: \n VV2. If V R dominates V S , then R discards the updated version  x s sent by S. In effect, this says that  x r should \noverwrite  x s , but since  x r arrived at R before  x s , R simply discards  x s . \n VV3. If V S dominates V R , then R replaces its version  x r by  x s , along with version ID [R i , c] and version vector \n[s 1 ,  … , s n ]. \n VV4. If V R and V S are incomparable, then there’s a conﬂ ict and conﬂ ict resolution is needed. If R resolves the \nconﬂ ict, then the version that R generates by its conﬂ ict resolution procedure has a version vector that’s the \nmerge of the version vectors of the conﬂ icting versions (i.e., taking the maximum count for each entry in \nthe two version vectors), except for the position corresponding to R, which has the version ID of the new \nversion generated by R. \n As explained in the previous section, after R has processed all the updates it received from S, R should \nmerge S’s version vector with its own. \n The goal of the rules is to ensure that if a version  x 2 overwrites another version  x 1 , then  x 1  →  x 2 . Clearly, if \na transaction executes according to VV1 or VV4 and overwrites  x 1 by  x 2 , then  x 1  →  x 2 . The more interesting \ncases are VV2 and VV3. \n In VV2 and VV3, the decisions are governed by version vector dominance. Consider VV2. If V R domi-\nnates V S , then every vector position of V R is greater than or equal to the corresponding position of V S . The \nonly way to create a version vector is to execute a transaction using VV1 or VV4. Each transaction modiﬁ es a \nversion vector by increasing one of the elements in the vector. Therefore, the only way that V R can come into \nexistence is that starting with V S , there must be a sequence of transactions that generates successive version \nvectors where each one updates the version of  x generated by the previous one and where the last transaction \nin the sequence generates V R . By deﬁ nition of replication conﬂ ict, there are no replication conﬂ icts in this \nsequence. Therefore, if V R dominates V S , then  x s  →  x r , so  x r should be retained and  x s should be discarded. \nThis is exactly what rule VV2 does. A symmetric argument holds for VV3. \n The remaining possibility is VV4, namely that V R does not dominate V S and V S does not dominate V R . In \nthat case V R and V S are incomparable. Thus, there must be elements r a , r b in V R and s a , s b in V S such that r a  \f  s a \nand s b  \f  r b . Since r a  \f  s a , the transaction that produced version [R a , r a ] was in the sequence of transactions that \n",
      "content_length": 4223,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 288,
      "content": "produced V R but not in the sequence that produced V S , so  x r does not precede  x s . Similarly, since s b  \f  r b , the \ntransaction that produced version [R b , r b ] was in the sequence of transactions that produced V S but was not in \nthe sequence that produced V R , so  x s does not precede  x r . Thus the versions tagged by V R and V S exhibit a repli-\ncation conﬂ ict. \n Simpliﬁ ed Version Vector Update Rules \n Instead of comparing version vectors, it is actually enough to compare version IDs of data items to version \nvectors of replicas, rather than comparing version vectors for dominance. That is, the rules VV2 and VV3 are \nmodiﬁ ed to the following: \n VI2. If r i  \n c, then R discards S’s updated version. \n VI3. If s k  \n d, then R replaces its version of  x by the one sent by S, along with version ID [R i , c] and version \nvector [s 1 ,  … , s n ]. \n As in the previous section, the goal of these rules is to ensure that if a version  x 2 overwrites another version \n x 1 then  x 1  →  x 2 . Since VV1 and VV4 are unchanged, they ensure this goal as before. \n The simplest correctness argument we know of that covers rules VI2 and VI3 involves some fairly subtle \nreasoning. We provide a proof here. However, you can skip the rest of this section without loss of continuity in \nunderstanding the rest of the chapter. \n We say that a version ID v  \u0003  [R i , c]  is in a version vector V if the R i position of V is greater than or equal \nto c. Notice that the test in VI2 of r i  \n c is testing whether version ID [R i , c] is in version vector [r 1 ,  … , r n ]. \nSimilarly, the test in VI3 of s k  \n d is testing whether version ID [R k , d] is in version vector [s 1 ,  … , s n ]. \n Suppose we are given two versions  x 1 and  x 2 of  x that have version IDs v 1 and v 2 and version vectors V 1 \nand V 2 , respectively. We want to show that if VI2 or VI3 overwrites  x 1 with  x 2 , then  x 1  →  x 2 . By the observa-\ntion of the previous paragraph, this is equivalent to showing that if v 1 is in V 2 , then  x 1  →  x 2 . \n First , we restate the deﬁ nition of  → recursively as follows: Given versions  x 1 and  x 2 of  x ,  x 1  →  x 2 if and \nonly if either there exists a transaction T that overwrote version  x 1 with  x 2 or there exists a transaction T and a \nversion  x 3 such that  x 1 →  x 3 and T overwrote  x 3 with  x 2 . \n We say that a version  x i is  made by the replica that executed the transaction that created  x i . We say that  x i is \n made from the version  x j that was held by the replica when it executed the transaction that created  x i . When a rep-\nlica R receives a version  x i from replica S and R replaces its version of  x by  x i , we say that  x i  moved from S to R. \n Now we deﬁ ne a total ordering over the versions. For any version held by a replica R, deﬁ ne its  age to be \nthe number of make and move steps that it took to arrive at this state. For conﬂ ict-resolving makes (according \nto VV4), let its age be one greater than the maximum age over all conﬂ icting versions it is resolving. Our proof \nis by induction on version age, but we will have to strengthen the statement to be proved to make the induction \nstep work: \n For every version  x 2 with version ID v 2 , version vector V 2 , and age c held by replica R, and for every version \n x 1  \u0002  x 2 with version ID v 1 : \n 1.  If v 1 is in V 2 then  x 1 →  x 2 . \n 2.  If  x 1 was made by replica R,  x 1 has age c 1 , and c 1 \u000b c, then  x 1  →  x 2 . In other words, every version made \nby a given replica precedes every version that is later held by that replica. \n Basis step: If age  \u0003  1,  x 2 must have been created from  x 1 by a make step, that is, VV1 or VV4. Clearly, these \nsteps ensure  x 1  →  x 2 , so both (1) and (2) hold. \n9.5 Multimaster Replication  269\n",
      "content_length": 3808,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 289,
      "content": "270  CHAPTER 9 Replication\n Induction step: Suppose  x 2 is held by replica R k and has age c k and v 2  \u0003  [R n , c n ]. Version  x 2 was made from \nsome version  x 3 , possibly resolving a set of conﬂ icting versions, Con. As in the basis step,  x 3  →  x 2 and for \nall versions  x c in Con,  x c  →  x 2 . Observe that V 2 is the merge of the version vector of  x 3 and those of Con, \nplus with c n in n th  position. \n To prove (1), there are two cases: \n a.  x 1 was not made by R n . The transaction that made v 2 only updated position  n of its version vector. \nTherefore, if v 1 is in V 2 , it must be that v 1 is in the version vector of  x 3 or of one of the versions  x c of \nCon. Since all of these versions are younger than  x 2 , by part (1) of the induction hypothesis,  x 1  →  x 3 or \n x 1  →  x c . Since  x 3  →  x 2 and for all versions  x c in Con,  x c  →  x 2 , by transitivity  x 1  →  x 2 . \n b.  x 1 itself was made by R n with an age smaller than c n . Thus, by induction hypothesis part (2),  x 1  →  x 3 , \nand by transitivity  x 1  →  x 2 . \n To prove (2), observe that there are two cases: \n c.  x 2 was made by R k  (in other words, R k   \u0003  R n ). In that case,  x 3  was held by R n  before it made  x 2 , and so \nby induction hypothesis part (2),  x 1   →  x 3 , and we are done by transitivity. \n d.  x 2  moved to R k , overwriting what R k was holding, say  x 4 with version ID v 4 . In this case, according to \nVV 1  and VI 2 , v 4 is in V 2 . Before  x 2 moved, it was younger than it currently is, so we apply part (1) of \nthe induction hypothesis to conclude that  x 4  →  x 2 . But by induction hypothesis part (2),  x 1  →  x 4 , and so \nwe are done by transitivity. \n Example Revisited \n Using these rules, let’s revisit the example of  Figure 9.14 using version vectors instead of timestamps. The result \nis shown in  Figure 9.15 . We rename the primary to be replica R 3 , so we can use the more compact version v ector \nReplica R1\nInitially, x \u0003 [0, [R3,1], [1, 1, 1]]\nT1: x \u0003 x \u0005 1 \nx \u0003 [1, [R1,2], [2, 1, 1]]\nSend (x \u0003 [1, [R1,2], [2, 1, 1]])\nReceive (x \u0003 [2, [R2,2], [1, 2, 1]])\n       x \u0003 {[1, [R1,2], [2, 1, 1]]\n               [2, [R2,2], [1, 2, 1]]}\nReplica R3\nInitially, x \u0003 [0, [R3,1], [1, 1, 1]]\nReceive (x \u0003 [1, [R1,2], [2, 1, 1]])\nx \u0003 [1, [R1,2], [2, 1, 1]]\n Send (x \u0003 [1, [R1,2], [2, 1, 1]])\n Receive (x \u0003 [2, [R2,2], [1, 2, 1]])\n       x \u0003 {[1, [R1,2], [2, 1, 1]]\n                [2, [R2,2], [1, 2, 1]]}\nSend (x \u0003 [2, [R2,2], [1, 2, 1]])\nReplica R2\nInitially, x \u0003 [0, [R3,1], [1, 1, 1]]\nT2: x \u0003 x \u0005 2 \nx \u0003 [2, [R2,2], [1, 2, 1]]\n Send (x \u0003 [2, [R2,2], [1, 2, 1]])\n \n Receive (x \u0003 [1, [R1,2], [2, 1, 1]])\n        x \u0003 {[1, [R1,2], [2, 1, 1]]\n                 [2, [R2,2], [1, 2, 1]]}\n FIGURE 9.15 \n Using Version Vectors to Reconcile Updates. Initially,  x has value 0, produced by version [R 3 ,1] in the state characterized \nby version vector [1, 1, 1]. Since T 1 and T 2 produce incomparable version IDs and version vectors, their updated \nversions conﬂ ict and are retained at all replicas. \n",
      "content_length": 3055,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 290,
      "content": "notation. The version of  x is now a triple, comprised of a value, a version ID, and a version vector. Initially,  x is \n0 at the three replicas. It was last written by a transaction running at replica R 3 that generated version ID [R 3 , 1] \nafter which its state is summarized by the version vector [1, 1, 1]. The sequence of actions is exactly as before. \nThe interesting cases are when each site receives the second updated version. In each case, the recipient rec-\nognizes that the second updated version’s version ID and version vector are incomparable to the ones it has \nstored, so it detects a replication conﬂ ict and ends in a state containing both conﬂ icting updates. For example, \nconsider replica R 2 when it receives R 1 ’s updated version [1, [R 1 , 2], [2, 1, 1]] from R 3 . R 2 ’s local version of  x \nis [2, [R 2 , 2], [1, 2, 1]]. These versions of  x satisfy VV4, which means there is a replication conﬂ ict: R 2 ’s local \nversion [R 2 , 2] was written without having seen version [R 1 , 2], and the version [R 1 , 2] sent by R 1 was written \nwithout having seen version [R 2 , 2]. \n In this example, it seems like the use of version vectors has only helped a little bit in handling concurrent \nupdates of different replicas of the same data item. It correctly diagnosed the replication conﬂ ict but did not \nfully resolve it. However, there are other cases where the use of version vectors fully resolves the situation. \n For example, consider  Figure 9.16 , which is a variation of the scenario in  Figure 9.15 where R 1 sends its \nupdate by T 1 directly to R 2 in addition to sending it to R 3 . If R 1 ’s updated version arrives at R 2 before R 2 executes \nT 2 , then T 2 will overwrite R 1 ’s updated version of  x . R 3 will recognize this fact when it receives R 2 ’s updated ver-\nsion of  x from R 2 and will replace R 1 ’s version of  x by R 2 ’s updated version. On the other hand, if R 1 ’s updated \nversion arrives at R 2  after R 2 executes T 2 , then T 2 will not overwrite R 1 ’s updated version of  x . R 2 will still send \nthe updated version to R 3 , but in this case R 3 will recognize it as a conﬂ ict. Notice that timestamps alone cannot \nmake this distinction. For example, if T 2 is assigned a larger timestamp than T 1 , then it will always overwrite T 1 ’s \nupdated version at all replicas, whether or not T 2 saw T 1 ’s updated version of  x at the time it executed. \n Although version vectors do identify replication conﬂ icts, they do not ensure one-copy serializability because \nthey detect conﬂ icts only on a single data item, not across two or more data items. For example, suppose the \ndatabase has data items  x and  y that are stored at replicas R 1 and R 2 . Initially,  x has the version [3, [R 1 , 1], [1, 2]] \nand  y has the version [5, [R 2 , 2], [1, 2]] at both replicas. Suppose transaction T 1 at R 1 adds  x and  y and stores the \nresult, 8, into  x with version ID [R 1 , 2]. Suppose transaction T 2 does the same thing, but stores the result, 8, into \n y with version ID [R 2 , 3]. Each of them propagates their updated version to the other replica. According to the \nversion ID-based update rules, each replica will apply the updated version that it receives from the other replica. \nSo the ﬁ nal state at both replicas will have  x  \u0003  [8, [R 1 , 2], [2, 2]] and  y  \u0003  [8, [R 2 , 2], [1, 3]]. However, if the \ntransactions ran on a one-copy database, either the resulting value of  x would be 11 or the resulting value of  y \nwould be 13. So the result is not one-copy serializable. \nR1\nR2\nR3\nT1’s update \nT1’s \nupdate \nT2’s \nupdate \nT1 runs\nat R1\nT2 runs\nat R2\n FIGURE 9.16 \n Diagnosing a Replication Conﬂ ict. Using version vectors, when R 3 receives T 2 ’s update, it can tell whether that update \nran before or after R 2 received T 1 ’s update. \n9.5 Multimaster Replication  271\n",
      "content_length": 3853,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 291,
      "content": "272  CHAPTER 9 Replication\n Consistency, Availability, and Partition-Tolerance Revisited \n At the end of Section 9.4 we introduced the tradeoff between data consistency, system availability, and parti-\ntion-tolerance. We saw that the primary-copy approach with synchronous replication offers data consistency \nand partition-tolerance at the cost of system availability when a partition occurs. With asynchronous replica-\ntion, it improves availability in some cases at the cost of data consistency. \n The multimaster approach with asynchronous replication offers further improvement of availability and \npartition-tolerance but with decreased data consistency. If a replica R is up and running, then R can be read or \nwritten. R need not be part of a quorum of replicas. In fact, even if R is partitioned from the rest of the network, \nit is available. However, there is a cost in data consistency. First, since there is delay in propagating updates to \nreplicas, the system is only eventually consistent, not instantaneously consistent. And second, since transactions \ncan update other replicas concurrently with transactions that update R, there may be replication conﬂ icts. Such \nconﬂ icts represent a loss of data consistency. \n As we saw, these conﬂ icts can be detected in certain cases, at which point an application-speciﬁ c conﬂ ict \nresolution procedure can try to return the data to a consistent state. Still, a conﬂ ict resolution procedure may \nnot be able to make the data perfectly consistent, in the sense that it makes the execution one-copy serializ-\nable. For example, if replicas are used for ﬂ ight reservations, and two replicas ran transactions that sold the last \nseat on a ﬂ ight, then the best that the conﬂ ict resolution procedure can do is run a compensation for one of the \nticket holders. This is not a result that would occur in a one-copy system. \n Microsoft Sync Framework \n As an example of a multimaster replication system that uses version vectors, we consider Microsoft Sync \nFramework, which was introduced in 2007. Like the approach described in this section, it generates a version ID \nfor each update and maintains a version vector for each replica. Like most multimaster implementations, it uses \na number of variations of the basic techniques outlined in this section. We highlight two of them here. First, in \nmost cases it does not attach a version vector to each data item. Instead, it detects replication conﬂ icts using the \nreplica’s version vector (not the data item’s version vector) and modiﬁ ed version ID-based update rules. Second, \nit allows a transfer of updates from one replica to another to be interrupted and resumed at another time. This \nrequires additional modiﬁ cations to the maintenance and use of version vectors. \n Like before, suppose that replica R receives from replica S an updated version of some data item  x with \nversion ID [R i , c] and that R’s version of  x has version ID [R k , d]. At the time R receives the updated version, \nits current version vector is [r 1 ,  … , r n ] and replica S’s current version vector is [s 1 ,  … , s n ]. Then R decides how \nto process the update using the following  modiﬁ ed version ID-based update rules : \n MVI1. If r i  \n c, then discard S’s update. \n MVI2. If s k  \n d, then replace the value of  x at R by the one sent by S, along with version ID [R i , c]. \n MVI3. Otherwise, there is a conﬂ ict and conﬂ ict resolution is needed. \n In the case of MVI3, both values of  x are retained. The value sent by S is stored with its version ID and \nwith S’s version vector [s 1 ,  … , s n ]. Thus, some data items have per-data-item version vectors. But these are \npresumably a small fraction of the data items at the replica. In an application where they are a large fraction \nof the data items, there is a large number of unresolved replication conﬂ icts, which casts doubt on the value of \nusing multimaster replication in this application. \n If a later updated version arrives at R for  x , then when deciding whether to overwrite the stored version, R \nuses the version vector associated with  x rather than R’s version vector. Similarly, if R forwards this updated \nversion of  x to another replica R \u0002 , R forwards it with the version vector associated with  x and R \u0002 uses that ver-\nsion vector when applying the modiﬁ ed version ID-based update rules, not R’s version vector. \n",
      "content_length": 4401,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 292,
      "content": " The surprising fact about the modiﬁ ed version ID-based update rules is that they have the same effect as \nthe original version ID-based rules. \n The second feature of the Microsoft Sync Framework that we discuss is that it allows the transfer of \nupdated versions from replica S to R to be interrupted. Ordinarily, that would cause a problem for R, since \nit may have received an updated version of some data item  x but not some updates on which the version \ndepended. It avoids this problem through a technique similar to conﬂ ict detection. \n To be more precise, if R receives an updated version with version ID [R i , c] for data item  x and the modiﬁ ed \nversion vector-based update rule says to apply the updated version (either overwriting  x or adding a conﬂ icting \nversion of  x ), then R’s state for  x is more up to date for  x than for other data items. If the transfer is interrupted, \nR needs to know that S’s version vector characterizes the state of updates from S that R has applied. These are \ncalled exceptions. Eventually, possibly after several lengthy interruptions, S completes its transfer of updates to \nR. Now R knows that it is not missing any information earlier than S’s version vector. Therefore, any exceptions \nthat it accumulated due to updates it received from R and that are not replication conﬂ icts can be dropped. At \nthat point, S’s version vector can be merged with R’s version vector, as in the normal case. \n Suppose there is a total order over data items; for example, by name or storage address. Then to minimize \nthe number of the exceptions at R, S can send the updated versions to R in data item order. If the transfer is \ninterrupted after R has received items in (say) the range 1 to  m , it can summarize its exceptions by the range \nexception [1, m] and S’s version vector. Clearly, this is a much denser representation than enumerating excep-\ntions for each updated data item that was transferred. \n Given these techniques, a replica has several sources of knowledge about past updates: a per-replica version \nvector and per-data-item version vectors for replication conﬂ icts and for exceptions. When a replica R requests \nrecent changes from another replica S, R sends all this knowledge of its current state to S, so that S can avoid \nsending updates that R already knows about. \n There are several other special techniques used in this system; for example, to garbage collect tombstones, \nto enable replicas to join and leave a system, and to allow different conﬂ ict handlers at different replicas. See \nthe bibliographic notes for articles that describe these and other features. \n 9.6  OTHER REPLICATION TECHNIQUES \n Replication algorithms have been an active area of database research for over three decades. Many algorithms \nhave been published beyond those described here, which are the ones that are primarily used in today’s data-\nbase systems. Some interesting other approaches include: \n ■  Nontransactional replication, based on timestamped updates. That is, each original update executes as an \natomic action outside the context of any transaction. These algorithms often are used for distributed sys-\ntem services, such as a directory service, where multimaster replication is needed but not transactions. \n ■  Quorum consensus applied to every transaction. Each transaction reads a quorum of copies of each data \nitem it accesses, and uses the most up-to-date value among those copies as input. This approach avoids \nelections and other reconﬁ guration algorithms, at the cost of more work for each transaction. It is also \none of the ﬁ rst correct replication algorithms published. \n ■  Read-one-write-all-available, where instead of using a primary copy, each transaction writes to all avail-\nable copies of every data item it updates. One well-known algorithm, called Virtual Partitions, uses this \napproach along with quorum consensus, to ensure a data item is updatable only if the set of connected \nsites have a quorum of copies of that item. \n See the Bibliographic Notes for further reading. \n9.6 Other Replication Techniques  273\n",
      "content_length": 4112,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 293,
      "content": "274  CHAPTER 9 Replication\n 9.7  DATA SHARING SYSTEMS \n A  data sharing system is one where two data manager processes can both access the same database. This is \na case where the server is replicated but not the resource. Data sharing arises in systems where two or more \nmachines have access to the same stable storage devices. In this case, the data managers executing on indepen-\ndent machines have to synchronize their access to shared pages. This usage scenario was made popular in the \n1980s in clustered systems, such as VMScluster. Currently, it arises when multiple machines can access the same \nstorage using a storage area network, such as in Oracle Real Application Clusters and IBM DB2 Data Sharing. \n Another rather different scenario where data sharing arises is mid-tier caching, where two or more mid-\ntier machines cache data that is stored on the same backend data manager. Often, the mid-tier machines cache \nonly static data, in which case there are no special concurrency control or recovery problems. However, if the \nmid-tier machines can update data, then concurrency control problems occur that are similar to those of shared \nstable storage. \n In a data sharing system, it is no longer satisfactory to have the lock manager be local to the data manager, \nbecause a lock that is set by one data manager would not be visible to another server that accesses the same \ndatabase. This changes the locking architecture quite a bit and has some effect on the recovery algorithm. \n Locking \n In a data sharing system, when a data manager process obtains a lock on a data item it must be sure that no other \ndata manager has a conﬂ icting lock. This usually entails the use of a global lock manager that lives outside of the \ndata manager processes that access it. Thus, invocations of lock and unlock operations are usually more expen-\nsive than with an in-process lock manager, due to the expense of a context switch and a message if the lock man-\nager is remote. This expense affects the design of concurrency control algorithms for data sharing. Some systems \ntry to reduce the expense with special hardware or operating system support. Others try to reduce the frequency \nof calls to the global lock manager. \n One way to reduce the number of calls to the global lock manager is to combine it with a local (i.e., in-p rocess) \nlock manager. When a transaction T accesses a data item  x , its data manager S sets a lock at the global lock \nmanager and, if it succeeds, then T sets a lock in the local lock manager. When T commits or aborts, it releases \nits lock on  x at the local lock manager. However, S retains its lock on  x at the global lock manager. This allows \nlater transactions running in S to lock  x using only the local lock manager. \n If a transaction T \u0002 running in another data manager accesses  x , its data manager S \u0002 must lock  x at the global \nlock manager. However, it will be unable to do so if S holds a conﬂ icting lock on  x . There needs to be a proto-\ncol that ensures S will release its lock on  x . One way to do this is via a  call-back from the global lock manager \nto S. That is, if the global lock manager receives a request by S \u0002 to lock  x at a time when S holds a conﬂ icting \nlock, the global lock manager sends a call-back message to S asking it to release the lock. If there is no active \ntransaction in S that is using  x (i.e., that has a local lock on  x ), then S releases the lock on  x at the global lock \nmanager. If there is such a transaction, then S waits until that transaction has completed before releasing its \nlock on  x . If S has other transactions waiting in its local lock manager for the lock on  x , then it’s a policy ques-\ntion as to whether S releases the lock right away at the global lock manager or waits until there are no active \ntransactions in S that are waiting for the lock. \n Caching \n In a data sharing system two data manager processes can have a cached copy of the same data item. So they \nnot only need to synchronize access using locks, but they also need to ensure they see each other’s cached \n",
      "content_length": 4101,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 294,
      "content": "updates. For example, in  Figure 9.17 data managers S and S \u0002 both have a cached copy of page P whose per-\nsistent copy resides in a shared database. S sets a lock on P at the global lock manager, executes a transaction \nT 1 that updates record r 1 on page P, and then releases its lock on P. Now S \u0002 sets a lock on P at the global lock \nmanager so that it can run a transaction T 2 that updates a different record r 2 on page P. To ensure that T 1 ’s \nupdate to r 1 does not get lost, it’s essential that T 2 reads the copy of P that was updated by T 1 . This will work \nﬁ ne if S writes P to the shared database on behalf of T 1 before T 1 releases its lock on P. \n Since a transaction needs to be durable, it would seem to be obvious that S must write P to the database \nbefore T 1 commits. However, as we saw in Section 7.8, often this is not done. Instead, T 1 ’s update to r 1 might \nbe written only to a log, without writing P itself to the database. In this case, S does not need to write P on \nbehalf of each transaction, because later transactions that execute in S will access the cached copy of P and \ntherefore are not in danger of losing earlier transactions ’ updates. However, before S releases its lock on P \nat the global lock manager, it needs to ensure that, if another data manager process locks P at the global lock \nmanager, it will access the latest copy of P in the shared database. For example, before releasing its lock on P, \nS can write P to the shared database. An alternative is for S to set a ﬂ ag in the global lock for P that indicates \nit has the latest version of P in cache. When another data manager sets a lock on P, it sees that it should get the \nlatest copy of P from S, not from stable storage. \n Continuing the example, let’s suppose S writes P to the stable database and releases its global lock on P. Data \nmanager S \u0002 gets the global lock on P, reads P from the shared database, runs one or more transactions that update \nP, and eventually writes P back to the shared database and releases its global lock on P. Now, suppose S has \nanother transaction that wants to access page P. So S sets a global lock on P. However, notice that S might still \nhave a copy of P in its cache. If so, it will use its cached copy rather than reading it from the shared database. \nObviously, this would be a mistake since S would ignore the updated value of P that was produced by transac-\ntions running in process S \u0002 . Therefore, even though S has a cached copy of P, it should invalidate this copy and \nreread P from the shared database. \n What if no other process updated page P between the time S released its global lock on P and the time it \nset the lock again? In that case, it’s safe for S to use its cached copy of P. A simple bookkeeping technique can \nenable S to recognize this case. Each page header includes a version number. (An LSN could be used for this \npurpose; see Chapter 7.) The ﬁ rst time that a data manager updates a page P, it increments the version number. \nP\nr1\nData Manager S\nData Manager S\u0002\nP\nP\nShared\nDatabase\nr2\n FIGURE 9.17 \n A Data Sharing System. Page P is stored on disk. Processes S and S \u0002 cache P in their private main memory. \n9.7 Data Sharing Systems  275\n",
      "content_length": 3227,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 295,
      "content": "276  CHAPTER 9 Replication\nWhen it releases the global lock on P, it tells the lock manager the version number of the page. Although the \nlock has been released, the global lock manager retains the lock in its lock table with the associated version \nnumber. When a data manager sets a global lock on the page, the lock manager returns the page’s version num-\nber to the data manager. If the data manager has a cached copy of the page, it can compare this version number \nto that of its cached copy. If they’re the same, then it doesn’t need to reread the page from the shared database. \n Using this version number technique, locks will remain in the lock manager even if no transaction is hold-\ning them. How does a lock disappear from the global lock manager, to avoid having the lock manager become \ncluttered with locks that are no longer being used? This could be done implicitly by a timer. If a lock is not \nowned by any data manager and has been unused for a period of time, then the lock can be deallocated. The \ntime period should be long enough that any page that was unused in a data manager’s cache for that long is \nlikely to have been deallocated. If the lock manager deallocates a lock too soon, then a data manager may \nrequest that lock while it still has the corresponding page in cache. In that case, since the lock manager is \nunable to tell the data manager the version number of the latest version of the page, the data manager needs to \ninvalidate the cached copy of the page and reread it from stable storage. \n Another approach to lock deallocation is to explicitly maintain a reference count of the number of data \nmanagers that have a cached copy of the page corresponding to each lock. When a data manager invalidates a \ncached page, it tells the lock manager to decrement the reference count. There is no urgency to have the lock \nmanager do this decrement, so the data manager could save such calls in a batch and send them to the lock \nmanager periodically. \n Synchronizing shared pages between the caches of different data managers is one of the major costs in a \ndata sharing system. One way to reduce this cost is to reduce the chance that a page needs to be accessed by \ntwo or more data managers. To take an extreme case, the database could be partitioned so that each data man-\nager has exclusive access to one partition and each transaction only accesses data in one partition. Thus, each \ntransaction uses the data manager that manages the partition needed by the transaction. Two data managers \nnever need the same page, so cache synchronization doesn’t arise. \n Of course, if all databases and transaction loads could be partitioned in this way, then the mechanism for \ndynamic cache synchronization would have little value, since each data manager can be assigned a partition \nstatically. However, even if a perfect partitioning isn’t possible, an approximate partitioning may be within \nreach and serve the purpose. That is, each data manager is assigned a partition of the database, but it is allowed \nto access the rest of the database for the occasional transaction that needs data outside the partition. Similarly, \ntransaction types are partitioned so that each transaction gets most, usually all, of its data from one data man-\nager’s partition. Thus, cache synchronization is required only occasionally, since it is relatively unlikely that \ntransactions running in different partitions happen to access the same data page. \n For example, consider the debit-credit transaction workload of TPC-B, discussed in Section 1.5. The data-\nbase could be partitioned by bank branch, so that each branch balance is accessed by at most one data manager. \nBy the nature of the application, tellers are partitioned by bank branch and each account has a home branch. \nSo account records could be organized so that each page has account records with the same home branch. \nEach request takes an account ID, branch ID, and teller ID as input parameters. The branch ID parameter is \nused to send the request to that branch’s data manager. So the branch balance and teller balance for that branch \nare guaranteed to be in that data manager’s cache. Usually this branch ID for the request is the home branch of \nthe account ID, since people do most of their banking at their home branch. In this case, the account informa-\ntion is very unlikely to be in the cache of any other data manager. Occasionally, the account ID is not for the \nhome branch. In this case, the data manager for the branch is accessing a page of accounts all of which are for \nanother branch. There is a nonnegligible probability that this page is in the cache of the data manager of those \naccounts ’ home branch. But it’s still a relatively low probability. Therefore, although cache synchronization for \nsuch cases does happen, it is relatively rare. \n",
      "content_length": 4858,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 296,
      "content": " Logging \n When logging is used for database recovery, there is one log for each database. The log describes the sequence \nof updates that was applied to the database. The recovery algorithm uses this sequence to reconstruct the cor-\nrect database state after a failure, as discussed in Chapter 7. \n In a data sharing system, multiple data managers are updating the database and therefore are writing \nrecords to the end of the same log. One way to implement this log is to have data managers send  “ append-log-\nrecord ” operations to a shared log server process. The append-log-record operation appends the given record \nto the log and returns the LSN (i.e., log address) of the log record being appended. The append operation \nhas a parameter indicating whether the append must be forced to stable storage before returning to the caller. \nSince the log is often a bottleneck that limits transaction throughput, it’s important that the log server be able \nto process append operations at a high rate. Therefore, it may be worthwhile for each data manager to send \na sequence of append operations in each call to the log server, to amortize the cost of calling the log server \nacross multiple operations. \n Another way to implement the log is to allow data mangers to write log pages directly into a shared log \nﬁ le (rather than log records to a shared log server). This is possible because a data sharing system has shared \npersistent storage, some of which can be used for a shared log ﬁ le that is directly accessible to all data manag-\ners. To ensure that the data managers don’t overwrite each others ’ data at the end of the log, a log space server \ncan be used to allocate log space to each data manager. The log space server supports the  “ allocate ” operation, \nwhich returns a range of physical log pages and a range of LSNs that are reserved for the caller. This range of \npages may be written only by the data manager to which they were allocated. So the data manager can write \ninto those log pages directly. It can use a local buffer to collect updates to the log and periodically write that \nbuffer to the log pages that are allocated for it. To simplify the following discussion, we assume that the log \nspace server allocates one log page in response to each call to the allocate operation. \n In the log server approach, a data manager needs to receive the LSN from the log server to complete each \nupdate. By contrast, in this direct writing approach, the data manager has a private pool of LSNs it can use, so \nit can process updates locally. This helps reduce the amount of communications required for interacting with \nthe log and therefore speeds up the processing of writes. \n In both approaches, some care is needed to enforce the write-ahead log protocol. In the log server approach, \neach data manager needs to be told periodically the LSN of the last log record that was written to disk. This \ncan be one of the return values of every append operation. In the direct writing approach, a data manager \nuses the same technique as in a system that does not use data sharing.  That is, before it ﬂ ushes a data page, it \nensures that the log page containing the last update record to that data page has already been ﬂ ushed. \n To commit a transaction, a commit record is written and the tail of the log is forced to stable storage, pos-\nsibly after a short delay for group commit. In the direct writing approach, each log page is written by only one \ndata manager. Hence, there may be more partially ﬁ lled log pages than with the log server approach, where log \nrecords from different data managers can be written to the same log page. \n The ﬁ rst step of a recovery procedure is to ﬁ nd the end of the log. This is a bit more complicated for the \ndirect writing approach than for the log server approach. Using the direct writing approach, the order in which \ndata managers write their log pages may be different than the order in which those pages were allocated. \nTherefore, there may be holes in the sequence at the end of the stable log. For example, if pages  n-1 and  n were \nthe last two log pages that were allocated (to different data managers), it is possible that page  n was written \nbefore the failure but page  n-1 was not. This does not add any cost to the algorithm for ﬁ nding the end of the \nlog, but it does add some algorithmic complexity. \n The ﬁ nal issue relates to transactions that execute in different data managers and update the same data item. \nSome synchronization is needed to ensure that log records for conﬂ icting updates are written to the log in the \n9.7 Data Sharing Systems  277\n",
      "content_length": 4645,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 297,
      "content": "278  CHAPTER 9 Replication\nsame order that the updates themselves executed. With the log server approach, this is automatic, since a data \nmanager does not release a page for use by other data managers until after it has sent its last update record for \nthat page to the log manager. \n By contrast, in the direct writing approach it is possible that the update records can appear out of order. \nFor example, suppose a data manager D writes into page P and appends an update record to its log page, say \npage  n . It ﬂ ushes that log page and then ﬂ ushes P and releases its lock on P, thereby making P available to \nother data managers. The next data manager D \u0002 that updates P might be using a log page that precedes  n and \nhence has smaller LSNs than the LSN written by D. If D \u0002 wrote a smaller LSN on P than the one written by D, \nthat would suggest that the update from D \u0002 had been applied to P but the one from D had not, which is incor-\nrect. Thus, the recovery algorithm could no longer use LSNs to determine which updates had or had not been \napplied to a page before the last failure. \n A simple solution is that when D \u0002 updates P, if it sees that P’s LSN is larger than the largest LSN currently \nallocated to D \u0002 , then it ﬂ ushes the remainder of its allocated log and gets new log pages from the log space \nserver. This incurs an extra log ﬂ ush and increases the likelihood of partially-ﬁ lled  log pages. However, if the \ndatabase is partially partitioned as described at the end of the previous subsection on  Caching , then this type of \nsynchronization will be relatively rare. \n 9.8  SUMMARY \n The main goal of replication is to improve availability, since a service is available even if some of its replicas \nare not. Replication can also improve response time, since the capacity of a set of replicated servers can be \ngreater than the capacity of a single server. \n The most widely-used  approach to replication is to replicate the resource (i.e., the database) in addition to \nthe server that manages it. This requires synchronizing updates with queries and each other when these opera-\ntions execute on different replicas, so that the effects are indistinguishable from a nonreplicated system. The \nsynchronization mechanism must allow for replicas or communications between replicas to be down for long \nperiods. Communication failures are especially troublesome, since noncommunicating replicas may process \nconﬂ icting updates that they are unable to synchronize until after they reconnect. \n One popular approach to replication is to designate one replica as the primary copy and to allow update \ntransactions to originate only at that replica. Updates on the primary are distributed and applied to other repli-\ncas, called secondaries, in the order in which they executed at the primary. Since all replicas process the same \nupdates in the same order, the replicas converge toward the same state as the primary. \n The stream of updates sent from the primary can be quite large, so it is worth minimizing its size by only \nincluding data items that are modiﬁ ed and by ﬁ ltering out aborted transactions. The stream can be generated \nby processing the resource manager’s log or by using triggers to generate the update stream directly from \nupdates on the primary copy. \n An alternative to propagating updates is to send the requests to run the original transactions to all second-\naries and ensure that the transactions execute in the same order at all secondaries and the primary, either by \nphysically running them in that order, which is slow, or synchronizing their execution between primary and \nsecondaries, which can be tricky. \n In any case, when a secondary fails and subsequently recovers, it must catch up processing the updates \nproduced by the primary while it was down. If the primary fails, the remaining secondaries must elect a new \nprimary and ensure it has the most up-to-date view of the updates that executed before the primary failed. \n When a primary or secondary fails, the remaining replicas must check that they have a majority or quorum \nof copies, to ensure that they are the only group of communicating replicas. For if there were two partitions of \n",
      "content_length": 4212,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 298,
      "content": "replicas that could communicate within the partition but not between partitions, then the two partitions could \nprocess conﬂ icting updates that would be hard to reconcile after the groups were reunited. \n Sometimes partitioning is a planned and frequent event, as with laptop computers that contain replicas but \nare only periodically connected to the network. This requires that every partition be allowed to process updates, \nallowing for multiple masters, not just one primary. Some variation of Thomas ’ write rule often is used for \nthese situations: each data item is tagged by the timestamp of the latest update to it. An update is applied only if \nits timestamp is larger than the data item’s tag in the database. That way, updates can arrive in different orders, \nsometimes with long delays, yet the replicas will all eventually have the same value, namely the one produced \nby using the update with the largest timestamp.  \n The problem with this approach is that an update can be lost if it’s overwritten by another update with larger \ntimestamp that didn’t see the output of the earlier update. One way to avoid this problem is to use version vec-\ntors in place of timestamps. Each version vector tells which updates were received by the replica before pro-\nducing the current version of the data item. This enables more accurate conﬂ ict detection at the cost of more \ninformation attached to each data item. An optimization used in Microsoft Sync Framework avoids this per-\ndata-item version vector in most cases, but still requires version vectors for data items involved in a conﬂ ict or \nreceived out of order. \n The CAP conjecture says that a system can offer at most two of the following three properties: data consis-\ntency, system availability, and tolerance to network partitions. The primary-copy approach with synchronous \nreplication ensures data consistency and partition-tolerance. It gives up on the availability of replicas that are \noutside the quorum. Asynchronous replication gives up on instantaneous consistency, ensuring eventual con-\nsistency instead, which improves availability further in some cases. Multimaster replication offers availability \nand partition-tolerance at the cost of data consistency. \n The primary copy and multimaster algorithms described here are the ones used most widely in practice. \nHowever, since replication has been much studied by database researchers, there are many other published \nalgorithms beyond the ones in this chapter. \n Another form of replication is data sharing, where data manager replicas share access to a common resource, \nsuch as a database. Since two data managers can access the same page of the database, some synchronization \nis needed between the data managers. This is usually done with a global lock manager that is accessible to all \ndata managers. A data manager sets a global lock before operating on a page. If it updates a page, then it ﬂ ushes \nthe page to stable storage before releasing the lock. This ensures the next data manager that reads the page will \nsee the latest version. Synchronization is also needed to enable all the data managers to write to the shared \nlog. This can be done with a global log server. Data managers call the log server to append records to the log. \nAlternatively, a log space server can be used to allocate log pages to each data manager, which can then write to \nthose log pages without further synchronization. \n \n9.8 Summary  279\n",
      "content_length": 3467,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 299,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 300,
      "content": " 10.1  INTRODUCTION \n In this chapter, we’ll survey some popular transactional middleware products and standards, including: \n ■  Current products from Microsoft and Java vendors \n ■  Popular persistence abstractions mechanisms that simplify database access \n ■  Legacy TP monitors, including information on how each product can be reused in a modern system, such \nas a Service Oriented Architecture (SOA)-based application \n ■  Widely-adopted  TP standards \n Trends in Transactional Middleware \n Over the past 20 years, we have seen a continual repackaging of transactional middleware functionality, both \nthe aggregation of components into transactional middleware packages and the decomposition of packages into \nindependently conﬁ gurable components. For example, transaction management is a basic capability in most \ndatabase management systems. It is also offered in enterprise service buses and other products designed for use \nwith an SOA-based application. Some features and functions of front-end programs, request controllers, and \ntransaction servers have migrated from integrated TP monitors and application servers to separate products. \nOthers are migrating into operating systems, such as distributed transaction management. The innovations of \nlarge web sites such as Amazon.com, Google, and eBay have also been inﬂ uential, such as the use of custom \ntransactional middleware components for replicated state management and simple scalable data management. \n The goal of this chapter is to give you a feeling for the state of the art of transactional middleware products \nand some conﬁ dence that the technical issues discussed in this book do give you the necessary background to \nunderstand transactional middleware. A secondary goal is to help you think about which technology is most \nappropriate for your speciﬁ c requirements. \n It is not a goal of this chapter to provide sufﬁ ciently detailed feature comparisons to help you select the \nexact products that best suit your needs. Product features change with each succeeding product release, so we \nrecommend that you evaluate the latest information from a product’s vendor when making such a decision. It is \nalso not a goal to explain each product in enough detail to enable you to use it. In particular, example programs \nare meant only to illustrate each product’s approach, not to be used as a template for developing applications. \n For the most part, when describing each product or technology, we use this book’s terminology rather than \nthat of the product or technology. If you know a given product well, it may seem strange to see it described using \n Transactional Middleware Products \nand Standards \n 10 \nCHAPTER\n",
      "content_length": 2700,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 301,
      "content": "282  CHAPTER 10 Transactional Middleware Products and Standards\n unfamiliar terms. However, for a reader learning about the product for the ﬁ rst time, we hope this approach \nmakes it easier to gain a basic understanding of how the product is structured and what features it offers. \n Transactional Middleware Programming Models \n Today ’s transactional middleware products provide a conﬁ gurable deployment container for application objects. \nThe goal of the container is to reduce complexity by packaging together system capabilities such as transaction \ncontrol, threading, and persistence, and enabling a developer to customize them using conﬁ guration properties. \nDeployment of a transactional object into a container requires a conﬁ guration step to set its properties. This is \nthe approach described in Section 2.2,  Transaction Bracketing in Object-Oriented Programming . Both the .NET \nFramework and Java-based products recommend using container-managed transactions for most applications. \n Container -managed transactions are called the  implicit programming model because an application devel-\noper creates TP programs that incorporate the business logic without describing transactional behavior. This \nsimpliﬁ es programming by not requiring the developer to think about which parts of the code need to run as \ntransactions. It also helps address the transaction composition problem by enabling programs to be composed \nin different combinations without being rewritten. \n In this model, transactional behavior is deﬁ ned in another step, perhaps by another person, using conﬁ gura-\ntion properties. Conﬁ guration properties can be deﬁ ned in a separate ﬁ le associated with the program, as attri-\nbutes embedded within a program and its interface, or as a combination of the two. Sometimes the separate \nconﬁ guration ﬁ le is generated from the embedded attributes. Some technologies allow attributes in a conﬁ gu-\nration ﬁ le to override embedded attributes. Others do not. \n The implicit model is increasingly popular, but there are cases where developers want the ﬂ exibility to \nexpress transactional behavior in the business logic. To meet this need, both the Java-based and .NET-based \ntransactional middleware systems also offer  explicit programming control of transactions. In this model, devel-\nopers use transaction management APIs to explicitly start and end transactions within their objects. \n The explicit programming model adds ﬂ exibility, but usually at the cost of more difﬁ culty in creating and \nmaintaining complex systems. However, whether developers use explicit or implicit transaction control, the \nbehavior of the underlying transactional system remains the same because the execution of the transaction \ncontrol operations relies on the same transactional infrastructure. \n Java EE and the .NET Framework \n Currently , the two primary transactional middleware environments are Java Enterprise Edition-based applica-\ntion servers and Microsoft’s .NET Framework. Both environments provide comprehensive capabilities for creating \nand deploying TP applications. \n In keeping with the ongoing trend to repackage transactional middleware functionality, some TP envi-\nronments use only parts of the Java Enterprise Edition (EE) and .NET Frameworks. Sometimes these parts \nare combined with legacy TP monitors, for example, to modernize an existing application or to enable new \napplications to interoperate with older ones. \n Comparing the Java EE and .NET Framework environments, one obvious difference is platform coverage. \nFor example, Microsoft’s .NET Framework offers a comprehensive and full-featured programming model for \ndeveloping and deploying TP applications, but it is available only on Windows operating systems. A second sig-\nniﬁ cant difference between products is their set of programming interfaces and communication paradigms. For \nexample, .NET Framework APIs differ from Java EE APIs. Although the APIs share many common features, \nthey each offer some unique ones. A third difference is standards conformance. Products typically conform to \nvarious TP standards, but not necessarily to the same ones. \n",
      "content_length": 4164,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 302,
      "content": " We describe the details of the .NET Framework and Java EE in Sections 10.3 and 10.4, respectively. But \nﬁ rst, we discuss technologies for developing front-end programs using web browsers, since they are largely \ncommon to both environments. \n 10.2  WEB BROWSER FRONT-END PROGRAMS \n As described in Chapter 3, a web browser is a common front-end program for TP applications. Most TP applica-\ntions support them directly or can be adapted to support them, so we’ll cover them as a general topic applicable \nto any transactional middleware. \n A web browser requires a web server to handle HTTP requests and replies. In the multitier architecture the \nweb server may directly interact with the database or with one or more intermediate tiers created using transac-\ntional middleware components, as illustrated in  Figure 10.1 . In some cases the database system can function as \na web server. Intermediate tiers typically introduce mechanisms for scalability and availability, such as partition-\ning, replication, caching, and request routing. HTTP load balancers can be used to scale up browser access to \nthe web server itself. Typical web servers include Microsoft’s Internet Information Server (IIS) and the Apache \nHTTP Server. \n One popular type of web browser programming environment is AJAX (Asynchronous JavaScript and XML). \nAJAX enables browser-based forms and menus to be highly efﬁ cient and interactive. Compared to browsers \nusing plain HTML or XML, AJAX introduces three major beneﬁ ts for TP applications: using AJAX the browser \nneeds to exchange only the changed information with the web server, instead of the entire page, thereby reduc-\ning communication expense and improving response time; AJAX allows asynchronous interaction with the web \nserver, which does not block the user’s interaction with forms and menus; and AJAX allows the browser to \nofﬂ oad the web server by absorbing more of the application processing load. \n A simple AJAX program typically involves the exchange of an XML document with a web server and map-\nping the data into and out of the ﬁ elds in the menus and forms that users interact with. A more complex AJAX \nprogram might handle a REST-style interaction or a Web Service invocation. Java Script Object Notation \n(JSON) is another popular supported data format for AJAX. \n Figure 10.2 illustrates a simpliﬁ ed browser-based form for a money transfer operation. The form obtains \naccount numbers from the user along with the amount to be transferred. This data is sent to the server where \nWeb Browser \nDatabase/\nWeb Server \nWeb Browser \nWeb Server \nDatabase \nWeb Browser \nWeb Server\nDatabase \nTransactional\nMiddleware \n FIGURE 10.1 \n Web Browsers and Multitier TP Architecture. Web browsers work with TP applications in a variety of ways, including \ndirect database access and multitier architectures using transactional middleware. \n10.2 Web Browser Front-End Programs  283\n",
      "content_length": 2924,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 303,
      "content": "284  CHAPTER 10 Transactional Middleware Products and Standards\n the accounts are updated and the resulting balances for the two accounts are returned to the browser. While this \nexchange is taking place the user does not leave the form. \n Figure 10.3 shows an AJAX program snippet that works for both Microsoft’s Internet Explorer and other \nbrowsers. Internet Explorer implements AJAX using an ActiveX control ( XMLHTTP ), which is a mechanism \nspeciﬁ c to Windows, whereas other browsers typically use the standard  XMLHttpRequest class. AJAX sup-\nport also is included in the .NET Framework Active Server Pages (ASP) .NET library, including integration \nbetween AJAX and server-side ASP.NET. \n In either case, the  XMLHttpRequest class interacts with the web server asynchronously. It provides \nm ethods for exchanging data in various formats with the web server, including SOAP, XML, and JSON. \nSince AJAX is also a popular technology for developing Web Service clients, an AJAX library is available \nfor g enerating and handling Web Services, called  ws.js . Apache CXF provides an option for generating \nc lient-side JavaScript from a server-side Web Service deﬁ nition. In ASP.NET, an AJAX script can be used to \ncall either an ASP.NET Web Service (.asmx) or a Windows Communication Foundation (WCF)-based Web \nService (.svc). \n Typically , an HTTP  GET operation is performed ﬁ rst to display an HTML form. The modiﬁ ed ﬁ elds are \nsent to the server as XML elements in an HTTP  POST operation, returned in the response message, and dis-\nplayed on the form. In the example a  POST operation sends the URL of the server along with the data from \nthe form (in this case to and from account numbers and the transfer amount). The  true parameter in the open \nmethod indicates that the HTTP operation is to be performed asynchronously. The  onreadystatechange \nmethod is used to detect a state change in the data and trigger the data exchange with the server. \n Like any other front-end program, the AJAX script creates a request to run a transaction. The subsequent \ncontrol ﬂ ow depends on whether the application uses one resource manager, many resource managers, or \nmultiple tiers. Some applications simply connect the web tier to the database tier, so no independent transac-\ntion manager is needed. Others introduce tiers in between, some of which may need to control transactions. \nStill others may introduce a business process layer, which also controls transactions. Each of these back-end \ndesigns requires transactional middleware functionality to glue it together. This can be implemented using the \n.NET Framework and/or  Java-EE-based transactional middleware products, which are the subjects of the next \ntwo sections. \nTransfer\nFrom Account\nTo Account\nTransfer Amount\nFrom Balance\nTo Balance\nCustomer ID\n FIGURE 10.2 \n Simple Web Browser Form. The left boxes are labels. The user types the customer ID, transfer accounts, and transfer \namount as input and receives the updated account balances in the shaded boxes as output. \n",
      "content_length": 3047,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 304,
      "content": " 10.3  .NET FRAMEWORK \n Microsoft ’s .NET Framework provides a complete environment for developing and deploying multitier TP \napplications, including: \n ■  Windows Presentation Foundation (WPF), ASP.NET, and Silverlight for developing PC-based or \nbrowser-based front-end programs. \n<script type=“text/javascript”>\nvar fep = null;\nif(navigator.appName == “Microsoft Internet Explorer”) {\n  fep = new ActiveXObject(“Microsoft.XMLHTTP”);\n} else {\n  fep = new XMLHttpRequest();\n}\nfunction transfer(Customer) {\n fep.open(“POST”, “document”+CustomerID, FromAccountNo, ToAccountNo, \n          TransferAmt, true);\n fep.onreadystatechange=function() {\n   if(fep.readyState == 4) {\n      document.getElementById(‘account1Balance’).innerHTML = fep.responseText1\n      document.getElementById(‘account2Balance’).innerHTML = fep.responseText2;    \n}\n  }\nfep.send(document);\n}\n</script>\n<h1>Transfer</h1>\n<form>\n  <input type=“text” />\n  <div id=“Customer”>\n  </div>\n  <input type=“int” />\n  <div id=“FromAccountNo”>\n  </div>\n  <input type=“int” />\n  <div id=“ToAccountNo”>\n  </div>\n  <input type=“int” />\n  <div id=“TransferAmt”>\n  </div>\n  <input type=“int” />\n  <div id=“FromAccountBalance”>\n  </div>\n  <input type=“int” />\n  <div id=“ToAccountBalance”>\n  </div>\n</form>\n FIGURE 10.3 \n Sample AJAX Program for Browser-Based Funds Transfer Operation. The AJAX program is divided between its related \nJavaScript and HTML elements. After it detects the user input, it obtains the changed information from the form, sends \nit asynchronously to the web server, and then displays the results. \n10.3 .NET Framework  285\n",
      "content_length": 1604,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 305,
      "content": "286  CHAPTER 10 Transactional Middleware Products and Standards\n ■  Windows Communication Foundation (WCF) and the Internet Information Server (IIS) for developing \nand deploying request controllers and transaction servers. \n ■  Host Integration Server (HIS) and BizTalk Server adapters for integration with legacy environments. \nIn some instances of the multitier architecture, the transaction server and/or  resource manager can be \nhosted within a legacy environment. Interoperability tools such as these can include them into the .NET \nFramework environment. \n ■  Windows Workﬂ ow Foundation (WF) and WS-BPEL support in BizTalk Server for creating and execut-\ning business processes, including those that combine multiple services. \n Except for HIS and BizTalk Server, these components are bundled into Windows operating systems, start-\ning with the Vista release. Most components are also available as downloads for prior versions of Windows. \n Figure 10.4 shows that a front-end program can be written to run in a web browser and connect to a web \nserver acting as a request controller. Or it can connect directly to the database acting as a web server (not shown) \nor transaction server. \n A native PC program created using WPF can also connect to a web server. Or it can communicate directly \nwith either a request controller or a transaction server. Similarly, a Web Services client can communicate \ndirectly with an application process or the database (not shown in the ﬁ gure). \n A request controller can be developed to run in a web server or as an application process using WCF. A \ntransaction server can be implemented to run as an application process using WCF or as a stored procedure in \na database system. \n An application developed using the .NET Framework transactional middleware components can therefore \nimplement a two-tier, three-tier, or multitier architecture to meet scalability, availability, and other TP applica-\ntion requirements. \n Any server-side component or combination of components can use the transaction management capabilities \nof the platform through either the implicit or explicit programming models, either with or without using WCF. \n A variety of deployment functions also are supported to meet TP application requirements for scalabil-\nity, availability, and reliability. These include Windows operating system services, IIS application spaces, and \nWindows Server clusters. \nBrowser\nFront-End\nProgram:\nSilverlight,\nASP.NET or\nAJAX    \nPC\nFront-End\nProgram:\nWPF,\nSilverlight, or\nWeb services\nWeb Server\nRequest\nController\nProgram \nStored\nprocedures\nacting as\ntransaction\nserver\nPersistence\nTier\nApplication\nProcess\nRequest Controller\nand Transaction\nServer Programs:\nWCF\nADO.NET\nEntities \nDatabase \n FIGURE 10.4 \n .NET Framework Multitier Transactional Middleware Architecture. The components of the .NET Framework multitier \narchitecture provide multiple options for developing and deploying front-end programs, request controllers, and \ntransaction servers. \n",
      "content_length": 3009,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 306,
      "content": " A WCF program can use Web Services standards to interoperate with a legacy TP monitor or Java-based \nproduct, such as a Java-EE-compliant application server. \n Developing Front-End Programs \n In the .NET Framework the technologies used for front-end programs include: \n ■  Windows Presentation Foundation for PC- or browser-based GUIs \n ■  ASP.NET and Silverlight for web browser-based GUIs \n The Windows Presentation Foundation (WPF) provides a comprehensive environment for developing front-\nend programs that implement menus and forms with high levels of interactivity, control, and graphical capabil-\nity. WPF is intended to consolidate and replace prior generations of Windows-based graphical user interface \n(GUI) frameworks. WPF also can be used to create a GUI that runs in a web browser. \n ASP .NET provides a complete development and deployment environment for web-based applications. A sec-\nond option, Silverlight, provides a subset of WPF and .NET for cross-platform use; that is, for multiple operating \nsystems and web browsers. \n Windows Presentation Foundation \n WPF uses  XAML ( Extensible Application Markup Language , pronounced  “ zammel ” ), which is an XML \nsyntax for initializing structured values. In WPF, these structured values deﬁ ne components of a GUI. WPF \ncommands are expressed using XAML, or alternatively using a CLR-based programming language such as C# \nor Visual Basic (VB). \n Front -end programs developed using XAML commands can be deployed in a browser or in a native PC \nenvironment, which Microsoft calls a standalone application. A standalone application can be hosted in its \nown window or in a special window provided by WPF that offers basic navigation features. WPF can directly \naccess data in a database or other resource. The .NET Framework provides several options for this, including \nADO.NET, LINQ (Language-Integrated Query), and various mechanisms to execute a stored procedure in SQL \nServer (see Section 10.5 for further information). WPF also can be used in combination with WCF to connect \nto request controllers and transaction servers in a multitier architecture. \n A complete front-end program requires a combination of a XAML markup ﬁ le to deﬁ ne the display char-\nacteristics, a CLR-based program for the execution logic, and a conﬁ guration ﬁ le to bind the display charac-\nteristics to the program. The conﬁ guration ﬁ le generates an executable ﬁ le for deployment in the target hosting \nenvironment (Visual Studio, standalone, or web browser). \n Figure 10.5 illustrates a simple front-end program snippet deﬁ ned using WPF. XAML commands exist \nwithin the XAML namespace. The XAML commands are contained within a top-level structure called a  page , \n<Page \n  xmlns=“http://schemas.microsoft.com/winfx/2006/xaml/presentation”\n  xmlns:x=“http://schemas.microsoft.com/winfx/2006/xaml”\n  x:Class=“Transfer.HomePage”\n  WindowTitle=“Transfer Funds”\n  Title=“Transfer - Home” \n  WindowWidth=“550” WindowHeight=“380”>\n</Page>\n FIGURE 10.5 \n Simple XAML Commands for WPF. These sample XAML commands deﬁ ne a form title and the form’s position on the screen. \n10.3 .NET Framework  287\n",
      "content_length": 3148,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 307,
      "content": "288  CHAPTER 10 Transactional Middleware Products and Standards\n which is similar to an operating system window or a web page. The top-level page is called a  home page , \nwhich in the example is the  Transfer page. A single front-end program can have multiple pages correspond-\ning to multiple display panels for additional menus and forms. \n The display panel deﬁ ned by the home page in the example is given the title  “ Transfer Funds. ” The \n Transfer class is set as the namespace for all subpages and programs associated with this display. The dis-\nplay width and height are speciﬁ ed in pixels. Additional controls typically are added to deﬁ ne ﬁ elds and but-\ntons and to map data into and out of the page. For example, input ﬁ elds could be added in C# to capture the \nuser’s bank account numbers and transfer amount for an update operation. \n The C# snippet in  Figure 10.6 illustrates a program associated with the  Transfer home page. Additional \nC# logic typically is added to handle GUI events, such as what steps to perform on a button click or pressing \nEnter. In WPF terminology this is called a  code behind ﬁ le to handle events deﬁ ned in the XAML ﬁ le. The code \nbehind ﬁ le is merged with the code generated by processing the XAML deﬁ nitions. For example, the XAML \nsteps would obtain from the user the account number and amount to transfer between bank accounts and the C# \ncode would execute the actual transfer operation. A build step combines any XAML ﬁ les and associated C# ﬁ les \ninto an executable that can be run from a command line or within Visual Studio for testing and debugging. \n The .NET Framework environment supports the use of multiple approaches for front-end program con-\nstruction. In particular, a front-end program developed independently of .NET can use standard HTTP, the \nREST/HTTP protocol, or another Web Service invocation mechanism compatible with WCF to invoke a .NET \nFramework request controller or transaction server. \n ASP.NET and Silverlight \n ASP .NET supports the development and deployment of web-based applications, including components to cre-\nate a GUI for a web browser and a hosting environment in the IIS web server for processing requests. ASP.\nNET applications can be developed using any CLR-based language and can use any of the classes in the .NET \nFramework, including capabilities for security, transactions, and system administration. ASP.NET also sup-\nports Web Services development and deployment. \nusing System;\nusing System.Windows;\nusing System.Windows.Controls;\nusing System.Windows.Navigation;\nnamespace Transfer\n{\n    public partial class HomePage : Page\n    {\n        public HomePage()\n        {\n            InitializeComponent();\n            void Button(object sender, FormInput e)\n        }\n    }    \n}\n FIGURE 10.6 \n Sample C# Class Associated with a WPF Page. The C# code is merged with code generated from the corresponding \nXAML ﬁ le, for example to implement a button object that submits form input data. \n",
      "content_length": 2999,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 308,
      "content": " Silverlight is used similarly to WPF to develop front-end programs that can be used natively on Windows \nor with any web browser. Silverlight programs can be included within static HTML ﬁ les and server-generated \npages (e.g., using PHP, Python, or Ruby scripts). Like WPF, Silverlight programs include XAML ﬁ les and \ncode in the form of class ﬁ les that are associated with the XAML ﬁ les. \n Silverlight supports a JavaScript/AJAX programming model and a cross-platform, cross-browser version of \nthe .NET Framework. This allows developers of front-end programs to write Silverlight applications using any \n.NET language (including VB, C#, JavaScript, IronPython, and IronRuby) and deploy it on a range of operating \nsystems and web browsers. Silverlight supports REST, Web Services, XML over HTTP, RDF Site Summary \n(RSS), and standard HTTP communication protocols for interaction with web servers and WCF services. \n Developing Request Controllers and Transaction Servers \n WCF provides a set of capabilities that can be used to connect a front-end program to a request controller or \ntransaction server developed using the .NET Framework. WCF implements a service-oriented interaction model \nthat can be conﬁ gured for CLR objects created using Visual Basic .NET and C#. Many of the WCF libraries \nare also available to programs created using C \u0005 \u0005 , J#, and JScript. WCF supports both implicit and explicit \ntransaction programming models and works with all Microsoft SQL Server versions and ADO.NET compliant \nresource managers. WCF also includes .NET libraries that work with COM and COM \u0005 components. \n For communications WCF supports a variety of conﬁ gurable messaging models and data formats, includ-\ning native remote procedure call (RPC), Web Services, and asynchronous queuing (using Microsoft Message \nQueuing). WCF also supports custom-developed protocols and formats. \n A WCF service requires an explicit  contract , which is an interface to a .NET Framework object. The inter-\nface must be associated with an executable class ﬁ le that contains the program logic. It must also be associated \nwith a binding that speciﬁ es the data format, communication protocol, and additional characteristics of the com-\nmunication session (such as reliability, security, or transaction propagation) for the operations in the interface. \n A WCF interface describes a service that can be invoked remotely and deﬁ nes any additional distrib-\nuted computing characteristics for each method. For example, the interface shown in  Figure 10.7 is called \n[ServiceContract]\nInterface ITransfer\n{\n     [OperationContract]\n      void AccountBalance (decimal AccountNumber, decimal);\n     [OperationContract]\n      void WithdrawAccount (decimal AccountNumber, decimal Amount);\n     [OperationContract]\n      void DepositAccount (decimal AccountNumber, decimal Amount);\n     [OperationContract]\n      void Transfer(decimal FromAccountNumber, decimal ToAccountNumber, \n                   decimal Amount);\n}\n FIGURE 10.7 \n WCF Interface Deﬁ nition. An interface that exposes a service remotely is a core feature of WCF. Multiple bindings can be \nconﬁ gured for an interface, including Web Services and native. \n10.3 .NET Framework  289\n",
      "content_length": 3227,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 309,
      "content": "290  CHAPTER 10 Transactional Middleware Products and Standards\n ITransfer and includes four methods:  AccountBalance ,  WithdrawAccount ,  DepositAccount , and \n Transfer . The interface is marked as a service using  [ServiceContract] , and each method in the ser-\nvice is marked as being remotely accessible using  [OperationContract] . Not all methods have to be made \navailable remotely, but when they are they must be tagged with the  [OperationContract] attribute. \n Transactions \n Three main attributes affect the transaction behavior of a method: \n ■  TransactionFlowOption is speciﬁ ed on the interface to the method and tells whether the method will \naccept a transaction context propagated from its caller. \n ■  TransactionScopeRequired property of the  OperationBehavior attribute is speciﬁ ed on an \nimplementation of the method and tells whether the method must execute within a transaction. \n ■  TransactionFlow is speciﬁ ed on the binding that the caller uses to invoke the method and tells \nwhether the caller’s transaction context can ﬂ ow across the binding. \n The  [TransactionFlow] attribute on an interface has three possible values:  Mandatory ,  Allowed , and \n NotAllowed . The  Mandatory attribute shown in  Figure 10.8 indicates that the  WithdrawAccount operation \nmust receive a transaction context when invoked by another method.  Allowed means that the service accepts \na transaction context if one is received with the message, but it does not require the message to contain one. \n NotAllowed is the default and means that the service ignores a propagated transaction context. \n An annotated class implements a WCF interface deﬁ nition. The class deﬁ nes the execution logic for each of \nthe methods listed in the service, such as methods that access a database, do computation, or invoke other ser-\nvices. The  TransactionScopeRequired attribute on each method is set to  true or  false , indicating whether \nor not the operation must be executed within a transaction. For example, in  Figure 10.9 the  WithdrawAccount \n[OperationContract]\n     [TransactionFlow(TransactionFlowOption.Mandatory)]\n      void WithdrawAccount(int AccountNumber,int Amount);\n FIGURE 10.8 \n Using the TransactionFlow Attribute to Require Propagation. Adding attributes to the WCF interface controls transaction \npropagation. \nclass TransferService : Transfer\n{\n    [OperationBehavior(TransactionScopeRequired = true)]\n     public void WithdrawAccount (int accountNumber, decimal amount)\n} \n{\n    [OperationBehavior(TransactionScopeRequired = true)]\n     public void DepositAccount (int accountNumber, decimal amount)\n      ...\n}\n FIGURE 10.9 \n Deﬁ ning the Object Class for the Interface. Each operation in a WCF interface has a method in a corresponding object \nclass for its implementation. \n",
      "content_length": 2805,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 310,
      "content": " and  DepositAccount methods have a  TransactionScopeRequired attribute of  true , so they must always \nexecute in the context of a transaction. \n Suppose the binding between the caller and the service indicates that the caller’s transaction context can ﬂ ow \nacross the binding (details are in the next section). The combination of values for  TransactionFlowOption \nand  TransactionScopeRequired lead to a variety of possible behaviors. For example: \n ■  If the caller is executing a transaction, the  TransactionFlowOption on the method is  Mandatory \nor  Allowed , and  TransactionScopeRequired is  true , then the method executes in the caller’s \ntransaction. \n ■  If the caller is executing a transaction, the  TransactionFlowOption is  NotAllowed , and \n TransactionScopeRequired is  true , then the method executes in a new transaction. \n ■  If the caller is  not executing a transaction and  TransactionScopeRequired is  true , then the method \nexecutes in a new transaction, no matter what value is speciﬁ ed for  TransactionFlowOption . \n Transaction termination depends on the successful completion of each method executed within the transac-\ntion. That is, a transactional object is considered a participant in the transaction and must provide a comple-\ntion vote for the transaction to commit. If the  TransactionAutoComplete attribute is  true (which is the \ndefault), then the transaction is completed automatically if it exits without throwing an unhandled exception. \nSuch an exception means the transactional object will vote to abort. \n A one-way ﬂ ow (i.e., a one-way asynchronous message exchange) is not allowed to propagate a transaction \ncontext, although a correlated request/reply message exchange using an asynchronous communication protocol \nis allowed to propagate a context. \n So far nothing has indicated which wire format is used. The type of transaction context is speciﬁ ed in the \nWCF binding. \n Bindings \n Internally , WCF is based on the  chain of responsibility architecture, in which a series of  handlers (some-\ntimes called  interceptors ) are inserted into the call chain between client and server, including a handler that \npropagates transaction context for a remote service. The chain of responsibility pattern can be implemented as \nan extension to the RPC mechanism. When the proxies and stubs are generated from the interface, the code for \nthe handlers is inserted into the call chain to implement any additional characteristics associated with the inter-\nface deﬁ ned using conﬁ guration metadata. Handlers are inserted into the call chain in a predetermined order, \naccording to the type of functionality they provide. For example, a message serialization handler must execute \nbefore a handler that dispatches the serialized message onto the communications protocol. \n The call chain handlers in WCF are called  channels and are visible to developers in collections called \n bindings . A binding is basically a collection of related channels designed to fulﬁ ll a speciﬁ c task, such as \ntransmit a Web Services request using HTTP. A binding contains an ordered collection of  binding elements , \nsuch as the  TransactionFlowBindingElement in a transaction propagation channel. The various commu-\nnication and transaction propagation capabilities offered by WCF therefore are expressed in the collection of \navailable channels. Custom bindings can also be deﬁ ned. A local optimization of a WCF binding is used when \nservices are deployed into the same address space. \n An extended HTTP binding,  WSHttpBinding , shown in  Figure 10.10 , is used for messages that need bind-\ning elements for SOAP headers deﬁ ned in extended Web Services speciﬁ cations such as WS-Security for mes-\nsage-based security, WS-ReliableMessaging for reliable message exchange, and WS-AtomicTransaction for \ntransaction context propagation. A simpler HTTP binding,  BasicHttpBinding , which is aimed at WS-I Basic \nProﬁ le conformance, is used to transmit a basic SOAP-formatted message over HTTP. In the simpler binding, \nHTTP security is used for basic encryption, authentication, and authorization, and transactions are not supported. \n10.3 .NET Framework  291\n",
      "content_length": 4194,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 311,
      "content": "292  CHAPTER 10 Transactional Middleware Products and Standards\n The example in  Figure 10.11 illustrates a conﬁ guration for the  Transfer service. The executable service \nlogic, interface contract, and communications binding are combined in an  endpoint deﬁ nition. The endpoint \nidentiﬁ es the executable ﬁ le for the service as  TransferService.svc and gives its network address as a URL. \nThe service uses the  WSHttpBinding for the interface contract  ITransfer , and a  TransactionalHTTP bind-\ning conﬁ guration, which will propagate the transaction context using WS-AtomicTransaction. \n WCF also offers a binding, called  NetTcpBinding, for directly sending a binary message over TCP/IP. The \nmessage format is optimized for internal communications and available for use only among WCF services. The \n NetTcpBinding supports transaction propagation and a conﬁ gurable selection of formats for the transaction con-\ntext. The format choices include OLE Transactions, WS-AtomicTransaction 2004, or WS-AtomicTransaction 1.1. \n A WCF service can be conﬁ gured to support multiple bindings and thus multiple communication protocols \nand data formats. For example, a developer may want to publish a service over  NetTcpBinding for optimized \nWCF-WCF communications and over  WSHttpBinding to allow access from external Web Services clients. \nThis simply requires specifying multiple bindings for the service in its associated endpoint conﬁ guration ﬁ le. \nTo propagate transaction context, however, it’s always necessary to choose a transactional binding; that is, one \nthat can include a  TransactionFlowBindingElement . \n The code in  Figure 10.12 illustrates a WCF service endpoint that uses two bindings,  TransactionalTCP \nand  TransactionalHTTP . This makes  TransferService available over each protocol on a different port \nnumber (8001 and 8002, respectively). In the binding deﬁ nitions for  NetTCPBinding and  WsHttpBinding , \nthe  transactionFlow attribute is set to  true (the default is  false ). In this case both bindings are transaction-\naware and the ﬂ ow attribute requires transaction context to propagate. In other words, the  TransferService is \nconﬁ gured to accept a transactional service invocation over both TCP and HTTP. The TCP channel will receive \nOLE-Transactions context and the HTTP channel will receive WS-Transaction ’ s WS-AT context. \nTCP/IP \nWCF\nService\nRequester \nWCF\nService\nProvider\nChannel (WS-\nAtomic Transaction)\nChannel (SOAP) \nChannel (HTTP) \nChannel (WS-\nAtomic Transaction)\nChannel (SOAP) \nChannel (HTTP) \nWSHttpBinding \nWSHttpBinding \n FIGURE 10.10 \n WCF Bindings Consist of a Collection of Channels. The  WSHttpBinding combines channels for Web Service \ntransaction context propagation, message formatting, and transport. \n<endpoint \n    address  = “http://localhost:8002/TransferService.svc”\n               bindingConfiguration = “TransactionalHTTP”\n               binding  = “wsHttpBinding”\n               contract = “ITransfer”/>\n FIGURE 10.11 \n Endpoint Deﬁ nition for a WCF Service. The endpoint deﬁ nition maps an interface to one or more bindings, such as \n WSHttpBinding for transactional Web Services. \n",
      "content_length": 3162,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 312,
      "content": " Discussion \n The implicit programming model was ﬁ rst implemented in .NET as a single attribute associated with an inter-\nface that applied to all methods of the interface. The attribute deﬁ ned both how the method would handle a \ntransaction context when invoked, and whether or not the method would create a new transaction if it did not \nreceive a context on the invocation. That is, a single setting controlled whether or not a method would accept \na transaction context propagation and whether or not the called method would create a new transaction if it \ndidn’t receive one. This is still the model use in Java EE. \n This changed in WCF. First, attributes are associated with individual methods, not the entire interface. \nSecond, WCF uses separate attributes to demarcate a transaction and to control the propagation of transaction \ncontext. This allows a potential separation of roles between a developer and system integrator. A developer \nwants to require that his method executes in a transaction because it accesses transactional resources. But he \nwants to allow the method to be called by another method that is already operating inside a transaction. He \ndoes not necessarily want to deﬁ ne an exception handler, because the exception handler’s behavior may be dif-\nferent depending on whether the transaction is demarcated by his method or a method that invokes his method. \n<?xml version = “1.0” encoding = “utf-8” ?>\n<configuration>\n   <system.serviceModel>\n      <services>\n         <service name = “TransferService”>\n            <endpoint\n               address = “net.tcp://localhost:8001/TransferService/”\n               bindingConfiguration = “TransactionalTCP”\n               binding  = “netTcpBinding”\n               contract = “ITransfer”\n            />\n            <endpoint\n               address  = “http://localhost:8002/TransferService/”\n               bindingConfiguration = “TransactionalHTTP”\n               binding  = “wsHttpBinding”\n               contract = “ITransfer”\n            />\n         </service>\n      <bindings>\n         <NetTcpBinding>\n            <binding name = “TransactionalTCP”\n               transactionFlow = “true”\n            />\n         </NetTcpBinding>\n         <WsHttpBinding>\n            <binding name = “TransactionalHTTP”\n               transactionFlow = “true”\n            />\n         </WsHttpBinding>\n      </bindings>\n   </system.serviceModel>\n</configuration>\n FIGURE 10.12 \n Conﬁ guration File Example for WCF Services. Transactional bindings for both binary and HTTP-based protocols can be \nconﬁ gured for the same service, using different port numbers. \n10.3 .NET Framework  293\n",
      "content_length": 2651,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 313,
      "content": "294  CHAPTER 10 Transactional Middleware Products and Standards\n Consider a system integrator who is reusing an existing transactional method  M in a larger application. He or \nshe may need to control whether  M executes in the context of the caller’s transaction. For example, if  M logs a \nsecurity violation, it needs to run as a transaction, which the developer of  M can specify. The system integrator \nneeds to control whether or not the security violation will be logged even if the caller’s transaction aborts. He or \nshe can do this by deciding whether or not the caller’s transaction context is propagated to  M . If so, then  M will \nrun in the caller’s transaction. If not, then  M will run as a top-level transaction and commit independently of the \ncaller. The system integrator can conﬁ gure two different callers so that one propagates transaction context and the \nother doesn’t. \n In the earlier model, the decisions of transaction demarcation and context propagation were linked. That is, \na single attribute controlled whether  M executes as a transaction and whether it executes in the context of the \ncaller’s transaction. In WCF, these decisions are made separately. \n REST/HTTP Support \n REST /HTTP support in NET is provided using enhancements to WCF, including templates for constructing \nand using URLs with HTTP verbs, and attributes for deﬁ ning REST-based operations in a WCF interface. \nWCF provides a nontransactional binding for REST/HTTP style services called  WebHttpBinding . \n WCF Deployment Options \n WCF supports several hosting options, including IIS running on Windows Server clusters for scalability and \navailability. For production, one option is to use a Windows hosted  “ service ” (not to be confused with a WCF \nservice). WCF programs can also be hosted using IIS worker processes. Or they can be included in ASP.NET \napplications. \n Initially , the IIS hosting environment was available only for HTTP-based communications. As of the Windows \nVista release, the application hosting environment portion of IIS is packaged separately, so it can now accept \nincoming requests over any communication protocol that WCF supports. \n In a Windows Server cluster environment, it’s possible to conﬁ gure the transaction manager to manage trans-\nactions centrally or per machine. When conﬁ gured per machine, if one machine fails, then a transaction manager \non another machine can assume responsibility for coordinating transactions for the failed machine’s transaction \nmanager. A clustered transactional application must use a cluster-aware transaction manager to ensure correct \nresults and meet availability requirements. In general, performance is improved by colocating the transaction \nmanager in a cluster with the resource manager(s) being coordinated. \n Transaction Management Using  System.Transactions \n The runtime infrastructure for creating transactional services and objects in the .NET Framework is delivered \nin the  System.Transactions API. The API supports both implicit and explicit transaction programming \nmodels, either for .NET programs running on their own or for those deﬁ ned within WCF. The .NET transaction \nmanagement infrastructure uses a context called an  ambient transaction , which is created for any Windows \noperating system thread that runs transactional code. If an ambient transaction already exists when an object \nneeds a transaction context, then the existing ambient transaction is used. If not, then a new one is created. \n Two transaction managers are used in .NET. The general-purpose transaction manager for transactions that \nuse multiple resource managers (RMs) is the Microsoft Distributed Transaction Coordinator (DTC). There is \nalso the Lightweight Transaction Manager (LTM), which can handle any number of volatile resources and at \nmost one persistent resource. LTM is cheaper than DTC because it doesn’t require a log. \n",
      "content_length": 3915,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 314,
      "content": " To minimize transaction overhead,  System.Transactions optimizes transaction coordination by attempting \nto use the LTM when possible. A transaction starts out being managed by LTM. If the transaction only accesses \nvolatile resources, then LTM coordinates the transaction. If the transaction accesses a persistent resource, such as \nSQL Server or the transactional NT File System (TxF), then an optimization strategy called  Promotable Single \nPhase Enlistment (PSPE) comes into play. It transparently promotes the lightweight in-memory transaction to \na persistent single-phase transaction. To coordinate the transaction, LTM commits the volatile resources and then \ntransfers commit coordination responsibility to the durable RM. If the transaction accesses a second durable RM, \npropagates the transaction to another process, or takes other actions that are beyond LTM’s ability to manage, \nthen LTM delegates the transaction coordination to DTC. \n SQL Server version 2005 and higher are compatible with PSPE and can therefore handle the delegation or \npromotion of control when a transaction is started by  System.Transactions . DTC supports any XA-compliant \nRM, such as Oracle Database and IBM’s DB2, and can include them within a DTC managed transaction. \n The Explicit Programming Model \n The explicit model in  System.Transactions incorporates transaction management APIs directly into appli-\ncation code. Developers use the methods in the  Transaction class to manage transactional behavior. Similar \nto the implicit programming model, the explicit programming model can be used in any .NET programming \nlanguage, within or outside of WCF. \n A typical approach to manage transactions explicitly is to set a transaction scope on a  using or  try block. \nAll operations on data within the block execute within the scope of the transaction. This includes any methods \ncalled from within the block, unless explicitly excluded. \n An example is shown in  Figure 10.13 . The  TransactionScope() object is instantiated within a  using \nblock, and the  AccountDeposit operation within the block is contained within the transaction. Instantiating \na  TransactionScope() object starts a new transaction or joins an ambient transaction, if one exists. The \ndefault  TransactionScopeOption is  Required . In the explicit model, the transaction is completed using \nthe  complete method instead of using the  Autocomplete attribute. However, the result is the same — the \ntransaction is committed if all participants vote complete and the execution of all methods is successful (i.e., \nno unhandled exceptions are thrown). \n The  System.Transactions explicit model API also can be used to bracket multiple SQL connections. \nIn  Figure 10.14 a new transaction scope is created explicitly. The ﬁ rst  using block creates an initial SQL \nusing (TransactionScope tx = new TransactionScope())\n{\n  //...\n  AccountCredit = 100.00M;\n  AccountID = 77392;\n  AccountDeposit(AccountID, AccountCredit);\n  //...  \n  \n  tx.Complete();\n}\n FIGURE 10.13 \n Explicit Transaction Management Using  TransactionScope() . The  TransactionScope() class code snippet \nshown picks up an existing ambient transaction or initiates a new transaction and votes to successfully complete the \ntransaction if no exception is thrown. \n10.3 .NET Framework  295\n",
      "content_length": 3322,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 315,
      "content": "296  CHAPTER 10 Transactional Middleware Products and Standards\n connection that executes an  insert command. A second  using block creates a second SQL connection that \nexecutes an  update command. After both SQL commands complete successfully, the  scope.complete() \noperation indicates the work of this method is done, and the method is prepared for the transaction to be com-\nmitted. For simplicity, exception handling logic that typically is added to the  using blocks has been omitted. \n The  TransactionScopeOption  choices are: \n ■  Required : Join the existing ambient transaction, or create a new one if one does not exist. \n ■  RequiresNew : Create a new transaction whether or not an ambient transaction was present. \n ■  Suppress : Execute outside the scope of a transaction, that is, suppress the ambient transaction. \n A transaction context is associated with a scope object created when a transaction is initiated. The decision \nto create a new transaction depends on the  TransactionScopeOption attribute deﬁ ned for the object. \n The explicit programming model offered by  System.Transactions allows a developer to control trans-\naction bracketing without decomposing transactions into separate methods. It also offers more control over the \ndetails of transaction management, such as getting and manipulating the transaction context and logging trans-\naction IDs. For example, a program can obtain a reference to the ambient transaction context as follows: \n Transaction ambientTransaction  \u0003 Transaction.Current; \n This enables a program to pass its ambient transaction to another party. The ambient transaction can be \nchanged by setting  Transaction.Current , which enables a program to control its transaction context explicitly. \nusing (TransactionScope scope =\n    \n  new TransactionScope(TransactionScopeOption.Required))\n{\n    using (SqlConnection connection =\n        new SqlConnection(connectionString))\n    {\n        SqlCommand command = connection.CreateCommand();\n        command.CommandText = “Insert....”;\n        \n        connection.Open();\n        command.ExecuteNonQuery();\n        connection.Close();\n \n using (SqlConnection connection2 = \n          new SqlConnection (connectionString)\n       {\n         SqlCommand command2 = connection2.CreateCommand();\n         command2.CommandText = “Update....”;\n         connection.Open();\n         \n         command2.ExecuteNonQuery(); \n       }\n    }\n    scope.Complete();\n}\n FIGURE 10.14 \n Bracketing Multiple SQL Connections. In this example, nested  using blocks are deﬁ ned to connect to two SQL \ndatabases and coordinate a transaction across both. \n",
      "content_length": 2634,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 316,
      "content": " Integration with Legacy TP Monitors \n The .NET Framework includes the Microsoft Host Integration Server to access CICS and IMS transactions \nand DB2 databases. BizTalk Server Adapters for Host Systems can be used to integrate with other existing \nsystems and legacy TP monitors. The Line of Business adapter toolkit in WCF and BizTalk Server can be used \nto develop a custom adapter where no packaged adapter exists. \n Transactional integration with existing systems and legacy TP monitors is offered speciﬁ cally for CICS and \nIMS using a two-phase commit bridge between DTC and mainframe transaction managers using the LU6.2 \nprotocol in the Host Integration Server product. Transactional integration also is offered generically via Web \nServices transactions in WCF and XA support in DTC, both of which can also be used with BizTalk Server. \nExisting systems also can be wrapped using Web Services and accessed via WCF, either standalone or together \nwith BizTalk Server. \n Host Integration Server offers a direct connection to DB2 databases from the .NET Framework. Programs \nthat access mainframe transactions from the .NET Framework can be developed using Visual Studio, includ-\ning the ability to import metadata from legacy environments in the form of COBOL Copy Books and RPG \ndata deﬁ nitions. A data access tool provides a mapping to the DB2 data sources. It’s also possible to manage \ndatabase connections to mainframe databases from the .NET Framework environment and integrate them with \nconnections to SQL Server data sources. \n Host Integration Server also supports an option for using IBM 3270 terminal communications protocol \nover TCP/IP. \n 10.4  JAVA ENTERPRISE EDITION \n Java Enterprise Edition (Java EE) refers to an umbrella speciﬁ cation that groups 79 API speciﬁ cations (as of \nJava EE 5) designed for enterprise computing applications such as transaction processing. Java EE API features \nwork together to provide a complete environment for developing and deploying TP applications, including: \n ■  The Swing Library, Servlets, Java Server Pages, and Java Server Faces for developing front-end programs, \nincluding interactive menu and forms capabilities for web browsers and native PC and UNIX programs \n ■  Enterprise Java Beans (EJBs), a distributed computing component model for developing request control-\nlers and transaction servers that support a variety of front-end programs \n ■  The Java Persistence API (JPA), a lightweight object-relational mapping integrated with EJBs to interact \nwith persistent entities stored in a relational database \n ■  The Java Connector Architecture (JCA) API, a programming environment for integration with legacy \nsystems that includes a standard client and adapter toolkit \n ■  The Java Transaction API (JTA), an infrastructure and programming environment for transaction man-\nagement, used in both the implicit and explicit programming models for Java EE \n ■  A WS-BPEL engine for business process management, which is also provided by most Java EE vendors \n Java EE is deﬁ ned through the Java Community Process, a consortium of Java vendors chaired by Sun \nMicrosystems. Java EE originally was released in December 1999, and has gone through several iterations since \nthen. Its original name was Java 2 Enterprise Edition, or J2EE, which was changed to Java EE as of its fourth \nrelease, called Java EE 5. A major difference between the enterprise edition and the standard edition of Java is \nthe addition of EJBs. The current version, EJB3, represents a signiﬁ cant change from earlier versions of EJB \n(1.1 through 2.1), with a lighter weight container, JPA in place of entity beans, and the use of Java 5 annotations \nfor transaction demarcation and other EJB functions. \n10.4 Java Enterprise Edition  297\n",
      "content_length": 3783,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 317,
      "content": "298  CHAPTER 10 Transactional Middleware Products and Standards\n Java EE APIs are delivered in Java-EE-compliant application server products from IBM, Oracle, Red Hat, \nand others. Java-EE-compliant vendors must pass a set of conformance tests to receive a certiﬁ cation from the \nJava Community Process, which indicates that the vendor has successfully implemented each of the required \nAPIs. Examples of certiﬁ ed products include IBM’s WebSphere Application Server, Oracle’s WebLogic \nApplication Server, and Red Hat’s JBoss Application Server. These products are available on UNIX, Windows, \nand zOS operating systems. Java-EE-compliant application servers typically include vendor-speciﬁ c mecha-\nnisms for server clustering and failover, sometimes including state caching and replication. However, these \nfeatures are not included in the Java EE APIs and are therefore beyond the scope of this book. \n In contrast to the Microsoft transactional middleware, which runs only on Windows operating systems, Java-\nbased transactional middleware runs on virtually any operating system. But operating system portability has its \ncosts. In particular, .NET Framework components are generally better integrated with the operating system than \nJava-based components. As might be expected, the speciﬁ c details of how to create and deploy transactional \nprograms with Java EE and the .NET Framework are different, even though the technologies and underlying \nconcepts are very similar. \n Figure 10.15 illustrates the relationships among the transactional middleware components of the Java \nEE architecture. It includes two types of front-end programs, those designed to run in a web browser and \nthose designed to run on a desktop PC or UNIX system. The Java EE architecture is very similar to the .NET \nFramework in this respect, but a signiﬁ cant difference is the presence of EJBs, which are programs and associ-\nated containers that were speciﬁ cally designed for use in TP applications. \n Typically , a browser-based front-end program communicates with the web tier, which in turn calls the EJB \ntier. The EJB tier then invokes one or more JPA entities at the persistence tier. An EJB may also use JCA to \ninvoke a back-end system, such as a legacy TP monitor, or may directly access a database using SQL com-\nmands through Java Database Connectivity (JDBC). \n The standard protocol for remote communication between the web tier and the EJB tier is the Java Remote \nMethod Invocation over the CORBA Internet Inter-Orb Protocol (RMI/IIOP). Other communication protocols \ncan also be used. SOAP over HTTP is supported from a Web Services client to the EJB tier. Java EE vendors \ntypically offer proprietary communications protocols and data formats speciﬁ cally tuned for their individual \nproducts. It is also fairly common practice for the web tier to communicate locally with the EJB tier. \nBrowser\nFront-end\nprogram\nwith Java\nServer\nPages \nPC\nFront-end\nprogram\nusing Swing\nor Web\nServices\nWeb Tier\nServlets, Java\nServer\nFaces\nStored\nprocedures\nacting as\ntransaction\nserver\nPersistence\nTier\nEJB Tier\nSession Beans \nJPA Entities\nDatabase \n FIGURE 10.15 \n Java EE Multitier Transactional Middleware Architecture. The components of the Java EE environment provide several \noptions for developing and deploying front-end programs, request controllers, and transaction servers. \n",
      "content_length": 3375,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 318,
      "content": " An application developed using Java-EE-compliant transactional middleware components can therefore \nimplement a two-tier, three-tier, or multitier architecture to meet scalability, availability, and other TP applica-\ntion requirements. For example: \n ■  When a web browser is used for the front-end program, a web server can function as the request control-\nler by including an EJB that routes the request to a transaction server program. \n ■  When a PC- or UNIX-based front-end program is used, the EJB tier can be used to fulﬁ ll the request \ncontroller function on its own, without a web server. \n ■  When multiple tiers are needed, EJBs can be used to fulﬁ ll both the request controller and transaction \nserver functions (including the persistence tier). \n ■  Stored procedures can also fulﬁ ll the transaction server function for web server hosted or plain EJB-\nbased request controllers. \n As in the .NET environment, both implicit and explicit transaction programming models are supported, and \nthe implicit model is recommended for most applications. \n Developing Front-End Programs \n In Java EE the technologies used for front-end programs include: \n ■  The Swing Library for PC- and UNIX-based GUIs \n ■  Servlets, Java Server Pages (JSP), and Java Server Faces (JSF) for web browser-based GUIs \n Swing is the name of a collection of libraries and functions used to develop highly interactive PC- and UNIX-\nbased front-end programs. The Swing Library is comparable to the .NET Framework’s WPF and Silverlight. \nLibrary functions deﬁ ne a screen’s area and layout, menus, scroll bars, tabs, buttons, sliders, tables, frames, tool-\nbars, and so on. The example in  Figure 10.16 uses the Swing libraries to display a table of information. As shown \nin the ﬁ gure, Swing classes can be used to construct a variety of GUI features. In this case the  JTable class is \nused to create a table of a customer’s accounts. Although the main program thread exits at the end of the example, \nSwing supplies a second thread that continues processing in the background to handle GUI components. \n A Java  servlet extends the capability of a standard web server to support dynamic content generation. The Java \nServlet API is an alternative to web server callout mechanisms such as Common Gateway Interface (CGI) scripts \nand web server APIs such as Apache API or ISAPI (IIS). Servlets handle HTTP sessions and route requests to Java \nobjects, EJBs, or databases. Servlets also handle REST and Web Services communications. The server can use any \ntechnique to maintain session state, typically using cookies or URL rewriting. All Java-EE-based application server \nproducts include a servlet engine. Apache Tomcat is an example of a popular standalone servlet engine. \n Java Server Pages (JSP) layer on servlets and replace static HTML and XML pages with dynamic content \ngenerated using JSP tags embedded in HTML or XML pages. The tags access and generate content that is then \nformatted into HTML or XML. When the page request is executed, a JSP is converted to a servlet for handling \nthe content to be displayed in the browser. \n The example in  Figure 10.17 illustrates the use of JSP tags to generate information within an HTML bulleted \nlist. When executed, the JSP tags dynamically generate the content for the bank name, the account balance, and \nthe current date of the web server access.  Java Server Faces (JSF) components are server-side controllers of \nbrowser-based menu and form components such as buttons, tables, and graphics. JSF and JSP technologies can \nwork together, for example when JSFs are used to create JSPs, and JSPs generate content for JSF-deﬁ ned menu \nand form elements. JSPs and JSFs can work in combination to drive server-side and client-side user interaction \nscenarios. For example, the JSF custom library can be used by the JSP to generate content and GUI elements for \nthe browser. \n10.4 Java Enterprise Edition  299\n",
      "content_length": 3950,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 319,
      "content": "300  CHAPTER 10 Transactional Middleware Products and Standards\n The example in  Figure 10.18 illustrates a simple form deﬁ ned using JSF tag libraries. The JSF component \nclasses maintain the component’s state and the rendering tags deﬁ ne how to render the content for the user. \nFor example, the  commandButton tag is rendered as a button. The example also illustrates a validation func-\ntion to check a username when the button is clicked. When a JSP is created using JSF, a tree of components is \nmapped into memory from which a response to a browser request is generated. \n REST Support \n REST support in Java EE environments is provided by the Java API for Restful Web Services (JAX-RS). JAX-\nRS deﬁ nes a set of annotations and interfaces that can be used in Java objects to expose them as RESTful web \nresources. JAX-RS objects can be deployed to either a standalone servlet engine or a servlet engine within a \nJava EE application server. JAX-RS enables front-end programs to call the objects using HTTP as the network \nprotocol, using HTTP content types to deﬁ ne the data formats. \nimport java.awt.*;\n       import javax.swing.*;\n  \npublic class SimpleTable extends JFrame {\n \n  \npublic SimpleTable() {\n \n \n  \nsuper(“Transfer”);\n \n \n  \nsetSize(300, 200);\n \n \n        setDefaultCloseOperation(EXIT_ON_CLOSE);\n                       JTable jt = new JTable(\n                         new String[][] { \n                         {“John Smith”, “Savings”, “100.0”} }, \n                         new String[] { “Customer”, “Account”, “Balance”} \n                       );\n \n \n \nJScrollPane scp = new JScrollPane(jt);\n \n \n \ngetContentPane().add(scp, BorderLayout.CENTER);\n \n        }\n \n \npublic  static void main(String args[]) {\n \n \n \nSimpleTable st = new SimpleTable();\n \n \n \nst.setVisible(true);\n \n        }\n}\n FIGURE 10.16 \n Code for a Java Swing-Based Table. The Swing client displays a list of accounts and balances for a customer. \n<UL>   \n  <LI> Web Bank name: ${account.bankName}   \n  <LI> Current Balance: ${account.balance} \n  <LI><B> JSP 1.2 expression: </B><BR>       \n   Current date: <%= new java.util.Date()%> \n</UL> \n FIGURE 10.17 \n JSP Tags Generate Content for an HTML List. JSP 2.0 tags inside an HTML list include an expression that ﬁ nds the web \nbank’s name, an account balance, and a directive that gets and displays the current date. \n",
      "content_length": 2362,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 320,
      "content": " Developing Request Controllers and Transaction Servers \n An  Enterprise Java Bean (EJB) refers both to a type of Java program designed for TP applications and to a \ncontainer within which such a program is deployed. An EJB abstracts transactional middleware functionality, \nsuch as threading, transaction control, and security. EJBs originally were designed for compatibility with legacy \nTP monitors, although the most popular implementations of EJBs have been written from scratch. EJBs have \nevolved signiﬁ cantly from their initial deﬁ nition. Compared to EJB2, EJB3 beans feature a lighter weight con-\ntainer, dependency injection, and Java 5 attributes for expressing conﬁ guration properties. \n In Java EE, a request controller can be developed for the web tier or the EJB tier. When developed for the \nweb tier, the request controller typically is implemented using a servlet engine running inside a web server, \nwhich routes the request to an EJB. The EJB can execute in the web server or in a separate process. \n EJB types include: \n ■  Session beans: Designed for hosting an interactive session with the front-end program. A session bean \ncan be stateless or stateful and can manage transactions. \n ■  Message-driven beans: Designed for interacting with asynchronous messaging systems that conform to \nthe Java Messaging Service (JMS) API. \n EJB2 deﬁ ned a third EJB type, an entity bean. Entity beans are preserved in EJB3 for compatibility with \nEJB2 applications. In EJB3, entity beans are replaced by JPA entities (covered next and in Section 10.6). \n An EJB can manage transactions and participate in transactional compositions. A message-driven bean can \nalso manage transactions, but cannot be composed into a transaction started by another bean. \n A session bean is allocated to a single instance of a front-end program and is terminated when the front-end \nprogram terminates. A stateful session bean maintains the state of its instance variables for the duration of its \ninteraction with the front-end program; a stateless session bean does not. \n Stateful session bean state is volatile and not transactional. For a web browser front-end program, ses-\nsion state management also can be provided by the  HttpSession object. For PC- or UNIX-based Swing cli-\nents stateful session beans are the only mechanism available to preserve in-memory conversational state across \nmultiple interactions between the front-end program and the request controller. \n As with any stateless design, the advantage of a stateless session bean is that the application server can maintain \na reusable pool of stateless session beans, allocate them to any request on demand, and deallocate them once a bean \nﬁ nishes executing the request. With a stateful bean the application server has to direct a subsequent call by a given \nfront-end program to the same bean instance so that it has access to the state of its conversation with the front end. \n<%@ taglib uri=“http://java.sun.com/jsf/html” prefix=“h” %>\n    <%@ taglib uri=“http://java.sun.com/jsf/core” prefix=“f” %>\n    <body bgcolor=“white”>\n    <f:view>\n    <h:form id=“Sign In Form”>\n    <h2>Username:</h2>\n   \n<h:inputText id=“username” value=“#{UserNameBean.userName}”\n            validator=“#{UserNameBean.validate}”/>\n   \n<h:commandButton id=“submit” action=“success” value=“Submit”/>\n    </h:form>\n    </f:view>\n FIGURE 10.18 \n JSF Components Prompt for a Username and Create a Submit Button. This JSF component prompts the user for his or her \nname and checks it with the server-side username validation program. \n10.4 Java Enterprise Edition  301\n",
      "content_length": 3612,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 321,
      "content": "302  CHAPTER 10 Transactional Middleware Products and Standards\n A stateless session bean can have a Web Service interface, allowing a Web Service client to invoke an EJB \nmethod. Web Services support is included in the Java EE speciﬁ cations through the inclusion of the Java API \nfor XML-Based Web Services (JAX-WS) speciﬁ cation. Therefore, all Java-EE-complaint application server \nproducts offer toolkits that generate a Web Service interface from an EJB interface. \n A session bean can query and update a relational database by using one or more JPA entities. The data \nmembers of a JPA entity are transactionally persistent, and a session bean can access that state by issuing oper-\nations on the JPA  EntityManager . Like a web server, however, a session bean also has the option to access \na database directly to execute embedded SQL or to invoke a stored procedure using JDBC. Direct database \naccess is commonly used in practice. \n A  bean implementation class is an ordinary Java class ﬁ le that contains the method implementations for \nthe EJB. An implementation class exposes a  business interface for remote and local access to business logic \nmethods. Restrictions on the Java class and methods used for an EJB ensure that everything works correctly \nwhen deployed within a container, such that they must be public, cannot be ﬁ nal, and cannot be abstract. \n A bean implementation class becomes an EJB by importing one or more EJB libraries and either including \none or more EJB annotations or declaring it an EJB in an associated descriptor ﬁ le (see  Figure 10.24 ). EJB anno-\ntations control the abstractions of the container and generate deployment metadata. As of EJB3 the embedded \nannotations can be used to generate the descriptor ﬁ le. As with entity beans, a manually coded descriptor ﬁ le \n(i.e., created without using annotations) is supported for backward compatibility with EJB2. In EJB3, the embed-\nded annotations typically are used to generate the deployment metadata, including any vendor-speciﬁ c variations. \n The EJB type annotations are: \n ■  @javax.ejb.Stateless \n ■  @javax.ejb.Stateful \n ■  @javax.ejb.MessageDriven \n The ﬁ rst two deﬁ ne a session bean as being either stateless or stateful. The third deﬁ nes a message-driven \nbean (i.e., one that interacts with JMS message queues). The  Stateless annotation is more commonly used \nthan  Stateful . In EJB3, the  @javax.ejb.entity annotation is used only to include an EJB 2.1 entity bean \ninto an EJB3-compliant application server. \n Other annotations specify transaction control, security, and how to handle messages and resources. Each of \nthe annotations other than the EJB type has a default value if not speciﬁ ed. For example, if a transaction con-\ntrol annotation is not speciﬁ ed, the default is to require a transaction for each method in a class. \n The example in  Figure 10.19 illustrates a stateless session bean for a group of methods that can perform \nseveral operations for a ﬁ ctitious bank account management application. A session bean typically is invoked by \nthe servlet engine, although it can also be invoked using a Web Service, another EJB, or a Swing client. Since \nno  @TransactionAttribute annotation is included, the bean uses default of container-managed transac-\ntions with a transaction required for the execution of each method. Thus, if a method is called from another \nmethod, the calling method’s transaction will be used. Otherwise a new transaction will be created. \n An EJB  reference is needed to invoke a bean, with the exception of a Web Service invocation of a stateless \nsession bean method. The EJB reference can be injected or retrieved using a directory lookup. A typical direc-\ntory service for a Java EE-based application server is the Java Naming and Directory Interface (JNDI).  Figure \n10.20 shows an example of a client with an EJB reference injected using the  @EJB annotation to provide the \nreference that can be used to invoke the  Transfer EJB. The  @Resource annotation also can be used to inject \na variety of other external information, such an environment variable, an EJB context, a JMS destination, a \nconnection factory, or a data source. \n The default for accessing an interface is local access; that is, from an EJB client running in the same address \nspace. A remotely accessible interface needs to be explicitly identiﬁ ed using the  @javax.ejb.Remote annota-\ntion. The  @javax.ejb.Local annotation explicitly restricts an interface to local access. \n",
      "content_length": 4514,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 322,
      "content": " The  @TransactionManagement annotation deﬁ nes whether the implicit or explicit programming model \nis used for a bean. Valid values for this attribute are: \n ■  TransactionManagementType.CONTAINER \n ■  TransactionManagementType.BEAN \nimport javax.ejb.Stateless;\n@Stateless\npublic class AccountOperationBean implements AccountOperation {\n    public double balance(int accountNumber) {\n        Account acct = this.getAccount(accountNumber);\n        return acct.getBalance();\n    }\n    public void deposit(int accountNumber, double amount) {\n        Account acct = this.getAccount(accountNumber);\n        acct.setBalance(acct.getBalance() + amount);\n    }\n    public void withdraw(int accountNumber, double amount) {\n        Account acct = this.getAccount(accountNumber);\n        if (acct.getBalance() < amount) {\n            throw new InsufficientFundsException();\n        }\n        acct.setBalance(acct.getBalance() - amount);\n    }\n    private Account getAccount(int accountNumber) {\n        // Code to retrieve the Account balance\n    }\n}\n FIGURE 10.19 \n Stateless Session Bean. This stateless EJB implements the operations of the  AccountOperation interface to check a \ncustomer’s account balance and to withdraw or deposit funds. \nimport javax.naming.Context;\nimport javax.naming.InitialContext;\npublic class TransferClient \n{\npublic static void main(String [] args)\n  {\n    @EJB Transfer myTransfer; \n    myTransfer.transfer(123, 456, 100.00);\n }\n}\n FIGURE 10.20 \n Sample EJB Reference for Transfer Class. An EJB reference can be injected to allow a front-end program or request \ncontroller to invoke an EJB. \n10.4 Java Enterprise Edition  303\n",
      "content_length": 1649,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 323,
      "content": "304  CHAPTER 10 Transactional Middleware Products and Standards\n When the value is  CONTAINER the implicit programming model is used, which is called  container man-\naged in EJB terminology. When it’s  BEAN , the explicit programming model is used, called  bean managed . \n The  @javax.ejb.ApplicationException annotation marks an application exception that can be thrown by \na method in a bean managed transaction. The exception is reported directly to the EJB client when it occurs. The \nrollback attribute of the annotation can be used to deﬁ ne whether the exception automatically causes a rollback. \n The  @TransactionAttribute is used to control the operations of the implicit programming model, such \nas whether or not the container is required to start a new transaction before executing each method in the class. \nThe next section lists the valid values for this attribute. \n A  JPA entity can be deﬁ ned within an EJB to map its data to a relational database, using an object-relational \nmapping. The  @javax.persistence.Entity annotation deﬁ nes a Java class as a JPA entity. A JPA entity \ncan be used from within a session bean or a plain Java class. \n In previous versions of EJB this functionality was called bean-managed or container-managed persistence. \nJPA is lighter weight, easier to use, and more efﬁ cient than the previous EJB approach. A JPA entity maps the \ndata items and attributes of a Java class to one or more rows in one or more database tables. Optional attributes \ncan be used to specify ﬁ ne-grained control over which data items are persisted. \n The example in  Figure 10.21 shows a stateless session bean that uses a JPA  EntityManager to create a new \naccount record. Bean methods access and update the persistent resource. Operations to create or update an entity \nshould execute in the context of a transaction, which is why the  @TransactionAttribute annotation is set to \n REQUIRED . It creates a new  Account record based on parameters passed to the  createAccount method, and \nthen calls the  em.persist method to add a row to the database table. When used in an EJB, a JPA entity partici-\npates in the global transaction managed by the Java Transaction API (JTA; described later in this section). When \nused outside of an EJB, a JPA entity can use a JDBC managed transaction or a global transaction managed by JTA. \n Transaction Management in Java \n Java developers creating TP applications may choose to use a persistence abstraction from a plain Java object \nor from within an EJB. If using a plain Java object, a session can be established with a single resource manager \nimport javax.ejb.Stateless;\nimport javax.ejb.TransactionManagement;\nimport javax.persistence.PersistenceContext;\nimport javax.persistence.EntityManager;\n...\n@Stateless\n@TransactionAttribute(REQUIRED)\npublic class AccountCreationBean implements AccountCreation {\n    @PersistenceContext(unitName=“AccountSystem”)\n    private EntityManager em;\n    public void createAccount(String customerName, int accountNumber, \n                              double initialDeposit) {\n        Account acct = new Account(accountNumber);\n        acct.setCustomerName(customerName);\n        acct.setBalance(initialDeposit);\n        em.persist(acct);\n    }\n}\n FIGURE 10.21 \n Using a JPA Entity to Create an Account Record. A JPA entity manager retrieves and updates persistent items in a database. \n",
      "content_length": 3397,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 324,
      "content": " to directly control its transactions. If using a persistence abstraction within an EJB, JTA is used to control the \ntransaction. \n An EJB does not have an equivalent mechanism to the .NET Framework  set.complete() method because \nan EJB is not treated as a transaction participant. Nor does the EJB speciﬁ cation include a concept directly com-\nparable to an ambient transaction; that is, one that exists independently of the lifecycle of an object for which a \ntransaction is started. However, Java EE does offer the  setRollbackOnly command for a subobject to tell the \ntop-level object to abort. \n The Implicit Programming Model \n In the implicit programming model the EJB container automatically starts and terminates a transaction when a \ntransactional EJB method is invoked. Successful completion commits the transaction and an exception can be \nset to cause an automatic abort. \n By default, the EJB container automatically invokes a business method within a transaction context and \nautomatically decides whether to commit or abort the transaction, depending on whether the method completes \nsuccessfully or not. A transaction annotation can be speciﬁ ed on the entire bean class, or on individual methods \nto override the default behavior. An annotation at the method level overrides an annotation at the class level, if \nboth are speciﬁ ed. \n Valid values for the  @TransactionAttribute annotation are: \n ■  REQUIRES_NEW \n ■  REQUIRED \n ■  SUPPORTS \n ■  NOT_SUPPORTED \n ■  MANDATORY \n ■  NEVER \n The transaction attribute values instruct the container to perform the following operations: \n ■  REQUIRES_NEW . Every invocation of the method starts executing in a new transaction, whether or not \nthe caller was already executing in a transaction. \n ■  REQUIRED . If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method starts executing in a new transaction. \n ■  SUPPORTS . If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, then the called method does not execute within a transaction. \n ■  NOT_SUPPORTED . The called method does not execute within a transaction, even if the caller is running \nwithin a transaction. \n ■  MANDATORY . If the caller is already running within a transaction, then the called method executes within \nthat transaction. If not, an exception is raised. \n ■  NEVER . If the caller is already running within a transaction, an exception is raised. \n If the transaction attribute of a message-driven bean is  REQUIRED , then the bean executes as a top-level \ntransaction. The transaction includes its operations on the message queue and on any other transactional \nresources. Operations in a message-driven bean cannot join the transactional operations of any other bean. When \nthe transaction attribute is  NOT_SUPPORTED , the message-driven bean’s operations do not execute in the context \nof a transaction. A container-managed transaction is required to coordinate operations on message queues with \noperations on other persistent resources. \n An EJB always uses JTA unless the  NOT_SUPPORTED attribute is speciﬁ ed. JTA implementations use a \none-phase commit optimization whenever there’s a single resource manager. This optimization is sufﬁ cient for \n10.4 Java Enterprise Edition  305\n",
      "content_length": 3383,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 325,
      "content": "306  CHAPTER 10 Transactional Middleware Products and Standards\n most applications. However, unlike the PSPE optimization in .NET’s  System.Transactions , it still involves \nthe application server’s transaction manager. There are workarounds, but they involve the EJB doing explicit \ntransaction control with the RM. \n Figure 10.22 illustrates a session bean that uses the  REQUIRED attribute to invoke two methods within the \nsame transaction. The  REQUIRED attribute means that if the caller is executing in a transaction, then any called \nmethods also execute within the caller’s transaction. If the caller is not executing a transaction, the method \nexecutes in a new top-level transaction. \n An exception class can be deﬁ ned so that when the execution of a transaction throws an exception, the \napplication can catch it in the exception handler and throw an application-speciﬁ c exception. In the example \nin  Figure 10.23 the  @ApplicationException annotation sets the  rollback attribute to  true , meaning that \nwhen the exception handler catches an exception of the deﬁ ned type, a  TransferException is raised, and a \nrollback is signaled for the transaction. \npublic class TransferBean implements Transfer {\n    @EJB AccountOperation op;\n   ...\n    @TransactionAttribute(REQUIRED)\n    public void transfer(int acct1, int acct2, double amount) {\n        op.withdraw(acct1, amount);\n        op.deposit(acct2, amount);\n    }\n}\n FIGURE 10.22 \n Transactional Session Bean Invoking Two Methods. Both the  Withdraw and  Deposit methods are invoked within the \nsame transaction. \n>>> Exception class:\nimport javax.ejb.ApplicationException;\n@ApplicationException(rollback = true)\npublic class TransferException extends RuntimeException {}\n>>> Session bean class:\nimport javax.ejb.*;\n@Stateless\n@TransactionManagement(TransactionManagementType.CONTAINER) \npublic class TransferBean implements Transfer {\n  @TransactionAttribute(TransactionAttributeType.REQUIRES_NEW)\n  public void transfer(int acct1, int acct2, double amount) {\n    try {\n        <<do transfer>>\n    } catch (Exception e1) {\n        <<log>>\n        throw new TransferException(e1);\n    }\n  }\n}\n FIGURE 10.23 \n Using a Try Block to Catch an Exception. The  try block allows an exception to be caught and transferred for the transaction. \n",
      "content_length": 2306,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 326,
      "content": " Transaction control attributes can be speciﬁ ed either as embedded annotations and attributes in EJB3 or in a \ndeployment descriptor ﬁ le, which is illustrated in  Figure 10.24 . A descriptor ﬁ le can be either hand-coded or gen-\nerated from annotations and attributes. For each EJB listed in the example ﬁ le, the implicit programming model \nis speciﬁ ed ( transaction-type is  container ) and a transaction control attribute is associated with either all \nmethods of a class (using an asterisk) or with a particular method of the class (for example,  transfer ). \n The Explicit Programming Model \n In the Java EE environment, explicit transaction programming directly uses the Java Transaction API (JTA) in \na bean-managed transaction. JTA has three major functional areas: \n ■  Simple transaction demarcation: javax.transaction.UserTransaction \n ■  Transaction manger control: javax.transaction.TransactionManager \n ■  A Java mapping of the XA API for resource integration: javax.transaction.xa.XAResource \n<ejb-jar>\n  ...\n  <session>\n    <ejb-name>AccountOperationBean</ejb-name>\n    ...\n    <transaction-type>Container</transaction-type>\n  </session>\n  <session>\n    <ejb-name>TransferBean</ejb-name>\n    ...\n    <transaction-type>Container</transaction-type>\n  </session>\n  <assembly-descriptor>\n      ...\n    <container-transaction>\n      <method>\n        <ejb-name>AccountOperationBean</ejb-name>\n        <method-name>*</method-name>\n      </method>\n      <trans-attribute>Required</trans-attribute>\n    </container-transaction>\n   \n    <container-transaction>\n      <method>\n        <ejb-name>TransferBean</ejb-name>\n        <method-name>transfer</method-name>\n      </method>\n      <trans-attribute>RequiresNew</trans-attribute>\n    </container-transaction>\n  </assembly-descriptor>\n</ejb-jar>\n FIGURE 10.24 \n Using an EJB Deployment Descriptor to Specify Transaction Control Attributes. The EJB descriptor ﬁ le associates EJB \nmethod names with attributes that deﬁ ne whether the program in the bean uses the explicit or implicit programming \nmodel, and whether or not a transaction context is required to invoke the method. \n10.4 Java Enterprise Edition  307\n",
      "content_length": 2172,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 327,
      "content": "308  CHAPTER 10 Transactional Middleware Products and Standards\n The  UserTransaction part of the API is used for bean managed transactions; that is, for explicit trans-\naction programming in an EJB. The  TransactionManager part of the API typically is used by applica-\ntion server vendors to access and control the functions of an independent transaction manager, such as a Java \nTransaction Service (JTS) compliant transaction manager. Some application server products explicitly prohibit \nits use. The  XAResource portion of the API is a Java mapping of the standard XA interface that the applica-\ntion server uses to include XA-compliant resource managers into JTA-managed transactions. \n The underlying implementation of JTA isn’t explicitly deﬁ ned and may vary from vendor to vendor. JTS \nspeciﬁ es one implementation, using the Object Management Group’s Object Transaction Service (OTS, \ndescribed in Section 10.8) and General Inter-ORB Protocol (IIOP). Vendors typically use a combination of \nJTS and XA-compliant libraries. Transaction interoperability between transactional Java EE application serv-\ners is optional, but if supported it must use JTS/OTS. \n JTA can be used in a Java EE environment. It can also be used outside a Java EE environment when an \nindependent implementation of JTA is available, such as Atomikos or the JBoss Transaction Manager. \n Figure 10.25 illustrates the use of explicit transaction management within a stateless session bean. The \n UserTransaction part of the JTA API is used in a stateless EJB to start ( utx.begin() ) and terminate \n( utx.commit() ) a transaction. A transaction has to be started and completed in the same method, although \nthe transaction context (as in the implicit model) can be propagated to other methods. As shown in the exam-\nple, an exception handler can be deﬁ ned to issue the  utx.rollback() command and throw an exception to \nthe client if there’s a problem. \n Integration with Legacy TP Monitors \n The Java Connector Architecture (JCA) deﬁ nes a standard way for Java-EE-compliant transactional middleware \nto connect to legacy TP monitors and other existing systems such as packaged applications. JCA provides a set \nof APIs and system programming interfaces for developing and deploying connections and adapters to existing \n@Stateless\n@TransactionManagement(TransactionManagementType.BEAN) \npublic class TransferBean implements Transfer {\n@Resource private UserTransaction utx;\npublic void transfer(int acct1, int acct2, double amount) {\n    try {\n        utx.begin();\n        <<do transfer>>\n        utx.commit();\n    } catch (Exception e1) {\n        try { utx.rollback(); } catch (Exception e2) {}\n        <<log>>\n        throw new TransferException(e1);\n    }\n}\n FIGURE 10.25 \n Explicit Transaction Control in a Stateless Session Bean. A stateless session bean can explicitly manage a transaction \nthat includes updates to multiple resource managers. \n",
      "content_length": 2935,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 328,
      "content": " systems. JCA can propagate a transaction context from an EJB to a legacy TP monitor, depending on the \ncompatibility of the application server’s and legacy TP monitor’s transaction protocols. \n JCA deﬁ nes a set of system-level contracts between a Java EE application server and an existing system. \nThey include contracts for communications, security, and transaction management. JCA deﬁ nes a common \nclient interface that allows an EJB to call an adapter written for an existing technology’s external client or a \ncustom-developed adapter. It can propagate application server features using one or more connection contracts, \nsuch as one that propagates transaction context. JCA calls such a contract a  resource adapter . A resource \nadapter plugs into the application server as a protocol and functional bridge between an application server and \nan existing system. \n Transaction management is integrated with JTA and is based on wrapping each existing transactional envi-\nronment as an XA resource so it can be coordinated using the application server’s transaction manager. JCA \noffers the application server the option to delegate transaction management to the local resource when a single \nresource manager is involved in the transaction, saving the overhead of two-phase commit coordination when \nit isn’t needed. Transaction propagation works with both the implicit and explicit programming models. \n Existing systems such as legacy TP monitors typically support external clients, for example ECI for CICS \nand TP Web Connector for ACMS. Vendors also have the option of providing their own JCA-compliant adapter. \nJCA adapters are capable of bidirectional communication, including transactions, between existing systems and \napplication servers. \n Spring Transactions \n The Spring Framework is a popular open source programming model for developing enterprise applications, \nsuch as TP applications, using plain old Java objects (POJOs) and EJBs. Spring objects, called Spring Beans, \ncan be deployed into Java-EE-compliant application servers, standalone servlet engines that don’t support \nEJBs, or OSGi Frameworks such as Eclipse Equinox and Apache Felix. \n The Spring Framework offers a widely-adopted lightweight alternative to EJBs, including transactional mid-\ndleware functions. Spring works with popular EJB containers and standalone JTA-compliant transaction manag-\ners such as the JBoss Transaction Manager, the Atomikos transaction manager, or the Java Open Transaction \nManager (JOTM) from the OW2 Consortium. The Spring Framework extends transaction processing applica-\ntions outside of the Java-EE-compliant application server environment and offers a lightweight alternative for \nsingle resource transactions. \n Spring supports two models for transaction management: \n ■  Local: Delegates transaction management to the persistence abstraction mechanism (e.g., JDBC or JPA) \n ■  JTA: Uses the JTA API from within the Spring Platform Transaction Manager API explicitly to initiate \nand terminate transactions \n Spring supports both implicit and explicit programming models for either the local or JTA transaction man-\nagement models. The implicit and explicit models are called  declarative and  programmatic demarcation , \nrespectively. Declarative demarcation uses embedded annotations whereas programmatic demarcation uses the \nJTA API. Spring Beans using transactions can be deployed within an EJB container or independently of an \nEJB container as long as the requisite transaction management infrastructure is available (i.e., a transactional \npersistence abstraction mechanism and/or a standalone JTA implementation). \n Spring transaction management uses the Spring Platform Transaction Manager API to abstract the transac-\ntion management and programming models. The local and JTA transaction management models are  strategies . \nA transaction management strategy is deﬁ ned or altered using a conﬁ guration ﬁ le associated with a Spring \n10.4 Java Enterprise Edition  309\n",
      "content_length": 4007,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 329,
      "content": "310  CHAPTER 10 Transactional Middleware Products and Standards\n Bean. The Spring Framework focuses primarily on local transaction management as the most common use of \ntwo-phase commit; that is, coordinating transactional resources that reside on the same machine. \n The Spring Framework supports local propagation of transaction context across method invocations using \neither strategy. Remote propagation of transaction context uses a JTA-aware communication protocol (e.g., \nRMI and RMI/IIOP) and requires explicit JTA programming. \n The Spring Framework allows TP application developers to deﬁ ne which exceptions will cause a rollback, \na capability that is also available in EJB3. \n As shown in  Figure 10.26 , the Spring Framework uses the  PlatformTransactionManager interface to \nimplement the transaction strategy declared for a Spring Bean. The strategy can choose a transaction manager \nthat provides a JTA API, or it can use the transaction management capabilities of a JDBC connection. However, \nit is also possible for a Java programmer to use this interface directly from a Spring Bean to programmatically \nset the strategy. \n In  Figure 10.27 the  PROPAGATION_REQUIRED attribute is set to ensure that the method is invoked within a \ntransaction context. Note that remote context propagation requires the use of the explicit programming model. \nThe example also illustrates the way in which the Spring Framework allows a rollback to be associated with an \napplication deﬁ ned exception, such as  MyException . \npublic interface PlatformTransactionManager {\n    TransactionStatus getTransaction(TransactionDefinition definition)\n        throws TransactionException;\n   void commit(TransactionStatus status) throws TransactionException;\n   void rollback(TransactionStatus status) throws TransactionException;\n}\n FIGURE 10.26 \n The Spring Framework Abstract Interface for Transaction Management. The interface is used internally by the Spring \nFramework to set the transaction strategy, which is deﬁ ned in an associated conﬁ guration ﬁ le. It can also be used \nexplicitly by developers to control the transaction strategy programmatically. \nDefaultTransactionDefinition def = new DefaultTransactionDefinition();\n  def.setName(“Transfer”);\n  def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED);\n  TransactionStatus status = txManager.getTransaction(def);\n    try {\n      //execute your business logic here\n    }\n    catch (MyException ex) {\n      txManager.rollback(status);\n      throw ex;\n    }\n  txManager.commit(status);\n FIGURE 10.27 \n Using the Spring Framework for Explicit Transaction Management. A new transaction is deﬁ ned for the  Transfer \nmethod along with its propagation behavior. The transaction is initiated and completed within the  try block, which also \ncan throw the rollback exception. \n",
      "content_length": 2843,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 330,
      "content": " The implicit model implements declarative demarcation using Spring’s  @Transactional annotation. This \nworks similarly to EJB’s annotation system. Spring supports the EJB  @TransactionAttribute values and \nextends them for deﬁ ning a custom isolation level or a read-only transaction, or to control cache ﬂ ushing. \n In the example in  Figure 10.28 , the  @Transactional annotation indicates using the  Propagation.\nREQUIRES_NEW property that a new transaction must be started before executing the  withdrawFunds method, \neven when a transaction context is propagated on the method invocation. Spring supports EJB propagation \noptions and adds a  NESTED option to support nested transactions. This can be used by persistence abstraction \nmechanisms that support savepoints, such as a JDBC3 driver or Apache OpenJPA. \n Switching the transaction management strategy from local to JTA is accomplished using a conﬁ guration \nchange. For example, the ﬁ rst part of  Figure 10.29 conﬁ gures the local Spring transaction management strat-\negy to use a JDBC driver and the second part conﬁ gures a JTA strategy. A conﬁ guration change to a JTA strat-\negy may be necessary when a Spring Bean accesses multiple resource managers within the same transaction, \nor needs to propagate transaction context remotely. \n 10.5  SERVICE-ORIENTED ARCHITECTURE \n The SOA style of design provides many beneﬁ ts, including functional reuse across multiple applications, \nimproved ﬂ exibility in developing new applications, and interoperability across disparate software systems, \nsuch as .NET, Java EE, and legacy TP monitors. SOA-based applications can include services created from \nJava EE or .NET Framework objects, legacy TP monitor procedures, asynchronous message queues, or data-\nbases. SOA products create and manage services for these and other environments. They also combine services \ninto business process ﬂ ows. Interoperability across disparate software systems enhances the beneﬁ ts of SOA \nfor reuse and ﬂ exibility, but presents additional challenges for transaction management. \n@Transactional(propagation=Propagation.REQUIRES_NEW)\n  public void withdrawFunds(Account Amount) {\n    ...\n  }\n FIGURE 10.28 \n Spring Transactions Implicit Model. Spring uses the  @Transactional annotation to declaratively specify transaction \ncontrol for a method (method code not shown). \n<tx:annotation-driven/>\n<bean id=“transactionManager”\n class=“org.springframework.jdbc.datasource.DataSourceTransactionManager”>\n   <property name=“dataSource” ref=“myTargetDataSourceBean”/>\n</bean>\n <tx:annotation-driven/>\n<bean id=“transactionManager”\n class=“org.springframework.transaction.jta.JtaTransactionManager”/>\n FIGURE 10.29 \n Switching Transaction Strategies. Spring transactions use conﬁ guration to switch transaction management strategies. \n10.5 Service-Oriented Architecture  311\n",
      "content_length": 2864,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 331,
      "content": "312  CHAPTER 10 Transactional Middleware Products and Standards\n Applications based on the Service-Oriented Architecture (SOA) style of design began to appear in the \nlate 1990s and early 2000s using products such as Progress Software’s CORBA-compliant Orbix and IBM’s \nWebSphere MQ. Some applications based on the SOA design use both, such as the well-documented Credit \nSuisse Information Bus. \n More recently, Web Services have become a popular technology for SOA. As mentioned in the .NET \nFramework and Java EE sections, both of those technology suites support Web Services. They also support \nREST/HTTP, another popular technology for SOA. We will discuss both technologies for SOA. \n Products and services speciﬁ cally designed for use with SOA are offered by HP, IBM, Microsoft, Oracle, \nProgress Software, Red Hat, Software AG, TIBCO Software, and others. Most SOA products support a two-\nphase commit protocol for services that execute as a transaction. Some products also include a compensation-\nbased protocol for services that execute as a business process. SOA-based applications often include both kinds \nof services, sometimes in the same application. Sometimes these two types of services are called ﬁ ne-grained \nand coarse-grained, or tightly-coupled and loosely-coupled, respectively. \n The exact characteristics and details of the SOA products vary, but they tend to fall into these general \ncategories: \n ■  Service enablement: Create Web Service interfaces and REST/HTTP access to existing and new pro-\ngrams, objects, databases, and message queues. \n ■  Business process management: Compose and execute ﬂ ows of sequences of services. \n ■  Governance: Store and retrieve service metadata, including development lifecycle support. \n ■  Management: Monitor runtime service execution and enforce policy contracts such as security and \navailability. \n In a typical SOA-based application, a request type can invoke a transaction that uses cooperating services \nwithin a single application environment, or a business process that invokes multiple services in sequence. In \nthe ﬁ rst case, any transaction protocol can be used, such as a native two-phase commit or the WS-AT protocol \nfrom WS-Transactions. For a business process, however, a compensation-based protocol is more likely to be \nrequired, such as the WS-BusinessActivity protocol from WS-Transactions. \n Several factors apply to the choice of Web Services or REST/HTTP based technologies for an SOA-based \napplication. In general, requirements for RPC communications and for wrapping existing systems favor the \nuse of Web Services, and requirements for hosting applications on the Web favors the use of REST/HTTP. \nOther factors include whether the application is a purely web-based application, or whether the application is a \nmixture of web components and transactional middleware components. Web Services are readily available for \ntransactional middleware environments, including legacy TP monitors. However, given the success of the Web, \ndevelopers would do well to prepare for a web-based architecture whenever possible. \n Web Services-Based SOA \n Web Services use SOAP as the message format, with parameters expressed in XML and interfaces expressed \nin Web Services Deﬁ nition Language (WSDL). Some implementations allow a SOAP message to contain a \nsingle XML document instead of RPC-style arguments. Optional headers are added to SOAP messages to \nexpress requirements for system functions such as security, reliability, and transaction propagation. \n One popular application of Web Services is interoperability between native RPC protocols, such as Java \nEE’s RMI and the Microsoft RPC. This is done by programs that understand both formats, translating native \nRPC messages into and out of the SOAP format. \n In  Figure 10.30 , the SOAP message is created using a C# object linked with a proxy generated from a \nWCF interface that uses a Web Services binding. The SOAP processor in the WCF environment obtains the \n",
      "content_length": 4010,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 332,
      "content": "WSDL  interface from the remote service, perhaps using a registry, and marshals the C# data types into XSD \ndata types using the message deﬁ nition in the remote service’s WSDL ﬁ le. The caller uses the Web Services \naddress, or obtains the address of the remote service from the WSDL ﬁ le as well as the transport to be used, \ntypically HTTP. The WSDL ﬁ le may also include a WS-Policy assertion that requires a transaction context \nto invoke the remote service. In that case the WCF SOAP processor includes in the SOAP message header a \ntransaction context conforming to the policy assertion. \n When the remote Java service receives the request message, its SOAP processor unmarshals the XSD data \ntypes into Java data types (perhaps using the Java Architecture for XML Binding (JAXB)). The SOAP proces-\nsor checks whether any SOAP headers need to be interpreted, such as a transactional context, and then uses \nthe service name in the interface to dispatch the request to a local Java object for processing. When a transac-\ntion context header is received, the SOAP processor calls a transaction manager to enroll the local transaction \nin a transaction initiated by the service requester and propagated on the request. Results are returned in the \nresponse message, following this path in reverse. If an exception occurs, it is passed back to the calling service \nusing a SOAP Fault message. The WS-Transactions standard deﬁ nes how the transaction context is propagated \nand how the commitment protocol is executed. \n The style of Web Services illustrated in this example focuses on their use within the .NET Framework \nand Java EE-based application server environment. However, SOA vendors also provide products that do not \ndepend upon either of these transactional middleware systems. Instead, they use a  mediator to process a SOAP \nmessage and submit requests to programs, queues, and databases. A mediator is software that sits between the \nservice requester and the service provider. It is also typically responsible for processing any optional SOAP \nheaders for security, reliability, or transactions. \n Another popular application of Web Services is to encapsulate a series of ﬁ ne-grained services inside a busi-\nness process, exposed using a coarse-grained service. A coarse-grained service may not need the RPC-oriented \nmechanisms described in the previous example. Instead, an XML payload may be consumed directly. However, \nthe message can still carry optional SOAP headers such as a WS-Security or WS-Transactions context. \n The transaction context for the ﬁ ne-grained services shown in  Figure 10.31 executes within a business pro-\ncess and uses a compensation-based protocol such as WS-Transactions ’ WS-BA to undo the results of transac-\ntions executed within the steps of the business process. A compensation-based protocol can also be used for \nRM \nSOAP\nProcessor \nSOAP Message\nSOAP\nProcessor\nC#\nService\nJava\nService\nOptional Transaction\nContext Header\nTM \nTM \nRM \n FIGURE 10.30 \n Web Services Interoperability. Two different execution environments can interoperate using SOAP, potentially including a \ntransaction context. \n10.5 Service-Oriented Architecture  313\n",
      "content_length": 3192,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 333,
      "content": "314  CHAPTER 10 Transactional Middleware Products and Standards\n recovery from failures in interactions among coarse-grained services, especially those using asynchronous com-\nmunication protocols. \n REST/HTTP-Based SOA \n In the REST/HTTP approach to SOA, interfaces such as WSDL are not used. Nor are message headers such \nas those deﬁ ned for SOAP. Instead, HTTP headers are used and resource representations are exchanged \nand processed. Resource representations typically use XML or JavaScript Object Notation (JSON) formats. \nInformation contained within the resources tells the client what it’s allowed to do. The server accepts HTTP \nverb requests (GET, PUT, DELETE) or interprets information it receives from the client on a POST request. \nTherefore, typical RPC artifacts aren’t necessary, such as an interface compiler, proxies and stubs, and mar-\nshaled parameters in the form of method arguments. \n Instead , REST/HTTP assigns a URI to a resource and exchanges representations of the resource using \nHTTP verbs. For example, the resource could be a database and the exchanged representation could be an \nXML representation of rows retrieved from or to be stored in a database table. \n Unlike Web Services, transaction propagation for REST/HTTP isn’t deﬁ ned. However, transactions can be \nsupported by representing each transaction as a unique resource with which HTTP verbs interact. To start a trans-\naction T, the server creates a resource R T that represents the transaction. All of T’s operations on (other) trans-\nactional resources R \u0002 (such as rows of database tables) are sent to R T , so that it can keep track of before- and \nafter-images of R \u0002 . T ﬁ nishes by sending a commit or abort operation to R T , which does the corresponding action \nand then deletes R T . \n The reason for representing the transaction as a resource is that REST/HTTP doesn’t support shared ses-\nsion state. Since there is no session on which to propagate the transaction context, the resource is used to hold \nthat context. Indeed, it holds the entire transaction state. The client maintains its application state and drives \nthe state changes of the server resource that represents the transaction. \n REST /HTTP is often a good choice for communication between companies, in which the cost of pro-\ncessing a self-describing XML message isn’t justiﬁ ed due to the relatively small volume of such messages. \nThe REST/HTTP approach is also simpler than the RPC style of interaction more commonly used with Web \nServices, and thus is easier to use. A multistep REST/HTTP-based exchange between two companies can use \na compensation-based transaction protocol. \nService A\ncan be a business\nprocess that invokes\nfine-grained services\nS1, S2, S3   \nService Requester\ninvokes coarse-\ngrained service A \nS3\nS2\nS1\nTransaction\nContext \nCompensation\nSteps  \n FIGURE 10.31 \n Encapsulating Fine-Grained Services in a Business Process. In an SOA environment, the service requester may invoke \na coarse-grained service that encapsulates and invokes a series of ﬁ ne-grained services within a compensation-based \ntransaction context. \n",
      "content_length": 3120,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 334,
      "content": " Figure 10.32 illustrates clients that understand REST/HTTP, such as Silverlight, WCF, Java EE (through the \nJAX-RS API), and Java Script. These interact with the web server via HTTP verbs. The web server typically \ndispatches the document received via REST/HTTP to a program on the server side, such as a .NET Framework \nor Java EE object to interact with the resource, such as a database. \n REST /HTTP architectures typically use reliable messaging to capture and process messages after they are \nreceived. Large web businesses also typically deploy redundant hardware and software systems to ensure reli-\nable request capture and processing. For example, a REST/HTTP request message may be durably stored before \nsending it to the transaction server and processing it against the database. Reliable schemes also include the \nability to detect and ﬁ lter duplicate messages, or to design messages as idempotent. \n An SOA project initially should deﬁ ne a blueprint or style of design before identifying a particular technol-\nogy or how to apply it. The examples in this section illustrate some possible implementations, highlighting the \nrelationship between transaction management and SOA designs using popular technologies. However, many \nmore approaches are possible. \n 10.6  PERSISTENCE ABSTRACTION MECHANISMS \n Much of the application code in a TP system makes direct use of database functionality. Some of this function-\nality is closely related to transactional middleware, namely, database sessions and stored procedures. Therefore, \neven though database APIs are beyond the scope of this book, this chapter on transactional middleware prod-\nucts and standards would be incomplete without some discussion of these closely-related  topics. \n Early database systems for enterprise computing executed in the same address space as the application and \ntherefore could be invoked directly as a runtime library. With the advent of client-server architectures in the \n1980s, these database systems were redesigned to execute in a separate process, that is, as a database server. \nThis enables the database system to run on a separate machine from the applications that use the database. In \nthis architecture, the application and database system need to communicate using messages. This communica-\ntion requires that a fair bit of context is shared between the application and database system, such as the identity \nof the database that the application is using (since a database server may have access to multiple databases), \nthe security credentials of the application for access control, and the transaction ID of the transaction that the \napplication is currently executing. It would be expensive and cumbersome to pass this context information back \nand forth between the application and database system with every message. To avoid this, a session is needed to \nmaintain the shared context between the application and database server. \nHTTP Get  \nHTTP Post  \nRM\nTransaction\nContext\n.NET or\nJava\nprogram \nWeb\nServer\nJavaScript\nSilverlight\nWCF\nJAX-RS \n FIGURE 10.32 \n REST/HTTP Architecture for SOA. A program capable of using HTTP verbs constructs a document to exchange as a \nrepresentation of a server-side resource. The service requester receives a hypermedia document representing a resource, \nwhich can direct the requester with URIs and forms to POST information back to the resource to effect changes. \n10.6 Persistence Abstraction Mechanisms  315\n",
      "content_length": 3464,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 335,
      "content": "316  CHAPTER 10 Transactional Middleware Products and Standards\n A database session API has two main kinds of operations: operations to create, destroy, and update the ses-\nsion; and operations to send and receive database commands and data over the session. In addition, there are \nprovider interfaces that enable vendors to plug in drivers that enable the session API to be used with different \ndatabase server products. \n When it became clear that the session API would be a part of every database application, various efforts \nwere undertaken to standardize it, notably the SQL Access Group (originally an independent consortium whose \nactivities were transferred to the Open Group). To make it easy for PCs to access database servers, Microsoft \ndeveloped the Open Database Connectivity (ODBC) speciﬁ cation in conjunction with the SQL Access Group, \npublishing the ﬁ rst version in September 1992. The corresponding Java Database Connectivity (JDBC) \nstandard for Java objects, modeled on ODBC, was ﬁ rst published in 1997. \n Since then, there has been a steady stream of new APIs introduced, some of which include an ODBC or \nJDBC session. Many of the new APIs make it easier to access data from an object-oriented programming lan-\nguage and add support for a wider range of data types. Some also support access to other types of resources \nin addition to SQL databases. Examples include the Java Persistence API (JPA), OASIS Service Data Objects \n(SDO), Microsoft’s OLE DB (Object Linking and Embedding, Database), and Microsoft’s ActiveX Data \nObjects (ADO). There are also APIs that support more ﬂ exible mappings between the application’s view of the \ndatabase schema and the schema supported by the underlying database system, such as Red Hat’s Hibernate, \nOracle’s TopLink, and Microsoft’s ADO.NET Entity Framework and Language Integrated Query (LINQ). \n These APIs can be used independently of, or in conjunction with, transactional middleware. In either case, \ntheir use has to be considered as part of a multitier TP architecture. The following sections brieﬂ y describe \nODBC and JDBC and the use of stored procedures as transaction servers. \n ODBC and JDBC \n The architecture used for ODBC and JDBC deﬁ nes a client-side driver for use by the application program. The \nclient-side driver exposes a standard interface on top of the store-speciﬁ c functions and protocols. These func-\ntions and protocols receive and execute application commands against the database on behalf of the client. The \nclient and server usually run in different address spaces. The use of ODBC and JDBC drivers allows client-\nside SQL statements to be created dynamically and passed to the server for execution. ODBC can be used by a \nvariety of programming languages. JDBC is intended for use by Java applications. \n ODBC and JDBC provide a common architecture for accessing database products, ensuring some level \nof application portability and application interoperation with different database systems. ODBC clients and \ndrivers ship with every version of the Windows operating system and most versions of Linux. ODBC and \nJDBC drivers are supported by most database products, including Microsoft SQL Server, IBM’s DB2, Oracle \nDatabase, MySQL, and PostgreSQL. Bridges are also available to layer JDBC on ODBC and vice versa. \n ODBC access starts by deﬁ ning a data source, as follows: \n DSN  \u0003  mydsn;attribute1  \u0003  value;attribute2  \u0003  value;attributeN  \u0003  value; \n The data source deﬁ nition includes a data source name (DSN) and attributes of the connection, such as \nsecurity requirements, server address, and isolation level. JDBC uses a very similar format. \n Given a data source deﬁ nition, an application starts by opening a data source connection and then creates \nSQL statements to send to the connection. For example, a Java object using JDBC instantiates a driver man-\nager object to connect to the database and execute SQL statements against it. Once ODBC or JDBC establishes \na connection object to the database the application executes methods on the connection object. \n For example, the code fragment in  Figure 10.33 starts by instantiating a connection using the \n DriverManager object, thereby logging into the database. Then it instantiates a  Statement object in the \ncontext of the connection and uses it to execute a SQL statement. The result of the query is assigned to a \n",
      "content_length": 4397,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 336,
      "content": " ResultSet object, which in general can contain many rows. The program executes a simple  while loop to \nretrieve results from those rows. \n ODBC and JDBC features include transaction control. An ODBC or JDBC connection is created in \n AutoCommit mode by default, meaning that each SQL statement automatically is committed after it is com-\npleted. Turning off  AutoCommit allows two or more SQL statements to be grouped into the same transaction \nand committed using the  commit() method on the connection object. Similarly, the  rollback() method \naborts all SQL statements that executed after the last  commit() or  rollback() on the connection object. \nJDBC and ODBC both support savepoints for partial rollback. \n In  Figure 10.34 ,  AutoCommit mode is disabled for the connection, allowing the two statements, \n DepositAccount and  WithdrawAccount , to commit their updates together when the  commit() method is \ncalled. The question marks in the SQL statements act as a placeholder for the substituted amount, which in the \nexample is simply hardcoded for convenience. \n A popular function for an ODBC/JDBC driver is to execute a stored procedure, as in the following example. \n CallableStatement proc  \u0003 conn.prepareCall(“ { ?  \u0003 call TransferFunds(?, ?)  } ”); \n Executing the  proc command in the client causes the driver program to request the execution of the \n TransferFunds stored procedure. The application program assigns values to the second and third question-\nmark parameters before executing the statement and gets the value of the ﬁ rst question mark parameter after the \nstatement executes. \nConnection con = DriverManager.getConnection\n           (“jdbc:myDriver:Wombat”, “Login”,“Password”);\n \nStatement stmt = con.createStatement();\nResultSet rs = stmt.executeQuery(“SELECT a, b, c FROM Table1”);\nwhile (rs.next()) {\n \nint x = rs.getInt(“a”);\n \nString s = rs.getString(“b”);\n \nfloat f = rs.getFloat(“c”);\n \n}\n FIGURE 10.33 \n JDBC Connection and SQL Statement Execution. JDBC (and ODBC, not shown) establishes a connection by providing a \nlogin username and password and then sends SQL statements to the connection. \ncon.setAutoCommit(false);\nPreparedStatement DepositAccount = con.prepareStatement(\n    “UPDATE ACCOUNT SET Balance = Balance + ?”);\nDepositAccount.setInt(1, 100);\nDepositAccount.executeUpdate();\nPreparedStatement WithdrawAccount = con.prepareStatement(\n    “UPDATE ACCOUNT SET Balance = Balance - ?”);\nWithdrawAccount.setInt(1, 100);\nWithdrawAccount.executeUpdate();\ncon.commit();\n FIGURE 10.34 \n Disabling Auto Commit for a JDBC Connection. When  AutoCommit is disabled, it’s possible to group multiple operations \ninto the same transaction, such as these statements that execute withdrawal and deposit operations. \n10.6 Persistence Abstraction Mechanisms  317\n",
      "content_length": 2802,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 337,
      "content": "318  CHAPTER 10 Transactional Middleware Products and Standards\n Object -relational mapping solutions generate mappings from classes and their members to tables and col-\numns of a relational database. For example, the Java Persistence API (JPA), which is part of Java EE, maps \nJava objects to rows in a relational database system. The ADO.NET Entity Framework provides similar func-\ntionality for the .NET Framework. Other APIs support data item mappings to other types of resource managers \nand allow multiple resource managers to be combined in a single program access. \n Stored Procedures \n Most relational database systems support stored procedures, which can be used to implement a transaction server. \nStored procedures can be called directly from application code from any tier in a multitier TP architecture. \n Database system products typically offer a stored procedure language derived from SQL. Often it’s a pro-\nprietary one because the SQL/PSM standard is not widely implemented. The Oracle Database calls its stored \nprocedure language PL/SQL, SQL Server calls it Transact-SQL, and IBM’s DB2 calls it the SQL procedure \nlanguage. Database systems typically also support stored procedures written using standard programming lan-\nguages such as Java or a CLR-based language from the .NET Framework, such as C#. \n As with proprietary language stored procedures, the rules vary by product as to how much of the Java and \n.NET languages are supported, and how to deploy Java or .NET classes into the database. For example, in \nOracle Java methods must be public and static. The  LoadJava command is used to prepare a Java class for \nloading. Rules for deploying Java in DB2 include  “ fencing ” the Java code (i.e., restricting its capabilities), \nconﬁ guring it, and determining the argument types to be supported. For example, no user-deﬁ ned signal han-\ndlers are permitted in DB2. \n The inclusion of Java and CLR-based language procedures in the database provides the ability to run all \nor part of the transaction server code within the database process. This gives developers the ﬂ exibility to write \ntransaction server code before deciding how much of it to run as stored procedures and how much to deploy in \nanother address space, whether on the same machine or on a remote machine (see  Figure 10.35 ). Parts of the \nApplication Code\n[SQL]\nDatabase \nApplication Code\n[Call SQL]\nDatabase with\nSQL Stored\nProcedure\nApplication Code\n[Call procedure]\nDatabase with\nJava or .NET\nApplication Code \n FIGURE 10.35 \n Options for Using a SQL in Application Code or as a Stored Procedure. Stored procedures offer an application the choice \nof executing SQL statements inside the database instead of in the application code, using a proprietary SQL stored \nprocedure language, Java, or a .NET language. \n",
      "content_length": 2813,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 338,
      "content": " application that frequently invoke SQL statements should execute in a stored procedure, to minimize context \nswitching overhead. Parts of the application that are processor-intensive and make infrequent calls to SQL \nshould execute outside the stored procedure, so they can run on a different machine and not limit the scalabil-\nity of the database server, which is often a bottleneck. \n SQL Server Stored Procedure Examples \n We show some examples of stored procedures using Microsoft SQL Server. Stored procedures in other data-\nbase products work similarly. The example in  Figure 10.36 illustrates the native SQL Server stored procedure \nlanguage, Transact-SQL. This could be accessed from a web server or application process using an ODBC \nconnection by executing the  @Transfer command. In SQL Server, the stored procedure can also be invoked \nusing a Web Service. The procedure allocates variables using the @-sign preﬁ x and executes SQL statements \nsuch as  SELECT and  SET . A stored procedure is created using the database  CREATE command and can accept \ninput arguments and return output arguments. \n Figure 10.37 illustrates the use of SQL commands in a stored procedure written in C#. The stored proce-\ndure needs to include the partial class  StoredProcedures and manages the connection to SQL server as it \nwould in a WCF service. In either case, transaction control can group multiple operations on data. Transaction \nbracketing operations are the same for proprietary SQL and CLR-based or Java-based stored procedures. \nHowever, nested transactions and savepoints are supported only by proprietary SQL stored procedures. \n Using the .NET Framework’s ambient transaction feature, it’s possible to delegate transaction control from \nthe middleware to the stored procedure, and to include multiple resource managers in the same transaction, \nwhether control is deﬁ ned in the middleware or the stored procedure. \n Java Persistence API \n The Java Persistence API (JPA) deﬁ nes a standard for object-relational mapping between Java objects and rela-\ntional databases. JPA can be used independently from an EJB in a plain Java object and also can be used within \na stateless or stateful session bean. JPA was developed as part of the EJB3 speciﬁ cation as a replacement for \nEJB2 entity beans, which were used in EJB2’s container-managed persistence and bean-managed persistence \nobject-relational mappings. EJB2 entity beans continue to be supported in EJB3 for backward compatibility. \n The JPA speciﬁ cation is intended to unify multiple object-relational mechanisms for Java, such as \nJDO, Hibernate, and entity beans. In doing so JPA abandoned the heavyweight EJB2 persistence model that \nintegrated container-managed transactions, security, and concurrency within a single entity bean. JPA is based \non the lightweight persistent model made popular by products such as Red Hat’s Hibernate and Oracle’s \nTopLink. \nCREATE PROCEDURE Transfer (@fromAccount int, @toAccount int, @amount int) \nBEGIN TRAN  \n  UPDATE Account SET Balance = Balance - @amount WHERE AccountID = @fromAccount\n  UPDATE Account SET Balance = Balance + @amount WHERE AccountID = @toAccount\nCOMMIT TRAN\nEND\n FIGURE 10.36 \n Transact-SQL Stored Procedure for Transfer Operation. Execution of the stored procedure, whether directly from within \nobject code or using an ODBC or JDBC connection, results in the transfer of the given amount from one of the customer’s \naccounts to the other. \n10.6 Persistence Abstraction Mechanisms  319\n",
      "content_length": 3519,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 339,
      "content": "320  CHAPTER 10 Transactional Middleware Products and Standards\n JPA uses Java 5 annotations and XML descriptors to map the data items and attributes of a Java class to \nrelational database tables. JPA also includes a runtime  EntityManager API for processing queries and updates \nagainst the objects mapped to the database, using an object-level query language called Java Persistence Query \nLanguage (JPQL). \n Each JPA entity maps to a particular row in one or more tables and is uniquely identiﬁ ed by one or more \nﬁ elds or properties that comprise an identiﬁ er. The identiﬁ er of each entity is unique within the scope of an \ninheritance hierarchy for that entity. It can be used both by clients for querying and by the implementation for \nmaintaining instance identity throughout the transactional or persistence context. \n An implementation of JPA is called a  JPA provider . Examples of JPA providers include Oracle’s Kodo, \nRed Hat’s Hibernate, the Eclipse Foundation’s EclipseLink, and Apache OpenJPA. The JPA speciﬁ cation also \ndeﬁ nes a service provider interface that describes how an EJB container hosts a JPA entity, using such mecha-\nnisms as  EntityManager injection, propagation of persistence contexts, and Java classloading. Through these \nmechanisms, any EJB3-compliant application server can plug in any JPA provider and run it within the host \ncontainer. The Spring Framework’s container is also capable of hosting a JPA provider. \n JPA can be used outside of an EJB in a plain Java environment. In plain Java, the  EntityManager API is \nused directly to initiate and terminate transactions, which are always local to the  EntityManager that cre-\nated them (see  Figure 10.38 ). JPA transactions in a plain Java environment are simple JDBC-level single-RM \ntransactions. \nusing System;\nusing System.Data;\nusing System.Data.Sql;\nusing System.Data.SqlTypes;\nusing Microsoft.SqlServer.Server;\npublic partial class StoredProcedures\n{\n    [Microsoft.SqlServer.Server.SqlProcedure]\n     public static void Transfer()\n     {\n       SqlConnection conn = new SqlConnection();\n       conn.ConnectionString = “Context Connection=true”;\n       SqlCommand cmd = new SqlCommand();\n       cmd.Connection = conn;\n       cmd.CommandText = @“SELECT ToAccount, [Number] \n                         FROM Account ;”\n       conn.Open();\n       SqlDataReader rdr = cmd.ExecuteReader();\n       SqlContext.Pipe.Send(rdr);\n       rdr.Close();\n       conn.Close();    \n     }\n};\n FIGURE 10.37 \n Stored Procedure Written in C#. This stored procedure retrieves all matching account numbers. \n",
      "content_length": 2586,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 340,
      "content": " When running in an EJB the  EntityManager transaction joins the global transaction managed by JTA \n(see  Figure 10.39 ). Updates to JPA entities can then be coordinated with updates to any other transactional \nresources enlisted in the same transaction for the EJB. \n A JPA entity can be used in any stateful or stateless session bean with either the implicit or explicit pro-\ngramming models. \nEntityManager em = emf.getEntityManager();\nEntityTransaction tx = em.getTransaction();\ntry\n{\n    tx.begin();\n      {user code to persist objects}\n    tx.commit();\n}\ndone\n{\n    if (tx.isActive())\n    {\n        tx.rollback();\n    }\n}\nem.close();\n FIGURE 10.38 \n JPA Uses Locally Managed Transactions in Plain Java. An  EntityManager API transaction is associated with a local \nJDBC transaction when used outside of an EJB. \n@Stateless \n@TransactionManagement(TransactionManagementType.BEAN)\npublic class TransferBean implements Transfer {\n    @PersistenceContext EntityManager em;\n    @Resource UserTransaction tx;\n    public boolean transfer(int sourceAcct, int destAcct, int amount) {\n        Account src = em.find(Account.class, sourceAcct);\n        Account dest = em.find(Account.class, destAcct);\n        if (src == null || dest == null) return false;\n        try {\n            tx.begin();\n            src.setBalance(src.getBalance() – amt);\n            dest.setBalance(dest.getBalance() + amt);\n            tx.commit();\n        } catch  (Exception ex) {\n            try { tx.rollback(); } catch (Exception e) {}\n            return false;\n        }\n        return true;\n}\n FIGURE 10.39 \n JPA Transactions Enlist with a JTA Managed Transaction When Used within an EJB. The example illustrates a bean-\nmanaged transaction using JPA with JTA to update two account records. \n10.6 Persistence Abstraction Mechanisms  321\n",
      "content_length": 1815,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 341,
      "content": "322  CHAPTER 10 Transactional Middleware Products and Standards\n ADO.NET and the ADO.NET Entity Framework \n ADO .NET provides a consistent abstraction for .NET programs to access data resources, such as SQL Server \ndatabases, XML ﬁ les, and other resources accessible through OLE DB or ODBC. It offers generic classes for \naccessing the data, such as  DataTableCollection to access the tables in a database and  DataTable to \naccess the schema and rows of a table. A client program can directly retrieve data, update data, or run a stored \nprocedure. A client can also retrieve data into a  DataSet object, which is an in-memory relational database. \nData that is modiﬁ ed in the  DataSet object can optionally be transferred back to the data source. \n ADO .NET connects to a resource manager through an adaptor called a  data provider . There are built-in \ndata providers for SQL Server, Oracle, OLE DB, and ODBC. Various database vendors also offer ADO.NET \ndata providers. \n In addition to ADO.NET, there is a newer data-access API called the ADO.NET Entity Framework, which \noffers access to data expressed in a new data model called the  entity data model (EDM) . EDM is based on \nthe extended entity-relationship model commonly used for database design. It has constructs for inheritance, \nassociations (i.e., relationships), and complex types. The Entity Framework simpliﬁ es programmatic access \nto relational data by mapping a conceptual schema expressed in EDM into an underlying relational database, \nwhich is connected to the Entity Framework using an ADO.NET data provider. \n The Entity Framework differs from an object-relational mapping because an EDM schema represents an \nabstract deﬁ nition of data separate from either the programming object or the relational database. Relationships \namong entities are explicitly deﬁ ned within the model, eliminating the need to join relational tables using for-\neign keys. Multiple different EDM schemas can be mapped to the same physical database. \n The Entity Framework offers four ways to access data. First, data can be accessed as entities using Entity SQL, \nwhich is an extension of SQL that can manipulate data that conforms to an EDM schema. This enables access \nusing standard database interfaces, such as query builders and report writers. Second, the Entity Framework can \ngenerate an object-oriented interface that corresponds to the EDM schema. This provides strongly-typed  read \nand write access through object-oriented programming languages, such as C# and VB. Third, queries against this \nobject-oriented representation can be expressed in the language-integrated query (LINQ) mechanism of the .NET \nFramework. LINQ enables compile-time checking of queries against the schema. Finally, data can be represented \nas web resources that are addressed by URIs and accessed using HTTP commands. \n For example, consider an EDM schema  BankDB that has two entity sets,  Customers and  Accounts , and \na relationship between them called  CustomerAccounts . The entity type  Accounts has a role  Customer that \nrelates each account to the customer that owns it.  Figure 10.40 illustrates an Entity SQL statement that ﬁ nds the \nbalance for a given customer account. In this case,  acct.Customer.CustomerName  navigates the relationship \nbetween the  Customers and  Accounts sets to retrieve the  CustomerName from the appropriate entity. \n ADO .NET Data Services offers REST-style access to EDM data, returning data in the format of ATOM/XML \nor JSON. ADO.NET Data Services are implemented using a specialized version of a WCF service to which \ninstructions are sent via URL parameters. For example, the following URI accesses  Customers of  BankDB : \n http://www.BankDB.com/transfer.svc/Customers \nSELECT acct.Customer.CustomerName, acct.Balance\nFROM BankDB.Accounts AS acct\nWHERE acct.AccountNumber = @acctNum\n FIGURE 10.40 \n Entity SQL Example. The Entity Framework’s Entity SQL is similar to SQL but abstracts data access mechanics to use a \nmapping layer called an entity provider. \n",
      "content_length": 4051,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 342,
      "content": " If customer number is the key of  Customers , then a query to return  CustomerName of customer number \n345 could be expressed like this: \n http://www.BankDB.com/transfer.svc/Customers(345)/CustomerName \n An EDM schema is deﬁ ned in a separate schema ﬁ le, expressed as an XML document. A mapping from \na conceptual EDM schema into a relational database schema is expressed in a similar format. These ﬁ les can \nbe generated by a graphical schema and mapping editor or created manually. The mapping is compiled into an \ninternal form that the runtime layer uses to translate operations on the conceptual schema into operations on \nthe relational database. \n If an application accesses an EDM database as a set of objects, then the Entity Framework generates a class \nfor the EDM database derived from the class  ObjectContext . This class includes a connection to the data-\nbase, metadata that describes the EDM schema, and the state of objects in the client cache. It tracks each object \nhanded out through a query, notes any objects that change, and generates the required statements for implic-\nitly updating the objects when they are returned to the entity provider. The Entity Framework uses a form of \noptimistic concurrency control in which the user optionally speciﬁ es a subset of properties to be used to track \nchanges (for example, a timestamp or version property), along with the identity properties of any entities to \nbe updated. During update operations, if the values on the server no longer match the values obtained by the \noriginal query, the update fails and the framework throws an exception. The application then decides whether \nto refresh the client objects with the values on the server or commit the changes made on the client. An appli-\ncation can explicitly issue an update using the  SaveChanges() command.  Figure 10.41 shows an example of \na transaction that updates two accounts, very similar to the JPA example in  Figure 10.39 . \npublic class TransferClass implements Transfer {\n  public bool transfer(int sourceAcct, int destAcct, int amount) {\n     // Connection string for BankDB is specified in a configuration file\n     BankDB db = new BankDB();\n     var src = from a in db.Accounts\n               where a.AccountNumber = sourceAcct\n               select a;\n     var dest = from a in db.Accounts\n                where a.AccountNumber = destAcct\n                select a;\n     try {\n         src.FirstOrDefault().Balance = src.FirstOrDefault().Balance – amt);\n         dest.FirstOrDefault().Balance = dest.FirstOrDefault().Balance + amt);\n         db.SaveChanges();\n     } catch  (OptimisticConcurrencyException) {\n         try {\n             db.Refresh(src, RefreshMode.StoreWins); \n             db.Refresh(dest, RefreshMode.StoreWins); }\n         catch (Exception) {}\n         return false;\n     } catch  (NullReferenceException) {\n         return false;\n     }\n     return true;\n  }\n}\n FIGURE 10.41 \n A Transaction in the ADO.NET Entity Framework. This example illustrates a transaction that updates two accounts. The \nqueries assigned to  src and  dest are expressed in LINQ. \n10.6 Persistence Abstraction Mechanisms  323\n",
      "content_length": 3165,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 343,
      "content": "324  CHAPTER 10 Transactional Middleware Products and Standards\n 10.7  LEGACY TP MONITORS \n Transactional middleware products began with the development and deployment of dedicated hardware and \nsoftware systems, designed speciﬁ cally for use in processing transactions. The ﬁ rst such system, called SABRE, \nwas developed by IBM and American Airlines in the late 1950s and early 1960s as an automated way of reserv-\ning seats on airplanes. Later it was adapted for use by other airlines. The operating system layer became an IBM \nproduct called ACP (Airline Control Program) with PARS (Programmed Airline Reservation System) as one of \nthe applications. An offshoot named PARS-Financial was used in the ﬁ nance industry. The product introduced \nmany useful innovations, such as system performance modeling prior to system construction, replicated writes, \nfast restart (at most 5 seconds), intelligent terminal controller, client failover, and workload migration. However, \nin one respect, it was quite bare-bones by today’s standards: ACID transaction semantics was implemented \nby the application. Many years later, acknowledging its use outside the airline industry, IBM renamed it TPF \n(Transaction Processing Facility). TPF is still used for airline reservations some 40 years later, and by several \nﬁ nancial institutions, for example to process credit card payments. \n In the late 1960s, IBM released two TP monitor products with much more functionality, IMS (Information \nManagement System) and CICS (Customer Information Control System). CICS was developed before IMS, \nby IBM’s ﬁ eld engineering group, initially for one speciﬁ c customer, but was not released as a product until \nafter IMS. All of these TP monitors were designed for the mainframe environment and typically were used on \nmachines dedicated to a single application. \n During the minicomputer area, roughly from 1980 to 2000, a new generation of distributed TP monitors \nemerged. Operating systems for these machines were designed to work well with many more processes than \nmainframe systems. So these TP monitors make heavier use of processes, which enable them to scale up an \napplication by moving processes onto more machines. This is in contrast to earlier mainframe TP monitors, \nwhere scaling up usually involves buying a larger mainframe machine. \n Legacy TP monitors typically include a lot of product-speciﬁ c components. They are part of the TP moni-\ntor because they’re essential for the construction and deployment of TP applications but were not part of the \nunderlying platform at the time the TP monitor product was developed. Examples include specialized resource \nmanagers such as database management systems, indexed ﬁ les, and queues; specialized presentation technol-\nogy for vendor-speciﬁ c terminals; program development tools; and system management environments. Today, \nmany of these components are available as general-purpose technology, such as general-purpose system man-\nagement tools, display devices, and database systems. \n Many applications still exist that are based on legacy TP monitors, because the applications work well and \nthe cost of rewriting the application exceeds the expected savings in moving to commodity technologies. This \nsection describes some of these products — ones that you may still encounter, for example in the context of a \nlegacy modernization, interoperability, or SOA project. \n One challenge with modernization, interoperability, and SOA projects is ﬁ nding a good point of entry for \nan external call into the legacy application. Many older applications are not very modular, due to poor initial \ndesign, tight integration of components to meet stringent performance requirements, or many changes made to \nthe application over the years. Sometimes this means that the applications themselves have to be modiﬁ ed to \ncomplete the project, and it can be difﬁ cult ﬁ nding programmers who are qualiﬁ ed to work in the legacy com-\nputing environment. \n The legacy TP monitors described in this section all are popular enough that interfaces to modern TP environ-\nments have been built for them, such as Web Services wrappers, Java EE connectors, CORBA interfaces, and mes-\nsage queue adapters. In some cases capabilities such as these have been added directly into the legacy TP monitors \nthemselves. And as we have already seen, both the .NET Framework and Java EE transactional middleware envi-\nronments include capabilities speciﬁ cally designed for integration with these (and other) legacy environments. \n",
      "content_length": 4551,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 344,
      "content": " CICS Transaction Server \n CICS is IBM’s most popular legacy TP monitor. It pioneered many of the technologies and approaches found \nin modern transactional middleware products, including two-phase commit and transactional RPC. \n Developed in 1968 to improve the efﬁ ciency of mainframe operating system environments, CICS is now \na family of products running on the VSE and z/OS operating systems. A version of the CICS product called \nTX Series runs on the UNIX and Windows operating systems. Although there is some variation of features \nbetween the different implementations, the products all support essentially the same  “ command level ” API. \n Commands are embedded using the preﬁ x  EXEC CICS in any of the supported languages: COBOL, PL/I, \nAssembler, C/C \u0005 \u0005 , and Java. The commands are translated by a precompiler into CICS function calls to carry \nout the requested operations. For example, the following are commands to send a form to a terminal, receive a \nform from a terminal, and link to another CICS program: \n EXEC CICS SEND… \n EXEC CICS RECEIVE… \n EXEC CICS LINK… \n IBM and various third-party vendors offer toolkits for enabling Web Service access of CICS applications, \nallowing them to participate in SOA-based applications. These convert existing COBOL data types to XML \nand generate SOAP messages and WSDL interfaces from the COBOL metadata (often called the Copy Book \nor  COMMAREA ). CICS supports HTTP as a transport, which allows SOAP and plain XML messages to be \nexchanged with CICS transactions. \n Other approaches to legacy integration employ an intermediate node, such as a UNIX or Windows system \nrunning the TX Series version of CICS. The intermediate node runs Web Services or other formats and pro-\ntocols, which are converted into legacy formats and protocols. Deploying the integration solution on an inter-\nmediate machine can avoid having to modify the mainframe CICS application or install additional integration \nsoftware on the mainframe. \n Most CICS remote communication today uses TCP/IP and HTTP. LU6.2 gateways are still in use but IIOP, \nRMI, and WebSphere MQ protocols are more typical. IBM also has ported WebSphere Application Server to \nthe mainframe, which can invoke EJB Session Beans hosted in CICS. \n System Architecture \n CICS offers a process-like abstraction called a  region . A region is an address space that can execute mul-\ntiple threads. CICS implements its own middleware-level threading abstraction (see Section 2.3). A region can \nown resources, such as terminals, programs, communications, and databases. The failure of an application is \nscoped to a region; that is, when a failure occurs, it affects only the region. The unit of distribution likewise is \na region. \n Each CICS resource type is described by a table, whose entries list resources of that type (see  Figure \n10.42 ). In early mainframe versions of CICS, it was common practice to have all resources of a TP application \nbe owned by a single region. Early communications mechanisms were limited and had high overhead, so this \nwas the most efﬁ cient structure. It amounts to running all tiers of a TP application in a single process. Today, \ncommunications capabilities are much improved, so the recommended practice is to partition an application \ninto three regions that correspond roughly to the multitier transactional middleware model: a terminal region \n(the front-end program), an application region (request controller), and a data region (transaction server). \n A CICS region can communicate with another region and with an external application using a dynamic pro-\ngram link (DPL), an RPC-style mechanism speciﬁ c to CICS. Inter-region  communication points offer good \nopportunities for integration with applications based on other technologies, including through an external client. \n10.7 Legacy TP Monitors  325\n",
      "content_length": 3864,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 345,
      "content": "326  CHAPTER 10 Transactional Middleware Products and Standards\n In a terminal region, the terminal table identiﬁ es the terminals attached to the region. When a user logs in, \nthe user is authenticated via a password; later accesses to data resources are controlled via an access control \nlist external to CICS. The region can support geographical entitlement by optionally checking that the user is \nauthorized to operate from the given terminal within a given time period and to fulﬁ ll a given role (such as the \nmaster terminal operator). \n “ Transaction ” is the CICS term for a request. Each request entered by a user includes a four-character \ntransaction code. Using the region’s transaction table, the request can be sent to a region that can process it. In \nCICS, this is called  transaction routing . In our model, it corresponds to using a request controller to route a \nrequest from a front-end program to a transaction server. \n Requests that arrive at a region are classiﬁ ed based on request type, user, and terminal ID. Once the request \nis scheduled, the program table checks whether or not this request type can be processed locally, and whether \nthe user and terminal are authorized to run this request. It then loads the application program if it’s not already \nloaded. (Multiple users can share the same copy of a transaction program.) Then CICS creates a  task , which \nis the execution of a transaction program for a given user and request, assigns it an execution thread, and auto-\nmatically starts a transaction using the chained transaction model. Each execution thread is reclaimed for use \nby another program when the reply message is sent. \n Front-End Program \n Before the widespread adoption of PCs, most CICS systems were accessed by IBM 3270 block-mode termi-\nnals, which send and receive a screen of data at a time. This is still a popular mode of access, sometimes with \n3270 emulation software running on the PC or other displays that conform to the 3270’s data stream communi-\ncations protocol. Thus, one way for an external system to communicate with a CICS application is to emulate a \n3270 terminal and communicate using the 3270 protocol. A function called the external programming interface \n(EPI) provides this support. EPI is also used to connect a variety of external clients. \n CICS has a built-in forms manager, called Basic Mapping Services (BMS), which maps between a device-\noriented view of the data and program-oriented data structures. BMS can be used to interact with 3270 terminals and \nTransaction\nprogram\nlibrary\nOther CICS regions\nand non-CICS\napplications\nDisplays\nCICS region\nCommunications\nlinks\nTerminal and user tables\nTransaction program table\nCommunications\ntable\nResource\ntable\nLoaded programs\nCommands for display access,\nresource access, communications,\nand transaction control\nData\nresources\n FIGURE 10.42 \n A CICS Region. A region provides multithreading and controls application resources, including devices, transaction \nprograms, data resources, and communications links. \n",
      "content_length": 3047,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 346,
      "content": " other types of devices. Typical Web Service enablement and other interoperability tools support COMMAREA \ndirect calls (DPL style), 3270 emulation, and BMS emulation. \n TP Communications \n CICS offers applications a variety of ways to call remote programs. We have already encountered EPI. Some \nothers are: \n ■  Distributed Program Link (DPL), which is a programming model similar to a remote procedure call. \nDPL is synchronous, that is, the application waits for the results (see  Figure 10.43 ). \n ■  Multiregion Operation (MRO) and Inter-Systems Communication (ISC), which are available on CICS \nVSE and zOS, are transport mechanisms that enable communications between regions running on the \nsame mainframe (i.e., transaction routing and DPL can be implemented using MRO or ISC). \n ■  Distributed Transaction Processing (DTP), which is the interface to a peer-to-peer communications \ntransport. It uses the LU6.2 protocol, which is a session-based protocol that associates a transaction with \neach session using the chained transaction model. It propagates transaction context across send-message \noperations and includes a two-phase commit protocol. LU6.2 is part of IBM’s proprietary network archi-\ntecture called SNA (System Network Architecture). \n The COMMAREA is the standard place in main memory to put information to pass via inter-region com-\nmunications facilities such as DPL. Web Services toolkits for CICS also use the COMMAREA to obtain mes-\nsage deﬁ nitions. COMMAREA data types typically are converted to XML data types for use in Web Services. \n The CICS Universal Client product from IBM includes programming libraries for Visual Basic, C/C \u0005 \u0005 , \nand COBOL, and supports both TCP/IP and SNA-based communication protocols. \n Database Access \n CICS initially was implemented on mainframe operating systems that did not support efﬁ cient multithread-\ning. Thus, multithreading was implemented by CICS. Recall from Section 2.3 that such an implementation \nmust not allow application programs to issue blocking operations, since they would delay all the threads in the \nCICS server (z/OS  VSE, UNIX) \nDPL\nECI/ESI\nEPI\nHTTP\nCICS region\nTX series or native\nWindows/Unix\nCICS terminal table\nCICS program\nOther CICS\nregions\nProgram table\nCICS universal\nclient\nWeb service\nDesktop/GUI\napplication\n FIGURE 10.43 \n Communications from CICS Clients and External Interfaces. CICS provides multiple communications options for \ndistributed processing and interoperability with external platforms, including the integration of browsers, PCs, and UNIX \nServers. \n10.7 Legacy TP Monitors  327\n",
      "content_length": 2599,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 347,
      "content": "328  CHAPTER 10 Transactional Middleware Products and Standards\n process. Therefore, applications issued all of their database operations to CICS, which could thereby switch \nthreads if a database operation would ordinarily cause the process to be blocked. \n Early versions of CICS did most of their database processing through COBOL indexed ﬁ les, accessing the \nVSAM (Virtual Sequential Access Method) ﬁ le store. CICS and VSAM include services for buffer manage-\nment, block management, indexed access, and optional logging for rollback. CICS was among the ﬁ rst TP \nsystems to offer remote data access, using a facility called  function shipping , which allows an application to \naccess a remote VSAM ﬁ le. \n Later , support was added for IMS databases via the DL/I interface and, more recently, for relational data-\nbases including IBM’s DB2 family via the SQL interface. Implementations of all continue to be found in \nproduction. \n IMS \n IMS (Information Management System) is another popular TP monitor product from IBM. IMS was designed \nwith Rockwell and Caterpillar for the Apollo space program. IMS’s challenge was to inventory the very large \nbill-of-materials for the Saturn V moon rocket and Apollo space vehicle. Thus, its design originally centered \naround its powerful hierarchical database. \n IMS was released in 1968 for IBM mainframes. It was among the ﬁ rst products to offer online database and \ntransaction processing at a time when nearly all data processing was done in batch. IMS runs in both online \nand batch modes, allowing the incremental conversion of an application from batch to online. Like many TP \napplications, most IMS applications still contain a large portion of batch programming. \n IMS consists of both a TP monitor called IMS Transaction Manager (TM) and a hierarchical-style database \nsystem called IMS Database Manager (DB). The TP monitor and database systems are independent and can \nbe conﬁ gured separately, which allows considerable ﬂ exibility. For example, the IMS DB can be used with the \nCICS TP monitor, or IMS TM can be used with DB2, IBM’s relational database product. Multiple IMS sys-\ntems can be conﬁ gured for distributed processing environments and as standby systems for high availability. In \naddition, IMS supports multiple optimizations for fast performance. \n IMS TM is among the ﬁ rst queued messaging systems dedicated to TP. Like CICS, IMS TM can be accessed \nfrom devices, PCs, and UNIX systems outside the mainframe environment. It has speciﬁ c external access points \nfor XML, Web Services, Java EE, and BPEL. A variety of third-party products provide support for Web Service \nenablement and interoperability with IMS, such as Orbix, WebSphere MQ, and WebSphere Application Server. \nIMS DB includes support for XML data mapping, JDBC drivers, and XML Query. \n Basic System Architecture \n Applications run in a  system , which contains the application program itself and the facilities required to sup-\nport the application. In contrast to CICS, which manages its own address space, an IMS application runs in \nan operating system process and accesses TP monitor services such as threading, dispatching, and program \nloading through a call interface to a system library (instead of using an embedded command style language). \nAn example appears in  Figure 10.44 . Multiple applications can run in separate processes to take advantage of \nzSeries symmetric multiprocessing. \n The basic IMS TM model is queued. An end user inputs some data on a device (see  Figure 10.45 ). IMS \nextracts the data, adds a transaction ID, formats the input into a request message, and enqueues it on the input \nqueue. IMS then loads the program associated with the transaction, if it is not already running. Then IMS \ndequeues the input message (starting the transaction), translates the transaction ID into the transaction program \nname, and routes the message to the application, which executes the transaction program using the input data. \nDequeuing a message starts a transaction. When the transaction program completes, the application enqueues \n",
      "content_length": 4105,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 348,
      "content": " a reply message to the output queue associated with the input device or program. There are options to enqueue \nthe reply message to a different device, another application, or a speciﬁ c user, instead of or in addition to the \ninput device. \n IMS TM also offers an optimization called Fast Path, which essentially allows the application to bypass \nthe queuing system (i.e., request controller) and send simple request messages directly from the device to the \ntransaction program, using a predeﬁ ned mapping that is kept resident in main memory. Requests identify the \nfast path transaction programs, which are preloaded and ready to process the requests. The fast path can also \nuse a special main memory database, with advanced concurrency control features, as described in Section 6.5 \non Hot Spot locking. \n An interface called the Open Transaction Manager Access (OTMA), allows multiple communications man-\nagers to connect to IMS. Using OTMA, IMS receives transaction requests from any source on the network and \nroutes responses back. \nPROCEDURE DIVISION.\nENTRY-LINKAGE.\n     ENTRY ‘DLITCBL’ USING I-O-PCB DB-PCB.\nMAIN PROGRAM.\n     PERFORM GET-MSG-ROUTINE THRU GET-MESSAGE-ROUTINE-EXIT\n                    UNITL I-O-STATUS-CODE EQUAL NO-MORE-MESSAGES.\n    GO BACK\n FIGURE 10.44 \n IMS COBOL Example. The PROCEDURE DIVISION starts with a loop that executes until no more messages are found on \nthe queue. The ﬁ rst time a request is issued for this program, IMS loads it and keeps it loaded until all requests for the \nprogram are completed. \nWeb services\nJava EE\nAPPC/IMS \nInput\nQueue\nOutput\nQueue\nDevice\nIMS System\nExternal Subsystem\nApplication\nProgram\nMQI\nSQL\nIMS/DB\nDB2\nMSC\nISC\n FIGURE 10.45 \n Basic IMS System Architecture. Request and reply messages move between a device and an application via queues. \nVarious gateways connect IMS to external communications systems and resource managers. \n10.7 Legacy TP Monitors  329\n",
      "content_length": 1935,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 349,
      "content": "330  CHAPTER 10 Transactional Middleware Products and Standards\n Security options include device security (which controls the entry of IMS commands), password security, \nand access control on transactions, commands, control regions, and application programs. \n Front-End Program \n IMS TM includes a built-in forms manager, called Message Format Service (MFS), and an optional Screen \nDeﬁ nition Facility (SDF) that deﬁ nes and formats IBM 3270 terminal screens and collects the input data and \ntransaction ID for the request message. \n TP Communications \n IMS TM is based on a queued TP model, rather than a direct TP model such as RPC. This has enhanced recov-\nery compared to most TP monitors, at the cost of extra transactions and I/O, as described in Chapter 4. \n Applications access the input and output queues using calls to retrieve input messages, to return output \nmessages to the sending device, and to send output messages to other application programs and devices. MFS \nassists in translating messages between device format (originally the terminal format) and the application pro-\ngram format. \n Extensions to IMS allow it to accept a remote call from a PC or workstation, access an IMS database via SQL, \nuse APPC for LU6.2 conversational communications with CICS, access the message queue interface (MQI) to \ninteroperate with WebSphere MQ, and accept calls from a CORBA wrapper, EJB, or Web Service. IMS also \nsupports TCP/IP sockets for LU6.2-style conversations. And IMS supports IBM’s Intersystem Communication \n(ISC), which allows communication among multiple IMS systems or between an IMS system and a CICS region; \nand Multiple Systems Coupling (MSC), which allows communication among multiple IMS systems. \n Database Access \n The native database system that comes with IMS is based on a hierarchical model, which preceded the devel-\nopment of relational database systems. The higher performance of the hierarchical model is one of the rea-\nsons IMS-based applications are still in production. Today’s IMS applications can also use DB2, in addition \nto or in place of the IMS DB database. The database access runs using the application’s thread. A data propa-\ngation utility is available that moves data updates from IMS DB to DB2, or vice versa, automatically. Java \nlibrary support allows IMS DB to invoke stored procedures hosted in DB2. Other tools allow data to be moved \nbetween IMS and non-IBM relational databases. \n Tuxedo \n Tuxedo is a legacy TP monitor from Oracle. Tuxedo runs on a variety of UNIX and Windows platforms. Oracle \nowns the rights for Tuxedo, as do a few resellers who customize the product for their own platforms (e.g., \nUNISYS and Bull). AT & T’s Bell Laboratories created Tuxedo in 1984, primarily to service telecommunication \napplications, which remains its largest market. The Tuxedo design is based on IMS, and originally was intended \nto replace IMS at the US telephone companies (who are large IMS users). \n Tuxedo supports several options for interoperability with external systems, including Java EE, Web Services, \nand CORBA. \n Tuxedo was the basis for many of the X/Open DTP standards, including the DTP model itself, XA, TX, \nand XATMI. Tuxedo also implements OTS via its CORBA API. \n",
      "content_length": 3247,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 350,
      "content": " System Architecture \n Tuxedo provides two main APIs. One is called the  Application Transaction Monitor Interface (ATMI) , \nwhich is a collection of runtime services that are called directly by a C, C \u0005 \u0005 , or COBOL application. The \nother is the CORBA C \u0005 \u0005 API. Tuxedo runtime services provide support for communications, distributed \ntransactions, and system management. In contrast to the full-featured CICS API, ATMI relies heavily on UNIX \nsystem libraries and external database system services for ﬁ lling some TP application requirements. \n The ATMI function  tpcall() invokes a Tuxedo service. A typical  tpcall is shown in the following \nexample: \n tpcall (  “ TRANS ” , (char *)reqfb, 0, (char **) & reqfb, (long *) & reqlen, ); \n Tuxedo services can be developed using C, C \u0005 \u0005 , or COBOL. Native Tuxedo API clients can be developed \nusing C, C \u0005 \u0005 , COBOL, and Java. Tuxedo services can be written using Java when they are hosted on the \nOracle WebLogic Server using its domain gateway feature. And CORBA-compliant Tuxedo API clients and \nservers can be developed using C \u0005 \u0005 . \n Tuxedo ’s services are implemented using a shared memory area called the  bulletin board , which con-\ntains conﬁ guration information (similar to CICS tables) that supports many TP monitor functions (see  Figure \n10.46 ). For example, it contains transaction service names, a mapping of transaction service names to transac-\ntion server addresses, parameter-based routing information, and conﬁ guration options for transaction services \nand servers. \n In a distributed environment, one system at a time is designated as having the master bulletin board. \nThe bulletin board at each node is loaded into shared memory from a conﬁ guration ﬁ le when Tuxedo boots. \nChanges to the master bulletin board are written to the conﬁ guration ﬁ le, which is propagated at boot time if \nit has changed since the last boot. The master copy of the bulletin board is propagated at the boot of a new \nmachine. Other nodes reload the ﬁ le to see the updated state. Servers and services can be added, modiﬁ ed, or \nremoved dynamically. \nClient\nClient\nBulletin Board\nBulletin Board\nNode A\nNode B\nServer\nServer\nBridge\nBridge\n FIGURE 10.46 \n Tuxedo Client/Server Architecture. Requests are routed to the correct server process using the bulletin board, whether \non a local or remote node. \n10.7 Legacy TP Monitors  331\n",
      "content_length": 2392,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 351,
      "content": "332  CHAPTER 10 Transactional Middleware Products and Standards\n A Tuxedo system consists of client and server processes. Clients typically provide presentation services to \nusers. That is, they interact with devices that issue requests and do not access transactional resource manag-\ners. Unlike CICS and IMS, a Tuxedo client is allowed to issue a Start operation, which may optionally be for-\nwarded to the server (request controller or transaction server) to actually start the transaction. \n Tuxedo systems are conﬁ gured in a  domain , which deﬁ nes the scope of computers in the network that par-\nticipate in a given application. The domain concept essentially represents an administrative boundary around \nparticipating client and server processes in a network and represents the scope of shared access to bulletin \nboard metadata. A domain also can be federated with other domains to increase the scalability of large Tuxedo \ninstallations. \n Although the bulletin board typically is used for the request controller, a Tuxedo server can perform the \nfunctions of request controller, transaction server, or both. This ﬂ exibility allows an application to be struc-\ntured into a multitier architecture, but doesn’t require it. \n In Tuxedo, a  service is the name of a server interface. When a client calls a service, the bulletin board for-\nwards the call to a server that supports the service, similar to how IMS routes a queued message to a transaction \nprogram. The server might be on a different node than the client, in which case the bulletin board routes the \nrequest via a bridge to the other node. When a service becomes available, the server advertises the service by \nposting the service name to the bulletin board. Each server process has a main memory queue that is used for \nincoming messages (see  Figure 10.47 ). A call to a service causes a message to be put into its queue. As in IMS, \nthe server dequeues messages sent by the client and does the requested work, optionally in priority order. When \nit’s done, the server sends a reply message to a message queue associated with the client, which includes a status \nthat tells whether the call completed successfully or resulted in an error. The client dequeues the message and \nprocesses the reply. \n The Tuxedo API offers programmers explicit transaction control primitives — for example,  tpbegin , \n tpcommit , and  tpabort . \n Flags can be set in the client program and in the conﬁ guration ﬁ le to place the execution of transaction \np rograms in automatic, or implicit, transaction mode. In implicit transaction mode, a transaction is started \nautomatically when the transaction program receives control from the front-end program (or client program, \nin Tuxedo terminology), and is automatically committed if the execution of the server program is successful. \nServer\nClient\nQueues\nService\nTPCALL\n FIGURE 10.47 \n Tuxedo Request Message Flow. Requests are routed between client and server processes using input and output queues. \n",
      "content_length": 3011,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 352,
      "content": " If the client program starts a transaction, automatic transaction mode detects the existing transaction and \nincludes the called transaction program in the same transaction. An execution error (that is, a return of bad \nstatus) results in an automatic transaction abort. This is similar to the way CICS handles transactions for DPL-\ninvoked programs. \n An explicit programming model option is asynchronous commit processing, where an application can con-\ntinue without waiting for the second phase to complete in a two-phase commit operation. \n Error handling is at the application level. The program examines a global variable to get an error message, \nand checks this error status after every call, as in IMS programming. \n Front-End Program \n Some legacy applications still use Tuxedo’s Data Entry System forms package, originally designed for use on \ncharacter cell terminals. The input on such a form contains the desired transaction type’s service name and a typed \nbuffer that contains the input data. It also includes ﬂ ags that select various options, such as automatically starting a \ntransaction for the server being called and automatically retrying after an operating system interrupt signal. \n Native communication messages are constructed using Tuxedo’s Field Manipulation Language (FML). \nThis creates typed buffers, which are similar to the CICS COMMAREA. \n Tuxedo offers several options for external client access, including the /WS package for UNIX and PC cli-\nents, web browser and Web Services clients, CORBA clients, and a Java client for use with Oracle’s WebLogic \napplication server. Tuxedo also supports interoperability with JMS-based message queues. \n TP Communications \n Processes using the ATMI protocol can communicate using a choice of peer-to-peer message passing, remote \nprocedure calls, or an event posting mechanism. An RPC can be synchronous (i.e., the application waits for \nthe results) or asynchronous (i.e., the application asks sometime later for the results). Using peer-to-peer mes-\nsage passing, the programmer can establish a conversational session between the front-end program and the \ntransaction server and exchange messages in an application-deﬁ ned order, rather than in the strict request-reply \nstyle of RPC. A subscription service puts events on the bulletin board, and an event posting mechanism allows \na server to raise an event, which sends an unsolicited message to one or more clients (in the case of multiple \nclients this represents a type of broadcast facility). \n Servers developed using the CORBA API can communicate using the RMI/IIOP protocol. Tuxedo serv-\ners can interact bidirectionally with an HTTP Web Service through Tuxedo’s SALT (Services Architecture \nLeveraging Tuxedo) gateway. Tuxedo also includes a variety of mainframe connectivity options, including \nTCP/IP, SNA, and OSI TP-based protocols with speciﬁ c support for invoking CICS and IMS transactions. \n When a server calls another server, the caller can specify whether the callee runs in the same transaction or \noutside of the transaction context. \n Database Access \n TUXEDO has a built-in transaction manager that supports two-phase commit. It can use any XA-compliant \nresource manager, such as Oracle, Sybase, DB2, or SQL Server. \n ACMS \n ACMS (Application Control and Management System) is a legacy TP monitor from HP. ACMS was developed \nby Digital Equipment Corporation in the early 1980s as part of an effort to gain market share in commercial \n10.7 Legacy TP Monitors  333\n",
      "content_length": 3520,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 353,
      "content": "334  CHAPTER 10 Transactional Middleware Products and Standards\n applications. (Digital’s initial strength was in scientiﬁ c computing.) ACMS runs on the HP OpenVMS operating \nsystem. \n ACMS was originally released in 1984 as part of the integrated VAX Information Architecture product set \nalong with Rdb (relational database system), DBMS (CODASYL database system), TDMS (original forms \nsystem), DECforms (a newer forms system), CDD (Common Data Dictionary), and Datatrieve (query and \nreport writer for record-oriented ﬁ les and databases). ACMS pioneered many transactional RPC and abstrac-\ntion concepts, and remains a popular TP monitor for the HP OpenVMS environment. \n System Architecture \n ACMS uses a three-process TP monitor model in which each of the three tiers is mapped to a different operat-\ning system process, very similar to our multitier architecture: front-end program, request controller, and trans-\naction server (see  Figure 10.48 ). The processes communicate via a proprietary RPC. \n ACMS applications accept a request for the execution of a transaction from a terminal or other display \ndevice connected to the process running the front-end program, called the  Command Process . It is multi-\nthreaded to handle multiple devices concurrently. The front-end program sends a request message to the \nrequest controller process, called the  Task Server . (A  task is a program in a request controller that controls \na request.) The request controller is also multithreaded to handle multiple requests concurrently. The request \ncontroller calls a procedure running in the transaction server, which ACMS calls the  Procedure Server . Since \nthe transaction server is single-threaded, it is typically deployed as a server class consisting of multiple server \nprocesses. ACMS monitors the workload on transaction servers to determine whether enough server process \ninstances are active to handle the application workload. If there are too few, it automatically starts another \nserver instance. If a server is idle for too long, ACMS automatically deletes it to conserve system resources. \nDECforms:\nlogin,\nmenus and\nforms  \nSI: External\ndisplay and\ndevice\naccess\nTDL: Task\nflow and\ntransaction\ncontrol \nTDL:\nException\nhandling,\nthreading,\nRPC stubs\nand proxies \nStandard\nprocedures\n& SQL:\ndatabase\nand file\naccess\nCommuni-\ncations\ngateways\nRPC \nRPC\nResource\nmanagers\nOther TP\nMonitors\nCommand\nProcess\nExecution\nController\nProcedure\nServer\n FIGURE 10.48 \n ACMS Three-Process Model. Remote procedure calls communicate among predeﬁ ned processes tuned for speciﬁ c \ntypes of application work. The Task Deﬁ nition Language deﬁ nes the workﬂ ow and controls transactions. \n",
      "content_length": 2688,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 354,
      "content": " In contrast to CICS, IMS, and Tuxedo, ACMS has a specialized compiled language, the Task Deﬁ nition \nLanguage (TDL), for specifying request control. It supports features that were required by the ACMS model \nbut not present in traditional imperative languages in the early 1980s when ACMS was designed, such as RPC, \nmultithreading, transaction control, and structured exception handling. TDL is designed to work in conjunc-\ntion with TDMS and DECforms for menu and forms handling and with any OpenVMS language for transac-\ntion server development. It was standardized by X/Open as the Structured Transaction Deﬁ nition Language \n(STDL). ACMS was also the basis of the X/Open Transactional RPC speciﬁ cation (TxRPC).  Figure 10.49 \ncontains an example of TDL calls to transaction server procedures. \n When an exception occurs, control is passed to the ACTION portion of the task. Certain exceptions auto-\nmatically abort the transaction before branching to the exception handler, as in CICS or automatic transaction \nmode of Tuxedo. A single resource transaction can be started in the procedure server. \n ACMS offers an open, call-level interface to its RPC, called the Systems Interface (SI) API, for connecting \nspecialized devices such as ATMs, gas pumps, and telecom switches. The SI also has been used to create cli-\nents external to ACMS, such as .NET clients, web browsers, and Java EE clients. \n TP Communications \n All process-to-process communication is via a proprietary RPC protocol, including calling a procedure in \nanother process on the same machine. It is possible to change a local call (i.e., in the same process) to a remote \ncall via a conﬁ guration change. \n REPLACE TASK TRANSFER \n \n WORKSPACES ARE CUSTOMER_WKSP, \n                ACCOUNTS_WKSP; \n TASK ARGUMENTS ARE CUSTOMER_WKSP WITH ACCESS READ,\n                    ACCOUNTS_WKSP WITH ACCESS MODIFY; \n BLOCK\n    ...\n        BLOCK WORK WITH TRANSACTION IS \n  \n           PROCESSING WORK IS  \n           CALL WITHDRAW_PROC USING CUSTOMER_WKSP, ACCOUNT_WKSP; \n           CALL DEPOSIT_PROC USING CUSTOMER_WKSP, ACCOUNT_WKSP; \n                                                     \n           EXCHANGE WORK IS  ...\n           ACTION IS  ...\n \n        END BLOCK WORK; \n \n END BLOCK; \n END DEFINITION;\n FIGURE 10.49 \n ACMS TDL Example for the Transfer Task. The ACMS task deﬁ nition declares the data to be passed to a procedure using \nrecord deﬁ nitions and can call multiple procedures within the same transaction block. \n10.7 Legacy TP Monitors  335\n",
      "content_length": 2522,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 355,
      "content": "336  CHAPTER 10 Transactional Middleware Products and Standards\n TDL includes an interface deﬁ nition language called the  task group . The TDL compiler uses the task group \ninformation to generate proxy and stub programs to be linked with the RPC caller and callee. The callee typically \nwould be a procedure server developed using any of the OpenVMS supported languages, such as COBOL, C, \nFORTRAN, Basic, Pascal, and Ada. This allows callers to use standard procedure call syntax, rather than explic-\nitly constructing a specially-formatted  buffer and then passing it in the call (as in CICS and Tuxedo). Information \nabout the request, such as the security context and display identiﬁ er, is automatically placed in hidden arguments \nand is forwarded transparently to the server, where it becomes part of the server’s context. \n ACMS uses OpenVMS cluster technology to support high availability for applications, by automati-\ncally redirecting an RPC from a failed node to a surviving node. It uses the OpenVMS transaction manager, \nDECdtm, for two-phase commit. It also uses the OpenVMS database, Rdb (now owned by Oracle Corp), for \nautomatic failover in an OpenVMS cluster. That is, the database is available from multiple nodes in the cluster, \nand the application can fail over automatically from a database connection on one machine to a database con-\nnection on another machine, using the OpenVMS lock manager. Using these mechanisms, ACMS is able to \nachieve very high levels of availability. \n ACMS has been extended using a product called TP Ware that includes support for .NET Framework cli-\nents, Java clients, web browsers, and Web Services clients running on the Windows operating system. A product \ncalled the Web Services Integration Toolkit, running on OpenVMS, exposes ACMS tasks as EJBs and Web \nServices. ACMS server procedures can include HP’s APPC/LU6.2 gateway for interoperability with CICS-based \napplications. TP Ware basically replaces the command process in the three-tier architecture with web browser, \n.NET, and Java clients, providing libraries and an API to directly invoke a task in the task server, bypassing the \nCommand Process. \n Database Access \n Transaction server programs directly access any database or resource manager. Certain specialized databases \nare directly accessible from TDL. ACMS includes a queue manager for durable request queue operations. \n If a transaction is bracketed within a TDL program (in a request controller), then ACMS controls the com-\nmitment activity using DECdtm. If it is bracketed within the transaction server, then ACMS is uninvolved in \nthe commitment process. This is useful for database systems that are not integrated with DECdtm, or that offer \nspecialized options that can only be set in the transaction bracket statements. \n Pathway TS/MP \n Pathway with NonStop Transaction Services (TS/MP) is another legacy TP monitor from HP. It was developed \noriginally by Tandem Computers and released in the mid-1980s as a TP development platform for Tandem’s \nGuardian operating system running on their fault-tolerant platform. \n Tandem later teased apart its operating system into a kernel portion, the NonStop Kernel (NSK), with two \nlayers on top: one that supports the Guardian API, and one that supports a POSIX (UNIX) API, called Open \nSystem Services (OSS). OSS supports a native port of Tuxedo and a nonnative port of a Java EE application \nserver (Oracle’s WebLogic). Pathway and Tandem in general, was a pioneer of high availability, fault toler-\nance, and data replication technologies. \n Pathway is based on a client/server process structure and a transaction abstraction. NonStop TS/MP pro-\nvides server process management (e.g., load balancing and automatic server restart). Transaction management \nis implemented using infrastructure called the NonStop Transaction Management Facility (TMF). This TP \ninfrastructure supports all application environments, including Pathway, NonStop Tuxedo, NonStop CORBA, \nNonStop JSP, NonStop SOAP, and NonStop Web Server. TS/MP recently has been completely rearchitected \n",
      "content_length": 4101,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 356,
      "content": " using a new component called Application Cluster Services that extends server management and load balanc-\ning capabilities to the new generation of HP Integrity NonStop processors. \n System Architecture \n Pathway uses a two-process model to implement its client/server architecture, which is called requester/server \n(see  Figure 10.50 ). The client is a multithreaded Terminal Control Program (TCP), which handles multiple \nsimultaneous interactions with end users. It supports both front-end program and request controller functions. \nThe TCP interpretively executes programs written in Tandem’s COBOL dialect, SCREEN COBOL, which \nincludes features for terminal handling and communication with single-threaded transaction servers. An exam-\nple of SCREEN COBOL is in  Figure 10.51 . Enhancements to the NonStop environment have allowed the devel-\nopment of multithreaded transaction servers. Similarly to ACMS, transaction servers execute compiled object \ncode written in a standard language with embedded SQL and run in server classes. Supported languages include \nC/C \u0005 \u0005 , COBOL, Java, and TAL (Transaction Application Language, which is proprietary to HP NonStop). \n The TCP interprets a SCREEN COBOL application program to display menus, paint and read a screen, \nvalidate the input data, and format a request message with the name of the target server class. The application \nprogram then starts a transaction and executes a SEND command to issue an RPC to a transaction server in the \nserver class named by the request. \n The RPC mechanism establishes a new link to a server in the requested server class, if it doesn’t already \nhave one or if all existing links are busy processing other requests. The server accepts the message and does \nthe work of the request, accessing a database if appropriate. When the server program completes, it sends a \nreply message to the TCP. The TCP’s application program can invoke many such RPCs before forwarding the \nreply to the terminal and committing the transaction. Finally, the reply message is displayed. \n The Guardian operating system implements software fault-tolerance through  process pairs , a mechanism \nby which a given operating system process has a second, shadow process as a backup to each primary process. \n}\nTerminal Control\nPrograms (TCP)\nSCREEN COBOL\nProcess\nPair\nRPCs\nAda, C, C++, COBOL,\nFORTRAN,  TAL\nCheckpoints\nTerminal\nServer Class\nServer\nServer\nServer\nNonStop SQL\nEnscribe\n FIGURE 10.50 \n Pathway Monitor Two-Process Model. The Terminal Control Program interprets SCREEN COBOL programs to interact \nwith the display and format requests, and to call servers via RPC. The servers access the Tandem resource managers. \nTCPs are implemented using process pairs for fault-tolerance. \n10.7 Legacy TP Monitors  337\n",
      "content_length": 2784,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 357,
      "content": "338  CHAPTER 10 Transactional Middleware Products and Standards\n A conﬁ guration option tells Pathway to run each TCP as a process pair. A server monitoring feature called \nPathmon, which is also implemented as a process pair, monitors Pathway servers and restarts them in the event \nof a process or processor failure. The primary and backup processes in a process pair conﬁ guration run on dif-\nferent processors so that at least one of them will survive any processor failure. \n At the beginning of each transaction, Pathway checkpoints the display context (essentially, the request), \nwhich means that it copies this state from the primary process to its backup process. It checkpoints again just \nbefore commit (essentially, the reply). If the primary fails during the transaction execution, the transaction \naborts and the backup can re-execute  the transaction using the checkpointed display context, without asking \nthe user to re-enter  the data. If the transaction executes without any failures and commits, then the precommit \ncheckpoint replaces the start-of-transaction checkpoint, and can be sent to the display. The checkpoints play \na similar role to queue elements in queued TP. The NonStop process pair and checkpoint/restart capability is \nunique in the TP industry. \n Servers are typically stateless, which allows successive calls to a server class within the same transaction to \nbe handled by different servers. Servers are automatically restarted in the event of process or processor failure. \n Transactions are managed by the TMF. Updates to data are logged to an audit ﬁ le, from which TMF man-\nages various types of recovery. There is one log per node. TMF provides a system logging service for both \nitself (as a transaction manager), and for the NonStop resource managers (NonStop SQL and Enscribe). All \nupdates by a transaction are written as a single log write, no matter how many resource managers are involved, \nthereby minimizing the number I/Os per transaction to improve performance and scalability. \n NonStop resource managers provide fault tolerance through disk mirroring and hot backup, and provide \nupward scalability through data partitioning and parallel processing. System server processes typically run as \nprocess pairs to ensure high availability. \n Front-End Program \n Pathway was introduced in the days of low-function terminals. So its front-end program, TCP, supports ter-\nminal devices via a multithreaded process, where each thread maintains a context for a terminal and initiates \na request on behalf of the user. Later on, the TCP interface was opened up for access from PCs, workstations, \nand other devices, such as ATMs, gas pumps, and bar code readers. \n External client support has been added for web browsers, Web Services, .NET, CORBA, JMS, and Tuxedo \nusing a set of special gateway processes that replace the TCP for modern display devices and interoperability \nPROCEDURE DIVISION.\n000-BEGIN SECTION.\nACCEPT INPUT-MSG.\n  BEGIN-TRANSACTION.\n  MOVE ACCOUNT-ID OF INPUT-MSG TO ACCOUNT-ID OF DBCR-MSG.\n  MOVE AMOUNT OF INPUT-MSG TO AMOUNT OF DBCR-MSG.\n  SEND MESSAGE DBCR-MSG TO /LOCAL\n      REPLY CODE STATUS.\n  MOVE BALANCE OF DBCR-MSG TO BALANCE1 OF CONFIRM-MSG.\n  SEND MESSAGE DBCR-MSG TO /REMOTE\n      REPLY CODE STATUS.\n  END-TRANSACTION.\n FIGURE 10.51 \n SCREEN COBOL Example. The program accepts input from the display, begins a transaction, and sends messages to two \nservers, one locally for the debit operation and the other to a remote node for the credit operation. \n",
      "content_length": 3538,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 358,
      "content": " solutions. A Web Services toolkit is available to generate a WSDL interface from a Pathway interface so that a \nstandard Web Services client can access a Pathway server. Similarly, the NonStop JSP product, together with \nthe NonStop Web Server product, supports direct access to Pathway servers from standard HTTP clients. \n TP Communications \n A NonStop system (or node) is a loosely-coupled  cluster of processors, connected by a high-speed bus called \nServerNet. Processors do not share memory, but this architecture is supported by the common operating sys-\ntem environment that provides high performance, availability, and scalability. \n The NonStop operating system uses a transactional interprocess communications mechanism based on the \nNonStop messaging system, between processes both on the same node and on remote nodes. The communica-\ntion mechanism is accessed using the PathSend API. \n Database Access \n The NonStop environment includes an SQL-compliant resource manager called NonStop SQL and a trans-\nactional ﬁ le system called Enscribe. Both resource managers support parallel processing and distributed pro-\ncessing features of the NonStop platform. When it was released in the mid-1980s, NonStop SQL was the ﬁ rst \ndistributed, parallel relational database system product. \n Mirrored disks are supported for local backup, and the Remote Database Facility (RDF) supports a remote \nhot backup. RDF uses the process pair architecture to forward log records from the primary database to the \nremote replica, where another process pair applies the log records to the database replica. \n Multiple processors can execute separate SQL requests simultaneously or divide a large single request for \nparallel processing on multiple processors. The resource managers support the standard locking and logging \napproaches described in Chapters 6 and 7, including record locking, relaxed isolation levels for improved read \nperformance, and logs for undo-redo recovery. Online reconﬁ guration is supported for such things as moving a \npartition or splitting an index. \n 10.8  TP STANDARDS \n Historically , standardization has been very challenging for TP technologies, due to the broad variety of imple-\nmentation architectures, programming models, communications protocols, and integration points among mod-\nern and legacy products. The main goals of TP standardization are: \n ■  Portability: Allowing the same transaction program to run on different transactional middleware products \n ■  Interoperability: Allowing multiple transactional middleware products to exchange data or control infor-\nmation while executing within the same transaction \n ■  Integration: Allowing components from multiple transactional middleware products that perform differ-\nent functions to work in combination \n We will focus primarily on standards pertinent to the .NET Framework and Java EE transactional middle-\nware and touch only brieﬂ y on other related standardization efforts. The primary standard for transactional \ninteroperability is deﬁ ned by the Web Services transactions set of speciﬁ cations. We describe the following \nstandards: \n ■  The Web Services Transactions (WS-Transactions) set of speciﬁ cations from OASIS \n ■  The XA protocol from the Open Group \n10.8 TP Standards  339\n",
      "content_length": 3285,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 359,
      "content": "340  CHAPTER 10 Transactional Middleware Products and Standards\n ■  The Object Transaction Service (OTS) from the Object Management Group \n ■  The Java Transaction API (JTA) from the Java Community Process \n These last three standards are related. The XA protocol is incorporated into OTS, and both XA and OTS \nare incorporated into JTA. The XA protocol is perhaps the most successful TP standard. Most transactional \nresource managers support it for two-phase commit, including relational database systems and asynchronous \nmessage queues. \n We also brieﬂ y mention the emerging Service Component Architecture (SCA), OSGi enterprise edition, \nand Advanced Message Queuing Protocol (AMQP) speciﬁ cations since they support transactions. \n WS-Transactions \n WS -Transactions is  a set of transactional interoperability speciﬁ cations standardized by OASIS. It extends \nbasic Web Services (i.e., SOAP and WSDL) by including a transaction context in a SOAP header and deﬁ ning \na protocol for transactional interoperability across Web Services. Both vendor and open source products imple-\nment it, including Microsoft’s Windows Communications Framework, IBM’s WebSphere Application Server, \nRed Hat’s JBoss Application Server, Progress Software’s Artix ESB, Sun’s Metro, and Apache’s Kandula2. \n WS -Transactions includes three speciﬁ cations: \n ■  WS-Coordination (WS-C) is the core speciﬁ cation, deﬁ ning a generic state machine coordinator that \nsupports pluggable protocols for various transaction models, such as WS-AT and WS-BA. \n ■  WS-AtomicTransactions (WS-AT) deﬁ nes a durable and volatile variation of the classic two-phase com-\nmit protocol that plug into WS-C. \n ■  WS-BusinessActivity (WS-BA) deﬁ nes an  “ open nested ” transaction protocol with compensation actions \nthat plugs into WS-C. It can be used with long running transaction ﬂ ows such as those deﬁ ned using \nWS-BPEL. \n An implementation of WS-C is a prerequisite for WS-AT and/or WS-BA. However, it is also possible to \nimplement WS-C without implementing either WS-AT or WS-BA, for example by deﬁ ning a new protocol to \nplug into WS-C, such as a notiﬁ cation, publish/subscribe, consensus, or three-phase commit protocol. \n The WS-C speciﬁ cation deﬁ nes how a Web Service implementation interacts with a transaction coordinator \nto obtain and manage the context for a given transaction type. The WS-AT and WS-BA speciﬁ cations deﬁ ne \nspeciﬁ c context formats for WS-C to manage. The context is obtained from WS-C and passed from a Web \nService requester to a Web Service provider using SOAP headers. A WS-Policy assertion can be attached to \nthe Web Service’s WSDL interface to advertise its transactional requirements. \n For example, in  Figure 10.52 the .NET client obtains a WSDL interface from the Java EE application \nserver that includes a policy requiring WS-AT. It therefore knows it has to start a transaction and obtain a \nWS-AT context for propagation to the remote service. The context is included in the header of the SOAP \nmessage that invokes the remote EJB server. When the service provider receives the SOAP header it recognizes \nthe WS-AT context and registers the transaction with a WS-C coordinator — either a local coordinator that con-\ntacts the remote coordinator on its behalf, or directly with the remote coordinator. \n Figure 10.53 shows an example of the context structure for WS-AT. It includes URIs that identify the coordi-\nnation (i.e., context) type, the coordinator, and the address of the coordinator with which to register the context. \n The two-phase commit protocol includes volatile and durable variations. The open nested model deﬁ ned in \nWS-BA allows a nested transaction to commit without requiring the top-level or root transaction to commit. \nHowever, if the top-level transaction aborts, a compensation action must be applied to any subtransaction that \npreviously committed. WS-BA includes two variations: one for participant completion and the other for coor-\ndinator completion. \n",
      "content_length": 4008,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 360,
      "content": " WS -Transactions uses the Web Services Policy (WS-Policy) Framework as the format for the policies it \ndeﬁ nes for association with a WSDL interface. In WS-Policy the policy items, called  assertions , are used \nto advertise the transactional capabilities of a Web Service. For example, an assertion can tell the service \nrequester whether or not a transaction context is required in order to invoke the service. Each WSDL operation \ncan have its own policies. \n5. Register\ntransaction\n4. SOAP call with WS-AT header \n3. Get WS-AT\ncontext   \n2. Receive WSDL with WS-AT policy \nWS-C \nWS-C \n1. Request WSDL \n6. SOAP response \n.NET\nFramework \nWCF\nJava EE\nApplication\nServer EJB \n FIGURE 10.52 \n The .NET Client Obtains a WSDL Interface Requiring WS-AT. The example illustrates a transactional Web Service \ninvocation that coordinates Java EE and NET Framework resources. \n<SOAP11:Envelope xmlns:S11=“http://www.w3.org/2003/05/soap-envelope”>\n    <SOAP11:Header>\n        ...\n        <wscoor:CoordinationContext \n           ... \n            <wscoor:Identifier>\n                 uuid:1234567890\n            </wscoor:Identifier>\n           ...\n           <wscoor:CoordinationType>\n               http://docs.oasis-open.org/ws-tx/wsat/2006/06\n           </wscoor:CoordinationType>\n           <wscoor:RegistrationService>\n                <wsa:Address>\n                 http://WWW.MyLargeBank.com/CoordinationService/registration\n                </wsa:Address>\n           </wscoor:RegistrationService>\n    </SOAP11:Header>\n    ...\n</SOAP11:Envelope>\n FIGURE 10.53 \n WS-Transactions Context for WS-Atomic Transactions. The context type for WS-AT is included in the SOAP header along \nwith the URL for the coordinator. \n10.8 TP Standards  341\n",
      "content_length": 1732,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 361,
      "content": "342  CHAPTER 10 Transactional Middleware Products and Standards\n For example,  Figure 10.54 deﬁ nes the transacted policy for the  Transfer operation. It indicates that a \ntransaction context, such as the WS-AT context, is required in order to request this service. If a SOAP message \narrives for the  Transfer operation without a transaction context an exception will be generated. \n The XA Interface \n The XA speciﬁ cation originally was developed by X/Open in 1991 as part of a family of speciﬁ cations deﬁ n-\ning a complete distributed transaction processing environment. XA is supported by most relational database \nproducts, including Oracle, Sybase, IBM’s DB2, Microsoft’s SQL Server, and Sun’s MySQL. XA is also sup-\nported by most asynchronous message queuing products, including IBM’s WebSphere MQ, TIBCO Software’s \nEnterprise Message Service, Progress Software’s SonicMQ, and the Apache Foundation’s ActiveMQ. \n X /Open was established to deﬁ ne portability and interoperability standards for UNIX. X/Open is now \npart of The Open Group, Inc., which was formed in 1994 by combining X/Open with the Open Software \nFoundation. X/Open’s original goal was to promote application portability through the development of API \nstandards for UNIX. In fact, The Open Group owns the UNIX brand. \n Although the complete family of X/Open speciﬁ cations failed to gain adoption, the X/Open Distributed \nTransaction Processing (DTP) model remains a good framework for identifying both the components involved \nin a distributed transaction and the appropriate areas for standardization (see  Figure 10.55 ). It divides a distrib-\nuted TP system into three major components — transaction manager, resource manager, and application — and \ndeﬁ nes the interfaces between them. \n Within the X/Open DTP model, the XA speciﬁ cation deﬁ nes a bidirectional interface between the transac-\ntion manager (TM) and the resource manager (RM). Today it’s common to think of the .NET Framework or \nJava EE deﬁ ning the transaction demarcation API instead of the TX API. SQL is the most widely-used  API \nfor RM access, but there are others for access to queues and other nonrelational resources. XA is intended pri-\nmarily for transactions that span multiple resource managers. For example, a common application of XA is to \ncoordinate a transaction that includes a database and a message queue. \n The XA speciﬁ cation deﬁ nes the protocol to allow the transactional work of an RM to be externally coor-\ndinated by a TM in a distributed transaction. XA is a presumed-abort, two-phase commit protocol with opti-\nmizations that enable a TM to chose a one-phase commit when there is only a single RM involved in the \ntransaction. When an application starts a transaction the TM creates a new transaction and assigns it a global \ntransaction ID (which XA calls an  XID ). When the application calls the RM (for example, using an SQL state-\nment), the runtime hosting the application passes the ID it obtained from the TM to the RM. The RM’s trans-\naction manager recognizes the ID as coming from an independent TM (i.e., it’s not a transaction that the RM \n<wsdl:operation name=“Transfer”>\n   <wsp:PolicyReference URI-“#TransactedPolicy” wsdl:required=“true” />\n   <!-- omitted elements -->\n</wsdl:operation>\n<wsp:Policy wsu:Id=“TransactedPolicy” >\n    <wsat:ATAssertion/>\n</wsp:Policy>\n FIGURE 10.54 \n Policy Assertion Requiring a Transaction for the  Transfer Operation. The Transfer operation has a reference to a  wsp:\nPolicy element that contains a  wsat:ATAssertion indicating that a transaction context is required for this operation. \n",
      "content_length": 3620,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 362,
      "content": " initiated) and enlists its transaction with the TM’s transaction using the address of the TM, which is passed \nas part of the transaction context. At termination, the TM notiﬁ es all registered participants of the transaction \noutcome. \n Object Transaction Service \n The Object Transaction Service (OTS) was deﬁ ned in 1994 by the Object Management Group (OMG), an \nindustry consortium. OMG was founded to develop the Common Object Request Broker Architecture (or \nCORBA) speciﬁ cations and now is responsible for a variety of standards, including the well-known Uniﬁ ed \nModeling Language (UML). OTS is one of the CORBA services that extend the core interfacing and interop-\nerability technology for use in enterprise applications such as transaction processing. \n OTS is incorporated into Java EE as the interoperable format for transaction context propagation on remote \nEJB requests. JTA provides the local Java interfaces in Java EE for TX and XA protocols. Implementations of \nCORBA and OTS include Progress Software’s Orbix, Borland Software’s VisiBroker, Oracle’s Tuxedo, HP’s \nNonStop Kernel, and Hitachi’s TP Broker. OTS often is mapped to Java Transaction Service (JTS) implemen-\ntations. And the WS-Transactions approach is derived from the OMG’s  Additional Structuring Mechanisms \nfor the OTS Speciﬁ cation , which ﬁ rst included the concept of separating the coordinator from the transaction \nprotocol. \n The OTS model (as of V1.4) includes a transactional server and recoverable server, which correspond to \nthe request controller and transaction server in our multitier model (see  Figure 10.56 ). \n Objects in the transactional clients and servers communicate with each other using the ORB. They also \naccess the transaction service to initiate and terminate a transaction and to register resources for a transaction. \nThe transactional server does not directly interact with persistent resources, but calls one or more objects in the \nrecoverable server to do so. \n In XA terms, the transactional client, transactional server, and recoverable server comprise the application \n(AP) and the transaction service implements the transaction manager (TM). The RM is the same as in XA and, \nin fact, interacts with the TM using the XA protocol. \n OTS supports both implicit and explicit programming models. The implicit programming model uses an \nobject called  current to associate a context with the execution thread. The  begin command initializes the \ncurrent context. Once a context is associated with the execution thread, it can be automatically propagated to \nany other transactional object invoked from that thread, depending on the transactional policy associated with \nResource Manager (RM) \nApplication Program (AP) \nTransaction Manager (TM) \nSQL\nXA\nTX\n FIGURE 10.55 \n X/Open DTP Model. In the X/Open DTP model an application program typically uses the TX API to access transaction \nmanagement services and SQL to access a resource manager. The XA standard allows different vendors ’ transactional \nmiddleware and resource managers to interoperate. \n10.8 TP Standards  343\n",
      "content_length": 3098,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 363,
      "content": "344  CHAPTER 10 Transactional Middleware Products and Standards\n the target object. The scope of a transaction is determined by the extent of the context sharing among objects, \nwhether explicit or implicit. \n The following properties can be associated with an object’s interoperable object reference (IOR) to deﬁ ne \nwhether or not it will accept implicit context propagation: \n ■  REQUIRES: A transaction context must be present when the object is invoked. \n ■  FORBIDS: A transaction context must not be present when the object is invoked. \n ■  ADAPTS: The object can be invoked whether or not a transaction context is present. \n Properties cannot be set on individual methods in an object. A transactional object can perform both trans-\nactional and nontransactional work. \n The explicit programming model uses the complete set of methods on the current object to explicitly start a \ntransaction, get a context object, control the transaction through the methods on the object, and propagate the \ncontext to other transactional objects. \n Transaction semantics in OTS are compatible with XA, and transactions can be exported and imported \nbetween the two environments. OTS supports subtransactions but they are not widely implemented in resource \nmanagers. \n An OTS coordinator can become a resource to another coordinator. This is called  interposition , in which \na coordinator acts as a resource to the root coordinator. Interposition was designed for network efﬁ ciency. \nWhen multiple remote resources are included in the transaction, it’s more efﬁ cient for the root coordinator \nto exchange remote messages with an interposed coordinator than it would be with all the remote resources \nindividually. The interposed coordinator receives messages from the root coordinator and passes them along to \nthe local resources enrolled with it. An interposed coordinator can also reduce the number of sessions a given \nresource manager has to support, and can help enforce security for a given domain. This is essentially the tree-\nof-processes model discussed in Section 8.5. \n JTA \n The Java Transaction API (JTA) deﬁ nes the Java interfaces for the TX and XA protocols. JTA originally was \ndeﬁ ned in 1999 and joins OTS and XA within a common Java programming environment. JTA is used in JCA, \nXA\nRegisters\nresources, full\nparticipant\nCan only\nforce rollback \nInitiate and\nterminate\ntransactions \nObject Request Broker (ORB)\nRM\nRM\nSQL\nSQL\nTransaction Service\nTransactional\nClient \nTransactional\nServer\nRecoverable\nServer\n FIGURE 10.56 \n Object Transaction Service Architecture. The ORB provides the communication among objects participating in an OTS \ntransaction while the transaction service provides transaction coordination. \n",
      "content_length": 2734,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 364,
      "content": " JDBC, and JMS, and is included in any Java-EE-compliant application server product. See Section 10.4,  The \nExplicit Programming Model for additional examples. \n JTA consists of three main parts: \n ■  An interface that allows an application to explicitly initiate, propagate, and terminate a transaction \n ■  A Java language mapping of the XA interface (XAResource) \n ■  An interface between the TM and other application server components such as containers and cache \nmanagers to support enlistment of durable and volatile resources (XAResources and Synchronizations). \n The  javax.transaction.UserTransaction interface deﬁ nes an explicit transaction programming \nmodel that can be used by Java clients and EJBs. \n The  javax.transaction.TransactionManager interface deﬁ nes a programming model for the appli-\ncation server vendor to control transactions that use the implicit programming model. When an EJB container \nmanages the transaction state for a transactional EJB, the container uses the  TransactionManager interface \nto create, manage, and propagate a transaction context for a given thread of execution. \n The  javax.transaction.xa.XAResource interface is a Java mapping of the industry standard XA \ninterface. As of JTA 1.1, the  javax.transaction.TransactionSynchronizationRegistry interface \ndeﬁ nes a distinct set of operations for components such as persistence managers that typically would not have \naccess to the full  TransactionManager interface. \n Service Component Architecture \n The OASIS Service Component Architecture (SCA) deﬁ nes a set of metadata for identifying services for an \nSOA, mapping them into a component model for deployment, and assembling them into various applications. \nSCA also includes a mechanism for attaching policies to the components and identiﬁ es a way in which Java \nprograms can include SCA metadata as annotations. \n Transactions are incorporated into SCA components using extended policy information incorporating \nthe WS-Policy speciﬁ cation from W3C. For example, when deploying an SCA component or assembly of \ncomponents into a Java EE runtime environment, the transaction policies attached to the SCA components \nare translated into Java EE transaction attributes. See the Section 10.4,  The Implicit Programming Model , for \ninformation on Java EE transaction attributes. When SCA components are deployed onto other runtimes, the \npolicies are mapped into WS-Policy elements as deﬁ ned in the WS-TX set of speciﬁ cations, described earlier \nin this section. \n OSGi Alliance \n The OSGi Alliance creates and maintains the OSGi speciﬁ cations, which deﬁ ne a core framework for Java \nmodularization and an associated set of framework services for discovery, security, logging, and so on. The \nOSGi Alliance was created as the Open Server Gateway initiative in 1998 based on Java Speciﬁ cation Request \n8. Its original goal was to modularize Java for embedded devices, such as those intended for home automation, \nallowing the dynamic loading and unloading of selected sets of Java libraries needed to support the device’s \nresource constraints and capability requirements. OSGi technology had mixed early adoption in various \nembedded applications, including automotive and mobile telephone application. \n Following the adoption of the OSGi platform by the Eclipse Foundation in 2004, the OSGi framework \nbecame popular as a deployment mechanism for Java-based products such as IBM’s WebSphere Application \nServer, Oracle’s WebLogic, Red Hat’s JBoss, Spring Source’s dm Server, and the Apache Foundation’s \nServiceMix, among others. \n10.8 TP Standards  345\n",
      "content_length": 3621,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 365,
      "content": "346  CHAPTER 10 Transactional Middleware Products and Standards\n The OSGi framework deﬁ nes a dynamic component model for Java, and addresses other shortcomings of \nthe standalone Java virtual machine environment, such as improved classloading, versioning, and lifecycle \ncontrol. Applications can be deﬁ ned as a set of cooperating components that can be remotely installed, started, \nstopped, updated, and uninstalled dynamically (i.e., without requiring application reboot). A service registry \nallows modules to detect the addition of new services or the removal of services, and to adapt dynamically, \nincluding the automatic installation of new components as required by the application. \n The enterprise release of the OSGi speciﬁ cations, R 4.2, extends the OSGi framework to meet the require-\nment of enterprise Java applications, including components for distributed computing, extensions to the com-\nponent model itself (based on the Spring Framework’s component model), and a mapping of various Java EE \ncomponents such as JTA, JDBC, JPA, JNDI, and Web applications. The Java EE and other enterprise compo-\nnents are accessible from application code using the OSGi service model. That means web applications, trans-\naction, persistence abstractions, and other enterprise components are available as dynamically-loadable  services \nfor OSGi-compliant applications. \n Advanced Message Queuing Protocol \n The Advanced Message Queuing Protocol (AMQP) is an open standard originally deﬁ ned by JP Morgan Chase \nand then submitted to an independent consortium, which maintains and improves it. AMQP focused initially \non deﬁ ning a wire format interoperability standard for asynchronous messaging systems, such as JMS-based \nmessage queues. \n JMS deﬁ nes a standard API for message queuing, but it does not deﬁ ne a data format. Among the goals of \nthe AMQP Working Group is achieving interoperability across multiple asynchronous message queuing tech-\nnologies and products. AMQP supports XA transactions for coordinating queue operations with operations \non another resource. Current implementations include Red Hat’s Enterprise MRG, Apache Qpid, iMatix’s \nOpenAMQ, and Cohesive FT and LShift’s RabbitMQ. \n Members of the AMQP Working Group consortium include Cisco Systems; Credit Suisse; Deutsche Borse \nSystems; Envoy Technologies; Goldman Sachs; iMatix Corporation; JP Morgan Chase Bank  & Co.; Microsoft \nCorporation; Novell; Progress Software; Rabbit Technologies (a joint venture of CohesiveFT and LShift); Red \nHat, Inc.; Twist Process Innovations; WSO2, Inc.; and 29West, Inc. \n 10.9  SUMMARY \n Transactional middleware products meet the requirements of multitier TP applications. Twenty years ago, \ntransactional middleware was delivered to market as a single product category, the TP (or OLTP) monitor. \nMany of these products are still in production, but the most popular transactional middleware environments are \nnow delivered in the Java EE and .NET Framework environments. \n As the new environments have gained popularity, components of the original monolithic TP monitors now \nare sold as independent products. Examples include forms products, database management systems, system \nmanagement consoles, distributed computing communications systems, and application development environ-\nments. Modern TP applications often include server components of legacy TP monitors, general purpose prod-\nucts, and components from the .NET Framework, Java EE-compliant application servers, or both. We expect \nthe trend toward componentization to continue. Yet the features and functions of transactional middleware \nremain unchanged — to help scale up, improve performance, reliability, security, manageability, maintenance, \ntransaction control, recovery, and availability. \n",
      "content_length": 3789,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 366,
      "content": " TP applications typically consist of two or more tiers that provide the functions of the front-end program, \nrequest controller, and transaction server. In their simplest and most direct design, a front-end program might \ndirectly access the transaction server in a database. However, since connections between front-end programs \nand databases can be expensive to maintain, one or more middle tiers often are introduced to improve scalabil-\nity and performance. Transactions can be controlled by the resource manager or the transactional middleware. \nDifferent transactional middleware systems provide different options for composing multiple resources into \nlocal and distributed transactions. \n Most transactional middleware systems also support the use of web servers as request controllers, and rich \nInternet applications such as AJAX deliver desktop-like levels of interactivity and features to the web browser. \nAll transactional middleware, including legacy TP monitors, supports access from web browsers either directly \nor through an intermediary. \n Transactional middleware products typically support both an implicit and explicit programming model for \ntransaction control. The implicit model uses conﬁ guration properties of abstract runtime containers to automat-\nically begin, propagate, and terminate a transaction. The explicit model relies on APIs incorporated directly \ninto programs. The tradeoffs are generally between ease of use of the implicit model and ﬂ exibility of control \nof the explicit model. \n Legacy TP monitors such as CICS, IMS, ACMS, Tuxedo, and Pathway continue to be used in many pro-\nduction environments. They now include support for modern front ends such as .NET, Java, and Web Services, \nfor integration with newer applications and SOA-based designs. \n Microsoft ’s .NET Framework includes multiple technologies for creating front-end programs, such as \nWPF, Silverlight, and ASP.NET. WCF can be used to develop request controllers and transaction servers. SQL \nServer can run stored procedures, which functions as a complete transaction server in some environments. \n Transaction management in the .NET Framework uses the  System.Transactions API set. It underlies the \nimplicit programming model in WCF and can also be accessed explicitly from .NET Framework objects. When \nused with WCF, attributes embedded within .NET objects cause them to execute as transactions. Annotations \ncan also be embedded in programs and interfaces to automatically complete and propagate a transaction. \n The Java EE environment includes multiple technologies for creating front-end programs, such as Swing, \nJSP, JSF, and servlets. EJBs can be used to develop request controllers and transaction servers, and can include \nJPA beans for object-relational persistence. SQL database systems run stored procedures, which can function \nas transaction servers. \n Transaction management in the Java EE environment uses the Java Transaction API (JTA), which underlies \nthe implicit programming model in EJBs, and can also be accessed directly from Java objects. As in WCF, \nannotations embedded in EJBs control transaction initiation, termination, and propagation. In the Java world, \nthe Spring Framework is emerging as an alternative for TP application development. It includes a transaction \nmanagement abstraction API that’s conﬁ gurable for either JDBC- or JTA-managed transactions. \n In Java EE the same set of annotations is used for transaction control and propagation, whereas these func-\ntions can be controlled separately in the .NET Framework. Another difference between the environments \nis that the .NET Framework automatically promotes a single resource transaction to a multiresource trans-\naction when it detects an application accessing a second resource manager.  System.Transactions can \nautomatically reassign coordination responsibility from the resource manager’s transaction manager to an \nindependent transaction manager (i.e., DTC). In the Java EE environment, such a change has to be explicitly \nprogrammed. \n SOA -based designs are gaining adoption for TP applications using various technologies, such as Web \nServices and REST/HTTP. The transactional models differ for these two approaches. In Web Services, trans-\nactional RPC and compensation protocols are formalized in the WS-Transactions speciﬁ cations, which make \nmapping transactional capabilities fairly straightforward. With REST/HTTP, a transaction can be modeled as \n10.9 Summary  347\n",
      "content_length": 4498,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 367,
      "content": "348  CHAPTER 10 Transactional Middleware Products and Standards\n a resource. The server maintains the state of the resource and the front-end program maintains the application \nstate separately. Representations of state changes are exchanged using HTTP verbs. \n Persistence abstractions enable easier access to resource managers, especially relational databases. The ini-\ntial abstraction was designed to improve the use of remote database connections, and was formalized in ODBC \nand JDBC, which are still widely used. Newer abstractions include object-relational mappings such as JPA and \nentity data models such as ADO.NET Entity Framework. The abstraction mechanisms typically include trans-\naction management capabilities. \n TP standards help promote interoperability of TP environments and portability of applications. The most \nwidely adopted is the XA protocol, which deﬁ nes the relationship between a resource manager and an inde-\npendent transaction manager, so resource managers and transaction managers from different vendors can eas-\nily integrate. Other widely-adopted  standards include the Object Transaction Service from OMG, which is \nincluded in Java EE’s JTA, JTA itself, and WS-Transactions for Web services transactions. Emerging standards \ngaining adoption include SCA, OSGi’s enterprise edition, and AMQP. \n",
      "content_length": 1332,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 368,
      "content": " 11.1  INTRODUCTION \n Although the principles of transaction processing change very slowly, the technology that implements those \nprinciples changes all the time. Some of these changes involve repackaging well-known mechanisms to ﬁ t into \nnew software architectures. For example, over the years we have seen transactional RPC appear in TP moni-\ntors, client-server database systems, object request brokers, application servers, and web services. Other changes \nare driven by cost reductions in hardware and communications that put additional applications within reach. For \nexample, airline reservation systems evolved from simply keeping track of the number of available seats to add-\ning applications for frequent ﬂ yer programs, special meals, seat assignments, complex fares, and notiﬁ cations via \ne-mail and text messaging. Banking and stock brokerage systems have undergone a similar evolution. We are now \nseeing a growing use of mobile devices to access TP applications, such as managing a doctor’s appointments. \n A third driver of changes are web-based enterprises with large TP sites. When off-the-shelf technology \nfails to meet their needs, they often roll their own. Forty years ago, early corporate on-line TP application \ndevelopers rolled their own middleware. Later, transactional middleware products, such as TP monitors, came \nalong with general-purpose implementations of the same functionality. We expect to see this trend continue, \nwith custom solutions for the largest e-commerce sites migrating into transactional middleware and database \nsystem products. \n This chapter highlights four areas where we expect that technological changes will have a major effect on \nthe design of TP systems and products: cloud computing, scalable distributed computing, ﬂ ash memory, and \nstream processing. Since these areas are changing rapidly, anything we say about the technology is likely to \nbecome quickly outdated. So we will focus on overall trends, not on technical detail. \n 11.2  CLOUD COMPUTING \n Cloud computing is a computing service offered over the Internet. That is, a customer plugs into the  “ network \ncloud ” and uses computing capabilities owned and operated by another company called the  service provider . \nThe service provider may be a large company with many data centers containing hundreds of thousands of \nmachines, such as Microsoft, Google, Yahoo!, Amazon.com, IBM, or  Salesforce.com . \n Roughly speaking, a computing service can be an application-speciﬁ c service or a generic service. An \napplication-speciﬁ c service offers a particular application, such as e-mail, search, enterprise resource planning \n Future Trends \n 11 \nCHAPTER\n",
      "content_length": 2682,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 369,
      "content": "350  CHAPTER 11 Future Trends\n (ERP), customer relationship management (CRM), or social networking. An application-speciﬁ c service usu-\nally is offered both as a web site that can be accessed from a browser and as a web service that can be invoked \nby other applications. The application is usually customizable and extensible. \n A generic service offers a general-purpose computing service, such as raw storage, record-oriented data \nstorage, data warehousing, or raw processing power. The latter often is provided in the form of a virtual \nmachine (VM) into which the customer can load any kind of software. \n An application-speciﬁ c service may be combined with generic services. For example, a social networking \napplication may run in one cloud service but store large media ﬁ les on another service provider’s cloud service. \n The customer may use the generic service as extra data center capacity, for processing, storage, or both. \nFor example, a company could use cloud computing services to test new functionality or to handle temporary \nworkload spikes. Or the customer may use the service as its primary computing infrastructure. Sometimes, the \ncustomer starts using it as extra capacity and, after gaining conﬁ dence in the service, evolves into using it as its \nprimary computing facility. \n One of the attractions of most cloud computing services is that they gracefully scale up or down to meet \nthe current workload. That is, the customer pays only for the capacity that’s needed at any given moment. For \nexample, if a company is suddenly front-page news and hence gets a huge burst of trafﬁ c, the cloud computing \nservice can quickly respond by scaling up the company’s application to run on triple the number of machines \nto handle the load. \n A set of generic services can be packaged together, much like system software components that are pack-\naged into transactional middleware. For example, a service may offer a combination of computing, storage, \nand database management. A customer writes his or her application to the service’s API in much the same way \nhe or she would write it to a transactional middleware API. The service provider ensures that any application \nwritten to their API will scale up. Usually, this requires that the API restricts functionality in certain ways; for \nexample, to minimize or avoid the use of two-phase commit or database queries that span many machines. \nThese restrictions are designed to ensure that data and computation can be partitioned efﬁ ciently across many \nmachines, and that the partitioning automatically adjusts to changing the load by dynamically repartitioning \nacross more machines and balancing the load among them. \n Another attraction of cloud computing services is that the customer beneﬁ ts from the economies of scale \nthat are available to the service provider. A large-scale service provider can invest in complex system manage-\nment software to minimize the staff required to run the service, something that is beyond the reach of most \ncustomers today. They can buy communications bandwidth at wholesale rates. They can design custom hard-\nware with lower power requirements. And they can reduce the need for expensive backup electrical power by \ngeo-replicating applications, so if a data center goes off-line another can immediately pick up the load. These \ncost savings can be shared with the customer, so that both customer and service provider beneﬁ t. \n Today , to obtain economies of scale, a generic service typically runs a ﬁ xed small set of components of \neach type, often just one. For example, it may support only one message queuing system and two database \nsystem products. Thus, by choosing a generic service, customers are choosing the software platform on which \ntheir applications will run. Over time, service providers may compete by the range of platforms they offer. \n Multitenant Systems \n This book is about the technology for building application-speciﬁ c services for TP applications. However, we \nhave not covered one important aspect of such applications that arise in cloud computing, that of supporting \nindependent enterprises using the same service provider’s computing infrastructure. This is called  multitenant \nsupport. Consider a CRM service that supports many enterprise customers. When an enterprise signs up as a \ncustomer of the service, the service provider needs to  provision the system; that is, assign resources that are \n",
      "content_length": 4459,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 370,
      "content": " required to serve the customer. For example, it might need to allocate storage space, adjust the conﬁ guration so \nthat requests from this customer are serviced by server machines that have access to the customer’s database, \nand update the network name service with a customer-speciﬁ c URL that is directed to the service provider’s \nnetwork address. \n The service provider faces architectural decisions about how to isolate customers from each other. For \nexample, it could create a separate database for each customer. This ensures that data from different custom-\ners isn’t accidentally comingled. However, this doesn’t scale very well if the service provider supports a large \nnumber of small customers, due to the ﬁ xed overhead of each separate database. An alternative is to have one \ndatabase that serves all customers, where the customer ID is a ﬁ eld of every table in the database. In this case, \nthe service provider’s application needs to be very careful to give each customer access only to those database \nrecords that have that customer’s ID. \n Virtual machine technology can also be used to isolate customers from each other. A virtual machine can \nbe conﬁ gured for each customer with all the customer’s required resources. Since an application has access \nonly to the resources assigned to its virtual machine, this approach reduces the chance that one customer’s data \nleaks to another customer. \n 11.3  SCALABLE DISTRIBUTED COMPUTING \n With a corporate TP application, the users are known — usually, they are the employees of the company. The \nload is fairly predictable, especially for back-ofﬁ ce applications and customer-facing applications whose load \nis bounded by physical constraints, such as the number of cash registers or gas pumps where a customer can be \nserved. And downtime for upgrades and maintenance can be scheduled since the application is running inside \nof the business. \n By contrast, the web environment is less predictable and controllable. Large web sites have to be prepared \nto react immediately to huge spikes in application load, to maintain higher levels of availability, and to upgrade \ntheir systems without taking them out of service. \n Many of these requirements are not easily met by traditional transactional middleware products, since \nthey were designed to meet the requirements of internal systems. Still, the mechanisms required to meet these \nrequirements are well known. Indeed, many of them were covered in this book. What changes is how the mech-\nanisms are assembled into a complete system that has satisfactory availability, performance, scalability, secu-\nrity, manageability, and so on. By looking at the largest e-commerce web sites, many trends can be identiﬁ ed: \n ■  More use of caching: While browsing, a user expects instant response time. To do this in a cost-effective \nway, systems exploit skewed access patterns by caching frequently accessed information. This is done at \nevery layer of the multitier architecture — in HTTP proxy servers, web servers, application servers, and \ndatabase servers. Ordinarily, the system refreshes its cache frequently, especially for items that change \nrapidly. During workload spikes, the system may use fewer of its resources to refresh its cache, thereby \ngiving good response time to more users but offering more stale results. Cache management has become \nso important that it has become a separate product category. \n ■  More use of updatable caches: Not all cached data is static. When cached data is updated, the update must \nﬂ ow to all the caches that store it. We described the approaches in Chapter 9: primary copy, where the \nupdate is ﬁ rst applied to the master and then propagated to the caches; and multimaster, where an update \ncan be directly applied to any cache and then propagated lazily to the other caches. In either case, the rep-\nlication model is one of eventual consistency, not instantaneous consistency. In many cases, this weaker \nmodel offers acceptable behavior to end users, while yielding better availability and partition tolerance. \n11.3 Scalable Distributed Computing  351\n",
      "content_length": 4126,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 371,
      "content": "352  CHAPTER 11 Future Trends\n ■  More use of queued transactions: After a user has ﬁ nished browsing and is ready to take action, such \nas placing an order, it is usually enough that the system captures the request reliably and quickly. It is \nusually not necessary to process the request instantly. Thus, if there is a burst of trafﬁ c the system can \ngive a good customer experience as long as the queuing system can handle the load. When combined \nwith caching, this sometimes leads to rejected requests, because the user issued the request based on \ninformation that turned out to be too stale, such as quantity on hand or highest bid. In effect, rejecting \nsuch requests is a form of optimistic concurrency control. This occasional undesirable result usually is \nregarded as an acceptable compromise in return for better scalability. \n ■  More use of business processes: This is a natural consequence of increased use of queued transactions. \nSince an instant response isn’t required, it is not critical that the entire request run as a single transaction. \nTherefore, for all the reasons discussed in Chapter 5, it makes sense to break up the request into multiple \nsteps, which often execute on different systems. This is a form of partitioning, which makes the system \nmore scalable. Also, the system can be made more available by continuing to offer some level of service \neven when some subsystems are down. This leads to more application programming for compensating \ntransactions and more system support to automate their invocation. \n ■  More use of dynamic partitioning: When a server becomes overloaded, its workload needs to be spread \nover more servers. This entails installing the application on those servers and often partitioning the database \nacross those servers. Some systems have made this an automated process, thereby enabling graceful growth. \n ■  More physical componentization of applications: With the use of service-oriented architecture and \nobject-oriented design, applications are more componentized and reusable in multiple contexts. For eas-\nier manageability, it is beneﬁ cial to partition these application components on different systems. This iso-\nlates their workload for easier performance management and enables them to be independently upgraded \nwithout affecting other applications on the web site. \n ■  More exploitation of user requirements: Some technology problems can be addressed by trading off cus-\ntomer requirements. For example, users have learned to accept communication errors as a fact of life, since \nthey can occur for a broader set of reasons and are largely outside their control. Therefore, following a \ncommunication error, customers may prefer fast resubmission of requests rather than ensuring reliable cap-\nture of all input. Another example of a tradeoff is relaxing immediate consistency of some data to ensure \nonly eventual consistency, but gaining performance and availability in the face of network partitions. \n ■  More use of cloud computing: A TP system needs to be conﬁ gured for its peak workload. If the work-\nload increases rapidly, a common occurrence when an Internet site becomes popular, a  “ success disaster ” \ncan occur where the system is unable to grow fast enough to handle the increasing load. As a result, \ncustomers leave in frustration. Instead of each system paying for spare capacity that it probably will not \nneed, a cloud-based service can be conﬁ gured with enough headroom to handle load spikes from a few \nof its many tenants. The cost of the headroom is therefore spread across many more applications, reduc-\ning the system cost for all of them. \n The current generation of transactional middleware and database systems is not ﬂ exible enough to enable \nthe cost-effective construction of the largest web sites, such as those managed by Amazon, Google, eBay, and \nMicrosoft. These companies have therefore invested heavily in building out their own solutions. The older \ntechnologies are often in the mix, but play designated roles rather than serving as the primary infrastructure. \n We expect the system architecture for assembling such sites to stabilize, at which point we expect to see a new \ngeneration of transactional middleware products modeled on that architecture. These may be packaged products, \nlike classical transactional middleware, or cloud-based platforms that are made available to application tenants. \nWhatever form they take, we expect them to borrow heavily from the solutions adopted by today’s largest web sites. \n",
      "content_length": 4545,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 372,
      "content": " 11.4  MEMORY TECHNOLOGY \n Magnetic disks were one of the main technologies that enabled the development of the ﬁ rst TP systems in the \n1960s. Until very recently, it has remained the only nonvolatile storage medium for on-line random access to \nlarge databases. We are now beginning to see nonvolatile solid state devices that are viable alternatives to disk, \nparticularly those based on ﬂ ash memory. Given the high demand for ﬂ ash memory for use in digital cameras, \nmusic players, and cell phones, manufacturers have been able to ramp up production to very high volumes. As \na consequence, the cost and capacity of ﬂ ash memory has been dropping rapidly. \n There are three main performance metrics for nonvolatile storage: \n ■  Capacity: The number of gigabytes it can store \n ■  Bandwidth: The rate at which data can be streamed onto or off of the device \n ■  Latency: The time required for a random read or write \n Although the capacity of magnetic disks has improved dramatically, their bandwidth and latency have \nimproved much more slowly. There are physical limits to how fast the disk can spin, which along with bit den-\nsity determine disk bandwidth. And there are limits to how quickly a head can seek to a new cylinder, which \ndetermines disk latency. \n Semiconductor devices offer much shorter latency than magnetic disks, roughly two orders of magnitude \nshorter. However, until recently, they were too expensive per gigabyte to offer a meaningful alternative to mag-\nnetic disk. This is now changing due to the availability of higher-density ﬂ ash memory chips, which reduce \nthe cost per gigabyte. Solid state disk devices are now available that use ﬂ ash memory, have the capacity of a \nsmall magnetic disk drive, and are competitively priced. Given that fast random access to nonvolatile storage is \na major determinant of TP performance, it is likely that these solid state storage devices will become a popular \nalternative to magnetic disks for TP systems. \n Other solid state memory technologies are under development, which have characteristics that make them \npotentially competitive with dynamic RAM (DRAM) and ﬂ ash memory. Current examples are magnetoresis-\ntive RAM (MRAM), memristors, and phase-change memory (PCM or PRAM). It is too soon to tell whether \nany of these technologies will reach commodity status and hence be candidates to dislodge today’s market \ndominance of DRAM and ﬂ ash. However, they are sufﬁ ciently promising to be worth tracking as a possible \nsource of disruptive change to the storage device market. \n 11.5  STREAMS AND EVENT PROCESSING \n One source of inputs for a TP system are real-time devices that detect events in the physical world. Example \napplications include processing streams of price changes in ﬁ nancial markets, monitoring events in a computer \nnetwork, tracking packages using RFID tags, and monitoring automobile movement for trafﬁ c control. \n Such applications take as input streams of messages — essentially requests in our terminology. In many \nof these applications it is inappropriate or infeasible to store messages in a persistent database before taking \naction based on that data. It may be inappropriate because it introduces too much delay before the input event \nis processed. It may be infeasible because the incoming data rate is too high. This breaks the classical TP \nparadigm, where the message causes a transaction to execute, the transaction stores the data in a database, and \nusers query that data later. \n Instead , the messages need to be processed while they pass through main memory on their way to persistent \nstorage (if they are stored at all). This processing usually involves a query that ﬁ lters the data for events that \ndetermine whether the data is of special interest and, if so, what action to take. The query may need to access \n11.5 Streams and Event Processing  353\n",
      "content_length": 3883,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 373,
      "content": "354  CHAPTER 11 Future Trends\n a persistent database to compare the new message to past behavior, for example, to identify an unusual price \nchange for electronic trading or an unusual purchase for fraud detection. It may also need to access a range of \nrecent messages, to determine a trend or a break in a trend in a ﬁ nancial market. It may need to deal with errone-\nous and out-of-order messages, which requires retracting query results , much like a compensating transaction. \n This style of application is reminiscent of messaging applications that are supported by message-oriented \nmiddleware, as described in Chapter 5. What makes them different are primarily the performance requirements: \nresponse time, throughput, and scalability. These requirements create challenges for conventional transactional \nmiddleware and database systems, where data must be stored before it can be processed. This has led to the \ndevelopment of specialized database systems for stream processing. \n Stream processing functionality is already becoming an important capability of database systems. It is impor-\ntant for TP as well, and this importance is likely to continue growing for some time. Contributing factors include \nthe decreasing cost and increasing function of sensor devices, the growth and declining cost of wireless networks, \nand the desire to monitor more events of the physical world in real time. \n 11.6  SUMMARY \n Businesses continually adapt to changing technology capabilities and pricing. Although transaction processing \nprinciples have remained fairly constant during the past 20 years or so, the technologies that implement the \nprinciples have been evolving. Recent changes starting to impact transactional middleware products include \ncloud computing, highly scalable computing designs, solid state memory, and streaming event processing. \nThese changes are too recent for us to predict with any certainty what impact they’ll have on the next genera-\ntion of transactional middleware, but we can at least identify the trends to watch. \n Cloud computing is a computing service offered over the Internet. A service provider may offer a complete \napplication, such as e-mail, search, enterprise resource planning (ERP), customer relationship management \n(CRM), or social networking. Or they may offer generic infrastructure services such as providing processing and \nstorage capacity on demand. Some cloud computing systems provide a combination of these capabilities. Usually, \nthe service can scale up quickly when the workload increases, and the customer pays only for the capacity that \nactually is used. \n The largest web sites are innovating in the use of custom designs for scalable computing. This customiza-\ntion is needed to cope with the unpredictability of workloads and the need to optimize fast response times for a \ngood customer experience. Such customization is reminiscent of the early years of transaction processing tech-\nnologies, where companies developed middleware for their internal applications. Among the techniques now \nbeing employed are additional caching at every level of the multitier TP architecture to improve performance \nand ensure good response time, increased use of queued transactions and business processes, and more dynamic \napplication partitioning. \n The evolution of nonvolatile solid state memory as an alternative to magnetic disk is another trend inﬂ u-\nencing TP system design. Flash memory is now being used for solid state disks. Its capacity is continually \nincreasing, while its cost is decreasing. Its latency is much smaller than that of magnetic disk, making it very \nattractive for TP applications. Solid state memory is also likely to have a signiﬁ cant impact on mid-tier cach-\ning solutions for scalability. \n Finally , the growing importance of processing data and event streams is another trend likely to affect trans-\nactional middleware products. Stream processing technology enables data to be processed in real time, while \nit is in ﬂ ight — that is, before it is persisted. This is similar to message processing, but with higher performance \nand throughput. \n",
      "content_length": 4142,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 374,
      "content": " The following acronyms are used in this book. If an acronym is speciﬁ c to a company, organization, or product, the company, \norganization, or product name is appended. \n 2PC \n two-phase commit \n 3270 \n block-mode terminal — IBM \n 4GL \n fourth-generation language \n ACID \n atomicity, consistency, isolation, durability (properties of a transaction) \n ACMS \n Application Control and Management System — HP \n ACP \n Airline Control Program — IBM \n ADO \n ActiveX Data Objects — Microsoft \n AJAX \n Asynchronous JavaScript And XML \n AMD \n Advanced Micro Devices \n ANSI \n American National Standards Institute \n AP \n application program \n API \n application programming interface \n APPC \n Advanced Program to Program Communication — IBM \n AQ \n Advanced Queuing — Oracle \n ARM \n Advanced RISC Machine  – ARM Holdings \n ASP \n Active Server Pages — Microsoft \n ATM \n automated teller machine \n ATMI \n Application Transaction Manager Interface — Oracle \n BMS \n Basic Mapping Services — IBM \n BPM \n business process management \n BPMN \n Business Process Modeling Notation — OMG \n CAP \n consistency, availability, and partition-tolerance \n CCI \n Common Client Interface (part of JCA) — JCP \n CDR \n Common Data Representation — OMG \n CGI \n Common Gateway Interface — W3C \n CICS \n Customer Information and Control System — IBM \n CLR \n Common Language Runtime — Microsoft \n COM \n Component Object Model — Microsoft \n COM \u0005 \n Component Object Model plus — Microsoft \n CORBA \n Common Object Request Broker Architecture — OMG \n CRM \n customer relationship management \n DAG \n directed acyclic graph \n DB \n database manager \n DBA \n database administrator \n DL/I \n Data Language/I — IBM \n DM \n data manager \n DNS \n Domain Name System — IETF \n DPL \n Distributed Program Link — IBM \n DRAM \n dynamic random access memory \n DSN \n data source name \n DTC \n Distributed Transaction Coordinator — Microsoft \n DTP \n distributed transaction processing \n ECI \n external call interface (part of CICS) — IBM \n EDI \n Electronic Data Interchange — UN/EDIFACT \n EDM \n entity data model \n EAI \n enterprise application integration \n Glossary of Acronyms \n",
      "content_length": 2114,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 375,
      "content": "356  Glossary of Acronyms\n EJB \n Enterprise Java Beans — Java Enterprise Edition \n EPI \n external programming interface (part of CICS) — IBM \n ERP \n enterprise resource planning \n ESB \n enterprise service bus \n FML \n Field Manipulation Language — Oracle \n GUI \n graphical user interface \n HIS \n Host Integration Server — Microsoft \n HTML \n Hypertext Markup Language — W3C \n HTTP \n Hypertext Transfer Protocol — IETF \n HTTPS \n HTTP/TLS — IETF \n ID \n identiﬁ er \n IDE \n interactive development environment \n IDL \n interface deﬁ nition language \n IETF \n Internet Engineering Task Force \n IIOP \n Internet Inter-Orb Protocol — OMG \n IIS \n Internet Information Server — Microsoft \n IMS \n Information Management System — IBM \n I/O \n input/output \n ISAPI \n Internet Server Application Programming Interface — Microsoft \n ISC \n Intersystem Communication — IBM \n Java EE \n Java Enterprise Edition — JCP \n Javax \n Java extensions — JCP \n JAXB \n Java Architecture for XML Binding — JCP \n JAX-RS \n Java API for Restful Web Services — JCP \n JAX-WS \n Java API for XML Web Services — JCP \n JCA \n Java Connector Architecture — JCP \n JCP \n Java Community Process \n JDBC \n Java Database Connectivity — JCP \n JMS \n Java Messaging Service — JCP \n JNDI \n Java Naming and Directory Interface — JCP \n JPA \n Java Persistence Architecture — JCP \n JSON \n JavaScript Object Notation — JSON.org \n JSF \n Java Server Faces — JCP \n JSP \n Java Server Pages — JCP \n JTA \n Java Transaction API — JCP \n JTS \n Java Transaction Service — JCP \n LAN \n Local Area Network \n LINQ \n Language-Integrated Query — Microsoft \n LOB \n Line of Business adapter — Microsoft \n LSN \n log sequence number \n LTM \n Lightweight Transaction Manager — Microsoft \n LU6.2 \n Logical Unit 6.2 protocol — IBM \n MFS \n Message Format Service — IBM \n MQ \n message queue \n MQI \n Message Queue Interface — IBM \n MRAM \n magnetoresistive random access memory \n MRO \n Multiregion Operation — IBM \n MSC \n Multiple Systems Coupling — IBM \n MSMQ \n Microsoft Message Queue — Microsoft \n MTBF \n mean time between failures \n MTTR \n mean time to repair \n MVI \n modiﬁ ed version ID \n NSAPI \n Netscape Server API — Sun \n NSK \n NonStop Kernel — HP \n OASIS \n Organization for the Advancement of Structured Information Standards \n",
      "content_length": 2246,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 376,
      "content": "Glossary of Acronyms  357\n ODBC \n Open Database Connectivity — SQL Access Group \n OLE \n Object Linking and Embedding — Microsoft \n OLE DB \n Object Linking and Embedding, Database — Microsoft \n OLTP \n on-line transaction processing \n OMG \n Object Management Group \n OpenVMS \n Open Virtual Management System — HP \n OO \n object-oriented \n OSI TP \n Open Software Interconnect Transaction Processing — ISO \n OSS \n Open System Services — HP \n OTMA \n Open Transaction Manager Access — IBM \n OTS \n Object Transaction Service — OMG \n PARS \n Programmed Airline Reservation System — IBM \n PC \n personal computer \n PCM \n phase change memory \n PL/SQL \n Procedural Language/Structured Query Language — Oracle \n POJO \n plain old Java object \n POWER \n Performance Optimization With Enhanced RISC — IBM \n PowerPC \n Power Performance Computing — Apple, IBM, and Motorola \n PRAM \n parameter random access memory \n PSPE \n Promotable Single Phase Enlistment — Microsoft \n RAID \n redundant array of inexpensive disks \n RAM \n random access memory \n RCP \n Rich Client Platform — Eclipse \n RDF \n Remote Database Facility — HP \n REST \n representational state transfer \n RFID \n radio frequency identiﬁ cation \n RM \n resource manager \n RMI \n Remote Method Invocation — JCP \n RMI/IIOP \n RMI over IIOP — JCP \n RPC \n remote procedure call \n RSS \n RDF Site Summary — RSS-DEV Working Group \n RTR \n Reliable Transaction Router — HP \n SABRE \n Semi-Automated Business Research Environment — Sabre Holdings \n SALT \n Services Architecture Leveraging Tuxedo — Oracle \n SCA \n Service Component Architecture — OASIS \n SCSI \n Small Computer System Interface — ANSI \n SDF \n Screen Deﬁ nition Facility — IBM \n SDO \n Service Data Objects — OASIS \n SI \n Systems Interface — HP \n SLA \n service level agreement \n SMP \n symmetric multiprocessor \n SNA \n System Network Architecture — IBM \n SOA \n service-oriented architecture \n SPARC \n Scalable Processor Architecture — Sun \n SPI \n system programming interface \n SQL \n Structured Query Language — ISO \n SQL/PSM \n Structured Query Language/Persistent Stored Modules — ANSI \n SSL \n Secure Socket Layer — IETF \n STDL \n Structured Transaction Deﬁ nition Language — The Open Group (formerly X/Open) \n TAL \n Transaction Application Language — HP \n TCP \n Terminal Control Program — HP \n TCP/IP \n Transmission Control Protocol/Internet Protocol — IETF \n TDL \n Task Deﬁ nition Language — HP \n TLS \n Transport Layer Security — IETF \n TM \n transaction manager \n",
      "content_length": 2450,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 377,
      "content": "358  Glossary of Acronyms\n TMF \n Transaction Management Facility — HP \n TP \n transaction processing \n TPC \n Transaction Processing Performance Council \n TPC-A, -B, -C, -E, -H \n Transaction Processing Performance Council benchmarks A, B, C, E, and H \n TPF \n Transaction Processing Facility — IBM \n tpm \n transactions per minute \n tpmC \n transactions per minute — TPC-C \n tps \n transactions per second \n tpsE \n transactions per second — TPC-E \n $/tpsE \n cost per transaction per second — TPC-E \n TX \n Transaction Demarcation API — The Open Group (formerly X/Open) \n TxF \n Transactional NT File System — Microsoft \n TxRPC \n Transactional Remote Procedure Call — The Open Group (formerly X/Open) \n UDDI \n Universal Description, Discovery, and Integration  – OASIS \n UML \n Uniﬁ ed Modeling Language — OMG \n UN/EDIFACT \n United Nations/ Electronic Data Interchange For Administration, Commerce, and Transport \n URI \n Uniform Resource Identiﬁ er — W3C \n URL \n Uniform Resource Locator — W3C \n VAX \n Virtual Address Extension — HP \n VB \n Visual Basic — Microsoft \n VM \n virtual machine \n VSAM \n Virtual Sequential Access Method — IBM \n VSE \n Virtual Storage Extended \n W3C \n World Wide Web Consortium \n WAN \n wide area network \n WCF \n Windows Communication Foundation — Microsoft \n WF \n Windows Workﬂ ow Foundation — Microsoft \n WPF \n Windows Presentation Foundation — Microsoft \n WSDL \n Web Services Description Language — W3C \n WS-AT \n Web Services Atomic Transaction — OASIS \n WS-BA \n Web Services Business Activity — OASIS \n WS-BPEL \n Web Services Business Process Execution Language — OASIS \n WS-C \n Web Services Coordination — OASIS \n WS-I \n Web Services Interoperability Organization \n WWW \n World Wide Web \n WYSIWYG \n What you see is what you get \n XA \n Interface between TM and RM — The Open Group (formerly X/Open) \n XAML \n Extensible Application Markup Language — Microsoft \n XATMI \n X/Open Application Transaction Manager Interface — The Open Group (formerly X/Open) \n XDR \n External Data Representation — IETF \n XHTML \n Extensible Hypertext Markup Language — W3C \n XID \n X/Open transaction ID — The Open Group (formerly X/Open) \n XML \n Extensible Markup Language — W3C \n XPath \n XML Path Language — W3C \n XRF \n extended recovery facility — IBM \n XSD \n XML Schema Deﬁ nition language — W3C \n XSL \n Extensible Stylesheet Language — W3C \n XSLT \n XSL Transformations — W3C \n \n",
      "content_length": 2377,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 378,
      "content": " The goal of these bibliographic notes is to provide some historical context and offer places to ﬁ nd additional material on each \ntopic. It is not intended to be a comprehensive bibliography. \n The deﬁ nitive work on TP technology is  Transaction Processing: Concepts and Techniques , by Jim Gray and Andreas Reuter \n(1992). Most of the topics in this book are covered there in more detail, usually from the viewpoint of someone developing a data-\nbase system or transactional middleware. For the reader who wants to dig deeper into TP technology, this is an excellent place to \nlook. However, it is no longer the last word on some topics, since there has been technical progress since it was published. For a \nmore up-to-date view on any particular topic, see the following bibliographic notes. \n Most articles on advanced transaction processing technology are published in the database research ﬁ eld. A very complete \nbibliography search engine called DBLP is available at  http://www.sigmod.org/dblp/db/index.html . Most of the relevant confer-\nence proceedings can be obtained from the ACM SIGMOD Anthology ( http://www.sigmod.org/sigmod/anthology/index.htm ) and \nthe ACM Digital Library ( http://portal.acm.org/dl.cfm ). \n More extensive bibliographic notes for Chapters 6 through 9 can be found in Bernstein et al. (1987) and for Chapters 6 \nthrough 8 in Weikum and Vossen (2002). These are academic-style textbooks that cover the material in more depth. Other books \non transaction processing are Claybrook (1992) and Lewis et al. (2002). \n CHAPTER 1 INTRODUCTION \n The concepts of transaction and TP monitor appeared in the early 1970s. There is a rich literature on the theory of transactions, \nstarting from the mid 1970s (see Bernstein, Hadzilacos, and Goodman, 1987, for references), and on their implementation (ﬁ rst \nsummarized in Gray, 1978, and later in Gray and Reuter, 1992). SOA and Web Services are described in Newcomer and Lomow \n(2004). REST is described in Richardson and Ruby (2007). For references on transactional middleware, see the Bibliographic \nNotes for Chapter 3. \n An early inﬂ uential paper on the transaction concept was Eswaran et al. (1976), which includes some earlier references. The \nacronym ACID was coined in H ä rder and Reuter (1983). For references on the two-phase commit protocol, see the Bibliographic \nNotes for Chapter 7. \n The most up-to-date information on TPC benchmarks can be found at the Transaction Processing Performance Council web site, \n http://www.tpc.org . A description of the evolution of TPC-A/B into TPC-C is in Levine et al. (1993). Articles about many database \nand TP benchmarks can be found in Gray (1993). Much of Section 1.6 on availability is from Gray (1986). \n CHAPTER 2 TRANSACTION PROCESSING ABSTRACTIONS \n The material on transaction bracketing is mostly from the authors ’ experience in designing and using transaction APIs. \nDescriptions of the use of transaction attributes in object-oriented programming in .NET can be found at the Microsoft web site, \n http://msdn.microsoft.com . For Java EE, see  http://java.sun.com/javaee . The nested transaction model described here is from Moss \n(1985); see also Lynch et al. (1993) for a mathematical treatment and Liskov (1988) for a language that embodies the model. \nDetails about threads can be found in any modern operating systems textbook, such as Silberschatz et al. (2008). The core mate-\nrial on RPC is from Birrell and Nelson (1984), the classic research paper on this topic. \n CHAPTER 3 TRANSACTION PROCESSING APPLICATION ARCHITECTURE \n The three-tier TP application architecture model is from Bernstein (1990) and Bernstein et al. (1991). See also Gray and Edwards \n(1995) and Chapter 5 of Gray and Reuter (1992). The more up-to-date view of multitier TP application architecture is based on the \nauthors ’ knowledge of current products. The REST architectural pattern was introduced in Chapter 5 of Fielding (2000). Details of the \nSecure Socket Layer can be found in Rescorla (2001). Kaufman et al. (2002) give a general treatment of network security. Howard and \nLeBlanc (2003) give a more prescriptive view of how to ensure code is secure. See the Bibliographic Notes for Chapter 10 for speciﬁ c \nproduct references. \n Bibliographic Notes \n",
      "content_length": 4287,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 379,
      "content": "360  Bibliographic Notes\n CHAPTER 4 QUEUED TRANSACTION PROCESSING \n Much of this chapter evolved from Bernstein et al. (1990), which in turn was inﬂ uenced by many sources, such as Gray (1978) and \nPausch (1988). A good place to ﬁ nd more details about the publish-subscribe paradigm is in books about the Java Messaging Service \nor at  http://java.sun.com/products/jms/ . Further information on Websphere MQ and Oracle Streams AQ can be found at  http://www.\nibm.com and  http://www.oracle.com , respectively. The Advanced Message Queue Protocol is described at  www.amqp.org . \n CHAPTER 5 BUSINESS PROCESS MANAGEMENT \n Jajodia and Kerschberg (1997) is an anthology of business process models, written by many top researchers working in that ﬁ eld. \nLeymann and Roller (2000) present a broad overview of business process technology from requirements and design through run-\ntime deployment. The WS-BPEL standard and associated documents are at  http://www.oasis-open.org/ . Wolter (2006) explains the \ntechnology of SQL Server Service Broker and how to use it. Documents about the Business Process Modeling Notation are at  http://\nwww.omg.org . WS-BPEL is described at  http://www.oasis-open.org/committees/tc_home.php?wg_abbrev=wsbpel . Other relevant \nmaterial about business processes can be found at the web site of the Workﬂ ow Management Coalition ( http://www.wfmc.org ). \n CHAPTER 6 LOCKING \n Two -phase locking was introduced in Eswaran et al. (1976). The deadlock discussion is from Chapter 3 of Bernstein et al. (1987). \nThe description of lock managers is from Gray (1978). The view of locking performance is from Tay (1987) and Thomasian (1996, \n1998); for further reading, see Shasha and Bonnet (2002). Most of the hot spot methods originated in IMS Fast Path (Gawlick and \nKinkade 1985). Degrees of isolation originated in Gray et al. (1976); see Berenson et al. (1995) for an updated presentation. \nChan et al. (1982) describes an early implementation of multiversion data. The phantom problem was introduced in Eswaran \net al. (1976). The use of index locking to avoid phantoms appears in Lomet (1993). Optimistic concurrency control was introduced \nin Kung and Robinson (1981). \n B -trees were introduced in Bayer and McCreight (1972). There are many papers on B-tree variations and optimizations. An \nearly survey is Comer (1979). The preﬁ x B-tree optimization is in Bayer and Unterauer (1977). The lock coupling protocol is from \nBayer and Schkolnick (1977) and Kedem and Silberschatz (1980). The B-link optimization is by Lehman and Yao (1981). \n Multigranularity locking was introduced in Gray et al. (1975, 1976). The nested transaction model was introduced in Reed \n(1978). The locking protocol for nested transactions is from Moss (1985). \n Timestamp ordering and serialization graph testing are described in Chapter 4 of Bernstein et al. (1987). Commit ordering is \npresented in Raz (1992). \n CHAPTER 7 SYSTEM RECOVERY \n The introduction that summarizes causes of failure was inspired by Gray (1986). The explanation of recovery and checkpoint-\ning techniques in Section 7.2 was developed for this book, but was heavily inﬂ uenced by ideas in early products from Tandem \nComputers. The model of recovery management in Sections 7.4 and 7.5 is an expanded version of material in Chapter 6 of \nBernstein et al. (1987), which was in turn heavily inﬂ uenced by Gray (1978) and H ä rder and Reuter (1983). The shadow-paging \nalgorithm in Section 7.6 is from Lorie (1977). \n Many logging algorithms have been published, going back at least to Gray (1978). The use of LSNs in pages are discussed in \nLindsay (1980). The ARIES algorithm is described in Mohan et al. (1992). Mohan (1999) gives a retrospective of ARIES and its vari-\nations with an extensive bibliography. Other details about logging can be found in Gray and Reuter (1992), Lomet (1992), Lomet and \nTuttle (2003), and Weikum and Vossen (2002). Kumar and Hsu (1998) is an anthology that includes many of these articles and others. \n Disk failure rates are presented in Gray and Van Ingen (2005) and Pinheiro et al. (2007). RAID was introduced in Patterson et al. \n(1988). \n CHAPTER 8 TWO-PHASE COMMIT \n The two-phase commit protocol was ﬁ rst published in Lampson and Sturgis (1976) and explained further in Gray (1978) and \nLampson (1981). The tree of processes model is from Lindsay et al. (1984) and the presumed abort optimization is from Mohan \net al. (1986). This particular description borrows heavily from Chapter 7 of Bernstein et al. (1987). \n",
      "content_length": 4537,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 380,
      "content": "Bibliographic Notes  361\n The X/Open model is published in The Open Group (1992). For descriptions of particular products, see Laing et al. (1991) for \nDigital’s VMS transaction manager, and Microsoft (2000) for Microsoft’s Distributed Transaction Coordinator. \n CHAPTER 9 REPLICATION \n One -copy serializability was introduced in Attar et al. (1984). The primary copy approach was ﬁ rst published in Stonebraker \n(1979). Majority consensus comes from Thomas (1979), and was extended in Gifford (1979) to quorum consensus. The behavior \nof timestamps is explained in Lamport (1978). \n There are many articles on how to reach consensus, not limited to the problem of deciding which replicas are alive and which \nis primary. An early such algorithm for data replication is the Virtual Partitions algorithm in El Abbadi et al. (1985) and El Abbadi \nand Toueg (1989). The algorithm for reaching consensus near the end of Section 9.4 is a variation of the Paxos algorithm in Oki and \nLiskov (1988) and Lamport (1998). An implementation is described in Chandra et al. (2007). \n The CAP conjecture was posed in Brewer (2000). It was proved in Gilbert and Lynch (2002). \n The multimaster implementation of Lotus Notes is described in Kawell et al. (1988). Early use of version vectors for rep-\nlication are Fischer and Michael (1982) and Parker et al. (1983). A later algorithm is described in Ladin et al. (1992) with an \nextensive bibliography. The algorithms described here are based on Microsoft’s WinFS and Sync Framework, described in Novik \net al. (2006) and Malkhi et al. (2007). Terry (2008) presents an excellent survey of replication techniques for mobile computing. \nDeCandia et al. (2007) describes multimaster techniques used by  Amazon.com . \n The description of data sharing was modeled on Oracle’s Rdb/VMS, described in Lomet et al. (1992). Data sharing in IBM DB2 is \ndescribed in Josten et al. (1997). Concurrency control for data sharing is also discussed in Mohan and Narang (1991) and Rahm (1993). \n CHAPTER 10 TRANSACTIONAL MIDDLEWARE PRODUCTS AND STANDARDS \n Primary sources were used for most of the information in this chapter. The most signiﬁ cant web references are listed next. MSDN \nwas our source of most of the information about the .NET Framework. An excellent source of general information on Java EE and \nEJB3 is Burke and Monson-Haefel (2006). Java Swing is described in Loy et al. (2003). Further information about Java TP tech-\nnologies, standards, and programming techniques are in Little et al. (2004). \n SOA design principles and concepts, with case studies and a detailed description of the Credit Suisse SOA-based application, \nis in Krafzig et al. (2004). Richardson and Ruby (2007) explore how to use REST/HTTP for web services and SOA. Another view \nof RESTful services is in Vinoski (2008a,b). \n Alonso et al. (2004) give an overview of Web Services. Detailed descriptions of Web Services standards and their relation-\nships is in Werrawarana et al. (2005). \n The following books were used for the ﬁ rst edition as source material on legacy TP monitors, and much of the information \nremains relevant: Andrade et al. (1996), for Tuxedo; LeBert (1989), for CICS; UNIX International (1992), for Tuxedo and CICS; \nand Willis (1994), for OpenVMS. \n Other general sources of product and standards information are  http://www.infoq.com/ ,  http://www.theserverside.com/ , and of \ncourse  http://www.wikipedia.org/ . \n Apache \n General:  http://www.apache.org/ \n Apache HTTP Server:  http://httpd.apache.org/ \n Apache CXF:  http://cxf.apache.org/ \n Apache OpenJPA:  http://openjpa.apache.org/ \n Apache Tomcat:  http://tomcat.apache.org/ \n Apache ActiveMQ:  http://activemq.apache.org/ \n Eclipse \n General:  http://www.eclipse.org/ \n SOA Tools Platform Project BPMN Editor Screenshot examples:  http://www.eclipse.org/projects/\nproject_summary.php?projectid  \u0003  stp.bpmn http://www.eclipse.org/bpmn/images/screenshots/ \n",
      "content_length": 3950,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 381,
      "content": "362  Bibliographic Notes\n HP \n ACMS:  http://h71000.www7.hp.com/commercial/acms/index.html \n NonStop Software/Pathway:  http://h20219.www2.hp.com/NonStopComputing/cache/76380-0-0-230-470.html \n IBM \n IMS:  http://www.ibm.com/software/data/ims/ \n CICS:  http://www.ibm.com/software/htp/cics/ \n DB2:  http://www.ibm.com/software/data/db2/ \n WebSphere:  http://www.ibm.com/software/websphere/ \n Java Enterprise Edition (Java EE) \n General:  http://java.sun.com/javaee/ \n Enterprise Java Beans:  http://java.sun.com/products/ejb/ \n J2EE Connector Architecture:  http://java.sun.com/j2ee/connector/ \n Java Message Service:  http://java.sun.com/products/jms/ \n Java Persistence API:  http://java.sun.com/javaee/technologies/persistence.jsp \n Java Server Faces:  http://java.sun.com/javaee/javaserverfaces/ \n Java Server Pages:  http://java.sun.com/products/jsp/ \n Java Servlets:  http://java.sun.com/products/servlet/index.jsp \n Java Swing:  http://java.sun.com/javase/6/docs/technotes/guides/swing/ \n Java Transaction API:  http://java.sun.com/javaee/technologies/jta/ \n JDBC:  http://java.sun.com/products/jdbc/overview.html \n REST- JAX-RS:  http://jcp.org/aboutJava/communityprocess/ﬁ nal/jsr311/index.html \n Web services- JAX-WS:  http://jcp.org/en/jsr/detail?id \u0003 224 \n Microsoft \n NET Framework Overview:  http://msdn.microsoft.com/en-us/netframework/default.aspx \n ADO.NET:  http://msdn.microsoft.com/en-us/data/default.aspx \n BizTalk Server:  http://www.microsoft.com/biztalk/en/us/default.aspx \n Host Integration Server:  http://www.microsoft.com/hiserver/default.mspx \n Internet Information Services:  http://msdn.microsoft.com/en-us/library/aa737439.aspx \n Open Database Connectivity (ODBC):  http://msdn.microsoft.com/en-us/library/ms710252(VS.85).aspx \n Silverlight:  http://silverlight.net/ \n SQL Server:  http://www.microsoft.com/sqlserver/2008/en/us/default.aspx \n System.Transactions:  http://msdn.microsoft.com/en-us/library/system.transactions.aspx \n Visual Studio:  http://msdn.microsoft.com/en-us/vstudio/default.aspx \n Windows Communication Foundation:  http://msdn.microsoft.com/en-us/library/ms735119.aspx \n Windows Presentation Foundation:  http://msdn.microsoft.com/en-us/netframework/aa663326.aspx \n Windows Workﬂ ow Foundation:  http://msdn.microsoft.com/en-us/netframework/aa663328.aspx \n Oracle \n Database:  http://www.oracle.com/database/index.html \n Tuxedo:  http://www.oracle.com/products/middleware/tuxedo/tuxedo.html \n WebLogic Server:  http://www.oracle.com/appserver/weblogic/enterprise-edition.html \n",
      "content_length": 2532,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 382,
      "content": "Bibliographic Notes  363\n Red Hat \n JBoss:  http://www.jboss.com/ \n Object Management Group (OMG) \n General:  http://www.omg.org/ \n Object Transaction Service:  http://www.omg.org/technology/documents/formal/transaction_service.htm \n The Open Group \n General:  http://www.opengroup.org/ \n DTP Model:  http://www.opengroup.org/pubs/catalog/c193.htm \n XA:  http://www.opengroup.org/onlinepubs/009680699/toc.pdf \n Organization for the Advancement of Structured Information Standards (OASIS) \n General:  http://www.oasis-open.org/home/index.php \n WS-Transactions:  http://www.oasis-open.org/committees/tc_home.php?wg_abbrev \u0003 ws-tx \n OSGi Alliance \n General:  http://www.osgi.org/ \n Service Composition Architecture (SCA) \n General:  http://www.oasis-opencsa.org/sca \n The Web Services Interoperability Organization (WS-I) \n General:  http://www.ws-i.org/ \n World Wide Web Consortium (W3C) \n General:  http://www.w3.org/ \n Web Services Activity:  http://www.w3.org/2002/ws/ \n",
      "content_length": 971,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 383,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 384,
      "content": " Alonso ,  G. ,  Casati ,  F. ,  Kuno ,  H. ,  Machiraju ,  V. ,  2004 .  Web Services .  Springer-Verlag ,  Berlin .  \n Andrade ,  J.M. ,  Carges ,  M.T. ,  Dwyer ,  T.J. ,  Felts ,  S.D. ,  1996 .  The TUXEDO System, Software for Constructing and Managing \nDistributed Business Applications .  Addison Wesley ,  Reading, MA .  \n Attar ,  R. ,  Bernstein ,  P.A. ,  Goodman ,  N. ,  1984 .  Site initialization, recovery, and backup in a distributed database system .  IEEE \nTrans. Software Eng.  10 ( 6 ) ,  645 – 650 .  \n Bayer ,  R. ,  McCreight ,  E.M. ,  1972 .  Organization and maintenance of large ordered indices .  Acta Inform.  1 ,  173 – 189 .  \n Bayer ,  R. ,  Schkolnick ,  M. ,  1977 .  Concurrency of operations on B-trees .  Acta Inform.  9 ( 1 ) ,  1 – 21 .  \n Bayer ,  R. ,  Unterauer ,  K. ,  1977 .  Preﬁ x B-Trees .  ACM Trans. Database Syst.  2 ( 1 ) ,  11 – 26 .  \n Berenson, H., Bernstein, P.A., Gray, J.N., Melton, J., O’Neil, E., O’Neil, P., 1995. Levels of isolation. In: Proceedings of the 1995 \nACM SIGMOD Conference on Management of Data, pp. 1 – 10. \n Bernstein ,  P.A. ,  1990 .  Transaction processing monitors .  Commun. ACM  33 ( 11 ) ,  75 – 86 .  \n Bernstein ,  P.A. ,  Emberton ,  W. ,  Trehan ,  V. ,  1991 .  DECdta: digital’s distributed transaction processing architecture .  Digital Tech. J. \n 3 ( 1 ) ,  10 – 17 .  \n Bernstein ,  P.A. ,  Hadzilacos ,  V. ,  Goodman ,  N. ,  1987 .  Concurrency Control and Recovery in Database Systems .  Addison-Wesley , \n Reading, MA.  Freely downloadable at:  http://research.microsoft.com/~philbe .  \n Bernstein, P.A., Hsu, M., Mann, B., 1990. Implementing recoverable requests using queues. In: Proceedings of the 1990 ACM \nSIGMOD Conference on Management of Data, pp. 112 – 122. \n Bernstein ,  P.A. ,  Shipman ,  D.W. ,  Wong ,  W.S. ,  1979 .  Formal aspects of serializability in database concurrency control .  IEEE Trans. \nSoftware Eng.  SE-5 ( 3 ) ,  203 – 215 .  \n Birrell ,  A.D. ,  Nelson ,  B.J. ,  1984 .  Implementing remote procedure calls .  ACM Trans. Comput. Syst.  2 ( 1 ) ,  39 – 59 .  \n Brewer, E.A., 2000. Towards robust distributed systems (abstract). In: Proceedings of the Nineteenth Annual ACM Symposium on \nPrinciples of Distributed Computing, p. 7. \n Burke ,  B. ,  Monson-Haefel ,  R. ,  2006 .  Enterprise Java Beans ,  ﬁ fth ed.  O’Reilly Media ,  Sebastopol, CA .  \n Chan, A., Fox, S., Lin, W.T.K., Nori, A., Ries, D.R., 1982. The implementation of an integrated concurrency control and recovery \nscheme. In: Proceedings of the 1982 ACM SIGMOD Conference on Management of Data, pp. 184 – 191. \n Chandra, T.D., Griesemer, R., Redstone, J., 2007. Paxos made live: an engineering perspective. In: Proceedings of the 1988 ACM \nConference on Principles of Distributed Computing, pp. 398 – 407. \n Claybrook ,  B.J. ,  1992 .  OLTP — Online Transaction Processing Systems .  J. Wiley  & Sons ,  New York .  \n Comer ,  D. ,  1979 .  The ubiquitous B-Tree .  ACM Comput. Surv.  11 ( 2 ) ,  121 – 137 .  \n DeCandia, G., Hastorun, D., Jampani, M., Kakulapati, G., Lakshman, A., Pilchin, A., Sivasubramanian, S., Vosshall, P., Vogels, \nW., 2007. Dynamo: amazon’s highly available key-value store. In: Proceedings of the 21st ACM Symposium on Operating \nSystems Principles, pp. 205 – 220. \n El Abbadi, A., Skeen, D., Cristian, F., 1985. An efﬁ cient, fault-tolerant protocol for replicated data management. In: Proceedings \nof the 1985 Symposium on Principles of Database Systems, pp. 215 – 229. \n El Abbadi ,  A. ,  Toueg ,  S. ,  1989 .  Maintaining availability in partitioned replicated databases .  ACM Trans. Database Syst.  14 ( 2 ) , \n 264 – 290 .  \n Bibliography \n",
      "content_length": 3675,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 385,
      "content": "366  Bibliography\n Eswaran ,  K.P. ,  Gray ,  J.N. ,  Lorie ,  R.A. ,  Traiger ,  I.L. ,  1976 .  The notions of consistency and predicate locks in a database system . \n Commun. ACM  19 ( 11 ) ,  624 – 633 .  \n Fielding ,  R.T. ,  2000 .  Architectural Styles and the Design of Network-based Software Architectures .  University of California , \n Irvine,  http://www.ics.uci.edu/~ﬁ elding/pubs/dissertation/top.htm .  \n Fischer, M.J., Michael, A., 1982. Sacriﬁ cing serializability to attain high availability of data in an unreliable network. In: Proceedings \nof the 1982 Symposium on Principles of Database Systems, pp. 70 – 75. \n Gawlick ,  D. ,  Kinkade ,  D. ,  1985 .  Varieties of concurrency control in IMS/VS fastpath .  IEEE Database Eng.  8 ( 2 ) ,  3 – 10 .  \n Gifford, D.K., 1979. Weighted voting for replicated data. In: 7th ACM SIGOPS Symposium on Operating System Principles, \npp. 150 – 159. \n Gilbert ,  S. ,  Lynch ,  N. ,  2002 .  Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services .  ACM \nSIGACT News  33 ( 2 ) ,  51 – 59 .  \n Gray ,  J.N. ,  1978 .  Notes on database operating systems .  In:  Operating Systems: An Advanced Course, Springer-Verlag Lecture \nNotes in Computer Science ,  vol. 60 .  Springer-Verlag ,  New York .   \n Gray, J.N., 1981. The transaction concept: virtues and limitations (Invited Paper). In: Proceedings of the 7th International \nConference on Very Large Data Bases. IEEE Press, pp. 144 – 154. \n Gray, J.N., 1986. Why do computers stop and what can we do about it. In: 5th Symposium on Reliability in Distributed Soft-\nware and Database Systems. IEEE Computer Society Press, pp. 3 – 12. Early version available at:  http://research.microsoft.\ncom/~gray/papers/TandemTR85.7_WhyDoComputersStop.pdf . \n Gray ,  J.N. (Ed.),  1993 .  The Benchmark Handbook for Database and Transaction Processing Systems ,  second ed.  Morgan Kaufmann \nPublishers ,  San Francisco . Online at:  http://research.microsoft.com/users/gray/BenchmarkHandbook/TOC.htm. \n Gray ,  J.N. ,  Edwards ,  J. ,  1994 .  Scale up with TP monitors .  Byte Mag.  April .  \n Gray ,  J.N. ,  Lorie ,  R.A. ,  Putzolu ,  G.R. ,  Traiger ,  I.L. ,  1976 .  Granularity of locks and degrees of consistency in a shared database . \n In:  Modeling in Data Base Management Systems .  Elsevier ,  Amsterdam .  \n Gray, J.N., Lorie, R.A., Traiger, I.L., 1975. Granularity of locks in a shared data base. In: Proceedings of 1975 International Con-\nference on Very Large Data Bases, pp. 428 – 451. \n Gray ,  J.N. ,  Reuter ,  A. ,  1992 .  Transaction Processing: Concepts and Techniques .  Morgan Kaufmann ,  San Francisco .  \n Gray, J.N., Van Ingen, C., 2005. Empirical measurements of disk failure rates and error rates. In: Microsoft Research Technical \nReport MSR-TR-2005-166.  http://research.microsoft.com/research/pubs . \n H ä rder ,  T. ,  Reuter ,  A. ,  1983 .  Principles of transaction-oriented database recovery .  ACM Comput. Surv.  15 ( 4 ) ,  287 – 317 .  \n Howard ,  M. ,  LeBlanc ,  D. ,  2003 .  Writing Secure Code .  Microsoft Press ,  Redmond, WA .  \n Jajodia ,  S. ,  Kerschberg ,  L. (Eds.) ,  1997 .  Advanced Transaction Models and Architecture .  Springer-Verlag ,  Berlin . \n Josten ,  J.W. ,  Mohan ,  C. ,  Narang ,  I. ,  Teng ,  J.Z. ,  1997 .  DB2’s use of the coupling facility for data sharing .  IBM Sys. J.  36 ( 2 ) , \n 327 – 351 .  \n Kaufman ,  C. ,  Perlman ,  R. ,  Speciner ,  M. ,  2002 .  Network Security – PRIVATE Communication in a PUBLIC World .  Prentice Hall \nPTR ,  Upper Saddle River, NJ .  \n Kawell Jr. L., Beckhardt, S., Halvorsen, T., Ozzie, R., Greif, I., 1988. Replicated document management in a group communica-\ntion system. In: Proceedings of the 1988 ACM Conference on Computer-Supported Cooperative Work. Online at the ACM \nDigital Library. \n Kedem, Z.M., Silberschatz, A., 1980. Non-two-phase locking protocols with shared and exclusive locks. In: Proceedings of 1980 \nInternational Conference on Very Large Data Bases, pp. 309 – 317. \n Krafzig ,  D. ,  Banke ,  K. ,  Slama ,  D. ,  2004 .  Enterprise SOA: Service-Oriented Architecture Best Practices (Coad Series) .  Prentice \nHall PTR ,  Upper Saddle River, NJ .  \n",
      "content_length": 4227,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 386,
      "content": "Bibliography  367\n Kumar ,  V. ,  Hsu ,  M. ,  1998 .  Recovery Mechanisms in Database Systems .  Prentice Hall PTR ,  Upper Saddle River, NJ .  \n Kung ,  H.T. ,  Robinson ,  J.T. ,  1982 .  On optimistic methods for concurrency control .  ACM Trans. Database Syst.  6 ( 2 ) ,  213 – 226 .  \n Ladin ,  R. ,  Liskov ,  B. ,  Shrira ,  L. ,  Ghemawat ,  S. ,  November 1992 .  Providing high availability using lazy replication .  ACM Trans. \nComput. Syst.  10 ( 4 ) ,  360 .  \n Laing ,  W.A. ,  Johnson ,  J.E. ,  Landau ,  R.V. ,  1991 .  Transaction management support in the VMS operating system kernel .  Digital \nTech. J.  3 ( 1 ) ,  33 – 44 .  \n Lamport ,  L. ,  1978 .  Time, clocks, and the ordering of events in a distributed system .  Commun. ACM  21 ( 7 ) ,  558 – 565 .  \n Lamport ,  L. ,  1998 .  The part-time parliament .  ACM Trans. Comput. Syst.  16 ( 2 ) ,  133 – 169 .  \n Lampson ,  B.W. ,  1981 .  Atomic transactions .  In:  Goos ,  G. ,  Hartmanis ,  J. (Eds.) ,  Distributed Systems — Architecture and Imple-\nmentation: An Advanced Course. LNCS 105 .  Springer Verlag ,  Berlin , pp.  246 – 265 .  \n Lampson, B.W., Sturgis, H., 1976. Crash recovery in a distributed data storage system. In: Technical Report, Computer Science \nLaboratory, Xerox Palo Alto Research Center, Palo Alto, CA. \n LeBert ,  J.J. ,  1989 .  CICS for microcomputers .  McGraw Hill ,  New York .  \n Lehman ,  P.L. ,  Yao ,  S.B. ,  1981 .  Efﬁ cient locking for concurrent operations on B-trees .  ACM Trans. Database Syst.  6 ( 4 ) ,  550 – 670 . \n Levine, C., Gray, J.N., Kiss, S., Kohler, W., 1993. The Evolution of TPC Benchmarks: Why TPC-A and TPC-B are Obsolete. \nTandem Technical Report 93.1, Tandem Computers. Online at:  http://www.hpl.hp.com/techreports/tandem/TR-93.1.pdf . \n Lewis ,  P.M. ,  Bernstein ,  A. ,  Kifer ,  M. ,  2002 .  Databases and Transaction Processing, An Application-Oriented Approach .  Addison-Wesley , \n Boston .  \n Leymann ,  F. ,  Roller ,  D. ,  2000 .  Production Workﬂ ow, Concepts and Techniques .  Prentice Hall PTR ,  Upper Saddle River, NJ .  \n Lindsay ,  B.G. ,  Haas ,  L.M. ,  Mohan ,  C. ,  Wilms ,  P.F. ,  Yost ,  R.A. ,  1984 .  Computation and communication in R*: a distributed data-\nbase manager .  ACM Trans. Comput. Syst.  2 ( 1 ) ,  24 – 38 .  \n Liskov ,  B. ,  1988 .  Distributed programming in Argus .  Commun. ACM  31 ( 3 ) ,  300 – 312 .  \n Little ,  M. ,  Maron ,  J. ,  Pavlik ,  G. ,  2004 .  Java Transaction Processing .  Prentice Hall PTR ,  Upper Saddle River, NJ .  \n Lomet, D.B., 1992. MLR: A recovery method for multi-level systems. In: Proceedings of the 1992 ACM SIGMOD Conference on \nManagement of Data, pp. 185 – 194. \n Lomet, D.B., 1993. Key range locking strategies for improved concurrency. In: Proceedings of the 1993 International Conference \non Very Large Data Bases, pp. 655 – 664. \n Lomet, D.B., Anderson, R., Rengarajan, T.K., Spiro, P., 1992. How the Rdb/VMS data sharing system became fast. In: Technical \nReport CRL 92/4, Digital Equipment Corp., Cambridge Research Lab.  http://www.hpl.hp.com/techreports/Compaq-DEC/\nCRL-92-4.pdf . \n Lomet, D.B., Tuttle, M.R., 2003. A theory of redo recovery. In: Proceedings of the 2003 ACM SIGMOD Conference on Manage-\nment of Data, pp. 397 – 406. \n Lomet, D.B., Weikum, G., 1998. Efﬁ cient and transparent application recovery in client-server information systems. In: Proceed-\nings of the 1995 ACM SIGMOD Conference on Management of Data, pp. 460 – 471. \n Lorie ,  R.A. ,  1977 .  Physical integrity in a large segmented database .  ACM Trans. Database Syst.  2 ( 1 ) ,  91 – 104 .  \n Loy ,  M. ,  Eckstein ,  R. ,  Wood ,  D. ,  Elliot ,  J. ,  Cole ,  B. ,  2003 .  Java Swing ,  second ed.  O’Reilly Media  Examples:  http://examples.\noreilly.com/jswing2/code/ .  \n Lynch ,  N. ,  Merritt ,  M. ,  Weihl ,  W.E. ,  Fekete ,  A. ,  1993 .  Atomic Transactions in Concurrent and Distributed Systems .  Morgan \nKaufmann Publishers ,  San Francisco .  \n Malkhi ,  D. ,  Novik ,  L. ,  Purcell ,  C. ,  2007 .  P2P replica synchronization with vector sets .  Operating Syst. Rev.  41 ( 2 ) ,  68 – 74 .  \n",
      "content_length": 4124,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 387,
      "content": "368  Bibliography\n Microsoft Corporation ,   2000 .  COM  \u0005  Developer’s Reference Library .  Microsoft Press ,  Redmond, WA .  \n Mohan, C., 1999. Repeating history beyond ARIES. In: Proceedings of the 1999 International Conference on Very Large Data \nBases, pp. 1 – 17. \n Mohan ,  C. ,  Haderle ,  D. ,  Lindsay ,  B. ,  Pirahesh ,  H. ,  Schwarz ,  P. ,  1992 .  ARIES: a transaction recovery method supporting ﬁ ne-\ngranularity locking and partial rollback using write-ahead logging .  ACM Trans. Database Syst.  17 ( 1 ) ,  94 – 162 .  \n Mohan ,  C. ,  Lindsay ,  B.G. ,  Obermarck ,  R. ,  1986 .  Transaction management in the R* distributed database management system . \n ACM Trans. Database Syst.  11 ( 4 ) ,  378 – 396 .  \n Mohan, C., Narang, I., 1991. Recovery and coherency-control protocols for fast intersystem page transfer and ﬁ ne-granularity \nlocking in a shared disks transaction environment. In: Proceedings of the 1991 International Conference on Very Large Data-\nbases, pp. 193 – 207. \n Moss ,  E. ,  1985 .  Nested Transactions: An Approach to Reliable Distributed Computing .  MIT Press ,  Boston .  \n Newcomer ,  E. ,  Lomow ,  G. ,  2004 .  Understanding SOA with Web Services .  Addison-Wesley ,  Upper Saddle River, NJ .  \n Novik, L., Hudis, I., Terry, D.B., Anand, S., Jhaveri, V., Shah, A., Wu, Y., 2006. Peer-to-peer replication in WinFS. In: Microsoft \nResearch Technical Report MSR-TR-2006-78. \n Oki, B.M., Liskov, B., 1988. View stamped replication: a general primary copy. In: Proceedings of the 1988 ACM Symposium on \nPrinciples of Distributed Computing, pp. 8 – 17. \n Parker   Jr. ,  D.S. ,  Popek ,  G.J. ,  Rudisin ,  G. ,  Stoughton ,  A. ,  Walker ,  B.J. ,  Walton ,  E. ,  Chow ,  J.M. ,  Edwards ,  D. ,  Kiser ,  S. ,  Kline ,  C. , \n 1983 .  Detection of mutual inconsistency in distributed systems .  IEEE Trans. Software Eng.  9 ( 3 ) ,  240 – 247 .  \n Patterson, D.A., Gibson, G., Katz, R.H., 1988. A case for redundant arrays of inexpensive disks (RAID). In: Proceedings of the \n1988 ACM SIGMOD Conference on Management of Data, pp. 109 – 116. \n Pausch, R., 1988. Adding input and output to the transaction model. Ph.D. Thesis, Computer Science Dept., Carnegie Mellon \nUniversity, August (CMU-CS-88-171). \n Pinheiro, E., Weber, W.-D., Barroso, L.A., 2007. Failure trends in large disk drive populations. In: Proceedings of the 5th USENIX \nConference on File and Storage Technologies (FAST  ’ 07), pp. 17 – 28. \n Rahm ,  E. ,  1993 .  Empirical performance evaluation of concurrency and coherency control protocols for database sharing systems . \n ACM Trans. Database Syst.  18 ( 2 ) ,  333 – 377 .  \n Raz, Y., 1992. The principle of commitment ordering, or guaranteeing serializability in a heterogeneous environment of multiple \nautonomous resource managers using atomic commitment. In: Proceedings of the 1992 International Conference on Very \nLarge Data Bases, pp. 292 – 312. \n Reed, D.P., 1978. Naming and synchronization in a decentralized computer system. Ph.D. Dssertation, Department of Electrical \nEngineering and Computer Science, MIT., Cambridge, MA. Technical Report TR-205, Laboratory for Computer Science, \nCambridge, MA. \n Rescorla ,  E. ,  2001 .  SSL and TLS — Designing and Building Secure Systems .  Addison-Wesley ,  Upper Saddle River, NJ .  \n Richardson ,  L. ,  Ruby ,  S. ,  2007 .  RESTful Web Services .  O’Reilly Media ,  Sebastopol, CA .  \n Shasha ,  D. ,  Bonnet ,  P. ,  2002 .  Database Tuning: Principles, Experiments, and Troubleshooting Techniques .  Morgan Kaufmann \nPublishers ,  San Francisco .  \n Silberschatz ,  A. ,  Galvin ,  P.B. ,  Gagne ,  G. ,  2008 .  Operating System Concepts ,  seventh ed.  Wiley ,  Hoboken, NJ .  \n Stonebraker ,  M. ,  1979 .  Concurrency control and consistency of multiple copies of data in distributed INGRES .  IEEE Trans. Soft-\nware Eng.  3 ( 3 ) ,  188 – 194 .  \n Tay ,  Y.C. ,  1987 .  Locking Performance in Centralized Databases .  Academic Press ,  Orlando, FL .  \n Terry, D.B., 2008. Replicated data management for mobile computing. In: Synthesis Lectures on Mobile and Pervasive Computing \n#5, Morgan  & Claypool Publishers. \n",
      "content_length": 4155,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 388,
      "content": "Bibliography  369\n The Open Group, 1992. Distributed TP: The XA Speciﬁ cation.  http://www.opengroup.org/bookstore/catalog/c193.htm . \n Thomas ,  R. ,  1979 .  A majority consensus approach to concurrency control for multiple copy databases .  ACM Trans. Database \nSyst.  4 ( 2 ) ,  180 – 209 .  \n Thomasian ,  A. ,  1996 .  Database Concurrency Control: Methods, Performance, and Analysis .  Kluwer Academic Publishers ,  \nBoston .  \n Thomasian ,  A. ,  1998 .  Concurrency control: methods, performance, and analysis .  ACM Comput. Surv.  30 ( 1 ) ,  70 – 119 .  \n UNIX International, 1992. Open Enterprise Transaction Processing: Integrating the TUXEDO System with Mainframe CICS. \n Vinoski ,  S. ,  2008 a .  RPC and REST — dilemma, disruption, and displacement .  IEEE Internet Comput.  September/October ,  92 – 95 , \n Toward Integration Column .  \n Vinoski ,  S. ,  2008 b .  RESTful web services development checklist .  IEEE Internet Comput.  November/December ,  94 – 96,  Toward \nIntegration Column .  \n Weerawarana ,  S. ,  Curbera ,  F. ,  Leymann ,  F. ,  Storey ,  T. ,  Ferguson ,  D. ,  2005 .  Web Services Platform Architecture: SOAP, WSDL, \nWS-Policy, WS-Addressing, WS-BPEL, WS-Reliable Messaging, and More .  Prentice-Hall ,  Upper Saddle River, NJ .  \n Weikum ,  G. ,  Vossen ,  G. ,  2002 .  Transactional Information Systems — Theory, Algorithms, and the Practice of Concurrency Control \nand Recovery .  Morgan Kaufmann Publishers ,  San Francisco .  \n Willis ,  J.M. ,  1994 .  TP Software Development for OpenVMS .  CBM Books ,  Horsham, PA .  \n Wolter ,  R. ,  2006 .  The Rational Guide to SQL Server 2005 Service Broker .  Rational Press ,  Rollinsford, NH .  \n",
      "content_length": 1691,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 389,
      "content": "This page intentionally left blank\n",
      "content_length": 35,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 390,
      "content": " Page numbers followed by  “ f ” indicate ﬁ gures \n Index \n A \n Abort cascading  196 \n Abort operation  208 – 209 ,  234 – 235 \n Abort record  230 \n Abstract process  137 \n Abstractions  see  Persistence abstraction \nmechanisms; Transaction \nprocessing abstractions \n Accept message  259 \n ACID properties  10 \n Activities  136 \n Acyclic directed graphs  184 \n Address space  41 – 42 \n ADO.NET/ADO.NET entity framework \n 322 – 323 \n Advanced Message Queueing Protocol \n(AMQP)  115 ,  346 \n After-image log  200 \n AJAX (Asynchronous JavaScript and \nXML)  283 \n All-or-nothing behavior  10 ,  12f \n Ambient transaction  294 \n Apache  361 \n Application Control and Management System \n(ACMS) (HP)  333 – 336 \n Application programming interface (API) \n ADO.NET/ADO.NET entity framework \n 322 – 323 \n deﬁ nition of  31 \n front-end programs and the  79 \n Java Persistence API (JPA)  319 – 321 \n ODBC and JDBC  316 – 318 \n transactional middleware and  93 \n Tuxedo (Oracle)  331 – 333 \n Applications \n stateful and stateless  60 – 61 \n transaction processing  3 \n Archiving  219 – 221 \n ARIES restart algorithm  216 \n ASP.Net  285 ,  288 – 289 \n Assertions  341 \n Atomicity \n in business process management  127 – 128 \n deﬁ nition  10 \n ensuring with two-phase commit  15 \n introduction to  10 – 13 \n real-time systems  26 \n subtransactions  38 \n TP monitors \n legacy, integrating \n in .NET Framework  297 \n in Java  308 – 309 \n on-line TP (OLTP)  6 \n Attributes  35 – 36 \n Authentication  86 – 88 \n Automated teller machine (ATM) \nexample  10 – 11 ,  12f \n Automatic reconﬁ guration \npartitioning  67 \n Availability \n 2PC  272 \n deﬁ nition of  185 \n introduction to  22 – 24 \n B \n Backups, hot/warm/cold  246 \n Batch processing systems  24 – 25 \n Batching to relieve hot spots  162 \n Bean implementation class  302 \n Bean managed  304 \n Before-image log  200 \n Benchmarks \n TPC-A/B  18 – 19 \n TPC-C  19 – 21 \n TPC-E  21 – 22 \n for vendors, deﬁ ning  17 \n Bindings  291 – 292 \n BizTalk Server adapters  286 \n Blind updates  263 – 264 \n B-link optimization  176 – 178 \n Blocking, 2PC systems  227 – 228 \n Boxcarring  208 \n Bracketing  32 – 34 ,  35 – 37 ,  69 – 70 ,  89 \n Branch transaction  240 \n Broken requests  40 \n Broker-based architecture  113 – 114 \n B-tree indexing \n B \u0005 trees  172 – 174 \n B-links  176 \n locking  175 – 176 \n sidewise pointers  177f \n tree insertion  174 – 175 \n Bus-based architecture  114 – 115 \n Business activity monitoring  126 \n Business interface  302 \n Business objects  77 – 78 \n Business process \n deﬁ nition of  39 ,  121 \n examples of  121 – 122 \n partially automated  122 ,  123 – 124 \n Business process deﬁ nition  123 – 124 \n Business process execution  124 – 126 \n Business process management \n bibliographic notes  360 \n conﬁ guration management \nsystems  135 \n interactions involving people  \n122 ,  123 – 124 ,  124 \n introduction to  121 – 123 \n products and standards  135 – 138 \n scientiﬁ c workﬂ ow model  134 – 135 \n special purpose runtime  129 – 130 \n state management  62 ,  124 – 126 \n summary  139 \n techniques for maintaining durability \n 129 – 134 \n transactional properties  126 – 129 \n using queued requests  130 – 131 \n Business Processing Modeling Notation \n(BPMN)  136 \n Business rules  78 \n Business transaction  121 \n Byzantine failures  225 – 226 \n C \n Cache afﬁ nity  69 \n Cache invalidation  64 \n Cache manager  198 – 199 \n Caching  64 ,  274 – 276 \n Callbacks  52 \n Call-backs  274 \n CAP conjecture  261 \n",
      "content_length": 3466,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 391,
      "content": "372  Index\n Chain of responsibility architecture  291 \n Chained transactions  35 ,  39 \n Channels  291 \n Checkpoint record  198 – 199 \n Checkpointing \n basic  210 \n fuzzy  211 \n Choreography  121 \n CICS (IBM)  35 ,  325 – 328 \n Client-server binding  48 – 52 \n Client-server communications \n direct TP  99 \n queued TP  104 – 106 \n Client-server systems  27 \n Cloud computing  349 – 351 \n Code behind ﬁ le  288 \n Cold backup  246 \n Cold ﬁ elds  156 \n Command Process  334 \n Commit  10 ,  11f \n Commit list  166 \n Commit operation  207 – 208 \n Commit ordering  145 \n Commit record  229 – 230 ,  230 \n Communication \n ACMS (HP)  335 – 336 \n CICS  327 \n client-server \n in direct aTP  99 \n in queued TP  104 – 106 \n IMS TM  330 \n Pathway TS/MP  339 \n publish-subscribe  112 – 113 \n transaction handshakes  144 – 145 \n Tuxedo (Oracle)  333 \n see also  RPC (remote procedure call) \nsystems, queued transaction \nprocessing \n Communication binding  50 – 51 ,  99 – 100 \n Communication manager  240 \n Communication session  58 – 60 \n Compensating transaction  12 ,  128 \n Compensation log record  214 \n Composability problem  33 ,  38 \n Conﬁ guration management systems  135 \n Conﬁ guration management, Transaction \nProcessing systems  28 \n Conﬂ ict in operations  141 \n Consensus, majority and quorum  257 – 258 \n Consensus algorithm  258 \n Conservative locking  157 \n Consistency \n 2PC  261 ,  272 \n deﬁ nition of  13 \n Container  93 \n Container managed  304 \n Context handle  52 \n Contract  289 \n Control thread  41 – 42 \n Conversation  137 \n Conversation group  138 \n Cookie  63 \n Cooperative termination protocol  237 – 238 \n Coordinator  225 \n Correctness and the two-phase rule \n 142 – 143 \n Correlation set  137 \n Cost of ownership  18 \n Crabbing  175 \n Cursor  164 \n Cursor stability  164 – 165 \n Cycles in directed graphs  184 \n Cyclic restart  152 \n D \n Data manager  145 ,  224 \n Data provider  322 \n Data sharing systems \n caching  274 – 276 \n deﬁ nition of  274 – 278 \n locking  274 \n Data warehouse systems  26 ,  163 – 164 \n Database access \n ACMS (HP)  336 \n CICS  327 – 328 \n IMS  330 \n Pathway TS/MP  339 \n persistence abstraction mechanisms \n 315 – 323 \n Tuxedo (Oracle)  333 \n Database cache  198 \n Database log  199 – 200 \n Database mirroring  252 – 253 \n Database recovery \n implementing abort  201 – 202 \n implementing commit  202 – 203 \n introduction  194 – 195 \n log-based  207 – 211 \n Database recovery manager  201 – 203 \n Database servers vs. transactional \nmiddleware  96 – 97 \n Database system  5 \n Database(s) \n TPC-A/B  18 \n TPC-C  19 \n TPC-E  21 \n Deadlock \n deﬁ nition of  150 – 154 \n detection  151 – 152 \n prevention  150 – 151 \n victim selection  152 – 153 \n Decision, heuristic  228 \n Declarative demarcation  309 \n Degree 1 isolation  165 \n Degree 2 isolation  164 \n Degree 3 isolation  165 \n Degrees of isolation  164 – 166 \n Delivery transactions  20 \n Dependent log page address  208 – 209 \n Direct transaction processing \n limitations  99 \n queued TP vs.  99 \n Dirty page table  216 \n Dirty read isolation  165 \n Disaster  219 \n Dispatching  51 ,  112 \n Distributed deadlock detection  153 – 154 \n Document-oriented application  125 \n Domain  332 \n Dominant version vector  266 \n Done record  230 \n Downtime  see  availability \n Durability \n business process management  129 \n deﬁ nition of  14 – 15 \n real-time systems  26 \n subtransactions  38 \n Durability, techniques for maintaining \n logging  133 – 134 \n pseudo-conversations  131 – 132 \n queued requests  130 – 131 \n special-purpose runtime system  129 – 130 \n E \n Eager log writers  229 \n Eclipse  361 \n Efﬁ ciency  1 \n Electronic Data Interchange (EDI)  125 \n Encryption  86 – 88 \n End user  5 \n Endpoint deﬁ nition  292 \n Enlisting in a transaction  239 – 241 \n Enterprise application integration (EAI) \n 113 \n Enterprise Java Bean (EJB)  36 ,  301 \n Enterprise Java Bean (EJB) reference  302 \n Enterprise service buses (ESBs)  113 \n Entity data model (EDM)  322 \n Epoch  259 \n Epoch number  259 \n Epoch set  259 \n Eswaran, K.P., et al.  143 \n Event processing  353 – 354 \n Exception handling  38 – 39 \n Exclusive (X) locks  141 \n",
      "content_length": 4124,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 392,
      "content": "Index  373\n Explicit programming model \n .NET  295 – 296 \n Java EE  307 – 308 \n F \n Failure \n Byzantine  225 \n replication systems  255 – 256 \n total  256 \n see also  Software failures ;  System \nrecovery \n Failure, reducing \n environment  186 \n hardware  187 \n software  187 – 188 \n system management  186 – 187 \n Failure handling in 2PC \n coordinator’s view  228 – 229 \n participant’s view  229 \n termination protocol  231 \n timeout period  228 \n Fault tolerance, RPC systems  54 – 55 \n Filtering  110 \n Flash memory  353 \n Flattening, tree-of-process  242 \n Flow  137 \n Flush log record  215 \n Forms and menus  79 – 82 \n Front-end program layers  78 – 79 \n Front-end programs \n application architecture  78 – 88 \n CICS  326 – 327 \n deﬁ nition of  5 ,  74 \n developing in Java EE  299 – 300 \n developing in .NET Framework  285 – 297 \n IMS TM  330 \n Pathway TS/MP  338 – 339 \n Tuxedo (Oracle)  333 \n use of term client vs.  100 \n web browsers  283 – 284 \n web servers  83 – 84 \n Full disclosure report  17 – 18 \n Function shipping  328 \n Fuzzy checkpointing  211 – 212 \n G \n Geographical entitlement  87 – 88 \n Granularity  148 – 149 \n Graph-based detection  151 \n Graphs \n acyclic directed  184 \n lock instance  178 \n lock type  178 \n serialization  145 ,  183 – 184 \n waits-for  151 \n Gray, Jim  359 \n Group commit  208 \n H \n Handlers  291 \n Handshakes  144 – 145 \n Hardware architecture  9 \n Hardware failure  187 \n Hash partitioning  67 \n Heuristic decision  228 \n Home page  288 \n Host Integration Server (HIS)  286 \n Hot backup  246 \n Hot ﬁ elds  156 \n Hot spots, locking  159 – 163 \n HP \n Application Control and Management \nSystem (HP)  333 – 336 \n bibliographic notes  362 \n Pathway TS/MP  336 – 339 \n Hypertext Transfer Protocol (HTTP)  8 \n I \n IBM \n bibliographic notes  362 \n CICS  35 ,  325 – 328 \n IMS  328 – 330 \n Websphere MQ  115 – 117 \n Identiﬁ ers  16 ,  34 – 35 \n Incomparable version vectors  266 \n Independent recovery  227 – 228 \n Information Management System (IMS) \n(IBM)  328 – 330 \n Integration \n example  47 \n legacy TP monitors \n in .NET Framework  297 \n in Java  308 – 309 \n message-oriented middleware  113 – 115 \n Intention locks  149 ,  178 \n Intention read  178 \n Intention-to-write/intention-to-read lock \ntypes  178 \n Interceptors  291 \n Interface deﬁ nitions  49 \n Internet, computing services over the \n 349 – 351 \n Internet Information Server (IIS)  286 \n Internet websites, response times  18 \n Interoperability \n 2PC systems  243 \n deﬁ nition of  8 ,  94 \n RPC systems  55 – 56 \n Interposition  344 \n Invalidation, cache  64 \n Invitation message  259 \n Isolation \n ANSI SQL terminology  166f \n business process management  127 \n deﬁ nition of  13 – 14 \n Degree 1  165 \n Degree 2  164 \n Degree 3  165 \n read committed  164 \n read uncommitted  165 \n serializable  165 \n snapshot  167 \n speciﬁ cation of scopes and  137 \n subtransactions  38 \n two-phase  164 \n see also  Locking \n Isolation levels  164 – 166 \n J \n Java Database Connectivity (JDBC) \n 316 – 318 \n Java Enterprise Edition (Java EE)  36 , \n 282 – 283 ,  297 – 311 ,  362 \n Java Persistence API (JPA)  319 – 321 \n Java Server Faces (JSF)  299 \n Java Server Pages (JSP)  299 \n Java Transaction API (JTA)  307 ,  344 – 345 \n Joining a transaction  239 \n Journaling  110 \n JPA entity  304 \n L \n Latch  200 \n Lazy log writers  229 \n Leaf pages  172 \n Least-recently-used algorithm  64 \n Legacy TP monitors \n ACMS  333 – 336 \n background  324 – 339 \n CICS transaction server  325 – 328 \n Information Management System (IMS) \n(IBM)  328 – 330 \n integration \n in .NET Framework  297 \n in Java  308 – 309 \n Pathway TS/MP  336 – 339 \n Tuxedo  330 – 333 \n Load balancing  99 – 100 ,  101 \n Lock \n conﬂ ict  141 \n contention, tuning to reduce  156 \n conversions  154 – 155 \n coupling  175 \n deﬁ nition of  141 \n escalation  149 \n",
      "content_length": 3820,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 393,
      "content": "374  Index\nLock (Continued)\n intention  149 ,  178 \n intention-to-write/intention-to-read  178 \n read locks  141 \n read-with-intention-to-write  179 – 180 \n setting and releasing  147 – 148 \n Lock instance graph  178 \n Lock managers  146 – 147 \n Lock table  146 \n Lock thrashing  155 – 158 \n Lock type compatability  179f \n Lock type graph  178 \n Locking \n automated  145 \n batch update  162 \n bibliographic notes  360 \n B-tree  172 – 178 \n conservative  157 \n correctness and the two-phase rule \n 142 – 143 \n in data sharing systems  274 \n deadlocks  150 – 154 \n hot spots  159 – 163 \n implementation  145 – 150 \n introduction to  141 – 145 \n optimistic  160 – 162 \n optimistic concurrency control  171 – 172 \n performance  145 – 146 ,  154 – 159 , \n 158 – 159 ,  170 – 171 \n phantom avoidance  169 – 171 \n query-update problems  163 – 168 \n reducing contention  156 – 158 \n summary  182 – 183 \n transaction handshakes  144 – 145 \n transactions interactions  143 \n tree/B-tree  172 – 178 \n Locking granularity  148 – 149 ,  178 – 181 , \n 179f ,  180f \n Locking nested transactions  181 – 182 \n Log sequence number (LSN)  213 ,  277 \n Log writers, eager or lazy  229 \n Log-based recovery algorithms \n deﬁ nition of  207 – 211 \n implementing abort  207 – 208 \n implementing commit  208 – 209 \n implementing restart  210 – 211 \n Logging  83 ,  133 – 134 ,  277 – 278 \n M \n Machine  9 \n Majority consensus  257 – 258 \n Manufacturing, product data management \nsystem  135 \n Marshaling  49 \n Mean time between failures (MTBF)  185 \n Mean time to repair (MTTR)  185 \n Media failure  195 \n Media recovery \n archiving  219 – 221 \n deﬁ nition of  217 – 221 \n mirrored disks  217 – 219 \n RAID  218 \n Media recovery log  220 \n Mediator  313 \n Memory technology  353 \n Message context  116 \n Message ordering  109 – 110 \n Message-oriented applications  125 \n Message-oriented middleware \n broker-based architecture  113 – 114 \n bus-based architecture  114 – 115 \n Messages, invitation, accept and reject  259 \n Messages, poisoned  109 \n Messaging, queued TP  109 \n Methods  77 – 78 \n Microsoft \n .Net Enterprise Services  36 \n .NET Framework  282 – 283 ,  285 – 297 \n bibliographic notes  362 \n Com  \u0005   36 \n Open Database Connectivity (ODBC) \n 316 – 318 \n SQL Server Service Broker  137 – 138 \n Sync Framework  272 – 273 \n Transaction Server  36 \n Windows Communication Foundation \n(WCF)  286 \n Windows Presentation Foundation (WPF) \n 285 ,  287 – 288 \n Windows Workﬂ ow Foundation (WF)  286 \n Microsoft Windows Communication \nFoundation  36 \n Middleware threads  43 – 46 \n Mirrored database  252 – 253 \n Mirrored disks  217 \n Mission critical services  22 \n Multigranularity locking  149 – 150 , \n 178 – 181 ,  179f ,  180f \n Multistep business processes  12 – 13 \n Multitenant systems  350 – 351 \n Multithreading  51 ,  44 – 45 ,  90 \n Multitier architecture  74 ,  75 – 76 ,  283, 285 – 297 \n Multiversion data  166 – 168 \n N \n Nested transactions \n locking  181 – 182 \n programming model  37 – 38 \n savepoints for supporting  40 – 41 \n New-order transactions  20 \n Node  9 \n Nonblind updates  263 – 265 \n Nonrepeatable reads  164 \n Nontransactional replication  273 \n Nonvolatile storage  14 \n O \n OASIS Service Component Architecture \n(SCA)  345 ,  363 \n Object Management Group (OMG)  \n36 ,  363 \n Object Transaction Service (OTS)  \n343 – 344 \n Object-oriented (OO) paradigm  7 \n Object-oriented design  77 – 78 \n Object-oriented RPC  51 – 52 \n Off-line  3 \n On-line TP (OLTP) monitors  6 \n On-line transaction  2 \n Open Database Connectivity (ODBC) \n(Microsoft)  316 – 318 \n Operating system threads  44 – 45 \n Operation logging  212 – 216 \n Operations, real-world  10 – 11 ,  12f \n Optimistic concurrency control  162 , \n 171 – 172 \n Optimistic locking  160 – 162 \n Oracle \n bibliographic notes  362 \n Tuxedo  330 – 333 \n Oracle Streams AQ  117 – 118 \n Orchestration  121 \n Order-status transactions  20 \n Organization for the Advancement of \nStructured Information Standards \n(OASIS)  340 ,  363 \n OSGi Alliance  345 – 346 ,  363 \n P \n Page granularity operations  197 \n Pages  287 \n Parameter-based routing  66 \n Participants, 2PC  225 \n Partitioning \n 2PC systems  261 – 273 \n automatic reconﬁ guration  67 \n basics of  65 – 67 \n hash  67 \n queued TP  111 \n range  66 \n to relieve hot spots  163 \n table-lookup  67 \n Partitioning sessions  67 – 68 ,  90 \n Partition-tolerance  261 ,  272 \n Partner link/partner link type  136 \n",
      "content_length": 4427,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 394,
      "content": "Index  375\n Path length  149 – 150 \n Pathway TS/MP (HP)  336 – 339 \n Payment transactions  20 \n Performance \n 2PC systems  226 – 227 \n batch processing systems  24 – 25 \n locking  145 – 146 ,  154 – 159 ,  158 – 159 , \n 170 – 171 \n queued TP  103 – 104 \n RPC systems  56 \n transaction processing  17 – 22 \n Persistence abstraction mechanisms \n 315 – 323 \n Persistent storage  14 \n Phantoms in locking  169 – 171 \n Phase zero  234 \n Pick (in BPEL)  137 \n Platforms  94 \n Portability  94 \n Prepared record  230 \n Prepared to commit  16 \n Presentation independence  78 – 79 \n Presumed abort  234 – 235 \n Priority-based scheduling  100 ,  109 – 110 \n Procedure Server  334 \n Processor context  41 – 42 \n Product data management system  135 \n Programmatic demarcation  309 \n Promotable Single Phase Enlistment \n(PSPE)  295 \n Provenance  134 \n Provisioning  350 – 351 \n Pseudo-conversations  131 – 132 \n Publish-subscribe communication  112 – 113 \n Pure restart policy  157 \n Q \n Queue manager  108 – 112 ,  115 \n Queued requests, business process \nmanagement  130 – 131 \n Queued transaction processing \n bibliographic notes  360 \n client recovery  104 – 106 \n client’s viewpoint  103 – 104 \n message-oriented middleware  113 – 115 \n non-undoable operations, handling \n 107 – 108 \n products and standards  115 – 118 \n publish-subscribe  112 – 113 \n queue manager  108 – 112 \n reasons for using  99 – 102 \n server’s viewpoint  102 \n summary  118 – 119 \n Queued transaction processing model \n broker-based  113 – 114 \n Queued transaction processing model \n bus-based  114 – 115 \n database servers vs. middleware  94 – 96 \n Queued transaction processing model \n deﬁ nition of  102 \n Quorum consensus  257 – 258 ,  273 \n R \n RAID (redundant arrays of inexpensive \ndisks)  218 \n Range partitioning  66 \n Read committed isolation  164 \n Read locks  141 \n Read stability  171 \n Read uncommitted isolation  165 \n Read-one-write-all available replication \n 273 \n Read-only transactions  235 – 237 \n Reads \n nonrepeatable  164 \n repeatable  165 ,  171 \n Read-with-intention-to-write locks \n 179 – 180 \n Real-time systems  25 – 26 \n Records of transactions  2 \n Recoverable execution  196 \n Recovery \n 2PC  255 – 256 \n database  194 – 195 ,  207 – 211 \n independent  227 – 228 \n media  217 – 221 \n queued transaction processing  104 – 106 \n strategies  195 \n see also  System recovery \n Recovery log  220 \n Recovery manager  201 – 203 \n Red Hat  363 \n Redundant arrays of inexpensive disks \n(RAID)  218 \n Region  325 \n Registry service  50 – 51 \n Reinfection  232 \n Reject message  259 \n Reliability  185 \n Remote procedure call (RPC)  46 – 57 , \n 70 – 71 \n Repeatable reads  165 ,  171 \n Replacement algorithm  64 \n Replica conﬁ guration  258 \n Replica consensus \n deﬁ nition of  258 \n epoch number and set  259 \n establishing state for  260 – 261 \n messages, invitation, accept and \nreject  259 \n Replica set  258 \n Replicas \n deﬁ nition of  245 \n update streams for  253f \n weighting  258 \n Replicated data \n one-copy serialization  258 – 260 \n replicating requests  251 \n replicating updates  249 – 251 \n synchronizing updates to  248 – 252 \n Replicated servers \n 2PC systems  245 – 248 \n cold backup  246 \n hot backup  246 \n primary backup  245 \n resource management  247 \n warm backup  246 \n Replication \n bibliographic notes  361 \n data sharing systems  274 – 278 \n to distribute workload  68 – 69 \n failure and recovery  255 – 256 \n introduction to  245 \n multimaster \n conﬂ icting resolution  266 \n conﬂ icting updates  262f ,  266 \n deﬁ nition of  261 – 273 \n detecting conﬂ icts  263 – 265 \n Thomas ’ Write Rule  247 \n tombstone  248 \n update propagation  262 \n version vectors  265 – 266 \n nontransactional  273 \n single-master primary-copy  252 – 261 \n summary  278 – 279 \n synchronizing updates to data  248 – 252 \n synchronous vs. asynchronous  \n249 – 251 \n total failure  256 \n Replication conﬂ icts, detecting  265 – 266 \n Representational State Transfer (REST)  8 \n Request controller \n deﬁ nition of  5 ,  75 ,  88 – 89 \n developing in Java EE  301 – 304 \n developing in .NET  289 – 294 \n Enterprise Java Bean (EJB)  301 – 304 \n purpose of  88 – 90 \n Request identiﬁ er  82 – 83 \n Request integrity  89 – 90 \n Request message  3 ,  82 – 83 \n Resource manager  145 ,  224 \n Resource pooling  65 \n Resource replication  247 \n Resources  126 \n REST (representational state transfer)  300 \n",
      "content_length": 4388,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 395,
      "content": "376  Index\n REST (representational state transfer) \narchitectural pattern  8, 85, 300 \n REST/HTTP  8 ,  21 – 22 ,  85 ,  294 \n REST/HTTP-based SOA  314 – 315 \n Reuter, Andreas  359 \n Routing \n parameter-based  66 ,  111 \n queued TP  111 \n RPC (remote procedure call) systems \n comparing  56 – 57 \n fault tolerance  54 – 55 \n interoperability  55 – 56 \n object-oriented  51 – 52 \n performance  56 \n programmer’s view  51 \n security  54 \n summary  70 – 71 \n system management  55 \n transactional  48 \n walkthrough  52 \n S \n SABRE system  3 \n Saga  128 \n Savepoints  39 – 40 ,  40 – 41 \n Scalability  2 ,  17 ,  85 \n Scalability techniques  63 – 69 ,  71 \n Scalable distributed computing  351 – 352 \n Scale-out  65 – 69 ,  111 \n Scheduling priority  100 \n Scientiﬁ c workﬂ ow business model \n 134 – 135 \n Secure sockets layer (SSL)  86 \n Security \n authentication and encryption  86 – 88 \n RPC systems  54 \n user/process authorization  91 \n Serializability \n deﬁ nition of  13 \n one-copy  248 – 252 \n real-time systems  26 \n two-phase locking and  143 ,  183 \n see also  Locking \n Serializability Theorem  183 – 184 \n Serializable isolation  165 \n Serialization graphs  145 ,  183 – 184 \n Server classes  45 – 46 \n Server interface  332 \n Server machine  9 \n Server process  9 \n Server recovery  190 – 191 \n Servers \n database vs. transactional middleware \n 96 – 97 \n replicating with a shared resource  247 – 248 \n scaling up  64 \n stateless  60 – 61 ,  84 – 86 \n Service Component Architecture (SCA) \n 345 ,  363 \n Service level agreement (SLA)  185 \n Service Oriented Architecture (SOA)  7 , \n 76 – 77 ,  311 – 315 \n Service provider  349 \n Servlet  299 \n Session structure, communication  90 \n Shadow paging  204 \n Shadowed disks  217 \n Shared (S) locks  141 \n Shared state systems  57 – 63 ,  71 \n Silverlight  285 ,  288 – 289 \n Simple requests  78 \n Snapshot isolation  167 \n Snapshot mode  166 – 167 \n Software failures \n categories of  23 \n direct TP  99 \n queued TP  104 – 106 \n Special-purpose runtime systems  129 – 130 \n Spraying  68 \n Spring Framework  297 \n SQL database architecture  148f \n SQL Server Service Broker  137 \n Stable storage  14 \n State management  62 \n Stateful applications  61 \n Stateless servers  60 – 61 ,  84 – 86 \n Stock-level transactions  20 \n Storage, stable  14 \n Stored procedure  76, 318 – 319 \n Streams and event processing  353 – 354 \n Stripe  218 \n Subtransactions  37 \n Swing  299 \n Switch  137 \n Syncpoint  35 \n System engineering  24 \n System failure  185 ,  286 \n System management, RPC systems  55 \n System model  196 – 200 \n System recovery \n bibliographic notes  360 \n checkpoint based  191 – 192 \n client recovery  189 – 190 \n detecting process failures for  188 – 189 \n failure causes  185 – 188 \n model  188 – 194 \n server recovery  190 – 191 \n shadow-paging algorithm  203 – 207 \n stateless servers  193 – 194 \n transaction based  192 – 193 \n user techniques for  216 – 217 \n see also  Recovery \n System resources, queued TP  104 ,  111 \n Systems \n deﬁ nition of  9 \n scalability of  2 ,  17 \n styles of  24 \n TP  5 \n T \n Table-lookup partitioning  67 \n Task  334 \n Task group  336 \n Task Server  334 \n Termination protocol  231 ,  237 – 238 \n Testable state  107 \n Thick/thin client architecture  80 \n Thomas ’ Write Rule  247 \n Threads  41 – 46 ,  70 \n Thread-safe applications  51 \n Three-tier architecture  74 \n Timeout period  228 \n Timeout-based detection  151 \n Timeouts, queued TP  109 \n Timesharing systems  26 – 27 ,  42 \n Timestamp ordering  145 \n Tombstone  263 \n Top-level transaction  36 ,  37 \n Total failure  256 \n TPC-A/B benchmarks  18 – 19 \n TPC-C benchmark  19 – 21 \n TPC-E benchmark  21 – 22 \n Transaction abstraction  31 – 41 \n Transaction Handshake Theorem  144 \n Transaction processing \n abstractions \n bibliographic notes  359 \n processes and threads  41 – 46 ,  70 \n remote procedure calls  46 – 57 , \n 70 – 71 \n scalability  63 – 69 ,  71 \n shared state  57 – 63 ,  71 \n summary  69 – 71 \n transaction bracketing  32 – 34 ,  \n69 – 70 \n transactions  31 – 41 \n application architecture \n bibliographic notes  359 \n front-end programs  78 – 88 \n functional components  74 \n introduction to  73 – 74 \n middleware  92 – 94 \n multitier  75 – 76 ,  285 – 297 \n object-oriented design  77 – 78 \n request controllers  88 – 90 \n",
      "content_length": 4300,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 396,
      "content": "Index  377\n service-oriented (SOA)  7 ,  76 – 77 , \n 311 – 315 \n summary  96 – 97 \n transaction servers  91 – 92 \n applications  3 – 4 ,  4f ,  99 – 102 \n basics of  1 – 4 \n critical properties of  9 – 15 \n deﬁ nition of  1 – 2 ,  2 \n further resources  359 \n future trends \n cloud computing  349 – 351 \n introduction to  349 \n memory technology  353 \n multitenant systems  350 – 351 \n scalable distributed computing \n 351 – 352 \n streams and event processing  353 – 354 \n summary  354 \n history  359 \n requirements of  1 – 2 \n standards \n Advanced Message Queueing \nProtocol (AMQP)  346 \n bibliographic notes  361 \n introduction to  339 – 346 \n Java Transaction API (JTA)  344 – 345 \n Object Transaction Service (OTS) \n 343 – 344 \n OSGi Alliance  345 – 346 \n Service Component Architecture \n(SCA)  345 \n WS-Transactions  340 – 342 \n XA interface  342 – 343 \n summary  29 \n systems \n availability  22 – 24 \n database servers vs. middleware \n 94 – 96 \n distributed  2 \n hardware architecture  9 \n performance  17 – 22 \n personalizing  2 \n scaling up  2 \n styles of  24 – 28 \n system architecture  5 – 9 \n two-phase commit  15 – 17 \n Transaction Processing (Gray and Reuter) \n 359 \n Transaction Processing Performance \nCouncil (TPC)  17 – 18 \n Transaction program  3 ,  4 ,  6 \n Transaction rate metric (tpmC)  20 \n Transactional middleware \n basics of  92 – 94 \n database servers vs.  94 – 96 \n deﬁ nition of  6 \n message-oriented  113 – 115 \n persistence abstraction mechanisms and \n 315 – 323 \n products \n ASP.Net  288 – 289 \n bibliographic notes  361 \n future trends  351 – 352 \n Java Enterprise Edition  36 ,  282 – 283 , \n 297 – 311 \n legacy TP monitors  324 – 339 \n Microsoft’s .NET Framework \n 282 – 283 ,  285 – 297 \n Silverlight  288 – 289 \n Spring Framework  309 – 311 \n summary  346 – 348 \n web browser front-end programs \n 83 – 84 ,  283 – 284 \n programming models  282 \n trends in  281 – 282 \n see also  application programming \ninterface (API) \n Transactional RPC  48 \n Transaction(s) \n acknowledgement of  2 \n ambient  294 \n application parts  5f \n attributes \n .NET  290 – 291 \n deﬁ nition of  35 – 36 \n Java EE  303 ,  305 – 307 \n bracketing  32 – 34 ,  35 – 37 ,  69 – 70 ,  89 \n business  1 – 2 \n composability problem  33 \n critical properties of  9 \n deﬁ nition of  2 – 3 \n descriptor  208 \n failure  195 \n handshakes  144 – 145 \n identiﬁ er  16 ,  34 – 35 \n load  155 \n management \n in .NET Framework  294 – 295 \n in Java EE  293 – 294 \n Java EE and .NET discussion  293 \n manager  15 ,  238 – 242 \n on-line  2 \n path length  142 \n per second (tps)/per minute (tpm)  18 \n routing  326 \n servers \n basics of  91 – 92 \n deﬁ nition of  5 ,  75 \n developing  289 – 294 \n Enterprise Java Bean (EJB)  301 – 304 \n types of TPC-C  20 \n types of TPC-E  21t \n uncontrolled concurrent  1 \n Transport Layer Security (TLS)  86 \n Tree locking  172 – 178 \n Tree-of-processes model  241 – 242 \n Tuxedo (Oracle)  330 – 333 \n Two-phase commit (2PC) \n basics of  15 – 17 \n bibliographic notes  360 \n failure handling  228 – 232 \n introduction to  223 – 224 \n optimizations and variations  \n232 – 238 \n process structuring  238 – 242 \n summary  243 – 244 \n user checklist  243 \n Two-phase commit (2PC) protocol \n 224 – 228 \n Two-Phase Locking Theorem  143 , \n 143 – 144 ,  184 \n Two-phase rule in locking  145 ,  164 , \n 142 – 143 \n U \n Ullman, J. D.  143 ,  183 \n Uncertainty  227 \n Unchained transactions  35 ,  39 \n Undo log record  214 \n Unsolicited abort  38 \n Update lock  142 \n Update-bit  220 \n URL rewriting  63 \n User authentication  86 – 88 \n V \n Version ID  265 \n Version ID invariant  267 \n Version ID update rules  272 \n Version vector update rules  267 – 269 \n Version vectors  265 – 266 \n Victim selection, deadlock  152 – 153 \n W \n Waits-for graph  151 \n Warm backup  246 \n Web browsers \n cookies  63 \n front-end programs  283 – 284 \n in multitier TP architecture  283f \n Web servers \n front-end programs  83 – 84 \n state management  84 – 86 \n use of term client vs.  100 \n Web Services  6 ,  8 \n",
      "content_length": 4014,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 397,
      "content": "378  Index\n Web Services Business Process Execution \nLanguage (WS-BPEL) standard \n 136 – 137 ,  286 \n The Web Services Interoperability \nOrganization (WS-I)  363 \n Web Services-based SOA  312 – 314 \n Websphere MQ (IBM)  115 – 117 \n Weighting replicas  258 \n Workﬂ ow  39 ,  121 \n World Wide Web Consortium \n(W3C)  363 \n Write locks  141 \n Write-through/write-back cache  65 \n WS-Transactions  340 – 342 \n X \n X locks  141 \n XA interface  342 – 343 \n X/Open transaction model (XA)  16f ,  237f , \n 343f  \n",
      "content_length": 504,
      "extraction_method": "PyMuPDF_fallback"
    }
  ]
}