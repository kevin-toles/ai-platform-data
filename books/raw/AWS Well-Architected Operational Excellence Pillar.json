{
  "metadata": {
    "title": "AWS Well-Architected Operational Excellence Pillar",
    "author": "Amazon Web Services",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 226,
    "conversion_date": "2025-12-19T17:17:41.269990",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "AWS Well-Architected Operational Excellence Pillar.pdf",
    "extraction_method": "Unstructured"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 1-8)",
      "start_page": 1,
      "end_page": 8,
      "detection_method": "topic_boundary",
      "content": "AWS Well-Architected Framework\n\nOperational Excellence Pillar\n\nCopyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational Excellence Pillar: AWS Well-Architected Framework\n\nCopyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n\nAmazon's trademarks and trade dress may not be used in connection with any product or service\n\nthat is not Amazon's, in any manner that is likely to cause confusion among customers, or in any\n\nmanner that disparages or discredits Amazon. All other trademarks not owned by Amazon are\n\nthe property of their respective owners, who may or may not be aﬃliated with, connected to, or\n\nsponsored by Amazon.\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nTable of Contents\n\nAbstract and introduction ............................................................................................................... 1 Introduction ................................................................................................................................................... 1\n\nOperational excellence .................................................................................................................... 3 Design principles ........................................................................................................................................... 3\n\nDeﬁnition ........................................................................................................................................................ 4\n\nOrganization .................................................................................................................................... 6 Organization priorities ................................................................................................................................. 9\n\nOPS01-BP01 Evaluate external customer needs .............................................................................. 9\n\nOPS01-BP02 Evaluate internal customer needs ............................................................................ 10\n\nOPS01-BP03 Evaluate governance requirements .......................................................................... 12\n\nOPS01-BP04 Evaluate compliance requirements .......................................................................... 14\n\nOPS01-BP05 Evaluate threat landscape .......................................................................................... 17 OPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks ......................................... 19\n\nOperating model ........................................................................................................................................ 23\n\nOperating model 2 by 2 representations ........................................................................................ 24\n\nRelationships and ownership .............................................................................................................. 33\n\nOrganizational culture ............................................................................................................................... 53\n\nOPS03-BP01 Provide executive sponsorship .................................................................................. 54\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk ...... 57\n\nOPS03-BP03 Escalation is encouraged ............................................................................................ 60\n\nOPS03-BP04 Communications are timely, clear, and actionable ................................................ 63\n\nOPS03-BP05 Experimentation is encouraged ................................................................................. 68\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets .............. 70\n\nOPS03-BP07 Resource teams appropriately ................................................................................... 73\n\nPrepare ........................................................................................................................................... 77 Implement observability ........................................................................................................................... 78\n\nOPS04-BP01 Identify key performance indicators ........................................................................ 79\n\nOPS04-BP02 Implement application telemetry ............................................................................. 81\n\nOPS04-BP03 Implement user experience telemetry ..................................................................... 84\n\nOPS04-BP04 Implement dependency telemetry ........................................................................... 87\n\nOPS04-BP05 Implement distributed tracing .................................................................................. 90\n\nDesign for operations ................................................................................................................................ 93\n\nOPS05-BP01 Use version control ...................................................................................................... 93\n\nOPS05-BP02 Test and validate changes .......................................................................................... 94\n\niii\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS05-BP03 Use conﬁguration management systems ................................................................ 98\n\nOPS05-BP04 Use build and deployment management systems .............................................. 101 OPS05-BP05 Perform patch management ................................................................................... 103\n\nOPS05-BP06 Share design standards ............................................................................................ 106\n\nOPS05-BP07 Implement practices to improve code quality ..................................................... 109\n\nOPS05-BP08 Use multiple environments ...................................................................................... 112\n\nOPS05-BP09 Make frequent, small, reversible changes ............................................................. 114\n\nOPS05-BP10 Fully automate integration and deployment ....................................................... 115\n\nMitigate deployment risks ..................................................................................................................... 117\n\nOPS06-BP01 Plan for unsuccessful changes ................................................................................ 117\n\nOPS06-BP02 Test deployments ...................................................................................................... 120\n\nOPS06-BP03 Employ safe deployment strategies ...................................................................... 123\n\nOPS06-BP04 Automate testing and rollback ............................................................................... 126\n\nOperational readiness and change management ............................................................................. 130 OPS07-BP01 Ensure personnel capability .................................................................................... 130\n\nOPS07-BP02: Ensure a consistent review of operational readiness ......................................... 132\n\nOPS07-BP03 Use runbooks to perform procedures ................................................................... 136\n\nOPS07-BP04 Use playbooks to investigate issues ...................................................................... 140\n\nOPS07-BP05 Make informed decisions to deploy systems and changes ................................ 144\n\nOPS07-BP06 Create support plans for production workloads ................................................. 146\n\nOperate ........................................................................................................................................ 149 Utilizing workload observability ........................................................................................................... 150\n\nOPS08-BP01 Analyze workload metrics ........................................................................................ 151\n\nOPS08-BP02 Analyze workload logs .............................................................................................. 153\n\nOPS08-BP03 Analyze workload traces .......................................................................................... 155\n\nOPS08-BP04 Create actionable alerts ........................................................................................... 158\n\nOPS08-BP05 Create dashboards ..................................................................................................... 161\n\nUnderstanding operational health ....................................................................................................... 164\n\nOPS09-BP01 Measure operations goals and KPIs with metrics ................................................ 164\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation ................ 167\n\nOPS09-BP03 Review operations metrics and prioritize improvement .................................... 169\n\nResponding to events ............................................................................................................................. 171\n\nOPS10-BP01 Use a process for event, incident, and problem management .......................... 171\n\nOPS10-BP02 Have a process per alert .......................................................................................... 176\n\nOPS10-BP03 Prioritize operational events based on business impact .................................... 180\n\nOPS10-BP04 Deﬁne escalation paths ............................................................................................ 183\n\niv\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events ........... 185\n\nOPS10-BP06 Communicate status through dashboards ............................................................ 188 OPS10-BP07 Automate responses to events ............................................................................... 191\n\nEvolve ........................................................................................................................................... 194 Learn, share, and improve ..................................................................................................................... 195\n\nOPS11-BP01 Have a process for continuous improvement ....................................................... 195\n\nOPS11-BP02 Perform post-incident analysis ............................................................................... 197\n\nOPS11-BP03 Implement feedback loops ...................................................................................... 199\n\nOPS11-BP04 Perform knowledge management ......................................................................... 203\n\nOPS11-BP05 Deﬁne drivers for improvement ............................................................................. 205\n\nOPS11-BP06 Validate insights ......................................................................................................... 207\n\nOPS11-BP07 Perform operations metrics reviews ...................................................................... 209\n\nOPS11-BP08 Document and share lessons learned .................................................................... 211\n\nOPS11-BP09 Allocate time to make improvements ................................................................... 212\n\nConclusion .................................................................................................................................... 215\n\nContributors ................................................................................................................................. 216\n\nFurther reading ............................................................................................................................ 217\n\nDocument revisions ..................................................................................................................... 218\n\nNotices .......................................................................................................................................... 220\n\nAWS Glossary ............................................................................................................................... 221\n\nv\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational Excellence Pillar - AWS Well-Architected\n\nFramework\n\nPublication date: November 6, 2024 (Document revisions)\n\nThe focus of this paper is the operational excellence pillar of the AWS Well-Architected Framework.\n\nIt provides guidance to help you apply best practices in the design, delivery, and maintenance of\n\nAWS workloads.\n\nIntroduction\n\nThe AWS Well-Architected Framework helps you understand the beneﬁts and risks of decisions you\n\nmake while building workloads on AWS. By using the Framework you will learn operational and\n\narchitectural best practices for designing and operating reliable, secure, eﬃcient, cost-eﬀective,\n\nand sustainable workloads in the cloud. It provides a way to consistently measure your operations\n\nand architectures against best practices and identify areas for improvement. We believe that\n\nhaving Well-Architected workloads that are designed with operations in mind greatly increases the\n\nlikelihood of business success.\n\nThe framework is based on six pillars:\n\nOperational Excellence\n\nSecurity\n\nReliability\n\nPerformance Eﬃciency\n\nCost Optimization\n\nSustainability\n\nThis paper focuses on the operational excellence pillar and how to apply it as the foundation of\n\nyour well-architected solutions. Operational excellence is challenging to achieve in environments\n\nwhere operations is perceived as a function isolated and distinct from the lines of business\n\nand development teams that it supports. By adopting the practices in this paper you can build\n\narchitectures that provide insight to their status, are activated for eﬀective and eﬃcient operation\n\nand event response, and can continue to improve and support your business goals.\n\nIntroduction\n\n1\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThis paper is intended for those in technology roles, such as chief technology oﬃcers (CTOs),\n\narchitects, developers, and operations team members. After reading this paper, you will understand AWS best practices and the strategies to use when designing cloud architectures for operational\n\nexcellence. This paper does not provide implementation details or architectural patterns. However,\n\nit does include references to appropriate resources for this information.\n\nIntroduction\n\n2\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational excellence\n\nOperational excellence (OE) is a commitment to build software correctly while consistently\n\ndelivering a great customer experience. The operational excellence pillar contains best practices for\n\norganizing your team, designing your workload, operating it at scale, and evolving it over time.\n\nThe goal of operational excellence is to get new features and bug ﬁxes into customers’ hands\n\nquickly and reliably. Organizations that invest in operational excellence consistently delight\n\ncustomers while building new features, making changes, and dealing with failures. Along the way,\n\noperational excellence drives towards continuous integration and continuous delivery (CI/CD) by\n\nhelping developers achieve high quality results consistently.\n\nDesign principles\n\nThe following are the design principles for operational excellence in the cloud:\n\nOrganize teams around business outcomes: The ability of a team to achieve business outcomes\n\ncomes from leadership vision, eﬀective operations, and a business-aligned operating model.\n\nLeadership should be fully invested and committed to a CloudOps transformation with a suitable\n\ncloud operating model that incentivizes teams to operate in the most eﬃcient way and meet\n\nbusiness outcomes. The right operating model uses people, process, and technology capabilities\n\nto scale, optimize for productivity, and diﬀerentiate through agility, responsiveness, and\n\nadaptation. The organization's long-term vision is translated into goals that are communicated\n\nacross the enterprise to stakeholders and consumers of your cloud services. Goals and\n\noperational KPIs are aligned at all levels. This practice sustains the long-term value derived from\n\nimplementing the following design principles.\n\nImplement observability for actionable insights: Gain a comprehensive understanding\n\nof workload behavior, performance, reliability, cost, and health. Establish key performance indicators (KPIs) and leverage observability telemetry to make informed decisions and take\n\nprompt action when business outcomes are at risk. Proactively improve performance, reliability,\n\nand cost based on actionable observability data.\n\nSafely automate where possible: In the cloud, you can apply the same engineering discipline\n\nthat you use for application code to your entire environment. You can deﬁne your entire\n\nworkload and its operations (applications, infrastructure, conﬁguration, and procedures) as code,\n\nand update it. You can then automate your workload’s operations by initiating them in response\n\nto events. In the cloud, you can employ automation safety by conﬁguring guardrails, including\n\nDesign principles\n\n3",
      "page_number": 1
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 9-16)",
      "start_page": 9,
      "end_page": 16,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nrate control, error thresholds, and approvals. Through eﬀective automation, you can achieve\n\nconsistent responses to events, limit human error, and reduce operator toil.\n\nMake frequent, small, reversible changes: Design workloads that are scalable and loosely\n\ncoupled to permit components to be updated regularly. Automated deployment techniques\n\ntogether with smaller, incremental changes reduces the blast radius and allows for faster reversal\n\nwhen failures occur. This increases conﬁdence to deliver beneﬁcial changes to your workload\n\nwhile maintaining quality and adapting quickly to changes in market conditions.\n\nReﬁne operations procedures frequently: As you evolve your workloads, evolve your operations appropriately. As you use operations procedures, look for opportunities to improve them. Hold regular reviews and validate that all procedures are eﬀective and that teams are familiar with\n\nthem. Where gaps are identiﬁed, update procedures accordingly. Communicate procedural\n\nupdates to all stakeholders and teams. Gamify your operations to share best practices and\n\neducate teams.\n\nAnticipate failure: Maximize operational success by driving failure scenarios to understand the workload’s risk proﬁle and its impact on your business outcomes. Test the eﬀectiveness of your procedures and your team’s response against these simulated failures. Make informed decisions\n\nto manage open risks that are identiﬁed by your testing.\n\nLearn from all operational events and metrics: Drive improvement through lessons learned from all operational events and failures. Share what is learned across teams and through the entire organization. Learnings should highlight data and anecdotes on how operations\n\ncontribute to business outcomes.\n\nUse managed services: Reduce operational burden by using AWS managed services where\n\npossible. Build operational procedures around interactions with those services.\n\nDeﬁnition\n\nThere are four best practice areas for operational excellence in the cloud:\n\nOrganization\n\nPrepare\n\nOperate\n\nEvolve\n\nYour organization’s leadership deﬁnes business objectives. Your organization must understand\n\nrequirements and priorities and use these to organize and conduct work to support the\n\nDeﬁnition\n\n4\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nachievement of business outcomes. Your workload must emit the information necessary to support\n\nit. Implementing services to activate integration, deployment, and delivery of your workload will create an increased ﬂow of beneﬁcial changes into production by automating repetitive processes.\n\nThere may be risks inherent in the operation of your workload. You must understand those risks\n\nand make an informed decision to enter production. Your teams must be able to support your\n\nworkload. Business and operational metrics derived from desired business outcomes will help you\n\nto understand the health of your workload, your operations activities, and respond to incidents.\n\nYour priorities will change as your business needs and business environment changes. Use these as\n\na feedback loop to continually drive improvement for your organization and the operation of your\n\nworkload.\n\nDeﬁnition\n\n5\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOrganization\n\nYour teams must have a shared understanding of your entire workload, their role in it, and shared\n\nbusiness goals to set the priorities that will achieve business success. Well-deﬁned priorities will\n\nmaximize the beneﬁts of your eﬀorts. Evaluate internal and external customer needs involving\n\nkey stakeholders, including business, development, and operations teams, to determine where to\n\nfocus eﬀorts. Evaluating customer needs will verify that you have a thorough understanding of\n\nthe support that is required to achieve business outcomes. Verify that you are aware of guidelines\n\nor obligations deﬁned by your organizational governance and external factors, such as regulatory\n\ncompliance requirements and industry standards that may mandate or emphasize speciﬁc focus.\n\nValidate that you have mechanisms to identify changes to internal governance and external\n\ncompliance requirements. If no requirements are identiﬁed, validate that you have applied due diligence to this determination. Review your priorities regularly so that they can be updated as needs change.\n\nEvaluate threats to the business (for example, business risk and liabilities, and information security\n\nthreats) and maintain this information in a risk registry. Evaluate the impact of risks, and tradeoﬀs\n\nbetween competing interests or alternative approaches. For example, accelerating speed to market\n\nfor new features may be emphasized over cost optimization, or you may choose a relational\n\ndatabase for non-relational data to simplify the eﬀort to migrate a system without refactoring.\n\nManage beneﬁts and risks to make informed decisions when determining where to focus eﬀorts.\n\nSome risks or choices may be acceptable for a time, it may be possible to mitigate associated risks,\n\nor it may become unacceptable to permit a risk to remain, in which case you will take action to\n\naddress the risk.\n\nYour teams must understand their part in achieving business outcomes. Teams must understand\n\ntheir roles in the success of other teams, the role of other teams in their success, and have shared\n\ngoals. Understanding responsibility, ownership, how decisions are made, and who has authority to make decisions will help focus eﬀorts and maximize the beneﬁts from your teams. The needs of\n\na team will be shaped by the customer they support, their organization, the makeup of the team,\n\nand the characteristics of their workload. It's unreasonable to expect a single operating model to\n\nbe able to support all teams and their workloads in your organization.\n\nVerify that there are identiﬁed owners for each application, workload, platform, and infrastructure\n\ncomponent, and that each process and procedure has an identiﬁed owner responsible for its\n\ndeﬁnition, and owners responsible for their performance.\n\n6\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nHaving understanding of the business value of each component, process, and procedure, of why\n\nthose resources are in place or activities are performed, and why that ownership exists will inform the actions of your team members. Clearly deﬁne the responsibilities of team members so that\n\nthey may act appropriately and have mechanisms to identify responsibility and ownership. Have\n\nmechanisms to request additions, changes, and exceptions so that you do not constrain innovation.\n\nDeﬁne agreements between teams describing how they work together to support each other and\n\nyour business outcomes.\n\nProvide support for your team members so that they can be more eﬀective in taking action and\n\nsupporting your business outcomes. Engaged senior leadership should set expectations and\n\nmeasure success. Senior leadership should be the sponsor, advocate, and driver for the adoption\n\nof best practices and evolution of the organization. Let team members take action when outcomes\n\nare at risk to minimize impact and encourage them to escalate to decision makers and stakeholders\n\nwhen they believe there is a risk so that it can be addressed and incidents avoided. Provide timely,\n\nclear, and actionable communications of known risks and planned events so that team members\n\ncan take timely and appropriate action.\n\nEncourage experimentation to accelerate learning and keep team members interested and\n\nengaged. Teams must grow their skill sets to adopt new technologies, and to support changes in\n\ndemand and responsibilities. Support and encourage this by providing dedicated structured time\n\nfor learning. Verify that your team members have the resources, both tools and team members, to\n\nbe successful and scale to support your business outcomes. Leverage cross-organizational diversity\n\nto seek multiple unique perspectives. Use this perspective to increase innovation, challenge your\n\nassumptions, and reduce the risk of conﬁrmation bias. Grow inclusion, diversity, and accessibility\n\nwithin your teams to gain beneﬁcial perspectives.\n\nIf there are external regulatory or compliance requirements that apply to your organization,\n\nyou should use the resources provided by AWS Cloud Compliance to help educate your teams\n\nso that they can determine the impact on your priorities. The Well-Architected Framework\n\nemphasizes learning, measuring, and improving. It provides a consistent approach for you to\n\nevaluate architectures, and implement designs that will scale over time. AWS provides the\n\nAWS Well-Architected Tool to help you review your approach before development, the state\n\nof your workloads before production, and the state of your workloads in production. You can\n\ncompare workloads to the latest AWS architectural best practices, monitor their overall status,\n\nand gain insight into potential risks. AWS Trusted Advisor is a tool that provides access to a core\n\nset of checks that recommend optimizations that may help shape your priorities. Business and\n\nEnterprise Support customers receive access to additional checks focusing on security, reliability,\n\nperformance, cost-optimization, and sustainability that can further help shape their priorities.\n\n7\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS can help you educate your teams about AWS and its services to increase their understanding\n\nof how their choices can have an impact on your workload. Use the resources provided by AWS Support (AWS Knowledge Center, AWS Discussion Forums, and AWS Support Center) and AWS\n\nDocumentation to educate your teams. Reach out to AWS Support through AWS Support Center\n\nfor help with your AWS questions. AWS also shares best practices and patterns that we have\n\nlearned through the operation of AWS in The Amazon Builders' Library. A wide variety of other\n\nuseful information is available through the AWS Blog and The Oﬃcial AWS Podcast. AWS Training\n\nand Certiﬁcation provides some training through self-paced digital courses on AWS fundamentals.\n\nYou can also register for instructor-led training to further support the development of your teams’\n\nAWS skills.\n\nUse tools or services that permit you to centrally govern your environments across accounts,\n\nsuch as AWS Organizations, to help manage your operating models. Services like AWS Control\n\nTower expand this management capability by allowing you to deﬁne blueprints (supporting your operating models) for the setup of accounts, apply ongoing governance using AWS Organizations,\n\nand automate provisioning of new accounts. Managed Services providers such as AWS Managed\n\nServices, AWS Managed Services Partners, or Managed Services Providers in the AWS Partner\n\nNetwork, provide expertise implementing cloud environments, and support your security and\n\ncompliance requirements and business goals. Adding Managed Services to your operating model\n\ncan save you time and resources, and lets you keep your internal teams lean and focused on\n\nstrategic outcomes that will diﬀerentiate your business, rather than developing new skills and\n\ncapabilities.\n\nYou might ﬁnd that you want to emphasize a small subset of your priorities at some point in time.\n\nUse a balanced approach over the long term to verify the development of needed capabilities\n\nand management of risk. Review your priorities regularly and update them as needs change.\n\nWhen responsibility and ownership are undeﬁned or unknown, you are at risk of both not\n\nperforming necessary action in a timely fashion and of redundant and potentially conﬂicting\n\neﬀorts emerging to address those needs. Organizational culture has a direct impact on team\n\nmember job satisfaction and retention. Activate the engagement and capabilities of your team\n\nmembers to achieve the success of your business. Experimentation is required for innovation to\n\nhappen and turn ideas into outcomes. Recognize that an undesired result is a successful experiment\n\nthat has identiﬁed a path that will not lead to success.\n\nTopics\n\nOrganization priorities\n\nOperating model\n\n8\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOrganizational culture\n\nOrganization priorities\n\nYour teams need to have a shared understanding of your entire workload, their role in it, and\n\nshared business goals to set the priorities that will create business success. Well-deﬁned priorities\n\nwill maximize the beneﬁts of your eﬀorts. Review your priorities regularly so that they can be\n\nupdated as your organization's needs change.\n\nBest practices\n\nOPS01-BP01 Evaluate external customer needs\n\nOPS01-BP02 Evaluate internal customer needs\n\nOPS01-BP03 Evaluate governance requirements\n\nOPS01-BP04 Evaluate compliance requirements\n\nOPS01-BP05 Evaluate threat landscape\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nOPS01-BP01 Evaluate external customer needs\n\nInvolve key stakeholders, including business, development, and operations teams, to determine\n\nwhere to focus eﬀorts on external customer needs. This veriﬁes that you have a thorough\n\nunderstanding of the operations support that is required to achieve your desired business\n\noutcomes.\n\nDesired outcome:\n\nYou work backwards from customer outcomes.\n\nYou understand how your operational practices support business outcomes and objectives.\n\nYou engage all relevant parties.\n\nYou have mechanisms to capture external customer needs.\n\nCommon anti-patterns:\n\nOrganization priorities\n\n9\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou have decided not to have customer support outside of core business hours, but you haven't\n\nreviewed historical support request data. You do not know whether this will have an impact on your customers.\n\nYou are developing a new feature but have not engaged your customers to ﬁnd out if it is\n\ndesired, if desired in what form, and without experimentation to validate the need and method\n\nof delivery.\n\nBeneﬁts of establishing this best practice: Customers whose needs are satisﬁed are much more likely to remain customers. Evaluating and understanding external customer needs will inform how\n\nyou prioritize your eﬀorts to deliver business value.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nUnderstand business needs: Business success is created by shared goals and understanding across stakeholders, including business, development, and operations teams.\n\nReview business goals, needs, and priorities of external customers: Engage key stakeholders, including business, development, and operations teams, to discuss goals, needs, and priorities\n\nof external customers. This ensures that you have a thorough understanding of the operational\n\nsupport that is required to achieve business and customer outcomes.\n\nEstablish a shared understanding: Establish a shared understanding of the business functions of the workload, the roles of each of the teams in operating the workload, and how these factors\n\nsupport your shared business goals across internal and external customers.\n\nResources\n\nRelated best practices:\n\nOPS11-BP03 Implement feedback loops\n\nOPS01-BP02 Evaluate internal customer needs\n\nInvolve key stakeholders, including business, development, and operations teams, when\n\ndetermining where to focus eﬀorts on internal customer needs. This will ensure that you have a\n\nthorough understanding of the operations support that is required to achieve business outcomes.\n\nOPS01-BP02 Evaluate internal customer needs\n\n10\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome:\n\nYou use your established priorities to focus your improvement eﬀorts where they will have the\n\ngreatest impact (for example, developing team skills, improving workload performance, reducing\n\ncosts, automating runbooks, or enhancing monitoring).\n\nYou update your priorities as needs change.\n\nCommon anti-patterns:\n\nYou have decided to change IP address allocations for your product teams, without consulting\n\nthem, to make managing your network easier. You do not know the impact this will have on your\n\nproduct teams.\n\nYou are implementing a new development tool but have not engaged your internal customers to\n\nﬁnd out if it is needed or if it is compatible with their existing practices.\n\nYou are implementing a new monitoring system but have not contacted your internal customers\n\nto ﬁnd out if they have monitoring or reporting needs that should be considered.\n\nBeneﬁts of establishing this best practice: Evaluating and understanding internal customer needs informs how you prioritize your eﬀorts to deliver business value.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nUnderstand business needs: Business success is created by shared goals and understanding\n\nacross stakeholders including business, development, and operations teams.\n\nReview business goals, needs, and priorities of internal customers: Engage key stakeholders,\n\nincluding business, development, and operations teams, to discuss goals, needs, and priorities\n\nof internal customers. This ensures that you have a thorough understanding of the operational\n\nsupport that is required to achieve business and customer outcomes.\n\nEstablish shared understanding: Establish shared understanding of the business functions of\n\nthe workload, the roles of each of the teams in operating the workload, and how these factors\n\nsupport shared business goals across internal and external customers.\n\nResources\n\nRelated best practices:\n\nOPS01-BP02 Evaluate internal customer needs\n\n11",
      "page_number": 9
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 17-24)",
      "start_page": 17,
      "end_page": 24,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP03 Implement feedback loops\n\nOPS01-BP03 Evaluate governance requirements\n\nGovernance is the set of policies, rules, or frameworks that a company uses to achieve its business\n\ngoals. Governance requirements are generated from within your organization. They can aﬀect the\n\ntypes of technologies you choose or inﬂuence the way you operate your workload. Incorporate\n\norganizational governance requirements into your workload. Conformance is the ability to\n\ndemonstrate that you have implemented governance requirements.\n\nDesired outcome:\n\nGovernance requirements are incorporated into the architectural design and operation of your\n\nworkload.\n\nYou can provide proof that you have followed governance requirements.\n\nGovernance requirements are regularly reviewed and updated.\n\nCommon anti-patterns:\n\nYour organization mandates that the root account has multi-factor authentication. You failed to\n\nimplement this requirement and the root account is compromised.\n\nDuring the design of your workload, you choose an instance type that is not approved by the IT\n\ndepartment. You are unable to launch your workload and must conduct a redesign.\n\nYou are required to have a disaster recovery plan. You did not create one and your workload\n\nsuﬀers an extended outage.\n\nYour team wants to use new instances but your governance requirements have not been updated\n\nto allow them.\n\nBeneﬁts of establishing this best practice:\n\nFollowing governance requirements aligns your workload with larger organization policies.\n\nGovernance requirements reﬂect industry standards and best practices for your organization.\n\nLevel of risk exposed if this best practice is not established: High\n\nOPS01-BP03 Evaluate governance requirements\n\n12\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nIdentify governance requirement by working with stakeholders and governance organizations. Include governance requirements into your workload. Be able to demonstrate proof that you’ve\n\nfollowed governance requirements.\n\nCustomer example\n\nAt AnyCompany Retail, the cloud operations team works with stakeholders across the organization\n\nto develop governance requirements. For example, they prohibit SSH access into Amazon EC2\n\ninstances. If teams need system access, they are required to use AWS Systems Manager Session\n\nManager. The cloud operations team regularly updates governance requirements as new services\n\nbecome available.\n\nImplementation steps\n\n1. Identify the stakeholders for your workload, including any centralized teams.\n\n2. Work with stakeholders to identify governance requirements.\n\n3. Once you’ve generated a list, prioritize the improvement items, and begin implementing them\n\ninto your workload.\n\na. Use services like AWS Conﬁg to create governance-as-code and validate that governance\n\nrequirements are followed.\n\nb. If you use AWS Organizations, you can leverage Service Control Policies to implement\n\ngovernance requirements.\n\n4. Provide documentation that validates the implementation.\n\nLevel of eﬀort for the implementation plan: Medium. Implementing missing governance requirements may result in rework of your workload.\n\nResources\n\nRelated best practices:\n\nOPS01-BP04 Evaluate compliance requirements - Compliance is like governance but comes from\n\noutside an organization.\n\nRelated documents:\n\nOPS01-BP03 Evaluate governance requirements\n\n13\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Management and Governance Cloud Environment Guide\n\nBest Practices for AWS Organizations Service Control Policies in a Multi-Account Environment\n\nGovernance in the AWS Cloud: The Right Balance Between Agility and Safety\n\nWhat is Governance, Risk, And Compliance (GRC)?\n\nRelated videos:\n\nAWS Management and Governance: Conﬁguration, Compliance, and Audit - AWS Online Tech\n\nTalks\n\nAWS re:Inforce 2019: Governance for the Cloud Age (DEM12-R1)\n\nAWS re:Invent 2020: Achieve compliance as code using AWS Conﬁg\n\nAWS re:Invent 2020: Agile governance on AWS GovCloud (US)\n\nRelated examples:\n\nAWS Conﬁg Conformance Pack Samples\n\nRelated services:\n\nAWS Conﬁg\n\nAWS Organizations - Service Control Policies\n\nOPS01-BP04 Evaluate compliance requirements\n\nRegulatory, industry, and internal compliance requirements are an important driver for deﬁning\n\nyour organization’s priorities. Your compliance framework may preclude you from using speciﬁc\n\ntechnologies or geographic locations. Apply due diligence if no external compliance frameworks\n\nare identiﬁed. Generate audits or reports that validate compliance.\n\nIf you advertise that your product meets speciﬁc compliance standards, you must have an internal\n\nprocess for ensuring continuous compliance. Examples of compliance standards include PCI DSS,\n\nFedRAMP, and HIPAA. Applicable compliance standards are determined by various factors, such\n\nas what types of data the solution stores or transmits and which geographic regions the solution supports.\n\nDesired outcome:\n\nOPS01-BP04 Evaluate compliance requirements\n\n14\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRegulatory, industry, and internal compliance requirements are incorporated into architectural\n\nselection.\n\nYou can validate compliance and generate audit reports.\n\nCommon anti-patterns:\n\nParts of your workload fall under the Payment Card Industry Data Security Standard (PCI-DSS)\n\nframework but your workload stores credit cards data unencrypted.\n\nYour software developers and architects are unaware of the compliance framework that your\n\norganization must adhere to.\n\nThe yearly Systems and Organizations Control (SOC2) Type II audit is happening soon and you\n\nare unable to verify that controls are in place.\n\nBeneﬁts of establishing this best practice:\n\nEvaluating and understanding the compliance requirements that apply to your workload will\n\ninform how you prioritize your eﬀorts to deliver business value.\n\nYou choose the right locations and technologies that are congruent with your compliance\n\nframework.\n\nDesigning your workload for auditability helps you to prove you are adhering to your compliance\n\nframework.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplementing this best practice means that you incorporate compliance requirements into your architecture design process. Your team members are aware of the required compliance framework.\n\nYou validate compliance in line with the framework.\n\nCustomer example\n\nAnyCompany Retail stores credit card information for customers. Developers on the card storage\n\nteam understand that they need to comply with the PCI-DSS framework. They’ve taken steps\n\nto verify that credit card information is stored and accessed securely in line with the PCI-DSS\n\nframework. Every year they work with their security team to validate compliance.\n\nOPS01-BP04 Evaluate compliance requirements\n\n15\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Work with your security and governance teams to determine what industry, regulatory, or\n\ninternal compliance frameworks that your workload must adhere to. Incorporate the compliance\n\nframeworks into your workload.\n\na. Validate continual compliance of AWS resources with services like AWS Compute Optimizer\n\nand AWS Security Hub CSPM.\n\n2. Educate your team members on the compliance requirements so they can operate and evolve\n\nthe workload in line with them. Compliance requirements should be included in architectural\n\nand technological choices.\n\n3. Depending on the compliance framework, you may be required to generate an audit or\n\ncompliance report. Work with your organization to automate this process as much as possible.\n\na. Use services like AWS Audit Manager to validate compliance and generate audit reports.\n\nb. You can download AWS security and compliance documents with AWS Artifact.\n\nLevel of eﬀort for the implementation plan: Medium. Implementing compliance frameworks can be challenging. Generating audit reports or compliance documents adds additional complexity.\n\nResources\n\nRelated best practices:\n\nSEC01-BP03 Identify and validate control objectives - Security control objectives are an\n\nimportant part of overall compliance.\n\nSEC01-BP06 Automate testing and validation of security controls in pipelines - As part of your\n\npipelines, validate security controls. You can also generate compliance documentation for new\n\nchanges.\n\nSEC07-BP02 Deﬁne data protection controls - Many compliance frameworks have data handling\n\nand storage policies based.\n\nSEC10-BP03 Prepare forensic capabilities - Forensic capabilities can sometimes be used in\n\nauditing compliance.\n\nRelated documents:\n\nAWS Compliance Center\n\nAWS Compliance Resources\n\nOPS01-BP04 Evaluate compliance requirements\n\n16\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Risk and Compliance Whitepaper\n\nAWS Shared Responsibility Model\n\nAWS services in scope by compliance programs\n\nRelated videos:\n\nAWS re:Invent 2020: Achieve compliance as code using AWS Compute Optimizer\n\nAWS re:Invent 2021 - Cloud compliance, assurance, and auditing\n\nAWS Summit ATL 2022 - Implementing compliance, assurance, and auditing on AWS (COP202)\n\nRelated examples:\n\nPCI DSS and AWS Foundational Security Best Practices on AWS\n\nRelated services:\n\nAWS Artifact\n\nAWS Audit Manager\n\nAWS Compute Optimizer\n\nAWS Security Hub CSPM\n\nOPS01-BP05 Evaluate threat landscape\n\nEvaluate threats to the business (for example, competition, business risk and liabilities, operational\n\nrisks, and information security threats) and maintain current information in a risk registry. Include\n\nthe impact of risks when determining where to focus eﬀorts.\n\nThe Well-Architected Framework emphasizes learning, measuring, and improving. It provides a\n\nconsistent approach for you to evaluate architectures, and implement designs that will scale over\n\ntime. AWS provides the AWS Well-Architected Tool to help you review your approach prior to\n\ndevelopment, the state of your workloads prior to production, and the state of your workloads\n\nin production. You can compare them to the latest AWS architectural best practices, monitor the\n\noverall status of your workloads, and gain insight to potential risks.\n\nAWS customers are eligible for a guided Well-Architected Review of their mission-critical workloads\n\nto measure their architectures against AWS best practices. Enterprise Support customers are\n\nOPS01-BP05 Evaluate threat landscape\n\n17\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\neligible for an Operations Review, designed to help them to identify gaps in their approach to\n\noperating in the cloud.\n\nThe cross-team engagement of these reviews helps to establish common understanding of your\n\nworkloads and how team roles contribute to success. The needs identiﬁed through the review can\n\nhelp shape your priorities.\n\nAWS Trusted Advisor is a tool that provides access to a core set of checks that recommend\n\noptimizations that may help shape your priorities. Business and Enterprise Support customers\n\nreceive access to additional checks focusing on security, reliability, performance, and cost-\n\noptimization that can further help shape their priorities.\n\nDesired outcome:\n\nYou regularly review and act on Well-Architected and Trusted Advisor outputs\n\nYou are aware of the latest patch status of your services\n\nYou understand the risk and impact of known threats and act accordingly\n\nYou implement mitigations as necessary\n\nYou communicate actions and context\n\nCommon anti-patterns:\n\nYou are using an old version of a software library in your product. You are unaware of security\n\nupdates to the library for issues that may have unintended impact on your workload.\n\nYour competitor just released a version of their product that addresses many of your customers'\n\ncomplaints about your product. You have not prioritized addressing any of these known issues.\n\nRegulators have been pursuing companies like yours that are not compliant with legal regulatory\n\ncompliance requirements. You have not prioritized addressing any of your outstanding\n\ncompliance requirements.\n\nBeneﬁts of establishing this best practice: You identify and understand the threats to your organization and workload, which helps your determination of which threats to address, their\n\npriority, and the resources necessary to do so.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS01-BP05 Evaluate threat landscape\n\n18\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nEvaluate threat landscape: Evaluate threats to the business (for example, competition, business risk and liabilities, operational risks, and information security threats), so that you can include their impact when determining where to focus eﬀorts.\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nMaintain a threat model: Establish and maintain a threat model identifying potential threats,\n\nplanned and in place mitigations, and their priority. Review the probability of threats manifesting\n\nas incidents, the cost to recover from those incidents and the expected harm caused, and the cost\n\nto prevent those incidents. Revise priorities as the contents of the threat model change.\n\nResources\n\nRelated best practice:\n\nSEC01-BP07 Identify threats and prioritize mitigations using a threat model\n\nRelated documents:\n\nAWS Cloud Compliance\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nRelated videos:\n\nAWS re:Inforce 2023 - A tool to help improve your threat modeling\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nCompeting interests from multiple parties can make it challenging to prioritize eﬀorts, build\n\ncapabilities, and deliver outcomes aligned with business strategies. For example, you may be asked\n\nto accelerate speed-to-market for new features over optimizing IT infrastructure costs. This can\n\nput two interested parties in conﬂict with one another. In these situations, decisions need to be\n\nbrought to a higher authority to resolve conﬂict. Data is required to remove emotional attachment\n\nfrom the decision-making process.\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n19",
      "page_number": 17
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 25-37)",
      "start_page": 25,
      "end_page": 37,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe same challenge may occur at a tactical level. For example, the choice between using relational\n\nor non-relational database technologies can have a signiﬁcant impact on the operation of an application. It's critical to understand the predictable results of various choices.\n\nAWS can help you educate your teams about AWS and its services to increase their understanding\n\nof how their choices can have an impact on your workload. Use the resources provided by Support\n\n(AWS Knowledge Center, AWS Discussion Forums, and Support Center) and AWS Documentation to\n\neducate your teams. For further questions, reach out to Support.\n\nAWS also shares operational best practices and patterns in The Amazon Builders' Library. A wide\n\nvariety of other useful information is available through the AWS Blog and The Oﬃcial AWS\n\nPodcast.\n\nDesired outcome: You have a clearly deﬁned decision-making governance framework to facilitate important decisions at every level within your cloud delivery organization. This framework includes\n\nfeatures like a risk register, deﬁned roles that are authorized to make decisions, and a deﬁned\n\nmodels for each level of decision that can be made. This framework deﬁnes in advance how\n\nconﬂicts are resolved, what data needs to be presented, and how options are prioritized, so that\n\nonce decisions are made you can commit without delay. The decision-making framework includes\n\na standardized approach to reviewing and weighing the beneﬁts and risks of every decision to\n\nunderstand the tradeoﬀs. This may include external factors, such as adherence to regulatory\n\ncompliance requirements.\n\nCommon anti-patterns:\n\nYour investors request that you demonstrate compliance with Payment Card Industry Data\n\nSecurity Standards (PCI DSS). You do not consider the tradeoﬀs between satisfying their\n\nrequest and continuing with your current development eﬀorts. Instead, you proceed with your\n\ndevelopment eﬀorts without demonstrating compliance. Your investors stop their support of\n\nyour company over concerns about the security of your platform and their investments.\n\nYou have decided to include a library that one of your developers found on the internet. You\n\nhave not evaluated the risks of adopting this library from an unknown source and do not know if\n\nit contains vulnerabilities or malicious code.\n\nThe original business justiﬁcation for your migration was based upon the modernization of 60%\n\nof your application workloads. However, due to technical diﬃculties, a decision was made to\n\nmodernize only 20%, leading to a reduction in planned beneﬁts long-term, increased operator\n\ntoil for infrastructure teams to manually support legacy systems, and greater reliance on\n\ndeveloping new skillsets in your infrastructure teams that were not planning for this change.\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n20\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: Fully aligning and supporting board-level business priorities, understanding the risks to achieving success, making informed decisions, and acting appropriately when risks impede chances for success. Understanding the implications and\n\nconsequences of your decisions helps you to prioritize your options and bring leaders into\n\nagreement faster, leading to improved business outcomes. Identifying the available beneﬁts\n\nof your choices and being aware of the risks to your organization helps you make data-driven\n\ndecisions, rather than relying on anecdotes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nManaging beneﬁts and risks should be deﬁned by a governing body that drives the requirements\n\nfor key decision-making. You want decisions to be made and prioritized based on how they\n\nbeneﬁt the organization, with an understanding of the risks involved. Accurate information is\n\ncritical for making the organizational decisions. This should be based on solid measurements and\n\ndeﬁned by common industry practices of cost beneﬁt analysis. To make these types of decisions,\n\nstrike a balance between centralized and decentralized authority. There is always a tradeoﬀ, and\n\nit's important to understand how each choice impacts deﬁned strategies and desired business\n\noutcomes.\n\nImplementation steps\n\n1. Formalize beneﬁts measurement practices within a holistic cloud governance framework.\n\na. Balance central control of decision-making with decentralized authority for some decisions.\n\nb. Understand that burdensome decision-making processes imposed on every decision can slow\n\nyou down.\n\nc. Incorporate external factors into your decision making process (like compliance requirements).\n\n2. Establish an agreed-upon decision-making framework for various levels of decisions, which\n\nincludes who is required to unblock decisions that are subject to conﬂicted interests.\n\na. Centralize one-way door decisions that could be irreversible.\n\nb. Allow two-way door decisions to be made by lower level organizational leaders.\n\n3. Understand and manage beneﬁts and risks. Balance the beneﬁts of decisions against the risks\n\ninvolved.\n\na. Identify beneﬁts: Identify beneﬁts based on business goals, needs, and priorities. Examples include business case impact, time-to-market, security, reliability, performance, and cost.\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n21\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nb. Identify risks: Identify risks based on business goals, needs, and priorities. Examples include\n\ntime-to-market, security, reliability, performance, and cost.\n\nc. Assess beneﬁts against risks and make informed decisions: Determine the impact of\n\nbeneﬁts and risks based on goals, needs, and priorities of your key stakeholders, including\n\nbusiness, development, and operations. Evaluate the value of the beneﬁt against the\n\nprobability of the risk being realized and the cost of its impact. For example, emphasizing\n\nspeed-to-market over reliability might provide competitive advantage. However, it may result\n\nin reduced uptime if there are reliability issues.\n\n4. Programatically enforce key decisions that automate your adherence to compliance\n\nrequirements.\n\n5. Leverage known industry frameworks and capabilities, such as Value Stream Analysis and\n\nLEAN, to baseline current state performance, business metrics, and deﬁne iterations of progress\n\ntowards improvements to these metrics.\n\nLevel of eﬀort for the implementation plan: Medium-High\n\nResources\n\nRelated best practices:\n\nOPS01-BP05 Evaluate threat landscape\n\nRelated documents:\n\nElements of Amazon's Day 1 Culture | Make high quality, high velocity decisions\n\nCloud Governance\n\nManagement & Governance Cloud Environment\n\nGovernance in the Cloud and in the Digital Age: Parts One & Two\n\nRelated videos:\n\nPodcast | Jeﬀ Bezos | On how to make decisions\n\nRelated examples:\n\nMake informed decisions using data (The DevOps Sagas)\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n22\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUsing development value stream mapping to identify constraints to DevOps outcomes\n\nOperating model\n\nIn this section, we provide a way to understand the operating model you work within, how that\n\nmodel can be visualized, and how, at a team level, you should evolve to extract maximum value\n\nfrom your investment in cloud services. By doing so, you can enhance your operational practices,\n\nbuild agile teams and workloads, and positively contribute to business outcomes.\n\nIt is common for your team to exist within multiple organizational layers, and those layers have\n\nexisting ways of working. Participating with your team in achieving business outcomes means\n\nunderstanding where your teams are in those layers, the position of the teams you interact with,\n\nand how they work. Furthermore, teams need to understand their roles in the success of other teams, know the role of other teams in their success, and have shared goals.\n\nThese layers make up the overall operating model of the organization. How the organization\n\nfunctions to deliver business outcomes depends upon many factors, such as type, industry,\n\ngeography, size, and level of autonomy. However, it likely falls into three broad categories:\n\nCentralized\n\nDecentralized\n\nFederated\n\nThese organization-level topologies are described in Organize for success.\n\nYour team and workload exist within your organization's operating model. However, it is\n\nunreasonable to expect a single operating model to be able to support all teams and their\n\nworkloads. Therefore, your team also needs its own operating model. This way of working is\n\nshaped by your organization, your department, the makeup of your team, and the characteristics of\n\nthe workload itself.\n\nMost organizations that move to the cloud do so as part of an enterprise transformation program\n\nthat seeks to unlock new ways of working (the operating model) to support long-term strategic\n\naims. This journey is not a point in time exercise, but a process that requires continual evolution\n\nand incremental progress towards the strategic goal. This allows workloads owners to adapt to the\n\nevolving operating model with minimal disruption.\n\nOperating model\n\n23\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAmazon is often used as an example of how a large organization is able to innovate at scale by\n\nempowering teams to stay close to customers, rapidly launch innovative products and services, and take advantage of technical architectures that support speed and agility. This required us to\n\nrestructure how our teams are organized, now known as two-pizza teams. A two-pizza team has all\n\nthe right resources embedded within it (engineering, testing, product and program management,\n\nand operations) to own and run a workload end-to-end.\n\nWe advise working towards this operating model as a proven way for workload teams to move\n\nquickly and contribute to overall business outcomes in the way that best serves their customers.\n\nOrganizations seeking to emulate this success may need to adapt their operating model\n\nthroughout their transformation journey. At both organization and team level, this requires\n\nconsideration, planning, and communication. The following section provides a way to visualize\n\nthese team-level operating models and how they evolve to you build it, you run it.\n\nOperating model 2 by 2 representations\n\nThese operating model 2 by 2 representations are illustrations to help you understand the\n\nrelationships between teams in your environment. These diagrams focus on who does what and\n\nthe relationships between teams, but we will also discuss governance and decision making in\n\ncontext of these examples.\n\nYour teams may have responsibilities in multiple parts of multiple models depending on the\n\nworkloads they support. You may wish to break out more specialized discipline areas than the high-\n\nlevel ones described. There is the potential for endless variation on these models as you separate\n\nor aggregate activities, or overlay teams and provide more speciﬁc detail.\n\nYou may identify that you have overlapping or unrecognized capabilities across teams that can\n\nprovide additional advantage, or lead to eﬃciencies. You may also identify unsatisﬁed needs in\n\nyour organization that you can plan to address.\n\nWhen evaluating organizational change, examine the trade-oﬀs between models, where your\n\nindividual teams exist within the models (now and after the change), how your teams’ relationship\n\nand responsibilities will change, and if the beneﬁts merit the impact on your organization.\n\nYou can be successful using each of the following four operating models. Some models are more\n\nappropriate for speciﬁc use cases or at speciﬁc points in your development. Some of these models may provide advantages over the ones in use in your environment.\n\nTopics\n\nOperating model 2 by 2 representations\n\n24\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nFully separated operating model\n\nDevOps with cloud-managed service provider\n\nCloud operations and platform enablement (COPE)\n\nDistributed DevOps\n\nDecentralized DevOps\n\nEvolving your operating model\n\nFully separated operating model\n\nIn the following diagram, on the vertical axis we have Applications and Platform. Applications refer\n\nto the workload serving a business outcome and can be custom developed or purchased software.\n\nPlatform refers to the physical and virtual infrastructure and other software that supports that workload.\n\nOn the horizontal axis, we have Engineering and Operations. Engineering refers to the\n\ndevelopment, building, and testing of applications and infrastructure. Operations is the\n\ndeployment, update, and ongoing support of applications and infrastructure.\n\nTraditional model\n\nHistorically, organizations embraced frameworks such as ITIL or standards like ISO and shaped\n\ntheir operational activties around them, which often resulted in a fully-separated topology. In\n\nthis model, activities in each quadrant are performed by a separate team. Work is passed between\n\nteams through mechanisms such as work requests, queues, tickets, or by using an IT service\n\nmanagement (ITSM) system.\n\nOperating model 2 by 2 representations\n\n25\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe transition of tasks to or between teams increases complexity, and creates bottlenecks and\n\ndelays. Requests may be delayed until they are a priority. Defects identiﬁed late may require signiﬁcant rework and may have to pass through the same teams and their functions once again.\n\nIf there are incidents that require action by engineering teams, their responses are delayed by the\n\nhand oﬀ activity.\n\nThere is a higher risk of misalignment when business, development, and operations teams\n\nare organized around the activities or functions that are being performed. This can lead to\n\nteams focusing on their speciﬁc responsibilities instead of focusing on achieving business\n\noutcomes. Teams may be narrowly specialized, physically isolated, or logically isolated, hindering\n\ncommunication and collaboration.\n\nDevOps with cloud-managed service provider\n\nThe DevOps with cloud-managed service provider model follows a you build it, you run it\n\nmethodology for application teams. However, your organization may not have the existing skills or\n\nteam members to support a dedicated platform engineering and operations team, or you may not\n\nbe in a position to make the time and eﬀort investments to do so.\n\nAlternatively, you may wish to have a platform team that is focused on creating capabilities that\n\ndiﬀerentiate your business, but you want to outsource the undiﬀerentiated day-to-day operations.\n\nManaged services providers such as AWS Managed Services or providers in the AWS Partner\n\nNetwork provide expertise implementing cloud environments, and support your security and\n\ncompliance requirements and business goals.\n\nOperating model 2 by 2 representations\n\n26\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDevOps with cloud managed service provider\n\nFor this variation, we treat governance as centralized and managed by the platform team, with\n\naccount creation and policies managed with AWS Organizations and AWS Control Tower.\n\nThis model requires you to modify your mechanisms to work with those of your service provider.\n\nIt does not address the bottlenecks and delays created by transition of tasks between teams,\n\nincluding your service provider, or the potential rework related to the late identiﬁcation of defects.\n\nYou gain the advantage of your providers’ standards, best practices, processes, and expertise. You\n\nalso gain the beneﬁts of their ongoing development of their service oﬀerings.\n\nAdding managed services to your operating model can save you time and resources and keeps your\n\ninternal teams lean and focused on strategic outcomes that diﬀerentiate your business, rather than\n\ndeveloping new skills and capabilities. It can also provide time for you to build and mature your own platform capabilities without slowing down your cloud migration programs.\n\nCloud operations and platform enablement (COPE)\n\nThis cloud operations and platform enablement (COPE) model seeks to establish a you build it, you\n\nrun it methodology by supporting application teams to perform the engineering and operations\n\nactivities for their workloads, adopting a DevOps culture.\n\nYour application teams may be tasked with migrating, adopting the cloud, or modernizing your\n\nworkloads, but might not have the existing skills to adequately support cloud architecture and\n\noperations. This lack of application team capabilities and familiarity is likely to slow down your\n\norganization’s agility and impact business outcomes.\n\nTo address this concern, use your existing operational expertise from within your organization to\n\nsupport application teams on their journey to cloud operations. This can be a dedicated team of\n\nexperts or a virtual team with participants selected from across your organization. However, the\n\ngoal remains the same, which is to provide operational support that builds the capability of the\n\nworkload team, using cloud ﬁrst principles of automation, removing undiﬀerentiated heavy lifting,\n\nproviding standardized patterns, and promoting autonomy. The aim is to build suﬃcient maturity\n\nacross cloud capabilities and lower the barrier of operational responsibilities so that application\n\nteams no longer need additional support.\n\nThe COPE model focuses on the workload level. If this approach is needed across multiple teams\n\nat once, if you are performing a complex, large-scale, multi-year migration project, or if you are\n\nbuilding a platform to support these initiatives, consider using a Cloud Center of Excellence (CCoE).\n\nOperating model 2 by 2 representations\n\n27\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThis is a mechanism that many have found successful when seeking to accelerate their migrations\n\nto the cloud and broadly transform their organization.\n\nCloud Operations and Platform Enablement (COPE)\n\nYour platform engineering team builds a thin layer of core shared platform capabilities, which are\n\nbased on predeﬁned standards for application teams to adopt and are provided by the COPE team.\n\nThe platform engineering team codiﬁes the enterprise reference architectures and patterns that\n\nare provided to the application teams through a self-service mechanism. Using a service such as\n\nAWS Service Catalog, the application teams can deploy approved reference architectures, patterns,\n\nservices, and conﬁgurations, compliant by default with the centralized governance and security\n\nstandards.\n\nThe platform engineering team also provides a standardized set of services (for example,\n\ndevelopment tools, observability tools, backup and recovery tools, and networking) to the\n\napplication teams.\n\nThe COPE team manages and supports the standardized services and provides assistance to\n\napplication teams establishing their cloud presence based on the reference architectures and\n\npatterns. They work with the application teams to help them establish baseline operations. During\n\nthis process, the application teams progressively take more responsibility for their systems and\n\nresources over time. The COPE team drives continual improvement together with the platform\n\nengineering team and acts as proponents for the application teams.\n\nThe application teams get assistance setting up environments, CI/CD pipelines, change\n\nmanagement, observability and monitoring, and establishing incident and event management\n\nOperating model 2 by 2 representations\n\n28\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nprocesses, with the COPE team integrated as required. The COPE team participates with the\n\napplication teams in the performance of these operations activities, phasing out the COPE team engagement over time as the application teams take ownership.\n\nThe application team gains the beneﬁt of the skills of the COPE team and the lessons learned by\n\nthe organization. They are protected by the guardrails established through centralized governance.\n\nThe application team builds upon recognized successes and gains the beneﬁt of continuing\n\ndevelopment of the organizational standards they have adopted. They gain greater insight to the\n\noperation of their workload through the process of establishing observability and monitoring and\n\nare better able to understand the impact of changes they make to their workloads.\n\nThe COPE team may also retain the access necessary to support operations activities, provide an\n\nenterprise-operations view spanning application teams, and oﬀer critical incident management\n\nsupport. The COPE team retains responsibility for activities considered as undiﬀerentiated heavy\n\nlifting, which they satisfy through standard solutions supportable at scale. They also continue to\n\nmanage well-understood programmatic and automated operations activities for the application\n\nteams so that they can focus on diﬀerentiating their applications.\n\nYou gain the advantage of your organization’s standards, best practices, processes, and expertise,\n\nderived from the successes of your teams. You establish a mechanism to replicate these successful\n\npatterns for new teams adopting or modernizing in the cloud. This model places emphasis on\n\nthe COPE team’s ability to help application teams get established and transition knowledge\n\nand artifacts. It reduces the operational burdens of the application teams, with the risk that\n\napplication teams can fail to become independent. It establishes relationships between platform\n\nengineering, COPE, and application teams, creating a feedback loop to support further evolution\n\nand innovation.\n\nEstablishing your platform engineering and COPE teams, while deﬁning organization wide\n\nstandards, can facilitate cloud adoption and support modernization eﬀorts. By providing the\n\nadditional support of a COPE team acting as consultants and partners to your application teams,\n\nyou can remove workload level barriers that slow application team adoption of beneﬁcial cloud\n\ncapabilities.\n\nDistributed DevOps\n\nThe distributed DevOps model separates (or distributes) the application engineering operations\n\nand infrastructure engineering operations responsibilities across the engineering teams, following\n\nthe COPE methodology.\n\nOperating model 2 by 2 representations\n\n29\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYour application engineers perform both the engineering and the operation of their workloads.\n\nSimilarly, your infrastructure engineers perform both the engineering and operation of the platforms they use to support application teams.\n\nDistributed DevOps\n\nFor this example, we treat governance as centralized elsewhere within the organization. Standards\n\nare distributed, provided, or shared to the application and platform teams.\n\nUse tools or services that help you centrally govern your environments across accounts, such\n\nas AWS Organizations. Services like AWS Control Tower expand this management capability by\n\nhelping you deﬁne blueprints (supporting your operating models) for the setup of accounts, apply\n\nongoing governance using AWS Organizations, and automate provisioning of new accounts.\n\nYou build it, you run it does not mean that the application team is responsible for the full stack, tool\n\nchain, and platform.\n\nThe platform engineering team provides a standardized set of services (for example, development\n\ntools, monitoring tools, backup and recovery tools, and networking) to the application team. The\n\nplatform team may also provide the application team access to approved cloud provider services,\n\nspeciﬁc conﬁgurations of the same, or both.\n\nMechanisms that provide a self-service capability for deploying approved services and conﬁgurations, such as Service Catalog, can help limit delays associated with fulﬁllment requests\n\nwhile enforcing governance.\n\nOperating model 2 by 2 representations\n\n30\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe platform team activates full stack visibility so that application teams can diﬀerentiate between\n\nissues with their application components and the services and infrastructure components their applications consume. The platform team may also provide assistance conﬁguring these services\n\nand guidance on how to improve an application team's operations.\n\nAs discussed previously, it is critical that mechanisms exist for application teams to request\n\nadditions, changes, and exceptions to standards in support of activities and innovation of their\n\napplication.\n\nThe distributed DevOps model provides strong feedback loops to application teams. Day-to-day\n\noperations of a workload increase contact with customers, either through direct interaction or\n\nindirectly through support and feature requests. This heightened visibility allows application teams\n\nto address issues more quickly. The deeper engagement and closer relationship provides insight to\n\ncustomer needs and creates more rapid innovation.\n\nAll of this is also true for the platform team supporting the application teams, as the platform\n\nteam should view these application teams as their customers.\n\nAdopted standards may be pre-approved for use, reducing the amount of review necessary to\n\nenter production. Consuming supported and tested standards provided by the platform team may\n\nreduce the frequency of issues with those services. Adoption of standards helps application teams\n\nfocus on diﬀerentiating their workloads.\n\nDecentralized DevOps\n\nThe decentralized DevOps model is a variation of the you build it, you run it methodology where\n\noperations are primarily under the ownership of workload teams.\n\nYour application engineers perform both the engineering and the operations of their workloads.\n\nSimilarly, your infrastructure engineers perform both the engineering and operations of the\n\nplatforms they use to support application teams.\n\nOperating model 2 by 2 representations\n\n31\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDecentralized DevOps\n\nFor this example, we treat governance as decentralized. Standards are still distributed, provided, or\n\nshared to application teams by the platform team, but application teams are free to engineer and\n\noperate new platform capabilities in support of their workload.\n\nIn this model, there are fewer constraints on the application team, but that comes with a\n\nsigniﬁcant increase in responsibilities. Additional skills (and potentially team members) must be\n\npresent to support the additional platform capabilities. The risk of signiﬁcant rework is increased if\n\nskill sets are inadequate and defects are not recognized early.\n\nEnforce policies that are not speciﬁcally delegated to application teams. Use tools or services\n\nthat help you to centrally govern your environments across accounts, such as AWS Organizations.\n\nServices like AWS Control Tower expand this management capability by helping you deﬁne\n\nblueprints (supporting your operating models) for the setup of accounts, apply ongoing\n\ngovernance using AWS Organizations, and automate provisioning of new accounts.\n\nIt’s beneﬁcial to have mechanisms for the application team to request additions and changes to\n\nstandards. They can contribute new standards that can provide beneﬁt to other application teams.\n\nThe platform teams may decide that providing direct support for these additional capabilities is an\n\neﬀective support for business outcomes.\n\nThis model limits constraints on innovation with signiﬁcant skill and team member requirements. It\n\naddresses many of the bottlenecks and delays created by transition of tasks between teams, while\n\nstill promoting the development of eﬀective relationships between teams and customers.\n\nOperating model 2 by 2 representations\n\n32",
      "page_number": 25
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 38-46)",
      "start_page": 38,
      "end_page": 46,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEvolving your operating model\n\nThe models provided progressively move towards more autonomy at the workload level, matching\n\nthe two-pizza team principle. It is important to understand that this journey from a traditional\n\napproach to decentralized DevOps (as a foundation for continued evolution to a two-pizza\n\nteam model) is likely to take time and require building maturity across a number of capabilities.\n\nTherefore, we have provided an example of how you may transition between models as your team and organization move along the enterprise transformation journey. In each change or model, you\n\nare evolving towards a more autonomous, but still organizationally-aligned team.\n\nCloud operating model evolution\n\nWhen evaluating how your team can support your organizations evolution, examine the trade-\n\noﬀs between models, where your individual teams exist within the models (as they transition and\n\nevolve), how your team's relationship and responsibilities could change, and if the beneﬁts merit\n\nthe impact on your organization. Keep in mind that change is never linear. Some models are more appropriate for speciﬁc use cases or points in the journey, and some of these models may provide\n\nadvantages over the ones in your environment.\n\nRelationships and ownership\n\nYour operating model deﬁnes the relationships between teams and supports identiﬁable ownership and responsibility.\n\nBest practices\n\nRelationships and ownership\n\n33\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS02-BP01 Resources have identiﬁed owners\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their performance\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nOPS02-BP05 Mechanisms exist to request additions, changes, and exceptions\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nOPS02-BP01 Resources have identiﬁed owners\n\nResources for your workload must have identiﬁed owners for change control, troubleshooting,\n\nand other functions. Owners are assigned for workloads, accounts, infrastructure, platforms, and\n\napplications. Ownership is recorded using tools like a central register or metadata attached to\n\nresources. The business value of components informs the processes and procedures applied to\n\nthem.\n\nDesired outcome:\n\nResources have identiﬁed owners using metadata or a central register.\n\nTeam members can identify who owns resources.\n\nAccounts have a single owner where possible.\n\nCommon anti-patterns:\n\nThe alternate contacts for your AWS accounts are not populated.\n\nResources lack tags that identify what teams own them.\n\nYou have an ITSM queue without an email mapping.\n\nTwo teams have overlapping ownership of a critical piece of infrastructure.\n\nBeneﬁts of establishing this best practice:\n\nChange control for resources is straightforward with assigned ownership.\n\nYou can involve the right owners when troubleshooting issues.\n\nLevel of risk exposed if this best practice is not established: High\n\nRelationships and ownership\n\n34\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nDeﬁne what ownership means for the resource use cases in your environment. Ownership can\n\nmean who oversees changes to the resource, supports the resource during troubleshooting, or\n\nwho is ﬁnancially accountable. Specify and record owners for resources, including name, contact\n\ninformation, organization, and team.\n\nCustomer example\n\nAnyCompany Retail deﬁnes ownership as the team or individual that owns changes and support\n\nfor resources. They leverage AWS Organizations to manage their AWS accounts. Alternate account\n\ncontacts are conﬁguring using group inboxes. Each ITSM queue maps to an email alias. Tags\n\nidentify who own AWS resources. For other platforms and infrastructure, they have a wiki page that\n\nidentiﬁes ownership and contact information.\n\nImplementation steps\n\n1. Start by deﬁning ownership for your organization. Ownership can imply who owns the risk\n\nfor the resource, who owns changes to the resource, or who supports the resource when\n\ntroubleshooting. Ownership could also imply ﬁnancial or administrative ownership of the\n\nresource.\n\n2. Use AWS Organizations to manage accounts. You can manage the alternate contacts for your\n\naccounts centrally.\n\na. Using company owned email addresses and phone numbers for contact information helps\n\nyou to access them even if the individuals whom they belong to are no longer with your\n\norganization. For example, create separate email distribution lists for billing, operations,\n\nand security and conﬁgure these as Billing, Security, and Operations contacts in each active\n\nAWS account. Multiple people will receive AWS notiﬁcations and be able to respond, even if\n\nsomeone is on vacation, changes roles, or leaves the company.\n\nb. If an account is not managed by AWS Organizations, alternate account contacts help AWS\n\nget in contact with the appropriate personnel if needed. Conﬁgure the account's alternate\n\ncontacts to point to a group rather than an individual.\n\n3. Use tags to identify owners for AWS resources. You can specify both owners and their contact\n\ninformation in separate tags.\n\na. You can use AWS Conﬁg rules to enforce that resources have the required ownership tags.\n\nb. For in-depth guidance on how to build a tagging strategy for your organization, see AWS\n\nTagging Best Practices whitepaper.\n\nRelationships and ownership\n\n35\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Use Amazon Q Business, a conversational assistant that uses generative AI to enhance workforce\n\nproductivity, answer questions, and complete tasks based on information in your enterprise systems.\n\na. Connect Amazon Q Business to your company's data source. Amazon Q Business oﬀers\n\nprebuilt connectors to over 40 supported data sources, including Amazon Simple Storage\n\nService (Amazon S3), Microsoft SharePoint, Salesforce, and Atlassian Conﬂuence. For more\n\ninformation, see Amazon Q Business connectors.\n\n5. For other resources, platforms, and infrastructure, create documentation that identiﬁes\n\nownership. This should be accessible to all team members.\n\nLevel of eﬀort for the implementation plan: Low. Leverage account contact information and tags to assign ownership of AWS resources. For other resources you can use something as simple as a\n\ntable in a wiki to record ownership and contact information, or use an ITSM tool to map ownership.\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nRelated documents:\n\nAWS Account Management - Updating contact information\n\nAWS Organizations - Updating alternative contacts in your organization\n\nAWS Tagging Best Practices whitepaper\n\nBuild private and secure enterprise generative AI apps with Amazon Q Business and AWS IAM\n\nIdentity Center\n\nAmazon Q Business, now generally available, helps boost workforce productivity with generative\n\nAI\n\nAWS Cloud Operations & Migrations Blog - Implementing automated and centralized tagging\n\ncontrols with AWS Conﬁg and AWS Organizations\n\nAWS Security Blog - Extend your pre-commit hooks with AWS CloudFormation Guard\n\nAWS DevOps Blog - Integrating AWS CloudFormation Guard into CI/CD pipelines\n\nRelationships and ownership\n\n36\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated workshops:\n\nAWS Workshop - Tagging\n\nRelated examples:\n\nAWS Conﬁg Rules - Amazon EC2 with required tags and valid values\n\nRelated services:\n\nAWS Conﬁg Rules - required-tags\n\nAWS Organizations\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nUnderstand who has ownership of the deﬁnition of individual processes and procedures, why\n\nthose speciﬁc process and procedures are used, and why that ownership exists. Understanding\n\nthe reasons that speciﬁc processes and procedures are used aids in identiﬁcation of improvement\n\nopportunities.\n\nDesired outcome: Your organization has a well deﬁned and maintained set of process and procedures for operational tasks. The process and procedures are stored in a central location\n\nand available to your team members. Process and procedures are updated frequently, by\n\nclearly assigned ownership. Where possible, scripts, templates, and automation documents are\n\nimplemented as code.\n\nCommon anti-patterns:\n\nProcesses are not documented. Fragmented scripts may exist on isolated operator workstations.\n\nKnowledge of how to use scripts is held by a few individuals or informally as team knowledge.\n\nA legacy process is due for an update, but ownership of the update is unclear, and the original\n\nauthor is no longer part of the organization.\n\nProcesses and scripts are not discoverable, so they are not readily available when required (for\n\nexample, in response to an incident).\n\nBeneﬁts of establishing this best practice:\n\nRelationships and ownership\n\n37\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nProcesses and procedures boost your eﬀorts to operate your workloads.\n\nNew team members become eﬀective more quickly.\n\nReduced time to mitigate incidents.\n\nDiﬀerent team members (and teams) can use the same processes and procedures in a consistent\n\nmanner.\n\nTeams can scale their processes with repeatable processes.\n\nStandardized processes and procedures help mitigate the impact of transferring workload\n\nresponsibilities between teams.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nProcesses and procedures have identiﬁed owners who are responsible for their deﬁnition.\n\nIdentify the operations activities conducted in support of your workloads. Document these\n\nactivities in a discoverable location.\n\nUniquely identify the individual or team responsible for the speciﬁcation of an activity. They\n\nare responsible to verify that it can be successfully performed by an adequately skilled team\n\nmember with the correct permissions, access, and tools. If there are issues with performing\n\nthat activity, the team members performing it are responsible for providing the detailed\n\nfeedback necessary for the activity to be improved.\n\nCapture ownership in the metadata of the activity artifact through services like AWS Systems\n\nManager, through documents, and AWS Lambda. Capture resource ownership using tags or\n\nresource groups, specifying ownership and contact information. Use AWS Organizations to\n\ncreate tagging polices and capture ownership and contact information.\n\nOver time, these procedures should be evolved to be runnable as code, reducing the need for\n\nhuman intervention.\n\nFor example, consider AWS Lambda functions, CloudFormation templates, or AWS Systems\n\nManager automation docs.\n\nPerform version control in appropriate repositories.\n\nInclude suitable resource tagging so owners and documentation can readily be identiﬁed.\n\nCustomer example\n\nRelationships and ownership\n\n38\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail deﬁnes ownership as the team or individual that owns processes for an\n\napplication or groups of applications (that share common architetural practices and technologies). Initially, the process and procedures are documented as step-by-step guides in the document\n\nmanagement system, discoverable using tags on the AWS account that hosts the application and\n\non speciﬁc groups of resources within the account. They leverage AWS Organizations to manage\n\ntheir AWS accounts. Over time, these processes are converted to code, and resources are deﬁned\n\nusing infrastructure as code (such as CloudFormation or AWS Cloud Development Kit (AWS CDK)\n\ntemplates). The operational processes become automation documents in AWS Systems Manager\n\nor AWS Lambda functions, which can be initiated as scheduled tasks, in response to events such\n\nas AWS CloudWatch alarms or AWS EventBridge events, or started by requests within an IT service\n\nmanagement (ITSM) platform. All process have tags to identify ownership. Documentation for the\n\nautomation and process is maintained within the wiki pages generated by the code repository for\n\nthe process.\n\nImplementation steps\n\n1. Document the existing processes and procedures.\n\na. Review and keep them up-to-date.\n\nb. Identify an owner for each process or procedure.\n\nc. Place them under version control.\n\nd. Where possible, share processes and procedures across workloads and environments that\n\nshare architectural designs.\n\n2. Establish mechanisms for feedback and improvement.\n\na. Deﬁne policies for how frequently processes should be reviewed.\n\nb. Deﬁne processes for reviewers and approvers.\n\nc. Implement issues or a ticketing queue for feedback to be provided and tracked.\n\nd. Whereever possible, processes and procedures should have pre-approval and risk classiﬁcation\n\nfrom a change approval board (CAB).\n\n3. Verify that processes and procedures are accessible and discoverable by those who need to run\n\nthem.\n\na. Use tags to indicate where the process and procedures can be accessed for the workload.\n\nb. Use meaningful error and event messaging to indicate the appropriate processes or\n\nprocedures to address an issue.\n\nc. Use wikis and document management, and make processes and procedures searchable\n\nconsistently accross the organization.\n\nRelationships and ownership\n\n39\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Use Amazon Q Business, a conversational assistant that uses generative AI to enhance workforce\n\nproductivity, answer questions, and complete tasks based on information in your enterprise systems.\n\na. Connect Amazon Q Business to your company's data source. Amazon Q Business oﬀers\n\nprebuilt connectors to over 40 supported data sources, including Amazon S3, Microsoft\n\nSharePoint, Salesforce, and Atlassian Conﬂuence. For more information, see Amazon Q\n\nconnectors.\n\n5. Automate when appropriate.\n\na. Automations should be developed when services and technologies provide an API.\n\nb. Educate adequately on processes. Develop the user stories and requirements to automate\n\nthose processes.\n\nc. Measure the use of your processes and procedures successfully, and create issues or tickets to\n\nsupport iterative improvement.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS02-BP01 Resources have identiﬁed owners\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAWS Whitepaper - Introduction to DevOps on AWS\n\nAWS Whitepaper - Best Practices for Tagging AWS Resources\n\nAWS Whitepaper - Organizing Your AWS Environment Using Multiple Accounts\n\nAWS Cloud Operations and Migrations Blog - Using Amazon Q Business to streamline your\n\noperations\n\nAWS Cloud Operations & Migrations Blog - Build a Cloud Automation Practice for Operational\n\nExcellence: Best Practices from AWS Managed Services\n\nAWS Cloud Operations & Migrations Blog - Implementing automated and centralized tagging\n\ncontrols with AWS Conﬁg and AWS Organizations\n\nRelationships and ownership\n\n40\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Security Blog - Extend your pre-commit hooks with AWS CloudFormation Guard\n\nAWS DevOps Blog - Integrating AWS CloudFormation Guard into CI/CD pipelines\n\nRelated workshops:\n\nAWS Well-Architected Operational Excellence Workshop\n\nAWS Workshop - Tagging\n\nRelated videos:\n\nHow to automate IT Operations on AWS\n\nAWS re:Invent 2020 - Automate anything with AWS Systems Manager\n\nAWS re:Inforce 2022 - Automating patch management and compliance using AWS (NIS306)\n\nSupports You - Diving Deep into AWS Systems Manager\n\nRelated services:\n\nAWS Systems Manager - Automation\n\nAWS Service Management Connector\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their\n\nperformance\n\nUnderstand who has responsibility to perform speciﬁc activities on deﬁned workloads and why\n\nthat responsibility exists. Understanding who has responsibility to perform activities informs who\n\nwill conduct the activity, validate the result, and provide feedback to the owner of the activity.\n\nDesired outcome:\n\nYour organization clearly deﬁnes responsibilities to perform speciﬁc activities on deﬁned\n\nworkloads and respond to events generated by the workload. The organization documents\n\nownership of processes and fulﬁllment and makes this information discoverable. You review and\n\nupdate responsibilities when organizational changes take place, and teams track and measure\n\nthe performance of defect and ineﬃciency identiﬁcation activities. You implement feedback\n\nmechanisms to track defects and improvements and support iterative improvement.\n\nRelationships and ownership\n\n41",
      "page_number": 38
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 47-57)",
      "start_page": 47,
      "end_page": 57,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nYou do not document responsibilities.\n\nFragmented scripts exist on isolated operator workstations. Only a few individuals know how to\n\nuse them or informally refer to them as team knowledge.\n\nA legacy process is due for update, but no one knows who owns the process, and the original\n\nauthor is no longer part of the organization.\n\nProcesses and scripts can't be discovered, and they are not readily available when required (for\n\nexample, in response to an incident).\n\nBeneﬁts of establishing this best practice:\n\nYou understand who is responsible to perform an activity, who to notify when action is needed,\n\nand who performs the action, validates the result, and provides feedback to the owner of the\n\nactivity.\n\nProcesses and procedures boost your eﬀorts to operate your workloads.\n\nNew team members become eﬀective more quickly.\n\nYou reduce the time it takes to mitigate incidents.\n\nDiﬀerent teams use the same processes and procedures to perform tasks in a consistent manner.\n\nTeams can scale their processes with repeatable processes.\n\nStandardized processes and procedures help mitigate the impact of transferring workload\n\nresponsibilties between teams.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo begin to deﬁne responsibilities, start with existing documentation, like responsibility matrices,\n\nprocesses and procedures, roles and responsibilities, and tools and automation. Review and host\n\ndiscussions on the responsibilities for documented processes. Review with teams to identify\n\nmisalignments between document responsibilities and processes. Discuss services oﬀered with\n\ninternal customers of that team to identify expectations gaps between teams.\n\nAnalyze and address the discrepancies. Identify opportunities to improvement, and look for\n\nfrequently requested, resource-intensive activities, which are typically strong candidates for\n\nRelationships and ownership\n\n42\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nimprovement. Explore best practices, patterns, and prescriptive guidance to simplify and\n\nstandardize improvements. Record improvement opportunities, and track the improvements to completion.\n\nOver time, these procedures should be evolved to be run as code, reducing the need for human\n\nintervention. For example, procedures can be initiated as AWS Lambda functions, CloudFormation\n\ntemplates, or AWS Systems Manager Automation documents. Verify that these procedures are\n\nversion-controlled in appropriate repositories, and include suitable resource tagging so that teams\n\ncan readily identify owners and documentation. Document the responsibility for carrying out the\n\nactivities, and then monitor the automations for successful initiation and operation, as well as\n\nperformance of the desired outcomes.\n\nCustomer example\n\nAnyCompany Retail deﬁnes ownership as the team or individual that owns processes for an application or groups of applications that share common architectural practices and technologies.\n\nInitially, the company documents the processes and procedures as step-by-step guides in the\n\ndocument management system. They make the procedures discoverable using tags on the AWS\n\naccount that hosts the application and on speciﬁc groups of resources within the account, using\n\nAWS Organizations to manage their AWS accounts. Over time, AnyCompany Retail converts\n\nthese processes to code and deﬁnes resources using infrastructure as code (through services like\n\nCloudFormation or AWS Cloud Development Kit (AWS CDK) templates). The operational processes\n\nbecome Automation documents in AWS Systems Manager or AWS Lambda functions, which can be\n\ninitiated as scheduled tasks in response to events such as Amazon CloudWatch alarms or Amazon\n\nEventBridge events or by requests within an IT service management (ITSM) platform. All processes\n\nhave tags to identify who owns them. Teams manage documentation for the automation and\n\nprocess within the wiki pages generated by the code repository for the process.\n\nImplementation steps\n\n1. Document the existing processes and procedures.\n\na. Review and verify that they are up-to-date.\n\nb. Verify that each process or procedure has an owner.\n\nc. Place the procedures under version control.\n\nd. Where possible, share processes and procedures across workloads and environments that\n\nshare architectural designs.\n\n2. Establish mechanisms for feedback and improvement.\n\nRelationships and ownership\n\n43\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\na. Deﬁne policies for how frequently processes should be reviewed.\n\nb. Deﬁne processes for reviewers and approvers.\n\nc. Implement issues or a ticketing queue to provide and track feedback.\n\nd. Wherever possible, provide pre-approval and risk classiﬁcation for processes and procedures\n\nfrom a change approval board (CAB).\n\n3. Make process and procedures accessible and discoverable by users who need to run them.\n\na. Use tags to indicate where the process and procedures can be accessed for the workload.\n\nb. Use meaningful error and event messaging to indicate the appropriate process or proceedure\n\nto address the issue.\n\nc. Use wikis or document management to make processes and procedures consistently\n\nsearchable across the organization.\n\n4. Automate when it is appropriate to do so.\n\na. Where services and technologies provide an API, develop automations.\n\nb. Verify that processes are well-understood, and develop the user stories and requirements to\n\nautomate those processes.\n\nc. Measure the successful use of processes and procedures, with issue tracking to support\n\niterative improvement.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS02-BP01 Resources have identiﬁed owners\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nOPS02-BP05 Mechanisms exist to identify responsibility and ownership\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAWS Whitepaper | Introduction to DevOps on AWS\n\nAWS Whitepaper | Best Practices for Tagging AWS Resources\n\nRelationships and ownership\n\n44\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Whitepaper | Organizing Your AWS Environment Using Multiple Accounts\n\nAWS Cloud Operations & Migrations Blog | Build a Cloud Automation Practice for Operational\n\nExcellence: Best Practices from AWS Managed Services\n\nAWS Workshop - Tagging\n\nAWS Service Management Connector\n\nRelated videos:\n\nAWS Knowledge Center Live | Tagging AWS Resources\n\nAWS re:Invent 2020 | Automate anything with AWS Systems Manager\n\nAWS re:Inforce 2022 | Automating patch management and compliance using AWS (NIS306)\n\nSupports You | Diving Deep into AWS Systems Manager\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nUnderstand the responsibilities of your role and how you contribute to business outcomes, as\n\nthis understanding informs the prioritization of your tasks and why your role is important. This\n\nhelps team members recognize needs and respond appropriately. When team members know their\n\nrole, they can establish ownership, identify improvement opportunities, and understand how to\n\ninﬂuence or make appropriate changes.\n\nOccasionally, a responsibility might not have a clear owner. In these situations, design a mechanism\n\nto resolve this gap. Create a well-deﬁned escalation path to someone with the authority to assign\n\nownership or plan to address the need.\n\nDesired outcome: Teams within your organization have clearly-deﬁned responsibilities that include how they are related to resources, actions to be performed, processes, and procedures. These\n\nresponsibilities align to the team's responsibilities and goals, as well as the responsibilities of other\n\nteams. You document the routes of escalation in a consistent and discoverable manner and feed\n\nthese decisions into documentation artifacts, such as responsibility matrices, team deﬁnitions, or\n\nwiki pages.\n\nCommon anti-patterns:\n\nThe responsibilities of the team are ambiguous or poorly-deﬁned.\n\nThe team does not align roles with responsibilities.\n\nRelationships and ownership\n\n45\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe team does not align its goals and objectives its responsibilities, which makes it diﬃcult to\n\nmeasure success.\n\nTeam member responsibilities do not align with the team and the wider organization.\n\nYour team does not keep responsibilities up-to-date, which makes them inconsistent with the\n\ntasks performed by the team.\n\nEscalation paths for determining responsibilities aren't deﬁned or are unclear.\n\nEscalation paths have no single thread owner to ensure timely reponse.\n\nRoles, responsibilities, and escalation paths are not discoverable, and they are not readily\n\navailable when required (for example, in response to an incident).\n\nBeneﬁts of establishing this best practice:\n\nWhen you understand who has responsibility or ownership, you can contact the proper team or\n\nteam member to make a request or transition a task.\n\nTo reduce the risk of inaction and unaddressed needs, you have identiﬁed a person who has the\n\nauthority to assign responsibility or ownership.\n\nWhen you clearly deﬁne the scope of a responsibility, your team members gain autonomy and\n\nownership.\n\nYour responsibilities inform the decisions you make, the actions you take, and your handoﬀ\n\nactivities to their proper owners.\n\nIt's easy to identify abandoned responsibilities because you have a clear understanding of what\n\nfalls outside of your team's responsibility, which helps you escalate for clariﬁcation.\n\nTeams avoid confusion and tension, and they can more adequately manage their workloads and\n\nresources.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nIdentify team members roles and responsibilities, and verify that they understand the expectations\n\nof their role. Make this information discoverable so that members of your organization can identify\n\nwho they need to contact for speciﬁc needs, whether it's a team or individual. As organizations\n\nseek to capitalize on the opportunities to migrate and modernize on AWS, roles and responsibilities\n\nmight also change. Keep your teams and their members aware of their responsibilities, and train\n\nthem appropriately to carry out their tasks during this change.\n\nRelationships and ownership\n\n46\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDetermine the role or team that should receive escalations to identify responsibility and ownership.\n\nThis team can engage with various stakeholders to come to a decision. However, they should own the management of the decision making process.\n\nProvide accessible mechanisms for members of your organization to discover and identify\n\nownership and responsibility. These mechanisms teach them who to contact for speciﬁc needs.\n\nCustomer example\n\nAnyCompany Retail recently completed a migration of workloads from an on-premises\n\nenvironment to their landing zone in AWS with a lift and shift approach. They performed an\n\noperations review to reﬂect on how they accomplish common operational tasks and veriﬁed that\n\ntheir existing responsibility matrix reﬂects operations in the new environment. When they migrated\n\nfrom on-premises to AWS, they reduced the infrastructure teams responsibilities relating to the\n\nhardware and physical infrastructure. This move also revealed new opportunities to evolve the\n\noperating model for their workloads.\n\nWhile they identiﬁed, addressed, and documented the majority of responsibilities, they also\n\ndeﬁned escalation routes for any responsibilities that were missed or that may need to change as\n\noperations practices evolve. To explore new opportunities to standardize and improve eﬃciency\n\nacross your workloads, provide access to operations tools like AWS Systems Manager and security\n\ntools like AWS Security Hub CSPM and Amazon GuardDuty. AnyCompany Retail puts together a\n\nreview of responsibilities and strategy based on improvements they wants to address ﬁrst. As the\n\ncompany adopts new ways of working and technology patterns, they update their responsibility\n\nmatrix to match.\n\nImplementation steps\n\n1. Start with existing documentation. Some typical source documents might include:\n\na. Responsibility or responsible, accountable, consulted, and informed (RACI) matrices\n\nb. Team deﬁnitions or wiki pages\n\nc. Service deﬁnitions and oﬀerings\n\nd. Role or job descriptions\n\n2. Review and host discussions on the documented responsibilities:\n\na. Review with teams to identify misalignments between documented responsibilities and\n\nresponsibilities the team typically performs.\n\nb. Discuss potential services oﬀered by internal customers to identify gaps in expectations\n\nbetween teams.\n\nRelationships and ownership\n\n47\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n3. Analysis and address the discrepancies.\n\n4. Identify opportunities for improvement.\n\na. Identify frequently-requested, resource-intensive requests, which are typically strong\n\ncandidates for improvement.\n\nb. Look for best practices, understand patterns, follow prescriptive guidance, and simplify and\n\nstandardize improvements.\n\nc. Record improvement opportunities, and track them to completion.\n\n5. If a team doesn't already hold responsibility for managing and tracking the assignment of\n\nresponsibilities, identify someone on the team to hold this responsibility.\n\n6. Deﬁne a process for teams to request clariﬁcation of responsibility.\n\na. Review the process, and verify that it is clear and simple to use.\n\nb. Make sure that someone owns and tracks escalations to their conclusion.\n\nc. Establish operational metrics to measure eﬀectiveness.\n\nd. Create a feedback mechanisms to verify that teams can highlight improvement opportunities.\n\ne. Implement a mechanism for periodic review.\n\n7. Document in a discoverable and accessible location.\n\na. Wikis or documentation portal are common choices.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS01-BP06 Evaluate tradeoﬀs\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\nOPS03-BP03 Escalation is encouraged\n\nOPS03-BP07 Resource teams appropriately\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS11-BP01 Have a process for continuous improvement\n\nRelated documents:\n\nRelationships and ownership\n\n48\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Whitepaper - Introduction to DevOps on AWS\n\nAWS Whitepaper - AWS Cloud Adoption Framework: Operations Perspective\n\nAWS Well-Architected Framework Operational Excellence - Workload level Operating model\n\ntopologies\n\nAWS Prescriptive Guidance - Building your Cloud Operating Model\n\nAWS Prescriptive Guidance - Create a RACI or RASCI matrix for a cloud operating model\n\nAWS Cloud Operations & Migrations Blog - Delivering Business Value with Cloud Platform Teams\n\nAWS Cloud Operations & Migrations Blog - Why a Cloud Operating Model?\n\nAWS DevOps Blog - How organizations are modernizing for cloud operations\n\nRelated videos:\n\nAWS Summit Online - Cloud Operating Models for Accelerated Transformation\n\nAWS re:Invent 2023 - Future-prooﬁng cloud security: A new operating model\n\nOPS02-BP05 Mechanisms exist to request additions, changes, and exceptions\n\nYou can make requests to owners of processes, procedures, and resources. Requests include\n\nadditions, changes, and exceptions. These requests go through a change management process.\n\nMake informed decisions to approve requests where viable and determined to be appropriate after\n\nan evaluation of beneﬁts and risks.\n\nDesired outcome:\n\nYou can make requests to change processes, procedures, and resources based on assigned\n\nownership.\n\nChanges are made in a deliberate manner, weighing beneﬁts and risks.\n\nCommon anti-patterns:\n\nYou must update the way you deploy your application, but there is no way to request a change to\n\nthe deployment process from the operations team.\n\nThe disaster recovery plan must be updated, but there is no identiﬁed owner to request changes\n\nto.\n\nRelationships and ownership\n\n49\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nProcesses, procedures, and resources can evolve as requirements change.\n\nOwners can make informed decisions when to make changes.\n\nChanges are made in a deliberate manner.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nTo implement this best practice, you need to be able to request changes to processes, procedures,\n\nand resources. The change management process can be lightweight. Document the change\n\nmanagement process.\n\nCustomer example\n\nAnyCompany Retail uses a responsibility assignment (RACI) matrix to identify who owns changes\n\nfor processes, procedures, and resources. They have a documented change management process\n\nthat’s lightweight and easy to follow. Using the RACI matrix and the process, anyone can submit\n\nchange requests.\n\nImplementation steps\n\n1. Identify the processes, procedures, and resources for your workload and the owners for each.\n\nDocument them in your knowledge management system.\n\na. If you have not implemented OPS02-BP01 Resources have identiﬁed owners, OPS02-BP02\n\nProcesses and procedures have identiﬁed owners, or OPS02-BP03 Operations activities have\n\nidentiﬁed owners responsible for their performance, start with those ﬁrst.\n\n2. Work with stakeholders in your organization to develop a change management process.\n\nThe process should cover additions, changes, and exceptions for resources, processes, and\n\nprocedures.\n\na. You can use AWS Systems Manager Change Manager as a change management platform for\n\nworkload resources.\n\n3. Document the change management process in your knowledge management system.\n\nLevel of eﬀort for the implementation plan: Medium. Developing a change management process requires alignment with multiple stakeholders across your organization.\n\nRelationships and ownership\n\n50\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS02-BP01 Resources have identiﬁed owners - Resources need identiﬁed owners before you\n\nbuild a change management process.\n\nOPS02-BP02 Processes and procedures have identiﬁed owners - Processes need identiﬁed\n\nowners before you build a change management process.\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their performance -\n\nOperations activities need identiﬁed owners before you build a change management process.\n\nRelated documents:\n\nAWS Prescriptive Guidance - Foundation palybook for AWS large migrations: Creating RACI\n\nmatrices\n\nChange Management in the Cloud Whitepaper\n\nRelated services:\n\nAWS Systems Manager Change Manager\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nHave deﬁned or negotiated agreements between teams describing how they work with and\n\nsupport each other (for example, response times, service level objectives, or service-level\n\nagreements). Inter-team communications channels are documented. Understanding the impact of\n\nthe teams’ work on business outcomes and the outcomes of other teams and organizations informs\n\nthe prioritization of their tasks and helps them respond appropriately.\n\nWhen responsibility and ownership are undeﬁned or unknown, you are at risk of both not\n\naddressing necessary activities in a timely fashion and of redundant and potentially conﬂicting\n\neﬀorts emerging to address those needs.\n\nDesired outcome:\n\nInter-team working or support agreements are agreed to and documented.\n\nTeams that support or work with each other have deﬁned communication channels and response\n\nexpectations.\n\nRelationships and ownership\n\n51\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nAn issue occurs in production and two separate teams start troubleshooting independent of each\n\nother. Their siloed eﬀorts extend the outage.\n\nThe operations team needs assistance from the development team but there is no agreed to\n\nresponse time. The request is stuck in the backlog.\n\nBeneﬁts of establishing this best practice:\n\nTeams know how to interact and support each other.\n\nExpectations for responsiveness are known.\n\nCommunications channels are clearly deﬁned.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nImplementing this best practice means that there is no ambiguity about how teams work with\n\neach other. Formal agreements codify how teams work together or support each other. Inter-team\n\ncommunication channels are documented.\n\nCustomer example\n\nAnyCompany Retail’s SRE team has a service level agreement with their development team.\n\nWhenever the development team makes a request in their ticketing system, they can expect\n\na response within ﬁfteen minutes. If there is a site outage, the SRE team takes lead in the\n\ninvestigation with support from the development team.\n\nImplementation steps\n\n1. Working with stakeholders across your organization, develop agreements between teams based\n\non processes and procedures.\n\na. If a process or procedure is shared between two teams, develop a runbook on how the teams\n\nwill work together.\n\nb. If there are dependencies between teams, agree to a response SLA for requests.\n\n2. Document responsibilities in your knowledge management system.\n\nRelationships and ownership\n\n52",
      "page_number": 47
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 58-67)",
      "start_page": 58,
      "end_page": 67,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: Medium. If there are no existing agreements between teams, it can take eﬀort to come to agreement with stakeholders across your organization.\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners - Process ownership must be\n\nidentiﬁed before setting agreements between teams.\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their performance -\n\nOperations activities ownership must be identiﬁed before setting agreements between teams.\n\nRelated documents:\n\nAWS Executive Insights - Empowering Innovation with the Two-Pizza Team\n\nIntroduction to DevOps on AWS - Two-Pizza Teams\n\nOrganizational culture\n\nProvide support for your team members so they can be more eﬀective in taking action and\n\nsupporting your business outcome.\n\nBest practices\n\nOPS03-BP01 Provide executive sponsorship\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\nOPS03-BP03 Escalation is encouraged\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\nOPS03-BP05 Experimentation is encouraged\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\nOPS03-BP07 Resource teams appropriately\n\nOrganizational culture\n\n53\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS03-BP01 Provide executive sponsorship\n\nAt the highest level, senior leadership acts as the executive sponsor to clearly set expectations and\n\ndirection for the organization's outcomes, including evaluating its success. The sponsor advocates\n\nand drives adoption of best practices and evolution of the organization.\n\nDesired outcome: Organizations that endeavor to adopt, transform, and optimize their cloud operations establish clear lines of leadership and accountability for desired outcomes. The\n\norganization understands each capability required by the organization to accomplish a new\n\noutcome and assigns ownership to functional teams for development. Leadership actively\n\nsets this direction, assigns ownership, takes accountability, and deﬁnes the work. As a result,\n\nindividuals across the organization can mobilize, feel inspired, and actively work towards the\n\ndesired objectives.\n\nCommon anti-patterns:\n\nThere is a mandate for workload owners to migrate workloads to AWS without a clear sponsor\n\nand plan for cloud operations. This results in teams not consciously collaborating to improve\n\nand mature their operational capabilities. Lack of operational best practice standards overwhelm\n\nteams (such as operator-toil, on-calls, and technical debt), which constrains innovation.\n\nA new organization-wide goal has been set to adopt an emerging technology without providing\n\nleadership sponsor and strategy. Teams interpret goals diﬀerently, which causes confusion\n\non where to focus eﬀorts, why they matter, and how to measure impact. Consequently, the\n\norganization loses momentum in adopting the technology.\n\nBeneﬁts of establishing this best practice: When executive sponsorship clearly communicates and shares vision, direction, and goals, team members know what is expected of them. Individuals and\n\nteams begin to intensely focus eﬀort in the same direction to accomplish deﬁned objectives when\n\nleaders are actively engaged. As a result, the organization maximizes the ability to succeed. When\n\nyou evaluate success, you can better identify barriers to success so that they can be addressed\n\nthrough intervention by the executive sponsor.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nAt every phase of the cloud journey (migration, adoption, or optimization), success requires\n\nactive involvement at the highest level of leadership with a designated executive sponsor. The\n\nOPS03-BP01 Provide executive sponsorship\n\n54\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nexecutive sponsor aligns the team's mindset, skillsets, and ways of working to the deﬁned\n\nstrategy.\n\nExplain the why: Bring clarity and explain the reasoning behind the vision and strategy.\n\nSet expectations: Deﬁne and publish goals for your organizations, including how progress and\n\nsuccess are measured.\n\nTrack achievement of goals: Measure the incremental achievement of goals regularly (not just completion of tasks). Share the results so that appropriate action can be taken if outcomes are at risk.\n\nProvide the resources necessary to achieve your goals: Bring people and teams together to collaborate and build the right solutions that bring about the deﬁned outcomes. This reduces or eliminates organizational friction.\n\nAdvocate for your teams: Remain engaged with your teams so that you understand their\n\nperformance and whether there are external factors aﬀecting them. Identify obstacles that\n\nare impeding your teams progress. Act on behalf of your teams to help address obstacles and\n\nremove unnecessary burdens. When your teams are impacted by external factors, reevaluate\n\ngoals and adjust targets as appropriate.\n\nDrive adoption of best practices: Acknowledge best practices that provide quantiﬁable\n\nbeneﬁts, and recognize the creators and adopters. Encourage further adoption to magnify the\n\nbeneﬁts achieved.\n\nEncourage evolution of your teams: Create a culture of continual improvement, and\n\nproactively learn from progress made as well as failures. Encourage both personal and\n\norganizational growth and development. Use data and anecdotes to evolve the vision and\n\nstrategy.\n\nCustomer example\n\nAnyCompany Retail is in the process of business transformation through rapid reinvention\n\nof customer experiences, enhancement of productivity, and acceleration of growth through\n\ngenerative AI.\n\nImplementation steps\n\n1. Establish single-threaded leadership, and assign a primary executive sponsor to lead and drive\n\nthe transformation.\n\nOPS03-BP01 Provide executive sponsorship\n\n55\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n2. Deﬁne clear business outcomes of your transformation, and assign ownership and\n\naccountability. Empower the primary executive with the authority to lead and make critical decisions.\n\n3. Verify that your transformational strategy is very clear and communicated widely by the\n\nexecutive sponsor to every level of the organization.\n\na. Establish clearly deﬁned business objectives for IT and cloud initiatives.\n\nb. Document key business metrics to drive IT and cloud transformation.\n\nc. Communicate the vision consistently to all teams and individuals responsible for parts of the\n\nstrategy.\n\n4. Develop communication planning matrices that specify what message needs to be delivered to\n\nspeciﬁed leaders, managers, and individual contributors. Specify the person or team that should\n\ndeliver this message.\n\na. Fulﬁll communications plans consistently and reliably.\n\nb. Set and manage expectations through in-person events on a regular basis.\n\nc. Accept feedback on the eﬀectiveness of communications, and adjust the communications and\n\nplan accordingly.\n\nd. Schedule communication events to proactively understand challenges from teams, and\n\nestablish a consistent feedback loop that allows for correcting course where necessary.\n\n5. Actively engage each initiative from a leadership perspective to verify that all impacted teams\n\nunderstand the outcomes they are accountable to achieve.\n\n6. At every status meeting, executive sponsors should look for blockers, inspect established\n\nmetrics, anecdotes, or feedback from the teams, and measure progress towards objectives.\n\nLevel of eﬀort for the implementation plan Medium\n\nResources\n\nRelated best practices:\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\nOP11-BP01 Have a process for continuous improvement\n\nOPS11-BP07 Perform operations metrics reviews\n\nRelated documents:\n\nOPS03-BP01 Provide executive sponsorship\n\n56\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUntangling Your Organisational Hairball: Highly Aligned\n\nThe Living Transformation: Pragmatically approaching changes\n\nBecoming a Future-Ready Enterprise\n\n7 Pitfalls to Avoid When Building a CCOE\n\nNavigating the Cloud: Key Performance Indicators for Success\n\nRelated videos:\n\nAWS re:Invent 2023: A leader's guide to generative AI: Using history to shape the future (SEG204)\n\nRelated examples:\n\nProsci: Primary Sponsor's Role & Importance\n\nOPS03-BP02 Team members are empowered to take action when\n\noutcomes are at risk\n\nA cultural behavior of ownership instilled by leadership results in any employee feeling empowered\n\nto act on behalf of the entire company beyond their deﬁned scope of role and accountability.\n\nEmployees can act to proactively identify risks as they emerge and take appropriate action. Such a\n\nculture allows employees to make high value decisions with situational awareness.\n\nFor example, Amazon uses Leadership Principles as the guidelines to drive desired behavior for\n\nemployees to move forward in situations, solve problems, deal with conﬂict, and take action.\n\nDesired outcome: Leadership has inﬂuenced a new culture that allows individuals and teams to make critical decisions, even at lower levels of the organization (as long as decisions are\n\ndeﬁned with auditable permissions and safety mechanisms). Failure is not discouraged, and\n\nteams iteratively learn to improve their decision-making and responses to tackle similar situations\n\ngoing forward. If someone's actions result in an improvement that can beneﬁt other teams, they\n\nproactively share knowledge from such actions. Leadership measures operational improvements\n\nand incentivizes the individual and organization for adoption of such patterns.\n\nCommon anti-patterns:\n\nThere isn't clear guidance or mechanisms in an organization for what to do when a risk is\n\nidentiﬁed. For example, when an employee notices a phishing attack, they fail to report to the\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\n57\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nsecurity team, resulting in a large portion of the organization falling for the attack. This causes a\n\ndata breach.\n\nYour customers complain about service unavailability, which primarily stems from failed\n\ndeployments. Your SRE team is responsible for the deployment tool, and an automated rollback\n\nfor deployments is in their long-term roadmap. In a recent application rollout, one of the\n\nengineers devised a solution to automate rolling back their application to a previous version.\n\nThough their solution can become the pattern for SRE teams, other teams do not adopt, as there\n\nis no process to track such improvements. The organization continues to be plagued with failed\n\ndeployments impacting customers and causing further negative sentiment.\n\nIn order to stay compliant, your infosec team oversees a long-established process to rotate\n\nshared SSH keys regularly on behalf of operators connecting to their Amazon EC2 Linux\n\ninstances. It takes several days for the infosec teams to complete rotating keys, and you are\n\nblocked from connecting to those instances. No one inside or outside of infosec suggests using other options on AWS to achieve the same result.\n\nBeneﬁts of establishing this best practice: By decentralizing authority to make decisions and empowering your teams to decide key decisions, you are able to address issues more quickly with\n\nincreasing success rates. In addition, teams start to realize a sense of ownership, and failures are\n\nacceptable. Experimentation becomes a cultural mainstay. Managers and directors do not feel as\n\nthough they are micro-managed through every aspect of their work.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\n1. Develop a culture where it is expected that failures can occur.\n\n2. Deﬁne clear ownership and accountability for various functional areas within the organization.\n\n3. Communicate ownership and accountability to everyone so that individuals know who can help\n\nthem facilitate decentralized decisions.\n\n4. Deﬁne your one-way and two-way door decisions to help individuals know when they do need to\n\nescalate to higher levels of leadership.\n\n5. Create organizational awareness that all employees are empowered to take action at various\n\nlevels when outcomes are at risk. Provide your team members documentation of governance,\n\npermission-levels, tools, and opportunities to practice the skills necessary to respond eﬀectively.\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\n58\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n6. Give your team members the opportunity to practice the skills necessary to respond to various\n\ndecisions. Once decision levels are deﬁned, perform game days to verify that all individual contributors understand and can demonstrate the process.\n\na. Provide alternative safe environments where processes and procedures can be tested and\n\ntrained upon.\n\nb. Acknowledge and create awareness that team members have authority to take action when\n\nthe outcome has a predeﬁned level of risk.\n\nc. Deﬁne the authority of your team members to take action by assigning permissions and\n\naccess to the workloads and components they support.\n\n7. Provide ability for teams to share their learnings (operational successes and failures).\n\n8. Empower teams to challenge the status quo, and provide mechanisms to track and measure\n\nimprovements, as well as their impact to the organization.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nOPS02-BP05 Mechanisms exist to identify responsibility and ownership\n\nRelated documents:\n\nAWS Blog Post | The agile enterprise\n\nAWS Blog Post | Measuring success : A paradox and a plan\n\nAWS Blog Post | Letting go : Enabling autonomy in teams\n\nCentralize or Decentralize?\n\nRelated videos:\n\nre:Invent 2023 | How to not sabotage your transformation (SEG201)\n\nre:Invent 2021 | Amazon Builders' Library: Operational Excellence at Amazon\n\nCentralization vs. Decentralization\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\n59\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated examples:\n\nUsing architectural decision records to streamline technical decision-making for a software\n\ndevelopment project\n\nOPS03-BP03 Escalation is encouraged\n\nTeam members are encouraged by leadership to escalate issues and concerns to higher-level\n\ndecision makers and stakeholders if they believe desired outcomes are at risk and expected\n\nstandards are not met. This is a feature of the organization's culture and is driven at all levels.\n\nEscalation should be done early and often so that risks can be identiﬁed and prevented from\n\ncausing incidents. Leadership does not reprimand individuals for escalating an issue.\n\nDesired outcome: Individuals throughout the organization are comfortable to escalate problems to their immediate and higher levels of leadership. Leadership has deliberately and consciously\n\nestablished expectations that their teams should feel safe to escalate any issue. A mechanism\n\nexists to escalate issues at each level within the organization. When employees escalate to their\n\nmanager, they jointly decide the level of impact and whether the issue should be escalated. In\n\norder to initiate an escalation, employees are required to include a recommended work plan to\n\naddress the issue. If direct management does not take timely action, employees are encouraged to\n\ntake issues to the highest level of leadership if they feel strongly that the risks to the organization\n\nwarrant the escalation.\n\nCommon anti-patterns:\n\nExecutive leaders do not ask enough probing questions during your cloud transformation\n\nprogram status meeting to ﬁnd where issues and blockers are occurring. Only good news is\n\npresented as status. The CIO has made it clear that she only likes to hear good news, as any\n\nchallenges brought up make the CEO think that the program is failing.\n\nYou are a cloud operations engineer and you notice that the new knowledge management\n\nsystem is not being widely adopted by application teams. The company invested one year and\n\nseveral million dollars to implement this new knowledge management system, but people\n\nare still authoring their runbooks locally and sharing them on an organizational cloud share,\n\nmaking it diﬃcult to ﬁnd knowledge pertinent to supported workloads. You try to bring this\n\nto leadership's attention, because consistent use of this system can enhance operational\n\neﬃciency. When you bring this to the director who lead the implementation of the knowledge\n\nmanagement system, she reprimands you because it calls the investment into question.\n\nOPS03-BP03 Escalation is encouraged\n\n60\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe infosec team responsible for hardening compute resources has decided to put a process\n\nin place that requires performing the scans necessary to ensure that EC2 instances are fully secured before the compute team releases the resource for use. This has created a time delay of\n\nan additional week for resources to be deployed, which breaks their SLA. The compute team is\n\nafraid to escalate this to the VP over cloud because this makes the VP of information security\n\nlook bad.\n\nBeneﬁts of establishing this best practice:\n\nComplex or critical issues are addressed before they impact the business. Less time is wasted. Risks\n\nare minimized. Teams become more proactive and results focused when solving problems.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nThe willingness and ability to escalate freely at every level in the organization is an organizational\n\nand cultural foundation that should be consciously developed through emphasized training,\n\nleadership communications, expectation setting, and the deployment of mechanisms throughout\n\nthe organization at every level.\n\nImplementation steps\n\n1. Deﬁne policies, standards, and expectations for your organization.\n\na. Ensure wide adoption and understanding of policies, expectations, and standards.\n\n2. Encourage, train, and empower workers for early and frequent escalation when standards are\n\nnot met.\n\n3. Organizationally acknowledge that early and frequent escalation is the best practice. Accept that\n\nescalations may prove to be unfounded, and that it is better to have the opportunity to prevent\n\nan incident then to miss that opportunity by not escalating.\n\na. Build a mechanism for escalation (like an Andon cord system).\n\nb. Have documented procedures deﬁning when and how escalation should occur.\n\nc. Deﬁne the series of people with increasing authority to take or approve action, as well as each\n\nstakeholder's contact information.\n\n4. When escalation occurs, it should continue until the team member is satisﬁed that the risk has\n\nbeen mitigated through actions driven from leadership.\n\na. Escalations should include:\n\nOPS03-BP03 Escalation is encouraged\n\n61\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\ni. Description of the situation, and the nature of the risk\n\nii. Criticality of the situation\n\niii. Who or what is impacted\n\niv. How great the impact is\n\nv. Urgency if impact occurs\n\nvi. Suggested remedies and plans to mitigate\n\nb. Protect employees who escalate. Have policy that protects team members from retribution\n\nif they escalate around a non-responsive decision maker or stakeholder. Have mechanisms in\n\nplace to identify if this is occurring and respond appropriately.\n\n5. Encourage a culture of continuous improvement feedback loops in everything that the\n\norganization produces. Feedback loops act as minor escalations to individuals responsible, and\n\nthey identify improvement opportunities, even when escalation is not needed. Continuous\n\nimprovement cultures force everyone to be more proactive.\n\n6. Leadership should periodically reemphasize the policies, standards, mechanisms, and the desire\n\nfor open escalation and continuous feedback loops without retribution.\n\nLevel of eﬀort for the Implementation Plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS02-BP05 Mechanisms exist to request additions, changes, and exceptions\n\nRelated documents:\n\nHow do you foster a culture of continuous improvement and learning from Andon and escalation\n\nsystems?\n\nThe Andon Cord (IT Revolution)\n\nAWS DevOps Guidance | Establish clear escalation paths and encourage constructive\n\ndisagreement\n\nRelated videos:\n\nJeﬀ Bezos on how to make decisions (& increase velocity)\n\nOPS03-BP03 Escalation is encouraged\n\n62",
      "page_number": 58
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 68-77)",
      "start_page": 68,
      "end_page": 77,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nToyota Product System: Stopping Production, a Button, and an Andon Electric Board\n\nAndon Cord in LEAN Manufacturing\n\nRelated examples:\n\nWorking with escalation plans in Incident Manager\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\nLeadership is responsible for the creation of strong and eﬀective communications, especially\n\nwhen the organization adopts new strategies, technologies, or ways of working. Leaders should\n\nset expectations for all staﬀ to work towards the company objectives. Devise communication\n\nmechanisms that create and maintain awareness among the teams responsible for running plans that are funded and sponsored by leadership. Make use of cross-organizational diversity, and\n\nlisten attentively to multiple unique perspectives. Use this perspective to increase innovation,\n\nchallenge your assumptions, and reduce the risk of conﬁrmation bias. Foster inclusion, diversity,\n\nand accessibility within your teams to gain beneﬁcial perspectives.\n\nDesired outcome: Your organization designs communication strategies to address the impact of change to the organization. Teams remain informed and motivated to continue working with\n\none another rather than against each other. Individuals understand how important their role is\n\nto achieve the stated objectives. Email is only a passive mechanism for communications and used\n\naccordingly. Management spends time with their individual contributors to help them understand\n\ntheir responsibility, the tasks to complete, and how their work contributes to the overall mission.\n\nWhen necessary, leaders engage people directly in smaller venues to convey messages and verify\n\nthat these messages are being delivered eﬀectively. As a result of good communications strategies,\n\nthe organization performs at or above the expectations of leadership. Leadership encourages and\n\nseeks diverse opinions within and across teams.\n\nCommon anti-patterns:\n\nYour organization has a ﬁve year plan to migrate all workloads to AWS. The business case for\n\ncloud includes the modernization of 25% of all workloads to take advantage of serverless\n\ntechnology. The CIO communicates this strategy to direct reports and expects each leader to\n\ncascade this presentation to managers, directors, and individual contributors without any in-\n\nperson communication. The CIO steps back and expects his organization to perform the new\n\nstrategy.\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n63\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLeadership does not provide or use a mechanism for feedback, and an expectation gap grows,\n\nwhich leads to stalled projects.\n\nYou are asked to make a change to your security groups, but you are not given any details of\n\nwhat change needs to be made, what the impact of the change could be on all the workloads,\n\nand when it should happen. The manager forwards an email from the VP of InfoSec and adds the\n\nmessage \"Make this happen.\"\n\nChanges were made to your migration strategy that reduce the planned modernization number from 25% to 10%. This has downstream eﬀects on the operations organization. They were not informed of this strategic change and thus, they are not ready with enough skilled capacity to\n\nsupport a greater number of workloads lifted and shifted into AWS.\n\nBeneﬁts of establishing this best practice:\n\nYour organization is well-informed on new or changed strategies, and they act accordingly with\n\nstrong motivation to help each other achieve the overall objectives and metrics set by leadership.\n\nMechanisms exist and are used to provide timely notice to team members of known risks and\n\nplanned events.\n\nNew ways of working (including changes to people or the organization, processes, or\n\ntechnology), along with required skills, are more eﬀectively adopted by the organization, and\n\nyour organization realizes business beneﬁts more quickly.\n\nTeam members have the necessary context of the communications being received, and they can\n\nbe more eﬀective in their jobs.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo implement this best practice, you must work with stakeholders across your organization\n\nto agree to communication standards. Publicize those standards to your organization. For any\n\nsigniﬁcant IT transitions, an established planning team can more successfully manage the impact\n\nof change to its people than an organization that ignores this practice. Larger organizations can\n\nbe more challenging when managing change because it's critical to establish strong buy-in on a\n\nnew strategy with all individual contributors. In the absence of such a transition planning team,\n\nleadership holds 100% of the responsibility for eﬀective communications. When establishing\n\na transition planning team, assign team members to work with all organizational leadership to\n\ndeﬁne and manage eﬀective communications at every level.\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n64\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCustomer example\n\nAnyCompany Retail signed up for AWS Enterprise Support and depends on other third-\n\nparty providers for its cloud operations. The company uses chat and chatops as their main\n\ncommunication medium for operational activities. Alerts and other information populate speciﬁc\n\nchannels. When someone must act, they clearly state the desired outcome, and in many cases, they\n\nreceive a runbook or playbook to use. They schedule major changes to production systems with a\n\nchange calendar.\n\nImplementation steps\n\n1. Establish a core team within the organization that has accountability to build and initiate\n\ncommunication plans for changes that happen at multiple levels within the organization.\n\n2. Institute single-threaded ownership to achieve oversight. Give individual teams the ability to\n\ninnovate independently, and balance the use of consistent mechanisms, which allows for the\n\nright level of inspection and directional vision.\n\n3. Work with stakeholders across your organization to agree to communication standards,\n\npractices, and plans.\n\n4. Verify that the core communications team collaborates with organizational and program\n\nleadership to craft messages to appropriate staﬀ on behalf of leaders.\n\n5. Build strategic communication mechanisms to manage change through announcements, shared\n\ncalendars, all-hands meetings, and in-person or one-on-one methods so that team members\n\nhave proper expectations on the actions they should take.\n\n6. Provide necessary context, details, and time (when possible) to determine if action is necessary.\n\nWhen action is needed, provide the required action and its impact.\n\n7. Implement tools that facilitate tactical communications, like internal chat, email, and knowledge\n\nmanagement.\n\n8. Implement mechanisms to measure and verify that all communications lead to desired\n\noutcomes.\n\n9. Establish a feedback loop that measures the eﬀectiveness of all communications, especially\n\nwhen communications are related to resistance to changes throughout the organization.\n\n10.For all AWS accounts, establish alternate contacts for billing, security, and operations. Ideally,\n\neach contact should be an email distribution as opposed to a speciﬁc individual contact.\n\n11.Establish an escalation and reverse escalation communication plan to engage with your internal\n\nand external teams, including AWS support and other third-party providers.\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n65\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n12.Initiate and perform communication strategies consistently throughout the life of each\n\ntransformation program.\n\n13.Prioritize actions that are repeatable where possible to safely automate at scale.\n\n14.When communications are required in scenarios with automated actions, the communication's\n\npurpose should be to inform teams, for auditing, or a part of the change management process.\n\n15.Analyze communications from your alert systems for false positives or alerts that are constantly\n\ncreated. Remove or change these alerts so that they start when human intervention is required.\n\nIf an alert is initiated, provide a runbook or playbook.\n\na. You can use AWS Systems Manager Documents to build playbooks and runbooks for alerts.\n\n16.Mechanisms are in place to provide notiﬁcation of risks or planned events in a clear and\n\nactionable way with enough notice to allow appropriate responses. Use email lists or chat\n\nchannels to send notiﬁcations ahead of planned events.\n\na. AWS Chatbot can be used to send alerts and respond to events within your organizations\n\nmessaging platform.\n\n17.Provide an accessible source of information where planned events can be discovered. Provide\n\nnotiﬁcations of planned events from the same system.\n\na. AWS Systems Manager Change Calendar can be used to create change windows when\n\nchanges can occur. This provides team members notice when they can make changes safely.\n\n18.Monitor vulnerability notiﬁcations and patch information to understand vulnerabilities in the\n\nwild and potential risks associated to your workload components. Provide notiﬁcation to team\n\nmembers so that they can act.\n\na. You can subscribe to AWS Security Bulletins to receive notiﬁcations of vulnerabilities on AWS.\n\n19.Seek diverse opinions and perspectives: Encourage contributions from everyone. Give\n\ncommunication opportunities to under-represented groups. Rotate roles and responsibilities in\n\nmeetings.\n\na. Expand roles and responsibilities: Provide opportunities for team members to take on roles that they might not otherwise. They can gain experience and perspective from the role and\n\nfrom interactions with new team members with whom they might not otherwise interact.\n\nThey can also bring their experience and perspective to the new role and team members\n\nthey interact with. As perspective increases, identify emergent business opportunities or new\n\nopportunities for improvement. Rotate common tasks between members within a team that\n\nothers typically perform to understand the demands and impact of performing them.\n\nb. Provide a safe and welcoming environment: Establish policy and controls that protect the\n\nmental and physical safety of team members within your organization. Team members should\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n66\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nbe able to interact without fear of reprisal. When team members feel safe and welcome, they\n\nare more likely to be engaged and productive. The more diverse your organization, the better your understanding can be of the people you support, including your customers. When your\n\nteam members are comfortable, feel free to speak, and are conﬁdent they are heard, they\n\nare more likely to share valuable insights (for example, marketing opportunities, accessibility\n\nneeds, unserved market segments, and unacknowledged risks in your environment).\n\nc. Encourage team members to participate fully: Provide the resources necessary for your employees to participate fully in all work related activities. Team members that face daily\n\nchallenges develop skills for working around them. These uniquely-developed skills can\n\nprovide signiﬁcant beneﬁt to your organization. Support team members with necessary\n\naccommodations to increase the beneﬁts you can receive from their contributions.\n\nResources\n\nRelated best practices:\n\nOPS03-BP01 Provide executive sponsorship\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS07-BP04 Use playbooks to investigate issues\n\nRelated documents:\n\nAWS Blog post | Accountability and empowerment are key to high-performing agile\n\norganizations\n\nAWS Executive Insights | Learn to scale innovation, not complexity | Single-threaded Leaders\n\nAWS Security Bulletins\n\nOpen CVE\n\nSupport App in Slack to Manage Support Cases\n\nManage AWS resources in your Slack channels with Amazon Q Developer in chat applications\n\nRelated services:\n\nAmazon Q Developer in chat applications\n\nAWS Systems Manager Change Calendar\n\nAWS Systems Manager Documents\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n67\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS03-BP05 Experimentation is encouraged\n\nExperimentation is a catalyst for turning new ideas into products and features. It accelerates\n\nlearning and keeps team members interested and engaged. Team members are encouraged\n\nto experiment often to drive innovation. Even when an undesired result occurs, there is value\n\nin knowing what not to do. Team members are not punished for successful experiments with\n\nundesired results.\n\nDesired outcome:\n\nYour organization encourages experimentation to foster innovation.\n\nExperiments are used as an opportunity to learn.\n\nCommon anti-patterns:\n\nYou want to run an A/B test but there is no mechanism to run the experiment. You deploy a UI\n\nchange without the ability to test it. It results in a negative customer experience.\n\nYour company only has a stage and production environment. There is no sandbox environment\n\nto experiment with new features or products so you must experiment within the production\n\nenvironment.\n\nBeneﬁts of establishing this best practice:\n\nExperimentation drives innovation.\n\nYou can react faster to feedback from users through experimentation.\n\nYour organization develops a culture of learning.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nExperiments should be run in a safe manner. Leverage multiple environments to experiment\n\nwithout jeopardizing production resources. Use A/B testing and feature ﬂags to test experiments.\n\nProvide team members the ability to conduct experiments in a sandbox environment.\n\nCustomer example\n\nOPS03-BP05 Experimentation is encouraged\n\n68\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail encourages experimentation. Team members can use 20% of their work\n\nweek to experiment or learn new technologies. They have a sandbox environment where they can innovate. A/B testing is used for new features to validate them with real user feedback.\n\nImplementation steps\n\n1. Work with leadership across your organization to support experimentation. Team members\n\nshould be encouraged to conduct experiments in a safe manner.\n\n2. Provide your team members with an environment where they can safely experiment. They must\n\nhave access to an environment that is like production.\n\na. You can use a separate AWS account to create a sandbox environment for experimentation.\n\nAWS Control Tower can be used to provision these accounts.\n\n3. Use feature ﬂags and A/B testing to experiment safely and gather user feedback.\n\na. AWS AppConﬁg Feature Flags provides the ability to create feature ﬂags.\n\nb. You can use AWS Lambda versions to deploy a new version of a function for beta testing.\n\nLevel of eﬀort for the implementation plan: High. Providing team members with an environment to experiment in and a safe way to conduct experiments can require signiﬁcant investment. You\n\nmay also need to modify application code to use feature ﬂags or support A/B testing.\n\nResources\n\nRelated best practices:\n\nOPS11-BP02 Perform post-incident analysis - Learning from incidents is an important driver for\n\ninnovation along with experimentation.\n\nOPS11-BP03 Implement feedback loops - Feedback loops are an important part of\n\nexperimentation.\n\nRelated documents:\n\nAn Inside Look at the Amazon Culture: Experimentation, Failure, and Customer Obsession\n\nBest practices for creating and managing sandbox accounts in AWS\n\nCreate a Culture of Experimentation Enabled by the Cloud\n\nEnabling experimentation and innovation in the cloud at SulAmérica Seguros\n\nExperiment More, Fail Less\n\nOPS03-BP05 Experimentation is encouraged\n\n69\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOrganizing Your AWS Environment Using Multiple Accounts - Sandbox OU\n\nUsing AWS AppConﬁg Feature Flags\n\nRelated videos:\n\nAWS On Air ft. Amazon CloudWatch Evidently | AWS Events\n\nAWS On Air San Fran Summit 2022 ft. AWS AppConﬁg Feature Flags integration with Jira\n\nAWS re:Invent 2022 - A deployment is not a release: Control your launches w/feature ﬂags\n\n(BOA305-R)\n\nProgrammatically Create an AWS account with AWS Control Tower\n\nSet Up a Multi-Account AWS Environment that Uses Best Practices for AWS Organizations\n\nRelated examples:\n\nAWS Innovation Sandbox\n\nEnd-to-end Personalization 101 for E-Commerce\n\nRelated services:\n\nAmazon CloudWatch Evidently\n\nAWS AppConﬁg\n\nAWS Control Tower\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\nTeams must grow their skill sets to adopt new technologies, and to support changes in demand\n\nand responsibilities in support of your workloads. Growth of skills in new technologies is frequently\n\na source of team member satisfaction and supports innovation. Support your team members'\n\npursuit and maintenance of industry certiﬁcations that validate and acknowledge their growing\n\nskills. Cross train to promote knowledge transfer and reduce the risk of signiﬁcant impact when\n\nyou lose skilled and experienced team members with institutional knowledge. Provide dedicated\n\nstructured time for learning.\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\n70\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS provides resources, including the AWS Getting Started Resource Center, AWS Blogs, AWS\n\nOnline Tech Talks, AWS Events and Webinars, and the AWS Well-Architected Labs, that provide guidance, examples, and detailed walkthroughs to educate your teams.\n\nResources such as Support, (AWS re:Post, Support Center), and AWS Documentation help remove\n\ntechnical roadblocks and improve operations. Reach out to Support through Support Center for\n\nhelp with your questions.\n\nAWS also shares best practices and patterns that we have learned through the operation of AWS in\n\nThe Amazon Builders' Library and a wide variety of other useful educational material through the\n\nAWS Blog and The Oﬃcial AWS Podcast.\n\nAWS Training and Certiﬁcation includes free training through self-paced digital courses, along with\n\nlearning plans by role or domain. You can also register for instructor-led training to further support\n\nthe development of your teams' AWS skills.\n\nDesired outcome: Your organization constantly evaluates skill gaps and closes them with structured budget and investment. Teams encourage and incentivize their members with upskilling\n\nactivities such as acquiring leading industry certiﬁcations. Teams take advantage of dedicated\n\ncross-sharing knowledge programs such as lunch-and-learns, immersion days, hackathons, and\n\ngamedays. Your organization's keeps its knowledge systems up-to-date and relevant to cross-train\n\nteam members, including new-hire onboarding trainings.\n\nCommon anti-patterns:\n\nIn the absence of a structured training program and budget, teams experience uncertainty as\n\nthey try to keep pace with technology evolution, which results in increased attrition.\n\nAs part of migrating to AWS, your organization demonstrates skill gaps and varying cloud\n\nﬂuency amongst teams. Without an eﬀort to upskill, teams ﬁnd themselves overtasked with\n\nlegacy and ineﬃcient management of the cloud environment, which causes increased operator\n\ntoil. This burn out increases employee dissatisfaction.\n\nBeneﬁts of establishing this best practice: When your organization consciously invests in improving the skills of its teams, it also helps accelerate and scale cloud adoption and optimization.\n\nTargeted learning programs drive innovation and build operational ability for teams to be prepared\n\nto handle events. Teams consciously invest in the implementation and evolution of best practices. Team morale is high, and team members value their contribution to the business.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\n71\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nTo adopt new technologies, fuel innovation, and keep pace with changes in demand and\n\nresponsibilities to support your workloads, continually invest in the professional growth of your teams.\n\nImplementation steps\n\n1. Use structured cloud advocacy programs: AWS Skills Guild provides consultative training to\n\nincrease cloud skill conﬁdence and ignite a culture of continuous learning.\n\n2. Provide resources for education: Provide dedicated, structured time and access to training\n\nmaterials and lab resources, and support participation in conferences and access to professional\n\norganizations that provide opportunities for learning from both educators and peers. Provide\n\nyour junior team members with access to senior team members as mentors, or allow the junior team members to shadow their seniors' work and be exposed to their methods and skills. Encourage learning about content not directly related to work in order to have a broader\n\nperspective.\n\n3. Encourage use of expert technical resources: Leverage resources such as AWS re:Post to get\n\naccess to curated knowledge and vibrant community.\n\n4. Build and maintain an up-to-date knowledge repository: Use knowledge sharing platforms such as wikis and runbooks. Create your own reusable expert knowledge source with AWS re:Post Private to streamline collaboration, improve productivity, and accelerate employee\n\nonboarding.\n\n5. Team education and cross-team engagement: Plan for the continuing education needs of your team members. Provide opportunities for team members to join other teams (temporarily or permanently) to share skills and best practices beneﬁting your entire organization.\n\n6. Support pursuit and maintenance of industry certiﬁcations: Support your team members in\n\nthe acquisition and maintenance of industry certiﬁcations that validate what they have learned and acknowledge their accomplishments.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS03-BP01 Provide executive sponsorship\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\n72",
      "page_number": 68
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 78-88)",
      "start_page": 78,
      "end_page": 88,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAWS Whitepaper | Cloud Adoption Framework: People Perspective\n\nInvesting in continuous learning to grow your organization's future\n\nAWS Skills Guild\n\nAWS Training and Certiﬁcation\n\nSupport\n\nAWS re:Post\n\nAWS Getting Started Resource Center\n\nAWS Blogs\n\nAWS Cloud Compliance\n\nAWS Documentation\n\nThe Oﬃcial AWS Podcast.\n\nAWS Online Tech Talks\n\nAWS Events and Webinars\n\nAWS Well-Architected Labs\n\nThe Amazon Builders' Library\n\nRelated videos:\n\nAWS re:Invent 2023 | Reskilling at the speed of cloud: Turning employees into entrepreneurs\n\nWS re:Invent 2023 | Building a culture of curiosity through gamiﬁcation\n\nOPS03-BP07 Resource teams appropriately\n\nProvision the right amount of proﬁcient team members, and provide tools and resources to\n\nsupport your workload needs. Overburdening team members increases the risk of human error.\n\nInvestments in tools and resources, such as automation, can scale the eﬀectiveness of your team and help them support a greater number of workloads without requiring additional capacity.\n\nDesired outcome:\n\nOPS03-BP07 Resource teams appropriately\n\n73\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou have appropriately staﬀed your team to gain the skillsets needed for them to operate\n\nworkloads in AWS in accordance with your migration plan. As your team has scaled itself up during the course of your migration project, they have gained proﬁciency in the core AWS\n\ntechnologies that the business plans to use when migrating or modernizing their applications.\n\nYou have carefully aligned your staﬃng plan to make eﬃcient use of resources by leveraging\n\nautomation and workﬂow. A smaller team can now manage more infrastructure on behalf of the\n\napplication development teams.\n\nWith shifting operational priorities, any resource staﬃng constraints are proactively identiﬁed to\n\nprotect the success of business initiatives.\n\nOperational metrics that report operational toil (such as on-call fatigue or excessive paging) are\n\nreviewed to verify that staﬀ are not overwhelmed.\n\nCommon anti-patterns:\n\nYour staﬀ have not ramped up on AWS skills as you close in on your multi-year cloud migration\n\nplan, which risks support of the workloads and lowers employee morale.\n\nYour entire IT organization is shifting into agile ways of working. The business is prioritizing\n\nthe product portfolio and setting metrics for what features need to be developed ﬁrst. Your\n\nagile process does not require teams to assign story points to their work plans. As a result, it is\n\nimpossible to know the level of capacity required for the next amount of work, or if you have the\n\nright skills assigned to the work.\n\nYou are having an AWS partner migrate your workloads, and you don't have a support transition\n\nplan for your teams once the partner completes the migration project. Your teams struggle to\n\neﬃciently and eﬀectively support the workloads.\n\nBeneﬁts of establishing this best practice: You have appropriately-skilled team members available in your organization to support the workloads. Resource allocation can adapt to shifting\n\npriorities without impacting performance. The result is teams being proﬁcient at supporting\n\nworkloads while maximizing time to focus on innovating for customers, which in turn raises\n\nemployee satisfaction.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS03-BP07 Resource teams appropriately\n\n74\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nResource planning for your cloud migration should occur at an organizational level that aligns to\n\nyour migration plan, as well as the desired operating model being implemented to support your\n\nnew cloud environment. This should include understanding which cloud technologies are deployed\n\nfor the business and application development teams. Infrastructure and operations leadership\n\nshould plan for skills gap analysis, training, and role deﬁnition for engineers who are leading cloud adoption.\n\nImplementation steps\n\n1. Deﬁne success criteria for team's success with relevant operational metrics such as staﬀ\n\nproductivity (for example, cost to support a workload or operator hours spent during incidents).\n\n2. Deﬁne resource capacity planning and inspection mechanisms to verify that the right balance of\n\nqualiﬁed capacity is available when needed and can be adjusted over time.\n\n3. Create mechanisms (for example, sending a monthly survey to teams) to understand work-\n\nrelated challenges that impact teams (like increasing responsibilities, changes in technology, loss\n\nof personnel, or increase in customers supported).\n\n4. Use these mechanisms to engage with teams and spot trends that may contribute to employee\n\nproductivity challenges. When your teams are impacted by external factors, reevaluate goals\n\nand adjust targets as appropriate. Identify obstacles that are impeding your team's progress.\n\n5. Regularly review if your currently-provisioned resources are still suﬃcient, of if additional\n\nresources are needed, and make appropriate adjustments to support teams.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP07 Automate responses to events\n\nRelated documents:\n\nOPS03-BP07 Resource teams appropriately\n\n75\n\nOperational Excellence Pillar\n\nAWS Cloud Adoption Framework: People Perspective\n\nBecoming a Future-Ready Enterprise\n\nPrioritize your Employees' Skills to Drive Business Growth\n\nHigh performing organization - the Amazon Two-Pizza team\n\nHow Cloud-Mature Enterprises Succeed\n\nOPS03-BP07 Resource teams appropriately\n\nAWS Well-Architected Framework\n\n76\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nPrepare\n\nTo prepare for operational excellence, you have to understand your workloads and their expected behaviors. You will then be able to design them to provide insight to their status and build the\n\nprocedures to support them.\n\nDesign your workload so that it provides the information necessary for you to understand its internal state (for example, metrics, logs, events, and traces) across all components in support of\n\nobservability and investigating issues. Observability goes beyond simple monitoring, providing\n\na comprehensive understanding of a system's internal workings based on its external outputs.\n\nRooted in metrics, logs, and traces, observability oﬀers profound insights into system behavior and\n\ndynamics. With eﬀective observability, teams can discern patterns, anomalies, and trends, allowing\n\nthem to proactively address potential issues and maintain optimal system health. Identifying key performance indicators (KPIs) is pivotal to ensure alignment between monitoring activities and\n\nbusiness objectives. This alignment ensures that teams are making data-driven decisions using\n\nmetrics that genuinely matter, optimizing both system performance and business outcomes.\n\nFurthermore, observability empowers businesses to be proactive rather than reactive. Teams can\n\nunderstand the cause-and-eﬀect relationships within their systems, predicting and preventing\n\nissues rather than just reacting to them. As workloads evolve, it's essential to revisit and reﬁne the\n\nobservability strategy, ensuring it remains relevant and eﬀective.\n\nAdopt approaches that improve the ﬂow of changes into production and that achieves refactoring,\n\nfast feedback on quality, and bug ﬁxing. These accelerate beneﬁcial changes entering production,\n\nlimit issues deployed, and activate rapid identiﬁcation and remediation of issues introduced\n\nthrough deployment activities or discovered in your environments.\n\nAdopt approaches that provide fast feedback on quality and achieves rapid recovery from changes\n\nthat do not have desired outcomes. Using these practices mitigates the impact of issues introduced\n\nthrough the deployment of changes. Plan for unsuccessful changes so that you are able to respond faster if necessary and test and validate the changes you make. Be aware of planned activities\n\nin your environments so that you can manage the risk of changes impacting planned activities.\n\nEmphasize frequent, small, reversible changes to limit the scope of change. This results in faster\n\ntroubleshooting and remediation with the option to roll back a change. It also means you are able\n\nto get the beneﬁt of valuable changes more frequently.\n\nEvaluate the operational readiness of your workload, processes, procedures, and personnel to\n\nunderstand the operational risks related to your workload. Use a consistent process (including\n\nmanual or automated checklists) to know when you are ready to go live with your workload or\n\n77\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\na change. This will also help you to ﬁnd any areas that you must make plans to address. Have\n\nrunbooks that document your routine activities and playbooks that guide your processes for issue resolution. Understand the beneﬁts and risks to make informed decisions to permit changes to\n\nenter production.\n\nAWS allows you to view your entire workload (applications, infrastructure, policy, governance, and\n\noperations) as code. This means you can apply the same engineering discipline that you use for\n\napplication code to every element of your stack and share these across teams or organizations to\n\nmagnify the beneﬁts of development eﬀorts. Use operations as code in the cloud and the ability\n\nto safely experiment to develop your workload, your operations procedures, and practice failure.\n\nUsing CloudFormation allows you to have consistent, templated, sandbox development, test, and\n\nproduction environments with increasing levels of operations control.\n\nInvest in implementing operations activities as code to maximize the productivity of operations\n\npersonnel, minimize error rates, and achieve automated responses. Use “pre-mortems” to anticipate failure and create procedures where appropriate. Apply metadata using Resource Tags\n\nand AWS Resource Groups following a consistent tagging strategy to achieve identiﬁcation of your\n\nresources. Tag your resources for organization, cost accounting, access controls, and targeting the\n\nrunning of automated operations activities. Adopt deployment practices that take advantage of\n\nthe elasticity of the cloud to facilitate development activities, and pre-deployment of systems\n\nfor faster implementations. When you make changes to the checklists you use to evaluate your\n\nworkloads, plan what you will do with live systems that no longer comply.\n\nTopics\n\nImplement observability\n\nDesign for operations\n\nMitigate deployment risks\n\nOperational readiness and change management\n\nImplement observability\n\nImplement observability in your workload so that you can understand its state and make data-\n\ndriven decisions based on business requirements.\n\nObservability goes beyond simple monitoring, providing a comprehensive understanding of a\n\nsystem's internal workings based on its external outputs. Rooted in metrics, logs, and traces,\n\nobservability oﬀers profound insights into system behavior and dynamics. With eﬀective\n\nImplement observability\n\n78\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nobservability, teams can discern patterns, anomalies, and trends, allowing them to proactively\n\naddress potential issues and maintain optimal system health.\n\nIdentifying key performance indicators (KPIs) is pivotal to ensure alignment between monitoring activities and business objectives. This alignment ensures that teams are making data-driven\n\ndecisions using metrics that genuinely matter, optimizing both system performance and business\n\noutcomes.\n\nFurthermore, observability empowers businesses to be proactive rather than reactive. Teams can\n\nunderstand the cause-and-eﬀect relationships within their systems, predicting and preventing\n\nissues rather than just reacting to them. As workloads evolve, it's essential to revisit and reﬁne the\n\nobservability strategy, ensuring it remains relevant and eﬀective.\n\nBest practices\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user experience telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement distributed tracing\n\nOPS04-BP01 Identify key performance indicators\n\nImplementing observability in your workload starts with understanding its state and making\n\ndata-driven decisions based on business requirements. One of the most eﬀective ways to ensure\n\nalignment between monitoring activities and business objectives is by deﬁning and monitoring key\n\nperformance indicators (KPIs).\n\nDesired outcome: Eﬃcient observability practices that are tightly aligned with business objectives, ensuring that monitoring eﬀorts are always in service of tangible business outcomes.\n\nCommon anti-patterns:\n\nUndeﬁned KPIs: Working without clear KPIs can lead to monitoring too much or too little,\n\nmissing vital signals.\n\nStatic KPIs: Not revisiting or reﬁning KPIs as the workload or business objectives evolve.\n\nMisalignment: Focusing on technical metrics that don’t correlate directly with business outcomes\n\nor are harder to correlate with real-world issues.\n\nOPS04-BP01 Identify key performance indicators\n\n79\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nEase of issue identiﬁcation: Business KPIs often surface issues more clearly than technical\n\nmetrics. A dip in a business KPI can pinpoint a problem more eﬀectively than sifting through\n\nnumerous technical metrics.\n\nBusiness alignment: Ensures that monitoring activities directly support business objectives.\n\nEﬃciency: Prioritize monitoring resources and attention on metrics that matter.\n\nProactivity: Recognize and address issues before they have broader business implications.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo eﬀectively deﬁne workload KPIs:\n\n1. Start with business outcomes: Before diving into metrics, understand the desired business\n\noutcomes. Is it increased sales, higher user engagement, or faster response times?\n\n2. Correlate technical metrics with business objectives: Not all technical metrics have a direct impact on business outcomes. Identify those that do, but it's often more straightforward to identify an issue using a business KPI.\n\n3. Use Amazon CloudWatch: Employ CloudWatch to deﬁne and monitor metrics that represent\n\nyour KPIs.\n\n4. Regularly review and update KPIs: As your workload and business evolve, keep your KPIs\n\nrelevant.\n\n5. Involve stakeholders: Involve both technical and business teams in deﬁning and reviewing KPIs.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nthe section called “OPS04-BP02 Implement application telemetry”\n\nthe section called “OPS04-BP03 Implement user experience telemetry”\n\nthe section called “OPS04-BP04 Implement dependency telemetry”\n\nthe section called “OPS04-BP05 Implement distributed tracing”\n\nOPS04-BP01 Identify key performance indicators\n\n80\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nAWS Observability Best Practices\n\nCloudWatch User Guide\n\nAWS Observability Skill Builder Course\n\nRelated videos:\n\nDeveloping an observability strategy\n\nRelated examples:\n\nOne Observability Workshop\n\nOPS04-BP02 Implement application telemetry\n\nApplication telemetry serves as the foundation for observability of your workload. It's crucial\n\nto emit telemetry that oﬀers actionable insights into the state of your application and the\n\nachievement of both technical and business outcomes. From troubleshooting to measuring the\n\nimpact of a new feature or ensuring alignment with business key performance indicators (KPIs),\n\napplication telemetry informs the way you build, operate, and evolve your workload.\n\nMetrics, logs, and traces form the three primary pillars of observability. These serve as diagnostic\n\ntools that describe the state of your application. Over time, they assist in creating baselines and\n\nidentifying anomalies. However, to ensure alignment between monitoring activities and business\n\nobjectives, it's pivotal to deﬁne and monitor KPIs. Business KPIs often make it easier to identify\n\nissues compared to technical metrics alone.\n\nOther telemetry types, like real user monitoring (RUM) and synthetic transactions, complement\n\nthese primary data sources. RUM oﬀers insights into real-time user interactions, whereas synthetic\n\ntransactions simulate potential user behaviors, helping detect bottlenecks before real users\n\nencounter them.\n\nDesired outcome: Derive actionable insights into the performance of your workload. These insights allow you to make proactive decisions about performance optimization, achieve increased workload stability, streamline CI/CD processes, and utilize resources eﬀectively.\n\nCommon anti-patterns:\n\nOPS04-BP02 Implement application telemetry\n\n81\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIncomplete observability: Neglecting to incorporate observability at every layer of the\n\nworkload, resulting in blind spots that can obscure vital system performance and behavior insights.\n\nFragmented data view: When data is scattered across multiple tools and systems, it becomes\n\nchallenging to maintain a holistic view of your workload's health and performance.\n\nUser-reported issues: A sign that proactive issue detection through telemetry and business KPI\n\nmonitoring is lacking.\n\nBeneﬁts of establishing this best practice:\n\nInformed decision-making: With insights from telemetry and business KPIs, you can make data-\n\ndriven decisions.\n\nImproved operational eﬃciency: Data-driven resource utilization leads to cost-eﬀectiveness.\n\nEnhanced workload stability: Faster detection and resolution of issues leading to improved\n\nuptime.\n\nStreamlined CI/CD processes: Insights from telemetry data facilitate reﬁnement of processes\n\nand reliable code delivery.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo implement application telemetry for your workload, use AWS services like Amazon CloudWatch\n\nand AWS X-Ray. Amazon CloudWatch provides a comprehensive suite of monitoring tools, allowing\n\nyou to observe your resources and applications in AWS and on-premises environments. It collects,\n\ntracks, and analyzes metrics, consolidates and monitors log data, and responds to changes in your\n\nresources, enhancing your understanding of how your workload operates. In tandem, AWS X-Ray\n\nlets you trace, analyze, and debug your applications, giving you a deep understanding of your workload's behavior. With features like service maps, latency distributions, and trace timelines,\n\nAWS X-Ray provides insights into your workload's performance and the bottlenecks aﬀecting it.\n\nImplementation steps\n\n1. Identify what data to collect: Ascertain the essential metrics, logs, and traces that would oﬀer\n\nsubstantial insights into your workload's health, performance, and behavior.\n\n2. Deploy the CloudWatch agent: The CloudWatch agent is instrumental in procuring system and application metrics and logs from your workload and its underlying infrastructure. The\n\nOPS04-BP02 Implement application telemetry\n\n82\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCloudWatch agent can also be used to collect OpenTelemetry or X-Ray traces and send them to\n\nX-Ray.\n\n3. Implement anomaly detection for logs and metrics: Use CloudWatch Logs anomaly detection\n\nand CloudWatch Metrics anomaly detection to automatically identify unusual activities in\n\nyour application's operations. These tools use machine learning algorithms to detect and alert\n\non anomalies, which enanhces your monitoring capabilities and speeds up response time to\n\npotential disruptions or security threats. Set up these features to proactively manage application\n\nhealth and security.\n\n4. Secure sensitive log data: Use Amazon CloudWatch Logs data protection to mask sensitive information within your logs. This feature helps maintain privacy and compliance through automatic detection and masking of sensitive data before it is accessed. Implement data\n\nmasking to securely handle and protect sensitive details such as personally identiﬁable\n\ninformation (PII).\n\n5. Deﬁne and monitor business KPIs: Establish custom metrics that align with your business\n\noutcomes.\n\n6. Instrument your application with AWS X-Ray: In addition to deploying the CloudWatch agent, it's crucial to instrument your application to emit trace data. This process can provide further insights into your workload's behavior and performance.\n\n7. Standardize data collection across your application: Standardize data collection practices across your entire application. Uniformity aids in correlating and analyzing data, providing a comprehensive view of your application's behavior.\n\n8. Implement cross-account observability: Enhance monitoring eﬃciency across multiple AWS accounts with Amazon CloudWatch cross-account observability. With this feature, you can consolidate metrics, logs, and alarms from diﬀerent accounts into a single view, which simpliﬁes\n\nmanagement and improves response times for identiﬁed issues across your organization's AWS\n\nenvironment.\n\n9. Analyze and act on the data: Once data collection and normalization are in place, use Amazon CloudWatch for metrics and logs analysis, and AWS X-Ray for trace analysis. Such analysis can yield crucial insights into your workload's health, performance, and behavior, guiding your\n\ndecision-making process.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS04-BP02 Implement application telemetry\n\n83",
      "page_number": 78
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 89-97)",
      "start_page": 89,
      "end_page": 97,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS04-BP01 Deﬁne workload KPIs\n\nOPS04-BP03 Implement user activity telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement transaction traceability\n\nRelated documents:\n\nAWS Observability Best Practices\n\nCloudWatch User Guide\n\nAWS X-Ray Developer Guide\n\nInstrumenting distributed systems for operational visibility\n\nAWS Observability Skill Builder Course\n\nWhat's New with Amazon CloudWatch\n\nWhat's new with AWS X-Ray\n\nRelated videos:\n\nAWS re:Invent 2022 - Observability best practices at Amazon\n\nAWS re:Invent 2022 - Developing an observability strategy\n\nRelated examples:\n\nOne Observability Workshop\n\nAWS Solutions Library: Application Monitoring with Amazon CloudWatch\n\nOPS04-BP03 Implement user experience telemetry\n\nGaining deep insights into customer experiences and interactions with your application is crucial.\n\nReal user monitoring (RUM) and synthetic transactions serve as powerful tools for this purpose.\n\nRUM provides data about real user interactions granting an unﬁltered perspective of user\n\nsatisfaction, while synthetic transactions simulate user interactions, helping in detecting potential\n\nissues even before they impact real users.\n\nDesired outcome: A holistic view of the customer experience, proactive detection of issues, and optimization of user interactions to deliver seamless digital experiences.\n\nOPS04-BP03 Implement user experience telemetry\n\n84\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nApplications without real user monitoring (RUM):\n\nDelayed issue detection: Without RUM, you might not become aware of performance\n\nbottlenecks or issues until users complain. This reactive approach can lead to customer\n\ndissatisfaction.\n\nLack of user experience insights: Not using RUM means you lose out on crucial data that\n\nshows how real users interact with your application, limiting your ability to optimize the user\n\nexperience.\n\nApplications without synthetic transactions:\n\nMissed edge cases: Synthetic transactions help you test paths and functions that might not be\n\nfrequently used by typical users but are critical to certain business functions. Without them,\n\nthese paths could malfunction and go unnoticed.\n\nChecking for issues when the application is not being used: Regular synthetic testing can\n\nsimulate times when real users aren't actively interacting with your application, ensuring the\n\nsystem always functions correctly.\n\nBeneﬁts of establishing this best practice:\n\nProactive issue detection: Identify and address potential issues before they impact real users.\n\nOptimized user experience: Continuous feedback from RUM aids in reﬁning and enhancing the\n\noverall user experience.\n\nInsights on device and browser performance: Understand how your application performs across\n\nvarious devices and browsers, enabling further optimization.\n\nValidated business workﬂows: Regular synthetic transactions ensure that core functionalities and\n\ncritical paths remain operational and eﬃcient.\n\nEnhanced application performance: Leverage insights gathered from real user data to improve\n\napplication responsiveness and reliability.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo leverage RUM and synthetic transactions for user activity telemetry, AWS oﬀers services like\n\nAmazon CloudWatch RUM and Amazon CloudWatch Synthetics. Metrics, logs, and traces, coupled\n\nOPS04-BP03 Implement user experience telemetry\n\n85\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nwith user activity data, provide a comprehensive view of both the application's operational state\n\nand the user experience.\n\nImplementation steps\n\n1. Deploy Amazon CloudWatch RUM: Integrate your application with CloudWatch RUM to collect,\n\nanalyze, and present real user data.\n\na. Use the CloudWatch RUM JavaScript library to integrate RUM with your application.\n\nb. Set up dashboards to visualize and monitor real user data.\n\n2. Conﬁgure CloudWatch Synthetics: Create canaries, or scripted routines, that simulate user\n\ninteractions with your application.\n\na. Deﬁne critical application workﬂows and paths.\n\nb. Design canaries using CloudWatch Synthetics scripts to simulate user interactions for these\n\npaths.\n\nc. Schedule and monitor canaries to run at speciﬁed intervals, ensuring consistent performance\n\nchecks.\n\n3. Analyze and act on data: Utilize data from RUM and synthetic transactions to gain insights and take corrective measures when anomalies are detected. Use CloudWatch dashboards and alarms to stay informed.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement distributed tracing\n\nRelated documents:\n\nAmazon CloudWatch RUM Guide\n\nAmazon CloudWatch Synthetics Guide\n\nOPS04-BP03 Implement user experience telemetry\n\n86\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated videos:\n\nOptimize applications through end user insights with Amazon CloudWatch RUM\n\nAWS on Air ft. Real-User Monitoring for Amazon CloudWatch\n\nRelated examples:\n\nOne Observability Workshop\n\nGit Repository for Amazon CloudWatch RUM Web Client\n\nUsing Amazon CloudWatch Synthetics to measure page load time\n\nOPS04-BP04 Implement dependency telemetry\n\nDependency telemetry is essential for monitoring the health and performance of the external\n\nservices and components your workload relies on. It provides valuable insights into reachability,\n\ntimeouts, and other critical events related to dependencies such as DNS, databases, or third-\n\nparty APIs. When you instrument your application to emit metrics, logs, and traces about these\n\ndependencies, you gain a clearer understanding of potential bottlenecks, performance issues, or\n\nfailures that might impact your workload.\n\nDesired outcome: Ensure that the dependencies your workload relies on are performing as expected, allowing you to proactively address issues and ensure optimal workload performance.\n\nCommon anti-patterns:\n\nOverlooking external dependencies: Focusing only on internal application metrics while\n\nneglecting metrics related to external dependencies.\n\nLack of proactive monitoring: Waiting for issues to arise instead of continuously monitoring\n\ndependency health and performance.\n\nSiloed monitoring: Using multiple, disparate monitoring tools which can result in fragmented\n\nand inconsistent views of dependency health.\n\nBeneﬁts of establishing this best practice:\n\nImproved workload reliability: By ensuring that external dependencies are consistently\n\navailable and performing optimally.\n\nOPS04-BP04 Implement dependency telemetry\n\n87\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nFaster issue detection and resolution: Proactively identifying and addressing issues with\n\ndependencies before they impact the workload.\n\nComprehensive view: Gaining a holistic view of both internal and external components that\n\ninﬂuence workload health.\n\nEnhanced workload scalability: By understanding the scalability limits and performance\n\ncharacteristics of external dependencies.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplement dependency telemetry by starting with identifying the services, infrastructure, and\n\nprocesses that your workload depends on. Quantify what good conditions look like when those\n\ndependencies are functioning as expected, and then determine what data will be needed to\n\nmeasure those. With that information you can craft dashboards and alerts that provide insights to\n\nyour operations teams on the state of those dependencies. Use AWS tools to discover and quantify\n\nthe impacts when dependencies cannot deliver as needed. Continually revisit your strategy to\n\naccount for changes in priorities, goals, and gained insights.\n\nImplementation steps\n\nTo implement dependency telemetry eﬀectively:\n\n1. Identify external dependencies: Collaborate with stakeholders to pinpoint the external\n\ndependencies your workload relies on. External dependencies can encompass services like\n\nexternal databases, third-party APIs, network connectivity routes to other environments, and\n\nDNS services. The ﬁrst step towards eﬀective dependency telemetry is being comprehensive in\n\nunderstanding what those dependencies are.\n\n2. Develop a monitoring strategy: Once you have a clear picture of your external dependencies, architect a monitoring strategy tailored to them. This involves understanding the criticality of each dependency, its expected behavior, and any associated service-level agreements or targets\n\n(SLA or SLTs). Set up proactive alerts to notify you of status changes or performance deviations.\n\n3. Use network monitoring: Use Internet Monitor and Network Monitor, which provide\n\ncomprehensive insights into global internet and network conditions. These tools help you\n\nunderstand and respond to outages, disruptions, or performance degradations that aﬀect your\n\nexternal dependencies.\n\nOPS04-BP04 Implement dependency telemetry\n\n88\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Stay informed with AWS Health: AWS Health is the authoritative source of information about the health of your AWS Cloud resources. Use AWS Health to visualize and receive notiﬁcations about any current service events and upcoming changes, such as planned lifecycle events, so you can take steps to mitigate impacts.\n\na. Create purpose-ﬁt AWS Health event notiﬁcations to e-mail and chat channels through AWS\n\nUser Notiﬁcations, and integrate programatically with your monitoring and alerting tools\n\nthrough Amazon EventBridge or the AWS Health API.\n\nb. Plan and track progress on health events that require action by integrating with change\n\nmanagement or ITSM tools (like Jira or ServiceNow) that you may already use through\n\nAmazon EventBridge or the AWS Health API.\n\nc. If you use AWS Organizations, enable organization view for AWS Health to aggregate AWS\n\nHealth events across accounts.\n\n5. Instrument your application with AWS X-Ray: AWS X-Ray provides insights into how\n\napplications and their underlying dependencies are performing. By tracing requests from start\n\nto end, you can identify bottlenecks or failures in the external services or components your\n\napplication relies on.\n\n6. Use Amazon DevOps Guru: This machine learning-driven service identiﬁes operational issues,\n\npredicts when critical issues might occur, and recommends speciﬁc actions to take. It's invaluable\n\nfor gaining insights into dependencies and ensuring they're not the source of operational\n\nproblems.\n\n7. Monitor regularly: Continually monitor metrics and logs related to external dependencies. Set\n\nup alerts for unexpected behavior or degraded performance.\n\n8. Validate after changes: Whenever there's an update or change in any of the external\n\ndependencies, validate their performance and check their alignment with your application's\n\nrequirements.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Deﬁne workload KPIs\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user activity telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\n89\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS04-BP05 Implement transaction traceability\n\nOP08-BP04 Create actionable alerts\n\nRelated documents:\n\nAmazon Personal AWS Health Dashboard User Guide\n\nAWS Internet Monitor User Guide\n\nAWS X-Ray Developer Guide\n\nAWS DevOps Guru User Guide\n\nRelated videos:\n\nVisibility into how internet issues impact app performance\n\nIntroduction to Amazon DevOps Guru\n\nManage resource lifecycle events at scale with AWS Health\n\nRelated examples:\n\nAWS Health Aware\n\nUsing Tag-Based Filtering to Manage AWS Health Monitoring and Alerting at Scale\n\nOPS04-BP05 Implement distributed tracing\n\nDistributed tracing oﬀers a way to monitor and visualize requests as they traverse through various\n\ncomponents of a distributed system. By capturing trace data from multiple sources and analyzing\n\nit in a uniﬁed view, teams can better understand how requests ﬂow, where bottlenecks exist, and where optimization eﬀorts should focus.\n\nDesired outcome: Achieve a holistic view of requests ﬂowing through your distributed system, allowing for precise debugging, optimized performance, and improved user experiences.\n\nCommon anti-patterns:\n\nInconsistent instrumentation: Not all services in a distributed system are instrumented for\n\ntracing.\n\nOPS04-BP05 Implement distributed tracing\n\n90\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIgnoring latency: Only focusing on errors and not considering the latency or gradual\n\nperformance degradations.\n\nBeneﬁts of establishing this best practice:\n\nComprehensive system overview: Visualizing the entire path of requests, from entry to exit.\n\nEnhanced debugging: Quickly identifying where failures or performance issues occur.\n\nImproved user experience: Monitoring and optimizing based on actual user data, ensuring the\n\nsystem meets real-world demands.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nBegin by identifying all of the elements of your workload that require instrumentation. Once all\n\ncomponents are accounted for, leverage tools such as AWS X-Ray and OpenTelemetry to gather\n\ntrace data for analysis with tools like X-Ray and Amazon CloudWatch ServiceLens Map. Engage\n\nin regular reviews with developers, and supplement these discussions with tools like Amazon\n\nDevOps Guru, X-Ray Analytics and X-Ray Insights to help uncover deeper ﬁndings. Establish alerts\n\nfrom trace data to notify when outcomes, as deﬁned in the workload monitoring plan, are at risk.\n\nImplementation steps\n\nTo implement distributed tracing eﬀectively:\n\n1. Adopt AWS X-Ray: Integrate X-Ray into your application to gain insights into its behavior,\n\nunderstand its performance, and pinpoint bottlenecks. Utilize X-Ray Insights for automatic trace\n\nanalysis.\n\n2. Instrument your services: Verify that every service, from an AWS Lambda function to an EC2 instance, sends trace data. The more services you instrument, the clearer the end-to-end view.\n\n3. Incorporate CloudWatch Real User Monitoring and synthetic monitoring: Integrate Real User\n\nMonitoring (RUM) and synthetic monitoring with X-Ray. This allows for capturing real-world user\n\nexperiences and simulating user interactions to identify potential issues.\n\n4. Use the CloudWatch agent: The agent can send traces from either X-Ray or OpenTelemetry,\n\nenhancing the depth of insights obtained.\n\n5. Use Amazon DevOps Guru: DevOps Guru uses data from X-Ray, CloudWatch, AWS Conﬁg, and\n\nAWS CloudTrail to provide actionable recommendations.\n\nOPS04-BP05 Implement distributed tracing\n\n91\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n6. Analyze traces: Regularly review the trace data to discern patterns, anomalies, or bottlenecks\n\nthat might impact your application's performance.\n\n7. Set up alerts: Conﬁgure alarms in CloudWatch for unusual patterns or extended latencies,\n\nallowing proactive issue addressing.\n\n8. Continuous improvement: Revisit your tracing strategy as services are added or modiﬁed to\n\ncapture all relevant data points.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user experience telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nRelated documents:\n\nAWS X-Ray Developer Guide\n\nAmazon CloudWatch agent User Guide\n\nAmazon DevOps Guru User Guide\n\nRelated videos:\n\nUse AWS X-Ray Insights\n\nAWS on Air ft. Observability: Amazon CloudWatch and AWS X-Ray\n\nRelated examples:\n\nInstrumenting your application for AWS X-Ray\n\nOPS04-BP05 Implement distributed tracing\n\n92",
      "page_number": 89
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 98-105)",
      "start_page": 98,
      "end_page": 105,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesign for operations\n\nAdopt approaches that improve the ﬂow of changes into production and that help refactoring, fast\n\nfeedback on quality, and bug ﬁxing. These accelerate beneﬁcial changes entering production, limit\n\nissues deployed, and provide rapid identiﬁcation and remediation of issues introduced through\n\ndeployment activities.\n\nIn AWS, you can view your entire workload (applications, infrastructure, policy, governance, and\n\noperations) as code. It can all be deﬁned in and updated using code. This means you can apply the\n\nsame engineering discipline that you use for application code to every element of your stack.\n\nBest practices\n\nOPS05-BP01 Use version control\n\nOPS05-BP02 Test and validate changes\n\nOPS05-BP03 Use conﬁguration management systems\n\nOPS05-BP04 Use build and deployment management systems\n\nOPS05-BP05 Perform patch management\n\nOPS05-BP06 Share design standards\n\nOPS05-BP07 Implement practices to improve code quality\n\nOPS05-BP08 Use multiple environments\n\nOPS05-BP09 Make frequent, small, reversible changes\n\nOPS05-BP10 Fully automate integration and deployment\n\nOPS05-BP01 Use version control\n\nUse version control to activate tracking of changes and releases.\n\nMany AWS services oﬀer version control capabilities. Use a revision or source control system\n\nsuch as Git to manage code and other artifacts such as version-controlled AWS CloudFormation\n\ntemplates of your infrastructure.\n\nDesired outcome: Your teams collaborate on code. When merged, the code is consistent and no changes are lost. Errors are easily reverted through correct versioning.\n\nCommon anti-patterns:\n\nDesign for operations\n\n93\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou have been developing and storing your code on your workstation. You have had an\n\nunrecoverable storage failure on the workstation and your code is lost.\n\nAfter overwriting the existing code with your changes, you restart your application and it is no\n\nlonger operable. You are unable to revert the change.\n\nYou have a write lock on a report ﬁle that someone else needs to edit. They contact you asking\n\nthat you stop work on it so that they can complete their tasks.\n\nYour research team has been working on a detailed analysis that shapes your future work.\n\nSomeone has accidentally saved their shopping list over the ﬁnal report. You are unable to revert\n\nthe change and have to recreate the report.\n\nBeneﬁts of establishing this best practice: By using version control capabilities you can easily revert to known good states and previous versions, and limit the risk of assets being lost.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nMaintain assets in version controlled repositories. Doing so supports tracking changes, deploying\n\nnew versions, detecting changes to existing versions, and reverting to prior versions (for example,\n\nrolling back to a known good state in the event of a failure). Integrate the version control\n\ncapabilities of your conﬁguration management systems into your procedures.\n\nResources\n\nRelated best practices:\n\nOPS05-BP04 Use build and deployment management systems\n\nRelated videos:\n\nAWS re:Invent 2023 - How Lockheed Martin builds software faster, powered by DevSecOps\n\nAWS re:Invent 2023 - How GitHub operationalizes AI for team collaboration and productivity\n\nOPS05-BP02 Test and validate changes\n\nEvery change deployed must be tested to avoid errors in production. This best practice is focused\n\non testing changes from version control to artifact build. Besides application code changes, testing\n\nOPS05-BP02 Test and validate changes\n\n94\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nshould include infrastructure, conﬁguration, security controls, and operations procedures. Testing\n\ntakes many forms, from unit tests to software component analysis (SCA). Move tests further to the left in the software integration and delivery process results in higher certainty of artifact quality.\n\nYour organization must develop testing standards for all software artifacts. Automated tests\n\nreduce toil and avoid manual test errors. Manual tests may be necessary in some cases. Developers\n\nmust have access to automated test results to create feedback loops that improve software quality.\n\nDesired outcome: Your software changes are tested before they are delivered. Developers have access to test results and validations. Your organization has a testing standard that applies to all\n\nsoftware changes.\n\nCommon anti-patterns:\n\nYou deploy a new software change without any tests. It fails to run in production, which leads to\n\nan outage.\n\nNew security groups are deployed with AWS CloudFormation without being tested in a pre-\n\nproduction environment. The security groups make your app unreachable for your customers.\n\nA method is modiﬁed but there are no unit tests. The software fails when it is deployed to\n\nproduction.\n\nBeneﬁts of establishing this best practice: Change fail rate of software deployments are reduced. Software quality is improved. Developers have increased awareness on the viability of their\n\ncode. Security policies can be rolled out with conﬁdence to support organization's compliance.\n\nInfrastructure changes such as automatic scaling policy updates are tested in advance to meet\n\ntraﬃc needs.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTesting is done on all changes, from application code to infrastructure, as part of your continuous\n\nintegration practice. Test results are published so that developers have fast feedback. Your\n\norganization has a testing standard that all changes must pass.\n\nUse the power of generative AI with Amazon Q Developer to improve developer productivity\n\nand code quality. Amazon Q Developer includes generation of code suggestions (based on large\n\nlanguage models), production of unit tests (including boundary conditions), and code security\n\nenhancements through detection and remediation of security vulnerabilities.\n\nOPS05-BP02 Test and validate changes\n\n95\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCustomer example\n\nAs part of their continuous integration pipeline, AnyCompany Retail conducts several types of tests\n\non all software artifacts. They practice test driven development so all software has unit tests. Once\n\nthe artifact is built, they run end-to-end tests. After this ﬁrst round of tests is complete, they run a\n\nstatic application security scan, which looks for known vulnerabilities. Developers receive messages\n\nas each testing gate is passed. Once all tests are complete, the software artifact is stored in an\n\nartifact repository.\n\nImplementation steps\n\n1. Work with stakeholders in your organization to develop a testing standard for software artifacts.\n\nWhat standard tests should all artifacts pass? Are there compliance or governance requirements\n\nthat must be included in the test coverage? Do you need to conduct code quality tests? When tests complete, who needs to know?\n\n1. The AWS Deployment Pipeline Reference Architecture contains an authoritative list of types\n\nof tests that can be conducted on software artifacts as part of an integration pipeline.\n\n2. Instrument your application with the necessary tests based on your software testing standard.\n\nEach set of tests should complete in under ten minutes. Tests should run as part of an\n\nintegration pipeline.\n\na. Use Amazon Q Developer, a generative AI tool that can help create unit test cases (including\n\nboundary conditions), generate functions using code and comments, and implement well-\n\nknown algorithms.\n\nb. Use Amazon CodeGuru Reviewer to test your application code for defects.\n\nc. You can use AWS CodeBuild to conduct tests on software artifacts.\n\nd. AWS CodePipeline can orchestrate your software tests into a pipeline.\n\nResources\n\nRelated best practices:\n\nOPS05-BP01 Use version control\n\nOPS05-BP06 Share design standards\n\nOPS05-BP07 Implement practices to improve code quality\n\nOPS05-BP10 Fully automate integration and deployment\n\nOPS05-BP02 Test and validate changes\n\n96\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nAdopt a test-driven development approach\n\nAccelerate your Software Development Lifecycle with Amazon Q\n\nAmazon Q Developer, now generally available, includes previews of new capabilities to reimagine\n\ndeveloper experience\n\nThe Ultimate Cheat Sheet for Using Amazon Q Developer in Your IDE\n\nShift-Left Workload, leveraging AI for Test Creation\n\nAmazon Q Developer Center\n\n10 ways to build applications faster with Amazon CodeWhisperer\n\nLooking beyond code coverage with Amazon CodeWhisperer\n\nBest Practices for Prompt Engineering with Amazon CodeWhisperer\n\nAutomated AWS CloudFormation Testing Pipeline with TaskCat and CodePipeline\n\nBuilding end-to-end AWS DevSecOps CI/CD pipeline with open source SCA, SAST, and DAST\n\ntools\n\nGetting started with testing serverless applications\n\nMy CI/CD pipeline is my release captain\n\nPracticing Continuous Integration and Continuous Delivery on AWS Whitepaper\n\nRelated videos:\n\nImplement an API with Amazon Q Developer Agent for Software Development\n\nInstalling, Conﬁguring, & Using Amazon Q Developer with JetBrains IDEs (How-to)\n\nMastering the art of Amazon CodeWhisperer - YouTube playlist\n\nAWS re:Invent 2020: Testable infrastructure: Integration testing on AWS\n\nAWS Summit ANZ 2021 - Driving a test-ﬁrst strategy with CDK and test driven development\n\nTesting Your Infrastructure as Code with AWS CDK\n\nRelated resources:\n\nAWS Deployment Pipeline Reference Architecture - Application\n\nAWS Kubernetes DevSecOps Pipeline\n\nRun unit tests for a Node.js application from GitHub by using AWS CodeBuild\n\nOPS05-BP02 Test and validate changes\n\n97\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUse Serverspec for test-driven development of infrastructure code\n\nRelated services:\n\nAmazon Q Developer\n\nAmazon CodeGuru Reviewer\n\nAWS CodeBuild\n\nAWS CodePipeline\n\nOPS05-BP03 Use conﬁguration management systems\n\nUse conﬁguration management systems to make and track conﬁguration changes. These systems reduce errors caused by manual processes and reduce the level of eﬀort to deploy changes.\n\nStatic conﬁguration management sets values when initializing a resource that are expected\n\nto remain consistent throughout the resource’s lifetime. Dynamic conﬁguration management\n\nsets values at initialization that can or are expected to change during the lifetime of a resource.\n\nFor example, you could set a feature toggle to activate functionality in your code through a\n\nconﬁguration change, or change the level of log detail during an incident.\n\nConﬁgurations should be deployed in a known and consistent state. You should use automated\n\ninspection to continually monitor resource conﬁgurations across environments and regions.\n\nThese controls should be deﬁned as code and management automated to ensure rules are\n\nconsistently appplied across environments. Changes to conﬁgurations should be updated through\n\nagreed change control procedures and applied consistently, honoring version control. Application\n\nconﬁguration should be managed independently of application and infrastructure code. This allows\n\nfor consistent deployment across multiple environments. Conﬁguration changes do not result in\n\nrebuilding or redeploying the application.\n\nDesired outcome: You conﬁgure, validate, and deploy as part of your continuous integration, continuous delivery (CI/CD) pipeline. You monitor to validate conﬁgurations are correct. This\n\nminimizes any impact to end users and customers.\n\nCommon anti-patterns:\n\nYou manually update the web server conﬁguration across your ﬂeet and a number of servers\n\nbecome unresponsive due to update errors.\n\nOPS05-BP03 Use conﬁguration management systems\n\n98\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou manually update your application server ﬂeet over the course of many hours. The\n\ninconsistency in conﬁguration during the change causes unexpected behaviors.\n\nSomeone has updated your security groups and your web servers are no longer accessible.\n\nWithout knowledge of what was changed you spend signiﬁcant time investigating the issue\n\nextending your time to recovery.\n\nYou push a pre-production conﬁguration into production through CI/CD without validation. You\n\nexpose users and customers to incorrect data and services.\n\nBeneﬁts of establishing this best practice: Adopting conﬁguration management systems reduces the level of eﬀort to make and track changes, and the frequency of errors caused by manual\n\nprocedures. Conﬁguration management systems provide assurances with regards to governance,\n\ncompliance, and regulatory requirements.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nConﬁguration management systems are used to track and implement changes to application and\n\nenvironment conﬁgurations. Conﬁguration management systems are also used to reduce errors\n\ncaused by manual processes, make conﬁguration changes repeatable and auditable, and reduce the\n\nlevel of eﬀort.\n\nOn AWS, you can use AWS Conﬁg to continually monitor your AWS resource conﬁgurations\n\nacross accounts and Regions. It helps you to track their conﬁguration history, understand how a\n\nconﬁguration change would aﬀect other resources, and audit them against expected or desired\n\nconﬁgurations using AWS Conﬁg Rules and AWS Conﬁg Conformance Packs.\n\nFor dynamic conﬁgurations in your applications running on Amazon EC2 instances, AWS Lambda,\n\ncontainers, mobile applications, or IoT devices, you can use AWS AppConﬁg to conﬁgure, validate, deploy, and monitor them across your environments.\n\nImplementation steps\n\n1. Identify conﬁguration owners.\n\na. Make conﬁgurations owners aware of any compliance, governance, or regulatory needs.\n\n2. Identify conﬁguration items and deliverables.\n\na. Conﬁguration items are all application and environmental conﬁgurations aﬀected by a\n\ndeployment within your CI/CD pipeline.\n\nOPS05-BP03 Use conﬁguration management systems\n\n99\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nb. Deliverables include success criteria, validation, and what to monitor.\n\n3. Select tools for conﬁguration management based on your business requirements and delivery\n\npipeline.\n\n4. Consider weighted deployments such as canary deployments for signiﬁcant conﬁguration\n\nchanges to minimize the impact of incorrect conﬁgurations.\n\n5. Integrate your conﬁguration management into your CI/CD pipeline.\n\n6. Validate all changes pushed.\n\nResources\n\nRelated best practices:\n\nOPS06-BP01 Plan for unsuccessful changes\n\nOPS06-BP02 Test deployments\n\nOPS06-BP03 Employ safe deployment strategies\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nAWS Control Tower\n\nAWS Landing Zone Accelerator\n\nAWS Conﬁg\n\nWhat is AWS Conﬁg?\n\nAWS AppConﬁg\n\nWhat is AWS CloudFormation?\n\nAWS Developer Tools\n\nAWS CodeBuild\n\nAWS CodePipeline\n\nAWS CodeDeploy\n\nRelated videos:\n\nAWS re:Invent 2022 - Proactive governance and compliance for AWS workloads\n\nOPS05-BP03 Use conﬁguration management systems\n\n100",
      "page_number": 98
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 106-113)",
      "start_page": 106,
      "end_page": 113,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS re:Invent 2020: Achieve compliance as code using AWS Conﬁg\n\nManage and Deploy Application Conﬁgurations with AWS AppConﬁg\n\nOPS05-BP04 Use build and deployment management systems\n\nUse build and deployment management systems. These systems reduce errors caused by manual\n\nprocesses and reduce the level of eﬀort to deploy changes.\n\nIn AWS, you can build continuous integration/continuous deployment (CI/CD) pipelines using\n\nservices such as AWS Developer Tools (for example, AWS CodeBuild, AWS CodePipeline, and AWS\n\nCodeDeploy).\n\nDesired outcome: Your build and deployment management systems support your organization's continuous integration continuous delivery (CI/CD) system that provide capabilities for automating\n\nsafe rollouts with the correct conﬁgurations.\n\nCommon anti-patterns:\n\nAfter compiling your code on your development system, you copy the executable onto your\n\nproduction systems and it fails to start. The local log ﬁles indicates that it has failed due to\n\nmissing dependencies.\n\nYou successfully build your application with new features in your development environment and\n\nprovide the code to quality assurance (QA). It fails QA because it is missing static assets.\n\nOn Friday, after much eﬀort, you successfully built your application manually in your\n\ndevelopment environment including your newly coded features. On Monday, you are unable to\n\nrepeat the steps that allowed you to successfully build your application.\n\nYou perform the tests you have created for your new release. Then you spend the next week\n\nsetting up a test environment and performing all the existing integration tests followed by\n\nthe performance tests. The new code has an unacceptable performance impact and must be\n\nredeveloped and then retested.\n\nBeneﬁts of establishing this best practice: By providing mechanisms to manage build and deployment activities you reduce the level of eﬀort to perform repetitive tasks, free your team\n\nmembers to focus on their high value creative tasks, and limit the introduction of error from manual procedures.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS05-BP04 Use build and deployment management systems\n\n101\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nBuild and deployment management systems are used to track and implement change, reduce\n\nerrors caused by manual processes, and reduce the level of eﬀort required for safe deployments.\n\nFully automate the integration and deployment pipeline from code check-in through build,\n\ntesting, deployment, and validation. This reduces lead time, decreases cost, encourages increased\n\nfrequency of change, reduces the level of eﬀort, and increases collaboration.\n\nImplementation steps\n\nDiagram showing a CI/CD pipeline using AWS CodePipeline and related services\n\n1. Use a version control system to store and manage assets (such as documents, source code, and\n\nbinary ﬁles).\n\n2. Use CodeBuild to compile your source code, runs unit tests, and produces artifacts that are ready\n\nto deploy.\n\n3. Use CodeDeploy as a deployment service that automates application deployments to Amazon\n\nEC2 instances, on-premises instances, serverless AWS Lambda functions, or Amazon ECS.\n\n4. Monitor your deployments.\n\nOPS05-BP04 Use build and deployment management systems\n\n102\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nAWS Developer Tools\n\nWhat is AWS CodeBuild?\n\nAWS CodeBuild\n\nWhat is AWS CodeDeploy?\n\nRelated videos:\n\nAWS re:Invent 2022 - AWS Well-Architected best practices for DevOps on AWS\n\nOPS05-BP05 Perform patch management\n\nPerform patch management to gain features, address issues, and remain compliant with\n\ngovernance. Automate patch management to reduce errors caused by manual processes, scale, and\n\nreduce the level of eﬀort to patch.\n\nPatch and vulnerability management are part of your beneﬁt and risk management activities. It is\n\npreferable to have immutable infrastructures and deploy workloads in veriﬁed known good states.\n\nWhere that is not viable, patching in place is the remaining option.\n\nAWS Health is the authoritative source of information about planned lifecycle events and other\n\naction-required events that aﬀect the health of your AWS Cloud resources. You should be aware of\n\nupcoming changes and updates that should be performed. Major planned lifecycle events are sent\n\nat least six months in advance.\n\nAmazon EC2 Image Builder provides pipelines to update machine images. As a part of patch\n\nmanagement, consider Amazon Machine Images (AMIs) using an AMI image pipeline or container\n\nimages with a Docker image pipeline, while AWS Lambda provides patterns for custom runtimes\n\nand additional libraries to remove vulnerabilities.\n\nOPS05-BP05 Perform patch management\n\n103\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou should manage updates to Amazon Machine Images for Linux or Windows Server images using\n\nAmazon EC2 Image Builder. You can use Amazon Elastic Container Registry (Amazon ECR) with your existing pipeline to manage Amazon ECS images and manage Amazon EKS images. Lambda\n\nincludes version management features.\n\nPatching should not be performed on production systems without ﬁrst testing in a safe\n\nenvironment. Patches should only be applied if they support an operational or business outcome.\n\nOn AWS, you can use AWS Systems Manager Patch Manager to automate the process of patching\n\nmanaged systems and schedule the activity using Systems Manager Maintenance Windows.\n\nDesired outcome: Your AMI and container images are patched, up-to-date, and ready for launch. You are able to track the status of all deployed images and know patch compliance. You are able to\n\nreport on current status and have a process to meet your compliance needs.\n\nCommon anti-patterns:\n\nYou are given a mandate to apply all new security patches within two hours resulting in multiple\n\noutages due to application incompatibility with patches.\n\nAn unpatched library results in unintended consequences as unknown parties use vulnerabilities\n\nwithin it to access your workload.\n\nYou patch the developer environments automatically without notifying the developers. You\n\nreceive multiple complaints from the developers that their environment cease to operate as\n\nexpected.\n\nYou have not patched the commercial oﬀ-the-shelf software on a persistent instance. When\n\nyou have an issue with the software and contact the vendor, they notify you that version is not\n\nsupported and you have to patch to a speciﬁc level to receive any assistance.\n\nA recently released patch for the encryption software you used has signiﬁcant performance\n\nimprovements. Your unpatched system has performance issues that remain in place as a result of not patching.\n\nYou are notiﬁed of a zero-day vulnerability requiring an emergency ﬁx and you have to patch all\n\nyour environments manually.\n\nYou are not aware of critical actions needed to maintain your resources, such as mandatory\n\nversion updates because you do not review upcoming planned lifecycle events and other\n\ninformation. You lose critical time for planning and execution, resulting in emergency changes\n\nfor your teams and potential impact or unexpected downtime.\n\nOPS05-BP05 Perform patch management\n\n104\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: By establishing a patch management process, including your criteria for patching and methodology for distribution across your environments, you can scale and report on patch levels. This provides assurances around security patching and ensure\n\nclear visibility on the status of known ﬁxes being in place. This encourages adoption of desired\n\nfeatures and capabilities, the rapid removal of issues, and sustained compliance with governance.\n\nImplement patch management systems and automation to reduce the level of eﬀort to deploy\n\npatches and limit errors caused by manual processes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nPatch systems to remediate issues, to gain desired features or capabilities, and to remain compliant\n\nwith governance policy and vendor support requirements. In immutable systems, deploy with the appropriate patch set to achieve the desired result. Automate the patch management mechanism\n\nto reduce the elapsed time to patch, to avoid errors caused by manual processes, and lower the\n\nlevel of eﬀort to patch.\n\nImplementation steps\n\nFor Amazon EC2 Image Builder:\n\n1. Using Amazon EC2 Image Builder, specify pipeline details:\n\na. Create an image pipeline and name it\n\nb. Deﬁne pipeline schedule and time zone\n\nc. Conﬁgure any dependencies\n\n2. Choose a recipe:\n\na. Select existing recipe or create a new one\n\nb. Select image type\n\nc. Name and version your recipe\n\nd. Select your base image\n\ne. Add build components and add to target registry\n\n3. Optional - deﬁne your infrastructure conﬁguration.\n\n4. Optional - deﬁne conﬁguration settings.\n\n5. Review settings.\n\n6. Maintain recipe hygiene regularly.\n\nOPS05-BP05 Perform patch management\n\n105\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nFor Systems Manager Patch Manager:\n\n1. Create a patch baseline.\n\n2. Select a patching operations method.\n\n3. Enable compliance reporting and scanning.\n\nResources\n\nRelated best practices:\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nWhat is Amazon EC2 Image Builder\n\nCreate an image pipeline using the Amazon EC2 Image Builder\n\nCreate a container image pipeline\n\nAWS Systems Manager Patch Manager\n\nWorking with Patch Manager\n\nWorking with patch compliance reports\n\nAWS Developer Tools\n\nRelated videos:\n\nCI/CD for Serverless Applications on AWS\n\nDesign with Ops in Mind\n\nRelated examples:\n\nAWS Systems Manager Patch Manager tutorials\n\nOPS05-BP06 Share design standards\n\nShare best practices across teams to increase awareness and maximize the beneﬁts of development\n\neﬀorts. Document them and keep them up to date as your architecture evolves. If shared standards\n\nOPS05-BP06 Share design standards\n\n106\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nare enforced in your organization, it’s critical that mechanisms exist to request additions, changes,\n\nand exceptions to standards. Without this option, standards become a constraint on innovation.\n\nDesired outcome: Design standards are shared across teams in your organizations. They are documented and kept up-to-date as best practices evolve.\n\nCommon anti-patterns:\n\nTwo development teams have each created a user authentication service. Your users must\n\nmaintain a separate set of credentials for each part of the system they want to access.\n\nEach team manages their own infrastructure. A new compliance requirement forces a change to\n\nyour infrastructure and each team implements it in a diﬀerent way.\n\nBeneﬁts of establishing this best practice: Using shared standards supports the adoption of best practices and maximizes the beneﬁts of development eﬀorts. Documenting and updating design\n\nstandards keeps your organization up-to-date with best practices and security and compliance\n\nrequirements.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nShare existing best practices, design standards, checklists, operating procedures, guidance, and\n\ngovernance requirements across teams. Have procedures to request changes, additions, and\n\nexceptions to design standards to support improvement and innovation. Make teams are aware of\n\npublished content. Have a mechanism to keep design standards up-to-date as new best practices\n\nemerge.\n\nCustomer example\n\nAnyCompany Retail has a cross-functional architecture team that creates software architecture\n\npatterns. This team builds the architecture with compliance and governance built in. Teams that\n\nadopt these shared standards get the beneﬁts of having compliance and governance built in. They\n\ncan quickly build on top of the design standard. The architecture team meets quarterly to evaluate\n\narchitecture patterns and update them if necessary.\n\nImplementation steps\n\n1. Identify a cross-functional team that owns developing and updating design standards. This team\n\nshould work with stakeholders across your organization to develop design standards, operating\n\nOPS05-BP06 Share design standards\n\n107\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nprocedures, checklists, guidance, and governance requirements. Document the design standards\n\nand share them within your organization.\n\na. AWS Service Catalog can be used to create portfolios representing design standards using\n\ninfrastructure as code. You can share portfolios across accounts.\n\n2. Have a mechanism in place to keep design standards up-to-date as new best practices are\n\nidentiﬁed.\n\n3. If design standards are centrally enforced, have a process to request changes, updates, and\n\nexemptions.\n\nLevel of eﬀort for the implementation plan: Medium. Developing a process to create and share design standards can take coordination and cooperation with stakeholders across your\n\norganization.\n\nResources\n\nRelated best practices:\n\nOPS01-BP03 Evaluate governance requirements - Governance requirements inﬂuence design\n\nstandards.\n\nOPS01-BP04 Evaluate compliance requirements - Compliance is a vital input in creating design\n\nstandards.\n\nOPS07-BP02 Ensure a consistent review of operational readiness - Operational readiness\n\nchecklists are a mechanism to implement design standards when designing your workload.\n\nOPS11-BP01 Have a process for continuous improvement - Updating design standards is a part\n\nof continuous improvement.\n\nOPS11-BP04 Perform knowledge management - As part of your knowledge management\n\npractice, document and share design standards.\n\nRelated documents:\n\nAutomate AWS Backups with AWS Service Catalog\n\nAWS Service Catalog Account Factory-Enhanced\n\nHow Expedia Group built Database as a Service (DBaaS) oﬀering using AWS Service Catalog\n\nMaintain visibility over the use of cloud architecture patterns\n\nSimplify sharing your AWS Service Catalog portfolios in an AWS Organizations setup\n\nOPS05-BP06 Share design standards\n\n108",
      "page_number": 106
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 114-121)",
      "start_page": 114,
      "end_page": 121,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated videos:\n\nAWS Service Catalog – Getting Started\n\nAWS re:Invent 2020: Manage your AWS Service Catalog portfolios like an expert\n\nRelated examples:\n\nAWS Service Catalog Reference Architecture\n\nAWS Service Catalog Workshop\n\nRelated services:\n\nAWS Service Catalog\n\nOPS05-BP07 Implement practices to improve code quality\n\nImplement practices to improve code quality and minimize defects. Some examples include test-\n\ndriven development, code reviews, standards adoption, and pair programming. Incorporate these\n\npractices into your continuous integration and delivery process.\n\nDesired outcome: Your organization uses best practices like code reviews or pair programming to improve code quality. Developers and operators adopt code quality best practices as part of the\n\nsoftware development lifecycle.\n\nCommon anti-patterns:\n\nYou commit code to the main branch of your application without a code review. The change\n\nautomatically deploys to production and causes an outage.\n\nA new application is developed without any unit, end-to-end, or integration tests. There is no\n\nway to test the application before deployment.\n\nYour teams make manual changes in production to address defects. Changes do not go through\n\ntesting or code reviews and are not captured or logged through continuous integration and\n\ndelivery processes.\n\nBeneﬁts of establishing this best practice: By adopting practices to improve code quality, you can help minimize issues introduced to production. Code quality best practices include pair\n\nprogramming, code reviews, and implementation of AI productivity tools.\n\nOPS05-BP07 Implement practices to improve code quality\n\n109\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nImplement practices to improve code quality to minimize defects before they are deployed. Use\n\npractices like test-driven development, code reviews, and pair programming to increase the quality\n\nof your development.\n\nUse the power of generative AI with Amazon Q Developer to improve developer productivity\n\nand code quality. Amazon Q Developer includes generation of code suggestions (based on large\n\nlanguage models), production of unit tests (including boundary conditions), and code security\n\nenhancements through detection and remediation of security vulnerabilities.\n\nCustomer example\n\nAnyCompany Retail adopts several practices to improve code quality. They have adopted test- driven development as the standard for writing applications. For some new features, they will have\n\ndevelopers pair program together during a sprint. Every pull request goes through a code review by\n\na senior developer before being integrated and deployed.\n\nImplementation steps\n\n1. Adopt code quality practices like test-driven development, code reviews, and pair programming\n\ninto your continuous integration and delivery process. Use these techniques to improve software\n\nquality.\n\na. Use Amazon Q Developer, a generative AI tool that can help create unit test cases (including\n\nboundary conditions), generate functions using code and comments, implement well-known\n\nalgorithms, detect security policy violations and vulnerabilities in your code, detect secrets,\n\nscan infrastructure as code (IaC), document code, and learn third-party code libraries more\n\nquickly.\n\nb. Amazon CodeGuru Reviewer can provide programming recommendations for Java and Python\n\ncode using machine learning.\n\nLevel of eﬀort for the implementation plan: Medium. There are many ways of implementing this best practice, but getting organizational adoption may be challenging.\n\nResources\n\nRelated best practices:\n\nOPS05-BP07 Implement practices to improve code quality\n\n110\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS05-BP02 Test and validate changes\n\nOPS05-BP06 Share design standards\n\nRelated documents:\n\nAdopt a test-driven development approach\n\nAccelerate your Software Development Lifecycle with Amazon Q\n\nAmazon Q Developer, now generally available, includes previews of new capabilities to reimagine\n\ndeveloper experience\n\nThe Ultimate Cheat Sheet for Using Amazon Q Developer in Your IDE\n\nShift-Left Workload, leveraging AI for Test Creation\n\nAmazon Q Developer Center\n\n10 ways to build applications faster with Amazon CodeWhisperer\n\nLooking beyond code coverage with Amazon CodeWhisperer\n\nBest Practices for Prompt Engineering with Amazon CodeWhisperer\n\nAgile Software Guide\n\nMy CI/CD pipeline is my release captain\n\nAutomate code reviews with Amazon CodeGuru Reviewer\n\nAdopt a test-driven development approach\n\nHow DevFactory builds better applications with Amazon CodeGuru\n\nOn Pair Programming\n\nRENGA Inc. automates code reviews with Amazon CodeGuru\n\nThe Art of Agile Development: Test-Driven Development\n\nWhy code reviews matter (and actually save time!)\n\nRelated videos:\n\nImplement an API with Amazon Q Developer Agent for Software Development\n\nInstalling, Conﬁguring, & Using Amazon Q Developer with JetBrains IDEs (How-to)\n\nMastering the art of Amazon CodeWhisperer - YouTube playlist\n\nAWS re:Invent 2020: Continuous improvement of code quality with Amazon CodeGuru\n\nOPS05-BP07 Implement practices to improve code quality\n\n111\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Summit ANZ 2021 - Driving a test-ﬁrst strategy with CDK and test driven development\n\nRelated services:\n\nAmazon Q Developer\n\nAmazon CodeGuru Reviewer\n\nAmazon CodeGuru Proﬁler\n\nOPS05-BP08 Use multiple environments\n\nUse multiple environments to experiment, develop, and test your workload. Use increasing levels\n\nof controls as environments approach production to gain conﬁdence your workload operates as\n\nintended when deployed.\n\nDesired outcome: You have multiple environments that reﬂect your compliance and governance needs. You test and promote code through environments on your path to production.\n\n1. Your organization does this through the establishment of a landing zone, which provides\n\ngovernance, controls, account automations, networking, security, and operational observability.\n\nManage these landing zone capabilities by using multiple environments. A common example\n\nis a sandbox organization for developing and testing changes to an AWS Control Tower-based\n\nlanding zone, which includes AWS IAM Identity Center and policies such as service control\n\npolicies (SCPs). All of these elements can signiﬁcantly impact the access to and operation of\n\nAWS accounts within the landing zone.\n\n2. In addition to these services, your teams extend the landing zones capabilites with solutions\n\npublished by AWS and AWS partners or as custom solutions developed within your organization.\n\nExamples of solutions published by AWS include Customizations for AWS Control Tower (CfCT)\n\nand AWS Control Tower Account Factory for Terraform (AFT).\n\n3. Your organization applies the same principles of testing, promoting code, and policy changes\n\nfor the landing zone through environments on your path to production. This strategy provides a\n\nstable and secure landing zone environment for your application and workload teams.\n\nCommon anti-patterns:\n\nYou are performing development in a shared development environment and another developer\n\noverwrites your code changes.\n\nOPS05-BP08 Use multiple environments\n\n112\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe restrictive security controls on your shared development environment are preventing you\n\nfrom experimenting with new services and features.\n\nYou perform load testing on your production systems and cause an outage for your users.\n\nA critical error resulting in data loss has occurred in production. In your production environment,\n\nyou attempt to recreate the conditions that lead to the data loss so that you can identify how it\n\nhappened and prevent it from happening again. To prevent further data loss during testing, you\n\nare forced to make the application unavailable to your users.\n\nYou are operating a multi-tenant service and are unable to support a customer request for a\n\ndedicated environment.\n\nYou may not always test, but when you do, you test in your production environment.\n\nYou believe that the simplicity of a single environment overrides the scope of impact of changes\n\nwithin the environment.\n\nYou upgrade a key landing zone capability, but the change impairs your team's ability to vend\n\naccounts for either new projects or your existing workloads.\n\nYou apply new controls to your AWS accounts, but the change impacts your workload team's\n\nability to deploy changes within their AWS accounts.\n\nBeneﬁts of establishing this best practice: When you deploy multiple environments, you can support multiple simultaneous development, testing, and production environments without\n\ncreating conﬂicts between developers or user communities. For complex capabilities such as\n\nlanding zones, it signiﬁcantly reduces the risk of changes, simpliﬁes the improvement process,\n\nand reduces the risk of critical updates to the environment. Organizations that use landing\n\nzones naturally beneﬁt from multi-accounts in their AWS environment, with account structure,\n\ngovernance, network, and security conﬁgurations. Over time, as your organization grows, the\n\nlanding zone can evolve to secure and organize your workloads and resources.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nUse multiple environments and provide developers sandbox environments with minimized\n\ncontrols to aid in experimentation. Provide individual development environments to help\n\nwork in parallel, increasing development agility. Implement more rigorous controls in the\n\nenvironments approaching production to allow developers to innovate. Use infrastructure as code\n\nand conﬁguration management systems to deploy environments that are conﬁgured consistent\n\nwith the controls present in production to ensure systems operate as expected when deployed.\n\nOPS05-BP08 Use multiple environments\n\n113\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nWhen environments are not in use, turn them oﬀ to avoid costs associated with idle resources\n\n(for example, development systems on evenings and weekends). Deploy production equivalent environments when load testing to improve valid results.\n\nTeams such as platform engineering, networking, and security operations often manage capabilies\n\nat the organization level with distinct requirements. A separation of accounts alone is insuﬃcient\n\nto provide and maintain separate environments for experimentation, development, and testing. In\n\nsuch cases, create separate instances of AWS Organizations.\n\nResources\n\nRelated documents:\n\nInstance Scheduler on AWS\n\nWhat is AWS CloudFormation?\n\nOrganizing Your AWS Environment Using Multiple Accounts - Multiple organizations - Test\n\nchanges to your overall AWS environment\n\nAWS Control Tower Guide\n\nOPS05-BP09 Make frequent, small, reversible changes\n\nFrequent, small, and reversible changes reduce the scope and impact of a change. When used in\n\nconjunction with change management systems, conﬁguration management systems, and build and\n\ndelivery systems frequent, small, and reversible changes reduce the scope and impact of a change.\n\nThis results in more eﬀective troubleshooting and faster remediation with the option to roll back\n\nchanges.\n\nCommon anti-patterns:\n\nYou deploy a new version of your application quarterly with a change window that means a core\n\nservice is turned oﬀ.\n\nYou frequently make changes to your database schema without tracking changes in your\n\nmanagement systems.\n\nYou perform manual in-place updates, overwriting existing installations and conﬁgurations, and\n\nhave no clear roll-back plan.\n\nOPS05-BP09 Make frequent, small, reversible changes\n\n114\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: Development eﬀorts are faster by deploying small changes frequently. When the changes are small, it is much easier to identify if they have unintended consequences, and they are easier to reverse. When the changes are reversible, there is\n\nless risk to implementing the change, as recovery is simpliﬁed. The change process has a reduced\n\nrisk and the impact of a failed change is reduced.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nUse frequent, small, and reversible changes to reduce the scope and impact of a change. This eases\n\ntroubleshooting, helps with faster remediation, and provides the option to roll back a change. It\n\nalso increases the rate at which you can deliver value to the business.\n\nResources\n\nRelated best practices:\n\nOPS05-BP03 Use conﬁguration management systems\n\nOPS05-BP04 Use build and deployment management systems\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nImplementing Microservices on AWS\n\nMicroservices - Observability\n\nOPS05-BP10 Fully automate integration and deployment\n\nAutomate build, deployment, and testing of the workload. This reduces errors caused by manual\n\nprocesses and reduces the eﬀort to deploy changes.\n\nApply metadata using Resource Tags and AWS Resource Groups following a consistent tagging\n\nstrategy to aid in identiﬁcation of your resources. Tag your resources for organization, cost\n\naccounting, access controls, and targeting the run of automated operations activities.\n\nDesired outcome: Developers use tools to deliver code and promote through to production. Developers do not have to log into the AWS Management Console to deliver updates. There is a\n\nfull audit trail of change and conﬁguration, meeting the needs of governance and compliance.\n\nOPS05-BP10 Fully automate integration and deployment\n\n115\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nProcesses are repeatable and are standardized across teams. Developers are free to focus on\n\ndevelopment and code pushes, increasing productivity.\n\nCommon anti-patterns:\n\nOn Friday, you ﬁnish authoring the new code for your feature branch. On Monday, after running\n\nyour code quality test scripts and each of your unit tests scripts, you check in your code for the\n\nnext scheduled release.\n\nYou are assigned to code a ﬁx for a critical issue impacting a large number of customers in\n\nproduction. After testing the ﬁx, you commit your code and email change management to\n\nrequest approval to deploy it to production.\n\nAs a developer, you log into the AWS Management Console to create a new development\n\nenvironment using non-standard methods and systems.\n\nBeneﬁts of establishing this best practice: By implementing automated build and deployment management systems, you reduce errors caused by manual processes and reduce the eﬀort to\n\ndeploy changes helping your team members to focus on delivering business value. You increase the\n\nspeed of delivery as you promote through to production.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nYou use build and deployment management systems to track and implement change, to reduce\n\nerrors caused by manual processes, and reduce the level of eﬀort. Fully automate the integration\n\nand deployment pipeline from code check-in through build, testing, deployment, and validation.\n\nThis reduces lead time, encourages increased frequency of change, reduces the level of eﬀort,\n\nincreases the speed to market, results in increased productivity, and increases the security of your\n\ncode as you promote through to production.\n\nResources\n\nRelated best practices:\n\nOPS05-BP03 Use conﬁguration management systems\n\nOPS05-BP04 Use build and deployment management systems\n\nRelated documents:\n\nOPS05-BP10 Fully automate integration and deployment\n\n116",
      "page_number": 114
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 122-134)",
      "start_page": 122,
      "end_page": 134,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nWhat is AWS CodeBuild?\n\nWhat is AWS CodeDeploy?\n\nRelated videos:\n\nAWS re:Invent 2022 - AWS Well-Architected best practices for DevOps on AWS\n\nMitigate deployment risks\n\nAdopt approaches that provide fast feedback on quality and provide rapid recovery from changes\n\nthat do not have desired outcomes. Using these practices mitigates the impact of issues introduced\n\nthrough the deployment of changes.\n\nThe design of your workload should include how it will be deployed, updated, and operated. You\n\nwill want to implement engineering practices that align with defect reduction and quick and safe\n\nﬁxes.\n\nBest practices\n\nOPS06-BP01 Plan for unsuccessful changes\n\nOPS06-BP02 Test deployments\n\nOPS06-BP03 Employ safe deployment strategies\n\nOPS06-BP04 Automate testing and rollback\n\nOPS06-BP01 Plan for unsuccessful changes\n\nPlan to revert to a known good state, or remediate in the production environment if the deployment causes an undesired outcome. Having a policy to establish such a plan helps all teams\n\ndevelop strategies to recover from failed changes. Some example strategies are deployment and\n\nrollback steps, change policies, feature ﬂags, traﬃc isolation, and traﬃc shifting. A single release\n\nmay include multiple related component changes. The strategy should provide the ability to\n\nwithstand or recover from a failure of any component change.\n\nDesired outcome: You have prepared a detailed recovery plan for your change in the event it is unsuccessful. In addition, you have reduced the size of your release to minimize the potential\n\nimpact on other workload components. As a result, you have reduced your business impact by\n\nMitigate deployment risks\n\n117\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nshortening the potential downtime caused by a failed change and increased the ﬂexibility and\n\neﬃciency of recovery times.\n\nCommon anti-patterns:\n\nYou performed a deployment and your application has become unstable but there appear to be\n\nactive users on the system. You have to decide whether to rollback the change and impact the\n\nactive users or wait to rollback the change knowing the users may be impacted regardless.\n\nAfter making a routine change, your new environments are accessible, but one of your subnets\n\nhas become unreachable. You have to decide whether to rollback everything or try to ﬁx the\n\ninaccessible subnet. While you are making that determination, the subnet remains unreachable.\n\nYour systems are not architected in a way that allows them to be updated with smaller releases.\n\nAs a result, you have diﬃculty in reversing those bulk changes during a failed deployment.\n\nYou do not use infrastructure as code (IaC) and you made manual updates to your infrastructure that resulted in an undesired conﬁguration. You are unable to eﬀectively track and revert the manual changes.\n\nBecause you have not measured increased frequency of your deployments, your team is not\n\nincentivized to reduce the size of their changes and improve their rollback plans for each change,\n\nleading to more risk and increased failure rates.\n\nYou do not measure the total duration of an outage caused by unsuccessful changes. Your team\n\nis unable to prioritize and improve its deployment process and recovery plan eﬀectiveness.\n\nBeneﬁts of establishing this best practice: Having a plan to recover from unsuccessful changes minimizes the mean time to recover (MTTR) and reduces your business impact.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nA consistent, documented policy and practice adopted by release teams allows an organization\n\nto plan what should happen if unsuccessful changes occur. The policy should allow for ﬁxing\n\nforward in speciﬁc circumstances. In either situation, a ﬁx forward or rollback plan should be well\n\ndocumented and tested before deployment to live production so that the time it takes to revert a\n\nchange is minimized.\n\nOPS06-BP01 Plan for unsuccessful changes\n\n118\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Document the policies that require teams to have eﬀective plans to reverse changes within a\n\nspeciﬁed period.\n\na. Policies should specify when a ﬁx-forward situation is allowed.\n\nb. Require a documented rollback plan to be accessible by all involved.\n\nc. Specify the requirements to rollback (for example, when it is found that unauthorized\n\nchanges have been deployed).\n\n2. Analyze the level of impact of all changes related to each component of a workload.\n\na. Allow repeatable changes to be standardized, templated, and preauthorized if they follow a\n\nconsistent workﬂow that enforces change policies.\n\nb. Reduce the potential impact of any change by making the size of the change smaller so\n\nrecovery takes less time and causes less business impact.\n\nc. Ensure rollback procedures revert code to the known good state to avoid incidents where\n\npossible.\n\n3. Integrate tools and workﬂows to enforce your policies programatically.\n\n4. Make data about changes visible to other workload owners to improve the speed of diagnosis of\n\nany failed change that cannot be rolled back.\n\na. Measure success of this practice using visible change data and identify iterative\n\nimprovements.\n\n5. Use monitoring tools to verify the success or failure of a deployment to speed up decision-\n\nmaking on rolling back.\n\n6. Measure your duration of outage during an unsuccessful change to continually improve your\n\nrecovery plans.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nOPS06-BP01 Plan for unsuccessful changes\n\n119\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Builders Library | Ensuring Rollback Safety During Deployments\n\nAWS Whitepaper | Change Management in the Cloud\n\nRelated videos:\n\nre:Invent 2019 | Amazon’s approach to high-availability deployment\n\nOPS06-BP02 Test deployments\n\nTest release procedures in pre-production by using the same deployment conﬁguration, security\n\ncontrols, steps, and procedures as in production. Validate that all deployed steps are completed\n\nas expected, such as inspecting ﬁles, conﬁgurations, and services. Further test all changes with\n\nfunctional, integration, and load tests, along with any monitoring such as health checks. By doing these tests, you can identify deployment issues early with an opportunity to plan and mitigate\n\nthem prior to production.\n\nYou can create temporary parallel environments for testing every change. Automate the\n\ndeployment of the test environments using infrastructure as code (IaC) to help reduce amount of\n\nwork involved and ensure stability, consistency, and faster feature delivery.\n\nDesired outcome: Your organization adopts a test-driven development culture that includes testing deployments. This ensures teams are focused on delivering business value rather than\n\nmanaging releases. Teams are engaged early upon identiﬁcation of deployment risks to determine\n\nthe appropriate course of mitigation.\n\nCommon anti-patterns:\n\nDuring production releases, untested deployments cause frequent issues that require\n\ntroubleshooting and escalation.\n\nYour release contains infrastructure as code (IaC) that updates existing resources. You are unsure\n\nif the IaC runs successfully or causes impact to the resources.\n\nYou deploy a new feature to your application. It doesn't work as intended and there is no\n\nvisibility until it gets reported by impacted users.\n\nYou update your certiﬁcates. You accidentally install the certiﬁcates to the wrong components,\n\nwhich goes undetected and impacts website visitors because a secure connection to the website\n\ncan't be established.\n\nOPS06-BP02 Test deployments\n\n120\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: Extensive testing in pre-production of deployment procedures, and the changes introduced by them, minimizes the potential impact to production caused by the deployments steps. This increases conﬁdence during production release and\n\nminimizes operational support without slowing down velocity of the changes being delivered.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTesting your deployment process is as important as testing the changes that result from\n\nyour deployment. This can be achieved by testing your deployment steps in a pre-production\n\nenvironment that mirrors production as closely as possible. Common issues, such as incomplete\n\nor incorrect deployment steps, or misconﬁgurations, can be caught as a result before going to\n\nproduction. In addition, you can test your recovery steps.\n\nCustomer example\n\nAs part of their continuous integration and continuous delivery (CI/CD) pipeline, AnyCompany\n\nRetail performs the deﬁned steps needed to release infrastructure and software updates for its\n\ncustomers in a production-like environment. The pipeline is comprised of pre-checks to detect drift\n\n(detecting changes to resources performed outside of your IaC) in resources prior to deployment,\n\nas well as validate actions that the IaC takes upon its initiation. It validates deployment steps, like\n\nverifying that certain ﬁles and conﬁgurations are in place and services are in running states and are\n\nresponding correctly to health checks on local host before re-registering with the load balancer.\n\nAdditionally, all changes ﬂag a number of automated tests, such as functional, security, regression,\n\nintegration, and load tests.\n\nImplementation steps\n\n1. Perform pre-install checks to mirror the pre-production environment to production.\n\na. Use drift detection to detect when resources have been changed outside of CloudFormation.\n\nb. Use change sets to validate that the intent of a stack update matches the actions that\n\nCloudFormation takes when the change set is initiated.\n\n2. This triggers a manual approval step in AWS CodePipeline to authorize the deployment to the\n\npre-production environment.\n\n3. Use deployment conﬁgurations such as AWS CodeDeploy AppSpec ﬁles to deﬁne deployment\n\nand validation steps.\n\nOPS06-BP02 Test deployments\n\n121\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Where applicable, integrate AWS CodeDeploy with other AWS services or integrate AWS\n\nCodeDeploy with partner product and services.\n\n5. Monitor deployments using Amazon CloudWatch, AWS CloudTrail, and Amazon SNS event\n\nnotiﬁcations.\n\n6. Perform post-deployment automated testing, including functional, security, regression,\n\nintegration, and load testing.\n\n7. Troubleshoot deployment issues.\n\n8. Successful validation of preceding steps should initiate a manual approval workﬂow to authorize\n\ndeployment to production.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS05-BP02 Test and validate changes\n\nRelated documents:\n\nAWS Builders' Library | Automating safe, hands-oﬀ deployments | Test Deployments\n\nAWS Whitepaper | Practicing Continuous Integration and Continuous Delivery on AWS\n\nThe Story of Apollo - Amazon's Deployment Engine\n\nHow to test and debug AWS CodeDeploy locally before you ship your code\n\nIntegrating Network Connectivity Testing with Infrastructure Deployment\n\nRelated videos:\n\nre:Invent 2020 | Testing software and systems at Amazon\n\nRelated examples:\n\nTutorial | Deploy and Amazon ECS service with a validation test\n\nOPS06-BP02 Test deployments\n\n122\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS06-BP03 Employ safe deployment strategies\n\nSafe production roll-outs control the ﬂow of beneﬁcial changes with an aim to minimize any\n\nperceived impact for customers from those changes. The safety controls provide inspection\n\nmechanisms to validate desired outcomes and limit the scope of impact from any defects\n\nintroduced by the changes or from deployment failures. Safe roll-outs may include strategies such\n\nas feature-ﬂags, one-box, rolling (canary releases), immutable, traﬃc splitting, and blue/green\n\ndeployments.\n\nDesired outcome: Your organization uses a continuous integration continuous delivery (CI/ CD) system that provides capabilities for automating safe rollouts. Teams are required to use\n\nappropriate safe roll-out strategies.\n\nCommon anti-patterns:\n\nYou deploy an unsuccessful change to all of production all at once. As a result, all customers are\n\nimpacted simultaneously.\n\nA defect introduced in a simultaneous deployment to all systems requires an emergency release.\n\nCorrecting it for all customers takes several days.\n\nManaging production release requires planning and participation of several teams. This puts\n\nconstraints on your ability to frequently update features for your customers.\n\nYou perform a mutable deployment by modifying your existing systems. After discovering that\n\nthe change was unsuccessful, you are forced to modify the systems again to restore the old\n\nversion, extending your time to recovery.\n\nBeneﬁts of establishing this best practice: Automated deployments balance speed of roll-outs against delivering beneﬁcial changes consistently to customers. Limiting impact prevents costly\n\ndeployment failures and maximizes teams ability to eﬃciently respond to failures.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nContinuous-delivery failures can lead to reduced service availability and bad customer experiences.\n\nTo maximize the rate of successful deployments, implement safety controls in the end-to-end release process to minimize deployment errors, with a goal of achieving zero deployment failures.\n\nCustomer example\n\nOPS06-BP03 Employ safe deployment strategies\n\n123\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail is on a mission to achieve minimal to zero downtime deployments, meaning\n\nthat there's no perceivable impact to its users during deployments. To accomplish this, the company has established deployment patterns (see the following workﬂow diagram), such as\n\nrolling and blue/green deployments. All teams adopt one or more of these patterns in their CI/CD\n\npipeline.\n\nCodeDeploy workﬂow for Amazon EC2\n\nCodeDeploy workﬂow for Amazon ECS\n\nCodeDeploy workﬂow for Lambda\n\nImplementation steps\n\n1. Use an approval workﬂow to initiate the sequence of production roll-out steps upon promotion\n\nto production .\n\n2. Use an automated deployment system such as AWS CodeDeploy. AWS CodeDeploy deployment\n\noptions include in-place deployments for EC2/On-Premises and blue/green deployments for\n\nEC2/On-Premises, AWS Lambda, and Amazon ECS (see the preceding workﬂow diagram).\n\na. Where applicable, integrate AWS CodeDeploy with other AWS services or integrate AWS\n\nCodeDeploy with partner product and services.\n\n3. Use blue/green deployments for databases such as Amazon Aurora and Amazon RDS.\n\n4. Monitor deployments using Amazon CloudWatch, AWS CloudTrail, and Amazon Simple\n\nNotiﬁcation Service (Amazon SNS) event notiﬁcations.\n\nOPS06-BP03 Employ safe deployment strategies\n\n124\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n5. Perform post-deployment automated testing including functional, security, regression,\n\nintegration, and any load tests.\n\n6. Troubleshoot deployment issues.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS05-BP02 Test and validate changes\n\nOPS05-BP09 Make frequent, small, reversible changes\n\nOPS05-BP10 Fully automate integration and deployment\n\nRelated documents:\n\nAWS Builders Library | Automating safe, hands-oﬀ deployments | Production deployments\n\nAWS Builders Library | My CI/CD pipeline is my release captain | Safe, automatic production\n\nreleases\n\nAWS Whitepaper | Practicing Continuous Integration and Continuous Delivery on AWS |\n\nDeployment methods\n\nAWS CodeDeploy User Guide\n\nWorking with deployment conﬁgurations in AWS CodeDeploy\n\nSet up an API Gateway canary release deployment\n\nAmazon ECS Deployment Types\n\nFully Managed Blue/Green Deployments in Amazon Aurora and Amazon RDS\n\nBlue/Green deployments with AWS Elastic Beanstalk\n\nRelated videos:\n\nre:Invent 2020 | Hands-oﬀ: Automating continuous delivery pipelines at Amazon\n\nre:Invent 2019 | Amazon's Approach to high-availability deployment\n\nRelated examples:\n\nOPS06-BP03 Employ safe deployment strategies\n\n125\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nTry a Sample Blue/Green Deployment in AWS CodeDeploy\n\nWorkshop | Building CI/CD pipelines for Lambda canary deployments using AWS CDK\n\nWorkshop | Building your ﬁrst DevOps Blue/Green pipeline with Amazon ECS\n\nWorkshop | Building your ﬁrst DevOps Blue/Green pipeline with Amazon EKS\n\nWorkshop | EKS GitOps with ArgoCD\n\nWorkshop | CI/CD on AWS Workshop\n\nImplementing cross-account CI/CD with AWS SAM for container-based Lambda functions\n\nOPS06-BP04 Automate testing and rollback\n\nTo increase the speed, reliability, and conﬁdence of your deployment process, have a strategy\n\nfor automated testing and rollback capabilities in pre-production and production environments. Automate testing when deploying to production to simulate human and system interactions\n\nthat verify the changes being deployed. Automate rollback to revert back to a previous known\n\ngood state quickly. The rollback should be initiated automatically on pre-deﬁned conditions such\n\nas when the desired outcome of your change is not achieved or when the automated test fails.\n\nAutomating these two activities improves your success rate for your deployments, minimizes\n\nrecovery time, and reduces the potential impact to the business.\n\nDesired outcome: Your automated tests and rollback strategies are integrated into your continuous integration, continuous delivery (CI/CD) pipeline. Your monitoring is able to validate\n\nagainst your success criteria and initiate automatic rollback upon failure. This minimizes any\n\nimpact to end users and customers. For example, when all testing outcomes have been satisﬁed,\n\nyou promote your code into the production environment where automated regression testing is\n\ninitiated, leveraging the same test cases. If regression test results do not match expectations, then\n\nautomated rollback is initiated in the pipeline workﬂow.\n\nCommon anti-patterns:\n\nYour systems are not architected in a way that allows them to be updated with smaller releases.\n\nAs a result, you have diﬃculty in reversing those bulk changes during a failed deployment.\n\nYour deployment process consists of a series of manual steps. After you deploy changes to your\n\nworkload, you start post-deployment testing. After testing, you realize that your workload is\n\ninoperable and customers are disconnected. You then begin rolling back to the previous version.\n\nAll of these manual steps delay overall system recovery and cause a prolonged impact to your\n\ncustomers.\n\nOPS06-BP04 Automate testing and rollback\n\n126\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou spent time developing automated test cases for functionality that is not frequently used in\n\nyour application, minimizing the return on investment in your automated testing capability.\n\nYour release is comprised of application, infrastructure, patches and conﬁguration updates that\n\nare independent from one another. However, you have a single CI/CD pipeline that delivers\n\nall changes at once. A failure in one component forces you to revert all changes, making your\n\nrollback complex and ineﬃcient.\n\nYour team completes the coding work in sprint one and begins sprint two work, but your plan\n\ndid not include testing until sprint three. As a result, automated tests revealed defects from\n\nsprint one that had to be resolved before testing of sprint two deliverables could be started and\n\nthe entire release is delayed, devaluing your automated testing.\n\nYour automated regression test cases for the production release are complete, but you are not\n\nmonitoring workload health. Since you have no visibility into whether or not the service has\n\nrestarted, you are not sure if rollback is needed or if it has already occurred.\n\nBeneﬁts of establishing this best practice: Automated testing increases the transparency of your testing process and your ability to cover more features in a shorter time period. By testing and\n\nvalidating changes in production, you are able to identify issues immediately. Improvement in\n\nconsistency with automated testing tools allows for better detection of defects. By automatically\n\nrolling back to the previous version, the impact on your customers is minimized. Automated\n\nrollback ultimately inspires more conﬁdence in your deployment capabilities by reducing business\n\nimpact. Overall, these capabilities reduce time-to-delivery while ensuring quality.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nAutomate testing of deployed environments to conﬁrm desired outcomes more quickly. Automate rollback to a previous known good state when pre-deﬁned outcomes are not achieved to minimize\n\nrecovery time and reduce errors caused by manual processes. Integrate testing tools with your\n\npipeline workﬂow to consistently test and minimize manual inputs. Prioritize automating test\n\ncases, such as those that mitigate the greatest risks and need to be tested frequently with every\n\nchange. Additionally, automate rollback based on speciﬁc conditions that are pre-deﬁned in your\n\ntest plan.\n\nOPS06-BP04 Automate testing and rollback\n\n127\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Establish a testing lifecycle for your development lifecycle that deﬁnes each stage of the testing\n\nprocess from requirements planning to test case development, tool conﬁguration, automated\n\ntesting, and test case closure.\n\na. Create a workload-speciﬁc testing approach from your overall test strategy.\n\nb. Consider a continuous testing strategy where appropriate throughout the development\n\nlifecycle.\n\n2. Select automated tools for testing and rollback based on your business requirements and\n\npipeline investments.\n\n3. Decide which test cases you wish to automate and which should be performed manually. These\n\ncan be deﬁned based on business value priority of the feature being tested. Align all team\n\nmembers to this plan and verify accountability for performing manual tests.\n\na. Apply automated testing capabilities to speciﬁc test cases that make sense for automation,\n\nsuch as repeatable or frequently run cases, those that require repetitive tasks, or those that\n\nare required across multiple conﬁgurations.\n\nb. Deﬁne test automation scripts as well as the success criteria in the automation tool so\n\ncontinued workﬂow automation can be initiated when speciﬁc cases fail.\n\nc. Deﬁne speciﬁc failure criteria for automated rollback.\n\n4. Prioritize test automation to drive consistent results with thorough test case development where\n\ncomplexity and human interaction have a higher risk of failure.\n\n5. Integrate your automated testing and rollback tools into your CI/CD pipeline.\n\na. Develop clear success criteria for your changes.\n\nb. Monitor and observe to detect these criteria and automatically reverse changes when speciﬁc\n\nrollback criteria are met.\n\n6. Perform diﬀerent types of automated production testing, such as:\n\na. A/B testing to show results in comparison to the current version between two user testing\n\ngroups.\n\nb. Canary testing that allows you to roll out your change to a subset of users before releasing it\n\nto all.\n\nc. Feature-ﬂag testing which allows a single feature of the new version at a time to be ﬂagged\n\non and oﬀ from outside the application so that each new feature can be validated one at a\n\ntime.\n\nd. Regression testing to verify new functionality with existing interrelated components.\n\nOPS06-BP04 Automate testing and rollback\n\n128\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n7. Monitor the operational aspects of the application, transactions, and interactions with other\n\napplications and components. Develop reports to show success of changes by workload so that you can identify what parts of the automation and workﬂow can be further optimized.\n\na. Develop test result reports that help you make quick decisions on whether or not rollback\n\nprocedures should be invoked.\n\nb. Implement a strategy that allows for automated rollback based upon pre-deﬁned failure\n\nconditions that result from one or more of your test methods.\n\n8. Develop your automated test cases to allow for reusability across future repeatable changes.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS06-BP01 Plan for unsuccessful changes\n\nOPS06-BP02 Test deployments\n\nRelated documents:\n\nAWS Builders Library | Ensuring rollback safety during deployments\n\nRedeploy and rollback a deployment with AWS CodeDeploy\n\n8 best practices when automating your deployments with AWS CloudFormation\n\nRelated examples:\n\nServerless UI testing using Selenium, AWS Lambda, AWS Fargate, and AWS Developer Tools\n\nRelated videos:\n\nre:Invent 2020 | Hands-oﬀ: Automating continuous delivery pipelines at Amazon\n\nre:Invent 2019 | Amazon's Approach to high-availability deployment\n\nOPS06-BP04 Automate testing and rollback\n\n129",
      "page_number": 122
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 135-148)",
      "start_page": 135,
      "end_page": 148,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational readiness and change management\n\nEvaluate the operational readiness of your workload, processes, procedures, and personnel to\n\nunderstand the operational risks related to your workload. Manage the ﬂow of change into your\n\nenvironments.\n\nYou should use a consistent process (including manual or automated checklists) to know when you are ready to go live with your workload or a change. This will also help you to ﬁnd any areas that\n\nyou need to make plans to address. You will have runbooks that document your routine activities\n\nand playbooks that guide your processes for issue resolution. Use a mechanism to manage changes\n\nthat supports the delivery of business value and help mitigate risks associated to change.\n\nBest practices\n\nOPS07-BP01 Ensure personnel capability\n\nOPS07-BP02 Ensure a consistent review of operational readiness\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS07-BP04 Use playbooks to investigate issues\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\nOPS07-BP06 Create support plans for production workloads\n\nOPS07-BP01 Ensure personnel capability\n\nHave a mechanism to validate that you have the appropriate number of trained personnel to\n\nsupport the workload. They must be trained on the platform and services that make up your\n\nworkload. Provide them with the knowledge necessary to operate the workload. You must have\n\nenough trained personnel to support the normal operation of the workload and troubleshoot any incidents that occur. Have enough personnel so that you can rotate during on-call and vacations to\n\navoid burnout.\n\nDesired outcome:\n\nThere are enough trained personnel to support the workload at times when the workload is\n\navailable.\n\nYou provide training for your personnel on the software and services that make up your\n\nworkload.\n\nOperational readiness and change management\n\n130\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nDeploying a workload without team members trained to operate the platform and services in\n\nuse.\n\nNot having enough personnel to support on-call rotations or personnel taking time oﬀ.\n\nBeneﬁts of establishing this best practice:\n\nHaving skilled team members helps eﬀective support of your workload.\n\nWith enough team members, you can support the workload and on-call rotations while\n\ndecreasing the risk of burnout.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nValidate that there are suﬃcient trained personnel to support the workload. Verify that you have\n\nenough team members to cover normal operational activities, including on-call rotations.\n\nCustomer example\n\nAnyCompany Retail makes sure that teams supporting the workload are properly staﬀed and\n\ntrained. They have enough engineers to support an on-call rotation. Personnel get training on the\n\nsoftware and platform that the workload is built on and are encouraged to earn certiﬁcations.\n\nThere are enough personnel so that people can take time oﬀ while still supporting the workload\n\nand the on-call rotation.\n\nImplementation steps\n\n1. Assign an adequate number of personnel to operate and support your workload, including on-\n\ncall duties, security issues, and lifecycle events, such as end of support and certiﬁcate rotation\n\ntasks.\n\n2. Train your personnel on the software and platforms that compose your workload.\n\na. AWS Training and Certiﬁcation has a library of courses about AWS. They provide free and paid\n\ncourses, online and in-person.\n\nb. AWS hosts events and webinars where you learn from AWS experts.\n\n3. Perform the following on a regular basis:\n\nOPS07-BP01 Ensure personnel capability\n\n131\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEvaluate team size and skills as operating conditions and the workload change.\n\nAdjust team size and skills to match operational requirements.\n\nVerify ability and capacity to address planned lifecycle events, unplanned security, and\n\noperational notiﬁcations through AWS Health.\n\nLevel of eﬀort for the implementation plan: High. Hiring and training a team to support a workload can take signiﬁcant eﬀort but has substantial long-term beneﬁts.\n\nResources\n\nRelated best practices:\n\nOPS11-BP04 Perform knowledge management - Team members must have the information\n\nnecessary to operate and support the workload. Knowledge management is the key to providing\n\nthat.\n\nRelated documents:\n\nAWS Events and Webinars\n\nAWS Training and Certiﬁcation\n\nOPS07-BP02 Ensure a consistent review of operational readiness\n\nUse Operational Readiness Reviews (ORRs) to validate that you can operate your workload. ORR is\n\na mechanism developed at Amazon to validate that teams can safely operate their workloads. An\n\nORR is a review and inspection process using a checklist of requirements. An ORR is a self-service\n\nexperience that teams use to certify their workloads. ORRs include best practices from lessons\n\nlearned from our years of building software.\n\nAn ORR checklist is composed of architectural recommendations, operational process, event\n\nmanagement, and release quality. Our Correction of Error (CoE) process is a major driver of these\n\nitems. Your own post-incident analysis should drive the evolution of your own ORR. An ORR is\n\nnot only about following best practices but preventing the recurrence of events that you’ve seen\n\nbefore. Lastly, security, governance, and compliance requirements can also be included in an ORR.\n\nRun ORRs before a workload launches to general availability and then throughout the software\n\ndevelopment lifecycle. Running the ORR before launch increases your ability to operate the\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n132\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nworkload safely. Periodically re-run your ORR on the workload to catch any drift from best\n\npractices. You can have ORR checklists for new services launches and ORRs for periodic reviews. This helps keep you up to date on new best practices that arise and incorporate lessons learned\n\nfrom post-incident analysis. As your use of the cloud matures, you can build ORR requirements into\n\nyour architecture as defaults.\n\nDesired outcome: You have an ORR checklist with best practices for your organization. ORRs are conducted before workloads launch. ORRs are run periodically over the course of the workload\n\nlifecycle.\n\nCommon anti-patterns:\n\nYou launch a workload without knowing if you can operate it.\n\nGovernance and security requirements are not included in certifying a workload for launch.\n\nWorkloads are not re-evaluated periodically.\n\nWorkloads launch without required procedures in place.\n\nYou see repetition of the same root cause failures in multiple workloads.\n\nBeneﬁts of establishing this best practice:\n\nYour workloads include architecture, process, and management best practices.\n\nLessons learned are incorporated into your ORR process.\n\nRequired procedures are in place when workloads launch.\n\nORRs are run throughout the software lifecycle of your workloads.\n\nLevel of risk if this best practice is not established: High\n\nImplementation guidance\n\nAn ORR is two things: a process and a checklist. Your ORR process should be adopted by your\n\norganization and supported by an executive sponsor. At a minimum, ORRs must be conducted\n\nbefore a workload launches to general availability. Run the ORR throughout the software\n\ndevelopment lifecycle to keep it up to date with best practices or new requirements. The ORR\n\nchecklist should include conﬁguration items, security and governance requirements, and best\n\npractices from your organization. Over time, you can use services, such as AWS Conﬁg, AWS\n\nSecurity Hub CSPM, and AWS Control Tower Guardrails, to build best practices from the ORR into\n\nguardrails for automatic detection of best practices.\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n133\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCustomer example\n\nAfter several production incidents, AnyCompany Retail decided to implement an ORR process. They\n\nbuilt a checklist composed of best practices, governance and compliance requirements, and lessons\n\nlearned from outages. New workloads conduct ORRs before they launch. Every workload conducts\n\na yearly ORR with a subset of best practices to incorporate new best practices and requirements\n\nthat are added to the ORR checklist. Over time, AnyCompany Retail used AWS Conﬁg to detect\n\nsome best practices, speeding up the ORR process.\n\nImplementation steps\n\nTo learn more about ORRs, read the Operational Readiness Reviews (ORR) whitepaper. It provides\n\ndetailed information on the history of the ORR process, how to build your own ORR practice,\n\nand how to develop your ORR checklist. The following steps are an abbreviated version of that\n\ndocument. For an in-depth understanding of what ORRs are and how to build your own, we\n\nrecommend reading that whitepaper.\n\n1. Gather the key stakeholders together, including representatives from security, operations, and\n\ndevelopment.\n\n2. Have each stakeholder provide at least one requirement. For the ﬁrst iteration, try to limit the\n\nnumber of items to thirty or less.\n\nAppendix B: Example ORR questions from the Operational Readiness Reviews (ORR)\n\nwhitepaper contains sample questions that you can use to get started.\n\n3. Collect your requirements into a spreadsheet.\n\nYou can use custom lenses in the AWS Well-Architected Tool to develop your ORR and share\n\nthem across your accounts and AWS Organization.\n\n4. Identify one workload to conduct the ORR on. A pre-launch workload or an internal workload is\n\nideal.\n\n5. Run through the ORR checklist and take note of any discoveries made. Discoveries might be\n\nacceptable if a mitigation is in place. For any discovery that lacks a mitigation, add those to your\n\nbacklog of items and implement them before launch.\n\n6. Continue to add best practices and requirements to your ORR checklist over time.\n\nSupport customers with Enterprise Support can request the Operational Readiness Review\n\nWorkshop from their Technical Account Manager. The workshop is an interactive working\n\nbackwards session to develop your own ORR checklist.\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n134\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: High. Adopting an ORR practice in your organization requires executive sponsorship and stakeholder buy-in. Build and update the checklist with inputs from across your organization.\n\nResources\n\nRelated best practices:\n\nOPS01-BP03 Evaluate governance requirements – Governance requirements are a natural ﬁt for\n\nan ORR checklist.\n\nOPS01-BP04 Evaluate compliance requirements – Compliance requirements are sometimes\n\nincluded in an ORR checklist. Other times they are a separate process.\n\nOPS03-BP07 Resource teams appropriately – Team capability is a good candidate for an ORR\n\nrequirement.\n\nOPS06-BP01 Plan for unsuccessful changes – A rollback or rollforward plan must be established\n\nbefore you launch your workload.\n\nOPS07-BP01 Ensure personnel capability – To support a workload you must have the required\n\npersonnel.\n\nSEC01-BP03 Identify and validate control objectives – Security control objectives make excellent\n\nORR requirements.\n\nREL13-BP01 Deﬁne recovery objectives for downtime and data loss – Disaster recovery plans are\n\na good ORR requirement.\n\nCOST02-BP01 Develop policies based on your organization requirements – Cost management\n\npolicies are good to include in your ORR checklist.\n\nRelated documents:\n\nAWS Control Tower - Guardrails in AWS Control Tower\n\nAWS Well-Architected Tool - Custom Lenses\n\nOperational Readiness Review Template by Adrian Hornsby\n\nOperational Readiness Reviews (ORR) Whitepaper\n\nRelated videos:\n\nAWS Supports You | Building an Eﬀective Operational Readiness Review (ORR)\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n135\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated examples:\n\nSample Operational Readiness Review (ORR) Lens\n\nRelated services:\n\nAWS Conﬁg\n\nAWS Control Tower\n\nAWS Security Hub CSPM\n\nAWS Well-Architected Tool\n\nOPS07-BP03 Use runbooks to perform procedures\n\nA runbook is a documented process to achieve a speciﬁc outcome. Runbooks consist of a series of steps that someone follows to get something done. Runbooks have been used in operations going\n\nback to the early days of aviation. In cloud operations, we use runbooks to reduce risk and achieve\n\ndesired outcomes. At its simplest, a runbook is a checklist to complete a task.\n\nRunbooks are an essential part of operating your workload. From onboarding a new team member\n\nto deploying a major release, runbooks are the codiﬁed processes that provide consistent outcomes\n\nno matter who uses them. Runbooks should be published in a central location and updated as the\n\nprocess evolves, as updating runbooks is a key component of a change management process. They\n\nshould also include guidance on error handling, tools, permissions, exceptions, and escalations in\n\ncase a problem occurs.\n\nAs your organization matures, begin automating runbooks. Start with runbooks that are short and\n\nfrequently used. Use scripting languages to automate steps or make steps easier to perform. As\n\nyou automate the ﬁrst few runbooks, you'll dedicate time to automating more complex runbooks.\n\nOver time, most of your runbooks should be automated in some way.\n\nDesired outcome: Your team has a collection of step-by-step guides for performing workload tasks. The runbooks contain the desired outcome, necessary tools and permissions, and\n\ninstructions for error handling. They are stored in a central location (version control system) and\n\nupdated frequently. For example, your runbooks provide capabilities for your teams to monitor,\n\ncommunicate, and respond to AWS Health events for critical accounts during application alarms, operational issues, and planned lifecycle events.\n\nCommon anti-patterns:\n\nOPS07-BP03 Use runbooks to perform procedures\n\n136\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelying on memory to complete each step of a process.\n\nManually deploying changes without a checklist.\n\nDiﬀerent team members performing the same process but with diﬀerent steps or outcomes.\n\nLetting runbooks drift out of sync with system changes and automation.\n\nBeneﬁts of establishing this best practice:\n\nReducing error rates for manual tasks.\n\nOperations are performed in a consistent manner.\n\nNew team members can start performing tasks sooner.\n\nRunbooks can be automated to reduce toil.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nRunbooks can take several forms depending on the maturity level of your organization. At a\n\nminimum, they should consist of a step-by-step text document. The desired outcome should\n\nbe clearly indicated. Clearly document necessary special permissions or tools. Provide detailed\n\nguidance on error handling and escalations in case something goes wrong. List the runbook\n\nowner and publish it in a central location. Once your runbook is documented, validate it by having\n\nsomeone else on your team run it. As procedures evolve, update your runbooks in accordance with\n\nyour change management process.\n\nYour text runbooks should be automated as your organization matures. Using services like\n\nAWS Systems Manager automations, you can transform ﬂat text into automations that can be\n\nrun against your workload. These automations can be run in response to events, reducing the operational burden to maintain your workload. AWS Systems Manager Automation also provides a\n\nlow-code visual design experience to create automation runbooks more easily.\n\nCustomer example\n\nAnyCompany Retail must perform database schema updates during software deployments.\n\nThe Cloud Operations Team worked with the Database Administration Team to build a runbook\n\nfor manually deploying these changes. The runbook listed each step in the process in checklist\n\nform. It included a section on error handling in case something went wrong. They published the\n\nOPS07-BP03 Use runbooks to perform procedures\n\n137\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nrunbook on their internal wiki along with their other runbooks. The Cloud Operations Team plans\n\nto automate the runbook in a future sprint.\n\nImplementation steps\n\nIf you don't have an existing document repository, a version control repository is a great place\n\nto start building your runbook library. You can build your runbooks using Markdown. We have provided an example runbook template that you can use to start building runbooks.\n\n# Runbook Title\n\n## Runbook Info\n\n| Runbook ID | Description | Tools Used | Special Permissions | Runbook Author | Last\n\nUpdated | Escalation POC |\n\n|-------|-------|-------|-------|-------|-------|-------|\n\n| RUN001 | What is this runbook for? What is the desired outcome? | Tools | Permissions\n\n| Your Name | 2022-09-21 | Escalation Name |\n\n## Steps\n\n1. Step one\n\n2. Step two\n\n1. If you don't have an existing documentation repository or wiki, create a new version control\n\nrepository in your version control system.\n\n2. Identify a process that does not have a runbook. An ideal process is one that is conducted\n\nsemiregularly, short in number of steps, and has low impact failures.\n\n3. In your document repository, create a new draft Markdown document using the template. Fill in\n\nRunbook Title and the required ﬁelds under Runbook Info.\n\n4. Starting with the ﬁrst step, ﬁll in the Steps portion of the runbook.\n\n5. Give the runbook to a team member. Have them use the runbook to validate the steps. If\n\nsomething is missing or needs clarity, update the runbook.\n\n6. Publish the runbook to your internal documentation store. Once published, tell your team and\n\nother stakeholders.\n\n7. Over time, you'll build a library of runbooks. As that library grows, start working to automate\n\nrunbooks.\n\nLevel of eﬀort for the implementation plan: Low. The minimum standard for a runbook is a step- by-step text guide. Automating runbooks can increase the implementation eﬀort.\n\nOPS07-BP03 Use runbooks to perform procedures\n\n138\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS07-BP04 Use playbooks to investigate issues\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP02 Have a process per alert\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAchieving Operational Excellence using automated playbook and runbook\n\nAWS Systems Manager: Working with runbooks\n\nMigration playbook for AWS large migrations - Task 4: Improving your migration runbooks\n\nUse AWS Systems Manager Automation runbooks to resolve operational tasks\n\nRelated videos:\n\nAWS re:Invent 2019: DIY guide to runbooks, incident reports, and incident response\n\nHow to automate IT Operations on AWS | Amazon Web Services\n\nIntegrate Scripts into AWS Systems Manager\n\nRelated examples:\n\nWell-Architected Labs: Automating operations with Playbooks and Runbooks\n\nAWS Blog Post: Build a Cloud Automation Practice for Operational Excellence: Best Practices\n\nfrom AWS Managed Services\n\nAWS Systems Manager: Automation walkthroughs\n\nAWS Systems Manager: Restore a root volume from the latest snapshot runbook\n\nBuilding an AWS incident response runbook using Jupyter notebooks and CloudTrail Lake\n\nGitlab - Runbooks\n\nRubix - A Python library for building runbooks in Jupyter Notebooks\n\nOPS07-BP03 Use runbooks to perform procedures\n\n139\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUsing Document Builder to create a custom runbook\n\nRelated services:\n\nAWS Systems Manager Automation\n\nOPS07-BP04 Use playbooks to investigate issues\n\nPlaybooks are step-by-step guides used to investigate an incident. When incidents happen,\n\nplaybooks are used to investigate, scope impact, and identify a root cause. Playbooks are used\n\nfor a variety of scenarios, from failed deployments to security incidents. In many cases, playbooks\n\nidentify the root cause that a runbook is used to mitigate. Playbooks are an essential component of\n\nyour organization's incident response plans.\n\nA good playbook has several key features. It guides the user, step by step, through the process of\n\ndiscovery. Thinking outside-in, what steps should someone follow to diagnose an incident? Clearly\n\ndeﬁne in the playbook if special tools or elevated permissions are needed in the playbook. Having a\n\ncommunication plan to update stakeholders on the status of the investigation is a key component.\n\nIn situations where a root cause can't be identiﬁed, the playbook should have an escalation plan. If\n\nthe root cause is identiﬁed, the playbook should point to a runbook that describes how to resolve\n\nit. Playbooks should be stored centrally and regularly maintained. If playbooks are used for speciﬁc\n\nalerts, provide your team with pointers to the playbook within the alert.\n\nAs your organization matures, automate your playbooks. Start with playbooks that cover low-\n\nrisk incidents. Use scripting to automate the discovery steps. Make sure that you have companion\n\nrunbooks to mitigate common root causes.\n\nDesired outcome: Your organization has playbooks for common incidents. The playbooks are stored in a central location and available to your team members. Playbooks are updated frequently.\n\nFor any known root causes, companion runbooks are built.\n\nCommon anti-patterns:\n\nThere is no standard way to investigate an incident.\n\nTeam members rely on muscle memory or institutional knowledge to troubleshoot a failed\n\ndeployment.\n\nNew team members learn how to investigate issues through trial and error.\n\nBest practices for investigating issues are not shared across teams.\n\nOPS07-BP04 Use playbooks to investigate issues\n\n140\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nPlaybooks boost your eﬀorts to mitigate incidents.\n\nDiﬀerent team members can use the same playbook to identify a root cause in a consistent\n\nmanner.\n\nKnown root causes can have runbooks developed for them, speeding up recovery time.\n\nPlaybooks help team members to start contributing sooner.\n\nTeams can scale their processes with repeatable playbooks.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nHow you build and use playbooks depends on the maturity of your organization. If you are new to the cloud, build playbooks in text form in a central document repository. As your organization\n\nmatures, playbooks can become semi-automated with scripting languages like Python. These\n\nscripts can be run inside a Jupyter notebook to speed up discovery. Advanced organizations have\n\nfully automated playbooks for common issues that are auto-remediated with runbooks.\n\nStart building your playbooks by listing common incidents that happen to your workload. Choose\n\nplaybooks for incidents that are low risk and where the root cause has been narrowed down to\n\na few issues to start. After you have playbooks for simpler scenarios, move on to the higher risk\n\nscenarios or scenarios where the root cause is not well known.\n\nYour text playbooks should be automated as your organization matures. Using services like AWS\n\nSystems Manager Automations, ﬂat text can be transformed into automations. These automations\n\ncan be run against your workload to speed up investigations. These automations can be activated\n\nin response to events, reducing the mean time to discover and resolve incidents.\n\nCustomers can use AWS Systems Manager Incident Manager to respond to incidents. This service\n\nprovides a single interface to triage incidents, inform stakeholders during discovery and mitigation,\n\nand collaborate throughout the incident. It uses AWS Systems Manager Automations to speed up\n\ndetection and recovery.\n\nCustomer example\n\nA production incident impacted AnyCompany Retail. The on-call engineer used a playbook to\n\ninvestigate the issue. As they progressed through the steps, they kept the key stakeholders,\n\nOPS07-BP04 Use playbooks to investigate issues\n\n141\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nidentiﬁed in the playbook, up to date. The engineer identiﬁed the root cause as a race condition\n\nin a backend service. Using a runbook, the engineer relaunched the service, bringing AnyCompany Retail back online.\n\nImplementation steps\n\nIf you don't have an existing document repository, we suggest creating a version control repository\n\nfor your playbook library. You can build your playbooks using Markdown, which is compatible with\n\nmost playbook automation systems. If you are starting from scratch, use the following example\n\nplaybook template.\n\n# Playbook Title\n\n## Playbook Info\n\n| Playbook ID | Description | Tools Used | Special Permissions | Playbook Author | Last\n\nUpdated | Escalation POC | Stakeholders | Communication Plan |\n\n|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n\n| RUN001 | What is this playbook for? What incident is it used for? | Tools |\n\nPermissions | Your Name | 2022-09-21 | Escalation Name | Stakeholder Name | How will\n\nupdates be communicated during the investigation? |\n\n## Steps\n\n1. Step one\n\n2. Step two\n\n1. If you don't have an existing document repository or wiki, create a new version control\n\nrepository for your playbooks in your version control system.\n\n2. Identify a common issue that requires investigation. This should be a scenario where the root\n\ncause is limited to a few issues and resolution is low risk.\n\n3. Using the Markdown template, ﬁll in the Playbook Name section and the ﬁelds under Playbook\n\nInfo.\n\n4. Fill in the troubleshooting steps. Be as clear as possible on what actions to perform or what\n\nareas you should investigate.\n\n5. Give a team member the playbook and have them go through it to validate it. If there's anything\n\nmissing or something isn't clear, update the playbook.\n\n6. Publish your playbook in your document repository and inform your team and any stakeholders.\n\n7. This playbook library will grow as you add more playbooks. Once you have several playbooks,\n\nstart automating them using tools like AWS Systems Manager Automations to keep automation\n\nand playbooks in sync.\n\nOPS07-BP04 Use playbooks to investigate issues\n\n142\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: Low. Your playbooks should be text documents stored in a central location. More mature organizations will move towards automating playbooks.\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP02 Have a process per alert\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAchieving Operational Excellence using automated playbook and runbook\n\nAWS Systems Manager: Working with runbooks\n\nUse AWS Systems Manager Automation runbooks to resolve operational tasks\n\nRelated videos:\n\nAWS re:Invent 2019: DIY guide to runbooks, incident reports, and incident response (SEC318-R1)\n\nAWS Systems Manager Incident Manager - AWS Virtual Workshops\n\nIntegrate Scripts into AWS Systems Manager\n\nRelated examples:\n\nAWS Customer Playbook Framework\n\nAWS Systems Manager: Automation walkthroughs\n\nBuilding an AWS incident response runbook using Jupyter notebooks and CloudTrail Lake\n\nRubix – A Python library for building runbooks in Jupyter Notebooks\n\nUsing Document Builder to create a custom runbook\n\nRelated services:\n\nOPS07-BP04 Use playbooks to investigate issues\n\n143",
      "page_number": 135
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 149-171)",
      "start_page": 149,
      "end_page": 171,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Systems Manager Automation\n\nAWS Systems Manager Incident Manager\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\nHave processes in place for successful and unsuccessful changes to your workload. A pre-mortem is an exercise where a team simulates a failure to develop mitigation strategies. Use pre-mortems\n\nto anticipate failure and create procedures where appropriate. Evaluate the beneﬁts and risks of\n\ndeploying changes to your workload. Verify that all changes comply with governance.\n\nDesired outcome:\n\nYou make informed decisions when deploying changes to your workload.\n\nChanges comply with governance.\n\nCommon anti-patterns:\n\nDeploying a change to our workload without a process to handle a failed deployment.\n\nMaking changes to your production environment that are out of compliance with governance\n\nrequirements.\n\nDeploying a new version of your workload without establishing a baseline for resource\n\nutilization.\n\nBeneﬁts of establishing this best practice:\n\nYou are prepared for unsuccessful changes to your workload.\n\nChanges to your workload are compliant with governance policies.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nUse pre-mortems to develop processes for unsuccessful changes. Document your processes for\n\nunsuccessful changes. Ensure that all changes comply with governance. Evaluate the beneﬁts and risks to deploying changes to your workload.\n\nCustomer example\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\n144\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail regularly conducts pre-mortems to validate their processes for unsuccessful\n\nchanges. They document their processes in a shared Wiki and update it frequently. All changes comply with governance requirements.\n\nImplementation steps\n\n1. Make informed decisions when deploying changes to your workload. Establish and review\n\ncriteria for a successful deployment. Develop scenarios or criteria that would initiate a rollback\n\nof a change. Weigh the beneﬁts of deploying changes against the risks of an unsuccessful\n\nchange.\n\n2. Verify that all changes comply with governance policies.\n\n3. Use pre-mortems to plan for unsuccessful changes and document mitigation strategies. Run a\n\ntable-top exercise to model an unsuccessful change and validate roll-back procedures.\n\nLevel of eﬀort for the implementation plan: Moderate. Implementing a practice of pre-mortems requires coordination and eﬀort from stakeholders across your organization\n\nResources\n\nRelated best practices:\n\nOPS01-BP03 Evaluate governance requirements - Governance requirements are a key factor in\n\ndetermining whether to deploy a change.\n\nOPS06-BP01 Plan for unsuccessful changes - Establish plans to mitigate a failed deployment and\n\nuse pre-mortems to validate them.\n\nOPS06-BP02 Test deployments - Every software change should be properly tested before\n\ndeployment in order to reduce defects in production.\n\nOPS07-BP01 Ensure personnel capability - Having enough trained personnel to support the\n\nworkload is essential to making an informed decision to deploy a system change.\n\nRelated documents:\n\nAmazon Web Services: Risk and Compliance\n\nAWS Shared Responsibility Model\n\nGovernance in the AWS Cloud: The Right Balance Between Agility and Safety\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\n145\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS07-BP06 Create support plans for production workloads\n\nEnable support for any software and services that your production workload relies on. Select an\n\nappropriate support level to meet your production service-level needs. Support plans for these\n\ndependencies are necessary in case there is a service disruption or software issue. Document\n\nsupport plans and how to request support for all service and software vendors. Implement\n\nmechanisms that verify that support points of contacts are kept up to date.\n\nDesired outcome:\n\nImplement support plans for software and services that production workloads rely on.\n\nChoose an appropriate support plan based on service-level needs.\n\nDocument the support plans, support levels, and how to request support.\n\nCommon anti-patterns:\n\nYou have no support plan for a critical software vendor. Your workload is impacted by them and\n\nyou can do nothing to expedite a ﬁx or get timely updates from the vendor.\n\nA developer that was the primary point of contact for a software vendor left the company.\n\nYou are not able to reach the vendor support directly. You must spend time researching and\n\nnavigating generic contact systems, increasing the time required to respond when needed.\n\nA production outage occurs with a software vendor. There is no documentation on how to ﬁle a\n\nsupport case.\n\nBeneﬁts of establishing this best practice:\n\nWith the appropriate support level, you are able to get a response in the time frame necessary to\n\nmeet service-level needs.\n\nAs a supported customer you can escalate if there are production issues.\n\nSoftware and services vendors can assist in troubleshooting during an incident.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nEnable support plans for any software and services vendors that your production workload relies\n\non. Set up appropriate support plans to meet service-level needs. For AWS customers, this means\n\nOPS07-BP06 Create support plans for production workloads\n\n146\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nactivating AWS Business Support or greater on any accounts where you have production workloads.\n\nMeet with support vendors on a regular cadence to get updates about support oﬀerings, processes, and contacts. Document how to request support from software and services vendors, including\n\nhow to escalate if there is an outage. Implement mechanisms to keep support contacts up to date.\n\nCustomer example\n\nAt AnyCompany Retail, all commercial software and services dependencies have support plans.\n\nFor example, they have AWS Enterprise Support activated on all accounts with production\n\nworkloads. Any developer can raise a support case when there is an issue. There is a wiki page with\n\ninformation on how to request support, whom to notify, and best practices for expediting a case.\n\nImplementation steps\n\n1. Work with stakeholders in your organization to identify software and services vendors that your\n\nworkload relies on. Document these dependencies.\n\n2. Determine service-level needs for your workload. Select a support plan that aligns with them.\n\n3. For commercial software and services, establish a support plan with the vendors.\n\na. Subscribing to AWS Business Support or greater for all production accounts provides faster\n\nresponse time from AWS Support and strongly recommended. If you don’t have premium\n\nsupport, you must have an action plan to handle issues, which require help from AWS\n\nSupport. AWS Support provides a mix of tools and technology, people, and programs\n\ndesigned to proactively help you optimize performance, lower costs, and innovate faster. In\n\naddition, AWS Business Support provides additional beneﬁts, including API access to AWS\n\nTrusted Advisor and AWS Health for programmatic integration with your systems, alongside\n\nother access methods like the AWS Management Console and Amazon EventBridge channels.\n\n4. Document the support plan in your knowledge management tool. Include how to request\n\nsupport, who to notify if a support case is ﬁled, and how to escalate during an incident. A wiki\n\nis a good mechanism to allow anyone to make necessary updates to documentation when they\n\nbecome aware of changes to support processes or contacts.\n\nLevel of eﬀort for the implementation plan: Low. Most software and services vendors oﬀer opt-in support plans. Documenting and sharing support best practices on your knowledge management\n\nsystem veriﬁes that your team knows what to do when there is a production issue.\n\nResources\n\nRelated best practices:\n\nOPS07-BP06 Create support plans for production workloads\n\n147\n\nOperational Excellence Pillar\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nRelated documents:\n\nAWS Support Plans\n\nRelated services:\n\nAWS Business Support\n\nAWS Enterprise Support\n\nOPS07-BP06 Create support plans for production workloads\n\nAWS Well-Architected Framework\n\n148\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperate\n\nObservability allows you to focus on meaningful data and understand your workload's interactions and output. By concentrating on essential insights and eliminating unnecessary data, you maintain\n\na straightforward approach to understanding workload performance. It's essential not only\n\nto collect data but also to interpret it correctly. Deﬁne clear baselines, set appropriate alert\n\nthresholds, and actively monitor for any deviations. A shift in a key metric, especially when\n\ncorrelated with other data, can pinpoint speciﬁc problem areas. With observability, you're better\n\nequipped to foresee and address potential challenges, ensuring that your workload operates\n\nsmoothly and meets business needs.\n\nSuccessful operation of a workload is measured by the achievement of business and customer\n\noutcomes. Deﬁne expected outcomes, determine how success will be measured, and identify metrics that will be used in those calculations to determine if your workload and operations are\n\nsuccessful. Operational health includes both the health of the workload and the health and success\n\nof the operations activities performed in support of the workload (for example, deployment and\n\nincident response). Establish metrics baselines for improvement, investigation, and intervention,\n\ncollect and analyze your metrics, and then validate your understanding of operations success and\n\nhow it changes over time. Use collected metrics to determine if you are satisfying customer and\n\nbusiness needs, and identify areas for improvement.\n\nEﬃcient and eﬀective management of operational events is required to achieve operational\n\nexcellence. This applies to both planned and unplanned operational events. Use established\n\nrunbooks for well-understood events, and use playbooks to aid in investigation and resolution of\n\nissues. Prioritize responses to events based on their business and customer impact. Verify that if\n\nan alert is raised in response to an event, there is an associated process to run with a speciﬁcally\n\nidentiﬁed owner. Deﬁne in advance the personnel required to resolve an event and include\n\nescalation processes to engage additional personnel, as it becomes necessary, based on urgency\n\nand impact. Identify and engage individuals with the authority to make a decision on courses of\n\naction where there will be a business impact from an event response not previously addressed.\n\nCommunicate the operational status of workloads through dashboards and notiﬁcations that are\n\ntailored to the target audience (for example, customer, business, developers, operations) so that\n\nthey may take appropriate action, so that their expectations are managed, and so that they are\n\ninformed when normal operations resume.\n\nIn AWS, you can generate dashboard views of your metrics collected from workloads and natively\n\nfrom AWS. You can leverage CloudWatch or third-party applications to aggregate and present\n\n149\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nbusiness, workload, and operations level views of operations activities. AWS provides workload\n\ninsights through logging capabilities including AWS X-Ray, CloudWatch, CloudTrail, and VPC Flow Logs to identify workload issues in support of root cause analysis and remediation.\n\nAll of the metrics you collect should be aligned to a business need and the outcomes they support.\n\nDevelop scripted responses to well-understood events and automate their performance in\n\nresponse to recognizing the event.\n\nTopics\n\nUtilizing workload observability\n\nUnderstanding operational health\n\nResponding to events\n\nUtilizing workload observability\n\nEnsure optimal workload health by leveraging observability. Utilize relevant metrics, logs, and\n\ntraces to gain a comprehensive view of your workload's performance and address issues eﬃciently.\n\nObservability allows you to focus on meaningful data and understand your workload's interactions\n\nand output. By concentrating on essential insights and eliminating unnecessary data, you maintain\n\na straightforward approach to understanding workload performance.\n\nIt's essential not only to collect data but also to interpret it correctly. Deﬁne clear baselines, set\n\nappropriate alert thresholds, and actively monitor for any deviations. A shift in a key metric,\n\nespecially when correlated with other data, can pinpoint speciﬁc problem areas.\n\nWith observability, you're better equipped to foresee and address potential challenges, ensuring\n\nthat your workload operates smoothly and meets business needs.\n\nAWS oﬀers speciﬁc tools like Amazon CloudWatch for monitoring and logging, and AWS X-Ray for\n\ndistributed tracing. These services integrate eﬀortlessly with various AWS resources, allowing for\n\neﬃcient data collection, setting up alerts based on predeﬁned thresholds, and presenting data\n\non dashboards for easy interpretation. By leveraging these insights, you can make well-informed,\n\ndata-driven decisions that align with your operational goals.\n\nBest practices\n\nOPS08-BP01 Analyze workload metrics\n\nUtilizing workload observability\n\n150\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\nOPS08-BP04 Create actionable alerts\n\nOPS08-BP05 Create dashboards\n\nOPS08-BP01 Analyze workload metrics\n\nAfter implementing application telemetry, regularly analyze the collected metrics. While latency,\n\nrequests, errors, and capacity (or quotas) provide insights into system performance, it's vital to\n\nprioritize the review of business outcome metrics. This ensures you're making data-driven decisions\n\naligned with your business objectives.\n\nDesired outcome: Accurate insights into workload performance that drive data-informed decisions, ensuring alignment with business objectives.\n\nCommon anti-patterns:\n\nAnalyzing metrics in isolation without considering their impact on business outcomes.\n\nOver-reliance on technical metrics while sidelining business metrics.\n\nInfrequent review of metrics, missing out on real-time decision-making opportunities.\n\nBeneﬁts of establishing this best practice:\n\nEnhanced understanding of the correlation between technical performance and business\n\noutcomes.\n\nImproved decision-making process informed by real-time data.\n\nProactive identiﬁcation and mitigation of issues before they aﬀect business outcomes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nLeverage tools like Amazon CloudWatch to perform metric analysis. AWS services such as\n\nCloudWatch anomaly detection and Amazon DevOps Guru can be used to detect anomalies,\n\nespecially when static thresholds are unknown or when patterns of behavior are more suited for\n\nanomaly detection.\n\nOPS08-BP01 Analyze workload metrics\n\n151\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Analyze and review: Regularly review and interpret your workload metrics.\n\na. Prioritize business outcome metrics over purely technical metrics.\n\nb. Understand the signiﬁcance of spikes, drops, or patterns in your data.\n\n2. Utilize Amazon CloudWatch: Use Amazon CloudWatch for a centralized view and deep-dive\n\nanalysis.\n\na. Conﬁgure CloudWatch dashboards to visualize your metrics and compare them over time.\n\nb. Use percentiles in CloudWatch to get a clear view of metric distribution, which can help in\n\ndeﬁning SLAs and understanding outliers.\n\nc. Set up CloudWatch anomaly detection to identify unusual patterns without relying on static\n\nthresholds.\n\nd. Implement CloudWatch cross-account observability to monitor and troubleshoot applications\n\nthat span multiple accounts within a Region.\n\ne. Use CloudWatch Metric Insights to query and analyze metric data across accounts and\n\nRegions, identifying trends and anomalies.\n\nf. Apply CloudWatch Metric Math to transform, aggregate, or perform calculations on your\n\nmetrics for deeper insights.\n\n3. Employ Amazon DevOps Guru: Incorporate Amazon DevOps Guru for its machine learning- enhanced anomaly detection to identify early signs of operational issues for your serverless applications and remediate them before they impact your customers.\n\n4. Optimize based on insights: Make informed decisions based on your metric analysis to adjust\n\nand improve your workloads.\n\nLevel of eﬀort for the Implementation Plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nRelated documents:\n\nOPS08-BP01 Analyze workload metrics\n\n152\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe Wheel Blog - Emphasizing the importance of continually reviewing metrics\n\nPercentile are important\n\nUsing AWS Cost Anomaly Detection\n\nCloudWatch cross-account observability\n\nQuery your metrics with CloudWatch Metrics Insights\n\nRelated videos:\n\nEnable Cross-Account Observability in Amazon CloudWatch\n\nIntroduction to Amazon DevOps Guru\n\nContinuously Analyze Metrics using AWS Cost Anomaly Detection\n\nRelated examples:\n\nOne Observability Workshop\n\nGaining operation insights with AIOps using Amazon DevOps Guru\n\nOPS08-BP02 Analyze workload logs\n\nRegularly analyzing workload logs is essential for gaining a deeper understanding of the\n\noperational aspects of your application. By eﬃciently sifting through, visualizing, and interpreting\n\nlog data, you can continually optimize application performance and security.\n\nDesired outcome: Rich insights into application behavior and operations derived from thorough log analysis, ensuring proactive issue detection and mitigation.\n\nCommon anti-patterns:\n\nNeglecting the analysis of logs until a critical issue arises.\n\nNot using the full suite of tools available for log analysis, missing out on critical insights.\n\nSolely relying on manual review of logs without leveraging automation and querying\n\ncapabilities.\n\nBeneﬁts of establishing this best practice:\n\nOPS08-BP02 Analyze workload logs\n\n153\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nProactive identiﬁcation of operational bottlenecks, security threats, and other potential issues.\n\nEﬃcient utilization of log data for continuous application optimization.\n\nEnhanced understanding of application behavior, aiding in debugging and troubleshooting.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nAmazon CloudWatch Logs is a powerful tool for log analysis. Integrated features like CloudWatch\n\nLogs Insights and Contributor Insights make the process of deriving meaningful information from\n\nlogs intuitive and eﬃcient.\n\nImplementation steps\n\n1. Set up CloudWatch Logs: Conﬁgure applications and services to send logs to CloudWatch Logs.\n\n2. Use log anomaly detection: Utilize Amazon CloudWatch Logs anomaly detection to\n\nautomatically identify and alert on unusual log patterns. This tool helps you proactively manage\n\nanomalies in your logs and detect potential issues early.\n\n3. Set up CloudWatch Logs Insights: Use CloudWatch Logs Insights to interactively search and\n\nanalyze your log data.\n\na. Craft queries to extract patterns, visualize log data, and derive actionable insights.\n\nb. Use CloudWatch Logs Insights pattern analysis to analyze and visualize frequent log patterns.\n\nThis feature helps you understand common operational trends and potential outliers in your\n\nlog data.\n\nc. Use CloudWatch Logs compare (diﬀ) to perform diﬀerential analysis between diﬀerent time\n\nperiods or across diﬀerent log groups. Use this capability to pinpoint changes and assess their\n\nimpacts on your system's performance or behavior.\n\n4. Monitor logs in real-time with Live Tail: Use Amazon CloudWatch Logs Live Tail to view log\n\ndata in real-time. You can actively monitor your application's operational activities as they occur,\n\nwhich provides immediate visibility into system performance and potential issues.\n\n5. Leverage Contributor Insights: Use CloudWatch Contributor Insights to identify top talkers in\n\nhigh cardinality dimensions like IP addresses or user-agents.\n\n6. Implement CloudWatch Logs metric ﬁlters: Conﬁgure CloudWatch Logs metric ﬁlters to convert log data into actionable metrics. This allows you to set alarms or further analyze patterns.\n\nOPS08-BP02 Analyze workload logs\n\n154\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n7. Implement CloudWatch cross-account observability: Monitor and troubleshoot applications\n\nthat span multiple accounts within a Region.\n\n8. Regular review and reﬁnement: Periodically review your log analysis strategies to capture all\n\nrelevant information and continually optimize application performance.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS08-BP01 Analyze workload metrics\n\nRelated documents:\n\nAnalyzing Log Data with CloudWatch Logs Insights\n\nUsing CloudWatch Contributor Insights\n\nCreating and Managing CloudWatch Log Metric Filters\n\nRelated videos:\n\nAnalyze Log Data with CloudWatch Logs Insights\n\nUse CloudWatch Contributor Insights to Analyze High-Cardinality Data\n\nRelated examples:\n\nCloudWatch Logs Sample Queries\n\nOne Observability Workshop\n\nOPS08-BP03 Analyze workload traces\n\nAnalyzing trace data is crucial for achieving a comprehensive view of an application's operational\n\njourney. By visualizing and understanding the interactions between various components,\n\nperformance can be ﬁne-tuned, bottlenecks identiﬁed, and user experiences enhanced.\n\nOPS08-BP03 Analyze workload traces\n\n155\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome: Achieve clear visibility into your application's distributed operations, enabling quicker issue resolution and an enhanced user experience.\n\nCommon anti-patterns:\n\nOverlooking trace data, relying solely on logs and metrics.\n\nNot correlating trace data with associated logs.\n\nIgnoring the metrics derived from traces, such as latency and fault rates.\n\nBeneﬁts of establishing this best practice:\n\nImprove troubleshooting and reduce mean time to resolution (MTTR).\n\nGain insights into dependencies and their impact.\n\nSwift identiﬁcation and rectiﬁcation of performance issues.\n\nLeveraging trace-derived metrics for informed decision-making.\n\nImproved user experiences through optimized component interactions.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nAWS X-Ray oﬀers a comprehensive suite for trace data analysis, providing a holistic view of\n\nservice interactions, monitoring user activities, and detecting performance issues. Features like\n\nServiceLens, X-Ray Insights, X-Ray Analytics, and Amazon DevOps Guru enhance the depth of\n\nactionable insights derived from trace data.\n\nImplementation steps\n\nThe following steps oﬀer a structured approach to eﬀectively implementing trace data analysis\n\nusing AWS services:\n\n1. Integrate AWS X-Ray: Ensure X-Ray is integrated with your applications to capture trace data.\n\n2. Analyze X-Ray metrics: Delve into metrics derived from X-Ray traces, such as latency, request\n\nrates, fault rates, and response time distributions, using the service map to monitor application\n\nhealth.\n\nOPS08-BP03 Analyze workload traces\n\n156\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n3. Use ServiceLens: Leverage the ServiceLens map for enhanced observability of your services and applications. This allows for integrated viewing of traces, metrics, logs, alarms, and other health information.\n\n4. Enable X-Ray Insights:\n\na. Turn on X-Ray Insights for automated anomaly detection in traces.\n\nb. Examine insights to pinpoint patterns and ascertain root causes, such as increased fault rates\n\nor latencies.\n\nc. Consult the insights timeline for a chronological analysis of detected issues.\n\n5. Use X-Ray Analytics: X-Ray Analytics allows you to thoroughly explore trace data, pinpoint\n\npatterns, and extract insights.\n\n6. Use groups in X-Ray: Create groups in X-Ray to ﬁlter traces based on criteria such as high\n\nlatency, allowing for more targeted analysis.\n\n7. Incorporate Amazon DevOps Guru: Engage Amazon DevOps Guru to beneﬁt from machine\n\nlearning models pinpointing operational anomalies in traces.\n\n8. Use CloudWatch Synthetics: Use CloudWatch Synthetics to create canaries for continually\n\nmonitoring your endpoints and workﬂows. These canaries can integrate with X-Ray to provide\n\ntrace data for in-depth analysis of the applications being tested.\n\n9. Use Real User Monitoring (RUM): With AWS X-Ray and CloudWatch RUM, you can analyze and debug the request path starting from end users of your application through downstream AWS managed services. This helps you identify latency trends and errors that impact your end users.\n\n10.Correlate with logs: Correlate trace data with related logs within the X-Ray trace view for a granular perspective on application behavior. This allows you to view log events directly\n\nassociated with traced transactions.\n\n11.Implement CloudWatch cross-account observability: Monitor and troubleshoot applications\n\nthat span multiple accounts within a Region.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS08-BP01 Analyze workload metrics\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\n157\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nUsing ServiceLens to Monitor Application Health\n\nExploring Trace Data with X-Ray Analytics\n\nDetecting Anomalies in Traces with X-Ray Insights\n\nContinuous Monitoring with CloudWatch Synthetics\n\nRelated videos:\n\nAnalyze and Debug Applications Using Amazon CloudWatch Synthetics & AWS X-Ray\n\nUse AWS X-Ray Insights\n\nRelated examples:\n\nOne Observability Workshop\n\nImplementing X-Ray with AWS Lambda\n\nCloudWatch Synthetics Canary Templates\n\nOPS08-BP04 Create actionable alerts\n\nPromptly detecting and responding to deviations in your application's behavior is crucial. Especially\n\nvital is recognizing when outcomes based on key performance indicators (KPIs) are at risk or when\n\nunexpected anomalies arise. Basing alerts on KPIs ensures that the signals you receive are directly\n\ntied to business or operational impact. This approach to actionable alerts promotes proactive\n\nresponses and helps maintain system performance and reliability.\n\nDesired outcome: Receive timely, relevant, and actionable alerts for rapid identiﬁcation and mitigation of potential issues, especially when KPI outcomes are at risk.\n\nCommon anti-patterns:\n\nSetting up too many non-critical alerts, leading to alert fatigue.\n\nNot prioritizing alerts based on KPIs, making it hard to understand the business impact of issues.\n\nNeglecting to address root causes, leading to repetitive alerts for the same issue.\n\nBeneﬁts of establishing this best practice:\n\nOPS08-BP04 Create actionable alerts\n\n158\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nReduced alert fatigue by focusing on actionable and relevant alerts.\n\nImproved system uptime and reliability through proactive issue detection and mitigation.\n\nEnhanced team collaboration and quicker issue resolution by integrating with popular alerting\n\nand communication tools.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo create an eﬀective alerting mechanism, it's vital to use metrics, logs, and trace data that ﬂag\n\nwhen outcomes based on KPIs are at risk or anomalies are detected.\n\nImplementation steps\n\n1. Determine key performance indicators (KPIs): Identify your application's KPIs. Alerts should be\n\ntied to these KPIs to reﬂect the business impact accurately.\n\n2. Implement anomaly detection:\n\nUse Amazon CloudWatch anomaly detection: Set up Amazon CloudWatch anomaly detection to automatically detect unusual patterns, which helps you only generate alerts for genuine anomalies.\n\nUse AWS X-Ray Insights:\n\na. Set up X-Ray Insights to detect anomalies in trace data.\n\nb. Conﬁgure notiﬁcations for X-Ray Insights to be alerted on detected issues.\n\nIntegrate with Amazon DevOps Guru:\n\na. Leverage Amazon DevOps Guru for its machine learning capabilities in detecting\n\noperational anomalies with existing data.\n\nb. Navigate to the notiﬁcation settings in DevOps Guru to set up anomaly alerts.\n\n3. Implement actionable alerts: Design alerts that provide adequate information for immediate\n\naction.\n\n1. Monitor AWS Health events with Amazon EventBridge rules, or integrate programatically with\n\nthe AWS Health API to automate actions when you receive AWS Health events. These can be general actions, such as sending all planned lifecycle event messages to a chat interface, or\n\nspeciﬁc actions, such as the initiation of a workﬂow in an IT service management tool.\n\nOPS08-BP04 Create actionable alerts\n\n159\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Reduce alert fatigue: Minimize non-critical alerts. When teams are overwhelmed with numerous\n\ninsigniﬁcant alerts, they can lose oversight of critical issues, which diminishes the overall eﬀectiveness of the alert mechanism.\n\n5. Set up composite alarms: Use Amazon CloudWatch composite alarms to consolidate multiple\n\nalarms.\n\n6. Integrate with alert tools: Incorporate tools like Ops Genie and PagerDuty.\n\n7. Engage Amazon Q Developer in chat applications: Integrate Amazon Q Developer in chat\n\napplications to relay alerts to Amazon Chime, Microsoft Teams, and Slack.\n\n8. Alert based on logs: Use log metric ﬁlters in CloudWatch to create alarms based on speciﬁc log\n\nevents.\n\n9. Review and iterate: Regularly revisit and reﬁne alert conﬁgurations.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user experience telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement distributed tracing\n\nOPS08-BP01 Analyze workload metrics\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\nRelated documents:\n\nUsing Amazon CloudWatch alarms\n\nCreate a composite alarm\n\nCreate a CloudWatch alarm based on anomaly detection\n\nDevOps Guru Notiﬁcations\n\nX-ray insights notiﬁcations\n\nOPS08-BP04 Create actionable alerts\n\n160\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nMonitor, operate, and troubleshoot your AWS resources with interactive ChatOps\n\nAmazon CloudWatch Integration Guide | PagerDuty\n\nIntegrate Opsgenie with Amazon CloudWatch\n\nRelated videos:\n\nCreate Composite Alarms in Amazon CloudWatch\n\nAmazon Q Developer in chat applications Overview\n\nAWS On Air ft. Mutative Commands in Amazon Q Developer in chat applications\n\nRelated examples:\n\nAlarms, incident management, and remediation in the cloud with Amazon CloudWatch\n\nTutorial: Creating an Amazon EventBridge rule that sends notiﬁcations to Amazon Q Developer\n\nin chat applications\n\nOne Observability Workshop\n\nOPS08-BP05 Create dashboards\n\nDashboards are the human-centric view into the telemetry data of your workloads. While they\n\nprovide a vital visual interface, they should not replace alerting mechanisms, but complement\n\nthem. When crafted with care, not only can they oﬀer rapid insights into system health and\n\nperformance, but they can also present stakeholders with real-time information on business\n\noutcomes and the impact of issues.\n\nDesired outcome:\n\nClear, actionable insights into system and business health using visual representations.\n\nCommon anti-patterns:\n\nOvercomplicating dashboards with too many metrics.\n\nRelying on dashboards without alerts for anomaly detection.\n\nNot updating dashboards as workloads evolve.\n\nBeneﬁts of this best practice:\n\nOPS08-BP05 Create dashboards\n\n161\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImmediate visibility into critical system metrics and KPIs.\n\nEnhanced stakeholder communication and understanding.\n\nRapid insight into the impact of operational issues.\n\nLevel of risk if this best practice isn't established: Medium\n\nImplementation guidance\n\nBusiness-centric dashboards\n\nDashboards tailored to business KPIs engage a wider array of stakeholders. While these individuals\n\nmight not be interested in system metrics, they are keen on understanding the business\n\nimplications of these numbers. A business-centric dashboard ensures that all technical and\n\noperational metrics being monitored and analyzed are in sync with overarching business goals.\n\nThis alignment provides clarity, ensuring everyone is on the same page regarding what's essential\n\nand what's not. Additionally, dashboards that highlight business KPIs tend to be more actionable.\n\nStakeholders can quickly understand the health of operations, areas that need attention, and the\n\npotential impact on business outcomes.\n\nWith this in mind, when creating your dashboards, ensure that there's a balance between technical\n\nmetrics and business KPIs. Both are vital, but they cater to diﬀerent audiences. Ideally, you should\n\nhave dashboards that provide a holistic view of the system's health and performance while also\n\nemphasizing key business outcomes and their implications.\n\nAmazon CloudWatch Dashboards are customizable home pages in the CloudWatch console that\n\nyou can use to monitor your resources in a single view, even those resources that are spread across\n\ndiﬀerent AWS Regions and accounts.\n\nImplementation steps\n\n1. Create a basic dashboard: Create a new dashboard in CloudWatch, giving it a descriptive name.\n\n2. Use Markdown widgets: Before diving into the metrics, use Markdown widgets to add textual context at the top of your dashboard. This should explain what the dashboard covers, the signiﬁcance of the represented metrics, and can also contain links to other dashboards and\n\ntroubleshooting tools.\n\n3. Create dashboard variables: Incorporate dashboard variables where appropriate to allow for\n\ndynamic and ﬂexible dashboard views.\n\nOPS08-BP05 Create dashboards\n\n162\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Create metrics widgets: Add metric widgets to visualize various metrics your application emits,\n\ntailoring these widgets to eﬀectively represent system health and business outcomes.\n\n5. Log Insights queries: Utilize CloudWatch Log Insights to derive actionable metrics from your\n\nlogs and display these insights on your dashboard.\n\n6. Set up alarms: Integrate CloudWatch Alarms into your dashboard for a quick view of any metrics\n\nbreaching their thresholds.\n\n7. Use Contributor Insights: Incorporate CloudWatch Contributor Insights to analyze high- cardinality ﬁelds and get a clearer understanding of your resource's top contributors.\n\n8. Design custom widgets: For speciﬁc needs not met by standard widgets, consider creating custom widgets. These can pull from various data sources or represent data in unique ways.\n\n9. Use AWS Health: AWS Health is the authoritative source of information about the health of your\n\nAWS Cloud resources. Use AWS Health Dashboard out of the box, or use AWS Health data in\n\nyour own dashboards and tools so you have the right information available to make informed decisions.\n\n10.Iterate and reﬁne: As your application evolves, regularly revisit your dashboard to ensure its\n\nrelevance.\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS08-BP01 Analyze workload metrics\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\nOPS08-BP04 Create actionable alerts\n\nRelated documents:\n\nBuilding Dashboards for Operational Visibility\n\nUsing Amazon CloudWatch Dashboards\n\nRelated videos:\n\nCreate Cross Account & Cross Region CloudWatch Dashboards\n\nOPS08-BP05 Create dashboards\n\n163\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS re:Invent 2021 - Gain enterprise visibility with AWS Cloud operation dashboards)\n\nRelated examples:\n\nOne Observability Workshop\n\nApplication Monitoring with Amazon CloudWatch\n\nAWS Health Events Intelligence Dashboards and Insights\n\nVisualize AWS Health events using Amazon Managed Grafana\n\nUnderstanding operational health\n\nDeﬁne, capture, and analyze operations metrics to gain visibility to the activities of operations teams so that you can take appropriate action.\n\nYour organization should be able to understand the health of your operations easily. You will want\n\nto deﬁne the business goals of your operations teams, identify key performance indicators that\n\nreﬂect those goals. Afterwards, develop and use metrics based on operations outcomes to gain\n\nuseful insights. You should use these metrics to implement dashboards and reports with business\n\nand technical viewpoints that will help leaders and stakeholders make informed decisions.\n\nAWS makes it easier to bring together and analyze your operations logs so that you can generate\n\nmetrics, know the status of your operations, and gain insight from operations over time.\n\nBest practices\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nObtain goals and KPIs that deﬁne operations success from your organization and determine that\n\nmetrics reﬂect these. Set baselines as a point of reference and reevaluate regularly. Develop\n\nmechanisms to collect these metrics from teams for evaluation. The DevOps Research and\n\nAssessment (DORA) metrics provide a popular method to measure progress towards DevOps\n\npractices of software delivery.\n\nUnderstanding operational health\n\n164\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome:\n\nThe organization publishes and shares the goals and KPIs for the operations teams.\n\nYou establish metrics that reﬂect these KPIs. Examples may include:\n\nTicket queue depth or average age of ticket\n\nTicket count grouped by type of issue\n\nTime spent working issues with or without a standardized operating procedure (SOP)\n\nAmount of time spent recovering from a failed code push\n\nCall volume\n\nCommon anti-patterns:\n\nDeployment deadlines are missed because developers are pulled away to perform\n\ntroubleshooting tasks. Development teams argue for more personnel, but cannot quantify how\n\nmany they need because the time taken away cannot be measured.\n\nA Tier 1 desk was set up to handle user calls. Over time, more workloads were added, but no\n\nheadcount was allocated to the Tier 1 desk. Customer satisfaction suﬀers as call times increase\n\nand issues go longer without resolution, but management sees no indicators of such, preventing\n\nany action.\n\nA problematic workload has been handed oﬀ to a separate operations team for upkeep. Unlike\n\nother workloads, this new one was not supplied with proper documentation and runbooks. As\n\nsuch, teams spend longer troubleshooting and addressing failures. However, there are no metrics\n\ndocumenting this, which makes accountability diﬃcult.\n\nBeneﬁts of establishing this best practice: Where workload monitoring shows the state of our applications and services, monitoring operations teams provides owners insight into\n\nchanges among the consumers of those workloads, such as shifting business needs. Measure the\n\neﬀectiveness of these teams and evaluate them against business goals by creating metrics that can\n\nreﬂect the state of operations. Metrics can highlight support issues or identify when drifts occur\n\naway from a service level target.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\n165\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nSchedule time with business leaders and stakeholders to determine what the overall goals of\n\nthe service will be. Determine what the tasks of various operations teams should be and what\n\nchallenges they could be approached with. Using these, brainstorm key performance indicators\n\n(KPIs) that might reﬂect these operations goals. These might be customer satisfaction, time from\n\nfeature conception to deployment, average issue resolution time, or cost eﬃciencies.\n\nWorking from KPIs, identify the metrics and sources of data that might reﬂect these goals best.\n\nCustomer satisfaction may be an combination of various metrics such as call wait or response\n\ntimes, satisfaction scores, and types of issues raised. Deployment times may be the sum of time\n\nneeded for testing and deployment, plus any post-deployment ﬁxes that needed to be added.\n\nStatistics showing the time spent on diﬀerent types of issues (or the counts of those issues) can\n\nprovide a window into where targeted eﬀort is needed.\n\nResources\n\nRelated documents:\n\nQuick Suite - Using KPIs\n\nAmazon CloudWatch - Using Metrics\n\nBuilding Dashboards\n\nHow to track your cost optimization KPIs with KPI Dashboard\n\nAWS DevOps Guidance\n\nRelated examples:\n\nMonitor the performance of your software delivery using native AWS monitoring and\n\nobservability tools\n\nBalance deployment speed and stability with DORA metrics\n\nExample MLOps operational metrics in the ﬁnancial services industry\n\nHow to track your cost optimization KPIs with the KPI Dashboard\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\n166",
      "page_number": 149
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 172-182)",
      "start_page": 172,
      "end_page": 182,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS09-BP02 Communicate status and trends to ensure visibility into\n\noperation\n\nKnowing the state of your operations and its trending direction is necessary to identify when\n\noutcomes may be at risk, whether or not added work can be supported, or the eﬀects that\n\nchanges have had to your teams. During operations events, having status pages that users and\n\noperations teams can refer to for information can reduce pressure on communication channels and\n\ndisseminate information proactively.\n\nDesired outcome:\n\nOperations leaders have insight at a glance to see what sort of call volumes their teams are\n\noperating under and what eﬀorts may be under way, such as deployments.\n\nAlerts are disseminated to stakeholders and user communities when impacts to normal\n\noperations occur.\n\nOrganization leadership and stakeholders can check a status page in response to an alert or\n\nimpact, and obtain information surrounding an operational event, such as points of contact,\n\nticket information, and estimated recovery times.\n\nReports are made available to leadership and other stakeholders to show operations statistics\n\nsuch as call volumes over a period of time, user satisfaction scores, numbers of outstanding\n\ntickets and their ages.\n\nCommon anti-patterns:\n\nA workload goes down, leaving a service unavailable. Call volumes spike as users request to\n\nknow what's going on. Managers add to the volume requesting to know who's working an issue.\n\nVarious operations teams duplicate eﬀorts in trying to investigate.\n\nA desire for a new capability leads to several personnel being reassigned to an engineering\n\neﬀort. No backﬁll is provided, and issue resolution times spike. This information is not captured,\n\nand only after several weeks and dissatisﬁed user feedback does leadership become aware of the\n\nissue.\n\nBeneﬁts of establishing this best practice: During operational events where the business is impacted, much time and energy can be wasted querying information from various teams\n\nattempting to understand the situation. By establishing widely-disseminated status pages and\n\ndashboards, stakeholders can quickly obtain information such as whether or not an issue was\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation\n\n167\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\ndetected, who has lead on the issue, or when a return to normal operations may be expected. This\n\nfrees team members from spending too much time communicating status to others and more time addressing issues.\n\nIn addition, dashboards and reports can provide insights to decision-makers and stakeholders to\n\nsee how operations teams are able to respond to business needs and how their resources are being\n\nallocated. This is crucial for determining if adequate resources are in place to support the business.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nBuild dashboards that show the current key metrics for your ops teams, and make them readily\n\naccessible both to operations leaders and management.\n\nBuild status pages that can be updated quickly to show when an incident or event is unfolding,\n\nwho has ownership and who is coordinating the response. Share any steps or workarounds that\n\nusers should consider on this page, and disseminate the location widely. Encourage users to check\n\nthis location ﬁrst when confronted with an unknown issue.\n\nCollect and provide reports that show the health of operations over time, and distribute this to\n\nleaders and decision makers to illustrate the work of operations along with challenges and needs.\n\nShare between teams these metrics and reports that best reﬂect goals and KPIs and where they\n\nhave been inﬂuential in driving change. Dedicate time to these activities to elevate the importance\n\nof operations inside of and between teams.\n\nUse AWS Health alongside your own dashboards, or integrate AWS Health events into them, so\n\nthat your teams can correlate application issues to AWS service status.\n\nResources\n\nRelated best practices:\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nRelated documents:\n\nMeasure Progress\n\nBuilding dashboards for operation visibility\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation\n\n168\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated examples:\n\nData Operations\n\nHow to track your cost optimization KPIs with KPI Dashboard\n\nThe Importance of Key Performance Indicators (KPIs) for Large-Scale Cloud Migrations\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nSetting aside dedicated time and resources for reviewing the state of operations ensures that\n\nserving the day-to-day line of business remains a priority. Pull together operations leaders and\n\nstakeholders to regularly review metrics, reaﬃrm or modify goals and objectives, and prioritize\n\nimprovements.\n\nDesired outcome:\n\nOperations leaders and staﬀ regularly meet to review metrics over a given reporting period.\n\nChallenges are communicated, wins are celebrated, and lessons learned are shared.\n\nStakeholders and business leaders are regularly briefed on the state of operations and solicited\n\nfor input regarding goals, KPIs, and future initiatives. Tradeoﬀs between service delivery,\n\noperations, and maintenance are discussed and placed into context.\n\nCommon anti-patterns:\n\nA new product is launched, but the Tier 1 and Tier 2 operations teams are not adequately trained\n\nto support or given additional staﬀ. Metrics that show the decrease in ticket resolution times\n\nand increase in incident volumes are not seen by leaders. Action is taken weeks later when\n\nsubscription numbers start to fall as discontent users move oﬀ the platform.\n\nA manual process for performing maintenance on a workload has been in place for a long time.\n\nWhile a desire to automate has been present, this was a low priority given the low importance\n\nof the system. Over time however, the system has grown in importance and now these manual\n\nprocesses consume a majority of operations' time. No resources are scheduled for providing\n\nincreased tooling to operations, leading to staﬀ burnout as workloads increase. Leadership\n\nbecomes aware once it's reported that staﬀ are leaving for other competitors.\n\nBeneﬁts of establishing this best practice: In some organizations, it can become a challenge to allocate the same time and attention that is aﬀorded to service delivery and new products or\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\n169\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\noﬀerings. When this occurs, the line of business can suﬀer as the level of service expected slowly\n\ndeteriorates. This is because operations does not change and evolve with the growing business, and can soon be left behind. Without regular review into the insights operations collects, the risk\n\nto the business may become visible only when it's too late. By allocating time to review metrics\n\nand procedures both among the operations staﬀ and with leadership, the crucial role operations\n\nplays remains visible, and risks can be identiﬁed long before they reach critical levels. Operations\n\nteams get better insight into impending business changes and initiatives, allowing for proactive\n\neﬀorts to be undertaken. Leadership visibility into operations metrics showcases the role that these\n\nteams play in customer satisfaction, both internal and external, and let them better weigh choices\n\nfor priorities, or ensure that operations has the time and resources to change and evolve with new\n\nbusiness and workload initiatives.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nDedicate time to review operations metrics between stakeholders and operations teams and\n\nreview report data. Place these reports in the contexts of the organizations goals and objectives to\n\ndetermine if they're being met. Identify sources of ambiguity where goals are not clear, or where\n\nthere may be conﬂicts between what is asked for and what is given.\n\nIdentify where time, people, and tools can aid in operations outcomes. Determine which KPIs this\n\nwould impact and what targets for success should be. Revisit regularly to ensure operations is\n\nresourced suﬃciently to support the line of business.\n\nResources\n\nRelated documents:\n\nAmazon Athena\n\nAmazon CloudWatch metrics and dimensions reference\n\nAmazon Quick Suite\n\nAWS Glue\n\nAWS Glue Data Catalog\n\nCollect metrics and logs from Amazon EC2 instances and on-premises servers with the Amazon\n\nCloudWatch Agent\n\nUsing Amazon CloudWatch metrics\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\n170\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResponding to events\n\nYou should anticipate operational events, both planned (for example, sales promotions,\n\ndeployments, and failure tests) and unplanned (for example, surges in utilization and component\n\nfailures). You should use your existing runbooks and playbooks to deliver consistent results when\n\nyou respond to alerts. Deﬁned alerts should be owned by a role or a team that is accountable\n\nfor the response and escalations. You will also want to know the business impact of your system\n\ncomponents and use this to target eﬀorts when needed. You should perform a root cause analysis\n\n(RCA) after events, and then prevent recurrence of failures or document workarounds.\n\nAWS simpliﬁes your event response by providing tools supporting all aspects of your workload and\n\noperations as code. These tools allow you to script responses to operations events and start their\n\ninitiation in response to monitoring data.\n\nIn AWS, you can improve recovery time by replacing failed components with known good versions,\n\nrather than trying to repair them. You can then carry out analysis on the failed resource out of\n\nband.\n\nBest practices\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP02 Have a process per alert\n\nOPS10-BP03 Prioritize operational events based on business impact\n\nOPS10-BP04 Deﬁne escalation paths\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\nOPS10-BP06 Communicate status through dashboards\n\nOPS10-BP07 Automate responses to events\n\nOPS10-BP01 Use a process for event, incident, and problem\n\nmanagement\n\nThe ability to eﬃciently manage events, incidents, and problems is key to maintaining workload\n\nhealth and performance. It's crucial to recognize and understand the diﬀerences between these\n\nelements to develop an eﬀective response and resolution strategy. Establishing and following a\n\nwell-deﬁned process for each aspect helps your team swiftly and eﬀectively handle any operational\n\nchallenges that arise.\n\nResponding to events\n\n171\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome: Your organization eﬀectively manages operational events, incidents, and problems through well-documented and centrally stored processes. These processes are consistently updated to reﬂect changes, streamlining handling and maintaining high service\n\nreliability and workload performance.\n\nCommon anti-patterns:\n\nYou reactively, rather than proactively, respond to events.\n\nInconsistent approaches are taken to diﬀerent types of events or incidents.\n\nYour organization does not analyze and learn from incidents to prevent future occurrences.\n\nBeneﬁts of establishing this best practice:\n\nStreamlined and standardized response processes.\n\nReduced impact of incidents on services and customers.\n\nExpedited issue resolution.\n\nContinuous improvement in operational processes.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplementing this best practice means you are tracking workload events. You have processes to\n\nhandle incidents and problems. The processes are documented, shared, and updated frequently.\n\nProblems are identiﬁed, prioritized, and ﬁxed.\n\nUnderstanding events, incidents, and problems\n\nEvents: An event is an observation of an action, occurrence, or change of state. Events can be\n\nplanned or unplanned and they can originate internally or externally to the workload.\n\nIncidents: Incidents are events that require a response, like unplanned interruptions or\n\ndegradations of service quality. They represent disruptions that need immediate attention to\n\nrestore normal workload operation.\n\nProblems: Problems are the underlying causes of one or more incidents. Identifying and\n\nresolving problems involves digging deeper into the incidents to prevent future occurrences.\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n172\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\nEvents\n\n1. Monitor events:\n\nImplement observability and utilize workload observability.\n\nMonitor actions taken by a user, role, or an AWS service are recorded as events in AWS\n\nCloudTrail.\n\nRespond to operational changes in your applications in real time with Amazon EventBridge.\n\nContinually assess, monitor, and record resource conﬁguration changes with AWS Conﬁg.\n\n2. Create processes:\n\nDevelop a process to assess which events are signiﬁcant and require monitoring. This involves\n\nsetting thresholds and parameters for normal and abnormal activities.\n\nDetermine criteria escalating an event to an incident. This could be based on the severity,\n\nimpact on users, or deviation from expected behavior.\n\nRegularly review the event monitoring and response processes. This includes analyzing past\n\nincidents, adjusting thresholds, and reﬁning alerting mechanisms.\n\nIncidents\n\n1. Respond to incidents:\n\nUse insights from observability tools to quickly identify and respond to incidents.\n\nImplement AWS Systems Manager Ops Center to aggregate, organize, and prioritize\n\noperational items and incidents.\n\nUse services like Amazon CloudWatch and AWS X-Ray for deeper analysis and\n\ntroubleshooting.\n\nConsider AWS Managed Services (AMS) for enhanced incident management, leveraging its\n\nproactive, preventative, and detective capabilities. AMS extends operational support with\n\nservices like monitoring, incident detection and response, and security management.\n\nEnterprise Support customers can use AWS Incident Detection and Response, which provides\n\ncontinual proactive monitoring and incident management for production workloads.\n\n2. Create an incident management process:\n\nEstablish a structured incident management process, including clear roles, communication\n\nprotocols, and steps for resolution.\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n173\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIntegrate incident management with tools like Amazon Q Developer in chat applications for\n\neﬃcient response and coordination.\n\nCategorize incidents by severity, with predeﬁned incident response plans for each category.\n\n3. Learn and improve:\n\nConduct post-incident analysis to understand root causes and resolution eﬀectiveness.\n\nContinually update and improve response plans based on reviews and evolving practices.\n\nDocument and share lessons learned across teams to enhance operational resilience.\n\nEnterprise Support customers can request the Incident Management Workshop from their\n\nTechnical Account Manager. This guided workshop tests your existing incident response plan\n\nand helps you identify areas for improvement.\n\nProblems\n\n1. Identify problems:\n\nUse data from previous incidents to identify recurring patterns that may indicate deeper\n\nsystemic issues.\n\nLeverage tools like AWS CloudTrail and Amazon CloudWatch to analyze trends and uncover\n\nunderlying problems.\n\nEngage cross-functional teams, including operations, development, and business units, to gain\n\ndiverse perspectives on the root causes.\n\n2. Create a problem management process:\n\nDevelop a structured process for problem management, focusing on long-term solutions\n\nrather than quick ﬁxes.\n\nIncorporate root cause analysis (RCA) techniques to investigate and understand the underlying\n\ncauses of incidents.\n\nUpdate operational policies, procedures, and infrastructure based on ﬁndings to prevent\n\nrecurrence.\n\n3. Continue to improve:\n\nFoster a culture of constant learning and improvement, encouraging teams to proactively\n\nidentify and address potential problems.\n\nRegularly review and revise problem management processes and tools to align with evolving\n\nbusiness and technology landscapes.\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n174\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nShare insights and best practices across the organization to build a more resilient and eﬃcient\n\noperational environment.\n\n4. Engage AWS Support:\n\nUse AWS support resources, such as AWS Trusted Advisor, for proactive guidance and\n\noptimization recommendations.\n\nEnterprise Support customers can access specialized programs like AWS Countdown for\n\nsupport during critical events.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS07-BP04 Use playbooks to investigate issues\n\nOPS08-BP01 Analyze workload metrics\n\nOPS11-BP02 Perform post-incident analysis\n\nRelated documents:\n\nAWS Security Incident Response Guide\n\nAWS Incident Detection and Response\n\nAWS Cloud Adoption Framework: Operations Perspective - Incident and problem management\n\nIncident Management in the Age of DevOps and SRE\n\nPagerDuty - What is Incident Management?\n\nRelated videos:\n\nTop incident response tips from AWS\n\nAWS re:Invent 2022 - The Amazon Builders' Library: 25 yrs of Amazon operational excellence\n\nAWS re:Invent 2022 - AWS Incident Detection and Response (SUP201)\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n175\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIntroducing Incident Manager from AWS Systems Manager\n\nRelated examples:\n\nAWS Proactive Services – Incident Management Workshop\n\nHow to Automate Incident Response with PagerDuty and AWS Systems Manager Incident\n\nManager\n\nEngage Incident Responders with the On-Call Schedules in AWS Systems Manager Incident\n\nManager\n\nImprove the Visibility and Collaboration during Incident Handling in AWS Systems Manager\n\nIncident Manager\n\nIncident reports and service requests in AMS\n\nRelated services:\n\nAmazon EventBridge\n\nOPS10-BP02 Have a process per alert\n\nEstablishing a clear and deﬁned process for each alert in your system is essential for eﬀective and\n\neﬃcient incident management. This practice ensures that every alert leads to a speciﬁc, actionable\n\nresponse, improving the reliability and responsiveness of your operations.\n\nDesired outcome: Every alert initiates a speciﬁc, well-deﬁned response plan. Where possible, responses are automated, with clear ownership and a deﬁned escalation path. Alerts are linked\n\nto an up-to-date knowledge base so that any operator can respond consistently and eﬀectively.\n\nResponses are quick and uniform across the board, enhancing operational eﬃciency and reliability.\n\nCommon anti-patterns:\n\nAlerts have no predeﬁned response process, leading to makeshift and delayed resolutions.\n\nAlert overload causes important alerts to be overlooked.\n\nAlerts are inconsistently handled due to lack of clear ownership and responsibility.\n\nBeneﬁts of establishing this best practice:\n\nOPS10-BP02 Have a process per alert\n\n176\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nReduced alert fatigue by only raising actionable alerts.\n\nDecreased mean time to resolution (MTTR) for operational issues.\n\nDecreased mean time to investigate (MTTI), which helps reduce MTTR.\n\nEnhanced ability to scale operational responses.\n\nImproved consistency and reliability in handling operational events.\n\nFor example, you have a deﬁned process for AWS Health events for critical accounts, including\n\napplication alarms, operational issues, and planned lifecycle events (like updating Amazon EKS\n\nversions before clusters are auto-updated), and you provide the capability for your teams to\n\nactively monitor, communicate, and respond to these events. These actions help you prevent\n\nservice disruptions caused by AWS-side changes or mitigate them faster when unexpected issues\n\noccur.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nHaving a process per alert involves establishing a clear response plan for each alert, automating\n\nresponses where possible, and continually reﬁning these processes based on operational feedback\n\nand evolving requirements.\n\nImplementation steps\n\nThe following diagram illustrates the incident management workﬂow within AWS Systems\n\nManager Incident Manager. It is designed to respond swiftly to operational issues by automatically\n\ncreating incidents in response to speciﬁc events from Amazon CloudWatch or Amazon EventBridge.\n\nWhen an incident is created, either automatically or manually, Incident Manager centralizes\n\nthe management of the incident, organizes relevant AWS resource information, and initiates\n\npredeﬁned response plans. This includes running Systems Manager Automation runbooks for\n\nimmediate action, as well as creating a parent operational work item in OpsCenter to track related\n\ntasks and analyses. This streamlined process speeds up and coordinates incident response across\n\nyour AWS environment.\n\nOPS10-BP02 Have a process per alert\n\n177",
      "page_number": 172
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 183-195)",
      "start_page": 183,
      "end_page": 195,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n1. Use composite alarms: Create composite alarms in CloudWatch to group related alarms,\n\nreducing noise and allowing for more meaningful responses.\n\n2. Stay informed with AWS Health: AWS Health is the authoritative source of information about the health of your AWS Cloud resources. Use AWS Health to visualize and get notiﬁed of any\n\nOPS10-BP02 Have a process per alert\n\n178\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\ncurrent service events and upcoming changes, such as planned lifecycle events, so you can take\n\nsteps to mitigate impacts.\n\na. Create purpose-ﬁt AWS Health event notiﬁcations to e-mail and chat channels through AWS\n\nUser Notiﬁcations, and integrate programatically with your monitoring and alerting tools\n\nthrough Amazon EventBridge or the AWS Health API.\n\nb. Plan and track progress on health events that require action by integrating with change\n\nmanagement or ITSM tools (like Jira or ServiceNow) that you may already use through\n\nAmazon EventBridge or the AWS Health API.\n\nc. If you use AWS Organizations, enable organization view for AWS Health to aggregate AWS\n\nHealth events across accounts.\n\n3. Integrate Amazon CloudWatch alarms with Incident Manager: Conﬁgure CloudWatch alarms\n\nto automatically create incidents in AWS Systems Manager Incident Manager.\n\n4. Integrate Amazon EventBridge with Incident Manager: Create EventBridge rules to react to\n\nevents and create incidents using deﬁned response plans.\n\n5. Prepare for incidents in Incident Manager:\n\nEstablish detailed response plans in Incident Manager for each type of alert.\n\nEstablish chat channels through Amazon Q Developer in chat applications connected to\n\nresponse plans in Incident Manager, facilitating real-time communication during incidents\n\nacross platforms like Slack, Microsoft Teams, and Amazon Chime.\n\nIncorporate Systems Manager Automation runbooks within Incident Manager to drive\n\nautomated responses to incidents.\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS08-BP04 Create actionable alerts\n\nRelated documents:\n\nAWS Cloud Adoption Framework: Operations Perspective - Incident and problem management\n\nUsing Amazon CloudWatch alarms\n\nSetting up AWS Systems Manager Incident Manager\n\nOPS10-BP02 Have a process per alert\n\n179\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nPreparing for incidents in Incident Manager\n\nRelated videos:\n\nTop incident response tips from AWS\n\nre:Invent 2023 | Manage resource lifecycle events at scale with AWS Health\n\nRelated examples:\n\nAWS Workshops - AWS Systems Manager Incident Manager - Automate incident response to\n\nsecurity events\n\nOPS10-BP03 Prioritize operational events based on business impact\n\nResponding promptly to operational events is critical, but not all events are equal. When you\n\nprioritize based on business impact, you also prioritize addressing events with the potential\n\nfor signiﬁcant consequences, such as safety, ﬁnancial loss, regulatory violations, or damage to\n\nreputation.\n\nDesired outcome: Responses to operational events are prioritized based on potential impact to business operations and objectives. This makes the responses eﬃcient and eﬀective.\n\nCommon anti-patterns:\n\nEvery event is treated with the same level of urgency, leading to confusion and delays in\n\naddressing critical issues.\n\nYou fail to distinguish between high and low impact events, leading to misallocation of\n\nresources.\n\nYour organization lacks a clear prioritization framework, resulting in inconsistent responses to\n\noperational events.\n\nEvents are prioritized based on the order they are reported, rather than their impact on business\n\noutcomes.\n\nBeneﬁts of establishing this best practice:\n\nEnsures critical business functions receive attention ﬁrst, minimizing potential damage.\n\nImproves resource allocation during multiple concurrent events.\n\nOPS10-BP03 Prioritize operational events based on business impact\n\n180\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEnhances the organization's ability to maintain trust and meet regulatory requirements.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nWhen faced with multiple operational events, a structured approach to prioritization based on\n\nimpact and urgency is essential. This approach helps you make informed decisions, direct eﬀorts\n\nwhere they're needed most, and mitigate the risk to business continuity.\n\nImplementation steps\n\n1. Assess impact: Develop a classiﬁcation system to evaluate the severity of events in terms of their potential impact on business operations and objectives. The following example shows impact categories:\n\nImpact level\n\nDescription\n\nHigh\n\nAﬀects many staﬀ or customers, high ﬁnancial impact, high reputational damage,\n\nor injury.\n\nMedium\n\nAﬀects a groups of staﬀ or customers, moderate ﬁnancial impact, or moderate\n\nreputational damage.\n\nLow\n\nAﬀects individual staﬀ or customers, low ﬁnancial impact, or low reputational damage.\n\n2. Assess urgency: Deﬁne urgency levels for how quickly an event needs a response, considering\n\nfactors such as safety, ﬁnancial implications, and service-level agreements (SLAs). The following\n\nexample demonstrates urgency categories:\n\nUrgency level\n\nDescription\n\nHigh\n\nExponentially increasing damage, time-sens itive work impacted, imminent escalation, or\n\nVIP users or groups aﬀected.\n\nOPS10-BP03 Prioritize operational events based on business impact\n\n181\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUrgency level\n\nDescription\n\nMedium\n\nDamage increases over time, or single VIP user or group aﬀected.\n\nLow\n\nMarginal damage increase over time, or non- time-sensitive work impacted.\n\n3. Create a prioritization matrix:\n\nUse a matrix to cross-reference impact and urgency, assigning priority levels to diﬀerent\n\ncombinations.\n\nMake the matrix accessible and understood by all team members responsible for operational\n\nevent responses.\n\nThe following example matrix displays incident severity according to urgency and impact:\n\nUrgency and impact\n\nHigh\n\nMedium\n\nLow\n\nHigh\n\nCritical\n\nUrgent\n\nHigh\n\nMedium\n\nUrgent\n\nHigh\n\nNormal\n\nLow\n\nHigh\n\nNormal\n\nLow\n\n4. Train and communicate: Train response teams on the prioritization matrix and the importance\n\nof following it during an event. Communicate the prioritization process to all stakeholders to set\n\nclear expectations.\n\n5. Integrate with incident response:\n\nIncorporate the prioritization matrix into your incident response plans and tools.\n\nAutomate the classiﬁcation and prioritization of events where possible to speed up response\n\ntimes.\n\nEnterprise Support customers can leverage AWS Incident Detection and Response, which\n\nprovides 24x7 proactive monitoring and incident management for production workloads.\n\n6. Review and adapt: Regularly review the eﬀectiveness of the prioritization process and make\n\nadjustments based on feedback and changes in the business environment.\n\nOPS10-BP03 Prioritize operational events based on business impact\n\n182\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS03-BP03 Escalation is encouraged\n\nOPS08-BP04 Create actionable alerts\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nRelated documents:\n\nAtlassian - Understanding incident severity levels\n\nIT Process Map - Checklist Incident Priority\n\nOPS10-BP04 Deﬁne escalation paths\n\nEstablish clear escalation paths within your incident response protocols to facilitate timely and\n\neﬀective action. This includes specifying prompts for escalation, detailing the escalation process,\n\nand pre-approving actions to expedite decision-making and reduce mean time to resolution\n\n(MTTR).\n\nDesired outcome: A structured and eﬃcient process that escalates incidents to the appropriate personnel, minimizing response times and impact.\n\nCommon anti-patterns:\n\nLack of clarity on recovery procedures leads to makeshift responses during critical incidents.\n\nAbsence of deﬁned permissions and ownership results in delays when urgent action is needed.\n\nStakeholders and customers are not informed in line with expectations.\n\nImportant decisions are delayed.\n\nBeneﬁts of establishing this best practice:\n\nStreamlined incident response through predeﬁned escalation procedures.\n\nReduced downtime with pre-approved actions and clear ownership.\n\nImproved resource allocation and support-level adjustments according to incident severity.\n\nImproved communication to stakeholders and customers.\n\nOPS10-BP04 Deﬁne escalation paths\n\n183\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nProperly deﬁned escalation paths are crucial for rapid incident response. AWS Systems Manager\n\nIncident Manager supports the setup of structured escalation plans and on-call schedules, which\n\nalert the right personnel so that they are ready to act when incidents occur.\n\nImplementation steps\n\n1. Set up escalation prompts: Set up CloudWatch alarms to create an incident in AWS Systems\n\nManager Incident Manager.\n\n2. Set up on-call schedules: Create on-call schedules in Incident Manager that align with your\n\nescalation paths. Equip on-call personnel with the necessary permissions and tools to act swiftly.\n\n3. Detail escalation procedures:\n\nDetermine speciﬁc conditions under which an incident should be escalated.\n\nCreate escalation plans in Incident Manager.\n\nEscalation channels should consist of a contact or an on-call schedule.\n\nDeﬁne the roles and responsibilities of the team at each escalation level.\n\n4. Pre-approve mitigation actions: Collaborate with decision-makers to pre-approve actions for anticipated scenarios. Use Systems Manager Automation runbooks integrated with Incident Manager to speed up incident resolution.\n\n5. Specify ownership: Clearly identify internal owners for each step of the escalation path.\n\n6. Detail third-party escalations:\n\nDocument third-party service-level agreements (SLAs), and align them with internal goals.\n\nSet clear protocols for vendor communication during incidents.\n\nIntegrate vendor contacts into incident management tools for direct access.\n\nConduct regular drills that include third-party response scenarios.\n\nKeep vendor escalation information well-documented and easily accessible.\n\n7. Train and rehearse escalation plans: Train your team on the escalation process and conduct regular incident response drills or game days. Enterprise Support customers can request an Incident Management Workshop.\n\n8. Continue to improve: Review the eﬀectiveness of your escalation paths regularly. Update your processes based on lessons learned from incident post-mortems and continuous feedback. 184\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: Moderate\n\nResources\n\nRelated best practices:\n\nOPS08-BP04 Create actionable alerts\n\nOPS10-BP02 Have a process per alert\n\nOPS11-BP02 Perform post-incident analysis\n\nRelated documents:\n\nAWS Systems Manager Incident Manager Escalation Plans\n\nWorking with on-call schedules in Incident Manager\n\nCreating and Managing Runbooks\n\nTemporary elevated access management with AWS IAM Identity Center\n\nAtlassian - Escalation policies for eﬀective incident management\n\nOPS10-BP05 Deﬁne a customer communication plan for service-\n\nimpacting events\n\nEﬀective communication during service impacting events is critical to maintain trust and\n\ntransparency with customers. A well-deﬁned communication plan helps your organization quickly\n\nand clearly share information, both internally and externally, during incidents.\n\nDesired outcome:\n\nA robust communication plan that eﬀectively informs customers and stakeholders during service\n\nimpacting events.\n\nTransparency in communication to build trust and reduce customer anxiety.\n\nMinimizing the impact of service impacting events on customer experience and business\n\noperations.\n\nCommon anti-patterns:\n\nInadequate or delayed communication leads to customer confusion and dissatisfaction.\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\n185\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOverly technical or vague messaging fails to convey the actual impact on users.\n\nThere is no predeﬁned communication strategy, resulting in inconsistent and reactive messaging.\n\nBeneﬁts of establishing this best practice:\n\nEnhanced customer trust and satisfaction through proactive and clear communication.\n\nReduced burden on support teams by preemptively addressing customer concerns.\n\nImproved ability to manage and recover from incidents eﬀectively.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nCreating a comprehensive communication plan for service impacting events involves multiple\n\nfacets, from choosing the right channels to crafting the message and tone. The plan should be\n\nadaptable, scalable, and cater to diﬀerent outage scenarios.\n\nImplementation steps\n\n1. Deﬁne roles and responsibilities:\n\nAssign a major incident manager to oversee incident response activities.\n\nDesignate a communications manager responsible for coordinating all external and internal\n\ncommunications.\n\nInclude the support manager to provide consistent communication through support tickets.\n\n2. Identify communication channels: Select channels like workplace chat, email, SMS, social\n\nmedia, in-app notiﬁcations, and status pages. These channels should be resilient and able to\n\noperate independently during service impacting events.\n\n3. Communicate quickly, clearly, and regularly to customers:\n\nDevelop templates for various service impairment scenarios, emphasizing simplicity and\n\nessential details. Include information about the service impairment, expected resolution time,\n\nand impact.\n\nUse Amazon Pinpoint to alert customers using push notiﬁcations, in-app notiﬁcations, emails,\n\ntext messages, voice messages, and messages over custom channels.\n\nUse Amazon Simple Notiﬁcation Service (Amazon SNS) to alert subscribers programatically or\n\nthrough email, mobile push notiﬁcations, and text messages.\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\n186\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommunicate status through dashboards by sharing an Amazon CloudWatch dashboard\n\npublicly.\n\nEncourage social media engagement:\n\nActively monitor social media to understand customer sentiment.\n\nPost on social media platforms for public updates and community engagement.\n\nPrepare templates for consistent and clear social media communication.\n\n4. Coordinate internal communication: Implement internal protocols using tools like Amazon Q Developer in chat applications for team coordination and communication. Use CloudWatch dashboards to communicate status.\n\n5. Orchestrate communication with dedicated tools and services:\n\nUse AWS Systems Manager Incident Manager with Amazon Q Developer in chat applications\n\nto set up dedicated chat channels for real-time internal communication and coordination during incidents.\n\nUse AWS Systems Manager Incident Manager runbooks to automate customer notiﬁcations\n\nthrough Amazon Pinpoint, Amazon SNS, or third-party tools like social media platforms\n\nduring incidents.\n\nIncorporate approval workﬂows within runbooks to optionally review and authorize all\n\nexternal communications before sending.\n\n6. Practice and improve:\n\nConduct training on the use of communication tools and strategies. Empower teams to make\n\ntimely decisions during incidents.\n\nTest the communication plan through regular drills or gamedays. Use these tests to reﬁne\n\nmessaging and evaluate the eﬀectiveness of channels.\n\nImplement feedback mechanisms to assess communication eﬀectiveness during incidents.\n\nContinually evolve the communication plan based on feedback and changing needs.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS10-BP06 Communicate status through dashboards\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\n187\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP02 Perform post-incident analysis\n\nRelated documents:\n\nAtlassian - Incident communication best practices\n\nAtlassian - How to write a good status update\n\nPagerDuty - A Guide to Incident Communications\n\nRelated videos:\n\nAtlassian - Create your own incident communication plan: Incident templates\n\nRelated examples:\n\nAWS Health Dashboard\n\nOPS10-BP06 Communicate status through dashboards\n\nUse dashboards as a strategic tool to convey real-time operational status and key metrics\n\nto diﬀerent audiences, including internal technical teams, leadership, and customers. These\n\ndashboards oﬀer a centralized, visual representation of system health and business performance,\n\nenhancing transparency and decision-making eﬃciency.\n\nDesired outcome:\n\nYour dashboards provide a comprehensive view of the system and business metrics relevant to\n\ndiﬀerent stakeholders.\n\nStakeholders can proactively access operational information, reducing the need for frequent\n\nstatus requests.\n\nReal-time decision-making is enhanced during normal operations and incidents.\n\nCommon anti-patterns:\n\nEngineers joining an incident management call require status updates to get up to speed.\n\nRelying on manual reporting for management, which leads to delays and potential inaccuracies.\n\nOperations teams are frequently interrupted for status updates during incidents.\n\nOPS10-BP06 Communicate status through dashboards\n\n188\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nEmpowers stakeholders with immediate access to critical information, promoting informed\n\ndecision-making.\n\nReduces operational ineﬃciencies by minimizing manual reporting and frequent status inquiries.\n\nIncreases transparency and trust through real-time visibility into system performance and\n\nbusiness metrics.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nDashboards eﬀectively communicate the status of your system and business metrics and can be\n\ntailored to the needs of diﬀerent audience groups. Tools like Amazon CloudWatch dashboards and Amazon Quick Suite help you create interactive, real-time dashboards for system monitoring and\n\nbusiness intelligence.\n\nImplementation steps\n\n1. Identify stakeholder needs: Determine the speciﬁc information needs of diﬀerent audience\n\ngroups, such as technical teams, leadership, and customers.\n\n2. Choose the right tools: Select appropriate tools like Amazon CloudWatch dashboards for\n\nsystem monitoring and Amazon Quick Suite for interactive business intelligence. AWS Health\n\nprovides a ready-to-use experience in the AWS Health Dashboard, or you can use Health events\n\nin Amazon EventBridge or through the AWS Health API to augment your own dashboards.\n\n3. Design eﬀective dashboards:\n\nDesign dashboards to clearly present relevant metrics and KPIs, ensuring they are\n\nunderstandable and actionable.\n\nIncorporate system-level and business-level views as needed.\n\nInclude both high-level (for broad overviews) and low-level (for detailed analysis) dashboards.\n\nIntegrate automated alarms within dashboards to highlight critical issues.\n\nAnnotate dashboards with important metrics thresholds and goals for immediate visibility.\n\n4. Integrate data sources:\n\nUse Amazon CloudWatch to aggregate and display metrics from various AWS services and\n\nquery metrics from other data sources, creating a uniﬁed view of your system's health and\n\nbusiness metrics.\n\nOPS10-BP06 Communicate status through dashboards\n\n189\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUse features like CloudWatch Logs Insights to query and visualize log data from diﬀerent\n\napplications and services.\n\nUse AWS Health events to stay informed about the operational status and conﬁrmed\n\noperational issues from AWS services through the AWS Health API or AWS Health events on\n\nAmazon EventBridge.\n\n5. Provide self-service access:\n\nShare CloudWatch dashboards with relevant stakeholders for self-service information access\n\nusing dashboard sharing features.\n\nEnsure that dashboards are easily accessible and provide real-time, up-to-date information.\n\n6. Regularly update and reﬁne:\n\nContinually update and reﬁne dashboards to align with evolving business needs and\n\nstakeholder feedback.\n\nRegularly review the dashboards to keep them relevant and eﬀective for conveying the\n\nnecessary information.\n\nResources\n\nRelated best practices:\n\nOPS08-BP05 Create dashboards\n\nRelated documents:\n\nBuilding dashboards for operational visibility\n\nUsing Amazon CloudWatch dashboards\n\nCreate ﬂexible dashboards with dashboard variables\n\nSharing CloudWatch dashboards\n\nQuery metrics from other data sources\n\nAdd a custom widget to a CloudWatch dashboard\n\nRelated examples:\n\nOne Observability Workshop - Dashboards\n\nOPS10-BP06 Communicate status through dashboards\n\n190",
      "page_number": 183
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 196-203)",
      "start_page": 196,
      "end_page": 203,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS10-BP07 Automate responses to events\n\nAutomating event responses is key for fast, consistent, and error-free operational handling. Create\n\nstreamlined processes and use tools to automatically manage and respond to events, minimizing\n\nmanual interventions and enhancing operational eﬀectiveness.\n\nDesired outcome:\n\nReduced human errors and faster resolution times through automation.\n\nConsistent and reliable operational event handling.\n\nEnhanced operational eﬃciency and system reliability.\n\nCommon anti-patterns:\n\nManual event handling leads to delays and errors.\n\nAutomation is overlooked in repetitive, critical tasks.\n\nRepetitive, manual tasks lead to alert fatigue and missing critical issues.\n\nBeneﬁts of establishing this best practice:\n\nAccelerated event responses, reducing system downtime.\n\nReliable operations with automated and consistent event handling.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nIncorporate automation to create eﬃcient operational workﬂows and minimize manual interventions.\n\nImplementation steps\n\n1. Identify automation opportunites: Determine repetitive tasks for automation, such as issue remediation, ticket enrichment, capacity management, scaling, deployments, and testing.\n\n2. Identify automation prompts:\n\nAssess and deﬁne speciﬁc conditions or metrics that initiate automated responses using\n\nAmazon CloudWatch alarm actions.\n\nOPS10-BP07 Automate responses to events\n\n191\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUse Amazon EventBridge to respond to events in AWS services, custom workloads, and SaaS\n\napplications.\n\nConsider initiation events such as speciﬁc log entries, performance metrics thresholds, or state\n\nchanges in AWS resources.\n\n3. Implement event-driven automation:\n\nUse AWS Systems Manager Automation runbooks to simplify maintenance, deployment, and\n\nremediation tasks.\n\nCreating incidents in Incident Manager automatically gathers and adds details about the\n\ninvolved AWS resources to the incident.\n\nProactively monitor quotas using Quota Monitor for AWS.\n\nAutomatically adjust capacity with AWS Auto Scaling to maintain availability and\n\nperformance.\n\nAutomate development pipelines with Amazon CodeCatalyst.\n\nSmoke test or continually monitor endpoints and APIs using synthetic monitoring.\n\n4. Perform risk mitigation through automation:\n\nImplement automated security responses to swiftly address risks.\n\nUse AWS Systems Manager State Manager to reduce conﬁguration drift.\n\nRemediate noncompliant resources with AWS Conﬁg Rules.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS08-BP04 Create actionable alerts\n\nOPS10-BP02 Have a process per alert\n\nRelated documents:\n\nUsing Systems Manager Automation runbooks with Incident Manager\n\nCreating incidents in Incident Manager\n\nAWS service quotas\n\nMonitor resource usage and send notiﬁcations when approaching quotas\n\nOPS10-BP07 Automate responses to events\n\n192\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Auto Scaling\n\nWhat is Amazon CodeCatalyst?\n\nUsing Amazon CloudWatch alarms\n\nUsing Amazon CloudWatch alarm actions\n\nRemediating Noncompliant Resources with AWS Conﬁg Rules\n\nCreating metrics from log events using ﬁlters\n\nAWS Systems Manager State Manager\n\nRelated videos:\n\nCreate Automation Runbooks with AWS Systems Manager\n\nHow to automate IT Operations on AWS\n\nAWS Security Hub CSPM automation rules\n\nStart your software project fast with Amazon CodeCatalyst blueprints\n\nRelated examples:\n\nAmazon CodeCatalyst Tutorial: Creating a project with the Modern three-tier web application\n\nblueprint\n\nOne Observability Workshop\n\nRespond to incidents using Incident Manager\n\nOPS10-BP07 Automate responses to events\n\n193\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEvolve\n\nLearn, share, and continuously improve to sustain operational excellence. Dedicate work cycles\n\nto making nearly continuous incremental improvements. Perform post-incident analysis of all\n\ncustomer impacting events. Identify the contributing factors and preventative action to limit or\n\nprevent recurrence. Communicate contributing factors with aﬀected communities as appropriate.\n\nRegularly evaluate and prioritize opportunities for improvement (for example, feature requests,\n\nissue remediation, and compliance requirements), including both the workload and operations\n\nprocedures.\n\nInclude feedback loops within your procedures to rapidly identify areas for improvement and\n\ncapture learnings from running operations.\n\nShare lessons learned across teams. Analyze trends within lessons learned and perform cross-\n\nteam retrospective analysis of operations metrics to identify opportunities and methods for\n\nimprovement. Implement changes intended to bring about improvement and evaluate the results\n\nto determine success.\n\nOn AWS, you can export your log data to Amazon S3 or send logs directly to Amazon S3 for\n\nlong-term storage. Using AWS Glue, you can discover and prepare your log data in Amazon S3\n\nfor analytics, and store associated metadata in the AWS Glue Data Catalog. Amazon Athena,\n\nthrough its native integration with AWS Glue, can then be used to analyze your log data, querying\n\nit using standard SQL. Using a business intelligence tool like Amazon Quick Suite, you can\n\nvisualize, explore, and analyze your data. Discovering trends and events of interest that may drive\n\nimprovement.\n\nSuccessful evolution of operations is founded in frequent small improvements, providing safe\n\nenvironments and time to experiment, develop, and test improvements, and environments in which\n\nlearning from failures is encouraged. Operations support for sandbox, development, test, and\n\nproduction environments, with increasing level of operational controls, facilitates development and\n\nincreases the predictability of successful results from changes deployed into production.\n\nTopics\n\nLearn, share, and improve\n\n194\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLearn, share, and improve\n\nIt’s essential that you regularly provide time for analysis of operations activities, analysis of failures,\n\nexperimentation, and making improvements. When things fail, you will want to ensure that your\n\nteam, as well as your larger engineering community, learns from those failures. You should analyze\n\nfailures to identify lessons learned and plan improvements. You will want to regularly review your\n\nlessons learned with other teams to validate your insights.\n\nBest practices\n\nOPS11-BP01 Have a process for continuous improvement\n\nOPS11-BP02 Perform post-incident analysis\n\nOPS11-BP03 Implement feedback loops\n\nOPS11-BP04 Perform knowledge management\n\nOPS11-BP05 Deﬁne drivers for improvement\n\nOPS11-BP06 Validate insights\n\nOPS11-BP07 Perform operations metrics reviews\n\nOPS11-BP08 Document and share lessons learned\n\nOPS11-BP09 Allocate time to make improvements\n\nOPS11-BP01 Have a process for continuous improvement\n\nEvaluate your workload against internal and external architecture best practices. Conduct\n\nfrequent, intentional workload reviews. Prioritize improvement opportunities into your software\n\ndevelopment cadence.\n\nDesired outcome:\n\nYou analyze your workload against architecture best practices frequently.\n\nYou give improvement opportunities equal priority to features in your software development\n\nprocess.\n\nCommon anti-patterns:\n\nYou have not conducted an architecture review on your workload since it was deployed several\n\nyears ago.\n\nLearn, share, and improve\n\n195\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou give a lower priority to improvement opportunities. Compared to new features, these\n\nopportunities stay in the backlog.\n\nThere is no standard for implementing modiﬁcations to best practices for the organization.\n\nBeneﬁts of establishing this best practice:\n\nYour workload is kept up-to-date on architecture best practices.\n\nYou evolve your workload in an intentional manner.\n\nYou can leverage organization best practices to improve all workloads.\n\nYou make marginal gains that have a cumulative impact, which drives deeper eﬃciencies.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nFrequently conduct an architectural review of your workload. Use internal and external best\n\npractices, evaluate your workload, and identify improvement opportunities. Prioritize improvement\n\nopportunities into your software development cadence.\n\nImplementation steps\n\n1. Conduct periodic architecture reviews of your production workload with an agreed-upon\n\nfrequency. Use a documented architectural standard that includes AWS-speciﬁc best practices.\n\na. Use your internally-deﬁned standards for these reviews. If you do not have an internal\n\nstandard, use the AWS Well-Architected Framework.\n\nb. Use the AWS Well-Architected Tool to create a custom lens of your internal best practices and\n\nconduct your architecture review.\n\nc. Contact your AWS Solution Architect or Technical Account Manager to conduct a guided Well-\n\nArchitected Framework Review of your workload.\n\n2. Prioritize improvement opportunities identiﬁed during the review into your software\n\ndevelopment process.\n\nLevel of eﬀort for the implementation plan: Low. You can use the AWS Well-Architected Framework to conduct your yearly architecture review.\n\nOPS11-BP01 Have a process for continuous improvement\n\n196\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS11-BP02 Perform post-incident analysis\n\nOPS11-BP08 Document and share lessons learned\n\nOPS04 Implement Observability\n\nRelated documents:\n\nAWS Well-Architected Tool - Custom lenses\n\nAWS Well-Architected Whitepaper - The review process\n\nCustomize Well-Architected Reviews using Custom Lenses and the AWS Well-Architected Tool\n\nImplementing the AWS Well-Architected Custom Lens lifecycle in your organization\n\nRelated videos:\n\nAWS re:Invent 2023 - Scaling AWS Well-Architected best practices across your organization\n\nRelated examples:\n\nAWS Well-Architected Tool\n\nOPS11-BP02 Perform post-incident analysis\n\nReview customer-impacting events and identify the contributing factors and preventative actions.\n\nUse this information to develop mitigations to limit or prevent recurrence. Develop procedures\n\nfor prompt and eﬀective responses. Communicate contributing factors and corrective actions as\n\nappropriate, tailored to target audiences.\n\nDesired outcome:\n\nYou have established incident management processes that include post-incident analysis.\n\nYou have observability plans in place to collect data on events.\n\nWith this data, you understand and collect metrics that support your post-incident analysis\n\nprocess.\n\nOPS11-BP02 Perform post-incident analysis\n\n197\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou learn from incidents to improve future outcomes.\n\nCommon anti-patterns:\n\nYou administer an application server. Approximately every 23 hours and 55 minutes all\n\nyour active sessions are terminated. You have tried to identify what is going wrong on your\n\napplication server. You suspect it could instead be a network issue but are unable to get\n\ncooperation from the network team as they are too busy to support you. You lack a predeﬁned\n\nprocess to follow to get support and collect the information necessary to determine what is\n\ngoing on.\n\nYou have had data loss within your workload. This is the ﬁrst time it has happened and the cause\n\nis not obvious. You decide it is not important because you can recreate the data. Data loss starts\n\noccurring with greater frequency impacting your customers. This also places addition operational burden on you as you restore the missing data.\n\nBeneﬁts of establishing this best practice:\n\nYou have a predeﬁned process to determine the components, conditions, actions, and events\n\nthat contributed to an incident, which helps you identify opportunities for improvement.\n\nYou use data from post-incident analysis to make improvements.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nUse a process to determine contributing factors. Review all customer impacting incidents. Have a\n\nprocess to identify and document the contributing factors of an incident so that you can develop\n\nmitigations to limit or prevent recurrence and you can develop procedures for prompt and eﬀective responses. Communicate incident root causes as appropriate, and tailor the communication to your\n\ntarget audience. Share learnings openly within your organization.\n\nImplementation steps\n\n1. Collect metrics such as deployment change, conﬁguration change, incident start time, alarm\n\ntime, time of engagement, mitigation start time, and incident resolved time.\n\n2. Describe key time points on the timeline to understand the events of the incident.\n\n3. Ask the following questions:\n\nOPS11-BP02 Perform post-incident analysis\n\n198",
      "page_number": 196
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 204-211)",
      "start_page": 204,
      "end_page": 211,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\na. Could you improve time to detection?\n\nb. Are there updates to metrics and alarms that would detect the incident sooner?\n\nc. Can you improve the time to diagnosis?\n\nd. Are there updates to your response plans or escalation plans that would engage the correct\n\nresponders sooner?\n\ne. Can you improve the time to mitigation?\n\nf. Are there runbook or playbook steps that you could add or improve?\n\ng. Can you prevent future incidents from occurring?\n\n4. Create checklists and actions. Track and deliver all actions.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS11-BP01 Have a process for continuous improvement\n\nOPS 4 - Implement observability\n\nRelated documents:\n\nPerforming a post-incident analysis in Incident Manager\n\nOperational Readiness Review\n\nOPS11-BP03 Implement feedback loops\n\nFeedback loops provide actionable insights that drive decision making. Build feedback loops into your procedures and workloads. This helps you identify issues and areas that need improvement.\n\nThey also validate investments made in improvements. These feedback loops are the foundation\n\nfor continuously improving your workload.\n\nFeedback loops fall into two categories: immediate feedback and retrospective analysis. Immediate\n\nfeedback is gathered through review of the performance and outcomes from operations activities.\n\nThis feedback comes from team members, customers, or the automated output of the activity.\n\nImmediate feedback is received from things like A/B testing and shipping new features, and it is\n\nessential to failing fast.\n\nOPS11-BP03 Implement feedback loops\n\n199\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRetrospective analysis is performed regularly to capture feedback from the review of operational\n\noutcomes and metrics over time. These retrospectives happen at the end of a sprint, on a cadence, or after major releases or events. This type of feedback loop validates investments in operations or\n\nyour workload. It helps you measure success and validates your strategy.\n\nDesired outcome: You use immediate feedback and retrospective analysis to drive improvements. There is a mechanism to capture user and team member feedback. Retrospective analysis is used to\n\nidentify trends that drive improvements.\n\nCommon anti-patterns:\n\nYou launch a new feature but have no way of receiving customer feedback on it.\n\nAfter investing in operations improvements, you don’t conduct a retrospective to validate them.\n\nYou collect customer feedback but don’t regularly review it.\n\nFeedback loops lead to proposed action items but they aren’t included in the software\n\ndevelopment process.\n\nCustomers don’t receive feedback on improvements they’ve proposed.\n\nBeneﬁts of establishing this best practice:\n\nYou can work backwards from the customer to drive new features.\n\nYour organization culture can react to changes faster.\n\nTrends are used to identify improvement opportunities.\n\nRetrospectives validate investments made to your workload and operations.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplementing this best practice means that you use both immediate feedback and retrospective\n\nanalysis. These feedback loops drive improvements. There are many mechanisms for immediate\n\nfeedback, including surveys, customer polls, or feedback forms. Your organization also uses\n\nretrospectives to identify improvement opportunities and validate initiatives.\n\nCustomer example\n\nAnyCompany Retail created a web form where customers can give feedback or report issues.\n\nDuring the weekly scrum, user feedback is evaluated by the software development team. Feedback\n\nOPS11-BP03 Implement feedback loops\n\n200\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nis regularly used to steer the evolution of their platform. They conduct a retrospective at the end of\n\neach sprint to identify items they want to improve.\n\nImplementation steps\n\n1. Immediate feedback\n\nYou need a mechanism to receive feedback from customers and team members. Your\n\noperations activities can also be conﬁgured to deliver automated feedback.\n\nYour organization needs a process to review this feedback, determine what to improve, and\n\nschedule the improvement.\n\nFeedback must be added into your software development process.\n\nAs you make improvements, follow up with the feedback submitter.\n\nYou can use AWS Systems Manager OpsCenter to create and track these improvements as\n\nOpsItems.\n\n2. Retrospective analysis\n\nConduct retrospectives at the end of a development cycle, on a set cadence, or after a major\n\nrelease.\n\nGather stakeholders involved in the workload for a retrospective meeting.\n\nCreate three columns on a whiteboard or spreadsheet: Stop, Start, and Keep.\n\nStop is for anything that you want your team to stop doing.\n\nStart is for ideas that you want to start doing.\n\nKeep is for items that you want to keep doing.\n\nGo around the room and gather feedback from the stakeholders.\n\nPrioritize the feedback. Assign actions and stakeholders to any Start or Keep items.\n\nAdd the actions to your software development process and communicate status updates to\n\nstakeholders as you make the improvements.\n\nLevel of eﬀort for the implementation plan: Medium. To implement this best practice, you need a way to take in immediate feedback and analyze it. Also, you need to establish a retrospective\n\nanalysis process.\n\nResources\n\nRelated best practices: OPS11-BP03 Implement feedback loops\n\n201\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS01-BP01 Evaluate external customer needs: Feedback loops are a mechanism to gather\n\nexternal customer needs.\n\nOPS01-BP02 Evaluate internal customer needs: Internal stakeholders can use feedback loops to\n\ncommunicate needs and requirements.\n\nOPS11-BP02 Perform post-incident analysis: Post-incident analyses are an important form of\n\nretrospective analysis conducted after incidents.\n\nOPS11-BP07 Perform operations metrics reviews: Operations metrics reviews identify trends and\n\nareas for improvement.\n\nRelated documents:\n\n7 Pitfalls to Avoid When Building a CCOE\n\nAtlassian Team Playbook - Retrospectives\n\nEmail Deﬁnitions: Feedback Loops\n\nEstablishing Feedback Loops Based on the AWS Well-Architected Framework Review\n\nIBM Garage Methodology - Hold a retrospective\n\nInvestopedia – The PDCS Cycle\n\nMaximizing Developer Eﬀectiveness by Tim Cochran\n\nOperations Readiness Reviews (ORR) Whitepaper - Iteration\n\nITIL CSI - Continual Service Improvement\n\nWhen Toyota met e-commerce: Lean at Amazon\n\nRelated videos:\n\nBuilding Eﬀective Customer Feedback Loops\n\nRelated examples:\n\nAstuto - Open source customer feedback tool\n\nAWS Solutions - QnABot on AWS\n\nFider - A platform to organize customer feedback\n\nRelated services:\n\nOPS11-BP03 Implement feedback loops\n\n202\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Systems Manager OpsCenter\n\nOPS11-BP04 Perform knowledge management\n\nKnowledge management helps team members ﬁnd the information to perform their job. In\n\nlearning organizations, information is freely shared which empowers individuals. The information\n\ncan be discovered or searched. Information is accurate and up to date. Mechanisms exist to create\n\nnew information, update existing information, and archive outdated information. The most\n\ncommon example of a knowledge management platform is a content management system like a\n\nwiki.\n\nDesired outcome:\n\nTeam members have access to timely, accurate information.\n\nInformation is searchable.\n\nMechanisms exist to add, update, and archive information.\n\nCommon anti-patterns:\n\nThere is no centralized knowledge storage. Team members manage their own notes on their\n\nlocal machines.\n\nYou have a self-hosted wiki but no mechanisms to manage information, resulting in outdated\n\ninformation.\n\nSomeone identiﬁes missing information but there’s no process to request adding it the team\n\nwiki. They add it themselves but they miss a key step, leading to an outage.\n\nBeneﬁts of establishing this best practice:\n\nTeam members are empowered because information is shared freely.\n\nNew team members are onboarded faster because documentation is up to date and searchable.\n\nInformation is timely, accurate, and actionable.\n\nLevel of risk exposed if this best practice is not established: High\n\nOPS11-BP04 Perform knowledge management\n\n203\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nKnowledge management is an important facet of learning organizations. To begin, you need a\n\ncentral repository to store your knowledge (as a common example, a self-hosted wiki). You must\n\ndevelop processes for adding, updating, and archiving knowledge. Develop standards for what\n\nshould be documented and let everyone contribute.\n\nCustomer example\n\nAnyCompany Retail hosts an internal Wiki where all knowledge is stored. Team members are\n\nencouraged to add to the knowledge base as they go about their daily duties. On a quarterly basis,\n\na cross-functional team evaluates which pages are least updated and determines if they should be\n\narchived or updated.\n\nImplementation steps\n\n1. Start with identifying the content management system where knowledge will be stored. Get\n\nagreement from stakeholders across your organization.\n\na. If you don’t have an existing content management system, consider running a self-hosted wiki\n\nor using a version control repository as a starting point.\n\n2. Develop runbooks for adding, updating, and archiving information. Educate your team on these\n\nprocesses.\n\n3. Identify what knowledge should be stored in the content management system. Start with daily\n\nactivities (runbooks and playbooks) that team members perform. Work with stakeholders to\n\nprioritize what knowledge is added.\n\n4. On a periodic basis, work with stakeholders to identify out-of-date information and archive it or\n\nbring it up to date.\n\nLevel of eﬀort for the implementation plan: Medium. If you don’t have an existing content management system, you can set up a self-hosted wiki or a version-controlled document\n\nrepository.\n\nResources\n\nRelated best practices:\n\nOPS11-BP08 Document and share lessons learned - Knowledge management facilitates\n\ninformation sharing about lessons learned.\n\nOPS11-BP04 Perform knowledge management\n\n204\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nAtlassian - Knowledge Management\n\nRelated examples:\n\nDokuWiki\n\nGollum\n\nMediaWiki\n\nWiki.js\n\nOPS11-BP05 Deﬁne drivers for improvement\n\nIdentify drivers for improvement to help you evaluate and prioritize opportunities based on data\n\nand feedback loops. Explore improvement opportunities in your systems and processes, and\n\nautomate where appropriate.\n\nDesired outcome:\n\nYou track data from across your environment.\n\nYou correlate events and activities to business outcomes.\n\nYou can compare and contrast between environments and systems.\n\nYou maintain a detailed activity history of your deployments and outcomes.\n\nYou collect data to support your security posture.\n\nCommon anti-patterns:\n\nYou collect data from across your environment but do not correlate events and activities.\n\nYou collect detailed data from across your estate, and it drives high Amazon CloudWatch and\n\nAWS CloudTrail activity and cost. However, you do not use this data meaningfully.\n\nYou do not account for business outcomes when deﬁning drivers for improvement.\n\nYou do not measure the eﬀects of new features.\n\nBeneﬁts of establishing this best practice:\n\nOPS11-BP05 Deﬁne drivers for improvement\n\n205\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou minimize the impact of event-based motivations or emotional investment by determining\n\ncriteria for improvement.\n\nYou respond to business events, not just technical ones.\n\nYou measure your environment to identify areas of improvement.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nUnderstand drivers for improvement: You should only make changes to a system when a desired\n\noutcome is supported.\n\nDesired capabilities: Evaluate desired features and capabilities when evaluating opportunities\n\nfor improvement.\n\nWhat's New with AWS\n\nUnacceptable issues: Evaluate unacceptable issues, bugs, and vulnerabilities when evaluating\n\nopportunities for improvement. Track rightsizing options, and seek optimization opportunities.\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nCloud Intelligence Dashboards\n\nCompliance requirements: Evaluate updates and changes required to maintain compliance\n\nwith regulation, policy, or to remain under support from a third party, when reviewing\n\nopportunities for improvement.\n\nAWS Compliance\n\nAWS Compliance Programs\n\nAWS Compliance Latest News\n\nResources\n\nRelated best practices:\n\nOPS01 Organization priorities\n\nOPS02 Relationships and Ownerships\n\nOPS04-BP01 Identify key performance indicators\n\nOPS08 Utilizing Workload Observability\n\nOPS11-BP05 Deﬁne drivers for improvement\n\n206",
      "page_number": 204
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 212-219)",
      "start_page": 212,
      "end_page": 219,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS09 Understanding Operational Health\n\nOPS11-BP03 Implement feedback loops\n\nRelated documents:\n\nAmazon Athena\n\nQuick Suite\n\nAWS Compliance\n\nAWS Compliance Latest News\n\nAWS Compliance Programs\n\nAWS Glue\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nExport your log data to Amazon S3\n\nWhat's New with AWS\n\nThe Imperatives of Customer-Centric Innovation\n\nDigital Transformation: Hype or a Strategic Necessity?\n\nRelated Videos\n\nAWS re:Invent 2023 - Improve operational eﬃciency and resilience with Support (SUP310)\n\nOPS11-BP06 Validate insights\n\nReview your analysis results and responses with cross-functional teams and business owners. Use\n\nthese reviews to establish common understanding, identify additional impacts, and determine\n\ncourses of action. Adjust responses as appropriate.\n\nDesired outcomes:\n\nYou review insights with business owners on a regular basis. Business owners provide additional\n\ncontext to newly-gained insights.\n\nYou review insights and request feedback from technical peers, and you share your learnings\n\nacross teams.\n\nOPS11-BP06 Validate insights\n\n207\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou publish data and insights for other technical and business teams to review. You factor in\n\nyour learnings to new practices by other departments.\n\nSummarize and review new insights with senior leaders. Senior leaders use new insights to deﬁne\n\nstrategy.\n\nCommon anti-patterns:\n\nYou release a new feature. This feature changes some of your customer behaviors. Your\n\nobservability does not take these changes into account. You do not quantify the beneﬁts of\n\nthese changes.\n\nYou push a new update and neglect refreshing your CDN. The CDN cache is no longer compatible\n\nwith the latest release. You measure the percentage of requests with errors. All of your users\n\nreport HTTP 400 errors when communicating with backend servers. You investigate the client\n\nerrors and ﬁnd that because you measured the wrong dimension, your time was wasted.\n\nYour service-level agreement stipulates 99.9% uptime, and your recovery point objective is\n\nfour hours. The service owner maintains that the system is zero downtime. You implement an\n\nexpensive and complex replication solution, which wastes time and money.\n\nBeneﬁts of establishing this best practice:\n\nWhen you validate insights with business owners and subject matter experts, you establish\n\ncommon understanding and more eﬀectively guide improvement.\n\nYou discover hidden issues and factor them into future decisions.\n\nYour focus moves from technical outcomes to business outcomes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nValidate insights: Engage with business owners and subject matter experts to ensure there is\n\ncommon understanding and agreement of the meaning of the data you have collected. Identify\n\nadditional concerns, potential impacts, and determine a courses of action.\n\nResources\n\nRelated best practices:\n\nOPS11-BP06 Validate insights\n\n208\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nOPS11-BP03 Implement feedback loops\n\nRelated documents:\n\nDesigning a Cloud Center of Excellence (CCOE)\n\nRelated videos:\n\nBuilding observability to increase resiliency\n\nOPS11-BP07 Perform operations metrics reviews\n\nRegularly perform retrospective analysis of operations metrics with cross-team participants from\n\ndiﬀerent areas of the business. Use these reviews to identify opportunities for improvement,\n\npotential courses of action, and to share lessons learned. Look for opportunities to improve in all of\n\nyour environments (for example, development, test, and production).\n\nDesired outcome:\n\nYou frequently review business-aﬀecting metrics\n\nYou detect and review anomalies through your observability capabilities\n\nYou use data to support business outcomes and goals\n\nCommon anti-patterns:\n\nYour maintenance window interrupts a signiﬁcant retail promotion. The business remains\n\nunaware that there is a standard maintenance window that could be delayed if there are other\n\nbusiness impacting events.\n\nYou suﬀered an extended outage because you commonly use an outdated library in your\n\norganization. You have since migrated to a supported library. The other teams in your\n\norganization do not know that they are at risk.\n\nYou do not regularly review attainment of customer SLAs. You are trending to not meet your\n\ncustomer SLAs. There are ﬁnancial penalties related to not meeting your customer SLAs.\n\nOPS11-BP07 Perform operations metrics reviews\n\n209\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nWhen you meet regularly to review operations metrics, events, and incidents, you maintain\n\ncommon understanding across teams.\n\nYour team meets routinely to review metrics and incidents, which positions you to take action on\n\nrisks and recognize customer SLAs.\n\nYou share lessons learned, which provides data for prioritization and targeted improvements for\n\nbusiness outcomes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nRegularly perform retrospective analysis of operations metrics with cross-team participants from\n\ndiﬀerent areas of the business.\n\nEngage stakeholders, including the business, development, and operations teams, to validate\n\nyour ﬁndings from immediate feedback and retrospective analysis and share lessons learned.\n\nUse their insights to identify opportunities for improvement and potential courses of action.\n\nResources\n\nRelated best practices:\n\nOPS08-BP05 Create dashboards\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nRelated documents:\n\nAmazon CloudWatch\n\nAmazon CloudWatch metrics and dimensions reference\n\nPublish custom metrics\n\nUsing Amazon CloudWatch metrics\n\nDashboards and visualizations with CloudWatch\n\nOPS11-BP07 Perform operations metrics reviews\n\n210\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP08 Document and share lessons learned\n\nDocument and share lessons learned from the operations activities so that you can use them\n\ninternally and across teams. You should share what your teams learn to increase the beneﬁt\n\nacross your organization. Share information and resources to prevent avoidable errors and ease\n\ndevelopment eﬀorts, and focus on delivery of desired features.\n\nUse AWS Identity and Access Management (IAM) to deﬁne permissions that permit controlled\n\naccess to the resources you wish to share within and across accounts.\n\nDesired outcome:\n\nYou use version-controlled repositories to share application libraries, scripted procedures,\n\nprocedure documentation, and other system documentation.\n\nYou share your infrastructure standards as version-controlled AWS CloudFormation templates.\n\nYou review lessons learned across teams.\n\nCommon anti-patterns:\n\nYou suﬀered an extended outage because your organization commonly uses buggy library. You\n\nhave since migrated to a reliable library. The other teams in your organization do not know they\n\nare at risk. No one documents and shares the experience with this library, and they are not aware\n\nof the risk.\n\nYou have identiﬁed an edge case in an internally-shared microservice that causes sessions to\n\ndrop. You have updated your calls to the service to avoid this edge case. The other teams in your\n\norganization do not know that they are at risk.\n\nYou have found a way to signiﬁcantly reduce the CPU utilization requirements for one of your\n\nmicroservices. You do not know if any other teams could take advantage of this technique.\n\nBeneﬁts of establishing this best practice: Share lessons learned to support improvement and to maximize the beneﬁts of experience.\n\nLevel of risk exposed if this best practice is not established: Low\n\nOPS11-BP08 Document and share lessons learned\n\n211\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nDocument and share lessons learned: Have procedures to document the lessons learned from the running of operations activities and retrospective analysis so that they can be used by other teams.\n\nShare learnings: Have procedures to share lessons learned and associated artifacts across teams. For example, share updated procedures, guidance, governance, and best practices through an accessible wiki. Share scripts, code, and libraries through a common repository.\n\nLeverage AWS re:Post Private as a knowledge service to streamline collaboration and\n\nknowledge sharing within your organization.\n\nResources\n\nRelated best practices:\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nOPS05-BP01 Use version control\n\nOPS05-BP06 Share design standards\n\nOPS11-BP03 Implement feedback loops\n\nOPS11-BP07 Perform operations metrics reviews\n\nRelated documents:\n\nIncrease collaboration and securely share cloud knowledge with AWS re:Post Private\n\nReduce project delays with a docs-as-code solution\n\nRelated videos:\n\nAWS re:Invent 2023 - Collaborate within your company and with AWS using AWS re:Post Private\n\nSupports You | Exploring the Incident Management Tabletop Exercise\n\nOPS11-BP09 Allocate time to make improvements\n\nDedicate time and resources within your processes to make continuous incremental improvements\n\npossible.\n\nOPS11-BP09 Allocate time to make improvements\n\n212\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome:\n\nYou create temporary duplicates of environments, which lowers the risk, eﬀort, and cost of\n\nexperimentation and testing.\n\nThese duplicated environments can be used to test the conclusions from your analysis,\n\nexperiment, and develop and test planned improvements.\n\nYou run gamedays, and you use Fault Injection Service (FIS) to provide the controls and\n\nguardrails that teams need to run experiments in a production-like environment.\n\nCommon anti-patterns:\n\nThere is a known performance issue in your application server. It is added to the backlog behind\n\nevery planned feature implementation. If the rate of planned features being added remains constant, the performance issue would never be addressed.\n\nTo support continual improvement, you approve administrators and developers using all their\n\nextra time to select and implement improvements. No improvements are ever completed.\n\nOperational acceptance is complete, and you do not test operational practices again.\n\nBeneﬁts of establishing this best practice: By dedicating time and resources within your processes, you can make continuous, incremental improvements possible.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nAllocate time to make improvements: Dedicate time and resources within your processes to make\n\ncontinuous, incremental improvements.\n\nImplement changes to improve and evaluate the results to determine success.\n\nIf the results do not satisfy the goals and the improvement is still a priority, pursue alternative\n\ncourses of action.\n\nSimulate production workloads through game days, and use learnings from these simulations to\n\nimprove.\n\nResources\n\nRelated best practices:\n\nOPS11-BP09 Allocate time to make improvements\n\n213\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS05-BP08 Use multiple environments\n\nRelated videos:\n\nAWS re:Invent 2023 - Improve application resilience with AWS Fault Injection Service\n\nOPS11-BP09 Allocate time to make improvements\n\n214",
      "page_number": 212
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 220-226)",
      "start_page": 220,
      "end_page": 226,
      "detection_method": "topic_boundary",
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nConclusion\n\nOperational excellence is an ongoing and iterative eﬀort.\n\nSet up your organization for success by having shared goals. Ensure that everyone understands\n\ntheir part in achieving business outcomes and how they impact the ability of others to succeed.\n\nProvide support for your team members so that they can support your business outcomes.\n\nEvery operational event and failure should be treated as an opportunity to improve the operations\n\nof your architecture. By understanding the needs of your workloads, predeﬁning runbooks for\n\nroutine activities, and playbooks to guide issue resolution, using the operations as code features in\n\nAWS, and maintaining situational awareness, your operations will be better prepared and able to\n\nrespond more eﬀectively when incidents occur.\n\nThrough focusing on incremental improvement based on priorities as they change, and lessons\n\nlearned from event response and retrospective analysis, you will help the success of your business\n\nby increasing the eﬃciency and eﬀectiveness of your activities.\n\nAWS strives to help you build and operate architectures that maximize eﬃciency while you build\n\nhighly responsive and adaptive deployments. To increase the operational excellence of your\n\nworkloads, you should use the best practices discussed in this paper.\n\n215\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nContributors\n\nRich Boyd, Operational Excellence Pillar Lead, Well-Architected, Amazon Web Services\n\nJon Steele, Solutions Architect Well-Architected, Amazon Web Services\n\nRyan King, Sr. Technical Program Manager, Amazon Web Services\n\nChris Kunselman, Advisory Consultant, Amazon Web Services\n\nPeter Mullen, Advisory Consultant, Amazon Web Services\n\nBrian Quinn, Sr. Advisory Consultant, Amazon Web Services\n\nDavid Stanley, Cloud Operating Model Lead, Amazon Web Services\n\nChris Kozlowski, Senior Specialist Technical Account Manager, Enterprise Support, Amazon Web\n\nServices\n\nAlex Livingstone, Principal Specialist Solutions Architect, Cloud Operations, Amazon Web\n\nServices\n\nPaul Moran, Principal Technologist, Enterprise Support, Amazon Web Services\n\nPeter Mullen, Advisory Consultant, Professional Services, Amazon Web Services\n\nChris Pates, Senior Specialist Technical Account Manager, Enterprise Support, Amazon Web\n\nServices\n\nArvind Raghunathan, Principal Specialist Technical Account Manager, Enterprise Support,\n\nAmazon Web Services\n\nFatih (Ben) Mergen, Senior Cost Lead Solutions Architect, Amazon Web Services\n\n216\n\nOperational Excellence Pillar\n\nFurther reading\n\nFor additional guidance, consult the following sources:\n\nAWS Well-Architected Framework\n\nAWS Architecture Center\n\nAWS Well-Architected Framework\n\n217\n\nOperational Excellence Pillar\n\nDocument revisions\n\nTo be notiﬁed about updates to this whitepaper, subscribe to the RSS feed.\n\nChange\n\nDescription\n\nUpdated best practice guidance\n\nBest practices were updated with new guidance in the\n\nfollowing areas: OPS 2,\n\nOPS 5, OPS 9, and OPS\n\n10. Guidance includes new\n\nrecommendations on AWS\n\nservices and generative AI.\n\nUpdated best practice guidance\n\nLarge-scale best practice updates were made\n\nthroughout the pillar. Multiple\n\nconsolidations of content in\n\nOPS 1, OPS 2, and OPS 3. Risk\n\nrating changes in OPS 10.\n\nMajor content update and consolidation\n\nContent has been updated and consolidated in multiple\n\nbest practice areas. Two best\n\npractice areas (OPS 4 and\n\nOPS 8) have been rewritten\n\nwith new content and focus.\n\nBest practices have been\n\nupdated and consolidated in\n\nthe following areas: Design\n\nfor operations, Mitigate\n\ndeployment risks, and\n\nUnderstanding operation\n\nal health. Best practice area OPS 04 has been updated to\n\nImplement observability. Best\n\nAWS Well-Architected Framework\n\nDate\n\nNovember 6, 2024\n\nJune 27, 2024\n\nOctober 3, 2023\n\n218\n\nOperational Excellence Pillar\n\nUpdates for new Framework\n\nWhitepaper updated\n\nWhitepaper updated\n\nMinor update\n\nWhitepaper updated\n\nUpdates for new Framework\n\nWhitepaper updated\n\nInitial publication\n\npractice area OPS 08 has been\n\nupdated to Utilizing workload observability.\n\nBest practices updated with prescriptive guidance and new\n\nbest practices added.\n\nBest practices updated with new implementation\n\nguidance.\n\nBest practices expanded and improvement plans added.\n\nSmall editorial update.\n\nUpdates to reﬂect new AWS services and features, and\n\nlatest best practices.\n\nUpdates to reﬂect new AWS services and features, and\n\nlatest best practices.\n\nUpdates to reﬂect new AWS services and features, and\n\nupdated references.\n\nOperational Excellence Pillar - AWS Well-Architected Framework published.\n\nAWS Well-Architected Framework\n\nApril 10, 2023\n\nDecember 15, 2022\n\nOctober 20, 2022\n\nAugust 8, 2022\n\nFebruary 2, 2022\n\nJuly 8, 2020\n\nJuly 1, 2018\n\nNovember 1, 2017\n\n219\n\nOperational Excellence Pillar\n\nAWS Well-Architected Framework\n\nNotices\n\nCustomers are responsible for making their own independent assessment of the information in\n\nthis document. This document: (a) is for informational purposes only, (b) represents current AWS\n\nproduct oﬀerings and practices, which are subject to change without notice, and (c) does not create\n\nany commitments or assurances from AWS and its aﬃliates, suppliers or licensors. AWS products or\n\nservices are provided “as is” without warranties, representations, or conditions of any kind, whether\n\nexpress or implied. The responsibilities and liabilities of AWS to its customers are controlled by\n\nAWS agreements, and this document is not part of, nor does it modify, any agreement between\n\nAWS and its customers.\n\n© 2023 Amazon Web Services, Inc. or its aﬃliates. All rights reserved.\n\n220\n\nOperational Excellence Pillar\n\nAWS Glossary\n\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.\n\nAWS Well-Architected Framework\n\n221",
      "page_number": 220
    }
  ],
  "pages": [
    {
      "page_number": 1,
      "content": "AWS Well-Architected Framework\n\nOperational Excellence Pillar\n\nCopyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.",
      "content_length": 147,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 2,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational Excellence Pillar: AWS Well-Architected Framework\n\nCopyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n\nAmazon's trademarks and trade dress may not be used in connection with any product or service\n\nthat is not Amazon's, in any manner that is likely to cause confusion among customers, or in any\n\nmanner that disparages or discredits Amazon. All other trademarks not owned by Amazon are\n\nthe property of their respective owners, who may or may not be aﬃliated with, connected to, or\n\nsponsored by Amazon.",
      "content_length": 612,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 3,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nTable of Contents\n\nAbstract and introduction ............................................................................................................... 1 Introduction ................................................................................................................................................... 1\n\nOperational excellence .................................................................................................................... 3 Design principles ........................................................................................................................................... 3\n\nDeﬁnition ........................................................................................................................................................ 4\n\nOrganization .................................................................................................................................... 6 Organization priorities ................................................................................................................................. 9\n\nOPS01-BP01 Evaluate external customer needs .............................................................................. 9\n\nOPS01-BP02 Evaluate internal customer needs ............................................................................ 10\n\nOPS01-BP03 Evaluate governance requirements .......................................................................... 12\n\nOPS01-BP04 Evaluate compliance requirements .......................................................................... 14\n\nOPS01-BP05 Evaluate threat landscape .......................................................................................... 17 OPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks ......................................... 19\n\nOperating model ........................................................................................................................................ 23\n\nOperating model 2 by 2 representations ........................................................................................ 24\n\nRelationships and ownership .............................................................................................................. 33\n\nOrganizational culture ............................................................................................................................... 53\n\nOPS03-BP01 Provide executive sponsorship .................................................................................. 54\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk ...... 57\n\nOPS03-BP03 Escalation is encouraged ............................................................................................ 60\n\nOPS03-BP04 Communications are timely, clear, and actionable ................................................ 63\n\nOPS03-BP05 Experimentation is encouraged ................................................................................. 68\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets .............. 70\n\nOPS03-BP07 Resource teams appropriately ................................................................................... 73\n\nPrepare ........................................................................................................................................... 77 Implement observability ........................................................................................................................... 78\n\nOPS04-BP01 Identify key performance indicators ........................................................................ 79\n\nOPS04-BP02 Implement application telemetry ............................................................................. 81\n\nOPS04-BP03 Implement user experience telemetry ..................................................................... 84\n\nOPS04-BP04 Implement dependency telemetry ........................................................................... 87\n\nOPS04-BP05 Implement distributed tracing .................................................................................. 90\n\nDesign for operations ................................................................................................................................ 93\n\nOPS05-BP01 Use version control ...................................................................................................... 93\n\nOPS05-BP02 Test and validate changes .......................................................................................... 94\n\niii",
      "content_length": 4649,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 4,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS05-BP03 Use conﬁguration management systems ................................................................ 98\n\nOPS05-BP04 Use build and deployment management systems .............................................. 101 OPS05-BP05 Perform patch management ................................................................................... 103\n\nOPS05-BP06 Share design standards ............................................................................................ 106\n\nOPS05-BP07 Implement practices to improve code quality ..................................................... 109\n\nOPS05-BP08 Use multiple environments ...................................................................................... 112\n\nOPS05-BP09 Make frequent, small, reversible changes ............................................................. 114\n\nOPS05-BP10 Fully automate integration and deployment ....................................................... 115\n\nMitigate deployment risks ..................................................................................................................... 117\n\nOPS06-BP01 Plan for unsuccessful changes ................................................................................ 117\n\nOPS06-BP02 Test deployments ...................................................................................................... 120\n\nOPS06-BP03 Employ safe deployment strategies ...................................................................... 123\n\nOPS06-BP04 Automate testing and rollback ............................................................................... 126\n\nOperational readiness and change management ............................................................................. 130 OPS07-BP01 Ensure personnel capability .................................................................................... 130\n\nOPS07-BP02: Ensure a consistent review of operational readiness ......................................... 132\n\nOPS07-BP03 Use runbooks to perform procedures ................................................................... 136\n\nOPS07-BP04 Use playbooks to investigate issues ...................................................................... 140\n\nOPS07-BP05 Make informed decisions to deploy systems and changes ................................ 144\n\nOPS07-BP06 Create support plans for production workloads ................................................. 146\n\nOperate ........................................................................................................................................ 149 Utilizing workload observability ........................................................................................................... 150\n\nOPS08-BP01 Analyze workload metrics ........................................................................................ 151\n\nOPS08-BP02 Analyze workload logs .............................................................................................. 153\n\nOPS08-BP03 Analyze workload traces .......................................................................................... 155\n\nOPS08-BP04 Create actionable alerts ........................................................................................... 158\n\nOPS08-BP05 Create dashboards ..................................................................................................... 161\n\nUnderstanding operational health ....................................................................................................... 164\n\nOPS09-BP01 Measure operations goals and KPIs with metrics ................................................ 164\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation ................ 167\n\nOPS09-BP03 Review operations metrics and prioritize improvement .................................... 169\n\nResponding to events ............................................................................................................................. 171\n\nOPS10-BP01 Use a process for event, incident, and problem management .......................... 171\n\nOPS10-BP02 Have a process per alert .......................................................................................... 176\n\nOPS10-BP03 Prioritize operational events based on business impact .................................... 180\n\nOPS10-BP04 Deﬁne escalation paths ............................................................................................ 183\n\niv",
      "content_length": 4544,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 5,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events ........... 185\n\nOPS10-BP06 Communicate status through dashboards ............................................................ 188 OPS10-BP07 Automate responses to events ............................................................................... 191\n\nEvolve ........................................................................................................................................... 194 Learn, share, and improve ..................................................................................................................... 195\n\nOPS11-BP01 Have a process for continuous improvement ....................................................... 195\n\nOPS11-BP02 Perform post-incident analysis ............................................................................... 197\n\nOPS11-BP03 Implement feedback loops ...................................................................................... 199\n\nOPS11-BP04 Perform knowledge management ......................................................................... 203\n\nOPS11-BP05 Deﬁne drivers for improvement ............................................................................. 205\n\nOPS11-BP06 Validate insights ......................................................................................................... 207\n\nOPS11-BP07 Perform operations metrics reviews ...................................................................... 209\n\nOPS11-BP08 Document and share lessons learned .................................................................... 211\n\nOPS11-BP09 Allocate time to make improvements ................................................................... 212\n\nConclusion .................................................................................................................................... 215\n\nContributors ................................................................................................................................. 216\n\nFurther reading ............................................................................................................................ 217\n\nDocument revisions ..................................................................................................................... 218\n\nNotices .......................................................................................................................................... 220\n\nAWS Glossary ............................................................................................................................... 221\n\nv",
      "content_length": 2692,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 6,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational Excellence Pillar - AWS Well-Architected\n\nFramework\n\nPublication date: November 6, 2024 (Document revisions)\n\nThe focus of this paper is the operational excellence pillar of the AWS Well-Architected Framework.\n\nIt provides guidance to help you apply best practices in the design, delivery, and maintenance of\n\nAWS workloads.\n\nIntroduction\n\nThe AWS Well-Architected Framework helps you understand the beneﬁts and risks of decisions you\n\nmake while building workloads on AWS. By using the Framework you will learn operational and\n\narchitectural best practices for designing and operating reliable, secure, eﬃcient, cost-eﬀective,\n\nand sustainable workloads in the cloud. It provides a way to consistently measure your operations\n\nand architectures against best practices and identify areas for improvement. We believe that\n\nhaving Well-Architected workloads that are designed with operations in mind greatly increases the\n\nlikelihood of business success.\n\nThe framework is based on six pillars:\n\nOperational Excellence\n\nSecurity\n\nReliability\n\nPerformance Eﬃciency\n\nCost Optimization\n\nSustainability\n\nThis paper focuses on the operational excellence pillar and how to apply it as the foundation of\n\nyour well-architected solutions. Operational excellence is challenging to achieve in environments\n\nwhere operations is perceived as a function isolated and distinct from the lines of business\n\nand development teams that it supports. By adopting the practices in this paper you can build\n\narchitectures that provide insight to their status, are activated for eﬀective and eﬃcient operation\n\nand event response, and can continue to improve and support your business goals.\n\nIntroduction\n\n1",
      "content_length": 1758,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 7,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThis paper is intended for those in technology roles, such as chief technology oﬃcers (CTOs),\n\narchitects, developers, and operations team members. After reading this paper, you will understand AWS best practices and the strategies to use when designing cloud architectures for operational\n\nexcellence. This paper does not provide implementation details or architectural patterns. However,\n\nit does include references to appropriate resources for this information.\n\nIntroduction\n\n2",
      "content_length": 544,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 8,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational excellence\n\nOperational excellence (OE) is a commitment to build software correctly while consistently\n\ndelivering a great customer experience. The operational excellence pillar contains best practices for\n\norganizing your team, designing your workload, operating it at scale, and evolving it over time.\n\nThe goal of operational excellence is to get new features and bug ﬁxes into customers’ hands\n\nquickly and reliably. Organizations that invest in operational excellence consistently delight\n\ncustomers while building new features, making changes, and dealing with failures. Along the way,\n\noperational excellence drives towards continuous integration and continuous delivery (CI/CD) by\n\nhelping developers achieve high quality results consistently.\n\nDesign principles\n\nThe following are the design principles for operational excellence in the cloud:\n\nOrganize teams around business outcomes: The ability of a team to achieve business outcomes\n\ncomes from leadership vision, eﬀective operations, and a business-aligned operating model.\n\nLeadership should be fully invested and committed to a CloudOps transformation with a suitable\n\ncloud operating model that incentivizes teams to operate in the most eﬃcient way and meet\n\nbusiness outcomes. The right operating model uses people, process, and technology capabilities\n\nto scale, optimize for productivity, and diﬀerentiate through agility, responsiveness, and\n\nadaptation. The organization's long-term vision is translated into goals that are communicated\n\nacross the enterprise to stakeholders and consumers of your cloud services. Goals and\n\noperational KPIs are aligned at all levels. This practice sustains the long-term value derived from\n\nimplementing the following design principles.\n\nImplement observability for actionable insights: Gain a comprehensive understanding\n\nof workload behavior, performance, reliability, cost, and health. Establish key performance indicators (KPIs) and leverage observability telemetry to make informed decisions and take\n\nprompt action when business outcomes are at risk. Proactively improve performance, reliability,\n\nand cost based on actionable observability data.\n\nSafely automate where possible: In the cloud, you can apply the same engineering discipline\n\nthat you use for application code to your entire environment. You can deﬁne your entire\n\nworkload and its operations (applications, infrastructure, conﬁguration, and procedures) as code,\n\nand update it. You can then automate your workload’s operations by initiating them in response\n\nto events. In the cloud, you can employ automation safety by conﬁguring guardrails, including\n\nDesign principles\n\n3",
      "content_length": 2728,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 9,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nrate control, error thresholds, and approvals. Through eﬀective automation, you can achieve\n\nconsistent responses to events, limit human error, and reduce operator toil.\n\nMake frequent, small, reversible changes: Design workloads that are scalable and loosely\n\ncoupled to permit components to be updated regularly. Automated deployment techniques\n\ntogether with smaller, incremental changes reduces the blast radius and allows for faster reversal\n\nwhen failures occur. This increases conﬁdence to deliver beneﬁcial changes to your workload\n\nwhile maintaining quality and adapting quickly to changes in market conditions.\n\nReﬁne operations procedures frequently: As you evolve your workloads, evolve your operations appropriately. As you use operations procedures, look for opportunities to improve them. Hold regular reviews and validate that all procedures are eﬀective and that teams are familiar with\n\nthem. Where gaps are identiﬁed, update procedures accordingly. Communicate procedural\n\nupdates to all stakeholders and teams. Gamify your operations to share best practices and\n\neducate teams.\n\nAnticipate failure: Maximize operational success by driving failure scenarios to understand the workload’s risk proﬁle and its impact on your business outcomes. Test the eﬀectiveness of your procedures and your team’s response against these simulated failures. Make informed decisions\n\nto manage open risks that are identiﬁed by your testing.\n\nLearn from all operational events and metrics: Drive improvement through lessons learned from all operational events and failures. Share what is learned across teams and through the entire organization. Learnings should highlight data and anecdotes on how operations\n\ncontribute to business outcomes.\n\nUse managed services: Reduce operational burden by using AWS managed services where\n\npossible. Build operational procedures around interactions with those services.\n\nDeﬁnition\n\nThere are four best practice areas for operational excellence in the cloud:\n\nOrganization\n\nPrepare\n\nOperate\n\nEvolve\n\nYour organization’s leadership deﬁnes business objectives. Your organization must understand\n\nrequirements and priorities and use these to organize and conduct work to support the\n\nDeﬁnition\n\n4",
      "content_length": 2295,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 10,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nachievement of business outcomes. Your workload must emit the information necessary to support\n\nit. Implementing services to activate integration, deployment, and delivery of your workload will create an increased ﬂow of beneﬁcial changes into production by automating repetitive processes.\n\nThere may be risks inherent in the operation of your workload. You must understand those risks\n\nand make an informed decision to enter production. Your teams must be able to support your\n\nworkload. Business and operational metrics derived from desired business outcomes will help you\n\nto understand the health of your workload, your operations activities, and respond to incidents.\n\nYour priorities will change as your business needs and business environment changes. Use these as\n\na feedback loop to continually drive improvement for your organization and the operation of your\n\nworkload.\n\nDeﬁnition\n\n5",
      "content_length": 958,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 11,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOrganization\n\nYour teams must have a shared understanding of your entire workload, their role in it, and shared\n\nbusiness goals to set the priorities that will achieve business success. Well-deﬁned priorities will\n\nmaximize the beneﬁts of your eﬀorts. Evaluate internal and external customer needs involving\n\nkey stakeholders, including business, development, and operations teams, to determine where to\n\nfocus eﬀorts. Evaluating customer needs will verify that you have a thorough understanding of\n\nthe support that is required to achieve business outcomes. Verify that you are aware of guidelines\n\nor obligations deﬁned by your organizational governance and external factors, such as regulatory\n\ncompliance requirements and industry standards that may mandate or emphasize speciﬁc focus.\n\nValidate that you have mechanisms to identify changes to internal governance and external\n\ncompliance requirements. If no requirements are identiﬁed, validate that you have applied due diligence to this determination. Review your priorities regularly so that they can be updated as needs change.\n\nEvaluate threats to the business (for example, business risk and liabilities, and information security\n\nthreats) and maintain this information in a risk registry. Evaluate the impact of risks, and tradeoﬀs\n\nbetween competing interests or alternative approaches. For example, accelerating speed to market\n\nfor new features may be emphasized over cost optimization, or you may choose a relational\n\ndatabase for non-relational data to simplify the eﬀort to migrate a system without refactoring.\n\nManage beneﬁts and risks to make informed decisions when determining where to focus eﬀorts.\n\nSome risks or choices may be acceptable for a time, it may be possible to mitigate associated risks,\n\nor it may become unacceptable to permit a risk to remain, in which case you will take action to\n\naddress the risk.\n\nYour teams must understand their part in achieving business outcomes. Teams must understand\n\ntheir roles in the success of other teams, the role of other teams in their success, and have shared\n\ngoals. Understanding responsibility, ownership, how decisions are made, and who has authority to make decisions will help focus eﬀorts and maximize the beneﬁts from your teams. The needs of\n\na team will be shaped by the customer they support, their organization, the makeup of the team,\n\nand the characteristics of their workload. It's unreasonable to expect a single operating model to\n\nbe able to support all teams and their workloads in your organization.\n\nVerify that there are identiﬁed owners for each application, workload, platform, and infrastructure\n\ncomponent, and that each process and procedure has an identiﬁed owner responsible for its\n\ndeﬁnition, and owners responsible for their performance.\n\n6",
      "content_length": 2861,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 12,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nHaving understanding of the business value of each component, process, and procedure, of why\n\nthose resources are in place or activities are performed, and why that ownership exists will inform the actions of your team members. Clearly deﬁne the responsibilities of team members so that\n\nthey may act appropriately and have mechanisms to identify responsibility and ownership. Have\n\nmechanisms to request additions, changes, and exceptions so that you do not constrain innovation.\n\nDeﬁne agreements between teams describing how they work together to support each other and\n\nyour business outcomes.\n\nProvide support for your team members so that they can be more eﬀective in taking action and\n\nsupporting your business outcomes. Engaged senior leadership should set expectations and\n\nmeasure success. Senior leadership should be the sponsor, advocate, and driver for the adoption\n\nof best practices and evolution of the organization. Let team members take action when outcomes\n\nare at risk to minimize impact and encourage them to escalate to decision makers and stakeholders\n\nwhen they believe there is a risk so that it can be addressed and incidents avoided. Provide timely,\n\nclear, and actionable communications of known risks and planned events so that team members\n\ncan take timely and appropriate action.\n\nEncourage experimentation to accelerate learning and keep team members interested and\n\nengaged. Teams must grow their skill sets to adopt new technologies, and to support changes in\n\ndemand and responsibilities. Support and encourage this by providing dedicated structured time\n\nfor learning. Verify that your team members have the resources, both tools and team members, to\n\nbe successful and scale to support your business outcomes. Leverage cross-organizational diversity\n\nto seek multiple unique perspectives. Use this perspective to increase innovation, challenge your\n\nassumptions, and reduce the risk of conﬁrmation bias. Grow inclusion, diversity, and accessibility\n\nwithin your teams to gain beneﬁcial perspectives.\n\nIf there are external regulatory or compliance requirements that apply to your organization,\n\nyou should use the resources provided by AWS Cloud Compliance to help educate your teams\n\nso that they can determine the impact on your priorities. The Well-Architected Framework\n\nemphasizes learning, measuring, and improving. It provides a consistent approach for you to\n\nevaluate architectures, and implement designs that will scale over time. AWS provides the\n\nAWS Well-Architected Tool to help you review your approach before development, the state\n\nof your workloads before production, and the state of your workloads in production. You can\n\ncompare workloads to the latest AWS architectural best practices, monitor their overall status,\n\nand gain insight into potential risks. AWS Trusted Advisor is a tool that provides access to a core\n\nset of checks that recommend optimizations that may help shape your priorities. Business and\n\nEnterprise Support customers receive access to additional checks focusing on security, reliability,\n\nperformance, cost-optimization, and sustainability that can further help shape their priorities.\n\n7",
      "content_length": 3234,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 13,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS can help you educate your teams about AWS and its services to increase their understanding\n\nof how their choices can have an impact on your workload. Use the resources provided by AWS Support (AWS Knowledge Center, AWS Discussion Forums, and AWS Support Center) and AWS\n\nDocumentation to educate your teams. Reach out to AWS Support through AWS Support Center\n\nfor help with your AWS questions. AWS also shares best practices and patterns that we have\n\nlearned through the operation of AWS in The Amazon Builders' Library. A wide variety of other\n\nuseful information is available through the AWS Blog and The Oﬃcial AWS Podcast. AWS Training\n\nand Certiﬁcation provides some training through self-paced digital courses on AWS fundamentals.\n\nYou can also register for instructor-led training to further support the development of your teams’\n\nAWS skills.\n\nUse tools or services that permit you to centrally govern your environments across accounts,\n\nsuch as AWS Organizations, to help manage your operating models. Services like AWS Control\n\nTower expand this management capability by allowing you to deﬁne blueprints (supporting your operating models) for the setup of accounts, apply ongoing governance using AWS Organizations,\n\nand automate provisioning of new accounts. Managed Services providers such as AWS Managed\n\nServices, AWS Managed Services Partners, or Managed Services Providers in the AWS Partner\n\nNetwork, provide expertise implementing cloud environments, and support your security and\n\ncompliance requirements and business goals. Adding Managed Services to your operating model\n\ncan save you time and resources, and lets you keep your internal teams lean and focused on\n\nstrategic outcomes that will diﬀerentiate your business, rather than developing new skills and\n\ncapabilities.\n\nYou might ﬁnd that you want to emphasize a small subset of your priorities at some point in time.\n\nUse a balanced approach over the long term to verify the development of needed capabilities\n\nand management of risk. Review your priorities regularly and update them as needs change.\n\nWhen responsibility and ownership are undeﬁned or unknown, you are at risk of both not\n\nperforming necessary action in a timely fashion and of redundant and potentially conﬂicting\n\neﬀorts emerging to address those needs. Organizational culture has a direct impact on team\n\nmember job satisfaction and retention. Activate the engagement and capabilities of your team\n\nmembers to achieve the success of your business. Experimentation is required for innovation to\n\nhappen and turn ideas into outcomes. Recognize that an undesired result is a successful experiment\n\nthat has identiﬁed a path that will not lead to success.\n\nTopics\n\nOrganization priorities\n\nOperating model\n\n8",
      "content_length": 2820,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 14,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOrganizational culture\n\nOrganization priorities\n\nYour teams need to have a shared understanding of your entire workload, their role in it, and\n\nshared business goals to set the priorities that will create business success. Well-deﬁned priorities\n\nwill maximize the beneﬁts of your eﬀorts. Review your priorities regularly so that they can be\n\nupdated as your organization's needs change.\n\nBest practices\n\nOPS01-BP01 Evaluate external customer needs\n\nOPS01-BP02 Evaluate internal customer needs\n\nOPS01-BP03 Evaluate governance requirements\n\nOPS01-BP04 Evaluate compliance requirements\n\nOPS01-BP05 Evaluate threat landscape\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nOPS01-BP01 Evaluate external customer needs\n\nInvolve key stakeholders, including business, development, and operations teams, to determine\n\nwhere to focus eﬀorts on external customer needs. This veriﬁes that you have a thorough\n\nunderstanding of the operations support that is required to achieve your desired business\n\noutcomes.\n\nDesired outcome:\n\nYou work backwards from customer outcomes.\n\nYou understand how your operational practices support business outcomes and objectives.\n\nYou engage all relevant parties.\n\nYou have mechanisms to capture external customer needs.\n\nCommon anti-patterns:\n\nOrganization priorities\n\n9",
      "content_length": 1371,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 15,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou have decided not to have customer support outside of core business hours, but you haven't\n\nreviewed historical support request data. You do not know whether this will have an impact on your customers.\n\nYou are developing a new feature but have not engaged your customers to ﬁnd out if it is\n\ndesired, if desired in what form, and without experimentation to validate the need and method\n\nof delivery.\n\nBeneﬁts of establishing this best practice: Customers whose needs are satisﬁed are much more likely to remain customers. Evaluating and understanding external customer needs will inform how\n\nyou prioritize your eﬀorts to deliver business value.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nUnderstand business needs: Business success is created by shared goals and understanding across stakeholders, including business, development, and operations teams.\n\nReview business goals, needs, and priorities of external customers: Engage key stakeholders, including business, development, and operations teams, to discuss goals, needs, and priorities\n\nof external customers. This ensures that you have a thorough understanding of the operational\n\nsupport that is required to achieve business and customer outcomes.\n\nEstablish a shared understanding: Establish a shared understanding of the business functions of the workload, the roles of each of the teams in operating the workload, and how these factors\n\nsupport your shared business goals across internal and external customers.\n\nResources\n\nRelated best practices:\n\nOPS11-BP03 Implement feedback loops\n\nOPS01-BP02 Evaluate internal customer needs\n\nInvolve key stakeholders, including business, development, and operations teams, when\n\ndetermining where to focus eﬀorts on internal customer needs. This will ensure that you have a\n\nthorough understanding of the operations support that is required to achieve business outcomes.\n\nOPS01-BP02 Evaluate internal customer needs\n\n10",
      "content_length": 2040,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 16,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome:\n\nYou use your established priorities to focus your improvement eﬀorts where they will have the\n\ngreatest impact (for example, developing team skills, improving workload performance, reducing\n\ncosts, automating runbooks, or enhancing monitoring).\n\nYou update your priorities as needs change.\n\nCommon anti-patterns:\n\nYou have decided to change IP address allocations for your product teams, without consulting\n\nthem, to make managing your network easier. You do not know the impact this will have on your\n\nproduct teams.\n\nYou are implementing a new development tool but have not engaged your internal customers to\n\nﬁnd out if it is needed or if it is compatible with their existing practices.\n\nYou are implementing a new monitoring system but have not contacted your internal customers\n\nto ﬁnd out if they have monitoring or reporting needs that should be considered.\n\nBeneﬁts of establishing this best practice: Evaluating and understanding internal customer needs informs how you prioritize your eﬀorts to deliver business value.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nUnderstand business needs: Business success is created by shared goals and understanding\n\nacross stakeholders including business, development, and operations teams.\n\nReview business goals, needs, and priorities of internal customers: Engage key stakeholders,\n\nincluding business, development, and operations teams, to discuss goals, needs, and priorities\n\nof internal customers. This ensures that you have a thorough understanding of the operational\n\nsupport that is required to achieve business and customer outcomes.\n\nEstablish shared understanding: Establish shared understanding of the business functions of\n\nthe workload, the roles of each of the teams in operating the workload, and how these factors\n\nsupport shared business goals across internal and external customers.\n\nResources\n\nRelated best practices:\n\nOPS01-BP02 Evaluate internal customer needs\n\n11",
      "content_length": 2068,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 17,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP03 Implement feedback loops\n\nOPS01-BP03 Evaluate governance requirements\n\nGovernance is the set of policies, rules, or frameworks that a company uses to achieve its business\n\ngoals. Governance requirements are generated from within your organization. They can aﬀect the\n\ntypes of technologies you choose or inﬂuence the way you operate your workload. Incorporate\n\norganizational governance requirements into your workload. Conformance is the ability to\n\ndemonstrate that you have implemented governance requirements.\n\nDesired outcome:\n\nGovernance requirements are incorporated into the architectural design and operation of your\n\nworkload.\n\nYou can provide proof that you have followed governance requirements.\n\nGovernance requirements are regularly reviewed and updated.\n\nCommon anti-patterns:\n\nYour organization mandates that the root account has multi-factor authentication. You failed to\n\nimplement this requirement and the root account is compromised.\n\nDuring the design of your workload, you choose an instance type that is not approved by the IT\n\ndepartment. You are unable to launch your workload and must conduct a redesign.\n\nYou are required to have a disaster recovery plan. You did not create one and your workload\n\nsuﬀers an extended outage.\n\nYour team wants to use new instances but your governance requirements have not been updated\n\nto allow them.\n\nBeneﬁts of establishing this best practice:\n\nFollowing governance requirements aligns your workload with larger organization policies.\n\nGovernance requirements reﬂect industry standards and best practices for your organization.\n\nLevel of risk exposed if this best practice is not established: High\n\nOPS01-BP03 Evaluate governance requirements\n\n12",
      "content_length": 1782,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 18,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nIdentify governance requirement by working with stakeholders and governance organizations. Include governance requirements into your workload. Be able to demonstrate proof that you’ve\n\nfollowed governance requirements.\n\nCustomer example\n\nAt AnyCompany Retail, the cloud operations team works with stakeholders across the organization\n\nto develop governance requirements. For example, they prohibit SSH access into Amazon EC2\n\ninstances. If teams need system access, they are required to use AWS Systems Manager Session\n\nManager. The cloud operations team regularly updates governance requirements as new services\n\nbecome available.\n\nImplementation steps\n\n1. Identify the stakeholders for your workload, including any centralized teams.\n\n2. Work with stakeholders to identify governance requirements.\n\n3. Once you’ve generated a list, prioritize the improvement items, and begin implementing them\n\ninto your workload.\n\na. Use services like AWS Conﬁg to create governance-as-code and validate that governance\n\nrequirements are followed.\n\nb. If you use AWS Organizations, you can leverage Service Control Policies to implement\n\ngovernance requirements.\n\n4. Provide documentation that validates the implementation.\n\nLevel of eﬀort for the implementation plan: Medium. Implementing missing governance requirements may result in rework of your workload.\n\nResources\n\nRelated best practices:\n\nOPS01-BP04 Evaluate compliance requirements - Compliance is like governance but comes from\n\noutside an organization.\n\nRelated documents:\n\nOPS01-BP03 Evaluate governance requirements\n\n13",
      "content_length": 1658,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 19,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Management and Governance Cloud Environment Guide\n\nBest Practices for AWS Organizations Service Control Policies in a Multi-Account Environment\n\nGovernance in the AWS Cloud: The Right Balance Between Agility and Safety\n\nWhat is Governance, Risk, And Compliance (GRC)?\n\nRelated videos:\n\nAWS Management and Governance: Conﬁguration, Compliance, and Audit - AWS Online Tech\n\nTalks\n\nAWS re:Inforce 2019: Governance for the Cloud Age (DEM12-R1)\n\nAWS re:Invent 2020: Achieve compliance as code using AWS Conﬁg\n\nAWS re:Invent 2020: Agile governance on AWS GovCloud (US)\n\nRelated examples:\n\nAWS Conﬁg Conformance Pack Samples\n\nRelated services:\n\nAWS Conﬁg\n\nAWS Organizations - Service Control Policies\n\nOPS01-BP04 Evaluate compliance requirements\n\nRegulatory, industry, and internal compliance requirements are an important driver for deﬁning\n\nyour organization’s priorities. Your compliance framework may preclude you from using speciﬁc\n\ntechnologies or geographic locations. Apply due diligence if no external compliance frameworks\n\nare identiﬁed. Generate audits or reports that validate compliance.\n\nIf you advertise that your product meets speciﬁc compliance standards, you must have an internal\n\nprocess for ensuring continuous compliance. Examples of compliance standards include PCI DSS,\n\nFedRAMP, and HIPAA. Applicable compliance standards are determined by various factors, such\n\nas what types of data the solution stores or transmits and which geographic regions the solution supports.\n\nDesired outcome:\n\nOPS01-BP04 Evaluate compliance requirements\n\n14",
      "content_length": 1622,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 20,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRegulatory, industry, and internal compliance requirements are incorporated into architectural\n\nselection.\n\nYou can validate compliance and generate audit reports.\n\nCommon anti-patterns:\n\nParts of your workload fall under the Payment Card Industry Data Security Standard (PCI-DSS)\n\nframework but your workload stores credit cards data unencrypted.\n\nYour software developers and architects are unaware of the compliance framework that your\n\norganization must adhere to.\n\nThe yearly Systems and Organizations Control (SOC2) Type II audit is happening soon and you\n\nare unable to verify that controls are in place.\n\nBeneﬁts of establishing this best practice:\n\nEvaluating and understanding the compliance requirements that apply to your workload will\n\ninform how you prioritize your eﬀorts to deliver business value.\n\nYou choose the right locations and technologies that are congruent with your compliance\n\nframework.\n\nDesigning your workload for auditability helps you to prove you are adhering to your compliance\n\nframework.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplementing this best practice means that you incorporate compliance requirements into your architecture design process. Your team members are aware of the required compliance framework.\n\nYou validate compliance in line with the framework.\n\nCustomer example\n\nAnyCompany Retail stores credit card information for customers. Developers on the card storage\n\nteam understand that they need to comply with the PCI-DSS framework. They’ve taken steps\n\nto verify that credit card information is stored and accessed securely in line with the PCI-DSS\n\nframework. Every year they work with their security team to validate compliance.\n\nOPS01-BP04 Evaluate compliance requirements\n\n15",
      "content_length": 1855,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 21,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Work with your security and governance teams to determine what industry, regulatory, or\n\ninternal compliance frameworks that your workload must adhere to. Incorporate the compliance\n\nframeworks into your workload.\n\na. Validate continual compliance of AWS resources with services like AWS Compute Optimizer\n\nand AWS Security Hub CSPM.\n\n2. Educate your team members on the compliance requirements so they can operate and evolve\n\nthe workload in line with them. Compliance requirements should be included in architectural\n\nand technological choices.\n\n3. Depending on the compliance framework, you may be required to generate an audit or\n\ncompliance report. Work with your organization to automate this process as much as possible.\n\na. Use services like AWS Audit Manager to validate compliance and generate audit reports.\n\nb. You can download AWS security and compliance documents with AWS Artifact.\n\nLevel of eﬀort for the implementation plan: Medium. Implementing compliance frameworks can be challenging. Generating audit reports or compliance documents adds additional complexity.\n\nResources\n\nRelated best practices:\n\nSEC01-BP03 Identify and validate control objectives - Security control objectives are an\n\nimportant part of overall compliance.\n\nSEC01-BP06 Automate testing and validation of security controls in pipelines - As part of your\n\npipelines, validate security controls. You can also generate compliance documentation for new\n\nchanges.\n\nSEC07-BP02 Deﬁne data protection controls - Many compliance frameworks have data handling\n\nand storage policies based.\n\nSEC10-BP03 Prepare forensic capabilities - Forensic capabilities can sometimes be used in\n\nauditing compliance.\n\nRelated documents:\n\nAWS Compliance Center\n\nAWS Compliance Resources\n\nOPS01-BP04 Evaluate compliance requirements\n\n16",
      "content_length": 1886,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 22,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Risk and Compliance Whitepaper\n\nAWS Shared Responsibility Model\n\nAWS services in scope by compliance programs\n\nRelated videos:\n\nAWS re:Invent 2020: Achieve compliance as code using AWS Compute Optimizer\n\nAWS re:Invent 2021 - Cloud compliance, assurance, and auditing\n\nAWS Summit ATL 2022 - Implementing compliance, assurance, and auditing on AWS (COP202)\n\nRelated examples:\n\nPCI DSS and AWS Foundational Security Best Practices on AWS\n\nRelated services:\n\nAWS Artifact\n\nAWS Audit Manager\n\nAWS Compute Optimizer\n\nAWS Security Hub CSPM\n\nOPS01-BP05 Evaluate threat landscape\n\nEvaluate threats to the business (for example, competition, business risk and liabilities, operational\n\nrisks, and information security threats) and maintain current information in a risk registry. Include\n\nthe impact of risks when determining where to focus eﬀorts.\n\nThe Well-Architected Framework emphasizes learning, measuring, and improving. It provides a\n\nconsistent approach for you to evaluate architectures, and implement designs that will scale over\n\ntime. AWS provides the AWS Well-Architected Tool to help you review your approach prior to\n\ndevelopment, the state of your workloads prior to production, and the state of your workloads\n\nin production. You can compare them to the latest AWS architectural best practices, monitor the\n\noverall status of your workloads, and gain insight to potential risks.\n\nAWS customers are eligible for a guided Well-Architected Review of their mission-critical workloads\n\nto measure their architectures against AWS best practices. Enterprise Support customers are\n\nOPS01-BP05 Evaluate threat landscape\n\n17",
      "content_length": 1689,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 23,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\neligible for an Operations Review, designed to help them to identify gaps in their approach to\n\noperating in the cloud.\n\nThe cross-team engagement of these reviews helps to establish common understanding of your\n\nworkloads and how team roles contribute to success. The needs identiﬁed through the review can\n\nhelp shape your priorities.\n\nAWS Trusted Advisor is a tool that provides access to a core set of checks that recommend\n\noptimizations that may help shape your priorities. Business and Enterprise Support customers\n\nreceive access to additional checks focusing on security, reliability, performance, and cost-\n\noptimization that can further help shape their priorities.\n\nDesired outcome:\n\nYou regularly review and act on Well-Architected and Trusted Advisor outputs\n\nYou are aware of the latest patch status of your services\n\nYou understand the risk and impact of known threats and act accordingly\n\nYou implement mitigations as necessary\n\nYou communicate actions and context\n\nCommon anti-patterns:\n\nYou are using an old version of a software library in your product. You are unaware of security\n\nupdates to the library for issues that may have unintended impact on your workload.\n\nYour competitor just released a version of their product that addresses many of your customers'\n\ncomplaints about your product. You have not prioritized addressing any of these known issues.\n\nRegulators have been pursuing companies like yours that are not compliant with legal regulatory\n\ncompliance requirements. You have not prioritized addressing any of your outstanding\n\ncompliance requirements.\n\nBeneﬁts of establishing this best practice: You identify and understand the threats to your organization and workload, which helps your determination of which threats to address, their\n\npriority, and the resources necessary to do so.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS01-BP05 Evaluate threat landscape\n\n18",
      "content_length": 1999,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 24,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nEvaluate threat landscape: Evaluate threats to the business (for example, competition, business risk and liabilities, operational risks, and information security threats), so that you can include their impact when determining where to focus eﬀorts.\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nMaintain a threat model: Establish and maintain a threat model identifying potential threats,\n\nplanned and in place mitigations, and their priority. Review the probability of threats manifesting\n\nas incidents, the cost to recover from those incidents and the expected harm caused, and the cost\n\nto prevent those incidents. Revise priorities as the contents of the threat model change.\n\nResources\n\nRelated best practice:\n\nSEC01-BP07 Identify threats and prioritize mitigations using a threat model\n\nRelated documents:\n\nAWS Cloud Compliance\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nRelated videos:\n\nAWS re:Inforce 2023 - A tool to help improve your threat modeling\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nCompeting interests from multiple parties can make it challenging to prioritize eﬀorts, build\n\ncapabilities, and deliver outcomes aligned with business strategies. For example, you may be asked\n\nto accelerate speed-to-market for new features over optimizing IT infrastructure costs. This can\n\nput two interested parties in conﬂict with one another. In these situations, decisions need to be\n\nbrought to a higher authority to resolve conﬂict. Data is required to remove emotional attachment\n\nfrom the decision-making process.\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n19",
      "content_length": 1720,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 25,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe same challenge may occur at a tactical level. For example, the choice between using relational\n\nor non-relational database technologies can have a signiﬁcant impact on the operation of an application. It's critical to understand the predictable results of various choices.\n\nAWS can help you educate your teams about AWS and its services to increase their understanding\n\nof how their choices can have an impact on your workload. Use the resources provided by Support\n\n(AWS Knowledge Center, AWS Discussion Forums, and Support Center) and AWS Documentation to\n\neducate your teams. For further questions, reach out to Support.\n\nAWS also shares operational best practices and patterns in The Amazon Builders' Library. A wide\n\nvariety of other useful information is available through the AWS Blog and The Oﬃcial AWS\n\nPodcast.\n\nDesired outcome: You have a clearly deﬁned decision-making governance framework to facilitate important decisions at every level within your cloud delivery organization. This framework includes\n\nfeatures like a risk register, deﬁned roles that are authorized to make decisions, and a deﬁned\n\nmodels for each level of decision that can be made. This framework deﬁnes in advance how\n\nconﬂicts are resolved, what data needs to be presented, and how options are prioritized, so that\n\nonce decisions are made you can commit without delay. The decision-making framework includes\n\na standardized approach to reviewing and weighing the beneﬁts and risks of every decision to\n\nunderstand the tradeoﬀs. This may include external factors, such as adherence to regulatory\n\ncompliance requirements.\n\nCommon anti-patterns:\n\nYour investors request that you demonstrate compliance with Payment Card Industry Data\n\nSecurity Standards (PCI DSS). You do not consider the tradeoﬀs between satisfying their\n\nrequest and continuing with your current development eﬀorts. Instead, you proceed with your\n\ndevelopment eﬀorts without demonstrating compliance. Your investors stop their support of\n\nyour company over concerns about the security of your platform and their investments.\n\nYou have decided to include a library that one of your developers found on the internet. You\n\nhave not evaluated the risks of adopting this library from an unknown source and do not know if\n\nit contains vulnerabilities or malicious code.\n\nThe original business justiﬁcation for your migration was based upon the modernization of 60%\n\nof your application workloads. However, due to technical diﬃculties, a decision was made to\n\nmodernize only 20%, leading to a reduction in planned beneﬁts long-term, increased operator\n\ntoil for infrastructure teams to manually support legacy systems, and greater reliance on\n\ndeveloping new skillsets in your infrastructure teams that were not planning for this change.\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n20",
      "content_length": 2918,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 26,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: Fully aligning and supporting board-level business priorities, understanding the risks to achieving success, making informed decisions, and acting appropriately when risks impede chances for success. Understanding the implications and\n\nconsequences of your decisions helps you to prioritize your options and bring leaders into\n\nagreement faster, leading to improved business outcomes. Identifying the available beneﬁts\n\nof your choices and being aware of the risks to your organization helps you make data-driven\n\ndecisions, rather than relying on anecdotes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nManaging beneﬁts and risks should be deﬁned by a governing body that drives the requirements\n\nfor key decision-making. You want decisions to be made and prioritized based on how they\n\nbeneﬁt the organization, with an understanding of the risks involved. Accurate information is\n\ncritical for making the organizational decisions. This should be based on solid measurements and\n\ndeﬁned by common industry practices of cost beneﬁt analysis. To make these types of decisions,\n\nstrike a balance between centralized and decentralized authority. There is always a tradeoﬀ, and\n\nit's important to understand how each choice impacts deﬁned strategies and desired business\n\noutcomes.\n\nImplementation steps\n\n1. Formalize beneﬁts measurement practices within a holistic cloud governance framework.\n\na. Balance central control of decision-making with decentralized authority for some decisions.\n\nb. Understand that burdensome decision-making processes imposed on every decision can slow\n\nyou down.\n\nc. Incorporate external factors into your decision making process (like compliance requirements).\n\n2. Establish an agreed-upon decision-making framework for various levels of decisions, which\n\nincludes who is required to unblock decisions that are subject to conﬂicted interests.\n\na. Centralize one-way door decisions that could be irreversible.\n\nb. Allow two-way door decisions to be made by lower level organizational leaders.\n\n3. Understand and manage beneﬁts and risks. Balance the beneﬁts of decisions against the risks\n\ninvolved.\n\na. Identify beneﬁts: Identify beneﬁts based on business goals, needs, and priorities. Examples include business case impact, time-to-market, security, reliability, performance, and cost.\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n21",
      "content_length": 2540,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 27,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nb. Identify risks: Identify risks based on business goals, needs, and priorities. Examples include\n\ntime-to-market, security, reliability, performance, and cost.\n\nc. Assess beneﬁts against risks and make informed decisions: Determine the impact of\n\nbeneﬁts and risks based on goals, needs, and priorities of your key stakeholders, including\n\nbusiness, development, and operations. Evaluate the value of the beneﬁt against the\n\nprobability of the risk being realized and the cost of its impact. For example, emphasizing\n\nspeed-to-market over reliability might provide competitive advantage. However, it may result\n\nin reduced uptime if there are reliability issues.\n\n4. Programatically enforce key decisions that automate your adherence to compliance\n\nrequirements.\n\n5. Leverage known industry frameworks and capabilities, such as Value Stream Analysis and\n\nLEAN, to baseline current state performance, business metrics, and deﬁne iterations of progress\n\ntowards improvements to these metrics.\n\nLevel of eﬀort for the implementation plan: Medium-High\n\nResources\n\nRelated best practices:\n\nOPS01-BP05 Evaluate threat landscape\n\nRelated documents:\n\nElements of Amazon's Day 1 Culture | Make high quality, high velocity decisions\n\nCloud Governance\n\nManagement & Governance Cloud Environment\n\nGovernance in the Cloud and in the Digital Age: Parts One & Two\n\nRelated videos:\n\nPodcast | Jeﬀ Bezos | On how to make decisions\n\nRelated examples:\n\nMake informed decisions using data (The DevOps Sagas)\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\n22",
      "content_length": 1619,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 28,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUsing development value stream mapping to identify constraints to DevOps outcomes\n\nOperating model\n\nIn this section, we provide a way to understand the operating model you work within, how that\n\nmodel can be visualized, and how, at a team level, you should evolve to extract maximum value\n\nfrom your investment in cloud services. By doing so, you can enhance your operational practices,\n\nbuild agile teams and workloads, and positively contribute to business outcomes.\n\nIt is common for your team to exist within multiple organizational layers, and those layers have\n\nexisting ways of working. Participating with your team in achieving business outcomes means\n\nunderstanding where your teams are in those layers, the position of the teams you interact with,\n\nand how they work. Furthermore, teams need to understand their roles in the success of other teams, know the role of other teams in their success, and have shared goals.\n\nThese layers make up the overall operating model of the organization. How the organization\n\nfunctions to deliver business outcomes depends upon many factors, such as type, industry,\n\ngeography, size, and level of autonomy. However, it likely falls into three broad categories:\n\nCentralized\n\nDecentralized\n\nFederated\n\nThese organization-level topologies are described in Organize for success.\n\nYour team and workload exist within your organization's operating model. However, it is\n\nunreasonable to expect a single operating model to be able to support all teams and their\n\nworkloads. Therefore, your team also needs its own operating model. This way of working is\n\nshaped by your organization, your department, the makeup of your team, and the characteristics of\n\nthe workload itself.\n\nMost organizations that move to the cloud do so as part of an enterprise transformation program\n\nthat seeks to unlock new ways of working (the operating model) to support long-term strategic\n\naims. This journey is not a point in time exercise, but a process that requires continual evolution\n\nand incremental progress towards the strategic goal. This allows workloads owners to adapt to the\n\nevolving operating model with minimal disruption.\n\nOperating model\n\n23",
      "content_length": 2241,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 29,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAmazon is often used as an example of how a large organization is able to innovate at scale by\n\nempowering teams to stay close to customers, rapidly launch innovative products and services, and take advantage of technical architectures that support speed and agility. This required us to\n\nrestructure how our teams are organized, now known as two-pizza teams. A two-pizza team has all\n\nthe right resources embedded within it (engineering, testing, product and program management,\n\nand operations) to own and run a workload end-to-end.\n\nWe advise working towards this operating model as a proven way for workload teams to move\n\nquickly and contribute to overall business outcomes in the way that best serves their customers.\n\nOrganizations seeking to emulate this success may need to adapt their operating model\n\nthroughout their transformation journey. At both organization and team level, this requires\n\nconsideration, planning, and communication. The following section provides a way to visualize\n\nthese team-level operating models and how they evolve to you build it, you run it.\n\nOperating model 2 by 2 representations\n\nThese operating model 2 by 2 representations are illustrations to help you understand the\n\nrelationships between teams in your environment. These diagrams focus on who does what and\n\nthe relationships between teams, but we will also discuss governance and decision making in\n\ncontext of these examples.\n\nYour teams may have responsibilities in multiple parts of multiple models depending on the\n\nworkloads they support. You may wish to break out more specialized discipline areas than the high-\n\nlevel ones described. There is the potential for endless variation on these models as you separate\n\nor aggregate activities, or overlay teams and provide more speciﬁc detail.\n\nYou may identify that you have overlapping or unrecognized capabilities across teams that can\n\nprovide additional advantage, or lead to eﬃciencies. You may also identify unsatisﬁed needs in\n\nyour organization that you can plan to address.\n\nWhen evaluating organizational change, examine the trade-oﬀs between models, where your\n\nindividual teams exist within the models (now and after the change), how your teams’ relationship\n\nand responsibilities will change, and if the beneﬁts merit the impact on your organization.\n\nYou can be successful using each of the following four operating models. Some models are more\n\nappropriate for speciﬁc use cases or at speciﬁc points in your development. Some of these models may provide advantages over the ones in use in your environment.\n\nTopics\n\nOperating model 2 by 2 representations\n\n24",
      "content_length": 2688,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 30,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nFully separated operating model\n\nDevOps with cloud-managed service provider\n\nCloud operations and platform enablement (COPE)\n\nDistributed DevOps\n\nDecentralized DevOps\n\nEvolving your operating model\n\nFully separated operating model\n\nIn the following diagram, on the vertical axis we have Applications and Platform. Applications refer\n\nto the workload serving a business outcome and can be custom developed or purchased software.\n\nPlatform refers to the physical and virtual infrastructure and other software that supports that workload.\n\nOn the horizontal axis, we have Engineering and Operations. Engineering refers to the\n\ndevelopment, building, and testing of applications and infrastructure. Operations is the\n\ndeployment, update, and ongoing support of applications and infrastructure.\n\nTraditional model\n\nHistorically, organizations embraced frameworks such as ITIL or standards like ISO and shaped\n\ntheir operational activties around them, which often resulted in a fully-separated topology. In\n\nthis model, activities in each quadrant are performed by a separate team. Work is passed between\n\nteams through mechanisms such as work requests, queues, tickets, or by using an IT service\n\nmanagement (ITSM) system.\n\nOperating model 2 by 2 representations\n\n25",
      "content_length": 1324,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 31,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe transition of tasks to or between teams increases complexity, and creates bottlenecks and\n\ndelays. Requests may be delayed until they are a priority. Defects identiﬁed late may require signiﬁcant rework and may have to pass through the same teams and their functions once again.\n\nIf there are incidents that require action by engineering teams, their responses are delayed by the\n\nhand oﬀ activity.\n\nThere is a higher risk of misalignment when business, development, and operations teams\n\nare organized around the activities or functions that are being performed. This can lead to\n\nteams focusing on their speciﬁc responsibilities instead of focusing on achieving business\n\noutcomes. Teams may be narrowly specialized, physically isolated, or logically isolated, hindering\n\ncommunication and collaboration.\n\nDevOps with cloud-managed service provider\n\nThe DevOps with cloud-managed service provider model follows a you build it, you run it\n\nmethodology for application teams. However, your organization may not have the existing skills or\n\nteam members to support a dedicated platform engineering and operations team, or you may not\n\nbe in a position to make the time and eﬀort investments to do so.\n\nAlternatively, you may wish to have a platform team that is focused on creating capabilities that\n\ndiﬀerentiate your business, but you want to outsource the undiﬀerentiated day-to-day operations.\n\nManaged services providers such as AWS Managed Services or providers in the AWS Partner\n\nNetwork provide expertise implementing cloud environments, and support your security and\n\ncompliance requirements and business goals.\n\nOperating model 2 by 2 representations\n\n26",
      "content_length": 1731,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 32,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDevOps with cloud managed service provider\n\nFor this variation, we treat governance as centralized and managed by the platform team, with\n\naccount creation and policies managed with AWS Organizations and AWS Control Tower.\n\nThis model requires you to modify your mechanisms to work with those of your service provider.\n\nIt does not address the bottlenecks and delays created by transition of tasks between teams,\n\nincluding your service provider, or the potential rework related to the late identiﬁcation of defects.\n\nYou gain the advantage of your providers’ standards, best practices, processes, and expertise. You\n\nalso gain the beneﬁts of their ongoing development of their service oﬀerings.\n\nAdding managed services to your operating model can save you time and resources and keeps your\n\ninternal teams lean and focused on strategic outcomes that diﬀerentiate your business, rather than\n\ndeveloping new skills and capabilities. It can also provide time for you to build and mature your own platform capabilities without slowing down your cloud migration programs.\n\nCloud operations and platform enablement (COPE)\n\nThis cloud operations and platform enablement (COPE) model seeks to establish a you build it, you\n\nrun it methodology by supporting application teams to perform the engineering and operations\n\nactivities for their workloads, adopting a DevOps culture.\n\nYour application teams may be tasked with migrating, adopting the cloud, or modernizing your\n\nworkloads, but might not have the existing skills to adequately support cloud architecture and\n\noperations. This lack of application team capabilities and familiarity is likely to slow down your\n\norganization’s agility and impact business outcomes.\n\nTo address this concern, use your existing operational expertise from within your organization to\n\nsupport application teams on their journey to cloud operations. This can be a dedicated team of\n\nexperts or a virtual team with participants selected from across your organization. However, the\n\ngoal remains the same, which is to provide operational support that builds the capability of the\n\nworkload team, using cloud ﬁrst principles of automation, removing undiﬀerentiated heavy lifting,\n\nproviding standardized patterns, and promoting autonomy. The aim is to build suﬃcient maturity\n\nacross cloud capabilities and lower the barrier of operational responsibilities so that application\n\nteams no longer need additional support.\n\nThe COPE model focuses on the workload level. If this approach is needed across multiple teams\n\nat once, if you are performing a complex, large-scale, multi-year migration project, or if you are\n\nbuilding a platform to support these initiatives, consider using a Cloud Center of Excellence (CCoE).\n\nOperating model 2 by 2 representations\n\n27",
      "content_length": 2850,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 33,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThis is a mechanism that many have found successful when seeking to accelerate their migrations\n\nto the cloud and broadly transform their organization.\n\nCloud Operations and Platform Enablement (COPE)\n\nYour platform engineering team builds a thin layer of core shared platform capabilities, which are\n\nbased on predeﬁned standards for application teams to adopt and are provided by the COPE team.\n\nThe platform engineering team codiﬁes the enterprise reference architectures and patterns that\n\nare provided to the application teams through a self-service mechanism. Using a service such as\n\nAWS Service Catalog, the application teams can deploy approved reference architectures, patterns,\n\nservices, and conﬁgurations, compliant by default with the centralized governance and security\n\nstandards.\n\nThe platform engineering team also provides a standardized set of services (for example,\n\ndevelopment tools, observability tools, backup and recovery tools, and networking) to the\n\napplication teams.\n\nThe COPE team manages and supports the standardized services and provides assistance to\n\napplication teams establishing their cloud presence based on the reference architectures and\n\npatterns. They work with the application teams to help them establish baseline operations. During\n\nthis process, the application teams progressively take more responsibility for their systems and\n\nresources over time. The COPE team drives continual improvement together with the platform\n\nengineering team and acts as proponents for the application teams.\n\nThe application teams get assistance setting up environments, CI/CD pipelines, change\n\nmanagement, observability and monitoring, and establishing incident and event management\n\nOperating model 2 by 2 representations\n\n28",
      "content_length": 1821,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 34,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nprocesses, with the COPE team integrated as required. The COPE team participates with the\n\napplication teams in the performance of these operations activities, phasing out the COPE team engagement over time as the application teams take ownership.\n\nThe application team gains the beneﬁt of the skills of the COPE team and the lessons learned by\n\nthe organization. They are protected by the guardrails established through centralized governance.\n\nThe application team builds upon recognized successes and gains the beneﬁt of continuing\n\ndevelopment of the organizational standards they have adopted. They gain greater insight to the\n\noperation of their workload through the process of establishing observability and monitoring and\n\nare better able to understand the impact of changes they make to their workloads.\n\nThe COPE team may also retain the access necessary to support operations activities, provide an\n\nenterprise-operations view spanning application teams, and oﬀer critical incident management\n\nsupport. The COPE team retains responsibility for activities considered as undiﬀerentiated heavy\n\nlifting, which they satisfy through standard solutions supportable at scale. They also continue to\n\nmanage well-understood programmatic and automated operations activities for the application\n\nteams so that they can focus on diﬀerentiating their applications.\n\nYou gain the advantage of your organization’s standards, best practices, processes, and expertise,\n\nderived from the successes of your teams. You establish a mechanism to replicate these successful\n\npatterns for new teams adopting or modernizing in the cloud. This model places emphasis on\n\nthe COPE team’s ability to help application teams get established and transition knowledge\n\nand artifacts. It reduces the operational burdens of the application teams, with the risk that\n\napplication teams can fail to become independent. It establishes relationships between platform\n\nengineering, COPE, and application teams, creating a feedback loop to support further evolution\n\nand innovation.\n\nEstablishing your platform engineering and COPE teams, while deﬁning organization wide\n\nstandards, can facilitate cloud adoption and support modernization eﬀorts. By providing the\n\nadditional support of a COPE team acting as consultants and partners to your application teams,\n\nyou can remove workload level barriers that slow application team adoption of beneﬁcial cloud\n\ncapabilities.\n\nDistributed DevOps\n\nThe distributed DevOps model separates (or distributes) the application engineering operations\n\nand infrastructure engineering operations responsibilities across the engineering teams, following\n\nthe COPE methodology.\n\nOperating model 2 by 2 representations\n\n29",
      "content_length": 2786,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 35,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYour application engineers perform both the engineering and the operation of their workloads.\n\nSimilarly, your infrastructure engineers perform both the engineering and operation of the platforms they use to support application teams.\n\nDistributed DevOps\n\nFor this example, we treat governance as centralized elsewhere within the organization. Standards\n\nare distributed, provided, or shared to the application and platform teams.\n\nUse tools or services that help you centrally govern your environments across accounts, such\n\nas AWS Organizations. Services like AWS Control Tower expand this management capability by\n\nhelping you deﬁne blueprints (supporting your operating models) for the setup of accounts, apply\n\nongoing governance using AWS Organizations, and automate provisioning of new accounts.\n\nYou build it, you run it does not mean that the application team is responsible for the full stack, tool\n\nchain, and platform.\n\nThe platform engineering team provides a standardized set of services (for example, development\n\ntools, monitoring tools, backup and recovery tools, and networking) to the application team. The\n\nplatform team may also provide the application team access to approved cloud provider services,\n\nspeciﬁc conﬁgurations of the same, or both.\n\nMechanisms that provide a self-service capability for deploying approved services and conﬁgurations, such as Service Catalog, can help limit delays associated with fulﬁllment requests\n\nwhile enforcing governance.\n\nOperating model 2 by 2 representations\n\n30",
      "content_length": 1588,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 36,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe platform team activates full stack visibility so that application teams can diﬀerentiate between\n\nissues with their application components and the services and infrastructure components their applications consume. The platform team may also provide assistance conﬁguring these services\n\nand guidance on how to improve an application team's operations.\n\nAs discussed previously, it is critical that mechanisms exist for application teams to request\n\nadditions, changes, and exceptions to standards in support of activities and innovation of their\n\napplication.\n\nThe distributed DevOps model provides strong feedback loops to application teams. Day-to-day\n\noperations of a workload increase contact with customers, either through direct interaction or\n\nindirectly through support and feature requests. This heightened visibility allows application teams\n\nto address issues more quickly. The deeper engagement and closer relationship provides insight to\n\ncustomer needs and creates more rapid innovation.\n\nAll of this is also true for the platform team supporting the application teams, as the platform\n\nteam should view these application teams as their customers.\n\nAdopted standards may be pre-approved for use, reducing the amount of review necessary to\n\nenter production. Consuming supported and tested standards provided by the platform team may\n\nreduce the frequency of issues with those services. Adoption of standards helps application teams\n\nfocus on diﬀerentiating their workloads.\n\nDecentralized DevOps\n\nThe decentralized DevOps model is a variation of the you build it, you run it methodology where\n\noperations are primarily under the ownership of workload teams.\n\nYour application engineers perform both the engineering and the operations of their workloads.\n\nSimilarly, your infrastructure engineers perform both the engineering and operations of the\n\nplatforms they use to support application teams.\n\nOperating model 2 by 2 representations\n\n31",
      "content_length": 2021,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 37,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDecentralized DevOps\n\nFor this example, we treat governance as decentralized. Standards are still distributed, provided, or\n\nshared to application teams by the platform team, but application teams are free to engineer and\n\noperate new platform capabilities in support of their workload.\n\nIn this model, there are fewer constraints on the application team, but that comes with a\n\nsigniﬁcant increase in responsibilities. Additional skills (and potentially team members) must be\n\npresent to support the additional platform capabilities. The risk of signiﬁcant rework is increased if\n\nskill sets are inadequate and defects are not recognized early.\n\nEnforce policies that are not speciﬁcally delegated to application teams. Use tools or services\n\nthat help you to centrally govern your environments across accounts, such as AWS Organizations.\n\nServices like AWS Control Tower expand this management capability by helping you deﬁne\n\nblueprints (supporting your operating models) for the setup of accounts, apply ongoing\n\ngovernance using AWS Organizations, and automate provisioning of new accounts.\n\nIt’s beneﬁcial to have mechanisms for the application team to request additions and changes to\n\nstandards. They can contribute new standards that can provide beneﬁt to other application teams.\n\nThe platform teams may decide that providing direct support for these additional capabilities is an\n\neﬀective support for business outcomes.\n\nThis model limits constraints on innovation with signiﬁcant skill and team member requirements. It\n\naddresses many of the bottlenecks and delays created by transition of tasks between teams, while\n\nstill promoting the development of eﬀective relationships between teams and customers.\n\nOperating model 2 by 2 representations\n\n32",
      "content_length": 1824,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 38,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEvolving your operating model\n\nThe models provided progressively move towards more autonomy at the workload level, matching\n\nthe two-pizza team principle. It is important to understand that this journey from a traditional\n\napproach to decentralized DevOps (as a foundation for continued evolution to a two-pizza\n\nteam model) is likely to take time and require building maturity across a number of capabilities.\n\nTherefore, we have provided an example of how you may transition between models as your team and organization move along the enterprise transformation journey. In each change or model, you\n\nare evolving towards a more autonomous, but still organizationally-aligned team.\n\nCloud operating model evolution\n\nWhen evaluating how your team can support your organizations evolution, examine the trade-\n\noﬀs between models, where your individual teams exist within the models (as they transition and\n\nevolve), how your team's relationship and responsibilities could change, and if the beneﬁts merit\n\nthe impact on your organization. Keep in mind that change is never linear. Some models are more appropriate for speciﬁc use cases or points in the journey, and some of these models may provide\n\nadvantages over the ones in your environment.\n\nRelationships and ownership\n\nYour operating model deﬁnes the relationships between teams and supports identiﬁable ownership and responsibility.\n\nBest practices\n\nRelationships and ownership\n\n33",
      "content_length": 1501,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 39,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS02-BP01 Resources have identiﬁed owners\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their performance\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nOPS02-BP05 Mechanisms exist to request additions, changes, and exceptions\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nOPS02-BP01 Resources have identiﬁed owners\n\nResources for your workload must have identiﬁed owners for change control, troubleshooting,\n\nand other functions. Owners are assigned for workloads, accounts, infrastructure, platforms, and\n\napplications. Ownership is recorded using tools like a central register or metadata attached to\n\nresources. The business value of components informs the processes and procedures applied to\n\nthem.\n\nDesired outcome:\n\nResources have identiﬁed owners using metadata or a central register.\n\nTeam members can identify who owns resources.\n\nAccounts have a single owner where possible.\n\nCommon anti-patterns:\n\nThe alternate contacts for your AWS accounts are not populated.\n\nResources lack tags that identify what teams own them.\n\nYou have an ITSM queue without an email mapping.\n\nTwo teams have overlapping ownership of a critical piece of infrastructure.\n\nBeneﬁts of establishing this best practice:\n\nChange control for resources is straightforward with assigned ownership.\n\nYou can involve the right owners when troubleshooting issues.\n\nLevel of risk exposed if this best practice is not established: High\n\nRelationships and ownership\n\n34",
      "content_length": 1640,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 40,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nDeﬁne what ownership means for the resource use cases in your environment. Ownership can\n\nmean who oversees changes to the resource, supports the resource during troubleshooting, or\n\nwho is ﬁnancially accountable. Specify and record owners for resources, including name, contact\n\ninformation, organization, and team.\n\nCustomer example\n\nAnyCompany Retail deﬁnes ownership as the team or individual that owns changes and support\n\nfor resources. They leverage AWS Organizations to manage their AWS accounts. Alternate account\n\ncontacts are conﬁguring using group inboxes. Each ITSM queue maps to an email alias. Tags\n\nidentify who own AWS resources. For other platforms and infrastructure, they have a wiki page that\n\nidentiﬁes ownership and contact information.\n\nImplementation steps\n\n1. Start by deﬁning ownership for your organization. Ownership can imply who owns the risk\n\nfor the resource, who owns changes to the resource, or who supports the resource when\n\ntroubleshooting. Ownership could also imply ﬁnancial or administrative ownership of the\n\nresource.\n\n2. Use AWS Organizations to manage accounts. You can manage the alternate contacts for your\n\naccounts centrally.\n\na. Using company owned email addresses and phone numbers for contact information helps\n\nyou to access them even if the individuals whom they belong to are no longer with your\n\norganization. For example, create separate email distribution lists for billing, operations,\n\nand security and conﬁgure these as Billing, Security, and Operations contacts in each active\n\nAWS account. Multiple people will receive AWS notiﬁcations and be able to respond, even if\n\nsomeone is on vacation, changes roles, or leaves the company.\n\nb. If an account is not managed by AWS Organizations, alternate account contacts help AWS\n\nget in contact with the appropriate personnel if needed. Conﬁgure the account's alternate\n\ncontacts to point to a group rather than an individual.\n\n3. Use tags to identify owners for AWS resources. You can specify both owners and their contact\n\ninformation in separate tags.\n\na. You can use AWS Conﬁg rules to enforce that resources have the required ownership tags.\n\nb. For in-depth guidance on how to build a tagging strategy for your organization, see AWS\n\nTagging Best Practices whitepaper.\n\nRelationships and ownership\n\n35",
      "content_length": 2401,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 41,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Use Amazon Q Business, a conversational assistant that uses generative AI to enhance workforce\n\nproductivity, answer questions, and complete tasks based on information in your enterprise systems.\n\na. Connect Amazon Q Business to your company's data source. Amazon Q Business oﬀers\n\nprebuilt connectors to over 40 supported data sources, including Amazon Simple Storage\n\nService (Amazon S3), Microsoft SharePoint, Salesforce, and Atlassian Conﬂuence. For more\n\ninformation, see Amazon Q Business connectors.\n\n5. For other resources, platforms, and infrastructure, create documentation that identiﬁes\n\nownership. This should be accessible to all team members.\n\nLevel of eﬀort for the implementation plan: Low. Leverage account contact information and tags to assign ownership of AWS resources. For other resources you can use something as simple as a\n\ntable in a wiki to record ownership and contact information, or use an ITSM tool to map ownership.\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nRelated documents:\n\nAWS Account Management - Updating contact information\n\nAWS Organizations - Updating alternative contacts in your organization\n\nAWS Tagging Best Practices whitepaper\n\nBuild private and secure enterprise generative AI apps with Amazon Q Business and AWS IAM\n\nIdentity Center\n\nAmazon Q Business, now generally available, helps boost workforce productivity with generative\n\nAI\n\nAWS Cloud Operations & Migrations Blog - Implementing automated and centralized tagging\n\ncontrols with AWS Conﬁg and AWS Organizations\n\nAWS Security Blog - Extend your pre-commit hooks with AWS CloudFormation Guard\n\nAWS DevOps Blog - Integrating AWS CloudFormation Guard into CI/CD pipelines\n\nRelationships and ownership\n\n36",
      "content_length": 1899,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 42,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated workshops:\n\nAWS Workshop - Tagging\n\nRelated examples:\n\nAWS Conﬁg Rules - Amazon EC2 with required tags and valid values\n\nRelated services:\n\nAWS Conﬁg Rules - required-tags\n\nAWS Organizations\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nUnderstand who has ownership of the deﬁnition of individual processes and procedures, why\n\nthose speciﬁc process and procedures are used, and why that ownership exists. Understanding\n\nthe reasons that speciﬁc processes and procedures are used aids in identiﬁcation of improvement\n\nopportunities.\n\nDesired outcome: Your organization has a well deﬁned and maintained set of process and procedures for operational tasks. The process and procedures are stored in a central location\n\nand available to your team members. Process and procedures are updated frequently, by\n\nclearly assigned ownership. Where possible, scripts, templates, and automation documents are\n\nimplemented as code.\n\nCommon anti-patterns:\n\nProcesses are not documented. Fragmented scripts may exist on isolated operator workstations.\n\nKnowledge of how to use scripts is held by a few individuals or informally as team knowledge.\n\nA legacy process is due for an update, but ownership of the update is unclear, and the original\n\nauthor is no longer part of the organization.\n\nProcesses and scripts are not discoverable, so they are not readily available when required (for\n\nexample, in response to an incident).\n\nBeneﬁts of establishing this best practice:\n\nRelationships and ownership\n\n37",
      "content_length": 1574,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 43,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nProcesses and procedures boost your eﬀorts to operate your workloads.\n\nNew team members become eﬀective more quickly.\n\nReduced time to mitigate incidents.\n\nDiﬀerent team members (and teams) can use the same processes and procedures in a consistent\n\nmanner.\n\nTeams can scale their processes with repeatable processes.\n\nStandardized processes and procedures help mitigate the impact of transferring workload\n\nresponsibilities between teams.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nProcesses and procedures have identiﬁed owners who are responsible for their deﬁnition.\n\nIdentify the operations activities conducted in support of your workloads. Document these\n\nactivities in a discoverable location.\n\nUniquely identify the individual or team responsible for the speciﬁcation of an activity. They\n\nare responsible to verify that it can be successfully performed by an adequately skilled team\n\nmember with the correct permissions, access, and tools. If there are issues with performing\n\nthat activity, the team members performing it are responsible for providing the detailed\n\nfeedback necessary for the activity to be improved.\n\nCapture ownership in the metadata of the activity artifact through services like AWS Systems\n\nManager, through documents, and AWS Lambda. Capture resource ownership using tags or\n\nresource groups, specifying ownership and contact information. Use AWS Organizations to\n\ncreate tagging polices and capture ownership and contact information.\n\nOver time, these procedures should be evolved to be runnable as code, reducing the need for\n\nhuman intervention.\n\nFor example, consider AWS Lambda functions, CloudFormation templates, or AWS Systems\n\nManager automation docs.\n\nPerform version control in appropriate repositories.\n\nInclude suitable resource tagging so owners and documentation can readily be identiﬁed.\n\nCustomer example\n\nRelationships and ownership\n\n38",
      "content_length": 2003,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 44,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail deﬁnes ownership as the team or individual that owns processes for an\n\napplication or groups of applications (that share common architetural practices and technologies). Initially, the process and procedures are documented as step-by-step guides in the document\n\nmanagement system, discoverable using tags on the AWS account that hosts the application and\n\non speciﬁc groups of resources within the account. They leverage AWS Organizations to manage\n\ntheir AWS accounts. Over time, these processes are converted to code, and resources are deﬁned\n\nusing infrastructure as code (such as CloudFormation or AWS Cloud Development Kit (AWS CDK)\n\ntemplates). The operational processes become automation documents in AWS Systems Manager\n\nor AWS Lambda functions, which can be initiated as scheduled tasks, in response to events such\n\nas AWS CloudWatch alarms or AWS EventBridge events, or started by requests within an IT service\n\nmanagement (ITSM) platform. All process have tags to identify ownership. Documentation for the\n\nautomation and process is maintained within the wiki pages generated by the code repository for\n\nthe process.\n\nImplementation steps\n\n1. Document the existing processes and procedures.\n\na. Review and keep them up-to-date.\n\nb. Identify an owner for each process or procedure.\n\nc. Place them under version control.\n\nd. Where possible, share processes and procedures across workloads and environments that\n\nshare architectural designs.\n\n2. Establish mechanisms for feedback and improvement.\n\na. Deﬁne policies for how frequently processes should be reviewed.\n\nb. Deﬁne processes for reviewers and approvers.\n\nc. Implement issues or a ticketing queue for feedback to be provided and tracked.\n\nd. Whereever possible, processes and procedures should have pre-approval and risk classiﬁcation\n\nfrom a change approval board (CAB).\n\n3. Verify that processes and procedures are accessible and discoverable by those who need to run\n\nthem.\n\na. Use tags to indicate where the process and procedures can be accessed for the workload.\n\nb. Use meaningful error and event messaging to indicate the appropriate processes or\n\nprocedures to address an issue.\n\nc. Use wikis and document management, and make processes and procedures searchable\n\nconsistently accross the organization.\n\nRelationships and ownership\n\n39",
      "content_length": 2393,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 45,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Use Amazon Q Business, a conversational assistant that uses generative AI to enhance workforce\n\nproductivity, answer questions, and complete tasks based on information in your enterprise systems.\n\na. Connect Amazon Q Business to your company's data source. Amazon Q Business oﬀers\n\nprebuilt connectors to over 40 supported data sources, including Amazon S3, Microsoft\n\nSharePoint, Salesforce, and Atlassian Conﬂuence. For more information, see Amazon Q\n\nconnectors.\n\n5. Automate when appropriate.\n\na. Automations should be developed when services and technologies provide an API.\n\nb. Educate adequately on processes. Develop the user stories and requirements to automate\n\nthose processes.\n\nc. Measure the use of your processes and procedures successfully, and create issues or tickets to\n\nsupport iterative improvement.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS02-BP01 Resources have identiﬁed owners\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAWS Whitepaper - Introduction to DevOps on AWS\n\nAWS Whitepaper - Best Practices for Tagging AWS Resources\n\nAWS Whitepaper - Organizing Your AWS Environment Using Multiple Accounts\n\nAWS Cloud Operations and Migrations Blog - Using Amazon Q Business to streamline your\n\noperations\n\nAWS Cloud Operations & Migrations Blog - Build a Cloud Automation Practice for Operational\n\nExcellence: Best Practices from AWS Managed Services\n\nAWS Cloud Operations & Migrations Blog - Implementing automated and centralized tagging\n\ncontrols with AWS Conﬁg and AWS Organizations\n\nRelationships and ownership\n\n40",
      "content_length": 1743,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 46,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Security Blog - Extend your pre-commit hooks with AWS CloudFormation Guard\n\nAWS DevOps Blog - Integrating AWS CloudFormation Guard into CI/CD pipelines\n\nRelated workshops:\n\nAWS Well-Architected Operational Excellence Workshop\n\nAWS Workshop - Tagging\n\nRelated videos:\n\nHow to automate IT Operations on AWS\n\nAWS re:Invent 2020 - Automate anything with AWS Systems Manager\n\nAWS re:Inforce 2022 - Automating patch management and compliance using AWS (NIS306)\n\nSupports You - Diving Deep into AWS Systems Manager\n\nRelated services:\n\nAWS Systems Manager - Automation\n\nAWS Service Management Connector\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their\n\nperformance\n\nUnderstand who has responsibility to perform speciﬁc activities on deﬁned workloads and why\n\nthat responsibility exists. Understanding who has responsibility to perform activities informs who\n\nwill conduct the activity, validate the result, and provide feedback to the owner of the activity.\n\nDesired outcome:\n\nYour organization clearly deﬁnes responsibilities to perform speciﬁc activities on deﬁned\n\nworkloads and respond to events generated by the workload. The organization documents\n\nownership of processes and fulﬁllment and makes this information discoverable. You review and\n\nupdate responsibilities when organizational changes take place, and teams track and measure\n\nthe performance of defect and ineﬃciency identiﬁcation activities. You implement feedback\n\nmechanisms to track defects and improvements and support iterative improvement.\n\nRelationships and ownership\n\n41",
      "content_length": 1634,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 47,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nYou do not document responsibilities.\n\nFragmented scripts exist on isolated operator workstations. Only a few individuals know how to\n\nuse them or informally refer to them as team knowledge.\n\nA legacy process is due for update, but no one knows who owns the process, and the original\n\nauthor is no longer part of the organization.\n\nProcesses and scripts can't be discovered, and they are not readily available when required (for\n\nexample, in response to an incident).\n\nBeneﬁts of establishing this best practice:\n\nYou understand who is responsible to perform an activity, who to notify when action is needed,\n\nand who performs the action, validates the result, and provides feedback to the owner of the\n\nactivity.\n\nProcesses and procedures boost your eﬀorts to operate your workloads.\n\nNew team members become eﬀective more quickly.\n\nYou reduce the time it takes to mitigate incidents.\n\nDiﬀerent teams use the same processes and procedures to perform tasks in a consistent manner.\n\nTeams can scale their processes with repeatable processes.\n\nStandardized processes and procedures help mitigate the impact of transferring workload\n\nresponsibilties between teams.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo begin to deﬁne responsibilities, start with existing documentation, like responsibility matrices,\n\nprocesses and procedures, roles and responsibilities, and tools and automation. Review and host\n\ndiscussions on the responsibilities for documented processes. Review with teams to identify\n\nmisalignments between document responsibilities and processes. Discuss services oﬀered with\n\ninternal customers of that team to identify expectations gaps between teams.\n\nAnalyze and address the discrepancies. Identify opportunities to improvement, and look for\n\nfrequently requested, resource-intensive activities, which are typically strong candidates for\n\nRelationships and ownership\n\n42",
      "content_length": 2026,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 48,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nimprovement. Explore best practices, patterns, and prescriptive guidance to simplify and\n\nstandardize improvements. Record improvement opportunities, and track the improvements to completion.\n\nOver time, these procedures should be evolved to be run as code, reducing the need for human\n\nintervention. For example, procedures can be initiated as AWS Lambda functions, CloudFormation\n\ntemplates, or AWS Systems Manager Automation documents. Verify that these procedures are\n\nversion-controlled in appropriate repositories, and include suitable resource tagging so that teams\n\ncan readily identify owners and documentation. Document the responsibility for carrying out the\n\nactivities, and then monitor the automations for successful initiation and operation, as well as\n\nperformance of the desired outcomes.\n\nCustomer example\n\nAnyCompany Retail deﬁnes ownership as the team or individual that owns processes for an application or groups of applications that share common architectural practices and technologies.\n\nInitially, the company documents the processes and procedures as step-by-step guides in the\n\ndocument management system. They make the procedures discoverable using tags on the AWS\n\naccount that hosts the application and on speciﬁc groups of resources within the account, using\n\nAWS Organizations to manage their AWS accounts. Over time, AnyCompany Retail converts\n\nthese processes to code and deﬁnes resources using infrastructure as code (through services like\n\nCloudFormation or AWS Cloud Development Kit (AWS CDK) templates). The operational processes\n\nbecome Automation documents in AWS Systems Manager or AWS Lambda functions, which can be\n\ninitiated as scheduled tasks in response to events such as Amazon CloudWatch alarms or Amazon\n\nEventBridge events or by requests within an IT service management (ITSM) platform. All processes\n\nhave tags to identify who owns them. Teams manage documentation for the automation and\n\nprocess within the wiki pages generated by the code repository for the process.\n\nImplementation steps\n\n1. Document the existing processes and procedures.\n\na. Review and verify that they are up-to-date.\n\nb. Verify that each process or procedure has an owner.\n\nc. Place the procedures under version control.\n\nd. Where possible, share processes and procedures across workloads and environments that\n\nshare architectural designs.\n\n2. Establish mechanisms for feedback and improvement.\n\nRelationships and ownership\n\n43",
      "content_length": 2516,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 49,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\na. Deﬁne policies for how frequently processes should be reviewed.\n\nb. Deﬁne processes for reviewers and approvers.\n\nc. Implement issues or a ticketing queue to provide and track feedback.\n\nd. Wherever possible, provide pre-approval and risk classiﬁcation for processes and procedures\n\nfrom a change approval board (CAB).\n\n3. Make process and procedures accessible and discoverable by users who need to run them.\n\na. Use tags to indicate where the process and procedures can be accessed for the workload.\n\nb. Use meaningful error and event messaging to indicate the appropriate process or proceedure\n\nto address the issue.\n\nc. Use wikis or document management to make processes and procedures consistently\n\nsearchable across the organization.\n\n4. Automate when it is appropriate to do so.\n\na. Where services and technologies provide an API, develop automations.\n\nb. Verify that processes are well-understood, and develop the user stories and requirements to\n\nautomate those processes.\n\nc. Measure the successful use of processes and procedures, with issue tracking to support\n\niterative improvement.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS02-BP01 Resources have identiﬁed owners\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nOPS02-BP05 Mechanisms exist to identify responsibility and ownership\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAWS Whitepaper | Introduction to DevOps on AWS\n\nAWS Whitepaper | Best Practices for Tagging AWS Resources\n\nRelationships and ownership\n\n44",
      "content_length": 1694,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 50,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Whitepaper | Organizing Your AWS Environment Using Multiple Accounts\n\nAWS Cloud Operations & Migrations Blog | Build a Cloud Automation Practice for Operational\n\nExcellence: Best Practices from AWS Managed Services\n\nAWS Workshop - Tagging\n\nAWS Service Management Connector\n\nRelated videos:\n\nAWS Knowledge Center Live | Tagging AWS Resources\n\nAWS re:Invent 2020 | Automate anything with AWS Systems Manager\n\nAWS re:Inforce 2022 | Automating patch management and compliance using AWS (NIS306)\n\nSupports You | Diving Deep into AWS Systems Manager\n\nOPS02-BP04 Mechanisms exist to manage responsibilities and ownership\n\nUnderstand the responsibilities of your role and how you contribute to business outcomes, as\n\nthis understanding informs the prioritization of your tasks and why your role is important. This\n\nhelps team members recognize needs and respond appropriately. When team members know their\n\nrole, they can establish ownership, identify improvement opportunities, and understand how to\n\ninﬂuence or make appropriate changes.\n\nOccasionally, a responsibility might not have a clear owner. In these situations, design a mechanism\n\nto resolve this gap. Create a well-deﬁned escalation path to someone with the authority to assign\n\nownership or plan to address the need.\n\nDesired outcome: Teams within your organization have clearly-deﬁned responsibilities that include how they are related to resources, actions to be performed, processes, and procedures. These\n\nresponsibilities align to the team's responsibilities and goals, as well as the responsibilities of other\n\nteams. You document the routes of escalation in a consistent and discoverable manner and feed\n\nthese decisions into documentation artifacts, such as responsibility matrices, team deﬁnitions, or\n\nwiki pages.\n\nCommon anti-patterns:\n\nThe responsibilities of the team are ambiguous or poorly-deﬁned.\n\nThe team does not align roles with responsibilities.\n\nRelationships and ownership\n\n45",
      "content_length": 2022,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 51,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe team does not align its goals and objectives its responsibilities, which makes it diﬃcult to\n\nmeasure success.\n\nTeam member responsibilities do not align with the team and the wider organization.\n\nYour team does not keep responsibilities up-to-date, which makes them inconsistent with the\n\ntasks performed by the team.\n\nEscalation paths for determining responsibilities aren't deﬁned or are unclear.\n\nEscalation paths have no single thread owner to ensure timely reponse.\n\nRoles, responsibilities, and escalation paths are not discoverable, and they are not readily\n\navailable when required (for example, in response to an incident).\n\nBeneﬁts of establishing this best practice:\n\nWhen you understand who has responsibility or ownership, you can contact the proper team or\n\nteam member to make a request or transition a task.\n\nTo reduce the risk of inaction and unaddressed needs, you have identiﬁed a person who has the\n\nauthority to assign responsibility or ownership.\n\nWhen you clearly deﬁne the scope of a responsibility, your team members gain autonomy and\n\nownership.\n\nYour responsibilities inform the decisions you make, the actions you take, and your handoﬀ\n\nactivities to their proper owners.\n\nIt's easy to identify abandoned responsibilities because you have a clear understanding of what\n\nfalls outside of your team's responsibility, which helps you escalate for clariﬁcation.\n\nTeams avoid confusion and tension, and they can more adequately manage their workloads and\n\nresources.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nIdentify team members roles and responsibilities, and verify that they understand the expectations\n\nof their role. Make this information discoverable so that members of your organization can identify\n\nwho they need to contact for speciﬁc needs, whether it's a team or individual. As organizations\n\nseek to capitalize on the opportunities to migrate and modernize on AWS, roles and responsibilities\n\nmight also change. Keep your teams and their members aware of their responsibilities, and train\n\nthem appropriately to carry out their tasks during this change.\n\nRelationships and ownership\n\n46",
      "content_length": 2246,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 52,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDetermine the role or team that should receive escalations to identify responsibility and ownership.\n\nThis team can engage with various stakeholders to come to a decision. However, they should own the management of the decision making process.\n\nProvide accessible mechanisms for members of your organization to discover and identify\n\nownership and responsibility. These mechanisms teach them who to contact for speciﬁc needs.\n\nCustomer example\n\nAnyCompany Retail recently completed a migration of workloads from an on-premises\n\nenvironment to their landing zone in AWS with a lift and shift approach. They performed an\n\noperations review to reﬂect on how they accomplish common operational tasks and veriﬁed that\n\ntheir existing responsibility matrix reﬂects operations in the new environment. When they migrated\n\nfrom on-premises to AWS, they reduced the infrastructure teams responsibilities relating to the\n\nhardware and physical infrastructure. This move also revealed new opportunities to evolve the\n\noperating model for their workloads.\n\nWhile they identiﬁed, addressed, and documented the majority of responsibilities, they also\n\ndeﬁned escalation routes for any responsibilities that were missed or that may need to change as\n\noperations practices evolve. To explore new opportunities to standardize and improve eﬃciency\n\nacross your workloads, provide access to operations tools like AWS Systems Manager and security\n\ntools like AWS Security Hub CSPM and Amazon GuardDuty. AnyCompany Retail puts together a\n\nreview of responsibilities and strategy based on improvements they wants to address ﬁrst. As the\n\ncompany adopts new ways of working and technology patterns, they update their responsibility\n\nmatrix to match.\n\nImplementation steps\n\n1. Start with existing documentation. Some typical source documents might include:\n\na. Responsibility or responsible, accountable, consulted, and informed (RACI) matrices\n\nb. Team deﬁnitions or wiki pages\n\nc. Service deﬁnitions and oﬀerings\n\nd. Role or job descriptions\n\n2. Review and host discussions on the documented responsibilities:\n\na. Review with teams to identify misalignments between documented responsibilities and\n\nresponsibilities the team typically performs.\n\nb. Discuss potential services oﬀered by internal customers to identify gaps in expectations\n\nbetween teams.\n\nRelationships and ownership\n\n47",
      "content_length": 2426,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 53,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n3. Analysis and address the discrepancies.\n\n4. Identify opportunities for improvement.\n\na. Identify frequently-requested, resource-intensive requests, which are typically strong\n\ncandidates for improvement.\n\nb. Look for best practices, understand patterns, follow prescriptive guidance, and simplify and\n\nstandardize improvements.\n\nc. Record improvement opportunities, and track them to completion.\n\n5. If a team doesn't already hold responsibility for managing and tracking the assignment of\n\nresponsibilities, identify someone on the team to hold this responsibility.\n\n6. Deﬁne a process for teams to request clariﬁcation of responsibility.\n\na. Review the process, and verify that it is clear and simple to use.\n\nb. Make sure that someone owns and tracks escalations to their conclusion.\n\nc. Establish operational metrics to measure eﬀectiveness.\n\nd. Create a feedback mechanisms to verify that teams can highlight improvement opportunities.\n\ne. Implement a mechanism for periodic review.\n\n7. Document in a discoverable and accessible location.\n\na. Wikis or documentation portal are common choices.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS01-BP06 Evaluate tradeoﬀs\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\nOPS03-BP03 Escalation is encouraged\n\nOPS03-BP07 Resource teams appropriately\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS11-BP01 Have a process for continuous improvement\n\nRelated documents:\n\nRelationships and ownership\n\n48",
      "content_length": 1670,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 54,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Whitepaper - Introduction to DevOps on AWS\n\nAWS Whitepaper - AWS Cloud Adoption Framework: Operations Perspective\n\nAWS Well-Architected Framework Operational Excellence - Workload level Operating model\n\ntopologies\n\nAWS Prescriptive Guidance - Building your Cloud Operating Model\n\nAWS Prescriptive Guidance - Create a RACI or RASCI matrix for a cloud operating model\n\nAWS Cloud Operations & Migrations Blog - Delivering Business Value with Cloud Platform Teams\n\nAWS Cloud Operations & Migrations Blog - Why a Cloud Operating Model?\n\nAWS DevOps Blog - How organizations are modernizing for cloud operations\n\nRelated videos:\n\nAWS Summit Online - Cloud Operating Models for Accelerated Transformation\n\nAWS re:Invent 2023 - Future-prooﬁng cloud security: A new operating model\n\nOPS02-BP05 Mechanisms exist to request additions, changes, and exceptions\n\nYou can make requests to owners of processes, procedures, and resources. Requests include\n\nadditions, changes, and exceptions. These requests go through a change management process.\n\nMake informed decisions to approve requests where viable and determined to be appropriate after\n\nan evaluation of beneﬁts and risks.\n\nDesired outcome:\n\nYou can make requests to change processes, procedures, and resources based on assigned\n\nownership.\n\nChanges are made in a deliberate manner, weighing beneﬁts and risks.\n\nCommon anti-patterns:\n\nYou must update the way you deploy your application, but there is no way to request a change to\n\nthe deployment process from the operations team.\n\nThe disaster recovery plan must be updated, but there is no identiﬁed owner to request changes\n\nto.\n\nRelationships and ownership\n\n49",
      "content_length": 1722,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 55,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nProcesses, procedures, and resources can evolve as requirements change.\n\nOwners can make informed decisions when to make changes.\n\nChanges are made in a deliberate manner.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nTo implement this best practice, you need to be able to request changes to processes, procedures,\n\nand resources. The change management process can be lightweight. Document the change\n\nmanagement process.\n\nCustomer example\n\nAnyCompany Retail uses a responsibility assignment (RACI) matrix to identify who owns changes\n\nfor processes, procedures, and resources. They have a documented change management process\n\nthat’s lightweight and easy to follow. Using the RACI matrix and the process, anyone can submit\n\nchange requests.\n\nImplementation steps\n\n1. Identify the processes, procedures, and resources for your workload and the owners for each.\n\nDocument them in your knowledge management system.\n\na. If you have not implemented OPS02-BP01 Resources have identiﬁed owners, OPS02-BP02\n\nProcesses and procedures have identiﬁed owners, or OPS02-BP03 Operations activities have\n\nidentiﬁed owners responsible for their performance, start with those ﬁrst.\n\n2. Work with stakeholders in your organization to develop a change management process.\n\nThe process should cover additions, changes, and exceptions for resources, processes, and\n\nprocedures.\n\na. You can use AWS Systems Manager Change Manager as a change management platform for\n\nworkload resources.\n\n3. Document the change management process in your knowledge management system.\n\nLevel of eﬀort for the implementation plan: Medium. Developing a change management process requires alignment with multiple stakeholders across your organization.\n\nRelationships and ownership\n\n50",
      "content_length": 1903,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 56,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS02-BP01 Resources have identiﬁed owners - Resources need identiﬁed owners before you\n\nbuild a change management process.\n\nOPS02-BP02 Processes and procedures have identiﬁed owners - Processes need identiﬁed\n\nowners before you build a change management process.\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their performance -\n\nOperations activities need identiﬁed owners before you build a change management process.\n\nRelated documents:\n\nAWS Prescriptive Guidance - Foundation palybook for AWS large migrations: Creating RACI\n\nmatrices\n\nChange Management in the Cloud Whitepaper\n\nRelated services:\n\nAWS Systems Manager Change Manager\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nHave deﬁned or negotiated agreements between teams describing how they work with and\n\nsupport each other (for example, response times, service level objectives, or service-level\n\nagreements). Inter-team communications channels are documented. Understanding the impact of\n\nthe teams’ work on business outcomes and the outcomes of other teams and organizations informs\n\nthe prioritization of their tasks and helps them respond appropriately.\n\nWhen responsibility and ownership are undeﬁned or unknown, you are at risk of both not\n\naddressing necessary activities in a timely fashion and of redundant and potentially conﬂicting\n\neﬀorts emerging to address those needs.\n\nDesired outcome:\n\nInter-team working or support agreements are agreed to and documented.\n\nTeams that support or work with each other have deﬁned communication channels and response\n\nexpectations.\n\nRelationships and ownership\n\n51",
      "content_length": 1730,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 57,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nAn issue occurs in production and two separate teams start troubleshooting independent of each\n\nother. Their siloed eﬀorts extend the outage.\n\nThe operations team needs assistance from the development team but there is no agreed to\n\nresponse time. The request is stuck in the backlog.\n\nBeneﬁts of establishing this best practice:\n\nTeams know how to interact and support each other.\n\nExpectations for responsiveness are known.\n\nCommunications channels are clearly deﬁned.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nImplementing this best practice means that there is no ambiguity about how teams work with\n\neach other. Formal agreements codify how teams work together or support each other. Inter-team\n\ncommunication channels are documented.\n\nCustomer example\n\nAnyCompany Retail’s SRE team has a service level agreement with their development team.\n\nWhenever the development team makes a request in their ticketing system, they can expect\n\na response within ﬁfteen minutes. If there is a site outage, the SRE team takes lead in the\n\ninvestigation with support from the development team.\n\nImplementation steps\n\n1. Working with stakeholders across your organization, develop agreements between teams based\n\non processes and procedures.\n\na. If a process or procedure is shared between two teams, develop a runbook on how the teams\n\nwill work together.\n\nb. If there are dependencies between teams, agree to a response SLA for requests.\n\n2. Document responsibilities in your knowledge management system.\n\nRelationships and ownership\n\n52",
      "content_length": 1668,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 58,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: Medium. If there are no existing agreements between teams, it can take eﬀort to come to agreement with stakeholders across your organization.\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners - Process ownership must be\n\nidentiﬁed before setting agreements between teams.\n\nOPS02-BP03 Operations activities have identiﬁed owners responsible for their performance -\n\nOperations activities ownership must be identiﬁed before setting agreements between teams.\n\nRelated documents:\n\nAWS Executive Insights - Empowering Innovation with the Two-Pizza Team\n\nIntroduction to DevOps on AWS - Two-Pizza Teams\n\nOrganizational culture\n\nProvide support for your team members so they can be more eﬀective in taking action and\n\nsupporting your business outcome.\n\nBest practices\n\nOPS03-BP01 Provide executive sponsorship\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\nOPS03-BP03 Escalation is encouraged\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\nOPS03-BP05 Experimentation is encouraged\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\nOPS03-BP07 Resource teams appropriately\n\nOrganizational culture\n\n53",
      "content_length": 1321,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 59,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS03-BP01 Provide executive sponsorship\n\nAt the highest level, senior leadership acts as the executive sponsor to clearly set expectations and\n\ndirection for the organization's outcomes, including evaluating its success. The sponsor advocates\n\nand drives adoption of best practices and evolution of the organization.\n\nDesired outcome: Organizations that endeavor to adopt, transform, and optimize their cloud operations establish clear lines of leadership and accountability for desired outcomes. The\n\norganization understands each capability required by the organization to accomplish a new\n\noutcome and assigns ownership to functional teams for development. Leadership actively\n\nsets this direction, assigns ownership, takes accountability, and deﬁnes the work. As a result,\n\nindividuals across the organization can mobilize, feel inspired, and actively work towards the\n\ndesired objectives.\n\nCommon anti-patterns:\n\nThere is a mandate for workload owners to migrate workloads to AWS without a clear sponsor\n\nand plan for cloud operations. This results in teams not consciously collaborating to improve\n\nand mature their operational capabilities. Lack of operational best practice standards overwhelm\n\nteams (such as operator-toil, on-calls, and technical debt), which constrains innovation.\n\nA new organization-wide goal has been set to adopt an emerging technology without providing\n\nleadership sponsor and strategy. Teams interpret goals diﬀerently, which causes confusion\n\non where to focus eﬀorts, why they matter, and how to measure impact. Consequently, the\n\norganization loses momentum in adopting the technology.\n\nBeneﬁts of establishing this best practice: When executive sponsorship clearly communicates and shares vision, direction, and goals, team members know what is expected of them. Individuals and\n\nteams begin to intensely focus eﬀort in the same direction to accomplish deﬁned objectives when\n\nleaders are actively engaged. As a result, the organization maximizes the ability to succeed. When\n\nyou evaluate success, you can better identify barriers to success so that they can be addressed\n\nthrough intervention by the executive sponsor.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nAt every phase of the cloud journey (migration, adoption, or optimization), success requires\n\nactive involvement at the highest level of leadership with a designated executive sponsor. The\n\nOPS03-BP01 Provide executive sponsorship\n\n54",
      "content_length": 2553,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 60,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nexecutive sponsor aligns the team's mindset, skillsets, and ways of working to the deﬁned\n\nstrategy.\n\nExplain the why: Bring clarity and explain the reasoning behind the vision and strategy.\n\nSet expectations: Deﬁne and publish goals for your organizations, including how progress and\n\nsuccess are measured.\n\nTrack achievement of goals: Measure the incremental achievement of goals regularly (not just completion of tasks). Share the results so that appropriate action can be taken if outcomes are at risk.\n\nProvide the resources necessary to achieve your goals: Bring people and teams together to collaborate and build the right solutions that bring about the deﬁned outcomes. This reduces or eliminates organizational friction.\n\nAdvocate for your teams: Remain engaged with your teams so that you understand their\n\nperformance and whether there are external factors aﬀecting them. Identify obstacles that\n\nare impeding your teams progress. Act on behalf of your teams to help address obstacles and\n\nremove unnecessary burdens. When your teams are impacted by external factors, reevaluate\n\ngoals and adjust targets as appropriate.\n\nDrive adoption of best practices: Acknowledge best practices that provide quantiﬁable\n\nbeneﬁts, and recognize the creators and adopters. Encourage further adoption to magnify the\n\nbeneﬁts achieved.\n\nEncourage evolution of your teams: Create a culture of continual improvement, and\n\nproactively learn from progress made as well as failures. Encourage both personal and\n\norganizational growth and development. Use data and anecdotes to evolve the vision and\n\nstrategy.\n\nCustomer example\n\nAnyCompany Retail is in the process of business transformation through rapid reinvention\n\nof customer experiences, enhancement of productivity, and acceleration of growth through\n\ngenerative AI.\n\nImplementation steps\n\n1. Establish single-threaded leadership, and assign a primary executive sponsor to lead and drive\n\nthe transformation.\n\nOPS03-BP01 Provide executive sponsorship\n\n55",
      "content_length": 2064,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 61,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n2. Deﬁne clear business outcomes of your transformation, and assign ownership and\n\naccountability. Empower the primary executive with the authority to lead and make critical decisions.\n\n3. Verify that your transformational strategy is very clear and communicated widely by the\n\nexecutive sponsor to every level of the organization.\n\na. Establish clearly deﬁned business objectives for IT and cloud initiatives.\n\nb. Document key business metrics to drive IT and cloud transformation.\n\nc. Communicate the vision consistently to all teams and individuals responsible for parts of the\n\nstrategy.\n\n4. Develop communication planning matrices that specify what message needs to be delivered to\n\nspeciﬁed leaders, managers, and individual contributors. Specify the person or team that should\n\ndeliver this message.\n\na. Fulﬁll communications plans consistently and reliably.\n\nb. Set and manage expectations through in-person events on a regular basis.\n\nc. Accept feedback on the eﬀectiveness of communications, and adjust the communications and\n\nplan accordingly.\n\nd. Schedule communication events to proactively understand challenges from teams, and\n\nestablish a consistent feedback loop that allows for correcting course where necessary.\n\n5. Actively engage each initiative from a leadership perspective to verify that all impacted teams\n\nunderstand the outcomes they are accountable to achieve.\n\n6. At every status meeting, executive sponsors should look for blockers, inspect established\n\nmetrics, anecdotes, or feedback from the teams, and measure progress towards objectives.\n\nLevel of eﬀort for the implementation plan Medium\n\nResources\n\nRelated best practices:\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\nOP11-BP01 Have a process for continuous improvement\n\nOPS11-BP07 Perform operations metrics reviews\n\nRelated documents:\n\nOPS03-BP01 Provide executive sponsorship\n\n56",
      "content_length": 1949,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 62,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUntangling Your Organisational Hairball: Highly Aligned\n\nThe Living Transformation: Pragmatically approaching changes\n\nBecoming a Future-Ready Enterprise\n\n7 Pitfalls to Avoid When Building a CCOE\n\nNavigating the Cloud: Key Performance Indicators for Success\n\nRelated videos:\n\nAWS re:Invent 2023: A leader's guide to generative AI: Using history to shape the future (SEG204)\n\nRelated examples:\n\nProsci: Primary Sponsor's Role & Importance\n\nOPS03-BP02 Team members are empowered to take action when\n\noutcomes are at risk\n\nA cultural behavior of ownership instilled by leadership results in any employee feeling empowered\n\nto act on behalf of the entire company beyond their deﬁned scope of role and accountability.\n\nEmployees can act to proactively identify risks as they emerge and take appropriate action. Such a\n\nculture allows employees to make high value decisions with situational awareness.\n\nFor example, Amazon uses Leadership Principles as the guidelines to drive desired behavior for\n\nemployees to move forward in situations, solve problems, deal with conﬂict, and take action.\n\nDesired outcome: Leadership has inﬂuenced a new culture that allows individuals and teams to make critical decisions, even at lower levels of the organization (as long as decisions are\n\ndeﬁned with auditable permissions and safety mechanisms). Failure is not discouraged, and\n\nteams iteratively learn to improve their decision-making and responses to tackle similar situations\n\ngoing forward. If someone's actions result in an improvement that can beneﬁt other teams, they\n\nproactively share knowledge from such actions. Leadership measures operational improvements\n\nand incentivizes the individual and organization for adoption of such patterns.\n\nCommon anti-patterns:\n\nThere isn't clear guidance or mechanisms in an organization for what to do when a risk is\n\nidentiﬁed. For example, when an employee notices a phishing attack, they fail to report to the\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\n57",
      "content_length": 2090,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 63,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nsecurity team, resulting in a large portion of the organization falling for the attack. This causes a\n\ndata breach.\n\nYour customers complain about service unavailability, which primarily stems from failed\n\ndeployments. Your SRE team is responsible for the deployment tool, and an automated rollback\n\nfor deployments is in their long-term roadmap. In a recent application rollout, one of the\n\nengineers devised a solution to automate rolling back their application to a previous version.\n\nThough their solution can become the pattern for SRE teams, other teams do not adopt, as there\n\nis no process to track such improvements. The organization continues to be plagued with failed\n\ndeployments impacting customers and causing further negative sentiment.\n\nIn order to stay compliant, your infosec team oversees a long-established process to rotate\n\nshared SSH keys regularly on behalf of operators connecting to their Amazon EC2 Linux\n\ninstances. It takes several days for the infosec teams to complete rotating keys, and you are\n\nblocked from connecting to those instances. No one inside or outside of infosec suggests using other options on AWS to achieve the same result.\n\nBeneﬁts of establishing this best practice: By decentralizing authority to make decisions and empowering your teams to decide key decisions, you are able to address issues more quickly with\n\nincreasing success rates. In addition, teams start to realize a sense of ownership, and failures are\n\nacceptable. Experimentation becomes a cultural mainstay. Managers and directors do not feel as\n\nthough they are micro-managed through every aspect of their work.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\n1. Develop a culture where it is expected that failures can occur.\n\n2. Deﬁne clear ownership and accountability for various functional areas within the organization.\n\n3. Communicate ownership and accountability to everyone so that individuals know who can help\n\nthem facilitate decentralized decisions.\n\n4. Deﬁne your one-way and two-way door decisions to help individuals know when they do need to\n\nescalate to higher levels of leadership.\n\n5. Create organizational awareness that all employees are empowered to take action at various\n\nlevels when outcomes are at risk. Provide your team members documentation of governance,\n\npermission-levels, tools, and opportunities to practice the skills necessary to respond eﬀectively.\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\n58",
      "content_length": 2599,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 64,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n6. Give your team members the opportunity to practice the skills necessary to respond to various\n\ndecisions. Once decision levels are deﬁned, perform game days to verify that all individual contributors understand and can demonstrate the process.\n\na. Provide alternative safe environments where processes and procedures can be tested and\n\ntrained upon.\n\nb. Acknowledge and create awareness that team members have authority to take action when\n\nthe outcome has a predeﬁned level of risk.\n\nc. Deﬁne the authority of your team members to take action by assigning permissions and\n\naccess to the workloads and components they support.\n\n7. Provide ability for teams to share their learnings (operational successes and failures).\n\n8. Empower teams to challenge the status quo, and provide mechanisms to track and measure\n\nimprovements, as well as their impact to the organization.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nOPS02-BP05 Mechanisms exist to identify responsibility and ownership\n\nRelated documents:\n\nAWS Blog Post | The agile enterprise\n\nAWS Blog Post | Measuring success : A paradox and a plan\n\nAWS Blog Post | Letting go : Enabling autonomy in teams\n\nCentralize or Decentralize?\n\nRelated videos:\n\nre:Invent 2023 | How to not sabotage your transformation (SEG201)\n\nre:Invent 2021 | Amazon Builders' Library: Operational Excellence at Amazon\n\nCentralization vs. Decentralization\n\nOPS03-BP02 Team members are empowered to take action when outcomes are at risk\n\n59",
      "content_length": 1641,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 65,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated examples:\n\nUsing architectural decision records to streamline technical decision-making for a software\n\ndevelopment project\n\nOPS03-BP03 Escalation is encouraged\n\nTeam members are encouraged by leadership to escalate issues and concerns to higher-level\n\ndecision makers and stakeholders if they believe desired outcomes are at risk and expected\n\nstandards are not met. This is a feature of the organization's culture and is driven at all levels.\n\nEscalation should be done early and often so that risks can be identiﬁed and prevented from\n\ncausing incidents. Leadership does not reprimand individuals for escalating an issue.\n\nDesired outcome: Individuals throughout the organization are comfortable to escalate problems to their immediate and higher levels of leadership. Leadership has deliberately and consciously\n\nestablished expectations that their teams should feel safe to escalate any issue. A mechanism\n\nexists to escalate issues at each level within the organization. When employees escalate to their\n\nmanager, they jointly decide the level of impact and whether the issue should be escalated. In\n\norder to initiate an escalation, employees are required to include a recommended work plan to\n\naddress the issue. If direct management does not take timely action, employees are encouraged to\n\ntake issues to the highest level of leadership if they feel strongly that the risks to the organization\n\nwarrant the escalation.\n\nCommon anti-patterns:\n\nExecutive leaders do not ask enough probing questions during your cloud transformation\n\nprogram status meeting to ﬁnd where issues and blockers are occurring. Only good news is\n\npresented as status. The CIO has made it clear that she only likes to hear good news, as any\n\nchallenges brought up make the CEO think that the program is failing.\n\nYou are a cloud operations engineer and you notice that the new knowledge management\n\nsystem is not being widely adopted by application teams. The company invested one year and\n\nseveral million dollars to implement this new knowledge management system, but people\n\nare still authoring their runbooks locally and sharing them on an organizational cloud share,\n\nmaking it diﬃcult to ﬁnd knowledge pertinent to supported workloads. You try to bring this\n\nto leadership's attention, because consistent use of this system can enhance operational\n\neﬃciency. When you bring this to the director who lead the implementation of the knowledge\n\nmanagement system, she reprimands you because it calls the investment into question.\n\nOPS03-BP03 Escalation is encouraged\n\n60",
      "content_length": 2626,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 66,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe infosec team responsible for hardening compute resources has decided to put a process\n\nin place that requires performing the scans necessary to ensure that EC2 instances are fully secured before the compute team releases the resource for use. This has created a time delay of\n\nan additional week for resources to be deployed, which breaks their SLA. The compute team is\n\nafraid to escalate this to the VP over cloud because this makes the VP of information security\n\nlook bad.\n\nBeneﬁts of establishing this best practice:\n\nComplex or critical issues are addressed before they impact the business. Less time is wasted. Risks\n\nare minimized. Teams become more proactive and results focused when solving problems.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nThe willingness and ability to escalate freely at every level in the organization is an organizational\n\nand cultural foundation that should be consciously developed through emphasized training,\n\nleadership communications, expectation setting, and the deployment of mechanisms throughout\n\nthe organization at every level.\n\nImplementation steps\n\n1. Deﬁne policies, standards, and expectations for your organization.\n\na. Ensure wide adoption and understanding of policies, expectations, and standards.\n\n2. Encourage, train, and empower workers for early and frequent escalation when standards are\n\nnot met.\n\n3. Organizationally acknowledge that early and frequent escalation is the best practice. Accept that\n\nescalations may prove to be unfounded, and that it is better to have the opportunity to prevent\n\nan incident then to miss that opportunity by not escalating.\n\na. Build a mechanism for escalation (like an Andon cord system).\n\nb. Have documented procedures deﬁning when and how escalation should occur.\n\nc. Deﬁne the series of people with increasing authority to take or approve action, as well as each\n\nstakeholder's contact information.\n\n4. When escalation occurs, it should continue until the team member is satisﬁed that the risk has\n\nbeen mitigated through actions driven from leadership.\n\na. Escalations should include:\n\nOPS03-BP03 Escalation is encouraged\n\n61",
      "content_length": 2245,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 67,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\ni. Description of the situation, and the nature of the risk\n\nii. Criticality of the situation\n\niii. Who or what is impacted\n\niv. How great the impact is\n\nv. Urgency if impact occurs\n\nvi. Suggested remedies and plans to mitigate\n\nb. Protect employees who escalate. Have policy that protects team members from retribution\n\nif they escalate around a non-responsive decision maker or stakeholder. Have mechanisms in\n\nplace to identify if this is occurring and respond appropriately.\n\n5. Encourage a culture of continuous improvement feedback loops in everything that the\n\norganization produces. Feedback loops act as minor escalations to individuals responsible, and\n\nthey identify improvement opportunities, even when escalation is not needed. Continuous\n\nimprovement cultures force everyone to be more proactive.\n\n6. Leadership should periodically reemphasize the policies, standards, mechanisms, and the desire\n\nfor open escalation and continuous feedback loops without retribution.\n\nLevel of eﬀort for the Implementation Plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS02-BP05 Mechanisms exist to request additions, changes, and exceptions\n\nRelated documents:\n\nHow do you foster a culture of continuous improvement and learning from Andon and escalation\n\nsystems?\n\nThe Andon Cord (IT Revolution)\n\nAWS DevOps Guidance | Establish clear escalation paths and encourage constructive\n\ndisagreement\n\nRelated videos:\n\nJeﬀ Bezos on how to make decisions (& increase velocity)\n\nOPS03-BP03 Escalation is encouraged\n\n62",
      "content_length": 1576,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 68,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nToyota Product System: Stopping Production, a Button, and an Andon Electric Board\n\nAndon Cord in LEAN Manufacturing\n\nRelated examples:\n\nWorking with escalation plans in Incident Manager\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\nLeadership is responsible for the creation of strong and eﬀective communications, especially\n\nwhen the organization adopts new strategies, technologies, or ways of working. Leaders should\n\nset expectations for all staﬀ to work towards the company objectives. Devise communication\n\nmechanisms that create and maintain awareness among the teams responsible for running plans that are funded and sponsored by leadership. Make use of cross-organizational diversity, and\n\nlisten attentively to multiple unique perspectives. Use this perspective to increase innovation,\n\nchallenge your assumptions, and reduce the risk of conﬁrmation bias. Foster inclusion, diversity,\n\nand accessibility within your teams to gain beneﬁcial perspectives.\n\nDesired outcome: Your organization designs communication strategies to address the impact of change to the organization. Teams remain informed and motivated to continue working with\n\none another rather than against each other. Individuals understand how important their role is\n\nto achieve the stated objectives. Email is only a passive mechanism for communications and used\n\naccordingly. Management spends time with their individual contributors to help them understand\n\ntheir responsibility, the tasks to complete, and how their work contributes to the overall mission.\n\nWhen necessary, leaders engage people directly in smaller venues to convey messages and verify\n\nthat these messages are being delivered eﬀectively. As a result of good communications strategies,\n\nthe organization performs at or above the expectations of leadership. Leadership encourages and\n\nseeks diverse opinions within and across teams.\n\nCommon anti-patterns:\n\nYour organization has a ﬁve year plan to migrate all workloads to AWS. The business case for\n\ncloud includes the modernization of 25% of all workloads to take advantage of serverless\n\ntechnology. The CIO communicates this strategy to direct reports and expects each leader to\n\ncascade this presentation to managers, directors, and individual contributors without any in-\n\nperson communication. The CIO steps back and expects his organization to perform the new\n\nstrategy.\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n63",
      "content_length": 2518,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 69,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLeadership does not provide or use a mechanism for feedback, and an expectation gap grows,\n\nwhich leads to stalled projects.\n\nYou are asked to make a change to your security groups, but you are not given any details of\n\nwhat change needs to be made, what the impact of the change could be on all the workloads,\n\nand when it should happen. The manager forwards an email from the VP of InfoSec and adds the\n\nmessage \"Make this happen.\"\n\nChanges were made to your migration strategy that reduce the planned modernization number from 25% to 10%. This has downstream eﬀects on the operations organization. They were not informed of this strategic change and thus, they are not ready with enough skilled capacity to\n\nsupport a greater number of workloads lifted and shifted into AWS.\n\nBeneﬁts of establishing this best practice:\n\nYour organization is well-informed on new or changed strategies, and they act accordingly with\n\nstrong motivation to help each other achieve the overall objectives and metrics set by leadership.\n\nMechanisms exist and are used to provide timely notice to team members of known risks and\n\nplanned events.\n\nNew ways of working (including changes to people or the organization, processes, or\n\ntechnology), along with required skills, are more eﬀectively adopted by the organization, and\n\nyour organization realizes business beneﬁts more quickly.\n\nTeam members have the necessary context of the communications being received, and they can\n\nbe more eﬀective in their jobs.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo implement this best practice, you must work with stakeholders across your organization\n\nto agree to communication standards. Publicize those standards to your organization. For any\n\nsigniﬁcant IT transitions, an established planning team can more successfully manage the impact\n\nof change to its people than an organization that ignores this practice. Larger organizations can\n\nbe more challenging when managing change because it's critical to establish strong buy-in on a\n\nnew strategy with all individual contributors. In the absence of such a transition planning team,\n\nleadership holds 100% of the responsibility for eﬀective communications. When establishing\n\na transition planning team, assign team members to work with all organizational leadership to\n\ndeﬁne and manage eﬀective communications at every level.\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n64",
      "content_length": 2534,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 70,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCustomer example\n\nAnyCompany Retail signed up for AWS Enterprise Support and depends on other third-\n\nparty providers for its cloud operations. The company uses chat and chatops as their main\n\ncommunication medium for operational activities. Alerts and other information populate speciﬁc\n\nchannels. When someone must act, they clearly state the desired outcome, and in many cases, they\n\nreceive a runbook or playbook to use. They schedule major changes to production systems with a\n\nchange calendar.\n\nImplementation steps\n\n1. Establish a core team within the organization that has accountability to build and initiate\n\ncommunication plans for changes that happen at multiple levels within the organization.\n\n2. Institute single-threaded ownership to achieve oversight. Give individual teams the ability to\n\ninnovate independently, and balance the use of consistent mechanisms, which allows for the\n\nright level of inspection and directional vision.\n\n3. Work with stakeholders across your organization to agree to communication standards,\n\npractices, and plans.\n\n4. Verify that the core communications team collaborates with organizational and program\n\nleadership to craft messages to appropriate staﬀ on behalf of leaders.\n\n5. Build strategic communication mechanisms to manage change through announcements, shared\n\ncalendars, all-hands meetings, and in-person or one-on-one methods so that team members\n\nhave proper expectations on the actions they should take.\n\n6. Provide necessary context, details, and time (when possible) to determine if action is necessary.\n\nWhen action is needed, provide the required action and its impact.\n\n7. Implement tools that facilitate tactical communications, like internal chat, email, and knowledge\n\nmanagement.\n\n8. Implement mechanisms to measure and verify that all communications lead to desired\n\noutcomes.\n\n9. Establish a feedback loop that measures the eﬀectiveness of all communications, especially\n\nwhen communications are related to resistance to changes throughout the organization.\n\n10.For all AWS accounts, establish alternate contacts for billing, security, and operations. Ideally,\n\neach contact should be an email distribution as opposed to a speciﬁc individual contact.\n\n11.Establish an escalation and reverse escalation communication plan to engage with your internal\n\nand external teams, including AWS support and other third-party providers.\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n65",
      "content_length": 2523,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 71,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n12.Initiate and perform communication strategies consistently throughout the life of each\n\ntransformation program.\n\n13.Prioritize actions that are repeatable where possible to safely automate at scale.\n\n14.When communications are required in scenarios with automated actions, the communication's\n\npurpose should be to inform teams, for auditing, or a part of the change management process.\n\n15.Analyze communications from your alert systems for false positives or alerts that are constantly\n\ncreated. Remove or change these alerts so that they start when human intervention is required.\n\nIf an alert is initiated, provide a runbook or playbook.\n\na. You can use AWS Systems Manager Documents to build playbooks and runbooks for alerts.\n\n16.Mechanisms are in place to provide notiﬁcation of risks or planned events in a clear and\n\nactionable way with enough notice to allow appropriate responses. Use email lists or chat\n\nchannels to send notiﬁcations ahead of planned events.\n\na. AWS Chatbot can be used to send alerts and respond to events within your organizations\n\nmessaging platform.\n\n17.Provide an accessible source of information where planned events can be discovered. Provide\n\nnotiﬁcations of planned events from the same system.\n\na. AWS Systems Manager Change Calendar can be used to create change windows when\n\nchanges can occur. This provides team members notice when they can make changes safely.\n\n18.Monitor vulnerability notiﬁcations and patch information to understand vulnerabilities in the\n\nwild and potential risks associated to your workload components. Provide notiﬁcation to team\n\nmembers so that they can act.\n\na. You can subscribe to AWS Security Bulletins to receive notiﬁcations of vulnerabilities on AWS.\n\n19.Seek diverse opinions and perspectives: Encourage contributions from everyone. Give\n\ncommunication opportunities to under-represented groups. Rotate roles and responsibilities in\n\nmeetings.\n\na. Expand roles and responsibilities: Provide opportunities for team members to take on roles that they might not otherwise. They can gain experience and perspective from the role and\n\nfrom interactions with new team members with whom they might not otherwise interact.\n\nThey can also bring their experience and perspective to the new role and team members\n\nthey interact with. As perspective increases, identify emergent business opportunities or new\n\nopportunities for improvement. Rotate common tasks between members within a team that\n\nothers typically perform to understand the demands and impact of performing them.\n\nb. Provide a safe and welcoming environment: Establish policy and controls that protect the\n\nmental and physical safety of team members within your organization. Team members should\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n66",
      "content_length": 2857,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 72,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nbe able to interact without fear of reprisal. When team members feel safe and welcome, they\n\nare more likely to be engaged and productive. The more diverse your organization, the better your understanding can be of the people you support, including your customers. When your\n\nteam members are comfortable, feel free to speak, and are conﬁdent they are heard, they\n\nare more likely to share valuable insights (for example, marketing opportunities, accessibility\n\nneeds, unserved market segments, and unacknowledged risks in your environment).\n\nc. Encourage team members to participate fully: Provide the resources necessary for your employees to participate fully in all work related activities. Team members that face daily\n\nchallenges develop skills for working around them. These uniquely-developed skills can\n\nprovide signiﬁcant beneﬁt to your organization. Support team members with necessary\n\naccommodations to increase the beneﬁts you can receive from their contributions.\n\nResources\n\nRelated best practices:\n\nOPS03-BP01 Provide executive sponsorship\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS07-BP04 Use playbooks to investigate issues\n\nRelated documents:\n\nAWS Blog post | Accountability and empowerment are key to high-performing agile\n\norganizations\n\nAWS Executive Insights | Learn to scale innovation, not complexity | Single-threaded Leaders\n\nAWS Security Bulletins\n\nOpen CVE\n\nSupport App in Slack to Manage Support Cases\n\nManage AWS resources in your Slack channels with Amazon Q Developer in chat applications\n\nRelated services:\n\nAmazon Q Developer in chat applications\n\nAWS Systems Manager Change Calendar\n\nAWS Systems Manager Documents\n\nOPS03-BP04 Communications are timely, clear, and actionable\n\n67",
      "content_length": 1787,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 73,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS03-BP05 Experimentation is encouraged\n\nExperimentation is a catalyst for turning new ideas into products and features. It accelerates\n\nlearning and keeps team members interested and engaged. Team members are encouraged\n\nto experiment often to drive innovation. Even when an undesired result occurs, there is value\n\nin knowing what not to do. Team members are not punished for successful experiments with\n\nundesired results.\n\nDesired outcome:\n\nYour organization encourages experimentation to foster innovation.\n\nExperiments are used as an opportunity to learn.\n\nCommon anti-patterns:\n\nYou want to run an A/B test but there is no mechanism to run the experiment. You deploy a UI\n\nchange without the ability to test it. It results in a negative customer experience.\n\nYour company only has a stage and production environment. There is no sandbox environment\n\nto experiment with new features or products so you must experiment within the production\n\nenvironment.\n\nBeneﬁts of establishing this best practice:\n\nExperimentation drives innovation.\n\nYou can react faster to feedback from users through experimentation.\n\nYour organization develops a culture of learning.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nExperiments should be run in a safe manner. Leverage multiple environments to experiment\n\nwithout jeopardizing production resources. Use A/B testing and feature ﬂags to test experiments.\n\nProvide team members the ability to conduct experiments in a sandbox environment.\n\nCustomer example\n\nOPS03-BP05 Experimentation is encouraged\n\n68",
      "content_length": 1657,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 74,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail encourages experimentation. Team members can use 20% of their work\n\nweek to experiment or learn new technologies. They have a sandbox environment where they can innovate. A/B testing is used for new features to validate them with real user feedback.\n\nImplementation steps\n\n1. Work with leadership across your organization to support experimentation. Team members\n\nshould be encouraged to conduct experiments in a safe manner.\n\n2. Provide your team members with an environment where they can safely experiment. They must\n\nhave access to an environment that is like production.\n\na. You can use a separate AWS account to create a sandbox environment for experimentation.\n\nAWS Control Tower can be used to provision these accounts.\n\n3. Use feature ﬂags and A/B testing to experiment safely and gather user feedback.\n\na. AWS AppConﬁg Feature Flags provides the ability to create feature ﬂags.\n\nb. You can use AWS Lambda versions to deploy a new version of a function for beta testing.\n\nLevel of eﬀort for the implementation plan: High. Providing team members with an environment to experiment in and a safe way to conduct experiments can require signiﬁcant investment. You\n\nmay also need to modify application code to use feature ﬂags or support A/B testing.\n\nResources\n\nRelated best practices:\n\nOPS11-BP02 Perform post-incident analysis - Learning from incidents is an important driver for\n\ninnovation along with experimentation.\n\nOPS11-BP03 Implement feedback loops - Feedback loops are an important part of\n\nexperimentation.\n\nRelated documents:\n\nAn Inside Look at the Amazon Culture: Experimentation, Failure, and Customer Obsession\n\nBest practices for creating and managing sandbox accounts in AWS\n\nCreate a Culture of Experimentation Enabled by the Cloud\n\nEnabling experimentation and innovation in the cloud at SulAmérica Seguros\n\nExperiment More, Fail Less\n\nOPS03-BP05 Experimentation is encouraged\n\n69",
      "content_length": 1985,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 75,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOrganizing Your AWS Environment Using Multiple Accounts - Sandbox OU\n\nUsing AWS AppConﬁg Feature Flags\n\nRelated videos:\n\nAWS On Air ft. Amazon CloudWatch Evidently | AWS Events\n\nAWS On Air San Fran Summit 2022 ft. AWS AppConﬁg Feature Flags integration with Jira\n\nAWS re:Invent 2022 - A deployment is not a release: Control your launches w/feature ﬂags\n\n(BOA305-R)\n\nProgrammatically Create an AWS account with AWS Control Tower\n\nSet Up a Multi-Account AWS Environment that Uses Best Practices for AWS Organizations\n\nRelated examples:\n\nAWS Innovation Sandbox\n\nEnd-to-end Personalization 101 for E-Commerce\n\nRelated services:\n\nAmazon CloudWatch Evidently\n\nAWS AppConﬁg\n\nAWS Control Tower\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\nTeams must grow their skill sets to adopt new technologies, and to support changes in demand\n\nand responsibilities in support of your workloads. Growth of skills in new technologies is frequently\n\na source of team member satisfaction and supports innovation. Support your team members'\n\npursuit and maintenance of industry certiﬁcations that validate and acknowledge their growing\n\nskills. Cross train to promote knowledge transfer and reduce the risk of signiﬁcant impact when\n\nyou lose skilled and experienced team members with institutional knowledge. Provide dedicated\n\nstructured time for learning.\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\n70",
      "content_length": 1513,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 76,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS provides resources, including the AWS Getting Started Resource Center, AWS Blogs, AWS\n\nOnline Tech Talks, AWS Events and Webinars, and the AWS Well-Architected Labs, that provide guidance, examples, and detailed walkthroughs to educate your teams.\n\nResources such as Support, (AWS re:Post, Support Center), and AWS Documentation help remove\n\ntechnical roadblocks and improve operations. Reach out to Support through Support Center for\n\nhelp with your questions.\n\nAWS also shares best practices and patterns that we have learned through the operation of AWS in\n\nThe Amazon Builders' Library and a wide variety of other useful educational material through the\n\nAWS Blog and The Oﬃcial AWS Podcast.\n\nAWS Training and Certiﬁcation includes free training through self-paced digital courses, along with\n\nlearning plans by role or domain. You can also register for instructor-led training to further support\n\nthe development of your teams' AWS skills.\n\nDesired outcome: Your organization constantly evaluates skill gaps and closes them with structured budget and investment. Teams encourage and incentivize their members with upskilling\n\nactivities such as acquiring leading industry certiﬁcations. Teams take advantage of dedicated\n\ncross-sharing knowledge programs such as lunch-and-learns, immersion days, hackathons, and\n\ngamedays. Your organization's keeps its knowledge systems up-to-date and relevant to cross-train\n\nteam members, including new-hire onboarding trainings.\n\nCommon anti-patterns:\n\nIn the absence of a structured training program and budget, teams experience uncertainty as\n\nthey try to keep pace with technology evolution, which results in increased attrition.\n\nAs part of migrating to AWS, your organization demonstrates skill gaps and varying cloud\n\nﬂuency amongst teams. Without an eﬀort to upskill, teams ﬁnd themselves overtasked with\n\nlegacy and ineﬃcient management of the cloud environment, which causes increased operator\n\ntoil. This burn out increases employee dissatisfaction.\n\nBeneﬁts of establishing this best practice: When your organization consciously invests in improving the skills of its teams, it also helps accelerate and scale cloud adoption and optimization.\n\nTargeted learning programs drive innovation and build operational ability for teams to be prepared\n\nto handle events. Teams consciously invest in the implementation and evolution of best practices. Team morale is high, and team members value their contribution to the business.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\n71",
      "content_length": 2696,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 77,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nTo adopt new technologies, fuel innovation, and keep pace with changes in demand and\n\nresponsibilities to support your workloads, continually invest in the professional growth of your teams.\n\nImplementation steps\n\n1. Use structured cloud advocacy programs: AWS Skills Guild provides consultative training to\n\nincrease cloud skill conﬁdence and ignite a culture of continuous learning.\n\n2. Provide resources for education: Provide dedicated, structured time and access to training\n\nmaterials and lab resources, and support participation in conferences and access to professional\n\norganizations that provide opportunities for learning from both educators and peers. Provide\n\nyour junior team members with access to senior team members as mentors, or allow the junior team members to shadow their seniors' work and be exposed to their methods and skills. Encourage learning about content not directly related to work in order to have a broader\n\nperspective.\n\n3. Encourage use of expert technical resources: Leverage resources such as AWS re:Post to get\n\naccess to curated knowledge and vibrant community.\n\n4. Build and maintain an up-to-date knowledge repository: Use knowledge sharing platforms such as wikis and runbooks. Create your own reusable expert knowledge source with AWS re:Post Private to streamline collaboration, improve productivity, and accelerate employee\n\nonboarding.\n\n5. Team education and cross-team engagement: Plan for the continuing education needs of your team members. Provide opportunities for team members to join other teams (temporarily or permanently) to share skills and best practices beneﬁting your entire organization.\n\n6. Support pursuit and maintenance of industry certiﬁcations: Support your team members in\n\nthe acquisition and maintenance of industry certiﬁcations that validate what they have learned and acknowledge their accomplishments.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS03-BP01 Provide executive sponsorship\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\n72",
      "content_length": 2174,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 78,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAWS Whitepaper | Cloud Adoption Framework: People Perspective\n\nInvesting in continuous learning to grow your organization's future\n\nAWS Skills Guild\n\nAWS Training and Certiﬁcation\n\nSupport\n\nAWS re:Post\n\nAWS Getting Started Resource Center\n\nAWS Blogs\n\nAWS Cloud Compliance\n\nAWS Documentation\n\nThe Oﬃcial AWS Podcast.\n\nAWS Online Tech Talks\n\nAWS Events and Webinars\n\nAWS Well-Architected Labs\n\nThe Amazon Builders' Library\n\nRelated videos:\n\nAWS re:Invent 2023 | Reskilling at the speed of cloud: Turning employees into entrepreneurs\n\nWS re:Invent 2023 | Building a culture of curiosity through gamiﬁcation\n\nOPS03-BP07 Resource teams appropriately\n\nProvision the right amount of proﬁcient team members, and provide tools and resources to\n\nsupport your workload needs. Overburdening team members increases the risk of human error.\n\nInvestments in tools and resources, such as automation, can scale the eﬀectiveness of your team and help them support a greater number of workloads without requiring additional capacity.\n\nDesired outcome:\n\nOPS03-BP07 Resource teams appropriately\n\n73",
      "content_length": 1201,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 79,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou have appropriately staﬀed your team to gain the skillsets needed for them to operate\n\nworkloads in AWS in accordance with your migration plan. As your team has scaled itself up during the course of your migration project, they have gained proﬁciency in the core AWS\n\ntechnologies that the business plans to use when migrating or modernizing their applications.\n\nYou have carefully aligned your staﬃng plan to make eﬃcient use of resources by leveraging\n\nautomation and workﬂow. A smaller team can now manage more infrastructure on behalf of the\n\napplication development teams.\n\nWith shifting operational priorities, any resource staﬃng constraints are proactively identiﬁed to\n\nprotect the success of business initiatives.\n\nOperational metrics that report operational toil (such as on-call fatigue or excessive paging) are\n\nreviewed to verify that staﬀ are not overwhelmed.\n\nCommon anti-patterns:\n\nYour staﬀ have not ramped up on AWS skills as you close in on your multi-year cloud migration\n\nplan, which risks support of the workloads and lowers employee morale.\n\nYour entire IT organization is shifting into agile ways of working. The business is prioritizing\n\nthe product portfolio and setting metrics for what features need to be developed ﬁrst. Your\n\nagile process does not require teams to assign story points to their work plans. As a result, it is\n\nimpossible to know the level of capacity required for the next amount of work, or if you have the\n\nright skills assigned to the work.\n\nYou are having an AWS partner migrate your workloads, and you don't have a support transition\n\nplan for your teams once the partner completes the migration project. Your teams struggle to\n\neﬃciently and eﬀectively support the workloads.\n\nBeneﬁts of establishing this best practice: You have appropriately-skilled team members available in your organization to support the workloads. Resource allocation can adapt to shifting\n\npriorities without impacting performance. The result is teams being proﬁcient at supporting\n\nworkloads while maximizing time to focus on innovating for customers, which in turn raises\n\nemployee satisfaction.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS03-BP07 Resource teams appropriately\n\n74",
      "content_length": 2309,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 80,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nResource planning for your cloud migration should occur at an organizational level that aligns to\n\nyour migration plan, as well as the desired operating model being implemented to support your\n\nnew cloud environment. This should include understanding which cloud technologies are deployed\n\nfor the business and application development teams. Infrastructure and operations leadership\n\nshould plan for skills gap analysis, training, and role deﬁnition for engineers who are leading cloud adoption.\n\nImplementation steps\n\n1. Deﬁne success criteria for team's success with relevant operational metrics such as staﬀ\n\nproductivity (for example, cost to support a workload or operator hours spent during incidents).\n\n2. Deﬁne resource capacity planning and inspection mechanisms to verify that the right balance of\n\nqualiﬁed capacity is available when needed and can be adjusted over time.\n\n3. Create mechanisms (for example, sending a monthly survey to teams) to understand work-\n\nrelated challenges that impact teams (like increasing responsibilities, changes in technology, loss\n\nof personnel, or increase in customers supported).\n\n4. Use these mechanisms to engage with teams and spot trends that may contribute to employee\n\nproductivity challenges. When your teams are impacted by external factors, reevaluate goals\n\nand adjust targets as appropriate. Identify obstacles that are impeding your team's progress.\n\n5. Regularly review if your currently-provisioned resources are still suﬃcient, of if additional\n\nresources are needed, and make appropriate adjustments to support teams.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS03-BP06 Team members are encouraged to maintain and grow their skill sets\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP07 Automate responses to events\n\nRelated documents:\n\nOPS03-BP07 Resource teams appropriately\n\n75",
      "content_length": 2075,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 81,
      "content": "Operational Excellence Pillar\n\nAWS Cloud Adoption Framework: People Perspective\n\nBecoming a Future-Ready Enterprise\n\nPrioritize your Employees' Skills to Drive Business Growth\n\nHigh performing organization - the Amazon Two-Pizza team\n\nHow Cloud-Mature Enterprises Succeed\n\nOPS03-BP07 Resource teams appropriately\n\nAWS Well-Architected Framework\n\n76",
      "content_length": 348,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 82,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nPrepare\n\nTo prepare for operational excellence, you have to understand your workloads and their expected behaviors. You will then be able to design them to provide insight to their status and build the\n\nprocedures to support them.\n\nDesign your workload so that it provides the information necessary for you to understand its internal state (for example, metrics, logs, events, and traces) across all components in support of\n\nobservability and investigating issues. Observability goes beyond simple monitoring, providing\n\na comprehensive understanding of a system's internal workings based on its external outputs.\n\nRooted in metrics, logs, and traces, observability oﬀers profound insights into system behavior and\n\ndynamics. With eﬀective observability, teams can discern patterns, anomalies, and trends, allowing\n\nthem to proactively address potential issues and maintain optimal system health. Identifying key performance indicators (KPIs) is pivotal to ensure alignment between monitoring activities and\n\nbusiness objectives. This alignment ensures that teams are making data-driven decisions using\n\nmetrics that genuinely matter, optimizing both system performance and business outcomes.\n\nFurthermore, observability empowers businesses to be proactive rather than reactive. Teams can\n\nunderstand the cause-and-eﬀect relationships within their systems, predicting and preventing\n\nissues rather than just reacting to them. As workloads evolve, it's essential to revisit and reﬁne the\n\nobservability strategy, ensuring it remains relevant and eﬀective.\n\nAdopt approaches that improve the ﬂow of changes into production and that achieves refactoring,\n\nfast feedback on quality, and bug ﬁxing. These accelerate beneﬁcial changes entering production,\n\nlimit issues deployed, and activate rapid identiﬁcation and remediation of issues introduced\n\nthrough deployment activities or discovered in your environments.\n\nAdopt approaches that provide fast feedback on quality and achieves rapid recovery from changes\n\nthat do not have desired outcomes. Using these practices mitigates the impact of issues introduced\n\nthrough the deployment of changes. Plan for unsuccessful changes so that you are able to respond faster if necessary and test and validate the changes you make. Be aware of planned activities\n\nin your environments so that you can manage the risk of changes impacting planned activities.\n\nEmphasize frequent, small, reversible changes to limit the scope of change. This results in faster\n\ntroubleshooting and remediation with the option to roll back a change. It also means you are able\n\nto get the beneﬁt of valuable changes more frequently.\n\nEvaluate the operational readiness of your workload, processes, procedures, and personnel to\n\nunderstand the operational risks related to your workload. Use a consistent process (including\n\nmanual or automated checklists) to know when you are ready to go live with your workload or\n\n77",
      "content_length": 3001,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 83,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\na change. This will also help you to ﬁnd any areas that you must make plans to address. Have\n\nrunbooks that document your routine activities and playbooks that guide your processes for issue resolution. Understand the beneﬁts and risks to make informed decisions to permit changes to\n\nenter production.\n\nAWS allows you to view your entire workload (applications, infrastructure, policy, governance, and\n\noperations) as code. This means you can apply the same engineering discipline that you use for\n\napplication code to every element of your stack and share these across teams or organizations to\n\nmagnify the beneﬁts of development eﬀorts. Use operations as code in the cloud and the ability\n\nto safely experiment to develop your workload, your operations procedures, and practice failure.\n\nUsing CloudFormation allows you to have consistent, templated, sandbox development, test, and\n\nproduction environments with increasing levels of operations control.\n\nInvest in implementing operations activities as code to maximize the productivity of operations\n\npersonnel, minimize error rates, and achieve automated responses. Use “pre-mortems” to anticipate failure and create procedures where appropriate. Apply metadata using Resource Tags\n\nand AWS Resource Groups following a consistent tagging strategy to achieve identiﬁcation of your\n\nresources. Tag your resources for organization, cost accounting, access controls, and targeting the\n\nrunning of automated operations activities. Adopt deployment practices that take advantage of\n\nthe elasticity of the cloud to facilitate development activities, and pre-deployment of systems\n\nfor faster implementations. When you make changes to the checklists you use to evaluate your\n\nworkloads, plan what you will do with live systems that no longer comply.\n\nTopics\n\nImplement observability\n\nDesign for operations\n\nMitigate deployment risks\n\nOperational readiness and change management\n\nImplement observability\n\nImplement observability in your workload so that you can understand its state and make data-\n\ndriven decisions based on business requirements.\n\nObservability goes beyond simple monitoring, providing a comprehensive understanding of a\n\nsystem's internal workings based on its external outputs. Rooted in metrics, logs, and traces,\n\nobservability oﬀers profound insights into system behavior and dynamics. With eﬀective\n\nImplement observability\n\n78",
      "content_length": 2460,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 84,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nobservability, teams can discern patterns, anomalies, and trends, allowing them to proactively\n\naddress potential issues and maintain optimal system health.\n\nIdentifying key performance indicators (KPIs) is pivotal to ensure alignment between monitoring activities and business objectives. This alignment ensures that teams are making data-driven\n\ndecisions using metrics that genuinely matter, optimizing both system performance and business\n\noutcomes.\n\nFurthermore, observability empowers businesses to be proactive rather than reactive. Teams can\n\nunderstand the cause-and-eﬀect relationships within their systems, predicting and preventing\n\nissues rather than just reacting to them. As workloads evolve, it's essential to revisit and reﬁne the\n\nobservability strategy, ensuring it remains relevant and eﬀective.\n\nBest practices\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user experience telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement distributed tracing\n\nOPS04-BP01 Identify key performance indicators\n\nImplementing observability in your workload starts with understanding its state and making\n\ndata-driven decisions based on business requirements. One of the most eﬀective ways to ensure\n\nalignment between monitoring activities and business objectives is by deﬁning and monitoring key\n\nperformance indicators (KPIs).\n\nDesired outcome: Eﬃcient observability practices that are tightly aligned with business objectives, ensuring that monitoring eﬀorts are always in service of tangible business outcomes.\n\nCommon anti-patterns:\n\nUndeﬁned KPIs: Working without clear KPIs can lead to monitoring too much or too little,\n\nmissing vital signals.\n\nStatic KPIs: Not revisiting or reﬁning KPIs as the workload or business objectives evolve.\n\nMisalignment: Focusing on technical metrics that don’t correlate directly with business outcomes\n\nor are harder to correlate with real-world issues.\n\nOPS04-BP01 Identify key performance indicators\n\n79",
      "content_length": 2101,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 85,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nEase of issue identiﬁcation: Business KPIs often surface issues more clearly than technical\n\nmetrics. A dip in a business KPI can pinpoint a problem more eﬀectively than sifting through\n\nnumerous technical metrics.\n\nBusiness alignment: Ensures that monitoring activities directly support business objectives.\n\nEﬃciency: Prioritize monitoring resources and attention on metrics that matter.\n\nProactivity: Recognize and address issues before they have broader business implications.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo eﬀectively deﬁne workload KPIs:\n\n1. Start with business outcomes: Before diving into metrics, understand the desired business\n\noutcomes. Is it increased sales, higher user engagement, or faster response times?\n\n2. Correlate technical metrics with business objectives: Not all technical metrics have a direct impact on business outcomes. Identify those that do, but it's often more straightforward to identify an issue using a business KPI.\n\n3. Use Amazon CloudWatch: Employ CloudWatch to deﬁne and monitor metrics that represent\n\nyour KPIs.\n\n4. Regularly review and update KPIs: As your workload and business evolve, keep your KPIs\n\nrelevant.\n\n5. Involve stakeholders: Involve both technical and business teams in deﬁning and reviewing KPIs.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nthe section called “OPS04-BP02 Implement application telemetry”\n\nthe section called “OPS04-BP03 Implement user experience telemetry”\n\nthe section called “OPS04-BP04 Implement dependency telemetry”\n\nthe section called “OPS04-BP05 Implement distributed tracing”\n\nOPS04-BP01 Identify key performance indicators\n\n80",
      "content_length": 1830,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 86,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nAWS Observability Best Practices\n\nCloudWatch User Guide\n\nAWS Observability Skill Builder Course\n\nRelated videos:\n\nDeveloping an observability strategy\n\nRelated examples:\n\nOne Observability Workshop\n\nOPS04-BP02 Implement application telemetry\n\nApplication telemetry serves as the foundation for observability of your workload. It's crucial\n\nto emit telemetry that oﬀers actionable insights into the state of your application and the\n\nachievement of both technical and business outcomes. From troubleshooting to measuring the\n\nimpact of a new feature or ensuring alignment with business key performance indicators (KPIs),\n\napplication telemetry informs the way you build, operate, and evolve your workload.\n\nMetrics, logs, and traces form the three primary pillars of observability. These serve as diagnostic\n\ntools that describe the state of your application. Over time, they assist in creating baselines and\n\nidentifying anomalies. However, to ensure alignment between monitoring activities and business\n\nobjectives, it's pivotal to deﬁne and monitor KPIs. Business KPIs often make it easier to identify\n\nissues compared to technical metrics alone.\n\nOther telemetry types, like real user monitoring (RUM) and synthetic transactions, complement\n\nthese primary data sources. RUM oﬀers insights into real-time user interactions, whereas synthetic\n\ntransactions simulate potential user behaviors, helping detect bottlenecks before real users\n\nencounter them.\n\nDesired outcome: Derive actionable insights into the performance of your workload. These insights allow you to make proactive decisions about performance optimization, achieve increased workload stability, streamline CI/CD processes, and utilize resources eﬀectively.\n\nCommon anti-patterns:\n\nOPS04-BP02 Implement application telemetry\n\n81",
      "content_length": 1877,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 87,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIncomplete observability: Neglecting to incorporate observability at every layer of the\n\nworkload, resulting in blind spots that can obscure vital system performance and behavior insights.\n\nFragmented data view: When data is scattered across multiple tools and systems, it becomes\n\nchallenging to maintain a holistic view of your workload's health and performance.\n\nUser-reported issues: A sign that proactive issue detection through telemetry and business KPI\n\nmonitoring is lacking.\n\nBeneﬁts of establishing this best practice:\n\nInformed decision-making: With insights from telemetry and business KPIs, you can make data-\n\ndriven decisions.\n\nImproved operational eﬃciency: Data-driven resource utilization leads to cost-eﬀectiveness.\n\nEnhanced workload stability: Faster detection and resolution of issues leading to improved\n\nuptime.\n\nStreamlined CI/CD processes: Insights from telemetry data facilitate reﬁnement of processes\n\nand reliable code delivery.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo implement application telemetry for your workload, use AWS services like Amazon CloudWatch\n\nand AWS X-Ray. Amazon CloudWatch provides a comprehensive suite of monitoring tools, allowing\n\nyou to observe your resources and applications in AWS and on-premises environments. It collects,\n\ntracks, and analyzes metrics, consolidates and monitors log data, and responds to changes in your\n\nresources, enhancing your understanding of how your workload operates. In tandem, AWS X-Ray\n\nlets you trace, analyze, and debug your applications, giving you a deep understanding of your workload's behavior. With features like service maps, latency distributions, and trace timelines,\n\nAWS X-Ray provides insights into your workload's performance and the bottlenecks aﬀecting it.\n\nImplementation steps\n\n1. Identify what data to collect: Ascertain the essential metrics, logs, and traces that would oﬀer\n\nsubstantial insights into your workload's health, performance, and behavior.\n\n2. Deploy the CloudWatch agent: The CloudWatch agent is instrumental in procuring system and application metrics and logs from your workload and its underlying infrastructure. The\n\nOPS04-BP02 Implement application telemetry\n\n82",
      "content_length": 2314,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 88,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCloudWatch agent can also be used to collect OpenTelemetry or X-Ray traces and send them to\n\nX-Ray.\n\n3. Implement anomaly detection for logs and metrics: Use CloudWatch Logs anomaly detection\n\nand CloudWatch Metrics anomaly detection to automatically identify unusual activities in\n\nyour application's operations. These tools use machine learning algorithms to detect and alert\n\non anomalies, which enanhces your monitoring capabilities and speeds up response time to\n\npotential disruptions or security threats. Set up these features to proactively manage application\n\nhealth and security.\n\n4. Secure sensitive log data: Use Amazon CloudWatch Logs data protection to mask sensitive information within your logs. This feature helps maintain privacy and compliance through automatic detection and masking of sensitive data before it is accessed. Implement data\n\nmasking to securely handle and protect sensitive details such as personally identiﬁable\n\ninformation (PII).\n\n5. Deﬁne and monitor business KPIs: Establish custom metrics that align with your business\n\noutcomes.\n\n6. Instrument your application with AWS X-Ray: In addition to deploying the CloudWatch agent, it's crucial to instrument your application to emit trace data. This process can provide further insights into your workload's behavior and performance.\n\n7. Standardize data collection across your application: Standardize data collection practices across your entire application. Uniformity aids in correlating and analyzing data, providing a comprehensive view of your application's behavior.\n\n8. Implement cross-account observability: Enhance monitoring eﬃciency across multiple AWS accounts with Amazon CloudWatch cross-account observability. With this feature, you can consolidate metrics, logs, and alarms from diﬀerent accounts into a single view, which simpliﬁes\n\nmanagement and improves response times for identiﬁed issues across your organization's AWS\n\nenvironment.\n\n9. Analyze and act on the data: Once data collection and normalization are in place, use Amazon CloudWatch for metrics and logs analysis, and AWS X-Ray for trace analysis. Such analysis can yield crucial insights into your workload's health, performance, and behavior, guiding your\n\ndecision-making process.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS04-BP02 Implement application telemetry\n\n83",
      "content_length": 2447,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 89,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS04-BP01 Deﬁne workload KPIs\n\nOPS04-BP03 Implement user activity telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement transaction traceability\n\nRelated documents:\n\nAWS Observability Best Practices\n\nCloudWatch User Guide\n\nAWS X-Ray Developer Guide\n\nInstrumenting distributed systems for operational visibility\n\nAWS Observability Skill Builder Course\n\nWhat's New with Amazon CloudWatch\n\nWhat's new with AWS X-Ray\n\nRelated videos:\n\nAWS re:Invent 2022 - Observability best practices at Amazon\n\nAWS re:Invent 2022 - Developing an observability strategy\n\nRelated examples:\n\nOne Observability Workshop\n\nAWS Solutions Library: Application Monitoring with Amazon CloudWatch\n\nOPS04-BP03 Implement user experience telemetry\n\nGaining deep insights into customer experiences and interactions with your application is crucial.\n\nReal user monitoring (RUM) and synthetic transactions serve as powerful tools for this purpose.\n\nRUM provides data about real user interactions granting an unﬁltered perspective of user\n\nsatisfaction, while synthetic transactions simulate user interactions, helping in detecting potential\n\nissues even before they impact real users.\n\nDesired outcome: A holistic view of the customer experience, proactive detection of issues, and optimization of user interactions to deliver seamless digital experiences.\n\nOPS04-BP03 Implement user experience telemetry\n\n84",
      "content_length": 1457,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 90,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nApplications without real user monitoring (RUM):\n\nDelayed issue detection: Without RUM, you might not become aware of performance\n\nbottlenecks or issues until users complain. This reactive approach can lead to customer\n\ndissatisfaction.\n\nLack of user experience insights: Not using RUM means you lose out on crucial data that\n\nshows how real users interact with your application, limiting your ability to optimize the user\n\nexperience.\n\nApplications without synthetic transactions:\n\nMissed edge cases: Synthetic transactions help you test paths and functions that might not be\n\nfrequently used by typical users but are critical to certain business functions. Without them,\n\nthese paths could malfunction and go unnoticed.\n\nChecking for issues when the application is not being used: Regular synthetic testing can\n\nsimulate times when real users aren't actively interacting with your application, ensuring the\n\nsystem always functions correctly.\n\nBeneﬁts of establishing this best practice:\n\nProactive issue detection: Identify and address potential issues before they impact real users.\n\nOptimized user experience: Continuous feedback from RUM aids in reﬁning and enhancing the\n\noverall user experience.\n\nInsights on device and browser performance: Understand how your application performs across\n\nvarious devices and browsers, enabling further optimization.\n\nValidated business workﬂows: Regular synthetic transactions ensure that core functionalities and\n\ncritical paths remain operational and eﬃcient.\n\nEnhanced application performance: Leverage insights gathered from real user data to improve\n\napplication responsiveness and reliability.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo leverage RUM and synthetic transactions for user activity telemetry, AWS oﬀers services like\n\nAmazon CloudWatch RUM and Amazon CloudWatch Synthetics. Metrics, logs, and traces, coupled\n\nOPS04-BP03 Implement user experience telemetry\n\n85",
      "content_length": 2064,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 91,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nwith user activity data, provide a comprehensive view of both the application's operational state\n\nand the user experience.\n\nImplementation steps\n\n1. Deploy Amazon CloudWatch RUM: Integrate your application with CloudWatch RUM to collect,\n\nanalyze, and present real user data.\n\na. Use the CloudWatch RUM JavaScript library to integrate RUM with your application.\n\nb. Set up dashboards to visualize and monitor real user data.\n\n2. Conﬁgure CloudWatch Synthetics: Create canaries, or scripted routines, that simulate user\n\ninteractions with your application.\n\na. Deﬁne critical application workﬂows and paths.\n\nb. Design canaries using CloudWatch Synthetics scripts to simulate user interactions for these\n\npaths.\n\nc. Schedule and monitor canaries to run at speciﬁed intervals, ensuring consistent performance\n\nchecks.\n\n3. Analyze and act on data: Utilize data from RUM and synthetic transactions to gain insights and take corrective measures when anomalies are detected. Use CloudWatch dashboards and alarms to stay informed.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement distributed tracing\n\nRelated documents:\n\nAmazon CloudWatch RUM Guide\n\nAmazon CloudWatch Synthetics Guide\n\nOPS04-BP03 Implement user experience telemetry\n\n86",
      "content_length": 1489,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 92,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated videos:\n\nOptimize applications through end user insights with Amazon CloudWatch RUM\n\nAWS on Air ft. Real-User Monitoring for Amazon CloudWatch\n\nRelated examples:\n\nOne Observability Workshop\n\nGit Repository for Amazon CloudWatch RUM Web Client\n\nUsing Amazon CloudWatch Synthetics to measure page load time\n\nOPS04-BP04 Implement dependency telemetry\n\nDependency telemetry is essential for monitoring the health and performance of the external\n\nservices and components your workload relies on. It provides valuable insights into reachability,\n\ntimeouts, and other critical events related to dependencies such as DNS, databases, or third-\n\nparty APIs. When you instrument your application to emit metrics, logs, and traces about these\n\ndependencies, you gain a clearer understanding of potential bottlenecks, performance issues, or\n\nfailures that might impact your workload.\n\nDesired outcome: Ensure that the dependencies your workload relies on are performing as expected, allowing you to proactively address issues and ensure optimal workload performance.\n\nCommon anti-patterns:\n\nOverlooking external dependencies: Focusing only on internal application metrics while\n\nneglecting metrics related to external dependencies.\n\nLack of proactive monitoring: Waiting for issues to arise instead of continuously monitoring\n\ndependency health and performance.\n\nSiloed monitoring: Using multiple, disparate monitoring tools which can result in fragmented\n\nand inconsistent views of dependency health.\n\nBeneﬁts of establishing this best practice:\n\nImproved workload reliability: By ensuring that external dependencies are consistently\n\navailable and performing optimally.\n\nOPS04-BP04 Implement dependency telemetry\n\n87",
      "content_length": 1776,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 93,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nFaster issue detection and resolution: Proactively identifying and addressing issues with\n\ndependencies before they impact the workload.\n\nComprehensive view: Gaining a holistic view of both internal and external components that\n\ninﬂuence workload health.\n\nEnhanced workload scalability: By understanding the scalability limits and performance\n\ncharacteristics of external dependencies.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplement dependency telemetry by starting with identifying the services, infrastructure, and\n\nprocesses that your workload depends on. Quantify what good conditions look like when those\n\ndependencies are functioning as expected, and then determine what data will be needed to\n\nmeasure those. With that information you can craft dashboards and alerts that provide insights to\n\nyour operations teams on the state of those dependencies. Use AWS tools to discover and quantify\n\nthe impacts when dependencies cannot deliver as needed. Continually revisit your strategy to\n\naccount for changes in priorities, goals, and gained insights.\n\nImplementation steps\n\nTo implement dependency telemetry eﬀectively:\n\n1. Identify external dependencies: Collaborate with stakeholders to pinpoint the external\n\ndependencies your workload relies on. External dependencies can encompass services like\n\nexternal databases, third-party APIs, network connectivity routes to other environments, and\n\nDNS services. The ﬁrst step towards eﬀective dependency telemetry is being comprehensive in\n\nunderstanding what those dependencies are.\n\n2. Develop a monitoring strategy: Once you have a clear picture of your external dependencies, architect a monitoring strategy tailored to them. This involves understanding the criticality of each dependency, its expected behavior, and any associated service-level agreements or targets\n\n(SLA or SLTs). Set up proactive alerts to notify you of status changes or performance deviations.\n\n3. Use network monitoring: Use Internet Monitor and Network Monitor, which provide\n\ncomprehensive insights into global internet and network conditions. These tools help you\n\nunderstand and respond to outages, disruptions, or performance degradations that aﬀect your\n\nexternal dependencies.\n\nOPS04-BP04 Implement dependency telemetry\n\n88",
      "content_length": 2381,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 94,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Stay informed with AWS Health: AWS Health is the authoritative source of information about the health of your AWS Cloud resources. Use AWS Health to visualize and receive notiﬁcations about any current service events and upcoming changes, such as planned lifecycle events, so you can take steps to mitigate impacts.\n\na. Create purpose-ﬁt AWS Health event notiﬁcations to e-mail and chat channels through AWS\n\nUser Notiﬁcations, and integrate programatically with your monitoring and alerting tools\n\nthrough Amazon EventBridge or the AWS Health API.\n\nb. Plan and track progress on health events that require action by integrating with change\n\nmanagement or ITSM tools (like Jira or ServiceNow) that you may already use through\n\nAmazon EventBridge or the AWS Health API.\n\nc. If you use AWS Organizations, enable organization view for AWS Health to aggregate AWS\n\nHealth events across accounts.\n\n5. Instrument your application with AWS X-Ray: AWS X-Ray provides insights into how\n\napplications and their underlying dependencies are performing. By tracing requests from start\n\nto end, you can identify bottlenecks or failures in the external services or components your\n\napplication relies on.\n\n6. Use Amazon DevOps Guru: This machine learning-driven service identiﬁes operational issues,\n\npredicts when critical issues might occur, and recommends speciﬁc actions to take. It's invaluable\n\nfor gaining insights into dependencies and ensuring they're not the source of operational\n\nproblems.\n\n7. Monitor regularly: Continually monitor metrics and logs related to external dependencies. Set\n\nup alerts for unexpected behavior or degraded performance.\n\n8. Validate after changes: Whenever there's an update or change in any of the external\n\ndependencies, validate their performance and check their alignment with your application's\n\nrequirements.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Deﬁne workload KPIs\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user activity telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\n89",
      "content_length": 2162,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 95,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS04-BP05 Implement transaction traceability\n\nOP08-BP04 Create actionable alerts\n\nRelated documents:\n\nAmazon Personal AWS Health Dashboard User Guide\n\nAWS Internet Monitor User Guide\n\nAWS X-Ray Developer Guide\n\nAWS DevOps Guru User Guide\n\nRelated videos:\n\nVisibility into how internet issues impact app performance\n\nIntroduction to Amazon DevOps Guru\n\nManage resource lifecycle events at scale with AWS Health\n\nRelated examples:\n\nAWS Health Aware\n\nUsing Tag-Based Filtering to Manage AWS Health Monitoring and Alerting at Scale\n\nOPS04-BP05 Implement distributed tracing\n\nDistributed tracing oﬀers a way to monitor and visualize requests as they traverse through various\n\ncomponents of a distributed system. By capturing trace data from multiple sources and analyzing\n\nit in a uniﬁed view, teams can better understand how requests ﬂow, where bottlenecks exist, and where optimization eﬀorts should focus.\n\nDesired outcome: Achieve a holistic view of requests ﬂowing through your distributed system, allowing for precise debugging, optimized performance, and improved user experiences.\n\nCommon anti-patterns:\n\nInconsistent instrumentation: Not all services in a distributed system are instrumented for\n\ntracing.\n\nOPS04-BP05 Implement distributed tracing\n\n90",
      "content_length": 1319,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 96,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIgnoring latency: Only focusing on errors and not considering the latency or gradual\n\nperformance degradations.\n\nBeneﬁts of establishing this best practice:\n\nComprehensive system overview: Visualizing the entire path of requests, from entry to exit.\n\nEnhanced debugging: Quickly identifying where failures or performance issues occur.\n\nImproved user experience: Monitoring and optimizing based on actual user data, ensuring the\n\nsystem meets real-world demands.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nBegin by identifying all of the elements of your workload that require instrumentation. Once all\n\ncomponents are accounted for, leverage tools such as AWS X-Ray and OpenTelemetry to gather\n\ntrace data for analysis with tools like X-Ray and Amazon CloudWatch ServiceLens Map. Engage\n\nin regular reviews with developers, and supplement these discussions with tools like Amazon\n\nDevOps Guru, X-Ray Analytics and X-Ray Insights to help uncover deeper ﬁndings. Establish alerts\n\nfrom trace data to notify when outcomes, as deﬁned in the workload monitoring plan, are at risk.\n\nImplementation steps\n\nTo implement distributed tracing eﬀectively:\n\n1. Adopt AWS X-Ray: Integrate X-Ray into your application to gain insights into its behavior,\n\nunderstand its performance, and pinpoint bottlenecks. Utilize X-Ray Insights for automatic trace\n\nanalysis.\n\n2. Instrument your services: Verify that every service, from an AWS Lambda function to an EC2 instance, sends trace data. The more services you instrument, the clearer the end-to-end view.\n\n3. Incorporate CloudWatch Real User Monitoring and synthetic monitoring: Integrate Real User\n\nMonitoring (RUM) and synthetic monitoring with X-Ray. This allows for capturing real-world user\n\nexperiences and simulating user interactions to identify potential issues.\n\n4. Use the CloudWatch agent: The agent can send traces from either X-Ray or OpenTelemetry,\n\nenhancing the depth of insights obtained.\n\n5. Use Amazon DevOps Guru: DevOps Guru uses data from X-Ray, CloudWatch, AWS Conﬁg, and\n\nAWS CloudTrail to provide actionable recommendations.\n\nOPS04-BP05 Implement distributed tracing\n\n91",
      "content_length": 2245,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 97,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n6. Analyze traces: Regularly review the trace data to discern patterns, anomalies, or bottlenecks\n\nthat might impact your application's performance.\n\n7. Set up alerts: Conﬁgure alarms in CloudWatch for unusual patterns or extended latencies,\n\nallowing proactive issue addressing.\n\n8. Continuous improvement: Revisit your tracing strategy as services are added or modiﬁed to\n\ncapture all relevant data points.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user experience telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nRelated documents:\n\nAWS X-Ray Developer Guide\n\nAmazon CloudWatch agent User Guide\n\nAmazon DevOps Guru User Guide\n\nRelated videos:\n\nUse AWS X-Ray Insights\n\nAWS on Air ft. Observability: Amazon CloudWatch and AWS X-Ray\n\nRelated examples:\n\nInstrumenting your application for AWS X-Ray\n\nOPS04-BP05 Implement distributed tracing\n\n92",
      "content_length": 1071,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 98,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesign for operations\n\nAdopt approaches that improve the ﬂow of changes into production and that help refactoring, fast\n\nfeedback on quality, and bug ﬁxing. These accelerate beneﬁcial changes entering production, limit\n\nissues deployed, and provide rapid identiﬁcation and remediation of issues introduced through\n\ndeployment activities.\n\nIn AWS, you can view your entire workload (applications, infrastructure, policy, governance, and\n\noperations) as code. It can all be deﬁned in and updated using code. This means you can apply the\n\nsame engineering discipline that you use for application code to every element of your stack.\n\nBest practices\n\nOPS05-BP01 Use version control\n\nOPS05-BP02 Test and validate changes\n\nOPS05-BP03 Use conﬁguration management systems\n\nOPS05-BP04 Use build and deployment management systems\n\nOPS05-BP05 Perform patch management\n\nOPS05-BP06 Share design standards\n\nOPS05-BP07 Implement practices to improve code quality\n\nOPS05-BP08 Use multiple environments\n\nOPS05-BP09 Make frequent, small, reversible changes\n\nOPS05-BP10 Fully automate integration and deployment\n\nOPS05-BP01 Use version control\n\nUse version control to activate tracking of changes and releases.\n\nMany AWS services oﬀer version control capabilities. Use a revision or source control system\n\nsuch as Git to manage code and other artifacts such as version-controlled AWS CloudFormation\n\ntemplates of your infrastructure.\n\nDesired outcome: Your teams collaborate on code. When merged, the code is consistent and no changes are lost. Errors are easily reverted through correct versioning.\n\nCommon anti-patterns:\n\nDesign for operations\n\n93",
      "content_length": 1693,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 99,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou have been developing and storing your code on your workstation. You have had an\n\nunrecoverable storage failure on the workstation and your code is lost.\n\nAfter overwriting the existing code with your changes, you restart your application and it is no\n\nlonger operable. You are unable to revert the change.\n\nYou have a write lock on a report ﬁle that someone else needs to edit. They contact you asking\n\nthat you stop work on it so that they can complete their tasks.\n\nYour research team has been working on a detailed analysis that shapes your future work.\n\nSomeone has accidentally saved their shopping list over the ﬁnal report. You are unable to revert\n\nthe change and have to recreate the report.\n\nBeneﬁts of establishing this best practice: By using version control capabilities you can easily revert to known good states and previous versions, and limit the risk of assets being lost.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nMaintain assets in version controlled repositories. Doing so supports tracking changes, deploying\n\nnew versions, detecting changes to existing versions, and reverting to prior versions (for example,\n\nrolling back to a known good state in the event of a failure). Integrate the version control\n\ncapabilities of your conﬁguration management systems into your procedures.\n\nResources\n\nRelated best practices:\n\nOPS05-BP04 Use build and deployment management systems\n\nRelated videos:\n\nAWS re:Invent 2023 - How Lockheed Martin builds software faster, powered by DevSecOps\n\nAWS re:Invent 2023 - How GitHub operationalizes AI for team collaboration and productivity\n\nOPS05-BP02 Test and validate changes\n\nEvery change deployed must be tested to avoid errors in production. This best practice is focused\n\non testing changes from version control to artifact build. Besides application code changes, testing\n\nOPS05-BP02 Test and validate changes\n\n94",
      "content_length": 1991,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 100,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nshould include infrastructure, conﬁguration, security controls, and operations procedures. Testing\n\ntakes many forms, from unit tests to software component analysis (SCA). Move tests further to the left in the software integration and delivery process results in higher certainty of artifact quality.\n\nYour organization must develop testing standards for all software artifacts. Automated tests\n\nreduce toil and avoid manual test errors. Manual tests may be necessary in some cases. Developers\n\nmust have access to automated test results to create feedback loops that improve software quality.\n\nDesired outcome: Your software changes are tested before they are delivered. Developers have access to test results and validations. Your organization has a testing standard that applies to all\n\nsoftware changes.\n\nCommon anti-patterns:\n\nYou deploy a new software change without any tests. It fails to run in production, which leads to\n\nan outage.\n\nNew security groups are deployed with AWS CloudFormation without being tested in a pre-\n\nproduction environment. The security groups make your app unreachable for your customers.\n\nA method is modiﬁed but there are no unit tests. The software fails when it is deployed to\n\nproduction.\n\nBeneﬁts of establishing this best practice: Change fail rate of software deployments are reduced. Software quality is improved. Developers have increased awareness on the viability of their\n\ncode. Security policies can be rolled out with conﬁdence to support organization's compliance.\n\nInfrastructure changes such as automatic scaling policy updates are tested in advance to meet\n\ntraﬃc needs.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTesting is done on all changes, from application code to infrastructure, as part of your continuous\n\nintegration practice. Test results are published so that developers have fast feedback. Your\n\norganization has a testing standard that all changes must pass.\n\nUse the power of generative AI with Amazon Q Developer to improve developer productivity\n\nand code quality. Amazon Q Developer includes generation of code suggestions (based on large\n\nlanguage models), production of unit tests (including boundary conditions), and code security\n\nenhancements through detection and remediation of security vulnerabilities.\n\nOPS05-BP02 Test and validate changes\n\n95",
      "content_length": 2438,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 101,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCustomer example\n\nAs part of their continuous integration pipeline, AnyCompany Retail conducts several types of tests\n\non all software artifacts. They practice test driven development so all software has unit tests. Once\n\nthe artifact is built, they run end-to-end tests. After this ﬁrst round of tests is complete, they run a\n\nstatic application security scan, which looks for known vulnerabilities. Developers receive messages\n\nas each testing gate is passed. Once all tests are complete, the software artifact is stored in an\n\nartifact repository.\n\nImplementation steps\n\n1. Work with stakeholders in your organization to develop a testing standard for software artifacts.\n\nWhat standard tests should all artifacts pass? Are there compliance or governance requirements\n\nthat must be included in the test coverage? Do you need to conduct code quality tests? When tests complete, who needs to know?\n\n1. The AWS Deployment Pipeline Reference Architecture contains an authoritative list of types\n\nof tests that can be conducted on software artifacts as part of an integration pipeline.\n\n2. Instrument your application with the necessary tests based on your software testing standard.\n\nEach set of tests should complete in under ten minutes. Tests should run as part of an\n\nintegration pipeline.\n\na. Use Amazon Q Developer, a generative AI tool that can help create unit test cases (including\n\nboundary conditions), generate functions using code and comments, and implement well-\n\nknown algorithms.\n\nb. Use Amazon CodeGuru Reviewer to test your application code for defects.\n\nc. You can use AWS CodeBuild to conduct tests on software artifacts.\n\nd. AWS CodePipeline can orchestrate your software tests into a pipeline.\n\nResources\n\nRelated best practices:\n\nOPS05-BP01 Use version control\n\nOPS05-BP06 Share design standards\n\nOPS05-BP07 Implement practices to improve code quality\n\nOPS05-BP10 Fully automate integration and deployment\n\nOPS05-BP02 Test and validate changes\n\n96",
      "content_length": 2033,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 102,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nAdopt a test-driven development approach\n\nAccelerate your Software Development Lifecycle with Amazon Q\n\nAmazon Q Developer, now generally available, includes previews of new capabilities to reimagine\n\ndeveloper experience\n\nThe Ultimate Cheat Sheet for Using Amazon Q Developer in Your IDE\n\nShift-Left Workload, leveraging AI for Test Creation\n\nAmazon Q Developer Center\n\n10 ways to build applications faster with Amazon CodeWhisperer\n\nLooking beyond code coverage with Amazon CodeWhisperer\n\nBest Practices for Prompt Engineering with Amazon CodeWhisperer\n\nAutomated AWS CloudFormation Testing Pipeline with TaskCat and CodePipeline\n\nBuilding end-to-end AWS DevSecOps CI/CD pipeline with open source SCA, SAST, and DAST\n\ntools\n\nGetting started with testing serverless applications\n\nMy CI/CD pipeline is my release captain\n\nPracticing Continuous Integration and Continuous Delivery on AWS Whitepaper\n\nRelated videos:\n\nImplement an API with Amazon Q Developer Agent for Software Development\n\nInstalling, Conﬁguring, & Using Amazon Q Developer with JetBrains IDEs (How-to)\n\nMastering the art of Amazon CodeWhisperer - YouTube playlist\n\nAWS re:Invent 2020: Testable infrastructure: Integration testing on AWS\n\nAWS Summit ANZ 2021 - Driving a test-ﬁrst strategy with CDK and test driven development\n\nTesting Your Infrastructure as Code with AWS CDK\n\nRelated resources:\n\nAWS Deployment Pipeline Reference Architecture - Application\n\nAWS Kubernetes DevSecOps Pipeline\n\nRun unit tests for a Node.js application from GitHub by using AWS CodeBuild\n\nOPS05-BP02 Test and validate changes\n\n97",
      "content_length": 1661,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 103,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUse Serverspec for test-driven development of infrastructure code\n\nRelated services:\n\nAmazon Q Developer\n\nAmazon CodeGuru Reviewer\n\nAWS CodeBuild\n\nAWS CodePipeline\n\nOPS05-BP03 Use conﬁguration management systems\n\nUse conﬁguration management systems to make and track conﬁguration changes. These systems reduce errors caused by manual processes and reduce the level of eﬀort to deploy changes.\n\nStatic conﬁguration management sets values when initializing a resource that are expected\n\nto remain consistent throughout the resource’s lifetime. Dynamic conﬁguration management\n\nsets values at initialization that can or are expected to change during the lifetime of a resource.\n\nFor example, you could set a feature toggle to activate functionality in your code through a\n\nconﬁguration change, or change the level of log detail during an incident.\n\nConﬁgurations should be deployed in a known and consistent state. You should use automated\n\ninspection to continually monitor resource conﬁgurations across environments and regions.\n\nThese controls should be deﬁned as code and management automated to ensure rules are\n\nconsistently appplied across environments. Changes to conﬁgurations should be updated through\n\nagreed change control procedures and applied consistently, honoring version control. Application\n\nconﬁguration should be managed independently of application and infrastructure code. This allows\n\nfor consistent deployment across multiple environments. Conﬁguration changes do not result in\n\nrebuilding or redeploying the application.\n\nDesired outcome: You conﬁgure, validate, and deploy as part of your continuous integration, continuous delivery (CI/CD) pipeline. You monitor to validate conﬁgurations are correct. This\n\nminimizes any impact to end users and customers.\n\nCommon anti-patterns:\n\nYou manually update the web server conﬁguration across your ﬂeet and a number of servers\n\nbecome unresponsive due to update errors.\n\nOPS05-BP03 Use conﬁguration management systems\n\n98",
      "content_length": 2051,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 104,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou manually update your application server ﬂeet over the course of many hours. The\n\ninconsistency in conﬁguration during the change causes unexpected behaviors.\n\nSomeone has updated your security groups and your web servers are no longer accessible.\n\nWithout knowledge of what was changed you spend signiﬁcant time investigating the issue\n\nextending your time to recovery.\n\nYou push a pre-production conﬁguration into production through CI/CD without validation. You\n\nexpose users and customers to incorrect data and services.\n\nBeneﬁts of establishing this best practice: Adopting conﬁguration management systems reduces the level of eﬀort to make and track changes, and the frequency of errors caused by manual\n\nprocedures. Conﬁguration management systems provide assurances with regards to governance,\n\ncompliance, and regulatory requirements.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nConﬁguration management systems are used to track and implement changes to application and\n\nenvironment conﬁgurations. Conﬁguration management systems are also used to reduce errors\n\ncaused by manual processes, make conﬁguration changes repeatable and auditable, and reduce the\n\nlevel of eﬀort.\n\nOn AWS, you can use AWS Conﬁg to continually monitor your AWS resource conﬁgurations\n\nacross accounts and Regions. It helps you to track their conﬁguration history, understand how a\n\nconﬁguration change would aﬀect other resources, and audit them against expected or desired\n\nconﬁgurations using AWS Conﬁg Rules and AWS Conﬁg Conformance Packs.\n\nFor dynamic conﬁgurations in your applications running on Amazon EC2 instances, AWS Lambda,\n\ncontainers, mobile applications, or IoT devices, you can use AWS AppConﬁg to conﬁgure, validate, deploy, and monitor them across your environments.\n\nImplementation steps\n\n1. Identify conﬁguration owners.\n\na. Make conﬁgurations owners aware of any compliance, governance, or regulatory needs.\n\n2. Identify conﬁguration items and deliverables.\n\na. Conﬁguration items are all application and environmental conﬁgurations aﬀected by a\n\ndeployment within your CI/CD pipeline.\n\nOPS05-BP03 Use conﬁguration management systems\n\n99",
      "content_length": 2264,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 105,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nb. Deliverables include success criteria, validation, and what to monitor.\n\n3. Select tools for conﬁguration management based on your business requirements and delivery\n\npipeline.\n\n4. Consider weighted deployments such as canary deployments for signiﬁcant conﬁguration\n\nchanges to minimize the impact of incorrect conﬁgurations.\n\n5. Integrate your conﬁguration management into your CI/CD pipeline.\n\n6. Validate all changes pushed.\n\nResources\n\nRelated best practices:\n\nOPS06-BP01 Plan for unsuccessful changes\n\nOPS06-BP02 Test deployments\n\nOPS06-BP03 Employ safe deployment strategies\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nAWS Control Tower\n\nAWS Landing Zone Accelerator\n\nAWS Conﬁg\n\nWhat is AWS Conﬁg?\n\nAWS AppConﬁg\n\nWhat is AWS CloudFormation?\n\nAWS Developer Tools\n\nAWS CodeBuild\n\nAWS CodePipeline\n\nAWS CodeDeploy\n\nRelated videos:\n\nAWS re:Invent 2022 - Proactive governance and compliance for AWS workloads\n\nOPS05-BP03 Use conﬁguration management systems\n\n100",
      "content_length": 1047,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 106,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS re:Invent 2020: Achieve compliance as code using AWS Conﬁg\n\nManage and Deploy Application Conﬁgurations with AWS AppConﬁg\n\nOPS05-BP04 Use build and deployment management systems\n\nUse build and deployment management systems. These systems reduce errors caused by manual\n\nprocesses and reduce the level of eﬀort to deploy changes.\n\nIn AWS, you can build continuous integration/continuous deployment (CI/CD) pipelines using\n\nservices such as AWS Developer Tools (for example, AWS CodeBuild, AWS CodePipeline, and AWS\n\nCodeDeploy).\n\nDesired outcome: Your build and deployment management systems support your organization's continuous integration continuous delivery (CI/CD) system that provide capabilities for automating\n\nsafe rollouts with the correct conﬁgurations.\n\nCommon anti-patterns:\n\nAfter compiling your code on your development system, you copy the executable onto your\n\nproduction systems and it fails to start. The local log ﬁles indicates that it has failed due to\n\nmissing dependencies.\n\nYou successfully build your application with new features in your development environment and\n\nprovide the code to quality assurance (QA). It fails QA because it is missing static assets.\n\nOn Friday, after much eﬀort, you successfully built your application manually in your\n\ndevelopment environment including your newly coded features. On Monday, you are unable to\n\nrepeat the steps that allowed you to successfully build your application.\n\nYou perform the tests you have created for your new release. Then you spend the next week\n\nsetting up a test environment and performing all the existing integration tests followed by\n\nthe performance tests. The new code has an unacceptable performance impact and must be\n\nredeveloped and then retested.\n\nBeneﬁts of establishing this best practice: By providing mechanisms to manage build and deployment activities you reduce the level of eﬀort to perform repetitive tasks, free your team\n\nmembers to focus on their high value creative tasks, and limit the introduction of error from manual procedures.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS05-BP04 Use build and deployment management systems\n\n101",
      "content_length": 2242,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 107,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nBuild and deployment management systems are used to track and implement change, reduce\n\nerrors caused by manual processes, and reduce the level of eﬀort required for safe deployments.\n\nFully automate the integration and deployment pipeline from code check-in through build,\n\ntesting, deployment, and validation. This reduces lead time, decreases cost, encourages increased\n\nfrequency of change, reduces the level of eﬀort, and increases collaboration.\n\nImplementation steps\n\nDiagram showing a CI/CD pipeline using AWS CodePipeline and related services\n\n1. Use a version control system to store and manage assets (such as documents, source code, and\n\nbinary ﬁles).\n\n2. Use CodeBuild to compile your source code, runs unit tests, and produces artifacts that are ready\n\nto deploy.\n\n3. Use CodeDeploy as a deployment service that automates application deployments to Amazon\n\nEC2 instances, on-premises instances, serverless AWS Lambda functions, or Amazon ECS.\n\n4. Monitor your deployments.\n\nOPS05-BP04 Use build and deployment management systems\n\n102",
      "content_length": 1135,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 108,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nAWS Developer Tools\n\nWhat is AWS CodeBuild?\n\nAWS CodeBuild\n\nWhat is AWS CodeDeploy?\n\nRelated videos:\n\nAWS re:Invent 2022 - AWS Well-Architected best practices for DevOps on AWS\n\nOPS05-BP05 Perform patch management\n\nPerform patch management to gain features, address issues, and remain compliant with\n\ngovernance. Automate patch management to reduce errors caused by manual processes, scale, and\n\nreduce the level of eﬀort to patch.\n\nPatch and vulnerability management are part of your beneﬁt and risk management activities. It is\n\npreferable to have immutable infrastructures and deploy workloads in veriﬁed known good states.\n\nWhere that is not viable, patching in place is the remaining option.\n\nAWS Health is the authoritative source of information about planned lifecycle events and other\n\naction-required events that aﬀect the health of your AWS Cloud resources. You should be aware of\n\nupcoming changes and updates that should be performed. Major planned lifecycle events are sent\n\nat least six months in advance.\n\nAmazon EC2 Image Builder provides pipelines to update machine images. As a part of patch\n\nmanagement, consider Amazon Machine Images (AMIs) using an AMI image pipeline or container\n\nimages with a Docker image pipeline, while AWS Lambda provides patterns for custom runtimes\n\nand additional libraries to remove vulnerabilities.\n\nOPS05-BP05 Perform patch management\n\n103",
      "content_length": 1550,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 109,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou should manage updates to Amazon Machine Images for Linux or Windows Server images using\n\nAmazon EC2 Image Builder. You can use Amazon Elastic Container Registry (Amazon ECR) with your existing pipeline to manage Amazon ECS images and manage Amazon EKS images. Lambda\n\nincludes version management features.\n\nPatching should not be performed on production systems without ﬁrst testing in a safe\n\nenvironment. Patches should only be applied if they support an operational or business outcome.\n\nOn AWS, you can use AWS Systems Manager Patch Manager to automate the process of patching\n\nmanaged systems and schedule the activity using Systems Manager Maintenance Windows.\n\nDesired outcome: Your AMI and container images are patched, up-to-date, and ready for launch. You are able to track the status of all deployed images and know patch compliance. You are able to\n\nreport on current status and have a process to meet your compliance needs.\n\nCommon anti-patterns:\n\nYou are given a mandate to apply all new security patches within two hours resulting in multiple\n\noutages due to application incompatibility with patches.\n\nAn unpatched library results in unintended consequences as unknown parties use vulnerabilities\n\nwithin it to access your workload.\n\nYou patch the developer environments automatically without notifying the developers. You\n\nreceive multiple complaints from the developers that their environment cease to operate as\n\nexpected.\n\nYou have not patched the commercial oﬀ-the-shelf software on a persistent instance. When\n\nyou have an issue with the software and contact the vendor, they notify you that version is not\n\nsupported and you have to patch to a speciﬁc level to receive any assistance.\n\nA recently released patch for the encryption software you used has signiﬁcant performance\n\nimprovements. Your unpatched system has performance issues that remain in place as a result of not patching.\n\nYou are notiﬁed of a zero-day vulnerability requiring an emergency ﬁx and you have to patch all\n\nyour environments manually.\n\nYou are not aware of critical actions needed to maintain your resources, such as mandatory\n\nversion updates because you do not review upcoming planned lifecycle events and other\n\ninformation. You lose critical time for planning and execution, resulting in emergency changes\n\nfor your teams and potential impact or unexpected downtime.\n\nOPS05-BP05 Perform patch management\n\n104",
      "content_length": 2478,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 110,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: By establishing a patch management process, including your criteria for patching and methodology for distribution across your environments, you can scale and report on patch levels. This provides assurances around security patching and ensure\n\nclear visibility on the status of known ﬁxes being in place. This encourages adoption of desired\n\nfeatures and capabilities, the rapid removal of issues, and sustained compliance with governance.\n\nImplement patch management systems and automation to reduce the level of eﬀort to deploy\n\npatches and limit errors caused by manual processes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nPatch systems to remediate issues, to gain desired features or capabilities, and to remain compliant\n\nwith governance policy and vendor support requirements. In immutable systems, deploy with the appropriate patch set to achieve the desired result. Automate the patch management mechanism\n\nto reduce the elapsed time to patch, to avoid errors caused by manual processes, and lower the\n\nlevel of eﬀort to patch.\n\nImplementation steps\n\nFor Amazon EC2 Image Builder:\n\n1. Using Amazon EC2 Image Builder, specify pipeline details:\n\na. Create an image pipeline and name it\n\nb. Deﬁne pipeline schedule and time zone\n\nc. Conﬁgure any dependencies\n\n2. Choose a recipe:\n\na. Select existing recipe or create a new one\n\nb. Select image type\n\nc. Name and version your recipe\n\nd. Select your base image\n\ne. Add build components and add to target registry\n\n3. Optional - deﬁne your infrastructure conﬁguration.\n\n4. Optional - deﬁne conﬁguration settings.\n\n5. Review settings.\n\n6. Maintain recipe hygiene regularly.\n\nOPS05-BP05 Perform patch management\n\n105",
      "content_length": 1830,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 111,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nFor Systems Manager Patch Manager:\n\n1. Create a patch baseline.\n\n2. Select a patching operations method.\n\n3. Enable compliance reporting and scanning.\n\nResources\n\nRelated best practices:\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nWhat is Amazon EC2 Image Builder\n\nCreate an image pipeline using the Amazon EC2 Image Builder\n\nCreate a container image pipeline\n\nAWS Systems Manager Patch Manager\n\nWorking with Patch Manager\n\nWorking with patch compliance reports\n\nAWS Developer Tools\n\nRelated videos:\n\nCI/CD for Serverless Applications on AWS\n\nDesign with Ops in Mind\n\nRelated examples:\n\nAWS Systems Manager Patch Manager tutorials\n\nOPS05-BP06 Share design standards\n\nShare best practices across teams to increase awareness and maximize the beneﬁts of development\n\neﬀorts. Document them and keep them up to date as your architecture evolves. If shared standards\n\nOPS05-BP06 Share design standards\n\n106",
      "content_length": 982,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 112,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nare enforced in your organization, it’s critical that mechanisms exist to request additions, changes,\n\nand exceptions to standards. Without this option, standards become a constraint on innovation.\n\nDesired outcome: Design standards are shared across teams in your organizations. They are documented and kept up-to-date as best practices evolve.\n\nCommon anti-patterns:\n\nTwo development teams have each created a user authentication service. Your users must\n\nmaintain a separate set of credentials for each part of the system they want to access.\n\nEach team manages their own infrastructure. A new compliance requirement forces a change to\n\nyour infrastructure and each team implements it in a diﬀerent way.\n\nBeneﬁts of establishing this best practice: Using shared standards supports the adoption of best practices and maximizes the beneﬁts of development eﬀorts. Documenting and updating design\n\nstandards keeps your organization up-to-date with best practices and security and compliance\n\nrequirements.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nShare existing best practices, design standards, checklists, operating procedures, guidance, and\n\ngovernance requirements across teams. Have procedures to request changes, additions, and\n\nexceptions to design standards to support improvement and innovation. Make teams are aware of\n\npublished content. Have a mechanism to keep design standards up-to-date as new best practices\n\nemerge.\n\nCustomer example\n\nAnyCompany Retail has a cross-functional architecture team that creates software architecture\n\npatterns. This team builds the architecture with compliance and governance built in. Teams that\n\nadopt these shared standards get the beneﬁts of having compliance and governance built in. They\n\ncan quickly build on top of the design standard. The architecture team meets quarterly to evaluate\n\narchitecture patterns and update them if necessary.\n\nImplementation steps\n\n1. Identify a cross-functional team that owns developing and updating design standards. This team\n\nshould work with stakeholders across your organization to develop design standards, operating\n\nOPS05-BP06 Share design standards\n\n107",
      "content_length": 2267,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 113,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nprocedures, checklists, guidance, and governance requirements. Document the design standards\n\nand share them within your organization.\n\na. AWS Service Catalog can be used to create portfolios representing design standards using\n\ninfrastructure as code. You can share portfolios across accounts.\n\n2. Have a mechanism in place to keep design standards up-to-date as new best practices are\n\nidentiﬁed.\n\n3. If design standards are centrally enforced, have a process to request changes, updates, and\n\nexemptions.\n\nLevel of eﬀort for the implementation plan: Medium. Developing a process to create and share design standards can take coordination and cooperation with stakeholders across your\n\norganization.\n\nResources\n\nRelated best practices:\n\nOPS01-BP03 Evaluate governance requirements - Governance requirements inﬂuence design\n\nstandards.\n\nOPS01-BP04 Evaluate compliance requirements - Compliance is a vital input in creating design\n\nstandards.\n\nOPS07-BP02 Ensure a consistent review of operational readiness - Operational readiness\n\nchecklists are a mechanism to implement design standards when designing your workload.\n\nOPS11-BP01 Have a process for continuous improvement - Updating design standards is a part\n\nof continuous improvement.\n\nOPS11-BP04 Perform knowledge management - As part of your knowledge management\n\npractice, document and share design standards.\n\nRelated documents:\n\nAutomate AWS Backups with AWS Service Catalog\n\nAWS Service Catalog Account Factory-Enhanced\n\nHow Expedia Group built Database as a Service (DBaaS) oﬀering using AWS Service Catalog\n\nMaintain visibility over the use of cloud architecture patterns\n\nSimplify sharing your AWS Service Catalog portfolios in an AWS Organizations setup\n\nOPS05-BP06 Share design standards\n\n108",
      "content_length": 1820,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 114,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated videos:\n\nAWS Service Catalog – Getting Started\n\nAWS re:Invent 2020: Manage your AWS Service Catalog portfolios like an expert\n\nRelated examples:\n\nAWS Service Catalog Reference Architecture\n\nAWS Service Catalog Workshop\n\nRelated services:\n\nAWS Service Catalog\n\nOPS05-BP07 Implement practices to improve code quality\n\nImplement practices to improve code quality and minimize defects. Some examples include test-\n\ndriven development, code reviews, standards adoption, and pair programming. Incorporate these\n\npractices into your continuous integration and delivery process.\n\nDesired outcome: Your organization uses best practices like code reviews or pair programming to improve code quality. Developers and operators adopt code quality best practices as part of the\n\nsoftware development lifecycle.\n\nCommon anti-patterns:\n\nYou commit code to the main branch of your application without a code review. The change\n\nautomatically deploys to production and causes an outage.\n\nA new application is developed without any unit, end-to-end, or integration tests. There is no\n\nway to test the application before deployment.\n\nYour teams make manual changes in production to address defects. Changes do not go through\n\ntesting or code reviews and are not captured or logged through continuous integration and\n\ndelivery processes.\n\nBeneﬁts of establishing this best practice: By adopting practices to improve code quality, you can help minimize issues introduced to production. Code quality best practices include pair\n\nprogramming, code reviews, and implementation of AI productivity tools.\n\nOPS05-BP07 Implement practices to improve code quality\n\n109",
      "content_length": 1709,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 115,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nImplement practices to improve code quality to minimize defects before they are deployed. Use\n\npractices like test-driven development, code reviews, and pair programming to increase the quality\n\nof your development.\n\nUse the power of generative AI with Amazon Q Developer to improve developer productivity\n\nand code quality. Amazon Q Developer includes generation of code suggestions (based on large\n\nlanguage models), production of unit tests (including boundary conditions), and code security\n\nenhancements through detection and remediation of security vulnerabilities.\n\nCustomer example\n\nAnyCompany Retail adopts several practices to improve code quality. They have adopted test- driven development as the standard for writing applications. For some new features, they will have\n\ndevelopers pair program together during a sprint. Every pull request goes through a code review by\n\na senior developer before being integrated and deployed.\n\nImplementation steps\n\n1. Adopt code quality practices like test-driven development, code reviews, and pair programming\n\ninto your continuous integration and delivery process. Use these techniques to improve software\n\nquality.\n\na. Use Amazon Q Developer, a generative AI tool that can help create unit test cases (including\n\nboundary conditions), generate functions using code and comments, implement well-known\n\nalgorithms, detect security policy violations and vulnerabilities in your code, detect secrets,\n\nscan infrastructure as code (IaC), document code, and learn third-party code libraries more\n\nquickly.\n\nb. Amazon CodeGuru Reviewer can provide programming recommendations for Java and Python\n\ncode using machine learning.\n\nLevel of eﬀort for the implementation plan: Medium. There are many ways of implementing this best practice, but getting organizational adoption may be challenging.\n\nResources\n\nRelated best practices:\n\nOPS05-BP07 Implement practices to improve code quality\n\n110",
      "content_length": 2092,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 116,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS05-BP02 Test and validate changes\n\nOPS05-BP06 Share design standards\n\nRelated documents:\n\nAdopt a test-driven development approach\n\nAccelerate your Software Development Lifecycle with Amazon Q\n\nAmazon Q Developer, now generally available, includes previews of new capabilities to reimagine\n\ndeveloper experience\n\nThe Ultimate Cheat Sheet for Using Amazon Q Developer in Your IDE\n\nShift-Left Workload, leveraging AI for Test Creation\n\nAmazon Q Developer Center\n\n10 ways to build applications faster with Amazon CodeWhisperer\n\nLooking beyond code coverage with Amazon CodeWhisperer\n\nBest Practices for Prompt Engineering with Amazon CodeWhisperer\n\nAgile Software Guide\n\nMy CI/CD pipeline is my release captain\n\nAutomate code reviews with Amazon CodeGuru Reviewer\n\nAdopt a test-driven development approach\n\nHow DevFactory builds better applications with Amazon CodeGuru\n\nOn Pair Programming\n\nRENGA Inc. automates code reviews with Amazon CodeGuru\n\nThe Art of Agile Development: Test-Driven Development\n\nWhy code reviews matter (and actually save time!)\n\nRelated videos:\n\nImplement an API with Amazon Q Developer Agent for Software Development\n\nInstalling, Conﬁguring, & Using Amazon Q Developer with JetBrains IDEs (How-to)\n\nMastering the art of Amazon CodeWhisperer - YouTube playlist\n\nAWS re:Invent 2020: Continuous improvement of code quality with Amazon CodeGuru\n\nOPS05-BP07 Implement practices to improve code quality\n\n111",
      "content_length": 1490,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 117,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Summit ANZ 2021 - Driving a test-ﬁrst strategy with CDK and test driven development\n\nRelated services:\n\nAmazon Q Developer\n\nAmazon CodeGuru Reviewer\n\nAmazon CodeGuru Proﬁler\n\nOPS05-BP08 Use multiple environments\n\nUse multiple environments to experiment, develop, and test your workload. Use increasing levels\n\nof controls as environments approach production to gain conﬁdence your workload operates as\n\nintended when deployed.\n\nDesired outcome: You have multiple environments that reﬂect your compliance and governance needs. You test and promote code through environments on your path to production.\n\n1. Your organization does this through the establishment of a landing zone, which provides\n\ngovernance, controls, account automations, networking, security, and operational observability.\n\nManage these landing zone capabilities by using multiple environments. A common example\n\nis a sandbox organization for developing and testing changes to an AWS Control Tower-based\n\nlanding zone, which includes AWS IAM Identity Center and policies such as service control\n\npolicies (SCPs). All of these elements can signiﬁcantly impact the access to and operation of\n\nAWS accounts within the landing zone.\n\n2. In addition to these services, your teams extend the landing zones capabilites with solutions\n\npublished by AWS and AWS partners or as custom solutions developed within your organization.\n\nExamples of solutions published by AWS include Customizations for AWS Control Tower (CfCT)\n\nand AWS Control Tower Account Factory for Terraform (AFT).\n\n3. Your organization applies the same principles of testing, promoting code, and policy changes\n\nfor the landing zone through environments on your path to production. This strategy provides a\n\nstable and secure landing zone environment for your application and workload teams.\n\nCommon anti-patterns:\n\nYou are performing development in a shared development environment and another developer\n\noverwrites your code changes.\n\nOPS05-BP08 Use multiple environments\n\n112",
      "content_length": 2071,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 118,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe restrictive security controls on your shared development environment are preventing you\n\nfrom experimenting with new services and features.\n\nYou perform load testing on your production systems and cause an outage for your users.\n\nA critical error resulting in data loss has occurred in production. In your production environment,\n\nyou attempt to recreate the conditions that lead to the data loss so that you can identify how it\n\nhappened and prevent it from happening again. To prevent further data loss during testing, you\n\nare forced to make the application unavailable to your users.\n\nYou are operating a multi-tenant service and are unable to support a customer request for a\n\ndedicated environment.\n\nYou may not always test, but when you do, you test in your production environment.\n\nYou believe that the simplicity of a single environment overrides the scope of impact of changes\n\nwithin the environment.\n\nYou upgrade a key landing zone capability, but the change impairs your team's ability to vend\n\naccounts for either new projects or your existing workloads.\n\nYou apply new controls to your AWS accounts, but the change impacts your workload team's\n\nability to deploy changes within their AWS accounts.\n\nBeneﬁts of establishing this best practice: When you deploy multiple environments, you can support multiple simultaneous development, testing, and production environments without\n\ncreating conﬂicts between developers or user communities. For complex capabilities such as\n\nlanding zones, it signiﬁcantly reduces the risk of changes, simpliﬁes the improvement process,\n\nand reduces the risk of critical updates to the environment. Organizations that use landing\n\nzones naturally beneﬁt from multi-accounts in their AWS environment, with account structure,\n\ngovernance, network, and security conﬁgurations. Over time, as your organization grows, the\n\nlanding zone can evolve to secure and organize your workloads and resources.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nUse multiple environments and provide developers sandbox environments with minimized\n\ncontrols to aid in experimentation. Provide individual development environments to help\n\nwork in parallel, increasing development agility. Implement more rigorous controls in the\n\nenvironments approaching production to allow developers to innovate. Use infrastructure as code\n\nand conﬁguration management systems to deploy environments that are conﬁgured consistent\n\nwith the controls present in production to ensure systems operate as expected when deployed.\n\nOPS05-BP08 Use multiple environments\n\n113",
      "content_length": 2692,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 119,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nWhen environments are not in use, turn them oﬀ to avoid costs associated with idle resources\n\n(for example, development systems on evenings and weekends). Deploy production equivalent environments when load testing to improve valid results.\n\nTeams such as platform engineering, networking, and security operations often manage capabilies\n\nat the organization level with distinct requirements. A separation of accounts alone is insuﬃcient\n\nto provide and maintain separate environments for experimentation, development, and testing. In\n\nsuch cases, create separate instances of AWS Organizations.\n\nResources\n\nRelated documents:\n\nInstance Scheduler on AWS\n\nWhat is AWS CloudFormation?\n\nOrganizing Your AWS Environment Using Multiple Accounts - Multiple organizations - Test\n\nchanges to your overall AWS environment\n\nAWS Control Tower Guide\n\nOPS05-BP09 Make frequent, small, reversible changes\n\nFrequent, small, and reversible changes reduce the scope and impact of a change. When used in\n\nconjunction with change management systems, conﬁguration management systems, and build and\n\ndelivery systems frequent, small, and reversible changes reduce the scope and impact of a change.\n\nThis results in more eﬀective troubleshooting and faster remediation with the option to roll back\n\nchanges.\n\nCommon anti-patterns:\n\nYou deploy a new version of your application quarterly with a change window that means a core\n\nservice is turned oﬀ.\n\nYou frequently make changes to your database schema without tracking changes in your\n\nmanagement systems.\n\nYou perform manual in-place updates, overwriting existing installations and conﬁgurations, and\n\nhave no clear roll-back plan.\n\nOPS05-BP09 Make frequent, small, reversible changes\n\n114",
      "content_length": 1781,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 120,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: Development eﬀorts are faster by deploying small changes frequently. When the changes are small, it is much easier to identify if they have unintended consequences, and they are easier to reverse. When the changes are reversible, there is\n\nless risk to implementing the change, as recovery is simpliﬁed. The change process has a reduced\n\nrisk and the impact of a failed change is reduced.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nUse frequent, small, and reversible changes to reduce the scope and impact of a change. This eases\n\ntroubleshooting, helps with faster remediation, and provides the option to roll back a change. It\n\nalso increases the rate at which you can deliver value to the business.\n\nResources\n\nRelated best practices:\n\nOPS05-BP03 Use conﬁguration management systems\n\nOPS05-BP04 Use build and deployment management systems\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nImplementing Microservices on AWS\n\nMicroservices - Observability\n\nOPS05-BP10 Fully automate integration and deployment\n\nAutomate build, deployment, and testing of the workload. This reduces errors caused by manual\n\nprocesses and reduces the eﬀort to deploy changes.\n\nApply metadata using Resource Tags and AWS Resource Groups following a consistent tagging\n\nstrategy to aid in identiﬁcation of your resources. Tag your resources for organization, cost\n\naccounting, access controls, and targeting the run of automated operations activities.\n\nDesired outcome: Developers use tools to deliver code and promote through to production. Developers do not have to log into the AWS Management Console to deliver updates. There is a\n\nfull audit trail of change and conﬁguration, meeting the needs of governance and compliance.\n\nOPS05-BP10 Fully automate integration and deployment\n\n115",
      "content_length": 1940,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 121,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nProcesses are repeatable and are standardized across teams. Developers are free to focus on\n\ndevelopment and code pushes, increasing productivity.\n\nCommon anti-patterns:\n\nOn Friday, you ﬁnish authoring the new code for your feature branch. On Monday, after running\n\nyour code quality test scripts and each of your unit tests scripts, you check in your code for the\n\nnext scheduled release.\n\nYou are assigned to code a ﬁx for a critical issue impacting a large number of customers in\n\nproduction. After testing the ﬁx, you commit your code and email change management to\n\nrequest approval to deploy it to production.\n\nAs a developer, you log into the AWS Management Console to create a new development\n\nenvironment using non-standard methods and systems.\n\nBeneﬁts of establishing this best practice: By implementing automated build and deployment management systems, you reduce errors caused by manual processes and reduce the eﬀort to\n\ndeploy changes helping your team members to focus on delivering business value. You increase the\n\nspeed of delivery as you promote through to production.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nYou use build and deployment management systems to track and implement change, to reduce\n\nerrors caused by manual processes, and reduce the level of eﬀort. Fully automate the integration\n\nand deployment pipeline from code check-in through build, testing, deployment, and validation.\n\nThis reduces lead time, encourages increased frequency of change, reduces the level of eﬀort,\n\nincreases the speed to market, results in increased productivity, and increases the security of your\n\ncode as you promote through to production.\n\nResources\n\nRelated best practices:\n\nOPS05-BP03 Use conﬁguration management systems\n\nOPS05-BP04 Use build and deployment management systems\n\nRelated documents:\n\nOPS05-BP10 Fully automate integration and deployment\n\n116",
      "content_length": 1990,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 122,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nWhat is AWS CodeBuild?\n\nWhat is AWS CodeDeploy?\n\nRelated videos:\n\nAWS re:Invent 2022 - AWS Well-Architected best practices for DevOps on AWS\n\nMitigate deployment risks\n\nAdopt approaches that provide fast feedback on quality and provide rapid recovery from changes\n\nthat do not have desired outcomes. Using these practices mitigates the impact of issues introduced\n\nthrough the deployment of changes.\n\nThe design of your workload should include how it will be deployed, updated, and operated. You\n\nwill want to implement engineering practices that align with defect reduction and quick and safe\n\nﬁxes.\n\nBest practices\n\nOPS06-BP01 Plan for unsuccessful changes\n\nOPS06-BP02 Test deployments\n\nOPS06-BP03 Employ safe deployment strategies\n\nOPS06-BP04 Automate testing and rollback\n\nOPS06-BP01 Plan for unsuccessful changes\n\nPlan to revert to a known good state, or remediate in the production environment if the deployment causes an undesired outcome. Having a policy to establish such a plan helps all teams\n\ndevelop strategies to recover from failed changes. Some example strategies are deployment and\n\nrollback steps, change policies, feature ﬂags, traﬃc isolation, and traﬃc shifting. A single release\n\nmay include multiple related component changes. The strategy should provide the ability to\n\nwithstand or recover from a failure of any component change.\n\nDesired outcome: You have prepared a detailed recovery plan for your change in the event it is unsuccessful. In addition, you have reduced the size of your release to minimize the potential\n\nimpact on other workload components. As a result, you have reduced your business impact by\n\nMitigate deployment risks\n\n117",
      "content_length": 1732,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 123,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nshortening the potential downtime caused by a failed change and increased the ﬂexibility and\n\neﬃciency of recovery times.\n\nCommon anti-patterns:\n\nYou performed a deployment and your application has become unstable but there appear to be\n\nactive users on the system. You have to decide whether to rollback the change and impact the\n\nactive users or wait to rollback the change knowing the users may be impacted regardless.\n\nAfter making a routine change, your new environments are accessible, but one of your subnets\n\nhas become unreachable. You have to decide whether to rollback everything or try to ﬁx the\n\ninaccessible subnet. While you are making that determination, the subnet remains unreachable.\n\nYour systems are not architected in a way that allows them to be updated with smaller releases.\n\nAs a result, you have diﬃculty in reversing those bulk changes during a failed deployment.\n\nYou do not use infrastructure as code (IaC) and you made manual updates to your infrastructure that resulted in an undesired conﬁguration. You are unable to eﬀectively track and revert the manual changes.\n\nBecause you have not measured increased frequency of your deployments, your team is not\n\nincentivized to reduce the size of their changes and improve their rollback plans for each change,\n\nleading to more risk and increased failure rates.\n\nYou do not measure the total duration of an outage caused by unsuccessful changes. Your team\n\nis unable to prioritize and improve its deployment process and recovery plan eﬀectiveness.\n\nBeneﬁts of establishing this best practice: Having a plan to recover from unsuccessful changes minimizes the mean time to recover (MTTR) and reduces your business impact.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nA consistent, documented policy and practice adopted by release teams allows an organization\n\nto plan what should happen if unsuccessful changes occur. The policy should allow for ﬁxing\n\nforward in speciﬁc circumstances. In either situation, a ﬁx forward or rollback plan should be well\n\ndocumented and tested before deployment to live production so that the time it takes to revert a\n\nchange is minimized.\n\nOPS06-BP01 Plan for unsuccessful changes\n\n118",
      "content_length": 2308,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 124,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Document the policies that require teams to have eﬀective plans to reverse changes within a\n\nspeciﬁed period.\n\na. Policies should specify when a ﬁx-forward situation is allowed.\n\nb. Require a documented rollback plan to be accessible by all involved.\n\nc. Specify the requirements to rollback (for example, when it is found that unauthorized\n\nchanges have been deployed).\n\n2. Analyze the level of impact of all changes related to each component of a workload.\n\na. Allow repeatable changes to be standardized, templated, and preauthorized if they follow a\n\nconsistent workﬂow that enforces change policies.\n\nb. Reduce the potential impact of any change by making the size of the change smaller so\n\nrecovery takes less time and causes less business impact.\n\nc. Ensure rollback procedures revert code to the known good state to avoid incidents where\n\npossible.\n\n3. Integrate tools and workﬂows to enforce your policies programatically.\n\n4. Make data about changes visible to other workload owners to improve the speed of diagnosis of\n\nany failed change that cannot be rolled back.\n\na. Measure success of this practice using visible change data and identify iterative\n\nimprovements.\n\n5. Use monitoring tools to verify the success or failure of a deployment to speed up decision-\n\nmaking on rolling back.\n\n6. Measure your duration of outage during an unsuccessful change to continually improve your\n\nrecovery plans.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS06-BP04 Automate testing and rollback\n\nRelated documents:\n\nOPS06-BP01 Plan for unsuccessful changes\n\n119",
      "content_length": 1694,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 125,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Builders Library | Ensuring Rollback Safety During Deployments\n\nAWS Whitepaper | Change Management in the Cloud\n\nRelated videos:\n\nre:Invent 2019 | Amazon’s approach to high-availability deployment\n\nOPS06-BP02 Test deployments\n\nTest release procedures in pre-production by using the same deployment conﬁguration, security\n\ncontrols, steps, and procedures as in production. Validate that all deployed steps are completed\n\nas expected, such as inspecting ﬁles, conﬁgurations, and services. Further test all changes with\n\nfunctional, integration, and load tests, along with any monitoring such as health checks. By doing these tests, you can identify deployment issues early with an opportunity to plan and mitigate\n\nthem prior to production.\n\nYou can create temporary parallel environments for testing every change. Automate the\n\ndeployment of the test environments using infrastructure as code (IaC) to help reduce amount of\n\nwork involved and ensure stability, consistency, and faster feature delivery.\n\nDesired outcome: Your organization adopts a test-driven development culture that includes testing deployments. This ensures teams are focused on delivering business value rather than\n\nmanaging releases. Teams are engaged early upon identiﬁcation of deployment risks to determine\n\nthe appropriate course of mitigation.\n\nCommon anti-patterns:\n\nDuring production releases, untested deployments cause frequent issues that require\n\ntroubleshooting and escalation.\n\nYour release contains infrastructure as code (IaC) that updates existing resources. You are unsure\n\nif the IaC runs successfully or causes impact to the resources.\n\nYou deploy a new feature to your application. It doesn't work as intended and there is no\n\nvisibility until it gets reported by impacted users.\n\nYou update your certiﬁcates. You accidentally install the certiﬁcates to the wrong components,\n\nwhich goes undetected and impacts website visitors because a secure connection to the website\n\ncan't be established.\n\nOPS06-BP02 Test deployments\n\n120",
      "content_length": 2086,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 126,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice: Extensive testing in pre-production of deployment procedures, and the changes introduced by them, minimizes the potential impact to production caused by the deployments steps. This increases conﬁdence during production release and\n\nminimizes operational support without slowing down velocity of the changes being delivered.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTesting your deployment process is as important as testing the changes that result from\n\nyour deployment. This can be achieved by testing your deployment steps in a pre-production\n\nenvironment that mirrors production as closely as possible. Common issues, such as incomplete\n\nor incorrect deployment steps, or misconﬁgurations, can be caught as a result before going to\n\nproduction. In addition, you can test your recovery steps.\n\nCustomer example\n\nAs part of their continuous integration and continuous delivery (CI/CD) pipeline, AnyCompany\n\nRetail performs the deﬁned steps needed to release infrastructure and software updates for its\n\ncustomers in a production-like environment. The pipeline is comprised of pre-checks to detect drift\n\n(detecting changes to resources performed outside of your IaC) in resources prior to deployment,\n\nas well as validate actions that the IaC takes upon its initiation. It validates deployment steps, like\n\nverifying that certain ﬁles and conﬁgurations are in place and services are in running states and are\n\nresponding correctly to health checks on local host before re-registering with the load balancer.\n\nAdditionally, all changes ﬂag a number of automated tests, such as functional, security, regression,\n\nintegration, and load tests.\n\nImplementation steps\n\n1. Perform pre-install checks to mirror the pre-production environment to production.\n\na. Use drift detection to detect when resources have been changed outside of CloudFormation.\n\nb. Use change sets to validate that the intent of a stack update matches the actions that\n\nCloudFormation takes when the change set is initiated.\n\n2. This triggers a manual approval step in AWS CodePipeline to authorize the deployment to the\n\npre-production environment.\n\n3. Use deployment conﬁgurations such as AWS CodeDeploy AppSpec ﬁles to deﬁne deployment\n\nand validation steps.\n\nOPS06-BP02 Test deployments\n\n121",
      "content_length": 2423,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 127,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Where applicable, integrate AWS CodeDeploy with other AWS services or integrate AWS\n\nCodeDeploy with partner product and services.\n\n5. Monitor deployments using Amazon CloudWatch, AWS CloudTrail, and Amazon SNS event\n\nnotiﬁcations.\n\n6. Perform post-deployment automated testing, including functional, security, regression,\n\nintegration, and load testing.\n\n7. Troubleshoot deployment issues.\n\n8. Successful validation of preceding steps should initiate a manual approval workﬂow to authorize\n\ndeployment to production.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS05-BP02 Test and validate changes\n\nRelated documents:\n\nAWS Builders' Library | Automating safe, hands-oﬀ deployments | Test Deployments\n\nAWS Whitepaper | Practicing Continuous Integration and Continuous Delivery on AWS\n\nThe Story of Apollo - Amazon's Deployment Engine\n\nHow to test and debug AWS CodeDeploy locally before you ship your code\n\nIntegrating Network Connectivity Testing with Infrastructure Deployment\n\nRelated videos:\n\nre:Invent 2020 | Testing software and systems at Amazon\n\nRelated examples:\n\nTutorial | Deploy and Amazon ECS service with a validation test\n\nOPS06-BP02 Test deployments\n\n122",
      "content_length": 1279,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 128,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS06-BP03 Employ safe deployment strategies\n\nSafe production roll-outs control the ﬂow of beneﬁcial changes with an aim to minimize any\n\nperceived impact for customers from those changes. The safety controls provide inspection\n\nmechanisms to validate desired outcomes and limit the scope of impact from any defects\n\nintroduced by the changes or from deployment failures. Safe roll-outs may include strategies such\n\nas feature-ﬂags, one-box, rolling (canary releases), immutable, traﬃc splitting, and blue/green\n\ndeployments.\n\nDesired outcome: Your organization uses a continuous integration continuous delivery (CI/ CD) system that provides capabilities for automating safe rollouts. Teams are required to use\n\nappropriate safe roll-out strategies.\n\nCommon anti-patterns:\n\nYou deploy an unsuccessful change to all of production all at once. As a result, all customers are\n\nimpacted simultaneously.\n\nA defect introduced in a simultaneous deployment to all systems requires an emergency release.\n\nCorrecting it for all customers takes several days.\n\nManaging production release requires planning and participation of several teams. This puts\n\nconstraints on your ability to frequently update features for your customers.\n\nYou perform a mutable deployment by modifying your existing systems. After discovering that\n\nthe change was unsuccessful, you are forced to modify the systems again to restore the old\n\nversion, extending your time to recovery.\n\nBeneﬁts of establishing this best practice: Automated deployments balance speed of roll-outs against delivering beneﬁcial changes consistently to customers. Limiting impact prevents costly\n\ndeployment failures and maximizes teams ability to eﬃciently respond to failures.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nContinuous-delivery failures can lead to reduced service availability and bad customer experiences.\n\nTo maximize the rate of successful deployments, implement safety controls in the end-to-end release process to minimize deployment errors, with a goal of achieving zero deployment failures.\n\nCustomer example\n\nOPS06-BP03 Employ safe deployment strategies\n\n123",
      "content_length": 2241,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 129,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail is on a mission to achieve minimal to zero downtime deployments, meaning\n\nthat there's no perceivable impact to its users during deployments. To accomplish this, the company has established deployment patterns (see the following workﬂow diagram), such as\n\nrolling and blue/green deployments. All teams adopt one or more of these patterns in their CI/CD\n\npipeline.\n\nCodeDeploy workﬂow for Amazon EC2\n\nCodeDeploy workﬂow for Amazon ECS\n\nCodeDeploy workﬂow for Lambda\n\nImplementation steps\n\n1. Use an approval workﬂow to initiate the sequence of production roll-out steps upon promotion\n\nto production .\n\n2. Use an automated deployment system such as AWS CodeDeploy. AWS CodeDeploy deployment\n\noptions include in-place deployments for EC2/On-Premises and blue/green deployments for\n\nEC2/On-Premises, AWS Lambda, and Amazon ECS (see the preceding workﬂow diagram).\n\na. Where applicable, integrate AWS CodeDeploy with other AWS services or integrate AWS\n\nCodeDeploy with partner product and services.\n\n3. Use blue/green deployments for databases such as Amazon Aurora and Amazon RDS.\n\n4. Monitor deployments using Amazon CloudWatch, AWS CloudTrail, and Amazon Simple\n\nNotiﬁcation Service (Amazon SNS) event notiﬁcations.\n\nOPS06-BP03 Employ safe deployment strategies\n\n124",
      "content_length": 1347,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 130,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n5. Perform post-deployment automated testing including functional, security, regression,\n\nintegration, and any load tests.\n\n6. Troubleshoot deployment issues.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS05-BP02 Test and validate changes\n\nOPS05-BP09 Make frequent, small, reversible changes\n\nOPS05-BP10 Fully automate integration and deployment\n\nRelated documents:\n\nAWS Builders Library | Automating safe, hands-oﬀ deployments | Production deployments\n\nAWS Builders Library | My CI/CD pipeline is my release captain | Safe, automatic production\n\nreleases\n\nAWS Whitepaper | Practicing Continuous Integration and Continuous Delivery on AWS |\n\nDeployment methods\n\nAWS CodeDeploy User Guide\n\nWorking with deployment conﬁgurations in AWS CodeDeploy\n\nSet up an API Gateway canary release deployment\n\nAmazon ECS Deployment Types\n\nFully Managed Blue/Green Deployments in Amazon Aurora and Amazon RDS\n\nBlue/Green deployments with AWS Elastic Beanstalk\n\nRelated videos:\n\nre:Invent 2020 | Hands-oﬀ: Automating continuous delivery pipelines at Amazon\n\nre:Invent 2019 | Amazon's Approach to high-availability deployment\n\nRelated examples:\n\nOPS06-BP03 Employ safe deployment strategies\n\n125",
      "content_length": 1286,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 131,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nTry a Sample Blue/Green Deployment in AWS CodeDeploy\n\nWorkshop | Building CI/CD pipelines for Lambda canary deployments using AWS CDK\n\nWorkshop | Building your ﬁrst DevOps Blue/Green pipeline with Amazon ECS\n\nWorkshop | Building your ﬁrst DevOps Blue/Green pipeline with Amazon EKS\n\nWorkshop | EKS GitOps with ArgoCD\n\nWorkshop | CI/CD on AWS Workshop\n\nImplementing cross-account CI/CD with AWS SAM for container-based Lambda functions\n\nOPS06-BP04 Automate testing and rollback\n\nTo increase the speed, reliability, and conﬁdence of your deployment process, have a strategy\n\nfor automated testing and rollback capabilities in pre-production and production environments. Automate testing when deploying to production to simulate human and system interactions\n\nthat verify the changes being deployed. Automate rollback to revert back to a previous known\n\ngood state quickly. The rollback should be initiated automatically on pre-deﬁned conditions such\n\nas when the desired outcome of your change is not achieved or when the automated test fails.\n\nAutomating these two activities improves your success rate for your deployments, minimizes\n\nrecovery time, and reduces the potential impact to the business.\n\nDesired outcome: Your automated tests and rollback strategies are integrated into your continuous integration, continuous delivery (CI/CD) pipeline. Your monitoring is able to validate\n\nagainst your success criteria and initiate automatic rollback upon failure. This minimizes any\n\nimpact to end users and customers. For example, when all testing outcomes have been satisﬁed,\n\nyou promote your code into the production environment where automated regression testing is\n\ninitiated, leveraging the same test cases. If regression test results do not match expectations, then\n\nautomated rollback is initiated in the pipeline workﬂow.\n\nCommon anti-patterns:\n\nYour systems are not architected in a way that allows them to be updated with smaller releases.\n\nAs a result, you have diﬃculty in reversing those bulk changes during a failed deployment.\n\nYour deployment process consists of a series of manual steps. After you deploy changes to your\n\nworkload, you start post-deployment testing. After testing, you realize that your workload is\n\ninoperable and customers are disconnected. You then begin rolling back to the previous version.\n\nAll of these manual steps delay overall system recovery and cause a prolonged impact to your\n\ncustomers.\n\nOPS06-BP04 Automate testing and rollback\n\n126",
      "content_length": 2546,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 132,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou spent time developing automated test cases for functionality that is not frequently used in\n\nyour application, minimizing the return on investment in your automated testing capability.\n\nYour release is comprised of application, infrastructure, patches and conﬁguration updates that\n\nare independent from one another. However, you have a single CI/CD pipeline that delivers\n\nall changes at once. A failure in one component forces you to revert all changes, making your\n\nrollback complex and ineﬃcient.\n\nYour team completes the coding work in sprint one and begins sprint two work, but your plan\n\ndid not include testing until sprint three. As a result, automated tests revealed defects from\n\nsprint one that had to be resolved before testing of sprint two deliverables could be started and\n\nthe entire release is delayed, devaluing your automated testing.\n\nYour automated regression test cases for the production release are complete, but you are not\n\nmonitoring workload health. Since you have no visibility into whether or not the service has\n\nrestarted, you are not sure if rollback is needed or if it has already occurred.\n\nBeneﬁts of establishing this best practice: Automated testing increases the transparency of your testing process and your ability to cover more features in a shorter time period. By testing and\n\nvalidating changes in production, you are able to identify issues immediately. Improvement in\n\nconsistency with automated testing tools allows for better detection of defects. By automatically\n\nrolling back to the previous version, the impact on your customers is minimized. Automated\n\nrollback ultimately inspires more conﬁdence in your deployment capabilities by reducing business\n\nimpact. Overall, these capabilities reduce time-to-delivery while ensuring quality.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nAutomate testing of deployed environments to conﬁrm desired outcomes more quickly. Automate rollback to a previous known good state when pre-deﬁned outcomes are not achieved to minimize\n\nrecovery time and reduce errors caused by manual processes. Integrate testing tools with your\n\npipeline workﬂow to consistently test and minimize manual inputs. Prioritize automating test\n\ncases, such as those that mitigate the greatest risks and need to be tested frequently with every\n\nchange. Additionally, automate rollback based on speciﬁc conditions that are pre-deﬁned in your\n\ntest plan.\n\nOPS06-BP04 Automate testing and rollback\n\n127",
      "content_length": 2584,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 133,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Establish a testing lifecycle for your development lifecycle that deﬁnes each stage of the testing\n\nprocess from requirements planning to test case development, tool conﬁguration, automated\n\ntesting, and test case closure.\n\na. Create a workload-speciﬁc testing approach from your overall test strategy.\n\nb. Consider a continuous testing strategy where appropriate throughout the development\n\nlifecycle.\n\n2. Select automated tools for testing and rollback based on your business requirements and\n\npipeline investments.\n\n3. Decide which test cases you wish to automate and which should be performed manually. These\n\ncan be deﬁned based on business value priority of the feature being tested. Align all team\n\nmembers to this plan and verify accountability for performing manual tests.\n\na. Apply automated testing capabilities to speciﬁc test cases that make sense for automation,\n\nsuch as repeatable or frequently run cases, those that require repetitive tasks, or those that\n\nare required across multiple conﬁgurations.\n\nb. Deﬁne test automation scripts as well as the success criteria in the automation tool so\n\ncontinued workﬂow automation can be initiated when speciﬁc cases fail.\n\nc. Deﬁne speciﬁc failure criteria for automated rollback.\n\n4. Prioritize test automation to drive consistent results with thorough test case development where\n\ncomplexity and human interaction have a higher risk of failure.\n\n5. Integrate your automated testing and rollback tools into your CI/CD pipeline.\n\na. Develop clear success criteria for your changes.\n\nb. Monitor and observe to detect these criteria and automatically reverse changes when speciﬁc\n\nrollback criteria are met.\n\n6. Perform diﬀerent types of automated production testing, such as:\n\na. A/B testing to show results in comparison to the current version between two user testing\n\ngroups.\n\nb. Canary testing that allows you to roll out your change to a subset of users before releasing it\n\nto all.\n\nc. Feature-ﬂag testing which allows a single feature of the new version at a time to be ﬂagged\n\non and oﬀ from outside the application so that each new feature can be validated one at a\n\ntime.\n\nd. Regression testing to verify new functionality with existing interrelated components.\n\nOPS06-BP04 Automate testing and rollback\n\n128",
      "content_length": 2365,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 134,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n7. Monitor the operational aspects of the application, transactions, and interactions with other\n\napplications and components. Develop reports to show success of changes by workload so that you can identify what parts of the automation and workﬂow can be further optimized.\n\na. Develop test result reports that help you make quick decisions on whether or not rollback\n\nprocedures should be invoked.\n\nb. Implement a strategy that allows for automated rollback based upon pre-deﬁned failure\n\nconditions that result from one or more of your test methods.\n\n8. Develop your automated test cases to allow for reusability across future repeatable changes.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS06-BP01 Plan for unsuccessful changes\n\nOPS06-BP02 Test deployments\n\nRelated documents:\n\nAWS Builders Library | Ensuring rollback safety during deployments\n\nRedeploy and rollback a deployment with AWS CodeDeploy\n\n8 best practices when automating your deployments with AWS CloudFormation\n\nRelated examples:\n\nServerless UI testing using Selenium, AWS Lambda, AWS Fargate, and AWS Developer Tools\n\nRelated videos:\n\nre:Invent 2020 | Hands-oﬀ: Automating continuous delivery pipelines at Amazon\n\nre:Invent 2019 | Amazon's Approach to high-availability deployment\n\nOPS06-BP04 Automate testing and rollback\n\n129",
      "content_length": 1407,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 135,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperational readiness and change management\n\nEvaluate the operational readiness of your workload, processes, procedures, and personnel to\n\nunderstand the operational risks related to your workload. Manage the ﬂow of change into your\n\nenvironments.\n\nYou should use a consistent process (including manual or automated checklists) to know when you are ready to go live with your workload or a change. This will also help you to ﬁnd any areas that\n\nyou need to make plans to address. You will have runbooks that document your routine activities\n\nand playbooks that guide your processes for issue resolution. Use a mechanism to manage changes\n\nthat supports the delivery of business value and help mitigate risks associated to change.\n\nBest practices\n\nOPS07-BP01 Ensure personnel capability\n\nOPS07-BP02 Ensure a consistent review of operational readiness\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS07-BP04 Use playbooks to investigate issues\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\nOPS07-BP06 Create support plans for production workloads\n\nOPS07-BP01 Ensure personnel capability\n\nHave a mechanism to validate that you have the appropriate number of trained personnel to\n\nsupport the workload. They must be trained on the platform and services that make up your\n\nworkload. Provide them with the knowledge necessary to operate the workload. You must have\n\nenough trained personnel to support the normal operation of the workload and troubleshoot any incidents that occur. Have enough personnel so that you can rotate during on-call and vacations to\n\navoid burnout.\n\nDesired outcome:\n\nThere are enough trained personnel to support the workload at times when the workload is\n\navailable.\n\nYou provide training for your personnel on the software and services that make up your\n\nworkload.\n\nOperational readiness and change management\n\n130",
      "content_length": 1924,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 136,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommon anti-patterns:\n\nDeploying a workload without team members trained to operate the platform and services in\n\nuse.\n\nNot having enough personnel to support on-call rotations or personnel taking time oﬀ.\n\nBeneﬁts of establishing this best practice:\n\nHaving skilled team members helps eﬀective support of your workload.\n\nWith enough team members, you can support the workload and on-call rotations while\n\ndecreasing the risk of burnout.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nValidate that there are suﬃcient trained personnel to support the workload. Verify that you have\n\nenough team members to cover normal operational activities, including on-call rotations.\n\nCustomer example\n\nAnyCompany Retail makes sure that teams supporting the workload are properly staﬀed and\n\ntrained. They have enough engineers to support an on-call rotation. Personnel get training on the\n\nsoftware and platform that the workload is built on and are encouraged to earn certiﬁcations.\n\nThere are enough personnel so that people can take time oﬀ while still supporting the workload\n\nand the on-call rotation.\n\nImplementation steps\n\n1. Assign an adequate number of personnel to operate and support your workload, including on-\n\ncall duties, security issues, and lifecycle events, such as end of support and certiﬁcate rotation\n\ntasks.\n\n2. Train your personnel on the software and platforms that compose your workload.\n\na. AWS Training and Certiﬁcation has a library of courses about AWS. They provide free and paid\n\ncourses, online and in-person.\n\nb. AWS hosts events and webinars where you learn from AWS experts.\n\n3. Perform the following on a regular basis:\n\nOPS07-BP01 Ensure personnel capability\n\n131",
      "content_length": 1803,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 137,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEvaluate team size and skills as operating conditions and the workload change.\n\nAdjust team size and skills to match operational requirements.\n\nVerify ability and capacity to address planned lifecycle events, unplanned security, and\n\noperational notiﬁcations through AWS Health.\n\nLevel of eﬀort for the implementation plan: High. Hiring and training a team to support a workload can take signiﬁcant eﬀort but has substantial long-term beneﬁts.\n\nResources\n\nRelated best practices:\n\nOPS11-BP04 Perform knowledge management - Team members must have the information\n\nnecessary to operate and support the workload. Knowledge management is the key to providing\n\nthat.\n\nRelated documents:\n\nAWS Events and Webinars\n\nAWS Training and Certiﬁcation\n\nOPS07-BP02 Ensure a consistent review of operational readiness\n\nUse Operational Readiness Reviews (ORRs) to validate that you can operate your workload. ORR is\n\na mechanism developed at Amazon to validate that teams can safely operate their workloads. An\n\nORR is a review and inspection process using a checklist of requirements. An ORR is a self-service\n\nexperience that teams use to certify their workloads. ORRs include best practices from lessons\n\nlearned from our years of building software.\n\nAn ORR checklist is composed of architectural recommendations, operational process, event\n\nmanagement, and release quality. Our Correction of Error (CoE) process is a major driver of these\n\nitems. Your own post-incident analysis should drive the evolution of your own ORR. An ORR is\n\nnot only about following best practices but preventing the recurrence of events that you’ve seen\n\nbefore. Lastly, security, governance, and compliance requirements can also be included in an ORR.\n\nRun ORRs before a workload launches to general availability and then throughout the software\n\ndevelopment lifecycle. Running the ORR before launch increases your ability to operate the\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n132",
      "content_length": 2035,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 138,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nworkload safely. Periodically re-run your ORR on the workload to catch any drift from best\n\npractices. You can have ORR checklists for new services launches and ORRs for periodic reviews. This helps keep you up to date on new best practices that arise and incorporate lessons learned\n\nfrom post-incident analysis. As your use of the cloud matures, you can build ORR requirements into\n\nyour architecture as defaults.\n\nDesired outcome: You have an ORR checklist with best practices for your organization. ORRs are conducted before workloads launch. ORRs are run periodically over the course of the workload\n\nlifecycle.\n\nCommon anti-patterns:\n\nYou launch a workload without knowing if you can operate it.\n\nGovernance and security requirements are not included in certifying a workload for launch.\n\nWorkloads are not re-evaluated periodically.\n\nWorkloads launch without required procedures in place.\n\nYou see repetition of the same root cause failures in multiple workloads.\n\nBeneﬁts of establishing this best practice:\n\nYour workloads include architecture, process, and management best practices.\n\nLessons learned are incorporated into your ORR process.\n\nRequired procedures are in place when workloads launch.\n\nORRs are run throughout the software lifecycle of your workloads.\n\nLevel of risk if this best practice is not established: High\n\nImplementation guidance\n\nAn ORR is two things: a process and a checklist. Your ORR process should be adopted by your\n\norganization and supported by an executive sponsor. At a minimum, ORRs must be conducted\n\nbefore a workload launches to general availability. Run the ORR throughout the software\n\ndevelopment lifecycle to keep it up to date with best practices or new requirements. The ORR\n\nchecklist should include conﬁguration items, security and governance requirements, and best\n\npractices from your organization. Over time, you can use services, such as AWS Conﬁg, AWS\n\nSecurity Hub CSPM, and AWS Control Tower Guardrails, to build best practices from the ORR into\n\nguardrails for automatic detection of best practices.\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n133",
      "content_length": 2195,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 139,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCustomer example\n\nAfter several production incidents, AnyCompany Retail decided to implement an ORR process. They\n\nbuilt a checklist composed of best practices, governance and compliance requirements, and lessons\n\nlearned from outages. New workloads conduct ORRs before they launch. Every workload conducts\n\na yearly ORR with a subset of best practices to incorporate new best practices and requirements\n\nthat are added to the ORR checklist. Over time, AnyCompany Retail used AWS Conﬁg to detect\n\nsome best practices, speeding up the ORR process.\n\nImplementation steps\n\nTo learn more about ORRs, read the Operational Readiness Reviews (ORR) whitepaper. It provides\n\ndetailed information on the history of the ORR process, how to build your own ORR practice,\n\nand how to develop your ORR checklist. The following steps are an abbreviated version of that\n\ndocument. For an in-depth understanding of what ORRs are and how to build your own, we\n\nrecommend reading that whitepaper.\n\n1. Gather the key stakeholders together, including representatives from security, operations, and\n\ndevelopment.\n\n2. Have each stakeholder provide at least one requirement. For the ﬁrst iteration, try to limit the\n\nnumber of items to thirty or less.\n\nAppendix B: Example ORR questions from the Operational Readiness Reviews (ORR)\n\nwhitepaper contains sample questions that you can use to get started.\n\n3. Collect your requirements into a spreadsheet.\n\nYou can use custom lenses in the AWS Well-Architected Tool to develop your ORR and share\n\nthem across your accounts and AWS Organization.\n\n4. Identify one workload to conduct the ORR on. A pre-launch workload or an internal workload is\n\nideal.\n\n5. Run through the ORR checklist and take note of any discoveries made. Discoveries might be\n\nacceptable if a mitigation is in place. For any discovery that lacks a mitigation, add those to your\n\nbacklog of items and implement them before launch.\n\n6. Continue to add best practices and requirements to your ORR checklist over time.\n\nSupport customers with Enterprise Support can request the Operational Readiness Review\n\nWorkshop from their Technical Account Manager. The workshop is an interactive working\n\nbackwards session to develop your own ORR checklist.\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n134",
      "content_length": 2367,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 140,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: High. Adopting an ORR practice in your organization requires executive sponsorship and stakeholder buy-in. Build and update the checklist with inputs from across your organization.\n\nResources\n\nRelated best practices:\n\nOPS01-BP03 Evaluate governance requirements – Governance requirements are a natural ﬁt for\n\nan ORR checklist.\n\nOPS01-BP04 Evaluate compliance requirements – Compliance requirements are sometimes\n\nincluded in an ORR checklist. Other times they are a separate process.\n\nOPS03-BP07 Resource teams appropriately – Team capability is a good candidate for an ORR\n\nrequirement.\n\nOPS06-BP01 Plan for unsuccessful changes – A rollback or rollforward plan must be established\n\nbefore you launch your workload.\n\nOPS07-BP01 Ensure personnel capability – To support a workload you must have the required\n\npersonnel.\n\nSEC01-BP03 Identify and validate control objectives – Security control objectives make excellent\n\nORR requirements.\n\nREL13-BP01 Deﬁne recovery objectives for downtime and data loss – Disaster recovery plans are\n\na good ORR requirement.\n\nCOST02-BP01 Develop policies based on your organization requirements – Cost management\n\npolicies are good to include in your ORR checklist.\n\nRelated documents:\n\nAWS Control Tower - Guardrails in AWS Control Tower\n\nAWS Well-Architected Tool - Custom Lenses\n\nOperational Readiness Review Template by Adrian Hornsby\n\nOperational Readiness Reviews (ORR) Whitepaper\n\nRelated videos:\n\nAWS Supports You | Building an Eﬀective Operational Readiness Review (ORR)\n\nOPS07-BP02: Ensure a consistent review of operational readiness\n\n135",
      "content_length": 1689,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 141,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated examples:\n\nSample Operational Readiness Review (ORR) Lens\n\nRelated services:\n\nAWS Conﬁg\n\nAWS Control Tower\n\nAWS Security Hub CSPM\n\nAWS Well-Architected Tool\n\nOPS07-BP03 Use runbooks to perform procedures\n\nA runbook is a documented process to achieve a speciﬁc outcome. Runbooks consist of a series of steps that someone follows to get something done. Runbooks have been used in operations going\n\nback to the early days of aviation. In cloud operations, we use runbooks to reduce risk and achieve\n\ndesired outcomes. At its simplest, a runbook is a checklist to complete a task.\n\nRunbooks are an essential part of operating your workload. From onboarding a new team member\n\nto deploying a major release, runbooks are the codiﬁed processes that provide consistent outcomes\n\nno matter who uses them. Runbooks should be published in a central location and updated as the\n\nprocess evolves, as updating runbooks is a key component of a change management process. They\n\nshould also include guidance on error handling, tools, permissions, exceptions, and escalations in\n\ncase a problem occurs.\n\nAs your organization matures, begin automating runbooks. Start with runbooks that are short and\n\nfrequently used. Use scripting languages to automate steps or make steps easier to perform. As\n\nyou automate the ﬁrst few runbooks, you'll dedicate time to automating more complex runbooks.\n\nOver time, most of your runbooks should be automated in some way.\n\nDesired outcome: Your team has a collection of step-by-step guides for performing workload tasks. The runbooks contain the desired outcome, necessary tools and permissions, and\n\ninstructions for error handling. They are stored in a central location (version control system) and\n\nupdated frequently. For example, your runbooks provide capabilities for your teams to monitor,\n\ncommunicate, and respond to AWS Health events for critical accounts during application alarms, operational issues, and planned lifecycle events.\n\nCommon anti-patterns:\n\nOPS07-BP03 Use runbooks to perform procedures\n\n136",
      "content_length": 2106,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 142,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelying on memory to complete each step of a process.\n\nManually deploying changes without a checklist.\n\nDiﬀerent team members performing the same process but with diﬀerent steps or outcomes.\n\nLetting runbooks drift out of sync with system changes and automation.\n\nBeneﬁts of establishing this best practice:\n\nReducing error rates for manual tasks.\n\nOperations are performed in a consistent manner.\n\nNew team members can start performing tasks sooner.\n\nRunbooks can be automated to reduce toil.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nRunbooks can take several forms depending on the maturity level of your organization. At a\n\nminimum, they should consist of a step-by-step text document. The desired outcome should\n\nbe clearly indicated. Clearly document necessary special permissions or tools. Provide detailed\n\nguidance on error handling and escalations in case something goes wrong. List the runbook\n\nowner and publish it in a central location. Once your runbook is documented, validate it by having\n\nsomeone else on your team run it. As procedures evolve, update your runbooks in accordance with\n\nyour change management process.\n\nYour text runbooks should be automated as your organization matures. Using services like\n\nAWS Systems Manager automations, you can transform ﬂat text into automations that can be\n\nrun against your workload. These automations can be run in response to events, reducing the operational burden to maintain your workload. AWS Systems Manager Automation also provides a\n\nlow-code visual design experience to create automation runbooks more easily.\n\nCustomer example\n\nAnyCompany Retail must perform database schema updates during software deployments.\n\nThe Cloud Operations Team worked with the Database Administration Team to build a runbook\n\nfor manually deploying these changes. The runbook listed each step in the process in checklist\n\nform. It included a section on error handling in case something went wrong. They published the\n\nOPS07-BP03 Use runbooks to perform procedures\n\n137",
      "content_length": 2135,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 143,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nrunbook on their internal wiki along with their other runbooks. The Cloud Operations Team plans\n\nto automate the runbook in a future sprint.\n\nImplementation steps\n\nIf you don't have an existing document repository, a version control repository is a great place\n\nto start building your runbook library. You can build your runbooks using Markdown. We have provided an example runbook template that you can use to start building runbooks.\n\n# Runbook Title\n\n## Runbook Info\n\n| Runbook ID | Description | Tools Used | Special Permissions | Runbook Author | Last\n\nUpdated | Escalation POC |\n\n|-------|-------|-------|-------|-------|-------|-------|\n\n| RUN001 | What is this runbook for? What is the desired outcome? | Tools | Permissions\n\n| Your Name | 2022-09-21 | Escalation Name |\n\n## Steps\n\n1. Step one\n\n2. Step two\n\n1. If you don't have an existing documentation repository or wiki, create a new version control\n\nrepository in your version control system.\n\n2. Identify a process that does not have a runbook. An ideal process is one that is conducted\n\nsemiregularly, short in number of steps, and has low impact failures.\n\n3. In your document repository, create a new draft Markdown document using the template. Fill in\n\nRunbook Title and the required ﬁelds under Runbook Info.\n\n4. Starting with the ﬁrst step, ﬁll in the Steps portion of the runbook.\n\n5. Give the runbook to a team member. Have them use the runbook to validate the steps. If\n\nsomething is missing or needs clarity, update the runbook.\n\n6. Publish the runbook to your internal documentation store. Once published, tell your team and\n\nother stakeholders.\n\n7. Over time, you'll build a library of runbooks. As that library grows, start working to automate\n\nrunbooks.\n\nLevel of eﬀort for the implementation plan: Low. The minimum standard for a runbook is a step- by-step text guide. Automating runbooks can increase the implementation eﬀort.\n\nOPS07-BP03 Use runbooks to perform procedures\n\n138",
      "content_length": 2021,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 144,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS07-BP04 Use playbooks to investigate issues\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP02 Have a process per alert\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAchieving Operational Excellence using automated playbook and runbook\n\nAWS Systems Manager: Working with runbooks\n\nMigration playbook for AWS large migrations - Task 4: Improving your migration runbooks\n\nUse AWS Systems Manager Automation runbooks to resolve operational tasks\n\nRelated videos:\n\nAWS re:Invent 2019: DIY guide to runbooks, incident reports, and incident response\n\nHow to automate IT Operations on AWS | Amazon Web Services\n\nIntegrate Scripts into AWS Systems Manager\n\nRelated examples:\n\nWell-Architected Labs: Automating operations with Playbooks and Runbooks\n\nAWS Blog Post: Build a Cloud Automation Practice for Operational Excellence: Best Practices\n\nfrom AWS Managed Services\n\nAWS Systems Manager: Automation walkthroughs\n\nAWS Systems Manager: Restore a root volume from the latest snapshot runbook\n\nBuilding an AWS incident response runbook using Jupyter notebooks and CloudTrail Lake\n\nGitlab - Runbooks\n\nRubix - A Python library for building runbooks in Jupyter Notebooks\n\nOPS07-BP03 Use runbooks to perform procedures\n\n139",
      "content_length": 1418,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 145,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUsing Document Builder to create a custom runbook\n\nRelated services:\n\nAWS Systems Manager Automation\n\nOPS07-BP04 Use playbooks to investigate issues\n\nPlaybooks are step-by-step guides used to investigate an incident. When incidents happen,\n\nplaybooks are used to investigate, scope impact, and identify a root cause. Playbooks are used\n\nfor a variety of scenarios, from failed deployments to security incidents. In many cases, playbooks\n\nidentify the root cause that a runbook is used to mitigate. Playbooks are an essential component of\n\nyour organization's incident response plans.\n\nA good playbook has several key features. It guides the user, step by step, through the process of\n\ndiscovery. Thinking outside-in, what steps should someone follow to diagnose an incident? Clearly\n\ndeﬁne in the playbook if special tools or elevated permissions are needed in the playbook. Having a\n\ncommunication plan to update stakeholders on the status of the investigation is a key component.\n\nIn situations where a root cause can't be identiﬁed, the playbook should have an escalation plan. If\n\nthe root cause is identiﬁed, the playbook should point to a runbook that describes how to resolve\n\nit. Playbooks should be stored centrally and regularly maintained. If playbooks are used for speciﬁc\n\nalerts, provide your team with pointers to the playbook within the alert.\n\nAs your organization matures, automate your playbooks. Start with playbooks that cover low-\n\nrisk incidents. Use scripting to automate the discovery steps. Make sure that you have companion\n\nrunbooks to mitigate common root causes.\n\nDesired outcome: Your organization has playbooks for common incidents. The playbooks are stored in a central location and available to your team members. Playbooks are updated frequently.\n\nFor any known root causes, companion runbooks are built.\n\nCommon anti-patterns:\n\nThere is no standard way to investigate an incident.\n\nTeam members rely on muscle memory or institutional knowledge to troubleshoot a failed\n\ndeployment.\n\nNew team members learn how to investigate issues through trial and error.\n\nBest practices for investigating issues are not shared across teams.\n\nOPS07-BP04 Use playbooks to investigate issues\n\n140",
      "content_length": 2278,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 146,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nPlaybooks boost your eﬀorts to mitigate incidents.\n\nDiﬀerent team members can use the same playbook to identify a root cause in a consistent\n\nmanner.\n\nKnown root causes can have runbooks developed for them, speeding up recovery time.\n\nPlaybooks help team members to start contributing sooner.\n\nTeams can scale their processes with repeatable playbooks.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nHow you build and use playbooks depends on the maturity of your organization. If you are new to the cloud, build playbooks in text form in a central document repository. As your organization\n\nmatures, playbooks can become semi-automated with scripting languages like Python. These\n\nscripts can be run inside a Jupyter notebook to speed up discovery. Advanced organizations have\n\nfully automated playbooks for common issues that are auto-remediated with runbooks.\n\nStart building your playbooks by listing common incidents that happen to your workload. Choose\n\nplaybooks for incidents that are low risk and where the root cause has been narrowed down to\n\na few issues to start. After you have playbooks for simpler scenarios, move on to the higher risk\n\nscenarios or scenarios where the root cause is not well known.\n\nYour text playbooks should be automated as your organization matures. Using services like AWS\n\nSystems Manager Automations, ﬂat text can be transformed into automations. These automations\n\ncan be run against your workload to speed up investigations. These automations can be activated\n\nin response to events, reducing the mean time to discover and resolve incidents.\n\nCustomers can use AWS Systems Manager Incident Manager to respond to incidents. This service\n\nprovides a single interface to triage incidents, inform stakeholders during discovery and mitigation,\n\nand collaborate throughout the incident. It uses AWS Systems Manager Automations to speed up\n\ndetection and recovery.\n\nCustomer example\n\nA production incident impacted AnyCompany Retail. The on-call engineer used a playbook to\n\ninvestigate the issue. As they progressed through the steps, they kept the key stakeholders,\n\nOPS07-BP04 Use playbooks to investigate issues\n\n141",
      "content_length": 2314,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 147,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nidentiﬁed in the playbook, up to date. The engineer identiﬁed the root cause as a race condition\n\nin a backend service. Using a runbook, the engineer relaunched the service, bringing AnyCompany Retail back online.\n\nImplementation steps\n\nIf you don't have an existing document repository, we suggest creating a version control repository\n\nfor your playbook library. You can build your playbooks using Markdown, which is compatible with\n\nmost playbook automation systems. If you are starting from scratch, use the following example\n\nplaybook template.\n\n# Playbook Title\n\n## Playbook Info\n\n| Playbook ID | Description | Tools Used | Special Permissions | Playbook Author | Last\n\nUpdated | Escalation POC | Stakeholders | Communication Plan |\n\n|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n\n| RUN001 | What is this playbook for? What incident is it used for? | Tools |\n\nPermissions | Your Name | 2022-09-21 | Escalation Name | Stakeholder Name | How will\n\nupdates be communicated during the investigation? |\n\n## Steps\n\n1. Step one\n\n2. Step two\n\n1. If you don't have an existing document repository or wiki, create a new version control\n\nrepository for your playbooks in your version control system.\n\n2. Identify a common issue that requires investigation. This should be a scenario where the root\n\ncause is limited to a few issues and resolution is low risk.\n\n3. Using the Markdown template, ﬁll in the Playbook Name section and the ﬁelds under Playbook\n\nInfo.\n\n4. Fill in the troubleshooting steps. Be as clear as possible on what actions to perform or what\n\nareas you should investigate.\n\n5. Give a team member the playbook and have them go through it to validate it. If there's anything\n\nmissing or something isn't clear, update the playbook.\n\n6. Publish your playbook in your document repository and inform your team and any stakeholders.\n\n7. This playbook library will grow as you add more playbooks. Once you have several playbooks,\n\nstart automating them using tools like AWS Systems Manager Automations to keep automation\n\nand playbooks in sync.\n\nOPS07-BP04 Use playbooks to investigate issues\n\n142",
      "content_length": 2193,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 148,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: Low. Your playbooks should be text documents stored in a central location. More mature organizations will move towards automating playbooks.\n\nResources\n\nRelated best practices:\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP02 Have a process per alert\n\nOPS11-BP04 Perform knowledge management\n\nRelated documents:\n\nAchieving Operational Excellence using automated playbook and runbook\n\nAWS Systems Manager: Working with runbooks\n\nUse AWS Systems Manager Automation runbooks to resolve operational tasks\n\nRelated videos:\n\nAWS re:Invent 2019: DIY guide to runbooks, incident reports, and incident response (SEC318-R1)\n\nAWS Systems Manager Incident Manager - AWS Virtual Workshops\n\nIntegrate Scripts into AWS Systems Manager\n\nRelated examples:\n\nAWS Customer Playbook Framework\n\nAWS Systems Manager: Automation walkthroughs\n\nBuilding an AWS incident response runbook using Jupyter notebooks and CloudTrail Lake\n\nRubix – A Python library for building runbooks in Jupyter Notebooks\n\nUsing Document Builder to create a custom runbook\n\nRelated services:\n\nOPS07-BP04 Use playbooks to investigate issues\n\n143",
      "content_length": 1342,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 149,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Systems Manager Automation\n\nAWS Systems Manager Incident Manager\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\nHave processes in place for successful and unsuccessful changes to your workload. A pre-mortem is an exercise where a team simulates a failure to develop mitigation strategies. Use pre-mortems\n\nto anticipate failure and create procedures where appropriate. Evaluate the beneﬁts and risks of\n\ndeploying changes to your workload. Verify that all changes comply with governance.\n\nDesired outcome:\n\nYou make informed decisions when deploying changes to your workload.\n\nChanges comply with governance.\n\nCommon anti-patterns:\n\nDeploying a change to our workload without a process to handle a failed deployment.\n\nMaking changes to your production environment that are out of compliance with governance\n\nrequirements.\n\nDeploying a new version of your workload without establishing a baseline for resource\n\nutilization.\n\nBeneﬁts of establishing this best practice:\n\nYou are prepared for unsuccessful changes to your workload.\n\nChanges to your workload are compliant with governance policies.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nUse pre-mortems to develop processes for unsuccessful changes. Document your processes for\n\nunsuccessful changes. Ensure that all changes comply with governance. Evaluate the beneﬁts and risks to deploying changes to your workload.\n\nCustomer example\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\n144",
      "content_length": 1597,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 150,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAnyCompany Retail regularly conducts pre-mortems to validate their processes for unsuccessful\n\nchanges. They document their processes in a shared Wiki and update it frequently. All changes comply with governance requirements.\n\nImplementation steps\n\n1. Make informed decisions when deploying changes to your workload. Establish and review\n\ncriteria for a successful deployment. Develop scenarios or criteria that would initiate a rollback\n\nof a change. Weigh the beneﬁts of deploying changes against the risks of an unsuccessful\n\nchange.\n\n2. Verify that all changes comply with governance policies.\n\n3. Use pre-mortems to plan for unsuccessful changes and document mitigation strategies. Run a\n\ntable-top exercise to model an unsuccessful change and validate roll-back procedures.\n\nLevel of eﬀort for the implementation plan: Moderate. Implementing a practice of pre-mortems requires coordination and eﬀort from stakeholders across your organization\n\nResources\n\nRelated best practices:\n\nOPS01-BP03 Evaluate governance requirements - Governance requirements are a key factor in\n\ndetermining whether to deploy a change.\n\nOPS06-BP01 Plan for unsuccessful changes - Establish plans to mitigate a failed deployment and\n\nuse pre-mortems to validate them.\n\nOPS06-BP02 Test deployments - Every software change should be properly tested before\n\ndeployment in order to reduce defects in production.\n\nOPS07-BP01 Ensure personnel capability - Having enough trained personnel to support the\n\nworkload is essential to making an informed decision to deploy a system change.\n\nRelated documents:\n\nAmazon Web Services: Risk and Compliance\n\nAWS Shared Responsibility Model\n\nGovernance in the AWS Cloud: The Right Balance Between Agility and Safety\n\nOPS07-BP05 Make informed decisions to deploy systems and changes\n\n145",
      "content_length": 1861,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 151,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS07-BP06 Create support plans for production workloads\n\nEnable support for any software and services that your production workload relies on. Select an\n\nappropriate support level to meet your production service-level needs. Support plans for these\n\ndependencies are necessary in case there is a service disruption or software issue. Document\n\nsupport plans and how to request support for all service and software vendors. Implement\n\nmechanisms that verify that support points of contacts are kept up to date.\n\nDesired outcome:\n\nImplement support plans for software and services that production workloads rely on.\n\nChoose an appropriate support plan based on service-level needs.\n\nDocument the support plans, support levels, and how to request support.\n\nCommon anti-patterns:\n\nYou have no support plan for a critical software vendor. Your workload is impacted by them and\n\nyou can do nothing to expedite a ﬁx or get timely updates from the vendor.\n\nA developer that was the primary point of contact for a software vendor left the company.\n\nYou are not able to reach the vendor support directly. You must spend time researching and\n\nnavigating generic contact systems, increasing the time required to respond when needed.\n\nA production outage occurs with a software vendor. There is no documentation on how to ﬁle a\n\nsupport case.\n\nBeneﬁts of establishing this best practice:\n\nWith the appropriate support level, you are able to get a response in the time frame necessary to\n\nmeet service-level needs.\n\nAs a supported customer you can escalate if there are production issues.\n\nSoftware and services vendors can assist in troubleshooting during an incident.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nEnable support plans for any software and services vendors that your production workload relies\n\non. Set up appropriate support plans to meet service-level needs. For AWS customers, this means\n\nOPS07-BP06 Create support plans for production workloads\n\n146",
      "content_length": 2070,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 152,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nactivating AWS Business Support or greater on any accounts where you have production workloads.\n\nMeet with support vendors on a regular cadence to get updates about support oﬀerings, processes, and contacts. Document how to request support from software and services vendors, including\n\nhow to escalate if there is an outage. Implement mechanisms to keep support contacts up to date.\n\nCustomer example\n\nAt AnyCompany Retail, all commercial software and services dependencies have support plans.\n\nFor example, they have AWS Enterprise Support activated on all accounts with production\n\nworkloads. Any developer can raise a support case when there is an issue. There is a wiki page with\n\ninformation on how to request support, whom to notify, and best practices for expediting a case.\n\nImplementation steps\n\n1. Work with stakeholders in your organization to identify software and services vendors that your\n\nworkload relies on. Document these dependencies.\n\n2. Determine service-level needs for your workload. Select a support plan that aligns with them.\n\n3. For commercial software and services, establish a support plan with the vendors.\n\na. Subscribing to AWS Business Support or greater for all production accounts provides faster\n\nresponse time from AWS Support and strongly recommended. If you don’t have premium\n\nsupport, you must have an action plan to handle issues, which require help from AWS\n\nSupport. AWS Support provides a mix of tools and technology, people, and programs\n\ndesigned to proactively help you optimize performance, lower costs, and innovate faster. In\n\naddition, AWS Business Support provides additional beneﬁts, including API access to AWS\n\nTrusted Advisor and AWS Health for programmatic integration with your systems, alongside\n\nother access methods like the AWS Management Console and Amazon EventBridge channels.\n\n4. Document the support plan in your knowledge management tool. Include how to request\n\nsupport, who to notify if a support case is ﬁled, and how to escalate during an incident. A wiki\n\nis a good mechanism to allow anyone to make necessary updates to documentation when they\n\nbecome aware of changes to support processes or contacts.\n\nLevel of eﬀort for the implementation plan: Low. Most software and services vendors oﬀer opt-in support plans. Documenting and sharing support best practices on your knowledge management\n\nsystem veriﬁes that your team knows what to do when there is a production issue.\n\nResources\n\nRelated best practices:\n\nOPS07-BP06 Create support plans for production workloads\n\n147",
      "content_length": 2610,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 153,
      "content": "Operational Excellence Pillar\n\nOPS02-BP02 Processes and procedures have identiﬁed owners\n\nRelated documents:\n\nAWS Support Plans\n\nRelated services:\n\nAWS Business Support\n\nAWS Enterprise Support\n\nOPS07-BP06 Create support plans for production workloads\n\nAWS Well-Architected Framework\n\n148",
      "content_length": 287,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 154,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOperate\n\nObservability allows you to focus on meaningful data and understand your workload's interactions and output. By concentrating on essential insights and eliminating unnecessary data, you maintain\n\na straightforward approach to understanding workload performance. It's essential not only\n\nto collect data but also to interpret it correctly. Deﬁne clear baselines, set appropriate alert\n\nthresholds, and actively monitor for any deviations. A shift in a key metric, especially when\n\ncorrelated with other data, can pinpoint speciﬁc problem areas. With observability, you're better\n\nequipped to foresee and address potential challenges, ensuring that your workload operates\n\nsmoothly and meets business needs.\n\nSuccessful operation of a workload is measured by the achievement of business and customer\n\noutcomes. Deﬁne expected outcomes, determine how success will be measured, and identify metrics that will be used in those calculations to determine if your workload and operations are\n\nsuccessful. Operational health includes both the health of the workload and the health and success\n\nof the operations activities performed in support of the workload (for example, deployment and\n\nincident response). Establish metrics baselines for improvement, investigation, and intervention,\n\ncollect and analyze your metrics, and then validate your understanding of operations success and\n\nhow it changes over time. Use collected metrics to determine if you are satisfying customer and\n\nbusiness needs, and identify areas for improvement.\n\nEﬃcient and eﬀective management of operational events is required to achieve operational\n\nexcellence. This applies to both planned and unplanned operational events. Use established\n\nrunbooks for well-understood events, and use playbooks to aid in investigation and resolution of\n\nissues. Prioritize responses to events based on their business and customer impact. Verify that if\n\nan alert is raised in response to an event, there is an associated process to run with a speciﬁcally\n\nidentiﬁed owner. Deﬁne in advance the personnel required to resolve an event and include\n\nescalation processes to engage additional personnel, as it becomes necessary, based on urgency\n\nand impact. Identify and engage individuals with the authority to make a decision on courses of\n\naction where there will be a business impact from an event response not previously addressed.\n\nCommunicate the operational status of workloads through dashboards and notiﬁcations that are\n\ntailored to the target audience (for example, customer, business, developers, operations) so that\n\nthey may take appropriate action, so that their expectations are managed, and so that they are\n\ninformed when normal operations resume.\n\nIn AWS, you can generate dashboard views of your metrics collected from workloads and natively\n\nfrom AWS. You can leverage CloudWatch or third-party applications to aggregate and present\n\n149",
      "content_length": 2981,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 155,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nbusiness, workload, and operations level views of operations activities. AWS provides workload\n\ninsights through logging capabilities including AWS X-Ray, CloudWatch, CloudTrail, and VPC Flow Logs to identify workload issues in support of root cause analysis and remediation.\n\nAll of the metrics you collect should be aligned to a business need and the outcomes they support.\n\nDevelop scripted responses to well-understood events and automate their performance in\n\nresponse to recognizing the event.\n\nTopics\n\nUtilizing workload observability\n\nUnderstanding operational health\n\nResponding to events\n\nUtilizing workload observability\n\nEnsure optimal workload health by leveraging observability. Utilize relevant metrics, logs, and\n\ntraces to gain a comprehensive view of your workload's performance and address issues eﬃciently.\n\nObservability allows you to focus on meaningful data and understand your workload's interactions\n\nand output. By concentrating on essential insights and eliminating unnecessary data, you maintain\n\na straightforward approach to understanding workload performance.\n\nIt's essential not only to collect data but also to interpret it correctly. Deﬁne clear baselines, set\n\nappropriate alert thresholds, and actively monitor for any deviations. A shift in a key metric,\n\nespecially when correlated with other data, can pinpoint speciﬁc problem areas.\n\nWith observability, you're better equipped to foresee and address potential challenges, ensuring\n\nthat your workload operates smoothly and meets business needs.\n\nAWS oﬀers speciﬁc tools like Amazon CloudWatch for monitoring and logging, and AWS X-Ray for\n\ndistributed tracing. These services integrate eﬀortlessly with various AWS resources, allowing for\n\neﬃcient data collection, setting up alerts based on predeﬁned thresholds, and presenting data\n\non dashboards for easy interpretation. By leveraging these insights, you can make well-informed,\n\ndata-driven decisions that align with your operational goals.\n\nBest practices\n\nOPS08-BP01 Analyze workload metrics\n\nUtilizing workload observability\n\n150",
      "content_length": 2139,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 156,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\nOPS08-BP04 Create actionable alerts\n\nOPS08-BP05 Create dashboards\n\nOPS08-BP01 Analyze workload metrics\n\nAfter implementing application telemetry, regularly analyze the collected metrics. While latency,\n\nrequests, errors, and capacity (or quotas) provide insights into system performance, it's vital to\n\nprioritize the review of business outcome metrics. This ensures you're making data-driven decisions\n\naligned with your business objectives.\n\nDesired outcome: Accurate insights into workload performance that drive data-informed decisions, ensuring alignment with business objectives.\n\nCommon anti-patterns:\n\nAnalyzing metrics in isolation without considering their impact on business outcomes.\n\nOver-reliance on technical metrics while sidelining business metrics.\n\nInfrequent review of metrics, missing out on real-time decision-making opportunities.\n\nBeneﬁts of establishing this best practice:\n\nEnhanced understanding of the correlation between technical performance and business\n\noutcomes.\n\nImproved decision-making process informed by real-time data.\n\nProactive identiﬁcation and mitigation of issues before they aﬀect business outcomes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nLeverage tools like Amazon CloudWatch to perform metric analysis. AWS services such as\n\nCloudWatch anomaly detection and Amazon DevOps Guru can be used to detect anomalies,\n\nespecially when static thresholds are unknown or when patterns of behavior are more suited for\n\nanomaly detection.\n\nOPS08-BP01 Analyze workload metrics\n\n151",
      "content_length": 1706,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 157,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\n1. Analyze and review: Regularly review and interpret your workload metrics.\n\na. Prioritize business outcome metrics over purely technical metrics.\n\nb. Understand the signiﬁcance of spikes, drops, or patterns in your data.\n\n2. Utilize Amazon CloudWatch: Use Amazon CloudWatch for a centralized view and deep-dive\n\nanalysis.\n\na. Conﬁgure CloudWatch dashboards to visualize your metrics and compare them over time.\n\nb. Use percentiles in CloudWatch to get a clear view of metric distribution, which can help in\n\ndeﬁning SLAs and understanding outliers.\n\nc. Set up CloudWatch anomaly detection to identify unusual patterns without relying on static\n\nthresholds.\n\nd. Implement CloudWatch cross-account observability to monitor and troubleshoot applications\n\nthat span multiple accounts within a Region.\n\ne. Use CloudWatch Metric Insights to query and analyze metric data across accounts and\n\nRegions, identifying trends and anomalies.\n\nf. Apply CloudWatch Metric Math to transform, aggregate, or perform calculations on your\n\nmetrics for deeper insights.\n\n3. Employ Amazon DevOps Guru: Incorporate Amazon DevOps Guru for its machine learning- enhanced anomaly detection to identify early signs of operational issues for your serverless applications and remediate them before they impact your customers.\n\n4. Optimize based on insights: Make informed decisions based on your metric analysis to adjust\n\nand improve your workloads.\n\nLevel of eﬀort for the Implementation Plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nRelated documents:\n\nOPS08-BP01 Analyze workload metrics\n\n152",
      "content_length": 1750,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 158,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nThe Wheel Blog - Emphasizing the importance of continually reviewing metrics\n\nPercentile are important\n\nUsing AWS Cost Anomaly Detection\n\nCloudWatch cross-account observability\n\nQuery your metrics with CloudWatch Metrics Insights\n\nRelated videos:\n\nEnable Cross-Account Observability in Amazon CloudWatch\n\nIntroduction to Amazon DevOps Guru\n\nContinuously Analyze Metrics using AWS Cost Anomaly Detection\n\nRelated examples:\n\nOne Observability Workshop\n\nGaining operation insights with AIOps using Amazon DevOps Guru\n\nOPS08-BP02 Analyze workload logs\n\nRegularly analyzing workload logs is essential for gaining a deeper understanding of the\n\noperational aspects of your application. By eﬃciently sifting through, visualizing, and interpreting\n\nlog data, you can continually optimize application performance and security.\n\nDesired outcome: Rich insights into application behavior and operations derived from thorough log analysis, ensuring proactive issue detection and mitigation.\n\nCommon anti-patterns:\n\nNeglecting the analysis of logs until a critical issue arises.\n\nNot using the full suite of tools available for log analysis, missing out on critical insights.\n\nSolely relying on manual review of logs without leveraging automation and querying\n\ncapabilities.\n\nBeneﬁts of establishing this best practice:\n\nOPS08-BP02 Analyze workload logs\n\n153",
      "content_length": 1407,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 159,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nProactive identiﬁcation of operational bottlenecks, security threats, and other potential issues.\n\nEﬃcient utilization of log data for continuous application optimization.\n\nEnhanced understanding of application behavior, aiding in debugging and troubleshooting.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nAmazon CloudWatch Logs is a powerful tool for log analysis. Integrated features like CloudWatch\n\nLogs Insights and Contributor Insights make the process of deriving meaningful information from\n\nlogs intuitive and eﬃcient.\n\nImplementation steps\n\n1. Set up CloudWatch Logs: Conﬁgure applications and services to send logs to CloudWatch Logs.\n\n2. Use log anomaly detection: Utilize Amazon CloudWatch Logs anomaly detection to\n\nautomatically identify and alert on unusual log patterns. This tool helps you proactively manage\n\nanomalies in your logs and detect potential issues early.\n\n3. Set up CloudWatch Logs Insights: Use CloudWatch Logs Insights to interactively search and\n\nanalyze your log data.\n\na. Craft queries to extract patterns, visualize log data, and derive actionable insights.\n\nb. Use CloudWatch Logs Insights pattern analysis to analyze and visualize frequent log patterns.\n\nThis feature helps you understand common operational trends and potential outliers in your\n\nlog data.\n\nc. Use CloudWatch Logs compare (diﬀ) to perform diﬀerential analysis between diﬀerent time\n\nperiods or across diﬀerent log groups. Use this capability to pinpoint changes and assess their\n\nimpacts on your system's performance or behavior.\n\n4. Monitor logs in real-time with Live Tail: Use Amazon CloudWatch Logs Live Tail to view log\n\ndata in real-time. You can actively monitor your application's operational activities as they occur,\n\nwhich provides immediate visibility into system performance and potential issues.\n\n5. Leverage Contributor Insights: Use CloudWatch Contributor Insights to identify top talkers in\n\nhigh cardinality dimensions like IP addresses or user-agents.\n\n6. Implement CloudWatch Logs metric ﬁlters: Conﬁgure CloudWatch Logs metric ﬁlters to convert log data into actionable metrics. This allows you to set alarms or further analyze patterns.\n\nOPS08-BP02 Analyze workload logs\n\n154",
      "content_length": 2320,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 160,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n7. Implement CloudWatch cross-account observability: Monitor and troubleshoot applications\n\nthat span multiple accounts within a Region.\n\n8. Regular review and reﬁnement: Periodically review your log analysis strategies to capture all\n\nrelevant information and continually optimize application performance.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS08-BP01 Analyze workload metrics\n\nRelated documents:\n\nAnalyzing Log Data with CloudWatch Logs Insights\n\nUsing CloudWatch Contributor Insights\n\nCreating and Managing CloudWatch Log Metric Filters\n\nRelated videos:\n\nAnalyze Log Data with CloudWatch Logs Insights\n\nUse CloudWatch Contributor Insights to Analyze High-Cardinality Data\n\nRelated examples:\n\nCloudWatch Logs Sample Queries\n\nOne Observability Workshop\n\nOPS08-BP03 Analyze workload traces\n\nAnalyzing trace data is crucial for achieving a comprehensive view of an application's operational\n\njourney. By visualizing and understanding the interactions between various components,\n\nperformance can be ﬁne-tuned, bottlenecks identiﬁed, and user experiences enhanced.\n\nOPS08-BP03 Analyze workload traces\n\n155",
      "content_length": 1312,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 161,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome: Achieve clear visibility into your application's distributed operations, enabling quicker issue resolution and an enhanced user experience.\n\nCommon anti-patterns:\n\nOverlooking trace data, relying solely on logs and metrics.\n\nNot correlating trace data with associated logs.\n\nIgnoring the metrics derived from traces, such as latency and fault rates.\n\nBeneﬁts of establishing this best practice:\n\nImprove troubleshooting and reduce mean time to resolution (MTTR).\n\nGain insights into dependencies and their impact.\n\nSwift identiﬁcation and rectiﬁcation of performance issues.\n\nLeveraging trace-derived metrics for informed decision-making.\n\nImproved user experiences through optimized component interactions.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nAWS X-Ray oﬀers a comprehensive suite for trace data analysis, providing a holistic view of\n\nservice interactions, monitoring user activities, and detecting performance issues. Features like\n\nServiceLens, X-Ray Insights, X-Ray Analytics, and Amazon DevOps Guru enhance the depth of\n\nactionable insights derived from trace data.\n\nImplementation steps\n\nThe following steps oﬀer a structured approach to eﬀectively implementing trace data analysis\n\nusing AWS services:\n\n1. Integrate AWS X-Ray: Ensure X-Ray is integrated with your applications to capture trace data.\n\n2. Analyze X-Ray metrics: Delve into metrics derived from X-Ray traces, such as latency, request\n\nrates, fault rates, and response time distributions, using the service map to monitor application\n\nhealth.\n\nOPS08-BP03 Analyze workload traces\n\n156",
      "content_length": 1696,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 162,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n3. Use ServiceLens: Leverage the ServiceLens map for enhanced observability of your services and applications. This allows for integrated viewing of traces, metrics, logs, alarms, and other health information.\n\n4. Enable X-Ray Insights:\n\na. Turn on X-Ray Insights for automated anomaly detection in traces.\n\nb. Examine insights to pinpoint patterns and ascertain root causes, such as increased fault rates\n\nor latencies.\n\nc. Consult the insights timeline for a chronological analysis of detected issues.\n\n5. Use X-Ray Analytics: X-Ray Analytics allows you to thoroughly explore trace data, pinpoint\n\npatterns, and extract insights.\n\n6. Use groups in X-Ray: Create groups in X-Ray to ﬁlter traces based on criteria such as high\n\nlatency, allowing for more targeted analysis.\n\n7. Incorporate Amazon DevOps Guru: Engage Amazon DevOps Guru to beneﬁt from machine\n\nlearning models pinpointing operational anomalies in traces.\n\n8. Use CloudWatch Synthetics: Use CloudWatch Synthetics to create canaries for continually\n\nmonitoring your endpoints and workﬂows. These canaries can integrate with X-Ray to provide\n\ntrace data for in-depth analysis of the applications being tested.\n\n9. Use Real User Monitoring (RUM): With AWS X-Ray and CloudWatch RUM, you can analyze and debug the request path starting from end users of your application through downstream AWS managed services. This helps you identify latency trends and errors that impact your end users.\n\n10.Correlate with logs: Correlate trace data with related logs within the X-Ray trace view for a granular perspective on application behavior. This allows you to view log events directly\n\nassociated with traced transactions.\n\n11.Implement CloudWatch cross-account observability: Monitor and troubleshoot applications\n\nthat span multiple accounts within a Region.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS08-BP01 Analyze workload metrics\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\n157",
      "content_length": 2076,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 163,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nUsing ServiceLens to Monitor Application Health\n\nExploring Trace Data with X-Ray Analytics\n\nDetecting Anomalies in Traces with X-Ray Insights\n\nContinuous Monitoring with CloudWatch Synthetics\n\nRelated videos:\n\nAnalyze and Debug Applications Using Amazon CloudWatch Synthetics & AWS X-Ray\n\nUse AWS X-Ray Insights\n\nRelated examples:\n\nOne Observability Workshop\n\nImplementing X-Ray with AWS Lambda\n\nCloudWatch Synthetics Canary Templates\n\nOPS08-BP04 Create actionable alerts\n\nPromptly detecting and responding to deviations in your application's behavior is crucial. Especially\n\nvital is recognizing when outcomes based on key performance indicators (KPIs) are at risk or when\n\nunexpected anomalies arise. Basing alerts on KPIs ensures that the signals you receive are directly\n\ntied to business or operational impact. This approach to actionable alerts promotes proactive\n\nresponses and helps maintain system performance and reliability.\n\nDesired outcome: Receive timely, relevant, and actionable alerts for rapid identiﬁcation and mitigation of potential issues, especially when KPI outcomes are at risk.\n\nCommon anti-patterns:\n\nSetting up too many non-critical alerts, leading to alert fatigue.\n\nNot prioritizing alerts based on KPIs, making it hard to understand the business impact of issues.\n\nNeglecting to address root causes, leading to repetitive alerts for the same issue.\n\nBeneﬁts of establishing this best practice:\n\nOPS08-BP04 Create actionable alerts\n\n158",
      "content_length": 1549,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 164,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nReduced alert fatigue by focusing on actionable and relevant alerts.\n\nImproved system uptime and reliability through proactive issue detection and mitigation.\n\nEnhanced team collaboration and quicker issue resolution by integrating with popular alerting\n\nand communication tools.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nTo create an eﬀective alerting mechanism, it's vital to use metrics, logs, and trace data that ﬂag\n\nwhen outcomes based on KPIs are at risk or anomalies are detected.\n\nImplementation steps\n\n1. Determine key performance indicators (KPIs): Identify your application's KPIs. Alerts should be\n\ntied to these KPIs to reﬂect the business impact accurately.\n\n2. Implement anomaly detection:\n\nUse Amazon CloudWatch anomaly detection: Set up Amazon CloudWatch anomaly detection to automatically detect unusual patterns, which helps you only generate alerts for genuine anomalies.\n\nUse AWS X-Ray Insights:\n\na. Set up X-Ray Insights to detect anomalies in trace data.\n\nb. Conﬁgure notiﬁcations for X-Ray Insights to be alerted on detected issues.\n\nIntegrate with Amazon DevOps Guru:\n\na. Leverage Amazon DevOps Guru for its machine learning capabilities in detecting\n\noperational anomalies with existing data.\n\nb. Navigate to the notiﬁcation settings in DevOps Guru to set up anomaly alerts.\n\n3. Implement actionable alerts: Design alerts that provide adequate information for immediate\n\naction.\n\n1. Monitor AWS Health events with Amazon EventBridge rules, or integrate programatically with\n\nthe AWS Health API to automate actions when you receive AWS Health events. These can be general actions, such as sending all planned lifecycle event messages to a chat interface, or\n\nspeciﬁc actions, such as the initiation of a workﬂow in an IT service management tool.\n\nOPS08-BP04 Create actionable alerts\n\n159",
      "content_length": 1930,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 165,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Reduce alert fatigue: Minimize non-critical alerts. When teams are overwhelmed with numerous\n\ninsigniﬁcant alerts, they can lose oversight of critical issues, which diminishes the overall eﬀectiveness of the alert mechanism.\n\n5. Set up composite alarms: Use Amazon CloudWatch composite alarms to consolidate multiple\n\nalarms.\n\n6. Integrate with alert tools: Incorporate tools like Ops Genie and PagerDuty.\n\n7. Engage Amazon Q Developer in chat applications: Integrate Amazon Q Developer in chat\n\napplications to relay alerts to Amazon Chime, Microsoft Teams, and Slack.\n\n8. Alert based on logs: Use log metric ﬁlters in CloudWatch to create alarms based on speciﬁc log\n\nevents.\n\n9. Review and iterate: Regularly revisit and reﬁne alert conﬁgurations.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS04-BP03 Implement user experience telemetry\n\nOPS04-BP04 Implement dependency telemetry\n\nOPS04-BP05 Implement distributed tracing\n\nOPS08-BP01 Analyze workload metrics\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\nRelated documents:\n\nUsing Amazon CloudWatch alarms\n\nCreate a composite alarm\n\nCreate a CloudWatch alarm based on anomaly detection\n\nDevOps Guru Notiﬁcations\n\nX-ray insights notiﬁcations\n\nOPS08-BP04 Create actionable alerts\n\n160",
      "content_length": 1465,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 166,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nMonitor, operate, and troubleshoot your AWS resources with interactive ChatOps\n\nAmazon CloudWatch Integration Guide | PagerDuty\n\nIntegrate Opsgenie with Amazon CloudWatch\n\nRelated videos:\n\nCreate Composite Alarms in Amazon CloudWatch\n\nAmazon Q Developer in chat applications Overview\n\nAWS On Air ft. Mutative Commands in Amazon Q Developer in chat applications\n\nRelated examples:\n\nAlarms, incident management, and remediation in the cloud with Amazon CloudWatch\n\nTutorial: Creating an Amazon EventBridge rule that sends notiﬁcations to Amazon Q Developer\n\nin chat applications\n\nOne Observability Workshop\n\nOPS08-BP05 Create dashboards\n\nDashboards are the human-centric view into the telemetry data of your workloads. While they\n\nprovide a vital visual interface, they should not replace alerting mechanisms, but complement\n\nthem. When crafted with care, not only can they oﬀer rapid insights into system health and\n\nperformance, but they can also present stakeholders with real-time information on business\n\noutcomes and the impact of issues.\n\nDesired outcome:\n\nClear, actionable insights into system and business health using visual representations.\n\nCommon anti-patterns:\n\nOvercomplicating dashboards with too many metrics.\n\nRelying on dashboards without alerts for anomaly detection.\n\nNot updating dashboards as workloads evolve.\n\nBeneﬁts of this best practice:\n\nOPS08-BP05 Create dashboards\n\n161",
      "content_length": 1462,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 167,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImmediate visibility into critical system metrics and KPIs.\n\nEnhanced stakeholder communication and understanding.\n\nRapid insight into the impact of operational issues.\n\nLevel of risk if this best practice isn't established: Medium\n\nImplementation guidance\n\nBusiness-centric dashboards\n\nDashboards tailored to business KPIs engage a wider array of stakeholders. While these individuals\n\nmight not be interested in system metrics, they are keen on understanding the business\n\nimplications of these numbers. A business-centric dashboard ensures that all technical and\n\noperational metrics being monitored and analyzed are in sync with overarching business goals.\n\nThis alignment provides clarity, ensuring everyone is on the same page regarding what's essential\n\nand what's not. Additionally, dashboards that highlight business KPIs tend to be more actionable.\n\nStakeholders can quickly understand the health of operations, areas that need attention, and the\n\npotential impact on business outcomes.\n\nWith this in mind, when creating your dashboards, ensure that there's a balance between technical\n\nmetrics and business KPIs. Both are vital, but they cater to diﬀerent audiences. Ideally, you should\n\nhave dashboards that provide a holistic view of the system's health and performance while also\n\nemphasizing key business outcomes and their implications.\n\nAmazon CloudWatch Dashboards are customizable home pages in the CloudWatch console that\n\nyou can use to monitor your resources in a single view, even those resources that are spread across\n\ndiﬀerent AWS Regions and accounts.\n\nImplementation steps\n\n1. Create a basic dashboard: Create a new dashboard in CloudWatch, giving it a descriptive name.\n\n2. Use Markdown widgets: Before diving into the metrics, use Markdown widgets to add textual context at the top of your dashboard. This should explain what the dashboard covers, the signiﬁcance of the represented metrics, and can also contain links to other dashboards and\n\ntroubleshooting tools.\n\n3. Create dashboard variables: Incorporate dashboard variables where appropriate to allow for\n\ndynamic and ﬂexible dashboard views.\n\nOPS08-BP05 Create dashboards\n\n162",
      "content_length": 2227,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 168,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n4. Create metrics widgets: Add metric widgets to visualize various metrics your application emits,\n\ntailoring these widgets to eﬀectively represent system health and business outcomes.\n\n5. Log Insights queries: Utilize CloudWatch Log Insights to derive actionable metrics from your\n\nlogs and display these insights on your dashboard.\n\n6. Set up alarms: Integrate CloudWatch Alarms into your dashboard for a quick view of any metrics\n\nbreaching their thresholds.\n\n7. Use Contributor Insights: Incorporate CloudWatch Contributor Insights to analyze high- cardinality ﬁelds and get a clearer understanding of your resource's top contributors.\n\n8. Design custom widgets: For speciﬁc needs not met by standard widgets, consider creating custom widgets. These can pull from various data sources or represent data in unique ways.\n\n9. Use AWS Health: AWS Health is the authoritative source of information about the health of your\n\nAWS Cloud resources. Use AWS Health Dashboard out of the box, or use AWS Health data in\n\nyour own dashboards and tools so you have the right information available to make informed decisions.\n\n10.Iterate and reﬁne: As your application evolves, regularly revisit your dashboard to ensure its\n\nrelevance.\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS08-BP01 Analyze workload metrics\n\nOPS08-BP02 Analyze workload logs\n\nOPS08-BP03 Analyze workload traces\n\nOPS08-BP04 Create actionable alerts\n\nRelated documents:\n\nBuilding Dashboards for Operational Visibility\n\nUsing Amazon CloudWatch Dashboards\n\nRelated videos:\n\nCreate Cross Account & Cross Region CloudWatch Dashboards\n\nOPS08-BP05 Create dashboards\n\n163",
      "content_length": 1730,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 169,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS re:Invent 2021 - Gain enterprise visibility with AWS Cloud operation dashboards)\n\nRelated examples:\n\nOne Observability Workshop\n\nApplication Monitoring with Amazon CloudWatch\n\nAWS Health Events Intelligence Dashboards and Insights\n\nVisualize AWS Health events using Amazon Managed Grafana\n\nUnderstanding operational health\n\nDeﬁne, capture, and analyze operations metrics to gain visibility to the activities of operations teams so that you can take appropriate action.\n\nYour organization should be able to understand the health of your operations easily. You will want\n\nto deﬁne the business goals of your operations teams, identify key performance indicators that\n\nreﬂect those goals. Afterwards, develop and use metrics based on operations outcomes to gain\n\nuseful insights. You should use these metrics to implement dashboards and reports with business\n\nand technical viewpoints that will help leaders and stakeholders make informed decisions.\n\nAWS makes it easier to bring together and analyze your operations logs so that you can generate\n\nmetrics, know the status of your operations, and gain insight from operations over time.\n\nBest practices\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nObtain goals and KPIs that deﬁne operations success from your organization and determine that\n\nmetrics reﬂect these. Set baselines as a point of reference and reevaluate regularly. Develop\n\nmechanisms to collect these metrics from teams for evaluation. The DevOps Research and\n\nAssessment (DORA) metrics provide a popular method to measure progress towards DevOps\n\npractices of software delivery.\n\nUnderstanding operational health\n\n164",
      "content_length": 1914,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 170,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome:\n\nThe organization publishes and shares the goals and KPIs for the operations teams.\n\nYou establish metrics that reﬂect these KPIs. Examples may include:\n\nTicket queue depth or average age of ticket\n\nTicket count grouped by type of issue\n\nTime spent working issues with or without a standardized operating procedure (SOP)\n\nAmount of time spent recovering from a failed code push\n\nCall volume\n\nCommon anti-patterns:\n\nDeployment deadlines are missed because developers are pulled away to perform\n\ntroubleshooting tasks. Development teams argue for more personnel, but cannot quantify how\n\nmany they need because the time taken away cannot be measured.\n\nA Tier 1 desk was set up to handle user calls. Over time, more workloads were added, but no\n\nheadcount was allocated to the Tier 1 desk. Customer satisfaction suﬀers as call times increase\n\nand issues go longer without resolution, but management sees no indicators of such, preventing\n\nany action.\n\nA problematic workload has been handed oﬀ to a separate operations team for upkeep. Unlike\n\nother workloads, this new one was not supplied with proper documentation and runbooks. As\n\nsuch, teams spend longer troubleshooting and addressing failures. However, there are no metrics\n\ndocumenting this, which makes accountability diﬃcult.\n\nBeneﬁts of establishing this best practice: Where workload monitoring shows the state of our applications and services, monitoring operations teams provides owners insight into\n\nchanges among the consumers of those workloads, such as shifting business needs. Measure the\n\neﬀectiveness of these teams and evaluate them against business goals by creating metrics that can\n\nreﬂect the state of operations. Metrics can highlight support issues or identify when drifts occur\n\naway from a service level target.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\n165",
      "content_length": 2004,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 171,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nSchedule time with business leaders and stakeholders to determine what the overall goals of\n\nthe service will be. Determine what the tasks of various operations teams should be and what\n\nchallenges they could be approached with. Using these, brainstorm key performance indicators\n\n(KPIs) that might reﬂect these operations goals. These might be customer satisfaction, time from\n\nfeature conception to deployment, average issue resolution time, or cost eﬃciencies.\n\nWorking from KPIs, identify the metrics and sources of data that might reﬂect these goals best.\n\nCustomer satisfaction may be an combination of various metrics such as call wait or response\n\ntimes, satisfaction scores, and types of issues raised. Deployment times may be the sum of time\n\nneeded for testing and deployment, plus any post-deployment ﬁxes that needed to be added.\n\nStatistics showing the time spent on diﬀerent types of issues (or the counts of those issues) can\n\nprovide a window into where targeted eﬀort is needed.\n\nResources\n\nRelated documents:\n\nQuick Suite - Using KPIs\n\nAmazon CloudWatch - Using Metrics\n\nBuilding Dashboards\n\nHow to track your cost optimization KPIs with KPI Dashboard\n\nAWS DevOps Guidance\n\nRelated examples:\n\nMonitor the performance of your software delivery using native AWS monitoring and\n\nobservability tools\n\nBalance deployment speed and stability with DORA metrics\n\nExample MLOps operational metrics in the ﬁnancial services industry\n\nHow to track your cost optimization KPIs with the KPI Dashboard\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\n166",
      "content_length": 1658,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 172,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS09-BP02 Communicate status and trends to ensure visibility into\n\noperation\n\nKnowing the state of your operations and its trending direction is necessary to identify when\n\noutcomes may be at risk, whether or not added work can be supported, or the eﬀects that\n\nchanges have had to your teams. During operations events, having status pages that users and\n\noperations teams can refer to for information can reduce pressure on communication channels and\n\ndisseminate information proactively.\n\nDesired outcome:\n\nOperations leaders have insight at a glance to see what sort of call volumes their teams are\n\noperating under and what eﬀorts may be under way, such as deployments.\n\nAlerts are disseminated to stakeholders and user communities when impacts to normal\n\noperations occur.\n\nOrganization leadership and stakeholders can check a status page in response to an alert or\n\nimpact, and obtain information surrounding an operational event, such as points of contact,\n\nticket information, and estimated recovery times.\n\nReports are made available to leadership and other stakeholders to show operations statistics\n\nsuch as call volumes over a period of time, user satisfaction scores, numbers of outstanding\n\ntickets and their ages.\n\nCommon anti-patterns:\n\nA workload goes down, leaving a service unavailable. Call volumes spike as users request to\n\nknow what's going on. Managers add to the volume requesting to know who's working an issue.\n\nVarious operations teams duplicate eﬀorts in trying to investigate.\n\nA desire for a new capability leads to several personnel being reassigned to an engineering\n\neﬀort. No backﬁll is provided, and issue resolution times spike. This information is not captured,\n\nand only after several weeks and dissatisﬁed user feedback does leadership become aware of the\n\nissue.\n\nBeneﬁts of establishing this best practice: During operational events where the business is impacted, much time and energy can be wasted querying information from various teams\n\nattempting to understand the situation. By establishing widely-disseminated status pages and\n\ndashboards, stakeholders can quickly obtain information such as whether or not an issue was\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation\n\n167",
      "content_length": 2315,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 173,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\ndetected, who has lead on the issue, or when a return to normal operations may be expected. This\n\nfrees team members from spending too much time communicating status to others and more time addressing issues.\n\nIn addition, dashboards and reports can provide insights to decision-makers and stakeholders to\n\nsee how operations teams are able to respond to business needs and how their resources are being\n\nallocated. This is crucial for determining if adequate resources are in place to support the business.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nBuild dashboards that show the current key metrics for your ops teams, and make them readily\n\naccessible both to operations leaders and management.\n\nBuild status pages that can be updated quickly to show when an incident or event is unfolding,\n\nwho has ownership and who is coordinating the response. Share any steps or workarounds that\n\nusers should consider on this page, and disseminate the location widely. Encourage users to check\n\nthis location ﬁrst when confronted with an unknown issue.\n\nCollect and provide reports that show the health of operations over time, and distribute this to\n\nleaders and decision makers to illustrate the work of operations along with challenges and needs.\n\nShare between teams these metrics and reports that best reﬂect goals and KPIs and where they\n\nhave been inﬂuential in driving change. Dedicate time to these activities to elevate the importance\n\nof operations inside of and between teams.\n\nUse AWS Health alongside your own dashboards, or integrate AWS Health events into them, so\n\nthat your teams can correlate application issues to AWS service status.\n\nResources\n\nRelated best practices:\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nRelated documents:\n\nMeasure Progress\n\nBuilding dashboards for operation visibility\n\nOPS09-BP02 Communicate status and trends to ensure visibility into operation\n\n168",
      "content_length": 2026,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 174,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated examples:\n\nData Operations\n\nHow to track your cost optimization KPIs with KPI Dashboard\n\nThe Importance of Key Performance Indicators (KPIs) for Large-Scale Cloud Migrations\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nSetting aside dedicated time and resources for reviewing the state of operations ensures that\n\nserving the day-to-day line of business remains a priority. Pull together operations leaders and\n\nstakeholders to regularly review metrics, reaﬃrm or modify goals and objectives, and prioritize\n\nimprovements.\n\nDesired outcome:\n\nOperations leaders and staﬀ regularly meet to review metrics over a given reporting period.\n\nChallenges are communicated, wins are celebrated, and lessons learned are shared.\n\nStakeholders and business leaders are regularly briefed on the state of operations and solicited\n\nfor input regarding goals, KPIs, and future initiatives. Tradeoﬀs between service delivery,\n\noperations, and maintenance are discussed and placed into context.\n\nCommon anti-patterns:\n\nA new product is launched, but the Tier 1 and Tier 2 operations teams are not adequately trained\n\nto support or given additional staﬀ. Metrics that show the decrease in ticket resolution times\n\nand increase in incident volumes are not seen by leaders. Action is taken weeks later when\n\nsubscription numbers start to fall as discontent users move oﬀ the platform.\n\nA manual process for performing maintenance on a workload has been in place for a long time.\n\nWhile a desire to automate has been present, this was a low priority given the low importance\n\nof the system. Over time however, the system has grown in importance and now these manual\n\nprocesses consume a majority of operations' time. No resources are scheduled for providing\n\nincreased tooling to operations, leading to staﬀ burnout as workloads increase. Leadership\n\nbecomes aware once it's reported that staﬀ are leaving for other competitors.\n\nBeneﬁts of establishing this best practice: In some organizations, it can become a challenge to allocate the same time and attention that is aﬀorded to service delivery and new products or\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\n169",
      "content_length": 2257,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 175,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\noﬀerings. When this occurs, the line of business can suﬀer as the level of service expected slowly\n\ndeteriorates. This is because operations does not change and evolve with the growing business, and can soon be left behind. Without regular review into the insights operations collects, the risk\n\nto the business may become visible only when it's too late. By allocating time to review metrics\n\nand procedures both among the operations staﬀ and with leadership, the crucial role operations\n\nplays remains visible, and risks can be identiﬁed long before they reach critical levels. Operations\n\nteams get better insight into impending business changes and initiatives, allowing for proactive\n\neﬀorts to be undertaken. Leadership visibility into operations metrics showcases the role that these\n\nteams play in customer satisfaction, both internal and external, and let them better weigh choices\n\nfor priorities, or ensure that operations has the time and resources to change and evolve with new\n\nbusiness and workload initiatives.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nDedicate time to review operations metrics between stakeholders and operations teams and\n\nreview report data. Place these reports in the contexts of the organizations goals and objectives to\n\ndetermine if they're being met. Identify sources of ambiguity where goals are not clear, or where\n\nthere may be conﬂicts between what is asked for and what is given.\n\nIdentify where time, people, and tools can aid in operations outcomes. Determine which KPIs this\n\nwould impact and what targets for success should be. Revisit regularly to ensure operations is\n\nresourced suﬃciently to support the line of business.\n\nResources\n\nRelated documents:\n\nAmazon Athena\n\nAmazon CloudWatch metrics and dimensions reference\n\nAmazon Quick Suite\n\nAWS Glue\n\nAWS Glue Data Catalog\n\nCollect metrics and logs from Amazon EC2 instances and on-premises servers with the Amazon\n\nCloudWatch Agent\n\nUsing Amazon CloudWatch metrics\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\n170",
      "content_length": 2158,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 176,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResponding to events\n\nYou should anticipate operational events, both planned (for example, sales promotions,\n\ndeployments, and failure tests) and unplanned (for example, surges in utilization and component\n\nfailures). You should use your existing runbooks and playbooks to deliver consistent results when\n\nyou respond to alerts. Deﬁned alerts should be owned by a role or a team that is accountable\n\nfor the response and escalations. You will also want to know the business impact of your system\n\ncomponents and use this to target eﬀorts when needed. You should perform a root cause analysis\n\n(RCA) after events, and then prevent recurrence of failures or document workarounds.\n\nAWS simpliﬁes your event response by providing tools supporting all aspects of your workload and\n\noperations as code. These tools allow you to script responses to operations events and start their\n\ninitiation in response to monitoring data.\n\nIn AWS, you can improve recovery time by replacing failed components with known good versions,\n\nrather than trying to repair them. You can then carry out analysis on the failed resource out of\n\nband.\n\nBest practices\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nOPS10-BP02 Have a process per alert\n\nOPS10-BP03 Prioritize operational events based on business impact\n\nOPS10-BP04 Deﬁne escalation paths\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\nOPS10-BP06 Communicate status through dashboards\n\nOPS10-BP07 Automate responses to events\n\nOPS10-BP01 Use a process for event, incident, and problem\n\nmanagement\n\nThe ability to eﬃciently manage events, incidents, and problems is key to maintaining workload\n\nhealth and performance. It's crucial to recognize and understand the diﬀerences between these\n\nelements to develop an eﬀective response and resolution strategy. Establishing and following a\n\nwell-deﬁned process for each aspect helps your team swiftly and eﬀectively handle any operational\n\nchallenges that arise.\n\nResponding to events\n\n171",
      "content_length": 2084,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 177,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome: Your organization eﬀectively manages operational events, incidents, and problems through well-documented and centrally stored processes. These processes are consistently updated to reﬂect changes, streamlining handling and maintaining high service\n\nreliability and workload performance.\n\nCommon anti-patterns:\n\nYou reactively, rather than proactively, respond to events.\n\nInconsistent approaches are taken to diﬀerent types of events or incidents.\n\nYour organization does not analyze and learn from incidents to prevent future occurrences.\n\nBeneﬁts of establishing this best practice:\n\nStreamlined and standardized response processes.\n\nReduced impact of incidents on services and customers.\n\nExpedited issue resolution.\n\nContinuous improvement in operational processes.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplementing this best practice means you are tracking workload events. You have processes to\n\nhandle incidents and problems. The processes are documented, shared, and updated frequently.\n\nProblems are identiﬁed, prioritized, and ﬁxed.\n\nUnderstanding events, incidents, and problems\n\nEvents: An event is an observation of an action, occurrence, or change of state. Events can be\n\nplanned or unplanned and they can originate internally or externally to the workload.\n\nIncidents: Incidents are events that require a response, like unplanned interruptions or\n\ndegradations of service quality. They represent disruptions that need immediate attention to\n\nrestore normal workload operation.\n\nProblems: Problems are the underlying causes of one or more incidents. Identifying and\n\nresolving problems involves digging deeper into the incidents to prevent future occurrences.\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n172",
      "content_length": 1888,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 178,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation steps\n\nEvents\n\n1. Monitor events:\n\nImplement observability and utilize workload observability.\n\nMonitor actions taken by a user, role, or an AWS service are recorded as events in AWS\n\nCloudTrail.\n\nRespond to operational changes in your applications in real time with Amazon EventBridge.\n\nContinually assess, monitor, and record resource conﬁguration changes with AWS Conﬁg.\n\n2. Create processes:\n\nDevelop a process to assess which events are signiﬁcant and require monitoring. This involves\n\nsetting thresholds and parameters for normal and abnormal activities.\n\nDetermine criteria escalating an event to an incident. This could be based on the severity,\n\nimpact on users, or deviation from expected behavior.\n\nRegularly review the event monitoring and response processes. This includes analyzing past\n\nincidents, adjusting thresholds, and reﬁning alerting mechanisms.\n\nIncidents\n\n1. Respond to incidents:\n\nUse insights from observability tools to quickly identify and respond to incidents.\n\nImplement AWS Systems Manager Ops Center to aggregate, organize, and prioritize\n\noperational items and incidents.\n\nUse services like Amazon CloudWatch and AWS X-Ray for deeper analysis and\n\ntroubleshooting.\n\nConsider AWS Managed Services (AMS) for enhanced incident management, leveraging its\n\nproactive, preventative, and detective capabilities. AMS extends operational support with\n\nservices like monitoring, incident detection and response, and security management.\n\nEnterprise Support customers can use AWS Incident Detection and Response, which provides\n\ncontinual proactive monitoring and incident management for production workloads.\n\n2. Create an incident management process:\n\nEstablish a structured incident management process, including clear roles, communication\n\nprotocols, and steps for resolution.\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n173",
      "content_length": 1956,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 179,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIntegrate incident management with tools like Amazon Q Developer in chat applications for\n\neﬃcient response and coordination.\n\nCategorize incidents by severity, with predeﬁned incident response plans for each category.\n\n3. Learn and improve:\n\nConduct post-incident analysis to understand root causes and resolution eﬀectiveness.\n\nContinually update and improve response plans based on reviews and evolving practices.\n\nDocument and share lessons learned across teams to enhance operational resilience.\n\nEnterprise Support customers can request the Incident Management Workshop from their\n\nTechnical Account Manager. This guided workshop tests your existing incident response plan\n\nand helps you identify areas for improvement.\n\nProblems\n\n1. Identify problems:\n\nUse data from previous incidents to identify recurring patterns that may indicate deeper\n\nsystemic issues.\n\nLeverage tools like AWS CloudTrail and Amazon CloudWatch to analyze trends and uncover\n\nunderlying problems.\n\nEngage cross-functional teams, including operations, development, and business units, to gain\n\ndiverse perspectives on the root causes.\n\n2. Create a problem management process:\n\nDevelop a structured process for problem management, focusing on long-term solutions\n\nrather than quick ﬁxes.\n\nIncorporate root cause analysis (RCA) techniques to investigate and understand the underlying\n\ncauses of incidents.\n\nUpdate operational policies, procedures, and infrastructure based on ﬁndings to prevent\n\nrecurrence.\n\n3. Continue to improve:\n\nFoster a culture of constant learning and improvement, encouraging teams to proactively\n\nidentify and address potential problems.\n\nRegularly review and revise problem management processes and tools to align with evolving\n\nbusiness and technology landscapes.\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n174",
      "content_length": 1906,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 180,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nShare insights and best practices across the organization to build a more resilient and eﬃcient\n\noperational environment.\n\n4. Engage AWS Support:\n\nUse AWS support resources, such as AWS Trusted Advisor, for proactive guidance and\n\noptimization recommendations.\n\nEnterprise Support customers can access specialized programs like AWS Countdown for\n\nsupport during critical events.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS04-BP02 Implement application telemetry\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS07-BP04 Use playbooks to investigate issues\n\nOPS08-BP01 Analyze workload metrics\n\nOPS11-BP02 Perform post-incident analysis\n\nRelated documents:\n\nAWS Security Incident Response Guide\n\nAWS Incident Detection and Response\n\nAWS Cloud Adoption Framework: Operations Perspective - Incident and problem management\n\nIncident Management in the Age of DevOps and SRE\n\nPagerDuty - What is Incident Management?\n\nRelated videos:\n\nTop incident response tips from AWS\n\nAWS re:Invent 2022 - The Amazon Builders' Library: 25 yrs of Amazon operational excellence\n\nAWS re:Invent 2022 - AWS Incident Detection and Response (SUP201)\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\n175",
      "content_length": 1359,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 181,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nIntroducing Incident Manager from AWS Systems Manager\n\nRelated examples:\n\nAWS Proactive Services – Incident Management Workshop\n\nHow to Automate Incident Response with PagerDuty and AWS Systems Manager Incident\n\nManager\n\nEngage Incident Responders with the On-Call Schedules in AWS Systems Manager Incident\n\nManager\n\nImprove the Visibility and Collaboration during Incident Handling in AWS Systems Manager\n\nIncident Manager\n\nIncident reports and service requests in AMS\n\nRelated services:\n\nAmazon EventBridge\n\nOPS10-BP02 Have a process per alert\n\nEstablishing a clear and deﬁned process for each alert in your system is essential for eﬀective and\n\neﬃcient incident management. This practice ensures that every alert leads to a speciﬁc, actionable\n\nresponse, improving the reliability and responsiveness of your operations.\n\nDesired outcome: Every alert initiates a speciﬁc, well-deﬁned response plan. Where possible, responses are automated, with clear ownership and a deﬁned escalation path. Alerts are linked\n\nto an up-to-date knowledge base so that any operator can respond consistently and eﬀectively.\n\nResponses are quick and uniform across the board, enhancing operational eﬃciency and reliability.\n\nCommon anti-patterns:\n\nAlerts have no predeﬁned response process, leading to makeshift and delayed resolutions.\n\nAlert overload causes important alerts to be overlooked.\n\nAlerts are inconsistently handled due to lack of clear ownership and responsibility.\n\nBeneﬁts of establishing this best practice:\n\nOPS10-BP02 Have a process per alert\n\n176",
      "content_length": 1611,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 182,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nReduced alert fatigue by only raising actionable alerts.\n\nDecreased mean time to resolution (MTTR) for operational issues.\n\nDecreased mean time to investigate (MTTI), which helps reduce MTTR.\n\nEnhanced ability to scale operational responses.\n\nImproved consistency and reliability in handling operational events.\n\nFor example, you have a deﬁned process for AWS Health events for critical accounts, including\n\napplication alarms, operational issues, and planned lifecycle events (like updating Amazon EKS\n\nversions before clusters are auto-updated), and you provide the capability for your teams to\n\nactively monitor, communicate, and respond to these events. These actions help you prevent\n\nservice disruptions caused by AWS-side changes or mitigate them faster when unexpected issues\n\noccur.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nHaving a process per alert involves establishing a clear response plan for each alert, automating\n\nresponses where possible, and continually reﬁning these processes based on operational feedback\n\nand evolving requirements.\n\nImplementation steps\n\nThe following diagram illustrates the incident management workﬂow within AWS Systems\n\nManager Incident Manager. It is designed to respond swiftly to operational issues by automatically\n\ncreating incidents in response to speciﬁc events from Amazon CloudWatch or Amazon EventBridge.\n\nWhen an incident is created, either automatically or manually, Incident Manager centralizes\n\nthe management of the incident, organizes relevant AWS resource information, and initiates\n\npredeﬁned response plans. This includes running Systems Manager Automation runbooks for\n\nimmediate action, as well as creating a parent operational work item in OpsCenter to track related\n\ntasks and analyses. This streamlined process speeds up and coordinates incident response across\n\nyour AWS environment.\n\nOPS10-BP02 Have a process per alert\n\n177",
      "content_length": 2013,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 183,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\n1. Use composite alarms: Create composite alarms in CloudWatch to group related alarms,\n\nreducing noise and allowing for more meaningful responses.\n\n2. Stay informed with AWS Health: AWS Health is the authoritative source of information about the health of your AWS Cloud resources. Use AWS Health to visualize and get notiﬁed of any\n\nOPS10-BP02 Have a process per alert\n\n178",
      "content_length": 438,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 184,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\ncurrent service events and upcoming changes, such as planned lifecycle events, so you can take\n\nsteps to mitigate impacts.\n\na. Create purpose-ﬁt AWS Health event notiﬁcations to e-mail and chat channels through AWS\n\nUser Notiﬁcations, and integrate programatically with your monitoring and alerting tools\n\nthrough Amazon EventBridge or the AWS Health API.\n\nb. Plan and track progress on health events that require action by integrating with change\n\nmanagement or ITSM tools (like Jira or ServiceNow) that you may already use through\n\nAmazon EventBridge or the AWS Health API.\n\nc. If you use AWS Organizations, enable organization view for AWS Health to aggregate AWS\n\nHealth events across accounts.\n\n3. Integrate Amazon CloudWatch alarms with Incident Manager: Conﬁgure CloudWatch alarms\n\nto automatically create incidents in AWS Systems Manager Incident Manager.\n\n4. Integrate Amazon EventBridge with Incident Manager: Create EventBridge rules to react to\n\nevents and create incidents using deﬁned response plans.\n\n5. Prepare for incidents in Incident Manager:\n\nEstablish detailed response plans in Incident Manager for each type of alert.\n\nEstablish chat channels through Amazon Q Developer in chat applications connected to\n\nresponse plans in Incident Manager, facilitating real-time communication during incidents\n\nacross platforms like Slack, Microsoft Teams, and Amazon Chime.\n\nIncorporate Systems Manager Automation runbooks within Incident Manager to drive\n\nautomated responses to incidents.\n\nResources\n\nRelated best practices:\n\nOPS04-BP01 Identify key performance indicators\n\nOPS08-BP04 Create actionable alerts\n\nRelated documents:\n\nAWS Cloud Adoption Framework: Operations Perspective - Incident and problem management\n\nUsing Amazon CloudWatch alarms\n\nSetting up AWS Systems Manager Incident Manager\n\nOPS10-BP02 Have a process per alert\n\n179",
      "content_length": 1914,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 185,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nPreparing for incidents in Incident Manager\n\nRelated videos:\n\nTop incident response tips from AWS\n\nre:Invent 2023 | Manage resource lifecycle events at scale with AWS Health\n\nRelated examples:\n\nAWS Workshops - AWS Systems Manager Incident Manager - Automate incident response to\n\nsecurity events\n\nOPS10-BP03 Prioritize operational events based on business impact\n\nResponding promptly to operational events is critical, but not all events are equal. When you\n\nprioritize based on business impact, you also prioritize addressing events with the potential\n\nfor signiﬁcant consequences, such as safety, ﬁnancial loss, regulatory violations, or damage to\n\nreputation.\n\nDesired outcome: Responses to operational events are prioritized based on potential impact to business operations and objectives. This makes the responses eﬃcient and eﬀective.\n\nCommon anti-patterns:\n\nEvery event is treated with the same level of urgency, leading to confusion and delays in\n\naddressing critical issues.\n\nYou fail to distinguish between high and low impact events, leading to misallocation of\n\nresources.\n\nYour organization lacks a clear prioritization framework, resulting in inconsistent responses to\n\noperational events.\n\nEvents are prioritized based on the order they are reported, rather than their impact on business\n\noutcomes.\n\nBeneﬁts of establishing this best practice:\n\nEnsures critical business functions receive attention ﬁrst, minimizing potential damage.\n\nImproves resource allocation during multiple concurrent events.\n\nOPS10-BP03 Prioritize operational events based on business impact\n\n180",
      "content_length": 1648,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 186,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEnhances the organization's ability to maintain trust and meet regulatory requirements.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nWhen faced with multiple operational events, a structured approach to prioritization based on\n\nimpact and urgency is essential. This approach helps you make informed decisions, direct eﬀorts\n\nwhere they're needed most, and mitigate the risk to business continuity.\n\nImplementation steps\n\n1. Assess impact: Develop a classiﬁcation system to evaluate the severity of events in terms of their potential impact on business operations and objectives. The following example shows impact categories:\n\nImpact level\n\nDescription\n\nHigh\n\nAﬀects many staﬀ or customers, high ﬁnancial impact, high reputational damage,\n\nor injury.\n\nMedium\n\nAﬀects a groups of staﬀ or customers, moderate ﬁnancial impact, or moderate\n\nreputational damage.\n\nLow\n\nAﬀects individual staﬀ or customers, low ﬁnancial impact, or low reputational damage.\n\n2. Assess urgency: Deﬁne urgency levels for how quickly an event needs a response, considering\n\nfactors such as safety, ﬁnancial implications, and service-level agreements (SLAs). The following\n\nexample demonstrates urgency categories:\n\nUrgency level\n\nDescription\n\nHigh\n\nExponentially increasing damage, time-sens itive work impacted, imminent escalation, or\n\nVIP users or groups aﬀected.\n\nOPS10-BP03 Prioritize operational events based on business impact\n\n181",
      "content_length": 1525,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 187,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUrgency level\n\nDescription\n\nMedium\n\nDamage increases over time, or single VIP user or group aﬀected.\n\nLow\n\nMarginal damage increase over time, or non- time-sensitive work impacted.\n\n3. Create a prioritization matrix:\n\nUse a matrix to cross-reference impact and urgency, assigning priority levels to diﬀerent\n\ncombinations.\n\nMake the matrix accessible and understood by all team members responsible for operational\n\nevent responses.\n\nThe following example matrix displays incident severity according to urgency and impact:\n\nUrgency and impact\n\nHigh\n\nMedium\n\nLow\n\nHigh\n\nCritical\n\nUrgent\n\nHigh\n\nMedium\n\nUrgent\n\nHigh\n\nNormal\n\nLow\n\nHigh\n\nNormal\n\nLow\n\n4. Train and communicate: Train response teams on the prioritization matrix and the importance\n\nof following it during an event. Communicate the prioritization process to all stakeholders to set\n\nclear expectations.\n\n5. Integrate with incident response:\n\nIncorporate the prioritization matrix into your incident response plans and tools.\n\nAutomate the classiﬁcation and prioritization of events where possible to speed up response\n\ntimes.\n\nEnterprise Support customers can leverage AWS Incident Detection and Response, which\n\nprovides 24x7 proactive monitoring and incident management for production workloads.\n\n6. Review and adapt: Regularly review the eﬀectiveness of the prioritization process and make\n\nadjustments based on feedback and changes in the business environment.\n\nOPS10-BP03 Prioritize operational events based on business impact\n\n182",
      "content_length": 1558,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 188,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS03-BP03 Escalation is encouraged\n\nOPS08-BP04 Create actionable alerts\n\nOPS09-BP01 Measure operations goals and KPIs with metrics\n\nRelated documents:\n\nAtlassian - Understanding incident severity levels\n\nIT Process Map - Checklist Incident Priority\n\nOPS10-BP04 Deﬁne escalation paths\n\nEstablish clear escalation paths within your incident response protocols to facilitate timely and\n\neﬀective action. This includes specifying prompts for escalation, detailing the escalation process,\n\nand pre-approving actions to expedite decision-making and reduce mean time to resolution\n\n(MTTR).\n\nDesired outcome: A structured and eﬃcient process that escalates incidents to the appropriate personnel, minimizing response times and impact.\n\nCommon anti-patterns:\n\nLack of clarity on recovery procedures leads to makeshift responses during critical incidents.\n\nAbsence of deﬁned permissions and ownership results in delays when urgent action is needed.\n\nStakeholders and customers are not informed in line with expectations.\n\nImportant decisions are delayed.\n\nBeneﬁts of establishing this best practice:\n\nStreamlined incident response through predeﬁned escalation procedures.\n\nReduced downtime with pre-approved actions and clear ownership.\n\nImproved resource allocation and support-level adjustments according to incident severity.\n\nImproved communication to stakeholders and customers.\n\nOPS10-BP04 Deﬁne escalation paths\n\n183",
      "content_length": 1513,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 189,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nProperly deﬁned escalation paths are crucial for rapid incident response. AWS Systems Manager\n\nIncident Manager supports the setup of structured escalation plans and on-call schedules, which\n\nalert the right personnel so that they are ready to act when incidents occur.\n\nImplementation steps\n\n1. Set up escalation prompts: Set up CloudWatch alarms to create an incident in AWS Systems\n\nManager Incident Manager.\n\n2. Set up on-call schedules: Create on-call schedules in Incident Manager that align with your\n\nescalation paths. Equip on-call personnel with the necessary permissions and tools to act swiftly.\n\n3. Detail escalation procedures:\n\nDetermine speciﬁc conditions under which an incident should be escalated.\n\nCreate escalation plans in Incident Manager.\n\nEscalation channels should consist of a contact or an on-call schedule.\n\nDeﬁne the roles and responsibilities of the team at each escalation level.\n\n4. Pre-approve mitigation actions: Collaborate with decision-makers to pre-approve actions for anticipated scenarios. Use Systems Manager Automation runbooks integrated with Incident Manager to speed up incident resolution.\n\n5. Specify ownership: Clearly identify internal owners for each step of the escalation path.\n\n6. Detail third-party escalations:\n\nDocument third-party service-level agreements (SLAs), and align them with internal goals.\n\nSet clear protocols for vendor communication during incidents.\n\nIntegrate vendor contacts into incident management tools for direct access.\n\nConduct regular drills that include third-party response scenarios.\n\nKeep vendor escalation information well-documented and easily accessible.\n\n7. Train and rehearse escalation plans: Train your team on the escalation process and conduct regular incident response drills or game days. Enterprise Support customers can request an Incident Management Workshop.\n\n8. Continue to improve: Review the eﬀectiveness of your escalation paths regularly. Update your processes based on lessons learned from incident post-mortems and continuous feedback. 184",
      "content_length": 2206,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 190,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLevel of eﬀort for the implementation plan: Moderate\n\nResources\n\nRelated best practices:\n\nOPS08-BP04 Create actionable alerts\n\nOPS10-BP02 Have a process per alert\n\nOPS11-BP02 Perform post-incident analysis\n\nRelated documents:\n\nAWS Systems Manager Incident Manager Escalation Plans\n\nWorking with on-call schedules in Incident Manager\n\nCreating and Managing Runbooks\n\nTemporary elevated access management with AWS IAM Identity Center\n\nAtlassian - Escalation policies for eﬀective incident management\n\nOPS10-BP05 Deﬁne a customer communication plan for service-\n\nimpacting events\n\nEﬀective communication during service impacting events is critical to maintain trust and\n\ntransparency with customers. A well-deﬁned communication plan helps your organization quickly\n\nand clearly share information, both internally and externally, during incidents.\n\nDesired outcome:\n\nA robust communication plan that eﬀectively informs customers and stakeholders during service\n\nimpacting events.\n\nTransparency in communication to build trust and reduce customer anxiety.\n\nMinimizing the impact of service impacting events on customer experience and business\n\noperations.\n\nCommon anti-patterns:\n\nInadequate or delayed communication leads to customer confusion and dissatisfaction.\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\n185",
      "content_length": 1404,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 191,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOverly technical or vague messaging fails to convey the actual impact on users.\n\nThere is no predeﬁned communication strategy, resulting in inconsistent and reactive messaging.\n\nBeneﬁts of establishing this best practice:\n\nEnhanced customer trust and satisfaction through proactive and clear communication.\n\nReduced burden on support teams by preemptively addressing customer concerns.\n\nImproved ability to manage and recover from incidents eﬀectively.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nCreating a comprehensive communication plan for service impacting events involves multiple\n\nfacets, from choosing the right channels to crafting the message and tone. The plan should be\n\nadaptable, scalable, and cater to diﬀerent outage scenarios.\n\nImplementation steps\n\n1. Deﬁne roles and responsibilities:\n\nAssign a major incident manager to oversee incident response activities.\n\nDesignate a communications manager responsible for coordinating all external and internal\n\ncommunications.\n\nInclude the support manager to provide consistent communication through support tickets.\n\n2. Identify communication channels: Select channels like workplace chat, email, SMS, social\n\nmedia, in-app notiﬁcations, and status pages. These channels should be resilient and able to\n\noperate independently during service impacting events.\n\n3. Communicate quickly, clearly, and regularly to customers:\n\nDevelop templates for various service impairment scenarios, emphasizing simplicity and\n\nessential details. Include information about the service impairment, expected resolution time,\n\nand impact.\n\nUse Amazon Pinpoint to alert customers using push notiﬁcations, in-app notiﬁcations, emails,\n\ntext messages, voice messages, and messages over custom channels.\n\nUse Amazon Simple Notiﬁcation Service (Amazon SNS) to alert subscribers programatically or\n\nthrough email, mobile push notiﬁcations, and text messages.\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\n186",
      "content_length": 2091,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 192,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nCommunicate status through dashboards by sharing an Amazon CloudWatch dashboard\n\npublicly.\n\nEncourage social media engagement:\n\nActively monitor social media to understand customer sentiment.\n\nPost on social media platforms for public updates and community engagement.\n\nPrepare templates for consistent and clear social media communication.\n\n4. Coordinate internal communication: Implement internal protocols using tools like Amazon Q Developer in chat applications for team coordination and communication. Use CloudWatch dashboards to communicate status.\n\n5. Orchestrate communication with dedicated tools and services:\n\nUse AWS Systems Manager Incident Manager with Amazon Q Developer in chat applications\n\nto set up dedicated chat channels for real-time internal communication and coordination during incidents.\n\nUse AWS Systems Manager Incident Manager runbooks to automate customer notiﬁcations\n\nthrough Amazon Pinpoint, Amazon SNS, or third-party tools like social media platforms\n\nduring incidents.\n\nIncorporate approval workﬂows within runbooks to optionally review and authorize all\n\nexternal communications before sending.\n\n6. Practice and improve:\n\nConduct training on the use of communication tools and strategies. Empower teams to make\n\ntimely decisions during incidents.\n\nTest the communication plan through regular drills or gamedays. Use these tests to reﬁne\n\nmessaging and evaluate the eﬀectiveness of channels.\n\nImplement feedback mechanisms to assess communication eﬀectiveness during incidents.\n\nContinually evolve the communication plan based on feedback and changing needs.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS07-BP03 Use runbooks to perform procedures\n\nOPS10-BP06 Communicate status through dashboards\n\nOPS10-BP05 Deﬁne a customer communication plan for service-impacting events\n\n187",
      "content_length": 1923,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 193,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP02 Perform post-incident analysis\n\nRelated documents:\n\nAtlassian - Incident communication best practices\n\nAtlassian - How to write a good status update\n\nPagerDuty - A Guide to Incident Communications\n\nRelated videos:\n\nAtlassian - Create your own incident communication plan: Incident templates\n\nRelated examples:\n\nAWS Health Dashboard\n\nOPS10-BP06 Communicate status through dashboards\n\nUse dashboards as a strategic tool to convey real-time operational status and key metrics\n\nto diﬀerent audiences, including internal technical teams, leadership, and customers. These\n\ndashboards oﬀer a centralized, visual representation of system health and business performance,\n\nenhancing transparency and decision-making eﬃciency.\n\nDesired outcome:\n\nYour dashboards provide a comprehensive view of the system and business metrics relevant to\n\ndiﬀerent stakeholders.\n\nStakeholders can proactively access operational information, reducing the need for frequent\n\nstatus requests.\n\nReal-time decision-making is enhanced during normal operations and incidents.\n\nCommon anti-patterns:\n\nEngineers joining an incident management call require status updates to get up to speed.\n\nRelying on manual reporting for management, which leads to delays and potential inaccuracies.\n\nOperations teams are frequently interrupted for status updates during incidents.\n\nOPS10-BP06 Communicate status through dashboards\n\n188",
      "content_length": 1460,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 194,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nEmpowers stakeholders with immediate access to critical information, promoting informed\n\ndecision-making.\n\nReduces operational ineﬃciencies by minimizing manual reporting and frequent status inquiries.\n\nIncreases transparency and trust through real-time visibility into system performance and\n\nbusiness metrics.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nDashboards eﬀectively communicate the status of your system and business metrics and can be\n\ntailored to the needs of diﬀerent audience groups. Tools like Amazon CloudWatch dashboards and Amazon Quick Suite help you create interactive, real-time dashboards for system monitoring and\n\nbusiness intelligence.\n\nImplementation steps\n\n1. Identify stakeholder needs: Determine the speciﬁc information needs of diﬀerent audience\n\ngroups, such as technical teams, leadership, and customers.\n\n2. Choose the right tools: Select appropriate tools like Amazon CloudWatch dashboards for\n\nsystem monitoring and Amazon Quick Suite for interactive business intelligence. AWS Health\n\nprovides a ready-to-use experience in the AWS Health Dashboard, or you can use Health events\n\nin Amazon EventBridge or through the AWS Health API to augment your own dashboards.\n\n3. Design eﬀective dashboards:\n\nDesign dashboards to clearly present relevant metrics and KPIs, ensuring they are\n\nunderstandable and actionable.\n\nIncorporate system-level and business-level views as needed.\n\nInclude both high-level (for broad overviews) and low-level (for detailed analysis) dashboards.\n\nIntegrate automated alarms within dashboards to highlight critical issues.\n\nAnnotate dashboards with important metrics thresholds and goals for immediate visibility.\n\n4. Integrate data sources:\n\nUse Amazon CloudWatch to aggregate and display metrics from various AWS services and\n\nquery metrics from other data sources, creating a uniﬁed view of your system's health and\n\nbusiness metrics.\n\nOPS10-BP06 Communicate status through dashboards\n\n189",
      "content_length": 2114,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 195,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUse features like CloudWatch Logs Insights to query and visualize log data from diﬀerent\n\napplications and services.\n\nUse AWS Health events to stay informed about the operational status and conﬁrmed\n\noperational issues from AWS services through the AWS Health API or AWS Health events on\n\nAmazon EventBridge.\n\n5. Provide self-service access:\n\nShare CloudWatch dashboards with relevant stakeholders for self-service information access\n\nusing dashboard sharing features.\n\nEnsure that dashboards are easily accessible and provide real-time, up-to-date information.\n\n6. Regularly update and reﬁne:\n\nContinually update and reﬁne dashboards to align with evolving business needs and\n\nstakeholder feedback.\n\nRegularly review the dashboards to keep them relevant and eﬀective for conveying the\n\nnecessary information.\n\nResources\n\nRelated best practices:\n\nOPS08-BP05 Create dashboards\n\nRelated documents:\n\nBuilding dashboards for operational visibility\n\nUsing Amazon CloudWatch dashboards\n\nCreate ﬂexible dashboards with dashboard variables\n\nSharing CloudWatch dashboards\n\nQuery metrics from other data sources\n\nAdd a custom widget to a CloudWatch dashboard\n\nRelated examples:\n\nOne Observability Workshop - Dashboards\n\nOPS10-BP06 Communicate status through dashboards\n\n190",
      "content_length": 1326,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 196,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS10-BP07 Automate responses to events\n\nAutomating event responses is key for fast, consistent, and error-free operational handling. Create\n\nstreamlined processes and use tools to automatically manage and respond to events, minimizing\n\nmanual interventions and enhancing operational eﬀectiveness.\n\nDesired outcome:\n\nReduced human errors and faster resolution times through automation.\n\nConsistent and reliable operational event handling.\n\nEnhanced operational eﬃciency and system reliability.\n\nCommon anti-patterns:\n\nManual event handling leads to delays and errors.\n\nAutomation is overlooked in repetitive, critical tasks.\n\nRepetitive, manual tasks lead to alert fatigue and missing critical issues.\n\nBeneﬁts of establishing this best practice:\n\nAccelerated event responses, reducing system downtime.\n\nReliable operations with automated and consistent event handling.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nIncorporate automation to create eﬃcient operational workﬂows and minimize manual interventions.\n\nImplementation steps\n\n1. Identify automation opportunites: Determine repetitive tasks for automation, such as issue remediation, ticket enrichment, capacity management, scaling, deployments, and testing.\n\n2. Identify automation prompts:\n\nAssess and deﬁne speciﬁc conditions or metrics that initiate automated responses using\n\nAmazon CloudWatch alarm actions.\n\nOPS10-BP07 Automate responses to events\n\n191",
      "content_length": 1533,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 197,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nUse Amazon EventBridge to respond to events in AWS services, custom workloads, and SaaS\n\napplications.\n\nConsider initiation events such as speciﬁc log entries, performance metrics thresholds, or state\n\nchanges in AWS resources.\n\n3. Implement event-driven automation:\n\nUse AWS Systems Manager Automation runbooks to simplify maintenance, deployment, and\n\nremediation tasks.\n\nCreating incidents in Incident Manager automatically gathers and adds details about the\n\ninvolved AWS resources to the incident.\n\nProactively monitor quotas using Quota Monitor for AWS.\n\nAutomatically adjust capacity with AWS Auto Scaling to maintain availability and\n\nperformance.\n\nAutomate development pipelines with Amazon CodeCatalyst.\n\nSmoke test or continually monitor endpoints and APIs using synthetic monitoring.\n\n4. Perform risk mitigation through automation:\n\nImplement automated security responses to swiftly address risks.\n\nUse AWS Systems Manager State Manager to reduce conﬁguration drift.\n\nRemediate noncompliant resources with AWS Conﬁg Rules.\n\nLevel of eﬀort for the implementation plan: High\n\nResources\n\nRelated best practices:\n\nOPS08-BP04 Create actionable alerts\n\nOPS10-BP02 Have a process per alert\n\nRelated documents:\n\nUsing Systems Manager Automation runbooks with Incident Manager\n\nCreating incidents in Incident Manager\n\nAWS service quotas\n\nMonitor resource usage and send notiﬁcations when approaching quotas\n\nOPS10-BP07 Automate responses to events\n\n192",
      "content_length": 1518,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 198,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Auto Scaling\n\nWhat is Amazon CodeCatalyst?\n\nUsing Amazon CloudWatch alarms\n\nUsing Amazon CloudWatch alarm actions\n\nRemediating Noncompliant Resources with AWS Conﬁg Rules\n\nCreating metrics from log events using ﬁlters\n\nAWS Systems Manager State Manager\n\nRelated videos:\n\nCreate Automation Runbooks with AWS Systems Manager\n\nHow to automate IT Operations on AWS\n\nAWS Security Hub CSPM automation rules\n\nStart your software project fast with Amazon CodeCatalyst blueprints\n\nRelated examples:\n\nAmazon CodeCatalyst Tutorial: Creating a project with the Modern three-tier web application\n\nblueprint\n\nOne Observability Workshop\n\nRespond to incidents using Incident Manager\n\nOPS10-BP07 Automate responses to events\n\n193",
      "content_length": 779,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 199,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nEvolve\n\nLearn, share, and continuously improve to sustain operational excellence. Dedicate work cycles\n\nto making nearly continuous incremental improvements. Perform post-incident analysis of all\n\ncustomer impacting events. Identify the contributing factors and preventative action to limit or\n\nprevent recurrence. Communicate contributing factors with aﬀected communities as appropriate.\n\nRegularly evaluate and prioritize opportunities for improvement (for example, feature requests,\n\nissue remediation, and compliance requirements), including both the workload and operations\n\nprocedures.\n\nInclude feedback loops within your procedures to rapidly identify areas for improvement and\n\ncapture learnings from running operations.\n\nShare lessons learned across teams. Analyze trends within lessons learned and perform cross-\n\nteam retrospective analysis of operations metrics to identify opportunities and methods for\n\nimprovement. Implement changes intended to bring about improvement and evaluate the results\n\nto determine success.\n\nOn AWS, you can export your log data to Amazon S3 or send logs directly to Amazon S3 for\n\nlong-term storage. Using AWS Glue, you can discover and prepare your log data in Amazon S3\n\nfor analytics, and store associated metadata in the AWS Glue Data Catalog. Amazon Athena,\n\nthrough its native integration with AWS Glue, can then be used to analyze your log data, querying\n\nit using standard SQL. Using a business intelligence tool like Amazon Quick Suite, you can\n\nvisualize, explore, and analyze your data. Discovering trends and events of interest that may drive\n\nimprovement.\n\nSuccessful evolution of operations is founded in frequent small improvements, providing safe\n\nenvironments and time to experiment, develop, and test improvements, and environments in which\n\nlearning from failures is encouraged. Operations support for sandbox, development, test, and\n\nproduction environments, with increasing level of operational controls, facilitates development and\n\nincreases the predictability of successful results from changes deployed into production.\n\nTopics\n\nLearn, share, and improve\n\n194",
      "content_length": 2189,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 200,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nLearn, share, and improve\n\nIt’s essential that you regularly provide time for analysis of operations activities, analysis of failures,\n\nexperimentation, and making improvements. When things fail, you will want to ensure that your\n\nteam, as well as your larger engineering community, learns from those failures. You should analyze\n\nfailures to identify lessons learned and plan improvements. You will want to regularly review your\n\nlessons learned with other teams to validate your insights.\n\nBest practices\n\nOPS11-BP01 Have a process for continuous improvement\n\nOPS11-BP02 Perform post-incident analysis\n\nOPS11-BP03 Implement feedback loops\n\nOPS11-BP04 Perform knowledge management\n\nOPS11-BP05 Deﬁne drivers for improvement\n\nOPS11-BP06 Validate insights\n\nOPS11-BP07 Perform operations metrics reviews\n\nOPS11-BP08 Document and share lessons learned\n\nOPS11-BP09 Allocate time to make improvements\n\nOPS11-BP01 Have a process for continuous improvement\n\nEvaluate your workload against internal and external architecture best practices. Conduct\n\nfrequent, intentional workload reviews. Prioritize improvement opportunities into your software\n\ndevelopment cadence.\n\nDesired outcome:\n\nYou analyze your workload against architecture best practices frequently.\n\nYou give improvement opportunities equal priority to features in your software development\n\nprocess.\n\nCommon anti-patterns:\n\nYou have not conducted an architecture review on your workload since it was deployed several\n\nyears ago.\n\nLearn, share, and improve\n\n195",
      "content_length": 1577,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 201,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou give a lower priority to improvement opportunities. Compared to new features, these\n\nopportunities stay in the backlog.\n\nThere is no standard for implementing modiﬁcations to best practices for the organization.\n\nBeneﬁts of establishing this best practice:\n\nYour workload is kept up-to-date on architecture best practices.\n\nYou evolve your workload in an intentional manner.\n\nYou can leverage organization best practices to improve all workloads.\n\nYou make marginal gains that have a cumulative impact, which drives deeper eﬃciencies.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nFrequently conduct an architectural review of your workload. Use internal and external best\n\npractices, evaluate your workload, and identify improvement opportunities. Prioritize improvement\n\nopportunities into your software development cadence.\n\nImplementation steps\n\n1. Conduct periodic architecture reviews of your production workload with an agreed-upon\n\nfrequency. Use a documented architectural standard that includes AWS-speciﬁc best practices.\n\na. Use your internally-deﬁned standards for these reviews. If you do not have an internal\n\nstandard, use the AWS Well-Architected Framework.\n\nb. Use the AWS Well-Architected Tool to create a custom lens of your internal best practices and\n\nconduct your architecture review.\n\nc. Contact your AWS Solution Architect or Technical Account Manager to conduct a guided Well-\n\nArchitected Framework Review of your workload.\n\n2. Prioritize improvement opportunities identiﬁed during the review into your software\n\ndevelopment process.\n\nLevel of eﬀort for the implementation plan: Low. You can use the AWS Well-Architected Framework to conduct your yearly architecture review.\n\nOPS11-BP01 Have a process for continuous improvement\n\n196",
      "content_length": 1877,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 202,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nResources\n\nRelated best practices:\n\nOPS11-BP02 Perform post-incident analysis\n\nOPS11-BP08 Document and share lessons learned\n\nOPS04 Implement Observability\n\nRelated documents:\n\nAWS Well-Architected Tool - Custom lenses\n\nAWS Well-Architected Whitepaper - The review process\n\nCustomize Well-Architected Reviews using Custom Lenses and the AWS Well-Architected Tool\n\nImplementing the AWS Well-Architected Custom Lens lifecycle in your organization\n\nRelated videos:\n\nAWS re:Invent 2023 - Scaling AWS Well-Architected best practices across your organization\n\nRelated examples:\n\nAWS Well-Architected Tool\n\nOPS11-BP02 Perform post-incident analysis\n\nReview customer-impacting events and identify the contributing factors and preventative actions.\n\nUse this information to develop mitigations to limit or prevent recurrence. Develop procedures\n\nfor prompt and eﬀective responses. Communicate contributing factors and corrective actions as\n\nappropriate, tailored to target audiences.\n\nDesired outcome:\n\nYou have established incident management processes that include post-incident analysis.\n\nYou have observability plans in place to collect data on events.\n\nWith this data, you understand and collect metrics that support your post-incident analysis\n\nprocess.\n\nOPS11-BP02 Perform post-incident analysis\n\n197",
      "content_length": 1361,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 203,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou learn from incidents to improve future outcomes.\n\nCommon anti-patterns:\n\nYou administer an application server. Approximately every 23 hours and 55 minutes all\n\nyour active sessions are terminated. You have tried to identify what is going wrong on your\n\napplication server. You suspect it could instead be a network issue but are unable to get\n\ncooperation from the network team as they are too busy to support you. You lack a predeﬁned\n\nprocess to follow to get support and collect the information necessary to determine what is\n\ngoing on.\n\nYou have had data loss within your workload. This is the ﬁrst time it has happened and the cause\n\nis not obvious. You decide it is not important because you can recreate the data. Data loss starts\n\noccurring with greater frequency impacting your customers. This also places addition operational burden on you as you restore the missing data.\n\nBeneﬁts of establishing this best practice:\n\nYou have a predeﬁned process to determine the components, conditions, actions, and events\n\nthat contributed to an incident, which helps you identify opportunities for improvement.\n\nYou use data from post-incident analysis to make improvements.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nUse a process to determine contributing factors. Review all customer impacting incidents. Have a\n\nprocess to identify and document the contributing factors of an incident so that you can develop\n\nmitigations to limit or prevent recurrence and you can develop procedures for prompt and eﬀective responses. Communicate incident root causes as appropriate, and tailor the communication to your\n\ntarget audience. Share learnings openly within your organization.\n\nImplementation steps\n\n1. Collect metrics such as deployment change, conﬁguration change, incident start time, alarm\n\ntime, time of engagement, mitigation start time, and incident resolved time.\n\n2. Describe key time points on the timeline to understand the events of the incident.\n\n3. Ask the following questions:\n\nOPS11-BP02 Perform post-incident analysis\n\n198",
      "content_length": 2156,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 204,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\na. Could you improve time to detection?\n\nb. Are there updates to metrics and alarms that would detect the incident sooner?\n\nc. Can you improve the time to diagnosis?\n\nd. Are there updates to your response plans or escalation plans that would engage the correct\n\nresponders sooner?\n\ne. Can you improve the time to mitigation?\n\nf. Are there runbook or playbook steps that you could add or improve?\n\ng. Can you prevent future incidents from occurring?\n\n4. Create checklists and actions. Track and deliver all actions.\n\nLevel of eﬀort for the implementation plan: Medium\n\nResources\n\nRelated best practices:\n\nOPS11-BP01 Have a process for continuous improvement\n\nOPS 4 - Implement observability\n\nRelated documents:\n\nPerforming a post-incident analysis in Incident Manager\n\nOperational Readiness Review\n\nOPS11-BP03 Implement feedback loops\n\nFeedback loops provide actionable insights that drive decision making. Build feedback loops into your procedures and workloads. This helps you identify issues and areas that need improvement.\n\nThey also validate investments made in improvements. These feedback loops are the foundation\n\nfor continuously improving your workload.\n\nFeedback loops fall into two categories: immediate feedback and retrospective analysis. Immediate\n\nfeedback is gathered through review of the performance and outcomes from operations activities.\n\nThis feedback comes from team members, customers, or the automated output of the activity.\n\nImmediate feedback is received from things like A/B testing and shipping new features, and it is\n\nessential to failing fast.\n\nOPS11-BP03 Implement feedback loops\n\n199",
      "content_length": 1682,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 205,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRetrospective analysis is performed regularly to capture feedback from the review of operational\n\noutcomes and metrics over time. These retrospectives happen at the end of a sprint, on a cadence, or after major releases or events. This type of feedback loop validates investments in operations or\n\nyour workload. It helps you measure success and validates your strategy.\n\nDesired outcome: You use immediate feedback and retrospective analysis to drive improvements. There is a mechanism to capture user and team member feedback. Retrospective analysis is used to\n\nidentify trends that drive improvements.\n\nCommon anti-patterns:\n\nYou launch a new feature but have no way of receiving customer feedback on it.\n\nAfter investing in operations improvements, you don’t conduct a retrospective to validate them.\n\nYou collect customer feedback but don’t regularly review it.\n\nFeedback loops lead to proposed action items but they aren’t included in the software\n\ndevelopment process.\n\nCustomers don’t receive feedback on improvements they’ve proposed.\n\nBeneﬁts of establishing this best practice:\n\nYou can work backwards from the customer to drive new features.\n\nYour organization culture can react to changes faster.\n\nTrends are used to identify improvement opportunities.\n\nRetrospectives validate investments made to your workload and operations.\n\nLevel of risk exposed if this best practice is not established: High\n\nImplementation guidance\n\nImplementing this best practice means that you use both immediate feedback and retrospective\n\nanalysis. These feedback loops drive improvements. There are many mechanisms for immediate\n\nfeedback, including surveys, customer polls, or feedback forms. Your organization also uses\n\nretrospectives to identify improvement opportunities and validate initiatives.\n\nCustomer example\n\nAnyCompany Retail created a web form where customers can give feedback or report issues.\n\nDuring the weekly scrum, user feedback is evaluated by the software development team. Feedback\n\nOPS11-BP03 Implement feedback loops\n\n200",
      "content_length": 2103,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 206,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nis regularly used to steer the evolution of their platform. They conduct a retrospective at the end of\n\neach sprint to identify items they want to improve.\n\nImplementation steps\n\n1. Immediate feedback\n\nYou need a mechanism to receive feedback from customers and team members. Your\n\noperations activities can also be conﬁgured to deliver automated feedback.\n\nYour organization needs a process to review this feedback, determine what to improve, and\n\nschedule the improvement.\n\nFeedback must be added into your software development process.\n\nAs you make improvements, follow up with the feedback submitter.\n\nYou can use AWS Systems Manager OpsCenter to create and track these improvements as\n\nOpsItems.\n\n2. Retrospective analysis\n\nConduct retrospectives at the end of a development cycle, on a set cadence, or after a major\n\nrelease.\n\nGather stakeholders involved in the workload for a retrospective meeting.\n\nCreate three columns on a whiteboard or spreadsheet: Stop, Start, and Keep.\n\nStop is for anything that you want your team to stop doing.\n\nStart is for ideas that you want to start doing.\n\nKeep is for items that you want to keep doing.\n\nGo around the room and gather feedback from the stakeholders.\n\nPrioritize the feedback. Assign actions and stakeholders to any Start or Keep items.\n\nAdd the actions to your software development process and communicate status updates to\n\nstakeholders as you make the improvements.\n\nLevel of eﬀort for the implementation plan: Medium. To implement this best practice, you need a way to take in immediate feedback and analyze it. Also, you need to establish a retrospective\n\nanalysis process.\n\nResources\n\nRelated best practices: OPS11-BP03 Implement feedback loops\n\n201",
      "content_length": 1773,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 207,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS01-BP01 Evaluate external customer needs: Feedback loops are a mechanism to gather\n\nexternal customer needs.\n\nOPS01-BP02 Evaluate internal customer needs: Internal stakeholders can use feedback loops to\n\ncommunicate needs and requirements.\n\nOPS11-BP02 Perform post-incident analysis: Post-incident analyses are an important form of\n\nretrospective analysis conducted after incidents.\n\nOPS11-BP07 Perform operations metrics reviews: Operations metrics reviews identify trends and\n\nareas for improvement.\n\nRelated documents:\n\n7 Pitfalls to Avoid When Building a CCOE\n\nAtlassian Team Playbook - Retrospectives\n\nEmail Deﬁnitions: Feedback Loops\n\nEstablishing Feedback Loops Based on the AWS Well-Architected Framework Review\n\nIBM Garage Methodology - Hold a retrospective\n\nInvestopedia – The PDCS Cycle\n\nMaximizing Developer Eﬀectiveness by Tim Cochran\n\nOperations Readiness Reviews (ORR) Whitepaper - Iteration\n\nITIL CSI - Continual Service Improvement\n\nWhen Toyota met e-commerce: Lean at Amazon\n\nRelated videos:\n\nBuilding Eﬀective Customer Feedback Loops\n\nRelated examples:\n\nAstuto - Open source customer feedback tool\n\nAWS Solutions - QnABot on AWS\n\nFider - A platform to organize customer feedback\n\nRelated services:\n\nOPS11-BP03 Implement feedback loops\n\n202",
      "content_length": 1324,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 208,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nAWS Systems Manager OpsCenter\n\nOPS11-BP04 Perform knowledge management\n\nKnowledge management helps team members ﬁnd the information to perform their job. In\n\nlearning organizations, information is freely shared which empowers individuals. The information\n\ncan be discovered or searched. Information is accurate and up to date. Mechanisms exist to create\n\nnew information, update existing information, and archive outdated information. The most\n\ncommon example of a knowledge management platform is a content management system like a\n\nwiki.\n\nDesired outcome:\n\nTeam members have access to timely, accurate information.\n\nInformation is searchable.\n\nMechanisms exist to add, update, and archive information.\n\nCommon anti-patterns:\n\nThere is no centralized knowledge storage. Team members manage their own notes on their\n\nlocal machines.\n\nYou have a self-hosted wiki but no mechanisms to manage information, resulting in outdated\n\ninformation.\n\nSomeone identiﬁes missing information but there’s no process to request adding it the team\n\nwiki. They add it themselves but they miss a key step, leading to an outage.\n\nBeneﬁts of establishing this best practice:\n\nTeam members are empowered because information is shared freely.\n\nNew team members are onboarded faster because documentation is up to date and searchable.\n\nInformation is timely, accurate, and actionable.\n\nLevel of risk exposed if this best practice is not established: High\n\nOPS11-BP04 Perform knowledge management\n\n203",
      "content_length": 1539,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 209,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nKnowledge management is an important facet of learning organizations. To begin, you need a\n\ncentral repository to store your knowledge (as a common example, a self-hosted wiki). You must\n\ndevelop processes for adding, updating, and archiving knowledge. Develop standards for what\n\nshould be documented and let everyone contribute.\n\nCustomer example\n\nAnyCompany Retail hosts an internal Wiki where all knowledge is stored. Team members are\n\nencouraged to add to the knowledge base as they go about their daily duties. On a quarterly basis,\n\na cross-functional team evaluates which pages are least updated and determines if they should be\n\narchived or updated.\n\nImplementation steps\n\n1. Start with identifying the content management system where knowledge will be stored. Get\n\nagreement from stakeholders across your organization.\n\na. If you don’t have an existing content management system, consider running a self-hosted wiki\n\nor using a version control repository as a starting point.\n\n2. Develop runbooks for adding, updating, and archiving information. Educate your team on these\n\nprocesses.\n\n3. Identify what knowledge should be stored in the content management system. Start with daily\n\nactivities (runbooks and playbooks) that team members perform. Work with stakeholders to\n\nprioritize what knowledge is added.\n\n4. On a periodic basis, work with stakeholders to identify out-of-date information and archive it or\n\nbring it up to date.\n\nLevel of eﬀort for the implementation plan: Medium. If you don’t have an existing content management system, you can set up a self-hosted wiki or a version-controlled document\n\nrepository.\n\nResources\n\nRelated best practices:\n\nOPS11-BP08 Document and share lessons learned - Knowledge management facilitates\n\ninformation sharing about lessons learned.\n\nOPS11-BP04 Perform knowledge management\n\n204",
      "content_length": 1927,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 210,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nRelated documents:\n\nAtlassian - Knowledge Management\n\nRelated examples:\n\nDokuWiki\n\nGollum\n\nMediaWiki\n\nWiki.js\n\nOPS11-BP05 Deﬁne drivers for improvement\n\nIdentify drivers for improvement to help you evaluate and prioritize opportunities based on data\n\nand feedback loops. Explore improvement opportunities in your systems and processes, and\n\nautomate where appropriate.\n\nDesired outcome:\n\nYou track data from across your environment.\n\nYou correlate events and activities to business outcomes.\n\nYou can compare and contrast between environments and systems.\n\nYou maintain a detailed activity history of your deployments and outcomes.\n\nYou collect data to support your security posture.\n\nCommon anti-patterns:\n\nYou collect data from across your environment but do not correlate events and activities.\n\nYou collect detailed data from across your estate, and it drives high Amazon CloudWatch and\n\nAWS CloudTrail activity and cost. However, you do not use this data meaningfully.\n\nYou do not account for business outcomes when deﬁning drivers for improvement.\n\nYou do not measure the eﬀects of new features.\n\nBeneﬁts of establishing this best practice:\n\nOPS11-BP05 Deﬁne drivers for improvement\n\n205",
      "content_length": 1256,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 211,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou minimize the impact of event-based motivations or emotional investment by determining\n\ncriteria for improvement.\n\nYou respond to business events, not just technical ones.\n\nYou measure your environment to identify areas of improvement.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nUnderstand drivers for improvement: You should only make changes to a system when a desired\n\noutcome is supported.\n\nDesired capabilities: Evaluate desired features and capabilities when evaluating opportunities\n\nfor improvement.\n\nWhat's New with AWS\n\nUnacceptable issues: Evaluate unacceptable issues, bugs, and vulnerabilities when evaluating\n\nopportunities for improvement. Track rightsizing options, and seek optimization opportunities.\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nCloud Intelligence Dashboards\n\nCompliance requirements: Evaluate updates and changes required to maintain compliance\n\nwith regulation, policy, or to remain under support from a third party, when reviewing\n\nopportunities for improvement.\n\nAWS Compliance\n\nAWS Compliance Programs\n\nAWS Compliance Latest News\n\nResources\n\nRelated best practices:\n\nOPS01 Organization priorities\n\nOPS02 Relationships and Ownerships\n\nOPS04-BP01 Identify key performance indicators\n\nOPS08 Utilizing Workload Observability\n\nOPS11-BP05 Deﬁne drivers for improvement\n\n206",
      "content_length": 1436,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 212,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS09 Understanding Operational Health\n\nOPS11-BP03 Implement feedback loops\n\nRelated documents:\n\nAmazon Athena\n\nQuick Suite\n\nAWS Compliance\n\nAWS Compliance Latest News\n\nAWS Compliance Programs\n\nAWS Glue\n\nAWS Latest Security Bulletins\n\nAWS Trusted Advisor\n\nExport your log data to Amazon S3\n\nWhat's New with AWS\n\nThe Imperatives of Customer-Centric Innovation\n\nDigital Transformation: Hype or a Strategic Necessity?\n\nRelated Videos\n\nAWS re:Invent 2023 - Improve operational eﬃciency and resilience with Support (SUP310)\n\nOPS11-BP06 Validate insights\n\nReview your analysis results and responses with cross-functional teams and business owners. Use\n\nthese reviews to establish common understanding, identify additional impacts, and determine\n\ncourses of action. Adjust responses as appropriate.\n\nDesired outcomes:\n\nYou review insights with business owners on a regular basis. Business owners provide additional\n\ncontext to newly-gained insights.\n\nYou review insights and request feedback from technical peers, and you share your learnings\n\nacross teams.\n\nOPS11-BP06 Validate insights\n\n207",
      "content_length": 1148,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 213,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nYou publish data and insights for other technical and business teams to review. You factor in\n\nyour learnings to new practices by other departments.\n\nSummarize and review new insights with senior leaders. Senior leaders use new insights to deﬁne\n\nstrategy.\n\nCommon anti-patterns:\n\nYou release a new feature. This feature changes some of your customer behaviors. Your\n\nobservability does not take these changes into account. You do not quantify the beneﬁts of\n\nthese changes.\n\nYou push a new update and neglect refreshing your CDN. The CDN cache is no longer compatible\n\nwith the latest release. You measure the percentage of requests with errors. All of your users\n\nreport HTTP 400 errors when communicating with backend servers. You investigate the client\n\nerrors and ﬁnd that because you measured the wrong dimension, your time was wasted.\n\nYour service-level agreement stipulates 99.9% uptime, and your recovery point objective is\n\nfour hours. The service owner maintains that the system is zero downtime. You implement an\n\nexpensive and complex replication solution, which wastes time and money.\n\nBeneﬁts of establishing this best practice:\n\nWhen you validate insights with business owners and subject matter experts, you establish\n\ncommon understanding and more eﬀectively guide improvement.\n\nYou discover hidden issues and factor them into future decisions.\n\nYour focus moves from technical outcomes to business outcomes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nValidate insights: Engage with business owners and subject matter experts to ensure there is\n\ncommon understanding and agreement of the meaning of the data you have collected. Identify\n\nadditional concerns, potential impacts, and determine a courses of action.\n\nResources\n\nRelated best practices:\n\nOPS11-BP06 Validate insights\n\n208",
      "content_length": 1920,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 214,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS01-BP06 Evaluate tradeoﬀs while managing beneﬁts and risks\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nOPS11-BP03 Implement feedback loops\n\nRelated documents:\n\nDesigning a Cloud Center of Excellence (CCOE)\n\nRelated videos:\n\nBuilding observability to increase resiliency\n\nOPS11-BP07 Perform operations metrics reviews\n\nRegularly perform retrospective analysis of operations metrics with cross-team participants from\n\ndiﬀerent areas of the business. Use these reviews to identify opportunities for improvement,\n\npotential courses of action, and to share lessons learned. Look for opportunities to improve in all of\n\nyour environments (for example, development, test, and production).\n\nDesired outcome:\n\nYou frequently review business-aﬀecting metrics\n\nYou detect and review anomalies through your observability capabilities\n\nYou use data to support business outcomes and goals\n\nCommon anti-patterns:\n\nYour maintenance window interrupts a signiﬁcant retail promotion. The business remains\n\nunaware that there is a standard maintenance window that could be delayed if there are other\n\nbusiness impacting events.\n\nYou suﬀered an extended outage because you commonly use an outdated library in your\n\norganization. You have since migrated to a supported library. The other teams in your\n\norganization do not know that they are at risk.\n\nYou do not regularly review attainment of customer SLAs. You are trending to not meet your\n\ncustomer SLAs. There are ﬁnancial penalties related to not meeting your customer SLAs.\n\nOPS11-BP07 Perform operations metrics reviews\n\n209",
      "content_length": 1654,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 215,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nBeneﬁts of establishing this best practice:\n\nWhen you meet regularly to review operations metrics, events, and incidents, you maintain\n\ncommon understanding across teams.\n\nYour team meets routinely to review metrics and incidents, which positions you to take action on\n\nrisks and recognize customer SLAs.\n\nYou share lessons learned, which provides data for prioritization and targeted improvements for\n\nbusiness outcomes.\n\nLevel of risk exposed if this best practice is not established: Medium\n\nImplementation guidance\n\nRegularly perform retrospective analysis of operations metrics with cross-team participants from\n\ndiﬀerent areas of the business.\n\nEngage stakeholders, including the business, development, and operations teams, to validate\n\nyour ﬁndings from immediate feedback and retrospective analysis and share lessons learned.\n\nUse their insights to identify opportunities for improvement and potential courses of action.\n\nResources\n\nRelated best practices:\n\nOPS08-BP05 Create dashboards\n\nOPS09-BP03 Review operations metrics and prioritize improvement\n\nOPS10-BP01 Use a process for event, incident, and problem management\n\nRelated documents:\n\nAmazon CloudWatch\n\nAmazon CloudWatch metrics and dimensions reference\n\nPublish custom metrics\n\nUsing Amazon CloudWatch metrics\n\nDashboards and visualizations with CloudWatch\n\nOPS11-BP07 Perform operations metrics reviews\n\n210",
      "content_length": 1440,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 216,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS11-BP08 Document and share lessons learned\n\nDocument and share lessons learned from the operations activities so that you can use them\n\ninternally and across teams. You should share what your teams learn to increase the beneﬁt\n\nacross your organization. Share information and resources to prevent avoidable errors and ease\n\ndevelopment eﬀorts, and focus on delivery of desired features.\n\nUse AWS Identity and Access Management (IAM) to deﬁne permissions that permit controlled\n\naccess to the resources you wish to share within and across accounts.\n\nDesired outcome:\n\nYou use version-controlled repositories to share application libraries, scripted procedures,\n\nprocedure documentation, and other system documentation.\n\nYou share your infrastructure standards as version-controlled AWS CloudFormation templates.\n\nYou review lessons learned across teams.\n\nCommon anti-patterns:\n\nYou suﬀered an extended outage because your organization commonly uses buggy library. You\n\nhave since migrated to a reliable library. The other teams in your organization do not know they\n\nare at risk. No one documents and shares the experience with this library, and they are not aware\n\nof the risk.\n\nYou have identiﬁed an edge case in an internally-shared microservice that causes sessions to\n\ndrop. You have updated your calls to the service to avoid this edge case. The other teams in your\n\norganization do not know that they are at risk.\n\nYou have found a way to signiﬁcantly reduce the CPU utilization requirements for one of your\n\nmicroservices. You do not know if any other teams could take advantage of this technique.\n\nBeneﬁts of establishing this best practice: Share lessons learned to support improvement and to maximize the beneﬁts of experience.\n\nLevel of risk exposed if this best practice is not established: Low\n\nOPS11-BP08 Document and share lessons learned\n\n211",
      "content_length": 1924,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 217,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nImplementation guidance\n\nDocument and share lessons learned: Have procedures to document the lessons learned from the running of operations activities and retrospective analysis so that they can be used by other teams.\n\nShare learnings: Have procedures to share lessons learned and associated artifacts across teams. For example, share updated procedures, guidance, governance, and best practices through an accessible wiki. Share scripts, code, and libraries through a common repository.\n\nLeverage AWS re:Post Private as a knowledge service to streamline collaboration and\n\nknowledge sharing within your organization.\n\nResources\n\nRelated best practices:\n\nOPS02-BP06 Responsibilities between teams are predeﬁned or negotiated\n\nOPS05-BP01 Use version control\n\nOPS05-BP06 Share design standards\n\nOPS11-BP03 Implement feedback loops\n\nOPS11-BP07 Perform operations metrics reviews\n\nRelated documents:\n\nIncrease collaboration and securely share cloud knowledge with AWS re:Post Private\n\nReduce project delays with a docs-as-code solution\n\nRelated videos:\n\nAWS re:Invent 2023 - Collaborate within your company and with AWS using AWS re:Post Private\n\nSupports You | Exploring the Incident Management Tabletop Exercise\n\nOPS11-BP09 Allocate time to make improvements\n\nDedicate time and resources within your processes to make continuous incremental improvements\n\npossible.\n\nOPS11-BP09 Allocate time to make improvements\n\n212",
      "content_length": 1478,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 218,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nDesired outcome:\n\nYou create temporary duplicates of environments, which lowers the risk, eﬀort, and cost of\n\nexperimentation and testing.\n\nThese duplicated environments can be used to test the conclusions from your analysis,\n\nexperiment, and develop and test planned improvements.\n\nYou run gamedays, and you use Fault Injection Service (FIS) to provide the controls and\n\nguardrails that teams need to run experiments in a production-like environment.\n\nCommon anti-patterns:\n\nThere is a known performance issue in your application server. It is added to the backlog behind\n\nevery planned feature implementation. If the rate of planned features being added remains constant, the performance issue would never be addressed.\n\nTo support continual improvement, you approve administrators and developers using all their\n\nextra time to select and implement improvements. No improvements are ever completed.\n\nOperational acceptance is complete, and you do not test operational practices again.\n\nBeneﬁts of establishing this best practice: By dedicating time and resources within your processes, you can make continuous, incremental improvements possible.\n\nLevel of risk exposed if this best practice is not established: Low\n\nImplementation guidance\n\nAllocate time to make improvements: Dedicate time and resources within your processes to make\n\ncontinuous, incremental improvements.\n\nImplement changes to improve and evaluate the results to determine success.\n\nIf the results do not satisfy the goals and the improvement is still a priority, pursue alternative\n\ncourses of action.\n\nSimulate production workloads through game days, and use learnings from these simulations to\n\nimprove.\n\nResources\n\nRelated best practices:\n\nOPS11-BP09 Allocate time to make improvements\n\n213",
      "content_length": 1828,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 219,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nOPS05-BP08 Use multiple environments\n\nRelated videos:\n\nAWS re:Invent 2023 - Improve application resilience with AWS Fault Injection Service\n\nOPS11-BP09 Allocate time to make improvements\n\n214",
      "content_length": 254,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 220,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nConclusion\n\nOperational excellence is an ongoing and iterative eﬀort.\n\nSet up your organization for success by having shared goals. Ensure that everyone understands\n\ntheir part in achieving business outcomes and how they impact the ability of others to succeed.\n\nProvide support for your team members so that they can support your business outcomes.\n\nEvery operational event and failure should be treated as an opportunity to improve the operations\n\nof your architecture. By understanding the needs of your workloads, predeﬁning runbooks for\n\nroutine activities, and playbooks to guide issue resolution, using the operations as code features in\n\nAWS, and maintaining situational awareness, your operations will be better prepared and able to\n\nrespond more eﬀectively when incidents occur.\n\nThrough focusing on incremental improvement based on priorities as they change, and lessons\n\nlearned from event response and retrospective analysis, you will help the success of your business\n\nby increasing the eﬃciency and eﬀectiveness of your activities.\n\nAWS strives to help you build and operate architectures that maximize eﬃciency while you build\n\nhighly responsive and adaptive deployments. To increase the operational excellence of your\n\nworkloads, you should use the best practices discussed in this paper.\n\n215",
      "content_length": 1373,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 221,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nContributors\n\nRich Boyd, Operational Excellence Pillar Lead, Well-Architected, Amazon Web Services\n\nJon Steele, Solutions Architect Well-Architected, Amazon Web Services\n\nRyan King, Sr. Technical Program Manager, Amazon Web Services\n\nChris Kunselman, Advisory Consultant, Amazon Web Services\n\nPeter Mullen, Advisory Consultant, Amazon Web Services\n\nBrian Quinn, Sr. Advisory Consultant, Amazon Web Services\n\nDavid Stanley, Cloud Operating Model Lead, Amazon Web Services\n\nChris Kozlowski, Senior Specialist Technical Account Manager, Enterprise Support, Amazon Web\n\nServices\n\nAlex Livingstone, Principal Specialist Solutions Architect, Cloud Operations, Amazon Web\n\nServices\n\nPaul Moran, Principal Technologist, Enterprise Support, Amazon Web Services\n\nPeter Mullen, Advisory Consultant, Professional Services, Amazon Web Services\n\nChris Pates, Senior Specialist Technical Account Manager, Enterprise Support, Amazon Web\n\nServices\n\nArvind Raghunathan, Principal Specialist Technical Account Manager, Enterprise Support,\n\nAmazon Web Services\n\nFatih (Ben) Mergen, Senior Cost Lead Solutions Architect, Amazon Web Services\n\n216",
      "content_length": 1187,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 222,
      "content": "Operational Excellence Pillar\n\nFurther reading\n\nFor additional guidance, consult the following sources:\n\nAWS Well-Architected Framework\n\nAWS Architecture Center\n\nAWS Well-Architected Framework\n\n217",
      "content_length": 197,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 223,
      "content": "Operational Excellence Pillar\n\nDocument revisions\n\nTo be notiﬁed about updates to this whitepaper, subscribe to the RSS feed.\n\nChange\n\nDescription\n\nUpdated best practice guidance\n\nBest practices were updated with new guidance in the\n\nfollowing areas: OPS 2,\n\nOPS 5, OPS 9, and OPS\n\n10. Guidance includes new\n\nrecommendations on AWS\n\nservices and generative AI.\n\nUpdated best practice guidance\n\nLarge-scale best practice updates were made\n\nthroughout the pillar. Multiple\n\nconsolidations of content in\n\nOPS 1, OPS 2, and OPS 3. Risk\n\nrating changes in OPS 10.\n\nMajor content update and consolidation\n\nContent has been updated and consolidated in multiple\n\nbest practice areas. Two best\n\npractice areas (OPS 4 and\n\nOPS 8) have been rewritten\n\nwith new content and focus.\n\nBest practices have been\n\nupdated and consolidated in\n\nthe following areas: Design\n\nfor operations, Mitigate\n\ndeployment risks, and\n\nUnderstanding operation\n\nal health. Best practice area OPS 04 has been updated to\n\nImplement observability. Best\n\nAWS Well-Architected Framework\n\nDate\n\nNovember 6, 2024\n\nJune 27, 2024\n\nOctober 3, 2023\n\n218",
      "content_length": 1108,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 224,
      "content": "Operational Excellence Pillar\n\nUpdates for new Framework\n\nWhitepaper updated\n\nWhitepaper updated\n\nMinor update\n\nWhitepaper updated\n\nUpdates for new Framework\n\nWhitepaper updated\n\nInitial publication\n\npractice area OPS 08 has been\n\nupdated to Utilizing workload observability.\n\nBest practices updated with prescriptive guidance and new\n\nbest practices added.\n\nBest practices updated with new implementation\n\nguidance.\n\nBest practices expanded and improvement plans added.\n\nSmall editorial update.\n\nUpdates to reﬂect new AWS services and features, and\n\nlatest best practices.\n\nUpdates to reﬂect new AWS services and features, and\n\nlatest best practices.\n\nUpdates to reﬂect new AWS services and features, and\n\nupdated references.\n\nOperational Excellence Pillar - AWS Well-Architected Framework published.\n\nAWS Well-Architected Framework\n\nApril 10, 2023\n\nDecember 15, 2022\n\nOctober 20, 2022\n\nAugust 8, 2022\n\nFebruary 2, 2022\n\nJuly 8, 2020\n\nJuly 1, 2018\n\nNovember 1, 2017\n\n219",
      "content_length": 971,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 225,
      "content": "Operational Excellence Pillar\n\nAWS Well-Architected Framework\n\nNotices\n\nCustomers are responsible for making their own independent assessment of the information in\n\nthis document. This document: (a) is for informational purposes only, (b) represents current AWS\n\nproduct oﬀerings and practices, which are subject to change without notice, and (c) does not create\n\nany commitments or assurances from AWS and its aﬃliates, suppliers or licensors. AWS products or\n\nservices are provided “as is” without warranties, representations, or conditions of any kind, whether\n\nexpress or implied. The responsibilities and liabilities of AWS to its customers are controlled by\n\nAWS agreements, and this document is not part of, nor does it modify, any agreement between\n\nAWS and its customers.\n\n© 2023 Amazon Web Services, Inc. or its aﬃliates. All rights reserved.\n\n220",
      "content_length": 857,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 226,
      "content": "Operational Excellence Pillar\n\nAWS Glossary\n\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.\n\nAWS Well-Architected Framework\n\n221",
      "content_length": 165,
      "extraction_method": "Unstructured"
    }
  ]
}