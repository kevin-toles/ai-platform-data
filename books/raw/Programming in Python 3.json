{
  "metadata": {
    "title": "Programming in Python 3",
    "author": "Mark Summerfield",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 636,
    "conversion_date": "2025-12-25T18:16:51.402080",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Programming in Python 3.pdf",
    "extraction_method": "Unstructured"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 2-9)",
      "start_page": 2,
      "end_page": 9,
      "detection_method": "topic_boundary",
      "content": "Many of the designationsused by manufacturersand sellerstodistinguish their productsareclaimed as trademarks. Where those designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed with initial capital letters or in all capitals.\n\nThe author and publisher have taken care in the preparation of this book, but make no expressed or implied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.\n\nThe publisher offers excellent discounts on this book when ordered in quantity for bulk purchases or special sales, which may include electronic versions and/or custom covers and content particular to your business, training goals, marketing focus, and branding interests. For more information, please contact:\n\nU.S.Corporate and Government Sales (800) 382-3419 corpsales@pearsontechgroup.com\n\nFor sales outside the United States, please contact:\n\nInternational Sales international@pearsoned.com\n\nVisit us on the Web:informit.com/aw\n\nLibrary of Congress Cataloging-in-Publication Data\n\nSummerﬁeld,Mark. Programming in Python 3:a complete introduction to the Python language / Mark Summerﬁeld.—2nd ed. p. cm. Includes bibliographical referencesand index. ISBN 978-0-321-68056-3 (pbk. : alk. paper) 1. Python (Computer program language) 2. Object-oriented programming (Computer science) I. Title.\n\nQA76.73.P98S86 2010 005.13’3—dc22\n\n2009035430\n\nCopyright © 2010 Pearson Education,Inc.\n\nAll rights reserved. Printed in the United States of America. This publication is protected by copyright,and permission must be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording,or likewise. For information regarding permissions, write to:\n\nPearson Education,Inc. Rights and Contracts Department 501Boylston Street,Suite 900 Boston, MA 02116 Fax:(617) 671-3447\n\nISBN-13: 978-0-321-68056-3 ISBN-10: 0-321-68056-1 Text printed in the United States on recycled paper at RR Donnelley in Crawfordsville,Indiana. First printing, November 2009\n\nContents at a Glance\n\nList of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 1. Rapid Introduction to Procedural Programming . . .\n\nChapter 2. Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n\nChapter 3. Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n\nChapter 4. Control Structures and Functions . . . . . . . . . . . . . . . . . . . 159\n\nChapter 5. Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n\nChapter 6. Object-Oriented Programming . . . . . . . . . . . . . . . . . . . . . . 233\n\nChapter 7. File Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\n\nChapter 8. Advanced Programming Techniques . . . . . . . . . . . . . . . . 339\n\nChapter 9. Debugging, Testing, and Proﬁling . . . . . . . . . . . . . . . . . . . 413\n\nChapter 10. Processes and Threading . . . . . . . . . . . . . . . . . . . . . . . . . . . 439\n\nChapter 11. Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 457\n\nChapter 12. Database Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 475\n\nChapter 13. Regular Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489\n\nChapter 14. Introduction to Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 513\n\nChapter 15. Introduction to GUI Programming . . . . . . . . . . . . . . . . . 569\n\nEpilogue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595\n\nSelected Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 597\n\nIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 599\n\nwww.qtrac.eu/py3book.html\n\n1\n\n9\n\nContents\n\nList of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 1. Rapid Introduction to Procedural Programming . . . Creating and Running Python Programs . . . . . . . . . . . . . . . . . . . . . . . . Python’s “Beautiful Heart” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #1: Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #2: Object References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #3: Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #4: Logical Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #5: Control Flow Statements . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #6: Arithmetic Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #7: Input/Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #8: Creating and Calling Functions . . . . . . . . . . . . . . . . . . . . Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bigdigits.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . generate_grid.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 2. Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Identiﬁers and Keywords . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Integral Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Integers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Booleans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Floating-Point Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Floating-Point Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Decimal Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Comparing Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Slicing and Striding Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . String Operators and Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nix\n\nxv\n\n1\n\n9 9 14 14 16 18 21 26 30 33 36 39 39 42 44 47\n\n51 51 54 54 58 58 59 62 63 65 68 69 71\n\nString Formatting with the str.format() Method . . . . . . . . . . . . . . Character Encodings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . quadratic.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . csv2html.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 3. Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Sequence Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Named Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Set Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Frozen Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mapping Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Default Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ordered Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Iterating and Copying Collections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Iterators and Iterable Operations and Functions . . . . . . . . . . . . . Copying Collections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . generate_usernames.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . statistics.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 4. Control Structures and Functions . . . . . . . . . . . . . . . . . . . Control Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Conditional Branching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Looping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exception Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Catching and Raising Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . Custom Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Custom Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Names and Docstrings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Argument and Parameter Unpacking . . . . . . . . . . . . . . . . . . . . . . .\n\nx\n\n78 91 94 94 97 102 104\n\n107 107 108 111 113 120 121 125 126 126 135 136 138 138 146 148 149 152 156 158\n\n159 159 159 161 163 163 168 171 176 177\n\nAccessing Variables in the Global Scope . . . . . . . . . . . . . . . . . . . . . Lambda Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Assertions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Example:make_html_skeleton.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 5. Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Modules and Packages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Packages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Custom Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Overview of Python’s Standard Library . . . . . . . . . . . . . . . . . . . . . . . . . . String Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Command-Line Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mathematics and Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Times and Dates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Algorithms and Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . File Formats, Encodings, and Data Persistence . . . . . . . . . . . . . . . File, Directory, and Process Handling . . . . . . . . . . . . . . . . . . . . . . . . Networking and Internet Programming . . . . . . . . . . . . . . . . . . . . . XML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Other Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 6. Object-Oriented Programming . . . . . . . . . . . . . . . . . . . . . . The Object-Oriented Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Object-Oriented Concepts and Terminology . . . . . . . . . . . . . . . . . . Custom Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Attributes and Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Inheritance and Polymorphism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Using Properties to Control Attribute Access . . . . . . . . . . . . . . . . Creating Complete Fully Integrated Data Types . . . . . . . . . . . . . Custom Collection Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating Classes That Aggregate Collections . . . . . . . . . . . . . . . . Creating Collection Classes Using Aggregation . . . . . . . . . . . . . . Creating Collection Classes Using Inheritance . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxi\n\n180 182 183 185 191 192\n\n195 195 199 202 212 213 214 216 216 217 219 222 225 226 228 230 231\n\n233 234 235 238 238 243 246 248 261 261 269 276 283 285\n\nChapter 7. File Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Writing and Reading Binary Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Pickles with Optional Compression . . . . . . . . . . . . . . . . . . . . . . . . . . Raw Binary Data with Optional Compression . . . . . . . . . . . . . . . Writing and Parsing Text Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Writing Text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing Text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing Text Using Regular Expressions . . . . . . . . . . . . . . . . . . . . Writing and Parsing XML Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Element Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DOM (Document Object Model) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Manually Writing XML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing XML with SAX (Simple API for XML) . . . . . . . . . . . . . . . Random Access Binary Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A Generic BinaryRecordFile Class . . . . . . . . . . . . . . . . . . . . . . . . . . Example:The BikeStock Module’s Classes . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 8. Advanced Programming Techniques . . . . . . . . . . . . . . . . Further Procedural Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Branching Using Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Generator Expressions and Functions . . . . . . . . . . . . . . . . . . . . . . . Dynamic Code Execution and Dynamic Imports . . . . . . . . . . . . . . Local and Recursive Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Function and Method Decorators . . . . . . . . . . . . . . . . . . . . . . . . . . . . Function Annotations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Further Object-Oriented Programming . . . . . . . . . . . . . . . . . . . . . . . . . . Controlling Attribute Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Context Managers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Descriptors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Class Decorators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Abstract Base Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Multiple Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Metaclasses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Functional-Style Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Partial Function Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxii\n\n287 292 292 295 305 305 307 310 312 313 316 319 321 324 324 332 336 337\n\n339 340 340 341 344 351 356 360 363 363 367 369 372 378 380 388 390 395 398\n\nCoroutines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Example:Valid.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 9. Debugging, Testing, and Proﬁling . . . . . . . . . . . . . . . . . . . Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dealing with Syntax Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dealing with Runtime Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Scientiﬁc Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Unit Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proﬁling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 10. Processes and Threading . . . . . . . . . . . . . . . . . . . . . . . . . . . Using the Multiprocessing Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Using the Threading Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Example:A Threaded Find Word Program . . . . . . . . . . . . . . . . . . . Example:A Threaded Find Duplicate Files Program . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 11. Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a TCP Client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a TCP Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 12. Database Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DBM Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . SQL Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 13. Regular Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Python’s Regular Expression Language . . . . . . . . . . . . . . . . . . . . . . . . . . Characters and Character Classes . . . . . . . . . . . . . . . . . . . . . . . . . . Quantiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Grouping and Capturing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Assertions and Flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The Regular Expression Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxiii\n\n399 407 410 411\n\n413 414 414 415 420 425 432 437\n\n439 440 444 446 449 454 455\n\n457 458 464 471 471\n\n475 476 480 487 488\n\n489 490 490 491 494 496 499\n\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 14. Introduction to Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . BNF Syntax and Parsing Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . Writing Handcrafted Parsers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Simple Key–Value Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . Playlist Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing the Blocks Domain-Speciﬁc Language . . . . . . . . . . . . . . . Pythonic Parsing with PyParsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A Quick Introduction to PyParsing . . . . . . . . . . . . . . . . . . . . . . . . . . Simple Key–Value Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . Playlist Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing the Blocks Domain-Speciﬁc Language . . . . . . . . . . . . . . . Parsing First-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Lex/Yacc-Style Parsing with PLY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Simple Key–Value Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . Playlist Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing the Blocks Domain-Speciﬁc Language . . . . . . . . . . . . . . . Parsing First-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 15. Introduction to GUI Programming . . . . . . . . . . . . . . . . . Dialog-Style Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Main-Window-Style Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a Main Window . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a Custom Dialog . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nEpilogue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nSelected Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxiv\n\n509 510\n\n513 514 519 519 522 525 534 535 539 541 543 548 553 555 557 559 562 566 568\n\n569 572 578 578 590 593 593\n\n595\n\n597\n\n599",
      "page_number": 2
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 10-18)",
      "start_page": 10,
      "end_page": 18,
      "detection_method": "topic_boundary",
      "content": "List of Tables\n\n2.1. Python’s Keywords . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 2.2. Numeric Operators and Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 55 2.3.\n\nInteger Conversion Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Integer Bitwise Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 2.5. The Math Module’s Functions and Constants #1 . . . . . . . . . . . . . . 60 2.6. The Math Module’s Functions and Constants #2 . . . . . . . . . . . . . . 61 2.7. Python’s String Escapes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 2.8. String Methods #1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 2.9. String Methods #2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 2.10. String Methods #3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 3.1. List Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 3.2. Set Methods and Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 3.3. Dictionary Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 3.4. Common Iterable Operators and Functions . . . . . . . . . . . . . . . . . . . 140 6.1. Comparison Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 6.2. Fundamental Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250 6.3. Numeric and Bitwise Special Methods . . . . . . . . . . . . . . . . . . . . . . . 253 6.4. Collection Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265 7.1. Bytes and Bytearray Methods #1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299 7.2. Bytes and Bytearray Methods #2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300 7.3. Bytes and Bytearray Methods #3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301 7.4. File Object Attributes and Methods #1 . . . . . . . . . . . . . . . . . . . . . . . 325 7.5. File Object Attributes and Methods #2 . . . . . . . . . . . . . . . . . . . . . . . 326 8.1. Dynamic Programming and Introspection Functions . . . . . . . . . . 349 8.2. Attribute Access Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365 8.3. The Numbers Module’s Abstract Base Classes . . . . . . . . . . . . . . . . 381 8.4. The Collections Module’s Main Abstract Base Classes . . . . . . . . . 383 12.1. DB-API 2.0 Connection Object Methods . . . . . . . . . . . . . . . . . . . . . . 481 12.2. DB-API 2.0 Cursor Object Attributes and Methods . . . . . . . . . . . 482 13.1. Character Class Shorthands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492\n\n2.4.\n\nxv\n\n13.2. Regular Expression Quantiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 493 13.3. Regular Expression Assertions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 497 13.4. The Regular Expression Module’s Functions . . . . . . . . . . . . . . . . . 502 13.5. The Regular Expression Module’s Flags . . . . . . . . . . . . . . . . . . . . . . 502 13.6. Regular Expression Object Methods . . . . . . . . . . . . . . . . . . . . . . . . . 503 13.7. Match Object Attributes and Methods . . . . . . . . . . . . . . . . . . . . . . . . 507\n\nxvi\n\nIntroduction\n\nPython is probably the easiest-to-learn and nicest-to-use programming lan- guage in widespread use. Python code is clear to read and write, and it is con- cise without being cryptic. Python is a very expressive language,which means thatwecanusually writefar fewer linesof Pythoncodethanwouldberequired for an equivalent application written in, say, C++ or Java.\n\nPython is a cross-platformlanguage:In general,the same Python program can be run on Windows and Unix-like systems such as Linux, BSD, and Mac OS X, simply by copying the ﬁle or ﬁles that make up the program to the target machine, with no “building” or compiling necessary. It is possible to create Python programs that use platform-speciﬁc functionality, but this is rarely necessary since almost all of Python’s standard library and most third-party libraries are fully and transparently cross-platform.\n\nOne of Python’sgreat strengthsis that it comeswith a very complete standard library—this allows us to do such things as download a ﬁle from the Internet, unpack a compressed archive ﬁle, or create a web server, all with just one or a few lines of code. And in addition to the standard library, thousands of third- party libraries are available, some providing more powerful and sophisticat- ed facilities than the standard library—for example, the Twisted networking library and the NumPy numeric library—while others provide functionality that is too specialized to be included in the standard library—for example, the SimPy simulationpackage. Mostof thethird-partylibrariesareavailablefrom the Python Package Index, pypi.python.org/pypi.\n\nPython can be used to program in procedural, object-oriented, and to a lesser extent, in functional style, although at heart Python is an object-oriented language. This book shows how to write both procedural and object-oriented programs, and also teaches Python’s functional programming features.\n\nThe purpose of this book is to show you how to write Python programs in good idiomatic Python 3style,and to be a useful referencefor thePython 3language aftertheinitialreading. AlthoughPython3isanevolutionary ratherthanrev- olutionary advanceonPython2,someolder practicesarenolonger appropriate or necessary in Python 3, and new practices have been introduced to take ad- vantage of Python 3 features. Python 3is a better language than Python 2—it builds on the many years of experience with Python 2 and adds lots of new features(and omitsPython 2’smisfeatures),to makeit even moreof a pleasure to use than Python 2, as well as more convenient, easier, and more consistent.\n\n1\n\n2\n\nIntroduction\n\nThe book’s aim is to teach the Python language, and although many of the standard Python libraries are used, not all of them are. This is not a problem, because once you have read the book, you will have enough Python knowledge to be able to make use of any of the standard libraries, or any third-party Python library, and be able to create library modules of your own.\n\nThe book is designed to be useful to several different audiences,including self- taught and hobbyist programmers, students, scientists, engineers, and others who need to program as part of their work, and of course, computing profes- sionals and computer scientists. To be of use to such a wide range of people without boring the knowledgeable or losing the less-experienced, the book as- sumes at least some programming experience (in any language). In particu- lar, it assumes a basic knowledge of data types (such as numbers and strings), collection data types (such as sets and lists), control structures (such as if and while statements), and functions. In addition, some examples and exercises assumea basic knowledgeof HTML markup,and some of the morespecialized chapters at the end assume a basic knowledge of their subject area; for exam- ple, the databases chapter assumes a basic knowledge of SQL.\n\nThe book is structured in such a way as to make you as productive as possible as quickly as possible. By the end of the ﬁrst chapter you will be able to write small but useful Python programs. Each successive chapter introduces new topics, and often both broadens and deepens the coverage of topics introduced in earlier chapters. This means that if you read the chapters in sequence, you can stop at any point and you’ll be able to write complete programs with what you have learned up to that point, and then, of course, resume reading to learn more advanced and sophisticated techniques when you are ready. For this reason, some topics are introduced in one chapter, and then are explored further in one or more later chapters.\n\nTwo key problems arise when teaching a new programming language. The ﬁrst is that sometimes when it is necessary to teach one particular concept, that conceptdependson another concept,which in turndependseither directly or indirectly on the ﬁrst. The second is that, at the beginning, the reader may know little or nothing of the language, so it is very difﬁcult to present inter- esting or useful examples and exercises. In this book, we seek to solve both of these problems,ﬁrst by assuming some prior programming experience,and secondby presenting Python’s“beautifulheart”in Chapter 1—eight key pieces of Python that are sufﬁcient on their own to write decent programs. One con- sequence of this approach is that in the early chapters some of the examples are a bit artiﬁcial in style, since they use only what has been taught up to the point wherethey arepresented;thiseffect diminisheschapter by chapter,until by theendof Chapter7,alltheexamplesarewrittenin completely naturaland idiomatic Python 3 style.\n\nThe book’s approach is wholly practical,and you are encouraged to try out the examples and exercises for yourself to get hands-on experience. Wherever\n\nIntroduction\n\npossible, small but complete programs and modules are used as examples to provide realistic use cases. The examples, exercise solutions, and the book’s errata are available online at www.qtrac.eu/py3book.html.\n\nTwo sets of examples are provided. The standard examples work with any Python 3.x version—use these if you care about Python 3.0 compatibility. The “eg31” examples work with Python 3.1 or later—use these if you don’t need to support Python 3.0 because your programs’ users have Python 3.1or later. All of the examples have been tested on Windows, Linux, and Mac OS X.\n\nWhile it is best to use the most recent version of Python 3, this is not always possible if your users cannot or will not upgrade. Every example in this book works with Python 3.0 except where stated, and those examples and features that are speciﬁc to Python 3.1 are clearly indicated as such.\n\nAlthough it is possible to use this book to develop software that uses only Python 3.0, for those wanting to produce software that is expected to be in use for many years and that is expected to be compatible with later Python 3.x re- leases, it is best to use Python 3.1 as the oldest Python 3 version that you sup- port. This is partly because Python 3.1 has some very nice new features, but mostly because the Python developers strongly recommend using Python 3.1 (or later). The developers have decided that Python 3.0.1 will be the last Python 3.0.y release,and that there will be no more Python 3.0.y releaseseven if bugs or security problems are discovered. Instead, they want all Python 3 users to migrate to Python 3.1 (or to a later version), which will have the usu- al bugﬁx and security maintenance releases that Python versions normal- ly have.\n\nThe Structure of the Book\n\nChapter 1 presents eight key pieces of Python that are sufﬁcient for writing complete programs. It also describes some of the Python programming environmentsthatareavailableandpresentstwotiny exampleprograms,both built using the eight key pieces of Python covered earlier in the chapter.\n\nChapters 2 through 5 introduce Python’s procedural programming features, including its basic data types and collection data types,and many useful built- in functions and control structures, as well as very simple text ﬁle handling. Chapter 5 shows how to create custom modules and packages and provides an overview of Python’s standard library so that you will have a good idea of the functionality that Python provides out of the box and can avoid reinventing the wheel.\n\nChapter 6 provides a thorough introduction to object-oriented programming with Python. All of the material on procedural programming that you learned in earlier chapters is still applicable, since object-oriented programming is\n\n3\n\n4\n\nIntroduction\n\nbuilt on procedural foundations—for example, making use of the same data types, collection data types, and control structures.\n\nChapter 7 covers writing and reading ﬁles. For binary ﬁles, the coverage in- cludescompression and random access,and for text ﬁles,the coverage includes parsing manually and with regular expressions. This chapter also shows how to write and read XML ﬁles, including using element trees, DOM (Document Object Model), and SAX (Simple API for XML).\n\nChapter8revisitsmaterialcoveredinsomeearlierchapters,exploring manyof Python’smore advanced featuresin the areas of data typesand collection data types, control structures, functions, and object-oriented programming. This chapteralsointroducesmany newfunctions,classes,andadvancedtechniques, including functional-style programming and the use of coroutines—the mate- rial it covers is both challenging and rewarding.\n\nChapter9isdifferentfromalltheother chaptersin thatit discussestechniques and libraries for debugging, testing, and proﬁling programs, rather than introducing new Python features.\n\nTheremaining chapterscovervariousadvancedtopics. Chapter10showstech- niques for spreading a program’s workload over multiple processes and over multiple threads. Chapter 11 shows how to write client/server applications using Python’sstandardnetworking support. Chapter 12coversdatabasepro- gramming (both simple key–value “DBM” ﬁles and SQL databases).\n\nChapter13explainsandillustratesPython’sregularexpressionmini-language andcoverstheregularexpressionsmodule. Chapter14followsonfromthereg- ularexpressionschapterbyshowingbasicparsingtechniquesusingregularex- pressions,and also using twothird-party modules,PyParsing and PLY.Finally, Chapter 15introducesGUI (GraphicalUser Interface)programming using the tkinter module that is part of Python’s standard library. In addition,the book has a very brief epilogue, a selected bibliography, and of course, an index.\n\nMost of the book’s chapters are quite long to keep all the related material together in one place for ease of reference. However, the chapters are broken down into sections, subsections, and sometimes subsubsections,so it is easy to read at a pace that suits you;for example,by reading one section or subsection at a time.\n\nObtaining and Installing Python 3\n\nIf you have a modern and up-to-date Mac or other Unix-like system you may already have Python 3 installed. You can check by typing python -V (note the capital V) in a console (Terminal.app on Mac OS X)—if the version is 3.x you’ve already got Python 3 and don’t have to install it yourself. If Python wasn’t found at all it may be that it has a name which includesa version number. Try\n\nIntroduction\n\ntyping python3 -V,andif that doesnot work try python3.0 -V,andfailing thattry python3.1 -V.If any of these work you now know that you already have Python installed,whatversionit is,andwhat it iscalled. (Inthisbook weusethename python3, but use whatever name worked for you,for example, python3.1.) If you don’t have any version of Python 3 installed, read on.\n\nFor Windows and Mac OS X, easy-to-use graphical installer packages are pro- vided that take you step-by-step through the installation process. These are available from www.python.org/download.For Windows,download the “Windows x86 MSI Installer”,unless you know for sure that your machine has a different processor for which a separate installer is supplied—for example, if you have an AMD64, get the “Windows AMD64 MSI Installer”. Once you’ve got the in- staller, just run it and follow the on-screen instructions.\n\nFor Linux, BSD, and other Unixes (apart from Mac OS X for which a .dmg in- stallation ﬁle is provided),the easiest way to install Python is to use your oper- ating system’spackagemanagement system. In most casesPython isprovided in several separate packages. For example, in Ubuntu (from version 8), there is python3.0 for Python, idle-python3.0 for IDLE (a simple development envi- ronment), and python3.0-doc for the documentation—as well as many other packages that provide add-ons for even more functionality than that provided by the standard library. (Naturally, the package names will start with python- 3.1 for the Python 3.1 versions, and so on.)\n\nIf no Python 3 packages are available for your operating system you will need to download the source from www.python.org/download and build Python from scratch. Get either of the source tarballs and unpack it using tar xvfz Python-3.1.tgz if you got the gzipped tarball or tar xvfj Python-3.1.tar.bz2 if you got the bzip2 tarball. (The version numbers may be different,for example, Python-3.1.1.tgz or Python-3.1.2.tar.bz2,in which casesimply replace 3.1 with your actual version number throughout.) The conﬁguration and building are standard. First, change into the newly created Python-3.1 directory and run ./configure. (You can use the --prefix option if you want to do a local install.) Next, run make.\n\nIt is possible that you may get some messages at the end saying that not all modules could be built. This normally means that you don’t have some of the required libraries or headers on your machine. For example, if the readline module could not be built, use the package management system to install the corresponding development library; for example, readline-devel on Fedora- based systems and readline-dev on Debian-based systems such as Ubuntu. Another module that may not build straight away is the tkinter module—this depends on both the Tcl and Tk development libraries, tcl-devel and tk-devel on Fedora-based systems, and tcl8.5-dev and tk8.5-dev on Debian-based sys- tems (and where the minor version may not be 5). Unfortunately, the relevant package names are not always so obvious, so you might need to ask for help on\n\n5\n\n6\n\nIntroduction\n\nPython’smailing list. Oncethemissing packagesareinstalled,run ./configure and make again.\n\nAfter successfully making, you could run make test to see that everything is okay, although this is not necessary and can take many minutes to complete.\n\nIf you used --prefix to do a local installation, just run make install. For Python 3.1,if you installed into,say,~/local/python31,then by adding the ~/lo- cal/python31/bin directory to your PATH, you will be able to run Python using python3 andIDLEusing idle3.Alternatively,if you already havea localdirecto- ry for executables that is already in your PATH (such as ~/bin),you might prefer to add soft links instead of changing the PATH. For example, if you keep exe- cutablesin ~/bin andyou installedPythonin ~/local/python31,you couldcreate suitable links by executing ln -s ~/local/python31/bin/python3 ~/bin/python3, and ~/local/python31/bin/idle3 ~/bin/idle3.For this book we did a local install and added soft links on Linux and Mac OS X exactly as described here—and on Windows we used the binary installer.\n\nIf you did not use --prefix and have root access, log in as root and do make in- stall. On sudo-based systems like Ubuntu, do sudo make install. If Python 2 is on the system, /usr/bin/python won’t be changed, and Python 3 will be avail- able as python3.0 (or python3.1 depending on the version installed) and from Python 3.1, in addition, as python3. Python 3.0’s IDLE is installed as idle, so if access to Python 2’s IDLE is still required the old IDLE will need to be renamed—for example,to /usr/bin/idle2—beforedoing the install. Python 3.1 installs IDLE as idle3 and so does not conﬂict with Python 2’s IDLE.\n\nAcknowledgments\n\nI would ﬁrst like to acknowledge with thanks the feedback I have received from readers of the ﬁrst edition, who gave corrections, or made suggestions, or both.\n\nMy next acknowledgments are of the book’s technical reviewers, starting with Jasmin Blanchette, a computer scientist, programmer, and writer with whom I have cowritten two C++/Qt books. Jasmin’s involvement with chapter planning andhissuggestionsandcriticismsregarding alltheexamples,aswell as his careful reading, have immensely improved the quality of this book.\n\nGeorg Brandl is a leading Python developer and documentor responsible for creating Python’s new documentation tool chain. Georg spotted many sub- tle mistakes and very patiently and persistently explained them until they were understood and corrected. He also made many improvements to the ex- amples.\n\nIntroduction\n\nPhil Thompson is a Python expert and the creator of PyQt, probably the best Python GUI library available. Phil’s sharp-eyed and sometimes challenging feedback led to many clariﬁcations and corrections.\n\nTrenton Schulz is a senior software engineer at Nokia’s Qt Software (formerly Trolltech) who has been a valuable reviewer of all my previous books, and has once again come to my aid. Trenton’s careful reading and the numerous sug- gestions that he made helped clarify many issues and have led to considerable improvements to the text.\n\nIn addition to the aforementioned reviewers, all of whom read the whole book, David Boddie, a senior technical writer at Nokia’s Qt Software and an experiencedPythonpractitionerandopensourcedeveloper,hasreadandgiven valuable feedback on portions of it.\n\nFor this second edition, I would also like to thank Paul McGuire (author of the PyParsing module), who was kind enough to review the PyParsing examples that appear in thenew chapter on parsing,and who gave me a lot of thoughtful and useful advice. And for the same chapter, David Beazley (author of the PLY module) reviewed the PLY examples and provided valuable feedback. In addition, Jasmin, Trenton, Georg, and Phil read most of this second edition’s new material, and provided very valuable feedback.\n\nThanks are also due to Guido van Rossum, creator of Python, as well as to the wider Python community who have contributed so much to make Python, and especially its libraries, so useful and enjoyable to use.\n\nAs always, thanks to Jeff Kingston, creator of the Lout typesetting language that I have used for more than a decade.\n\nSpecial thanks to my editor, Debra Williams Cauley, for her support, and for once again making the entire process as smooth as possible. Thanks also to Anna Popick, who managed the production process so well, and to the proof- reader, Audrey Doyle, who did such ﬁne work once again. And for this second edition I also want to thank Jennifer Lindner for helping me keep the new ma- terial understandable,and theﬁrst edition’sJapanesetranslator TakahiroNa- gao ,for spotting some subtle mistakeswhich I’ve been able to correct in this edition.\n\nLast but not least, I want to thank my wife, Andrea, both for putting up with the 4 a.m. wake-ups when book ideas and code corrections often arrived and insisted upon being noted or tested there and then, and for her love, loyalty, and support.\n\n7",
      "page_number": 10
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 19-26)",
      "start_page": 19,
      "end_page": 26,
      "detection_method": "topic_boundary",
      "content": "1\n\nCreating and Running Python Programs\n\nPython’s “Beautiful Heart”\n\nRapid Introduction to Procedural Programming\n\nThis chapter provides enough information to get you started writing Python programs. We strongly recommend that you install Python if you have not already done so,so that you can get hands-on experience to reinforce what you learn here. (The Introduction explains how to obtain and install Python on all major platforms; 4 ➤.)\n\nThis chapter’s ﬁrst section shows you how to create and execute Python pro- grams. You can use your favorite plain text editor to write your Python code, but the IDLEprogramming environment discussed in thissection providesnot only a code editor, but also additional functionality, including facilities for ex- perimenting with Python code, and for debugging Python programs.\n\nThe second section presents eight key pieces of Python that on their own are sufﬁcient to write useful programs. These pieces are all covered fully in later chapters, and as the book progresses they are supplemented by all of the rest of Python so that by the end of the book, you will have covered the whole language and will be able to use all that it offers in your programs.\n\nThe chapter’sﬁnal section introducestwo short programswhich use the subset of Python features introduced in the second section so that you can get an immediate taste of Python programming.\n\nCreating and Running Python Programs\n\nPython code can be written using any plain text editor that can load and save encoding. By de- text using either the ASCII or the UTF-8 Unicode character fault, Python ﬁles are assumed to use the UTF-8 character encoding, a super- set of ASCII that can represent pretty well every character in every language. Pythonﬁlesnormally haveanextensionof .py,althoughonsomeUnix-likesys-\n\n9\n\n||||\n\n|||\n\nChar- acter encod- ings ➤ 91\n\n10\n\nChapter 1. Rapid Introduction to Procedural Programming\n\ntems (e.g., Linux and Mac OS X) some Python applications have no extension, and Python GUI (Graphical User Interface) programs usually have an exten- sion of .pyw,particularlyon WindowsandMac OSX.In thisbook wealwaysuse an extension of .py for Python console programsand Python modules,and .pyw for GUI programs. All the examples presented in this book run unchanged on all platforms that have Python 3 available.\n\nJust to make sure that everything is set up correctly, and to show the clas- sical ﬁrst example, create a ﬁle called hello.py in a plain text editor (Win- dows Notepad is ﬁne—we’ll use a better editor shortly), with the following contents:\n\n#!/usr/bin/env python3\n\nprint(\"Hello\", \"World!\")\n\nTheﬁrstlineisacomment. InPython,commentsbeginwitha # andcontinueto the end of the line. (We will explain the rather cryptic comment in a moment.) The second line is blank—outside quoted strings, Python ignores blank lines, but they are often useful to humans to break up large blocks of code to make them easier to read. The third line is Python code. Here, the print() function is called with two arguments, each of type str (string; i.e., a sequence of char- acters).\n\nEach statement encountered in a .py ﬁle is executed in turn, starting with the ﬁrst one and progressing line by line. This is different from some other languages, for example, C++ and Java, which have a particular function or method with a special name where they start from. The ﬂow of control can of course be diverted as we will see when we discuss Python’s control structures in the next section.\n\nWe will assume that Windows users keep their Python code in the C:\\py3eg directory and that Unix (i.e.,Unix,Linux,and Mac OS X) userskeep their code in the $HOME/py3eg directory. Save hello.py into the py3eg directory and close the text editor.\n\nNow that we have a program, we can run it. Python programs are executed by the Python interpreter, and normally this is done inside a console window. On Windows the console is called “Console”, or “DOS Prompt”, or “MS-DOS Prompt”, or something similar, and is usually available from Start→All Pro- grams→Accessories.On Mac OSX the console isprovided by the Terminal.apppro- gram (located in Applications/Utilities by default),available using Finder,and on other Unixes,we can use an xterm or the console provided by the windowing environment, for example, konsole or gnome-terminal.\n\nStart up a console, and on Windows enter the following commands (which assume that Python is installed in the default location)—the console’s output is shown in lightface; what you type is shown in bold:\n\nCreating and Running Python Programs\n\nC:\\>cd c:\\py3eg C:\\py3eg\\>c:\\python31\\python.exe hello.py\n\nSince the cd (change directory) command has an absolute path, it doesn’t matter which directory you start out from.\n\nUnix users enter this instead (assuming that Python 3 is in the PATH):★\n\n$ cd $HOME/py3eg $ python3 hello.py\n\nIn both cases the output should be the same:\n\nHello World!\n\nNote that unless stated otherwise, Python’s behavior on Mac OS X is the same as that on any other Unix system. In fact, whenever we refer to “Unix” it can be taken to mean Linux, BSD, Mac OS X, and most other Unixes and Unix-like systems.\n\nAlthough the program hasjust one executable statement,by running it we can infer some information about the print() function. For one thing, print() is a built-in part of the Python language—we didn’t need to “import” or “include” it from a library to make use of it. Also, it separates each item it prints with a single space, and prints a newline after the last item is printed. These are default behaviors that can be changed, as we will see later. Another thing worth noting about print() is that it can take as many or as few arguments as we care to give it.\n\nTyping such command lines to invoke our Python programs would quickly become tedious. Fortunately, on both Windows and Unix we can use more convenient approaches. Assuming we are in the py3eg directory, on Windows we can simply type:\n\nC:\\py3eg\\>hello.py\n\nWindows uses its registry of ﬁle associations to automatically call the Python interpreter when a ﬁlename with extension .py is entered in a console.\n\nUnfortunately, this convenience does not always work, since some versions of Windows have a bug that sometimes affects the execution of interpreted programs that are invoked as the result of a ﬁle association. This isn’t speciﬁc to Python; other interpreters and even some .bat ﬁles are affected by the bug too. If this problem arises, simply invoke Python directly rather than relying on the ﬁle association.\n\nIf the output on Windows is:\n\n★The Unix prompt may well be different from the $ shown here; it does not matter what it is.\n\n11\n\nprint() ➤ 181\n\n12\n\nChapter 1. Rapid Introduction to Procedural Programming\n\n('Hello', 'World!')\n\nthen it means that Python 2 is on the system and is being invoked instead of Python 3. One solution to this is to change the .py ﬁle association from Python 2 to Python 3. The other (less convenient, but safer) solution is to put the Python 3 interpreter in the path (assuming it is installed in the default lo- cation),andexecuteit explicitly each time. (ThisalsogetsaroundtheWindows ﬁle association bug mentioned earlier.) For example:\n\nC:\\py3eg\\>path=c:\\python31;%path% C:\\py3eg\\>python hello.py\n\nIt might be more convenient to create a py3.bat ﬁle with the single line path=c:\\python31;%path% and to save this ﬁle in the C:\\Windows directory. Then, whenever you start a console for running Python 3 programs, begin by exe- cuting py3.bat. Or alternatively you can have py3.bat executed automatically. To do this, change the console’s properties (ﬁnd the console in the Start menu, then right-click it to pop up its Properties dialog), and in the Shortcut tab’s Target string, append the text “ /u /k c:\\windows\\py3.bat” (note the space before, between, and after the “/u” and “/k” options, and be sure to add this at the end after “cmd.exe”).\n\nOn Unix, we must ﬁrst make the ﬁle executable, and then we can run it:\n\n$ chmod +x hello.py $ ./hello.py\n\nWe need to run the chmod command only once of course; after that we can simply enter ./hello.py and the program will run.\n\nOn Unix,when a program is invoked in the console,the ﬁle’s ﬁrst two bytesare read.★ If thesebytesaretheASCIIcharacters#!,theshell assumesthat theﬁle is to be executed by an interpreter and that the ﬁle’s ﬁrst line speciﬁes which interpreter to use. This line is called the shebang (shell execute) line, and if present must be the ﬁrst line in the ﬁle.\n\nThe shebang line is commonly written in one of two forms, either:\n\n#!/usr/bin/python3\n\nor:\n\n#!/usr/bin/env python3\n\nIf written using the ﬁrst form, the speciﬁed interpreter is used. This form may be necessary for Python programs that are to be run by a web server,\n\n★Theinteractionbetween theuser andtheconsoleishandledby a “shell”program. Thedistinction between the console and the shell does not concern us here, so we use the terms interchangeably.\n\nObtain- ing and install- ing Python 4➤\n\nCreating and Running Python Programs\n\nalthough the speciﬁc path may be different from the one shown. If written using the second form, the ﬁrst python3 interpreter found in the shell’s current environment is used. The second form is more versatile because it allows for the possibility that the Python 3 interpreter is not located in /usr/bin (e.g., it could be in /usr/local/bin or installed under $HOME). The shebang line is not needed (but is harmless) under Windows; all the examples in this book have a shebang line of the second form, although we won’t show it.\n\nNote that for Unix systems we assume that the name of Python 3’s executable (or a soft link to it) in the PATH is python3. If this is not the case, you will need to change the shebang line in the examples to use the correct name (or correct name and path if you use the ﬁrst form),or create a soft link from the Python 3 executable to the name python3 somewhere in the PATH.\n\nMany powerful plain text editors, such as Vim and Emacs, come with built-in typicallyinvolvesproviding supportforeditingPythonprograms. Thissupport color syntax highlighting and correctly indenting or unindenting lines. An al- ternative is to use the IDLE Python programming environment. On Windows and Mac OS X, IDLE is installed by default. On Unixes IDLE is built along with the Python interpreter if you build from the tarball,but if you use a pack- age manager, IDLE is usually provided as a separate package as described in the Introduction.\n\nAs the screenshot in Figure 1.1shows,IDLEhas a rather retro look that harks back to the days of Motif on Unix and Windows 95. This is because it uses the Tk-based Tkinter GUI library (covered in Chapter 15) rather than one of the more powerful modern GUI libraries such as PyGtk, PyQt, or wxPython. The reasons for the use of Tkinter are a mixture of history, liberal license condi- tions, and the fact that Tkinter is much smaller than the other GUI libraries. On the plus side, IDLE comes as standard with Python and is very simple to learn and use.\n\nIDLE provides three key facilities: the ability to enter Python expressions and code and to see the results directly in the Python Shell; a code editor that provides Python-speciﬁc color syntax highlighting and indentation support; and a debugger that can be used to step through code to help identify and kill bugs. The Python Shell is especially useful for trying out simple algorithms, snippets of code, and regular expressions, and can also be used as a very powerful and ﬂexible calculator.\n\nSeveral other Python development environments are available, but we recom- mend that you use IDLE, at least at ﬁrst. An alternative is to create your pro- grams in the plain text editor of your choice and debug using calls to print().\n\nIt is possible to invoke the Python interpreter without specifying a Python program. If this is done the interpreter starts up in interactive mode. In this mode it is possible to enter Python statements and see the results exactly the same as when using IDLE’s Python Shell window, and with the same >>>\n\n13\n\n14\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nFigure 1.1 IDLE’s Python Shell\n\nprompts. But IDLE is much easier to use, so we recommend using IDLE for experimenting with code snippets. The short interactive examples we show are all assumed to be entered in an interactive Python interpreter or in IDLE’s Python Shell.\n\nWe now know how to create and run Python programs,but clearly we won’t get very far knowing only a single function. In the next section we will consider- ably increaseour Python knowledge. Thiswill makeusableto createshort but useful Python programs, something we will do in this chapter’s last section.\n\nPython’s “Beautiful Heart”\n\nIn this section we will learn about eight key pieces of Python, and in the next section we will show how these piecescan be used to writea coupleof small but realistic programs. There is much more to say about all of the things covered in this section, so if as you read it you feel that Python is missing something or that things are sometimes done in a long-winded way, peek ahead using the forward references or using the table of contents or index, and you will almost certainly ﬁnd that Python hasthe feature you want and often hasmore concise forms of expression than we show here—and a lot more besides.\n\nPiece #1: Data Types\n\nOne fundamental thing that any programming language must be able to do is represent items of data. Python provides several built-in data types, but we will concern ourselves with only two of them for now. Python represents\n\n|||\n\n||\n\nPython’s “Beautiful Heart”\n\nintegers (positive and negative whole numbers) using the int type, and it represents strings (sequences of Unicode characters) using the str type. Here are some examples of integer and string literals:\n\n973 210624583337114373395836055367340864637790190801098222508621955072 0 \"Infinitely Demanding\" 'Simon Critchley' 'positively αβγ ÷©' ''\n\nIncidentally, the second number shown is 2217—the size of Python’s integers is limited only by machine memory, not by a ﬁxed number of bytes. Strings can be delimited by double or single quotes, as long as the same kind are used at both ends, and since Python uses Unicode, strings are not limited to ASCII characters, as the penultimate string shows. An empty string is simply one with nothing between the delimiters.\n\nPython uses square brackets ([]) to access an item from a sequence such as a string. For example, if we are in a Python Shell (either in the interactive interpreter,or in IDLE) we can enter the following—the Python Shell’s output is shown in lightface; what you type is shown in bold:\n\n>>> \"Hard Times\"[5] 'T' >>> \"giraffe\"[0] 'g'\n\nTraditionally, Python Shells use >>> as their prompt, although this can be changed. The square brackets syntax can be used with data items of any data type that is a sequence, such as strings and lists. This consistency of syntax is one of the reasons that Python is so beautiful. Note that all Python index positions start at 0.\n\nIn Python, both str and the basic numeric types such as int are im- mutable—that is,once set,their value cannot be changed. At ﬁrst thisappears to be a rather strange limitation,but Python’ssyntax means that this is a non- issuein practice. Theonly reason for mentioning it isthat although wecan use square brackets to retrieve the character at a given index position in a string, we cannot use them to set a new character. (Note that in Python a character is simply a string of length 1.)\n\nTo convert a data item from one type to another we can use the syntax datatype(item). For example:\n\n>>> int(\"45\") 45\n\n15\n\n16\n\nChapter 1. Rapid Introduction to Procedural Programming\n\n>>> str(912) '912'\n\nThe int() conversion is tolerant of leading and trailing whitespace, so int(\" 45 \") would have worked just as well. The str() conversion can be applied to almost any data item. We can easily make our own custom data types support str() conversion, and also int() or other conversions if they make sense, as we will see in Chapter 6. If a conversion fails, an exception is raised—we brieﬂy introduce exception-handling in Piece #5, and fully cover exceptions in Chapter 4.\n\nStrings and integers are fully covered in Chapter 2, along with other built-in data types and some data types from Python’s standard library. That chapter also covers operations that can be applied to immutable sequences, such as strings.\n\nPiece #2: Object References\n\nOnce we have some data types, the next thing we need are variables in which to store them. Python doesn’t have variables as such, but instead has object references. When it comes to immutable objects like ints and strs, there is no discernable difference between a variable and an object reference. As for mutable objects,there is a difference,but it rarely mattersin practice. We will use the terms variable and object reference interchangeably.\n\nLet’s look at a few tiny examples, and then discuss some of the details.\n\nx = \"blue\" y = \"green\" z = x\n\nThe syntax is simply objectReference = value. There is no need for predecla- ration and no need to specify the value’s type. When Python executes the ﬁrst statement it creates a str object with the text “blue”, and creates an object ref- erence called x that refers to the str object. For all practical purposes we can say that “variable x has been assigned the ‘blue’ string”.The second statement is similar. The third statement createsa new object reference called z and sets it to refer to the same object that the x object reference refers to (in this case the str containing the text “blue”).\n\nThe = operator is not the same as the variable assignment operator in some other languages. The = operator binds an object reference to an object in memory. If the object reference already exists,it is simply re-bound to refer to the object on the right of the = operator;if the object reference does not exist it is created by the = operator.\n\n||\n\nShallow and deep copying ➤ 146",
      "page_number": 19
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 27-35)",
      "start_page": 27,
      "end_page": 35,
      "detection_method": "topic_boundary",
      "content": "18\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nroute = \"North\" print(route, type(route)) # prints: North <class 'str'>\n\nHere we create a new object reference called route and set it to refer to a new int of value 866.At thispoint we could use / with route since division is a valid operation for integers. Then we reuse the route object reference to refer to a new str of value “North”,and the int object is scheduled for garbage collection sincenow no object referencerefersto it. At thispoint using / with route would cause a TypeError to be raised since / is not a valid operation for a string.\n\nThe type() function returns the data type (also known as the “class”) of the data item it is given—this function can be very useful for testing and debug- ging, but would not normally appear in production code, since there is a better alternative as we will see in Chapter 6.\n\nIf we are experimenting with Python code inside the interactive interpreter or in a Python Shell such as the one provided by IDLE, simply typing the name of an object reference is enough to have Python print its value. For example:\n\n>>> x = \"blue\" >>> y = \"green\" >>> z = x >>> x 'blue' >>> x, y, z ('blue', 'green', 'blue')\n\nThis is much more convenient than having to call the print() function all the time, but works only when using Python interactively—any programs and modules that we write must use print() or similar functions to produce output. Notice that Python displayedthe last output in parenthesesseparated by commas—this signiﬁes a tuple, that is, an ordered immutable sequence of objects. We will cover tuples in the next piece.\n\nPiece #3: Collection Data Types\n\nIt is often convenient to hold entire collections of data items. Python provides several collection data types that can hold items, including associative arrays andsets. But herewewillintroducejust two:tuple and list.Pythontuplesand lists can be used to hold any number of data items of any data types. Tuples are immutable, so once they are created we cannot change them. Lists are mutable, so we can easily insert items and remove items whenever we want.\n\nTuples are created using commas (,), as these examples show—and note that here, and from now on, we don’t use bold to distinguish what you type:\n\n>>> \"Denmark\", \"Finland\", \"Norway\", \"Sweden\" ('Denmark', 'Finland', 'Norway', 'Sweden')\n\n||\n\nisin- stance() ➤ 242\n\nPython’s “Beautiful Heart”\n\n19\n\n>>> \"one\", ('one',)\n\nPythonoutputsa tupleit enclosesitinparentheses. Many programmers When emulate this and always enclose the tuple literals they write in parentheses. If we have a one-item tuple and want to use parentheses, we must still use the comma—for example, (1,). An empty tuple is created by using empty parentheses, (). The comma is also used to separate arguments in function calls,so if we want to pass a tuple literal as an argument we must enclose it in parentheses to avoid confusion.\n\nHere are some example lists:\n\n[1, 4, 9, 16, 25, 36, 49] ['alpha', 'bravo', 'charlie', 'delta', 'echo'] ['zebra', 49, -879, 'aardvark', 200] []\n\nOne way to create a list is to use square brackets ([]) as we have later on we will see other ways. The fourth list shown is an empty list.\n\ndone here;\n\nUnder the hood, lists and tuples don’t store data items at all, but rather object references. When lists and tuples are created (and when items are inserted in the case of lists), they take copies of the object references they are given. In the case of literal itemssuch asintegersor strings,an object of theappropriate data type is created in memory and suitably initialized, and then an object reference referring to the object is created, and it is this object reference that is put in the list or tuple.\n\ncan nest Like everything else in Python,collection data typesare objects,so we collection data types inside other collection data types, for example, to create lists of lists, without formality. In some situations the fact that lists, tuples, and most of Python’s other collection data types hold object references rather than objects makes a difference—this is covered in Chapter 3.\n\nIn procedural programming we call functions and often pass in data items as arguments. For example, we have already seen the print() function. Another frequently used Python function is len(), which takes a single data item as its argument and returns the “length” of the item as an int. Here are a few calls to len():\n\n>>> len((\"one\",)) 1 >>> len([3, 5, 1, 2, \"pause\", 5]) 6 >>> len(\"automatically\") 13\n\ntuple type ➤ 108\n\nCreat- ing and calling func- tions ➤ 36\n\nlist type ➤ 113\n\nShallow and deep copying ➤ 146\n\n20\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nTuples, lists, and strings are “sized”, that is, they are data types that have a notion of size, and data items of any such data type can be meaningfully passed to the len() function. (An exception is raised if a nonsized data item is passed to len().)\n\nAll Python data items are objects (also called instances) of a particular data type (also called a class).We will use the termsdatatypeand classinterchange- ably. One key difference between an object, and the plain items of data that some other languages provide (e.g., C++ or Java’s built-in numeric types), is that an object can have methods. Essentially, a method is simply a function that iscalled for a particular object. For example,the list typehasan append() method, so we can append an object to a list like this:\n\n>>> x = [\"zebra\", 49, -879, \"aardvark\", 200] >>> x.append(\"more\") >>> x ['zebra', 49, -879, 'aardvark', 200, 'more']\n\nThe x object knows that it is a list (all Python objects know what their own data type is), so we don’t need to specify the data type explicitly. In the im- plementation of the append() method the ﬁrst argument will be the x object itself—this is done automatically by Python as part of its syntactic support for methods.\n\nThe append() method mutates, that is, changes, the original list. This is possi- ble becauselistsare mutable. It isalso potentially more efﬁcient than creating a new list with the original items and the extra item and then rebinding the object reference to the new list, particularly for very long lists.\n\nIn a procedural language the same thing could be achieved by using the list’s append() like this (which is perfectly valid Python syntax):\n\n>>> list.append(x, \"extra\") >>> x ['zebra', 49, -879, 'aardvark', 200, 'more', 'extra']\n\nHere we specify the data type and the data type’s method, and give as the ﬁrst argument the data item of the data type we want to call the method on, followed by any additional arguments. (In the face of inheritance there is a subtle semantic difference between the two syntaxes; the ﬁrst form is the one that is most commonly used in practice. Inheritance is covered in Chapter 6.)\n\nIf you are unfamiliar with object-oriented programming this may seem a bit strange at ﬁrst. For now, just accept that Python has conventional functions called like this: functionName(arguments); and methods which are called like this: objectName.methodName(arguments). (Object-oriented programming is cov- ered in Chapter 6.)\n\nSized ➤ 383\n\nPython’s “Beautiful Heart”\n\nThe dot (“access attribute”) operator is used to access an object’s attributes. An attribute can be any kind of object, although so far we have shown only method attributes. Since an attribute can be an object that has attributes, which in turn can have attributes,and so on,we can use as many dot operators as necessary to access the particular attribute we want.\n\nThe list type has many other methods, including insert() which is used to insert an item at a given index position,and remove() which removesan item at a given index position. As noted earlier, Python indexes are always 0-based.\n\nWe saw before that we can get characters from strings using the square brackets operator, and noted at the time that this operator could be used with any sequence. Lists are sequences, so we can do things like this:\n\n>>> x ['zebra', 49, -879, 'aardvark', 200, 'more', 'extra'] >>> x[0] 'zebra' >>> x[4] 200\n\nTuples are also sequences, so if x had been a tuple we could retrieve items us- ing square bracketsin exactly the same way as we have done for the x list. But sincelistsaremutable(unlikestringsandtupleswhich areimmutable),wecan also use the square brackets operator to set list elements. For example:\n\n>>> x[1] = \"forty nine\" >>> x ['zebra', 'forty nine', -879, 'aardvark', 200, 'more', 'extra']\n\nIf wegiveanindex positionthatisoutof range,anexceptionwillberaised—we brieﬂy introduce exception-handling in Piece #5, and fully cover exceptions in Chapter 4.\n\nWe have used the term sequencea few timesnow,relying on an informal under- standing of itsmeaning,and will continuetodoso for thetimebeing. However, Python deﬁnesprecisely what featuresa sequencemust support,and similarly deﬁnes what features a sized object must support, and so on for various other categories that a data type might belong to, as we will see in Chapter 8.\n\nLists, tuples, and Python’s other built-in collection data types are covered in Chapter 3.\n\nPiece #4: Logical Operations\n\nOne of the fundamental features of any programming language is its logical operations. Python provides four sets of logical operations,and we will review the fundamentals of all of them here.\n\n21\n\n||\n\n22\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nThe Identity Operator\n\nSince all Python variables are really object references, it sometimes makes sense to ask whether two or more object references are referring to the same object. The is operator isa binary operator that returnsTrue if itsleft-handob- ject reference is referring to the same object as its right-hand object reference. Here are some examples:\n\n>>> a = [\"Retention\", 3, None] >>> b = [\"Retention\", 3, None] >>> a is b False >>> b = a >>> a is b True\n\nNote that it usually doesnot make sense to use is for comparing ints, strs,and most other data typessincewealmost invariably want tocomparetheir values. In fact, using is to compare data items can lead to unintuitive results, as we can see in the preceding example, where although a and b are initially set to the same list values, the lists themselves are held as separate list objects and so is returns False the ﬁrst time we use it.\n\nOne beneﬁt of identity comparisons is that they are very fast. This is because the objectsreferred to do not have to be examined themselves. The is operator needs to compare only the memory addressesof the objects—the same address means the same object.\n\nThe most common use case for is is to compare a data item with the built-in null object, None, which is often used as a place-marking value to signify “unknown” or “nonexistent”:\n\n>>> a = \"Something\" >>> b = None >>> a is not None, b is None (True, True)\n\nTo invert the identity test we use is not.\n\nThe purpose of the identity operator is to see whether two object references refer to the same object, or to see whether an object is None. If we want to compare object values we should use a comparison operator instead.\n\nComparison Operators\n\nPython provides the standard set of binary comparison operators, with the expected semantics: < less than, <= less than or equal to, == equal to, != not\n\n|\n\n|\n\nPython’s “Beautiful Heart”\n\nequal to, >= greater than or equal to, and > greater than. These operators compare object values,that is,the objectsthat the object referencesused in the comparison refer to. Here are a few examples typed into a Python Shell:\n\n>>> a = 2 >>> b = 6 >>> a == b False >>> a < b True >>> a <= b, a != b, a >= b, a > b (True, True, False, False)\n\nEverything is as we would expect with integers. Similarly, strings appear to compare properly too:\n\n>>> a = \"many paths\" >>> b = \"many paths\" >>> a is b False >>> a == b True\n\nAlthough a and b are different objects (have different identities), they have though, that because the same values, so they compare equal. Be aware, Python uses Unicode for representing strings, comparing strings that contain non-ASCII characters can be a lot subtler and more complicated than it might at ﬁrst appear—we will fully discuss this issue in Chapter 2.\n\nIn some cases,comparing the identity of two stringsor numbers—for example, using a is b—will return True, even if each has been assigned separately as we did here. This is because some implementationsof Python will reuse the same object (since the value is the same and is immutable) for the sake of efﬁciency. The moral of this is to use == and != when comparing values, and to use is and is not only when comparing with None or when we really do want to see if two object references, rather than their values, are the same.\n\nOneparticularlynicefeatureof Python’scomparisonoperatorsisthatthey can be chained. For example:\n\n>>> a = 9 >>> 0 <= a <= 10 True\n\nThis is a nicer way of testing that a given data item is in range than having to do two separate comparisons joined by logical and, as most other languages require. It also has the additional virtue of evaluating the data item only once (since it appears once only in the expression), something that could make a\n\n23\n\nCom- paring strings ➤ 68\n\n24\n\nChapter 1. Rapid Introduction to Procedural Programming\n\ndifference if computing the data item’s value is expensive, or if accessing the data item causes side effects.\n\nThanks to the “strong” aspect of Python’s dynamic typing, comparisons that don’t make sense will cause an exception to be raised. For example:\n\n>>> \"three\" < 4 Traceback (most recent call last): ... TypeError: unorderable types: str() < int()\n\nWhen an exception is raised and not handled, Python outputs a traceback along with the exception’s error message. For clarity, we have omitted the traceback part of the output,replacing it with an ellipsis.★ The same TypeError exception would occur if we wrote \"3\" < 4 because Python does not try to guess our intentions—the right approach is either to explicitly convert, for example, int(\"3\") < 4, or to use comparable types, that is, both integers or both strings.\n\nPython makes it easy for us to create custom data types that will integrate nicely so that, for example, we could create our own custom numeric type which would be able to participate in comparisons with the built-in int type, and with other built-in or custom numeric types, but not with strings or other non-numeric types.\n\nThe Membership Operator\n\nFor data types that are sequences or collections such as strings, lists, and tu- ples,wecan test for membershipusing the in operator,and for nonmembership using the not in operator. For example:\n\n>>> p = (4, \"frog\", 9, -33, 9, 2) >>> 2 in p True >>> \"dog\" not in p True\n\nFor lists and tuples, the in operator uses a linear search which can be slow for very large collections (tens of thousands of items or more).On the other hand, in is very fast when used on a dictionary or a set; both of these collection data types are covered in Chapter 3. Here is how in can be used with a string:\n\n>>> phrase = \"Wild Swans by Jung Chang\" >>> \"J\" in phrase True\n\n★A traceback (sometimes called a backtrace)is a list of all the calls made from the point where the unhandled exception occurred back to the top of the call stack.\n\n|\n\nDealing with runtime errors ➤ 415\n\nAlter- native Fuzzy- Bool ➤ 256\n\nPython’s “Beautiful Heart”\n\n>>> \"han\" in phrase True\n\nConveniently, in the case of strings, the membership operator can be used to test for substrings of any length. (As noted earlier, a character is just a string of length 1.)\n\nLogical Operators\n\nPython provides three logical operators: and, or, and not. Both and and or use short-circuit logic and return the operand that determined the result—they do not return a Boolean (unless they actually have Boolean operands). Let’s see what this means in practice:\n\n>>> five = 5 >>> two = 2 >>> zero = 0 >>> five and two 2 >>> two and five 5 >>> five and zero 0\n\nIf the expression occurs in a Boolean context, the result is evaluated as a Boolean, so the preceding expressions would come out as True, True, and False in, say, an if statement.\n\n>>> nought = 0 >>> five or two 5 >>> two or five 2 >>> zero or five 5 >>> zero or nought 0\n\nThe or operator is similar; here the results in a Boolean context would be True, True, True, and False.\n\nThe not unary operator evaluates its argument in a Boolean context and always returns a Boolean result, so to continue the earlier example, not (zero or nought) would produce True, and not two would produce False.\n\n25\n\n|\n\n26\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nPiece #5: Control Flow Statements\n\nWe mentioned earlier that each statement encountered in a .py ﬁle is executed in turn, starting with the ﬁrst one and progressing line by line. The ﬂow of control can be diverted by a function or method call or by a control structure, such asa conditionalbranch or a loop statement. Controlisalsodivertedwhen an exception is raised.\n\nIn this subsection we will look at Python’s if statement and its while and for loops, deferring consideration of functions to Piece #8, and methods to Chap- ter 6. We will also look at the very basics of exception-handling; we cover the subject fully in Chapter 4. But ﬁrst we will clarify a couple of items of termi- nology.\n\nA Boolean expression is anything that can be evaluated to produce a Boolean value (True or False). In Python, such an expression evaluates to False if it is the predeﬁned constant False, the special object None, an empty sequence or collection (e.g., an empty string, list, or tuple), or a numeric data item of value 0; anything else is considered to be True. When we create our own custom data types (e.g., in Chapter 6), we can decide for ourselves what they should return in a Boolean context.\n\nIn Python-speak a block of code,that is,a sequence of one or more statements, is called a suite. Because some of Python’s syntax requires that a suite be present, Python provides the keyword pass which is a statement that does nothing and that can be used where a suite is required (or where we want to indicate that we have considered a particular case) but where no processing is necessary.\n\nThe if Statement\n\nThe general syntax for Python’s if statement is this:★\n\nif boolean_expression1:\n\nsuite1\n\nelif boolean_expression2:\n\nsuite2\n\n... elif boolean_expressionN:\n\nsuiteN\n\nelse:\n\nelse_suite\n\n★In this book, ellipses (…) are used to indicate lines that are not shown.\n\n||\n\n|",
      "page_number": 27
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 36-44)",
      "start_page": 36,
      "end_page": 44,
      "detection_method": "topic_boundary",
      "content": "Python’s “Beautiful Heart”\n\nThere can be zero or more elif clauses,and the ﬁnal else clause is optional. If we want to account for a particular case,but want to do nothing if it occurs,we can use pass as that branch’s suite.\n\nThe ﬁrst thing that stands out to programmers used to C++ or Java is that there are no parentheses and no braces. The other thing to notice is the colon: This is part of the syntax and is easy to forget at ﬁrst. Colons are used with else, elif, and essentially in any other place where a suite is to follow.\n\nUnlike most other programming languages,Python usesindentationtosignify its block structure. Some programmers don’t like this, especially before they have tried it, and some get quite emotional about the issue. But it takes just a few daysto get used to,and after a few weeks or months,brace-free code seems much nicer and less cluttered to read than code that uses braces.\n\nSince suites are indicated using indentation, the question that naturally aris- es is, “What kind of indentation?” The Python style guidelines recommend four spaces per level of indentation, and only spaces (no tabs). Most modern text editors can be set up to handle this automatically (IDLE’s editor does of course,and so do most other Python-aware editors).Python will work ﬁne with any number of spaces or with tabs or with a mixture of both, providing that the indentation used is consistent. In this book, we follow the ofﬁcial Python guidelines.\n\nHere is a very simple if statement example:\n\nif x:\n\nprint(\"x is nonzero\")\n\nIn thiscase,if the condition (x)evaluatesto True,the suite (the print() function call) will be executed.\n\nif lines < 1000:\n\nprint(\"small\")\n\nelif lines < 10000: print(\"medium\")\n\nelse:\n\nprint(\"large\")\n\nThisisa slightly more elaborate if statement that printsa word that describes the value of the lines variable.\n\nThe while Statement\n\nThe while statement is used to execute a suite zero or more times, the number of times depending on the state of the while loop’s Boolean expression. Here’s the syntax:\n\n27\n\n|\n\n28\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nwhile boolean_expression:\n\nsuite\n\nActually,the while loop’s full syntax is more sophisticated than this,since both break and continue are supported,and also an optional else clause that we will discuss in Chapter 4. The break statement switches control to the statement following the innermost loop in which the break statement appears—that is, it breaks out of the loop. The continue statement switches control to the start of the loop. Both break and continue are normally used inside if statementsto conditionally change a loop’s behavior.\n\nwhile True:\n\nitem = get_next_item() if not item: break\n\nprocess_item(item)\n\nThis while loop has a very typical structure and runs as long as there are items to process. (Both get_next_item() and process_item() are assumed to be custom functions deﬁned elsewhere.) In this example, the while statement’s suite contains an if statement, which itself has a suite—as it must—in this case consisting of a single break statement.\n\nThe for … in Statement\n\nPython’s for loop reuses the in keyword (which in other contexts is the mem- bership operator), and has the following syntax:\n\nfor variable in iterable:\n\nsuite\n\nJust like the while loop, the for loop supports both break and continue, and also has an optional else clause. The variable is set to refer to each object in the iterable in turn. An iterable is any data type that can be iterated over, and includes strings (where the iteration is character by character), lists, tuples, and Python’s other collection data types.\n\nfor country in [\"Denmark\", \"Finland\", \"Norway\", \"Sweden\"]:\n\nprint(country)\n\nHere we take a very simplistic approach to printing a list of countries. In practice it is much more common to use a variable:\n\ncountries = [\"Denmark\", \"Finland\", \"Norway\", \"Sweden\"] for country in countries:\n\nprint(country)\n\n|\n\nPython’s “Beautiful Heart”\n\nIn fact, an entire list (or tuple) can be printed using the print() function directly, for example, print(countries), but we often prefer to print collections using a for loop (or a list comprehension,covered later), to achieve full control over the formatting.\n\nfor letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n\nif letter in \"AEIOU\":\n\nprint(letter, \"is a vowel\")\n\nelse:\n\nprint(letter, \"is a consonant\")\n\nIn this snippet the ﬁrst use of the in keyword is part of a for statement, with the variable letter taking on the values \"A\", \"B\", and so on up to \"Z\", changing at each iteration of the loop. On the snippet’s second line we use in again, but this time as the membership testing operator. Notice also that this example shows nested suites. The for loop’s suite is the if … else statement, and both the if and the else branches have their own suites.\n\nBasic Exception Handling\n\nMany of Python’s functions and methods indicate errors or other important eventsby raising an exception. An exceptionisan object like any other Python object, and when converted to a string (e.g., when printed), the exception produces a message text. A simple form of the syntax for exception handlers is this:\n\ntry:\n\ntry_suite\n\nexcept exception1 as variable1:\n\nexception_suite1\n\n… except exceptionN as variableN:\n\nexception_suiteN\n\nNote that the as variable part is optional; we may care only that a particular exception was raised and not be interested in its message text.\n\nThe full syntax is more sophisticated; for example, each except clause can handle multiple exceptions, and there is an optional else clause. All of this is covered in Chapter 4.\n\nThe logic works like this. If the statements in the try block’s suite all execute without raising an exception, the except blocks are skipped. If an exception is raised inside the try block, control is immediately passed to the suite corre- sponding to the ﬁrst matching exception—this means that any statements in the suite that follow the one that caused the exception will not be executed. If\n\n29\n\n|\n\nList compre- hen- sions ➤ 118\n\n30\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nthis occurs and if the as variable part is given, then inside the exception-han- dling suite, variable refers to the exception object.\n\nIf an exception occurs in the handling except block, or if an exception is raised that does not match any of the except blocks in the ﬁrst place,Python looks for a matching except block in the next enclosing scope. The search for a suitable outward in scope and up the call stack until either exception handler works a match is found and the exception is handled, or no match is found, in which case the program terminates with an unhandled exception. In the case of an unhandled exception, Python prints a traceback as well as the exception’s message text.\n\nHere is an example:\n\ns = input(\"enter an integer: \") try:\n\ni = int(s) print(\"valid integer entered:\", i)\n\nexcept ValueError as err:\n\nprint(err)\n\nIf the user enters “3.5”, the output will be:\n\ninvalid literal for int() with base 10: '3.5'\n\nBut if they were to enter “13”, the output will be:\n\nvalid integer entered: 13\n\nMany books consider exception-handling to be an advanced topic and defer it aslateaspossible. Butraisingandespeciallyhandlingexceptionsisfundamen- tal to the way Python works, so we make use of it from the beginning. And as we shall see, using exception handlers can make code much more readable, by separating the “exceptional” cases from the processing we are really interest- ed in.\n\nPiece #6: Arithmetic Operators\n\nPython provides a full set of arithmetic operators, including binary operators for thefourbasicmathematicaloperations:+ addition,- subtraction,* multipli- cation, and / division. In addition, many Python data types can be used with augmented assignment operators such as += and *=. The +, -, and * operators all behave as expected when both of their operands are integers:\n\n>>> 5 + 6 11\n\n||\n\nDeal- ing with runtime errors ➤ 415\n\nPython’s “Beautiful Heart”\n\n>>> 3 - 7 -4 >>> 4 * 8 32\n\nNotice that - can be used both as a unary operator (negation) and as a binary operator (subtraction),as is common in most programming languages. Where Python differs from the crowd is when it comes to division:\n\n>>> 12 / 3 4.0 >>> 3 / 2 1.5\n\nThe division operator produces a ﬂoating-point value, not an integer; many other languages will produce an integer, truncating any fractional part. If we need an integer result, we can always convert using int() (or use the truncating division operator //, discussed later).\n\n>>> a = 5 >>> a 5 >>> a += 8 >>> a 13\n\nAt ﬁrst sight the preceding statements are unsurprising, particularly to those familiar with C-like languages. In such languages, augmented assignment is shorthand for assigning the results of an operation—for example, a += 8 is es- sentially thesameasa = a + 8.However,therearetwoimportantsubtletieshere, one Python-speciﬁc and one to do with augmented operators in any language.\n\nThe ﬁrst point to remember is that the int data type is immutable—that is, once assigned, an int’s value cannot be changed. So, what actually happens behind the scenes when an augmented assignment operator is used on an immutable object is that the operation is performed,and an object holding the result is created;and then the target object reference isre-bound to refer to the result object rather than the object it referred to before. So, in the preceding case when the statement a += 8 is encountered, Python computes a + 8, stores the result in a new int object, and then rebinds a to refer to this new int. (And if the original object a was referring to has no more object references referring to it, it will be scheduled for garbage collection.) Figure 1.3 illustrates this point.\n\nThe second subtlety is that a operator= b is not quite the same as a = a operator b.The augmented version looksup a’svalue only once,so it ispotentially faster. Also, if a is a complex expression (e.g., a list element with an index position calculation such as items[offset + index]), using the augmented version may\n\n31\n\nNumer- ic opera- tors and func- tions ➤ 55\n\nPython’s “Beautiful Heart”\n\n33\n\ner hand, mutable types can be more convenient to use. Where the distinction matters,we will discuss it—for example,in Chapter 4 when we discuss setting default arguments for custom functions, in Chapter 3 when we discuss lists, sets, and some other data types, and again in Chapter 6 when we show how to create custom data types.\n\nThe right-hand operand for the list += operator must be an iterable; an exception is raised:\n\nif it is not\n\n>>> seeds += 5 Traceback (most recent call last): ... TypeError: 'int' object is not iterable\n\nThe correct way to extend a list is to use an iterable object, such as a list:\n\n>>> seeds += [5] >>> seeds ['sesame', 'sunflower', 'pumpkin', 5]\n\nAnd of course, the iterable object used to extend the list can itself have more than one item:\n\n>>> seeds += [9, 1, 5, \"poppy\"] >>> seeds ['sesame', 'sunflower', 'pumpkin', 5, 9, 1, 5, 'poppy']\n\nAppending aplainstring—forexample,\"durian\"—ratherthanalistcontaining a string, [\"durian\"], leads to a logical but perhaps surprising result:\n\n>>> seeds = [\"sesame\", \"sunflower\", \"pumpkin\"] >>> seeds += \"durian\" >>> seeds ['sesame', 'sunflower', 'pumpkin', 'd', 'u', 'r', 'i', 'a', 'n']\n\nThe list += operator extends the list by appending each item of the iterable it is provided with; and since a string is an iterable, this leads to each character in the string being appended individually. If we use the list append() method, the argument is always added as a single item.\n\nPiece #7: Input/Output\n\n||\n\nTo be able to write genuinely useful programs we must be able to read input—for example, from the user at the console, and from ﬁles—and produce output, either to the console or to ﬁles. We have already made use of Python’s built-in print() function,although we will defer covering it further until Chap-\n\nDeal- ing with runtime errors ➤ 415\n\nBook’s exam- ples 3➤\n\n34\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nter 4. In this subsection we will concentrate on console I/O, and use shell redi- rection for reading and writing ﬁles.\n\nPython provides the built-in input() function to accept input from the user. This function takes an optional string argument (which it prints on the con- sole); it then waits for the user to type in a response and to ﬁnish by pressing Enter (or Return).If the user doesnot type any text but just presses Enter,the in- put() function returns an empty string; otherwise, it returns a string contain- ing what the user typed, without any line terminator.\n\nHere is our ﬁrst complete “useful” program; it draws on many of the previous pieces—the only new thing it shows is the input() function:\n\nprint(\"Type integers, each followed by Enter; or just Enter to finish\")\n\ntotal = 0 count = 0\n\nwhile True:\n\nline = input(\"integer: \") if line: try:\n\nnumber = int(line) except ValueError as err:\n\nprint(err) continue total += number count += 1\n\nelse:\n\nbreak\n\nif count:\n\nprint(\"count =\", count, \"total =\", total, \"mean =\", total / count)\n\nThe program (in ﬁle sum1.py in the book’s examples) has just 17 lines. Here is what a typical run looks like:\n\nexecutable\n\nType integers, each followed by Enter; or just Enter to finish number: 12 number: 7 number: 1x invalid literal for int() with base 10: '1x' number: 15 number: 5 number: count = 4 total = 39 mean = 9.75\n\nAlthough the program is very short, it is fairly robust. If the user enters a string that cannot be converted to an integer, the problem is caught by an\n\nWin- dows ﬁle associa- tion bug 11➤\n\nPython’s “Beautiful Heart”\n\nexception handler that prints a suitable message and switches control to the start of the loop (“continues the loop”).And the last if statement ensures that if the user doesn’t enter any numbers at all, the summary isn’t output, and division by zero is avoided.\n\nFile handling is fully covered in Chapter 7;but right now we can create ﬁles by redirecting the print() functions’ output from the console. For example:\n\nC:\\>test.py > results.txt\n\nwill cause the output of plain print() function calls made in the ﬁctitious test.py program to be written to the ﬁle results.txt. This syntax works in the Windows console (usually) and in Unix consoles. For Windows, we must write C:\\Python31\\python.exe test.py > results.txt if Python 2 is the machine’s de- fault Python version or if the console exhibits the ﬁle association bug; other- wise, assuming Python 3 is in the PATH, python test.py > results.txt should be sufﬁcient, if plain test.py > results.txt doesn’t work. For Unixes we must make the program executable (chmod +x test.py) and then invoke it by typing ./test.py unless the directory it is in happens to be in the PATH, in which case invoking it by typing test.py is sufﬁcient.\n\nReading data can be achieved by redirecting a ﬁle of data as input in an analogous way to redirecting output. However, if we used redirection with sum1.py, the program would fail. This is because the input() function raises an exception if it receives an EOF (end of ﬁle) character. Here is a more robust version (sum2.py) that can accept input from the user typing at the keyboard,or via ﬁle redirection:\n\nprint(\"Type integers, each followed by Enter; or ^D or ^Z to finish\")\n\ntotal = 0 count = 0\n\nwhile True: try:\n\nline = input() if line:\n\nnumber = int(line) total += number count += 1 except ValueError as err:\n\nprint(err) continue except EOFError:\n\nbreak\n\nif count:\n\nprint(\"count =\", count, \"total =\", total, \"mean =\", total / count)\n\n35\n\n36\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nGiven the command line sum2.py < data\\sum2.dat (where the sum2.dat ﬁle con- tains a list of numbers one per line and is in the examples’ data subdirectory), the output to the console is:\n\nType integers, each followed by Enter; or ^D or ^Z to finish count = 37 total = 1839 mean = 49.7027027027\n\nWe have made several small changes to make the program more suitable for use both interactively and using redirection. First, we have changed the termination from being a blank line to the EOF character (Ctrl+D on Unix, Ctrl+Z, Enter on Windows). This makes the program more robust when it comes to handling input ﬁles that contain blank lines. We have stopped printing a prompt for each number since it doesn’t make sense to have one for redirected input. And we have also used a single try block with two exception handlers.\n\nNotice that if an invalid integer is entered (either via the keyboard or due to a “bad” line of data in a redirected input ﬁle), the int() conversion will raise a ValueError exceptionandtheﬂowof controlwillimmediately switchtotherele- vant except block—thismeansthat neither total nor count will be incremented when invalid data is encountered, which is exactly what we want.\n\nWe could just as easily have used two separate exception-handling try blocks instead:\n\nwhile True: try:\n\nline = input() if line: try:\n\nnumber = int(line) except ValueError as err:\n\nprint(err) continue total += number count += 1\n\nexcept EOFError:\n\nbreak\n\nBut we preferred to group the exceptions together at the end to keep the main processing as uncluttered as possible.\n\nPiece #8: Creating and Calling Functions\n\nIt isperfectly possibletowriteprogramsusing thedata typesandcontrolstruc- tures that we have covered in the preceding pieces. However, very often we want to do essentially the same processing repeatedly, but with a small differ- ence, such as a different starting value. Python provides a means of encapsu-\n\n||",
      "page_number": 36
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 45-54)",
      "start_page": 45,
      "end_page": 54,
      "detection_method": "topic_boundary",
      "content": "Python’s “Beautiful Heart”\n\nlating suites as functions which can be parameterized by the arguments they are passed. Here is the general syntax for creating a function:\n\ndef functionName(arguments):\n\nsuite\n\nThe arguments are optional and multiple argumentsmust be comma-separated. Every Pythonfunctionhasareturnvalue;thisdefaults toNone unlesswereturn fromthefunctionusing thesyntax return value,inwhich casevalue isreturned. The return value can be just one value or a tuple of values. The return value can be ignored by the caller, in which case it is simply thrown away.\n\nNote that def is a statement that works in a similar way to the assignment operator. When def is executed a function object is created and an object reference with the speciﬁed name is created and set to refer to the function object. Since functions are objects, they can be stored in collection data types and passed as arguments to other functions, as we will see in later chapters.\n\nOne frequent need when writing interactive console applications is to obtain an integer from the user. Here is a function that does just that:\n\ndef get_int(msg):\n\nwhile True: try:\n\ni = int(input(msg)) return i\n\nexcept ValueError as err:\n\nprint(err)\n\nThisfunction takesone argument,msg.Insidethe while loop the user isprompt- ed to enter an integer. If they enter something invalid a ValueError exception will be raised,the error message will be printed,and the loop will repeat. Once a valid integer is entered, it is returned to the caller. Here is how we would call it:\n\nage = get_int(\"enter your age: \")\n\nIn this example the single argument is mandatory because we have provided no default value. In fact, Python supports a very sophisticated and ﬂexible syntax for function parameters that supports default argument values and positional and keyword arguments. All of the syntax is covered in Chapter 4.\n\nAlthough creating our own functions can be very satisfying, in many cases it is not necessary. This is because Python has a lot of functions built in, and a great many more functions in the modules in its standard library, so what we want may well already be available.\n\n37\n\nreturn state- ment ➤ 173\n\nDot (.) operator 21➤\n\nshebang (#!) line 12➤\n\n38\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nA Python module is just a .py ﬁle that contains Python code, such as custom function and class (custom data type) deﬁnitions,and sometimesvariables. To access the functionality in a module we must import it. For example:\n\nimport sys\n\nTo import a module we use the import statement followed by the name of the .py ﬁle, but omitting the extension.★ Once a module has been imported,we can access any functions, classes, or variables that it contains. For example:\n\nprint(sys.argv)\n\nThe sys module provides the argv variable—a list whose ﬁrst item is the name under which the program was invoked and whose second and subsequent items are the program’scommand-line arguments. The two previously quoted lines constitute the entire echoargs.py program. If the program is invoked with the command line echoargs.py -v,it will print ['echoargs.py', '-v'] on the console. (On Unix the ﬁrst entry may be './echoargs.py'.)\n\nIn general, the syntax for using a function from a module is moduleName.func- tionName(arguments). It makes use of the dot (“access attribute”) operator we introduced in Piece #3. The standard library contains lots of modules, and we will make use of many of them throughout the book. The standard modules all have lowercase names, so some programmers use title-case names (e.g., My- Module) for their own modules to keep them distinct.\n\nLet us look at just one example, the random module (in the standard library’s random.py ﬁle), which provides many useful functions:\n\nimport random x = random.randint(1, 6) y = random.choice([\"apple\", \"banana\", \"cherry\", \"durian\"])\n\nAfter these statements have been executed, x will contain an integer between 1 and 6 inclusive, and y will contain one of the strings from the list passed to the random.choice() function.\n\nIt is conventional to put all the import statements at the beginning of .py ﬁles, documentation. (Document- after the shebang line, and after the module’s ing modules is covered in Chapter 5.) We recommend importing standard li- brary modules ﬁrst, then third-party library modules, and ﬁnally your own modules.\n\n★The sys module, some other built-in modules, and modules implemented in C don’t necessarily have corresponding .py ﬁles—but they are used in just the same way as those that do.\n\nExamples\n\nExamples\n\nIn the preceding section we learned enough Python to write real programs. In this section we will study two complete programs that use only the Python covered earlier. This is both to show what is possible, and to help consolidate what has been learned so far.\n\nIn subsequent chapters we will increasingly cover more of Python’s language and library,so that we will be able to write programsthat are more concise and more robust than those shown here—but ﬁrst we must have the foundations on which to build.\n\nbigdigits.py\n\nThe ﬁrst program we will review is quite short, although it has some subtle aspects, including a list of lists. Here is what it does: Given a number on the command line, the program outputs the same number onto the console using “big” digits.\n\nAt sites where lots of users share a high-speed line printer, it used to be common practice for each user’s print job to be preceded by a cover page that showed their username and some other identifying details printed using this kind of technique.\n\nWe will review the code in three parts: the import, the creation of the lists holding the data the program uses, and the processing itself. But ﬁrst, let’s look at a sample run:\n\nbigdigits.py 41072819 * * *** ***** *** *** * **** ** ** * * * * * * * ** * * * * * * * * * * * * * * * * * * * * * * *** * **** ****** * * * * * * * * * * * * * * * * * * * * *** *** * ***** *** *** *\n\nWe have not shown the console prompt (or the leading ./ for Unix users); we will take them for granted from now on.\n\nimport sys\n\nSince we must read in an argument from the command line (the number to output), we need to access the sys.argv list, so we begin by importing the sys module.\n\nWe represent each number as a list of strings. For example, here is zero:\n\n39\n\n|||\n\n||\n\n40\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nZero = [\" *** \", * \", \" * *\", \"* *\", \"* *\", \"* \" * * \", \" *** \"]\n\nOne detail to note is that the Zero list of strings is spread over multiple lines. Python statements normally occupy a single line, but they can span multiple lines if they are a parenthesized expression, a list, set, or dictionary literal, a function call argument list, or a multiline statement where every end-of-line character except the last is escaped by preceding it with a backslash (\\). In all these cases any number of lines can be spanned and indentation does not matter for the second and subsequent lines.\n\nEach list representing a number has seven strings, all of uniform width, although what this width is differs from number to number. The lists for the other numbers follow the same pattern as for zero, although they are laid out for compactness rather than for clarity:\n\nOne = [\" * \", \"** \", \" * \", \" * \", \" * \", \" * \", \"***\"] Two = [\" *** \", \"* # ... Nine = [\" ****\", \"*\n\n\", \"* * \", \" * \", \" *\n\n\", \"*\n\n\", \"*\n\n\", \" ****\", \"\n\n\", \"\n\n\", \"*****\"]\n\n\", \"\n\n\"]\n\nThe last piece of data we need is a list of all the lists of digits:\n\nDigits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]\n\nWe could have created the Digits lists directly, and avoided creating the extra variables. For example:\n\nDigits = [\n\n[\" *** \", \" *\n\n\", \"*\n\n\", \"*\n\n\", \"*\n\n\",\n\n\" *\n\n\", \" *** \"], # Zero\n\n[\" * \", \"** \", \" * \", \" * \", \" * \", \" * \", \"***\"], # One # ... [\" ****\", \"* *\", \"* *\", \" ****\", \" *\", \" *\", \" *\"] # Nine ]\n\nWe preferred to use a separate variable for each number both for ease of understanding and because it looks neater using the variables.\n\nWe will quote the rest of the code in one go so that you can try to ﬁgure out how it works before reading the explanation that follows.\n\nset type ➤ 121\n\ndict type ➤ 126\n\nExamples\n\ntry:\n\ndigits = sys.argv[1] row = 0 while row < 7:\n\nline = \"\" column = 0 while column < len(digits):\n\nnumber = int(digits[column]) digit = Digits[number] line += digit[row] + \" \" column += 1\n\nprint(line) row += 1\n\nexcept IndexError:\n\nprint(\"usage: bigdigits.py <number>\")\n\nexcept ValueError as err:\n\nprint(err, \"in\", digits)\n\nThe whole code is wrapped in an exception handler that can catch the two things that can go wrong. We begin by retrieving the program’scommand-line argument. The sys.argv list is 0-based like all Python lists; the item at index position 0 is the name the program was invoked as, so in a running program this list always starts out with at least one item. If no argument was given we will be trying to access the second item in a one-item list and this will cause an IndexError exception to be raised. If this occurs,the ﬂow of control is imme- diately switched to the corresponding exception-handling block, and there we simply print the program’s usage. Execution then continues after the end of the try block; but there is no more code, so the program simply terminates.\n\nIf no IndexError occurs, the digits string holds the command-line argument, which wehopeisa sequenceof digit characters. (RememberfromPiece#2that identiﬁersarecase-sensitive,so digits and Digits aredifferent.) Each big digit is represented by seven strings, and to output the number correctly we must output the top row of every digit, then the next row, and so on, until all seven rows have been output. We use a while loop to iterate over each row. We could just as easily have done this instead: for row in (0, 1, 2, 3, 4, 5, 6): and later on we will see a much better way using the built-in range() function.\n\nWe usethe line string tohold therowstringsfromall thedigitsinvolved. Then we loop by column, that is, by each successive character in the command-line argument. We retrieve each character with digits[column] and convert the digit to an integer called number. If the conversion fails a ValueError exception is raised and the ﬂow of control immediately switches to the corresponding exception handler. In thiscase we print an error message,and controlresumes after the try block. As noted earlier, since there is no more code at this point, the program will simply terminate.\n\n41\n\nrange() ➤ 141\n\nrandom. rand- int() 38➤\n\n42\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nIf the conversion succeeds, we use number as an index into the Digits list, from which we extract the digit list of strings. We then add the row-th string from this list to the line we are building up,and also append two spacesto give some horizontal separation between each digit.\n\nEach time the inner while loop ﬁnishes, we print the line that has been built up. The key to understanding this program is where we append each digit’s row string to the current row’s line. Try running the program to get a feel for how it works. We will return to this program in the exercises to improve its output slightly.\n\ngenerate_grid.py\n\nOnefrequently occurring need isthegenerationof test data. Thereisnosingle generic program for doing this, since test data varies enormously. Python is often used to producetest data because it isso easy to writeand modify Python programs. In this subsection we will create a program that generates a grid of random integers; the user can specify how many rows and columns they want and over what range the integers should span. We’ll start by looking at a sample run:\n\ngenerate_grid.py rows: 4x invalid literal for int() with base 10: '4x' rows: 4 columns: 7 minimum (or Enter for 0): -100 maximum (or Enter for 1000): 554 720 550 217 810 649 912 -24 908 742 -65 -74 724 825 711 968 824 505 741 55 723 180 -60 794 173 487 4 -35\n\nThe program worksinteractively,and at the beginning we made a typing error when entering the number of rows. The program responded by printing an error message and then asking us to enter the number of rows again. For the maximum we just pressed Enter to accept the default.\n\nWe will review the code in four parts: the import, the deﬁnition of a get_int() function (a more sophisticated version than the one shown in Piece #8), the user interaction to get the values to use, and the processing itself.\n\nimport random\n\nWe need the random module to give us access to the random.randint()\n\nfunction.\n\n||\n\nExamples\n\ndef get_int(msg, minimum, default):\n\nwhile True: try:\n\nline = input(msg) if not line and default is not None:\n\nreturn default\n\ni = int(line) if i < minimum:\n\nprint(\"must be >=\", minimum)\n\nelse:\n\nreturn i except ValueError as err:\n\nprint(err)\n\nThis function requires three arguments: a message string, a minimum value, and a default value. If the user just pressesEnter there are two possibilities. If default is None, that is, no default value has been given, the ﬂow of control will drop through to the int() line. There the conversion will fail (since '' cannot be converted to an integer), and a ValueError exception will be raised. But if default is not None, then it is returned. Otherwise, the function will attempt to convert the text the user entered into an integer, and if the conversion is successful,it will then check that the integer is at least equal to the minimum that has been speciﬁed.\n\nSo, the function will always return either default (if the user just pressed Enter), or a valid integer that is greater than or equal to the speciﬁed minimum.\n\nrows = get_int(\"rows: \", 1, None) columns = get_int(\"columns: \", 1, None) minimum = get_int(\"minimum (or Enter for 0): \", -1000000, 0)\n\ndefault = 1000 if default < minimum:\n\ndefault = 2 * minimum\n\nmaximum = get_int(\"maximum (or Enter for \" + str(default) + \"): \",\n\nminimum, default)\n\nOur get_int() function makes it easy to obtain the number of rows and columns and the minimum random value that the user wants. For rows and columns we give a default value of None, meaning no default, so the user must enter an integer. In the case of the minimum, we supply a default value of 0, and for the maximum we give a default value of 1000, or twice the minimum if the minimum is greater than or equal to 1000.\n\nAs we noted in the previous example, function call argument lists can span any number of lines, and indentation is irrelevant for their second and subse- quent lines.\n\n43\n\n44\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nOnce we know how many rows and columns the user requires and the mini- mum and maximum values of the random numbersthey want,we are ready to do the processing.\n\nrow = 0 while row < rows: line = \"\" column = 0 while column < columns:\n\ni = random.randint(minimum, maximum) s = str(i) while len(s) < 10: s = \" \" + s\n\nline += s column += 1\n\nprint(line) row += 1\n\nTo generate the grid we use three while loops, the outer one working by rows, the middle one by columns, and the inner one by characters. In the middle loop we obtain a random number in the speciﬁed range and then convert it to a string. The inner while loop is used to pad the string with leading spaces so that each number is represented by a string 10 characters wide. We use the line string to accumulate the numbers for each row, and print the line after each column’s numbers have been added. This completes our second example.\n\nPython provides very sophisticated string formatting functionality, as well as excellent support for for … in loops, so more realistic versions of both bigdigits.py and generate_grid.py would have used for … in loops, and gener- ate_grid.py would have used Python’s string formatting capabilities rather than crudely padding with spaces. But we have limited ourselves to the eight pieces of Python introduced in this chapter, and they are quite sufﬁcient for writing complete and useful programs. In each subsequent chapter we will learn new Python features, so as we progress through the book the programs we will see and be capable of writing will grow in sophistication.\n\nSummary\n\nIn this chapter we learned how to edit and run Python programsand reviewed a few small but complete programs. But most of the chapter’s pages were devoted to the eight pieces of Python’s “beautiful heart”—enough of Python to write real programs.\n\nWe began with two of Python’smost basic data types,int and str.Integer liter- als are written just as they are in most other programming languages. String\n\n|||\n\nstr. format() ➤ 78\n\nSummary\n\nliterals are written using single or double quotes; it doesn’t matter which as long as the same kind of quote is used at both ends. We can convert between strings and integers, for example, int(\"250\") and str(125). If an integer con- version fails a ValueError exception is raised; whereas almost anything can be converted to a string.\n\nStrings are sequences,so those functions and operations that can be used with sequences can be used with strings. For example, we can access a particular character using the item access operator ([]), concatenate strings using +, and append one string to another using +=. Since strings are immutable, behind the scenes, appending creates a new string that is the concatenation of the given strings,and rebindsthe left-hand string object reference to the resultant string. Wecanalsoiterateovera string characterby characterusing a for …in loop. And we can use the built-in len() function to report how many characters are in a string.\n\nFor immutable objects like strings, integers, and tuples, we can write our code as though an object reference is a variable, that is, as though an object refer- ence is the object it refers to. We can also do this for mutable objects,although any change made to a mutable object will affect all occurrences of the object (i.e., all object references to the object); we will cover this issue in Chapter 3.\n\nPythonprovidesseveralbuilt-incollectiondatatypesandhassomeothersinits standard library. We learned about the list and tuple types,and in particular howtocreatetuplesandlistsfromliterals,for example,even = [2, 4, 6, 8].Lists, like everything else in Python,are objects,so we can call methodson them—for example, even.append(10) will add an extra item to the list. Like strings, lists and tuples are sequences, so we can iterate over them item by item using a for …in loop, and ﬁnd out how many items they have using len().We can also retrieve a particular item in a list or tuple using the item access operator ([]), concatenate two lists or tuples using +, and append one to another using +=. If we want to append a single item to a list we must either use list.append() or use += with the item made into a single-item list—for example, even += [12]. Since lists are mutable, we can use [] to change individual items, for example, even[1] = 16.\n\nThe fast is and is not identity operators can be used to check whether two ob- ject references refer to the same thing—this is particularly useful when check- ing against the unique built-in None object. All the usual comparison operators are available (<, <=, ==, !=, >=, >),but they can be used only with compatible data types, and then only if the operations are supported. The data types we have seen so far—int, str, list, and tuple—all support the complete set of compar- ison operators. Comparing incompatible types,for example, comparing an int with a str or list, will quite sensibly produce a TypeError exception.\n\nPython supports the standard logical operators and, or, and not. Both and and or are short-circuit operators that return the operand that determined their\n\n45\n\n46\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nresult—and this may not be a Boolean (although it can be converted to a Boolean); not always returns either True or False.\n\nWe can test for membership of sequence types, including strings, lists, and tu- ples, using the in and not in operators. Membership testing uses a slow linear search on lists and tuples, and a potentially much faster hybrid algorithm for strings, but performance is rarely an issue except for very long strings, lists, and tuples. In Chapter 3 we will learn about Python’s associative array and set collection data types, both of which provide very fast membership testing. It is also possible to ﬁnd out an object variable’stype (i.e.,the type of object the object referencerefersto)using type()—but thisfunction isnormally used only for debugging and testing.\n\nPython provides several control structures, including conditional branching with if … elif … else, conditional looping with while, looping over sequences with for … in, and exception-handling with try … except blocks. Both while and for … in loops can be prematurely terminated using a break statement, and both can switch control to the beginning using continue.\n\nThe usual arithmetic operatorsare supported,including +, -, *,and /,although Python isunusual in that / alwaysproducesa ﬂoating-point result even if both its operandsare integers. (The truncating division that many other languages use is also available in Python as //.) Python also provides augmented assign- ment operators such as += and *=; these create new objects and rebind behind the scenes if their left-hand operand is immutable. The arithmetic operators are overloaded by the str and list types as we noted earlier.\n\nConsole I/O can be achieved using input() and print(); and using ﬁle redi- rection in the console, we can use these same built-in functions to read and write ﬁles.\n\nIn addition to Python’s rich built-in functionality, its extensive standard library isalso available,with modulesaccessibleonce they have been imported using the import statement. One commonly imported module is sys, which holds the sys.argv list of command-line arguments. And when Python doesn’t have the function we need we can easily create one that does what we want using the def statement.\n\nBy making use of the functionality described in this chapter it is possible to write short but useful Python programs. In the following chapter we will learn more about Python’s data types, going into more depth for ints and strs and introducing some entirely new data types. In Chapter 3 we will learn more about tuples and lists, and also about some of Python’s other collection data types. Then, in Chapter 4 we will cover Python’s control structures in much more detail, and will learn how to create our own functions so that we can package up functionality to avoid code duplication and promote code reuse.",
      "page_number": 45
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 55-62)",
      "start_page": 55,
      "end_page": 62,
      "detection_method": "topic_boundary",
      "content": "Book’s exam- ples 3➤\n\nExercises\n\nExercises\n\nThepurposeof theexerciseshere,andthroughoutthebook,isto encourageyou to experiment with Python, and to get hands-on experience to help you absorb each chapter’s material. The examples and exercises cover both numeric and text processing to appeal to as wide an audience as possible, and they are kept fairly small so that the emphasis is on thinking and learning rather than just typing code. Every exercise has a solution provided with the book’s examples.\n\n1. One nice variation of the bigdigits.py program is where instead of printing *s, the relevant digit is printed instead. For example:\n\nbigdigits_ans.py 719428306 77777 1 9999 4 222 888 333 000 666 7 11 9 9 44 2 2 8 8 3 3 0 0 6 7 1 9 9 4 4 2 2 8 8 3 0 0 6 7 1 9999 4 4 2 888 33 0 0 6666 7 1 9 444444 2 8 8 3 0 0 6 6 7 1 9 4 2 8 8 3 3 0 0 6 6 7 111 9 4 22222 888 333 000 666\n\nTwo approaches can be taken. The easiest is to simply change the *s in the lists. But this isn’t very versatile and is not the approach you should take. Instead,change the processing code so that rather than adding each digit’s row string to the line in one go, you add character by character,and whenever a * is encountered you use the relevant digit.\n\nThis can be done by copying bigdigits.py and changing about ﬁve lines. It isn’t hard, but it is slightly subtle. A solution is provided as bigdig- its_ans.py.\n\n2. IDLE can be used as a very powerful and ﬂexible calculator, but some- times it is useful to have a task-speciﬁc calculator. Create a program that prompts the user to enter a number in a while loop, gradually building up a list of the numbers entered. When the user has ﬁnished (by simply pressing Enter),print out the numbersthey entered,the count of numbers, the sum of the numbers,the lowest and highest numbers entered,and the mean of the numbers (sum / count).Here is a sample run: average1_ans.py enter a number or Enter to finish: 5 enter a number or Enter to finish: 4 enter a number or Enter to finish: 1 enter a number or Enter to finish: 8 enter a number or Enter to finish: 5 enter a number or Enter to finish: 2 enter a number or Enter to finish:\n\n47\n\n|||\n\n48\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nnumbers: [5, 4, 1, 8, 5, 2] count = 6 sum = 25 lowest = 1 highest = 8 mean = 4.16666666667\n\nIt will take about four lines to initialize the necessary variables (an empty list is simply []), and less than 15 lines for the while loop, including basic error handling. Printing out at the end can be done in just a few lines, so the whole program,including blank lines for the sake of clarity, should be about 25 lines.\n\n3. In some situationswe need to generate test text—for example,to populate a web site design before the real content is available, or to provide test content whendeveloping a reportwriter. Tothisend,writea programthat generates awful poems (the kind that would make a Vogon blush). Create some lists of words, for example, articles (“the”, “a”, etc.), subjects (“cat”,“dog”,“man”,“woman”), verbs(“sang”,“ran”,“jumped”),andadverbs (“loudly”, “quietly”, “well”, “badly”). Then loop ﬁve times, and on each it- eration use the random.choice() function to pick an article, subject, verb, and adverb. Use random.randint() to choose between two sentence struc- tures: article, subject, verb, and adverb, or just article, subject, and verb, and print the sentence. Here is an example run:\n\n3. In some situationswe need to generate test text—for example,to populate a web site design before the real content is available, or to provide test content whendeveloping a reportwriter. Tothisend,writea programthat generates awful poems (the kind that would make a Vogon blush). Create some lists of words, for example, articles (“the”, “a”, etc.), subjects (“cat”,“dog”,“man”,“woman”), verbs(“sang”,“ran”,“jumped”),andadverbs (“loudly”, “quietly”, “well”, “badly”). Then loop ﬁve times, and on each it- eration use the random.choice() function to pick an article, subject, verb, and adverb. Use random.randint() to choose between two sentence struc- tures: article, subject, verb, and adverb, or just article, subject, and verb, and print the sentence. Here is an example run:\n\nawfulpoetry1_ans.py another boy laughed badly the woman jumped a boy hoped a horse jumped another man laughed rudely\n\nYou will need to import the random module. The lists can be done in about 4–10 lines depending on how many words you put in them, and the loop itself requires less than ten lines, so with some blank lines the whole program can be done in about 20 lines of code. A solution is provided as awfulpoetry1_ans.py.\n\n4. To make the awful poetry program more versatile, add some code to it so that if the user enters a number on the command line (between 1 and 10 inclusive), the program will output that many lines. If no command-line argument is given, default to printing ﬁve lines as before. You’ll need to change the main loop (e.g., to a while loop). Keep in mind that Python’s comparison operators can be chained, so there’s no need to use logical and whenchecking thattheargumentisinrange. Theadditionalfunctionality can be done by adding about ten lines of code. A solution is provided as awfulpoetry2_ans.py.\n\n5. It would be nice to be able to calculate the median (middle value) as well as the mean for the averagesprogram in Exercise 2,but to do thiswe must sort the list. In Python a list can easily be sorted using the list.sort()\n\nExercises\n\nmethod, but we haven’t covered that yet, so we won’t use it here. Ex- tend the averages program with a block of code that sorts the list of numbers—efﬁciency is of no concern, just use the easiest approach you can think of. Once the list is sorted, the median is the middle value if the list has an odd number of items, or the average of the two middle values if the list has an even number of items. Calculate the median and output that along with the other information.\n\nThis is rather tricky, especially for inexperienced programmers. If you have somePython experience,you might stillﬁnd it challenging,at least if you keep to the constraint of using only the Python we have covered so far. The sorting can be done in about a dozen lines and the median calculation (whereyoucan’tusethemodulusoperator,sinceit hasn’tbeencoveredyet) in four lines. A solution is provided in average2_ans.py.\n\n49\n\nObject refer- ences 16➤\n\n2\n\nIdentiﬁers and Keywords ● Integral Types ● Floating-Point Types ● Strings\n\nData Types\n\nIn this chapter we begin to take a much more detailed look at the Python lan- guage. We start with a discussion of the rules governing the names we give to object references, and provide a list of Python’s keywords. Then we look at all of Python’smost important data types—excluding collection data types,which are covered in Chapter 3. The data types considered are all built-in, except for one which comesfrom the standard library. The only difference between built- in data types and library data types is that in the latter case,we must ﬁrst im- port the relevant module and we must qualify the data type’s name with the name of the module it comes from—Chapter 5 covers importing in depth.\n\nIdentiﬁers and Keywords\n\nWhen we create a data item we can either assign it to a variable, or insert it we assign in into a collection. (As we noted in the preceding chapter, when Python, what really happens is that we bind an object reference to refer to the object in memory that holds the data.) The names we give to our object references are called identiﬁers or just plain names.\n\nA valid Python identiﬁer is a nonempty sequence of characters of any length that consistsof a “start character” and zero or more “continuation characters”. Such an identiﬁer must obey a couple of rules and ought to follow certain con- ventions.\n\nThe ﬁrst rule concerns the start and continuation characters. The start char- acter can beanything thatUnicodeconsiderstobea letter,including theASCII letters (“a”, “b”, …, “z”, “A”, “B”, …, “Z”), the underscore (“_”), as well as the let- ters from most non-English languages. Each continuation character can be any character that is permitted as a start character, or pretty well any non- whitespace character, including any character that Unicode considers to be a digit,such as (“0”,“1”,…,“9”),or the Catalan character “·”.Identiﬁersare case-\n\n51\n\n||||\n\n|||\n\n52\n\nChapter 2. Data Types\n\nsensitive,so for example, TAXRATE, Taxrate, TaxRate, taxRate, and taxrate are ﬁve different identiﬁers.\n\nThe precise set of characters that are permitted for the start and continuation are describedin thedocumentation(Python language reference,Lexical analy- sis,Identiﬁersandkeywordssection),andinPEP 3131(Supporting Non-ASCII Identiﬁers).★\n\nThe second rule isthat no identiﬁer can have the same nameasone of Python’s keywords, so we cannot use any of the names shown in Table 2.1.\n\nTable 2.1 Python’s Keywords\n\nand\n\ncontinue\n\nexcept\n\nglobal\n\nlambda\n\npass\n\nwhile\n\nas\n\ndef\n\nFalse\n\nif\n\nNone\n\nraise\n\nwith\n\nassert\n\ndel\n\nfinally\n\nimport\n\nnonlocal\n\nreturn\n\nyield\n\nbreak\n\nelif\n\nfor\n\nin\n\nnot\n\nTrue\n\nclass\n\nelse\n\nfrom\n\nis\n\nor\n\ntry\n\nWe already met most of these keywords in the preceding chapter, although 11 of them—assert, class, del, finally, from, global, lambda, nonlocal, raise, with, and yield—have yet to be discussed.\n\nThe ﬁrst conventionis:Don’t use thenamesof any of Python’spredeﬁnediden- tiﬁers for your own identiﬁers. So, avoid using NotImplemented and Ellipsis, and the name of any of Python’s built-in data types (such as int, float, list, str, and tuple), and any of Python’s built-in functions or exceptions. How can we tell whether an identiﬁer falls into one of these categories? Python has a built-in function called dir() that returnsa list of an object’sattributes. If it is called with no argumentsit returnsthe list of Python’sbuilt-in attributes. For example:\n\n>>> dir() # Python 3.1's list has an extra item, '__package__' ['__builtins__', '__doc__', '__name__']\n\nThe __builtins__ attribute is, in effect, a module that holds all of Python’s built-in attributes. We can use it as an argument to the dir() function:\n\n>>> dir(__builtins__) ['ArithmeticError', 'AssertionError', 'AttributeError', ... 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n\n★A “PEP” is a Python Enhancement Proposal. If someone wants to change or extend Python, providingthey get enoughsupportfromthePythoncommunity,they submita PEP withthedetails of their proposal so that it can be formally considered, and in some cases such as with PEP 3131, accepted and implemented. All the PEPs are accessible from www.python.org/dev/peps/.\n\nimport 38➤\n\nIdentiﬁers and Keywords\n\nThere are about 130 namesin the list,so we have omitted most of them. Those that begin with a capital letter are the names of Python’s built-in exceptions; the rest are function and data type names.\n\nThe second convention concerns the use of underscores (_). Names that begin and end with two underscores (such as __lt__) should not be used. Python deﬁnes various special methods and variables that use such names (and in the case of special methods, we can reimplement them, that is, make our own ver- sions of them), but we should not introduce new names of this kind ourselves. We will cover such namesin Chapter 6.Namesthat begin with one or two lead- ing underscores(andthat don’tendwith twounderscores)aretreatedspecially in some contexts. We will show when to use names with a single leading un- derscore in Chapter 5, and when to use those with two leading underscores in Chapter 6.\n\nA single underscore on its own can be used as an identiﬁer, and inside an interactiveinterpreteror Python Shell,_ holdstheresult of thelast expression that was evaluated. In a normal running program no _ exists,unless we use it explicitly in our code. Some programmers like to use _ in for … in loops when they don’t care about the items being looped over. For example:\n\nfor _ in (0, 1, 2, 3, 4, 5):\n\nprint(\"Hello\")\n\nBe aware, however, that those who write programs that are international- ized often use _ as the name of their translation function. They do this so that instead of writing gettext.gettext(\"Translate me\"), they can write _(\"Translate me\"). (For this code to work we must have ﬁrst imported the get- text module so that we can access the module’s gettext() function.)\n\nLet’s look at some valid identiﬁers in a snippet of code written by a Spanish- speaking programmer. The code assumes we have done import math and that the variables radio and vieja_área have been created earlier in the program:\n\nπ = math.pi ε = 0.0000001 nueva_área = π * radio * radio if abs(nueva_área - vieja_área) < ε: print(\"las áreas han convergido\")\n\nWe’ve used the math module, set epsilon (ε) to be a very small ﬂoating-point number, and used the abs() function to get the absolute value of the difference between the areas—we cover all of these later in this chapter. What we are concerned with here is that we are free to use accented characters and Greek letters for identiﬁers. We could just as easily create identiﬁers using Arabic, Chinese,Hebrew,Japanese,and Russian characters,or indeed charactersfrom any other language supported by the Unicode character set.\n\n53\n\nimport ➤ 196\n\n54\n\nChapter 2. Data Types\n\nThe easiest way to check whether something is a valid identiﬁer is to try to assign to it in an interactive Python interpreter or in IDLE’s Python Shell window. Here are some examples:\n\n>>> stretch-factor = 1 SyntaxError: can't assign to operator (...) >>> 2miles = 2 SyntaxError: invalid syntax (...) >>> str = 3 # Legal but BAD >>> l'impôt31 = 4 SyntaxError: EOL while scanning single-quoted string (...) >>> l_impôt31 = 5 >>>\n\nWhen aninvalididentiﬁerisusedit causesa SyntaxError exceptiontoberaised. In each case the part of the error message that appears in parentheses varies, so we have replaced it with an ellipsis. The ﬁrst assignment fails because “-” is not a Unicode letter, digit, or underscore. The second one fails because the start character is not a Unicode letter or underscore; only continuation characters can be digits. No exception is raised if we create an identiﬁer that is valid—even if the identiﬁer is the name of a built-in data type, exception, or function—so the third assignment works, although it is ill-advised. The fourth fails because a quote is not a Unicode letter, digit, or underscore. The ﬁfth is ﬁne.\n\nIntegral Types\n\n|||\n\nPython provides two built-in integral types, int and bool.★ Both integers and Booleans are immutable, but thanks to Python’s augmented assignment oper- ators this is rarely noticeable. When used in Boolean expressions, 0 and False are False, and any other integer and True are True. When used in numerical expressions True evaluates to 1 and False to 0. This means that we can write somerather odd things—for example,wecan incrementan integer,i,using the expression i += True. Naturally, the correct way to do this is i += 1.\n\nIntegers\n\n||\n\nThe size of an integer is limited only by the machine’s memory, so integers hundreds of digits long can easily be created and worked with—although they will be slower to use than integers that can be represented natively by the machine’s processor.\n\n★The standard library also provides the fractions.Fraction type (unlimited precision rationals) which may be useful in some specialized mathematical and scientiﬁc contexts.\n\nDeal- ing with syntax errors ➤ 414\n\nTuples 18➤\n\nIntegral Types\n\nTable 2.2 Numeric Operators and Functions\n\nSyntax\n\nDescription\n\nx + y\n\nAdds number x and number y\n\nx - y\n\nSubtracts y from x\n\nx * y\n\nMultiplies x by y\n\nx / y\n\nDivides x by y; always produces a float (or a complex if x or y is complex)\n\nx // y\n\nDivides x by y; truncates any fractional part so always pro- duces an int result; see also the round() function\n\nx % y\n\nProduces the modulus (remainder) of dividing x by y\n\nx ** y\n\nRaises x to the power of y; see also the pow() functions\n\nx\n\nNegates x; changes x’s sign if nonzero, does nothing if zero\n\n+x\n\nDoes nothing; is sometimes used to clarify code\n\nabs(x)\n\nReturns the absolute value of x\n\ndivmod(x, y) Returns the quotient and remainder of dividing\n\nx by y as a\n\ntuple of two ints\n\npow(x, y)\n\nRaises x to the power of y; the same as the ** operator\n\npow(x, y, z) A faster alternative to (x ** y) % z\n\nround(x, n)\n\nReturns x rounded to n integral digits if n is a negative int or returns x rounded to n decimal places if n is a positive int; the returned value has the same type as x; see the text\n\nTable 2.3 Integer Conversion Functions\n\nSyntax\n\nDescription\n\nbin(i)\n\nhex(i)\n\nint(x)\n\nReturns the binary representation of int i as a string, e.g., bin(1980) == '0b11110111100' Returnsthe hexadecimal representation of i as a string,e.g., hex(1980) == '0x7bc' Converts object x to an integer; raises ValueError on failure—or TypeError if x’sdata type doesnot support integer conversion. If x is a ﬂoating-point number it is truncated.\n\nint(s, base) Converts str s to an integer; raises ValueError on failure. If the optional base argument is given it should be an integer between 2 and 36 inclusive. Returns the octal representation of i as a string, e.g., oct(1980) == '0o3674'\n\noct(i)\n\n55\n\nTuples ➤ 108",
      "page_number": 55
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 63-75)",
      "start_page": 63,
      "end_page": 75,
      "detection_method": "topic_boundary",
      "content": "56\n\nChapter 2. Data Types\n\nInteger literals are written using base 10 (decimal) by default, but other number bases can be used when this is convenient:\n\n>>> 14600926 14600926 >>> 0b110111101100101011011110 14600926 >>> 0o67545336 14600926 >>> 0xDECADE 14600926\n\n# decimal\n\n# binary\n\n# octal\n\n# hexadecimal\n\nBinary numbers are written with a leading 0b, octal numbers with a leading 0o,★ and hexadecimal numbers with a leading 0x. Uppercase letters can also be used.\n\nAll the usual mathematical functions and operators can be used with integers, as Table 2.2 shows. Some of the functionality is provided by built-in functions like abs()—for example, abs(i) returns the absolute value of integer i—and other functionality is provided by int operators—for example,i + j returnsthe sum of integers i and j.\n\nWewillmentionjust oneof thefunctionsfromTable2.2,sincealltheothersare sufﬁciently explained in the table itself. While for floats, the round() function works in the expected way—for example, round(1.246, 2) produces 1.25—for ints, using a positive rounding value has no effect and results in the same number being returned,sincetherearenodecimaldigitstowork on. But when a negativerounding valueisused a subtleand usefulbehavior isachieved—for example, round(13579, -3) produces 14000, and round(34.8, -1) produces 30.0.\n\nAll the binary numeric operators (+, -, /, //, %, and **) have augmented assign- ment versions (+=, -=, /=, //=, %=,and **=) where x op= y is logically equivalent to x = xop y in the normal case when reading x’s value has no side effects.\n\nObjects can be created by assigning literals to variables, for example, x = 17, or by calling the relevant data type as a function, for example, x = int(17). Some objects (e.g., those of type decimal.Decimal) can be created only by using the data type since they have no literal representation. When an object is created using its data type there are three possible use cases.\n\nThe ﬁrst use case is when a data type is called with no arguments. In this case an object with a default value is created—for example, x = int() creates an integer of value 0. All the built-in types can be called with no arguments.\n\nThe second use case is when the data type is called with a single argument. If an argument of the same type is given, a new object which is a shallow copy of\n\n★Usersof C-stylelanguagesnote that a singleleading 0 isnot sufﬁcient to specify an octal number; 0o (zero, letter o) must be used in Python.\n\nIntegral Types\n\nthe original object is created. (Shallow copying is covered in Chapter 3.) If an argument of a different type is given, a conversion is attempted. This use is shown for the int type in Table 2.3. If the argument is of a type that supports conversions to the given type and the conversion fails, a ValueError exception is raised; otherwise, the resultant object of the given type is returned. If the argument’sdata type does not support conversion to the given type a TypeError exception is raised. The built-in float and str types both provide integer conversions; it is also possible to provide integer and other conversions for our own custom data types as we will see in Chapter 6.\n\nThe third use case is where two or more arguments are given—not all types support this, and for those that do the argument types and their meanings vary. For the int type two arguments are permitted where the ﬁrst is a string that represents an integer and the second is the number base of the string representation. For example, int(\"A4\", 16) creates an integer of value 164. This use is shown in Table 2.3.\n\nThe bitwise operators are shown in Table 2.4. All the binary bitwise operators (|, ^, &, <<, and >>) have augmented assignment versions (|=, ^=, &=, <<=, and >>=) where i op= j is logically equivalent to i = i op j in the normal case when reading i’s value has no side effects.\n\nFrom Python 3.1, the int.bit_length() method is available. This returns the number of bits required to represent the int it is called on. For example, (2145).bit_length() returns 12. (The parentheses are required if a literal inte- ger is used, but not if we use an integer variable.)\n\nIf many true/falseﬂagsneed tobeheld,onepossibility istousea singleinteger, and to test individual bits using the bitwise operators. The same thing can be achieved less compactly, but more conveniently, using a list of Booleans.\n\nTable 2.4 Integer Bitwise Operators\n\nSyntax Description\n\ni | j\n\nBitwise OR of int i and int j; negative numbers are assumed to be represented using 2’s complement\n\ni ^ j\n\nBitwise XOR (exclusive or) of i and j\n\ni & j\n\nBitwise AND of i and j\n\ni << j Shifts i left by j bits; like i * (2 ** j) without overﬂow checking\n\ni >> j Shifts i right by j bits; like i // (2 ** j) without overﬂow checking\n\n~i\n\nInverts i’s bits\n\n57\n\nCopying collec- tions ➤ 146\n\nType conver- sions ➤ 252\n\n3.1\n\nLogical opera- tors 25➤\n\n58\n\nChapter 2. Data Types\n\nBooleans\n\n||\n\nThere are two built-in Boolean objects: True and False. Like all other Python data types (whether built-in, library, or custom), the bool data type can be called asa function—with no argumentsit returnsFalse,with a bool argument it returns a copy of the argument, and with any other argument it attempts to convert the given object to a bool. All the built-in and standard library data types can be converted to produce a Boolean value, and it is easy to provide Boolean conversions for custom data types. Here are a couple of Boolean assignments and a couple of Boolean expressions:\n\n>>> t = True >>> f = False >>> t and f False >>> t and True True\n\nPython provides three logical operators: and, or, and not. As we noted earlier, Both and and or use short-circuit logic and return the operand that determined the result, whereas not always returns either True or False.\n\nProgrammers who have been using older versions of Python sometimes use 1 and 0 instead of True and False; this almost always works ﬁne, but new code should use the built-in Boolean objects when a Boolean value is required.\n\nFloating-Point Types\n\n|||\n\nPython provides three kinds of ﬂoating-point values: the built-in float and complex types,and the decimal.Decimal typefromthestandardlibrary. Allthree are immutable. Type float holds double-precision ﬂoating-point numbers whose range depends on the C (or C# or Java) compiler Python was built with; they have limited precision and cannot reliably be compared for equality. Numbers of type float are written with a decimal point, or using exponential notation, for example, 0.0, 4., 5.7, -2.5, -2e9, 8.9e-4.\n\nComputers natively represent ﬂoating-point numbers using base 2—this means that some decimals can be represented exactly (such as 0.5), but others only approximately(suchas0.1and0.2).Furthermore,therepresentationuses a ﬁxed number of bits, so there is a limit to the number of digits that can be held. Here is a salutary example typed into IDLE:\n\n>>> 0.0, 5.4, -2.5, 8.9e-4 (0.0, 5.4000000000000004, -2.5, 0.00088999999999999995)\n\n3.0\n\nFloating-Point Types\n\nThe inexactness is not a problem speciﬁc to Python—all programming lan- guages have this problem with ﬂoating-point numbers.\n\nPython 3.1 produces much more sensible-looking output:\n\n>>> 0.0, 5.4, -2.5, 8.9e-4 (0.0, 5.4, -2.5, 0.00089)\n\nWhen Python 3.1 outputs a ﬂoating-point number, in most cases it uses David Gay’s algorithm. This outputs the fewest possible digits without losing any accuracy. Although this produces nicer output, it doesn’t change the fact that computers (no matter what computer language is used) effectively store ﬂoating-point numbers as approximations.\n\nIf we need really high precision there are two approaches we can take. One approach is to use ints—for example, working in terms of pennies or tenths of a penny or similar—and scale the numbers when necessary. This requires us to be quite careful, especially when dividing or taking percentages. The other approach is to use Python’s decimal.Decimal numbers from the decimal module. Theseperformcalculationsthatareaccuratetothelevelof precisionwespecify (by default, to 28 decimal places) and can represent periodic numbers like 0.1 exactly; but processing is a lot slower than with floats. Because of their accu- racy, decimal.Decimal numbers are suitable for ﬁnancial calculations.\n\nMixed mode arithmetic is supported such that using an int and a float pro- duces a float,and using a float and a complex producesa complex.Because dec- imal.Decimals are of ﬁxed precision they can be used only with other decimal. Decimals and with ints, in the latter case producing a decimal.Decimal result. If an operation is attempted using incompatible types, a TypeError exception is raised.\n\nFloating-Point Numbers\n\nAll the numeric operators and functions in Table 2.2 (55 ➤) can be used with floats,including the augmented assignment versions. The float data typecan be called as a function—with no arguments it returns 0.0, with a float argu- ment it returns a copy of the argument, and with any other argument it at- temptstoconvertthegivenobjecttoa float.Whenusedforconversionsa string argument can be given, either using simple decimal notation or using expo- nential notation. It is possible that NaN (“not a number”) or “inﬁnity” may be produced by a calculation involving floats—unfortunately the behavior is not consistent across implementations and may differ depending on the system’s underlying math library.\n\nHere is a simple function for comparing floats for equality to the limit of the machine’s accuracy:\n\n59\n\n||\n\n3.1\n\nTuples 18➤\n\n60\n\nChapter 2. Data Types\n\nTable 2.5 The Math Module’s Functions and Constants #1\n\nSyntax\n\nDescription\n\nmath.acos(x)\n\nReturns the arc cosine of x in radians\n\nmath.acosh(x)\n\nReturns the arc hyperbolic cosine of x in radians\n\nmath.asin(x)\n\nReturns the arc sine of x in radians\n\nmath.asinh(x)\n\nReturns the arc hyperbolic sine of x in radians\n\nmath.atan(x)\n\nReturns the arc tangent of x in radians\n\nmath.atan2(y, x)\n\nReturns the arc tangent of y / x in radians\n\nmath.atanh(x)\n\nReturns the arc hyperbolic tangent of x in radians\n\nmath.ceil(x)\n\nReturns ⎡x⎤ , i.e., the smallest integer greater than or equal to x as an int; e.g., math.ceil(5.4) == 6\n\nmath.copysign(x,y) Returns x with y’s sign\n\nmath.cos(x)\n\nReturns the cosine of x in radians\n\nmath.cosh(x)\n\nReturns the hyperbolic cosine of x in radians\n\nmath.degrees(r)\n\nConverts float r from radians to degrees\n\nmath.e\n\nmath.exp(x)\n\nmath.fabs(x)\n\nmath.factorial(x)\n\nmath.floor(x)\n\nThe constant e; approximately 2.7182818284590451 Returns ex, i.e., math.e ** x Returns | x |, i.e., the absolute value of x as a float Returns x! Returns ⎣x⎦ ,i.e.,the largest integer less than or equal to x as an int; e.g., math.floor(5.4) == 5\n\nmath.fmod(x, y)\n\nProduces the modulus (remainder) of dividing x by y; this produces better results than % for floats\n\nmath.frexp(x)\n\nmath.fsum(i)\n\nmath.hypot(x, y)\n\nmath.isinf(x)\n\nmath.isnan(x)\n\nReturns a 2-tuple with the mantissa (as a m × 2 ; see math.ldexp() the exponent (as an int) so, x = Returns the sum of the values in iterable i as a float Returns√ 2x + 2y Returns True if float x is ± inf (± ∞) Returns True if float x is nan (“not a number”)\n\nfloat) and\n\ne\n\nmath.ldexp(m, e)\n\nmath.log(x, b)\n\nmath.log10(x)\n\nmath.log1p(x)\n\nmath.modf(x)\n\ne\n\nm × 2 ; effectively the inverse of math.frexp()\n\nReturns Returns logbx; b is optional and defaults to math.e Returns log10x Returns loge Returns x’s fractional and whole parts as two floats\n\n(1+ x); accurate even when x is close to 0\n\nTuples ➤ 108\n\nFloating-Point Types\n\nTable 2.6 The Math Module’s Functions and Constants #2\n\nSyntax\n\nDescription The constant π; approximately 3.1415926535897931 Returns yx as a float math.radians(d) Converts float d from degrees to radians\n\nmath.pi\n\nmath.pow(x, y)\n\nmath.sin(x)\n\nReturns the sine of x in radians\n\nmath.sinh(x)\n\nmath.sqrt(x)\n\nmath.tan(x)\n\nReturns the hyperbolic sine of x in radians Returns√x Returns the tangent of x in radians\n\nmath.tanh(x)\n\nReturns the hyperbolic tangent of x in radians\n\nmath.trunc(x)\n\nReturns the whole part of x as an int; same as int(x)\n\ndef equal_float(a, b):\n\nreturn abs(a - b) <= sys.float_info.epsilon\n\nThis requiresus to import the sys module. The sys.float_info object hasmany attributes;sys.float_info.epsilon iseffectively thesmallestdifferencethatthe machine can distinguish between two ﬂoating-point numbers. On one of the author’s 32-bit machines it is just over 0.0000000000000002. (Epsilon is the traditional name for this number.) Python floats normally provide reliable accuracy for up to 17 signiﬁcant digits.\n\nIf you type sys.float_info into IDLE, all its attributes will be displayed; these include the minimum and maximum ﬂoating-point numbers the machine can represent. And typing help(sys.float_info) will print some information about the sys.float_info object.\n\nFloating-point numbers can be converted to integers using the int() func- tion which returns the whole part and throws away the fractional part, or using round() which accounts for the fractional part, or using math.floor() or math.ceil() which convert down to or up to the nearest integer. The float.is_integer() method returns True if a ﬂoating-point number’s frac- tional part is 0, and a float’s fractional representation can be obtained using the float.as_integer_ratio() method. For example, given x = 2.75, the call x.as_integer_ratio() returns (11, 4). Integers can be converted to ﬂoating- point numbers using float().\n\nFloating-point numbers can also be represented as strings in hexadecimal format using the float.hex() method. Such strings can be converted back to ﬂoating-point numbers using the float.fromhex() method. For example:\n\ns = 14.25.hex()\n\n# str s == '0x1.c800000000000p+3'\n\n61\n\n62\n\nChapter 2. Data Types\n\nf = float.fromhex(s) t = f.hex()\n\n# float f == 14.25 # str t == '0x1.c800000000000p+3'\n\nThe exponent is indicated using p (“power”) rather than e since e is a valid hexadecimal digit.\n\nIn addition to the built-in ﬂoating-point functionality,the math moduleprovides many more functions that operate on floats, as shown in Tables 2.5 and 2.6. Here are some code snippets that show how to make use of the module’s func- tionality:\n\n>>> import math >>> math.pi * (5 ** 2) # Python 3.1 outputs: 78.53981633974483 78.539816339744831 >>> math.hypot(5, 12) 13.0 >>> math.modf(13.732) # Python 3.1 outputs: (0.7319999999999993, 13.0) (0.73199999999999932, 13.0)\n\nThe math.hypot() function calculates the distance from the origin to the point (x, y) and produces the same result as math.sqrt((x ** 2) + (y ** 2)).\n\nThe math moduleisvery dependenton theunderlying mathlibrary thatPython was compiled against. This means that some error conditions and boundary cases may behave differently on different platforms.\n\nComplex Numbers\n\nThe complex data type is an immutable type that holds a pair of floats, one representing the real part and the other the imaginary part of a complex number. Literal complex numbers are written with the real and imaginary partsjoined by a + or - sign,and with the imaginary part followed by a j.★ Here are some examples: 3.5+2j, 0.5j, 4+0j, -1-3.7j. Notice that if the real part is 0, we can omit it entirely.\n\nThe separate parts of a complex are available as attributes real and imag. For example:\n\n>>> z = -89.5+2.125j >>> z.real, z.imag (-89.5, 2.125)\n\nExcept for //, %, divmod(), and the three-argument pow(), all the numeric operators and functions in Table 2.2 (55➤) can be used with complex numbers, and so can the augmented assignment versions. In addition, complex numbers\n\n★Mathematicians use i to signify √ − 1, but Python follows the engineering tradition and uses j.\n\n||\n\n3.x\n\nFloating-Point Types\n\nhave a method, conjugate(), which changes the sign of the imaginary part. For example:\n\n>>> z.conjugate() (-89.5-2.125j) >>> 3-4j.conjugate() (3+4j)\n\nNoticethatherewehavecalleda methodon a literal complex number. In gener- al, Python allows us to call methods or access attributes on any literal, as long as the literal’sdata type providesthe called method or the attribute—however, this does not apply to special methods, since these always have corresponding operatorssuch as + that should be used instead. For example,4j.real produces 0.0, 4j.imag produces 4.0, and 4j + 3+2j produces 3+6j.\n\nThe complex data type can be called as a function—with no arguments it returns 0j, with a complex argument it returns a copy of the argument, and with any other argument it attempts to convert the given object to a complex. When used for conversions complex() accepts either a single string argument, or one or two floats. If just one float is given, the imaginary part is taken to be 0j.\n\nThe functions in the math module do not work with complex numbers. This is a deliberate design decision that ensures that users of the math module get exceptions rather than silently getting complex numbers in some situations.\n\nUsers of complex numbers can import the cmath module, which provides com- plex number versions of most of the trigonometric and logarithmic functions that are in the math module,plus some complex number-speciﬁc functions such as cmath.phase(), cmath.polar(), and cmath.rect(), and also the cmath.pi and cmath.e constants which hold the same float values as their math module coun- terparts.\n\nDecimal Numbers\n\nIn many applications the numerical inaccuracies that can occur when using floats don’t matter, and in any case are far outweighed by the speed of calcu- lation that floats offer. But in some cases we prefer the opposite trade-off,and wantcompleteaccuracy,evenatthecostof speed. The decimal moduleprovides immutable Decimal numbers that are as accurate as we specify. Calculations involving Decimals are slower than those involving floats, but whether this is noticeable will depend on the application.\n\nTo create a Decimal we must import the decimal module. For example:\n\n>>> import decimal >>> a = decimal.Decimal(9876)\n\n63\n\n||\n\n64\n\nChapter 2. Data Types\n\n>>> b = decimal.Decimal(\"54321.012345678987654321\") >>> a + b Decimal('64197.012345678987654321')\n\nDecimal numbers are created using the decimal.Decimal() function. This functioncantakean integeror a string argument—butnot a float,since floats are held inexactly whereas decimals are represented exactly. If a string is used it can use simple decimal notation or exponential notation. In addition to providing accuracy,the exact representation of decimal.Decimals means that they can be reliably compared for equality.\n\nFrom Python 3.1 it is possible to convert floats to decimals using the deci- mal.Decimal.from_float() function. This function takes a float as argument and returnsthe decimal.Decimal that is closest to the number the float approx- imates.\n\nAll the numeric operators and functions listed in Table 2.2 (55 ➤), including the augmented assignment versions, can be used with decimal.Decimals, but with a couple of caveats. If the ** operator has a decimal.Decimal left-hand operand, its right-hand operand must be an integer. Similarly, if the pow() function’s ﬁrst argument is a decimal.Decimal, then its second and optional third arguments must be integers.\n\nThe math and cmath modules are not suitable for use with decimal.Decimals, but some of the functions provided by the math module are provided as deci- mal.Decimal methods. For example, to calculate xe where x is a float, we write math.exp(x), but where x is a decimal.Decimal, we write x.exp(). From the dis- cussion in Piece #3 (20 ➤), we can see that x.exp() is, in effect, syntactic sugar for decimal.Decimal.exp(x).\n\nThe decimal.Decimal data type also provides ln() which calculates the natural (base e)logarithm(just like math.log() with one argument),log10(),and sqrt(), along with many other methods speciﬁc to the decimal.Decimal data type.\n\nNumbers of type decimal.Decimal work within the scope of a context; the context is a collection of settings that affect how decimal.Decimals behave. The context speciﬁes the precision that should be used (the default is 28 decimal places), the rounding technique, and some other details.\n\nIn some situations the difference in accuracy between floats and decimal. Decimals becomes obvious:\n\n>>> 23 / 1.05 21.904761904761905 >>> print(23 / 1.05) 21.9047619048 >>> print(decimal.Decimal(23) / decimal.Decimal(\"1.05\")) 21.90476190476190476190476190\n\n3.1\n\nFloating-Point Types\n\n>>> decimal.Decimal(23) / decimal.Decimal(\"1.05\") Decimal('21.90476190476190476190476190')\n\nAlthough the division using decimal.Decimals is more accurate than the one involving floats, in this case (on a 32-bit machine) the difference only shows up in the ﬁfteenth decimal place. In many situations this is insigniﬁcant—for example, in this book, all the examples that need ﬂoating-point numbers use floats.\n\nOne other point to note is that the last two of the preceding examples reveal for the ﬁrst time that printing an object involves some behind-the-scenes for- matting. When we call print() on the result of decimal.Decimal(23) / deci- mal.Decimal(\"1.05\") the bare number is printed—this output is in string form. If we simply enter theexpressionwe get a decimal.Decimal output—thisoutput is in representational form. All Python objects have two output forms. String form is designed to be human-readable. Representational form is designed to produce output that if fed to a Python interpreter would (when possible) re- produce the represented object. We will return to this topic in the next section where we discuss strings, and again in Chapter 6 when we discuss providing string and representational forms for our own custom data types.\n\nThe Library Reference’s decimal module documentation provides all the details that are too obscure or beyond our scope to cover; it also provides more examples, and a FAQ list.\n\nStrings\n\nStringsarerepresentedby theimmutablestr datatypewhichholdsasequence of Unicode characters. The str data type can be called as a function to create string objects—with no arguments it returns an empty string, with a non- string argument it returns the string form of the argument, and with a string argument it returns a copy of the string. The str() function can also be used as a conversion function, in which case the ﬁrst argument should be a string or something convertable to a string,with up to two optional string arguments being passed, one specifying the encoding to use and the other specifying how to handle encoding errors.\n\nEarlier we mentioned that string literalsare created using quotes,and that we are free to use single or double quotes providing we use the same at both ends. In addition,we can use a triplequoted string—thisis Python-speak for a string that begins and ends with three quote characters(either three single quotes or three double quotes). For example:\n\ntext = \"\"\"A triple quoted string like this can include 'quotes' and \"quotes\" without formality. We can also escape newlines \\ so this particular string is actually only two lines long.\"\"\"\n\n65\n\n|||\n\nChar- acter encod- ings ➤ 91\n\n66\n\nChapter 2. Data Types\n\nTable 2.7 Python’s String Escapes\n\nEscape\n\nMeaning\n\n\\newline\n\nEscape (i.e., ignore) the newline\n\n\\\\\n\nBackslash (\\)\n\n\\'\n\nSingle quote (’)\n\n\\\"\n\nDouble quote (\")\n\n\\a\n\nASCII bell (BEL)\n\n\\b\n\nASCII backspace (BS)\n\n\\f\n\nASCII formfeed (FF)\n\n\\n\n\nASCII linefeed (LF)\n\n\\N{name}\n\nUnicode character with the given name\n\n\\ooo\n\nCharacter with the given octal value\n\n\\r\n\nASCII carriage return (CR)\n\n\\t\n\nASCII tab (TAB)\n\n\\uhhhh\n\nUnicode character with the given 16-bit hexadecimal value\n\n\\Uhhhhhhhh Unicode character with the given 32-bit hexadecimal value\n\n\\v\n\nASCII vertical tab (VT)\n\n\\xhh\n\nCharacter with the given 8-bit hexadecimal value\n\nIf we want to use quotes inside a normal quoted string we can do so without formality if they are different from the delimiting quotes; otherwise, we must escape them:\n\na = \"Single 'quotes' are fine; \\\"doubles\\\" must be escaped.\" b = 'Single \\'quotes\\' must be escaped; \"doubles\" are fine.'\n\nPython uses newline as its statement terminator, except inside parentheses (()), square brackets ([]), braces ({}), or triple quoted strings. Newlines can be used without formality in triple quoted strings, and we can include newlines in any string literal using the \\n escape sequence. All of Python’s escape se- quencesareshownin Table2.7.In somesituations—forexample,whenwriting regular expressions—we need to create stringswith lots of literal backslashes. (Regular expressions are the subject of Chapter 13.) This can be inconvenient since each one must be escaped:\n\nimport re phone1 = re.compile(\"^((?:[(]\\\\d+[)])?\\\\s*\\\\d+(?:-\\\\d+)?)$\")\n\nStrings\n\nThe solution is to use raw strings. These are quoted or triple quoted strings whose ﬁrst quote is preceded by the letter r. Inside such strings all characters are taken to be literals, so no escaping is necessary. Here is the phone regular expression using a raw string:\n\nphone2 = re.compile(r\"^((?:[(]\\d+[)])?\\s*\\d+(?:-\\d+)?)$\")\n\nIf we want to write a long string literal spread over two or more lines but with- out using a triple quoted string there are a couple of approaches we can take:\n\nt = \"This is not the best way to join two long strings \" + \\ \"together since it relies on ugly newline escaping\"\n\ns = (\"This is the nice way to join two long strings \"\n\n\"together; it relies on string literal concatenation.\")\n\nNotice that in the second case we must use parentheses to create a single expression—without them, s would be assigned only to the ﬁrst string, and the second string would cause an IndentationError exception to be raised. The Python documentation’s “Idioms and Anti-Idioms” HOWTO document recom- mends always using parentheses to spread statements of any kind over mul- tiple lines rather than escaping newlines; a recommendation we endeavor to follow.\n\nSince .py ﬁles default to using the UTF-8 Unicode encoding, we can write any Unicode characters in our string literals without formality. We can also put any Unicode characters inside strings using hexadecimal escape sequences or using Unicode names. For example:\n\n>>> euros = \" >>> print(euros)\n\n\\N{euro sign} \\u20AC \\U000020AC\"\n\nIn this case we could not use a hexadecimal escape because they are limited to two digits, so they cannot exceed 0xFF. Note that Unicode character names are not case-sensitive, and spaces inside them are optional.\n\nIf we want to know the Unicode code point (the integer assigned to the charac- ter in the Unicode encoding) for a particular character in a string, we can use the built-in ord() function. For example:\n\n>>> ord(euros[0]) 8364 >>> hex(ord(euros[0])) '0x20ac'\n\nSimilarly, we can convert any integer that represents a valid code point into the corresponding Unicode character using the built-in chr() function:\n\n67\n\nChar- acter encod- ings ➤ 91\n\n68\n\nChapter 2. Data Types\n\n>>> s = \"anarchists are \" + chr(8734) + chr(0x23B7) >>> s 'anarchists are ∞√' >>> ascii(s) \"'anarchists are \\u221e\\u23b7'\"\n\nIf we enter s on itsown in IDLE,it isoutput in itsstring form,which for strings means the characters are output enclosed in quotes. If we want only ASCII characters,wecanusethebuilt-in ascii() functionwhichreturnstherepresen- tational form of itsargument using 7-bit ASCII characterswhere possible,and using the shortest form of \\xhh, \\uhhhh,or \\Uhhhhhhhh escape otherwise. We will see how to achieve precise control of string output later in this chapter.\n\nComparing Strings\n\nStrings support the usual comparison operators <, <=, ==, !=, >, and >=. These operators compare strings byte by byte in memory. Unfortunately, two prob- lems arise when performing comparisons, such as when sorting lists of strings. Both problemsafﬂict every programming language that uses Unicode strings—neither is speciﬁc to Python.\n\nThe ﬁrst problem is that some Unicode characters can be represented by two or more different byte sequences. For example, the character Å (Unicode code point 0x00C5) can be represented in UTF-8 encoded bytes in three different ways: [0xE2, 0x84, 0xAB], [0xC3, 0x85], and [0x41, 0xCC, 0x8A]. Fortunately, we can solve this problem. If we import the unicodedata module and call unicode- data.normalize() with \"NFKC\" as the ﬁrst argument (this is a normalization method—three others are also available, \"NFC\", \"NFD\", and \"NFKD\"), and a string containing the Å character using any of its valid byte sequences, the function will return a string that when represented as UTF-8 encoded byteswill always be the byte sequence [0xC3, 0x85].\n\nThe second problem is that the sorting of some charactersis language-speciﬁc. Oneexampleisthat in Swedishäissortedafter z,whereasin German,äissort- ed as if though were spelled ae. Another example is that although in English we sort ø as if it were o, in Danish and Norwegian it is sorted after z. There are lots of problems along these lines, and they can be complicated by the fact thatsometimesthesameapplicationisusedby peopleof differentnationalities (who therefore expect different sorting orders),and sometimes strings are in a mixtureof languages(e.g.,someSpanish,othersEnglish),andsomecharacters (such as arrows,dingbats,and mathematical symbols) don’t really have mean- ingful sort positions.\n\nAs a matter of policy—to prevent subtle mistakes—Python does not make guesses. In the case of string comparisons, it compares using the strings’ in- memory byte representation. This gives a sort order based on Unicode code\n\n||\n\nstr. format() ➤ 78\n\nChar- acter encod- ings ➤ 91",
      "page_number": 63
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 76-86)",
      "start_page": 76,
      "end_page": 86,
      "detection_method": "topic_boundary",
      "content": "Piece #3 18➤\n\nStrings\n\npoints which gives ASCII sorting for English. Lower- or uppercasing all the stringscomparedproducesamorenaturalEnglishlanguageordering. Normal- izing is unlikely to be needed unless the strings are from external sources like ﬁles or network sockets, but even in these cases it probably shouldn’t be done unless there is evidence that it is needed. We can of course customize Python’s sort methods as we will see in Chapter 3. The whole issue of sorting Unicode strings is explained in detail in the Unicode Collation Algorithm document (unicode.org/reports/tr10).\n\nSlicing and Striding Strings\n\nWe know from Piece #3 that individual items in a sequence, and therefore in- dividual charactersin a string,can be extracted using the item accessoperator ([]).In fact,this operator is much more versatile and can be used to extract not just one item or character,but an entire slice (subsequence)of itemsor charac- ters, in which context it is referred to as the slice operator.\n\nFirst we will begin by looking at extracting individual characters. Index positions into a string begin at 0 and go up to the length of the string minus 1. But it is also possible to use negative index positions—these count from the last character back toward the ﬁrst. Given the assignment s = \"Light ray\", Figure 2.1 shows all the valid index positions for string s.\n\ns[-9]\n\ns[-8]\n\ns[-7]\n\ns[-6]\n\ns[-5]\n\ns[-4]\n\ns[-3]\n\ns[-2]\n\ns[-1]\n\nL\n\ni g h t\n\nr a y\n\ns[0]\n\ns[1]\n\ns[2]\n\ns[3]\n\ns[4]\n\ns[5]\n\ns[6]\n\ns[7]\n\ns[8]\n\nFigure 2.1 String index positions\n\nNegative indexes are surprisingly useful, especially -1 which always gives us the last character in a string. Accessing an out-of-range index (or any index in an empty string) will cause an IndexError exception to be raised.\n\nThe slice operator has three syntaxes:\n\nseq[start] seq[start:end] seq[start:end:step]\n\nThe seq can be any sequence,such as a list,string,or tuple. The start, end,and step values must all be integers (or variables holding integers). We have used the ﬁrst syntax already: It extracts the start-th item from the sequence. The second syntax extracts a slice from and including the start-th item, up to and excluding the end-th item. We’ll discuss the third syntax shortly.\n\n69\n\n||\n\n72\n\nChapter 2. Data Types\n\noffers a better solution. The method takes a sequence as an argument (e.g., a list or tuple of strings), and joins them together into a single string with the string the method was called on between each one. For example:\n\n>>> treatises = [\"Arithmetica\", \"Conics\", \"Elements\"] >>> \" \".join(treatises) 'Arithmetica Conics Elements' >>> \"-<>-\".join(treatises) 'Arithmetica-<>-Conics-<>-Elements' >>> \"\".join(treatises) 'ArithmeticaConicsElements'\n\nThe ﬁrst exampleisperhapsthe most common, joining with a single character, in this case a space. The third example is pure concatenation thanks to the empty string which meansthat thesequenceof stringsarejoined with nothing in between.\n\nThe str.join() method can also be used with the built-in reversed() function, to reversea string,for example,\"\".join(reversed(s)),although thesameresult can be achieved more concisely by striding, for example, s[::-1].\n\nThe * operator provides string replication:\n\n>>> s = \"=\" * 5 >>> print(s) ===== >>> s *= 10 >>> print(s) ==================================================\n\nAs the example shows, we can also use the augmented assignment version of the replication operator.★\n\nWhen applied to strings, the in membership operator returns True if its left- hand string argument is a substring of, or equal to, its right-hand string ar- gument.\n\nIn cases where we want to ﬁnd the position of one string inside another, we have two methods to choose from. One is the str.index() method; this returns the index position of the substring, or raises a ValueError exception on failure. The other is the str.find() method; this returns the index position of the sub- string, or -1 on failure. Both methods take the string to ﬁnd as their ﬁrst ar- gument,and can accept a couple of optional arguments. The second argument is the start position in the string being searched,and the third argument isthe end position in the string being searched.\n\n★Stringsalso support the % operator for formatting. Thisoperator is deprecated and provided only to ease conversion from Python 2 to Python 3. It is not used in any of the book’s examples.\n\nIdenti- ﬁers and key- words 51➤\n\nStrings\n\nTable 2.8 String Methods #1\n\nSyntax\n\nDescription\n\ns.capitalize()\n\ns.center(width,\n\nchar)\n\nReturns a copy of str s with the ﬁrst letter capitalized; see also the str.title() method Returns a copy of s centered in a string of length width padded with spaces or optionally with char (a string of length 1); see str.ljust(), str.rjust(), and str.format()\n\ns.count(t,\n\nstart, end)\n\ns.encode(\n\nencoding, err)\n\nReturnsthe number of occurrencesof str t in str s (or in the start:end slice of s) Returns a bytes object that represents the string using the default encoding or using the speciﬁed encoding and handling errors according to the optional err argument\n\ns.endswith(x,\n\nstart, end)\n\ns.expandtabs( size)\n\nReturnsTrue if s (or the start:end sliceof s)endswith str x or with any of the strings in tuple x; otherwise,returns False. See also str.startswith(). Returns a copy of s with tabs replaced with spaces in multiples of 8 or of size if speciﬁed\n\ns.find(t,\n\nstart, end)\n\nReturnstheleftmostpositionof t in s (or in the start:end slice of s) or -1 if not found. Use str.rfind() to ﬁnd the rightmost position. See also str.index().\n\ns.format(...)\n\ns.index(t,\n\nstart, end)\n\nReturns a copy of s arguments. This method and its arguments are covered in the next subsection. Returns the leftmost position of t in s (or in the start:end sliceof s)or raisesValueError if not found. Use str.rindex() to search from the right. See str.find().\n\nformatted according to the given\n\ns.isalnum()\n\nReturns True if s is nonempty and every character in s is alphanumeric\n\ns.isalpha()\n\nReturns True if s is nonempty and every character in s is alphabetic\n\ns.isdecimal()\n\nReturns True if s is nonempty and every character in s is a Unicode base 10 digit\n\ns.isdigit()\n\nReturns True if s is nonempty and every character in s is an ASCII digit\n\ns.isidentifier() Returns True if s is nonempty and is\n\na valid identiﬁer\n\ns.islower()\n\nReturns True if s has at least one lowercaseable charac- ter and all its lowercaseable characters are lowercase; see also str.isupper()\n\n73\n\nbytes type ➤ 293\n\nChar- acter encod- ings ➤ 91\n\nstr. format() ➤ 78\n\n74\n\nChapter 2. Data Types\n\nTable 2.9 String Methods #2\n\nSyntax\n\nDescription\n\ns.isnumeric()\n\nReturns True if s is nonempty and every character in s is a numeric Unicode character such as a digit or fraction\n\ns.isprintable() Returns True if s is empty or if every character in s is con- sidered to be printable, including space, but not newline\n\ns.isspace()\n\nReturns True if s is nonempty and every character in s is a whitespace character\n\ns.istitle()\n\ns.isupper()\n\ns.join(seq)\n\nReturns True if s is a nonempty title-cased string; see also str.title() Returns True if str s has at least one uppercaseable char- acter and all its uppercaseable characters are uppercase; see also str.islower() Returns the concatenation of every item in the sequence seq, with str s (which may be empty) between each one\n\ns.ljust(\n\nwidth, char)\n\ns.lower()\n\nReturnsa copy of s left-aligned in a string of length width padded with spaces or optionally with char (a string of length 1). Use str.rjust() to right-align and str.center() to center. See also str.format(). Returns a lowercased copy of s; see also str.upper()\n\ns.maketrans()\n\nCompanion of str.translate(); see text for details\n\ns.partition(\n\nt)\n\nReturns a tuple of three strings—the part of str s before the leftmost str t,t,and thepart of s after t;or if t isn’t in s returns s and two empty strings. Use str.rpartition() to partition on the rightmost occurrence of t.\n\ns.replace(t, u, n)\n\nReturns a copy of s with every (or a maximum of n if given) occurrences of str t replaced with str u\n\ns.split(t, n)\n\nReturns a list of strings splitting at most n times on str t; if n isn’t given, splits as many times as possible; if t isn’t given,splitson whitespace. Use str.rsplit() to split from the right—thismakesa difference only if n is given and is less than the maximum number of splits possible.\n\ns.splitlines(\n\nf)\n\nReturns the list of lines produced by splitting s on line terminators, stripping the terminators unless f is True\n\ns.startswith( x, start, end)\n\nReturns True if s (or the start:end slice of s) starts with str x or with any of the strings in tuple x; otherwise, returns False. See also str.endswith().\n\nStrings\n\nTable 2.10 String Methods #3\n\nSyntax\n\nDescription\n\ns.strip(chars) Returns a copy of s with leading and trailing whitespace\n\n(or thecharactersin str chars)removed;str.lstrip() strips only at the start, and str.rstrip() strips only at the end\n\ns.swapcase()\n\nReturns a copy of s with uppercase characters lowercased and lowercase characters uppercased; see also str.lower() and str.upper()\n\ns.title()\n\ns.translate()\n\nReturns a copy of s where the ﬁrst letter of each word is uppercased and all other letters are lowercased; see str.istitle() Companion of str.maketrans(); see text for details\n\ns.upper()\n\nReturns an uppercased copy of s; see also str.lower()\n\ns.zfill(w)\n\nReturns a copy of s, which if shorter than w is padded with leading zeros to make it w characters long\n\nWhich search method we use is purely a matter of taste and circumstance, although if we are looking for multiple index positions, using the str.index() method often produces cleaner code, as the following two equivalent functions illustrate:\n\ndef extract_from_tag(tag, line): opener = \"<\" + tag + \">\" closer = \"</\" + tag + \">\" try:\n\ni = line.index(opener) start = i + len(opener) j = line.index(closer, start) return line[start:j]\n\ndef extract_from_tag(tag, line): opener = \"<\" + tag + \">\" closer = \"</\" + tag + \">\" i = line.find(opener) if i != -1:\n\nstart = i + len(opener) j = line.find(closer, start) if j != -1:\n\nexcept ValueError: return None\n\nreturn line[start:j]\n\nreturn None\n\nBoth versions of the extract_from_tag() function have exactly the same be- havior. For example, extract_from_tag(\"red\", \"what a <red>rose</red> this is\") returns the string “rose”.The exception-handling version on the left separates out the code that doeswhat we want from the code that handleserrors,and the error return value version on the right intersperses what we want with error handling.\n\nThe methods str.count(), str.endswith(), str.find(), str.rfind(), str.index(), str.rindex(), and str.startswith() all accept up to two optional arguments: a start position and an end position. Here are a couple of equivalences to put this in context, assuming that s is a string:\n\n75\n\n76\n\nChapter 2. Data Types\n\ns.count(\"m\", 6) == s[6:].count(\"m\") s.count(\"m\", 5, -3) == s[5:-3].count(\"m\")\n\nAs we can see,the string methodsthat accept start and end indexesoperate on the slice of the string speciﬁed by those indexes.\n\nNow we will look at another equivalence, this time to help clarify the behavior of str.partition()—although we’ll actually use a str.rpartition() example:\n\ni = s.rfind(\"/\") if i == -1:\n\nresult = \"\", \"\", s\n\nelse:\n\nresult = s.rpartition(\"/\")\n\nresult = s[:i], s[i], s[i + 1:]\n\nThe left- and right-hand code snippets are not quite equivalent because the one on the right also createsa new variable, i.Notice that we can assign tuples without formality, and that in both cases we looked for the rightmost occur- rence of /.If s isthe string \"/usr/local/bin/firefox\",both snippetsproducethe same result: ('/usr/local/bin', '/', 'firefox').\n\nWe can use str.endswith() (and str.startswith()) with a single string argu- ment, for example, s.startswith(\"From:\"), or with a tuple of strings. Here is a statement that uses both str.endswith() and str.lower() to print a ﬁlename if it is a JPEG ﬁle:\n\nif filename.lower().endswith((\".jpg\", \".jpeg\")):\n\nprint(filename, \"is a JPEG image\")\n\nThe is*() methods such as isalpha() and isspace() return True if the string they are called on has at least one character,and every character in the string meets the criterion. For example:\n\n>>> \"917.5\".isdigit(), \"\".isdigit(), \"-2\".isdigit(), \"203\".isdigit() (False, False, False, True)\n\nThe is*() methods work on the basis of Unicode character classiﬁcations, so for example, calling str.isdigit() on the strings \"\\N{circled digit two}03\" and \"➁03\" returns True for both of them. For this reason we cannot assume that a string can be converted to an integer when isdigit() returns True.\n\nWhen we receive strings from external sources (other programs,ﬁles, network connections,and especially interactive users),the strings may have unwanted leading and trailing whitespace. We can strip whitespace from the left using str.lstrip(), from the right using str.rstrip(), or from both ends using str.strip(). We can also give a string as an argument to the strip methods, in which case every occurrence of every character given will be stripped from the appropriate end or ends. For example:\n\nStrings\n\n>>> s = \"\\t no parking \" >>> s.lstrip(), s.rstrip(), s.strip() ('no parking ', '\\t no parking', 'no parking') >>> \"<[unbracketed]>\".strip(\"[](){}<>\") 'unbracketed'\n\nWe can also replace strings within strings using the str.replace() method. This method takes two string arguments, and returns a copy of the string it is called on with every occurrence of the ﬁrst string replaced with the second. If the second argument is an empty string the effect is to delete every occurrence of the ﬁrst string. We will see examplesof str.replace() and some other string methodsin the csv2html.py example in the Examplessection toward the end of the chapter.\n\nOne frequent requirement is to split a string into a list of strings. For exam- ple,we might have a text ﬁle of data with one record per line and each record’s ﬁelds separated by asterisks. This can be done using the str.split() method and passing in the string to split on as its ﬁrst argument, and optionally the maximum number of splits to make as the second argument. If we don’t spec- ify the second argument, as many splits are made as possible. Here is an ex- ample:\n\n>>> record = \"Leo Tolstoy*1828-8-28*1910-11-20\" >>> fields = record.split(\"*\") >>> fields ['Leo Tolstoy', '1828-8-28', '1910-11-20']\n\nNow we can use str.split() again on the date of birth and date of death to calculate how long he lived (give or take a year):\n\n>>> born = fields[1].split(\"-\") >>> born ['1828', '8', '28'] >>> died = fields[2].split(\"-\") >>> print(\"lived about\", int(died[0]) - int(born[0]), \"years\") lived about 82 years\n\nWe had touse int() to convert theyearsfromstringstointegers,but other than that the snippet is straightforward. We could have gotten the years directly from the fields list, for example, year_born = int(fields[1].split(\"-\")[0]).\n\nThe two methods that we did not summarize in Tables 2.8, 2.9, and 2.10 are str.maketrans() and str.translate(). The str.maketrans() method is used to create a translation table which maps charactersto characters. It acceptsone, two, or three arguments, but we will show only the simplest (two argument) callwheretheﬁrstargumentisastring containing characterstotranslatefrom and the second argument is a string containing the characters to translate to.\n\n77\n\ncsv2- html.py example ➤ 97\n\n78\n\nChapter 2. Data Types\n\nBoth arguments must be the same length. The str.translate() method takes a translation table as an argument and returns a copy of its string with the characterstranslated according to the translation table. Here is how we could translate strings that might contain Bengali digits to English digits:\n\ntable = \"\".maketrans(\"\\N{bengali digit zero}\"\n\n\"\\N{bengali digit one}\\N{bengali digit two}\" \"\\N{bengali digit three}\\N{bengali digit four}\" \"\\N{bengali digit five}\\N{bengali digit six}\" \"\\N{bengali digit seven}\\N{bengali digit eight}\" \"\\N{bengali digit nine}\", \"0123456789\")\n\nprint(\"20749\".translate(table)) print(\"\\N{bengali digit two}07\\N{bengali digit four}\" \"\\N{bengali digit nine}\".translate(table))\n\n# prints: 20749\n\n# prints: 20749\n\nNotice that we have taken advantage of Python’s string literal concatenation inside the str.maketrans() call and inside the second print() call to spread strings over multiple lines without having to escape newlines or use explicit concatenation.\n\nWe called str.maketrans() on an empty string because it doesn’t matter what string it is called on; it simply processes its arguments and returns a transla- tion table. The str.maketrans() and str.translate() methods can also be used to delete charactersby passing a string containing the unwanted charactersas the third argument to str.maketrans(). If more sophisticated character trans- lations are required, we could create a custom codec—see the codecs module documentation for more about this.\n\nPython has a few other library modules that provide string-related function- ality. We’ve already brieﬂy mentioned the unicodedata module, and we’ll show it in use in the next subsection. Other modules worth looking up are difflib which can be used to show differences between ﬁles or between strings, the io module’s io.StringIO class which allows us to read from or write to strings as though they were ﬁles, and the textwrap module which provides facilities for wrapping and ﬁlling strings. There is also a string module that has a few use- ful constants such as ascii_letters and ascii_lowercase. We will see examples of some of these modules in use in Chapter 5.In addition,Python provides ex- cellent support for regular expressions in the re module—Chapter 13 is dedi- cated to this topic.\n\nString Formatting with the str.format() Method\n\nThe str.format() method providesa very ﬂexible and powerful way of creating strings. Using str.format() iseasy for simplecases,butfor complex formatting we need to learn the formatting syntax the method requires.\n\n||\n\nStrings\n\nThe str.format() method returns a new string with the replacement ﬁelds in its string replaced with its arguments suitably formatted. For example:\n\n>>> \"The novel '{0}' was published in {1}\".format(\"Hard Times\", 1854) \"The novel 'Hard Times' was published in 1854\"\n\nEach replacement ﬁeld is identiﬁed by a ﬁeld name in braces. If the ﬁeld name is a simple integer, it is taken to be the index position of one of the arguments passed to str.format(). So in this case, the ﬁeld whose name was 0 was replaced by the ﬁrst argument, and the one with name 1 was replaced by the second argument.\n\nIf we need to include braces inside format strings, we can do so by doubling them up. Here is an example:\n\n>>> \"{{{0}}} {1} ;-}}\".format(\"I'm in braces\", \"I'm not\") \"{I'm in braces} I'm not ;-}\"\n\nIf we try to concatenate a string and a number, Python will quite rightly raise a TypeError. But we can easily achieve what we want using str.format():\n\n>>> \"{0}{1}\".format(\"The amount due is $\", 200) 'The amount due is $200'\n\nWe can also concatenate strings using str.format() (although the str.join() method is best for this):\n\n>>> x = \"three\" >>> s =\"{0} {1} {2}\" >>> s = s.format(\"The\", x, \"tops\") >>> s 'The three tops'\n\nHere we have used a couple of string variables, but in most of this section we’ll use string literals for str.format() examples, simply for the sake of convenience—just keep in mind that any example that uses a string literal could use a string variable in exactly the same way.\n\nThe replacement ﬁeld can have any of the following general syntaxes:\n\n{field_name} {field_name!conversion} {field_name:format_specification} {field_name!conversion:format_specification}\n\nOne other point to note is that replacement ﬁelds can contain replacement ﬁelds. Nested replacement ﬁelds cannot have any formatting;their purpose is to allow for computed formatting speciﬁcations. We will see an example of this\n\n79\n\n80\n\nChapter 2. Data Types\n\nwhen we take a detailed look at format speciﬁcations. We will now study each part of the replacement ﬁeld in turn, starting with ﬁeld names.\n\nField Names\n\nA ﬁeld name can be either an integer corresponding to one of the str.format() method’s arguments, or the name of one of the method’s keyword arguments. We discuss keyword arguments in Chapter 4, but they are not difﬁcult, so we will provide a couple of examples here for completeness:\n\n>>> \"{who} turned {age} this year\".format(who=\"She\", age=88) 'She turned 88 this year' >>> \"The {who} was {0} last week\".format(12, who=\"boy\") 'The boy was 12 last week'\n\nThe ﬁrst example uses two keyword arguments, who and age, and the second example uses one positional argument (the only kind we have used up to now) and one keyword argument. Notice that in an argument list, keyword argumentsalwayscomeafter positionalarguments;andof coursewecanmake use of any arguments in any order inside the format string.\n\nField names may refer to collection data types—for example, lists. In such cases we can include an index (not a slice!) to identify a particular item:\n\n>>> stock = [\"paper\", \"envelopes\", \"notepads\", \"pens\", \"paper clips\"] >>> \"We have {0[1]} and {0[2]} in stock\".format(stock) 'We have envelopes and notepads in stock'\n\nThe 0 refers to the positional argument, so {0[1]} is the stock list argument’s second item, and {0[2]} is the stock list argument’s third item.\n\nLater on wewill learn about Pythondictionaries. Thesestorekey–valueitems, and since they can be used with str.format(), we’ll just show a quick example here. Don’t worry if it doesn’t make sense; it will once you’ve read Chapter 3.\n\n>>> d = dict(animal=\"elephant\", weight=12000) >>> \"The {0[animal]} weighs {0[weight]}kg\".format(d) 'The elephant weighs 12000kg'\n\nJust asweaccesslist and tupleitemsusing an integer positionindex,weaccess dictionary items using a key.\n\nWecanalsoaccessnamedattributes. Assuming wehaveimportedthe math and sys modules, we can do this:\n\n>>> \"math.pi=={0.pi} sys.maxunicode=={1.maxunicode}\".format(math, sys) 'math.pi==3.14159265359 sys.maxunicode==65535'\n\n|\n\ndict type ➤ 126\n\nStrings\n\nSo in summary, the ﬁeld name syntax allows us to refer to positional and key- word argumentsthat are passed to the str.format() method. If the arguments are collection data typeslike lists or dictionaries,or have attributes,we can ac- cess the part we want using [] or . notation. This is illustrated in Figure 2.5.\n\npositional argument index\n\n{0}\n\n{1[5]}\n\n{2[capital]}\n\n{3.rate}\n\nindex\n\nkey\n\nattribute\n\n{title}\n\n{color[12]}\n\n{point[y]}\n\n{book.isbn}\n\nkeyword argument name\n\nFigure 2.5 Annotated format speciﬁer ﬁeld name examples\n\nFrom effect put them in for us, using numbers starting from 0. For example:\n\nPython 3.1it is possible to omit ﬁeld names,in which case Python will in\n\n>>> \"{} {} {}\".format(\"Python\", \"can\", \"count\") 'Python can count'\n\nIf we are using Python 3.0, the format string used here would have to be \"{0} {1} {2}\". Using this technique is convenient for formatting one or two items, but the approach we will look at next is more convenient when several items are involved, and works just as well with Python 3.0.\n\nBefore ﬁnishing our discussion of string format ﬁeld names, it is worth men- tioning a rather different way to get values into a format string. This involves using an advanced technique,but one useful to learn as soon as possible, since it is so convenient.\n\nThe local variables that are currently in scope are available from the built-in locals() function. This function returns a dictionary whose keys are local variable names and whose values are references to the variables’ values. Now we can use mapping unpacking to feed this dictionary into the str.format() method. The mapping unpacking operator is ** and it can be applied to a mapping (such as a dictionary)to produce a key–value list suitable for passing to a function. For example:\n\n>>> element = \"Silver\" >>> number = 47 >>> \"Element {number} is {element}\".format(**locals()) 'Element 47 is Silver'\n\n81\n\n3.1\n\nMap- ping unpack- ing ➤ 179",
      "page_number": 76
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 87-95)",
      "start_page": 87,
      "end_page": 95,
      "detection_method": "topic_boundary",
      "content": "Decimal num- bers 63➤\n\n82\n\nChapter 2. Data Types\n\nThe syntax may seem weird enough to make a Perl programmer feel at home, but don’t worry—it is explained in Chapter 4. All that matters for now is that we can use variable names in format strings and leave Python to ﬁll in their values simply by unpacking the dictionary returned by locals()—or some other dictionary—intothe str.format() method. For example,wecould rewrite the “elephant” example we saw earlier to have a much nicer format string with simpler ﬁeld names.\n\n>>> \"The {animal} weighs {weight}kg\".format(**d) 'The elephant weighs 12000kg'\n\nUnpacking a dictionary into the str.format() method allows us to use the dictionary’s keys as ﬁeld names. This makes string formats much easier to understand, and also easier to maintain, since they are not dependent on the order of the arguments. Note, however, that if we want to pass more than one argument to str.format(), only the last one can use mapping unpacking.\n\nConversions\n\n|\n\nWhen we discussed decimal.Decimal numbers we noticed that such are output in one of two ways. For example:\n\nnumbers\n\n>>> decimal.Decimal(\"3.4084\") Decimal('3.4084') >>> print(decimal.Decimal(\"3.4084\")) 3.4084\n\nThe ﬁrst way that the decimal.Decimal is shown is in its representational form. The purpose of this form is to provide a string which if interpreted by Python would re-create the object it represents. Python programs can evaluate snip- pets of Python code or entire programs, so this facility can be useful in some situations. Not all objects can provide a reproducing representation, in which case they provide a string enclosed in angle brackets. For example, the repre- sentational form of the sys module is the string \"<module 'sys' (built-in)>\".\n\nThe second way that decimal.Decimal isshown isin itsstring form. Thisform is aimed at human readers,sotheconcern istoshowsomething that makessense to people. If a data type doesn’t have a string form and a string is required, Python will use the representational form.\n\nPython’s built-in data types know about str.format(), and when passed as an argument to this method they return a suitable string to display themselves. It is also straightforward to add str.format() support to custom data types as we will see in Chapter 6. In addition, it is possible to override the data type’s normal behavior and force it to provide either its string or its representational form. Thisisdoneby adding a conversionspeciﬁertotheﬁeld. Currentlythere are three such speciﬁers:sto forcestring form,r to force representationalform,\n\nParame- ter unpack- ing ➤ 177\n\neval() ➤ 344\n\nStrings\n\nand a to force representational form but only using ASCII characters. Here is an example:\n\n>>> \"{0} {0!s} {0!r} {0!a}\".format(decimal.Decimal(\"93.4\")) \"93.4 93.4 Decimal('93.4') Decimal('93.4')\"\n\nIn this case, decimal.Decimal’s string form produces the same string as the string it provides for str.format() which is what commonly happens. Also, in this particular example, there is no difference between the representational and ASCII representational forms since both use only ASCII characters.\n\nHere is another example, this time concerning a string that contains the ti- tle of a movie, \" \", held in the variable movie. If we print the string using \"{0}\".format(movie) the string will be output unchanged, but if we want to avoid non-ASCII characters we can use either ascii(movie) or \"{0!a}\".format(movie), both of which will produce the string '\\u7ffb\\u8a33 \\u3067\\u5931\\u308f\\u308c\\u308b'.\n\nSo far we have seen how to put the valuesof variablesinto a format string,and how to force string or representational forms to be used. Now we are ready to consider the formatting of the values themselves.\n\nFormat Speciﬁcations\n\nThe default formatting of integers,ﬂoating-point numbers,and stringsisoften perfectly satisfactory. But if we want to exercise ﬁne control, we can easily do sousing formatspeciﬁcations. Wewilldealseparately withformatting strings, integers, and ﬂoating-point numbers, to make learning the details easier. The the general syntax that covers all of them is shown in Figure 2.6.\n\nFor strings,the things that we can control are the ﬁll character,the alignment within the ﬁeld, and the minimum and maximum ﬁeld widths.\n\nA string format speciﬁcation is introduced with a colon (:) and this is followed by an optional pair of characters—a ﬁll character (which may not be }) and an alignment character (< for left align, ^ for center, > for right align).Then comes an optional minimum width integer, and if we want to specify a maximum width, this comes last as a period followed by an integer.\n\nNote that if we specify a ﬁll character we must also specify an alignment. We omit the sign and type parts of the format speciﬁcation because they have no effect on strings. It is harmless (but pointless) to have a colon without any of the optional elements.\n\nLet’s see some examples:\n\n>>> s = \"The sword of truth\" >>> \"{0}\".format(s) 'The sword of truth'\n\n# default formatting\n\n83\n\n|\n\n84\n\nChapter 2. Data Types\n\n:\n\nﬁll\n\nAny char- acter except }\n\nalign\n\n< left > right ^ center = pad between sign and digits for numbers\n\nsign + force sign; - sign if needed; “ ” space or - as appro- priate\n\n#\n\np r e ﬁ x\n\ni n t s w\n\ni t h 0 b , 0 o , o r\n\n0 width\n\n0 - p a d n u m b e r s\n\nMini- mum ﬁeld width\n\n, . precision type\n\nu s e c o m m a s f o r g r o u p n g ★\n\ni\n\nMaximum ﬁeld width for strings; number of decimal places for ﬂoating- point numbers\n\nints b,c,d, n,o,x, X; floats e,E,f, g,G,n, %\n\n0 x\n\nFigure 2.6 The general form of a format speciﬁcation\n\n>>> \"{0:25}\".format(s) 'The sword of truth >>> \"{0:>25}\".format(s) # right align, minimum width 25 ' >>> \"{0:^25}\".format(s) # center align, minimum width 25 ' >>> \"{0:-^25}\".format(s) # - fill, center align, minimum width 25 '---The sword of truth----' >>> \"{0:.<25}\".format(s) # . fill, left align, minimum width 25 'The sword of truth.......' >>> \"{0:.10}\".format(s) # maximum width 10 'The sword '\n\n# minimum width 25\n\n'\n\nThe sword of truth'\n\nThe sword of truth\n\n'\n\nIn the penultimate example we had to specify the left alignment (even though this is the default). If we left out the <, we would have :.25, and this simply means a maximum ﬁeld width of 25 characters.\n\nAs we noted earlier,it is possible to have replacement ﬁeldsinside format spec- iﬁcations. Thismakesit possibletohavecomputedformats. Here,for example, are two ways of setting a string’s maximum width using a maxwidth variable:\n\n>>> maxwidth = 12 >>> \"{0}\".format(s[:maxwidth]) 'The sword of' >>> \"{0:.{1}}\".format(s, maxwidth) 'The sword of'\n\nThe ﬁrst approach uses standard string slicing; the second uses an inner replacement ﬁeld.\n\n★The grouping comma was introduced with Python 3.1.\n\nStrings\n\nFor integers, the format speciﬁcation allows us to control the ﬁll character,the alignment within the ﬁeld, the sign, whether to use a nonlocale-aware comma separator to group digits (from Python 3.1), the minimum ﬁeld width, and the number base.\n\nAn integer format speciﬁcation begins with a colon, after which we can have an optional pair of characters—a ﬁll character (which may not be }) and an alignment character (< for left align, ^ for center, > for right align, and = for the ﬁlling to be done between the sign and the number). Next is an optional sign character: + forces the output of the sign, - outputs the sign only for negative numbers, and a space outputs a space for positive numbers and a - sign for negative numbers. Then comes an optional minimum width integer—this can be preceded by a # character to get the base preﬁx output (for binary,octal,and hexadecimal numbers), and by a 0 to get 0-padding. Then, from Python 3.1, comes an optional comma—if present this will cause the number’s digits to be grouped into threes with a comma separating each group. If we want the out- put in a base other than decimal we must add a type character—b for binary, o for octal, x for lowercase hexadecimal, and X for uppercase hexadecimal, al- though for completeness, d for decimal integer is also allowed. There are two other type characters: c, which means that the Unicode character correspond- ing to the integer should be output, and n, which outputs numbers in a locale- sensitive way. (Note that if n is used, using , doesn’t make sense.)\n\nWe can get 0-padding in two different ways:\n\n>>> \"{0:0=12}\".format(8749203) # 0 fill, minimum width 12 '000008749203' >>> \"{0:0=12}\".format(-8749203) # 0 fill, minimum width 12 '-00008749203' >>> \"{0:012}\".format(8749203) '000008749203' >>> \"{0:012}\".format(-8749203) # 0-pad and minimum width 12 '-00008749203'\n\n# 0-pad and minimum width 12\n\nThe ﬁrst two examples have a ﬁll character of 0 and ﬁll between the sign and the number itself (=). The second two examples have a minimum width of 12 and 0-padding.\n\nHere are some alignment examples:\n\n>>> \"{0:*<15}\".format(18340427) # * fill, left align, min width 15 '18340427*******' >>> \"{0:*>15}\".format(18340427) # * fill, right align, min width 15 '*******18340427' >>> \"{0:*^15}\".format(18340427) # * fill, center align, min width 15 '***18340427****' >>> \"{0:*^15}\".format(-18340427) # * fill, center align, min width 15 '***-18340427***'\n\n85\n\n3.x\n\n86\n\nChapter 2. Data Types\n\nHere are some examples that show the effects of the sign characters:\n\n>>> \"[{0: }] [{1: }]\".format(539802, -539802) # space or - sign '[ 539802] [-539802]' >>> \"[{0:+}] [{1:+}]\".format(539802, -539802) # force sign '[+539802] [-539802]' >>> \"[{0:-}] [{1:-}]\".format(539802, -539802) # - sign if needed '[539802] [-539802]'\n\nAnd here are two examples that use some of the type characters:\n\n>>> \"{0:b} {0:o} {0:x} {0:X}\".format(14613198) '110111101111101011001110 67575316 deface DEFACE' >>> \"{0:#b} {0:#o} {0:#x} {0:#X}\".format(14613198) '0b110111101111101011001110 0o67575316 0xdeface 0XDEFACE'\n\nIt isnot possible to specify a maximum ﬁeld width for integers. Thisisbecause doing so might require digits to be chopped off, thereby rendering the integer meaningless.\n\nIf we are using Python 3.1 and use a comma in the format speciﬁcation, the integer will use commas for grouping. For example:\n\n>>> \"{0:,} {0:*>13,}\".format(int(2.39432185e6)) '2,394,321 ****2,394,321'\n\nBoth ﬁelds have grouping applied, and in addition, the second ﬁeld is padded with *s, right aligned, and given a minimum width of 13 characters. This is very convenient for many scientiﬁcand ﬁnancialprograms,but it doesnot take into account the current locale. For example, many Continental Europeans would expect the thousands separator to be . and the decimal separator to be ,.\n\nThe last format character available for integers(and which isalso available for ﬂoating-point numbers) is n. This has the same effect as d when given an inte- ger andthesameeffectasg whengivena ﬂoating-point number. What makesn special is that it respectsthe current locale,and will use the locale-speciﬁc dec- imal separator and grouping separator in the output it produces. The default locale is called the C locale, and for this the decimal and grouping characters are a period and an empty string. We can respect the user’s locale by starting our programs with the following two lines as the ﬁrst executable statements:★\n\nimport locale locale.setlocale(locale.LC_ALL, \"\")\n\n★In multithreadedprogramsit isbest to call locale.setlocale()only once,at programstart-up,and before any additional threads have been started, since the function is not usually thread-safe.\n\n3.1\n\nStrings\n\nPassing an empty string as the locale tells Python to try to automatically determine the user’s locale (e.g.,by examining the LANG environment variable), with a fallback of the C locale. Here are some examples that show the effects of different locales on an integer and a ﬂoating-point number:\n\nx, y = (1234567890, 1234.56) locale.setlocale(locale.LC_ALL, \"C\") c = \"{0:n} {1:n}\".format(x, y) locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\") en = \"{0:n} {1:n}\".format(x, y) locale.setlocale(locale.LC_ALL, \"de_DE.UTF-8\") de = \"{0:n} {1:n}\".format(x, y)\n\n# c == \"1234567890 1234.56\"\n\n# en == \"1,234,567,890 1,234.56\"\n\n# de == \"1.234.567.890 1.234,56\"\n\nAlthough n is very useful for integers, it is of more limited use with ﬂoating- point numbers because as soon as they become large they are output using ex- ponential form.\n\nFor ﬂoating-point numbers, the format speciﬁcation gives us control over the ﬁll character, the alignment within the ﬁeld, the sign, whether to use a non- locale aware comma separator to group digits (from Python 3.1), the mini- mum ﬁeld width, the number of digits after the decimal place, and whether to present the number in standard or exponential form, or as a percentage.\n\nThe format speciﬁcation for ﬂoating-point numbers is the same as for integers, exceptfor twodifferencesat theend. After theoptionalminimumwidth—from Python 3.1, after the optional grouping comma—we can specify the number of digitsafterthedecimalplaceby writing a periodfollowedby aninteger. Wecan also add a type character at the end: e for exponential form with a lowercase e, E for exponential form with an uppercase E, f for standard ﬂoating-point form, g for “general” form—this is the same as f unless the number is very large, in which case it is the same as e—and G, which is almost the same as g, but uses either f or E.Also availableis %—thisresultsin the number being multipliedby 100 with the resultant number output in f format with a % symbol appended.\n\nHere are a few examples that show exponential and standard forms:\n\n>>> amount = (10 ** 3) * math.pi >>> \"[{0:12.2e}] [{0:12.2f}]\".format(amount) '[ >>> \"[{0:*>12.2e}] [{0:*>12.2f}]\".format(amount) '[****3.14e+03] [*****3141.59]' >>> \"[{0:*>+12.2e}] [{0:*>+12.2f}]\".format(amount) '[***+3.14e+03] [****+3141.59]'\n\n3.14e+03] [\n\n3141.59]'\n\nThe ﬁrst example has a minimum width of 12 charactersand has 2 digits after the decimal point. The second example builds on the ﬁrst, and adds a * ﬁll character. If we use a ﬁll character we must also have an alignment character, so we have speciﬁed align right (even though that is the default for numbers).\n\n87\n\n3.x\n\n88\n\nChapter 2. Data Types\n\nThe third example builds on the previous two, and adds the + sign character to force the output of the sign.\n\nIn Python 3.0, decimal.Decimal numbers are treated by str.format() as strings rather than asnumbers. Thismakesit quite tricky to get nicely formattedout- put. From Python 3.1, decimal.Decimal numbers can be formatted as floats,in- cluding support for , to get comma-separated groups. Here is an example—we have omitted the ﬁeld name since we don’t need it for Python 3.1:\n\n>>> \"{:,.6f}\".format(decimal.Decimal(\"1234567890.1234567890\")) '1,234,567,890.123457'\n\nIf we omitted the f format character (or used the g format character), the number would be formatted as '1.23457E+9'.\n\nPython 3.0 does not provide any direct support for formatting complex numbers—support was added with Python 3.1. However, we can easily solve this by formatting the real and imaginary parts as individual ﬂoating-point numbers. For example:\n\n>>> \"{0.real:.3f}{0.imag:+.3f}j\".format(4.75917+1.2042j) '4.759+1.204j' >>> \"{0.real:.3f}{0.imag:+.3f}j\".format(4.75917-1.2042j) '4.759-1.204j'\n\nWe accesseach attributeof the complex number individually,and format them both as ﬂoating-point numbers, in this case with three digits after the decimal place. We have also forced the sign to be output for the imaginary part; we must add on the j ourselves.\n\nPython 3.1supportsformatting complex numbersusing the same syntax asfor floats:\n\n>>> \"{:,.4f}\".format(3.59284e6-8.984327843e6j) '3,592,840.0000-8,984,327.8430j'\n\nOne slight drawback of this approach is that exactly the same formatting is applied to both the real and the imaginary parts; but we can always use the Python 3.0 technique of accessing the complex number’sattributesindividual- ly if we want to format each one differently.\n\nExample: print_unicode.py\n\nIntheprecedingsubsubsectionswecloselyexaminedthestr.format()method’s format speciﬁcations, and we have seen many code snippets that show partic- ular aspects. In this subsubsection we will review a small yet useful example that makes use of str.format() so that we can see format speciﬁcations in a\n\n|\n\n3.1\n\n3.1\n\nStrings\n\nrealistic context. The example also uses some of the string methods we saw in the previous section, and introduces a function from the unicodedata module.★\n\nThe program has just 25 lines of executable code. It imports two modules, sys and unicodedata, and deﬁnes one custom function, print_unicode_table(). We’ll begin by looking at a sample run to see what it does, then we will look at the code at the end of the program where processing really starts, and ﬁnally we will look at the custom function.\n\nprint_unicode.py spoked hex decimal ------- ----- --- ---------------------------------------- 2722 ✢ Four Teardrop-Spoked Asterisk 2723 ✣ Four Balloon-Spoked Asterisk 2724 ✤ Heavy Four Balloon-Spoked Asterisk 2725 ✥ Four Club-Spoked Asterisk 2733 ✳ Eight Spoked Asterisk 273B Teardrop-Spoked Asterisk 273C ✼ Open Centre Teardrop-Spoked Asterisk Heavy Teardrop-Spoked Asterisk 273D 2743 ❃ Heavy Teardrop-Spoked Pinwheel Asterisk 2749 ❈ Balloon-Spoked Asterisk 274A ❊ Eight Teardrop-Spoked Propeller Asterisk 274B ❋ Heavy Eight Teardrop-Spoked Propeller Asterisk\n\nchr\n\nname\n\n10018 10019 10020 10021 10035 10043 10044 10045 10051 10057 10058 10059\n\n✽\n\n✽\n\nIf run with no arguments, the program produces a table of every Unicode character,starting from the spacecharacter and going up to the character with the highest available code point. If an argument is given, as in the example, only those rows in the table where the lowercased Unicode character name contains the argument are printed.\n\nword = None if len(sys.argv) > 1:\n\nif sys.argv[1] in (\"-h\", \"--help\"):\n\nprint(\"usage: {0} [string]\".format(sys.argv[0])) word = 0\n\nelse:\n\nword = sys.argv[1].lower()\n\nif word != 0:\n\nprint_unicode_table(word)\n\n★ This program assumes that the console uses the Unicode UTF-8 encoding. Unfortunate- ly, the Windows console has poor UTF-8 support. As a workaround, the examples include print_unicode_uni.py, a version of the program that writes its output to a ﬁle which can then be opened using a UTF-8-savvy editor, such as IDLE.\n\n89\n\nChapter 7 (File Han- dling) ➤ 287\n\n90\n\nChapter 2. Data Types\n\nAfter the imports and the creation of the print_unicode_table() function, exe- cution reaches the code shown here. We begin by assuming that the user has not given a word to match on the command line. If a command-line argument is given and is -h or --help, we print the program’s usage information and set word to 0 as a ﬂag to indicate that we are ﬁnished. Otherwise, we set the word to a lowercase copy of the argument the user typed in. If the word is not 0,then we print the table.\n\nWhen we print the usage information we use a format speciﬁcation that just has the format name—in this case, the position number of the argument. We could have written the line like this instead:\n\nprint(\"usage: {0[0]} [string]\".format(sys.argv))\n\nUsing this approach the ﬁrst 0 is the index position of the argument we want to use,and [0] is the index withinthe argument,and it worksbecause sys.argv is a list.\n\ndef print_unicode_table(word):\n\nprint(\"decimal print(\"------- ----- --- {0:-<40}\".format(\"\"))\n\nhex\n\nchr {0:^40}\".format(\"name\"))\n\ncode = ord(\" \") end = sys.maxunicode\n\nwhile code < end: c = chr(code) name = unicodedata.name(c, \"*** unknown ***\") if word is None or word in name.lower():\n\nprint(\"{0:7} {0:5X} {0:^3c} {1}\".format(\n\ncode, name.title()))\n\ncode += 1\n\nWe’ve used a couple of blank lines for the sake of clarity. The ﬁrst two lines of the function’s suite print the title lines. The ﬁrst str.format() prints the text “name” centered in a ﬁeld 40 characters wide, whereas the second one prints an empty string in a ﬁeld 40 characters wide, using a ﬁll character of “-”, and aligned left. (We must give an alignment if we specify a ﬁll character.) An alternative approach for the second line is this:\n\nprint(\"------- ----- --- {0}\".format(\"-\" * 40))\n\nHerewehaveused thestring replicationoperator (*)to createa suitablestring, and simply inserted it into the format string. A third alternative would be to simply type in 40 “-”s and use a literal string.\n\nWe keep track of Unicode code points in the code variable, initializing it to the code point for a space (0x20). We set the end variable to be the highest",
      "page_number": 87
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 96-103)",
      "start_page": 96,
      "end_page": 103,
      "detection_method": "topic_boundary",
      "content": "Strings\n\nUnicode code point available—this will vary depending on whether Python was compiled to use the UCS-2 or the UCS-4 character encoding.\n\nInside the while loop we get the Unicode character that correspondsto the code point using the chr() function. The unicodedata.name() function returns the Unicode character name for the given Unicode character; its optional second argument is the name to use if no character name is deﬁned.\n\nIf the user didn’t specify a word (word is None), or if they did and it is in a low- ercased copy of the Unicode character name, then we print the correspond- ing row.\n\nAlthough we pass the code variable to the str.format() method only once, it is used three times in the format string, ﬁrst to print the code as an integer in a ﬁeld 7 characters wide (the ﬁll character defaults to space, so we did not need to specify it), second to print the code as an uppercase hexadecimal number in a ﬁeld 5 characters wide, and third to print the Unicode character that corresponds to the code—using the “c” format speciﬁer, and centered in a ﬁeld with a minimum width of three characters. Notice that we did not have to specify the type “d” in the ﬁrst format speciﬁcation; this is because it is the defaultfor integerarguments. Thesecondargumentisthecharacter’sUnicode character name, printed using “title” case, that is, with the ﬁrst letter of each word uppercased, and all other letters lowercased.\n\nNow that we are familiar with the versatile str.format() method,we will make great use of it throughout the rest of the book.\n\nCharacter Encodings\n\nUltimately, computers can store only bytes, that is, 8-bit values which, if un- signed,range from 0x00 to 0xFF.Every character must somehow be represented intermsof bytes. Intheearly daysof computingthepioneersdevisedencoding schemesthatassigneda particularcharactertoa particularbyte. Forexample, using the ASCII encoding,A is represented by 0x41,Bby 0x42,and so on. In the U.S. and Western Europe the Latin-1 encoding was often used; its characters in the range 0x20–0x7E are the same as the corresponding characters in 7-bit ASCII,with those in the range 0xA0–0xFF used for accented charactersand oth- er symbols needed by those using non-English Latin alphabets. Many other encodings have been devised over the years, and now there are lots of them in use—however, development has ceased for many of them, in favor of Unicode.\n\nHaving all these different encodings has proved very inconvenient, especially when writing internationalized software. One solution that has been almost universally adopted is the Unicode encoding. Unicode assigns every charac- ter to an integer—called a code point in Unicode-speak—just like the earlier encodings. But Unicode is not limited to using one byte per character, and is thereforeabletorepresentevery characterin every languagein a singleencod-\n\n91\n\n||\n\n92\n\nChapter 2. Data Types\n\ning, so unlike other encodings, Unicode can handle characters from a mixture of languages, rather than just one.\n\nBut how is Unicode stored? Currently, slightly more than 100000 Unicode characters are deﬁned, so even using signed numbers, a 32-bit integer is more than adequate to store any Unicode code point. So the simplest way to store Unicode characters is as a sequence of 32-bit integers, one integer per charac- ter. This sounds very convenient since it should produce a one to one mapping of characters to 32-bit integers, which would make indexing to a particular character very fast. However, in practice things aren’t so simple, since some Unicode characters can be represented by one or by two code points—for ex- ample,é can be represented by the single code point 0xE9 or by two code points, 0x65 and 0x301 (e and a combining acute accent).\n\nNowadays, Unicode is usually stored both on disk and in memory using UTF- 8, UTF-16, or UTF-32. The ﬁrst of these, UTF-8, is backward compatible with 7-bit ASCII since its ﬁrst 128 code points are represented by single-byte val- ues that are the same as the 7-bit ASCII character values. To represent all the other Unicode characters, UTF-8 uses two, three, or more bytes per character. This makes UTF-8 very compact for representing text that is all or mostly En- glish. TheGtk library (usedby theGNOMEwindowing system,among others) uses UTF-8, and it seems that UTF-8 is becoming the de facto standard format for storing Unicode text in ﬁles—for example, UTF-8 is the default format for XML, and many web pages these days use UTF-8.\n\nA lot of other software, such as Java, uses UCS-2 (which in modern form is the same as UTF-16).This representation uses two or four bytes per character, with the most common characters represented by two bytes. The UTF-32 rep- resentation (also called UCS-4) uses four bytes per character. Using UTF-16 or UTF-32for storing Unicode in ﬁlesor for sending over a network connection has a potential pitfall:If the data is sent as integers then the endianness mat- ters. One solution to this is to precede the data with a byte order mark so that readers can adapt accordingly. This problem doesn’t arise with UTF-8, which is another reason why it is so popular.\n\nPython represents Unicode using either UCS-2 (UTF-16) format, or UCS-4 (UTF-32) format. In fact,when using UCS-2, Python uses a slightly simpliﬁed versionthatalwaysusestwobytesper characterandsocanonly representcode points up to 0xFFFF. When using UCS-4, Python can represent all the Unicode code points. The maximum code point is stored in the read-only sys.maxunicode attribute—if its value is 65535, then Python was compiled to use UCS-2; if larger, then Python is using UCS-4.\n\nThe str.encode() method returns a sequence of bytes—actually a bytes object, covered in Chapter 7—encoded according to the encoding argument we supply. Using this method we can get some insight into the difference between encod- ings, and why making incorrect encoding assumptions can lead to errors:\n\nStrings\n\n>>> artist = \"Tage Åsén\" >>> artist.encode(\"Latin1\") b'Tage \\xc5s\\xe9n' >>> artist.encode(\"CP850\") b'Tage \\x8fs\\x82n' >>> artist.encode(\"utf8\") b'Tage \\xc3\\x85s\\xc3\\xa9n' >>> artist.encode(\"utf16\") b'\\xff\\xfeT\\x00a\\x00g\\x00e\\x00 \\x00\\xc5\\x00s\\x00\\xe9\\x00n\\x00'\n\nA b before an opening quote signiﬁes a bytes literal rather than a string literal. As a convenience,when creating bytes literals we can use a mixture of printable ASCII characters and hexadecimal escapes.\n\nWe cannot encode Tage Åsén’s name using the ASCII encoding because it does not have the Å character or any accented characters, so attempting to do so will result in a UnicodeEncodeError exception being raised. The Latin-1 encod- ing (also known as ISO-8859-1) is an 8-bit encoding that has all the necessary characters for this name. On the other hand, artist Erno″ Bánk would be less fortunate since the o″ character is not a Latin-1 character and so could not be successfully encoded. Both names can be successfully encoded using Uni- code encodings, of course. Notice, though, that for UTF-16, the ﬁrst two bytes are the byte order mark—these are used by the decoding function to detect whether the data is big- or little-endian so that it can adapt accordingly.\n\nIt is worth noting a couple more points about the str.encode() method. The ﬁrst argument (the encoding name) is case-insensitive, and hyphens and un- derscores in the name are treated as equivalent, so “us-ascii” and “US_ASCII” are considered the same. There are also many aliases—for example, “latin”, “latin1”, “latin_1”, “ISO-8859-1”, “CP819”, and some others are all “Latin-1”. Themethodcanalsoacceptan optionalsecondargumentwhich isusedtotellit how to handle errors. For example, we can encode any string into ASCII if we pass a second argument of “ignore” or “replace”—at the price of losing data,of course—or losslessly if we use “backslashreplace” which replaces non-ASCII characters with \\x, \\u, and \\U escapes. For example, artist.encode(\"ascii\", \"ignore\") will produce b'Tage sn' and artist.encode(\"ascii\", \"replace\") will produce b'Tage ?s?n', whereas artist.encode(\"ascii\", \"backslashreplace\") will produce b'Tage \\xc5s\\xe9n'. (We can also get an ASCII string using \"{0!a}\".format(artist), which produces 'Tage \\xc5s\\xe9n'.)\n\nThe complement of str.encode() is bytes.decode() (and bytearray.decode()) which returns a string with the bytes decoded using the given encoding. For example:\n\n>>> print(b\"Tage \\xc3\\x85s\\xc3\\xa9n\".decode(\"utf8\"))\n\nTage Åsén\n\n93\n\n94\n\nChapter 2. Data Types\n\n>>> print(b\"Tage \\xc5s\\xe9n\".decode(\"latin1\"))\n\nTage Åsén\n\nThe differences between the 8-bit Latin-1, CP850 (an IBM PC encoding), and UTF-8 encodings make it clear that guessing encodings is not likely to be a successful strategy. Fortunately, UTF-8 is becoming the de facto standard for plain text ﬁles, so later generations may not even know that other encodings ever existed.\n\nPython .py ﬁles use UTF-8, so Python always knows the encoding to use with string literals. This means that we can type any Unicode characters into our strings—providing our editor supports this.★\n\nWhen Python readsdata from external sourcessuch as sockets,it cannot know what encoding is used,so it returnsbytes which we can then decode according- ly. For textﬁlesPythontakesa softerapproach,using thelocalencoding unless we specify an encoding explicitly.\n\nFortunately, some ﬁle formats specify their encoding. For example, we can as- sumethat an XML ﬁle usesUTF-8,unlessthe <?xml?> directiveexplicitly speci- ﬁes a different encoding. So when reading XML we might extract,say,the ﬁrst 1000 bytes, look for an encoding speciﬁcation, and if found, decode the ﬁle us- ing thespeciﬁedencoding,otherwisefalling backtodecodingusing UTF-8.This approach should work for any XML or plain text ﬁle that uses any of the sin- gle byte encodings supported by Python, except for EBCDIC-based encodings (CP424,CP500)and a fewothers(CP037,CP864,CP865,CP1026,CP1140,HZ, SHIFT-JIS-2004, SHIFT-JISX0213). Unfortunately, this approach won’t work for multibyte encodings (such as UTF-16 and UTF-32). At least two Python packages for automatically detecting a ﬁle’s encoding are available from the Python Package Index, pypi.python.org/pypi.\n\nExamples\n\n|||\n\nIn this section we will draw on what we have covered in this chapter and the one before, to present two small but complete programs to help consolidate what we have learned so far. The ﬁrst program is a bit mathematical,but it is quite short at around 35 lines. The second is concerned with text processing and is more substantial, with seven functions in around 80 lines of code.\n\nquadratic.py\n\n||\n\nQuadratic equations are equations of the form 2ax + bx + c = 0 where a ≠ 0 describe parabolas. The roots of such equations are derived from the formula\n\n★It is possible to use other encodings. See the Python Tutorial’s “Source Code Encoding” topic.\n\nExamples\n\nx = −b±√ 2 2 b −4ac b − 4ac part of the formula is called the discriminant—if it 2a is positive there are two real roots,if it is zero there is one real root, and if it is negative there are two complex roots. We will writea programthat acceptsthe a, b, and c factors from the user (with the b and c factors allowed to be 0), and then calculates and outputs the root or roots.★\n\n. The\n\nFirst we will look at a sample run, and then we will review the code.\n\nquadratic.py ax² + bx + c = 0 enter a: 2.5 enter b: 0 enter c: -7.25 2.5x² + 0.0x + -7.25 = 0 → x = 1.70293863659 or x = -1.70293863659\n\nWith factors 1.5, -3, and 6, the output (with some digits trimmed) is:\n\n1.5x² + -3.0x + 6.0 = 0 → x = (1+1.7320508j) or x = (1-1.7320508j)\n\nThe output isn’t quite as tidy as we’d like—for example, rather than + -3.0x it would be nicer to have - 3.0x, and we would prefer not to have any 0 factors shown at all. You will get the chance to ﬁx these problems in the exercises.\n\nNow we will turn to the code, which begins with three imports:\n\nimport cmath import math import sys\n\nWe need both the float and the complex math libraries since the square root functions for real and complex numbers are different, and we need sys for sys.float_info.epsilon which we need to compare ﬂoating-point numbers with 0.\n\nWe also need a function that can get a ﬂoating-point number from the user:\n\ndef get_float(msg, allow_zero):\n\nx = None while x is None:\n\ntry:\n\nx = float(input(msg)) if not allow_zero and abs(x) < sys.float_info.epsilon:\n\nprint(\"zero is not allowed\") x = None\n\n★Since the Windows console has poor UTF-8 support, there are problems with a couple of the characters(² and →) that quadratic.pyuses. We have provided quadratic_uni.pywhich displaysthe correct symbols on Linux and Mac OS X, and alternatives (^2 and ->) on Windows.\n\n95\n\n96\n\nChapter 2. Data Types\n\nexcept ValueError as err:\n\nprint(err)\n\nreturn x\n\nThisfunctionwillloopuntiltheuser entersa validﬂoating-pointnumber (such as 0.5, -9, 21, 4.92), and will accept 0 only if allow_zero is True.\n\nOnce the get_float() function is deﬁned,the rest of the code is executed. We’ll look at it in three parts, starting with the user interaction:\n\nprint(\"ax\\N{SUPERSCRIPT TWO} + bx + c = 0\") a = get_float(\"enter a: \", False) b = get_float(\"enter b: \", True) c = get_float(\"enter c: \", True)\n\nThanksto the get_float() function,getting the a,b,and c factorsissimple. The Boolean second argument says whether 0 is acceptable.\n\nx1 = None x2 = None discriminant = (b ** 2) - (4 * a * c) if discriminant == 0:\n\nx1 = -(b / (2 * a))\n\nelse:\n\nif discriminant > 0:\n\nroot = math.sqrt(discriminant)\n\nelse: # discriminant < 0\n\nroot = cmath.sqrt(discriminant)\n\nx1 = (-b + root) / (2 * a) x2 = (-b - root) / (2 * a)\n\nThe code looks a bit different to the formula because we begin by calculating the discriminant. If the discriminant is 0, we know that we have one real solution and so we calculate it directly. Otherwise,we take the real or complex square root of the discriminant and calculate the two roots.\n\nequation = (\"{0}x\\N{SUPERSCRIPT TWO} + {1}x + {2} = 0\"\n\n\" \\N{RIGHTWARDS ARROW} x = {3}\").format(a, b, c, x1)\n\nif x2 is not None:\n\nequation += \" or x = {0}\".format(x2)\n\nprint(equation)\n\nWehaven’tdoneany fancy formatting sincePython’sdefaultsfor ﬂoating-point numbers are ﬁne for this example, but we have used Unicode character names for a couple of special characters.\n\nUs- ing str. format() with map- ping un- packing 81➤\n\nExamples\n\nA more robust alternative to using positional argumentswith their index posi- tions as ﬁeld names, is to use the dictionary returned by locals(), a technique we saw earlier in the chapter.\n\nequation = (\"{a}x\\N{SUPERSCRIPT TWO} + {b}x + {c} = 0\"\n\n\" \\N{RIGHTWARDS ARROW} x = {x1}\").format(**locals())\n\nAnd if weareusing Python3.1,wecouldomit theﬁeldnamesandleavePython to populate the ﬁelds using the positional arguments passed to str.format().\n\nequation = (\"{}x\\N{SUPERSCRIPT TWO} + {}x + {} = 0\"\n\n\" \\N{RIGHTWARDS ARROW} x = {}\").format(a, b, c, x1)\n\nThis is convenient, but not as robust as using named parameters, nor as versatile if we needed to use format speciﬁcations. Nonetheless, for many simple cases this syntax is both easy and useful.\n\ncsv2html.py\n\nOne common requirement is to take a data set and present it using HTML. In this subsection we will develop a program that reads a ﬁle that uses a simple CSV (Comma Separated Value)format and outputsan HTML tablecontaining the ﬁle’s data. Python comes with a powerful and sophisticated module for handling CSV and similar formats—the csv module—but here we will write all the code by hand.\n\nThe CSV format we will support has one record per line, with each record divided into ﬁelds by commas. Each ﬁeld can be either a string or a number. Strings must be enclosed in single or double quotes and numbers should be unquoted unless they contain commas. Commas are allowed inside strings, and must not be treated as ﬁeld separators. We assume that the ﬁrst record contains ﬁeld labels. The output we will produce is an HTML table with text left-aligned (the default in HTML) and numbers right-aligned, with one row per record and one cell per ﬁeld.\n\nThe programmust output theHTMLtable’sopening tag,then read each lineof data and for each one output an HTML row, and at the end output the HTML table’s closing tag. We want the background color of the ﬁrst row (which will display the ﬁeld labels) to be light green, and the background of the data rows to alternate between white and light yellow. We must also make sure that the special HTML characters(“&”,“<”,and “>”) are properly escaped,and we want strings to be tidied up a bit.\n\nHere’s a tiny piece of sample data:\n\n\"COUNTRY\",\"2000\",\"2001\",2002,2003,2004 \"ANTIGUA AND BARBUDA\",0,0,0,0,0\n\n97\n\n||\n\n3.1\n\n98\n\nChapter 2. Data Types\n\n\"ARGENTINA\",37,35,33,36,39 \"BAHAMAS, THE\",1,1,1,1,1 \"BAHRAIN\",5,6,6,6,6\n\nAssuming the sample data is in the ﬁle data/co2-sample.csv, and given the command csv2html.py < data/co2-sample.csv > co2-sample.html, the ﬁle co2-sample.html will have contents similar to this:\n\n<table border='1'><tr bgcolor='lightgreen'> <td>Country</td><td align='right'>2000</td><td align='right'>2001</td> <td align='right'>2002</td><td align='right'>2003</td> <td align='right'>2004</td></tr> ... <tr bgcolor='lightyellow'><td>Argentina</td> <td align='right'>37</td><td align='right'>35</td> <td align='right'>33</td><td align='right'>36</td> <td align='right'>39</td></tr> ... </table>\n\nWe’ve tidied the output slightly and omitted some lines where indicated by ellipses. We have used a very simple version of HTML—HTML 4 transitional, with no style sheet. Figure 2.7 shows what the output looks like in a web browser.\n\nFigure 2.7 A csv2html.py table in a web browser\n\nNow that we’ve seen how the program is used and what it does, we are ready to review the code. The program begins with the import of the sys module; we won’t show this, or any other imports from now on, unless they are unusual or warrant discussion. And the last statement in the program is a single function call:\n\nmain()\n\nAlthough Python does not need an entry point as some languages require, it is quite common in Python programs to create a function called main() and to call it to start off processing. Since no function can be called before it has been created, we must make sure we call main() after the functions it relies on have",
      "page_number": 96
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 104-111)",
      "start_page": 104,
      "end_page": 111,
      "detection_method": "topic_boundary",
      "content": "Examples\n\nbeen deﬁned. The order in which the functionsappear in the ﬁle (i.e.,the order in which they are created) does not matter.\n\nIn the csv2html.py program, the ﬁrst function we call is main() which in turn calls print_start() and then print_line(). And print_line() calls extract_ fields() and escape_html(). The program structure we have used is shown in Figure 2.8.\n\nimport sys\n\ndef main():\n\ndef print_start():\n\ndef print_line():\n\ncalls\n\ndef extract_fields():\n\ncalls\n\ncalls\n\ndef escape_html():\n\ndef print_end():\n\nmain()\n\nFigure 2.8 The csv2html.py program’s structure\n\nWhen Python reads a ﬁle it begins at the top. So for this example, it starts by performing the import, then it creates the main() function, and then it creates the other functionsin the order in which they appear in the ﬁle. When Python ﬁnally reaches the call to main() at the end of the ﬁle, all the functions that main() will call (and all the functions that those functions will call) now exist. Execution as we normally think of it begins where the call to main() is made.\n\nWe will look at each function in turn, starting with main().\n\ndef main():\n\nmaxwidth = 100 print_start() count = 0 while True: try:\n\nline = input() if count == 0:\n\ncolor = \"lightgreen\"\n\nelif count % 2:\n\ncolor = \"white\"\n\nelse:\n\ncolor = \"lightyellow\"\n\n99\n\n100\n\nChapter 2. Data Types\n\nprint_line(line, color, maxwidth) count += 1\n\nexcept EOFError:\n\nbreak\n\nprint_end()\n\nThe maxwidth variable is used to constrain the number of characters in a cell—if a ﬁeld is bigger than this we will truncate it and signify this by adding an ellipsis to the truncated text. We’ll look at the print_start(), print_line(), and print_end() functions in a moment. The while loop iterates over each line of input—this could come from the user typing at the keyboard, but we expect it to be a redirected ﬁle. We set the color we want to use and call print_line() to output the line as an HTML table row.\n\ndef print_start():\n\nprint(\"<table border='1'>\")\n\ndef print_end():\n\nprint(\"</table>\")\n\nWe could have avoided creating these two functions and simply put the rel- evant print() function calls in main(). But we prefer to separate out the logic since this is more ﬂexible, even though it doesn’t really matter in this small example.\n\ndef print_line(line, color, maxwidth):\n\nprint(\"<tr bgcolor='{0}'>\".format(color)) fields = extract_fields(line) for field in fields: if not field:\n\nprint(\"<td></td>\")\n\nelse:\n\nnumber = field.replace(\",\", \"\") try:\n\nx = float(number) print(\"<td align='right'>{0:d}</td>\".format(round(x)))\n\nexcept ValueError:\n\nfield = field.title() field = field.replace(\" And \", \" and \") if len(field) <= maxwidth:\n\nfield = escape_html(field)\n\nelse:\n\nfield = \"{0} ...\".format(\n\nescape_html(field[:maxwidth]))\n\nprint(\"<td>{0}</td>\".format(field))\n\nprint(\"</tr>\")\n\nExamples\n\nWe cannot use str.split(\",\") to split each line into ﬁelds because commas can occur inside quoted strings. So we have farmed this work out to the extract_fields() function. Once we have a list of the ﬁelds (as strings,with no surrounding quotes), we iterate over them, creating a table cell for each one.\n\nIf a ﬁeld is empty, we output an empty cell. If a ﬁeld is quoted, it could be a string or it could be a number that has been quoted to allow for internal commas, for example, \"1,566\". To account for this, we make a copy of the ﬁeld with commasremovedandtry toconverttheﬁeldtoa float.If theconversionis successful we output a right-aligned cell with the ﬁeld rounded to the nearest whole number and output it asan integer. If theconversionfailswe output the ﬁeld asa string. In thiscaseweuse str.title() toneaten thecaseof theletters and we replace the word And with and as a correction to str.title()’s effect. If the ﬁeld isn’t too long we use all of it, otherwise we truncate it to maxwidth characters and add an ellipsis to signify the truncation, and in either case we escape any special HTML characters the ﬁeld might contain.\n\ndef extract_fields(line):\n\nfields = [] field = \"\" quote = None for c in line:\n\nif c in \"\\\"'\":\n\nif quote is None: # start of quoted string\n\nquote = c\n\nelif quote == c: # end of quoted string\n\nquote = None\n\nelse:\n\nfield += c\n\n# other quote inside quoted string\n\ncontinue\n\nif quote is None and c == \",\": # end of a field\n\nfields.append(field) field = \"\"\n\nelse:\n\nfield += c\n\n# accumulating a field\n\nif field:\n\nfields.append(field) # adding the last field\n\nreturn fields\n\nThis function reads the line it is given character by character, accumulating a list of ﬁelds—each one a string without any enclosing quotes. The function copes with ﬁelds that are unquoted,and with ﬁelds that are quoted with single or double quotes, and correctly handles commas and quotes (single quotes in double quoted strings, double quotes in single quoted strings).\n\n101\n\n102\n\nChapter 2. Data Types\n\ndef escape_html(text):\n\ntext = text.replace(\"&\", \"&amp;\") text = text.replace(\"<\", \"&lt;\") text = text.replace(\">\", \"&gt;\") return text\n\nThis function straightforwardly replaces each special HTML character with the appropriate HTML entity. We must of course replace ampersands ﬁrst, although the order doesn’t matter for the angle brackets. Python’s standard library includes a slightly more sophisticated version of this function—you’ll get the chance to use it in the exercises, and will see it again in Chapter 7.\n\nSummary\n\n|||\n\nThischapter began by showing the list of Python’skeywordsand describedthe rules that Python applies to identiﬁers. Thanks to Python’s Unicode support, identiﬁers are not limited to a subset of characters from a small character set like ASCII or Latin-1.\n\nWe also described Python’s int data type, which differs from similar types in mostotherlanguagesinthatithasnointrinsicsizelimitation. Pythonintegers canbeaslargeasthemachine’smemory willallow,andit isperfectlyfeasibleto work with numbersthat arehundredsof digitslong. All of Python’smostbasic data types are immutable, but this is rarely noticable since the augmented as- signment operators(+=,*=,-=,/=,and others)meansthat we can use a very nat- ural syntax while behind the scenes Python creates result objects and rebinds ourvariablestothem. Literalintegersareusuallywrittenasdecimalnumbers, but we can write binary literals using the 0b preﬁx, octal literals using the 0o preﬁx, and hexadecimal literals using the 0x preﬁx.\n\nWhen two integers are divided using /, the result is always a float. This is different from many other widely used languages, but helps to avoid some quite subtle bugs that can occur when division silently truncates. (And if we want integer division we can use the // operator.)\n\nPython has a bool data type which can hold either True or False. Python has three logical operators, and, or, and not, of which the two binary operators (and and or) use short-circuit logic.\n\nThree kinds of ﬂoating-point numbers are available: float, complex, and dec- imal.Decimal. The most commonly used is float; this is a double-precision ﬂoating-point number whose exact numerical characteristics depend on the underlying C, C#, or Java library that Python was built with. Complex num- bersare representedastwo floats,one holding the real value and the other the imaginary value. The decimal.Decimal type is provided by the decimal module.\n\nSummary\n\nThese numbersdefault to having 28 decimal placesof accuracy,but this can be increased or decreased to suit our needs.\n\nAll three ﬂoating-point types can be used with the appropriate built-in math- ematical operators and functions. And in addition,the math module provides a varietyof trigonometric,hyperbolic,andlogarithmicfunctionsthatcanbeused with floats,and the cmath moduleprovidesa similar set of functionsfor complex numbers.\n\nMost of the chapter was devoted to strings. Python string literals can be created using single quotes or double quotes, or using a triple quoted string if we want to include newlines and quotes without formality. Various escape sequences can be used to insert special characterssuch as tab (\\t) and newline (\\n), and Unicode characters both using hexadecimal escapes and Unicode character names. Although strings support the same comparison operators as other Python types, we noted that sorting strings that contain non-English characters can be problematic.\n\nSince strings are sequences, the slicing operator ([]) can be used to slice and stride strings with a very simple yet powerful syntax. Strings can also be concatenated with the + operator and replicated with the * operator, and we can also use the augmented assignment versions of these operators (+= and *=), although the str.join() method is more commonly used for concatenation. Stringshave many other methods,including some for testing string properties (e.g.,str.isspace() and str.isalpha()),somefor changing case(e.g.,str.lower() and str.title()), some for searching (e.g., str.find() and str.index()), and many others.\n\nPython’s string support is really excellent, enabling us to easily ﬁnd and extract or compare whole strings or parts of strings, to replace characters or substrings, and to split strings into a list of substrings and to join lists of strings into a single string.\n\nProbably the most versatile string method is str.format().Thismethod is used tocreatestringsusing replacementﬁeldsandvariablestogointhoseﬁelds,and format speciﬁcations to precisely deﬁne the characteristicsof each ﬁeld which isreplacedwitha value. Thereplacementﬁeldnamesyntax allowsustoaccess the method’s arguments by position or by name (for keyword arguments),and to use an index,key,or attributename to accessan argument item or attribute. The format speciﬁcations allow us to specify the ﬁll character, the alignment, and the minimum ﬁeld width. Furthermore, for numbers we can also control how the sign is output,and for ﬂoating-point numbers we can specify the num- ber of digits after the decimal point and whether to use standard or exponen- tial notation.\n\nWe also discussedthethorny issueof character encodings. Python .py ﬁlesuse the Unicode UTF-8 encoding by default and so can have comments,identiﬁers, and data written in just about any human language. We can convert a string\n\n103\n\n104\n\nChapter 2. Data Types\n\ninto a sequence of bytes using a particular encoding using the str.encode() method,and we can convert a sequence of bytesthat use a particular encoding back to a string using the bytes.decode() method. The wide variety of charac- ter encodings currently in use can be very inconvenient, but UTF-8 is fast be- coming the de facto standard for plain text ﬁles (and is already the default for XML ﬁles), so this problem should diminish in the coming years.\n\nIn addition to the data typescovered in thischapter,Python providestwo other built-in data types,bytes and bytearray,both of which arecoveredin Chapter7. Python also provides several collection data types, some built-in and others in the standard library. In the next chapter we will look at Python’s most important collection data types.\n\nExercises\n\n|||\n\n1. Modify the print_unicode.py program so that the user can enter several separate words on the command line, and print rows only where the Unicode character name contains all the words the user has speciﬁed. This means that we can type commands like this: print_unicode_ans.py greek symbol\n\nOne way of doing this is to replace the word variable (which held 0, None, or a string), with a words list. Don’t forget to update the usage informa- tion as well as the code. The changes involve adding less than ten lines of code, and changing less than ten more. A solution is provided in ﬁle print_unicode_ans.py. (Windows and cross-platform users should modify print_unicode_uni.py; a solution is provided in print_unicode_uni_ans.py.)\n\n2. Modify quadratic.py so that 0.0factorsare not output,and so that negative factors are output as - n rather than as + -n. This involves replacing the last ﬁve lines with about ﬁfteen lines. A solution is provided in quadrat- ic_ans.py. (Windows and cross-platform users should modify quadrat- ic_uni.py; a solution is provided in quadratic_uni_ans.py.)\n\n3. Delete the escape_html() function from csv2html.py, and use the xml.sax. saxutils.escape()functionfromthexml.sax.saxutilsmoduleinstead. This is easy,requiring one new line (the import),ﬁve deleted lines (the unwant- ed function), and one changed line (to use xml.sax.saxutils.escape() in- stead of escape_html()). A solution is provided in csv2html1_ans.py.\n\n4. Modify csv2html.py again, this time adding a new function called pro- cess_options(). This function should be called from main() and should return a tuple of two values: maxwidth (an int) and format (a str). When process_options() is called it should set a default maxwidth of 100, and a default format of “.0f”—this will be used as the format speciﬁer when out- putting numbers.\n\nExercises\n\nIf theuser hastyped“-h”or “--help”on thecommandline,a usagemessage should be output and (None, None) returned. (In this case main() should do nothing.) Otherwise, the function should read any command-line arguments that are given and perform the appropriate assignments. For example, setting maxwidth if “maxwidth=n” is given, and similarly setting format if “format=s” is given. Here is a run showing the usage output:\n\ncsv2html2_ans.py -h usage: csv2html.py [maxwidth=int] [format=str] < infile.csv > outfile.html\n\nmaxwidth is an optional integer; if specified, it sets the maximum number of characters that can be output for string fields, otherwise a default of 100 characters is used.\n\nformat is the format to use for numbers; if not specified it defaults to \".0f\".\n\nAnd here is a command line with both options set:\n\ncsv2html2_ans.py maxwidth=20 format=0.2f < mydata.csv > mydata.html\n\nDon’t forget to modify print_line() to make use of the format for out- putting numbers—you’ll need to pass in an extra argument, add one line, and modify another line. And this will slightly affect main() too. The pro- cess_options() function should be about twenty-ﬁve lines (including about nine for the usage message).This exercise may prove challenging for inex- perienced programmers.\n\nTwo ﬁlesof test data are provided:data/co2-sample.csv and data/co2-from- fossilfuels.csv. A solution is provided in csv2html2_ans.py. In Chapter 5 we will see how to use Python’s optparse module to simplify command-line processing.\n\n105\n\n3\n\nSequence Types ● Set Types ● Mapping Types ● Iterating and Copying Collections\n\nCollection Data Types\n\n||||\n\nIn the preceding chapter we learned about Python’s most important funda- mental data types. In this chapter we will extend our programming options by learning how to gather data items together using Python’s collection data types. We will cover tuples and lists, and also introduce new collection data types, including sets and dictionaries, and cover all of them in depth.★\n\nIn addition to collections, we will also see how to create data items that are aggregates of other data items (like C or C++ structs or Pascal records)—such items can be treated as a single unit when this is convenient for us, while the items they contain remain individually accessible. Naturally, we can put aggregated items in collections just like any other items.\n\nHaving data items in collections makes it much easier to perform operations that must be applied to all of the items, and also makes it easier to handle col- lections of items read in from ﬁles. We’ll cover the very basics of text ﬁle han- dling in this chapter as we need them, deferring most of the detail (including error handling) to Chapter 7.\n\nAfter covering the individual collection data types, we will look at how to it- erate over collections, since the same syntax is used for all of Python’s collec- tions, and we will also explore the issues and techniques involved in copying collections.\n\nSequence Types\n\n|||\n\nA sequence type is one that supports the membership operator (in), the size function (len()), slices ([]), and is iterable. Python provides ﬁve built-in se- quence types: bytearray, bytes, list, str, and tuple—the ﬁrst two are covered\n\n★The deﬁnitions of what constitutes a sequence type, a set type, or a mapping type given in this chapter are practical but informal. More formal deﬁnitions are given in Chapter 8.\n\n107",
      "page_number": 104
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 112-119)",
      "start_page": 112,
      "end_page": 119,
      "detection_method": "topic_boundary",
      "content": "Strings 65➤\n\nString slicing and striding 69➤\n\n108\n\nChapter 3. Collection Data Types\n\nseparately in Chapter 7. Some other sequence types are provided in the stan- dard library, most notably, collections.namedtuple. When iterated, all of these sequences provide their items in order.\n\nWe covered strings in the preceding chapter. tuples, named tuples, and lists.\n\nIn this section we will cover\n\nTuples\n\nA tuple is an ordered sequence of zero or more object references. Tuples strings. This makes it easy to support the same slicing and striding syntax as extract items from a tuple. Like strings, tuples are immutable, so we cannot replace or delete any of their items. If we want to be able to modify an ordered sequence, we simply use a list instead of a tuple; or if we already have a tuple but want to modify it, we can convert it to a list using the list() conversion function and then apply the changes to the resultant list.\n\nThe tuple data type can be called as a function, tuple()—with no arguments it returns an empty tuple, with a tuple argument it returns a shallow copy of the argument, and with any other argument it attempts to convert the given object to a tuple. It does not accept more than one argument. Tuples can also be created without using the tuple() function. An empty tuple iscreated using empty parentheses,(),and a tupleof oneor moreitemscan becreatedby using commas. Sometimestuplesmust be enclosed in parenthesesto avoid syntactic ambiguity. For example, to pass the tuple 1, 2, 3 to a function, we would write function((1, 2, 3)).\n\nFigure 3.1 shows the tuple t = \"venus\", -28, \"green\", \"21\", 19.74, and the index positions of the items inside the tuple. Strings are indexed in the same way, but whereas strings have a character at every position, tuples have an object reference at each position.\n\nt[-5]\n\nt[-4]\n\nt[-3]\n\nt[-2]\n\nt[-1]\n\n'venus'\n\n28\n\n'green'\n\n'21'\n\n19.74\n\nt[0]\n\nt[1]\n\nt[2]\n\nt[3]\n\nt[4]\n\nFigure 3.1 Tuple index positions\n\nTuples provide just two methods, t.count(x), which returns the number of timesobject x occursintuplet,and t.index(x),whichreturnstheindex position of the leftmost occurrence of object x in tuple t—or raises a ValueError excep- tion if there is no x in the tuple. (These methods are also available for lists.)\n\nIn addition, tuples can be used with the operators + (concatenation), * (repli- cation), and [] (slice), and with in and not in to test for membership. The += and *= augmented assignment operators can be used even though tuples are\n\n||\n\nShallow and deep copying ➤ 146\n\nSequence Types\n\nimmutable—behind the scenes Python creates a new tuple to hold the result and sets the left-hand object reference to refer to it;the same technique is used when these operatorsare applied to strings. Tuplescan be compared using the standard comparison operators (<, <=, ==, !=, >=, >), with the comparisons being applied item by item (and recursively for nested items such as tuples inside tuples).\n\nLet’s look at a few slicing examples, starting with extracting one item, and a slice of items:\n\n>>> hair = \"black\", \"brown\", \"blonde\", \"red\" >>> hair[2] 'blonde' >>> hair[-3:] # same as: hair[1:] ('brown', 'blonde', 'red')\n\nThese work the same for strings, lists, and any other sequence type.\n\n>>> hair[:2], \"gray\", hair[2:] (('black', 'brown'), 'gray', ('blonde', 'red'))\n\nHerewetriedtocreatea new 5-tuple,but ended upwith a 3-tuplethat contains two 2-tuples. This happened because we used the comma operator with three items (a tuple,a string,and a tuple).To get a single tuple with all the items we must concatenate tuples:\n\n>>> hair[:2] + (\"gray\",) + hair[2:] ('black', 'brown', 'gray', 'blonde', 'red')\n\nTo make a 1-tuple the comma is essential, but in this case, if we had just put in the comma we would get a TypeError (since Python would think we were trying to concatenate a string and a tuple), so here we must have the comma and parentheses.\n\nIn this book (from this point on), we will use a particular coding style when writing tuples. When we have tupleson the left-hand side of a binary operator or on the right-hand side of a unary statement, we will omit the parentheses, and in all other cases we will use parentheses. Here are a few examples:\n\na, b = (1, 2)\n\n# left of binary operator\n\ndel a, b\n\n# right of unary statement\n\ndef f(x):\n\nreturn x, x ** 2\n\n# right of unary statement\n\nfor x, y in ((1, 1), (2, 4), (3, 9)): # left of binary operator\n\nprint(x, y)\n\n109\n\n110\n\nChapter 3. Collection Data Types\n\nThere is no obligation to follow this coding style; some programmers prefer to alwaysuseparentheses—whichisthesameasthetuplerepresentationalform, whereas others use them only if they are strictly necessary.\n\n>>> eyes = (\"brown\", \"hazel\", \"amber\", \"green\", \"blue\", \"gray\") >>> colors = (hair, eyes) >>> colors[1][3:-1] ('green', 'blue')\n\nHere we have nested two tuplesinside another tuple. Nested collectionsto any level of depth can be created like this without formality. The slice operator [] can be applied to a slice, with as many used as necessary. For example:\n\n>>> things = (1, -7.5, (\"pea\", (5, \"Xyz\"), \"queue\")) >>> things[2][1][1][2] 'z'\n\nLet’s look at this piece by piece, beginning with things[2] which gives us the third item in the tuple (since the ﬁrst item has index 0), which is itself a tu- ple, (\"pea\", (5, \"Xyz\"), \"queue\"). The expression things[2][1] gives us the second item in the things[2] tuple, which is again a tuple, (5, \"Xyz\"). And things[2][1][1] givesus the second item in thistuple,which is the string \"Xyz\". Finally,things[2][1][1][2] givesusthethirditem(character)inthestring,that is, \"z\".\n\nTuples are able to hold any items of any data type, including collection types such as tuples and lists, since what they really hold are object references. Using complex nested data structures like this can easily become confusing. One solution is to give names to particular index positions. For example:\n\n>>> MANUFACTURER, MODEL, SEATING = (0, 1, 2) >>> MINIMUM, MAXIMUM = (0, 1) >>> aircraft = (\"Airbus\", \"A320-200\", (100, 220)) >>> aircraft[SEATING][MAXIMUM] 220\n\nThis is certainly more meaningful than writing aircraft[2][1], but it involves creating lots of variables and is rather ugly. We will see an alternative in the next subsection.\n\nIn the ﬁrst two lines of the “aircraft” code snippet, we assigned to tuples in both statements. When we have a sequence on the right-hand side of an assignment (here we have tuples), and we have a tuple on the left-hand side, we say that the right-hand side has been unpacked. Sequence unpacking can be used to swap values, for example:\n\na, b = (b, a)\n\nSequence Types\n\nStrictly speaking,the parenthesesare not needed on the right,but as we noted earlier, the coding style used in this book is to omit parentheses for left-hand operands of binary operators and right-hand operands of unary statements, but to use parentheses in all other cases.\n\nWe have already seen examples of sequence unpacking in the context of for … in loops. Here is a reminder:\n\nfor x, y in ((-3, 4), (5, 12), (28, -45)):\n\nprint(math.hypot(x, y))\n\nHere we loop over a tuple of 2-tuples, unpacking each 2-tuple into variables x and y.\n\nNamed Tuples\n\nA named tuple behaves just like a plain tuple, and has the same performance characteristics. What it adds is the ability to refer to items in the tuple by name as well as by index position, and this allows us to create aggregates of data items.\n\nThe collections module provides the namedtuple() function. This function is used to create custom tuple data types. For example:\n\nSale = collections.namedtuple(\"Sale\",\n\n\"productid customerid date quantity price\")\n\nThe ﬁrst argument to collections.namedtuple() isthename of the customtuple data typethat wewant tobecreated. Thesecondargumentisa string of space- separated names, one for each item that our custom tuples will take. The ﬁrst argument, and the names in the second argument, must all be valid Python identiﬁers. The function returns a custom class (data type) that can be used to create named tuples. So, in this case, we can treat Sale just like any other Python class (such as tuple), and create objects of type Sale.(In object-oriented terms, every class created this way is a subclass of tuple; object-oriented pro- gramming, including subclassing, is covered in Chapter 6.)\n\nHere is an example:\n\nsales = [] sales.append(Sale(432, 921, \"2008-09-14\", 3, 7.99)) sales.append(Sale(419, 874, \"2008-09-15\", 1, 18.49))\n\nHere we have created a list of two Sale items,that is,of two custom tuples. We can refer to itemsin the tuplesusing index positions—for example,the price of the ﬁrst sale item is sales[0][-1] (i.e.,7.99)—but we can also use names,which makes things much clearer:\n\n111\n\n||\n\nUs- ing str. format() with map- ping un- packing 81➤\n\n112\n\nChapter 3. Collection Data Types\n\ntotal = 0 for sale in sales:\n\ntotal += sale.quantity * sale.price\n\nprint(\"Total ${0:.2f}\".format(total)) # prints: Total $42.46\n\nThe clarity and convenience that named tuples provide are often useful. For example, here is the “aircraft” example from the previous subsection (110 ➤) done the nice way:\n\n>>> Aircraft = collections.namedtuple(\"Aircraft\", ... >>> Seating = collections.namedtuple(\"Seating\", \"minimum maximum\") >>> aircraft = Aircraft(\"Airbus\", \"A320-200\", Seating(100, 220)) >>> aircraft.seating.maximum 220\n\n\"manufacturer model seating\")\n\nWhen it comes to extracting named tuple items for use in strings there are three main approaches we can take.\n\n>>> print(\"{0} {1}\".format(aircraft.manufacturer, aircraft.model)) Airbus A320-200\n\nHere we have accessed each of the tuple’s items that we are interested in using named tuple attribute access. This gives us the shortest and simplest format string. (And in Python 3.1 we could reduce this format string to just \"{} {}\".) But this approach means that we must look at the arguments passed to str.format() to see what the replacement textswill be. Thisseemslessclear than using named ﬁelds in the format string.\n\n\"{0.manufacturer} {0.model}\".format(aircraft)\n\nHere we have used a single positional argument and used named tuple at- tribute names as ﬁeld names in the format string. This is much clearer than just using positional arguments alone, but it is a pity that we must speci- fy the positional value (even when using Python 3.1). Fortunately, there is a nicer way.\n\nNamed tuples have a few private methods—that is, methods whose name begins with a leading underscore. One of them—namedtuple._asdict()—is so useful that we will show it in action.★\n\n\"{manufacturer} {model}\".format(**aircraft._asdict())\n\nThe private namedtuple._asdict() method returns a mapping of key–value pairs,where each key is the name of a tuple element and each value is the cor-\n\n★Private methods such as namedtuple._asdict()are not guaranteed to be availablein all Python 3.x versions; although the namedtuple._asdict()method is available in both Python 3.0 and 3.1.\n\nString slicing and striding 69➤\n\nSequence Types\n\nresponding value. We have used mapping unpacking to convert the mapping into key–value arguments for the str.format() method.\n\nAlthough named tuples can be very convenient, in Chapter 6 we introduce object-oriented programming, and there we will go beyond simple named tuplesand learn how to create custom data typesthat hold data itemsand that also have their own custom methods.\n\nLists\n\nA list is an ordered sequence of zero or more object references. Lists support the same slicing and striding syntax as strings and tuples. This makes it easy to extract items from a list. Unlike strings and tuples, lists are mutable, so we can replace and delete any of their items. It is also possible to insert, replace, and delete slices of lists.\n\nThe list data type can be called as a function, list()—with no arguments it returns an empty list, with a list argument it returns a shallow copy of the argument,and with any other argument it attemptsto convert thegiven object to a list.It does not accept more than one argument. Lists can also be created without using the list() function. An empty list iscreated using empty brack- ets, [], and a list of one or more items can be created by using a comma-sepa- rated sequence of itemsinside brackets. Another way of creating listsisto use a list comprehension—a topic we will cover later in this subsection.\n\nSince all the items in a list are really object references, lists, like tuples, can hold items of any data type, including collection types such as lists and tuples. Listscan be comparedusing thestandardcomparisonoperators(<,<=,==,!=,>=, >),with the comparisonsbeing applied item by item (and recursively for nested items such as lists or tuples inside lists).\n\nGiven the assignment L = [-17.5, \"kilo\", 49, \"V\", [\"ram\", 5, \"echo\"], 7],we get the list shown in Figure 3.2.\n\nL[-6]\n\nL[-5]\n\nL[-4]\n\nL[-3]\n\nL[-2]\n\nL[-1]\n\n17.5\n\n'kilo'\n\n49\n\n'V'\n\n['ram', 5, 'echo']\n\n7\n\nL[0]\n\nL[1]\n\nL[2]\n\nL[3]\n\nL[4]\n\nL[5]\n\nFigure 3.2 List index positions\n\nAnd given this list, L, we can use the slice operator—repeatedly if neces- sary—to access items in the list, as the following equalities show:\n\nL[0] == L[-6] == -17.5 L[1] == L[-5] == 'kilo' L[1][0] == L[-5][0] == 'k'\n\n113\n\n||\n\nShallow and deep copying ➤ 146\n\nList compre- hen- sions ➤ 118\n\n114\n\nChapter 3. Collection Data Types\n\nL[4][2] == L[4][-1] == L[-2][2] == L[-2][-1] == 'echo' L[4][2][1] == L[4][2][-3] == L[-2][-1][1] == L[-2][-1][-3] == 'c'\n\nLists can be nested, iterated over, and sliced, the same as tuples. In fact, all the tuple examples presented in the preceding subsection would work exactly the same if we used lists instead of tuples. Lists support membership testing with in and not in, concatenation with +,extending with += (i.e.,the appending of all the items in the right-hand operand),and replication with * and *=.Lists can also be used with the built-in len() function, and with the del statement discussed here and described in the sidebar “Deleting Items Using the del Statement” (➤ 116). In addition, lists provide the methods shown in Table 3.1.\n\nAlthough we can use the slice operator to access items in a list, in some situa- tions we want to take two or more pieces of a list in one go. This can be done by sequenceunpacking. Any iterable(lists,tuples,etc.) canbeunpackedusing thesequenceunpacking operator,anasterisk or star(*).Whenusedwithtwoor morevariableson theleft-hand sideof an assignment,oneof which ispreceded by *,itemsare assigned to the variables,with all those left over assigned to the starred variable. Here are some examples:\n\n>>> first, *rest = [9, 2, -4, 8, 7] >>> first, rest (9, [2, -4, 8, 7]) >>> first, *mid, last = \"Charles Philip Arthur George Windsor\".split() >>> first, mid, last ('Charles', ['Philip', 'Arthur', 'George'], 'Windsor') >>> *directories, executable = \"/usr/local/bin/gvim\".split(\"/\") >>> directories, executable (['', 'usr', 'local', 'bin'], 'gvim')\n\nWhen the sequence unpacking operator is used like this, the expression *rest, and similar expressions, are called starred expressions.\n\nPython also has a related concept called starred arguments.For example,if we have the following function that requires three arguments:\n\ndef product(a, b, c):\n\nreturn a * b * c #here, * is the multiplication operator\n\nwe can call it with three arguments, or by using starred arguments:\n\n>>> product(2, 3, 5) 30 >>> L = [2, 3, 5] >>> product(*L) 30 >>> product(2, *L[1:]) 30\n\nSequence Types\n\n115\n\nTable 3.1 List Methods\n\nSyntax\n\nDescription\n\nL.append(x)\n\nAppends item x to the end of list L\n\nL.count(x)\n\nReturns the number of times item x occurs in list L\n\nL.extend(m) L += m\n\nAppends all of iterable m’s items to the end of list L; the operator += does the same thing\n\nL.index(x, start, end)\n\nReturns the index position of the leftmost occurrence of item x in list L (or in the start:end slice of L); otherwise, raises a ValueError exception\n\nL.insert(i, x)\n\nInserts item x into list L at index position int i\n\nL.pop()\n\nReturns and removes the rightmost item of list L\n\nL.pop(i)\n\nReturns and removes the item at index position int i in L\n\nL.remove(x)\n\nRemoves the leftmost occurrence of item x from list L, or raises a ValueError exception if x is not found\n\nL.reverse()\n\nReverses list L in-place\n\nL.sort(...)\n\nSorts list L in-place;this method accepts reverse optional arguments as the built-in sorted()\n\nthe same key and\n\nIn the ﬁrst call we provide the three arguments normally. In the second call we use a starred argument—what happens here is that the three-item list is unpackedby the * operator,soasfar asthefunctionisconcernedit hasreceived the three arguments it is expecting. We could have achieved the same thing using a3-tuple. Andinthethirdcallwepasstheﬁrstargumentconventionally, and the other two argumentsby unpacking a two-item slice of the L list. Func- tions and argument passing are covered fully in Chapter 4.\n\nThere is never any syntactic ambiguity regarding whether operator * is the multiplication or the sequence unpacking operator. When it appears on the left-hand side of an assignment it is the unpacking operator, and when it appears elsewhere (e.g., in a function call) it is the unpacking operator when used as a unary operator and the multiplication operator when used as a binary operator.\n\nWe have already seen that we can iterate over the items in a list using the syntax for item in L:. If we want to change the items in a list the idiom to use is:\n\nfor i in range(len(L)):\n\nL[i] = process(L[i])\n\nThe built-in range() function returns an iterator that provides integers. With one integer argument, n, the iterator range() returns, producing 0, 1, …, n - 1.\n\nsorted() ➤ 140, 144\n\nrange() ➤ 141",
      "page_number": 112
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 120-128)",
      "start_page": 120,
      "end_page": 128,
      "detection_method": "topic_boundary",
      "content": "116\n\nChapter 3. Collection Data Types\n\nDeleting Items Using the del Statement\n\nAlthough the name of the del statement is reminiscent of the word delete, it does not necessarily delete any data. When applied to an object reference that refers to a data item that is not a collection, the del statement unbinds the object reference from the data item and deletes the object reference. For example:\n\n>>> x = 8143 # object ref. 'x' created; int of value 8143 created >>> x 8143 >>> del x # object ref. 'x' deleted; int ready for garbage collection >>> x Traceback (most recent call last): ... NameError: name 'x' is not defined\n\nWhen an object reference is deleted, Python schedules the data item to which it referredto be garbage-collected if no other object referencesrefer to thedataitem. When,orevenif,garbagecollectiontakesplacemay benonde- terministic (depending on the Python implementation),so if any cleanup is required we must handle it ourselves. Python provides two solutions to the nondeterminism. One is to use a try …finally block to ensure that cleanup is done, and another is to use a with statement as we will see in Chapter 8.\n\nWhen del is used on a collection data type such as a tuple or a list, only the object referenceto the collection isdeleted. The collection and itsitems(and for those items that are themselves collections, for their items, recursively) are scheduled for garbage collection if no other object references refer to the collection.\n\nFor mutable collections such as lists, del can be applied to individual items or slices—in both cases using the slice operator, []. If the item or items referred to are removed from the collection, and if there are no other object references referring to them, they are scheduled for garbage collection.\n\nWe could use this technique to increment all the numbers in a list of integers. For example:\n\nfor i in range(len(numbers)):\n\nnumbers[i] += 1\n\nSince lists support slicing, in several cases the same effect can be achieved using either slicing or one of thelist methods. For example,given thelist woods = [\"Cedar\", \"Yew\", \"Fir\"], we can extend the list in either of two ways:\n\nwoods += [\"Kauri\", \"Larch\"]\n\nwoods.extend([\"Kauri\", \"Larch\"])\n\nSlicing and striding 69➤\n\nSequence Types\n\nIn either case the result is the list ['Cedar', 'Yew', 'Fir', 'Kauri', 'Larch'].\n\nIndividual items can be added at the end of a list using list.append(). Items can be inserted at any index position within the list using list.insert(), or by assigning to a slice of length 0. For example, given the list woods = [\"Cedar\", \"Yew\", \"Fir\", \"Spruce\"], we can insert a new item at index position 2 (i.e., as the list’s third item) in either of two ways:\n\nwoods[2:2] = [\"Pine\"]\n\nwoods.insert(2, \"Pine\")\n\nIn both cases the result is the list ['Cedar', 'Yew', 'Pine', 'Fir', 'Spruce'].\n\nIndividual items can be replaced in a list by assigning to a particular index position, for example, woods[2] = \"Redwood\". Entire slices can be replaced by assigning an iterable to a slice, for example, woods[1:3] = [\"Spruce\", \"Sugi\", \"Rimu\"].Thesliceandtheiterabledon’thavetobethesamelength. In allcases, the slice’s items are removed and the iterable’s items are inserted. This makes the list shorter if the iterable has fewer items than the slice it replaces, and longer if the iterable has more items than the slice.\n\nTo make what happens when assigning an iterable to a slice really clear, we will consider one further example. Imagine that we have the list L = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"], and that we assign an iterable (in this case, a list) to a slice of it with the code L[2:5] = [\"X\", \"Y\"]. First, the slice is removed, so behind the scenes the list becomes ['A', 'B', 'F']. And then all the iterable’s items are inserted at the slice’s start position, so the resultant list is ['A', 'B', 'X', 'Y', 'F'].\n\nItems can be removed in a number of other ways. We can use list.pop() with no arguments to remove the rightmost item in a list—the removed item is also returned. Similarly we can use list.pop() with an integer index argument to remove (and return) an item at a particular index position. Another way of removing an item is to call list.remove() with the item to be removed as the argument. The del statementcan also be used to removeindividualitems—for example, del woods[4]—or to remove slicesof items. Slicescan also be removed by assigning an empty list to a slice, so these two snippets are equivalent:\n\nwoods[2:4] = []\n\ndel woods[2:4]\n\nIn the left-hand snippet we have assigned an iterable (an empty list) to a slice, so ﬁrst the slice is removed, and since the iterable to insert is empty, no insertion takes place.\n\nWhen we ﬁrst covered slicing and striding, we did so in the context of strings where striding wasn’t very interesting. But in the case of lists,striding allows us to access every n-th item which can often be useful. For example, suppose we have the list, x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], and we want to set every odd-indexed item (i.e., x[1], x[3],etc.) to 0.We can access every second item by\n\n117\n\n118\n\nChapter 3. Collection Data Types\n\nstriding, for example, x[::2]. But this will give us the items at index positions 0, 2, 4, and so on. We can ﬁx this by giving an initial starting index, so now we have x[1::2], and this gives us a slice of the items we want. To set each item in the slice to 0, we need a list of 0s, and this list must have exactly the same number of 0s as there are items in the slice.\n\nHere is the complete solution: x[1::2] = [0] * len(x[1::2]). Now list x is [1, 0, 3, 0, 5, 0, 7, 0, 9, 0].We used the replication operator *,to produce a list consisting of the number of 0s we needed based on the length (i.e.,the number of items)of the slice. The interesting aspect isthat when we assign the list [0, 0, 0, 0, 0] to the strided slice, Python correctly replaces x[1]’s value with the ﬁrst 0, x[3]’s value with the second 0, and so on.\n\nLists can be reversed and sorted in the same way as any other iterable using the built-in reversed() and sorted() functionscovered in the Iteratorsand Iter- able Operations and Functions subsection (➤ 138). Lists also have equivalent methods, list.reverse() and list.sort(), both of which work in-place (so they don’t return anything), the latter accepting the same optional arguments as sorted(). One common idiom is to case-insensitively sort a list of strings—for example, we could sort the woods list like this: woods.sort(key=str.lower). The key argument is used to specify a function which is applied to each item, and whose return value is used to perform the comparisons used when sorting. As we noted in the previous chapter’s section on string comparisons (68 ➤), for languages other than English, sorting strings in a way that is meaningful to humans can be quite challenging.\n\nFor inserting items,listsperform best when itemsare added or removed at the end (list.append(), list.pop()).The worst performance occurs when we search for items in a list, for example, using list.remove() or list.index(), or using in for membership testing. If fast searching or membership testing is required, a set or a dict (both covered later in this chapter) may be a more suitable collectionchoice. Alternatively,listscan providefast searching if they arekept in order by sorting them—Python’ssort algorithm is especially well optimized for sorting partially sorted lists—and using a binary search (provided by the bisect module), to ﬁnd items. (In Chapter 6 we will create an intrinsically sorted custom list class.)\n\nList Comprehensions\n\nSmall lists are often created using list literals, but longer lists are usually createdprogrammatically. For a listof integerswecanuse list(range(n)),or if we just need an integer iterator, range() is sufﬁcient,but for other lists using a for …in loopisvery common. Suppose,for example,thatwewantedtoproduce a list of the leap years in a given range. We might start out like this:\n\nleaps = [] for year in range(1900, 1940):\n\n|\n\nsorted() ➤ 140, 144\n\nSequence Types\n\n119\n\nif (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n\nleaps.append(year)\n\nWhen the built-in range() function is given two integer arguments, the iterator it returns produces the integers n, n + 1, …, m - 1.\n\nn and m,\n\nOf course,if we knew the exact range beforehand we could use a list literal,for example, leaps = [1904, 1908, 1912, 1916, 1920, 1924, 1928, 1932, 1936].\n\nA list comprehension is an expression and a loop with an optional condition enclosed in brackets where the loop is used to generate items for the list, and where the condition can ﬁlter out unwanted items. The simplest form of a list comprehension is this:\n\n[item for item in iterable]\n\nThis will return a list of every item in the iterable, and is semantically no different from list(iterable).Two things that make list comprehensionsmore interesting and powerful are that we can use expressions,and we can attach a condition—this takes us to the two general syntaxes for list comprehensions:\n\n[expression for item in iterable] [expression for item in iterable if condition]\n\nThe second syntax is equivalent to:\n\ntemp = [] for item in iterable: if condition:\n\ntemp.append(expression)\n\nNormally, the expression will either be or involve the item. Of course, the list comprehension does not need the temp variable needed by the for … in loop version.\n\nNow we can rewrite the code to generate the leaps list using a list comprehen- sion. We will developthe codein threestages. First we will generatea list that has all the years in the given range:\n\nleaps = [y for y in range(1900, 1940)]\n\nThis could also be done using leaps = list(range(1900, 1940)). Now we’ll add a simple condition to get every fourth year:\n\nleaps = [y for y in range(1900, 1940) if y % 4 == 0]\n\nFinally, we have the complete version:\n\nleaps = [y for y in range(1900, 1940)\n\nif (y % 4 == 0 and y % 100 != 0) or (y % 400 == 0)]\n\nrange() ➤ 141\n\n120\n\nChapter 3. Collection Data Types\n\nUsing a list comprehension in this case reduced the code from four lines to two—a small savings, but one that can add up quite a lot in large projects.\n\nSince list comprehensions produce lists,that is, iterables,and since the syntax for list comprehensions requires an iterable, it is possible to nest list compre- hensions. This is the equivalent of having nested for …in loops. For example, if we wanted to generate all the possible clothing label codes for given sets of sexes, sizes, and colors, but excluding labels for the full-ﬁgured females whom the fashion industry routinely ignores, we could do so using nested for … in loops:\n\ncodes = [] for sex in \"MF\":\n\nfor size in \"SMLX\":\n\n# Male, Female # Small, Medium, Large, eXtra large\n\nif sex == \"F\" and size == \"X\":\n\ncontinue\n\nfor color in \"BGW\": # Black, Gray, White codes.append(sex + size + color)\n\nThis producesthe 21item list, ['MSB', 'MSG', …, 'FLW'].The same thing can be achieved in just a couple of lines using a list comprehension:\n\ncodes = [s + z + c for s in\"MF\" for z in \"SMLX\" for c in \"BGW\"\n\nif not (s == \"F\" and z == \"X\")]\n\nHere,each item in the list is produced by the expression s + z + c.Also,we have used subtly different logic for the list comprehension where we skip invalid sex/size combinationsin the innermost loop,whereasthe nested for …in loops version skips invalid combinations in its middle loop. Any list comprehension can be rewritten using one or more for … in loops.\n\nIf thegeneratedlist isvery large,it may bemoreefﬁcient to generateeach item as it is needed rather than produce the whole list at once. Thiscan be achieved by using a generator rather than a list comprehension. We discuss this later, in Chapter 8.\n\nSet Types\n\nA set type is a collection data type that supportsthe membership operator (in), the size function (len()), and is iterable. In addition, set types at least provide a set.isdisjoint() method, and support for comparisons, as well as support for the bitwise operators (which in the context of sets are used for union, intersection,etc.).Python provides two built-in set types:the mutable set type and the immutable frozenset. When iterated, set types provide their items in an arbitrary order.\n\n|||\n\nGenera- tors ➤ 341\n\nSet Types\n\nOnly hashable objects may be added to a set. Hashable objects are objects which have a __hash__() special method whose return value is alwaysthe same throughout the object’slifetime,and which can be compared for equality using the __eq__() special method. (Special methods—methods whose name begins and ends with two underscores—are covered in Chapter 6.)\n\nAll the built-in immutable data types, such as float, frozenset, int, str, and tuple, are hashable and can be added to sets. The built-in mutable data types, such as dict, list, and set, are not hashable since their hash value changes depending on the items they contain, so they cannot be added to sets.\n\nSet types can be compared using the standard comparison operators (<, <=, ==, !=, >=, >). Note that although == and != have their usual meanings, with the comparisonsbeing applied item by item (and recursively for nested itemssuch as tuples or frozen sets inside sets), the other comparison operators perform subset and superset comparisons, as we will see shortly.\n\nSets\n\nA set is an unordered collection of zero or more object references that refer to hashable objects. Sets are mutable, so we can easily add or remove items, but since they are unordered they have no notion of index position and so cannot be sliced or strided. Figure 3.3 illustrates the set created by the following code snippet:\n\nS = {7, \"veil\", 0, -29, (\"x\", 11), \"sun\", frozenset({8, 4, 7}), 913}\n\n29\n\n913\n\nfrozenset({8, 4, 7})\n\n'veil'\n\n('x', 11)\n\n0\n\n'sun'\n\n7\n\nFigure 3.3 A set is an unordered collection of unique items.\n\narguments it The set data type can be called as a function, set()—with no returns an empty set, with a set argument it returns a shallow copy of the argument,and with any other argument it attemptsto convert thegiven object to a set. It does not accept more than one argument. Nonempty sets can also be created without using the set() function,but the empty set must be created\n\n121\n\n||\n\nShallow and deep copying ➤ 146\n\nSet Types\n\nTable 3.2 Set Methods and Operators\n\nSyntax\n\nDescription\n\ns.add(x)\n\nAdds item x to set s if it is not already in s\n\ns.clear()\n\ns.copy()\n\nRemoves all the items from set s ❄ s\n\nReturns a shallow copy of set\n\ns.difference(t) s - t\n\ns.difference_update(t) s -= t s.discard(x)\n\ns.intersection(t) s & t\n\ns.intersection_update(t) s &= t\n\ns.isdisjoint(t)\n\ns.issubset(t) s <= t\n\ns.issuperset(t) s >= t\n\ns.pop()\n\nReturns a new set that has every item that is in set s that is not in set t❄ Removes every item that is in set t from set s\n\nRemoves item x from set s if it is in s; see also set.remove() Returns a new set that has each item that is in both set s and set Makes set s contain the intersection of itself and set t Returns True if sets s and t have no items in ❄ common ReturnsTrue if set s isequal to or a subset of set t; use s < t to test whether s is a proper subset of ❄ t Returns True if set s is equal to or a superset of set t; use s > t to test whether s is a proper superset of ❄ t Returns and removes a random item from set s, or raises a KeyError exception if s is empty\n\n❄ t\n\ns.remove(x)\n\nRemoves item x from set s, or raises a KeyError exception if x is not in s; see also set.discard()\n\ns.symmetric_ difference(t) s ^ t\n\nReturns a new set that has every item that is in set s and every item that is in set t, but exclud- ing items that are in both\n\n❄ sets\n\ns.symmetric_ difference_update(t) s ^= t s.union(t) s | t\n\ns.update(t) s |= t\n\nMakes set s contain the symmetric difference of itself and set t\n\nReturns a new set that has all the items in set s ❄ and all the items in set t that are not in set s Adds every item in set t that is not in set s, to set s\n\n❄This method and its operator (if it has one) can also be used with frozensets.\n\n123\n\nShallow and deep copying ➤ 146\n\n124\n\nChapter 3. Collection Data Types\n\nprocessing,once for each unique address. Assuming that the IP addresses are hashable and are in iterable ips, and that the function we want called for each one is called process_ip() and is already deﬁned, the following code snippets will do what we want, although with subtly different behavior:\n\nseen = set() for ip in ips:\n\nif ip not in seen:\n\nseen.add(ip) process_ip(ip)\n\nfor ip in set(ips):\n\nprocess_ip(ip)\n\nFor the left-hand snippet,if we haven’t processedthe IP addressbefore,we add it tothe seen setandprocessit;otherwise,weignoreit. For theright-handsnip- pet, we only ever get each unique IP address to process in the ﬁrst place. The differencesbetween thesnippetsareﬁrst that theleft-hand snippet createsthe seen set which the right-hand snippet doesn’t need, and second that the left- hand snippet processes the IP addresses in the order they are encountered in the ips iterable while the right-hand snippet processes them in an arbitrary order.\n\nThe right-hand approach is easier to code, but if the ordering of the ips iterable is important we must either use the left-hand approach or change the right-hand snippet’s ﬁrst line to something like for ip in sorted(set(ips)): if this is sufﬁcient to get the required order. In theory the right-hand approach might be slower if the number of items in ips is very large, since it creates the set in one go rather than incrementally.\n\nSets are also used to eliminate unwanted items. For example,if we have a list of ﬁlenames but don’t want any makeﬁles included (perhaps because they are generated rather than handwritten), we might write:\n\nfilenames = set(filenames) for makefile in {\"MAKEFILE\", \"Makefile\", \"makefile\"}:\n\nfilenames.discard(makefile)\n\nThis code will remove any makeﬁle that is in the list using any of the standard capitalizations. It will do nothing if no makeﬁle is in the ﬁlenames list. The same thing can be achieved in one line using the set difference (-) operator:\n\nfilenames = set(filenames) - {\"MAKEFILE\", \"Makefile\", \"makefile\"}\n\nWe can also use set.remove() to remove items, although this method raises a KeyError exception if the item it is asked to remove is not in the set.\n\nSet Types\n\nSet Comprehensions\n\nIn additiontocreating setsby calling set(),or by using a set literal,wecanalso createsetsusing setcomprehensions.A set comprehensionisan expressionand a loop with an optional condition enclosed in braces. Like list comprehensions, two syntaxes are supported:\n\n{expression for item in iterable} {expression for item in iterable if condition}\n\nWe can use these to achieve a ﬁltering effect (providing the order doesn’t matter).Here is an example:\n\nhtml = {x for x in files if x.lower().endswith((\".htm\", \".html\"))}\n\nGiven a list of ﬁlenames in files, this set comprehension makes the set html hold only those ﬁlenames that end in .htm or .html, regardless of case.\n\nJust like list comprehensions, the iterable used in a set comprehension can itself be a set comprehension (or any other kind of comprehension), so quite sophisticated set comprehensions can be created.\n\nFrozen Sets\n\nA frozen set is a set that, once created, cannot be changed. We can of course rebindthevariablethat referstoa frozen set torefer tosomething else,though. Frozen sets can only be created using the frozenset data type called as a function. With no arguments, frozenset() returns an empty frozen set, with a frozenset argument it returns a shallow copy of the argument, and with any other argument it attempts to convert the given object to a frozenset. It does not accept more than one argument.\n\nSince frozen sets are immutable, they support only those methods and oper- ators that produce a result without affecting the frozen set or sets to which they are applied. Table 3.2 (123 ➤) lists all the set methods—frozen sets sup- port frozenset.copy(), frozenset.difference() (-), frozenset.intersection() (&), frozenset.isdisjoint(), frozenset.issubset() (<=; also < for proper subsets), frozenset.issuperset() (>=; also > for proper supersets), frozenset.union() (|), and frozenset.symmetric_difference() (^), all of which are indicated by a in the table.\n\nIf a binary operator is used with a set and a frozen set, the data type of the result is the same as the left-hand operand’s data type. So if f is a frozen set and s is a set, f & s will produce a frozen set and s & f will produce a set. In the case of the == and != operators, the order of the operands does not matter, and f == s will produce True if both sets contain the same items.\n\n125\n\n|\n\n||\n\n❄\n\nShallow and deep copying ➤ 146",
      "page_number": 120
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 129-138)",
      "start_page": 129,
      "end_page": 138,
      "detection_method": "topic_boundary",
      "content": "Hash- able objects 121➤\n\n126\n\nChapter 3. Collection Data Types\n\nAnother consequence of the immutability of frozen sets is that they meet the hashable criterion for set items, so sets and frozen sets can contain frozen sets.\n\nWe will see more examples of set use in the next section, and also in the chapter’s Examples section.\n\nMapping Types\n\nA mapping type is one that supports the membership operator (in) and the size function (len()), and is iterable. Mappings are collections of key–value items and provide methods for accessing items and their keys and values. When iterated, unordered mapping types provide their items in an arbitrary order. Python 3.0 provides two unordered mapping types, the built-in dict type and the standard library’s collections.defaultdict type. A new, ordered mapping type,collections.OrderedDict,wasintroduced with Python 3.1;thisis a dictionary that has the same methods and properties (i.e., the same API) as the built-in dict, but stores its items in insertion order.★ We will use the term dictionary to refer to any of these types when the difference doesn’t matter.\n\nOnly hashableobjectsmay beused asdictionary keys,soimmutable data types such as float, frozenset, int, str, and tuple can be used as dictionary keys, but mutable typessuch as dict,list,and set cannot. On the other hand,each key’s associated value can be an object reference referring to an object of any type, including numbers, strings, lists, sets, dictionaries, functions, and so on.\n\nDictionary types can be compared using the standard equality comparison op- erators(== and !=),withthecomparisonsbeing applieditemby item(andrecur- sively for nested items such as tuples or dictionariesinside dictionaries).Com- parisons using the other comparison operators (<, <=, >=, >) are not supported since they don’t make sense for unordered collections such as dictionaries.\n\nDictionaries\n\nA dict is an unordered collection of zero or more key–value pairs whose keys are object referencesthat refer to hashableobjects,and whosevaluesareobject referencesreferring to objectsof any type. Dictionariesare mutable,so we can easily add or remove items, but since they are unordered they have no notion of index position and so cannot be sliced or strided.\n\n★API stands for Application Programming Interface, a generic term used to refer to the public methods and propertiesthat classes provide,and to the parametersand return valuesof functions and methods. For example, Python’s documentation documents the APIs that Python provides.\n\n|||\n\n||\n\n3.x\n\nMapping Types\n\nThe dict data type can be called as a function, dict()—with no arguments it returns an empty dictionary, and with a mapping argument it returns a dic- tionary based on the argument; for example, returning a shallow copy if the argument is a dictionary. It is also possible to use a sequence argument, pro- viding that each item in the sequence is itself a sequence of two objects, the ﬁrst of which is used as a key and the second of which is used as a value. Alternatively,for dictionarieswhere the keysare valid Python identiﬁers,key- word argumentscan be used,with the key as the keyword and the value as the key’s value. Dictionaries can also be created using braces—empty braces, {}, createanemptydictionary;nonemptybracesmustcontainoneormorecomma- items, each of which consists of a key, a literal colon, and a value. separated Another way of creating dictionaries is to use a dictionary comprehension—a topic we will cover later in this subsection.\n\nHere are some examples to illustrate the various syntaxes—they all produce the same dictionary:\n\nd1 = dict({\"id\": 1948, \"name\": \"Washer\", \"size\": 3}) d2 = dict(id=1948, name=\"Washer\", size=3) d3 = dict([(\"id\", 1948), (\"name\", \"Washer\"), (\"size\", 3)]) d4 = dict(zip((\"id\", \"name\", \"size\"), (1948, \"Washer\", 3))) d5 = {\"id\": 1948, \"name\": \"Washer\", \"size\": 3}\n\nDictionary d1 is created using a dictionary literal. Dictionary d2 is created us- ing keyword arguments. Dictionaries d3 and d4 are created from sequences, and dictionary d5 is created from a dictionary literal. The built-in zip() func- tionthatisusedtocreatedictionary d4 returnsa listof tuples,theﬁrstof which hastheﬁrstitemsof eachof the zip() function’siterablearguments,thesecond of which hasthe second items,and so on. The keyword argument syntax (used to create dictionary d2) is usually the most compact and convenient, providing the keys are valid identiﬁers.\n\nFigure 3.5 illustrates the dictionary created by the following code snippet:\n\nd = {\"root\": 18, \"blue\": [75, \"R\", 2], 21: \"venus\", -14: None,\n\n\"mars\": \"rover\", (4, 11): 18, 0: 45}\n\nDictionary keys are unique, so if we add a key–value item whose key is the same as an existing key,the effect is to replace that key’s value with a new val- ue. Brackets are used to access individual values—for example, d[\"root\"] re- turns 18,d[21] returnsthestring \"venus\",and d[91] causesa KeyError exception to be raised, given the dictionary shown in Figure 3.5.\n\nBrackets can also be used to add and delete dictionary items. To add an item we use the = operator, for example, d[\"X\"] = 59. And to delete an item we use the del statement—for example, del d[\"mars\"] will delete the item whose key is “mars” from the dictionary, or raise a KeyError exception if no item has that\n\n127\n\nShallow and deep copying ➤ 146\n\nKey- word argu- ments ➤ 174\n\nDic- tionary compre- hen- sions ➤ 134\n\nzip() ➤ 143\n\n128\n\nChapter 3. Collection Data Types\n\n'mars'\n\n21\n\n(4, 11)\n\n18\n\n'rover'\n\n'venus'\n\n0\n\n'blue'\n\n14\n\n45\n\n[75, 'R', 2]\n\n'root'\n\nNone\n\n18\n\nFigure 3.5 A dictionary is an unsorted collection of (key,value) items with unique keys.\n\nkey. Items can also be removed (and returned) from the dictionary using the dict.pop() method.\n\nDictionaries support the built-in len() function, and for their keys, fast membershiptesting with in and not in.All the dictionary methodsare listed in Table 3.3.\n\nBecause dictionaries have both keys and values,we might want to iterate over a dictionary by (key, value) items, by values, or by keys. For example, here are two equivalent approaches to iterating by (key, value) pairs:\n\nfor item in d.items():\n\nfor key, value in d.items():\n\nprint(item[0], item[1])\n\nprint(key, value)\n\nIterating over a dictionary’s values is very similar:\n\nfor value in d.values():\n\nprint(value)\n\nTo iterate over a dictionary’s keys we can use dict.keys(), or we can simply treat the dictionary as an iterable that iterates over its keys, as these two equivalent code snippets illustrate:\n\nfor key in d:\n\nfor key in d.keys():\n\nprint(key)\n\nprint(key)\n\nIf we want to change the values in a dictionary, the idiom to use is to iterate over the keys and change the values using the bracketsoperator. For example, here is how we would increment every value in dictionary d, assuming that all the values are numbers:\n\nfor key in d:\n\nd[key] += 1\n\nMapping Types\n\nTable 3.3 Dictionary Methods\n\nSyntax\n\nDescription\n\nd.clear()\n\nRemoves all items from dict d\n\nd.copy()\n\nReturns a shallow copy of dict d\n\nd.fromkeys(\n\ns, v)\n\nReturns a dict whose keys are the items in sequence s and whose values are None or v if v is given\n\nd.get(k)\n\nReturns key k’s associated value, or None if k isn’t in dict d\n\nd.get(k, v)\n\nd.items()\n\nReturns key k’s associated value, or v if k isn’t in dict d Returns a view★ of all the (key, value) pairs in dict d\n\nd.keys()\n\nReturns a view\n\n★\n\nof all the keys in dict d\n\nd.pop(k)\n\nReturns key k’s associated value and removes the item whose key is k, or raises a KeyError exception if k isn’t in d\n\nd.pop(k, v)\n\nReturns key k’s associated value and removes the item whose key is k, or returns v if k isn’t in dict d\n\nd.popitem()\n\nReturns and removes an arbitrary (key, value) pair from dict d, or raises a KeyError exception if d is empty\n\nd.setdefault( k, v)\n\nThe same as the dict.get() method,except that if the key is not in dict d,a new item is inserted with the key k,and with a value of None or of v if v is given\n\nd.update(a)\n\nAdds every (key, value) pair from a that isn’t in dict d to d, and for every key that is in both d and a, replaces the corre- sponding value in d with the one in a—a can be a dictionary, an iterable of (key, value) pairs, or keyword arguments\n\nd.values()\n\nReturns a view\n\n★\n\nof all the values in dict d\n\nThe dict.items(), dict.keys(), and dict.values() methods all return dictionary views. A dictionary view is effectively a read-only iterable object that appears to hold the dictionary’sitems or keys or values,depending on the view we have asked for.\n\nIn general, we can simply treat views as iterables. However, two things make a view different from a normal iterable. One is that if the dictionary the view refers to is changed, the view reﬂects the change. The other is that key and item views support some set-like operations. Given dictionary view v and set or dictionary view x, the supported operations are:\n\nv & x v | x\n\n# Intersection # Union\n\n★Dictionary views can be thought of—and used as—iterables; they are discussed in the text.\n\n129\n\nShallow and deep copying ➤ 146\n\n130\n\nChapter 3. Collection Data Types\n\nv - x v ^ x\n\n# Difference # Symmetric difference\n\nWe can use the membership operator, in, to see whether a particular key is in a dictionary,for example,x in d.And we can use the intersection operator to see which keys from a given set are in a dictionary. For example:\n\nd = {}.fromkeys(\"ABCD\", 3) # d == {'A': 3, 'B': 3, 'C': 3, 'D': 3} s = set(\"ACX\") matches = d.keys() & s\n\n# s == {'A', 'C', 'X'} # matches == {'A', 'C'}\n\nNote that in the snippet’s comments we have used alphabetical order—this is purely for ease of reading since dictionaries and sets are unordered.\n\nDictionaries are often used to keep counts of unique items. One such example of this is counting the number of occurrences of each unique word in a ﬁle. Here is a complete program (uniquewords1.py) that lists every word and the number of times it occurs in alphabetical order for all the ﬁles listed on the command line:\n\nimport string import sys\n\nwords = {} strip = string.whitespace + string.punctuation + string.digits + \"\\\"'\" for filename in sys.argv[1:]:\n\nfor line in open(filename):\n\nfor word in line.lower().split(): word = word.strip(strip) if len(word) > 2:\n\nwords[word] = words.get(word, 0) + 1\n\nfor word in sorted(words):\n\nprint(\"'{0}' occurs {1} times\".format(word, words[word]))\n\nWe begin by creating an empty dictionary called words.Then we create a string that contains all those characters that we want to ignore, by concatenating some useful strings provided by the string module. We iterate over each ﬁle- name given on the command line, and over each line in each ﬁle. See the side- bar “Reading and Writing Text Files” (➤ 131) for an explanation of the open() function. We don’t specify an encoding (because we don’t know what each ﬁle’s encoding will be),so we let Python open each ﬁle using the default local encod- ing. We split each lowercased line into words,and then strip off the characters that we want to ignore from both ends of each word. If the resultant word is at least three characters long we need to update the dictionary.\n\nWe cannot use the syntax words[word] += 1 because this will raise a KeyError exception the ﬁrst time a new word is encountered—after all, we can’t incre- ment the value of an item that does not yet exist in the dictionary. So we use\n\nChar- acter encod- ings 91➤\n\nMapping Types\n\nReading and Writing Text Files\n\nFiles are opened using the built-in open() function, which returns a “ﬁle object” (of type io.TextIOWrapper for text ﬁles).The open() function takesone mandatory argument—the ﬁlename, which may include a path—and up to six optional arguments, two of which we brieﬂy cover here. The second argumentisthemode—thisisused tospecify whether theﬁleistobetreated as a text ﬁle or as a binary ﬁle, and whether the ﬁle is to be opened for reading, writing, appending, or a combination of these.\n\nFor text ﬁles, Python uses an encoding that is platform-dependent. Where possible it is best to specify the encoding using open()’s encoding argument, so the syntaxes we normally use for opening ﬁles are these:\n\nfin = open(filename, encoding=\"utf8\") # for reading text fout = open(filename, \"w\", encoding=\"utf8\") # for writing text\n\nBecause open()’smodedefaultsto“readtext”,andby using a keywordrather thana positionalargumentfor the encoding argument,wecanomit theother optional positional arguments when opening for reading. And similarly, when opening to write we need to give only the argumentswe actually want to use. (Argument passing is covered in depth in Chapter 4.)\n\nOnce a ﬁle isopened for reading in text mode,we can read the whole ﬁle into a single string using the ﬁle object’s read() method, or into a list of strings using the ﬁle object’s readlines() method. A very common idiom for reading line by line is to treat the ﬁle object as an iterator:\n\nfor line in open(filename, encoding=\"utf8\"):\n\nprocess(line)\n\nThis works because a ﬁle object can be iterated over, just like a sequence, with each successive item being a string containing the next line from the ﬁle. The lines we get back include the line termination character, \\n.\n\nIf we specify a mode of “w”,the ﬁle is opened in “write text” mode. We write to a ﬁle using the ﬁle object’s write() method, which takes a single string as its argument. Each line written should end with a \\n.Python automatically translates between \\n and the underlying platform’s line termination characters when reading and writing.\n\nOncewehaveﬁnishedusing a ﬁleobjectwecancallitsclose() method—this will cause any outstanding writes to be ﬂushed. In small Python programs it is very common not to bother calling close(), since Python does this automatically when the ﬁle object goes out of scope. If a problem occurs, it will be indicated by an exception being raised.\n\n131\n\nChap- ter 7 (File Han- dling) ➤ 287\n\n132\n\nChapter 3. Collection Data Types\n\na subtler approach. We call dict.get() with a default value of 0. If the word is already in the dictionary, dict.get() will return the associated number, and this value plus 1 will be set as the item’s new value. If the word is not in the dictionary, dict.get() will return the supplied default of 0, and this value plus 1 (i.e., 1) will be set as the value of a new item whose key is the string held by word.To clarify,here are two code snippetsthat do the same thing,although the code using dict.get() is more efﬁcient:\n\nif word not in words:\n\nwords[word] = 0\n\nwords[word] = words.get(word, 0) + 1\n\nwords[word] += 1\n\nIn the next subsection where we cover default dictionaries, we will see an alternative solution.\n\nOnce we have accumulated the dictionary of words, we iterate over its keys (the words) in sorted order, and print each word and the number of times it occurs.\n\nUsing dict.get() allows us to easily update dictionary values, providing the valuesaresingleitemslike numbersor strings. But what if each value isitself a collection? To demonstrate how to handle this we will look at a program that reads HTML ﬁles given on the command line and prints a list of each unique Web site that is referred to in the ﬁles with a list of the referring ﬁles listed indented below the name of each Web site. Structurally, the program (external_sites.py) is very similar to the unique words program we have just reviewed. Here is the main part of the code:\n\nsites = {} for filename in sys.argv[1:]:\n\nfor line in open(filename):\n\ni = 0 while True:\n\nsite = None i = line.find(\"http://\", i) if i > -1:\n\ni += len(\"http://\") for j in range(i, len(line)):\n\nif not (line[j].isalnum() or line[j] in \".-\"):\n\nsite = line[i:j].lower() break\n\nif site and \".\" in site:\n\nsites.setdefault(site, set()).add(filename)\n\ni = j\n\nelse:\n\nbreak\n\nMapping Types\n\nWe begin by creating an empty dictionary. Then we iterate over each ﬁle listed on the command line and each line within each ﬁle. We must account for the fact that each line may refer to any number of Web sites,which is why we keep calling str.find() until it fails. If we ﬁnd the string “http://”, we increment i (our starting index position)by the length of “http://”,and then we look at each succeeding character until we reach one that isn’t valid for a Web site’s name. If we ﬁnd a site (and as a simply sanity check, only if it contains a period), we add it to the dictionary.\n\nWe cannot use the syntax sites[site].add(filename) because this will raise a KeyError exception the ﬁrst time a new site is encountered—after all, we can’t add to a set that is the value of an item that doesnot yet exist in the dictionary. Sowemustusea differentapproach. The dict.setdefault() methodreturnsan object reference to the item in the dictionary that has the given key (the ﬁrst argument). If there is no such item, the method creates a new item with the key and sets its value either to None, or to the given default value (the second argument).In this case we pass a default value of set(), that is, an empty set. So the call to dict.setdefault() always returns an object reference to a value, either one that existed before or a new one. (Of course, if the given key is not hashable a TypeError exception will be raised.)\n\nIn this example, the returned object reference always refers to a set (an empty set the ﬁrst time any particular key, that is, site, is encountered), and we then add the ﬁlename that refers to the site to the site’s set of ﬁlenames. By using a set we ensure that even if a ﬁle refers to a site repeatedly, we record the ﬁlename only once for the site.\n\nTo make the dict.setdefault() method’s functionality clear, here are two equivalent code snippets:\n\nif site not in sites:\n\nsites[site] = set()\n\nsites.setdefault(site, set()).add(fname)\n\nsites[site].add(fname)\n\nFor the sake of completeness, here is the rest of the program:\n\nfor site in sorted(sites):\n\nprint(\"{0} is referred to in:\".format(site)) for filename in sorted(sites[site], key=str.lower): {0}\".format(filename))\n\nprint(\"\n\nunder- Each Web site is printed with the ﬁles that refer to it printed indented neath. The sorted() call in the outer for … in loop sorts all the dictionary’s keys—whenever a dictionary is used in a context that requires an iterable it is the keys that are used. If we want the iterable to be the (key, value) items or the values, we can use dict.items() or dict.values(). The inner for … in loop iterates over the sorted ﬁlenames from the current site’s set of ﬁlenames.\n\n133\n\nsorted() ➤ 140, 144\n\nUs- ing str. format() with map- ping un- packing 81➤\n\n134\n\nChapter 3. Collection Data Types\n\nAlthough a dictionary of web sites is likely to contain a lot of items, many other dictionaries have only a few items. For small dictionaries, we can print their contents using their keys as ﬁeld names and using mapping unpacking to convert the dictionary’s key–value items into key–value arguments for the str.format() method.\n\n>>> greens = dict(green=\"#0080000\", olive=\"#808000\", lime=\"#00FF00\") >>> print(\"{green} {olive} {lime}\".format(**greens)) #0080000 #808000 #00FF00\n\nHere, using mapping unpacking (**) has exactly the same effect as writing .format(green=greens.green, olive=greens.olive, lime=greens.lime), but is eas- ier to write and arguably clearer. Note that it doesn’t matter if the dictionary has more keys than we need, since only those keys whose names appear in the format string are used.\n\nDictionary Comprehensions\n\nA dictionary comprehension is an expression and a loop with an optional condition enclosed in braces,very similar to a set comprehension. Likelist and set comprehensions, two syntaxes are supported:\n\n{keyexpression: valueexpression for key, value in iterable} {keyexpression: valueexpression for key, value in iterable if condition}\n\nHere is how we could use a dictionary comprehension to create a dictionary where each key is the name of a ﬁle in the current directory and each value is the size of the ﬁle in bytes:\n\nfile_sizes = {name: os.path.getsize(name) for name in os.listdir(\".\")}\n\nThe os (“operating system”) module’s os.listdir() function returns a list of the ﬁles and directories in the path it is passed, although it never includes “.” or “..” in the list. The os.path.getsize() function returns the size of the given ﬁle in bytes. We can avoid directoriesand other nonﬁle entriesby adding a condition:\n\nfile_sizes = {name: os.path.getsize(name) for name in os.listdir(\".\")\n\nif os.path.isfile(name)}\n\nThe os.path module’s os.path.isfile() function returns True if the path passed to it is that of a ﬁle, and False otherwise—that is, for directories, links, and so on.\n\nA dictionary comprehension can also be used to create an inverted dictionary. For example, given dictionary d, we can produce a new dictionary whose keys are d’s values and whose values are d’s keys:\n\n|\n\nMap- ping unpack- ing ➤ 177\n\nos and os.path modules ➤ 224\n\nunique- words1. py 130➤\n\nMapping Types\n\ninverted_d = {v: k for k, v in d.items()}\n\nThe resultant dictionary can be inverted back to the original dictionary if all the original dictionary’s values are unique—but the inversion will fail with a TypeError being raised if any value is not hashable.\n\nJust like list and set comprehensions, the iterable in a dictionary comprehen- sion can be another comprehension,so all kinds of nested comprehensions are possible.\n\nDefault Dictionaries\n\nDefault dictionariesare dictionaries—they have all the operatorsand methods that dictionaries provide. What makes default dictionaries different from plain dictionaries is the way they handle missing keys; in all other respects they behave identically to dictionaries. (In object-oriented terms, defaultdict is a subclass of dict; object-oriented programming, including subclassing, is covered in Chapter 6.)\n\nIf we use a nonexistent (“missing”)key when accessing a dictionary,a KeyError is raised. This is useful because we often want to know whether a key that we expected to be present is absent. But in some cases we want every key we use to be present, even if it means that an item with the key is inserted into the dictionary at the time we ﬁrst access it.\n\nFor example, if we have a dictionary d which does not have an item with key m, the code x = d[m] will raise a KeyError exception. But if d is a suitably created default dictionary,if an item with key m is in the default dictionary,the corresponding value is returned the same as for a dictionary—but if m is not a key in the default dictionary, a new item with key m is created with a default value, and the newly created item’s value is returned.\n\nEarlier we wrote a small program that counted the unique words in the ﬁles it was given on the command line. The dictionary of words was created like this:\n\nwords = {}\n\nEach key in the words dictionary was a word and each value an integer holding the number of times the word had occurred in all the ﬁles that were read. Here’s how we incremented whenever a suitable word was encountered:\n\nwords[word] = words.get(word, 0) + 1\n\nWe had to use dict.get() to account for when the word was encountered the ﬁrst time (where we needed to create a new item with a count of 1) and for when thewordwasencounteredsubsequently (whereweneeded toadd 1tothe word’s existing count).\n\n135\n\n||",
      "page_number": 129
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 139-146)",
      "start_page": 139,
      "end_page": 146,
      "detection_method": "topic_boundary",
      "content": "136\n\nChapter 3. Collection Data Types\n\nWhenadefaultdictionaryiscreated,wecanpassina factoryfunction.A factory function is a function that, when called, returns an object of a particular type. All of Python’sbuilt-in data typescan beused asfactory functions,for example, data type str can be called as str()—and with no argument it returns an emp- ty string object. The factory function passed to a default dictionary is used to create default values for missing keys.\n\nNote that the name of a function is an object reference to the function—so when we want to pass functions as parameters, we just pass the name. When we use a function with parentheses, the parentheses tell Python that the function should be called.\n\nThe program uniquewords2.py has one more line than the original unique- words1.py program(import collections),and the linesfor creating and updating the dictionary are written differently. Here is how the default dictionary is created:\n\nwords = collections.defaultdict(int)\n\nThe words default dictionary will never raise a KeyError. If we were to write x = words[\"xyz\"] and there was no item with key \"xyz\", when the access is attempted and the key isn’t found, the default dictionary will immediately create a new item with key \"xyz\" and value 0 (by calling int()), and this value is what will be assigned to x.\n\nwords[word] += 1\n\nNow we no longer need to use dict.get(); instead we can simply increment the item’s value. The very ﬁrst time a word is encountered, a new item is created with value 0 (to which 1 is immediately added), and on every subsequent access, 1 is added to whatever the current value happens to be.\n\nWe have now completed our review of all of Python’s built-in collection data types, and a couple of the standard library’s collection data types. In the next section we will look at some issuesthat are common to all of the collection data types.\n\nOrdered Dictionaries\n\nThe ordered dictionaries type—collections.OrderedDict—was introduced with Python 3.1 in fulﬁllment of PEP 372. Ordered dictionaries can be used as drop-in replacements for unordered dicts because they provide the same API. The difference between the two is that ordered dictionariesstore their itemsin the order in which they were inserted—a feature that can be very convenient.\n\nNote that if an ordered dictionary is passed an unordered dict or keyword ar- gumentswhen it is created,the item order will be arbitrary;this is because un- der the hood Python passes keyword arguments using a standard unordered\n\n||\n\n3.1\n\nMapping Types\n\ndict. A similar effect occurs with the use of the update() method. For these reasons, passing keyword arguments or an unordered dict when creating an ordereddictionaryor using update() ononeisbestavoided. However,if wepass a list or tuple of key–value 2-tuples when creating an ordered dictionary, the ordering is preserved (since they are passed as a single item—a list or tuple).\n\nHere’s how to create an ordered dictionary using a list of 2-tuples:\n\nd = collections.OrderedDict([('z', -4), ('e', 19), ('k', 7)])\n\nBecause we used a single list as argument the key ordering is preserved. It is probably more common to create ordered dictionaries incrementally, like this:\n\ntasks = collections.OrderedDict() tasks[8031] = \"Backup\" tasks[4027] = \"Scan Email\" tasks[5733] = \"Build System\"\n\nIf we had created unordered dicts the same way and asked for their keys, the order of the returned keys would be arbitrary. But for ordered dictionaries,we can rely on the keys to be returned in the same order they were inserted. So for theseexamples,if wewrote list(d.keys()),weareguaranteedtoget thelist ['z', 'e', 'k'], and if we wrote list(tasks.keys()), we are guaranteed to get the list [8031, 4027, 5733].\n\nOne other nice feature of ordered dictionaries is that if we change an item’s value—that is, if we insert an item with the same key as an existing key—the order is not changed. So if we did tasks[8031] = \"Daily backup\", and then asked for the list of keys,we would get exactly the same list in exactly the same order as before.\n\nIf we want to move an item to the end, we must delete it and then reinsert it. We can also call popitem() to remove and return the last key–value item in the ordered dictionary; or we can call popitem(last=False), in which case the ﬁrst item will be removed and returned.\n\nAnother, slightly more specialized use for ordered dictionaries is to produce sorted dictionaries. Given a dictionary, d, we can convert it into a sorted dictionary like this:d = collections.OrderedDict(sorted(d.items())).Note that if we were to insert any additional keys they would be inserted at the end, so after any insertion,to preservethe sorted order,we would have to re-createthe dictionary by executing the same code we used to create it in the ﬁrst place. Doing insertions and re-creating isn’t quite as inefﬁcient as it sounds, since Python’s sorting algorithm is highly optimized, especially for partially sorted data, but it is still potentially expensive.\n\nIn general, using an ordered dictionary to produce a sorted dictionary makes sense only if we expect to iterate over the dictionary multiple times, and if we do not expect to do any insertions (or very few), once the sorted dictionary has\n\n137\n\n3.1\n\n138\n\nChapter 3. Collection Data Types\n\nbeen created. ly maintains its keys in sorted order is presented in Chapter 6; ➤ 276.)\n\n(An implementationof a real sorted dictionary that automatical-\n\nIterating and Copying Collections\n\nOnce we have collections of data items, it is natural to want to iterate over all the itemsthey contain. In thissection’sﬁrst subsection we will introducesome of Python’s iterators and the operators and functions that involve iterators.\n\nAnother commonrequirementistocopy a collection. Therearesomesubtleties involved here because of Python’s use of object references (for the sake of efﬁciency), so in this section’s second subsection, we will examine how to copy collections and get the behavior we want.\n\nIterators and Iterable Operations and Functions\n\nAn iterabledata typeisone that can return each of itsitemsone at a time. Any object that hasan __iter__() method,or any sequence (i.e.,an object that hasa __getitem__() method taking integer arguments starting from 0) is an iterable and can provide an iterator. An iterator is an object that provides a __next__() method which returns each successive item in turn,and raises a StopIteration exception when there are no more items. Table 3.4 lists the operators and functions that can be used with iterables.\n\nThe order in which items are returned depends on the underlying iterable. In the case of lists and tuples, items are normally returned in sequential order starting from the ﬁrst item (index position 0), but some iterators return the items in an arbitrary order—for example, dictionary and set iterators.\n\nThe built-in iter() function has two quite different behaviors. When given a collection data type or a sequence it returns an iterator for the object it is passed—or raises a TypeError if the object cannot be iterated. This use arises when creating custom collection data types, but is rarely needed in other con- texts. The second iter() behavior occurswhen thefunction ispasseda callable (a function or method),and a sentinel value. In thiscasethefunction passedin iscalled onceat each iteration,returning thefunction’sreturn value each time, or raising a StopIteration exception if the return value equals the sentinel.\n\nWhen we use a for item in iterable loop, Python in effect calls iter(iterable) to get an iterator. This iterator’s __next__() method is then called at each loop iteration to get the next item, and when the StopIteration exception is raised, it is caught and the loop is terminated. Another way to get an iterator’s next item is to call the built-in next() function. Here are two equivalent pieces of code (multiplying the values in a list), one using a for … in loop and the other using an explicit iterator:\n\n|||\n\n||\n\n3.1\n\n__iter- __() ➤ 274\n\nIterating and Copying Collections\n\nproduct = 1 i = iter([1, 2, 4, 8]) while True: try:\n\nproduct = 1 for i in [1, 2, 4, 8]:\n\nproduct *= next(i)\n\nexcept StopIteration:\n\nproduct *= i\n\nbreak\n\nprint(product) # prints: 64\n\nprint(product) # prints: 64\n\nAny (ﬁnite) iterable, i, can be converted into a tuple by calling tuple(i), or can be converted into a list by calling list(i).\n\nThe all() and any() functions can be used on iterators and are often used in functional-styleprogramming. Here are a couple of usage examplesthat show all(), any(), len(), min(), max(), and sum():\n\n>>> x = [-2, 9, 7, -4, 3] >>> all(x), any(x), len(x), min(x), max(x), sum(x) (True, True, 5, -4, 9, 13) >>> x.append(0) >>> all(x), any(x), len(x), min(x), max(x), sum(x) (False, True, 6, -4, 9, 13)\n\nOf these little functions, len() is probably the most frequently used.\n\nThe enumerate() function takes an iterator and returns an enumerator object. This object can be treated like an iterator, and at each iteration it returns a 2-tuple with the tuple’s ﬁrst item the iteration number (by default starting from 0), and the second item the next item from the iterator enumerate() was called on. Let’s look at enumerate()’s use in the context of a tiny but complete program.\n\nThe grepword.py program takes a word and one or more ﬁlenames on the command line and outputs the ﬁlename, line number, and line whenever the line contains the given word.★ Here’s a sample run:\n\ngrepword.py Dom data/forenames.txt data/forenames.txt:615:Dominykas data/forenames.txt:1435:Dominik data/forenames.txt:1611:Domhnall data/forenames.txt:3314:Dominic\n\nData ﬁles data/forenames.txt and data/surnames.txt contain unsorted lists of names, one per line.\n\n★In Chapter 10 will see two other implementations of this program, grepword-p.py and grepword- t.py, which spread the work over multiple processes and multiple threads.\n\n139\n\nFunc- tional- style pro- gram- ming ➤ 395\n\n140\n\nChapter 3. Collection Data Types\n\nTable 3.4 Common Iterable Operators and Functions\n\nSyntax\n\nDescription\n\ns + t\n\ns * n\n\nReturns a sequence that is the concatenation of sequences s and t Returns a sequence that is int n concatenations of sequence s\n\nx in i\n\nall(i)\n\nReturns True if item x is in iterable i; use not in to reverse the test Returns True if every item in iterable i evaluates to True\n\nany(i)\n\nReturns True if any item in iterable i evaluates to True\n\nenumerate(i,\n\nstart)\n\nNormally used in for …in loops to provide a sequence of (in- dex, item) tuples with indexes starting at 0 or start; see text\n\nlen(x)\n\nReturns the “length” of x. If x is a collection it is the number of items; if x is a string it is the number of characters.\n\nmax(i, key) Returns the biggest item in iterable i or the item with the\n\nbiggest key(item) value if a key function is given\n\nmin(i, key) Returns the smallest item in iterable i or the item with the\n\nsmallest key(item) value if a key function is given\n\nrange(\n\nstart, stop, step)\n\nReturns an integer iterator. With one argument (stop), the it- erator goes from 0 to stop - 1; with two arguments (start, stop) the iterator goes from start to stop - 1; with three arguments it goes from start to stop - 1 in steps of step.\n\nreversed(i) Returns an iterator that returns the items from iterator i in\n\nsorted(i,\n\nkey, reverse)\n\nreverse order Returns a list of the items from iterator i in sorted order; key is used to provide DSU (Decorate, Sort, Undecorate) sorting. If reverse is True the sorting is done in reverse order.\n\nsum(i,\n\nstart)\n\nReturns the sum of the items in iterable i plus start (which defaults to 0); i may not contain strings\n\nzip(i1,\n\n..., iN)\n\nReturns an iterator of tuples using the iterators i1 to iN; see text\n\nApart from the sys import, the program is just ten lines long:\n\nif len(sys.argv) < 3:\n\nprint(\"usage: grepword.py word infile1 [infile2 [... infileN]]\") sys.exit()\n\nword = sys.argv[1] for filename in sys.argv[2:]:\n\nfor lino, line in enumerate(open(filename), start=1):\n\nif word in line:\n\nRead- ing and writing text ﬁles sidebar 131➤\n\nIterating and Copying Collections\n\nprint(\"{0}:{1}:{2:.40}\".format(filename, lino, line.rstrip()))\n\nWe begin by checking that there are at least two command-line arguments. If there are not, we print a usage message and terminate the program. The sys.exit()functionperformsanimmediatecleantermination,closinganyopen ﬁles. It accepts an optional int argument which is passed to the calling shell.\n\nWe assume that the ﬁrst argument is the word the user is looking for and that the other argumentsare the namesof the ﬁles to look in. We have deliberately called open() without specifying an encoding—the user might use wildcards to specify any number of ﬁles, each potentially with a different encoding,so in this case we leave Python to use the platform-dependent encoding.\n\nThe ﬁle object returned by the open() function in text mode can be used as an iterator, returning one line of the ﬁle on each iteration. By passing the iter- ator to enumerate(), we get an enumerator iterator that returns the iteration number (in variable lino, “line number”) and a line from the ﬁle, on each itera- tion. If the word the user islooking for isin the line,we print the ﬁlename,line number, and the ﬁrst 40 characters of the line with trailing whitespace (e.g., \\n) stripped. The enumerate() function accepts an optional keyword argument, start,which defaultsto 0;wehave used thisargument set to1,sinceby conven- tion, text ﬁle line numbers are counted from 1.\n\nQuite often we don’t need an enumerator, but rather an iterator that returns successive integers. This is exactly what the range() function provides. If we need a list or tuple of integers,we can convert the iterator returned by range() by using the appropriate conversion function. Here are a few examples:\n\n>>> list(range(5)), list(range(9, 14)), tuple(range(10, -11, -5)) ([0, 1, 2, 3, 4], [9, 10, 11, 12, 13], (10, 5, 0, -5, -10))\n\nThe range() function is most commonly used for two purposes:to create lists or tuples of integers,and to provide loop counting in for …in loops. For example, these two equivalent examples ensure that list x’s items are all non-negative:\n\ni = 0 while i < len(x):\n\nfor i in range(len(x)): x[i] = abs(x[i])\n\nx[i] = abs(x[i]) i += 1\n\nIn both cases, if list x was originally, say, [11, -3, -12, 8, -1], afterward it will be [11, 3, 12, 8, 1].\n\nSince we can unpack an iterable using the * operator, we can unpack the iterator returned by the range() function. For example, if we have a function called calculate() that takesfour arguments,here are some ways we could call it with arguments, 1, 2, 3, and 4:\n\n141\n\nTuple unpack- ing 110➤\n\n142\n\nChapter 3. Collection Data Types\n\ncalculate(1, 2, 3, 4) t = (1, 2, 3, 4) calculate(*t) calculate(*range(1, 5))\n\nInallthreecalls,fourargumentsarepassed. Thesecondcallunpacksa4-tuple, and the third call unpacks the iterator returned by the range() function.\n\nWe will now look at a small but complete program to consolidate some of the things we have covered so far, and for the ﬁrst time to explicitly write to a ﬁle. The generate_test_names1.py program reads in a ﬁle of forenames and a ﬁle of surnames, creating two lists, and then creates the ﬁle test-names1.txt and writes 100 random names into it.\n\nWe will use the random.choice() function which takes a random item from a sequence, so it is possible that some duplicate names might occur. First we’ll look at the function that returns the lists of names, and then we will look at the rest of the program.\n\ndef get_forenames_and_surnames():\n\nforenames = [] surnames = [] for names, filename in ((forenames, \"data/forenames.txt\"),\n\n(surnames, \"data/surnames.txt\")):\n\nfor name in open(filename, encoding=\"utf8\"):\n\nnames.append(name.rstrip())\n\nreturn forenames, surnames\n\nIn the outer for …in loop,we iterate over two 2-tuples, unpacking each 2-tuple into two variables. Even though the two lists might be quite large, returning them from a function is efﬁcient because Python uses object references, so the only thing that is really returned is a tuple of two object references.\n\nInside Python programs it is convenient to always use Unix-style paths, since they canbetypedwithouttheneedfor escaping,andthey work on allplatforms (including Windows). If we have a path we want to present to the user in, say, variable path, we can always import the os module and call path.replace(\"/\", os.sep) to replace forward slashes with the platform-speciﬁc directory sepa- rator.\n\nforenames, surnames = get_forenames_and_surnames() fh = open(\"test-names1.txt\", \"w\", encoding=\"utf8\") for i in range(100):\n\nline = \"{0} {1}\\n\".format(random.choice(forenames),\n\nrandom.choice(surnames))\n\nfh.write(line)\n\nRead- ing and writing text ﬁles sidebar 131➤\n\nIterating and Copying Collections\n\nHaving retrieved the two lists we open the output ﬁle for writing, and keep the ﬁle object in variable fh (“ﬁle handle”).We then loop 100 times,and in each iteration we create a line to be written to the ﬁle, remembering to include a newline at the end of every line. We make no use of the loop variable i; it is needed purely tosatisfy the for …in loop’ssyntax. Thepreceding codesnippet, the get_forenames_and_surnames() function,and an import statement constitute the entire program.\n\nIn the generate_test_names1.py program we paired items from two separate lists together into strings. Another way of combining items from two or more lists (or other iterables) is to use the zip() function. The zip() function takes one or more iterables and returns an iterator that returns tuples. The ﬁrst tuple has the ﬁrst item from every iterable, the second tuple the second item from every iterable, and so on, stopping as soon as one of the iterables is exhausted. Here is an example:\n\n>>> for t in zip(range(4), range(0, 10, 2), range(1, 10, 2)): ... (0, 0, 1) (1, 2, 3) (2, 4, 5) (3, 6, 7)\n\nprint(t)\n\nAlthough the iterators returned by the second and third range() calls can produce ﬁve items each, the ﬁrst can produce only four, so that limits the number of items zip() can return to four tuples.\n\nHere is a modiﬁed version of the program to generate test names, this time with each name occupying 25 characters and followed by a random year. The program is called generate_test_names2.py and outputs the ﬁle test-names2.txt. We have not shown the get_forenames_and_surnames() function or the open() call since, apart from the output ﬁlename, they are the same as before.\n\nlimit = 100 years = list(range(1970, 2013)) * 3 for year, forename, surname in zip(\n\nrandom.sample(years, limit), random.sample(forenames, limit), random.sample(surnames, limit)):\n\nname = \"{0} {1}\".format(forename, surname) fh.write(\"{0:.<25}.{1}\\n\".format(name, year))\n\nWe begin by setting a limit on how many nameswe want to generate. Then we create a list of years by making a list of the years from 1970 to 2012 inclusive, and then replicating this list three times so that the ﬁnal list has three occur- rences of each year. This is necessary because the random.sample() function that we are using (instead of random.choice()) takes both an iterable and how\n\n143",
      "page_number": 139
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 147-155)",
      "start_page": 147,
      "end_page": 155,
      "detection_method": "topic_boundary",
      "content": "Tuple unpack- ing 110➤\n\nstr. format() 78➤\n\n144\n\nChapter 3. Collection Data Types\n\nmany items it is to produce—a number that cannot be less than the number of items the iterable can return. The random.sample() function returns an iter- ator that will produce up to the speciﬁed number of items from the iterable it is given—with no repeats. So this version of the program will always produce unique names.\n\nzip() function. We In the for … in loop we unpack each tuple returned by the want to limit the length of each name to 25 characters,and to do this we must ﬁrst create a string with the complete name,and then set the maximum width for that string when we call str.format() the second time. We left-align each name,and for namesshorter than 25characterswe ﬁll with periods. The extra period ensures that names that occupy the full ﬁeld width are still separated from the year by a period.\n\nWe will conclude this subsection by mentioning two other iterable-related functions, sorted() and reversed(). The sorted() function returns a list with the items sorted, and the reversed() function simply returns an iterator that iterates in the reverse order to the iterator it is given as its argument. Here is an example of reversed():\n\n>>> list(range(6)) [0, 1, 2, 3, 4, 5] >>> list(reversed(range(6))) [5, 4, 3, 2, 1, 0]\n\nThe sorted() function is more sophisticated,as these examples show:\n\n>>> x = [] >>> for t in zip(range(-10, 0, 1), range(0, 10, 2), range(1, 10, 2)): ... >>> x [-10, 0, 1, -9, 2, 3, -8, 4, 5, -7, 6, 7, -6, 8, 9] >>> sorted(x) [-10, -9, -8, -7, -6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> sorted(x, reverse=True) [9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -6, -7, -8, -9, -10] >>> sorted(x, key=abs) [0, 1, 2, 3, 4, 5, 6, -6, -7, 7, -8, 8, -9, 9, -10]\n\nx += t\n\nIn the preceding snippet, the zip() function returns 3-tuples, (-10, 0, 1), (-9, 2, 3), and so on. The += operator extends a list,that is, it appends each item in the sequence it is given to the list.\n\nThe ﬁrst call to sorted() returns a copy of the list using the conventional sort order. The second call returns a copy of the list in the reverse of the conven- tional sort order. The last call to sorted() speciﬁes a “key” function which we will come back to in a moment.\n\nIterating and Copying Collections\n\n145\n\nNotice that since Python functions are objects like any other, they can be passed as arguments to other functions, and stored in collections without formality. Recall that a function’snameisan object referenceto thefunction;it is the parentheses that follow the name that tell Python to call the function.\n\nWhen a key function is passed (in this case the abs() function), it is called once for every item in the list (with the item passed as the function’s sole parameter), to create a “decorated” list. Then the decorated list is sorted, and the sorted list without the decoration is returned as the result. We are free to use our own custom function as the key function, as we will see shortly.\n\nFor example, we can case-insensitively sort a list of strings by passing the str.lower() method as a key. If we have the list, x, of [\"Sloop\", \"Yawl\", \"Cutter\", \"schooner\", \"ketch\"], we can sort it case-insensitively using DSU (Decorate, Sort, Undecorate) with a single line of code by passing a key func- tion, or do the DSU explicitly, as these two equivalent code snippets show:\n\ntemp = [] for item in x:\n\ntemp.append((item.lower(), item))\n\nx = [] for key, value in sorted(temp):\n\nx = sorted(x, key=str.lower)\n\nx.append(value)\n\nBoth snippets produce a new list: [\"Cutter\", \"ketch\", \"schooner\", \"Sloop\", \"Yawl\"], although the computationsthey perform are not identical because the right-hand snippet creates the temp list variable.\n\nPython’s sort algorithm is an adaptive stable mergesort that is both fast and smart, and it is especially well optimized for partially sorted lists—a very common case.★ The “adaptive” part means that the sort algorithm adapts to circumstances—for example, taking advantage of partially sorted data. The “stable” part means that items that sort equally are not moved in relation to each other (after all, there is no need), and the “mergesort” part is the generic name for the sorting algorithm used. When sorting collections of integers, strings, or other simple types their “less than” operator (<) is used. Python can sort collections that contain collections, working recursively to any depth. For example:\n\n>>> x = list(zip((1, 3, 1, 3), (\"pram\", \"dorie\", \"kayak\", \"canoe\"))) >>> x [(1, 'pram'), (3, 'dorie'), (1, 'kayak'), (3, 'canoe')] >>> sorted(x) [(1, 'kayak'), (1, 'pram'), (3, 'canoe'), (3, 'dorie')]\n\n★The algorithm was created by Tim Peters. An interesting explanation and discussion of the algorithm is in the ﬁle listsort.txt which comes with Python’s source code.\n\nObject refer- ences 16➤\n\n146\n\nChapter 3. Collection Data Types\n\nPython has sorted the list of tuples by comparing the ﬁrst item of each tuple, and when these are the same, by comparing the second item. This gives a sort order based on the integers, with the strings being tiebreakers. We can force the sort to be based on the strings and use the integers as tiebreakers by deﬁning a simple key function:\n\ndef swap(t):\n\nreturn t[1], t[0]\n\nThe swap() function takes a 2-tuple and returns a new 2-tuple with the argu- ments swapped. Assuming that we have entered the swap() function in IDLE, we can now do this:\n\n>>> sorted(x, key=swap) [(3, 'canoe'), (3, 'dorie'), (1, 'kayak'), (1, 'pram')]\n\nListscan also be sorted in-place using the list.sort() method,which takesthe same optional arguments as sorted().\n\nSorting can be applied only to collections where all the items can be compared with each other:\n\nsorted([3, 8, -7.5, 0, 1.3]) sorted([3, \"spanner\", -7.5, 0, 1.3]) # raises a TypeError\n\n# returns: [-7.5, 0, 1.3, 3, 8]\n\nAlthough the ﬁrst list has numbers of different types (int and float), these types can be compared with each other so that sorting a list containing them works ﬁne. But the second list has a string and this cannot be sensibly com- pared with a number,and so a TypeError exception is raised. If we want to sort a list that has integers, ﬂoating-point numbers, and strings that contain num- bers, we can give float() as the key function:\n\nsorted([\"1.3\", -7.5, \"5\", 4, \"-2.4\", 1], key=float)\n\nThisreturnsthelist [-7.5, '-2.4', 1, '1.3', 4, '5'].Noticethatthelist’svalues are not changed, so strings remain strings. If any of the strings cannot be converted to a number (e.g., “spanner”), a ValueError exception will be raised.\n\nCopying Collections\n\nSince Python uses object references,when we use the assignment operator (=), literal such as a string no copying takes place. If the right-hand operand is a or a number,the left-hand operand isset to be an object referencethat refersto the in-memory object that holds the literal’s value. If the right-hand operand isan object reference,the left-hand operand isset to be an object referencethat refers to the same object as the right-hand operand. One consequence of this is that assignment is very efﬁcient.\n\n||\n\nIterating and Copying Collections\n\nWhen we assign large collections, such as long lists, the savings are very apparent. Here is an example:\n\n>>> songs = [\"Because\", \"Boys\", \"Carol\"] >>> beatles = songs >>> beatles, songs (['Because', 'Boys', 'Carol'], ['Because', 'Boys', 'Carol'])\n\nHere, a new object reference (beatles) has been created, and both object references refer to the same list—no copying has taken place.\n\nSince lists are mutable, we can apply a change. For example:\n\n>>> beatles[2] = \"Cayenne\" >>> beatles, songs (['Because', 'Boys', 'Cayenne'], ['Because', 'Boys', 'Cayenne'])\n\nWe applied the change using the beatles variable—but this is an object refer- ence referring to the same list as songs refers to. So any change made through either object reference is visible to the other. This is most often the behavior wewant,sincecopying largecollectionsispotentially expensive. It alsomeans, for example,that we can pass a list or other mutable collection data type as an argumenttoa function,modify thecollectioninthefunction,andknowthatthe modiﬁed collection will be accessible after the function call has completed.\n\nHowever,in somesituations,wereally dowant a separatecopy of thecollection (or other mutable object). For sequences, when we take a slice—for example, songs[:2]—the slice is always an independent copy of the items copied. So to copy an entire sequence we can do this:\n\n>>> songs = [\"Because\", \"Boys\", \"Carol\"] >>> beatles = songs[:] >>> beatles[2] = \"Cayenne\" >>> beatles, songs (['Because', 'Boys', 'Cayenne'], ['Because', 'Boys', 'Carol'])\n\nFor dictionaries and sets, copying can be achieved using dict.copy() and set.copy(). In addition, the copy module provides the copy.copy() function that returns a copy of the object it is given. Another way to copy the built-in collec- tion types is to use the type as a function with the collection to be copied as its argument. Here are some examples:\n\ncopy_of_dict_d = dict(d) copy_of_list_L = list(L) copy_of_set_s = set(s)\n\nNote, though, that all of these copying techniques are shallow—that is, only object references are copied and not the objects themselves. For immutable\n\n147\n\n148\n\nChapter 3. Collection Data Types\n\ndata typeslike numbersand stringsthishasthe same effect as copying (except that it is more efﬁcient), but for mutable data types such as nested collections this means that the objects they refer to are referred to both by the original collection and by the copied collection. The following snippet illustrates this:\n\n>>> x = [53, 68, [\"A\", \"B\", \"C\"]] >>> y = x[:] # shallow copy >>> x, y ([53, 68, ['A', 'B', 'C']], [53, 68, ['A', 'B', 'C']]) >>> y[1] = 40 >>> x[2][0] = 'Q' >>> x, y ([53, 68, ['Q', 'B', 'C']], [53, 40, ['Q', 'B', 'C']])\n\nWhen list x is shallow-copied, the reference to the nested list [\"A\", \"B\", \"C\"] is copied. This means that both x and y have as their third item an object refer- ence that refers to this list, so any changes to the nested list are seen by both x and y.If we really need independent copiesof arbitrarily nested collections,we can deep-copy:\n\n>>> import copy >>> x = [53, 68, [\"A\", \"B\", \"C\"]] >>> y = copy.deepcopy(x) >>> y[1] = 40 >>> x[2][0] = 'Q' >>> x, y ([53, 68, ['Q', 'B', 'C']], [53, 40, ['A', 'B', 'C']])\n\nHere, lists x and y, and the list items they contain, are completely inde- pendent.\n\nNote that from now on we will use the terms copy and shallow copy interchangeably—if we mean deep copy, we will say so explicitly.\n\nExamples\n\nWe have now completed our review of Python’s built-in collection data types, and three of the standard library collection types (collections.namedtuple, collections.defaultdict, and collections.OrderedDict). Python also provides the collections.deque type, a double-ended queue, and many other collection types are available from third parties and from the Python Package Index, pypi.python.org/pypi.But now we will look at a couple of slightly longer exam- ples that draw together many of the things covered in this chapter, and in the preceding one.\n\n|||\n\nExamples\n\nThe ﬁrst programisabout seventy lineslong and involvestext processing. The second program is around ninety lines long and is mathematical in ﬂavor. Be- tween them, the programs make use of dictionaries, lists, named tuples, and sets, and both make great use of the str.format() method from the preceding chapter.\n\ngenerate_usernames.py\n\nImagine we are setting up a new computer system and need to generate user- names for all of our organization’s staff. We have a plain text data ﬁle (UTF- 8 encoding) where each line represents a record and ﬁelds are colon-delimited. Each record concerns one member of the staff and the ﬁelds are their unique staff ID, forename, middle name (which may be an empty ﬁeld), surname, and department name. Here is an extract of a few lines from an example data/users.txt data ﬁle:\n\n1601:Albert:Lukas:Montgomery:Legal 3702:Albert:Lukas:Montgomery:Sales 4730:Nadelle::Landale:Warehousing\n\nThe program must read in all the data ﬁles given on the command line,and for every line (record) must extract the ﬁelds and return the data with a suitable username. Each username must be unique and based on the person’s name. The output must be text sent to the console, sorted alphabetically by surname and forename, for example:\n\nName ID Username -------------------------------- ------ --------- Landale, Nadelle................ (4730) nlandale Montgomery, Albert L............ (1601) almontgo Montgomery, Albert L............ (3702) almontgo1\n\nEach record has exactly ﬁve ﬁelds, and although we could refer to them by number, we prefer to use names to keep our code clear:\n\nID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)\n\nIt is a Python convention that identiﬁers written in all uppercase characters are to be treated as constants.\n\nWe also need to create a named tuple type for holding the data on each user:\n\nUser = collections.namedtuple(\"User\",\n\n\"username forename middlename surname id\")\n\nWe will see how the constantsand the User named tuple are used when we look at the rest of the code.\n\n149\n\n||\n\n150\n\nChapter 3. Collection Data Types\n\nThe program’s overall logic is captured in the main() function:\n\ndef main():\n\nif len(sys.argv) == 1 or sys.argv[1] in {\"-h\", \"--help\"}:\n\nprint(\"usage: {0} file1 [file2 [... fileN]]\".format(\n\nsys.argv[0]))\n\nsys.exit()\n\nusernames = set() users = {} for filename in sys.argv[1:]:\n\nfor line in open(filename, encoding=\"utf8\"):\n\nline = line.rstrip() if line:\n\nuser = process_line(line, usernames) users[(user.surname.lower(), user.forename.lower(),\n\nuser.id)] = user\n\nprint_users(users)\n\nIf the user doesn’t provide any ﬁlenames on the command line, or if they type “-h” or “--help” on the command line, we simply print a usage message and terminate the program.\n\nFor each line read, we strip off any trailing whitespace (e.g., \\n) and process only nonempty lines. Thismeansthat if the data ﬁle containsblank linesthey will be safely ignored.\n\nWe keeptrack of all theallocated usernamesin the usernames set to ensurethat we don’t create any duplicates. The data itself is held in the users dictionary, with each user (member of the staff) stored as a dictionary item whose key is a tuple of the user’s surname, forename, and ID, and whose value is a named tupleof typeUser.Using a tupleof theuser’ssurname,forename,andIDfor the dictionary’s keys means that if we call sorted() on the dictionary, the iterable returned will be in the order we want (i.e.,surname,forename,ID),without us having to provide a key function.\n\ndef process_line(line, usernames):\n\nfields = line.split(\":\") username = generate_username(fields, usernames) user = User(username, fields[FORENAME], fields[MIDDLENAME],\n\nfields[SURNAME], fields[ID])\n\nreturn user\n\nSince the data format for each record is so simple, and because we’ve already stripped the trailing whitespace from the line, we can extract the ﬁelds simply by splitting on the colons. We pass the ﬁelds and the usernames set to the generate_username() function,andthenwecreateaninstanceof the User named\n\nExamples\n\ntuple type which we then return to the caller (main()), which inserts the user into the users dictionary, ready for printing.\n\nIf we had not created suitable constants to hold the index positions, we would be reduced to using numeric indexes, for example:\n\nuser = User(username, fields[1], fields[2], fields[3], fields[0])\n\nAlthough this is certainly shorter, it is poor practice. First it isn’t clear to future maintainers what each ﬁeld is, and second it is vulnerable to data ﬁle format changes—if the order or number of ﬁelds in a record changes,this code will break everywhere it is used. But by using named constants in the face of changes to the record struture,we would have to change only the values of the constants, and all uses of the constants would continue to work.\n\ndef generate_username(fields, usernames):\n\nusername = ((fields[FORENAME][0] + fields[MIDDLENAME][:1] +\n\nfields[SURNAME]).replace(\"-\", \"\").replace(\"'\", \"\"))\n\nusername = original_name = username[:8].lower() count = 1 while username in usernames:\n\nusername = \"{0}{1}\".format(original_name, count) count += 1\n\nusernames.add(username) return username\n\nWe make a ﬁrst attempt at creating a username by concatenating the ﬁrst let- ter of theforename,theﬁrstletter of themiddlename,andthewholesurname, and deleting any hyphens or single quotes from the resultant string. The code for getting the ﬁrst letter of the middle name is quite subtle. If we had used fields[MIDDLENAME][0] we would get an IndexError exception for empty middle names. But by using a slice we get the ﬁrst letter if there is one, or an empty string otherwise.\n\nNext wemaketheusernamelowercaseandnomorethan eight characterslong. If the username is in use (i.e., it is in the usernames set), we try the username with a “1” tacked on at the end, and if that is in use we try with a “2”, and so on until we get one that isn’t in use. Then we add the username to the set of usernames and return the username to the caller.\n\ndef print_users(users): namewidth = 32 usernamewidth = 9\n\nprint(\"{0:<{nw}} {1:^6} {2:{uw}}\".format(\n\n\"Name\", \"ID\", \"Username\", nw=namewidth, uw=usernamewidth))\n\nprint(\"{0:-<{nw}} {0:-<6} {0:-<{uw}}\".format(\n\n\"\", nw=namewidth, uw=usernamewidth))\n\n151\n\nstr. format() 78➤\n\n152\n\nChapter 3. Collection Data Types\n\nfor key in sorted(users): user = users[key] initial = \"\" if user.middlename:\n\ninitial = \" \" +user.middlename[0]\n\nname = \"{0.surname}, {0.forename}{1}\".format(user, initial) print(\"{0:.<{nw}} ({1.id:4}) {1.username:{uw}}\".format( name, user, nw=namewidth, uw=usernamewidth))\n\nOnce all the records have been processed, the print_users() function is called, with the users dictionary passed as its parameter.\n\nThe ﬁrst print() statement prints the column titles, and the second print() statement prints hyphens under each title. This second statement’s str. format() call isslightly subtle. Thestring we give to beprintedis \"\",that is,the empty string—we get the hyphens by printing the empty string padded with hyphens to the given widths.\n\nNext we use a for … in loop to print the details of each user, extracting the key for each user’s dictionary item in sorted order. For convenience we create the user variable so that we don’t have to keep writing users[key] throughout the rest of the function. In the loop’s ﬁrst call to str.format() we set the name variable to the user’s name in surname, forename (and optional initial) form. We access items in the user named tuple by name. Once we have the user’s name as a single string we print the user’s details, constraining each column, (name, ID, username) to the widths we want.\n\nThe complete program (which differs from what we have reviewed only in that it has some initial comment lines and some imports) is in gener- ate_usernames.py. The program’s structure—read in a data ﬁle, process each record, write output—is one that is very frequently used, and we will meet it again in the next example.\n\nstatistics.py\n\nSuppose we have a bunch of data ﬁles containing numbers relating to some processing we have done, and we want to produce some basic statistics to give us some kind of overview of the data. Each ﬁle uses plain text (ASCII encoding) with one or more numbers per line (whitespace-separated).\n\nHere is an example of the kind of output we want to produce:\n\ncount = 183 mean = 130.56 median = 43.00 mode = [5.00, 7.00, 50.00] std. dev. = 235.01\n\n||",
      "page_number": 147
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 156-165)",
      "start_page": 156,
      "end_page": 165,
      "detection_method": "topic_boundary",
      "content": "Examples\n\nHere, we read 183 numbers, with 5, 7, and 50 occurring most frequently, and with a sample standard deviation of 235.01.\n\nThe statistics themselves are held in a named tuple called Statistics:\n\nStatistics = collections.namedtuple(\"Statistics\",\n\n\"mean mode median std_dev\")\n\nThe main() function also serves as an overview of the program’s structure:\n\ndef main():\n\nif len(sys.argv) == 1 or sys.argv[1] in {\"-h\", \"--help\"}:\n\nprint(\"usage: {0} file1 [file2 [... fileN]]\".format(\n\nsys.argv[0]))\n\nsys.exit()\n\nnumbers = [] frequencies = collections.defaultdict(int) for filename in sys.argv[1:]:\n\nread_data(filename, numbers, frequencies)\n\nif numbers:\n\nstatistics = calculate_statistics(numbers, frequencies) print_results(len(numbers), statistics)\n\nelse:\n\nprint(\"no numbers found\")\n\nWe store all the numbers from all the ﬁles in the numbers list. To calculate the mode(“mostfrequently occurring”)numbers,we need toknow how many times each number occurs, so we create a default dictionary using the int() factory function, to keep track of the counts.\n\nWe iterateover each ﬁlename and read in itsdata. We passthe list and default dictionary as additional parameters so that the read_data() function can update them. Once we have read all the data, assuming some numbers were successfully read, we call calculate_statistics(). This returns a named tuple of type Statistics which we then use to print the results.\n\ndef read_data(filename, numbers, frequencies):\n\nfor lino, line in enumerate(open(filename, encoding=\"ascii\"),\n\nstart=1):\n\nfor x in line.split():\n\ntry:\n\nnumber = float(x) numbers.append(number) frequencies[number] += 1\n\nexcept ValueError as err:\n\nprint(\"{filename}:{lino}: skipping {x}: {err}\".format(\n\n**locals()))\n\n153\n\nUs- ing str. format() with map- ping un- packing 81➤\n\n154\n\nChapter 3. Collection Data Types\n\nWe split every line on whitespace,and for each item we attempt to convert it to a float. If a conversion succeeds—as it will for integers and for ﬂoating-point numbers in both decimal and exponential notations—we add the number to the numbers list and update the frequencies default dictionary. (If we had used a plain dict, the update code would have been frequencies[number] = frequen- cies.get(number, 0) + 1.)\n\nIf a conversion fails, we output the line number (starting from line 1 as is tra- ditional for text ﬁles), the text we attempted to convert, and the ValueError exception’s error text. Rather than using positional arguments (e.g., .for- mat(filename, lino, etc.,or explicitlynamedarguments,.format(filename=file- name, lino=lino, etc.), we have retrieved the names and values of the local variables by calling locals() and used mapping unpacking to pass these as key–value named arguments to the str.format() method.\n\ndef calculate_statistics(numbers, frequencies):\n\nmean = sum(numbers) / len(numbers) mode = calculate_mode(frequencies, 3) median = calculate_median(numbers) std_dev = calculate_std_dev(numbers, mean) return Statistics(mean, mode, median, std_dev)\n\nThis function is used to gather all the statistics together. Because the mean (“average”)issoeasy tocalculate,wedosodirectlyhere. Fortheotherstatistics we call dedicated functions,and at the end we return a Statistics named tuple object that contains the four statistics we have calculated.\n\ndef calculate_mode(frequencies, maximum_modes):\n\nhighest_frequency = max(frequencies.values()) mode = [number for number, frequency in frequencies.items()\n\nif frequency == highest_frequency]\n\nif not (1 <= len(mode) <= maximum_modes):\n\nmode = None\n\nelse:\n\nmode.sort()\n\nreturn mode\n\nThere may be more than one most-frequently-occurring number, so in ad- dition to the dictionary of frequencies, this function also requires the caller to specify the maximum number of modes that are acceptable. (The cal- culate_statistics() function is the caller, and it speciﬁed a maximum of three modes.)\n\nThe max() function is used to ﬁnd the highest value in the frequencies dictio- nary. Then, we use a list comprehension to create a list of those modes whose frequency equals the highest value. We can compare using operator == since all the frequencies are integers.\n\nExamples\n\nIf the number of modes is 0 or greater than the maximum modes that are acceptable, a mode of None is returned; otherwise, a sorted list of the modes is returned.\n\ndef calculate_median(numbers):\n\nnumbers = sorted(numbers) middle = len(numbers) // 2 median = numbers[middle] if len(numbers) % 2 == 0:\n\nmedian = (median + numbers[middle - 1]) / 2\n\nreturn median\n\nThe median (“middle value”) is the value that occurs in the middle if the numbers are arranged in order—except when the number of numbers is even, in which case themiddlefallsbetween twonumbers,so in that casethemedian is the mean of the two middle numbers.\n\nWebeginby sorting thenumbersintoascending order. Then weusetruncating (integer) division to ﬁnd the index position of the middle number, which we extract and store as the median. If the number of numbers is even, we make the median the mean of the two middle numbers.\n\ndef calculate_std_dev(numbers, mean):\n\ntotal = 0 for number in numbers:\n\ntotal += ((number - mean) ** 2)\n\nvariance = total / (len(numbers) - 1) return math.sqrt(variance)\n\nThe sample standard deviation is a measure of dispersion,that is, how far the numbers differ from the mean. This function calculates the sample standard deviation using the formula s =√∑(x − −x 2) n− 1 , where x is each number, −x is the mean, and n is the number of numbers.\n\ndef print_results(count, statistics):\n\nreal = \"9.2f\"\n\nif statistics.mode is None:\n\nmodeline = \"\"\n\nelif len(statistics.mode) == 1:\n\nmodeline = \"mode\n\n= {0:{fmt}}\\n\".format(\n\nstatistics.mode[0], fmt=real)\n\nelse:\n\nmodeline = (\"mode\n\n= [\" +\n\n\", \".join([\"{0:.2f}\".format(m) for m in statistics.mode]) + \"]\\n\")\n\nprint(\"\"\"\\\n\n155\n\nstr. format() 78➤\n\nNamed tuple 111➤\n\nUs- ing str. format() with map- ping un- packing 81➤\n\n156\n\nChapter 3. Collection Data Types\n\ncount mean median {1}\\ std. dev. = {std_dev:{fmt}}\"\"\".format(\n\n= {0:6} = {mean:{fmt}} = {median:{fmt}}\n\ncount, modeline, fmt=real, **statistics._asdict()))\n\nMost of thisfunction isconcerned with formatting the modeslist into the mode- line string. If there are no modes, the mode line is not printed at all. If there is one mode, the mode list has just one item (mode[0]) which is printed using the same format as is used for the other statistics. If there are several modes, we print them as a list with each one formatted appropriately. This is done by using a list comprehension to produce a list of mode strings, and then joining all the strings in the list together with “, ” in between each one. The printing at the end is easy thanksto our use of a named tuple and its _asdict() method, in conjunction with mapping unpacking. This lets us access the statistics in the statistics object using names rather than numeric indexes, and thanks to Python’striple-quoted stringswe can lay out the text to be printed in an under- standable way. Recall that if we use mapping unpacking to pass argumentsto the str.format() method, it may be done only once and only at the end.\n\nThere is one subtle point to note. The modes are printed as format item {1}, which is followed by a backslash. The backslash escapes the newline, so if the mode is the empty string no blank line will appear. And it is because we have escaped the newline that we must put \\n at the end of the modeline string if it is not empty.\n\nSummary\n\nIn this chapter we covered all of Python’s built-in collection types, and also a couple of collection types from the standard library. We covered the collection sequence types, tuple, collections.namedtuple, and list, which support the same slicing and striding syntax as strings. The use of the sequence unpack- ing operator (*) was also covered,and brief mention was made of starred argu- ments in function calls. We also covered the set types, set and frozenset, and the mapping types, dict and collections.defaultdict.\n\nWe saw how to use the named tuples provided by Python’s standard library to create simple custom tuple data types whose items can be accessed by index position,or more conveniently,by name. We also saw how to create“constants” by using variables with all uppercase names.\n\nIn the coverage of lists we saw that everything that can be done to tuples can be done to lists. And thanks to lists being mutable they offer considerably more functionality than tuples. This includes methods that modify the list\n\n|||\n\nSummary\n\n(e.g., list.pop()), and the ability to have slices on the left-hand side of an as- signment, to provide insertion, replacement, and deletion of slices. Lists are ideal for holding sequences of items, especially if we need fast access by index position.\n\nWhen we discussed the set and frozenset types, we noted that they may contain only hashable items. Sets provide fast membership testing and are useful for ﬁltering out duplicate data.\n\nDictionaries are in some ways similar to sets—for example, their keys must be hashable and are unique just like the items in a set. But dictionaries hold key–value pairs, whose values can be of any type. The dictionary coverage included the dict.get() and dict.setdefault() methods, and the coverage of default dictionaries showed an alternative to using these methods. Like sets, dictionaries provide very fast membership testing and fast access by key.\n\nLists,sets,and dictionariesall offer compact comprehension syntaxesthat can be used to create collections of these types from iterables (which themselves can be comprehensions),and with conditionsattached if required. The range() and zip() functions are frequently used in the creation of collections, both in conventional for … in loops and in comprehensions.\n\nItems can be deleted from the mutable collection types using the relevant methods, such as list.pop() and set.discard(), or using del, for example, del d[k] to delete an item with key k from dictionary d.\n\nPython’s use of object references makes assignment extremely efﬁcient, but it also means that objects are not copied when the assignment operator (=) is used. We saw the differences between shallow and deep copying, and later on sawhowlistscanbeshallow-copiedusing a sliceof theentirelist,L[:],andhow dictionariescanbeshallow-copiedusing the dict.copy() method. Any copyable object can be copied using functions from the copy module, with copy.copy() performing a shallow copy, and copy.deepcopy() performing a deep copy.\n\nWe introduced Python’s highly optimized sorted() function. This function is used a lot in Python programming, since Python doesn’t provide any intrinsi- cally ordered collection data types, so when we need to iterate over collections in sorted order, we use sorted().\n\nPython’s built-in collection data types—tuples, lists, sets, frozen sets, and dictionaries—are sufﬁcient in themselves for all purposes. Nonetheless,a few additional collection types are available in the standard library, and many more are available from third parties.\n\nWe often need to read in collections from ﬁles, or write collections to ﬁles. In this chapter we focused just on reading and writing lines of text in our very brief coverage of text ﬁle handling. Full coverage of ﬁle handling is given in Chapter 7, and additional means of providing data persistence is covered in Chapter 12.\n\n157\n\n158\n\nChapter 3. Collection Data Types\n\nIn the next chapter, we will look more closely at Python’s control structures, andintroduceonethatwehavenot seenbefore. Wewillalsolook inmoredepth at exception-handling and at some additional statements, such as assert, that we have not yet covered. In addition,we will cover the creation of customfunc- tions,and in particular we will look at Python’sincredibly versatile argument- handling facilities.\n\nExercises\n\n1. Modify the external_sites.py program to use a default dictionary. This is an easy change requiring an additional import, and changes to just two other lines. A solution is provided in external_sites_ans.py.\n\n2. Modify the uniquewords2.py program so that it outputs the words in fre- quency of occurrence order rather than in alphabetical order. You’ll need to iterate over the dictionary’s items and create a tiny two-line function to extract each item’s value and pass this function as sorted()’s key func- tion. Also, the call to print() will need to be changed appropriately. This isn’t difﬁcult, but it is slightly subtle. A solution is provided in unique- words_ans.py.\n\n3. Modify the generate_usernames.py program so that it prints the details of two users per line, limiting names to 17 characters and outputting a form feed character after every 64 lines, with the column titles printed at the start of every page. Here’s a sample of the expected output: Name ID Username Name ID Username ----------------- ------ --------- ----------------- ------ --------- Aitkin, Shatha... (2370) saitkin Alderson, Nicole. (8429) nalderso Allison, Karma... (8621) kallison Alwood, Kole E... (2095) kealwood Annie, Neervana.. (2633) nannie Apperson, Lucyann (7282) leappers\n\nThis is challenging. You’ll need to keep the column titles in variables so that they can be printed when needed,and you’ll need to tweak the format speciﬁcations to accommodate the narrower names. One way to achieve pagination is to write all the output items to a list and then iterate over thelist using striding toget theleft-and right-handitems,and using zip() to pair them up. A solution is provided in generate_usernames_ans.py and a longer sample data ﬁle is provided in data/users2.txt.\n\n|||\n\n4\n\nControl Structures ● Exception Handling ● Custom Functions\n\nControl Structures and Functions\n\nThis chapter’s ﬁrst two sections cover Python’s control structures, with the ﬁrst section dealing with branching and looping and the second section cov- ering exception-handling. Most of the control structures and the basics of exception-handling were introduced in Chapter 1, but here we give more com- plete coverage, including additional control structure syntaxes, and how to raise exceptions and create custom exceptions.\n\nThe third and largest section is devoted to creating custom functions, with detailed coverageof Python’sextremely versatileargument handling. Custom functionsallow us to package up and parameterizefunctionality—thisreduces the size of our code by eliminating code duplication and provides code reuse. (In the following chapter we will see how to create custom modules so that we can make use of our custom functions in multiple programs.)\n\nControl Structures\n\nPython provides conditional branching with if statements and looping with while and for …in statements. Python also has a conditional expression—this is a kind of if statement that is Python’s answer to the ternary operator (?:) used in C-style languages.\n\nConditional Branching\n\nAs we saw in Chapter 1, this is the general syntax for Python’s conditional branch statement:\n\nif boolean_expression1:\n\nsuite1\n\n159\n\n||||\n\n|||\n\n||\n\nControl Structures\n\nThe parentheses also make things clearer for human readers.\n\nConditional expressions can be used to improve messages printed for users. For example, when reporting the number of ﬁles processed, instead of print- ing “0 ﬁle(s)”, “1 ﬁle(s)”, and similar, we could use a couple of conditional ex- pressions:\n\nprint(\"{0} file{1}\".format((count if count != 0 else \"no\"),\n\n(\"s\" if count != 1 else \"\")))\n\nThis will print “no ﬁles”,“1ﬁle”,“2 ﬁles”,and similar,which gives a much more professional impression.\n\nLooping\n\nPython provides a while loop and a for … in loop, both of which have a more sophisticated syntax than the basics we showed in Chapter 1.\n\nwhile Loops\n\nHere is the complete general syntax of the while loop:\n\nwhile boolean_expression:\n\nwhile_suite\n\nelse:\n\nelse_suite\n\nThe else clause is optional. As long as the boolean_expression is True, the while block’s suite is executed. If the boolean_expression is or becomes False, the loop terminates,and if the optional else clause is present,its suite is executed. Inside the while block’s suite, if a continue statement is executed, control is immediately returned to the top of the loop, and the boolean_expression is evaluated again. If the loop does not terminate normally, any optional else clause’s suite is skipped.\n\nThe optional else clause is rather confusingly named since the else clause’s suite is always executed if the loop terminates normally. If the loop is broken out of due to a break statement, or a return statement (if the loop is in a function or method), or if an exception is raised, the else clause’s suite is not executed. (If an exception occurs, Python skips the else clause and looks for a suitable exception handler—this is covered in the next section.) On the plus side, the behavior of the else clause is the same for while loops, for …in loops, and try … except blocks.\n\nLet’s look at an example of the else clause in action. The str.index() and list.index() methods return the index position of a given string or item, or raise a ValueError exception if the string or item is not found. The str.find()\n\n161\n\n||\n\n|\n\nenumer- ate() 139➤\n\n162\n\nChapter 4. Control Structures and Functions\n\nmethod does the same thing, but on failure, instead of raising an exception it returnsan index of -1.Thereisno equivalent methodfor lists,but if wewanted a function that did this, we could create one using a while loop:\n\ndef list_find(lst, target):\n\nindex = 0 while index < len(lst):\n\nif lst[index] == target:\n\nbreak\n\nindex += 1\n\nelse:\n\nindex = -1\n\nreturn index\n\nThis function searches the given list looking for the target. If the target is found, the break statement terminates the loop, causing the appropriate index position to be returned. If the target is not found, the loop runs to completion and terminatesnormally. After normal termination,the else suite isexecuted, and the index position is set to -1 and returned.\n\nfor Loops\n\nLike a while loop, the full syntax of the for … in loop also includes an optional else clause:\n\nfor expression in iterable:\n\nfor_suite\n\nelse:\n\nelse_suite\n\nThe expression is normally either a single variable or a sequence of variables, usually in the form of a tuple. If a tuple or list is used for the expression, each item is unpacked into the expression’s items.\n\nIf a continue statement is executed inside the for … in loop’s suite, control is immediately passed to the top of the loop and the next iteration begins. If the loop runs to completion it terminates, and any else suite is executed. If the loop isbroken out of due to a break statement,or a return statement (if the loop is in a function or method), or if an exception is raised, the else clause’s suite is not executed. (If an exception occurs,Python skips the else clause and looks for a suitable exception handler—this is covered in the next section.)\n\nHere is a for … in loop version of the list_find() loop version, it shows the else clause in action:\n\nfunction, and like the while\n\ndef list_find(lst, target):\n\nfor index, x in enumerate(lst):\n\n|\n\nControl Structures\n\nif x == target:\n\nbreak\n\nelse:\n\nindex = -1\n\nreturn index\n\nAsthiscode snippet implies,the variablescreated in the for …in loop’s expres- sion continue to exist after the loop has terminated. Like all local variables, they cease to exist at the end of their enclosing scope.\n\nException Handling\n\nPython indicates errors and exceptional conditions by raising exceptions, al- though some third-party Python libraries use more old-fashioned techniques, such as “error” return values.\n\nCatching and Raising Exceptions\n\nExceptions are caught using try … except blocks, whose general syntax is:\n\ntry:\n\ntry_suite\n\nexcept exception_group1 as variable1:\n\nexcept_suite1\n\n… except exception_groupN as variableN:\n\nexcept_suiteN\n\nelse:\n\nelse_suite\n\nfinally:\n\nfinally_suite\n\nThere must be at least one except block, but both the else and the finally blocksareoptional. The else block’ssuiteisexecutedwhenthe try block’ssuite has ﬁnished normally—but it is not executed if an exception occurs. If there is a finally block, it is always executed at the end.\n\nEach except clause’s exception group can be a single exception or a parenthe- sized tuple of exceptions. For each group, the as variable part is optional; if used,the variable contains the exception that occurred,and can be accessed in the exception block’s suite.\n\nIf an exception occurs in the try block’s suite, each except clause is tried in turn. If the exception matches an exception group, the corresponding suite is executed. Tomatchan exceptiongroup,theexceptionmust beof thesametype\n\n163\n\n|||\n\n||",
      "page_number": 156
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 166-176)",
      "start_page": 166,
      "end_page": 176,
      "detection_method": "topic_boundary",
      "content": "166\n\nChapter 4. Control Structures and Functions\n\nHere is a ﬁnal version of the list_find() function, this time using exception- handling:\n\ndef list_find(lst, target):\n\ntry:\n\nindex = lst.index(target)\n\nexcept ValueError: index = -1\n\nreturn index\n\nHere, we have effectively used the try … except block to turn an exception into a return value; the same approach can also be used to catch one kind of exception and raise another instead—a technique we will see shortly.\n\nPython also offers a simpler try … finally block which is sometimes useful:\n\ntry:\n\ntry_suite\n\nfinally:\n\nfinally_suite\n\nNo matter what happens in the try block’s suite (apart from the computer or program crashing!), the finally block’s suite will be executed. The with statement used with a context manager (both covered in Chapter 8) can be used to achieve a similar effect to using a try … finally block.\n\nOne common pattern of use for try … except … finally blocks is for handling ﬁle errors. For example, the noblanks.py program reads a list of ﬁlenames on the command line, and for each one produces another ﬁle with the same name, but with its extension changed to .nb,and with the same contentsexcept for no blank lines. Here’s the program’s read_data() function:\n\ndef read_data(filename):\n\nlines = [] fh = None try:\n\nfh = open(filename, encoding=\"utf8\") for line in fh:\n\nif line.strip():\n\nlines.append(line)\n\nexcept (IOError, OSError) as err:\n\nprint(err) return []\n\nfinally:\n\nif fh is not None: fh.close()\n\nreturn lines\n\nException Handling\n\nWe set the ﬁle object, fh, to None because it is possible that the open() call will fail, in which case nothing will be assigned to fh (so it will stay as None), and an exception will be raised. If one of the exceptions we have speciﬁed occurs (IOError or OSError), after printing the error message we return an empty list. But note that beforereturning,the finally block’s suite will be executed,so the ﬁle will be safely closed—if it had been successfully opened in the ﬁrst place.\n\nNotice also that if an encoding error occurs, even though we don’t catch the relevant exception (UnicodeDecodeError), the ﬁle will still be safely closed. In such casesthe finally block’ssuiteisexecutedand then theexceptionispassed up the call stack—there is no return value since the function ﬁnishes as a result of the unhandled exception. And in this case, since there is no suitable except block to catch encoding error exceptions, the program will terminate and print a traceback.\n\nWe could have written the except clause slightly less verbosely:\n\nexcept EnvironmentError as err:\n\nprint(err) return []\n\nThis works because EnvironmentError is the base class for both IOError and OSError.\n\nIn Chapter 8we will show a are safely closed, that does not require a finally block.\n\nslightly more compact idiom for ensuring that ﬁles\n\nRaising Exceptions\n\nExceptions provide a useful means of changing the ﬂow of control. We can take advantage of this either by using the built-in exceptions, or by creating our own, raising either kind when we want to. There are three syntaxes for raising exceptions:\n\nraise exception(args) raise exception(args) from original_exception raise\n\nWhen the ﬁrst syntax is used the exception that is speciﬁed should be either one of the built-in exceptions, or a custom exception that is derived from Exception. If we give the exception some text as its argument, this text will be output if the exception is printed when it is caught. The second syntax is a exception is raised as a chained exception (covered variation of the ﬁrst—the in Chapter 9) that includes the original_exception exception, so this syntax is used inside except suites. When the third syntax is used, that is, when no exception is speciﬁed, raise will reraise the currently active exception—and if there isn’t one it will raise a TypeError.\n\n167\n\n|\n\nDeal- ing with runtime errors ➤ 415\n\nContext man- agers ➤ 369\n\nChained excep- tions ➤ 419\n\n168\n\nChapter 4. Control Structures and Functions\n\nCustom Exceptions\n\nCustom exceptions are custom data types (classes).Creating classes is covered in Chapter 6, but since it is easy to create simple custom exception types, we will show the syntax here:\n\nclass exceptionName(baseException): pass\n\nThe base class should be Exception or a class that inherits from Exception.\n\nOne use of custom exceptions is to break out of deeply nested loops. For example, if we have a table object that holds records (rows), which hold ﬁelds (columns),which have multiple values(items),we could search for a particular value with code like this:\n\nfound = False for row, record in enumerate(table):\n\nfor column, field in enumerate(record):\n\nfor index, item in enumerate(field):\n\nif item == target:\n\nfound = True break\n\nif found: break\n\nif found: break\n\nif found:\n\nprint(\"found at ({0}, {1}, {2})\".format(row, column, index))\n\nelse:\n\nprint(\"not found\")\n\nThe 15lines of code are complicated by the fact that we must break out of each loop separately. An alternative solution is to use a custom exception:\n\nclass FoundException(Exception): pass\n\ntry:\n\nfor row, record in enumerate(table):\n\nfor column, field in enumerate(record):\n\nfor index, item in enumerate(field):\n\nif item == target:\n\nraise FoundException()\n\nexcept FoundException:\n\nprint(\"found at ({0}, {1}, {2})\".format(row, column, index))\n\nelse:\n\nprint(\"not found\")\n\n||\n\nException Handling\n\nThis cuts the code down to ten lines, or 11 including deﬁning the exception, and is much easier to read. If the item is found we raise our custom exception and the except block’s suite is executed—and the else block is skipped. And if the item is not found,no exception is raised and so the else suite is executed at the end.\n\nLet’s look at another example to see some of the different ways that exception- handling can be done. All of the snippets are taken from the checktags.py pro- gram, a program that reads all the HTML ﬁles it is given on the command line and performssome simple tests to verify that tags begin with “<” and end with “>”, and that entities are correctly formed. The program deﬁnes four custom exceptions:\n\nclass InvalidEntityError(Exception): pass class InvalidNumericEntityError(InvalidEntityError): pass class InvalidAlphaEntityError(InvalidEntityError): pass class InvalidTagContentError(Exception): pass\n\nThe second and third exceptions inherit from the ﬁrst; we will see why this is useful when we discussthe code that usesthe exceptions. The parse() function that uses the exceptions is more than 70 lines long, so we will show only those parts that are relevant to exception-handling.\n\nfh = None try:\n\nfh = open(filename, encoding=\"utf8\") errors = False for lino, line in enumerate(fh, start=1):\n\nfor column, c in enumerate(line, start=1):\n\ntry:\n\nThe code begins conventionally enough, setting the ﬁle object to None and putting all the ﬁle handling in a try block. The program reads the ﬁle line by line and reads each line character by character.\n\nNotice that we have two try blocks; the outer one is used to handle ﬁle object exceptions, and the inner one is used to handle parsing exceptions.\n\n... elif state == PARSING_ENTITY:\n\nif c == \";\":\n\nif entity.startswith(\"#\"):\n\nif frozenset(entity[1:]) - HEXDIGITS: raise InvalidNumericEntityError()\n\nelif not entity.isalpha():\n\n...\n\nraise InvalidAlphaEntityError()\n\n169\n\nset type 121➤\n\n170\n\nChapter 4. Control Structures and Functions\n\nThe function has various states, for example, after reading an ampersand (&), it enters the PARSING_ENTITY state, and stores the characters between (but excluding) the ampersand and semicolon in the entity string.\n\nThe part of the code shown here handles the case when a semicolon has been found while reading an entity. If the entity is numeric (of the form “&#”, with we convert the hexadecimal digits, and then “;”, for example, “&#20AC;”), numeric part of it into a set and take away from the set all the hexadecimal digits; if anything is left at least one invalid character was present and we raise a custom exception. If the entity is alphabetic (of the form “&”, with letters, and then“;”, for example, “&copy;”), we raise a custom exception if any of its letters is not alphabetic.\n\n... except (InvalidEntityError,\n\nInvalidTagContentError) as err:\n\nif isinstance(err, InvalidNumericEntityError):\n\nerror = \"invalid numeric entity\"\n\nelif isinstance(err, InvalidAlphaEntityError):\n\nerror = \"invalid alphabetic entity\"\n\nelif isinstance(err, InvalidTagContentError):\n\nerror = \"invalid tag\"\n\nprint(\"ERROR {0} in {1} on line {2} column {3}\"\n\n.format(error, filename, lino, column))\n\nif skip_on_first_error:\n\nraise\n\n...\n\nIf a parsing exception is raised we catch it in this except block. By using the InvalidEntityError base class, we catch both InvalidNumericEntityError and InvalidAlphaEntityError exceptions. We then use isinstance() to check which type of exception occurred, and to set the error message accordingly. The built-in isinstance() functionreturnsTrue if itsﬁrst argumentisthesametype as the type (or one of that type’s base types) given as its second argument.\n\nWe could have used a separate except block for each of the three custom parsing exceptions, but in this case combining them means that we avoided repeating the last four lines (from the print() call to raise), in each one.\n\nThe program has two modes of use. If skip_on_first_error is False, the pro- gram continues checking a ﬁle even after a parsing error has occurred; this can lead to multiple error messages being output for each ﬁle. If skip_on_first_error is True, once a parsing error has occurred, after the (one and only) error message is printed, raise is called to reraise the parsing excep- tion and the outer (per-ﬁle) try block is left to catch it.\n\nisin- stance() ➤ 242\n\nException Handling\n\n... elif state == PARSING_ENTITY:\n\n...\n\nraise EOFError(\"missing ';' at end of \" + filename)\n\nAt theendof parsing a ﬁle,weneedtocheck toseewhether wehavebeenleftin the middleof an entity. If we have,we raise an EOFError,the built-in end-of-ﬁle exception,but give it our own messagetext. We could just aseasily haveraised a custom exception.\n\nexcept (InvalidEntityError, InvalidTagContentError):\n\npass # Already handled\n\nexcept EOFError as err:\n\nprint(\"ERROR unexpected EOF:\", err)\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nfinally:\n\nif fh is not None: fh.close()\n\nFor the outer try block we have used separate except blocks since the behavior wewantvaries. If wehavea parsing exception,weknowthatanerrormessage has already been output and the purpose is simply to break out of reading the ﬁle and to move on to the next ﬁle, so we don’t need to do anything in the ex- ception handler. If we get an EOFError it could be caused by a genuine prema- ture end of ﬁle or it could be the result of us raising the exception ourselves. In either case, we print an error message, and the exception’s text. If an Envi- ronmentError occurs (i.e.,if an IOError or an OSError occurs),we simply print its message. And ﬁnally, no matter what, if the ﬁle was opened, we close it.\n\nCustom Functions\n\nFunctionsarea meansby which wecanpackageupandparameterizefunction- ality. Four kinds of functions can be created in Python: global functions, local functions, lambda functions, and methods.\n\nEvery function we have created so far has been a global function. Global objects (including functions) are accessible to any code in the same module (i.e.,the same .py ﬁle) in which the object is created. Global objects can also be accessed from other modules, as we will see in the next chapter.\n\nLocal functions (also called nested functions) are functions that are deﬁned inside other functions. These functions are visible only to the function where they are deﬁned; they are especially useful for creating small helper functions that have no use elsewhere. We ﬁrst show them in Chapter 7.\n\n171\n\n|||\n\n172\n\nChapter 4. Control Structures and Functions\n\nOnline Documentation\n\nAlthough this book provides solid coverage of the Python 3 language and the built-in functions and most commonly used modules in the standard library, Python’s online documentation provides a considerable amount of reference documentation, both on the language, and particularly on Python’s extensive standard library. The documentation is available online at docs.python.org and is also provided with Python itself.\n\nOn Windowsthe documentation is supplied in the Windowshelp ﬁle format. Click Start→All Programs→Python 3.x→Python Manuals to launch the Windows help browser. Thistool has both an Index and a Search function that makes ﬁnding documentation easy. Unix users have the documentation in HTML format. In addition to the hyperlinks,there are various index pages. There isalsoa very convenient Quick Searchfunction availableon theleft-handside of each page.\n\nThe most frequently used online document for new users is the Library Reference, and for experienced users the Global Module Index. Both of these have links to pages covering Python’s entire standard library—and in the case of the Library Reference, links to pages covering all of Python’s built-in functionality as well.\n\nIt is well worth skimming through the documentation, particularly the Li- brary Reference or the Global Module Index, to see what Python’s standard library offers, and clicking through to the documentation of whichever top- icsareof interest. Thisshouldprovideaninitialimpressionof whatisavail- able and should also help you to establish a mental pictureof where you can ﬁnd the documentation you are interested in. (A brief summary of Python’s standard library is provided in Chapter 5.)\n\nHelp is also available from the interpreter itself. If you call the built- in help() function with no arguments, you will enter the online help system—simply follow the instructions to get the information you want, and type “q” or “quit” to return to the interpreter. If you know what module or data type you want help on, you can call help() with the module or data typeasitsargument. Forexample,help(str) providesinformationonthestr data type, including all of its methods, help(dict.update) provides informa- tion on the dict collection data type’supdate() method,and help(os) displays information about the os module (providing it has been imported).\n\nOnce familiar with Python, it is often sufﬁcient to just be reminded about what attributes(e.g.,what methods) a data type provides. This information is available using the dir() function—for example, dir(str) lists all the string methods,and dir(os) lists all the os module’sconstantsand functions (again, providing the module has been imported).\n\nCustom Functions\n\nLambdafunctions are expressions,so they can be created at their point of use; however, they are much more limited than normal functions.\n\nMethods are functions that are associated with a particular data type and can be used only in conjunction with the data type—they are introduced in Chapter 6 when we cover object-oriented programming.\n\nPython provides many built-in functions, and the standard library and third- party libraries add hundreds more (thousands if we count all the methods),so in many casesthe function we want has already been written. For this reason, it is always worth checking Python’s online documentation to see what is al- ready available. See the sidebar “Online Documentation” (172➤).\n\nThe general syntax for creating a (global or local) function is:\n\ndef functionName(parameters):\n\nsuite\n\nTheparametersareoptional,andif thereismorethanonethey arewrittenasa sequence of comma-separated identiﬁers,or as a sequence of identifier=value pairs as we will discussshortly. For example,here is a function that calculates the area of a triangle using Heron’s formula:\n\ndef heron(a, b, c):\n\ns = (a + b + c) / 2 return math.sqrt(s * (s - a) * (s - b) * (s - c))\n\nInside the function, each parameter, a, b, and c, is initialized with the corre- sponding value that was passed as an argument. When the function is called, we must supply all of the arguments,for example,heron(3, 4, 5).If we give too few or too many arguments, a TypeError exception will be raised. When we do a call like thiswe are said to be using positionalarguments,because each argu- ment passed is set as the value of the parameter in the corresponding position. So in this case, a is set to 3, b to 4, and c to 5, when the function is called.\n\nEvery function in Python returns a value, although it is perfectly acceptable (and common) to ignore the return value. The return value is either a single value or a tuple of values, and the values returned can be collections, so there are no practical limitations on what we can return. We can leave a function at any point by using the return statement. If we use return with no arguments, or if we don’t have a return statement at all, the function will return None. (In Chapter 6 we will cover the yield statement which can be used instead of return in certain kinds of functions.)\n\nSome functionshave parametersfor which there can be a sensible default. For example, here is a function that counts the letters in a string,defaulting to the ASCII letters:\n\n173\n\n174\n\nChapter 4. Control Structures and Functions\n\ndef letter_count(text, letters=string.ascii_letters):\n\nletters = frozenset(letters) count = 0 for char in text:\n\nif char in letters: count += 1\n\nreturn count\n\nWe have speciﬁed a default value for the letters parameter by using the parameter=default syntax. This allows us to call letter_count() with just one argument, for example, letter_count(\"Maggie and Hopey\"). Here, inside the function, letters will be the string that was given as the default value. But we can still change the default, for example, using an extra positional argument, letter_count(\"Maggie and Hopey\", \"aeiouAEIOU\"), or using a keyword argument (covered next), letter_count(\"Maggie and Hopey\", letters=\"aeiouAEIOU\").\n\nThe parameter syntax does not permit us to follow parameters with default values with parameters that don’t have defaults, so def bad(a, b=1, c): won’t work. On the other hand, we are not forced to pass our arguments in the order they appear in the function’s deﬁnition—instead, we can use keyword arguments, passing each argument in the form name=value.\n\nHere is a tiny function that returns the string it is given, or if it is longer than the speciﬁed length, it returns a shortened version with an indicator added:\n\ndef shorten(text, length=25, indicator=\"...\"):\n\nif len(text) > length:\n\ntext = text[:length - len(indicator)] + indicator\n\nreturn text\n\nHere are a few example calls:\n\n# returns: 'The Silkie' shorten(\"The Silkie\") # returns: 'The ...' shorten(length=7, text=\"The Silkie\") shorten(\"The Silkie\", indicator=\"&\", length=7) # returns: 'The Si&' # returns: 'The Si&' shorten(\"The Silkie\", 7, \"&\")\n\nBecause both length and indicator have default values, either or both can be omitted entirely, in which case the default is used—this is what happens in the ﬁrst call. In the second call we use keyword arguments for both of the speciﬁed parameters, so we can order them as we like. The third call mixes both positional and keyword arguments. We used a positional ﬁrst argument (positionalargumentsmustalwaysprecedekeywordarguments),andthentwo keyword arguments. The fourth call simply uses positional arguments.\n\nThe difference between a mandatory parameter and an optional parameter is that a parameter with a default is optional (because Python can use the default), and a parameter with no default is mandatory (because Python can-\n\n176\n\nChapter 4. Control Structures and Functions\n\nUsing a conditional expression we can save a line of code for each parameter that has a mutable default argument.\n\nNames and Docstrings\n\nUsing good names for a function and its parameters goes a long way toward making the purpose and use of the function clear to other programmers—and to ourselvessome timeafter we have createdthe function. Hereare a few rules of thumb that you might like to consider.\n\nUse a naming scheme, and use it consistently. In this book we use UP- PERCASE for constants, TitleCase for classes (including exceptions), camel- Case for GUI (Graphical User Interface) functions and methods (covered in Chapter 15), and lowercase or lowercase_with_underscores for every- thing else.\n\nFor all names,avoid abbreviations,unless they are both standardized and widely used.\n\nBe proportional with variable and parameter names: x is a perfectly good name for an x-coordinate and i is ﬁne for a loop counter,but in general the name should be long enough to be descriptive. The name should describe thedata’smeaning rather than itstype(e.g.,amount_due rather than money), unless the use is generic to a particular type—see, for example, the text parameter in the shorten() example (➤ 177).\n\nFunctions and methods should have names that say what they do or what they return (depending on their emphasis), but never how they do it—since that might change.\n\nHere are a few naming examples:\n\ndef find(l, s, i=0): def linear_search(l, s, i=0): def first_index_of(sorted_name_list, name, start=0): # GOOD\n\n# BAD # BAD\n\nAll three functions return the index position of the ﬁrst occurrence of a name in a list of names, starting from the given starting index and using an algorithm that assumes the list is already sorted.\n\nThe ﬁrst one is bad because the name gives no clue as to what will be found, and its parameters (presumably) indicate the required types (list, string, inte- ger) without indicating what they mean. The second one is bad because the function name describes the algorithm originally used—it might have been changed since. This may not matter to users of the function, but it will proba- bly confuse maintainersif the name implies a linear search,but the algorithm implemented has been changed to a binary search. The third one is good be-\n\n||\n\nSe- quence unpack- ing 114➤\n\nCustom Functions\n\ncausethefunctionnamesayswhatisreturned,andtheparameternamesclear- ly indicate what is expected.\n\nNone of the functions have any way of indicating what happens if the name isn’t found—do they return, say, -1, or do they raise an exception? Somehow such information needs to be documented for users of the function.\n\nWe can add documentationto any function by using a docstring—thisissimply a string that comes immediately after the def line, and before the function’s code proper begins. For example,here is the shorten() function we saw earlier, but this time reproduced in full:\n\ndef shorten(text, length=25, indicator=\"...\"):\n\n\"\"\"Returns text or a truncated copy with the indicator added\n\ntext is any string; length is the maximum length of the returned string (including any indicator); indicator is the string added at the end to indicate that the text has been shortened\n\n>>> shorten(\"Second Variety\") 'Second Variety' >>> shorten(\"Voices from the Street\", 17) 'Voices from th...' >>> shorten(\"Radio Free Albemuth\", 10, \"*\") 'Radio Fre*' \"\"\" if len(text) > length:\n\ntext = text[:length - len(indicator)] + indicator\n\nreturn text\n\nIt isnot unusualfor a functionor method’sdocumentationtobelonger thanthe function itself. One convention is to make the ﬁrst line of the docstring a brief one-line description, then have a blank line followed by a full description, and thentoreproducesomeexamplesasthey wouldappearif typedininteractively. In Chapter 5 and Chapter 9 we will see how examples in function documenta- tion can be used to provide unit tests.\n\nArgument and Parameter Unpacking\n\nWe saw in the previous chapter that we can use the sequence unpacking oper- ator (*) to supply positional arguments. For example,if we wanted to compute the area of a triangle and had the lengths of the sides in a list, we could make the call like this, heron(sides[0], sides[1], sides[2]),or simply unpack the list and do the much simpler call, heron(*sides).And if the list (or other sequence) has more items than the function has parameters,we can use slicing to extract exactly the right number of arguments.\n\n177\n\n||",
      "page_number": 166
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 177-185)",
      "start_page": 177,
      "end_page": 185,
      "detection_method": "topic_boundary",
      "content": "178\n\nChapter 4. Control Structures and Functions\n\nWe can also use the sequence unpacking operator in a function’s parameter list. This is useful when we want to create functions that can take a variable number of positional arguments. Here is a product() function that computes the product of the arguments it is given:\n\ndef product(*args): result = 1 for arg in args:\n\nresult *= arg\n\nreturn result\n\nThis function has one parameter called args. Having the * in front means that inside the function the args parameter will be a tuple with its items set to however many positional arguments are given. Here are a few example calls:\n\nproduct(1, 2, 3, 4) product(5, 3, 8) product(11)\n\n# args == (1, 2, 3, 4); returns: 24 # args == (5, 3, 8); returns: 120 # args == (11,); returns: 11\n\nWe can have keyword arguments following positional arguments, as this function to calculate the sum of its arguments, each raised to the given pow- er, shows:\n\ndef sum_of_powers(*args, power=1):\n\nresult = 0 for arg in args:\n\nresult += arg ** power\n\nreturn result\n\nThe function can be called with just positional arguments, for example, sum_of_powers(1, 3, 5), or with both positional and keyword arguments,for ex- ample, sum_of_powers(1, 3, 5, power=2).\n\nIt is also possible to use * as a “parameter” in its own right. This is used to signify thattherecanbenopositionalargumentsafter the *,althoughkeyword arguments are allowed. Here is a modiﬁed version of the heron() function. This time the function takes exactly three positional arguments, and has one optional keyword argument.\n\ndef heron2(a, b, c, *, units=\"square meters\"):\n\ns = (a + b + c) / 2 area = math.sqrt(s * (s - a) * (s - b) * (s - c)) return \"{0} {1}\".format(area, units)\n\nHere are a few example calls:\n\nheron2(25, 24, 7) heron2(41, 9, 40, units=\"sq. inches\") # returns: '180.0 sq. inches'\n\n# returns: '84.0 square meters'\n\nCustom Functions\n\nheron2(25, 24, 7, \"sq. inches\")\n\n# WRONG! raises TypeError\n\nIn the third call we have attempted to pass a fourth positional argument, but the * does not allow this and causes a TypeError to be raised.\n\nBy making the * the ﬁrst parameter we can prevent any positional arguments from being used, and force callers to use keyword arguments. Here is such a (ﬁctitious) function’s signature:\n\ndef print_setup(*, paper=\"Letter\", copies=1, color=False):\n\nWe can call print_setup() with no arguments, and accept the defaults. Or we can change some or all of the defaults, for example, print_setup(paper=\"A4\", color=True). But if we attempt to use positional arguments, for example, print_setup(\"A4\"), a TypeError will be raised.\n\nJust as we can unpack a sequence to populate a function’s positional argu- ments, we can also unpack a mapping using the mapping unpacking operator, asterisk asterisk (**).★ We can use ** to pass a dictionary to the print_setup() function. For example:\n\noptions = dict(paper=\"A4\", color=True) print_setup(**options)\n\nHere the options dictionary’s key–value pairs are unpacked with each key’s value being assigned to the parameter whose name is the same as the key. If the dictionary contains a key for which there is no corresponding parameter, a TypeError is raised. Any argument for which the dictionary has no corre- sponding item is set to its default value—but if there is no default,a TypeError is raised.\n\nWecanalsousethemapping unpacking operatorwithparameters. Thisallows us to create functions that will accept as many keyword arguments as are giv- en. Hereisan add_person_details() functionthattakesSocialSecuritynumber and surname positional arguments, and any number of keyword arguments:\n\ndef add_person_details(ssn, surname, **kwargs):\n\nprint(\"SSN =\", ssn) print(\" for key in sorted(kwargs):\n\nsurname =\", surname)\n\nprint(\"\n\n{0} = {1}\".format(key, kwargs[key]))\n\nThis function could be called with just the two positional arguments, or with additional information, for example, add_person_details(83272171, \"Luther\", forename=\"Lexis\", age=47). This provides us with a lot of ﬂexibility. And we\n\n★As we saw in Chapter 2, when used as a binary operator, ** is the pow() operator.\n\n179\n\n180\n\nChapter 4. Control Structures and Functions\n\ncan of course accept both a variable number of positional arguments and a variable number of keyword arguments:\n\ndef print_args(*args, **kwargs):\n\nfor i, arg in enumerate(args):\n\nprint(\"positional argument {0} = {1}\".format(i, arg))\n\nfor key in kwargs:\n\nprint(\"keyword argument {0} = {1}\".format(key, kwargs[key]))\n\nThis function just prints the arguments it is given. It can be called with no arguments, or with any number of positional and keyword arguments.\n\nAccessing Variables in the Global Scope\n\nIt is sometimes convenient to have a few global variables that are accessed by various functions in the program. This is usually okay for “constants”, but is not a good practice for variables, although for short one-off programs it isn’t always unreasonable.\n\nThe digit_names.py program takes an optional language (“en” or “fr”) and a number on the command line and outputs the names of each of the digits it is given. So if it is invoked with “123” on the command line, it will output “one two three”.The program has three global variables:\n\nLanguage = \"en\"\n\nENGLISH = {0: \"zero\", 1: \"one\", 2: \"two\", 3: \"three\", 4: \"four\",\n\n5: \"five\", 6: \"six\", 7: \"seven\", 8: \"eight\", 9: \"nine\"}\n\nFRENCH = {0: \"zéro\", 1: \"un\", 2: \"deux\", 3: \"trois\", 4: \"quatre\", 5: \"cinq\", 6: \"six\", 7: \"sept\", 8: \"huit\", 9: \"neuf\"}\n\nWe have followed the convention that all uppercase variable names indicate constants, and have set the default language to English. (Python does not provide a direct way to create constants, instead relying on programmers to respect the convention.) Elsewhere in the program we access the Language variable, and use it to choose the appropriate dictionary to use:\n\ndef print_digits(digits):\n\ndictionary = ENGLISH if Language == \"en\" else FRENCH for digit in digits:\n\nprint(dictionary[int(digit)], end=\" \")\n\nprint()\n\nWhen Python encounters the Language variable in this function it looks in the local (function) scope and doesn’t ﬁnd it. So it then looks in the global (.py ﬁle) scope,and ﬁndsit there. The end keyword argument used with theﬁrst print() call is explained in the sidebar “The print() Function” (➤ 181).\n\n||\n\nsorted()\n\n140, 144➤\n\n182\n\nChapter 4. Control Structures and Functions\n\n“fr”,but the global Language variable used in the print_digits() function would remain unchanged as “en”.\n\nFor nontrivial programs it is best not to use global variables except as con- stants, in which case there is no need to use the global statement.\n\nLambda Functions\n\nLambda functions are functions created using the following syntax:\n\nlambda parameters: expression\n\nThe parameters are optional, and if supplied they are normally just comma- separatedvariablenames,thatis,positionalarguments,althoughthecomplete argumentsyntaxsupportedby def statementscanbeused. Theexpressioncan- not contain branches or loops (although conditional expressions are allowed), and cannot have a return (or yield) statement. The result of a lambda expres- sion isan anonymousfunction. When a lambda function iscalled it returnsthe result of computing the expression as its result. If the expression is a tuple it should be enclosed in parentheses.\n\nHereisa simplelambda functionfor adding an s(or not)depending on whether its argument is 1:\n\ns = lambda x: \"\" if x == 1 else \"s\"\n\nThe lambda expression returns an anonymous function which we assign to the variable s.Any (callable)variable can be called using parentheses,so given the count of ﬁles processed in some operation we could output a message using the s() function like this: print(\"{0} file{1} processed\".format(count, s(count))).\n\nLambda functions are often used as the key function for the built-in sorted() function and for the list.sort() method. Suppose we have a list of elements as 3-tuplesof (group,number,name),and we wanted to sort this list in various ways. Here is an example of such a list:\n\nelements = [(2, 12, \"Mg\"), (1, 11, \"Na\"), (1, 3, \"Li\"), (2, 4, \"Be\")]\n\nIf we sort this list, we get this result:\n\n[(1, 3, 'Li'), (1, 11, 'Na'), (2, 4, 'Be'), (2, 12, 'Mg')]\n\nprovide a We saw earlier when we covered the sorted() function that we can key function to alter the sort order. For example, if we wanted to sort the list by number and name, rather than the natural ordering of group, number, and name, we could write a tiny function, def ignore0(e): return e[1], e[2], which could be provided as the key function. Creating lots of little functions like this can be inconvenient, so a frequently used alternative is a lambda function:\n\n||\n\nGenera- tor func- tions ➤ 279\n\nDefault dictio- naries 135➤\n\nCustom Functions\n\nelements.sort(key=lambda e: (e[1], e[2]))\n\nHere the key function is lambda e: (e[1], e[2]) with e being each 3-tuple ele- ment in the list. The parentheses around the lambda expression are required when the expression is a tuple and the lambda function is created as a func- tion’s argument. We could use slicing to achieve the same effect:\n\nelements.sort(key=lambda e: e[1:3])\n\nA slightly more elaborate version gives us sorting in case-insensitive name, number order:\n\nelements.sort(key=lambda e: (e[2].lower(), e[1]))\n\nHere are two equivalent ways to create a function that calculates the area of a triangle using the conventional 1 2\n\n× base × height formula:\n\ndef area(b, h):\n\narea = lambda b, h: 0.5 * b * h\n\nreturn 0.5 * b * h\n\nWe can call area(6, 5), whether we created the function using a lambda expres- sion or using a def statement, and the result will be the same.\n\nAnother neat use of lambda functionsis when we want to create default dictio- naries. Recall from the previous chapter that if we access a default dictionary using a nonexistent key,a suitable item is created with the given key and with a default value. Here are a few examples:\n\nminus_one_dict = collections.defaultdict(lambda: -1) point_zero_dict = collections.defaultdict(lambda: (0, 0)) message_dict = collections.defaultdict(lambda: \"No message available\")\n\nIf weaccessthe minus_one_dict with a nonexistentkey,a new itemwill becreat- ed with the given key and with a value of -1. Similarly for the point_zero_dict where the value will be the tuple (0, 0),and for the message_dict where the val- ue will be the “No message available” string.\n\nAssertions\n\nWhat happens if a function receives arguments with invalid data? What happens if we make a mistake in the implementation of an algorithm and performanincorrectcomputation? Theworstthing thatcanhappenisthatthe program executes without any (apparent)problem and no one is any the wiser. One way to help avoid such insidiousproblemsis to write tests—something we will brieﬂy look at in Chapter 5. Another way is to state the preconditions and postconditions and to indicate an error if any of these are not met. Ideally, we should use tests and also state preconditions and postconditions.\n\n183\n\n||\n\n184\n\nChapter 4. Control Structures and Functions\n\nPreconditions and postconditions can be speciﬁed using assert statements, which have the syntax:\n\nassert boolean_expression, optional_expression\n\nIf the boolean_expression evaluates to False an AssertionError exception is raised. If the optional optional_expression is given, it is used as the argument to the AssertionError exception—this is useful for providing error messages. Note, though, that assertions are designed for developers, not end-users. Problems that occur in normal program use such as missing ﬁles or invalid command-lineargumentsshouldbehandledby other means,such asproviding an error or log message.\n\nHere are two new versions of the product() function. Both versions are equiv- alent in that they require that all the arguments passed to them are nonzero, and consider a call with a 0 argument to be a coding error.\n\ndef product(*args): # pessimistic\n\ndef product(*args): # optimistic\n\nassert all(args), \"0 argument\" result = 1 for arg in args:\n\nresult = 1 for arg in args:\n\nresult *= arg\n\nresult *= arg\n\nreturn result\n\nassert result, \"0 argument\" return result\n\nThe “pessimistic”version on the left checksall the arguments(or up to the ﬁrst 0 argument)on every call. The “optimistic”version on the right just checksthe result; after all, if any argument was 0, then the result will be 0.\n\nIf one of these product() functions is called with a 0 argument an Assertion- Error exception will be raised, and output similar to the following will be writ- ten to the error stream (sys.stderr, usually the console):\n\nTraceback (most recent call last): File \"program.py\", line 456, in <module> x = product(1, 2, 0, 4, 8) File \"program.py\", line 452, in product assert result, \"0 argument\" AssertionError: 0 argument\n\nPython automatically provides a traceback that gives the ﬁlename, function, and line number, as well as the error message we speciﬁed.\n\nOncea programisready for publicrelease(andof coursepassesallitstestsand does not violate any assertions), what do we do about the assert statements? We can tell Python not to execute assert statements—in effect, to throw them away at runtime. This can be done by running the program at the command line with the -O option, for example, python -O program.py. Another approach is to set the PYTHONOPTIMIZE environment variable to O. If the docstrings are of\n\nCustom Functions\n\nno use to our users (and normally they wouldn’t be), we can use the -OO option which in effect strips out both assert statements and docstrings: Note that there is no environment variable for setting this option. Some developerstake a simpler approach:They producea copy of their programwith all assert state- ments commented out, and providing this passes their tests, they release the assertion-free version.\n\nExample: make_html_skeleton.py\n\nIn thissection we draw together some of the techniquescovered in thischapter and show them in the context of a complete example program.\n\nVery small Web sites are often created and maintained by hand. One way to make this slightly more convenient is to have a program that can gener- ate skeleton HTML ﬁles that can later be ﬂeshed out with content. The make_html_skeleton.py programisaninteractiveprogramthatpromptstheuser forvariousdetailsandthencreatesaskeletonHTMLﬁle. Theprogram’smain() function has a loop so that users can create skeleton after skeleton, and it re- tainscommon data (e.g.,copyright information)so that usersdon’t have to type it in more than once. Here is a transcript of a typical interaction:\n\nmake_html_skeleton.py\n\nMake HTML Skeleton\n\nEnter your name (for copyright): Harold Pinter Enter copyright year [2008]: 2009 Enter filename: career-synopsis Enter title: Career Synopsis Enter description (optional): synopsis of the career of Harold Pinter Enter a keyword (optional): playwright Enter a keyword (optional): actor Enter a keyword (optional): activist Enter a keyword (optional): Enter the stylesheet filename (optional): style Saved skeleton career-synopsis.html\n\nCreate another (y/n)? [y]:\n\nMake HTML Skeleton\n\nEnter your name (for copyright) [Harold Pinter]: Enter copyright year [2009]: Enter filename: Cancelled\n\nCreate another (y/n)? [y]: n\n\n185\n\n|||\n\nstr. format() 78➤\n\n186\n\nChapter 4. Control Structures and Functions\n\nNotice that for the second skeleton the name and year had as their defaults the values entered previously, so they did not need to be retyped. But no default for the ﬁlename is provided, so when that was not given the skeleton was cancelled.\n\nNow that we have seen how the program is used, we are ready to study the code. The program begins with two imports:\n\nimport datetime import xml.sax.saxutils\n\nThe datetime module provides some simple functions for creating date- time.date and datetime.time objects. The xml.sax.saxutils module has a useful xml.sax.saxutils.escape() function that takes a string and returns an equiv- alent string with the special HTML characters (“&”, “<”, and “>”) in their es- caped forms (“&amp;”, “&lt;”, and “&gt;”).\n\nThree global strings are deﬁned; these are used as templates.\n\nCOPYRIGHT_TEMPLATE = \"Copyright (c) {0} {1}. All rights reserved.\"\n\nSTYLESHEET_TEMPLATE = ('<link rel=\"stylesheet\" type=\"text/css\" '\n\n'media=\"all\" href=\"{0}\" />\\n')\n\nHTML_TEMPLATE = \"\"\"<?xml version=\"1.0\"?> <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \\ \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"> <html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"> <head> <title>{title}</title> <!-- {copyright} --> <meta name=\"Description\" content=\"{description}\" /> <meta name=\"Keywords\" content=\"{keywords}\" /> <meta equiv=\"content-type\" content=\"text/html; charset=utf-8\" /> {stylesheet}\\ </head> <body>\n\n</body> </html> \"\"\"\n\nThese strings will be used as templates in conjunction with the str.format() method. In the case of HTML_TEMPLATE we have used names rather than index positions for the ﬁeld names, for example, {title}. We will see shortly that we must use keyword arguments to provide values for these.\n\nclass CancelledError(Exception): pass\n\nExample: make_html_skeleton.py\n\nOne custom exception is deﬁned; we will see it in use when we look at a couple of the program’s functions.\n\nThe program’s main() function is used to set up some initial information, and to provide a loop. On each iteration the user has the chance to enter some information for the HTML page they want generated, and after each one they are given the chance to ﬁnish.\n\ndef main():\n\ninformation = dict(name=None, year=datetime.date.today().year,\n\nfilename=None, title=None, description=None, keywords=None, stylesheet=None)\n\nwhile True: try:\n\nprint(\"\\nMake HTML Skeleton\\n\") populate_information(information) make_html_skeleton(**information)\n\nexcept CancelledError: print(\"Cancelled\")\n\nif (get_string(\"\\nCreate another (y/n)?\", default=\"y\").lower()\n\nnot in {\"y\", \"yes\"}): break\n\nThe datetime.date.today() functionreturnsa datetime.date objectthatholdsto- day’s date. We want just the year attribute. All the other items of information are set to None since there are no sensible defaults that can be set.\n\nInside the while loop the program prints a title, then calls the populate_infor- mation() function with the information dictionary. This dictionary is updated inside the populate_information() function. Next, the make_html_skeleton() function iscalled—thisfunction takesa number of arguments,but rather than give explicit values for each one we have simply unpacked the information dic- tionary.\n\nIf the user cancels, for example, by not providing mandatory information, the program prints out “Cancelled”. At the end of each iteration (whether cancelled or not), the user is asked whether they want to create another skeleton—if they don’t, we break out of the loop and the program terminates.\n\ndef populate_information(information):\n\nname = get_string(\"Enter your name (for copyright)\", \"name\",\n\ninformation[\"name\"])\n\nif not name:\n\nraise CancelledError()\n\nyear = get_integer(\"Enter copyright year\", \"year\",\n\ninformation[\"year\"], 2000, datetime.date.today().year + 1, True)\n\n187",
      "page_number": 177
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 186-194)",
      "start_page": 186,
      "end_page": 194,
      "detection_method": "topic_boundary",
      "content": "str. format() 78➤\n\nUs- ing str. format() with map- ping un- packing 81➤\n\nExample: make_html_skeleton.py\n\ntitle = xml.sax.saxutils.escape(title) description = xml.sax.saxutils.escape(description) keywords = \",\".join([xml.sax.saxutils.escape(k)\n\nfor k in keywords]) if keywords else \"\"\n\nstylesheet = (STYLESHEET_TEMPLATE.format(stylesheet)\n\nif stylesheet else \"\")\n\nhtml = HTML_TEMPLATE.format(**locals())\n\nTo get the copyright text we call str.format() on the COPYRIGHT_TEMPLATE, sup- plying the year and name (suitably HTML-escaped) as positional arguments to replace {0} and {1}.For the title and description we produce HTML-escaped copies of their texts.\n\nFor the HTML keywords we have two cases to deal with, and we distinguish them using a conditionalexpression. If no keywordshave been entered, we set the keywords string to be the empty using. Otherwise,we use a list comprehen- sion to iterate over all the keywords to produce a new list of strings,with each one being HTML-escaped. This list is then joined into a single string with a comma separating each item using str.join().\n\nThe stylesheet text is created in a similar way to the copyright text,but within the context of a conditional expression so that the text is the empty string if no stylesheet is speciﬁed.\n\narguments used The html text is created from the HTML_TEMPLATE, with keyword to provide the data for the replacement ﬁelds rather than the positional argu- ments used for the other template strings. Rather than pass each argument explicitly using key=value syntax, we have used mapping unpacking on the mapping returned by locals() to do this for us. (The alternative would be to write the format() call as .format(title=title, copyright=copyright, etc.)\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") fh.write(html)\n\nexcept EnvironmentError as err:\n\nprint(\"ERROR\", err)\n\nelse:\n\nprint(\"Saved skeleton\", filename)\n\nfinally:\n\nif fh is not None: fh.close()\n\nOnce the HTML has been prepared we write it to the ﬁle with the given ﬁlename. We inform theuser that the skeleton hasbeen saved—or of theerror message if something went wrong. As usual we use a finally clause to ensure that the ﬁle is closed if it was opened.\n\n189\n\nUs- ing str. format() with map- ping un- packing 81➤\n\n190\n\nChapter 4. Control Structures and Functions\n\ndef get_string(message, name=\"string\", default=None, minimum_length=0, maximum_length=80):\n\nmessage += \": \" if default is None else \" [{0}]: \".format(default) while True: try:\n\nline = input(message) if not line:\n\nif default is not None: return default if minimum_length == 0:\n\nreturn \"\"\n\nelse:\n\nraise ValueError(\"{0} may not be empty\".format(\n\nname)) if not (minimum_length <= len(line) <= maximum_length):\n\nraise ValueError(\"{name} must have at least \"\n\n\"{minimum_length} and at most \" \"{maximum_length} characters\".format( **locals()))\n\nreturn line\n\nexcept ValueError as err:\n\nprint(\"ERROR\", err)\n\nThis function has one mandatory argument, message, and four optional argu- ments. If a default value is given we include it in the message string so that the user can see the default they would get if they just press Enter without typ- ing any text. The rest of the function is enclosed in an inﬁnite loop. The loop can be broken out of by the user entering a valid string—or by accepting the default (if given) by just pressing Enter. If the user makes a mistake, an error message is printed and the loop continues. As usual,rather than explicitly us- ing key=value syntax topasslocalvariablesto str.format() with a formatstring that uses named ﬁelds, we have simply used mapping unpacking on the map- ping returned by locals() to do this for us.\n\nThe user could also break out of the loop,and indeed out of the entire program, by typing Ctrl+C—this would cause a KeyboardInterrupt exception to be raised, and sincethisisnot handledby any of theprogram’sexceptionhandlers,would cause the program to terminate and print a traceback. Should we leave such a “loophole”? If we don’t,and there is a bug in our program,we could leave the user stuck in an inﬁnite loop with no way out except to kill the process. Unless there is a very strong reason to prevent Ctrl+C from terminating a program, it should not be caught by any exception handler.\n\nNotice that this function is not speciﬁc to the make_html_skeleton.py program—it could be reused in many interactive programs of this type. Such reuse could be achieved by copying and pasting, but that would lead to main-\n\nExample: make_html_skeleton.py\n\ntenance headaches—in the next chapter we will see how to create custom mod- ules with functionality that can be shared across any number of programs.\n\ndef get_integer(message, name=\"integer\", default=None, minimum=0,\n\nmaximum=100, allow_zero=True):\n\n...\n\nThis function is so similar in structure to the get_string() function that it would add nothing to reproduce it here. (It is included in the source code that accompanies the book, of course.) The allow_zero parameter can be useful when 0 is not a valid value but where we want to permit one invalid value to signify that the user has cancelled. Another approach would be to pass an invalid default value, and if that is returned, take it to mean that the user has cancelled.\n\nThe last statement in the program is simply a call to main(). Overall the pro- gram is slightly more than 150 lines and shows several features of the Python language introduced in this chapter and the previous ones.\n\nSummary\n\nThischapter covered the complete syntax for all of Python’scontrol structures. It also showed how to raise and catch exceptions, and how to create custom exception types.\n\nMost of the chapter was devoted to custom functions. We saw how to create functions and presented some rules of thumb for naming functions and their parameters. Wealsosawhowtoprovidedocumentationforfunctions. Python’s versatile parameter syntax and argument passing were covered in detail, in- cluding both ﬁxedand variablenumbersof positionaland keywordarguments, and default values for arguments of both immutable and mutable data types. We also brieﬂy recapped sequence unpacking with * and showed how to do mapping unpacking with **. Mapping unpacking is particularly useful when applied to a dictionary (or other mapping), or to the mapping returned by lo- cals(), for passing key–value arguments to a str.format() format string that uses named ﬁelds.\n\nIf we need to assign a new value to a global variable inside a function, we can do so by declaring that the variable is global, thereby preventing Python from creating a local variable and assigning to that. In general,though,it is best to use global variables only for constants.\n\nLambda functions are often used as key functions, or in other contexts where functions must be passed as parameters. This chapter showed how to create lambda functions, both as anonymous functions and as a means of creating small named one-line functions by assigning them to a variable.\n\n191\n\n|||\n\n192\n\nChapter 4. Control Structures and Functions\n\nThe chapter also covered the use of the assert statement. This statement is very useful for specifying the preconditions and postconditions that we expect to be true on every use of a function, and can be a real aid to robust programming and bug hunting.\n\nIn this chapter we covered all the fundamentals of creating functions, but many other techniques are available to us. These include creating dynamic functions (creating functions at runtime, possibly with implementations that differ depending on circumstances), covered in Chapter 5; local (nested) func- tions, covered in Chapter 7; and recursive functions, generator functions, and so on, covered in Chapter 8.\n\nAlthough Python has a considerable amount of built-in functionality, and a very extensive standard library, it is still likely that we will write some func- tions that would be useful in many of the programs we develop. Copying and pasting such functions would lead to maintenance nightmares, but fortunate- ly Python provides a clean easy-to-use solution: custom modules. In the next chapter we will learn how to create our own modules with our own functions inside them. We will also see how to import functionality from the standard library and from our own modules, and will brieﬂy review what the standard library has to offer so that we can avoid reinventing the wheel.\n\nExercise\n\nWrite an interactive program that maintains lists of strings in ﬁles.\n\nWhen the program is run it should create a list of all the ﬁles in the current directory that have the .lst extension. Use os.listdir(\".\") to get all the ﬁles andﬁlter out thosethatdon’thavethe .lst extension. If therearenomatching ﬁles the program should prompt the user to enter a ﬁlename—adding the .lst extension if the user doesn’t enter it. If there are one or more .lst ﬁles they should be printed as a numbered list starting from 1.The user should be asked toenter thenumber of theﬁlethey want toload,or 0,in which casethey should be asked to give a ﬁlename for a new ﬁle.\n\nIf an existing ﬁle was speciﬁed its items should be read. If the ﬁle is empty,or if a new ﬁle was speciﬁed, the program should show a message, “no items are in the list”.\n\nIf there are no items, two options should be offered: “Add” and “Quit”. Once the list has one or more items, the list should be shown with each item num- bered from 1, and the options offered should be “Add”, “Delete”, “Save” (unless already saved), and “Quit”. If the user chooses “Quit” and there are unsaved changes they should be given the chance to save. Here is a transcript of a ses- sion with the program (with most blank lines removed, and without the “List Keeper” title shown above the list each time):\n\n|||\n\nExercise\n\nChoose filename: movies\n\n-- no items are in the list -- [A]dd [Q]uit [a]: a Add item: Love Actually\n\n1: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: a Add item: About a Boy\n\n1: About a Boy 2: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: Add item: Alien\n\n1: About a Boy 2: Alien 3: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: k ERROR: invalid choice--enter one of 'AaDdSsQq' Press Enter to continue... [A]dd [D]elete [S]ave [Q]uit [a]: d Delete item number (or 0 to cancel): 2\n\n1: About a Boy 2: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: s Saved 2 items to movies.lst Press Enter to continue...\n\n1: About a Boy 2: Love Actually [A]dd [D]elete [Q]uit [a]: Add item: Four Weddings and a Funeral\n\n1: About a Boy 2: Four Weddings and a Funeral 3: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: q Save unsaved changes (y/n) [y]: Saved 3 items to movies.lst\n\nKeep the main() function fairly small (less than 30 lines) and use it to provide the program’s main loop. Write a function to get the new or existing ﬁlename (and in the latter case to load the items), and a function to present the op- tions and get the user’s choice of option. Also write functions to add an item, delete an item, print a list (of either items or ﬁlenames), load the list, and save the list. Either copy the get_string() and get_integer() functions from make_html_skeleton.py, or write your own versions.\n\n193\n\n194\n\nChapter 4. Control Structures and Functions\n\nWhen printing the list or the ﬁlenames, print the item numbers using a ﬁeld width of 1if there are less than ten items,of 2 if there are less than 100 items, and of 3 otherwise.\n\nKeep the items in case-insensitive alphabetical order, and keep track of whether the list is “dirty” (has unsaved changes). Offer the “Save” option only if the list is dirty and ask the user whether they want to save unsaved changes when they quit only if the list is dirty. Adding or deleting an item will make the list dirty; saving the list will make it clean again.\n\nA model solution is provided in listkeeper.py; it is less than 200 lines of code.\n\nOnline doc- umenta- tion 172➤\n\n5\n\nModules and Packages ● Overview of Python’s Standard Library\n\nModules\n\nWhereas functions allow us to parcel up pieces of code so that they can be reused throughout a program, modules provide a means of collecting sets of functions (and as we will see in the next chapter, custom data types) together so that they can be used by any number of programs. Python also hasfacilities for creating packages—these are sets of modules that are grouped together, usually because their modules provide related functionality or because they depend on each other.\n\nThis chapter’s ﬁrst section describes the syntaxes for importing functionality from modules and packages—whether from the standard library, or from our own custom modules and packages. The section then goes on to show how to create custom packages and custom modules. Two custom module examples are shown, the ﬁrst introductory and the second illustrating how to handle many of the practical issues that arise, such as platform independence and testing.\n\nThe second section providesa brief overview of Python’sstandard library. It is important to be aware of what the library has to offer, since using predeﬁned functionality makes programming much faster than creating everything from scratch. Also, many of the standard library’s modules are widely used, well tested, and robust. In addition to the overview, a few small examples are used to illustrate some common use cases. And cross-references are provided for modules covered in other chapters.\n\nModules and Packages\n\nA Python module, simply put, is a .py ﬁle. A module can contain any Python code we like. All the programswe have written so far have been contained in a single .py ﬁle,and so they are modulesaswell asprograms. The key difference\n\n195\n\n||||\n\n|||\n\n196\n\nChapter 5. Modules\n\nis that programs are designed to be run, whereas modules are designed to be imported and used by programs.\n\nNot all modules have associated .py ﬁles—for example, the sys module is built into Python, and some modules are written in other languages (most com- monly, C). However, much of Python’s library is written in Python, so, for ex- ample, if we write import collections we can create named tuples by calling collections.namedtuple(), and the functionality we are accessing is in the col- lections.py module ﬁle. It makes no difference to our programs what lan- guage a module is written in, since all modules are imported and used in the same way.\n\nSeveral syntaxes can be used when importing. For example:\n\nimport importable import importable1, importable2, ..., importableN import importable as preferred_name\n\nHere importable isusually a modulesuch as collections,but could bea package or a module in a package, in which case each part is separated with a dot (.), for example, os.path. The ﬁrst two syntaxes are the ones we use throughout this book. They are the simplest and also the safest because they avoid the possibility of having name conﬂicts, since they force us to always use fully qualiﬁed names.\n\nThe third syntax allows us to give a name of our choice to the package or mod- ule we are importing—theoretically this could lead to name clashes, but in practice the as syntax is used to avoid them. Renaming is particularly useful when experimenting with different implementations of a module. For ex- ample, if we had two modules MyModuleA and MyModuleB that had the same API (ApplicationProgramming Interface),wecouldwrite import MyModuleA as MyMod- ule in a program, and later on seamlessly switch to using import MyModuleB as MyModule.\n\nWhere should import statementsgo? It iscommon practiceto put all the import statements at the beginning of .py ﬁles, after the shebang line, and after the module’s documentation. And as we said back in Chapter 1, we recommend importing standard library modules ﬁrst, then third-party library modules, and ﬁnally our own modules.\n\nHere are some other import syntaxes:\n\nfrom importable import object as preferred_name from importable import object1, object2, ..., objectN from importable import (object1, object2, object3, object4, object5,\n\nobject6, ..., objectN)\n\nfrom importable import *\n\nPack- ages ➤ 199\n\nModules and Packages\n\nThese syntaxes can cause name conﬂicts since they make the imported objects (variables, functions, data types, or modules) directly accessible. If we want to use the from … import syntax to import lots of objects, we can use multiple lines either by escaping each newline except the last,or by enclosing the object names in parentheses, as the third syntax illustrates.\n\nIn thelast syntax,the * means“importeverything thatisnot private”,which in practicaltermsmeanseither thatevery objectin themoduleisimportedexcept for those whose names begin with a leading underscore, or, if the module has a global __all__ variable that holds a list of names, that all the objects named in the __all__ variable are imported.\n\nHere are a few import examples:\n\nimport os print(os.path.basename(filename))\n\n# safe fully qualified access\n\nimport os.path as path print(path.basename(filename)) # risk of name collision with path\n\nfrom os import path print(path.basename(filename)) # risk of name collision with path\n\nfrom os.path import basename print(basename(filename))\n\n# risk of name collision with basename\n\nfrom os.path import * print(basename(filename))\n\n# risk of many name collisions\n\nThe from importable import * syntax imports all the objects from the module (or all the modules from the package)—this could be hundreds of names. In the case of from os.path import *, almost 40 names are imported,including dirname, exists, and split, any of which might be names we would prefer to use for our own variables or functions.\n\nFor example, if we write from os.path import dirname, we can conveniently call dirname() without qualiﬁcation. But if further on in our code we write dirname = \".\",the object reference dirname will now be bound to the string \".\" instead of to the dirname() function, so if we try calling dirname() we will get a TypeError exception because dirname now refers to a string and strings are not callable.\n\nIn view of the potential for name collisions the import * syntax creates, some programming teams specify in their guidelines that only the import importable syntax may be used. However, certain large packages, particularly GUI (Graphical User Interface) libraries, are often imported this way because they have large numbers of functions and classes (custom data types) that can be tedious to type out by hand.\n\nA question that naturally arises is, how does Python know where to look for the modules and packages that are imported? The built-in sys module has a\n\n197\n\n__all__ ➤ 200",
      "page_number": 186
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 195-203)",
      "start_page": 195,
      "end_page": 203,
      "detection_method": "topic_boundary",
      "content": "Modules and Packages\n\nAt every subsequent import of the module Python will detect that the module has already been imported and will do nothing.\n\nWhen Python needs a module’s byte-code compiled code, it generates it automatically—this differs from, say, Java, where compiling to byte code must be done explicitly. First Python looks for a ﬁle with the same name as the module’s .py ﬁle but with the extension .pyo—this is an optimized byte-code compiled version of the module. If there is no .pyo ﬁle (or if it is older than the .py ﬁle, that is, if it is out of date), Python looks for a ﬁle with the exten- sion .pyc—this is a nonoptimized byte-code compiled version of the module. If Python ﬁnds an up-to-date byte-code compiled version of the module, it loads it; otherwise, Python loads the .py ﬁle and compiles a byte-code compiled ver- sion. Either way,Python endsupwith themodulein memory in byte-codecom- piled form.\n\nIf Python had to byte-compile the .py ﬁle, it saves a .pyc version (or .pyo if -O wasspeciﬁedon Python’scommand line,or isset in the PYTHONOPTIMIZE environ- ment variable), providing the directory is writable. Saving the byte code can be avoided by using the -B command-line option, or by setting the PYTHONDONT- WRITEBYTECODE environment variable.\n\nUsing byte-code compiled ﬁles leads to faster start-up times since the inter- preter only has to load and run the code, rather than load, compile, (save if possible),and run the code;runtimesare not affected,though. When Python is installed,the standard library modules are usually byte-code compiled as part of the installation process.\n\nPackages\n\nA package is simply a directory that contains a set of modules and a ﬁle called __init__.py. Suppose, for example, that we had a ﬁctitious set of module ﬁles for reading and writing various graphics ﬁle formats, such as Bmp.py, Jpeg.py, Png.py, Tiff.py, and Xpm.py, all of which provided the functions load(), save(), and so on.★ We could keep the modules in the same directory as our program, but for a large program that uses scores of custom modules the graphics modules will be dispersed. By putting them in their own subdirectory, say, Graphics, they can be kept together. And if we put an empty __init__.py ﬁle in the Graphics directory along with them, the directory will become a package:\n\nGraphics/ __init__.py Bmp.py Jpeg.py\n\n★Extensive support for handling graphics ﬁles is provided by a variety of third-party modules, most notably the Python Imaging Library (www.pythonware.com/products/pil).\n\n199\n\n||\n\n200\n\nChapter 5. Modules\n\nPng.py Tiff.py Xpm.py\n\nAslong asthe Graphics directory isa subdirectory inside our program’sdirecto- ry or is in the Python path, we can import any of these modules and make use of them. We must be careful to ensure that our top-level module name (Graph- ics) is not the same as any top-level name in the standard library so as to avoid name conﬂicts. (On Unix this is easily done by starting with an uppercase let- ter since all of the standard library’s modules have lowercase names.) Here’s how we can import and use our module:\n\nimport Graphics.Bmp image = Graphics.Bmp.load(\"bashful.bmp\")\n\nFor short programs some programmers prefer to use shorter names, and Python makes this possible using two slightly different approaches.\n\nimport Graphics.Jpeg as Jpeg image = Jpeg.load(\"doc.jpeg\")\n\nHere we have imported the Jpeg module from the Graphics package and told Python that we want to refer to it simply as Jpeg rather than using its fully qualiﬁed name, Graphics.Jpeg.\n\nfrom Graphics import Png image = Png.load(\"dopey.png\")\n\nThis code snippet imports the Png module directly from the Graphics package. This syntax (from … import) makes the Png module directly accessible.\n\nWe are not obliged to use the original package names in our code. For ex- ample:\n\nfrom Graphics import Tiff as picture image = picture.load(\"grumpy.tiff\")\n\nHere we are using the Tiff module, but have in effect renamed it inside our program as the picture module.\n\nIn some situations it is convenient to load in all of a package’s modules using a single statement. To do this we must edit the package’s __init__.py ﬁle to contain a statement which speciﬁes which modules we want loaded. This statement must assign a list of module names to the special variable __all__. For example, here is the necessary line for the Graphics/__init__.py ﬁle:\n\n__all__ = [\"Bmp\", \"Jpeg\", \"Png\", \"Tiff\", \"Xpm\"]\n\nModules and Packages\n\nThat isall that isrequired,although wearefreetoput any other codewelikein the __init__.py ﬁle. Now we can write a different kind of import statement:\n\nfrom Graphics import * image = Xpm.load(\"sleepy.xpm\")\n\nThe from package import * syntax directly imports all the modules named in the __all__ list. So,after thisimport,not only isthe Xpm module directly accessible, but so are all the others.\n\nAsnoted earlier,thissyntax can also be applied to a module,that is,from module import *, in which case all the functions,variables, and other objects deﬁned in the module (apart from those whose names begin with a leading underscore) will be imported. If we want to control exactly what is imported when the from module import * syntax isused,we can deﬁne an __all__ list in the module itself, in which case doing from module import * will import only those objects named in the __all__ list.\n\nSo far we have shown only one level of nesting, but Python allows us to nest packages as deeply as we like. So we could have a subdirectory inside the Graphics directory,say, Vector, with module ﬁles inside that,such as Eps.py and Svg.py:\n\nGraphics/ __init__.py Bmp.py Jpeg.py Png.py Tiff.py Vector/ __init__.py Eps.py Svg.py Xpm.py\n\nFor the Vector directory to be a package it must have an __init__.py ﬁle, and as noted, this can be empty or could have an __all__ list as a convenience for programmers who want to import using from Graphics.Vector import *.\n\nTo access a nested package we just build on the syntax we have already used:\n\nimport Graphics.Vector.Eps image = Graphics.Vector.Eps.load(\"sneezy.eps\")\n\nThe fully qualiﬁed name is rather long,so some programmerstry to keep their module hierarchies fairly ﬂat to avoid this.\n\n201\n\n202\n\nChapter 5. Modules\n\nimport Graphics.Vector.Svg as Svg image = Svg.load(\"snow.svg\")\n\nWe can always use our own short name for a module, as we have done here, although this does increase the risk of having a name conﬂict.\n\nAll the imports we have used so far (and that we will use throughout the rest of the book) are absolute imports—this means that every module we import is in one of sys.path’s directories (or subdirectories if the import name included one or more periodswhich effectively serve as path separators).When creating large multimodule multidirectory packages it is often useful to import other modules that are part of the same package. For example, in Eps.py or Svg.py we could get access to the Png module using a conventional import, or using a relative import:\n\nimport Graphics.Png as Png\n\nfrom ..Graphics import Png\n\nThesetwocodesnippetsareequivalent;they bothmakethe Png moduledirectly available inside the module where they are used. But note that relative im- ports, that is, imports that use the from module import syntax with leading dots in front of the module name (each dot representing stepping up one directory), can be used only in modules that are inside a package. Using relative imports makes it easier to rename the top-level package and prevents accidentally im- porting standard modules rather than our own inside packages.\n\nCustom Modules\n\nSince modules are just .py ﬁles they can be created without formality. In this section we will look at two custom modules. The ﬁrst module, TextUtil (in ﬁle TextUtil.py), contains just three functions: is_balanced() which returns True if the string it is passed has balanced parentheses of various kinds, shorten() (shown earlier; 177 ➤), and simplify(), a function that can strip spurious whitespace and other characters from a string. In the coverage of this module we will also see how to execute the code in docstrings as unit tests.\n\nThe second module,CharGrid (in ﬁle CharGrid.py),holdsa grid of charactersand allows us to “draw” lines, rectangles, and text onto the grid and to render the grid on the console. Thismodule showssome techniquesthat we have not seen before and is more typical of larger, more complex modules.\n\nThe TextUtil Module\n\nThe structure of this module (and most others) differs little from that of a program. The ﬁrst line is the shebang line, and then we have some comments (typically the copyright and license information). Next it is common to have a\n\n||\n\n|\n\nshort- en() 177➤\n\nModules and Packages\n\ntriple quoted string that provides an overview of the module’s contents, often including some usage examples—this is the module’s docstring. Here is the start of the TextUtil.py ﬁle (but with the license comment lines omitted):\n\n#!/usr/bin/env python3 # Copyright (c) 2008-9 Qtrac Ltd. All rights reserved. \"\"\" This module provides a few string manipulation functions.\n\n>>> is_balanced(\"(Python (is (not (lisp))))\") True >>> shorten(\"The Crossing\", 10) 'The Cro...' >>> simplify(\" some 'some text with spurious whitespace' \"\"\"\n\ntext\n\nwith spurious whitespace \")\n\nimport string\n\nThismodule’sdocstring isavailabletoprograms(or other modules)thatimport the module as TextUtil.__doc__. After the module docstring come the imports, in this case just one, and then the rest of the module.\n\nWe have already seen the shorten() function reproduced in full, so we will not repeat it here. And since our focus is on modules rather than on functions, although we will show the simplify() function in full, including its docstring, we will show only the code for is_balanced().\n\nThis is the simplify() function, broken into two parts:\n\ndef simplify(text, whitespace=string.whitespace, delete=\"\"):\n\nr\"\"\"Returns the text with multiple spaces reduced to single spaces\n\nThe whitespace parameter is a string of characters, each of which is considered to be a space. If delete is not empty it should be a string, in which case any characters in the delete string are excluded from the resultant string.\n\n>>> simplify(\" this 'this and that too' >>> simplify(\" Washington 'Washington D.C.' >>> simplify(\" Washington 'Washington DC' >>> simplify(\" disemvoweled \", delete=\"aeiou\") 'dsmvwld' \"\"\"\n\nand\\n that\\t too\")\n\nD.C.\\n\")\n\nD.C.\\n\", delete=\",;:.\")\n\n203\n\nRaw strings 67➤\n\n204\n\nChapter 5. Modules\n\nAfter the def line comes the function’s docstring, laid out conventionally with a single line description, a blank line, further description, and then some examples written as though they were typed in interactively. Because the quoted strings are inside a docstring we must either escape the backslashes inside them, or do what we have done here and use a raw triple quoted string.\n\nresult = [] word = \"\" for char in text:\n\nif char in delete:\n\ncontinue\n\nelif char in whitespace:\n\nif word:\n\nresult.append(word) word = \"\"\n\nelse:\n\nword += char\n\nif word:\n\nresult.append(word) return \" \".join(result)\n\nThe result list is used to hold “words”—strings that have no whitespace or deleted characters. The given text isiterated over character by character,with deleted characters skipped. If a whitespace character is encountered and a wordisin themaking,thewordisaddedtotheresultlist andset tobeanempty string; otherwise, the whitespace is skipped. Any other character is added to the word being built up. At the end a single string is returned consisting of all the words in the result list joined with a single space between each one.\n\nThe is_balanced() function follows the same pattern of having a def line, then a docstring with a single-line description, a blank line, further description, and some examples, and then the code itself. Here is the code without the docstring:\n\ndef is_balanced(text, brackets=\"()[]{}<>\"):\n\ncounts = {} left_for_right = {} for left, right in zip(brackets[::2], brackets[1::2]):\n\nassert left != right, \"the bracket characters must differ\" counts[left] = 0 left_for_right[right] = left\n\nfor c in text:\n\nif c in counts:\n\ncounts[c] += 1\n\nelif c in left_for_right:\n\nleft = left_for_right[c]\n\nModules and Packages\n\nif counts[left] == 0: return False\n\ncounts[left] -= 1\n\nreturn not any(counts.values())\n\nThe function builds two dictionaries. The counts dictionary’s keys are the opening characters (“(”, “[”, “{”, and “<”), and its values are integers. The left_for_right dictionary’skeys are the closing characters(“)”,“]”,“}”,and “>”), and itsvaluesarethecorresponding opening characters. Oncethedictionaries areset upthefunctioniteratescharacterby characterover thetext. Whenever an opening character is encountered, its corresponding count is incremented. Similarly,when a closing character is encountered,the function ﬁnds out what the corresponding opening character is. If the count for that character is 0 it means we have reached one closing character too many so can immediately return False; otherwise, the relevant count is decremented. At the end every count should be 0 if all the pairsare balanced,so if any one of them is not 0 the function returns False; otherwise, it returns True.\n\nUptothispointeverything hasbeenmuchlikeany other .py ﬁle. If TextUtil.py wasa programtherewould presumably be somemorefunctions,and at theend we would have a single call to one of those functionsto start off the processing. But since this is a module that is intended to be imported,deﬁning functionsis sufﬁcient. And now,any program or module can import TextUtil and make use of it:\n\nimport TextUtil\n\ntext = \" a text = TextUtil.simplify(text) # text == 'a puzzling conundrum'\n\npuzzling conundrum \"\n\nIf we want the TextUtil module to be available to a particular program, we just need to put TextUtil.py in the same directory as the program. If we want TextUtil.py to be available to all our programs,there are a few approachesthat can be taken. One approach is to put the module in the Python distribution’s site-packages subdirectory—this is usually C:\\Python31\\Lib\\site-packages on Windows, but it varies on Mac OS X and other Unixes. This directory is in the Python path, so any module that is here will always be found. A second approach is to create a directory speciﬁcally for the custom modules we want to use for all our programs, and to set the PYTHONPATH environment variable to this directory. A third approach is to put the module in the local site-packages subdirectory—this is %APPDATA%\\Python\\Python31\\site-packages on Windows and ~/.local/lib/python3.1/site-packages on Unix (including Mac OS X) and is in the Python path. The second and third approacheshave the advantage of keeping our own code separate from the ofﬁcial installation.\n\nHaving the TextUtil module is all very well, but if we end up with lots of pro- grams using it we might want to be more conﬁdent that it works as advertised.\n\n205\n\n206\n\nChapter 5. Modules\n\nOne really simple way to do this is to execute the examples in the docstrings and make sure that they produce the expected results. This can be done by adding just three lines at the end of the module’s .py ﬁle:\n\nif __name__ == \"__main__\":\n\nimport doctest doctest.testmod()\n\nWhenever a module is imported Python creates a variable for the module called __name__ and stores the module’s name in this variable. A module’s name is simply the name of its .py ﬁle but without the extension. So in this example,when the module is imported __name__ will have the value \"TextUtil\", and the if condition will not be met, so the last two lines will not be executed. This means that these last three lines have virtually no cost when the module is imported.\n\nWhenever a .py ﬁle is run Python creates a variable for the program called __name__ and sets it to the string \"__main__\". So if we were to run TextUtil.py as though it were a program, Python will set __name__ to \"__main__\" and the if condition will evaluate to True and the last two lines will be executed.\n\nThe doctest.testmod() functionusesPython’sintrospectionfeaturestodiscover all the functions in the module and their docstrings, and attempts to execute all the docstring code snippets it ﬁnds. Running a module like this produces outputonly if thereareerrors. Thiscanbedisconcertingatﬁrstsinceitdoesn’t look like anything happened at all, but if we pass a command-line ﬂag of -v, we will get output like this:\n\nTrying:\n\nis_balanced(\"(Python (is (not (lisp))))\")\n\nExpecting:\n\nTrue\n\nok ... Trying:\n\nsimplify(\" disemvoweled \", delete=\"aeiou\")\n\nExpecting:\n\n'dsmvwld'\n\nok 4 items passed all tests: 3 tests in __main__ 5 tests in __main__.is_balanced 3 tests in __main__.shorten 4 tests in __main__.simplify\n\n15 tests in 4 items. 15 passed and 0 failed. Test passed.\n\nModules and Packages\n\nWe have used an ellipsis to indicate a lot of lines that have been omitted. If therearefunctions(or classesor methods)thatdon’thavetests,thesearelisted when the -v option is used. Notice that the doctest module found the tests in the module’s docstring as well as those in the functions’ docstrings.\n\nExamples in docstrings that can be executed as tests are called doctests. Note that when we write doctests, we are able to call simplify() and the other func- tions unqualiﬁed (since the doctests occur inside the module itself). Outside the module,assuming we have done import TextUtil, we must use the qualiﬁed names, for example, TextUtil.is_balanced().\n\nIn thenext subsectionwewillseehowtodomorethoroughtests—inparticular, testing caseswhereweexpectfailures,for example,invaliddatacausing excep- tions. (Testing is covered more fully in Chapter 9.) We will also address some other issuesthat arisewhen creating modules,including moduleinitialization, accounting for platform differences,and ensuring that if the from module import * syntax is used, only the objects we want to be made public are actually im- ported into the importing program or module.\n\nThe CharGrid Module\n\nThe CharGrid module holds a grid of characters in memory. It provides func- tionsfor “drawing”lines,rectangles,and text on the grid,and for rendering the grid onto the console. Here are the module’s docstring’s doctests:\n\n>>> resize(14, 50) >>> add_rectangle(0, 0, *get_size()) >>> add_vertical_line(5, 10, 13) >>> add_vertical_line(2, 9, 12, \"!\") >>> add_horizontal_line(3, 10, 20, \"+\") >>> add_rectangle(0, 0, 5, 5, \"%\") >>> add_rectangle(5, 7, 12, 40, \"#\", True) >>> add_rectangle(7, 9, 10, 38, \" \") >>> add_text(8, 10, \"This is the CharGrid module\") >>> add_text(1, 32, \"Pleasantville\", \"@\") >>> add_rectangle(6, 42, 11, 46, fill=True) >>> render(False)\n\nThe CharGrid.add_rectangle() function takes at least four arguments, the top- left corner’s row and column and the bottom-right corner’s row and column. The character used to draw the outline can be given as a ﬁfth argument,and a Boolean indicating whether the rectangle should be ﬁlled (with the same char- acter as the outline) as a sixth argument. The ﬁrst time we call it we pass the third and fourth argumentsby unpacking the 2-tuple(width,height),returned by the CharGrid.get_size() function.\n\n207\n\n|",
      "page_number": 195
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 204-212)",
      "start_page": 204,
      "end_page": 212,
      "detection_method": "topic_boundary",
      "content": "208\n\nChapter 5. Modules\n\nBy default,the CharGrid.render() function clearsthe screen before printing the grid, but this can be prevented by passing False as we have done here. Here is the grid that results from the preceding doctests:\n\n%%%%%********************************************* % % @@@@@@@@@@@@@@@ * % % @Pleasantville@ * % % ++++++++++ @@@@@@@@@@@@@@@ * %%%%% * * ################################# * * ################################# **** * * ## ## **** * * ## This is the CharGrid module ## **** * * ! ## ## **** * * ! | ################################# **** * * ! | ################################# * * | * **************************************************\n\nThe module begins in the same way as the TextUtil module, with a shebang line, copyright and license comments, and a module docstring that describes the module and has the doctests quoted earlier. Then the code proper begins with twoimports,oneof the sys moduleandtheother of the subprocess module. The subprocess module is covered more fully in Chapter 10.\n\nThe module has two error-handling policies in place. Several functions have a char parameter whose actual argument must always be a string containing exactly one character;a violation of thisrequirement isconsideredto be a fatal coding error, so assert statements are used to verify the length. But passing out-of-range row or column numbers is considered erroneous but normal, so custom exceptions are raised when this happens.\n\nWe will now review some illustrative and key parts of the module’s code, beginning with the custom exceptions:\n\nclass RangeError(Exception): pass class RowRangeError(RangeError): pass class ColumnRangeError(RangeError): pass\n\nNone of the functions in the module that raise an exception ever raise a RangeError; they always raise the speciﬁc exception depending on whether an out-of-range row or column was given. But by using a hierarchy,we give users of the module the choice of catching the speciﬁc exception,or to catch either of them by catching their RangeError baseclass. Note also that inside docteststhe exception names are used as they appear here, but if the module is imported with import CharGrid, the exception names are, of course, CharGrid.RangeError, CharGrid.RowRangeError, and CharGrid.ColumnRangeError.\n\nModules and Packages\n\n_CHAR_ASSERT_TEMPLATE = (\"char must be a single character: '{0}' \"\n\n\"is too long\")\n\n_max_rows = 25 _max_columns = 80 _grid = [] _background_char = \" \"\n\nHere we deﬁne some private data for internal use by the module. We use leading underscores so that if the module is imported using from CharGrid import *, none of these variables will be imported. (An alternative approach would be to set an __all__ list.) The _CHAR_ASSERT_TEMPLATE is a string for use with the str.format() function; we will see it used to give an error message in assert statements. We will discuss the other variables as we encounter them.\n\nif sys.platform.startswith(\"win\"):\n\ndef clear_screen():\n\nsubprocess.call([\"cmd.exe\", \"/C\", \"cls\"])\n\nelse:\n\ndef clear_screen():\n\nsubprocess.call([\"clear\"])\n\nclear_screen.__doc__ = \"\"\"Clears the screen using the underlying \\ window system's clear screen command\"\"\"\n\nThe means of clearing the console screen is platform-dependent. On Windows we must execute the cmd.exe program with appropriate arguments and on most Unix systems we execute the clear program. The subprocess module’s subprocess.call() function lets us run an external program, so we can use it to clear the screen in the appropriate platform-speciﬁc way. The sys.platform string holds the name of the operating system the program is running on, for example, “win32” or “linux2”.So one way of handling the platform differences would be to have a single clear_screen() function like this:\n\ndef clear_screen():\n\ncommand = ([\"clear\"] if not sys.platform.startswith(\"win\") else\n\n[\"cmd.exe\", \"/C\", \"cls\"])\n\nsubprocess.call(command)\n\nThe disadvantage of this approach is that even though we know the platform cannot change while the program is running, we perform the check every time the function is called.\n\nTo avoid checking which platform the program is being run on every time the clear_screen() function is called, we have created a platform-speciﬁc clear_screen() function once when the module is imported, and from then on we always use it. This is possible because the def statement is a Python state- ment like any other; when the interpreter reaches the if it executes either the ﬁrst or the second def statement, dynamically creating one or the other\n\n209\n\nList compre- hen- sions 118➤\n\n210\n\nChapter 5. Modules\n\nclear_screen() function. Since the function is not deﬁned inside another func- tion (or inside a class as we will see in the next chapter),it is still a global func- tion, accessible like any other function in the module.\n\nAfter creating the function we explicitly set itsdocstring;this avoidsus having to write the same docstring in two places, and also illustrates that a docstring is simply one of the attributes of a function. Other attributes include the function’s module and its name.\n\ndef resize(max_rows, max_columns, char=None):\n\n\"\"\"Changes the size of the grid, wiping out the contents and changing the background if the background char is not None \"\"\" assert max_rows > 0 and max_columns > 0, \"too small\" global _grid, _max_rows, _max_columns, _background_char if char is not None:\n\nassert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char) _background_char = char\n\n_max_rows = max_rows _max_columns = max_columns _grid = [[_background_char for column in range(_max_columns)]\n\nfor row in range(_max_rows)]\n\nThis function uses an assert statement to enforce the policy that it is a coding error to attemptto resizethe grid smaller than 1× 1.If a backgroundcharacter is speciﬁed an assert is used to guarantee that it is a string of exactly one character;if it isnot,the assertion error messageisthe _CHAR_ASSERT_TEMPLATE’s text with the {0} replaced with the given char string.\n\nUnfortunately,we must use the global statement because we need to update a number of global variables inside this function. This is something that using an object-oriented approach can help us to avoid, as we will see in Chapter 6.\n\ncomprehension. The _grid is created using a list comprehension inside a list Using list replication such as [[char] *columns ] *rows will not work because the inner list will be shared (shallow-copied).We could have used nested for … in loops instead:\n\n_grid = [] for row in range(_max_rows):\n\n_grid.append([]) for column in range(_max_columns):\n\n_grid[-1].append(_background_char)\n\nThis code is arguably trickier to understand than the list comprehension, and is much longer.\n\nModules and Packages\n\nWe will review just one of the drawing functions to give a ﬂavor of how the drawing is done, since our primary concern is with the implementation of the module. Here is the add_horizontal_line() function, split into two parts:\n\ndef add_horizontal_line(row, column0, column1, char=\"-\"):\n\n\"\"\"Adds a horizontal line to the grid using the given char\n\n>>> add_horizontal_line(8, 20, 25, \"=\") >>> char_at(8, 20) == char_at(8, 24) == \"=\" True >>> add_horizontal_line(31, 11, 12) Traceback (most recent call last): ... RowRangeError \"\"\"\n\nThe docstring has two tests, one that is expected to work and another that is expected to raise an exception. When dealing with exceptions in doctests the pattern is to specify the “Traceback” line, since that is always the same and tells the doctest module an exception is expected, then to use an ellipsis to standfor theintervening lines(whichvary),andending with theexceptionline weexpecttoget. The char_at() functionisoneof thoseprovidedby themodule; it returns the character at the given row and column position in the grid.\n\nassert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char) try:\n\nfor column in range(column0, column1):\n\n_grid[row][column] = char\n\nexcept IndexError:\n\nif not 0 <= row <= _max_rows: raise RowRangeError()\n\nraise ColumnRangeError()\n\nThe code begins with the same character length check that is used in the re- size() function. Rather than explicitly checking the row and column argu- ments, the function works by assuming that the arguments are valid. If an IndexError exception occurs because a nonexistent row or column is accessed, we catch the exception and raise the appropriate module-speciﬁc exception in its place. This style of programming is known colloquially as “it’seasier to ask forgivenessthan permission”,and is generally considered more Pythonic(good Pythonprogrammingstyle)than“look beforeyouleap”,wherechecksaremade in advance. Relying onexceptionstoberaisedratherthanchecking inadvance is more efﬁcient when exceptions are rare. (Assertions don’t count as “look before you leap” because they should never occur—and are often commented out—in deployed code.)\n\n211\n\n212\n\nChapter 5. Modules\n\nAlmost at the end of the module, after all the functions have been deﬁned, there is a single call to resize():\n\nresize(_max_rows, _max_columns)\n\nThis call initializes the grid to the default size (25 × 80) and ensures that code that imports the module can safely make use of it immediately. Without this call, every time the module was imported, the importing program or module would have to call resize() to initialize the grid, forcing programmers to remember that fact and also leading to multiple initializations.\n\nif __name__ == \"__main__\":\n\nimport doctest doctest.testmod()\n\nThe last three lines of the module are the standard ones for modules that use the doctest module to check their doctests. (Testing is covered more fully in Chapter 9.)\n\nThe CharGrid module hasan important failing:It supportsonly a single charac- ter grid. One solution to this would be to hold a collection of grids in the mod- ule,but that would mean that users of the module would have to provide a key or index with every function call to identify which grid they were referring to. In caseswhere multiple instancesof an object are required,a better solution is to create a module that deﬁnes a class (a custom data type), since we can cre- ate as many class instances (objectsof the data type) as we like. An additional beneﬁt of creating a class is that we should be able to avoid using the global statementby storing class(static)data. Wewill seehow to createclassesin the next chapter.\n\nOverview of Python’s Standard Library\n\n|||\n\nPython’s standard library is generally described as “batteries included”, and certainly a wide range of functionality is available, spread over around two hundred packages and modules.\n\nIn fact,so many high-quality moduleshave been developed for Python over the years,that to include them all in the standard library would probably increase the size of the Python distribution packagesby at least an order of magnitude. So those modules that are in the library are more a reﬂection of Python’s his- tory and of the interests of its core developers than of any concerted or sys- tematic effort to create a “balanced” library. Also, some modules have proved very difﬁcult to maintain within the library—most notably the Berkeley DB module—and so have been taken out of the library and are now maintained independently. This means many excellent third-party modules are available for Pythonthat—despitetheir quality and usefulness—arenot in thestandard\n\nOverviewof Python’s Standard Library\n\nlibrary. (We will look at two such modules later on: the PyParsing and PLY modules that are used to create parsers in Chapter 14.)\n\nIn this section we present a broad overview of what is on offer, taking a thematic approach,but excluding those packagesand modulesthat are of very specialized interest and those which are platform-speciﬁc. In many cases a small example is shown to give a ﬂavor of some of the packages and modules; cross-referencesare provided for those packages and modules that are covered elsewhere in the book.\n\nString Handling\n\nThe string module provides some useful constants such as string.ascii_let- ters and string.hexdigits.It also provides the string.Formatter class which we can subclass to provide custom string formatters.★ The textwrap module can be used to wrap lines of text to a speciﬁed width, and to minimize indentation.\n\nThe struct module provides functions for packing and unpacking numbers, Booleans, and strings to and from bytes objects using their binary representa- tions. Thiscan be usefulwhen handling data tobesent to or receivedfromlow- level libraries written in C. The struct and textwrap modules are used by the convert-incidents.py program covered in Chapter 7.\n\nThe difflib module provides classes and methods for comparing sequences, such as strings, and is able to produce output both in standard “diff” formats and in HTML.\n\nPython’s most powerful string handling module is the re (regular expression) module. This is covered in Chapter 13.\n\nThe io.StringIO class can provide a string-like object that behaves like an in-memory text ﬁle. This can be convenient if we want to use the same code that writes to a ﬁle to write to a string.\n\nExample: The io.StringIO Class\n\nPython provides two different ways of writing text to ﬁles. One way is to use a ﬁle object’s write() method, and the other is to use the print() function with the file keyword argument set to a ﬁle object that is open for writing. For example:\n\nprint(\"An error message\", file=sys.stdout) sys.stdout.write(\"Another error message\\n\")\n\n★The term subclassing (or specializing) is used for when we create a custom data type (a class) based on another class. Chapter 6 gives full coverage of this topic.\n\n213\n\n||\n\n|\n\nbytes type ➤ 293\n\nThe struct module ➤ 297\n\n214\n\nChapter 5. Modules\n\nBoth lines of text are printed to sys.stdout, a ﬁle object that represents the “standard output stream”—this is normally the console and differs from sys.stderr, the “error output stream” only in that the latter is unbuffered. (Python automatically creates and opens sys.stdin, sys.stdout, and sys.stderr at programstart-up.) The print() functionaddsa newlineby default,although we can stop this by giving the end keyword argument set to an empty string.\n\nIn some situations it is useful to be able to capture into a string the output that is intended to go to a ﬁle. This can be achieved using the io.StringIO class which providesan object that can be used just like a ﬁle object,but which holds any data written to it in a string. If the io.StringIO object is given an initial string, it can also be read as though it were a ﬁle.\n\nWecanaccessio.StringIO if wedo import io,andwecanuseit tocaptureoutput destined for a ﬁle object such as sys.stdout:\n\nsys.stdout = io.StringIO()\n\nIf this line is put at the beginning of a program, after the imports but before any use is made of sys.stdout, any text that is sent to sys.stdout will actually be sent to the io.StringIO ﬁle-like object which this line has created and which has replaced the standard sys.stdout ﬁle object. Now, when the print() and sys.stdout.write() lines shown earlier are executed, their output will go to the io.StringIO object instead of the console. (At any time we can restore the original sys.stdout with the statement sys.stdout = sys.__stdout__.)\n\nWe can obtain all the strings that have been written to the io.StringIO ob- ject by calling the io.StringIO.getvalue() function, in this case by calling sys.stdout.getvalue()—thereturnvalueisa string containing allthelinesthat have been written. This string could be printed, or saved to a log or sent over a network connection like any other string. We will see another example of io.StringIO use a bit further on (➤ 227).\n\nCommand-Line Programming\n\nIf we need a program to be able to process text that may have been redirected in the console or that may be in ﬁles listed on the command line, we can use the fileinput module’s fileinput.input() function. This function iterates over all the lines redirected from the console (if any) and over all the lines in the ﬁles listed on the command line, as one continuous sequence of lines. The module can report the current ﬁlename and line number at any time using fileinput.filename() and fileinput.lineno(), and can handle some kinds of compressed ﬁles.\n\nTwo separate modules are provided for handling command-line options, optparse and getopt. The getopt module is popular because it is simple to use\n\n||\n\ncsv2- html.py example 97➤\n\nOverviewof Python’s Standard Library\n\nand has been in the library for a long time. The optparse module is newer and more powerful.\n\nExample: The optparse Module\n\nBack in Chapter 2 we described the csv2html.py program. In that chapter’sex- ercises we proposed extending the program to accept the command-line argu- ments, “maxwidth” taking an integer and “format” taking a string. The mod- el solution (csv2html2_ans.py) has a 26-line function to process the arguments. Here is the start of the main() function for csv2html2_opt.py, a version of the programthat usesthe optparse module to handle thecommand-line arguments rather than a custom function:\n\ndef main():\n\nparser = optparse.OptionParser() parser.add_option(\"-w\", \"--maxwidth\", dest=\"maxwidth\", type=\"int\",\n\nhelp=(\"the maximum number of characters that can be \" \"output to string fields [default: %default]\"))\n\nparser.add_option(\"-f\", \"--format\", dest=\"format\",\n\nhelp=(\"the format used for outputting numbers \"\n\n\"[default: %default]\"))\n\nparser.set_defaults(maxwidth=100, format=\".0f\") opts, args = parser.parse_args()\n\nOnly nine lines of code are needed, plus the import optparse statement. Fur- thermore, we do not need to explicitly provide -h and --help options; these are handled by the optparse module to produce a suitable usage message using the texts from the help keyword arguments,and with any “%default” text replaced with the option’s default value.\n\nNoticealsothat theoptionsnow usetheconventionalUnix styleof having both short and long option names that start with a hyphen. Short names are con- venient for interactiveuse at theconsole;long namesaremoreunderstandable when used in shell scripts. For example, to set the maximum width to 80 we can use any of -w80, -w 80, --maxwidth=80, or --maxwidth 80. After the command line is parsed, the options are available using the dest names, for example, opts.maxwidth and opts.format. Any command-line arguments that have not been processed (usually ﬁlenames) are in the args list.\n\nIf an error occurs when parsing the command line, the optparse parser will call sys.exit(2). This leads to a clean program termination and returns 2 to the operating system as the program’s result value. Conventionally, a return value of 2 signiﬁes a usage error, 1 signiﬁes any other kind of error, and 0 meanssuccess. When sys.exit() iscalled with no argumentsit returns0tothe operating system.\n\n215\n\n|\n\n216\n\nChapter 5. Modules\n\nMathematics and Numbers\n\nIn addition to the built-in int, float, and complex numbers,the library provides the decimal.Decimal and fractions.Fraction numbers. Three numeric libraries are available: math for the standard mathematical functions, cmath for complex number mathematicalfunctions,and random whichprovidesmany functionsfor random number generation; these modules were introduced in Chapter 2.\n\nPython’s numeric abstract base classes (classes that can be inherited from but that cannot be used directly) are in the numbers module. They are useful for checking that an object, say, x, is any kind of number using isinstance(x, numbers.Number), or is a speciﬁc kind of number, for example, isinstance(x, numbers.Rational) or isinstance(x, numbers.Integral).\n\nThose involved in scientiﬁc and engineering programming will ﬁnd the third- party NumPy package to be useful. This module provides highly efﬁcient n-di- mensional arrays, basic linear algebra functions and Fourier transforms, and tools for integration with C, C++, and Fortran code. The SciPy package incor- porates NumPy and extends it to include modules for statistical computations, signal and image processing, genetic algorithms, and a great deal more. Both are freely available from www.scipy.org.\n\nTimes and Dates\n\nThe calendar and datetime modules provide functions and classes for date and time handling. However, they are based on an idealized Gregorian calendar, so they are not suitable for dealing with pre-Gregorian dates. Time and date handling is a very complex topic—the calendars in use have varied in differ- ent places and at different times, a day is not precisely 24 hours, a year is not exactly 365 days, and daylight saving time and time zones vary. The date- time.datetime class (but not the datetime.date class) has provisions for han- dling time zones, but does not do so out of the box. Third-party modules are available to make good this deﬁciency, for example, dateutil from www.labix. org/python-dateutil, and mxDateTime from www.egenix.com/products/python/mx- Base/mxDateTime.\n\nThe time modulehandlestimestamps. Thesearesimply numbersthat hold the number of seconds since the epoch (1970-01-01T00:00:00 on Unix). This mod- ule can be used to get a timestamp of the machine’s current time in UTC (Co- ordinated Universal Time),or as a local time that accounts for daylight saving time,and to create date,time,and date/timestringsformatted in variousways. It can also parse strings that have dates and times.\n\n||\n\n||",
      "page_number": 204
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 213-220)",
      "start_page": 213,
      "end_page": 220,
      "detection_method": "topic_boundary",
      "content": "Overviewof Python’s Standard Library\n\nExample: The calendar, datetime, and time Modules\n\nObjects of type datetime.datetime are usually created programmatically, whereas objects that hold UTC date/times are usually received from external sources, such as ﬁle timestamps. Here are some examples:\n\nimport calendar, datetime, time moon_datetime_a = datetime.datetime(1969, 7, 20, 20, 17, 40) moon_time = calendar.timegm(moon_datetime_a.utctimetuple()) moon_datetime_b = datetime.datetime.utcfromtimestamp(moon_time) moon_datetime_a.isoformat() moon_datetime_b.isoformat() time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(moon_time))\n\n# returns: '1969-07-20T20:17:40' # returns: '1969-07-20T20:17:40'\n\nThe moon_datetime_a variable is of type datetime.datetime and holds the date and time that Apollo 11 landed on the moon. The moon_time variable is of type int and holds the number of seconds since the epoch to the moon landing—this number is provided by the calendar.timegm() function which takes a time_struct object returned by the datetime.datetime.utctimetuple() function, and returns the number of seconds that the time_struct represents. (Since the moon landing occurred before the Unix epoch, the number is nega- tive.) The moon_datetime_b variable is of type datetime.datetime and is created from the moon_time integer to show the conversion from the number of seconds since the epoch to a datetime.datetime object.★ The last three lines all return identical ISO 8601-format date/time strings.\n\nThe current UTCdate/timeisavailable asa datetime.datetime object by calling datetime.datetime.utcnow(), and as the number of seconds since the epoch by calling time.time(). For the local date/time, use datetime.datetime.now() or time.mktime(time.localtime()).\n\nAlgorithms and Collection Data Types\n\nThe bisect module provides functions for searching sorted sequences such as sorted lists, and for inserting items while preserving the sort order. This module’s functions use the binary search algorithm,so they are very fast. The heapq module provides functions for turning a sequence such as a list into a heap—a collection data type where the ﬁrst item (at index position 0) isalways the smallest item, and for inserting and removing items while keeping the sequence as a heap.\n\n★Unfortunately for Windowsusers,the datetime.datetime.utcfromtimestamp()function can’t handle negative timestamps, that is, timestamps for dates prior to January 1, 1970.\n\n217\n\n|\n\n||\n\nDefault dictio- nary 135➤\n\nNamed tuple 111➤\n\nOrdered dictio- nary 136➤\n\n218\n\nChapter 5. Modules\n\nThe collections package provides the collections.defaultdict dictionary and the collections.namedtuple collection data types that we have previously dis- cussed. In addition, this package provides the collections.UserList and col- lections.UserDict types, although subclassing the built-in list and dict types is probably more common than using these types. Another type is collec- tions.deque, which is similar to a list, but whereas a list is very fast for adding and removing items at the end, a collections.deque is very fast for adding and removing items both at the beginning and at the end.\n\nPython 3.1introducedthe collections.OrderedDict and the collections.Counter classes. OrderedDicts have the same API as normal dicts, although when iterated the items are always returned in insertion order (i.e.,from ﬁrst to last inserted), and the popitem() method always returns the most recently added (i.e., last) item. The Counter class is a dict subclass used to provide a fast and easy way of keeping various counts. Given an iterable or a mapping (such as a dictionary), a Counter instance can, for example, return a list of the unique elements or a list of the most common elements as (element, count) 2-tuples.\n\nPython’snon-numeric abstract base classes(classesthat can be inherited from but that cannot be used directly)are also in the collections package. They are discussed in Chapter 8.\n\nThe array module provides the array.array sequence type that can store num- bers or charactersin a very space-efﬁcient way. It has similar behavior to lists except that the type of object it can store is ﬁxed when it is created, so unlike lists it cannot store objects of different types. The third-party NumPy package mentioned earlier also provides efﬁcient arrays.\n\nThe weakref moduleprovidesfunctionality for creating weak references—these behave like normal object references,except that if the only reference to an ob- ject is a weak reference,the object can still be scheduled for garbage collection. Thispreventsobjectsfrombeing kept in memory simply becausewe have a ref- erence to them. Naturally, we can check whether the object a weak reference refers to still exists, and can access the object if it does.\n\nExample: The heapq Module\n\nThe heapq module provides functions for converting a list into a heap and for adding and removing items from the heap while preserving the heap property. A heap is a binary tree that respects the heap property, which is that the ﬁrst item (at index position 0) is always the smallest item.★ Each of a heap’s subtrees is also a heap, so they too respect the heap property. Here is how a heap could be created from scratch:\n\n★Strictly speaking,the heapq module provides a min heap; heaps where the ﬁrst item is always the largest are max heaps.\n\n|\n\n3.1\n\nChar- acter encod- ings 91➤\n\nOverviewof Python’s Standard Library\n\nimport heapq heap = [] heapq.heappush(heap, (5, \"rest\")) heapq.heappush(heap, (2, \"work\")) heapq.heappush(heap, (4, \"study\"))\n\nIf we already have a list, we can turn it into a heap with heapq.heapify(alist); this will do any necessary reordering in-place. The smallest item can be removed from the heap using heapq.heappop(heap).\n\nfor x in heapq.merge([1, 3, 5, 8], [2, 4, 7], [0, 1, 6, 8, 9]):\n\nprint(x, end=\" \") # prints: 0 1 1 2 3 4 5 6 7 8 8 9\n\nThe heapq.merge() function takesany number of sorted iterablesas arguments and returns an iterator that iterates over all the items from all the iterables in order.\n\nFile Formats, Encodings, and Data Persistence\n\nThe standard library has extensive support for a variety of standard ﬁle for- mats and encodings. The base64 module has functions for reading and writing using the Base16, Base32, and Base64 encodings speciﬁed in RFC 3548.★ The quopri module has functions for reading and writing “quoted-printable” for- mat. This format is deﬁned in RFC 1521 and is used for MIME (Multipurpose Internet Mail Extensions) data. The uu module has functions for reading and writing uuencoded data. RFC 1832 deﬁnes the External Data Representation Standard and module xdrlib provides functions for reading and writing data in this format.\n\nModules are also provided for reading and writing archive ﬁles in the most popularformats. The bz2 modulecanhandle .bz2 ﬁles,thegzip modulehandles .gz ﬁles,the tarfile module handles .tar, .tar.gz (also .tgz),and .tar.bz2 ﬁles, and the zipfile module handles .zip ﬁles. We will see an example of using the tarfile modulein thissubsection,and later on (➤227)thereisa smallexample that uses the gzip module; we will also see the gzip module in action again in Chapter 7.\n\nSupport is also provided for handling some audio formats, with the aifc mod- ule for AIFF (Audio Interchange File Format) and the wave module for (uncom- pressed) .wav ﬁles. Some forms of audio data can be manipulated using the audioop module,and the sndhdr module providesa couple of functionsfor deter- mining what kind of sound data is stored in a ﬁle and some of its properties, such as the sampling rate.\n\n★ RFC (Request for Comments) documents are used to specify various Internet technologies. Each one has a unique identiﬁcation number and many of them have become ofﬁcially adopted standards.\n\n219\n\n||\n\n220\n\nChapter 5. Modules\n\nA format for conﬁguration ﬁles (similar to old-style Windows .ini ﬁles) is speciﬁed in RFC 822, and the configparser module provides functions for reading and writing such ﬁles.\n\nMany applications, for example, Excel, can read and write CSV (Comma Separated Value)data,or variantssuch astab-delimited data. The csv module can read and write these formats, and can account for the idiosyncracies that prevent CSV ﬁles from being straightforward to handle directly.\n\nIn addition to its support of various ﬁle formats, the standard library also has packages and modules that provide data persistence. The pickle module is used to store and retrieve arbitrary Python objects (including entire collec- tions) to and from disk; this module is covered in Chapter 7. The library also supports DBM ﬁles of various kinds—these are like dictionaries except that their items are stored on disk rather than in memory, and both their keys and their values must be bytes objects or strings. The shelve module, covered in Chapter 12, can be used to provide DBM ﬁles with string keys and arbitrary Python objects as values—the module seamlessly converts the Python ob- jects to and from bytes objects behind the scenes. The DBM modules,Python’s database API, and using the built-in SQLite database are all covered in Chap- ter 12.\n\nExample: The base64 Module\n\nThe base64 module ismostly used for handling binary data that isembedded in emails as ASCII text. It can also be used to store binary data inside .py ﬁles. The ﬁrst step is to get the binary data into Base64 format. Here we assume that the base64 module has been imported and that the path and ﬁlename of a .png ﬁle are in the variable left_align_png:\n\nbinary = open(left_align_png, \"rb\").read() ascii_text = \"\" for i, c in enumerate(base64.b64encode(binary)):\n\nif i and i % 68 == 0:\n\nascii_text += \"\\\\\\n\"\n\nascii_text += chr(c)\n\nleft_align.png\n\nThis code snippet reads the ﬁle in binary mode and converts it to a Base64 string of ASCII characters. Every sixty-eighth character a backslash-newline combination is added. This limits the width of the lines of ASCII characters to 68,but ensures that when the data is read back the newlines will be ignored (becausethebackslashwill escapethem).TheASCIItext obtainedlikethiscan be stored as a bytes literal in a .py ﬁle, for example:\n\nLEFT_ALIGN_PNG = b\"\"\"\\ iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABGdBTUEAALGPC/xhBQAA\\\n\n|\n\nbytes type ➤ 293\n\nOverviewof Python’s Standard Library\n\n... bmquu8PAmVT2+CwVV6rCyA9UfFMCkI+bN6p18tCWqcUzrDOwBh2zVCR+JZVeAAAAAElF\\ TkSuQmCC\"\"\"\n\nWe’ve omitted most of the lines as indicated by the ellipsis.\n\nThe data can be converted back to its original binary form like this:\n\nbinary = base64.b64decode(LEFT_ALIGN_PNG)\n\nThe binary data could be written to a ﬁle using open(filename, \"wb\").write( binary). Keeping binary data in .py ﬁles is much less compact than keeping it in its original form, but can be useful if we want to provide a program that requires some binary data as a single .py ﬁle.\n\nExample: The tarﬁle Module\n\nMost versions of Windows don’t come with support for the .tar format that is so widely used on Unix systems. This inconvenient omission can easily be rectiﬁed using Python’s tarfile module,which can create and unpack .tar and .tar.gz archives (known as tarballs), and with the right libraries installed, .tar.bz2 archives. The untar.py programcan unpack tarballsusing the tarfile module;herewewill just showsomekey extracts,starting with theﬁrst import statement:\n\nBZ2_AVAILABLE = True try:\n\nimport bz2 except ImportError:\n\nBZ2_AVAILABLE = False\n\nThe bz2 module is used to handle the bzip2 compression format,but importing it will fail if Python was built without access to the bzip2 library. (The Python binary for Windows is always built with bzip2 compression built-in; it is only on some Unix builds that it might be absent.) We account for the possibility that the module isnot available using a try …except block,and keep a Boolean variable that we can refer to later (although we don’t quote the code that uses it).\n\nUNTRUSTED_PREFIXES = tuple([\"/\", \"\\\\\"] +\n\n[c + \":\" for c in string.ascii_letters])\n\nThis statement creates the tuple ('/', '\\', 'A:', 'B:', …, 'Z:', 'a:', 'b:', …, 'z:'). Any ﬁlename in the tarball being unpacked that begins with one of these is suspect—tarballs should not use absolute paths since then they risk overwriting system ﬁles, so as a precaution we will not unpack any ﬁle whose name starts with one of these preﬁxes.\n\n221\n\n|\n\n222\n\nChapter 5. Modules\n\ndef untar(archive): tar = None try:\n\ntar = tarfile.open(archive) for member in tar.getmembers():\n\nif member.name.startswith(UNTRUSTED_PREFIXES):\n\nprint(\"untrusted prefix, ignoring\", member.name)\n\nelif \"..\" in member.name:\n\nprint(\"suspect path, ignoring\", member.name)\n\nelse:\n\ntar.extract(member) print(\"unpacked\", member.name)\n\nexcept (tarfile.TarError, EnvironmentError) as err:\n\nerror(err)\n\nfinally:\n\nif tar is not None: tar.close()\n\nEach ﬁle in a tarball is called a member. The tarfile.getmembers() function returns a list of tarfile.TarInfo objects, one for each member. The member’s ﬁlename, including its path, is in the tarfile.TarInfo.name attribute. If the name begins with an untrusted preﬁx, or contains .. in its path, we output an error message;otherwise,we call tarfile.extract() to savethemember todisk. The tarfile modulehasitsown set of customexceptions,but wehavetakenthe simplistic approach that if any exception occurs we output the error message and ﬁnish.\n\ndef error(message, exit_status=1):\n\nprint(message) sys.exit(exit_status)\n\nWe have just quoted the error() function for completeness. The (unquoted) main() function prints a usage message if -h or --help is given; otherwise, it performs some basic checks before calling untar() with the tarball’s ﬁlename.\n\nFile, Directory, and Process Handling\n\nThe shutil moduleprovideshigh-levelfunctionsfor ﬁleanddirectory handling, including shutil.copy() and shutil.copytree() for copying ﬁles and entire directory trees, shutil.move() for moving directory trees, and shutil.rmtree() for removing entire directory trees, including nonempty ones.\n\nTemporary ﬁles and directories should be created using the tempfile module which provides the necessary functions, for example, tempfile.mkstemp(), and creates the temporaries in the most secure manner possible.\n\n||\n\nOverviewof Python’s Standard Library\n\nThe filecmp module can be used to compare ﬁles with the filecmp.cmp() func- tion and to compare entire directories with the filecmp.cmpfiles() function.\n\nOne very powerful and effective use of Python programs is to orchestrate the running of other programs. This can be done using the subprocess mod- ule which can start other processes, communicate with them using pipes, and retrieve their results. This module is covered in Chapter 10. An even more powerful alternative is to use the multiprocessing module which provides ex- tensivefacilitiesforofﬂoadingworktomultipleprocessesandforaccumulating results, and can often be used as an alternative to multithreading.\n\nThe os moduleprovidesplatform-independent accessto operating systemfunc- tionality. The os.environ variable holds a mapping object whose items are en- vironment variable names and their values. The program’s working directory is provided by os.getcwd() and can be changed using os.chdir(). The module also provides functions for low-level ﬁle-descriptor-based ﬁle handling. The os.access() function can be used to determine whether a ﬁle exists or whether it is readable or writable, and the os.listdir() function returns a list of the entries (e.g.,the ﬁles and directories,but excluding the . and .. entries),in the directory it is given. The os.stat() function returns various items of informa- tion about a ﬁle or directory, such as its mode, access time, and size.\n\nDirectories can be created using os.mkdir(), or if intermediate directories need to be created, using os.makedirs(). Empty directories can be removed using os.rmdir(), and directory trees that contain only empty directories can be removed using os.removedirs(). Files or directories can be removed using os.remove(), and can be renamed using os.rename().\n\nThe os.walk() function iterates over an entire directory tree, retrieving the name of every ﬁle and directory in turn.\n\nThe os module also provides many low-level platform-speciﬁc functions, for example, to work with ﬁle descriptors, and to fork (only on Unix systems), spawn, and exec.\n\nWhereas the os module provides functions for interacting with the operating system, especially in the context of the ﬁle system, the os.path module pro- vides a mixture of string manipulation (of paths), and some ﬁle system con- venience functions. The os.path.abspath() function returns the absolute path of its argument, with redundant path separators and .. elements removed. The os.path.split() function returns a 2-tuple with the ﬁrst element con- taining the path and the second the ﬁlename (which will be empty if a path with no ﬁlename was given). These two parts are also available directly using os.path.basename() and os.path.dirname(). A ﬁlename can also be split into two parts, name and extension, using os.path.splitext(). The os.path.join() function takes any number of path strings and returns a single path using the platform-speciﬁc path separator.\n\n223\n\n224\n\nChapter 5. Modules\n\nIf we need several pieces of information about a ﬁle or directory we can use os.stat(), but if we need just one piece, we can use the relevant os.path function,for example, os.path.exists(), os.path.getsize(), os.path.isfile(),or os.path.isdir().\n\nThe mimetypes module has the mimetypes.guess_type() function that tries to guess the given ﬁle’s MIME type.\n\nExample: The os and os.path Modules\n\nHere is how we can use the os and os.path modules to create a dictionary where each key is a ﬁlename (including its path) and where each value is the timestamp (seconds since the epoch) when the ﬁle was last modiﬁed, for those ﬁles in the given path:\n\ndate_from_name = {} for name in os.listdir(path):\n\nfullname = os.path.join(path, name) if os.path.isfile(fullname):\n\ndate_from_name[fullname] = os.path.getmtime(fullname)\n\nThis code is pretty straightforward, but can be used only for the ﬁles in a single directory. If we need to traverse an entire directory tree we can use the os.walk() function.\n\nHere is a code snippet taken from the finddup.py program.★ The code creates a dictionary where each key is a 2-tuple (ﬁle size, ﬁlename) where the ﬁlename excludes the path, and where each value is a list of the full ﬁlenames that match their key’s ﬁlename and have the same ﬁle size:\n\ndata = collections.defaultdict(list)\n\nfor root, dirs, files in os.walk(path):\n\nfor filename in files:\n\nfullname = os.path.join(root, filename) key = (os.path.getsize(fullname), filename) data[key].append(fullname)\n\nFor each directory,os.walk() returnsthe root and two lists,one of the subdirec- tories in the directory and the other of the ﬁles in the directory. To get the full path for a ﬁlename we need to combine just the root and the ﬁlename. Notice thatwedonothavetorecurseintothesubdirectoriesourselves—os.walk() does that for us. Once the data has been gathered,we can iterate over it to produce a report of possible duplicate ﬁles:\n\n★A much more sophisticated ﬁnd duplicates program, findduplicates-t.py, which uses multiple threads and MD5 checksums, is covered in Chapter 10.\n\n|",
      "page_number": 213
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 221-228)",
      "start_page": 221,
      "end_page": 228,
      "detection_method": "topic_boundary",
      "content": "Overviewof Python’s Standard Library\n\nfor size, filename in sorted(data):\n\nnames = data[(size, filename)] if len(names) > 1:\n\nprint(\"{filename} ({size} bytes) may be duplicated \" \"({0} files):\".format(len(names), **locals()))\n\nfor name in names:\n\nprint(\"\\t{0}\".format(name))\n\nBecause the dictionary keys are (size, ﬁlename) tuples, we don’t need to use a key function to get the data sorted in size order. If any (size, ﬁlename) tuple has more than one ﬁlename in its list, these might be duplicates.\n\n... shell32.dll (8460288 bytes) may be duplicated (2 files): \\windows\\system32\\shell32.dll \\windows\\system32\\dllcache\\shell32.dll\n\nThis is the last item taken from the 3282 lines of output produced by running finddup.py \\windows on a Windows XP system.\n\nNetworking and Internet Programming\n\nPackages and modules for networking and Internet programming are a major part of Python’s standard library. At the lowest level, the socket module pro- vides the most fundamental network functionality,with functions for creating sockets,doing DNS(DomainNameSystem)lookups,andhandling IP (Internet Protocol) addresses. Encrypted and authenticated sockets can be set up using the ssl module. The socketserver module providesTCP (TransmissionControl Protocol) and UDP (User Datagram Protocol) servers. These servers can han- dle requestsdirectly,or can create a separate process(by forking)or a separate thread to handle each request. Asynchronous client and server socket han- dling can be achieved using the asyncore module and the higher-level asynchat module that is built on top of it.\n\nPython has deﬁned the WSGI (Web Server Gateway Interface) to provide a standard interface between web servers and web applications written in Python. In support of the standard the wsgiref package provides a reference implementation of WSGI that has modules for providing WSGI-compliant HTTP servers, and for handling response header and CGI (Common Gateway Interface)scripts. In addition,the http.server module providesan HTTP serv- er which can be given a request handler (a standard one is provided), to run CGI scripts. The http.cookies and http.cookiejar modules provide functions for managing cookies, and CGI script support is provided by the cgi and cgitb modules.\n\n225\n\n||\n\n226\n\nChapter 5. Modules\n\nClientaccesstoHTTPrequestsisprovidedby thehttp.client module,although the higher-level urllib package’s modules, urllib.parse, urllib.request, url- lib.response, urllib.error, and urllib.robotparser, provide easier and more convenient access to URLs. Grabbing a ﬁle from the Internet is as simple as:\n\nfh = urllib.request.urlopen(\"http://www.python.org/index.html\") html = fh.read().decode(\"utf8\")\n\nThe urllib.request.urlopen() function returns an object that behaves much like a ﬁle object opened in read binary mode. Here we retrieve the Python Web site’s index.html ﬁle (as a bytes object), and store it as a string in the html variable. It is also possible to grab ﬁles and store them in local ﬁles with the urllib.request.urlretrieve() function.\n\nHTML and XHTML documents can be parsed using the html.parser module, URLscan be parsedand createdusing the urllib.parse module,and robots.txt ﬁlescan be parsed with the urllib.robotparser module. Data that isrepresent- ed using JSON (JavaScript Object Notation)can be read and written using the json module.\n\nIn addition to HTTP server and client support,the library provides XML-RPC (Remote Procedure Call) support with the xmlrpc.client and xmlrpc.server modules. Additional client functionality is provided for FTP (File Transfer Protocol) by the ftplib module, for NNTP (Network News Transfer Protocol) by the nntplib module, and for TELNET with the telnetlib module.\n\nThe smtpd module provides an SMTP (Simple Mail Transfer Protocol) server, and the email client modules are smtplib for SMTP, imaplib for IMAP4 (Inter- net Message Access Protocol),and poplib for POP3 (Post Ofﬁce Protocol).Mail- boxes in various formatscan be accessed using the mailbox module. Individual messages (including multipart messages) can be created and manipulated us- ing the email module.\n\nIf the standard library’s packages and modules are insufﬁcient in this area, Twisted (www.twistedmatrix.com) provides a comprehensive third-par- ty networking library. Many third-party web programming libraries are also available, including Django (www.djangoproject.com) and Turbogears (www.turbogears.org) for creating web applications, and Plone (www.plone.org) and Zope (www.zope.org) which provide complete web frameworks and content management systems. All of these libraries are written in Python.\n\nXML\n\nThere are two widely used approaches to parsing XML documents. One is the DOM (Document Object Model) and the other is SAX (Simple API for XML). Two DOM parsers are provided, one by the xml.dom module and the other by the xml.dom.minidom module. A SAX parser is provided by the xml.sax mod-\n\n||\n\nOverviewof Python’s Standard Library\n\nule. We have already used the xml.sax.saxutils module for its xml.sax.sax- utils.escape() function (to XML-escape “&”, “<”, and “>”). There is also an xml.sax.saxutils.quoteattr() function that does the same thing but addi- tionally escapes quotes (to make the text suitable for a tag’s attribute), and xml.sax.saxutils.unescape() to do the opposite conversion.\n\nTwo other parsers are available. The xml.parsers.expat module can be used to parse XML documentswith expat,providing the expat library isavailable,and the xml.etree.ElementTree can be used to parse XML documents using a kind of dictionary/list interface. (By default, the DOM and element tree parsers themselves use the expat parser under the hood.)\n\nWriting XML manually and writing XML using DOM and element trees, and parsing XML using the DOM, SAX, and element tree parsers, is covered in Chapter 7.\n\nThere is also a third-party library, lxml (www.codespeak.net/lxml), that claims to be “the most feature-rich and easy-to-use library for working with XML and HTML in the Python language.” This library provides an interface that is essentially a superset of what the element tree module provides, as well as many additional features such as support for XPath, XSLT, and many other XML technologies.\n\nExample: The xml.etree.ElementTree Module\n\nPython’s DOM and SAX parsers provide the APIs that experienced XML programmers are used to, and the xml.etree.ElementTree module offers a more Pythonic approach to parsing and writing XML. The element tree module is a fairly recent addition to the standard library,★ and so may not be familiar to some readers. In view of this,we will present a very short examplehereto give a ﬂavor of it—Chapter 7 provides a more substantial example and provides comparative code using DOM and SAX.\n\nThe U.S.government’sNOAA (NationalOceanic and AtmosphericAdministra- tion) Web site provides a wide variety of data, including an XML ﬁle that lists the U.S.weather stations. The ﬁle is more than 20000 lines long and contains details of around two thousand stations. Here is a typical entry:\n\n<station> <station_id>KBOS</station_id> <state>MA</state> <station_name>Boston, Logan International Airport</station_name> ... <xml_url>http://weather.gov/data/current_obs/KBOS.xml</xml_url> </station>\n\n★The xml.etree.ElementTree module ﬁrst appeared in Python 2.5.\n\n227\n\n|\n\nio. StringIO 213➤\n\n228\n\nChapter 5. Modules\n\nWe have cut out a few lines and reduced the indentation that is present in the ﬁle. The ﬁle is about 840K in size, so we have compressed it using gzip to a more manageable 72K. Unfortunately, the element tree parser requires either a ﬁlenameor a ﬁleobject toread,but wecannotgiveit thecompressedﬁlesince that will just appear to be random binary data. We can solve thisproblemwith two initial steps:\n\nbinary = gzip.open(filename).read() fh = io.StringIO(binary.decode(\"utf8\"))\n\nThe gzip module’s gzip.open() function is similar to the built-in open() except that it reads gzip-compressed ﬁles (those with extension .gz) as raw binary data. We need the data available as a ﬁle that the element tree parser can work with,so we use the bytes.decode() method to convert the binary data to a string using UTF-8 encoding (which is what the XML ﬁle uses), and we create a ﬁle-like io.StringIO object with the string containing the entire XML ﬁle as its data.\n\ntree = xml.etree.ElementTree.ElementTree() root = tree.parse(fh) stations = [] for element in tree.getiterator(\"station_name\"):\n\nstations.append(element.text)\n\nHerewecreatea new xml.etree.ElementTree.ElementTree object and give it a ﬁle object from which to read the XML we want it to parse. As far as the element tree parser is concerned it has been passed a ﬁle object open for reading, although in fact it is reading a string inside an io.StringIO object. We want to extract the names of all the weather stations,and this is easily achieved using the xml.etree.ElementTree.ElementTree.getiterator() method which returnsan iterator that returns all the xml.etree.ElementTree.Element objects that have the given tag name. We just use the element’s text attribute to retrieve the text. Like os.walk(), we don’t have to do any recursion ourselves; the iterator method does that for us. Nor do we have to specify a tag—in which case the iterator will return every element in the entire XML document.\n\nOther Modules\n\nWe don’t have the space to cover the nearly 200 packagesand modulesthat are available in the standard library. Nonetheless, this general overview should be sufﬁcient to get a ﬂavor of what the library provides and some of the key packages in the major areas it serves. In this section’s ﬁnal subsection we discuss just a few more areas of interest.\n\nIn the previous section we saw how easy it is to create tests in docstrings and to run them using the doctest module. The library also has a unit-testing\n\n||\n\nbytes type ➤ 293\n\nShallow and deep copying 146➤\n\nOverviewof Python’s Standard Library\n\n229\n\nframework provided by the unittest module—this is a Python version of the Java JUnit test framework. The doctest module also provides some basic in- tegration with the unittest module. (Testing is covered more fully in Chap- ter 9.) Several third-party testing frameworks are also available, for example, py.test from codespeak.net/py/dist/test/test.html and nose from code.google. com/p/python-nose.\n\nNoninteractive applications such as servers often report problems by writing to log ﬁles. The logging module provides a uniform interface for logging, and in addition to being able to log to ﬁles, it can log using HTTP GET or POST requests, or using email or sockets.\n\nThe library provides many modules for introspection and code manipulation, and although most of them are beyond the scope of thisbook,one that is worth mentioning is pprint which has functions for “pretty printing” Python objects, including collection data types, which is sometimes useful for debugging. We will see a simple use of the inspect module that introspects live objects in Chapter 8.\n\nThe threading module provides support for creating threaded applications, and the queue module provides three different kinds of thread-safe queues. Threading is covered in Chapter 10.\n\nPython has no native support for GUI programming,but several GUI libraries can be used by Python programs. The Tk library is available using the tkinter module,and is usually installed as standard. GUI programming is introduced in Chapter 15.\n\nThe abc (Abstract Base Class) module provides the functions necessary for creating abstract base classes. This module is covered in Chapter 8.\n\nThe copy module provides the copy.copy() and copy.deepcopy() were discussed in Chapter 3.\n\nfunctions that\n\nAccessto foreignfunctions,that is,to functionsin shared libraries (.dll ﬁles on Windows, .dylib ﬁles on Mac OS X, and .so ﬁles on Linux), is available using the ctypes module. Python also provides a C API, so it is possible to create custom data types and functions in C and make these available to Python. Both the ctypes module and Python’s C API are beyond the scope of this book.\n\nIf none of the packages and modules mentioned in this section provides the functionality you need, before writing anything from scratch it is worth checking the Python documentation’s Global Module Index to see whether a suitable module is available, since we have not been able to mention ev- ery one here. And failing that, try looking at the Python Package Index (pypi.python.org/pypi) which contains several thousand Python add-ons rang- ing from small one-ﬁle modules all the way up to large library and framework packages containing anything from scores to hundreds of modules.\n\n230\n\nChapter 5. Modules\n\nSummary\n\n|||\n\nThe chapter began by introducing the various syntaxes that can be used for importing packages, modules, and objects inside modules. We noted that many programmers only use the import importable syntax so as to avoid name clashes,and that we must be careful not to give a program or module the same name as a top-level Python module or directory.\n\nAlso discussed were Python packages. These are simply directories with an __init__.py ﬁle and one or more .py modules inside them. The __init__.py ﬁle can be empty, but to support the from importable import * syntax, we can create an __all__ special variable in the __init__.py ﬁle set to a list of module names. We can also put any common initialization code in the __init__.py ﬁle. It wasnoted that packagescan benestedsimply by creating subdirectoriesand having each of these contain its own __init__.py ﬁle.\n\nTwo custom modules were described. The ﬁrst just provided a few functions and had very simple doctests. The second was more elaborate with its own exceptions, the use of dynamic function creation to create a function with a platform-speciﬁcimplementation,privateglobaldata,a calltoaninitialization function, and more elaborate doctests.\n\nAbout half the chapter was devoted to a high-level overview of Python’s stan- dard library. Several string handling modules were mentioned and a couple of io.StringIO examples were presented. One example showed how to write text to a ﬁle using either the built-in print() function or a ﬁle object’s write() method,and how to use an io.StringIO object in place of a real ﬁle. In previous chapters we handled command-line options by reading sys.argv ourselves, but in the coverage of the library’s support for command-line programming we in- troducedtheoptparsemodulewhichgreatlysimpliﬁescommand-lineargument handling—we will use this module extensively from now on.\n\nMention wasmade of Python’sexcellent support for numbers,and the library’s numeric types and its three modules of mathematical functions, as well as the support for scientiﬁc and engineering mathematics provided by the SciPy project. Both library and third-party date/time handling classes were brieﬂy described and examples of how to obtain the current date/time and how to convert between datetime.datetime and the number of seconds since the epoch were shown. Also discussed were the additional collection data types and the algorithms for working with ordered sequences that the standard library provides, along with some examples of using the heapq module’s functions.\n\nThe modules that support various ﬁle encodings (besides character encodings) were discussed, as well as the modules for packing and unpacking the most popular archiveformats,and thosethat have supportfor audiodata. An exam- pleshowing howtousetheBase64encoding tostorebinary datain .py ﬁleswas given,andalsoa programtounpack tarballs. Considerablesupportisprovided\n\nSummary\n\nfor handling directories and ﬁles—and all of this is abstracted into platform- independent functions. Examples were shown for creating a dictionary with ﬁlename keys and last modiﬁed timestamp values, and for doing a recursive search of a directory to identify possible duplicate ﬁles based on their name and size.\n\nA largepartof thelibrary isdevotedtonetworking andInternetprogramming. We very brieﬂy surveyed what is available, from raw sockets (including encrypted sockets),to TCP and UDP servers, to HTTP servers and support for the WSGI.Also mentioned were the modules for handling cookies,CGI scripts, and HTTP data, and for parsing HTML, XHTML, and URLs. Other modules that were mentioned included those for handling XML-RPC and for handling higher-level protocols such as FTP and NNTP, as well as the email client and server support using SMTP and client support for IMAP4 and POP3.\n\nThe library’s comprehensive support for XML writing and parsing was also mentioned, including the DOM, SAX, and element tree parsers, and the expat module. And an example was given using the element tree module. Mention was also made of some of the many other packages and modules that the library provides.\n\nPython’s standard library represents an extremely useful resource that can save enormous amounts of time and effort, and in many cases allows us to write much smaller programs by relying on the functionality that the library provides. Inaddition,literally thousandsof third-party packagesareavailable to ﬁll any gaps the standard library may have. All of this predeﬁned function- ality allows us to focus much more on what we want our programs to do, while leaving the library modules to take care of most of the details.\n\nThis chapter brings us to the end of the fundamentals of procedural program- ming. Later chapters, and particularly Chapter 8, will look at more advanced and specialized procedural techniques, and the following chapter introduces object-orientedprogramming. UsingPythonasapurelyprocedurallanguageis both possibleand practical—especiallyfor small programs—butfor mediumto largeprograms,for custompackagesand modules,and for long-termmaintain- ability, the object-oriented approach usually wins out. Fortunately,all that we have covered up to now is both useful and relevant in object-oriented program- ming, so the subsequent chapters will continue to build up our Python knowl- edge and skills based on the foundations that have now been laid.\n\nExercise\n\nWrite a program to show directory listings, rather like the dir command in Windows or ls in Unix. The beneﬁt of creating our own listing program is that we can build in the defaults we prefer and can use the same program on\n\n231\n\n|||\n\nlocale. set- locale() 86➤\n\n232\n\nChapter 5. Modules\n\nall platforms without having to remember the differences between dir and ls. Create a program that supports the following interface:\n\nUsage: ls.py [options] [path1 [path2 [... pathN]]] The paths are optional; if not given . is used. Options: -h, --help show this help message and exit -H, --hidden show hidden files [default: off] -m, --modified show last modified date/time [default: off] -o ORDER, --order=ORDER order by ('name', 'n', 'modified', 'm', 'size', 's') [default: name] -r, --recursive recurse into subdirectories [default: off] -s, --sizes show sizes [default: off]\n\n(The output has been modiﬁed slightly to ﬁt the book’s page.)\n\nHere is an example of output on a small directory using the command line ls.py -ms -os misc/:\n\n2008-02-11 14:17:03 12,184 misc/abstract.pdf 2008-02-05 14:22:38 109,788 misc/klmqtintro.lyx 2007-12-13 12:01:14 1,359,950 misc/tracking.pdf misc/phonelog/ 3 files, 1 directory\n\nWe used option grouping in the command line (optparse handlesthisautomati- cally for us),but the same could have been achieved using separate options,for example, ls.py -m -s -os misc/, or by even more grouping, ls.py -msos misc/, or by using long options, ls.py --modified --sizes --order=size misc/, or any com- bination of these. Note that we deﬁne a “hidden” ﬁle or directory as one whose name begins with a dot (.).\n\nThe exercise is quite challenging. You will need to read the optparse documen- tation to see how to provide options that set a True value, and how to offer a ﬁxed list of choices. If the user sets the recursive option you will need to pro- cess the ﬁles (but not the directories) using os.walk(); otherwise, you will have to use os.listdir() and process both ﬁles and directories yourself.\n\nOne rather tricky aspect is avoiding hidden directories when recursing. They can be cut out of os.walk()’s dirs list—and therefore skipped by os.walk()—by modifying that list. But be carefulnot to assign to the dirs variableitself,since that won’t change the list it refers to but will simply (and uselessly) replace it; the approach used in the model solution is to assign to a slice of the whole list, that is, dirs[:] = [dir for dir in dirs if not dir.startswith(\".\")].\n\nThe best way to get grouping characters in the ﬁle sizes is to import the locale module, call locale.setlocale() to get the user’s default locale, and use the n format character. Overall, ls.py is about 130 lines split over four functions.",
      "page_number": 221
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 229-237)",
      "start_page": 229,
      "end_page": 237,
      "detection_method": "topic_boundary",
      "content": "6\n\nThe Object-Oriented Approach ● Custom Classes ● Custom Collection Classes\n\nObject-Oriented Programming\n\nIn all the previous chapters we used objects extensively, but our style of programming has been strictly procedural. Python is a multiparadigm language—it allowsusto programin procedural,object-oriented,and function- al style,or in any mixture of styles,since it does not force us to program in any one particular way.\n\nIt is perfectly possible to write any program in procedural style, and for very smallprograms(upto,say,500lines),doing soisrarely a problem. Butfor most programs,and especially for medium-size and large programs,object-oriented programming offers many advantages.\n\nThis chapter covers all the fundamental concepts and techniques for doing object-orientedprogramminginPython. Theﬁrstsectionisespeciallyforthose who arelessexperiencedand for thosecoming froma proceduralprogramming background (such as C or Fortran). The section starts by looking at some of the problemsthat can arise with proceduralprogramming that object-oriented programming can solve. Then it brieﬂy describes Python’s approach to object- oriented programming and explains the relevant terminology. After that, the chapter’s two main sections begin.\n\nThe second section covers the creation of custom data types that hold sin- gle items (although the items themselves may have many attributes), and the third section covers the creation of custom collection data types that can hold any number of objects of any types. These sections cover most aspects of object-oriented programming in Python, although we defer some more ad- vanced material to Chapter 8.\n\n233\n\n||||\n\n234\n\nChapter 6. Object-Oriented Programming\n\nThe Object-Oriented Approach\n\nIn this section we will look at some of the problems of a purely procedural ap- proach by considering a situation where we need to represent circles, poten- tially lots of them. The minimum data required to represent a circle is its (x,y) position and its radius. One simple approach is to use a 3-tuple for each circle. For example:\n\ncircle = (11, 60, 8)\n\nOne drawback of this approach is that it isn’t obvious what each element of the tuple represents. We could mean (x, y, radius) or, just as easily, (ra- dius, x, y). Another drawback is that we can access the elements by index position only. If we have two functions, distance_from_origin(x, y) and edge_distance_from_origin(x, y, radius),we would need to use tuple unpacking to call them with a circle tuple:\n\ndistance = distance_from_origin(*circle[:2]) distance = edge_distance_from_origin(*circle)\n\nBoth of these assume that the circle tuples are of the form (x, y, radius). We can solve the problem of knowing the element order and of using tuple unpacking by using a named tuple:\n\nimport collections Circle = collections.namedtuple(\"Circle\", \"x y radius\") circle = Circle(13, 84, 9) distance = distance_from_origin(circle.x, circle.y)\n\nThis allows us to create Circle 3-tuples with named attributes which makes function calls much easier to understand, since to access elements we can use their names. Unfortunately, problems remain. For example, there is nothing to stop an invalid circle from being created:\n\ncircle = Circle(33, 56, -5)\n\nIt doesn’t make sense to have a circle with a negative radius, but the circle named tuple is created here without raising an exception—just as it would be if the radius was given as a variable that held a negative number. The error will be noticed only if we call the edge_distance_from_origin() function—and then only if that function actually checks for a negative radius. This inability to validate when creating an object is probably the worst aspect of taking a purely procedural approach.\n\nIf we want circles to be mutable so that we can move them by changing their coordinates or resize them by changing their radius, we can do so by using the private collections.namedtuple._replace() method:\n\n|||\n\nThe Object-Oriented Approach\n\ncircle = circle._replace(radius=12)\n\nJust as when we create a Circle, there is nothing to stop us from (or warn us about) setting invalid data.\n\nIf the circles were going to need lots of changes,we might opt to use a mutable data type such as a list, for the sake of convenience:\n\ncircle = [36, 77, 8]\n\nThis doesn’t give us any protection from putting in invalid data, and the best we can doabout accessing elementsby nameistocreatesomeconstantssothat we can write things like circle[RADIUS] = 5. But using a list brings additional problems—for example, we can legitimately call circle.sort()! Using a dictio- nary might be an alternative, for example, circle = dict(x=36, y=77, radius=8), but again there is no way to ensure a valid radius and no way to prevent inap- propriate methods from being called.\n\nObject-Oriented Concepts and Terminology\n\nWhat we need is some way to package up the data that is needed to represent a circle, and some way to restrict the methods that can be applied to the data so that only valid operationsare possible. Both of these thingscan be achieved by creating a custom Circle data type. We will see how to create a Circle data type in later in this section, but ﬁrst we need to cover some preliminaries and explainsometerminology. Don’tworry if theterminology isunfamiliarat ﬁrst; it will become much clearer once we reach the examples.\n\nWe use the terms class, type, and data type interchangeably. In Python we can create custom classes that are fully integrated and that can be used just like the built-in data types. We have already encountered many classes, for example, dict, int, and str. We use the term object, and occasionally the term instance, to refer to an instance of a particular class. For example, 5 is an int object and \"oblong\" is a str object.\n\nMost classesencapsulateboth data andthemethodsthatcanbeappliedtothat data. For example,the str classholdsa string of Unicodecharactersasitsdata and supportsmethodssuch as str.upper().Many classesalso support addition- al features;for example,we can concatenatetwostrings(or any twosequences) using the + operator and ﬁnd a sequence’s length using the built-in len() func- tion. Such features are provided by special methods—these are like normal methods except that their names always begin and end with two underscores, and are predeﬁned. For example, if we want to create a class that supports concatenation using the + operator and also the len() function,we can do so by implementing the __add__() and __len__() special methods in our class. Con- versely, we should never deﬁne any method with a name that begins and ends with two underscores unless it is one of the predeﬁned special methods and is\n\n235\n\n||\n\n236\n\nChapter 6. Object-Oriented Programming\n\nappropriateto our class. This will ensure that we never get conﬂictswith later versions of Python even if they introduce new predeﬁned special methods.\n\nObjects usually have attributes—methods are callable attributes, and other attributes are data. For example, a complex object has imag and real attributes and lots of methods, including special methods like __add__() and __sub__ (to support the binary + and - operators), and normal methods like conjugate(). Data attributes (often referred to simply as “attributes”) are normally imple- mented as instance variables, that is, variables that are unique to a particular object. We will see examples of this, and also examples of how to provide data attributesasproperties.A propertyisanitemof objectdatathatisaccessedlike aninstancevariablebutwheretheaccessesarehandledby methodsbehindthe scenes. As we will see, using properties makes it easy to do data validation.\n\nInside a method (which is just a function whose ﬁrst argument is the instance onwhichitiscalledtooperate),severalkindsof variablesarepotentiallyacces- sible. The object’s instance variables can be accessed by qualifying their name withtheinstanceitself. Localvariablescanbecreatedinsidethemethod;these are accessed without qualiﬁcation. Class variables (sometimes called static variables) can be accessed by qualifying their name with the class name, and global variables, that is, module variables, are accessed without qualiﬁcation.\n\nSomeof thePythonliteratureusestheconceptof a namespace,a mapping from names to objects. Modules are namespaces—for example, after the statement import math we can access objects in the math module by qualifying them with their namespace name (e.g., math.pi and math.sin()). Similarly, classes and ob- jects are also namespaces; for example, if we have z = complex(1, 2), the z ob- ject’s namespace has two attributes which we can access (z.real and z.imag).\n\nOne of the advantages of object orientation is that if we have a class, we can specialize it. This means that we make a new class that inherits all the at- tributes (data and methods) from the original class,usually so that we can add or replace methods or add more instance variables. We can subclass (another term for specialize), any Python class, whether built-in or from the standard library, or one of our own custom classes.★ The ability to subclass is one of the great advantages offered by object-oriented programming since it makes it straightforward to use an existing class that has tried and tested functional- ity as the basis for a new class that extends the original, adding new data at- tributes or new functionality in a very clean and direct way. Furthermore, we can pass objects of our new class to functions and methods that were written for the original class and they will work correctly.\n\nWe use the term base class to refer to a class that is inherited; a base class may be the immediate ancestor, or may be further up the inheritance tree. Another term for base class is super class. We use the term subclass, derived\n\n★Some library classes that are implemented in C cannot be subclassed;such classes specify this in their documentation.\n\n238\n\nChapter 6. Object-Oriented Programming\n\nSome object-oriented languages have two features that Python does not pro- vide. The ﬁrst is overloading,that is,having methods with the same name but with different parameter lists in the same class. Thanks to Python’s versatile argument-handling capabilities this is never a limitation in practice. The sec- ond is access control—there are no bulletproof mechanisms for enforcing data privacy. However, if we create attributes (instance variables or methods) that begin with two leading underscores,Python will prevent unintentional access- essothatthey canbeconsideredtobeprivate. (Thisisdoneby namemangling; we will see an example in Chapter 8.)\n\nJust aswe use an uppercaseletter asthe ﬁrst letter of custom modules,we will do the same thing for customclasses. We can deﬁne asmany classesaswe like, either directly in a program or in modules—class names don’t have to match module names, and modules may contain as many class deﬁnitions as we like.\n\nNow that we have seen some of the problemsthat classescan solve,introduced the necessary terminology, and covered some background matters, we can begin to create some custom classes.\n\nCustom Classes\n\nIn earlier chapterswecreatedcustomclasses:customexceptions. Herearetwo new syntaxes for creating custom classes:\n\nclass className:\n\nsuite\n\nclass className(base_classes):\n\nsuite\n\nSince the exception subclasses we created did not add any new attributes (no instance data or methods) we used a suite of pass (i.e., nothing added), and since the suite was just one statement we put it on the same line as the class statement itself. Note that just like def statements, class is a statement, so we can create classes dynamically if we want to. A class’smethodsare created using def statementsin the class’ssuite. Classinstancesare created by calling the class with any necessary arguments;for example, x = complex(4, 8) creates a complex number and sets x to be an object reference to it.\n\nAttributes and Methods\n\nLet’s start with a very simple class, Point, that holds an (x, y) coordinate. The classisin ﬁle Shape.py,and itscompleteimplementation (excluding docstrings) is show here:\n\nclass Point:\n\n|||\n\n||\n\nCustom Classes\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\ndef distance_from_origin(self):\n\nreturn math.hypot(self.x, self.y)\n\ndef __eq__(self, other):\n\nreturn self.x == other.x and self.y == other.y\n\ndef __repr__(self):\n\nreturn \"Point({0.x!r}, {0.y!r})\".format(self)\n\ndef __str__(self):\n\nreturn \"({0.x!r}, {0.y!r})\".format(self)\n\nSince no base classes are speciﬁed, Point is a direct subclass of object, just as though we had written class Point(object). Before we discuss each of the methods, let’s see some examples of their use:\n\nimport Shape a = Shape.Point() repr(a) b = Shape.Point(3, 4) str(b) b.distance_from_origin() b.x = -19 str(b) a == b, a != b\n\n# returns: 'Point(0, 0)'\n\n# returns: '(3, 4)' # returns: 5.0\n\n# returns: '(-19, 4)' # returns: (False, True)\n\nThe Point class has two data attributes, self.x and self.y, and ﬁve methods (not counting inherited methods), four of which are special methods; they are illustrated in Figure 6.2. Once the Shape module is imported, the Point class can be used like any other. The data attributes can be accessed directly (e.g., y = a.y), and the class integrates nicely with all of Python’s other classes by providing support for the equality operator (==) and for producing strings in representational and string forms. And Python is smart enough to supply the inequality operator (!=) based on the equality operator. (It is also possible to specify each operator individually if we want total control,for example,if they are not exact opposites of each other.)\n\nPython automatically supplies the ﬁrst argument in method calls—it is an object reference to the object itself (called this in C++ and Java). We must in- clude this argument in the parameter list, and by convention the parameter is called self.All object attributes(data and methodattributes)must bequaliﬁed by self. This requires a little bit more typing compared with some other lan- guages, but has the advantage of providing absolute clarity: we always know that we are accessing an object attribute if we qualify with self.\n\n239\n\n240\n\nChapter 6. Object-Oriented Programming\n\nobject\n\n__new__() __init__() __eq__() __repr__() __str__() ...\n\nKey inherited implemented reimplemented\n\nPoint x y\n\n__new__() __init__() distance_from_origin() __eq__() __repr__() __str__() ...\n\nFigure 6.2 The Point class’s inheritancehierarchy\n\nTo create an object,two steps are necessary. First a raw or uninitialized object must be created, and then the object must be initialized, ready for use. Some object-oriented languages (such as C++ and Java) combine these two steps into one, but Python keeps them separate. When an object is created (e.g., p = Shape.Point()), ﬁrst the special method __new__() is called to create the object, and then the special method __init__() is called to initialize it.\n\nIn practice almost every Python class we create will require us to reimple- method is al- ment only the __init__() method, since the object.__new__() most always sufﬁcient and is automatically called if we don’t provide our own __new__() method. (Later in this chapter we will show a rare example where we do need to reimplement __new__().) Not having to reimplement methods in a subclass is another beneﬁt of object-oriented programming—if the base class method is sufﬁcient we don’t have to reimplement it in our subclass. This works because if we call a method on an object and the object’s class does not have an implementation of that method, Python will automatically go through the object’s base classes, and their base classes, and so on, until it ﬁnds the method—and if the method is not found an AttributeError exception is raised.\n\nFor example, if we execute p = Shape.Point(), Python begins by looking for the method Point.__new__(). Since we have not reimplemented this method, Python looks for the method in Point’s base classes. In this case there is only one base class, object, and this has the required method, so Python calls ob- ject.__new__() and creates a raw uninitialized object. Then Python looks for the initializer, __init__(), and since we have reimplemented it, Python doesn’t need to look further and calls Point.__init__(). Finally, Python sets p to be an object reference to the newly created and initialized object of type Point.\n\nBecause they are so short and a few pages away, for convenience we will show each method again before discussing it.\n\nAlter- native Fuzzy- Bool ➤ 256\n\nCustom Classes\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\nThe two instance variables, self.x and self.y, are created in the initializer, and assigned the values of the x and y parameters. Since Python will ﬁnd this initializer when we create a new Point object, the object.__init__() method will not be called. This is because as soon as Python has found the required method it calls it and doesn’t look further.\n\nObject-oriented purists might start the method off with a call to the base class __init__() method by calling super().__init__(). The effect of calling the super() function like this is to call the base class’s __init__() method. For classes that directly inherit object there is no need to do this, and in this book we call base class methods only when necessary—for example, when creating classes that are designed to be subclassed, or when creating classes that don’t directly inherit object. This is to some extent a matter of coding style—it is perfectly reasonable to always call super().__init__() at the start of a custom class’s __init__() method.\n\ndef distance_from_origin(self):\n\nreturn math.hypot(self.x, self.y)\n\nThis is a conventional method that performs a computation based on the object’s instance variables. It is quite common for methods to be fairly short and to have only the object they are called on as an argument, since often all the data the method needs is available inside the object.\n\ndef __eq__(self, other):\n\nreturn self.x == other.x and self.y == other.y\n\nMethods should not have names that begin and end with two under- scores—unless they are one of the predeﬁned special methods. Python pro- vides special methods for all the comparison operators as shown in Table 6.1.\n\nAll instances of custom classes support == by default, and the comparison returns False—unless we compare a custom object with itself. We can override this behavior by reimplementing the __eq__() special method as we have done here. Python will supply the __ne__() (not equal) inequality operator (!=) automatically if we implement __eq__() but don’t implement __ne__().\n\nBy default,all instancesof custom classesare hashable,so hash() can be called on them and they can be used as dictionary keys and stored in sets. But if we reimplement __eq__(),instancesare no longer hashable. We will see how to ﬁx this when we discuss the FuzzyBool class later on.\n\nBy implementing this special method we can compare Point objects, but if we were to try to compare a Point with an object of a different type—say, int—we\n\n241\n\nFuzzy- Bool ➤ 254\n\nstr. format() 78➤\n\n242\n\nChapter 6. Object-Oriented Programming\n\nTable 6.1 Comparison Special Methods\n\nSpecial Method\n\nUsage Description\n\n__lt__(self, other)\n\nx < y Returns True if x is less than y\n\n__le__(self, other)\n\nx <= y Returns True if x is less than or equal to y\n\n__eq__(self, other)\n\nx == y Returns True if x is equal to y\n\n__ne__(self, other)\n\nx != y Returns True if x is not equal to y\n\n__ge__(self, other)\n\nx >= y Returns True if x is greater than or equal to y\n\n__gt__(self, other)\n\nx > y Returns True if x is greater than y\n\nwould get an AttributeError exception (since ints don’t have an x attribute). On the other hand, we can compare Point objects with other objects that coincidentally just happen to have an x attribute (thanks to Python’s duck typing), but this may lead to surprising results.\n\nIf we want to avoid inappropriate comparisons there are a few approaches we can take. One is to use an assertion, for example, assert isinstance(other, Point).Another isto raisea TypeError to indicatethat comparisonsbetween the twotypesarenot supported,for example,if not isinstance(other, Point): raise TypeError().The third way (which is also the most Pythonically correct)is to do this: if not isinstance(other, Point): return NotImplemented. In this third case, if NotImplemented isreturned,Python will then try calling other.__eq__(self) to see whether the other type supportsthe comparison with the Point type,and if there is no such method or if that method also returns NotImplemented, Python willgiveupandraisea TypeErrorexception. (Notethatonly reimplementations of the comparisonspecial methodslisted in Table 6.1may return NotImplement- ed.)\n\nThe built-in isinstance() function takes an object and a class (or a tuple of classes),andreturnsTrue if theobjectisof thegivenclass(or of oneof thetuple of classes), or of one of the class’s (or one of the tuple of classes’) base classes.\n\ndef __repr__(self):\n\nreturn \"Point({0.x!r}, {0.y!r})\".format(self)\n\nThe built-in repr() function calls the __repr__() special method for the object it is given and returns the result. The string returned is one of two kinds. One kind is where the string returned can be evaluated using the built-in eval() function to produce an object equivalent to the one repr() was called on. The other kind is used where this is not possible; we will see an example later on. Here is how we can go from a Point object to a string and back to a Point object:",
      "page_number": 229
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 238-247)",
      "start_page": 238,
      "end_page": 247,
      "detection_method": "topic_boundary",
      "content": "import 195➤\n\nCustom Classes\n\np = Shape.Point(3, 9) repr(p) q = eval(p.__module__ + \".\" + repr(p)) repr(q)\n\n# returns: 'Point(3, 9)'\n\n# returns: 'Point(3, 9)'\n\nWe must give the module name when eval()-ing if we used import Shape. (This import differently,for example,from would not be necessary if we had done the Shape import Point.) Python provides every object with a few private attributes, one of which is __module__, a string that holds the object’s module name, which in this example is \"Shape\".\n\nq, both with the At the end of this snippet we have two Point objects, p and same attribute values, so they compare as equal. The eval() function returns the result of executing the string it is given—which must contain a valid Python statement.\n\ndef __str__(self):\n\nreturn \"({0.x!r}, {0.y!r})\".format(self)\n\nThe built-in str() function works like the repr() function, except that it calls the object’s __str__() special method. The result is intended to be understand- able to human readers and is not expected to be suitable for passing to the eval() function. Continuing the previous example, str(p) (or str(q)) would re- turn the string '(3, 9)'.\n\nWe have now covered the simple Point class—and also covered a lot of behind- the-scenes details that are important to know but which can mostly be left in thebackground. The Point classholdsan (x,y)coordinate—a fundamentalpart of what we need to represent a circle, as we discussed at the beginning of the chapter. In the next subsection we will see how to create a custom Circle class, inheriting from Point so that we don’t have to duplicate the code for the x and y attributes or for the distance_from_origin() method.\n\nInheritance and Polymorphism\n\nThe Circle class builds on the Point class using inheritance. The Circle class adds one additional data attribute (radius), and three new methods. It also reimplements a few of Point’s methods. Here is the complete class deﬁnition:\n\nclass Circle(Point):\n\ndef __init__(self, radius, x=0, y=0):\n\nsuper().__init__(x, y) self.radius = radius\n\ndef edge_distance_from_origin(self):\n\nreturn abs(self.distance_from_origin() - self.radius)\n\n243\n\n||\n\nDynam- ic code execu- tion ➤ 344\n\nShallow and deep copying 146➤\n\nCustom Classes\n\nof its computation. Since the Circle class does not provide an implementa- tion of the distance_from_origin() method, the one provided by the Point base class will be found and used. Contrast this with the reimplementation of the __eq__() method. This method compares this circle’s radius with the other cir- cle’sradius,andif they areequalit thenexplicitly callsthebaseclass’s__eq__() method using super(). If we did not use super() we would have inﬁnite recur- sion, since Circle.__eq__() would then just keep calling itself. Notice also that we don’t have to pass the self argument in the super() calls since Python au- tomatically passes it for us.\n\nHere are a couple of usage examples:\n\np = Shape.Point(28, 45) c = Shape.Circle(5, 28, 45) p.distance_from_origin() c.distance_from_origin()\n\n# returns: 53.0 # returns: 53.0\n\nWe can call the distance_from_origin() method on a Point or on a Circle, since Circles can stand in for Points.\n\nPolymorphism means that any object of a given class can be used as though it were an object of any of its class’s base classes. This is why when we create a subclass we need to implement only the additional methods we require and have to reimplement only those existing methods we want to replace. And when reimplementing methods, we can use the base class’s implementation if necessary by using super() inside the reimplementation.\n\nIn the Circle’s case we have implemented additional methods, such as area() and circumference(), and reimplemented methods we needed to change. The reimplementations of __repr__() and __str__() are necessary because without them the base class methods will be used and the strings returned will be of Points instead of Circles. The reimplementations of __init__() and __eq__() are necessary because we must account for the fact that Circles have an addi- tional attribute, and in both cases we make use of the base class implementa- tions of the methods to minimize the work we must do.\n\nThe Point and Circle classes are as complete as we need them to be. We could provide additional methods, such as other comparison special methods if we wanted to be able to order Points or Circles. Another thing that we might want to do for which no method is provided is to copy a Point or Circle. Most Python classes don’t provide a copy() method (exceptions being dict.copy() and set.copy()). If we want to copy a Point or Circle we can easily do so by importing the copy module and using the copy.copy() function. (There is no need to use copy.deepcopy() for Point and Circle objects since they contain only immutable instance variables.)\n\n245\n\n246\n\nChapter 6. Object-Oriented Programming\n\nUsing Properties to Control Attribute Access\n\nIn the previous subsection the Point class included a distance_from_origin() method, and the Circle class had the area(), circumference(), and edge_dis- tance_from_origin() methods. All these methodsreturn a single float value,so from the point of view of a user of these classes they could just as well be data attributes, but read-only, of course. In the ShapeAlt.py ﬁle alternative imple- mentations of Point and Circle are provided, and all the methods mentioned here are provided as properties. This allows us to write code like this:\n\ncircle = Shape.Circle(5, 28, 45) # assumes: import ShapeAlt as Shape circle.radius circle.edge_distance_from_origin # returns: 48.0\n\n# returns: 5\n\nHere are the implementations of the getter methods for the ShapeAlt.Circle class’s area and edge_ distance_from_origin properties:\n\n@property def area(self):\n\nreturn math.pi * (self.radius ** 2)\n\n@property def edge_distance_from_origin(self):\n\nreturn abs(self.distance_from_origin - self.radius)\n\nIf we provide only getters as we have done here, the properties are read-only. The code for the area property is the same as for the previous area() method. The edge_distance_from_origin’scode isslightly different from beforebecauseit now accesses the base class’s distance_from_origin property instead of calling a distance_from_origin() method. The most notable difference to both is the property decorator. A decorator is a function that takes a function or method as its argument and returns a “decorated” version, that is, a version of the function or method that is modiﬁed in some way. A decorator is indicated by preceding its name with an at symbol (@). For now, just treat decorators as syntax—in Chapter 8 we will see how to create custom decorators.\n\nThe property() decorator function is built-in and takes up to four arguments:a getter function, a setter function, a deleter function, and a docstring. The effect of using @property isthesame ascalling the property() function with just one argument, the getter function. We could have created the area property like this:\n\ndef area(self):\n\nreturn math.pi * (self.radius ** 2)\n\narea = property(area)\n\nWe rarely use this syntax, since using a decorator is shorter and clearer.\n\n||\n\nCustom Classes\n\nIn the previous subsection we noted that no validation is performed on the Circle’s radius attribute. We can provide validation by making radius into a property. This does not require any changes to the Circle.__init__() method, and any code that accesses the Circle.radius attribute will continue to work unchanged—only now the radius will be validated whenever it is set.\n\nPython programmers normally use properties rather than the explicit getters and setters (e.g., getRadius() and setRadius()) that are so commonly used in other object-oriented languages. This is because it is so easy to change a data attribute into a property without affecting the use of the class.\n\nToturnan attributeintoa readable/writableproperty wemust createa private attributewherethedata isactually held and supply getter and setter methods. Here is the radius’s getter, setter, and docstring in full:\n\n@property def radius(self):\n\n\"\"\"The circle's radius\n\n>>> circle = Circle(-2) Traceback (most recent call last): ... AssertionError: radius must be nonzero and non-negative >>> circle = Circle(4) >>> circle.radius = -1 Traceback (most recent call last): ... AssertionError: radius must be nonzero and non-negative >>> circle.radius = 6 \"\"\" return self.__radius\n\n@radius.setter def radius(self, radius):\n\nassert radius > 0, \"radius must be nonzero and non-negative\" self.__radius = radius\n\nWe use an assert to ensure a nonzero and non-negative radius and store the radius’svalue in the private attribute self.__radius.Notice that the getter and setter (and deleter if we needed one) all have the same name—it is the decora- tors that distinguish them, and the decorators rename them appropriately so that no name conﬂicts occur.\n\nThe decorator for the setter may look strange at ﬁrst sight. Every property that is created has a getter, setter, and deleter attribute, so once the radius property is created using @property, the radius.getter, radius.setter, and radius.deleter attributes become available. The radius.getter is set to the\n\n247\n\n248\n\nChapter 6. Object-Oriented Programming\n\ngetter method by the @property decorator. The other two are set up by Python so that they donothing (sotheattributecannot bewrittento or deleted),unless they are used as decorators, in which case they in effect replace themselves with the method they are used to decorate.\n\nThe Circle’sinitializer,Circle.__init__(),includesthe statement self.radius = radius; this will call the radius property’s setter, so if an invalid radius is given when a Circle is created an AssertionError exception will be raised. Similarly, if an attempt is made to set an existing Circle’s radius to an invalid value, again the setter will be called and an exception raised. The docstring includes doctests to test that the exception is correctly raised in these cases. (Testing is covered more fully in Chapter 9.)\n\nBoth the Point and Circle types are custom data types that have sufﬁcient functionality to be useful. Most of the data types that we are likely to create are like this, but occasionally it is necessary to create a custom data type that is complete in every respect. We will see examples of this in the next sub- section.\n\nCreating Complete Fully Integrated Data Types\n\nWhen creating a complete data type two possibilities are open to us. One is to create the data type from scratch. Although the data type will inherit object (as all Python classes do), every data attribute and method that the data type requires (apart from __new__()) must be provided. The other possibility is to inherit from an existing data type that is similar to the one we want to create. In this case the work usually involves reimplementing those methodswe want to behave differently and “unimplementing” those methods we don’t want at all.\n\nIn the following subsubsection we will implement a FuzzyBool data type from scratch, and in the subsubsection after that we will implement the same type but will use inheritance to reduce the work we must do. The built-in bool type is two-valued (True and False), but in some areas of AI (Artiﬁcial Intelligence), fuzzy Booleansareused,which havevaluescorresponding to“true”and“false”, and also to intermediates between them. In our implementations we will use ﬂoating-point values with 0.0 denoting False and 1.0 denoting True. In this system, 0.5 means 50 percent true, and 0.25 means 25 percent true, and so on. Here are some usage examples (they work the same with either implemen- tation):\n\na = FuzzyBool.FuzzyBool(.875) b = FuzzyBool.FuzzyBool(.25) a >= b bool(a), bool(b) ~a\n\n# returns: True # returns: (True, False) # returns: FuzzyBool(0.125)\n\n||\n\nShape- Alt. Circle. radius proper- ty 247➤\n\nCustom Classes\n\na & b b |= FuzzyBool.FuzzyBool(.5) \"a={0:.1%} b={1:.0%}\".format(a, b)\n\n# returns: FuzzyBool(0.25) # b is now: FuzzyBool(0.5) # returns: 'a=87.5% b=50%'\n\nWe want the FuzzyBool type to support the complete set of comparison oper- ators (<, <=, ==, !=, >=, >), and the three basic logical operations, not (~), and (&), and or (|). In addition to the logical operations we want to provide a couple of other logical methods, conjunction() and disjunction(), that take as many FuzzyBools as we like and return the appropriate resultant FuzzyBool. And to complete the data type we want to provide conversionsto types bool, int, float, andstr,andhaveaneval()-ablerepresentationalform. Theﬁnalrequirements are that FuzzyBool supports str.format() format speciﬁcations, that FuzzyBools can be used as dictionary keys or as members of sets, and that FuzzyBools are immutable—but with the provision of augmented assignment operators (&= and |=) to ensure that they are convenient to use.\n\nTable 6.1 (242 ➤) lists the comparison special methods, Table 6.2 (➤ 250) lists the fundamental special methods, and Table 6.3 (➤ 253) lists the numeric spe- cial methods—these include the bitwise operators(~, &,and |) which FuzzyBools use for their logical operators, and also arithmetic operators such as + and - which FuzzyBool does not implement because they are inappropriate.\n\nCreating Data Types from Scratch\n\nTo create the FuzzyBool type from scratch means that we must provide an attribute to hold the FuzzyBool’s value and all the methods that we require. Here are the class line and the initializer, taken from FuzzyBool.py:\n\nclass FuzzyBool:\n\ndef __init__(self, value=0.0):\n\nself.__value = value if 0.0 <= value <= 1.0 else 0.0\n\nWe have madethevalue attributeprivatebecausewe want FuzzyBool to behave like immutables,soallowing accessto theattributewould be wrong. Also,if an out-of-range value is given we force it to take a fail-safe value of 0.0 (false). In theprevioussubsection’sShapeAlt.Circle classwe used a stricterpolicy,raising an exception if an invalid radius value was used when creating a new Circle object. The FuzzyBool’s inheritance tree is shown in Figure 6.4.\n\nThe simplest logical operator is logical NOT, for which we have coopted the bitwise inversion operator (~):\n\ndef __invert__(self):\n\nreturn FuzzyBool(1.0 - self.__value)\n\n249\n\n|\n\nCustom Classes\n\nobject\n\nFuzzyBool\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() ...\n\nKey inherited implemented reimplemented\n\n__value\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() __bool__() __float__() __invert__() __and__() __iand__() conjunction() # static ...\n\nFigure 6.4 The FuzzyBool class’s inheritancehierarchy\n\ndef __iand__(self, other):\n\nself.__value = min(self.__value, other.__value) return self\n\nThe bitwise AND operator returns a new FuzzyBool based on this one and the other one, whereas the augmented assignment (in-place) version updates the private value. Strictly speaking, this is not immutable behavior, but it does match the behavior of some other Python immutables, such as int, where, for example, using += looks like the left-hand operand is being changed but in fact it is re-bound to refer to a new int object that holds the result of the addition. In this case no rebinding is needed because we really do change the FuzzyBool itself. And we return self to support the chaining of operations.\n\nWe could also implement __rand__().Thismethod iscalled when self and other are of different types and the __and__() method is not implemented for that particular pair of types. This isn’t needed for the FuzzyBool class. Most of the special methods for binary operators have both “i” (in-place) and “r” (reﬂect, that is, swap operands) versions.\n\nWehavenot shown theimplementationfor __or__() which providesthebitwise | operator, or for __ior__() which provides the in-place |= operator, since both are the same as the equivalent AND methodsexcept that we take the maximum value instead of the minimum value of self and other.\n\ndef __repr__(self):\n\nreturn (\"{0}({1})\".format(self.__class__.__name__,\n\nself.__value))\n\n251\n\n252\n\nChapter 6. Object-Oriented Programming\n\nWe have created an eval()-able representational form. For example, given f = FuzzyBool.FuzzyBool(.75); repr(f) will produce the string 'FuzzyBool(0.75)'.\n\nAll objects have some special attributes automatically supplied by Python, one of which is called __class__, a reference to the object’s class. All classes have a private __name__ attribute,again provided automatically. We have used these attributes to provide the class name used for the representation form. This means that if the FuzzyBool class is subclassed just to add extra methods, the inherited __repr__() method will work correctly without needing to be reimplemented, since it will pick up the subclass’s class name.\n\ndef __str__(self):\n\nreturn str(self.__value)\n\nFor the string form we just return the ﬂoating-point value formatted as a string. We don’t have to use super() to avoid inﬁnite recursion because we call str() on the self.__value attribute, not on the instance itself.\n\ndef __bool__(self):\n\nreturn self.__value > 0.5\n\ndef __int__(self):\n\nreturn round(self.__value)\n\ndef __float__(self):\n\nreturn self.__value\n\nThe __bool__() specialmethod convertstheinstanceto a Boolean,so it must al- waysreturn either True or False.The __int__() specialmethod providesinteger conversion. We have used the built-in round() function because int() simply truncates(so would return 0 for any FuzzyBool value except 1.0).Floating-point conversion is easy because the value is already a ﬂoating-point number.\n\ndef __lt__(self, other):\n\nreturn self.__value < other.__value\n\ndef __eq__(self, other):\n\nreturn self.__value == other.__value\n\nTo provide the complete set of comparisons (<, <=, ==, !=, >=, >) it is necessary to implement at least three of them, <, <=, and ==, since Python can infer > from <, != from ==, and >= from <=. We have shown only two representative methods here since all of them are very similar.★\n\ndef __hash__(self):\n\nreturn hash(id(self))\n\n★ In fact, we implemented only the __lt__() and __eq__() methods quoted here—the other comparison methods were automatically generated; we will see how in Chapter 8.\n\nCom- plete compar- isons ➤ 379\n\nCustom Classes\n\nTable 6.3 Numeric and Bitwise Special Methods\n\nSpecial Method\n\nUsage\n\nSpecial Method\n\n__abs__(self)\n\nabs(x)\n\n__complex__(self)\n\n__float__(self)\n\nfloat(x)\n\n__int__(self)\n\n__index__(self)\n\nbin(x) oct(x) hex(x)\n\n__round__(self,\n\ndigits)\n\n__pos__(self)\n\n+x\n\n__neg__(self)\n\n__add__(self, other)\n\nx + y\n\n__sub__(self, other)\n\n__iadd__(self, other)\n\nx += y\n\n__isub__(self, other)\n\n__radd__(self, other)\n\ny + x\n\n__rsub__(self, other)\n\n__mul__(self, other)\n\nx * y\n\n__mod__(self, other)\n\n__imul__(self, other)\n\nx *= y\n\n__imod__(self, other)\n\n__rmul__(self, other)\n\ny * x\n\n__rmod__(self, other)\n\n__floordiv__(self,\n\nx // y\n\n__truediv__(self,\n\nother)\n\nother)\n\n__ifloordiv__(self,\n\nx //= y\n\n__itruediv__(self,\n\nother)\n\nother)\n\n__rfloordiv__(self,\n\ny // x\n\n__rtruediv__(self,\n\nother)\n\nother)\n\n__divmod__(self,\n\ndivmod(x, y)\n\n__rdivmod__(self,\n\nother)\n\nother)\n\n__pow__(self, other)\n\nx ** y\n\n__and__(self, other)\n\n__ipow__(self, other)\n\nx **= y\n\n__iand__(self, other)\n\n__rpow__(self, other)\n\ny ** x\n\n__rand__(self, other)\n\n__xor__(self, other)\n\nx ^ y\n\n__or__(self, other)\n\n__ixor__(self, other)\n\nx ^= y\n\n__ior__(self, other)\n\n__rxor__(self, other)\n\ny ^ x\n\n__ror__(self, other)\n\n__lshift__(self,\n\nx << y\n\n__rshift__(self,\n\nother)\n\nother)\n\n__ilshift__(self,\n\nx <<= y\n\n__irshift__(self,\n\nother)\n\nother)\n\n__rlshift__(self,\n\ny << x\n\n__rrshift__(self,\n\nother)\n\nother)\n\n__invert__(self)\n\n253\n\nUsage\n\ncomplex(x)\n\nint(x)\n\nround(x,\n\ndigits)\n\nx\n\nx - y\n\nx -= y\n\ny - x\n\nx % y\n\nx %= y\n\ny % x\n\nx / y\n\nx /= y\n\ny / x\n\ndivmod(y, x)\n\nx & y\n\nx &= y\n\ny & x\n\nx | y\n\nx |= y\n\ny | x\n\nx >> y\n\nx >>= y\n\ny >> x\n\n~x\n\nFuzzy- Bool usage exam- ples 248➤\n\n254\n\nChapter 6. Object-Oriented Programming\n\nBy default, instances of custom classes support operator == (which always re- turns False), and are hashable (so can be dictionary keys and can be added to sets). But if we reimplement the __eq__() special method to provide proper equality testing,instancesare no longer hashable. Thiscan be ﬁxed by provid- ing a __hash__() special method as we have done here.\n\nPython provides hash functions for strings, numbers, frozen sets, and other classes. Here we have simply used the built-in hash() function (which can operate on any type which has a __hash__() special method), and given it the object’s unique ID from which to calculate the hash. (We can’t use the private self.__value since that can change as a result of augmented assignment, whereas an object’s hash value must never change.)\n\nThe built-in id() function returns a unique integer for the object it is given as its argument. This integer is usually the object’s address in memory, but all that we can assume is that no two objects have the same ID. Behind the scenes the is operator uses the id() function to determine whether two object references refer to the same object.\n\ndef __format__(self, format_spec):\n\nreturn format(self.__value, format_spec)\n\nThebuilt-in format() functionisonly really neededin classdeﬁnitions. It takes a single object and an optional format speciﬁcation and returns a string with the object suitably formatted.\n\nWhen an object is used in a format string the object’s __format__() method is called with the object and the format speciﬁcation as arguments. The method returns the instance suitably formatted as we saw earlier.\n\nAll the built-in classes already have suitable __format__() methods; here we make use of the float.__format__() method by passing the ﬂoating-point value and the format string we have been given. We could have achieved exactly the same thing like this:\n\ndef __format__(self, format_spec):\n\nreturn self.__value.__format__(format_spec)\n\nUsing the format() functionrequiresa tiny bitlesstyping andisclearertoread. Nothing forcesusto use the format() function at all,so we could invent our own format speciﬁcation language and interpret it inside the __format__() method, as long as we return a string.\n\n@staticmethod def conjunction(*fuzzies):\n\nreturn FuzzyBool(min([float(x) for x in fuzzies]))",
      "page_number": 238
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 248-262)",
      "start_page": 248,
      "end_page": 262,
      "detection_method": "topic_boundary",
      "content": "Custom Classes\n\nThe built-in staticmethod() function is designed to be used as a decorator as we have done here. Static methodsare simply methodsthat do not get self or any other ﬁrst argument specially passed by Python.\n\nThe & operator can be chained, so given FuzzyBool’s f, g, and h, we can get the conjunction of all of them by writing f & g & h. This works ﬁne for small num- bers of FuzzyBools, but if we have a dozen or more it starts to become rather inefﬁcient since each & represents a function call. With the method given here we can achieve the same thing using a single function call of Fuzzy- Bool.FuzzyBool.conjunction(f, g, h). This can be written more concisely us- ing a FuzzyBool instance, but since static methods don’t get self, if we call one using an instance and we want to process that instance we must pass it ourselves—for example, f.conjunction(f, g, h).\n\nWe have not shown the corresponding disjunction() method since it differs only in its name and that it uses max() rather than min().\n\nSomePythonprogrammersconsider theuseof staticmethodstobeun-Python- ic, and use them only if they are converting code from another language (such as C++ or Java), or if they have a method that does not use self. In Python, ratherthanusing staticmethodsitisusually bettertocreateamodulefunction instead, as we will see in the next subsubsection, or a class method, as we will see in the last section.\n\nIn a similar vein, creating a variable inside a class deﬁnition but outside any method creates a static (class) variable. For constants it is usually more convenient to use private module globals, but class variables can often be useful for sharing data among all of a class’s instances.\n\nWe have now completed the implementation of the FuzzyBool class “from scratch”. We have had to reimplement 15 methods (17 if we had done the minimum of all four comparison operators), and have implemented two static methods. In the following subsubsection we will show an alternative imple- mentation, this time based on the inheritance of float. It involves the reim- plementations of just eight methods and the implementation of two module functions—and the “unimplementation” of 32 methods.\n\nIn most object-oriented languages inheritance is used to create new classes that have all the methods and attributes of the classes they inherit, as well as the additional methods and attributes that we want the new class to have. Python fully supportsthis,allowing us to add new methods,or to reimplement inherited methods so as to modify their behavior. But in addition, Python allows us to effectively unimplement methods, that is, to make the new class behave as though it does not have some of the methods that it inherits. Doing this might not appeal to object-oriented purists since it breaks polymorphism, but in Python at least, it can occasionally be a useful technique.\n\n255\n\n256\n\nChapter 6. Object-Oriented Programming\n\nCreating Data Types from Other Data Types\n\nThe FuzzyBool implementation in this subsubsection is in the ﬁle Fuzzy- BoolAlt.py.One immediate difference from the previous version is that instead of providing static methods for conjunction() and disjunction(), we have pro- vided them as module functions. For example:\n\ndef conjunction(*fuzzies):\n\nreturn FuzzyBool(min(fuzzies))\n\nThe code for this is much simpler than before because FuzzyBoolAlt.FuzzyBool objects are float subclasses, and so can be used directly in place of a float without needing any conversion. (The inheritancetree isshown in Figure6.5.) Accessing the function is also cleaner than before. Instead of having to specify both the module and the class (or using an instance), having done import FuzzyBoolAlt we can just write FuzzyBoolAlt.conjunction().\n\nobject\n\nfloat\n\nFuzzyBool\n\n__new__() __init__() __eq__() __repr__() __str__() ...\n\nKey inherited implemented reimplemented\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() ...\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() __bool__() __invert__() __and__() __iand__() ...\n\nFigure 6.5 The alternativeFuzzyBool class’s inheritancehierarchy\n\nHere is the FuzzyBool’s class line and its __new__() method:\n\nclass FuzzyBool(float):\n\ndef __new__(cls, value=0.0):\n\nreturn super().__new__(cls,\n\nvalue if 0.0 <= value <= 1.0 else 0.0)\n\nWhen wecreatea newclassit isusually mutableandrelieson object.__new__() to create the raw uninitialized object. But in the case of immutable classes we need to do the creation and initialization in one step since once an immutable object has been created it cannot be changed.\n\n|\n\nCustom Classes\n\nThe __new__() method is called before any object has been created (since object creation is what __new__() does), so it cannot have a self object passed to it since one doesn’t yet exist. In fact, __new__() is a class method—these are similar to normal methods except that they are called on the class rather than on an instance and Python supplies as their ﬁrst argument the class they are called on. The variable name cls for classis just a convention,in the same way that self is the conventional name for the object itself.\n\nSo when we write f = FuzzyBool(0.7), under the hood Python calls Fuzzy- Bool.__new__(FuzzyBool, 0.7) to create a new object—say, fuzzy—and then calls fuzzy.__init__() to do any further initialization, and ﬁnally returns an object reference to the fuzzy object—it is this object reference that f is set to. Most of __new__()’s work is passed on to the base class implementation, ob- ject.__new__(); all we do is make sure that the value is in range.\n\nClass methods are set up by using the built-in classmethod() function used as a decorator. But as a convenience we don’t have to bother writing @classmethod before def __new__() because Python already knows that this method is always a classmethod. Wedo need to usethedecorator if we want to createother class methods, though, as we will see in the chapter’s ﬁnal section.\n\nNow that we have seen a class method we can clarify the different kinds of methods that Python provides. Class methods have their ﬁrst argument added by Python and it is the method’s class; normal methods have their ﬁrst argument addedby Python and it istheinstancethemethodwascalled on;and static methodshave no ﬁrst argument added. And all the kindsof methodsget any arguments we pass to them (as their second and subsequent arguments in the case of class and normal methods, and as their ﬁrst and subsequent arguments for static methods).\n\ndef __invert__(self):\n\nreturn FuzzyBool(1.0 - float(self))\n\nThis method is used to provide support for the bitwise NOT operator (~) just the same as before. Notice that instead of accessing a private attribute that holds the FuzzyBool’s value we use self directly. This is thanks to inher- iting float which means that a FuzzyBool can be used wherever a float is expected—providing none of the FuzzyBool’s “unimplemented” methods are used, of course.\n\ndef __and__(self, other):\n\nreturn FuzzyBool(min(self, other))\n\ndef __iand__(self, other):\n\nreturn FuzzyBool(min(self, other))\n\nThe logic for these is also the same as before (although the code is subtly different),and just like the __invert__() method we can use both self and other\n\n257\n\n258\n\nChapter 6. Object-Oriented Programming\n\ndirectly as though they were floats. We have omitted the OR versions since they differ only in their names(__or__() and __ior__()) and that they use max() rather than min().\n\ndef __repr__(self):\n\nreturn (\"{0}({1})\".format(self.__class__.__name__,\n\nsuper().__repr__()))\n\nWe must reimplement the __repr__() method since the base class version float.__repr__() justreturnsthenumberasa string,whereasweneedtheclass name to make the representation eval()-able. For the str.format()’ssecond ar- gument we cannot just pass self since that will result in an inﬁnite recursion of calls to this __repr__() method, so instead we call the base class implemen- tation.\n\nWe don’t have to reimplement the __str__() method because the base class version, float.__str__(), is sufﬁcient and will be used in the absence of a FuzzyBool.__str__() reimplementation.\n\ndef __bool__(self):\n\nreturn self > 0.5\n\ndef __int__(self):\n\nreturn round(self)\n\nWhen a float is used in a Boolean context it is False if its value is 0.0 and True otherwise. This is not the appropriate behavior for FuzzyBools, so we have had toreimplementthismethod. Similarly,using int(self) would simply truncate, turning everything but 1.0into 0,so herewe use round() to produce0for values up to 0.5 and 1 for values up to and including the maximum of 1.0.\n\nWe have not reimplemented the __hash__() method, the __format__() method, or any of the methods that are used to provide the comparison operators,since all those provided by the float base class work correctly for FuzzyBools.\n\nThe methods we have reimplemented provide a complete implementation of the FuzzyBool class—and have required far less code than the implementation presented in the previous subsubsection. However, this new FuzzyBool class has inherited more than 30 methods which don’t make sense for FuzzyBools. For example,none of the basic numeric and bitwise shift operators(+, -, *, /, <<, >>, etc.) can sensibly be applied to FuzzyBools. Here is how we could begin to “unimplement” addition:\n\ndef __add__(self, other):\n\nraise NotImplementedError()\n\nWe would also have to write the same code for the __iadd__() and __radd__() methods to completely prevent addition. (Note that NotImplementedError is a standardexceptionand isdifferentfromthebuilt-in NotImplemented object.) An\n\nCustom Classes\n\nalternative to raising a NotImplementedError exception, especially if we want to more closely mimic the behavior of Python’s built-in classes, is to raise a TypeError. Here is how we can make FuzzyBool.__add__() behave just like built-in classes that are faced with an invalid operation:\n\ndef __add__(self, other):\n\nraise TypeError(\"unsupported operand type(s) for +: \"\n\n\"'{0}' and '{1}'\".format(\n\nself.__class__.__name__, other.__class__.__name__))\n\nFor unary operations, we want to unimplement in a way that mimics the behavior of built-in types, the code is slightly easier:\n\ndef __neg__(self):\n\nraise TypeError(\"bad operand type for unary -: '{0}'\".format(\n\nself.__class__.__name__))\n\nFor comparison operators, there is a much simpler idiom. For example, to unimplement ==, we would write:\n\ndef __eq__(self, other):\n\nreturn NotImplemented\n\nIf a method implementing a comparison operator (<, <=, ==, !=, >=, >), returns the built-in NotImplemented object and an attempt is made to use the method, Python will ﬁrst try the reverse comparison by swapping the operands (in case the other object has a suitable comparison method since the self object does not), and if that doesn’t work Python raises a TypeError exception with a message that explains that the operation is not supported for operands of the types used. But for all noncomparison methods that we don’t want, we must raise either a NotImplementedError or a TypeError exception as we did for the __add__() and __neg__() methods shown earlier.\n\nIt would be tedious to unimplement every method we don’t want as we have done here, although it does work and has the virtue of being easy to under- stand. Here we will look at a more advanced technique for unimplementing methods—it is used in the FuzzyBoolAlt module—but it is probably best to skip to the next section (➤ 261) and return here only if the need arises in practice.\n\nHere is the code for unimplementing the two unary operations we don’t want:\n\nfor name, operator in ((\"__neg__\", \"-\"),\n\n(\"__index__\", \"index()\")):\n\nmessage = (\"bad operand type for unary {0}: '{{self}}'\"\n\n.format(operator))\n\nexec(\"def {0}(self): raise TypeError(\\\"{1}\\\".format(\"\n\n\"self=self.__class__.__name__))\".format(name, message))\n\n259\n\n260\n\nChapter 6. Object-Oriented Programming\n\nThebuilt-in exec() functiondynamically executesthecodepassedto it fromthe object it is given. In this case we have given it a string,but it is also possible to passsomeother kindsof objects. By default,thecodeisexecutedin thecontext of the enclosing scope, in this case within the deﬁnition of the FuzzyBool class, so the def statements that are executed create FuzzyBool methods which is what we want. The code is executed just once, when the FuzzyBoolAlt module is imported. Here is the code that is generated for the ﬁrst tuple (\"__neg__\", \"-\"):\n\ndef __neg__(self):\n\nraise TypeError(\"bad operand type for unary -: '{self}'\"\n\n.format(self=self.__class__.__name__))\n\nWe have made the exception and error message match those that Python uses for its own types. The code for handling binary methods and n-ary functions (suchaspow())followsa similarpatternbutwitha differenterrormessage. For completeness, here is the code we have used:\n\nfor name, operator in ((\"__xor__\", \"^\"), (\"__ixor__\", \"^=\"),\n\n(\"__add__\", \"+\"), (\"__iadd__\", \"+=\"), (\"__radd__\", \"+\"), (\"__sub__\", \"-\"), (\"__isub__\", \"-=\"), (\"__rsub__\", \"-\"), (\"__mul__\", \"*\"), (\"__imul__\", \"*=\"), (\"__rmul__\", \"*\"), (\"__pow__\", \"**\"), (\"__ipow__\", \"**=\"), (\"__rpow__\", \"**\"), (\"__floordiv__\", \"//\"), (\"__ifloordiv__\", \"//=\"), (\"__rfloordiv__\", \"//\"), (\"__truediv__\", \"/\"), (\"__itruediv__\", \"/=\"), (\"__rtruediv__\", \"/\"), (\"__divmod__\", \"divmod()\"), (\"__rdivmod__\", \"divmod()\"), (\"__mod__\", \"%\"), (\"__imod__\", \"%=\"), (\"__rmod__\", \"%\"), (\"__lshift__\", \"<<\"), (\"__ilshift__\", \"<<=\"), (\"__rlshift__\", \"<<\"), (\"__rshift__\", \">>\"), (\"__irshift__\", \">>=\"), (\"__rrshift__\", \">>\")):\n\nmessage = (\"unsupported operand type(s) for {0}: \"\n\n\"'{{self}}'{{join}} {{args}}\".format(operator))\n\nexec(\"def {0}(self, *args):\\n\"\n\n\" \"for arg in args]\\n\" \" \"self=self.__class__.__name__, \" \"join=(\\\" and\\\" if len(args) == 1 else \\\",\\\"),\" \"args=\\\", \\\".join(types)))\".format(name, message))\n\ntypes = [\\\"'\\\" + arg.__class__.__name__ + \\\"'\\\" \"\n\nraise TypeError(\\\"{1}\\\".format(\"\n\nThiscodeisslightly morecomplicatedthan beforebecausefor binary operators we must output messages where the two types are listed as type1 and type2, but for three or more types we must list them as type1, type2, type3 to mimic\n\nDynam- ic pro- gram- ming ➤ 349\n\nCustom Classes\n\nthe built-in behavior. Here is the code that is generated for the ﬁrst tuple (\"__xor__\", \"^\"):\n\ndef __xor__(self, *args):\n\ntypes = [\"'\" + arg.__class__.__name__ + \"'\" for arg in args] raise TypeError(\"unsupported operand type(s) for ^: \"\n\n\"'{self}'{join} {args}\".format( self=self.__class__.__name__, join=(\" and\" if len(args) == 1 else \",\"), args=\", \".join(types)))\n\nThe two for … in loop blocks we have used here can be simply cut and pasted, and then we can add or remove unary operators and methods from the ﬁrst one and binary or n-ary operators and methods from the second one to unim- plement whatever methods are not required.\n\nWith this last piece of code in place,if we had two FuzzyBools, f and g,and tried to add them using f + g, we would get a TypeError exception with the message “unsupported operand type(s) for +: 'FuzzyBool' and 'FuzzyBool'”, which is exactly the behavior we want.\n\nCreating classes the way we did for the ﬁrst FuzzyBool implementation is much more common and is sufﬁcient for almost every purpose. However, if we need to create an immutable class, the way to do it is to reimplement ob- ject.__new__() having inherited one of Python’s immutable types such as float, int, str, or tuple, and then implement all the other methods we need. The disadvantage of doing this is that we may need to unimplement some methods—thisbreakspolymorphism,so in most casesusing aggregation aswe did in the ﬁrst FuzzyBool implementation is a much better approach.\n\nCustom Collection Classes\n\nIn this section’ssubsectionswe will look at custom classesthat are responsible for largeamountsof data. The ﬁrst classwe will review,Image,isone that holds imagedata. Thisclassistypicalof many data-holding customclassesin that it not only providesin-memory accessto itsdata,but also hasmethodsfor saving and loading the data to and from disk. The second and third classes we will study, SortedList and SortedDict, are designed to ﬁll a rare and surprising gap in Python’s standard library for intrinsically sorted collection data types.\n\nCreating Classes That Aggregate Collections\n\nA simple way of representing a 2D color image is as a two-dimensional array with each array element being a color. So to represent a 100 × 100 image we must store 10000 colors. For the Image class (in ﬁle Image.py), we will take a\n\n261\n\n|||\n\n||\n\n262\n\nChapter 6. Object-Oriented Programming\n\npotentially more efﬁcient approach. An Image stores a single background color, plus the colors of those points in the image that differ from the background color. Thisisdoneby using a dictionaryasa kindof sparsearray,witheachkey being an (x, y) coordinate and the corresponding value being the color of that point. If we had a 100× 100image and half itspointsarethebackgroundcolor, we would need to store only 5000 + 1 colors, a considerable saving in memory.\n\nThe Image.py module follows what should now be a familiar pattern: It starts with a shebang line, then copyright information in comments, then a module docstring with some doctests, and then the imports, in this case of the os and pickle modules. We will brieﬂy cover the use of the pickle module when we cover saving and loading images. After the imports we create some custom exception classes:\n\nclass ImageError(Exception): pass class CoordinateError(ImageError): pass\n\nWe have shown only the ﬁrst two exception classes; the others (LoadError, SaveError, ExportError, and NoFilenameError) are all created the same way and all inherit from ImageError. Users of the Image class can choose to test for any of the speciﬁc exceptions, or just for the base class ImageError exception.\n\nThe rest of the module consists of the Image class and at the end the standard three lines for running the module’s doctests. Before looking at the class and its methods, let’s look at how it can be used:\n\nborder_color = \"#FF0000\" square_color = \"#0000FF\" width, height = 240, 60 midx, midy = width // 2, height // 2 image = Image.Image(width, height, \"square_eye.img\") for x in range(width):\n\n# red # blue\n\nfor y in range(height):\n\nif x < 5 or x >= width - 5 or y < 5 or y >= height - 5:\n\nimage[x, y] = border_color\n\nelif midx - 20 < x < midx + 20 and midy - 20 < y < midy + 20:\n\nimage[x, y] = square_color\n\nimage.save() image.export(\"square_eye.xpm\")\n\nNotice that we can use the item access operator ([]) for setting colors in the image. Brackets can also be used for getting or deleting (effectively setting to thebackgroundcolor)thecolorata particular(x,y)coordinate. Thecoordinates are passed as a single tuple object (thanksto the comma operator),the same as if we wrote image[(x, y)]. Achieving this kind of seamless syntax integration iseasy in Python—wejust have to implement theappropriatespecialmethods,\n\nPickles ➤ 292\n\nCustom Collection Classes\n\nwhich in the case of the item access operator are __getitem__(), __setitem__(), and __delitem__().\n\nThe Image class uses HTML-style hexadecimal strings to represent colors. The background color must be set when the image is created;otherwise,it defaults to white. The Image class saves and loads images in its own custom format, but it can also export in the .xpm format which is understood by many image processing applications. The .xpm imageproducedby thecodesnippet isshown in Figure 6.6.\n\nFigure 6.6 The square_eye.xpm image\n\nWe will now review the Image class’s methods, starting with the class line and the initializer:\n\nclass Image:\n\ndef __init__(self, width, height, filename=\"\",\n\nbackground=\"#FFFFFF\"):\n\nself.filename = filename self.__background = background self.__data = {} self.__width = width self.__height = height self.__colors = {self.__background}\n\nWhen an Image is created, the user (i.e., the class’s user) must provide a width and height, but the ﬁlename and background color are optional since defaults areprovided. Theself.__data dictionary’skeysare(x,y)coordinatesanditsval- ues are color strings. The self.__colors set is initialized with the background color; it is used to keep track of the unique colors used by the image.\n\nAll the data attributes are private except for the ﬁlename, so we must provide a means by which users of the class can access them. This is easily done using properties.★\n\n@property def background(self):\n\nreturn self.__background\n\n★In Chapter 8 we will see a completely different approach to providing attribute access, using special methods such as __getattr__() and __setattr__(), that is useful in some circumstances.\n\n263\n\nCopying collec- tions 146➤\n\n264\n\nChapter 6. Object-Oriented Programming\n\n@property def width(self):\n\nreturn self.__width\n\n@property def height(self):\n\nreturn self.__height\n\n@property def colors(self):\n\nreturn set(self.__colors)\n\nWhenreturning a data attributefromanobjectweneedtobeawareof whether theattributeisof an immutableor mutabletype. It isalwayssafetoreturnim- mutable attributes since they can’t be changed, but for mutable attributes we must consider some trade-offs. Returning a reference to a mutable attribute is very fast and efﬁcient because no copying takes place—but it also means that the caller now has access to the object’s internal state and might change it in a way that invalidates the object. One policy to consider is to always return a copy of mutable data attributes, unless proﬁling shows a signiﬁcant negative effect on performance. (In thiscase,an alternativeto keeping theset of unique colors would be to return set(self.__data.values()) | {self.__background} whenever the set of colors was needed; we will return to this theme shortly.)\n\ndef __getitem__(self, coordinate):\n\nassert len(coordinate) == 2, \"coordinate should be a 2-tuple\" if (not (0 <= coordinate[0] < self.width) or not (0 <= coordinate[1] < self.height)): raise CoordinateError(str(coordinate))\n\nreturn self.__data.get(tuple(coordinate), self.__background)\n\nThis method returns the color for a given coordinate using the item access operator ([]).The special methodsfor the item accessoperatorsand some other collection-relevant special methods are listed in Table 6.4.\n\nWe have chosen to apply two policies for item access. The ﬁrst policy is that a precondition for using an item accessmethod is that the coordinate it ispassed is a sequence of length 2 (usually a 2-tuple),and we use an assertion to ensure this. The second policy is that any coordinatevaluesare accepted,but if either is out of range, we raise a custom exception.\n\nWe have used the dict.get() method with a default value of the background color toretrievethecolorfor thegivencoordinate. Thisensuresthatif thecolor hasnever beenset for thecoordinatethebackgroundcolor iscorrectlyreturned instead of a KeyError exception being raised.\n\nCustom Collection Classes\n\nTable 6.4 Collection Special Methods\n\nSpecial Method\n\nUsage\n\nDescription\n\n__contains__(self, x)\n\nx in y\n\nReturns True if x is in sequence y or if x is a key in mapping y\n\n__delitem__(self, k)\n\ndel y[k]\n\nDeletes the k-th item of sequence y or the item with key k in mapping y\n\n__getitem__(self, k)\n\ny[k]\n\nReturnsthe k-th item of sequence y or the value for key k in mapping y\n\n__iter__(self)\n\nfor x in y: pass\n\nReturns an iterator for sequence y’s items or mapping y’s keys\n\n__len__(self)\n\nlen(y)\n\nReturns the number of items in y\n\n__reversed__(self)\n\nreversed(y) Returns a backward iterator for se- quence y’s items or mapping y’s keys\n\n__setitem__(self, k, v) y[k] = v\n\nSetsthe k-th item of sequence y or the value for key k in mapping y, to v\n\ndef __setitem__(self, coordinate, color):\n\nassert len(coordinate) == 2, \"coordinate should be a 2-tuple\" if (not (0 <= coordinate[0] < self.width) or not (0 <= coordinate[1] < self.height)): raise CoordinateError(str(coordinate))\n\nif color == self.__background:\n\nself.__data.pop(tuple(coordinate), None)\n\nelse:\n\nself.__data[tuple(coordinate)] = color self.__colors.add(color)\n\nIf the user sets a coordinate’s value to the background color we can simply delete the corresponding dictionary item since any coordinate not in the dic- tionary is assumed to have the background color. We must use dict.pop() and give a dummy second argument rather than use del because doing so avoids a KeyError being raised if the key (coordinate) is not in the dictionary.\n\nIf the color is different from the background color, we set it for the given coordinate and add it to the set of the unique colors used by the image.\n\ndef __delitem__(self, coordinate):\n\nassert len(coordinate) == 2, \"coordinate should be a 2-tuple\" if (not (0 <= coordinate[0] < self.width) or not (0 <= coordinate[1] < self.height)): raise CoordinateError(str(coordinate))\n\nself.__data.pop(tuple(coordinate), None)\n\n265\n\n266\n\nChapter 6. Object-Oriented Programming\n\nIf a coordinate’s color is deleted the effect is to make that coordinate’s color the background color. Again we use dict.pop() to remove the item since it will work correctly whether or not an item with the given coordinate is in the dictionary.\n\nBoth __setitem__() and __delitem__() have the potential to make the set of colors contain more colors than the image actually uses. For example, if a unique nonbackground color is deleted at a certain pixel, the color remains in the color set even though it is no longer used. Similarly,if a pixel has a unique nonbackground color and is set to the background color, the unique color is no longer used, but remains in the color set. This means that, at worst, the color set could contain more colors than are actually used by the image (but never less).\n\nWe have chosen to accept the trade-off of potentially having more colors in the color set than are actually used for the sake of better performance, that is, to make setting and deleting a color as fast as possible—especially since storing a few more colors isn’t usually a problem. Of course, if we wanted to ensure that the set of colors was in sync we could either create an additional method that could be called whenever we wanted, or accept the overhead and do the computationautomatically when it wasneeded. In either case,thecodeisvery simple (and is used when a new image is loaded):\n\nself.__colors = (set(self.__data.values()) |\n\n{self.__background})\n\nThis simply overwrites the set of colors with the set of colors actually used in the image unioned with the background color.\n\nWe have not provided a __len__() implementation since it does not make sense for a two-dimensional object. Also, we cannot provide a representational form since an Image cannot be created fully formed just by calling Image(), so we do not provide __repr__() (or __str__()) implementations either. If a user calls repr() or str() on an Image object, the object.__repr__() base class imple- mentation will return a suitable string, for example, '<Image.Image object at 0x9c794ac>'. This is a standard format used for non-eval()-able objects. The hexadecimal number is the object’s ID—this is unique (normally it is the ob- ject’s address in memory), but transient.\n\nWe want users of the Image class to be able to save and load their image data, so we have provided two methods, save() and load(), to carry out these tasks.\n\nWe have chosen to save the data by pickling it. In Python-speak pickling is a way of serializing (converting into a sequence of bytes, or into a string) a Python object. What is so powerful about pickling is that the pickled object can be a collection data type, such as a list or a dictionary, and even if the pickled object has other objects inside it (including other collections, which\n\n268\n\nChapter 6. Object-Oriented Programming\n\nwe had to open the ﬁle in binary mode. When reading pickles no protocol is speciﬁed—the pickle.load() function is smart enough to work out the protocol for itself.\n\ndef load(self, filename=None):\n\nif filename is not None:\n\nself.filename = filename\n\nif not self.filename:\n\nraise NoFilenameError()\n\nfh = None try:\n\nfh = open(self.filename, \"rb\") data = pickle.load(fh) (self.__width, self.__height, self.__background,\n\nself.__data) = data\n\nself.__colors = (set(self.__data.values()) |\n\n{self.__background})\n\nexcept (EnvironmentError, pickle.UnpicklingError) as err:\n\nraise LoadError(str(err))\n\nfinally:\n\nif fh is not None: fh.close()\n\nThis function starts off the same as the save() function to get the ﬁlename of the ﬁle to load. The ﬁle must be opened in read binary mode, and the data is read using the single statement, data = pickle.load(fh). The data object is an exact reconstruction of the one we saved, so in this case it is a list with the width and height integers, the background color string, and the dictionary of coordinate–color items. We use tuple unpacking to assign each of the data list’s items to the appropriate variable, so any previously held image data is (correctly) lost.\n\nThe set of unique colorsisreconstructedby making a set of all the colorsin the coordinate–color dictionary and then adding the background color.\n\ndef export(self, filename):\n\nif filename.lower().endswith(\".xpm\"):\n\nself.__export_xpm(filename)\n\nelse:\n\nraise ExportError(\"unsupported export format: \" + os.path.splitext(filename)[1])\n\nWe have provided one generic export method that uses the ﬁle extension to determine which private method to call—or raisesan exception for ﬁle formats that cannot be exported. In this case we only support saving to .xpm ﬁles (and then only for images with fewer than 8930 colors). We haven’t quoted the\n\nCustom Collection Classes\n\n__export_xpm() method because it isn’t really relevant to this chapter’s theme, but it is in the book’s source code, of course.\n\nWe have now completed our coverage of the custom Image class. This class is typical of those used to hold program-speciﬁc data, providing access to the data items it contains, the ability to save and load all its data to and from disk, and with only the essential methods it needs provided. In the next two subsections we will see how to create two generic custom collection types that offer complete APIs.\n\nCreating Collection Classes Using Aggregation\n\nIn thissubsection we will develop a completecustom collection data type,Sort- edList, that holds a list of items in sorted order. The items are sorted using their less than operator (<), provided by the __lt__() special method, or by us- ing a key function if one is given. The class tries to match the API of the built- in list class to make it as easy to learn and use as possible, but some methods cannot sensibly beprovided—forexample,using theconcatenationoperator (+) could result in items being out of order, so we do not implement it.\n\nAs always when creating custom classes, we are faced with the choices of inheriting a classthat issimilar to the one we want to make,or creating a class from scratch and aggregating instances of any other classes we need inside it, or doing a mixtureof both. For thissubsection’sSortedList we use aggregation (and implicitly inherit object, of course), and for the following subsection’s SortedDict we will use both aggregation and inheritance (inheriting dict).\n\nIn Chapter 8 we will see that classes can make promises about the API they offer. For example, a list provides the MutableSequence API which means that it supportsthe in operator,the iter() and len() built-in functions,and the item access operator ([]) for getting, setting, and deleting items, and an insert() method. The SortedList class implemented here does not support item setting and does not have an insert() method, so it does not provide a MutableSequence API. If we were to create SortedList by inheriting list, the resultant class would claim to be a mutable sequence but would not have the complete API. In view of this the SortedList does not inherit list and so makes no promises about its API. On the other hand, the next subsection’s SortedDict class sup- ports the complete MutableMapping API that the dict class provides, so we can make it a dict subclass.\n\nHere are some basic examples of using a SortedList:\n\nletters = SortedList.SortedList((\"H\", \"c\", \"B\", \"G\", \"e\"), str.lower) # str(letters) == \"['B', 'c', 'e', 'G', 'H']\" letters.add(\"G\") letters.add(\"f\") letters.add(\"A\")\n\n269\n\n||\n\nLambda func- tions 182➤\n\n270\n\nChapter 6. Object-Oriented Programming\n\n# str(letters) == \"['A', 'B', 'c', 'e', 'f', 'G', 'G', 'H']\" letters[2] # returns: 'c'\n\nA SortedList object aggregates (is composed of) two private attributes; a func- tion, self.__key() (held as object reference self.__key), and a list, self.__list.\n\nThe key function is passed as the second argument (or using the key keyword speciﬁed the argument if no initial sequence is given). If no key function is following private module function is used:\n\n_identity = lambda x: x\n\nThis is the identity function: It simply returns its argument unchanged, so when it isused asa SortedList’skey functionit meansthat thesort key for each object in the list is the object itself.\n\nThe SortedList type does not allow the item access operator ([]) to change an item (so it does not implement the __setitem__() special method), nor does it provide the append() or extend() method since these might invalidate the ordering. The only way to add items is to pass a sequence when the SortedList iscreatedor toaddthemlater using the SortedList.add() method. Ontheother hand, we can safely use the item access operator for getting or deleting the item at a given index position since neither operation affects the ordering, so both the __getitem__() and __delitem__() special methods are implemented.\n\nWe will now review the class method by method, starting as usual with the class line and the initializer:\n\nclass SortedList:\n\ndef __init__(self, sequence=None, key=None):\n\nself.__key = key or _identity assert hasattr(self.__key, \"__call__\") if sequence is None: self.__list = []\n\nelif (isinstance(sequence, SortedList) and\n\nsequence.key == self.__key): self.__list = sequence.__list[:]\n\nelse:\n\nself.__list = sorted(list(sequence), key=self.__key)\n\nSince a function’s name is an object reference (to its function), we can hold functions in variables just like any other object reference. Here the private self.__key variable holds a reference to the key function that was passed in, or totheidentity function. Themethod’sﬁrststatementrelieson thefact that the or operator returns its ﬁrst operand if it is True in a Boolean context (which a not-None key function is),or itssecond operand otherwise. A slightly longer but",
      "page_number": 248
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 263-277)",
      "start_page": 263,
      "end_page": 277,
      "detection_method": "topic_boundary",
      "content": "Custom Collection Classes\n\nmore obvious alternative would have been self.__key = key if key is not None else _identity.\n\nOnce we have the key function, we use an assert to ensure that it is callable. The built-in hasattr() function returns True if the object passed as its ﬁrst ar- gument hasthe attributewhose name is passed as itssecond argument. There are corresponding setattr() and delattr() functions—these functions are cov- ered in Chapter 8. All callable objects, for example, functions and methods, have a __call__ attribute.\n\nTo make the creation of SortedLists as similar as possible to the creation of lists we have an optional sequence argument that corresponds to the single optional argument that list() accepts. The SortedList class aggregates a list collection in the private variable self.__list and keeps the items in the aggregated list in sorted order using the given key function.\n\nThe elif clause uses type testing to see whether the given sequence is a Sort- edList and if that is the case whether it has the same key function as this sort- ed list. If these conditions are met we simply shallow-copy the sequence’s list without needing to sort it. If most key functions are created on the ﬂy using lambda, even though two may have the same code they will not compare as equal, so the efﬁciency gain may not be realized in practice.\n\n@property def key(self):\n\nreturn self.__key\n\nOnce a sorted list is created its key function is ﬁxed, so we keep it as a private variable to prevent users from changing it. But some users may want to get a reference to the key function (as we will see in the next subsection), and so we have made it accessible by providing the read-only key property.\n\ndef add(self, value):\n\nindex = self.__bisect_left(value) if index == len(self.__list): self.__list.append(value)\n\nelse:\n\nself.__list.insert(index, value)\n\nWhen this method is called the given value must be inserted into the private self.__list in the correct position to preserve the list’s order. The private SortedList.__bisect_left() method returns the required index position as we will see in a moment. If the new value islarger than any other value in the list it must go at the end,so the index position will be equal to the list’s length (list index positions go from 0 to len(L) - 1)—if this is the case we append the new value. Otherwise, we insert the new value at the given index position—which will be at index position 0 if the new value is smaller than any other value in the list.\n\n271\n\n272\n\nChapter 6. Object-Oriented Programming\n\ndef __bisect_left(self, value): key = self.__key(value) left, right = 0, len(self.__list) while left < right:\n\nmiddle = (left + right) // 2 if self.__key(self.__list[middle]) < key:\n\nleft = middle + 1\n\nelse:\n\nright = middle\n\nreturn left\n\nThis private method calculates the index position where the given value be- longsin the list,that is,the index position where the value is(if it isin the list), or where it should go (if it isn’t in the list). It computes the comparison key for the given value using the sorted list’s key function, and compares the com- parison key with the computed comparison keys of the items that the method examines. The algorithm used is binarysearch(also called binarychop),which has excellent performance even on very large lists—for example, at most, 21 comparisons are required to ﬁnd a value’s position in a list of 1000000 items.★ Comparethiswith a plain unsorted list which useslinear search and needsan average of 500000 comparisons, and at worst 1000000 comparisons, to ﬁnd a value in a list of 1000000 items.\n\ndef remove(self, value):\n\nindex = self.__bisect_left(value) if index < len(self.__list) and self.__list[index] == value:\n\ndel self.__list[index]\n\nelse:\n\nraise ValueError(\"{0}.remove(x): x not in list\".format(\n\nself.__class__.__name__))\n\nThis method is used to remove the ﬁrst occurrence of the given value. It uses the SortedList.__bisect_left() method to ﬁnd the index position where the value belongs and then tests to see whether that index position is within the list and that the item at that position is the same as the given value. If the conditions are met the item is removed; otherwise, a ValueError exception is raised (which is what list.remove() does in the same circumstances).\n\ndef remove_every(self, value):\n\ncount = 0 index = self.__bisect_left(value) while (index < len(self.__list) and\n\nself.__list[index] == value):\n\n★Python’s bisect module provides the bisect.bisect_left() function and some others, but at the time of this writing none of the bisect module’s functions can work with a key function.\n\nCustom Collection Classes\n\ndel self.__list[index] count += 1\n\nreturn count\n\nThis method is similar to the SortedList.remove() method, and is an extension of the list API. It starts off by ﬁnding the index position where the ﬁrst occurrence of the value belongs in the list, and then loops as long as the index position is within the list and the item at the index position is the same as the given value. The code is slightly subtle since at each iteration the matching item is deleted,and as a consequence,after each deletion the item at the index position is the item that followed the deleted item.\n\ndef count(self, value):\n\ncount = 0 index = self.__bisect_left(value) while (index < len(self.__list) and\n\nself.__list[index] == value):\n\nindex += 1 count += 1\n\nreturn count\n\nThis method returns the number of times the given value occurs in the list (which could be 0). It uses a very similar algorithm to SortedList.remove_ every(), only here we must increment the index position in each iteration.\n\ndef index(self, value):\n\nindex = self.__bisect_left(value) if index < len(self.__list) and self.__list[index] == value:\n\nreturn index\n\nraise ValueError(\"{0}.index(x): x not in list\".format(\n\nself.__class__.__name__))\n\nSincea SortedList isorderedwecan usea fast binary searchtoﬁnd (or not ﬁnd) the value in the list.\n\ndef __delitem__(self, index): del self.__list[index]\n\nThe __delitem__() special method provides support for the del L[n] syntax, where L is a sorted list and n is an integer index position. We don’t test for an out-of-range index since if one is given the self.__list[index] call will raise an IndexError exception, which is the behavior we want.\n\ndef __getitem__(self, index): return self.__list[index]\n\nThis method provides support for the x =L [n] syntax, where L is a sorted list and n is an integer index position.\n\n273\n\n274\n\nChapter 6. Object-Oriented Programming\n\ndef __setitem__(self, index, value):\n\nraise TypeError(\"use add() to insert a value and rely on \"\n\n\"the list to put it in the right place\")\n\nWe don’t want the user to change an item at a given index position (so L[n] = x is disallowed); otherwise, the sorted list’s order might be invalidated. The TypeError exceptionistheoneused tosignify that an operationisnot supported by a particular data type.\n\ndef __iter__(self):\n\nreturn iter(self.__list)\n\nThis method is easy to implement since we can just return an iterator to the private list using the built-in iter() function. This method is used to support the for value in iterable syntax.\n\nNote that if a sequence is required it is this method that is used. So to convert a SortedList, L, to a plain list we can call list(L), and behind the scenes Python will call SortedList.__iter__(L) to provide the sequence that the list() function requires.\n\ndef __reversed__(self):\n\nreturn reversed(self.__list)\n\nThis provides support for the built-in reversed() function so that we can write, for example, for value in reversed(iterable).\n\ndef __contains__(self, value):\n\nindex = self.__bisect_left(value) return (index < len(self.__list) and self.__list[index] == value)\n\nThe __contains__() method providessupport for the in operator.Once again we are able to use a fast binary search rather than the slow linear search used by a plain list.\n\ndef clear(self):\n\nself.__list = []\n\ndef pop(self, index=-1):\n\nreturn self.__list.pop(index)\n\ndef __len__(self):\n\nreturn len(self.__list)\n\ndef __str__(self):\n\nreturn str(self.__list)\n\nCustom Collection Classes\n\nThe SortedList.clear() method discardsthe existing list and replacesit with a new empty list. The SortedList.pop() method removes and returnsthe item at the given index position,or raises an IndexError exception if the index is out of range. For the pop(), __len__(), and __str__() methods, we simply pass on the work to the aggregated self.__list object.\n\nWe do not reimplement the __repr__() special method, so the base class ob- ject.__repr__() will be called when the user writes repr(L) and L is a Sort- edList. This will produce a string such as '<SortedList.SortedList object at 0x97e7cec>', although the hexadecimal ID will vary, of course. We cannot provide a sensible __repr__() implementation because we would need to give the key function and we cannot represent a function object reference as an eval()-able string.\n\nWe have not implemented the insert(), reverse(), or sort() method because none of them is appropriate. If any of them are called an AttributeError exception will be raised.\n\nIf we copy a sorted list using the L[:] idiom we will get a plain list object, rather than a SortedList. The easiest way to get a copy is to import the copy moduleand usethe copy.copy() function—thisissmartenough tocopy a sorted list (and instances of most other custom classes) without any help. However, we have decided to provide an explicit copy() method:\n\ndef copy(self):\n\nreturn SortedList(self, self.__key)\n\nBy passing self as the ﬁrst argument we ensure that self.__list is simply shallow-copied rather than being copied and re-sorted. (This is thanks to the __init__() method’s type-testing elif clause.) The theoretical performance advantage of copying this way is not available to the copy.copy() function, but we can easily make it available by adding this line:\n\n__copy__ = copy\n\nWhen copy.copy() is called it triesto use the object’s __copy__() special method, falling back to its own code if one isn’t provided. With this line in place copy.copy() will now use the SortedList.copy() method for sorted lists. (It is also possible to provide a __deepcopy__() special method, but this is slightly more involved—the copy module’s online documentation has the details.)\n\nWe have now completed the implementation of the SortedList class. In the next subsection we will make use of a SortedList to providea sorted list of keys for the SortedDict class.\n\n275\n\ncollec- tions. Ordered- Dict 136➤\n\n276\n\nChapter 6. Object-Oriented Programming\n\nCreating Collection Classes Using Inheritance\n\nThe SortedDict class shown in this subsection attempts to mimic a dict as closely as possible. The major difference is that a SortedDict’s keys are always ordered based on a speciﬁed key function or on the identity function. Sorted- Dict providesthesameAPIas dict (except for having a non-eval()-able repr()), plus two extra methods that make sense only for an ordered collection.★ (Note that Python 3.1 introduced the collections.OrderedDict class—this class is dif- ferent from SortedDict since it is insertion-ordered rather than key-ordered.)\n\nHere are a few examples of use to give a ﬂavor of how SortedDict works:\n\nd = SortedDict.SortedDict(dict(s=1, A=2, y=6), str.lower) d[\"z\"] = 4 d[\"T\"] = 5 del d[\"y\"] d[\"n\"] = 3 d[\"A\"] = 17 str(d) # returns: \"{'A': 17, 'n': 3, 's': 1, 'T': 5, 'z': 4}\"\n\nThe SortedDict implementation uses both aggregation and inheritance. The sortedlistof keysisaggregatedasaninstancevariable,whereastheSortedDict class itself inherits the dict class. We will start our code review by looking at the class line and the initializer,and then we will look at all of the other meth- ods in turn.\n\nclass SortedDict(dict):\n\ndef __init__(self, dictionary=None, key=None, **kwargs):\n\ndictionary = dictionary or {} super().__init__(dictionary) if kwargs:\n\nsuper().update(kwargs)\n\nself.__keys = SortedList.SortedList(super().keys(), key)\n\nThe dict base class is speciﬁed in the class line. The initializer tries to mimic the dict() function, but adds a second argument for the key function. The super().__init__() call is used to initialize the SortedDict using the base class dict.__init__() method. Similarly, if keyword arguments have been used, we use the base class dict.update() method to add them to the dictionary. (Note that only one occurrence of any keyword argument is accepted, so none of the keys in the kwargs keyword arguments can be “dictionary” or “key”.)\n\n★The SortedDict class presented here is different from the one in Rapid GUI Programming with Python and Qt by this author, ISBN 0132354187,and from the one in the Python Package Index.\n\n||\n\nCustom Collection Classes\n\nWe keep a copy of all the dictionary’s keys in a sorted list stored in the self.__keys variable. We pass the dictionary’s keys to initialize the sorted list using the base class’s dict.keys() method—we must not use SortedDict.keys() because that relies on the self.__keys variable which will exist only after the SortedList of keys has been created.\n\ndef update(self, dictionary=None, **kwargs):\n\nif dictionary is None:\n\npass\n\nelif isinstance(dictionary, dict): super().update(dictionary)\n\nelse:\n\nfor key, value in dictionary.items():\n\nsuper().__setitem__(key, value)\n\nif kwargs:\n\nsuper().update(kwargs)\n\nself.__keys = SortedList.SortedList(super().keys(),\n\nself.__keys.key)\n\nThis method is used to update one dictionary’s items with another dictionary’s items, or with keyword arguments, or both. Items which exist only in the other dictionary are added to thisone,and for itemswhose keysappear in both dictionaries, the other dictionary’s value replaces the original value. We have had toextendthebehavior slightly in thatwekeeptheoriginaldictionary’skey function, even if the other dictionary is a SortedDict.\n\nThe updating is done in two phases. First we update the dictionary’sitems. If the given dictionary is a dict subclass (which includes SortedDict, of course), we use the base class dict.update() to perform the update—using the base class version is essential to avoid calling SortedDict.update() recursively and going into an inﬁnite loop. If the dictionary is not a dict we iterate over the dictionary’s items and set each key–value pair individually. (If the dictionary object is not a dict and does not have an items() method an AttributeError exception will quite rightly be raised.) If keyword arguments have been used we again call the base class update() method to incorporate them.\n\nA consequence of the updating is that the self.__keys list becomes out of date, so we replace it with a new SortedList with the dictionary’s keys (again obtained from the base class, since the SortedDict.keys() method relies on the self.__keys list which we are in the process of updating),and with the original sorted list’s key function.\n\n@classmethod def fromkeys(cls, iterable, value=None, key=None):\n\nreturn cls({k: value for k in iterable}, key)\n\n277\n\n278\n\nChapter 6. Object-Oriented Programming\n\nThe dict API includes the dict.fromkeys() class method. This method is used to create a new dictionary based on an iterable. Each element in the iterable becomes a key, and each key’s value is either None or the speciﬁed value.\n\nBecause this is a class method the ﬁrst argument is provided automatically by Python and is the class. For a dict the class will be dict,and for a SortedDict it is SortedDict. The return value is a dictionary of the given class. For example:\n\nclass MyDict(SortedDict.SortedDict): pass d = MyDict.fromkeys(\"VEINS\", 3) str(d) d.__class__.__name__\n\n# returns: \"{'E': 3, 'I': 3, 'N': 3, 'S': 3, 'V': 3}\"\n\n# returns: 'MyDict'\n\nSo when inherited class methods are called, their cls variable is set to the correct class, just like when normal methods are called and their self variable is set to the current object. This is different from and better than using a static method because a static method is tied to a particular class and does not know whether it is being executed in the context of its original class or that of a subclass.\n\ndef __setitem__(self, key, value):\n\nif key not in self:\n\nself.__keys.add(key)\n\nreturn super().__setitem__(key, value)\n\nThis method implements the d[key] = value syntax. If the key isn’t in the dictionary we add it to the list of keys,relying on the SortedList to put it in the right place. Then we call the base class method, and return its result to the caller to support chaining, for example, x = d[key] = value.\n\nNotice that in the if statement we check to see whether the key already exists in the SortedDict by using not in self. Because SortedDict inherits dict, a SortedDict can be used wherever a dict is expected, and in this case self is a SortedDict. When we reimplement dict methods in SortedDict, if we need to call the base class implementation to get it to do some of the work for us, we must be careful to call the method using super(), as we do in this method’s last statement;doing so preventsthe reimplementation of the method from calling itself and going into inﬁnite recursion.\n\nWe do not reimplement the __getitem__() method since the base class version works ﬁne and has no effect on the ordering of the keys.\n\ndef __delitem__(self, key):\n\ntry:\n\nself.__keys.remove(key)\n\nexcept ValueError:\n\nraise KeyError(key)\n\nreturn super().__delitem__(key)\n\nCustom Collection Classes\n\nGenerator Functions\n\nA generator function or generator method is one which contains a yield ex- pression. When a generator function is called it returns an iterator. Values areextractedfromtheiteratoroneat a timeby calling its__next__() method. At each call to __next__() the generator function’s yield expression’s value (None if none is speciﬁed) is returned. If the generator function ﬁnishes or executes a return a StopIteration exception is raised.\n\nIn practice we rarely call __next__() or catch a StopIteration. Instead, we just use a generator like any other iterable. Here are two almost equivalent functions. The one on the left returns a list and the one on the right returns a generator.\n\n# Build and return a list def letter_range(a, z):\n\nresult = [] while ord(a) < ord(z):\n\n# Return each value on demand def letter_range(a, z):\n\nresult.append(a) a = chr(ord(a) + 1)\n\nreturn result\n\nwhile ord(a) < ord(z):\n\nyield a a = chr(ord(a) + 1)\n\nWe can iterate over the result produced by either function using a for loop, for example, for letter in letter_range(\"m\", \"v\"):. But if we want a list of the resultant letters,although calling letter_range(\"m\", \"v\") issufﬁcient for the left-hand function, for the right-hand generator function we must use list(letter_range(\"m\", \"v\")).\n\nGenerator functions and methods (and generator expressions) are covered more fully in Chapter 8.\n\nThis method provides the del d[key] syntax. If the key is not present the Sort- edList.remove() call will raise a ValueError exception. If this occurs we catch the exception and raise a KeyError exception instead so as to match the dict class’sAPI.Otherwise,we return the result of calling the base classimplemen- tation to delete the item with the given key from the dictionary itself.\n\ndef setdefault(self, key, value=None):\n\nif key not in self:\n\nself.__keys.add(key)\n\nreturn super().setdefault(key, value)\n\nThis method returns the value for the given key if the key is in the dictionary; otherwise, it creates a new item with the given key and value and returns the value. For the SortedDict we must make sure that the key is added to the keys list if the key is not already in the dictionary.\n\n279\n\n280\n\nChapter 6. Object-Oriented Programming\n\ndef pop(self, key, *args): if key not in self:\n\nif len(args) == 0:\n\nraise KeyError(key)\n\nreturn args[0] self.__keys.remove(key) return super().pop(key, args)\n\nIf the given key is in the dictionary this method returns the corresponding value and removes the key–value item from the dictionary. The key must also be removed from the keys list.\n\nThe implementation is quite subtle because the pop() method must support twodifferentbehaviorstomatch dict.pop().Theﬁrstisd.pop(k);herethevalue for key k is returned, or if there is no key k, a KeyError is raised. The second is d.pop(k, value);herethevalue for key k isreturned,or if there isno key k,value (which could be None)isreturned. In all cases,if key k exists,thecorresponding item is removed.\n\ndef popitem(self):\n\nitem = super().popitem() self.__keys.remove(item[0]) return item\n\nThe dict.popitem() method removes and returns a random key–value item from the dictionary. We must call the base class version ﬁrst since we don’t know in advance which item will be removed. We remove the item’s key from the keys list, and then return the item.\n\ndef clear(self):\n\nsuper().clear() self.__keys.clear()\n\nHere we clear all the dictionary’s items and all the keys list’s items.\n\ndef values(self):\n\nfor key in self.__keys: yield self[key]\n\ndef items(self):\n\nfor key in self.__keys:\n\nyield (key, self[key])\n\ndef __iter__(self):\n\nreturn iter(self.__keys)\n\nkeys = __iter__\n\nCustom Collection Classes\n\nDictionarieshave four methodsthat return iterators:dict.values() for the dic- tionary’s values, dict.items() for the dictionary’s key–value items, dict.keys() for the keys, and the __iter__() special method that provides support for the iter(d) syntax, and operates on the keys. (Actually, the base class versions of these methods return dictionary views, but for most purposes the behavior of the iterators implemented here is the same.)\n\nSince the __iter__() method and the keys() method have identical behavior, instead of implementing keys(), we simply create an object reference called keys and set it to refer to the __iter__() method. With this in place, users of SortedDict cancall d.keys() or iter(d) togetaniteratorovera dictionary’skeys, just the same as they can call d.values() to get an iterator over the dictionary’s values.\n\nThe values() and items() methods are generator methods—see the sidebar “Generator Functions” (279 ➤) for a brief explanation of generator methods. In both cases they iterate over the sorted keys list, so they always return iter- ators that iterate in key order (with the key order depending on the key func- tion given to the initializer). For the items() and values() methods, the values are looked up using the d[k] syntax (which uses dict.__getitem__() under the hood), since we can treat self as a dict.\n\ndef __repr__(self):\n\nreturn object.__repr__(self)\n\ndef __str__(self):\n\nreturn (\"{\" + \", \".join([\"{0!r}: {1!r}\".format(k, v)\n\nfor k, v in self.items()]) + \"}\")\n\nWe cannot provide an eval()-able representation of a SortedDict because we can’t produce an eval()-able representation of the key function. So for the __repr__() reimplementation we bypass dict.__repr__(), and instead call the ultimate base class version, object.__repr__(). This produces a string of the kind used for non-eval()-able representations, for example, '<Sorted- Dict.SortedDict object at 0xb71fff5c>'.\n\nWe have implemented the SortedDict.__str__() method ourselves because we want the output to show the items in key sorted order. The method could have been written like this instead:\n\nitems = [] for key, value in self.items():\n\nitems.append(\"{0!r}: {1!r}\".format(key, value))\n\nreturn \"{\" + \", \".join(items) + \"}\"\n\nUsing a list comprehension is shorter and avoids the need for the temporary items variable.\n\n281\n\nGenera- tors ➤ 341\n\n282\n\nChapter 6. Object-Oriented Programming\n\nThe base class methods dict.get(), dict.__getitem__() (for the v = d[k] syntax), dict.__len__() (for len(d)), and dict.__contains__() (for x in d) all work ﬁne as they are and don’t affect the key ordering, so we have not needed to reimple- ment them.\n\nThe last dict method that we must reimplement is copy().\n\ndef copy(self):\n\nd = SortedDict() super(SortedDict, d).update(self) d.__keys = self.__keys.copy() return d\n\nThe easiest reimplementation is simply def copy(self): return SortedDict( self). We’ve chosen a slightly more complicated solution that avoids re-sort- ing the already sorted keys. We create an empty sorted dictionary, then up- date it with the items in the original sorted dictionary using the base class dict.update() to avoid the SortedDict.update() reimplementation, and re- place the dictionary’s self.__keys SortedList with a shallow copy of the origi- nal one.\n\nWhen super() is called with no arguments it works on the base class and the self object. But we can make it work on any class and any object by passing in a class and an object explicitly. Using this syntax, the super() call works on the immediate base class of the class it is given,so in this case the code has the same effect as (and could be written as) dict.update(d, self).\n\nIn view of the fact that Python’s sort algorithm is very fast,and is particularly well optimized for partially sorted lists, the efﬁciency gain is likely to be little or nothing except for huge dictionaries. However, the implementation shows that at least in principle, a custom copy() method can be more efﬁcient than using the copy_of_x = ClassOfX(x) idiom that Python’s built-in types support. And just as we did for SortedList, we have set __copy__ = copy so that the copy.copy() function uses our custom copy method rather than its own code.\n\ndef value_at(self, index):\n\nreturn self[self.__keys[index]]\n\ndef set_value_at(self, index, value):\n\nself[self.__keys[index]] = value\n\nThesetwomethodsrepresentanextensiontothedict API.Since,unlikea plain dict, a SortedDict is ordered, it follows that the concept of key index positions isapplicable. For example,theﬁrstitemin thedictionaryisat index position0, and the last at position len(d) - 1.Both of these methods operate on the dictio- nary item whose key is at the index-th position in the sorted keys list. Thanks toinheritance,wecan look upvaluesin the SortedDict using theitemaccessop-\n\nCustom Collection Classes\n\nerator ([]) applied directly to self, since self is a dict. If an out-of-range index is given the methods raise an IndexError exception.\n\nWe have now completed the implementation of the SortedDict class. It is not often that we need to create complete generic collection classes like this, but when we do, Python’s special methods allow us to fully integrate our class so that its users can treat it like any of the built-in or standard library classes.\n\nSummary\n\nThischaptercoveredallthefundamentalsof Python’ssupportforobject-orient- ed programming. We began by showing some of the disadvantagesof a purely procedural approach and how these could be avoided by using object orienta- tion. We then described some of the most common terminology used in object- oriented programming, including many “duplicate” terms such as base class and super class.\n\nWe saw how to create simple classes with data attributesand custom methods. We also saw how to inherit classes and how to add additional data attributes and additional methods, and how methods can be “unimplemented”.Unimple- menting is needed when we inherit a class but want to restrict the methods that our subclass provides, but it should be used with care since it breaks the expectation that a subclass can be used wherever one of its base classes can be used, that is, it breaks polymorphism.\n\nCustom classes can be seamlessly integrated so that they support the same syntaxes as Python’s built-in and library classes. This is achieved by imple- menting special methods. We saw how to implement special methods to sup- portcomparisons,howtoproviderepresentationalandstring forms,andhowto provideconversionstoother typessuch as int and float when it makessenseto do so. We also saw how to implement the __hash__() method to make a custom class’s instances usable as dictionary keys or as members of a set.\n\nData attributes by themselves provide no mechanism for ensuring that they are set to valid values. We saw how easy it is to replace data attributes with properties—this allows us to create read-only properties, and for writable properties makes it easy to provide validation.\n\nMost of theclasseswe createare“incomplete”sincewe tend to provideonly the methods that we actually need. This works ﬁne in Python,but in addition it is possible to create complete custom classesthat provide every relevant method. We saw how to do this for single valued classes, both by using aggregation and more compactly by using inheritance. We also saw how to do this for multivalued (collection) classes. Custom collection classes can provide the same facilities as the built-in collection classes,including support for in, len(), iter(), reversed(), and the item access operator ([]).\n\n283\n\n|||\n\n284\n\nChapter 6. Object-Oriented Programming\n\nWe learned that object creation and initialization are separate operations and that Python allows us to control both, although in almost every case we only need to customize initialization. We also learned that although it is always safe to return an object’s immutable data attributes, we should normally only ever return copies of an object’s mutable data attributes to avoid the object’s internal state leaking out and being accidentally invalidated.\n\nPython provides normal methods, static methods, class methods, and module functions. We saw that most methodsare normal methods,with classmethods being occasionally useful. Static methods are rarely used,since class methods or module functions are almost always better alternatives.\n\nThe built-in repr() method calls an object’s __repr__() special method. Where possible, eval(repr(x)) == x, and we saw how to support this. When an eval()-able representation string cannot be produced we use the base class ob- ject.__repr__() method to produce a non-eval()-able representation in a stan- dard format.\n\nType testing using the built-in isinstance() function can provide some efﬁcien- cy beneﬁts, although object-oriented purists would almost certainly avoid its use. Accessing base class methods is achieved by calling the built-in super() function,and isessentialtoavoid inﬁniterecursionwhen weneed to call a base class method inside a subclass’s reimplementation of that method.\n\nGenerator functions and methods do lazy evaluation, returning (via the yield expression) each value one at a time on request and raising a StopIteration when (and if) they run out of values. Generators can be used wherever an iterator is expected, and for ﬁnite generators, all their values can be extracted into a tuple or list by passing the iterator returned by the generator to tuple() or list().\n\nThe object-oriented approach almost invariably simpliﬁescode compared with a purely proceduralapproach. Withcustomclasseswecanguaranteethatonly valid operationsare available (since we implement only appropriatemethods), and that no operation can put an object into an invalid state (e.g., by using propertiesto apply validation).Once we start using object orientation our style of programming is likely to change from being about global data structures and the global functions that are applied to the data, to creating classes and implementing the methods that are applicable to them. Object orientation makes it possible to package up data and those methods that make sense for thedata. Thishelpsusavoidmixing upallourdataandfunctionstogether,and makes it easier to produce maintainable programs since functionality is kept separated out into individual classes.\n\nExercises\n\nExercises\n\nThe ﬁrst two exercises involve modifying classes we covered in this chapter, and the last two exercises involve creating new classes from scratch.\n\n1. Modify the Point class (from Shape.py or ShapeAlt.py), to support the following operations, where p, q, and r are Points and n is a number:\n\np = q + r p += q p = q - r p -= q p = q * n p *= n p = q / n p /= n p = q // n #Point.__floordiv__() p //= n\n\n#Point.__add__() # Point.__iadd__() #Point.__sub__() # Point.__isub__() #Point.__mul__() # Point.__imul__() #Point.__truediv__() # Point.__itruediv__()\n\n# Point.__ifloordiv__()\n\nThe in-place methods are all four lines long, including the def line, and the other methods are each just two lines long, including the def line, and of course they are all very similar and quite simple. With a minimal description and a doctest for each it adds up to around one hundred thirty new lines. A model solution is provided in Shape_ans.py; the same code is also in ShapeAlt_ans.py.\n\n2. Modify the Image.py classto providea resize(width, height) method. If the new width or height is smaller than the current value, any colors outside the new boundariesmust be deleted. If either width or height is None then use the existing width or height. At the end, make sure you regenerate the self.__colors set. Return a Boolean to indicate whether a change was made or not. The method can be implemented in fewer than 20 lines (fewer than 35 including a docstring with a simple doctest). A solution is provided in Image_ans.py.\n\n3. Implement a Transaction class that takes an amount, a date, a curren- cy (default “USD”—U.S. dollars), a USD conversion rate (default 1), and a description (default None). All of the data attributes must be pri- vate. Provide the following read-only properties: amount, date, curren- cy, usd_conversion_rate, description, and usd (calculated from amount * usd_conversion_rate). This class can be implemented in about sixty lines including somesimpledoctests. A modelsolutionfor thisexercise(andthe next one) is in ﬁle Account.py.\n\n4. Implement an Account class that holds an account number, an account name, and a list of Transactions. The number should be a read-only prop-\n\n285\n\n|||",
      "page_number": 263
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 278-291)",
      "start_page": 278,
      "end_page": 291,
      "detection_method": "topic_boundary",
      "content": "286\n\nChapter 6. Object-Oriented Programming\n\nerty;the name should be a read-write property with an assertion to ensure that the name is at least four characters long. The class should support the built-in len() function (returning the number of transactions), and should provide two calculated read-only properties: balance which should return the account’s balance in USD and all_usd which should return True if all the transactions are in USD and False otherwise. Three other methods should be provided: apply() to apply (add) a transaction, save(), and load(). The save() and load() methods should use a binary pickle with the ﬁlename being the account number with extension .acc; they should save and load the account number, the name, and all the trans- actions. This class can be implemented in about ninety lines with some simple doctests that include saving and loading—use code such as name = os.path.join(tempfile.gettempdir(), account_name) to provide a suitable temporary ﬁlename,and make sure you delete the temporary ﬁle after the tests have ﬁnished. A model solution is in ﬁle Account.py.\n\n7\n\nWriting and Reading Binary Data ● Writing and Parsing Text Files ● Writing and Parsing XML Files ● Random Access Binary Files\n\nFile Handling\n\n||||\n\nMost programs need to save and load information, such as data or state information, to and from ﬁles. Python provides many different ways of doing this. We already brieﬂy discussed handling text ﬁles in Chapter 3 and pickles in the preceding chapter. In this chapter we will cover ﬁle handling in much more depth.\n\nAll the techniques presented in this chapter are platform-independent. This means that a ﬁle saved using one of the example programs on one operating system/processorarchitecturecombinationcan beloaded by thesameprogram on a machine with a different operating system/processor architecture com- bination. And this can be true of your programs too if you use the same tech- niques as the example programs.\n\nThe chapter’sﬁrst three sections cover the common case of saving and loading anentiredatacollectiontoandfromdisk. Theﬁrstsectionshowshowtodothis using binary ﬁle formats, with one subsection using (optionally compressed) pickles, and the other subsection showing how to do the work manually. The second section showshow to handle text ﬁles. Writing text is easy,but reading it back can be tricky if we need to handle nontextual data such as numbers and dates. We show two approaches to parsing text, doing it manually and using regular expressions. Thethirdsectionshowshow toread and writeXML ﬁles. This section covers writing and parsing using element trees,writing and parsing using the DOM (Document Object Model), and writing manually and parsing using SAX (Simple API for XML).\n\nThe fourth section shows how to handle random access binary ﬁles. This is useful when each data item is the same size and where we have more items than we want in (or can ﬁt into) memory.\n\nWhich is the best ﬁle format to use for holding entire collections—binary,text, or XML? Which isthe best way to handle each format? These questionsare too context-dependentto have a single deﬁnitiveanswer,especially since thereare\n\n287\n\n288\n\nChapter 7. File Handling\n\nName\n\nData Type Notes\n\nreport_id\n\nstr\n\nMinimum length 8 and no whitespace\n\ndate\n\ndatetime.date\n\nairport\n\nstr\n\nNonempty and no newlines\n\naircraft_id\n\nstr\n\nNonempty and no newlines\n\naircraft_type\n\nstr\n\nNonempty and no newlines\n\npilot_percent_hours_on_type\n\nfloat\n\nRange 0.0 to 100.0\n\npilot_total_hours\n\nint\n\nPositive and nonzero\n\nmidair\n\nbool\n\nnarrative\n\nstr\n\nMultiline\n\nFigure 7.1 Aircraft incident record\n\npros and cons for each format and for each way of handling them. We show all of them to help you make an informed decision on a case-by-case basis.\n\nBinary formats are usually very fast to save and load and they can be very compact. Binary data doesn’tneed parsing sinceeach data typeisstoredusing itsnaturalrepresentation. Binary data isnot human readableor editable,and without knowing the format in detail it is not possible to create separate tools to work with binary data.\n\nText formats are human readable and editable, and this can make text ﬁles easier to process with separate tools or to change using a text editor. Text formats can be tricky to parse and it is not always easy to give good error messages if a text ﬁle’s format is broken (e.g., by careless editing).\n\nXML formats are human readable and editable, although they tend to be verboseandcreatelargeﬁles. Liketextformats,XMLformatscanbeprocessed using separate tools. Parsing XML is straightforward (providing we use an XML parser rather than do it manually), and some parsers have good error reporting. XML parsers can be slow, so reading very large XML ﬁles can take a lot more time than reading an equivalent binary or text ﬁle. XML includes metadata such as the character encoding (either implicitly or explicitly) that is not often provided in text ﬁles, and this can make XML more portable than text ﬁles.\n\nText formats are usually the most convenient for end-users, but sometimes performance issues are such that a binary format is the only reasonable choice. However, it is always useful to provide import/export for XML since this makes it possible to process the ﬁle format with third-party tools without preventing the most optimal text or binary format being used by the program for normal processing.\n\nChapter 7. File Handling\n\n289\n\nFormat\n\nReader/Writer\n\nReader + Writer Lines of Code\n\nTotal Lines of Code\n\nOutput File Size (~KB)\n\nBinary\n\nPickle (gzip compressed)\n\n20 + 16\n\n=\n\n36\n\n160\n\nBinary\n\nPickle\n\n20 + 16\n\n=\n\n36\n\n416\n\nBinary\n\nManual (gzip compressed)\n\n60 + 34\n\n=\n\n94\n\n132\n\nBinary\n\nManual\n\n60 + 34\n\n=\n\n94\n\n356\n\nPlain text Regex reader/manual writer\n\n39 + 28\n\n=\n\n67\n\n436\n\nPlain text Manual\n\n53 + 28\n\n=\n\n81\n\n436\n\nXML\n\nElement tree\n\n37 + 27\n\n=\n\n64\n\n460\n\nXML\n\nDOM\n\n44 + 36\n\n=\n\n80\n\n460\n\nXML\n\nSAX reader/manual writer\n\n55 + 37\n\n=\n\n92\n\n464\n\nFigure 7.2 Aircraft incident ﬁle format reader/writer comparison\n\nThis chapter’s ﬁrst three sections all use the same data collection: a set of air- craft incident records. Figure 7.1 shows the names, data types, and validation constraints that apply to aircraft incident records. It doesn’t really matter what data we are processing. The important thing is that we learn to process thefundamentaldatatypesincluding strings,integers,ﬂoating-pointnumbers, Booleans,and dates,sinceif we can handle these we can handle any other kind of data.\n\nBy using the same set of aircraft incident data for binary, text, and XML formats,it makesit possible to compare and contrast the different formatsand the code necessary for handling them. Figure 7.2showsthe number of lines of code for reading and writing each format, and the totals.\n\nThe ﬁle sizesare approximateand based on a particular sample of 596 aircraft incident records.★ Compressed binary ﬁle sizes for the same data saved under different ﬁlenames may vary by a few bytes since the ﬁlename is included in the compressed data and ﬁlename lengths vary. Similarly, the XML ﬁle sizes vary slightly since some XML writersuse entities (&quot; for \" and &apos; for ') for quotes inside text data, and others don’t.\n\nThe ﬁrst three sections all quote code from the same program: convert-inci- dents.py.This program is used to read aircraft incident data in one format and to writeit in another format. Hereistheprogram’sconsolehelptext. (Wehave reformatted the output slightly to ﬁt the book’s page width.)\n\nUsage: convert-incidents.py [options] infile outfile\n\n★ThedataweusedisbasedonrealaircraftincidentdataavailablefromtheFAA (U.S.government’s Federal Aviation Administration, www.faa.gov).\n\n290\n\nChapter 7. File Handling\n\nReads aircraft incident data from infile and writes the data to outfile. The data formats used depend on the file extensions: .aix is XML, .ait is text (UTF-8 encoding), .aib is binary, .aip is pickle, and .html is HTML (only allowed for the outfile). All formats are platform-independent.\n\nOptions: -h, --help show this help message and exit -f, --force write the outfile even if it exists [default: off] -v, --verbose report results [default: off] -r READER, --reader=READER reader (XML): 'dom', 'd', 'etree', 'e', 'sax', 's' reader (text): 'manual', 'm', 'regex', 'r' [default: etree for XML, manual for text] -w WRITER, --writer=WRITER writer (XML): 'dom', 'd', 'etree', 'e', 'manual', 'm' [default: manual] -z, --compress compress .aib/.aip outfile [default: off] -t, --test execute doctests and exit (use with -v for verbose)\n\nThe options are more complex than would normally be required since an end-user will not care which reader or writer we use for any particular format. In a more realistic version of the program the reader and writer options would not exist and we would implement just one reader and one writer for each format. Similarly, the test option exists to help us test the code and would not be present in a production version.\n\nThe program deﬁnes one custom exception:\n\nclass IncidentError(Exception): pass\n\nAircraft incidents are held as Incident objects. Here is the class line and the initializer:\n\nclass Incident:\n\ndef __init__(self, report_id, date, airport, aircraft_id,\n\naircraft_type, pilot_percent_hours_on_type, pilot_total_hours, midair, narrative=\"\"):\n\nassert len(report_id) >= 8 and len(report_id.split()) == 1, \\\n\n\"invalid report ID\"\n\nself.__report_id = report_id self.date = date self.airport = airport self.aircraft_id = aircraft_id self.aircraft_type = aircraft_type self.pilot_percent_hours_on_type = pilot_percent_hours_on_type\n\nChapter 7. File Handling\n\nself.pilot_total_hours = pilot_total_hours self.midair = midair self.narrative = narrative\n\nThe report ID is validated when the Incident is created and is available as the read-only report_id property. All the other data attributes are read/write properties. For example, here is the date property’s code:\n\n@property def date(self):\n\nreturn self.__date\n\n@date.setter def date(self, date):\n\nassert isinstance(date, datetime.date), \"invalid date\" self.__date = date\n\nAll the other properties follow the same pattern, differing only in the details of their assertions, so we won’t reproduce them here. Since we have used assertions, the program will fail if an attempt is made to create an Incident with invalid data,or to set one of an existing incident’sread/writepropertiesto an invalid value. We have chosen this uncompromising approach because we want to be sure that the data we save and load is alwaysvalid,and if it isn’t we want the program to terminate and complain rather than silently continue.\n\nThe collection of incidents is held as an IncidentCollection. This class is a dict subclass, so we get a lot of functionality, such as support for the item access operator ([]) to get, set, and delete incidents, by inheritance. Here is the class line and a few of the class’s methods:\n\nclass IncidentCollection(dict):\n\ndef values(self):\n\nfor report_id in self.keys(): yield self[report_id]\n\ndef items(self):\n\nfor report_id in self.keys():\n\nyield (report_id, self[report_id])\n\ndef __iter__(self):\n\nfor report_id in sorted(super().keys()):\n\nyield report_id\n\nkeys = __iter__\n\nWe have not needed to reimplement the initializer since dict.__init__() is sufﬁcient. The keys are report IDs and the values are Incidents. We have reimplementedthe values(),items(),and keys() methodssothattheir iterators\n\n291\n\nstr. trans- late() 77➤\n\nWriting and Reading Binary Data\n\nThe Bytes and Bytearray Data Types\n\nPython provides two data types for handling raw bytes: bytes which is im- mutable,and bytearray whichismutable. Bothtypesholda sequenceof zero or more 8-bit unsigned integers (bytes) with each byte in the range 0…255.\n\nBoth types are very similar to strings and provide many of the same methods, including support for slicing. In addition, bytearrays also provide some mutating list-like methods. All their methods are listed in Tables 7.1 (➤ 299) and\n\n7.2 (➤ 300).\n\nWhereas a slice of a bytes or bytearray returns an object of the same type, accessing a single byte using the item access operator ([]) returns an int—the value of the speciﬁed byte. For example:\n\nword = b\"Animal\" x = b\"A\" # returns: False word[0] == x word[:1] == x # returns: True word[0] == x[0] # returns: True\n\n# word[0] == 65; x == b\"A\" # word[:1] == b\"A\"; x == b\"A\" # word[0] == 65;\n\nx[0] == 65\n\nHere are some other bytes and bytearray examples:\n\ndata = b\"5 Hills \\x35\\x20\\x48\\x69\\x6C\\x6C\\x73\" data.upper() data.replace(b\"ill\", b\"at\") bytes.fromhex(\"35 20 48 69 6C 6C 73\") # returns: b'5 Hills' # returns: b'5 Hills' bytes.fromhex(\"352048696C6C73\") # data is now a bytearray data = bytearray(data) # returns: 72 (ord(\"H\")) data.pop(10) # data == b'5 Hills 5 Bills' data.insert(10, ord(\"B\"))\n\n# returns: b'5 HILLS 5 HILLS' # returns: b'5 Hats 5 Hats'\n\nMethods that make sense only for strings, such as bytes.upper(), assume that the bytes are encoded using ASCII. The bytes.fromhex() class method ignoreswhitespaceandinterpretseachtwo-digitsubstringasahexadecimal number, so \"35\" is taken to be a byte of value 0x35, and so on.\n\npickle.dump(self, fh, pickle.HIGHEST_PROTOCOL) return True\n\nexcept (EnvironmentError, pickle.PicklingError) as err:\n\nprint(\"{0}: export error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nfinally:\n\nif fh is not None: fh.close()\n\n293\n\n294\n\nChapter 7. File Handling\n\nIf compression has been requested, we use the gzip module’s gzip.open() function to open the ﬁle; otherwise, we use the built-in open() function. We must use “write binary” mode (\"wb\") when pickling data in binary format. In Python 3.0 and 3.1, pickle.HIGHEST_PROTOCOL is protocol 3, a compact binary pickle format. This is the best protocol to use for data shared among Python 3 programs.★\n\nFor error handling we have chosen to report errors to the user as soon as they occur, and to return a Boolean to the caller indicating success or failure. And wehaveuseda finally block toensurethattheﬁleisclosedat theend,whether there was an error or not. In Chapter 8 we will use a more compact idiom to ensure that ﬁles are closed that avoids the need for a finally block.\n\nThis code is very similar to what we saw in the preceding chapter, but there is one subtle point to note. The pickled data is self, a dict. But the dictionary’s valuesare Incident objects,thatis,objectsof a customclass. Thepicklemodule is smart enough to be able to save objects of most custom classes without us needing to intervene.\n\nIn general, Booleans, numbers, and strings can be pickled, as can instances of __dict__ is picklable. classes including custom classes, providing their private In addition, any built-in collection types (tuples, lists, sets, dictionaries) can be pickled, providing they contain only picklable objects (including collection types, so recursive structures are supported).It is also possible to pickle other kinds of objects or instances of custom classes that can’t normally be pickled (e.g., because they have a nonpicklable attribute), either by giving some help to the pickle module or by implementing custom pickle and unpickle functions. All the relevant details are provided in the pickle module’s online documen- tation.\n\nToreadback thepickleddataweneedtodistinguishbetweena compressedand an uncompressed pickle. Any ﬁle that is compressed using gzip compression begins with a particular magic number. A magic number is a sequence of one or more bytes at the beginning of a ﬁle that is used to indicate the ﬁle’s type. For gzip ﬁles the magic number is the two bytes 0x1F 0x8B, which we store in a bytes variable:\n\nGZIP_MAGIC = b\"\\x1F\\x8B\"\n\nFor more about the bytes data type, see the sidebar “The Bytes and Bytearray Data Types” (293 ➤), and Tables 7.1, 7.2, and 7.3 (➤ 299–301), which list their methods.\n\nHere is the code for reading an incidents pickle ﬁle:\n\n★Protocol 3isPython3-speciﬁc. If wewant picklesthat arereadableandwritableby both Python2 and Python 3 programs,we must use protocol 2 instead. Note,though,that protocol 2 ﬁles written by Python 3.1 can be read by Python 3.1 and Python 2.x, but not by Python 3.0!\n\nContext man- agers ➤ 369\n\n__dict__ ➤ 363\n\n3.x\n\nWriting and Reading Binary Data\n\ndef import_pickle(self, filename):\n\nfh = None try:\n\nfh = open(filename, \"rb\") magic = fh.read(len(GZIP_MAGIC)) if magic == GZIP_MAGIC:\n\nfh.close() fh = gzip.open(filename, \"rb\")\n\nelse:\n\nfh.seek(0)\n\nself.clear() self.update(pickle.load(fh)) return True\n\nexcept (EnvironmentError, pickle.UnpicklingError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nfinally:\n\nif fh is not None: fh.close()\n\nWe don’t know whether the given ﬁle is compressed. In either case we begin by opening the ﬁle in “read binary” mode,and then we read the ﬁrst two bytes. If these bytes are the same as the gzip magic number we close the ﬁle and create a new ﬁle object using the gzip.open() function. And if the ﬁle is not compressed we use the ﬁle object returned by open(), calling its seek() method to restore the ﬁle pointer to the beginning so that the next read (made inside the pickle.load() function) will be from the start.\n\nWe can’t assign to self since that would wipe out the IncidentCollection object that isin use,soinsteadweclear alltheincidentstomakethedictionary empty and then use dict.update() to populate the dictionary with all the incidents from the IncidentCollection dictionary loaded from the pickle.\n\nNote that it does not matter whether the processor’s byte ordering is big- or little-endian, because for the magic number we read individual bytes, and for the data the pickle module handles endianness for us.\n\nRaw Binary Data with Optional Compression\n\nWriting our own code to handle raw binary data gives us complete control over our ﬁle format. It should also be safer than using pickles, since mali- ciously invalid data will be handled by our code rather than executed by the interpreter.\n\n295\n\n||\n\nChar- acter encod- ings 91➤\n\n296\n\nChapter 7. File Handling\n\nWhen creating custom binary ﬁle formats it is wise to create a magic number to identify your ﬁle type, and a version number to identify the version of the ﬁle format in use. Here are the deﬁnitions used in the convert-incidents.py program:\n\nMAGIC = b\"AIB\\x00\" FORMAT_VERSION = b\"\\x00\\x01\"\n\nWe have used four bytes for the magic number and two for the version. Endianness is not an issue because these will be written as individual bytes, not as the byte representations of integers, so they will always be the same on any processor architecture.\n\nTo write and read raw binary data we must have some means of converting Python objects to and from suitable binary representations. Most of the func- tionality weneedisprovidedby thestruct module,brieﬂy describedintheside- bar “The Struct Module” (➤ 297), and by the bytes and bytearray data types, brieﬂy describedin the sidebar “TheBytesand Bytearray Data Types”(293➤). The bytes and bytearray classes’ methods are listed in Tables 7.1 (➤ 299) and 7.2 (➤ 300).\n\nUnfortunately,the struct module can handle stringsonly of a speciﬁed length, and we need variable length strings for the report and aircraft IDs, as well as for the airport,the aircraft type,and the narrative texts. To meet this need we havecreateda function,pack_string(),which takesa string andreturnsa bytes object which containstwo components:The ﬁrst isan integer length count,and the second isa sequenceof length count UTF-8encoded bytesrepresenting the string’s text.\n\nSince the only place the pack_string() function is needed is inside the ex- port_binary() function, we have put the deﬁnition of pack_string() inside the export_binary() function. This means that pack_string() is not visible outside the export_binary() function,and makesclear that it is just a local helper func- tion. Here is the start of the export_binary() function,and the completenested pack_string() function:\n\ndef export_binary(self, filename, compress=False):\n\ndef pack_string(string):\n\ndata = string.encode(\"utf8\") format = \"<H{0}s\".format(len(data)) return struct.pack(format, len(data), data)\n\nThe str.encode() method returnsa bytes object with the string encoded accord- ing to the speciﬁed encoding. UTF-8 is a very convenient encoding because it can represent any Unicode character and is especially compact when repre- senting ASCII characters(just one byte each).The format variable isset to hold a struct format based on the string’s length. For example, given the string\n\nLocal func- tions ➤ 351\n\nWriting and Reading Binary Data\n\nThe Struct Module\n\nThe struct module provides struct.pack(), struct.unpack(), and some other functions, and the struct.Struct() class. The struct.pack() function takes a struct format string and one or more values and returns a bytes object that holds all the values represented in accordance with the format. The struct.unpack() function takes a format and a bytes or bytearray object and returns a tuple of the values that were originally packed using the format. For example:\n\ndata = struct.pack(\"<2h\", 11, -9) items = struct.unpack(\"<2h\", data) # items == (11, -9)\n\n# data == b'\\x0b\\x00\\xf7\\xff'\n\nFormatstringsconsistof oneor morecharacters. Mostcharactersrepresent a value of a particular type. If we need more than one value of a type we can either write the character as many times as there are values of the type (\"hh\"), or precede the character with a count as we have done here (\"2h\").\n\nMany format characters are described in the struct module’s online docu- mentation, including “b” (8-bit signed integer), “B” (8-bit unsigned integer), “h” (16-bit signed integer—used in the examples here),“H” (16-bit unsigned integer), “i” (32-bit signed integer), “I” (32-bit unsigned integer), “q” (64-bit signed integer), “Q” (64-bit unsigned integer), “f” (32-bit ﬂoat), “d” (64-bit ﬂoat—this corresponds to Python’s float type), “?” (Boolean), “s” (bytes or bytearray object—byte strings), and many others.\n\nFor some data types such as multibyte integers, the processor’s endianness makes a difference to the byte order. We can force a particular byte order to be used regardless of the processor architecture by starting the format string with an endianness character. In this book we always use “<”, which means little-endian since that’s the native endianness for the widely used Intel and AMD processors. Big-endian (also called network byte order) is signiﬁedby “>”(or by “!”).If noendiannessisspeciﬁedthemachine’sendian- ness is used. We recommend always specifying the endianness even if it is the same as the machine being used since doing so keeps the data portable.\n\nThe struct.calcsize() function takes a format and returns how many bytes a structusing theformatwilloccupy. A formatcanalsobestoredby creating a struct.Struct() object giving it the format as its argument, with the size of the struct.Struct() object given by its size attribute. For example:\n\nTWO_SHORTS = struct.Struct(\"<2h\") data = TWO_SHORTS.pack(11, -9) items = TWO_SHORTS.unpack(data)\n\n# data == b'\\x0b\\x00\\xf7\\xff' # items == (11, -9)\n\nIn both examples,11 is0x000b,but thisistransformedintothebytes0x0b 0x00 because we have used little-endian byte ordering.\n\n297\n\n298\n\nChapter 7. File Handling\n\n“en.wikipedia.org”, the format will be \"<H16s\" (little-endian byte order, 2-byte unsigned integer,16-bytebytestring),and the bytes object that isreturnedwill be b'\\x10\\x00en.wikipedia.org'. Conveniently, Python shows bytes objects in a compact form using printable ASCII characters where possible, and hexadeci- mal escapes (and some special escapes like \\t and \\n) otherwise.\n\nThe pack_string() function can handle strings of up to 65535 UTF-8 charac- ters. We could easily switch to using a different kind of integer for the byte count; for example, a 4-byte signed integer (format “i”) would allow for strings of up to 231-1 (more than 2 billion) characters.\n\nThe struct module does provide a similar built-in format,“p”,that stores a sin- gle byte as a character count followed by up to 255 characters. For packing, the code using “p” format is slightly simpler than doing all the work ourselves. But “p” format restricts us to a maximum of 255 UTF-8 characters and pro- videsalmost no beneﬁt when unpacking. (For thesakeof comparison,versions of pack_string() and unpack_string() that use “p” format are included in the convert-incidents.py source ﬁle.)\n\nWe can now turn our attention to the rest of the code in the export_binary() method.\n\nfh = None try:\n\nif compress:\n\nfh = gzip.open(filename, \"wb\")\n\nelse:\n\nfh = open(filename, \"wb\")\n\nfh.write(MAGIC) fh.write(FORMAT_VERSION) for incident in self.values():\n\ndata = bytearray() data.extend(pack_string(incident.report_id)) data.extend(pack_string(incident.airport)) data.extend(pack_string(incident.aircraft_id)) data.extend(pack_string(incident.aircraft_type)) data.extend(pack_string(incident.narrative.strip())) data.extend(NumbersStruct.pack(\n\nincident.date.toordinal(), incident.pilot_percent_hours_on_type, incident.pilot_total_hours, incident.midair))\n\nfh.write(data)\n\nreturn True\n\nChar- acter encod- ings 91➤\n\nWriting and Reading Binary Data\n\nTable 7.1 Bytes and Bytearray Methods #1\n\nSyntax\n\nDescription\n\nba.append(i)\n\nAppends int i (in range 0…255) to bytearray ba\n\nb.capitalize()\n\nReturns a copy of bytes/bytearray b with the ﬁrst charac- ter capitalized (if it is an ASCII letter)\n\nb.center(width,\n\nbyte)\n\nReturns a copy of b centered in length width padded with spaces or optionally with the given byte\n\nb.count(x,\n\nstart, end)\n\nReturnsthenumber of occurrencesof bytes/bytearray x in bytes/bytearray b (or in the start:end slice of b)\n\nb.decode(\n\nencoding, error)\n\nReturns a str object that represents the bytes using the UTF-8 encoding or using the speciﬁed encoding and han- dling errors according to the optional error argument\n\nb.endswith(x,\n\nstart, end)\n\nReturns True if b (or the start:end slice of b) ends with bytes/bytearray x or with any of the bytes/bytearrays in tuple x; otherwise, returns False\n\nb.expandtabs( size)\n\nReturns a copy of bytes/bytearray b with tabs replaced with spaces in multiples of 8 or of size if speciﬁed\n\nba.extend(seq)\n\nExtends bytearray ba with all the ints in sequence seq; all the ints must be in the range 0…255\n\nb.find(x,\n\nstart, end)\n\nReturns the leftmost position of bytes/bytearray x in b (or in the start:end slice of b) or -1 if not found. Use the rfind() method to ﬁnd the rightmost position.\n\nb.fromhex(h)\n\nReturns a bytes object with bytes corresponding to the hexadecimal integers in str h\n\nb.index(x,\n\nstart, end)\n\nReturns the leftmost position of x in b (or in the start:end slice of b) or raises ValueError if not found. Use the rindex() method to ﬁnd the rightmost position.\n\nba.insert(p, i)\n\nInserts integer i (in range 0…255) at position p in ba\n\nb.isalnum()\n\nReturns True if bytes/bytearray b is nonempty and every character in b is an ASCII alphanumeric character\n\nb.isalpha()\n\nReturns True if bytes/bytearray b is nonempty and every character in b is an ASCII alphabetic character\n\nb.isdigit()\n\nReturns True if bytes/bytearray b is nonempty and every character in b is an ASCII digit\n\nb.islower()\n\nb.isspace()\n\nReturns True if bytes/bytearray b has at least one lower- caseable ASCII character and all its lowercaseable char- acters are lowercase Returns True if bytes/bytearray b is nonempty and every character in b is an ASCII whitespace character\n\n299\n\n300\n\nChapter 7. File Handling\n\nTable 7.2 Bytes and Bytearray Methods #2\n\nSyntax\n\nDescription\n\nb.istitle()\n\nReturns True if b is nonempty and title-cased\n\nb.isupper()\n\nReturnsTrue if b hasat least one uppercaseableASCIIchar- acter and all its uppercaseable characters are uppercase\n\nb.join(seq)\n\nReturns the concatenation of every bytes/bytearray in se- quence seq, with b (which may be empty) between each one\n\nb.ljust(\n\nwidth, byte)\n\nReturns a copy of bytes/bytearray b left-aligned in length width padded with spaces or optionally with the given byte. Use the rjust() method to right-align.\n\nb.lower()\n\nReturns an ASCII-lowercased copy of bytes/bytearray b\n\nb.partition( sep)\n\nReturns a tuple of three bytes objects—the part of b before the leftmost bytes/bytearray sep, sep itself, and the part of b after sep; or if sep isn’t in b returns b and two empty bytes objects. Use the rpartition() method to partition on the rightmost occurrence of sep.\n\nba.pop(p)\n\nRemoves and returns the int at index position p in ba\n\nba.remove(i)\n\nRemoves the ﬁrst occurrence of int i from bytearray ba\n\nb.replace(x, y, n)\n\nReturns a copy of b with every (or a maximum of n if given) occurrence of bytes/bytearray x replaced with y\n\nba.reverse()\n\nReverses bytearray ba’s bytes in-place\n\nb.split(x, n) Returnsa list of bytes splitting atmost n timeson x.If n isn’t\n\ngiven, splits everywhere possible; if x isn’t given, splits on whitespace. Use rsplit() to split from the right.\n\nb.splitlines(\n\nf)\n\nReturns the list of lines produced by splitting b on line terminators, stripping the terminators unless f is True\n\nb.startswith( x, start, end)\n\nReturns True if bytes/bytearray b (or the start:end slice of b) starts with bytes/bytearray x or with any of the bytes/bytearrays in tuple x; otherwise, returns False\n\nb.strip(x)\n\nReturnsa copy of b with leading and trailing whitespace(or the bytes in bytes/bytearray x) removed; lstrip() strips only at the start, and rstrip() strips only at the end\n\nb.swapcase()\n\nReturnsa copy of b with uppercase ASCII characterslower- cased and lowercase ASCII characters uppercased\n\nb.title()\n\nReturnsa copy of b wheretheﬁrstASCIIletterof eachword is uppercased and all other ASCII letters are lowercased\n\nb.translate(\n\nbt, d)\n\nReturnsa copy of b that hasno bytesfrom d,and whereeach other byte is replaced by the byte-th byte from bytes bt",
      "page_number": 278
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 292-301)",
      "start_page": 292,
      "end_page": 301,
      "detection_method": "topic_boundary",
      "content": "Writing and Reading Binary Data\n\nTable 7.3 Bytes and Bytearray Methods #3\n\nSyntax\n\nDescription\n\nb.upper()\n\nReturns an ASCII-uppercased copy of bytes/bytearray b\n\nb.zfill(w) Returns a copy of b, which if shorter than w is padded with\n\nleading zeros (0x30 characters) to make it w bytes long\n\nWe have omitted the except and finally blocks since they are the same as the ones shown in the preceding subsection, apart from the particular exceptions that the except block catches.\n\nWe begin by opening the ﬁle in “write binary” mode, either a normal ﬁle or a gzip compressed ﬁle depending on the compress ﬂag. We then write the 4-byte magicnumber that is(hopefully)uniquetoour program,andthe2-byteversion number.★ Using a version number makes it easier to change the format in the future—when we read the version number we can use it to determine which code to use for reading.\n\nNext we iterate over all the incidents, and for each one we create a bytearray. We add each item of data to the byte array, starting with the variable length strings. The date.toordinal() method returns a single integer representing the stored date; the date can be restored by passing this integer to the date- time.date.fromordinal() method. The NumbersStruct is deﬁned earlier in the program with this statement:\n\nNumbersStruct = struct.Struct(\"<Idi?\")\n\nThis format speciﬁes little-endian byte order, an unsigned 32-bit integer (for the date ordinal), a 64-bit ﬂoat (for the percentage hours on type), a 32-bit in- teger (for the total hours ﬂown), and a Boolean (for whether the incident was midair).The structure of an entire aircraft incident record is shown schemati- cally in Figure 7.3.\n\nOnce the bytearray has all the data for one incident, we write it to disk. And once all the incidents have been written we return True (assuming no error oc- curred).The finally block ensures that the ﬁle is closed just before we return.\n\nReading back the data is not as straightforward as writing it—for one thing we have more error checking to do. Also, reading back variable length strings is slightly tricky. Here is the start of the import_binary() method and the complete nested unpack_string() function that we use to read back the variable length strings:\n\n★There is no central repository for magic numbers like there is for domain names,so we can never guarantee uniqueness.\n\n301\n\n302\n\nChapter 7. File Handling\n\nd i _ t r o p e r\n\nstring\n\nt r o p r i a\n\nstring\n\nd i _ t f a r c r i a\n\nstring\n\ne p y t _ t f a r c r i a\n\nstring\n\ne v i t a r r a n\n\nstring\n\ne t a d\n\nuint32\n\n_ t n e c r e p _ t o l i p\n\ne p y t _ n o _ s r u o h float64\n\n_ l a t o t _ t o l i p\n\ns r u o h int32\n\nr i a d i m\n\nbool\n\nuint16\n\nUTF-8 encoded bytes...\n\nFigure 7.3 The structure of a binary aircraft incident record\n\ndef import_binary(self, filename):\n\ndef unpack_string(fh, eof_is_error=True):\n\nuint16 = struct.Struct(\"<H\") length_data = fh.read(uint16.size) if not length_data:\n\nif eof_is_error:\n\nraise ValueError(\"missing or corrupt string size\")\n\nreturn None\n\nlength = uint16.unpack(length_data)[0] if length == 0:\n\nreturn \"\"\n\ndata = fh.read(length) if not data or len(data) != length:\n\nraise ValueError(\"missing or corrupt string\")\n\nformat = \"<{0}s\".format(length) return struct.unpack(format, data)[0].decode(\"utf8\")\n\nSince each incident record beginswith itsreport IDstring,when we attempt to read this string and we succeed, we are at the start of a new record. But if we fail, we’ve reached the end of the ﬁle and can ﬁnish. We set the eof_is_error ﬂag to False when attempting to read a report ID since if there is no data, it just meanswe have ﬁnished. For all other stringswe accept the default of True because if any other string has no data, it is an error. (Even an empty string will be preceded by a 16-bit unsigned integer length.)\n\nWe begin by attempting to read the string’s length. If this fails we return None to signify end of ﬁle (if we are attempting to read a new incident), or we raise a ValueError exceptiontoindicatecorruptor missing data. The struct.unpack() function and the struct.Struct.unpack() method always return a tuple, even if it contains only a single value. We unpack the length data and store the number it representsin the length variable. Now we know how many byteswe\n\nWriting and Reading Binary Data\n\nmust read to get the string. If the length is zero we simply return an empty string. Otherwise, we attempt to read the speciﬁed number of bytes. If we don’t get any data or if the data is not the size we expected (i.e., it is too little), we raise a ValueError exception.\n\nIf we have the right number of bytes we create a suitable format string for the struct.unpack() function,and we return thestring that resultsfromunpacking the data and decoding the bytes as UTF-8. (In theory, we could replace the last two lines with return data.decode(\"utf8\"), but we prefer to go through the unpacking process since it is possible—though unlikely—that the “s” format performs some transformation on our data which must be reversed when reading back.)\n\nWe will now look at therest of the import_binary() method,breaking it intotwo parts for ease of explanation.\n\nfh = None try:\n\nfh = open(filename, \"rb\") magic = fh.read(len(GZIP_MAGIC)) if magic == GZIP_MAGIC:\n\nfh.close() fh = gzip.open(filename, \"rb\")\n\nelse:\n\nfh.seek(0)\n\nmagic = fh.read(len(MAGIC)) if magic != MAGIC:\n\nraise ValueError(\"invalid .aib file format\")\n\nversion = fh.read(len(FORMAT_VERSION)) if version > FORMAT_VERSION:\n\nraise ValueError(\"unrecognized .aib file version\")\n\nself.clear()\n\nThe ﬁle may or may not be compressed, so we use the same technique that we used for reading pickles to open the ﬁle using gzip.open() or the built-in open() function.\n\nOnce the ﬁle is open and we are at the beginning, we read the ﬁrst four bytes (len(MAGIC)). If these don’t match our magic number we know that it isn’t a binary aircraft incident data ﬁle and so we raise a ValueError exception. Next we read in the 2-byte version number. It is at this point that we would use different reading code depending on the version. Here we just check that the version isn’t a later one than this program is able to read.\n\nIf the magic number is correct and the version is one we can handle, we are ready to read in the data, so we begin by clearing out all the existing incidents so that the dictionary is empty.\n\n303\n\nMap- ping unpack- ing 179➤\n\n304\n\nChapter 7. File Handling\n\nwhile True:\n\nreport_id = unpack_string(fh, False) if report_id is None:\n\nbreak data = {} data[\"report_id\"] = report_id for name in (\"airport\", \"aircraft_id\",\n\n\"aircraft_type\", \"narrative\"):\n\ndata[name] = unpack_string(fh)\n\nother_data = fh.read(NumbersStruct.size) numbers = NumbersStruct.unpack(other_data) data[\"date\"] = datetime.date.fromordinal(numbers[0]) data[\"pilot_percent_hours_on_type\"] = numbers[1] data[\"pilot_total_hours\"] = numbers[2] data[\"midair\"] = numbers[3] incident = Incident(**data) self[incident.report_id] = incident\n\nreturn True\n\nThe while block loopsuntilwerunoutof data. Westartby trying togeta report ID.If weget None we’vereachedtheendof theﬁleand canbreak out of theloop. Otherwise, we create a dictionary called data to hold the data for one incident and attempt to get the rest of the incident’s data. For the strings we use the unpack_string() method, and for the other data we read it all in one go using the NumbersStruct struct. Since we stored the date as an ordinal we must do the reverse conversion to get a date back. But for the other items, we can just use the unpacked data—no validation or conversion is required since we wrote the correct data typesin the ﬁrst place and have read back the same data types using the format held in the NumbersStruct struct.\n\nIf any error occurs, for example, if we fail to unpack all the numbers, an exception will be raised and will be handled in the except block. (We haven’t shown the except and finally blocks because they are structurally the same as those shown in the preceding subsection for the import_pickle() method.)\n\nToward the end we make use of the convenient mapping unpacking create an Incident object which we then store in the incidents dictionary.\n\nsyntax to\n\nApart from the handling of variable length strings, the struct module makes it very easy to save and load data in binary format. And for variable length strings the pack_string() and unpack_string() methods shown here should serve most purposes perfectly well.\n\nWriting and Parsing Text Files\n\nWriting and Parsing Text Files\n\nWriting text is easy, but reading it back can be problematic, so we need to choose the structure carefully so that it is not too difﬁcult to parse.★ Figure 7.4 shows an example aircraft incident record in the text format we are going to use. When we write the incident records to a ﬁle we will follow each one with a blank line, but when we parse the ﬁle we will accept zero or more blank lines between incident records.\n\nWriting Text\n\nEach incident record beginswith the report IDenclosed in brackets([]).Thisis followedby alltheone-linedataitemswritteninkey=valueform. Forthemulti- line narrative text we precede the text with a start marker (.NARRATIVE_START.) and follow it with an end marker (.NARRATIVE_END.), and we indent all the text in between to ensure that no line of text could be confused with a start or end marker.\n\n[20070927022009C] date=2007-09-27 aircraft_id=1675B aircraft_type=DHC-2-MK1 airport=MERLE K (MUDHOLE) SMITH pilot_percent_hours_on_type=46.1538461538 pilot_total_hours=13000 midair=0 .NARRATIVE_START. ACCORDING TO THE PILOT, THE DRAG LINK FAILED DUE TO AN OVERSIZED TAIL WHEEL TIRE LANDING ON HARD SURFACE. .NARRATIVE_END.\n\nFigure 7.4 An example text format aircraft incident record\n\nHere is the code for the export_text() function, but excluding the except and finally blocks since they are the same as ones we have seen before, except for the exceptions handled:\n\ndef export_text(self, filename):\n\nwrapper = textwrap.TextWrapper(initial_indent=\"\n\n\",\n\nsubsequent_indent=\"\n\n\")\n\n★Chapter 14 introducesvariousparsing techniques,including two third-party open source parsing modules that make parsing tasks much easier.\n\n305\n\n|||\n\n||\n\ndatetime module 216➤\n\nstr. format() 78➤\n\n__for- mat__() 254➤\n\n306\n\nChapter 7. File Handling\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") for incident in self.values():\n\nnarrative = \"\\n\".join(wrapper.wrap(\n\nincident.narrative.strip()))\n\nfh.write(\"[{0.report_id}]\\n\" \"date={0.date!s}\\n\" \"aircraft_id={0.aircraft_id}\\n\" \"aircraft_type={0.aircraft_type}\\n\" \"airport={airport}\\n\" \"pilot_percent_hours_on_type=\" \"{0.pilot_percent_hours_on_type}\\n\" \"pilot_total_hours={0.pilot_total_hours}\\n\" \"midair={0.midair:d}\\n\" \".NARRATIVE_START.\\n{narrative}\\n\" \".NARRATIVE_END.\\n\\n\".format(incident,\n\nairport=incident.airport.strip(), narrative=narrative))\n\nreturn True\n\nThe line breaks in the narrative text are not signiﬁcant, so we can wrap the text as we like. Normally we would use the textwrap module’s textwrap.wrap() function, but here we need to both indent and wrap, so we begin by creating a textwrap.TextWrap object, initialized with the indentation we want to use (four spaces for the ﬁrst and subsequent lines).By default,the object will wrap lines to a width of 70 characters, although we can change this by passing another keyword argument.\n\nWe could have written this using a triple quoted string, but we prefer to put in the newlines manually. The textwrap.TextWrapper object provides a wrap() method that takesa string asinput,in thiscase the narrativetext,and returns a list of strings with suitable indentation and each no longer than the wrap width. We then join this list of lines into a single string using newline as the separator.\n\nheld as a datetime.date object;we have forced str.format() The incident date is to use the string representation when writing the date—this very conve- niently produces the date in ISO 8601, YYYY-MM-DD format. We have told str.format() to write the midair bool as an integer—this produces 1 for True and 0 for False.In general,using str.format() makeswriting text very easy be- cause it handles all of Python’s data types (and custom types if we implement the __str__() or __format__() special method) automatically.\n\nWriting and Parsing Text Files\n\n307\n\nParsing Text\n\n||\n\nThe method for reading and parsing text format aircraft incident records is longer and more involved than the one used for writing. When reading the ﬁle we could be in one of several states. We could be in the middle of reading narrative lines; we could be at a key=value line; or we could be at a report ID line at the start of a new incident. We will look at the import_text_manual() method in ﬁve parts.\n\ndef import_text_manual(self, filename):\n\nfh = None try:\n\nfh = open(filename, encoding=\"utf8\") self.clear() data = {} narrative = None\n\nThe method begins by opening the ﬁle in “read text” mode. Then we clear the dictionary of incidents and create the data dictionary to hold the data for a single incident in the same way as we did when reading binary incident records. The narrative variable is used for two purposes: as a state indicator and to store the current incident’s narrative text. If narrative is None it means that we are not currently reading a narrative; but if it is a string (even an empty one) it means we are in the process of reading narrative lines.\n\nfor lino, line in enumerate(fh, start=1):\n\nline = line.rstrip() if not line and narrative is None:\n\ncontinue\n\nif narrative is not None:\n\nif line == \".NARRATIVE_END.\":\n\ndata[\"narrative\"] = textwrap.dedent(\n\nnarrative).strip()\n\nif len(data) != 9:\n\nraise IncidentError(\"missing data on \"\n\n\"line {0}\".format(lino))\n\nincident = Incident(**data) self[incident.report_id] = incident data = {} narrative = None\n\nelse:\n\nnarrative += line + \"\\n\"\n\nSince we are reading line by line we can keep track of the current line number and use this to provide more informative error messagesthan is possible when reading binary ﬁles. We begin by stripping off any trailing whitespace from\n\n308\n\nChapter 7. File Handling\n\nthe line, and if this leaves us with an empty line (and providing we are not in the middleof a narrative),we simply skipto the next line. Thismeansthat the number of blank lines between incidents doesn’t matter, but that we preserve any blank lines that are in narrative texts.\n\nIf the narrative is not None we know that we are in a narrative. If the line is the narrative end marker we know that we have not only ﬁnished reading the narrative, but also ﬁnished reading all the data for the current incident. In this case we put the narrative text into the data dictionary (having removed the indentation with the textwrap.dedent() function), and providing we have the nine pieces of data we need, we create a new incident and store it in the dictionary. Then we clear the data dictionary and reset the narrative variable ready for the next record. On the other hand, if the line isn’t the narrative end marker, we append it to the narrative—including the newline that was stripped off at the beginning.\n\nelif (not data and line[0] == \"[\"\n\nand line[-1] == \"]\"):\n\ndata[\"report_id\"] = line[1:-1]\n\nIf the narrative is None then we are at either a new report ID or are reading some other data. We could be at a new report ID only if the data dictionary is empty (because it starts that way and because we clear it after reading each incident), and if the line begins with [ and ends with ]. If this is the case we put the report ID into the data dictionary. This means that this elif condition will not be True again until the data dictionary is next cleared.\n\nelif \"=\" in line:\n\nkey, value = line.split(\"=\", 1) if key == \"date\":\n\ndata[key] = datetime.datetime.strptime(value,\n\n\"%Y-%m-%d\").date()\n\nelif key == \"pilot_percent_hours_on_type\":\n\ndata[key] = float(value) elif key == \"pilot_total_hours\":\n\ndata[key] = int(value)\n\nelif key == \"midair\":\n\ndata[key] = bool(int(value))\n\nelse:\n\ndata[key] = value elif line == \".NARRATIVE_START.\":\n\nnarrative = \"\"\n\nelse:\n\nraise KeyError(\"parsing error on line {0}\".format(\n\nlino))\n\nWriting and Parsing Text Files\n\nIf we are not in a narrative and are not reading a new report ID there are only three more possibilities:We are reading key=valueitems,we are at a narrative start marker, or something has gone wrong.\n\nIn the case of reading a line of key=value data, we split the line on the ﬁrst = character, specifying a maximum of one split—this means that the value can safely include = characters. All the data read is in the form of Unicode strings,so for date,numeric,and Boolean data typeswe must convert thevalue string accordingly.\n\nFor dates we use the datetime.datetime.strptime() function (“string parse time”) which takes a format string and returns a datetime.datetime ob- ject. We have used a format string that matches the ISO 8601 date format, and we use datetime.datetime.date() to retrieve a datetime.date object from the resultant datetime.datetime object, since we want only a date and not a date/time. We rely on Python’s built-in type functions, float() and int(), for the numeric conversions. Note, though that, for example, int(\"4.0\") will raise a ValueError; if we want to be more liberal in accepting integers, we could use int(float(\"4.0\")), or if we wanted to round rather than truncate, round(float(\"4.0\")). To get a bool is slightly subtler—for example, bool(\"0\") returns True (a nonempty string is True), so we must ﬁrst convert the string to an int.\n\nInvalid, missing, or out-of-range values will always cause an exception to be raised. If any of the conversions fail they raise a ValueError exception. And if any values are out of range an IncidentError exception will be raised when the data is used to create a corresponding Incident object.\n\nIf the line doesn’t contain an = character, we check to see whether we’ve read the narrative start marker. If we have, we set the narrative variable to be an empty string. Thismeansthat theﬁrst if condition will be True for subsequent lines, at least until the narrative end marker is read.\n\nIf none of the if or elif conditions is True then an error has occurred,so in the ﬁnal else clause we raise a KeyError exception to signify this.\n\nreturn True\n\nexcept (EnvironmentError, ValueError, KeyError,\n\nIncidentError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nfinally:\n\nif fh is not None: fh.close()\n\nAfter reading all the lines, we return True to the caller—unless an exception occurred, in which case the except block catches the exception, prints an error\n\n309\n\nraw strings 67➤\n\n310\n\nChapter 7. File Handling\n\nmessage for the user, and returns False. And no matter what, if the ﬁle was opened, it is closed at the end.\n\nParsing Text Using Regular Expressions\n\nReaders unfamiliar with regular expressions (“regexes”) are recommended to read Chapter 13 before reading this section—or to skip ahead to the following section (➤ 312), and return here later if desired.\n\nUsing regular expressions to parse text ﬁles can often produce shorter code than doing everything by hand as we did in the previous subsection, but it can be more difﬁcult to provide good error reporting. We will look at the im- port_text_regex() method in two parts,ﬁrst looking at the regular expressions and then at the parsing—but omitting the except and finally blockssince they have nothing new to teach us.\n\ndef import_text_regex(self, filename):\n\nincident_re = re.compile(\n\nr\"\\[(?P<id>[^]]+)\\](?P<keyvalues>.+?)\" r\"^\\.NARRATIVE_START\\.$(?P<narrative>.*?)\" r\"^\\.NARRATIVE_END\\.$\", re.DOTALL|re.MULTILINE) key_value_re = re.compile(r\"^\\s*(?P<key>[^=]+?)\\s*=\\s*\"\n\nr\"(?P<value>.+?)\\s*$\", re.MULTILINE)\n\nThe regular expressions are written as raw strings. This saves us from hav- ing to double each backslash (writing each \\ as \\\\)—for example, without us- ing raw strings the second regular expression would have to be written as \"^\\\\s*(?P<key>[^=]+?)\\\\s*=\\\\s*(?P<value>.+?)\\\\s*$\". In this book we always use raw strings for regular expressions.\n\nThe ﬁrst regular expression, incident_re, is used to capture an entire inci- dent record. One effect of this is that any spurious text between records will not be noticed. This regular expression really has two parts. The ﬁrst is \\[(?P<id>[^]]+)\\](?P<keyvalues>.+?) which matchesa [,then matchesand cap- tures into the id match group as many non-] characters as it can, then match- es a ] (so this gives us the report ID), and then matches as few—but at least one—of any characters(including newlines because of the re.DOTALL ﬂag),into the keyvalues match group. The characters matched for the keyvalues match group are the minimum necessary to take us to the second part of the regular expression.\n\nThe second part of the ﬁrst regular expression is ^\\.NARRATIVE_START\\.$ (?P<narrative>.*?)^\\.NARRATIVE_END\\.$ and this matches the literal text .NAR- RATIVE_START., then as few characters as possible which are captured into the narrative match group, and then the literal text .NARRATIVE_END., at the end of\n\n||",
      "page_number": 292
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 302-312)",
      "start_page": 302,
      "end_page": 312,
      "detection_method": "topic_boundary",
      "content": "Writing and Parsing Text Files\n\nthe incident record. The re.MULTILINE ﬂag means that in this regular expres- sion ^ matches at the start of every line (rather than just at the start of the string), and $ matches at the end of every line (rather than just at the end of the string), so the narrative start and end markers are matched only at the start of lines.\n\nThe second regular expression,key_value_re,isused to capturekey=valuelines, and it matchesat the start of every line in the text it is given to match against, where the line begins with any amount of whitespace (including none), fol- lowed by non-= characters which are captured into the key match group, fol- lowed by an = character, followed by all the remaining characters in the line (excluding any leading or trailing whitespace),and capturesthemintothe val- ue match group.\n\nThe fundamental logic used to parse the ﬁle is the same as we used for the manual text parser that we covered in the previous subsection, only this time we extract incident records and incident data within those records using regular expressions rather than reading line by line.\n\nfh = None try:\n\nfh = open(filename, encoding=\"utf8\") self.clear() for incident_match in incident_re.finditer(fh.read()):\n\ndata = {} data[\"report_id\"] = incident_match.group(\"id\") data[\"narrative\"] = textwrap.dedent(\n\nincident_match.group(\"narrative\")).strip()\n\nkeyvalues = incident_match.group(\"keyvalues\") for match in key_value_re.finditer(keyvalues):\n\ndata[match.group(\"key\")] = match.group(\"value\")\n\ndata[\"date\"] = datetime.datetime.strptime(\n\ndata[\"date\"], \"%Y-%m-%d\").date()\n\ndata[\"pilot_percent_hours_on_type\"] = (\n\nfloat(data[\"pilot_percent_hours_on_type\"]))\n\ndata[\"pilot_total_hours\"] = int(\n\ndata[\"pilot_total_hours\"]) data[\"midair\"] = bool(int(data[\"midair\"])) if len(data) != 9:\n\nraise IncidentError(\"missing data\")\n\nincident = Incident(**data) self[incident.report_id] = incident\n\nreturn True\n\nThe re.finditer() method returns an iterator which produces each nonover- lapping match in turn. We create a data dictionary to hold one incident’s data as we have done before, but this time we get the report ID and narrative text\n\n311\n\n312\n\nChapter 7. File Handling\n\nfrom each match of the incident_re regular expression. We then extract all the key=value strings in one go using the keyvalues match group, and apply the key_value_re regular expression’sre.finditer() methodto iterateover each individual key=valueline. For each (key,value) pair found,we put them in the data dictionary—soall the valuesgo in asstrings. Then,for those valueswhich should not be strings, we replace them with a value of the appropriate type using the same string conversions that we used when parsing the text manu- ally.\n\nWe have added a check to ensure that the data dictionary has nine items be- cause if an incident record is corrupt, the key_value.finditer() iterator might match too many or too few key=valuelines. The end is the same as before—we create a new Incident object and put it in the incidents dictionary, then return True. If anything went wrong, the except suite will issue a suitable error mes- sage and return False, and the finally suite will close the ﬁle.\n\nOne of the things that makes both the manual and the regular expression text parsers as short and straightforward as they are is Python’s exception- handling. The parsers don’t have to check any of the conversions of strings to dates,numbers,or Booleans,and they don’t have to do any range checking (the Incident classdoesthat).If any of these thingsfail,an exception will be raised, and we handle all the exceptions neatly in one place at the end. Another ben- eﬁt of using exception-handling rather than explicit checking is that the code scales well—even if the record format changes to include more data items, the error handling code doesn’t need to grow any larger.\n\nWriting and Parsing XML Files\n\n|||\n\nSome programs use an XML ﬁle format for all the data they handle, whereas others use XML as a convenient import/export format. The ability to import and export XML is useful and is always worth considering even if a program’s main format is a text or binary format.\n\nOut of the box, Python offers three ways of writing XML ﬁles: manually writ- ing the XML, creating an element tree and using its write() method, and cre- ating a DOM and using its write() method. Similarly,for reading and parsing XML ﬁles there are four out-of-the-box approaches that can be used:manually reading and parsing the XML (not recommended and not covered here—it can be quite difﬁcult to handle some of the more obscure and advanced details cor- rectly), or using an element tree, DOM, or SAX parser. In addition, there are also third-party XML librariesavailable,such asthe lxml library mentioned in Chapter 5 (227 ➤), that are well worth investigating.\n\nThe aircraftincident XML format isshown in Figure 7.5.In thissection we will show how to write this format manually and how to write it using an element treeanda DOM,aswellashowtoread andparsethisformatusing theelement\n\nWriting and Parsing XML Files\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?> <incidents> <incident report_id=\"20070222008099G\" date=\"2007-02-22\" aircraft_id=\"80342\" aircraft_type=\"CE-172-M\" pilot_percent_hours_on_type=\"9.09090909091\" pilot_total_hours=\"440\" midair=\"0\"> <airport>BOWERMAN</airport> <narrative> ON A GO-AROUND FROM A NIGHT CROSSWIND LANDING ATTEMPT THE AIRCRAFT HIT A RUNWAY EDGE LIGHT DAMAGING ONE PROPELLER. </narrative> </incident> <incident> ... </incident> : </incidents>\n\nFigure 7.5 An example XML format aircraft incident record in context\n\ntree, DOM, and SAX parsers. If you don’t care which approach is used to read or write the XML, you could just read the Element Trees subsection that follows, and then skip to the chapter’s ﬁnal section (Random Access Binary Files; ➤ 324).\n\nElement Trees\n\nWriting the data using an element tree is done in two phases:First an element tree representing the data must be created, and second the tree must be written to a ﬁle. Some programs might use the element tree as their data structure, in which case they already have the tree and can simply write out the data. We will look at the export_xml_etree() method in two parts:\n\ndef export_xml_etree(self, filename):\n\nroot = xml.etree.ElementTree.Element(\"incidents\") for incident in self.values():\n\nelement = xml.etree.ElementTree.Element(\"incident\",\n\nreport_id=incident.report_id, date=incident.date.isoformat(), aircraft_id=incident.aircraft_id, aircraft_type=incident.aircraft_type, pilot_percent_hours_on_type=str(\n\nincident.pilot_percent_hours_on_type),\n\npilot_total_hours=str(incident.pilot_total_hours),\n\n313\n\n||\n\n314\n\nChapter 7. File Handling\n\nmidair=str(int(incident.midair)))\n\nairport = xml.etree.ElementTree.SubElement(element,\n\n\"airport\")\n\nairport.text = incident.airport.strip() narrative = xml.etree.ElementTree.SubElement(element,\n\n\"narrative\")\n\nnarrative.text = incident.narrative.strip() root.append(element)\n\ntree = xml.etree.ElementTree.ElementTree(root)\n\nWe begin by creating the root element (<incidents>). Then we iterate over all theincident records. For each onewe createan element (<incident>)tohold the data for theincident,andusekeywordargumentstoprovidetheattributes. All the attributes must be text, so we convert the date, numeric,and Boolean data items accordingly. We don’t have to worry about escaping “&”, “<”, and “>” (or about quotesin attributevalues),since the element tree module (and the DOM and SAX modules) automatically take care of these details.\n\nEach <incident> has two subelements, one holding the airport name and the other the narrative text. When subelements are created we must provide the parent element and the tag name. An element’s read/write text attribute is used to hold its text.\n\nOnce the <incident> has been created with all its attributes and its <airport> and <narrative> subelements, we add the incident to the hierarchy’s root (<in- cidents>)element. Attheendwehavea hierarchy of elementsthatcontainsall the incident record data, which we then trivially convert into an element tree.\n\ntry:\n\ntree.write(filename, \"UTF-8\")\n\nexcept EnvironmentError as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nreturn True\n\nWriting the XML to represent an entire element tree is simply a matter of telling the tree to write itself to the given ﬁle using the given encoding.\n\nUp to now when we have speciﬁed an encoding we have almost always used the string \"utf8\". This works ﬁne for Python’s built-in open() function which can accept a wide range of encodings and a variety of names for them, such as “UTF-8”, “UTF8”, “utf-8”, and “utf8”.But for XML ﬁles the encoding name can be only one of the ofﬁcial names, so \"utf8\" is not acceptable, which is why we have used \"UTF-8\".★\n\n★ See www.w3.org/TR/2006/REC-xml11-20060816/#NT-EncodingDecl and www.iana.org/assignments/char- acter-sets for information about XML encodings.\n\nWriting and Parsing XML Files\n\nReading an XML ﬁle using an element tree is not much harder than writing one. Again there are two phases: First we read and parse the XML ﬁle, and then we traverse the resultant element tree to read off the data to populate the incidents dictionary. Again this second phase is not necessary if the el- ement tree itself is being used as the in-memory data store. Here is the im- port_xml_etree() method, split into two parts.\n\ndef import_xml_etree(self, filename):\n\ntry:\n\ntree = xml.etree.ElementTree.parse(filename)\n\nexcept (EnvironmentError,\n\nxml.parsers.expat.ExpatError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nBy default,the element tree parser uses the expat XML parser under the hood which is why we must be ready to catch expat exceptions.\n\nself.clear() for element in tree.findall(\"incident\"):\n\ntry:\n\ndata = {} for attribute in (\"report_id\", \"date\", \"aircraft_id\",\n\n\"aircraft_type\", \"pilot_percent_hours_on_type\", \"pilot_total_hours\", \"midair\"): data[attribute] = element.get(attribute)\n\ndata[\"date\"] = datetime.datetime.strptime(\n\ndata[\"date\"], \"%Y-%m-%d\").date()\n\ndata[\"pilot_percent_hours_on_type\"] = (\n\nfloat(data[\"pilot_percent_hours_on_type\"]))\n\ndata[\"pilot_total_hours\"] = int(\n\ndata[\"pilot_total_hours\"]) data[\"midair\"] = bool(int(data[\"midair\"])) data[\"airport\"] = element.find(\"airport\").text.strip() narrative = element.find(\"narrative\").text data[\"narrative\"] = (narrative.strip()\n\nif narrative is not None else \"\")\n\nincident = Incident(**data) self[incident.report_id] = incident\n\nexcept (ValueError, LookupError, IncidentError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nreturn True\n\n315\n\n316\n\nChapter 7. File Handling\n\nOnce we have the element tree we can iterate over every <incident> using the xml.etree.ElementTree.findall() method. Each incident is returned as an xml.etree.Element object. We use the same technique for handling the element attributesaswedid in theprevioussection’simport_text_regex() method—ﬁrst we store all the values in the data dictionary, and then we convert those val- ues which are dates, numbers, or Booleans to the correct type. For the airport and narrative subelements we use the xml.etree.Element.find() method to ﬁnd them and read their text attributes. If a text element has no text its text attribute will be None, so we must account for this when reading the narrative text element since it might be empty. In all cases, the attribute values and text returned to us do not contain XML escapes since they are automatically unescaped.\n\nAs with all the XML parsers used to process aircraft incident data, an excep- tion will occur if the aircraft or narrative element is missing, or if one of the attributesis missing,or if one of the conversionsfails,or if any of the numeric data is out of range—this ensures that invalid data will cause parsing to stop andforanerrormessagetobeoutput. Thecodeattheendforcreatingandstor- ing incidents and for handling exceptions is the same as we have seen before.\n\nDOM (Document Object Model)\n\nThe DOM is a standard API for representing and manipulating an XML document in memory. The code for creating a DOM and writing it to a ﬁle, and for parsing an XML ﬁle using a DOM, is structurally very similar to the element tree code, only slightly longer.\n\nWe will begin by reviewing the export_xml_dom() method in two parts. This method works in two phases: First a DOM is created to reﬂect the incident data, and then the DOM is written out to a ﬁle. Just as with an element tree, some programsmight use the DOM as their data structure,in which case they can simply write out the data.\n\ndef export_xml_dom(self, filename):\n\ndom = xml.dom.minidom.getDOMImplementation() tree = dom.createDocument(None, \"incidents\", None) root = tree.documentElement for incident in self.values():\n\nelement = tree.createElement(\"incident\") for attribute, value in (\n\n(\"report_id\", incident.report_id), (\"date\", incident.date.isoformat()), (\"aircraft_id\", incident.aircraft_id), (\"aircraft_type\", incident.aircraft_type), (\"pilot_percent_hours_on_type\",\n\nstr(incident.pilot_percent_hours_on_type)),\n\n||\n\nXML encod- ing 314➤\n\nWriting and Parsing XML Files\n\n(\"pilot_total_hours\",\n\nstr(incident.pilot_total_hours)),\n\n(\"midair\", str(int(incident.midair)))):\n\nelement.setAttribute(attribute, value)\n\nfor name, text in ((\"airport\", incident.airport),\n\n(\"narrative\", incident.narrative)):\n\ntext_element = tree.createTextNode(text) name_element = tree.createElement(name) name_element.appendChild(text_element) element.appendChild(name_element)\n\nroot.appendChild(element)\n\nThe method begins by getting a DOM implementation. By default, the imple- mentation is provided by the expat XML parser. The xml.dom.minidom module provides a simpler and smaller DOM implementation than that provided by the xml.dom module, although the objects it uses are from the xml.dom module. Once we have a DOM implementation we can create a document. The ﬁrst ar- gument to xml.dom.DOMImplementation.createDocument() is the namespace URI which we don’t need, so we pass None; the second argument is a qualiﬁed name (the tag name for the root element), and the third argument is the document type, and again we pass None since we don’t have a document type. Having gotten the tree that representsthe document,we retrieve the root element and then proceed to iterate over all the incidents.\n\nFor each incident we create an <incident> element, and for each attribute we want the incident to have we call setAttribute() with the attribute’sname and value. Just as with the element tree, we don’t have to worry about escaping “&”, “<”, and “>” (or about quotes in attribute values). For the airport and nar- rative text elements we must create a text element to hold the text and a nor- mal element (with the appropriatetag name) as the text element’sparent—we then add the normal element (and the text element it contains) to the current incident element. With the incident element complete, we add it to the root.\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") tree.writexml(fh, encoding=\"UTF-8\") return True\n\nWe have omitted the except and finally blocks since they are the same as ones we have already seen. What this piece of code makes clear is the difference between the encoding string used for the built-in open() function and the encoding string used for XML ﬁles, as we discussed earlier.\n\nImporting an XML document into a DOM is similar to importing into an el- ement tree, but like exporting, it requires more code. We will look at the im-\n\n317\n\n318\n\nChapter 7. File Handling\n\nport_xml_dom() function in threeparts,starting with the def line and thenested get_text() function.\n\ndef import_xml_dom(self, filename):\n\ndef get_text(node_list):\n\ntext = [] for node in node_list:\n\nif node.nodeType == node.TEXT_NODE:\n\ntext.append(node.data)\n\nreturn \"\".join(text).strip()\n\nThe get_text() function iterates over a list of nodes (e.g., a node’s child nodes), and for each one that is a text node, it extracts the node’s text and appends it to a list of texts. At the end the function returns all the text it has gathered as a single string, with whitespace stripped from both ends.\n\ntry:\n\ndom = xml.dom.minidom.parse(filename)\n\nexcept (EnvironmentError,\n\nxml.parsers.expat.ExpatError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nParsing anXMLﬁleintoa DOMiseasy sincethemoduledoesallthehardwork for us, but we must be ready to handle expat errors since just like an element tree, the expat XML parser is the default parser used by the DOM classes under the hood.\n\nself.clear() for element in dom.getElementsByTagName(\"incident\"):\n\ntry:\n\ndata = {} for attribute in (\"report_id\", \"date\", \"aircraft_id\",\n\n\"aircraft_type\", \"pilot_percent_hours_on_type\", \"pilot_total_hours\", \"midair\"):\n\ndata[attribute] = element.getAttribute(attribute)\n\ndata[\"date\"] = datetime.datetime.strptime(\n\ndata[\"date\"], \"%Y-%m-%d\").date()\n\ndata[\"pilot_percent_hours_on_type\"] = (\n\nfloat(data[\"pilot_percent_hours_on_type\"]))\n\ndata[\"pilot_total_hours\"] = int(\n\ndata[\"pilot_total_hours\"]) data[\"midair\"] = bool(int(data[\"midair\"])) airport = element.getElementsByTagName(\"airport\")[0]\n\nWriting and Parsing XML Files\n\ndata[\"airport\"] = get_text(airport.childNodes) narrative = element.getElementsByTagName(\n\n\"narrative\")[0]\n\ndata[\"narrative\"] = get_text(narrative.childNodes) incident = Incident(**data) self[incident.report_id] = incident\n\nexcept (ValueError, LookupError, IncidentError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nreturn True\n\nOnce the DOM exists we clear the current incidents data and iterate over all the incident tags. For each one we extract the attributes,and for date, numer- ic, and Booleans we convert them to the correct types in exactly the same way as we did when using an element tree. The only really signiﬁcant difference between using a DOM and an element tree is in the handling of text nodes. We use the xml.dom.Element.getElementsByTagName() method to get the child el- ements with the given tag name—in the cases of <airport> and <narrative> we know there is always one of each, so we take the ﬁrst (and only) child element of each type. Then we use the nested get_text() function to iterate over these tags’ child nodes to extract their texts.\n\nAs usual, if any error occurs we catch the relevant exception, print an error message for the user, and return False.\n\nThe differences in approach between DOM and element tree are not great, and since they both use the same expat parser under the hood, they’re both reasonably fast.\n\nManually Writing XML\n\nWriting a preexisting element tree or DOM as an XML document can be done with a single method call. But if our data is not already in one of these forms we must create an element tree or DOM ﬁrst, in which case it may be more convenient to simply write out our data directly.\n\nWhen writing XML ﬁles we must make sure that we properly escape text and attribute values, and that we write a well-formed XML document. Here is the export_xml_manual() method for writing out the incidents in XML:\n\ndef export_xml_manual(self, filename):\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") fh.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n') fh.write(\"<incidents>\\n\")\n\n319\n\n||\n\nLocal func- tions ➤ 351\n\n320\n\nChapter 7. File Handling\n\nfor incident in self.values():\n\nfh.write('<incident report_id={report_id} '\n\n'date=\"{0.date!s}\" ' 'aircraft_id={aircraft_id} ' 'aircraft_type={aircraft_type} ' 'pilot_percent_hours_on_type=' '\"{0.pilot_percent_hours_on_type}\" ' 'pilot_total_hours=\"{0.pilot_total_hours}\" ' 'midair=\"{0.midair:d}\">\\n' '<airport>{airport}</airport>\\n' '<narrative>\\n{narrative}\\n</narrative>\\n' '</incident>\\n'.format(incident, report_id=xml.sax.saxutils.quoteattr(\n\nincident.report_id),\n\naircraft_id=xml.sax.saxutils.quoteattr(\n\nincident.aircraft_id),\n\naircraft_type=xml.sax.saxutils.quoteattr(\n\nincident.aircraft_type),\n\nairport=xml.sax.saxutils.escape(incident.airport), narrative=\"\\n\".join(textwrap.wrap(\n\nxml.sax.saxutils.escape(\n\nincident.narrative.strip()), 70))))\n\nfh.write(\"</incidents>\\n\") return True\n\nAs we have often done in this chapter, we have omitted the except and finally blocks.\n\nWe writetheﬁle using theUTF-8encoding and must specify thisto thebuilt-in open() function. Strictly speaking,we don’t have to specify the encoding in the <?xml?> declaration since UTF-8 is the default encoding, but we prefer to be explicit. We have chosen to quote all the attribute values using double quotes (\"), and so for convenience have used single quotes to quote the string we put the incidents in to avoid the need to escape the quotes.\n\nThe sax.saxutils.quoteattr() function is similar to the sax.saxutils.escape() function we use for XML text in that it properly escapes “&”, “<”, and “>” characters. In addition, it escapes quotes (if necessary), and returns a string that has quotes around it ready for use. This is why we have not needed to put quotes around the report ID and other string attribute values.\n\nThe newlines we have inserted and the text wrapping for the narrative are purely cosmetic. They are designed to make the ﬁle easier for humans to read and edit, but they could just as easily be omitted.\n\nWriting thedata in HTMLformatisnot much differentfromwriting XML.The convert-incidents.py program includes the export_html() function as a simple\n\nWriting and Parsing XML Files\n\nexampleof this,althoughwewon’treviewit herebecauseit doesn’treally show anything new.\n\nParsing XML with SAX (Simple API for XML)\n\nUnlike the element tree and DOM, which represent an entire XML document in memory, SAX parsers work incrementally, which can potentially be both faster and lessmemory-hungry. A performanceadvantagecannot be assumed, however, especially since both the element tree and DOM use the fast expat parser.\n\nSAX parsers work by announcing “parsing events” when they encounter start tags, end tags, and other XML elements. To be able to handle those events that we are interested in we must create a suitable handler class, and provide certain predeﬁned methods which are called when matching parsing events take place. The most commonly implemented handler is a content handler, although it is possible to provide error handlers and other handlers if we want ﬁner control.\n\nHere is the complete import_xml_sax() method. It is very short because most of the work is done by the custom IncidentSaxHandler class:\n\ndef import_xml_sax(self, filename):\n\nfh = None try:\n\nhandler = IncidentSaxHandler(self) parser = xml.sax.make_parser() parser.setContentHandler(handler) parser.parse(filename) return True\n\nexcept (EnvironmentError, ValueError, IncidentError,\n\nxml.sax.SAXParseException) as err: print(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nWe createthe one handler we want to use and then we createa SAX parser and setitscontenthandlertobetheonewehavecreated. Thenwegivetheﬁlename to the parser’s parse() method and return True if no parsing errors occurred.\n\nWe pass self (i.e., this IncidentCollection dict subclass) to the custom Inci- dentSaxHandler class’sinitializer. Thehandlerclearstheoldincidentsaway and then builds up a dictionary of incidents as the ﬁle is parsed. Once the parse is complete the dictionary contains all the incidents that have been read.\n\n321\n\n||",
      "page_number": 302
    },
    {
      "number": 33,
      "title": "Segment 33 (pages 313-329)",
      "start_page": 313,
      "end_page": 329,
      "detection_method": "topic_boundary",
      "content": "322\n\nChapter 7. File Handling\n\nclass IncidentSaxHandler(xml.sax.handler.ContentHandler):\n\ndef __init__(self, incidents):\n\nsuper().__init__() self.__data = {} self.__text = \"\" self.__incidents = incidents self.__incidents.clear()\n\nCustom SAX handler classes must inherit the appropriate base class. This ensures that for any methods we don’t reimplement (because we are not interested in the parsing events they handle), the base class version will be called—and will safely do nothing.\n\nWe start by calling the base class’s initializer. This is generally good practice for all subclasses,although it is not necessary (though harmless) for direct ob- ject subclasses. The self.__data dictionary is used to keep one incident’sdata, the self.__text string is used to keep the text of an airport name or of a nar- rative depending on which we are reading,and the self.__incidents dictionary is an object reference to the IncidentCollection dictionary which the handler updates directly. (An alternative design would be to have an independent dic- tionary inside the handler and to copy it to the IncidentCollection at the end using dict.clear() and then dict.update().)\n\ndef startElement(self, name, attributes):\n\nif name == \"incident\":\n\nself.__data = {} for key, value in attributes.items():\n\nif key == \"date\":\n\nself.__data[key] = datetime.datetime.strptime(\n\nvalue, \"%Y-%m-%d\").date()\n\nelif key == \"pilot_percent_hours_on_type\":\n\nself.__data[key] = float(value)\n\nelif key == \"pilot_total_hours\":\n\nself.__data[key] = int(value)\n\nelif key == \"midair\":\n\nself.__data[key] = bool(int(value))\n\nelse:\n\nself.__data[key] = value\n\nself.__text = \"\"\n\nWhenever a start tag and its attributes are read the xml.sax.handler.Content- Handler.startElement() method is called with the tag name and the tag’s attributes. In the case of an aircraft incidents XML ﬁle, the start tags are <incidents>, which we ignore; <incident>, whose attributes we use to populate some of the self.__data dictionary; and <airport> and <narrative>, both of\n\nWriting and Parsing XML Files\n\nwhich we ignore. We always clear the self.__text string when we get a start tag because no text tags are nested in the aircraft incident XML ﬁle format.\n\nWe don’t do any exception-handling in the IncidentSaxHandler class. If an ex- ception occursit will be passedupto thecaller,in thiscasethe import_xml_sax() method, which will catch it and output a suitable error message.\n\ndef endElement(self, name):\n\nif name == \"incident\":\n\nif len(self.__data) != 9:\n\nraise IncidentError(\"missing data\")\n\nincident = Incident(**self.__data) self.__incidents[incident.report_id] = incident\n\nelif name in frozenset({\"airport\", \"narrative\"}):\n\nself.__data[name] = self.__text.strip()\n\nself.__text = \"\"\n\nWhen an end tag is read the xml.sax.handler.ContentHandler.endElement() method is called. If we have reached the end of an incident we should have all the necessary data, so we create a new Incident object and add it to the incidents dictionary. If we have reached the end of a text element, we add an item to the self.__data dictionary with the text that has been accumulated so far. At the end we clear the self.__text string ready for its next use. (Strictly speaking,we don’t have to clear it,since we clear it when we get a start tag,but clearing it could make a difference in some XML formats, for example, where tags can be nested.)\n\ndef characters(self, text): self.__text += text\n\nWhen the SAX parser reads text it calls the xml.sax.handler.ContentHand- ler.characters() method. Thereisnoguaranteethat thismethodwill becalled just once with all the text; the text might come in chunks. This is why we simply use the method to accumulate text, and actually put the text into the dictionary only when the relevant end tag is reached. (A more efﬁcient imple- mentation would have self.__text be a list with the body of this method being self.__text.append(text), and with the other methods adapted accordingly.)\n\nUsing the SAX API is very different from using element tree or DOM, but it is just as effective. We can provide other handlers, and can reimplement additional methods in the content handler to get as much control as we like. The SAX parser itself does not maintain any representation of the XML document—this makes SAX ideal for reading XML into our own custom data collections, and also means that there is no SAX “document” to write out as XML, so for writing XML we must use one of the approaches described earlier in this section.\n\n323\n\n324\n\nChapter 7. File Handling\n\nRandom Access Binary Files\n\n|||\n\nIn the earlier sections we worked on the basis that all of a program’s data was read into memory in one go, processed, and then all written out in one go. Modern computers have so much RAM that this is a perfectly viable approach, even for large data sets. However, in some situations holding the data on disk and just reading the bits we need and writing back changes might be a better solution. The disk-based random access approach is most easily done using a key–value database (a “DBM”), or a full SQL database—both are covered in Chapter 12—but in thissection we will show how to handle random accessﬁles by hand.\n\nWe will ﬁrst present the BinaryRecordFile.BinaryRecordFile class. Instances of this class represent a generic readable/writable binary ﬁle, structured as a sequence of ﬁxed length records. We will then look at the BikeStock.BikeStock class which holds a collection of BikeStock.Bike objects as records in a Bina- ryRecordFile.BinaryRecordFile to see how to make use of binary random ac- cess ﬁles.\n\nA Generic BinaryRecordFile Class\n\n||\n\nThe BinaryRecordFile.BinaryRecordFile class’sAPI is similar to a list in that we canget/set/deletearecordatagivenindexposition. Whenarecordisdeleted,it issimply marked“deleted”;thissaveshaving tomovealltherecordsthatfollow it up to ﬁll the gap, and also means that after a deletion all the original index positions remain valid. Another beneﬁt is that a record can be undeleted sim- ply by unmarking it. The price we pay for this is that deleting records doesn’t save any disk space. We will solve this by providing methods to “compact” the ﬁle, eliminating deleted records (and invalidating index positions).\n\nBefore reviewing the implementation, let’s look at some basic usage:\n\nContact = struct.Struct(\"<15si\") contacts = BinaryRecordFile.BinaryRecordFile(filename, Contact.size)\n\nHere we create a struct (little-endian byte order, a 15-byte byte string, and a 4-byte signed integer) that we will use to represent each record. Then we create a BinaryRecordFile.BinaryRecordFile instance with a ﬁlename and with a recordsize to match thestruct we are using. If theﬁle existsit will be opened with its contents left intact; otherwise, it will be created. In either case it will be opened in binary read/write mode, and once open, we can write data to it:\n\ncontacts[4] = Contact.pack(\"Abe Baker\".encode(\"utf8\"), 762) contacts[5] = Contact.pack(\"Cindy Dove\".encode(\"utf8\"), 987)\n\nRandom Access Binary Files\n\nTable 7.4 File Object Attributes and Methods #1\n\nSyntax\n\nDescription\n\nf.close()\n\nCloses ﬁle object f and sets attribute f.closed to True\n\nf.closed\n\nf.encoding\n\nReturns True if the ﬁle is closed The encoding used for bytes ↔ str conversions\n\nf.fileno()\n\nReturns the underlying ﬁle’s ﬁle descriptor. (Available only for ﬁle objects that have ﬁle descriptors.)\n\nf.flush()\n\nFlushes the ﬁle object f\n\nf.isatty()\n\nReturns True if the ﬁle object is associated with a console. (Available only for ﬁle objects that refer to actual ﬁles.)\n\nf.mode\n\nThe mode ﬁle object f was opened with\n\nf.name\n\nFile object f’s ﬁlename (if it has one)\n\nf.newlines\n\nThe kinds of newline strings encountered in text ﬁle f\n\nf.__next__()\n\nReturns the next line from ﬁle object f. In most cases, this method is used implicitly, for example, for line in f.\n\nf.peek(n)\n\nReturns n bytes without moving the ﬁle pointer position\n\nf.read(count) Reads at most count bytes from ﬁle object f. If count is not speciﬁed then every byte is read from the current ﬁle posi- tion to the end. Returns a bytes object when reading in bi- nary mode and a str when reading in text mode. If there is no more to read (end of ﬁle), an empty bytes or str is returned. Returns True if f was opened for reading\n\nf.readable()\n\nf.readinto( ba)\n\nReads at most len(ba) bytes into bytearray ba and returns the number of bytesread—thisis0at end of ﬁle. (Available only in binary mode.)\n\nf.readline(\n\ncount)\n\nReads the next line (or up to count bytes if count is speciﬁed and reached before the \\n character), including the \\n\n\nf.readlines(\n\nsizehint)\n\nReads all the lines to the end of the ﬁle and returnsthem as a list. If sizehint is given, then reads approximately up to sizehint bytes if the underlying ﬁle object supports this.\n\nf.seek(\n\noffset, whence)\n\nMovesthe ﬁle pointer position (wherethe next read or write will take place) to the given offset if whence is not given or is os.SEEK_SET.Movesthe ﬁle pointer to the given offset (which may be negative) relative to the current position if whence is os.SEEK_CUR or relative to the end if whence is os.SEEK_END. Writes are always done at the end in append \"a\" mode no matter where the ﬁle pointer is. In text mode only the re- turn value of tell() method calls should be used as offsets.\n\n325\n\n326\n\nChapter 7. File Handling\n\nTable 7.5 File Object Attributes and Methods #2\n\nSyntax\n\nDescription\n\nf.seekable()\n\nReturns True if f supports random access\n\nf.tell()\n\nf.truncate(\n\nsize)\n\nReturnsthecurrent ﬁle pointer position relativeto thestart of the ﬁle Truncates the ﬁle to the current ﬁle pointer position, or to the given size if size is speciﬁed\n\nf.writable()\n\nReturns True if f was opened for writing\n\nf.write(s)\n\nWrites bytes/bytearray object s to the ﬁle if opened in binary mode or a str object s to the ﬁle if opened in text mode\n\nf.writelines( seq)\n\nWrites the sequence of objects (strings for text ﬁles, byte strings for binary ﬁles) to the ﬁle\n\nWe can treat the ﬁle like a list using the item access operator ([]); here we assign two byte strings (bytes objects, each containing an encoded string and an integer) at two record index positions in the ﬁle. These assignments will overwrite any existing content;and if the ﬁle doesn’t already have six records, the earlier records will be created with every byte set to 0x00.\n\ncontact_data = Contact.unpack(contacts[5]) contact_data[0].decode(\"utf8\").rstrip(chr(0)) # returns: 'Cindy Dove'\n\nSince the string “Cindy Dove” is shorter than the 15 UTF-8 characters in the struct, when it is packed it is padded with 0x00 bytes at the end. So when we retrieve the record, the contact_data will hold the 2-tuple (b'Cindy Dove\\x00\\x00\\x00\\x00\\x00', 987).To get the name,we must decode the UTF-8 to produce a Unicode string, and strip off the 0x00 padding bytes.\n\nNow that we’ve had a glimpse of the class in action, we are ready to review the code. The BinaryRecordFile.BinaryRecordFile class is in ﬁle BinaryRecord- File.py. After the usual preliminaries the ﬁle begins with the deﬁnitions of a couple of private byte values:\n\n_DELETED = b\"\\x01\" _OKAY = b\"\\x02\"\n\nEach record starts with a “state” byte which is either _DELETED or _OKAY (or b\"\\x00\" in the case of blank records).\n\nHere is the class line and the initializer:\n\nclass BinaryRecordFile:\n\ndef __init__(self, filename, record_size, auto_flush=True):\n\nself.__record_size = record_size + 1\n\nRandom Access Binary Files\n\nmode = \"w+b\" if not os.path.exists(filename) else \"r+b\" self.__fh = open(filename, mode) self.auto_flush = auto_flush\n\nThere are two different record sizes. The BinaryRecordFile.record_size is the one set by the user and is the record size from the user’s point of view. The private BinaryRecordFile.__record_size is the real record size and includes the state byte.\n\nWe are careful not to truncate the ﬁle when we open it if it already exists (by using a mode of \"r+b\"), and to create it if it does not exist (by using a mode of \"w+b\")—the \"+\" partof themodestring iswhatsigniﬁesreading andwriting. If the BinaryRecordFile.auto_flush Boolean is True, the ﬁle is ﬂushed before every read and after every write.\n\n@property def record_size(self):\n\nreturn self.__record_size - 1\n\n@property def name(self):\n\nreturn self.__fh.name\n\ndef flush(self):\n\nself.__fh.flush()\n\ndef close(self):\n\nself.__fh.close()\n\nWe have made the record size and ﬁlename into read-only properties. The record size we report to the user is the one they requested and matches their records. The ﬂush and close methods simply delegate to the ﬁle object.\n\ndef __setitem__(self, index, record):\n\nassert isinstance(record, (bytes, bytearray)), \\\n\n\"binary data required\"\n\nassert len(record) == self.record_size, (\n\n\"record must be exactly {0} bytes\".format( self.record_size))\n\nself.__fh.seek(index * self.__record_size) self.__fh.write(_OKAY) self.__fh.write(record) if self.auto_flush:\n\nself.__fh.flush()\n\nThis method supportsthe brf[i] =data syntax where brf is a binary record ﬁle, i a record index position, and data a byte string. Notice that the record must be the same size asthe size isspeciﬁed when the binary record ﬁle wascreated.\n\n327\n\n328\n\nChapter 7. File Handling\n\nIf the arguments are okay, we move the ﬁle position pointer to the ﬁrst byte of the record—notice that here we use the real record size, that is, we account for the state byte. The seek() method moves the ﬁle pointer to an absolute byte position by default. A second argument can be given to make the movement relative to the current position or to the end. (The attributes and methods provided by ﬁle objects are listed in Tables 7.4 and 7.5.)\n\nSince the item is being set it obviously hasn’t been deleted, so we write the _OKAY state byte, and then we write the user’s binary record data. The binary record ﬁle does not know or care about the record structure that is being used—only that records are of the right size.\n\nWe do not check whether the index is in range. If the index is beyond the end of the ﬁle the record will be written in the correct position and every byte between the previous end of the ﬁle and the new record will automatically be set to b\"\\x00\". Such blank records are neither _OKAY nor _DELETED, so we can distinguish them when we need to.\n\ndef __getitem__(self, index):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY: return None\n\nreturn self.__fh.read(self.record_size)\n\nWhen retrieving a record there are four cases that we must account for: The record doesn’t exist, that is, the given index is beyond the end; the record is blank;the record hasbeen deleted;and the record is okay. If the record doesn’t exist the private __seek_to_index() method will raise an IndexError exception. Otherwise,it will seek to the byte where the record begins and we can read the state byte. If the state is not _OKAY the record must either be blank or be delet- ed,inwhichcasewereturnNone;otherwise,wereadandreturntherecord. (An- otherstrategywouldbetoraiseacustomexceptionforblank ordeletedrecords, say, BlankRecordError or DeletedRecordError, instead of returning None.)\n\ndef __seek_to_index(self, index):\n\nif self.auto_flush:\n\nself.__fh.flush()\n\nself.__fh.seek(0, os.SEEK_END) end = self.__fh.tell() offset = index * self.__record_size if offset >= end:\n\nraise IndexError(\"no record at index position {0}\".format(\n\nindex))\n\nself.__fh.seek(offset)\n\nRandom Access Binary Files\n\nThis is a private supporting method used by some of the other methods to move the ﬁle position pointer to the ﬁrst byte of the record at the given index position. We begin by checking to see whether the given index is in range. We do this by seeking to the end of the ﬁle (byte offset of 0 from the end), and using the tell() method to retrieve the byte position we have seeked to.★ If the record’s offset (index position × real record size) is at or after the end then the index is out of range and we raise a suitable exception. Otherwise, we seek to the offset position ready for the next read or write.\n\ndef __delitem__(self, index):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY:\n\nreturn\n\nself.__fh.seek(index * self.__record_size) self.__fh.write(_DELETED) if self.auto_flush:\n\nself.__fh.flush()\n\nFirst we move the ﬁle position pointer to the right place. If the index is in range (i.e., if no IndexError exception has occurred), and providing the record isn’t blank or already deleted,wedeletetherecordby overwriting itsstatebyte with _DELETED.\n\ndef undelete(self, index):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state == _DELETED:\n\nself.__fh.seek(index * self.__record_size) self.__fh.write(_OKAY) if self.auto_flush:\n\nself.__fh.flush()\n\nreturn True\n\nreturn False\n\nThis method begins by ﬁnding the record and reading its state byte. If the record is deleted we overwrite the state byte with _OKAY and return True to the caller to indicate success; otherwise (for blank or nondeleted records), we return False.\n\ndef __len__(self):\n\nif self.auto_flush:\n\nself.__fh.flush()\n\nself.__fh.seek(0, os.SEEK_END)\n\n★Both convenience, Python 3.1 also has these constants in its io module (e.g., io.SEEK_SET).\n\nPython 3.0 and 3.1 have the seek constants os.SEEK_SET, os.SEEK_CUR, and os.SEEK_END. For\n\n329\n\n3.x\n\n330\n\nChapter 7. File Handling\n\nend = self.__fh.tell() return end // self.__record_size\n\nThis method reports how many records are in the binary record ﬁle. It does this by dividing the end byte position (i.e., how many bytes are in the ﬁle) by the size of a record.\n\nWe have now covered all the basic functionality offered by the BinaryRecord- File.BinaryRecordFile class. There is one last matter to consider: compacting the ﬁle to eliminate blank and deleted records. There are essentially two ap- proaches we can take to this. One approach is to overwrite blank or deleted records with records that have higher record index positions so that there are no gaps,and truncating the ﬁle if there are any blank or deleted recordsat the end. The inplace_compact() method does this. The other approach is to copy the nonblank nondeleted records to a temporary ﬁle and then to rename the temporary to the original. Using a temporary ﬁle is particularly convenient if we also want to make a backup. The compact() method does this.\n\nWe will start by looking at the inplace_compact() method, in two parts.\n\ndef inplace_compact(self):\n\nindex = 0 length = len(self) while index < length:\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY:\n\nfor next in range(index + 1, length):\n\nself.__seek_to_index(next) state = self.__fh.read(1) if state == _OKAY:\n\nself[index] = self[next] del self[next] break\n\nelse:\n\nbreak\n\nindex += 1\n\nWe iterate over every record,reading the state of each one in turn. If we ﬁnd a blank or deleted record we look for the next nonblank nondeleted record in the ﬁle. If we ﬁnd one we replace the blank or deleted record with the nonblank nondeleted one and delete the original nonblank nondeleted one; otherwise, we break out of the while loop entirely since we have run out of nonblank nondeleted records.\n\nself.__seek_to_index(0) state = self.__fh.read(1)\n\nRandom Access Binary Files\n\nif state != _OKAY:\n\nself.__fh.truncate(0)\n\nelse:\n\nlimit = None for index in range(len(self) - 1, 0, -1):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY:\n\nlimit = index\n\nelse:\n\nbreak if limit is not None:\n\nself.__fh.truncate(limit * self.__record_size)\n\nself.__fh.flush()\n\nIf the ﬁrst record is blank or deleted, then they must all be blank or deleted since the previous code moved all nonblank nondeleted records to the begin- ning of the ﬁle and blank and deleted ones to the end. In this case we can sim- ply truncate the ﬁle to 0 bytes.\n\nIf there is at least one nonblank nondeleted record we iterate from the last record backwardtoward the ﬁrst since we know that blank and deleted records have been moved to the end. The limit variable is set to the earliest blank or deleted record (or left as None if there are no blank or deleted records),and the ﬁle is truncated accordingly.\n\nAn alternativetodoing thecompacting in-placeistodoit by copying toanother ﬁle—this is useful if we want to make a backup, as the compact() method that we will review next shows.\n\ndef compact(self, keep_backup=False):\n\ncompactfile = self.__fh.name + \".$$$\" backupfile = self.__fh.name + \".bak\" self.__fh.flush() self.__fh.seek(0) fh = open(compactfile, \"wb\") while True:\n\ndata = self.__fh.read(self.__record_size) if not data: break\n\nif data[:1] == _OKAY: fh.write(data)\n\nfh.close() self.__fh.close()\n\nos.rename(self.__fh.name, backupfile) os.rename(compactfile, self.__fh.name)\n\n331\n\nBytes and bytear- ray sidebar 293➤\n\n332\n\nChapter 7. File Handling\n\nif not keep_backup:\n\nos.remove(backupfile)\n\nself.__fh = open(self.__fh.name, \"r+b\")\n\nThis method creates two ﬁles, a compacted ﬁle and a backup copy of the original ﬁle. The compacted ﬁle starts out with the same name as the original but with .$$$ tackedon to theend of theﬁlename,and similarly thebackupﬁle has the original ﬁlename with .bak tacked on to the end. We read the existing ﬁle record by record, and for those records that are nonblank and nondeleted we write them to the compacted ﬁle. (Notice that we write the real record,that is, the state byte plus the user record, each time.)\n\nThe line if data[:1] == _OKAY: isquite subtle. Both the data object and the _OKAY object are of type bytes. We want to compare the ﬁrst byte of the data object to the (1 byte) _OKAY object. If we take a slice of a bytes object, we get a bytes object,but if we take a single byte,say,data[0],we get an int—the byte’svalue. So here we compare the 1 byte slice of data (its ﬁrst byte, the state byte) with the 1 byte _OKAY object. (Another way of doing it would be to write if data[0] == _OKAY[0]: which would compare the two int values.)\n\nAt theendwerenametheoriginalﬁleasthebackupandrenamethecompacted ﬁle as the original. We then remove the backup if keep_backup is False (the default). Finally, we open the compacted ﬁle (which now has the original ﬁlename), ready to be read or written.\n\nThe BinaryRecordFile.BinaryRecordFile class is quite low-level, but it can serve asthebasisof higher-levelclassesthat need randomaccessto ﬁlesof ﬁxed-size records, as we will see in the next subsection.\n\nExample: The BikeStock Module’s Classes\n\nThe BikeStock module uses a BinaryRecordFile.BinaryRecordFile to provide a simple stock control class. The stock items are bicycles, each represented by a BikeStock.Bike instance, and the entire stock of bikes is held in a Bike- Stock.BikeStock instance. The BikeStock.BikeStock class aggregates a dictio- nary whose keysare bike IDsand whose valuesare record index positions,into a BinaryRecordFile.BinaryRecordFile.Here isa brief exampleof use to get a feel for how these classes work:\n\nbicycles = BikeStock.BikeStock(bike_file) value = 0.0 for bike in bicycles:\n\nvalue += bike.value\n\nbicycles.increase_stock(\"GEKKO\", 2) for bike in bicycles:\n\nif bike.identity.startswith(\"B4U\"):\n\n||\n\nRandom Access Binary Files\n\nif not bicycles.increase_stock(bike.identity, 1):\n\nprint(\"stock movement failed for\", bike.identity)\n\nThis snippet opens a bike stock ﬁle and iterates over all the bicycle records it contains to ﬁnd the total value (sum of price × quantity) of the bikes held. It then increases the number of “GEKKO” bikes in stock by two and increments thestock heldfor allbikeswhosebikeIDbeginswith“B4U”by one. Allof these actions take place on disk, so any other process that reads the bike stock ﬁle will always get the most current data.\n\nAlthough the BinaryRecordFile.BinaryRecordFile works in terms of indexes, the BikeStock.BikeStock class works in terms of bike IDs. This is managed by the BikeStock.BikeStock instance holding a dictionary that relates bike IDs to indexes.\n\nWe will begin by looking at the BikeStock.Bike class’s class line and initializ- er, then we will look at a few selected BikeStock.BikeStock methods, and ﬁnal- ly we will look at the code that provides the bridge between BikeStock.Bike objects and the binary records used to represent them in a BinaryRecord- File.BinaryRecordFile. (All the code is in the BikeStock.py ﬁle.)\n\nclass Bike:\n\ndef __init__(self, identity, name, quantity, price):\n\nassert len(identity) > 3, (\"invalid bike identity '{0}'\"\n\n.format(identity))\n\nself.__identity = identity self.name = name self.quantity = quantity self.price = price\n\nAll of a bike’s attributes are available as properties—the bike ID (self.__iden- tity)astheread-only Bike.identity property and theothersasread/writeprop- ertieswithsomeassertionsforvalidation. Inaddition,theBike.value read-only property returnsthe quantity multiplied by the price. (We have not shown the implementation of the properties since we have seen similar code before.)\n\nThe BikeStock.BikeStock class provides its own methods for manipulating bike objects, and they in turn use the writable bike properties.\n\nclass BikeStock:\n\ndef __init__(self, filename):\n\nself.__file = BinaryRecordFile.BinaryRecordFile(filename,\n\n_BIKE_STRUCT.size)\n\nself.__index_from_identity = {} for index in range(len(self.__file)):\n\nrecord = self.__file[index] if record is not None:\n\n333\n\n334\n\nChapter 7. File Handling\n\nbike = _bike_from_record(record) self.__index_from_identity[bike.identity] = index\n\nThe BikeStock.BikeStock class is a custom collection class that aggregates a binary record ﬁle (self.__file) and a dictionary (self.__index_from_identity) whose keys are bike IDs and whose values are record index positions.\n\nOnce the ﬁle has been opened (and created if it didn’t already exist),we iterate over its contents (if any). Each bike is retrieved and converted from a bytes object to a BikeStock.Bike using the private _bike_from_record() function, and the bike’s identity and index are added to the self.__index_from_identity dic- tionary.\n\ndef append(self, bike):\n\nindex = len(self.__file) self.__file[index] = _record_from_bike(bike) self.__index_from_identity[bike.identity] = index\n\nAppending a new bike is a matter of ﬁnding a suitable index position and setting the record at that position to the bike’s binary representation. We also take care to update the self.__index_from_identity dictionary.\n\ndef __delitem__(self, identity):\n\ndel self.__file[self.__index_from_identity[identity]]\n\nDeleting a bike record is easy; we just ﬁnd its record index position from its identity and delete the record at that index position. In the case of the Bike- Stock.BikeStock class we have not made use of the BinaryRecordFile.Binary- RecordFile’s undeletion capability.\n\ndef __getitem__(self, identity):\n\nrecord = self.__file[self.__index_from_identity[identity]] return None if record is None else _bike_from_record(record)\n\nBike records are retrieved by bike ID. If there is no such ID the lookup in the self.__index_from_identity dictionary will raise a KeyError exception, and if therecordisblank or deletedthe BinaryRecordFile.BinaryRecordFilewillreturn None. But if a record is retrieved we return it as a BikeStock.Bike object.\n\ndef __change_stock(self, identity, amount):\n\nindex = self.__index_from_identity[identity] record = self.__file[index] if record is None:\n\nreturn False\n\nbike = _bike_from_record(record) bike.quantity += amount self.__file[index] = _record_from_bike(bike) return True\n\nRandom Access Binary Files\n\n335\n\nincrease_stock = (lambda self, identity, amount:\n\nself.__change_stock(identity, amount))\n\ndecrease_stock = (lambda self, identity, amount:\n\nself.__change_stock(identity, -amount))\n\nThe private __change_stock() method provides an implementation for the in- crease_stock() and decrease_stock() methods. The bike’s index position is found and the raw binary record is retrieved. Then the data is converted to a BikeStock.Bike object, the change is applied to the bike, and then the record in the ﬁle is overwritten with the binary representation of the updated bike ob- ject. (There is also a __change_bike() method that provides an implementation for the change_name() and change_price() methods,but none of these are shown because they are very similar to what’s shown here.)\n\ndef __iter__(self):\n\nfor index in range(len(self.__file)):\n\nrecord = self.__file[index] if record is not None:\n\nyield _bike_from_record(record)\n\nThismethod ensuresthat BikeStock.BikeStock objectscan be iterated over, just like a list,with a BikeStock.Bike object returned at each iteration,and skipping blank and deleted records.\n\nrecord0\n\nrecord1\n\nrecord2\n\n...\n\nrecordN\n\n8 × UTF-8 encoded bytes\n\n30 × UTF-8 encoded bytes\n\nint32\n\nfloat64\n\nidentity\n\nname\n\nquantity\n\nprice\n\nFigure 7.6 The logical structure of a bike record ﬁle\n\nThe private _bike_from_record() and _record_from_bike() functions isolate the binary representation of the BikeStock.Bike class from the BikeStock.BikeStock class that holds a collection of bikes. The logical structure of a bike record ﬁle isshown in Figure7.6.The physicalstructureisslightly different becauseeach record is preceded by a state byte.\n\n_BIKE_STRUCT = struct.Struct(\"<8s30sid\")\n\ndef _bike_from_record(record):\n\nID, NAME, QUANTITY, PRICE = range(4) parts = list(_BIKE_STRUCT.unpack(record)) parts[ID] = parts[ID].decode(\"utf8\").rstrip(\"\\x00\") parts[NAME] = parts[NAME].decode(\"utf8\").rstrip(\"\\x00\")\n\nSe- quence unpack- ing 114➤\n\n336\n\nChapter 7. File Handling\n\nreturn Bike(*parts)\n\ndef _record_from_bike(bike):\n\nreturn _BIKE_STRUCT.pack(bike.identity.encode(\"utf8\"),\n\nbike.name.encode(\"utf8\"), bike.quantity, bike.price)\n\nWhen we convert a binary record into a BikeStock.Bike we ﬁrst convert the tuple returned by unpack() into a list. This allows us to modify elements, in this case to convert UTF-8 encoded bytes into strings with padding 0x00 bytes stripped off. We then use the sequence unpacking operator (*) to feed the parts to the BikeStock.Bike initializer. Packing the data is much simpler; we just have to make sure that we encode the strings as UTF-8 bytes.\n\nFor modern desktop systems the need for application programs to use random accessbinary datadecreasesasRAMsizesanddiskspeedsincrease. Andwhen such functionality is needed, it is often easiest to use a DBM ﬁle or an SQL database. Nonetheless, there are systems where the functionality shown here may be useful, for example, on embedded and other resource limited systems.\n\nSummary\n\n|||\n\nThis chapter showed the most widely used techniques for saving and loading collections of data to and from ﬁles. We have seen how easy pickles are to use, and how we can handle both compressed and uncompressed ﬁles without knowing in advance whether compression has been used.\n\nWe saw how writing and reading binary data requires care, and saw that the code can be quite long if we need to handle variablelength strings. But we also learned that using binary ﬁlesusually resultsin the smallest possibleﬁle sizes and the fastest writing and reading times. We learned too that it is important to use a magic number to identify our ﬁle type and to use a version number to make it practical to change the format later on.\n\nIn thischapter wesawthat plain text istheeasiest formatfor userstoreadand that if the data is structured well it can be straightforward for additional tools to be created to manipulate the data. However,parsing text data can be tricky. We saw how to read text data both manually and using regular expressions.\n\nXML is a very popular data interchange format and it is generally useful to be able to at least import and export XML even when the normal format is a bina- ry or textone. WesawhowtowriteXMLmanually—including howtocorrectly escapeattributevaluesandtextualdata—andhowtowriteit using anelement tree and a DOM. We also learned how to parse XML using the element tree, DOM, and SAX parsers that Python’s standard library provides.\n\nSummary\n\nIn the chapter’s ﬁnal section we saw how to create a generic class to handle random accessbinary ﬁlesthat hold recordsof a ﬁxed size,and then how to use the generic class in a speciﬁc context.\n\nThis chapter brings us to the end of all the fundamentals of Python program- ming. It is possible to stop reading right here and to write perfectly good Python programsbased on everything you have learned so far. But it would be a shame to stop now—Python has so much more to offer, from neat techniques that can shorten and simplify code, to some mind-bending advanced facilities that are at least nice to know about, even if they are not often needed. In the next chapter we will go further with procedural and object-oriented program- ming, and we will also get a taste of functional programming. Then, in the following chapters we will focus more on broader programming techniques including threading,networking,database programming,regular expressions, and GUI (Graphical User Interface) programming.\n\nExercises\n\nThe ﬁrst exercise is to create a simpler binary record ﬁle module than the one presented in this chapter—one whose record size is exactly the same as what the user speciﬁes. The second exercise is to modify the BikeStock module to use your new binary record ﬁle module. The third exercise asks you to create a program from scratch—the ﬁle handling is quite straightforward, but some of the output formatting is rather challenging.\n\n1. Make a new, simpler version of the BinaryRecordFile module—one that does not use a state byte. For this version the record size speciﬁed by the user is the record size actually used. New records must be added us- ing a new append() method that simply moves the ﬁle pointer to the end and writes the given record. The __setitem__() method should only allow existing records to be replaced; one easy way of doing this is to use the __seek_to_index() method. With no state byte, __getitem__() is reduced to a mere three lines. The __delitem__() method will need to be completely rewritten since it must move all the records up to ﬁll the gap; this can be done in just over half a dozen lines, but does require some thought. The undelete() method must be removed since it is not supported,and the com- pact() and inplace_compact() methods must be removed because they are no longer needed. All told, the changes amount to fewer than 20 new or changed lines and at least 60 deleted lines compared with the original, and not counting doctests. A solution is provided in BinaryRecordFile_ans.py.\n\n2. Once you are conﬁdent that your simpler BinaryRecordFile class works, copy the BikeStock.py ﬁle and modify it to work with your BinaryRecordFile\n\n337\n\n|||\n\n338\n\nChapter 7. File Handling\n\nclass. Thisinvolveschanging only a handful of lines. A solution isprovid- ed in BikeStock_ans.py.\n\n3. Debugging binary formats can be difﬁcult, but a tool that can help is one that can do a hex dump of a binary ﬁle’s contents. Create a program that has the following console help text:\n\nUsage: xdump.py [options] file1 [file2 [... fileN]]\n\nOptions: -h, --help show this help message and exit -b BLOCKSIZE, --blocksize=BLOCKSIZE block size (8..80) [default: 16] -d, --decimal decimal block numbers [default: hexadecimal] -e ENCODING, --encoding=ENCODING encoding (ASCII..UTF-32) [default: UTF-8]\n\nUsing this program, if we have a BinaryRecordFile that is storing records with the structure \"<i10s\" (little-endian, 4-byte signed integer, 10-byte byte string),by setting the block size to match one record (15 bytes includ- ing the state byte), we can get a clear picture of what’s in the ﬁle. For ex- ample:\n\nxdump.py -b15 test.dat Block Bytes UTF-8 characters -------- --------------------------------- ---------------- 00000000 02000000 00416C70 68610000 000000 .....Alpha..... 00000001 01140000 00427261 766F0000 000000 .....Bravo..... 00000002 02280000 00436861 726C6965 000000 .(...Charlie... 00000003 023C0000 0044656C 74610000 000000 .<...Delta.....\n\nEach byte is represented by a two-digit hexadecimal number; the spacing between each set of four bytes (i.e., between each group of eight hexadec- imal digits) is purely to improve readability. Here we can see that the sec- ond record (“Bravo”) has been deleted since its state byte is 0x01 rather than the 0x02 used to indicate nonblank nondeleted records.\n\nUse the optparse module to handle the command-line options. (By specify- ing an option’s “type” you can get optparse to handle the string-to-integer conversion for the block size.) It can be quite tricky to get the headings to line up correctly for any given block size and to line up the characters correctly for the last block, so make sure you test with various block sizes (e.g.,8, 9, 10,…, 40).Also,don’t forget that in variable length ﬁles,the last block may be short. As the example illustrates, use periods to stand for nonprintable characters.\n\nThe program can be written in fewer than 70 lines spread over two functions. A solution is given in xdump.py.",
      "page_number": 313
    },
    {
      "number": 34,
      "title": "Segment 34 (pages 330-340)",
      "start_page": 330,
      "end_page": 340,
      "detection_method": "topic_boundary",
      "content": "8\n\nFurther Procedural Programming ● Further Object-Oriented Programming\n\nFunctional-Style Programming\n\nAdvanced Programming Techniques\n\n||||\n\nIn this chapter we will look at a wide variety of different programming tech- niques and introduce many additional,often more advanced,Python syntaxes. Some of thematerialin thischapter isquitechallenging,but keepin mind that the most advanced techniques are rarely needed and you can always skim the ﬁrst time to get an idea of what can be done and read more carefully when the need arises.\n\nThe chapter’s ﬁrst section digs more deeply into Python’s procedural features. It starts by showing how to use what we already covered in a novel way, and then returns to the theme of generators that we only touched on in Chapter 6. Thesectionthenintroducesdynamicprogramming—loadingmodulesby name at runtimeand executing arbitrary codeat runtime. The section returnsto the theme of local (nested) functions,but in addition covers the use of the nonlocal keyword and recursive functions. Earlier we saw how to use Python’s prede- ﬁned decorators—in this section we learn how to create our own decorators. The section concludes with coverage of function annotations.\n\nThe secondsectioncoversall new materialrelating toobject-orientedprogram- ming. It begins by introducing __slots__, a mechanism for minimizing the memory usedby eachobject. Itthenshowshowtoaccessattributeswithoutus- ing properties. The section also introduces functors (objects that can be called like functions),and context managers—these are used in conjunction with the with keyword,and in many cases(e.g.,ﬁle handling)they can beused toreplace try … except … finally constructs with simpler try … except constructs. The section also shows how to create custom context managers, and introduces ad- ditional advanced object-oriented features,including classdecorators,abstract base classes, multiple inheritance, and metaclasses.\n\nThe third section introduces some fundamental concepts of functional pro- gramming,and introducessome useful functionsfrom the functools, itertools,\n\n339\n\n340\n\nChapter 8. Advanced Programming Techniques\n\nand operator modules. This section also shows how to use partial function ap- plication to simplify code, and how to create and use coroutines.\n\nAll the previous chapters put together have provided us with the “standard Python toolbox”. This chapter takes everything that we have already covered and turns it into the “deluxe Python toolbox”, with all the original tools (tech- niques and syntaxes), plus many new ones that can make our programming easier,shorter,and more effective. Some of the tools can have interchangeable uses, for example, some jobs can be done using either a class decorator or a metaclass,whereasothers,such as descriptors,can be used in multiple waysto achieve different effects. Some of the tools covered here, for example, context managers, we will use all the time, and others will remain ready at hand for those particular situations for which they are the perfect solution.\n\nFurther Procedural Programming\n\nMost of this section deals with additional facilities relating to procedural programming and functions,but the very ﬁrst subsection is different in that it presents a useful programming technique based on what we already covered without introducing any new syntax.\n\nBranching Using Dictionaries\n\nAs we noted earlier, functions are objects like everything else in Python, and a function’s name is an object reference that refers to the function. If we write a function’s name without parentheses, Python knows we mean the object reference, and we can pass such object references around just like any others. We can use thisfact to replace if statementsthat have lotsof elif clauseswith a single function call.\n\nIn Chapter12wewillreviewaninteractiveconsoleprogramcalled dvds-dbm.py, that has the following menu:\n\n(A)dd (E)dit (L)ist (R)emove (I)mport e(X)port (Q)uit\n\nThe program has a function that gets the user’s choice and which will return only a valid choice, in this case one of “a”, “e”, “l”, “r”, “i”, “x”, and “q”. Here are two equivalent code snippets for calling the relevant function based on the user’s choice:\n\nif action == \"a\":\n\nadd_dvd(db) elif action == \"e\": edit_dvd(db)\n\n|||\n\n||\n\nGenera- tor func- tions 279➤\n\nFurther Procedural Programming\n\n341\n\nelif action == \"l\":\n\nlist_dvds(db)\n\nelif action == \"r\":\n\nremove_dvd(db)\n\nelif action == \"i\": import_(db) elif action == \"x\": export(db) elif action == \"q\":\n\nfunctions = dict(a=add_dvd, e=edit_dvd,\n\nl=list_dvds, r=remove_dvd, i=import_, x=export, q=quit)\n\nquit(db)\n\nfunctions[action](db)\n\nThe choice is held as a one-character string in the action variable, and the database to be used is held in the db variable. The import_() function has a trailing underscore to keep it distinct from the built-in import statement.\n\nIn the right-hand code snippet we create a dictionary whose keys are the valid menu choices, and whose values are function references. In the second state- ment we retrieve the function reference corresponding to the given action and call the function referred to using the call operator, (), and in this example, passing the db argument. Not only is the code on the right-hand side much shorter than the code on the left, but also it can scale (have far more dictio- nary items) without affecting its performance,unlike the left-hand code whose speed depends on how many elifs must be tested to ﬁnd the appropriate func- tion to call.\n\nThe convert-incidents.py program from the preceding chapter uses this technique in its import_() method, as this extract from the method shows:\n\ncall = {(\".aix\", \"dom\"): self.import_xml_dom,\n\n(\".aix\", \"etree\"): self.import_xml_etree, (\".aix\", \"sax\"): self.import_xml_sax, (\".ait\", \"manual\"): self.import_text_manual, (\".ait\", \"regex\"): self.import_text_regex, (\".aib\", None): self.import_binary, (\".aip\", None): self.import_pickle}\n\nresult = call[extension, reader](filename)\n\nThe complete method is 13 lines long; the extension parameter is computed in the method,and the reader is passed in. The dictionary keys are 2-tuples,and the values are methods. If we had used if statements, the code would be 22 lines long, and would not scale as well.\n\nGenerator Expressions and Functions\n\n||\n\nintroduced generator functions and methods. It is Back in Chapter 6 we also possible to create generator expressions. These are syntactically almost\n\n342\n\nChapter 8. Advanced Programming Techniques\n\nidentical to list comprehensions,the difference being that they are enclosed in parentheses rather than brackets. Here are their syntaxes:\n\n(expression for item in iterable) (expression for item in iterable if condition)\n\nIn the preceding chapter we created some iterator methods using yield expressions. Herearetwoequivalentcodesnippetsthatshowhowa simple for … in loop containing a yield expression can be coded as a generator:\n\ndef items_in_key_order(d):\n\ndef items_in_key_order(d):\n\nfor key in sorted(d): yield key, d[key]\n\nreturn ((key, d[key])\n\nfor key in sorted(d))\n\nBoth functions return a generator that produces a list of key–value items for the given dictionary. If we need all the items in one go we can pass the generator returned by the functions to list() or tuple(); otherwise, we can iterate over the generator to retrieve items as we need them.\n\nGenerators provide a means of performing lazy evaluation, which means that they compute only the values that are actually needed. This can be more efﬁ- cient than,say,computing a very large list in one go. Some generatorsproduce as many values as we ask for—without any upper limit. For example:\n\ndef quarters(next_quarter=0.0):\n\nwhile True:\n\nyield next_quarter next_quarter += 0.25\n\nThis function will return 0.0,0.25,0.5,and so on,forever. Here is how we could use the generator:\n\nresult = [] for x in quarters(): result.append(x) if x >= 1.0: break\n\nThe break statement isessential—without it the for …in loop will never ﬁnish. At the end the result list is [0.0, 0.25, 0.5, 0.75, 1.0].\n\nEvery time we call quarters() we get back a generator that starts at 0.0 and increments by 0.25; but what if we want to reset the generator’s current value? It is possible to pass a value into a generator,as this new version of the generator function shows:\n\ndef quarters(next_quarter=0.0):\n\nwhile True:\n\nFurther Procedural Programming\n\nreceived = (yield next_quarter) if received is None:\n\nnext_quarter += 0.25\n\nelse:\n\nnext_quarter = received\n\nThe yield expression returns each value to the caller in turn. In addition, if the caller calls the generator’s send() method, the value sent is received in the generator function as the result of the yield expression. Here is how we can use the new generator function:\n\nresult = [] generator = quarters() while len(result) < 5:\n\nx = next(generator) if abs(x - 0.5) < sys.float_info.epsilon:\n\nx = generator.send(1.0)\n\nresult.append(x)\n\nWe create a variable to refer to the generator and call the built-in next() func- tion which retrieves the next item from the generator it is given. (The same effect can be achieved by calling the generator’s __next__() special method, in thiscase,x = generator.__next__().)If thevalueisequalto0.5wesendthevalue 1.0intothegenerator(whichimmediately yieldsthisvalueback).Thistimethe result list is [0.0, 0.25, 1.0, 1.25, 1.5].\n\nIn the next subsection we will review the magic-numbers.py program which pro- cesses ﬁles given on the command line. Unfortunately,the Windows shell pro- gram(cmd.exe)doesnotprovidewildcardexpansion(alsocalledﬁleglobbing),so if a programisrunon Windowswith theargument *.*,theliteraltext “*.*”will go intothe sys.argv list instead of all theﬁlesin thecurrentdirectory. Wesolve this problem by creating two different get_files() functions, one for Windows and the other for Unix, both of which use generators. Here’s the code:\n\nif sys.platform.startswith(\"win\"):\n\ndef get_files(names):\n\nfor name in names:\n\nif os.path.isfile(name):\n\nyield name\n\nelse:\n\nfor file in glob.iglob(name):\n\nif not os.path.isfile(file):\n\ncontinue\n\nyield file\n\nelse:\n\ndef get_files(names):\n\nreturn (file for file in names if os.path.isfile(file))\n\n343\n\n344\n\nChapter 8. Advanced Programming Techniques\n\nIn either case the function is expected to be called with a list of ﬁlenames, for example, sys.argv[1:], as its argument.\n\nOn Windowsthe function iteratesover all the nameslisted. For each ﬁlename, the function yields the name, but for nonﬁles (usually directories), the glob module’s glob.iglob() function isused to return an iterator to the namesof the ﬁlesthat thenamerepresentsafter wildcardexpansion. For an ordinary name like autoexec.bat an iterator that produces one item (the name) is returned, and for a name that uses wildcards like *.txt an iterator that produces all the matching ﬁles (in this case those with extension .txt) is returned. (There is also a glob.glob() function that returns a list rather than an iterator.)\n\nOn Unix the shell does wildcard expansion for us, so we just need to return a generator for all the ﬁles whose names we have been given.★\n\nGenerator functions can also be used as coroutines, if we structure them correctly. Coroutines are functions that can be suspended in mid-execution (at the yield expression), waiting for the yield to provide a result to work on, and once received they continue processing. As we will see in the coroutines subsection later in this chapter (➤ 399), coroutines can be used to distribute work and to create processing pipelines.\n\nDynamic Code Execution and Dynamic Imports\n\nThere are some occasions when it is easier to write a piece of code that gen- erates the code we need than to write the needed code directly. And in some contexts it is useful to let users enter code (e.g., functions in a spreadsheet), and to let Python execute the entered code for us rather than to write a parser and handle it ourselves—although executing arbitrary code like this is a po- tential security risk, of course. Another use case for dynamic code execution is to provide plug-ins to extend a program’s functionality. Using plug-ins has the disadvantage that all the necessary functionality is not built into the pro- gram (which can make the program more difﬁcult to deploy and runs the risk of plug-ins getting lost),but has the advantages that plug-ins can be upgraded individually and can be provided separately,perhapsto provide enhancements that were not originally envisaged.\n\nDynamic Code Execution\n\nThe easiest way to execute an expression is to use the built-in eval() function we ﬁrst saw in Chapter 6. For example:\n\nx = eval(\"(2 ** 31) - 1\")\n\n# x == 2147483647\n\n★The glob.glob() functions are not as powerful as, say, the Unix bash shell, since although they support the *, ?, and [] syntaxes, they don’t support the {} syntax.\n\n||\n\n|\n\nFurther Procedural Programming\n\nThis is ﬁne for user-entered expressions, but what if we need to create a function dynamically? For that we can use the built-in exec() function. For example, the user might give us a formula such as 4π 2r and the name “area of sphere”, which they want turned into a function. Assuming that we replace π with math.pi, the function they want can be created like this:\n\nimport math code = ''' def area_of_sphere(r):\n\nreturn 4 * math.pi * r ** 2\n\n''' context = {} context[\"math\"] = math exec(code, context)\n\nWemustuseproperindentation—afterall,thequotedcodeisstandardPython. (Although in this case we could have written it all on a single line because the suite is just one line.)\n\nIf exec() is called with some code as its only argument there is no way to access any functions or variables that are created as a result of the code being executed. Furthermore, exec() cannot access any imported modules or any of the variables, functions, or other objects that are in scope at the point of the call. Bothof theseproblemscanbesolvedby passing a dictionaryasthesecond argument. The dictionary providesa place where object referencescan be kept for accessing after the exec() call has ﬁnished. For example, the use of the context dictionary meansthat after the exec() call,the dictionary hasan object reference to the area_of_sphere() function that was created by exec(). In this example we needed exec() to be able to access the math module, so we inserted an item into the context dictionary whose key is the module’s name and whose value is an object reference to the corresponding module object. This ensures that inside the exec() call, math.pi is accessible.\n\nIn some cases it is convenient to provide the entire global context to exec(). This can be done by passing the dictionary returned by the globals() function. One disadvantageof thisapproach isthat any objectscreated in the exec() call would be added to the global dictionary. A solution isto copy the global context into a dictionary,for example,context = globals().copy().This still gives exec() access to imported modules and the variables and other objects that are in scope,and because we have copied,any changes to the context made inside the exec() callarekeptinthe context dictionaryandarenotpropagatedtotheglob- al environment. (It would appear to be more secure to use copy.deepcopy(),but if security is a concern it is best to avoid exec() altogether.) We can also pass the local context, for example, by passing locals() as a third argument—this makes objects in the local scope accessible to the code executed by exec().\n\n345\n\n346\n\nChapter 8. Advanced Programming Techniques\n\nAfter the exec() call the context dictionary contains a key called \"area_of_ sphere\" whose value is the area_of_sphere() function. Here is how we can access and call the function:\n\narea_of_sphere = context[\"area_of_sphere\"] area = area_of_sphere(5)\n\n# area == 314.15926535897933\n\nThe area_of_sphere object isan object referenceto the function we have dynam- ically created and can be used just like any other function. And although we created only a single function in the exec() call, unlike eval(), which can oper- ate on only a single expression, exec() can handle as many Python statements as we like, including entire modules, as we will see in the next subsubsection.\n\nDynamically Importing Modules\n\nPython provides three straightforward mechanisms that can be used to create plug-ins, all of which involve importing modules by name at runtime. And once we have dynamically imported additional modules, we can use Python’s introspection functions to check the availability of the functionality we want, and to access it as required.\n\nIn this subsubsection we will review the magic-numbers.py program. This program reads the ﬁrst 1000 bytes of each ﬁle given on the command line and for each one outputs the ﬁle’s type (or the text “Unknown”), and the ﬁlename. Here is an example command line and an extract from its output:\n\nC:\\Python31\\python.exe magic-numbers.py c:\\windows\\*.* ... XML.................c:\\windows\\WindowsShell.Manifest Unknown.............c:\\windows\\WindowsUpdate.log Windows Executable..c:\\windows\\winhelp.exe Windows Executable..c:\\windows\\winhlp32.exe Windows BMP Image...c:\\windows\\winnt.bmp ...\n\nThe program tries to load in any module that is in the same directory as the programandwhosenamecontainsthetext“magic”.Suchmodulesareexpected to provide a single public function, get_file_type(). Two very simple example modules, StandardMagicNumbers.py and WindowsMagicNumbers.py, that each have a get_file_type() function are provided with the book’s examples.\n\nWe will review the program’s main() function in two parts.\n\ndef main():\n\nmodules = load_modules() get_file_type_functions = [] for module in modules:\n\n|\n\nFurther Procedural Programming\n\nget_file_type = get_function(module, \"get_file_type\") if get_file_type is not None:\n\nget_file_type_functions.append(get_file_type)\n\nIn a moment, we will the load_modules() functionwhich returnsa (possibly empty)list of moduleobjects, and we will look at the get_function() function further on. For each module found we try to retrieve a get_file_type() function,and add any we get to a list of such functions.\n\nlook at three different implementations of\n\nfor file in get_files(sys.argv[1:]):\n\nfh = None try:\n\nfh = open(file, \"rb\") magic = fh.read(1000) for get_file_type in get_file_type_functions:\n\nfiletype = get_file_type(magic,\n\nos.path.splitext(file)[1])\n\nif filetype is not None:\n\nprint(\"{0:.<20}{1}\".format(filetype, file)) break\n\nelse:\n\nprint(\"{0:.<20}{1}\".format(\"Unknown\", file))\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nfinally:\n\nif fh is not None: fh.close()\n\nThis loop iterates over every ﬁle listed on the command line and for each one reads its ﬁrst 1000 bytes. It then tries each get_file_type() function in turn to see whether it can determine the current ﬁle’s type. If the ﬁle type is deter- mined,the detailsare printed and the inner loop is broken out of,with process- ing continuing with thenext ﬁle. If no function can determinetheﬁle type—or if no get_file_type() functions were found—an “Unknown” line is printed.\n\nWe will now review three different (but equivalent) ways of dynamically importing modules,starting with thelongestandmostdifﬁcultapproach,since it shows every step explicitly:\n\ndef load_modules(): modules = [] for name in os.listdir(os.path.dirname(__file__) or \".\"):\n\nif name.endswith(\".py\") and \"magic\" in name.lower():\n\nfilename = name name = os.path.splitext(name)[0] if name.isidentifier() and name not in sys.modules:\n\n347\n\n348\n\nChapter 8. Advanced Programming Techniques\n\nfh = None try:\n\nfh = open(filename, \"r\", encoding=\"utf8\") code = fh.read() module = type(sys)(name) sys.modules[name] = module exec(code, module.__dict__) modules.append(module)\n\nexcept (EnvironmentError, SyntaxError) as err:\n\nsys.modules.pop(name, None) print(err)\n\nfinally:\n\nif fh is not None: fh.close()\n\nreturn modules\n\nWe begin by iterating over all the ﬁles in the program’sdirectory. If this is the current directory,os.path.dirname(__file__) will return an empty string which would cause os.listdir() to raise an exception, so we pass \".\" if necessary. For each candidate ﬁle (ends with .py and contains the text “magic”), we get the module name by chopping off the ﬁle extension. If the name is a valid identiﬁer it is a viable module name, and if it isn’t already in the global list of modules maintained in the sys.modules dictionary we can try to import it.\n\nWe read the text of the ﬁle into the code string. The next line, module = type(sys)(name), is quite subtle. When we call type() it returns the type object of the object it is given. So if we called type(1) we would get int back. If we print the type object we just get something human readable like “int”, but if we call the type object as a function, we get an object of that type back. For example, we can get the integer 5 in variable x by writing x = 5, or x = int(5), or x = type(0)(5), or int_type = type(0); x = int_type(5). In this case we’ve used type(sys) and sys isa module,sowegetback themoduletypeobject(essentially the same as a class object), and can use it to create a new module with the giv- en name. Just as with the int example where it didn’t matter what integer we used to get the int typeobject,it doesn’t matter what module we use (aslong as it is one that exists, that is, has been imported) to get the module type object.\n\nOnce we have a new (empty) module, we add it to the global list of modules to prevent the module from being accidentally reimported. This is done before calling exec() to more closely mimic the behavior of the import statement. Then we call exec() to execute the code we have read—and we use the module’s dictionary as the code’s context. At the end we add the module to the list of moduleswe will passback. And if a problem arises,we delete the module from the global modulesdictionary if it hasbeen added—it will not have been added to the list of modules if an error occurred. Notice that exec() can handle any\n\nFurther Procedural Programming\n\nTable 8.1 Dynamic Programming and Introspection Functions\n\nSyntax\n\nDescription\n\n__import__(...)\n\nImports a module by name; see text\n\ncompile(source,\n\nfile, mode)\n\nReturns the code object that results from compiling the source text; file should be the ﬁlename, or \"<string>\"; mode must be “single”, “eval”, or “exec”\n\ndelattr(obj,\n\nDeletes the attribute called name from object obj\n\nname)\n\ndir(obj)\n\nReturns the list of names in the local scope, or if obj is given then obj’s names (e.g., its attributes and methods)\n\neval(source,\n\nglobals, locals)\n\nexec(obj,\n\nglobals, locals)\n\nReturns the result of evaluating the single expression in source;if supplied,globals istheglobal contextand locals is the local context (as dictionaries) Evaluatesobject obj,which can bea string or a codeobject from compile(), and returns None; if supplied, globals is the global context and locals is the local context\n\ngetattr(obj,\n\nname, val)\n\nReturns the value of the attribute called name from object obj, or val if given and there is no such attribute\n\nglobals()\n\nReturns a dictionary of the current global context\n\nhasattr(obj, name)\n\nReturns True if object obj has an attribute called name\n\nlocals()\n\nReturns a dictionary of the current local context\n\nsetattr(obj,\n\nname, val)\n\nSetstheattributecalled name tothevalue val for theobject obj, creating the attribute if necessary\n\ntype(obj)\n\nReturns object obj’s type object\n\nvars(obj)\n\nReturns object obj’s context as a dictionary; or the local context if obj is not given\n\namount of code (whereas eval() evaluates a single expression—see Table 8.1), and raises a SyntaxError exception if there’s a syntax error.\n\nHere’s the second way to dynamically load a module at runtime—the code shown here replaces the ﬁrst approach’s try … except block:\n\ntry:\n\nexec(\"import \" + name) modules.append(sys.modules[name])\n\nexcept SyntaxError as err:\n\nprint(err)\n\n349",
      "page_number": 330
    },
    {
      "number": 35,
      "title": "Segment 35 (pages 341-350)",
      "start_page": 341,
      "end_page": 350,
      "detection_method": "topic_boundary",
      "content": "350\n\nChapter 8. Advanced Programming Techniques\n\nOne theoretical problem with this approach is that it is potentially insecure. The name variable could begin with sys; and be followed by some destruc- tive code.\n\nAnd hereisthethirdapproach,againjust showing thereplacementfor theﬁrst approach’s try … except block:\n\ntry:\n\nmodule = __import__(name) modules.append(module)\n\nexcept (ImportError, SyntaxError) as err:\n\nprint(err)\n\nThis is the easiest way to dynamically import modules and is slightly safer than using exec(), although like any dynamic import, it is by no means secure because we don’t know what is being executed when the module is imported.\n\nNone of the techniques shown here handles packages or modules in different paths,but it isnot difﬁcult to extend the code to accommodatethese—although it is worth reading the online documentation, especially for __import__(), if more sophistication is required.\n\nHaving imported the module we need to be able to access the functionality it provides. This can be achieved using Python’sbuilt-in introspection functions, getattr() and hasattr(). Here’s how we have used them to implement the get_function() function:\n\ndef get_function(module, function_name):\n\nfunction = get_function.cache.get((module, function_name), None) if function is None:\n\ntry:\n\nfunction = getattr(module, function_name) if not hasattr(function, \"__call__\"):\n\nraise AttributeError()\n\nget_function.cache[module, function_name] = function\n\nexcept AttributeError: function = None\n\nreturn function get_function.cache = {}\n\nIgnoring the cache-related code for a moment, what the function does is call getattr() on the module object with the name of the function we want. If there is no such attribute an AttributeError exception is raised, but if there is such an attribute we use hasattr() to check that the attribute itself has the __call__ attribute—something that all callables (functions and methods) have. (Further on we will see a nicer way of checking whether an attribute is\n\ncollec- tions. Callable ➤ 392\n\n352\n\nChapter 8. Advanced Programming Techniques\n\nOne common use case for local functions is when we want to use recursion. In these cases, the enclosing function is called, sets things up, and then makes the ﬁrst call to a local recursive function. Recursive functions(or methods)are ones that call themselves. Structurally, all directly recursive functions can be seen as having two cases:the base case and the recursivecase. The base case is used to stop the recursion.\n\nRecursive functions can be computationally expensive because for every re- cursive call another stack frame is used; however, some algorithms are most naturally expressed using recursion. Most Python implementations have a ﬁxed limit to how many recursive calls can be made. The limit is returned by sys.getrecursionlimit() and can be changed by sys.setrecursionlimit(), al- though increasing the limit is most often a sign that the algorithm being used is inappropriate or that the implementation has a bug.\n\nThe classic example of a recursive function is one that is used to calculate factorials.★ For example, factorial(5) will calculate 5! and return 120, that is, 1 × 2 × 3 × 4 × 5:\n\ndef factorial(x): if x <= 1:\n\nreturn 1\n\nreturn x * factorial(x - 1)\n\nThis is not an efﬁcient solution,but it does show the two fundamental features of recursive functions. If the given number, x, is 1 or less, 1 is returned and no recursion occurs—this is the base case. But if x is greater than 1 the value returned is x * factorial(x - 1), and this is the recursive case because here the factorial function calls itself. The function is guaranteed to terminate because if the initial x is less than or equal to 1 the base case will be used and the function will ﬁnish immediately, and if x is greater than 1, each recursive call will be on a number one less than before and so will eventually be 1.\n\nTo see both local functions and recursive functions in a meaningful context we will study the indented_list_sort() function from module ﬁle IndentedList.py. This function takes a list of strings that use indentation to create a hierarchy, and a string that holds one level of indent, and returns a list with the same strings but where all the strings are sorted in case-insensitive alphabetical order, with indented items sorted under their parent item, recursively, as the before and after lists shown in Figure 8.1 illustrate.\n\nGiven the before list, the after list is produced by this call: after = Indent- edList.indented_list_sort(before).The default indent value is four spaces,the same as the indent used in the before list, so we did not need to set it explic- itly.\n\n★Python’s math module provides a much more efﬁcient math.factorial() function.\n\nFurther Procedural Programming\n\nbefore = [\"Nonmetals\", \" \" \" \" \"Inner Transitionals\", Lanthanides\", \" \" \" \" \" \" \" \"Alkali Metals\", \" \" \"\n\nHydrogen\", Carbon\", Nitrogen\", Oxygen\",\n\nCerium\", Europium\",\n\nActinides\",\n\nUranium\", Curium\", Plutonium\",\n\nLithium\", Sodium\", Potassium\"]\n\nafter = [\"Alkali Metals\",\n\n\" \" \" \"Inner Transitionals\", \" Actinides\", \" \" \" \" \" \" \"Nonmetals\", \" \" \" \"\n\nLithium\", Potassium\", Sodium\",\n\nCurium\", Plutonium\", Uranium\", Lanthanides\",\n\nCerium\", Europium\",\n\nCarbon\", Hydrogen\", Nitrogen\", Oxygen\"]\n\nFigure 8.1 Before and after sorting an indented list\n\nWe will begin by looking at the indented_list_sort() function as a whole, and then we will look at its two local functions.\n\ndef indented_list_sort(indented_list, indent=\"\n\n\"):\n\nKEY, ITEM, CHILDREN = range(3)\n\ndef add_entry(level, key, item, children):\n\n...\n\ndef update_indented_list(entry):\n\n...\n\nentries = [] for item in indented_list:\n\nlevel = 0 i = 0 while item.startswith(indent, i):\n\ni += len(indent) level += 1\n\nkey = item.strip().lower() add_entry(level, key, item, entries)\n\nindented_list = [] for entry in sorted(entries):\n\nupdate_indented_list(entry)\n\nreturn indented_list\n\n353\n\n354\n\nChapter 8. Advanced Programming Techniques\n\nThe code begins by creating three constantsthat are used to provide names for index positions used by the local functions. Then we deﬁne the two local func- tions which we will review in a moment. The sorting algorithm works in two stages. In the ﬁrst stage we create a list of entries,each a 3-tuple consisting of a “key” that will be used for sorting,the original string,and a list of the string’s child entries. The key is just a lowercased copy of the string with whitespace strippedfromboth ends. Thelevelistheindentationlevel,0for top-levelitems, 1for children of top-level items,and so on. In the second stage we create a new indented list and add each string from the sorted entries list,and each string’s child strings, and so on, to produce a sorted indented list.\n\ndef add_entry(level, key, item, children):\n\nif level == 0:\n\nchildren.append((key, item, []))\n\nelse:\n\nadd_entry(level - 1, key, item, children[-1][CHILDREN])\n\nThis function is called for each string in the list. The children argument is the list to which new entries must be added. When called from the outer function (indented_list_sort()), this is the entries list. This has the effect of turning a list of strings into a list of entries, each of which has a top-level (unindented) string and a (possibly empty) list of child entries.\n\nIf the level is 0 (top-level), we add a new 3-tuple to the entries list. This holds the key (for sorting), the original item (which will go into the resultant sorted list), and an empty children list. This is the base case since no recursion takes place. If the level is greater than 0, the item is a child (or descendant) of the last item in the children list. In thiscase we recursively call add_entry() again, reducing thelevel by 1and passing thechildren list’slast item’schildren list as the list to add to. If the level is 2 or more, more recursive calls will take place, until eventually the level is 0 and the children list is the right one for the entry to be added to.\n\nFor example, when the “Inner Transitionals” string is reached, the outer func- tion calls add_entry() with a level of 0,a key of “inner transitionals”,an item of “Inner Transitionals”,and the entries list asthechildrenlist. Sincethelevel is 0, a new item will be appended to the children list (entries), with the key, item, and an empty children list. The next string is“ Lanthanides”—thisisindent- ed, so it is a child of the “Inner Transitionals” string. The add_entry() call this time has a level of 1, a key of “lanthanides”, an item of “ Lanthanides”, and the entries list asthechildren list. Sincethelevel is1,the add_entry() function calls itself recursively,this time with level 0 (1 - 1), the same key and item,but with the children list being the children list of the last item,that is,the “Inner Transitionals” item’s children list.\n\nHereiswhat the entries list lookslike onceall thestringshave been added,but before the sorting has been done:\n\nFurther Procedural Programming\n\n[('nonmetals', 'Nonmetals', [('hydrogen', ' Hydrogen', []), ('carbon', ' Carbon', []), ('nitrogen', ' Nitrogen', []), ('oxygen', ' Oxygen', [])]), ('inner transitionals', 'Inner Transitionals', [('lanthanides', ' Lanthanides', [('cerium', ' Cerium', []), ('europium', ' Europium', [])]), ('actinides', ' Actinides', [('uranium', ' Uranium', []), ('curium', ' Curium', []), ('plutonium', ' Plutonium', [])])]), ('alkali metals', 'Alkali Metals', [('lithium', ' Lithium', []), ('sodium', ' Sodium', []), ('potassium', ' Potassium', [])])]\n\nThe output was produced using the pprint (“pretty print”) module’s pprint. pprint() function. Noticethat the entries list hasonly threeitems(allof which are 3-tuples), and that each 3-tuple’s last element is a list of child 3-tuples (or is an empty list).\n\nThe add_entry() function isboth a local function and a recursivefunction. Like all recursive functions, it has a base case (in this function, when the level is 0) that ends the recursion, and a recursive case.\n\nThe function could be written in a slightly different way:\n\ndef add_entry(key, item, children):\n\nnonlocal level if level == 0:\n\nchildren.append((key, item, []))\n\nelse:\n\nlevel -= 1 add_entry(key, item, children[-1][CHILDREN])\n\nHere, instead of passing level as a parameter, we use a nonlocal statement to accessa variable in an outer enclosing scope. If we did not change level inside the function we would not need the nonlocal statement—in such a situation, Python would not ﬁnd it in the local (inner function) scope, and would look at the enclosing scope and ﬁnd it there. But in this version of add_entry() we\n\n355\n\n356\n\nChapter 8. Advanced Programming Techniques\n\nneed to change level’s value, and just as we need to tell Python that we want to change global variables using the global statement (to prevent a new local variable from being created rather than the global variable updated),the same appliesto variablesthat we want to change but which belong to an outer scope. Although it is often best to avoid using global altogether, it is also best to use nonlocal with care.\n\ndef update_indented_list(entry):\n\nindented_list.append(entry[ITEM]) for subentry in sorted(entry[CHILDREN]):\n\nupdate_indented_list(subentry)\n\nIn the algorithm’s ﬁrst stage we build up a list of entries, each a (key, item, children) 3-tuple, in the same order as they are in the original list. In the algorithm’s second stage we begin with a new empty indented list and iterate over the sorted entries, calling update_indented_list() for each one to build up the new indented list. The update_indented_list() function is recursive. For each top-level entry it adds an item to the indented_list, and then calls itself for each of the item’s child entries. Each child is added to the indented_list, and then the function callsitself for each child’schildren—andso on. The base case (when the recursion stops) is when an item, or child, or child of a child, and so on has no children of its own.\n\nPython looks for indented_list in the local (inner function) scope and doesn’t ﬁnd it,so it then looks in the enclosing scope and ﬁndsit there. But notice that inside the function we append items to the indented_list even though we have not used nonlocal.Thisworksbecause nonlocal (and global) are concerned with object references, not with the objects they refer to. In the second version of add_entry() we had to use nonlocal for level because the += operator applied to a number rebinds the object reference to a new object—what really happens is level = level + 1,so level isset torefer toa newinteger object. But whenwecall list.append() on the indented_list, it modiﬁes the list itself and no rebinding takes place, and therefore nonlocal is not necessary. (For the same reason, if we have a dictionary,list,or other global collection,we can add or removeitems from it without using a global statement.)\n\nFunction and Method Decorators\n\nA decorator is a function that takes a function or method as its sole argument and returnsa new function or method that incorporatesthe decoratedfunction We have already made or method with some additional functionality added. use of some predeﬁned decorators,for example, @property and @classmethod. In this subsection we will learn how to create our own function decorators, and later in this chapter we will see how to create class decorators.\n\n||\n\nClass decora- tors ➤ 378\n\nFurther Procedural Programming\n\nFor our ﬁrst decorator example, let us suppose that we have many functions that perform calculations,and that some of these must always produce a posi- tive result. We could add an assertion to each of these,but using a decorator is easier and clearer. Here’s a function decorated with the @positive_result deco- rator that we will create in a moment:\n\n@positive_result def discriminant(a, b, c):\n\nreturn (b ** 2) - (4 * a * c)\n\nThanks to the decorator, if the result is ever less than 0, an AssertionError ex- ception will be raised and the program will terminate. And of course, we can use the decorator on as many functions as we like. Here’s the decorator’s im- plementation:\n\ndef positive_result(function):\n\ndef wrapper(*args, **kwargs):\n\nresult = function(*args, **kwargs) assert result >= 0, function.__name__ + \"() result isn't >= 0\" return result\n\nwrapper.__name__ = function.__name__ wrapper.__doc__ = function.__doc__ return wrapper\n\nDecorators deﬁne a new local function that calls the original function. Here, the local function is wrapper(); it calls the original function and stores the result, and it uses an assertion to guarantee that the result is positive (or that the program will terminate). The wrapper ﬁnishes by returning the result computedby thewrappedfunction. Aftercreating thewrapper,wesetitsname and docstring to those of the original function. This helps with introspection, since we want error messagesto mention thename of theoriginal function,not the wrapper. Finally, we return the wrapper function—it is this function that will be used in place of the original.\n\ndef positive_result(function): @functools.wraps(function) def wrapper(*args, **kwargs):\n\nresult = function(*args, **kwargs) assert result >= 0, function.__name__ + \"() result isn't >= 0\" return result\n\nreturn wrapper\n\nHere is a slightly cleaner version of the @positive_result decorator. The wrap- per itself is wrapped using the functools module’s @functools.wraps decorator, which ensures that the wrapper() function has the name and docstring of the original function.\n\n357\n\n358\n\nChapter 8. Advanced Programming Techniques\n\nIn some cases it would be useful to be able to parameterize a decorator, but at ﬁrst sight this does not seem possible since a decorator takes just one argu- ment, a function or method. But there is a neat solution to this. We can call a function with the parameters we want and that returns a decorator which can then decorate the function that follows it. For example:\n\n@bounded(0, 100) def percent(amount, total):\n\nreturn (amount / total) * 100\n\nHere, the bounded() function is called with two arguments, and returns a deco- ratorthatisusedtodecoratethe percent() function. Thepurposeof thedecora- tor in thiscase isto guarantee that the number returned is alwaysin the range 0 to 100 inclusive. Here’s the implementation of the bounded() function:\n\ndef bounded(minimum, maximum):\n\ndef decorator(function):\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\nresult = function(*args, **kwargs) if result < minimum:\n\nreturn minimum elif result > maximum: return maximum\n\nreturn result\n\nreturn wrapper\n\nreturn decorator\n\nThe function creates a decorator function, that itself creates a wrapper func- tion. The wrapper performsthe calculation and returns a result that is within the bounded range. The decorator() function returns the wrapper() function, and the bounded() function returns the decorator.\n\nOne further point to note is that each time a wrapper is created inside the bounded() function, the particular wrapper uses the minimum and maximum values that were passed to bounded().\n\nThelast decoratorwewill createin thissubsectionisa bit morecomplex. It isa logging function that records the name, arguments,and result of any function it is used to decorate. For example:\n\n@logged def discounted_price(price, percentage, make_integer=False):\n\nresult = price * ((100 - percentage) / 100) if not (0 < result <= price):\n\nraise ValueError(\"invalid price\")\n\nreturn result if not make_integer else int(round(result))\n\nFurther Procedural Programming\n\nIf Python is run in debug mode (the normal mode), every time the discount- ed_price() function is called a log message will be added to the ﬁle logged.log in the machine’s local temporary directory, as this log ﬁle extract illustrates:\n\ncalled: discounted_price(100, 10) -> 90.0 called: discounted_price(210, 5) -> 199.5 called: discounted_price(210, 5, make_integer=True) -> 200 called: discounted_price(210, 14, True) -> 181 called: discounted_price(210, -8) <type 'ValueError'>: invalid price\n\nIf Python is run in optimized mode (using the -O command-line option or if the PYTHONOPTIMIZE environment variable is set to -O), then no logging will take place. Here’s the code for setting up logging and for the decorator:\n\nif __debug__:\n\nlogger = logging.getLogger(\"Logger\") logger.setLevel(logging.DEBUG) handler = logging.FileHandler(os.path.join(\n\ntempfile.gettempdir(), \"logged.log\"))\n\nlogger.addHandler(handler)\n\ndef logged(function):\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\nlog = \"called: \" + function.__name__ + \"(\" log += \", \".join([\"{0!r}\".format(a) for a in args] +\n\n[\"{0!s}={1!r}\".format(k, v)\n\nfor k, v in kwargs.items()])\n\nresult = exception = None try:\n\nresult = function(*args, **kwargs) return result\n\nexcept Exception as err: exception = err\n\nfinally:\n\nlog += ((\") -> \" + str(result)) if exception is None\n\nelse \") {0}: {1}\".format(type(exception),\n\nexception))\n\nlogger.debug(log) if exception is not None:\n\nraise exception\n\nreturn wrapper\n\nelse:\n\ndef logged(function):\n\nreturn function\n\n359\n\nDic- tionary compre- hen- sions 134➤\n\n360\n\nChapter 8. Advanced Programming Techniques\n\nIn debug mode the global variable __debug__ is True.If this is the case we set up logging using the logging module, and then create the @logged decorator. The logging module is very powerful and ﬂexible—it can log to ﬁles, rotated ﬁles, emails, network connections, HTTP servers, and more. Here we’ve used only the most basic facilities by creating a logging object, setting its logging level (several levels are supported),and choosing to use a ﬁle for the output.\n\nThe wrapper’scode beginsby setting upthe log string with thefunction’sname and arguments. We then try calling the function and storing its result. If any exception occurs we store it. In all cases the finally block is executed, and there we add the return value (or exception) to the log string and write to the log. If no exception occurred, the result is returned; otherwise, we reraise the exception to correctly mimic the original function’s behavior.\n\nIf Python is running in optimized mode, __debug__ is False; in this case we deﬁne the logged() function to simply return the function it is given, so apart from the tiny overhead of this indirection when the function is ﬁrst created, there is no runtime overhead at all.\n\nNote that the standard library’s trace and cProfile modules can run and anal- yse programs and modules to produce various tracing and proﬁling reports. Both use introspection,so unlike the @logged decorator we have used here,nei- ther trace nor cProfile requires any source code changes.\n\nFunction Annotations\n\nFunctionsand methodscan be deﬁned with annotations—expressionsthat can be used in a function’s signature. Here’s the general syntax:\n\ndef functionName(par1 : exp1, par2 : exp2, ..., parN : expN) -> rexp:\n\nsuite\n\nEvery colon expression part (: expX) is an optional annotation, and so is the arrow return expression part (-> rexp). The last (or only) positional parameter (if present) can be of the form *args, with or without an annotation; similarly, the last (or only) keyword parameter (if present) can be of the form **kwargs, again with or without an annotation.\n\nIf annotationsare present they are added to the function’s __annotations__ dic- tionary; if they are not present this dictionary is empty. The dictionary’s keys are the parameter names, and the values are the corresponding expressions. The syntax allows us to annotate all, some, or none of the parameters and to annotate the return value or not. Annotations have no special signiﬁcance to Python. The only thing that Python does in the face of annotations is to put them in the __annotations__ dictionary;any other action is up to us. Here is an example of an annotated function that is in the Util module:\n\n||",
      "page_number": 341
    },
    {
      "number": 36,
      "title": "Segment 36 (pages 351-358)",
      "start_page": 351,
      "end_page": 358,
      "detection_method": "topic_boundary",
      "content": "Further Procedural Programming\n\ndef is_unicode_punctuation(s : str) -> bool:\n\nfor c in s:\n\nif unicodedata.category(c)[0] != \"P\":\n\nreturn False\n\nreturn True\n\nEvery Unicode character belongs to a particular category and each category is identiﬁedby a two-characteridentiﬁer. Allthecategoriesthatbeginwith P are punctuation characters.\n\nHere we have used Python data types as the annotation expressions. But they have no particular meaning for Python, as these calls should make clear:\n\nUtil.is_unicode_punctuation(\"zebr\\a\") Util.is_unicode_punctuation(s=\"!@#?\") Util.is_unicode_punctuation((\"!\", \"@\"))\n\n# returns: False # returns: True # returns: True\n\nThe ﬁrst call uses a positional argument and the second call a keyword argu- ment, just to show that both kinds work as expected. The last call passes a tuple rather than a string,and thisisaccepted since Python doesnothing more than record the annotations in the __annotations__ dictionary.\n\nIf we want to give meaning to annotations, for example, to provide type check- ing, one approach is to decorate the functions we want the meaning to apply to with a suitable decorator. Here is a very basic type-checking decorator:\n\ndef strictly_typed(function):\n\nannotations = function.__annotations__ arg_spec = inspect.getfullargspec(function)\n\nassert \"return\" in annotations, \"missing type for return value\" for arg in arg_spec.args + arg_spec.kwonlyargs:\n\nassert arg in annotations, (\"missing type for parameter '\" +\n\narg + \"'\")\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\nfor name, arg in (list(zip(arg_spec.args, args)) +\n\nlist(kwargs.items())):\n\nassert isinstance(arg, annotations[name]), (\n\n\"expected argument '{0}' of {1} got {2}\".format( name, annotations[name], type(arg)))\n\nresult = function(*args, **kwargs) assert isinstance(result, annotations[\"return\"]), (\n\n\"expected return of {0} got {1}\".format( annotations[\"return\"], type(result)))\n\nreturn result\n\nreturn wrapper\n\n361\n\n362\n\nChapter 8. Advanced Programming Techniques\n\nThis decorator requires that every argument and the return value must be annotated with the expected type. It checksthat the function’sargumentsand return type are all annotated with their types when the function it is passed is created,and at runtime it checksthat the typesof the actual argumentsmatch those expected.\n\nThe inspect module provides powerful introspection services for objects. Here, we have made use of only a small part of the argument speciﬁcation object it returns, to get the names of each positional and keyword argument—in the correct order in the case of the positional arguments. These names are then used in conjunction with the annotations dictionary to ensure that every parameter and the return value are annotated.\n\nThe wrapper function created inside the decorator begins by iterating over every name–argument pair of the given positional and keyword arguments. Since zip() returns an iterator and dictionary.items() returns a dictionary view wecannot concatenatethemdirectly,soﬁrst weconvertthemboth tolists. If any actual argument has a different type from its corresponding annotation the assertion will fail; otherwise, the actual function is called and the type of thevaluereturnedischecked,and if it isof theright type,it isreturned. At the end of the strictly_typed() function,we return the wrapped function as usual. Notice that the checking is done only in debug mode (which is Python’sdefault mode—controlled by the -O command-line option and the PYTHONOPTIMIZE envi- ronment variable).\n\nIf we decorate the is_unicode_punctuation() function with the @strictly_typed decorator,and try thesameexamplesasbeforeusing thedecoratedversion,the annotations are acted upon:\n\nis_unicode_punctuation(\"zebr\\a\") is_unicode_punctuation(s=\"!@#?\") is_unicode_punctuation((\"!\", \"@\"))\n\n# returns: False # returns: True # raises AssertionError\n\nNow the argument types are checked, so in the last case an AssertionError is raised because a tuple is not a string or a subclass of str.\n\nNow we will look at a completely different use of annotations. Here’s a small functionthat hasthesamefunctionality asthebuilt-in range() function,except that it always returns floats:\n\ndef range_of_floats(*args) -> \"author=Reginald Perrin\":\n\nreturn (float(x) for x in range(*args))\n\nNouseismadeof theannotationby thefunctionitself,butit iseasy toenvisage a tool that imported all of a project’s modules and produced a list of function names and author names, extracting each function’s name from its __name__ attribute, and the author names from the value of the __annotations__ dictio- nary’s \"return\" item.\n\nAt- tribute access func- tions 349➤\n\nFurther Procedural Programming\n\nAnnotations are a very new feature of Python, and because Python does not impose any predeﬁned meaning on them, the uses they can be put to are lim- ited only by our imagination. Further ideas for possible uses, and some useful links, are available from PEP 3107 “Function Annotations”, www.python.org/ dev/peps/pep-3107.\n\nFurther Object-Oriented Programming\n\nIn this section we will look more deeply into Python’s support for object orientation, learning many techniques that can reduce the amount of code we must write, and that expand the power and capabilities of the programming features that are available to us. But we will begin with one very small and simple new feature. Here is the start of the deﬁnition of a Point class that has exactly the same behavior as the versions we created in Chapter 6:\n\nclass Point:\n\n__slots__ = (\"x\", \"y\")\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\nscenesPython When a class is created without the use of __slots__,behind the creates a private dictionary called __dict__ for each instance, and this dic- tionary holds the instance’s data attributes. This is why we can add or re- move attributes from objects. (For example, we added a cache attribute to the get_function() function earlier in this chapter.)\n\nIf we only need objects where we access the original attributes and don’t need to add or remove attributes, we can create classes that don’t have a __dict__. This is achieved simply by deﬁning a class attribute called __slots__ whose value is a tuple of attribute names. Each object of such a class will have attributesof the speciﬁed namesand no __dict__;no attributescan be added or removed from such classes. These objectsconsume lessmemory and are faster than conventional objects, although this is unlikely to make much difference unlesslargenumbersof objectsarecreated. If weinheritfroma classthatuses __slots__ wemustdeclareslotsin our subclass,even if empty,such as__slots__ = (); or the memory and speed savings will be lost.\n\nControlling Attribute Access\n\nIt issometimesconvenient to havea classwhereattributevaluesarecomputed on the ﬂy rather than stored. Here’s the complete implementation of such a class:\n\n363\n\n|||\n\n||\n\n364\n\nChapter 8. Advanced Programming Techniques\n\nclass Ord:\n\ndef __getattr__(self, char):\n\nreturn ord(char)\n\nWith the Ord class available, we can create an instance, ord = Ord(), and then have an alternative to the built-in ord() function that works for any character that is a valid identiﬁer. For example, ord.a returns 97, ord.Z returns 90, and ord.å returns 229. (But ord.! and similar are syntax errors.)\n\nNotethat if wetypedthe Ord classintoIDLEit would not work if wethentyped ord = Ord().Thisisbecausetheinstancehasthesamenameasthebuilt-in ord() function that the Ord class uses, so the ord() call would actually become a call to the ord instance and result in a TypeError exception. The problem would not ariseif weimportedamodulecontaining theOrd classbecausetheinteractively created ord object and the built-in ord() function used by the Ord classwould be in two separate modules,so one would not displace the other. If we really need tocreatea classinteractivelyandtoreusethenameof a built-inwecandosoby ensuring thattheclasscallsthebuilt-in—inthiscaseby importing thebuiltins module which provides unambiguous access to all the built-in functions, and calling builtins.ord() rather than plain ord().\n\nHere’sanothertiny yetcompleteclass. Thisoneallowsustocreate“constants”. It isn’t difﬁcult to change the values behind the class’s back, but it can at least prevent simple mistakes.\n\nclass Const:\n\ndef __setattr__(self, name, value):\n\nif name in self.__dict__:\n\nraise ValueError(\"cannot change a const attribute\")\n\nself.__dict__[name] = value\n\ndef __delattr__(self, name):\n\nif name in self.__dict__:\n\nraise ValueError(\"cannot delete a const attribute\") raise AttributeError(\"'{0}' object has no attribute '{1}'\"\n\n.format(self.__class__.__name__, name))\n\nWith this classwe can create a constant object,say, const = Const(),and set any attributes we like on it, for example, const.limit = 591. But once an attribute’s value has been set, although it can be read as often as we like, any attempt to change or delete it will result in a ValueError exception being raised. We have not reimplemented __getattr__() because the base class object.__getattr__() method does what we want—returns the given attribute’s value or raises an AttributeError exception if there is no such attribute. In the __delattr__() method we mimic the __getattr__() method’s error message for nonexistent attributes,and to do this we must get the name of the classwe are in as well as\n\nImage.py 261➤\n\nFurther Object-Oriented Programming\n\nTable 8.2 Attribute Access Special Methods\n\nSpecial Method\n\nUsage Description\n\n__delattr__(self, name)\n\ndel x.n Deletes object x’s n attribute\n\n__dir__(self)\n\ndir(x) Returns a list of x’s attribute\n\nnames\n\n__getattr__(self, name)\n\nv = x.n Returns the value of object x’s n\n\nattribute if it isn’t found directly\n\n__getattribute__(self, name)\n\nv = x.n Returns the value of object x’s n\n\nattribute; see text\n\n__setattr__(self, name,\n\nx.n = v Sets object x’s n attribute’s value\n\nvalue)\n\nto v\n\nthe name of the nonexistent attribute. The class works because we are using the object’s __dict__ which is what the base class __getattr__(), __setattr__(), and __delattr__() methods use, although here we have used only the base class’s __getattr__() method. All the special methods used for attribute access are listed in Table 8.2.\n\nThere is another way of getting constants:We can use named tuples. Here are a couple of examples:\n\nConst = collections.namedtuple(\"_\", \"min max\")(191, 591) Const.min, Const.max Offset = collections.namedtuple(\"_\", \"id name description\")(*range(3)) Offset.id, Offset.name, Offset.description # returns: (0, 1, 2)\n\n# returns: (191, 591)\n\nIn both cases we have just used a throwaway name for the named tuple be- cause we want just one named tuple instance each time, not a tuple subclass for creating instances of a named tuple. Although Python does not support an enum data type,we can use named tuplesaswe have done here to get a similar effect.\n\nFor our last look at attribute access special methods we will return to an example we ﬁrst saw in Chapter 6. In that chapter we created an Image class whose width, height, and background color are ﬁxed when an Image is created (although they are changed if an image is loaded).We provided access to them using read-only properties. For example, we had:\n\n@property def width(self):\n\nreturn self.__width\n\nThis is easy to code but could become tedious if there are a lot of read-only properties. Here is a different solution that handles all the Image class’s read-only properties in a single method:\n\n365\n\n366\n\nChapter 8. Advanced Programming Techniques\n\ndef __getattr__(self, name): if name == \"colors\":\n\nreturn set(self.__colors)\n\nclassname = self.__class__.__name__ if name in frozenset({\"background\", \"width\", \"height\"}): return self.__dict__[\"_{classname}__{name}\".format(\n\n**locals())]\n\nraise AttributeError(\"'{classname}' object has no \"\n\n\"attribute '{name}'\".format(**locals()))\n\nIf we attempt to access an object’s attribute and the attribute is not found, Python will call the __getattr__() method (providing it is implemented, and that we have not reimplemented __getattribute__()), with the name of the attribute as a parameter. Implementations of __getattr__() must raise an AttributeError exception if they do not handle the given attribute.\n\nFor example,if we have the statement image.colors,Python will look for a col- ors attributeandhaving failedtoﬁndit,willthencall Image.__getattr__(image, \"colors\"). In this case the __getattr__() method handles a \"colors\" attribute name and returns a copy of the set of colors that the image is using.\n\nThe other attributes are immutable, so they are safe to return directly to the caller. We could have written separate elif statements for each one like this:\n\nelif name == \"background\":\n\nreturn self.__background\n\nBut instead we have chosen a more compact approach. Since we know that under thehoodallof an object’snonspecialattributesareheldin self.__dict__, we have chosen to access them directly. For private attributes (those whose name begins with two leading underscores), the name is mangled to have the form _className__attributeName, so we must account for this when retrieving the attribute’s value from the object’s private dictionary.\n\nFor the name mangling needed to look up private attributesand to provide the standard AttributeError error text, we need to know the name of the class we are in. (It may not be Image because the object might be an instance of an Image subclass.) Every object has a __class__ special attribute, so self.__class__ is always available inside methods and can safely be accessed by __getattr__() without risking unwanted recursion.\n\nNote that there is a subtle difference in that using __getattr__() and self.__class__ provides access to the attribute in the instance’s class (which may be a subclass), but accessing the attribute directly uses the class the at- tribute is deﬁned in.\n\nOne special method that we have not covered is __getattribute__(). Where- as the __getattr__() method is called last when looking for (nonspecial) at-\n\n368\n\nChapter 8. Advanced Programming Techniques\n\ndef make_strip_function(characters): def strip_function(string):\n\nreturn string.strip(characters)\n\nreturn strip_function\n\nstrip_punctuation = make_strip_function(\",;:.!?\") strip_punctuation(\"Land ahoy!\")\n\n# returns: 'Land ahoy'\n\nThe make_strip_function() function takes the characters to be stripped as its sole argument and returns a function, strip_function(), that takes a string argument and which strips the characters that were given at the time the closure was created. So just as we can create as many instances of the Strip class as we want, each with its own characters to strip, we can create as many strip functions with their own characters as we like.\n\nThe classic use case for functors is to provide key functions for sort routines. Here is a generic SortKey functor class (from ﬁle SortKey.py):\n\nclass SortKey:\n\ndef __init__(self, *attribute_names):\n\nself.attribute_names = attribute_names\n\ndef __call__(self, instance):\n\nvalues = [] for attribute_name in self.attribute_names:\n\nvalues.append(getattr(instance, attribute_name))\n\nreturn values\n\nWhen a SortKey object is created it keeps a tuple of the attribute names it was initialized with. When the object is called it creates a list of the attribute values for the instance it is passed—in the order they were speciﬁed when the SortKey was initialized. For example, imagine we have a Person class:\n\nclass Person:\n\ndef __init__(self, forename, surname, email):\n\nself.forename = forename self.surname = surname self.email = email\n\nSuppose we have a list of Person objects in the people list. We can sort the list by surnames like this: people.sort(key=SortKey(\"surname\")). If there are a lot of people there are bound to be some surname clashes, so we can sort by surname, and then by forename within surname, like this: peo- ple.sort(key=SortKey(\"surname\", \"forename\")). And if we had people with the same surname and forename we could add the email attribute too. And of\n\nFurther Object-Oriented Programming\n\ncourse, we could sort by forename and then surname by changing the order of the attribute names we give to the SortKey functor.\n\nAnother way of achieving thesamething,but without needing tocreatea func- tor at all, is to use the operator module’s operator.attrgetter() function. For example, to sort by surname we could write: people.sort(key=operator.attr- getter(\"surname\")). And similarly, to sort by surname and forename: people.sort(key=operator.attrgetter(\"surname\", \"forename\")). The operator. attrgetter() function returnsa function (a closure) that,when called on an ob- ject,returnsthose attributesof the object that were speciﬁed when the closure was created.\n\nFunctors are probably used rather less frequently in Python than in other languages that support them because Python has other means of doing the same things—for example, using closures or item and attribute getters.\n\nContext Managers\n\nContext managers allow us to simplify code by ensuring that certain opera- tionsareperformedbeforeand after a particular block of codeisexecuted. The behavior is achieved because context managers deﬁne two special methods, __enter__() and __exit__(), that Python treats specially in the scope of a with statement. When a context manager is created in a with statement its __en- ter__() methodisautomaticallycalled,andwhenthecontextmanagergoesout of scope after its with statement its __exit__() method is automatically called.\n\nWe can create our own custom context managers or use predeﬁned ones—as we will see later in this subsection, the ﬁle objects returned by the built-in open() function are context managers. The syntax for using context managers is this:\n\nwith expression as variable:\n\nsuite\n\nThe expression must be or must produce a context manager object; if the optional as variable part is speciﬁed, the variable is set to refer to the object returned by the context manager’s __enter__() method (and this is often the context manager itself). Because a context manager is guaranteed to execute its “exit” code (even in the face of exceptions),context managers can be used to eliminate the need for finally blocks in many situations.\n\nSome of Python’s types are context managers—for example, all the ﬁle objects that open() can return—so we can eliminate finally blocks when doing ﬁle handling asthese equivalent code snippetsillustrate(assuming that process() is a function deﬁned elsewhere):\n\n369\n\n||",
      "page_number": 351
    },
    {
      "number": 37,
      "title": "Segment 37 (pages 359-371)",
      "start_page": 359,
      "end_page": 371,
      "detection_method": "topic_boundary",
      "content": "370\n\nChapter 8. Advanced Programming Techniques\n\nfh = None try:\n\nfh = open(filename) for line in fh:\n\nprocess(line)\n\ntry:\n\nexcept EnvironmentError as err:\n\nwith open(filename) as fh:\n\nprint(err)\n\nfor line in fh:\n\nfinally:\n\nprocess(line)\n\nif fh is not None: fh.close()\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nA ﬁle object is a context manager whose exit code always closes the ﬁle if it was opened. The exit code is executed whether or not an exception occurs, but in the latter case, the exception is propagated. This ensures that the ﬁle gets closed and we still get the chance to handle any errors,in this case by printing a message for the user.\n\nIn fact, context managers don’t have to propagate exceptions, but not doing so effectively hides any exceptions, and this would almost certainly be a coding error. All the built-in and standard library context managers propagate ex- ceptions.\n\nSometimes we need to use more than one context manager at the same time. For example:\n\ntry:\n\nwith open(source) as fin:\n\nwith open(target, \"w\") as fout:\n\nfor line in fin:\n\nfout.write(process(line))\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nHere we read lines from the source ﬁle and write processed versionsof them to the target ﬁle.\n\nUsing nested with statements can quickly lead to a lot of indentation. Fortu- nately, the standard library’s contextlib module provides some additional sup- port for context managers, including the contextlib.nested() function which allowstwo or more context managersto be handled in the same with statement rather than having to nest with statements. Here is a replacement for the code just shown, but omitting most of the lines that are identical to before:\n\ntry:\n\nwith contextlib.nested(open(source), open(target, \"w\")) as (\n\nfin, fout):\n\nfor line in fin:\n\nFurther Object-Oriented Programming\n\nIt is only necessary to use contextlib.nested() for Python 3.0; from Python 3.1 this function is deprecated because Python 3.1 can handle multiple context managers in a single with statement. Here is the same example—again omitting irrelevant lines—but this time for Python 3.1:\n\ntry:\n\nwith open(source) as fin, open(target, \"w\") as fout:\n\nfor line in fin:\n\nUsing this syntax keeps context managers and the variables they are associ- ated with together,making the with statement much more readable than if we were to nest them or to use contextlib.nested().\n\nIt isn’t only ﬁle objects that are context managers. For example, several threading-related classes used for locking are context managers. Context managers can also be used with decimal.Decimal numbers; this is useful if we want to perform some calculations with certain settings (such as a particular precision) in effect.\n\nIf we want to create a custom context manager we must create a class that provides two methods:__enter__() and __exit__().Whenever a with statement is used on an instance of such a class, the __enter__() method is called and the return value is used for the as variable (or thrown away if there isn’t one). When control leaves the scope of the with statement the __exit__() method is called (with details of an exception if one has occurred passed as arguments).\n\nSuppose we want to perform several operations on a list in an atomic manner—that is, we either want all the operations to be done or none of them so that the resultant list is always in a known state. For example, if we have a list of integers and want to append an integer, delete an integer, and change a couple of integers, all as a single operation, we could write code like this:\n\ntry:\n\nwith AtomicList(items) as atomic:\n\natomic.append(58289) del atomic[3] atomic[8] = 81738 atomic[index] = 38172\n\nexcept (AttributeError, IndexError, ValueError) as err:\n\nprint(\"no changes applied:\", err)\n\nIf no exception occurs,all the operations are applied to the original list (items), but if an exception occurs, no changes are made at all. Here is the code for the AtomicList context manager:\n\nclass AtomicList:\n\ndef __init__(self, alist, shallow_copy=True):\n\n371\n\n3.1\n\nThread- ing ➤ 439\n\nShallow and deep copying 146➤\n\n372\n\nChapter 8. Advanced Programming Techniques\n\nself.original = alist self.shallow_copy = shallow_copy\n\ndef __enter__(self):\n\nself.modified = (self.original[:] if self.shallow_copy\n\nelse copy.deepcopy(self.original))\n\nreturn self.modified\n\ndef __exit__(self, exc_type, exc_val, exc_tb):\n\nif exc_type is None:\n\nself.original[:] = self.modified\n\nWhen the AtomicList object is created we keep a reference to the original list and note whether shallow copying is to be used. (Shallow copying is ﬁne for lists of numbers or strings; but for lists that contain lists or other collections, shallow copying is not sufﬁcient.)\n\nThen, when the AtomicList context manager object is used in the with state- ment its __enter__() method is called. At this point we copy the original list and return the copy so that all the changes can be made on the copy.\n\nOnce we reach the end of the with statement’s scope the __exit__() method is called. If no exception occurred the exc_type (“exception type”)will be None and we know that we can safely replace the original list’sitemswith the itemsfrom the modiﬁed list. (We cannot do self.original = self.modified because that would just replace one object reference with another and would not affect the original list at all.) But if an exception occurred,we do nothing to the original list and the modiﬁed list is discarded.\n\nThe return value of __exit__() is used to indicate whether any exception that occurred should be propagated. A True value means that we have handled any exception and so no propagation should occur. Normally we always return False or something that evaluates to False in a Boolean context to allow any exception that occurred to propagate. By not giving an explicit return value, our __exit__() returns None which evaluates to False and correctly causes any exception to propagate.\n\nCustom context managers are used in Chapter 11 to ensure that socket connections and gzipped ﬁles are closed, and some of the threading modules contextmanagersareusedin Chapter10toensurethatmutualexclusionlocks are unlocked. You’ll also get the chance to create a more generic atomic contex manager in this chapter’s exercises.\n\nDescriptors\n\nDescriptors are classes which provide access control for the attributes of other classes. Any class that implements one or more of the descriptor special\n\n||\n\nFurther Object-Oriented Programming\n\nmethods, __get__(), __set__(), and __delete__(), is called (and can be used as) a descriptor.\n\nThe built-in property() and classmethod() functions are implemented using descriptors. The key to understanding descriptors is that although we create an instance of a descriptor in a class as a class attribute, Python accesses the descriptor through the class’s instances.\n\nTo make things clear, let’s imagine that we have a class whose instances hold some strings. We want to access the strings in the normal way, for example, as a property, but we also want to get an XML-escaped version of the strings whenever we want. One simple solution would be that whenever a string is set we immediately create an XML-escaped copy. But if we had thousands of strings and only ever read the XML version of a few of them, we would be wasting a lot of processing and memory for nothing. So we will create a descriptor that will provide XML-escaped strings on demand without storing them. We will start with the beginning of the client (owner) class, that is, the class that uses the descriptor:\n\nclass Product:\n\n__slots__ = (\"__name\", \"__description\", \"__price\")\n\nname_as_xml = XmlShadow(\"name\") description_as_xml = XmlShadow(\"description\")\n\ndef __init__(self, name, description, price):\n\nself.__name = name self.description = description self.price = price\n\nThe only code we have not shown are the properties; the name is a read-only property and the description and price are readable/writableproperties,all set up in the usual way. (All the code is in the XmlShadow.py ﬁle.) We have used the __slots__ variable to ensure that the class has no __dict__ and can store only the three speciﬁed private attributes;this is not related to or necessary for our use of descriptors. The name_as_xml and description_as_xml classattributesare set to be instancesof the XmlShadow descriptor. Although no Product object hasa name_as_xml attributeor a description_as_xml attribute,thankstothedescriptor we can write code like this (here quoting from the module’s doctests):\n\n>>> product = Product(\"Chisel <3cm>\", \"Chisel & cap\", 45.25) >>> product.name, product.name_as_xml, product.description_as_xml ('Chisel <3cm>', 'Chisel &lt;3cm&gt;', 'Chisel &amp; cap')\n\nThis works because when we try to access, for example, the name_as_xml attribute, Python ﬁnds that the Product class has a descriptor with that name,\n\n373\n\n374\n\nChapter 8. Advanced Programming Techniques\n\nand so usesthe descriptor to get the attribute’svalue. Here’sthe completecode for the XmlShadow descriptor class:\n\nclass XmlShadow:\n\ndef __init__(self, attribute_name):\n\nself.attribute_name = attribute_name\n\ndef __get__(self, instance, owner=None): return xml.sax.saxutils.escape(\n\ngetattr(instance, self.attribute_name))\n\nWhen the name_as_xml and description_as_xml objects are created we pass the name of the Product class’s corresponding attribute to the XmlShadow initializ- er so that the descriptor knows which attribute to work on. Then, when the name_as_xml or description_as_xml attribute is looked up, Python calls the de- scriptor’s __get__() method. The self argument is the instance of the descrip- tor, the instance argument is the Product instance (i.e., the product’s self), and the owner argument is the owning class (Product in this case).We use the getat- tr() function to retrieve the relevant attribute from the product (in this case the relevant property), and return an XML-escaped version of it.\n\nIf the use case was that only a small proportion of the products were accessed for their XML strings, but the strings were often long and the same ones were frequently accessed, we could use a cache. For example:\n\nclass CachedXmlShadow:\n\ndef __init__(self, attribute_name):\n\nself.attribute_name = attribute_name self.cache = {}\n\ndef __get__(self, instance, owner=None):\n\nxml_text = self.cache.get(id(instance)) if xml_text is not None: return xml_text\n\nreturn self.cache.setdefault(id(instance),\n\nxml.sax.saxutils.escape(\n\ngetattr(instance, self.attribute_name)))\n\nWestoretheuniqueidentity of theinstanceasthekey ratherthantheinstance itself because dictionary keys must be hashable (which IDs are), but we don’t want to impose that as a requirement on classes that use the CachedXmlShad- ow descriptor. The key is necessary because descriptors are created per class rather than per instance. (The dict.setdefault() method conveniently returns the value for the given key,or if no item with that key is present,createsa new item with the given key and value and returns the value.)\n\nFurther Object-Oriented Programming\n\nHaving seen descriptors used to generate data without necessarily storing it, we will now look at a descriptor that can be used to store all of an object’s at- tribute data, with the object not needing to store anything itself. In the exam- ple,we will just use a dictionary,but in a more realistic context,the data might be stored in a ﬁle or a database. Here’s the start of a modiﬁed version of the Point class that makes use of the descriptor (from the ExternalStorage.py ﬁle):\n\nclass Point:\n\n__slots__ = () x = ExternalStorage(\"x\") y = ExternalStorage(\"y\")\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\nBy setting __slots__ to an empty tuple we ensure that the class cannot store any data attributes at all. When self.x is assigned to, Python ﬁnds that there isa descriptorwith thename“x”,and sousesthedescriptor’s__set__() method. The rest of the class isn’t shown, but is the same as the original Point class shown in Chapter 6. Here is the complete ExternalStorage descriptor class:\n\nclass ExternalStorage:\n\n__slots__ = (\"attribute_name\",) __storage = {}\n\ndef __init__(self, attribute_name):\n\nself.attribute_name = attribute_name\n\ndef __set__(self, instance, value):\n\nself.__storage[id(instance), self.attribute_name] = value\n\ndef __get__(self, instance, owner=None):\n\nif instance is None: return self\n\nreturn self.__storage[id(instance), self.attribute_name]\n\nEach ExternalStorage object has a single data attribute, attribute_name, which holds the name of the owner class’s data attribute. Whenever an attribute is set we store its value in the private class dictionary, __storage. Similarly, whenever an attribute is retrieved we get it from the __storage dictionary.\n\nAs with all descriptor methods,self is the instance of the descriptor object and instance is the self of the object that contains the descriptor,so here self is an ExternalStorage object and instance is a Point object.\n\n375\n\n376\n\nChapter 8. Advanced Programming Techniques\n\nAlthough __storage is a class attribute,we can access it as self.__storage (just as we can call methods using self.method()), because Python will look for it as an instanceattribute,and not ﬁnding it will then look for it asa classattribute. The one (theoretical) disadvantage of this approach is that if we have a class attribute and an instance attribute with the same name, one would hide the other. (If thiswerereally a problemwecould alwaysrefer totheclassattribute using the class, that is, ExternalStorage.__storage. Although hard-coding the class does not play well with subclassing in general, it doesn’t really matter for private attributes since Python name-mangles the class name into them anyway.)\n\nThe implementation of the __get__() special method is slightly more sophisti- cated than before because we provide a means by which the ExternalStorage instance itself can be accessed. For example,if we have p = Point(3, 4), we can access the x-coordinate with p.x, and we can access the ExternalStorage object that holds all the xs with Point.x.\n\nTo complete our coverage of descriptors we will create the Property descriptor that mimicsthe behavior of the built-in property() function,at least for setters and getters. The code is in Property.py. Here is the complete NameAndExtension class that makes use of it:\n\nclass NameAndExtension:\n\ndef __init__(self, name, extension):\n\nself.__name = name self.extension = extension\n\n@Property def name(self):\n\n# Uses the custom Property descriptor\n\nreturn self.__name\n\n@Property def extension(self):\n\n# Uses the custom Property descriptor\n\nreturn self.__extension\n\n@extension.setter def extension(self, extension):\n\n# Uses the custom Property descriptor\n\nself.__extension = extension\n\nThe usage is just the same as for the built-in @property decorator and for the @propertyName.setter decorator. Here is the start of the Property descriptor’s implementation:\n\nclass Property:\n\ndef __init__(self, getter, setter=None):\n\nself.__getter = getter\n\nFurther Object-Oriented Programming\n\nself.__setter = setter self.__name__ = getter.__name__\n\nThe class’s initializer takes one or two functions as arguments. If it is used as a decorator, it will get just the decorated function and this becomes the getter, while the setter is set to None.We use the getter’s name as the property’sname. So for each property, we have a getter, possibly a setter, and a name.\n\ndef __get__(self, instance, owner=None):\n\nif instance is None: return self\n\nreturn self.__getter(instance)\n\nWhen a property is accessed we return the result of calling the getter func- tion where we have passed the instance as its ﬁrst parameter. At ﬁrst sight, self.__getter() looks like a method call, but it is not. In fact, self.__getter is an attribute, one that happens to hold an object reference to a method that was passed in. So what happens is that ﬁrst we retrieve the attribute (self.__getter), and then we call it as a function (). And because it is called as a function rather than as a method we must pass in the relevant self object explicitly ourselves. And in the case of a descriptor the self object (from the class that is using the descriptor)is called instance (since self is the descriptor object).The same applies to the __set__() method.\n\ndef __set__(self, instance, value):\n\nif self.__setter is None:\n\nraise AttributeError(\"'{0}' is read-only\".format(\n\nself.__name__))\n\nreturn self.__setter(instance, value)\n\nIf no setter has been speciﬁed, we raise an AttributeError; otherwise, we call the setter with the instance and the new value.\n\ndef setter(self, setter):\n\nself.__setter = setter return self.__setter\n\nThis method is called when the interpreter reaches, for example, @exten- sion.setter, with the function it decorates as its setter argument. It stores the setter method it has been given (which can now be used in the __set__() method),and returns the setter,since decorators should return the function or method they decorate.\n\nWe have now looked at three quite different uses of descriptors. Descriptors are a very powerful and ﬂexible feature that can be used to do lots of under- the-hood work while appearing to be simple attributes in their client (own- er) class.\n\n377\n\nSorted- List 269➤\n\n378\n\nChapter 8. Advanced Programming Techniques\n\nClass Decorators\n\nJust as we can create decorators for functions and methods, we can also create decorators for entire classes. Class decorators take a class object (the result of the class statement), and should return a class—normally a modiﬁed version of theclassthey decorate. In thissubsection we will study twoclassdecorators to see how they can be implemented.\n\nIn Chapter 6 we created the SortedList custom collection classthat aggregated a plain list as the private attribute self.__list. Eight of the SortedList meth- odssimply passedon their work to theprivateattribute. For example,hereare how the SortedList.clear() and SortedList.pop() methods were implemented:\n\ndef clear(self):\n\nself.__list = []\n\ndef pop(self, index=-1):\n\nreturn self.__list.pop(index)\n\nThere is nothing we can do about the clear() method since there is no corre- sponding methodfor the list type,but for pop(),andtheother six methodsthat SortedList delegates,we can simply call the list class’scorresponding method. This can be done by using the @delegate class decorator from the book’s Util module. Here is the start of a new version of the SortedList class:\n\n@Util.delegate(\"__list\", (\"pop\", \"__delitem__\", \"__getitem__\",\n\n\"__iter__\", \"__reversed__\", \"__len__\", \"__str__\"))\n\nclass SortedList:\n\nThe ﬁrst argument is the name of the attribute to delegate to, and the second argument is a sequence of one or more methods that we want the delegate() decorator to implement for us so that we don’t have to do the work ourselves. The SortedList class in the SortedListDelegate.py ﬁle uses this approach and therefore does not have any code for the methods listed, even though it fully supports them. Here is the class decorator that implements the methods:\n\ndef delegate(attribute_name, method_names):\n\ndef decorator(cls):\n\nnonlocal attribute_name if attribute_name.startswith(\"__\"):\n\nattribute_name = \"_\" + cls.__name__ + attribute_name\n\nfor name in method_names:\n\nsetattr(cls, name, eval(\"lambda self, *a, **kw: \"\n\n\"self.{0}.{1}(*a, **kw)\".format( attribute_name, name)))\n\nreturn cls\n\nreturn decorator\n\n||\n\nFuzzy- Bool 248➤\n\nFurther Object-Oriented Programming\n\nWe could not use a plain decorator because we want to pass arguments to the decorator,so we have instead created a function that takes our argumentsand that returns a class decorator. The decorator itself takes a single argument, a class (just as a function decorator takes a single function or method as its argument).\n\nWe must use nonlocal so that the nested function uses the attribute_name from the outer scope rather than attempting to use one from its own scope. And we must be able to correct the attribute name if necessary to take account of the name mangling of private attributes. The decorator’s behavior is quite simple: It iterates over all the method names that the delegate() function has been given,and for each one createsa new method which it setsasan attribute on the class with the given method name.\n\nWe have used eval() to create each of the delegated methods since it can be used to execute a single statement,and a lambda statement produces a method or function. For example, the code executed to produce the pop() method is:\n\nlambda self, *a, **kw: self._SortedList__list.pop(*a, **kw)\n\nWe use the * and ** argument forms to allow for any arguments even though the methods being delegated to have speciﬁc argument lists. For example, list.pop() accepts a single index position (or nothing,in which case it defaults to the last item). This is okay because if the wrong number or kinds of argu- ments are passed, the list method that is called to do the work will raise an appropriate exception.\n\nThe second class decorator we will review was also used in Chapter 6. When we implemented the FuzzyBool class we mentioned that we had supplied only the __lt__() and __eq__() special methods (for < and ==), and had generated all the other comparison methods automatically. What we didn’t show was the complete start of the class deﬁnition:\n\n@Util.complete_comparisons class FuzzyBool:\n\nThe other four comparison operators were provided by the complete_compar- isons() classdecorator. Given a classthat deﬁnes only < (or < and ==),the deco- rator producesthe missing comparisonoperatorsby using the following logical equivalences:\n\nx = y ⇔ ¬ (x < y ∨ y < x) x ≠ y ⇔ ¬ (x = y) x > y ⇔ y < x x ≤ y ⇔ ¬ (y < x) x ≥ y ⇔ ¬ (x < y)\n\nIf the class to be decorated has < and ==, the decorator will use them both, falling back to doing everything in terms of < if that is the only operator\n\n379\n\n380\n\nChapter 8. Advanced Programming Techniques\n\nsupplied. (In fact, Python automatically produces > if < is supplied, != if == is supplied, and >= if <= is supplied, so it is sufﬁcient to just implement the three operators <, <=, and == and to leave Python to infer the others. However, using the class decorator reduces the minimum that we must implement to just <. This is convenient, and also ensures that all the comparison operators use the same consistent logic.)\n\ndef complete_comparisons(cls):\n\nassert cls.__lt__ is not object.__lt__, (\n\n\"{0} must define < and ideally ==\".format(cls.__name__))\n\nif cls.__eq__ is object.__eq__:\n\ncls.__eq__ = lambda self, other: (not\n\n(cls.__lt__(self, other) or cls.__lt__(other, self)))\n\ncls.__ne__ = lambda self, other: not cls.__eq__(self, other) cls.__gt__ = lambda self, other: cls.__lt__(other, self) cls.__le__ = lambda self, other: not cls.__lt__(other, self) cls.__ge__ = lambda self, other: not cls.__lt__(self, other) return cls\n\nOne problem that the decorator faces is that class object from which every other class is ultimately derived deﬁnes all six comparison operators, all of which raise a TypeError exception if used. So we need to know whether < and == havebeen reimplemented(and arethereforeusable).Thiscan easily bedone by comparing the relevant special methods in the class being decorated with those in object.\n\nIf the decorated class does not have a custom < the assertion fails because that is the decorator’s minimum requirement. And if there is a custom == we use it; otherwise, we create one. Then all the other methods are created and the decorated class, now with all six comparison methods, is returned.\n\nUsing class decorators is probably the simplest and most direct way of Meta- classes changing classes. Another approach isto use metaclasses,a topic we will cover ➤ 390 later in this chapter.\n\nAbstract Base Classes\n\n||\n\nAn abstract base class (ABC) is a class that cannot be used to create objects. Instead, the purpose of such classes is to deﬁne interfaces, that is, to in effect list the methodsand propertiesthat classesthat inherit the abstract base class must provide. This is useful because we can use an abstract base class as a kind of promise—a promise that any derived class will provide the methods and properties that the abstract base class speciﬁes.★\n\n★ Python’s abstract base classes are described in PEP 3119 (www.python.org/dev/peps/pep-3119), which also includes a very useful rationale and is well worth reading.\n\nFurther Object-Oriented Programming\n\n381\n\nTable 8.3 The Numbers Module’s Abstract Base Classes\n\nABC\n\nInherits\n\nAPI\n\nExamples\n\nNumber\n\nComplex\n\nReal\n\nobject\n\nNumber\n\nComplex\n\n==, !=, +, -, *, /, abs(), bool(), complex(), conjugate(); also real and imag properties\n\n<, <=, ==, !=, >=, >, +, -, *, /, //, %, abs(), bool(), complex(), conjugate(), divmod(), float(), math.ceil(), math.floor(), round(), trunc(); also real and imag properties\n\ncomplex, decimal.Decimal, float, fractions.Fraction, int complex, decimal.Decimal, float, fractions.Fraction, int decimal.Decimal, float, fractions.Fraction, int\n\nRational\n\nReal\n\n<, <=, ==, !=, >=, >, +, -, *, /, //, %, abs(), bool(), complex(), conjugate(), divmod(), float(), math.ceil(), math.floor(), round(), trunc(); also real, imag, numerator, and denominator properties\n\nfractions.Fraction, int\n\nIntegral\n\nRational <, <=, ==, !=, >=, >, +, -, *, /, //,\n\nint\n\n%, <<, >>, ~, &, ^, |, abs(), bool(), complex(), conjugate(), divmod(), float(), math.ceil(), math.floor(), pow(), round(), trunc(); also real, imag, numerator, and denominator properties\n\nAbstract base classes are classes that have at least one abstract method or property. Abstract methods can be deﬁned with no implementation (i.e., their suite is pass, or if we want to force reimplementation in a subclass, raise NotImplementedError()), or with an actual (concrete) implementation that can be invoked from subclasses, for example, when there is a common case. They can also have other concrete (i.e., nonabstract) methods and properties.\n\nClasses that derive from an ABC can be used to create instances only if they reimplement all the abstract methodsand abstract propertiesthey have inher- ited. For those abstract methods that have concrete implementations (even if it is only pass), the derived class could simply use super() to use the ABC’s ver-\n\n382\n\nChapter 8. Advanced Programming Techniques\n\nsion. Any concrete methodsor propertiesare available through inheritance as usual. All ABCs must have a metaclass of abc.ABCMeta (from the abc module), or from one of its subclasses. We cover metaclasses a bit further on.\n\nPython provides two groups of abstract base classes, one in the collections module and the other in the numbers module. They allow us to ask questions about an object; for example, given a variable x, we can see whether it is a se- quence using isinstance(x, collections.MutableSequence) or whether it is a whole number using isinstance(x, numbers.Integral). This is particularly use- ful in view of Python’s dynamic typing where we don’t necessarily know (or care) what an object’s type is, but want to know whether it supports the oper- ations we want to apply to it. The numeric and collection ABCs are listed in Tables8.3and 8.4.The other major ABCis io.IOBase from which all the ﬁle and stream-handling classes derive.\n\nTo fully integrate our own custom numeric and collection classes we ought to make them ﬁt in with the standard ABCs. For example,the SortedList class is a sequence, but as it stands, isinstance(L, collections.Sequence) returns False if L is a SortedList. One easy way to ﬁx this is to inherit the relevant ABC:\n\nclass SortedList(collections.Sequence):\n\nBy making collections.Sequence the base class, the isinstance() test will now return True. Furthermore, we will be required to implement __init__() (or __new__()), __getitem__(), and __len__() (which we do). The collec- tions.Sequence ABC also provides concrete (i.e., nonabstract) implementations for __contains__(), __iter__(), __reversed__(), count(), and index(). In the case of SortedList, we reimplement them all, but we could have used the ABC ver- sions if we wanted to, simply by not reimplementing them. We cannot make SortedList a subclass of collections.MutableSequence even though the list is mutable because SortedList does not have all the methods that a collec- tions.MutableSequence must provide, such as __setitem__() and append(). (The code for this SortedList is in SortedListAbc.py. We will see an alternative ap- proach to making a SortedList into a collections.Sequence in the Metaclasses subsection.)\n\nNow that we have seen how to make a custom class ﬁt in with the standard ABCs, we will turn to another use of ABCs: to provide an interface promise for our own custom classes. We will look at three rather different examples to cover different aspects of creating and using ABCs.\n\nWe will start with a very simple example that shows how to handle read- able/writable properties. The class is used to represent domestic appliances. Every appliancethat iscreatedmust have a read-only modelstring and a read- able/writable price. We also want to ensure that the ABC’s __init__() is reim- plemented. Here’s the ABC (from Appliance.py); we have not shown the import\n\nMeta- classes ➤ 390\n\nMeta- classes ➤ 390",
      "page_number": 359
    },
    {
      "number": 38,
      "title": "Segment 38 (pages 372-381)",
      "start_page": 372,
      "end_page": 381,
      "detection_method": "topic_boundary",
      "content": "Further Object-Oriented Programming\n\nTable 8.4 The Collections Module’s Main Abstract Base Classes\n\nABC\n\nInherits\n\nAPI\n\nExamples\n\nCallable\n\nContainer\n\nHashable\n\nIterable\n\nobject\n\nobject\n\nobject\n\nobject\n\n()\n\nin\n\nhash()\n\niter()\n\nAll functions, methods, and lambdas bytearray, bytes, dict, frozenset, list, set, str, tuple bytes, frozenset, str, tuple bytearray, bytes, collections.deque, dict, frozenset, list, set, str, tuple\n\nIterator\n\nIterable\n\niter(), next()\n\nSized\n\nobject\n\nlen()\n\nbytearray, bytes, collections.deque, dict, frozenset, list, set, str, tuple\n\nMapping\n\nMutable- Mapping\n\nSequence\n\nMutable- Sequence\n\nSet\n\nMutableSet\n\nContainer, Iterable, Sized\n\nMapping\n\nContainer, Iterable, Sized Container, Iterable, Sized\n\nContainer, Iterable, Sized Set\n\n==, !=, [], len(), iter(), in, get(), items(), keys(), values() ==, !=, [], del, len(), iter(), in, clear(), get(), items(), keys(), pop(), popitem(), setdefault(), update(), values() [], len(), iter(), reversed(), in, count(), index()\n\n[], +=, del, len(), iter(), reversed(), in, append(), count(), extend(), index(), insert(), pop(), remove(), reverse() <, <=, ==, !=, =>, >, &, |, ^, len(), iter(), in, isdisjoint()\n\n<, <=, ==, !=, =>, >, &, |, ^, &=, |=, ^=, -=, len(), iter(), in, add(), clear(), discard(), isdisjoint(), pop(), remove()\n\ndict\n\ndict\n\nbytearray, bytes, list, str, tuple\n\nbytearray, list\n\nfrozenset, set\n\nset\n\n383\n\n384\n\nChapter 8. Advanced Programming Techniques\n\nabc statement which is needed for the abstractmethod() and abstractproperty() functions, both of which can be used as decorators:\n\nclass Appliance(metaclass=abc.ABCMeta):\n\n@abc.abstractmethod def __init__(self, model, price):\n\nself.__model = model self.price = price\n\ndef get_price(self):\n\nreturn self.__price\n\ndef set_price(self, price): self.__price = price\n\nprice = abc.abstractproperty(get_price, set_price)\n\n@property def model(self):\n\nreturn self.__model\n\nWe have set the class’s metaclass to be abc.ABCMeta since this is a requirement for ABCs; any abc.ABCMeta subclass can be used instead, of course. We have made __init__() an abstract method to ensure that it is reimplemented, and we have also provided an implementation which we expect (but can’t force) inheritors to call. To make an abstract readable/writable property we cannot use decorator syntax; also we have not used private names for the getter and setter since doing so would be inconvenient for subclasses.\n\nThe price property isabstract(sowecannotusethe @property decorator),andis readable/writable. Here we follow a common pattern for when we have private readable/writable data (e.g., __price) as a property: We initialize the property in the __init__() method rather than setting the private data directly—this ensures that the setter is called (and may potentially do validation or other work, although it doesn’t in this particular example).\n\nThe model property is not abstract, so subclasses don’t need to reimplement it, and we can make it a property using the @property decorator. Here we follow a common pattern for when we have private read–only data (e.g., __model) as a property:We set the private __model data once in the __init__() method, and provide read access via the read–only model property.\n\nNote that no Appliance objects can be created, because the class contains abstract attributes. Here is an example subclass:\n\nFurther Object-Oriented Programming\n\nclass Cooker(Appliance):\n\ndef __init__(self, model, price, fuel): super().__init__(model, price) self.fuel = fuel\n\nprice = property(lambda self: super().price,\n\nlambda self, price: super().set_price(price))\n\nThe Cooker class must reimplement the __init__() method and the price property. For theproperty wehavejust passedon allthework tothebaseclass. The model read-only property is inherited. We could create many more classes based on Appliance, such as Fridge, Toaster, and so on.\n\nThe next ABC we will look at is even shorter; it is an ABC for text-ﬁltering functors (in ﬁle TextFilter.py):\n\nclass TextFilter(metaclass=abc.ABCMeta):\n\n@abc.abstractproperty def is_transformer(self):\n\nraise NotImplementedError()\n\n@abc.abstractmethod def __call__(self):\n\nraise NotImplementedError()\n\nThe TextFilter ABC provides no functionality at all; it exists purely to deﬁne an interface,in thiscase an is_transformer read-only property and a __call__() method, that all its subclasses must provide. Since the abstract property and method have no implementations we don’t want subclasses to call them, so instead of using an innocuous pass statement we raise an exception if they are used (e.g., via a super() call).\n\nHere is one simple subclass:\n\nclass CharCounter(TextFilter):\n\n@property def is_transformer(self):\n\nreturn False\n\ndef __call__(self, text, chars):\n\ncount = 0 for c in text:\n\nif c in chars: count += 1\n\nreturn count\n\n385\n\n386\n\nChapter 8. Advanced Programming Techniques\n\nThis text ﬁlter is not a transformer because rather than transforming the text it is given, it simply returns a count of the speciﬁed characters that occur in the text. Here is an example of use:\n\nvowel_counter = CharCounter() vowel_counter(\"dog fish and cat fish\", \"aeiou\")\n\n# returns: 5\n\nTwo other text ﬁlters are provided,both of which are transformers:RunLength- Encode and RunLengthDecode. Here is how they are used:\n\nrle_encoder = RunLengthEncode() rle_text = rle_encoder(text) ... rle_decoder = RunLengthDecode() original_text = rle_decoder(rle_text)\n\nThe run length encoder converts a string into UTF-8 encoded bytes, and replaces 0x00 bytes with the sequence 0x00, 0x01, 0x00, and any sequence of threeto 255repeatedbyteswith thesequence 0x00,count,byte.If thestring has lots of runs of four or more identical consecutive charactersthis can produce a shorter byte string than the raw UTF-8encoded bytes. The run length decoder takes a run length encoded byte string and returnsthe original string. Here is the start of the RunLengthDecode class:\n\nclass RunLengthDecode(TextFilter):\n\n@property def is_transformer(self):\n\nreturn True\n\ndef __call__(self, rle_bytes):\n\n...\n\nWe have omitted the body of the __call__() method, although it is in the source that accompanies this book. The RunLengthEncode class has exactly the same structure.\n\nThe last ABC we will look at provides an Application Programming Interface (API) and a default implementation for an undo mechanism. Here is the complete ABC (from ﬁle Abstract.py):\n\nclass Undo(metaclass=abc.ABCMeta):\n\n@abc.abstractmethod def __init__(self):\n\nself.__undos = []\n\nFurther Object-Oriented Programming\n\n@abc.abstractproperty def can_undo(self):\n\nreturn bool(self.__undos)\n\n@abc.abstractmethod def undo(self):\n\nassert self.__undos, \"nothing left to undo\" self.__undos.pop()(self)\n\ndef add_undo(self, undo):\n\nself.__undos.append(undo)\n\nThe __init__() and undo() methods must be reimplemented since they are both abstract; and so must the read-only can_undo property. Subclasses don’t have to reimplement the add_undo() method, although they are free to do so. The undo() method is slightly subtle. The self.__undos list is expected to hold object references to methods. Each method must cause the corresponding action to be undone if it is called—this will be clearer when we look at an Undo subclass in a moment. So to perform an undo we pop the last undo method off the self.__undos list,and then call the method as a function,passing self as an argument. (Wemust passself becausethemethodisbeing called asa function and not as a method.)\n\nHere is the beginning of the Stack class; it inherits Undo, so any actions per- formed on it can be undone by calling Stack.undo() with no arguments:\n\nclass Stack(Undo):\n\ndef __init__(self):\n\nsuper().__init__() self.__stack = []\n\n@property def can_undo(self):\n\nreturn super().can_undo\n\ndef undo(self):\n\nsuper().undo()\n\ndef push(self, item):\n\nself.__stack.append(item) self.add_undo(lambda self: self.__stack.pop())\n\ndef pop(self):\n\nitem = self.__stack.pop() self.add_undo(lambda self: self.__stack.append(item)) return item\n\n387\n\n388\n\nChapter 8. Advanced Programming Techniques\n\nWe have omitted Stack.top() and Stack.__str__() since neither adds anything new and neither interacts with the Undo base class. For the can_undo property and the undo() method, we simply pass on the work to the base class. If these two were not abstract we would not need to reimplement them at all and the same effect would be achieved; but in this case we wanted to force subclasses to reimplement them to encourage undo to be taken account of in the subclass. For push() and pop() we perform the operation and also add a function to the undo list which will undo the operation that has just been performed.\n\nAbstract base classes are most useful in large-scale programs, libraries, and application frameworks, where they can help ensure that irrespective of implementation details or author, classes can work cooperatively together because they provide the APIs that their ABCs specify.\n\nMultiple Inheritance\n\nMultipleinheritanceiswhereoneclassinheritsfromtwoor moreother classes. Although Python (and, for example, C++) fully supports multiple inheritance, some languages—most notably, Java—don’t allow it. One problem is that multiple inheritancecan lead to the same classbeing inherited more than once (e.g.,if twoof thebaseclassesinherit fromthesameclass),andthismeansthat the version of a method that is called, if it is not in the subclass but is in two or more of the base classes (or their base classes, etc.), depends on the method resolutionorder,whichpotentially makesclassesthatusemultipleinheritance somewhat fragile.\n\nMultiple inheritance can generally be avoided by using single inheritance(one base class), and setting a metaclass if we want to support an additional API, since as we will see in the next subsection, a metaclass can be used to give the promise of an API without actually inheriting any methodsor data attributes. An alternative is to use multiple inheritance with one concrete class and one or more abstract base classes for additional APIs. And another alternative is to use single inheritance and aggregate instances of other classes.\n\nNonetheless,in somecases,multipleinheritancecan providea very convenient solution. For example, suppose we want to create a new version of the Stack class from the previous subsection, but want the class to support loading and saving using a pickle. We might well want to add the loading and saving functionality to several classes, so we will implement it in a class of its own:\n\nclass LoadSave:\n\ndef __init__(self, filename, *attribute_names):\n\nself.filename = filename self.__attribute_names = [] for name in attribute_names:\n\nif name.startswith(\"__\"):\n\n||\n\nFurther Object-Oriented Programming\n\nname = \"_\" + self.__class__.__name__ + name\n\nself.__attribute_names.append(name)\n\ndef save(self):\n\nwith open(self.filename, \"wb\") as fh:\n\ndata = [] for name in self.__attribute_names:\n\ndata.append(getattr(self, name))\n\npickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)\n\ndef load(self):\n\nwith open(self.filename, \"rb\") as fh:\n\ndata = pickle.load(fh) for name, value in zip(self.__attribute_names, data):\n\nsetattr(self, name, value)\n\nThe class has two attributes: filename, which is public and can be changed at any time, and __attribute_names, which is ﬁxed and can be set only when the instance is created. The save() method iterates over all the attribute names and creates a list called data that holds the value of each attribute to be saved; it then saves the data into a pickle. The with statement ensures that the ﬁle is closed if it wassuccessfully opened,and any ﬁleor pickleexceptionsarepassed up to the caller. The load() method iterates over the attribute names and the corresponding data items that have been loaded and sets each attribute to its loaded value.\n\nHere is the start of the FileStack class that multiply-inherits the Undo class from the previous subsection and this subsection’s LoadSave class:\n\nclass FileStack(Undo, LoadSave):\n\ndef __init__(self, filename):\n\nUndo.__init__(self) LoadSave.__init__(self, filename, \"__stack\") self.__stack = []\n\ndef load(self):\n\nsuper().load() self.clear()\n\nThe rest of the class is just the same as the Stack class, so we have not repro- duced it here. Instead of using super() in the __init__() method we must spec- ify the base classesthat we initialize since super() cannot guessour intentions. For the LoadSave initialization we pass the ﬁlename to use and also the names of the attributes we want saved; in this case just one, the private __stack. (We don’t want to save the __undos; and nor could we in this case since it is a list of methods and is therefore unpicklable.)\n\n389\n\n390\n\nChapter 8. Advanced Programming Techniques\n\nThe FileStack classhasallthe Undo methods,andalsothe LoadSave class’ssave() and load() methods. We have not reimplemented save() since it works ﬁne, but for load() we must clear the undo stack after loading. This is necessary becausewemight doa save,then dovariouschanges,and then a load. Theload wipes out what went before, so any undos no longer make sense. The original Undo class did not have a clear() method, so we had to add one:\n\ndef clear(self):\n\n# In class Undo\n\nself.__undos = []\n\nIn the Stack.load() method we have used super() to call LoadSave.load() be- cause there is no Undo.load() method to cause ambiguity. If both base class- es had had a load() method, the one that would get called would depend on Python’s method resolution order. We prefer to use super() only when there is no ambiguity, and to use the appropriate base name otherwise, so we never rely on the method resolution order. For the self.clear() call,again there isno ambiguity since only the Undo class has a clear() method, and we don’t need to use super() since (unlike load()) FileStack does not have a clear() method.\n\nWhat would happen if, later on, a clear() method was added to the FileStack class? It would break the load() method. One solution would be to call su- per().clear() inside load() instead of plain self.clear(). This would result in the ﬁrst super-class’s clear() method that was found being used. To protect against such problemswe could make it a policy to use hard-coded base classes when using multipleinheritance(in thisexample,calling Undo.clear(self)).Or we could avoid multiple inheritance altogether and use aggregation,for exam- ple, inheriting the Undo class and creating a LoadSave class designed for aggre- gation.\n\nWhat multiple inheritance has given us here is a mixture of two rather dif- ferent classes, without the need to implement any of the undo or the loading and saving ourselves,relying instead on the functionality provided by the base classes. Thiscan be very convenient and worksespecially well when theinher- ited classes have no overlapping APIs.\n\nMetaclasses\n\nA metaclass is to a class what a class is to an instance; that is, a metaclass is used to create classes, just as classes are used to create instances. And just as we can ask whether an instance belongs to a class by using isinstance(), we can ask whether a classobject (such as dict,int,or SortedList)inheritsanother class using issubclass().\n\nThe simplest use of metaclasses is to make custom classes ﬁt into Python’s standard ABC hierarchy. For example, to make SortedList a collections.\n\n||\n\nFurther Object-Oriented Programming\n\nSequence, instead of inheriting the ABC (as we showed earlier), we can simply register the SortedList as a collections.Sequence:\n\nclass SortedList:\n\n...\n\ncollections.Sequence.register(SortedList)\n\nAfter the classis deﬁned normally,we register it with the collections.Sequence ABC. Registering a class like this makes it a virtual subclass.★ A virtual sub- classreportsthat it isa subclassof theclassor classesit isregisteredwith (e.g., using isinstance() or issubclass()), but does not inherit any data or methods from any of the classes it is registered with.\n\nRegistering a class like this provides a promise that the class provides the API of the classes it is registered with, but does not provide any guarantee that it will honor itspromise. One use of metaclassesisto provideboth a promiseand a guarantee about a class’s API. Another use is to modify a class in some way (like a class decorator does). And of course, metaclasses can be used for both purposes at the same time.\n\nSuppose we want to create a group of classesthat all provide load() and save() methods. We can do this by creating a class that when used as a metaclass, checks that these methods are present:\n\nclass LoadableSaveable(type):\n\ndef __init__(cls, classname, bases, dictionary):\n\nsuper().__init__(classname, bases, dictionary) assert hasattr(cls, \"load\") and \\\n\nisinstance(getattr(cls, \"load\"),\n\ncollections.Callable), (\"class '\" +\n\nclassname + \"' must provide a load() method\")\n\nassert hasattr(cls, \"save\") and \\\n\nisinstance(getattr(cls, \"save\"),\n\ncollections.Callable), (\"class '\" +\n\nclassname + \"' must provide a save() method\")\n\nClasses that are to serve as metaclasses must inherit from the ultimate metaclass base class, type, or one of its subclasses.\n\nNote that this class is called when classes that use it are instantiated, in all probability not very often, so the runtime cost is extremely low. Notice also that we must perform the checks after the class has been created (using the super() call), since only then will the class’s attributes be available in the class itself. (The attributesare in the dictionary,but we prefer to work on the actual initialized class when doing checks.)\n\n★In Python terminology, virtual does not mean the same thing as it does in C++ terminology.\n\n391\n\ncol- lections ABCs 383➤\n\n392\n\nChapter 8. Advanced Programming Techniques\n\nWe could have checked that the load and save attributes are callable using hasattr() to check that they have the __call__ attribute, but we prefer to check whether they are instancesof collections.Callable instead. The collec- tions.Callable abstractbaseclassprovidesthepromise(butnoguarantee)that instances of its subclasses (or virtual subclasses) are callable.\n\nOnce the class has been created (using type.__new__() or a reimplementation of __new__()), the metaclass is initialized by calling its __init__() method. The arguments given to __init__() are cls, the class that’s just been created; classname, the class’s name (also available from cls.__name__); bases, a list of the class’s base classes (excluding object, and therefore possibly empty); and dictionary that holds the attributes that became class attributes when the cls class was created, unless we intervened in a reimplementation of the meta- class’s __new__() method.\n\nHere are a couple of interactive examples that show what happens when we create classes using the LoadableSaveable metaclass:\n\n>>> class Bad(metaclass=Meta.LoadableSaveable): ... Traceback (most recent call last): ... AssertionError: class 'Bad' must provide a load() method\n\ndef some_method(self): pass\n\nThemetaclassspeciﬁesthat classesusing it must providecertainmethods,and when they don’t, as in this case, an AssertionError exception is raised.\n\n>>> class Good(metaclass=Meta.LoadableSaveable): ... ... >>> g = Good()\n\ndef load(self): pass def save(self): pass\n\nThe Good classhonorsthe metaclass’sAPI requirements,even if it doesn’t meet our informal expectations of how it should behave.\n\nWe can also use metaclassesto change the classesthat use them. If thechange involves the name, base classes, or dictionary of the class being created (e.g., its slots), then we need to reimplement the metaclass’s __new__() method; but for other changes, such as adding methods or data attributes,reimplementing __init__() issufﬁcient,although thiscan also be donein __new__().We will now look at a metaclass that modiﬁes the classes it is used with purely through its __new__() method.\n\nAs an alternative to using the @property and @name.setter decorators, we could create classeswhere we use a simple naming convention to identify properties. For example, if a class has methods of the form get_name() and set_name(), we would expect the class to have a private __name property accessed using",
      "page_number": 372
    },
    {
      "number": 39,
      "title": "Segment 39 (pages 382-389)",
      "start_page": 382,
      "end_page": 389,
      "detection_method": "topic_boundary",
      "content": "Further Object-Oriented Programming\n\ninstance.name for getting and setting. This can all be done using a metaclass. Here is an example of a class that uses this convention:\n\nclass Product(metaclass=AutoSlotProperties):\n\ndef __init__(self, barcode, description):\n\nself.__barcode = barcode self.description = description\n\ndef get_barcode(self):\n\nreturn self.__barcode\n\ndef get_description(self):\n\nreturn self.__description\n\ndef set_description(self, description):\n\nif description is None or len(description) < 3:\n\nself.__description = \"<Invalid Description>\"\n\nelse:\n\nself.__description = description\n\nWe must assign to the private __barcode property in the initializer since there is no setter for it; another consequence of this is that barcode is a read-only property. On the other hand,description isa readable/writableproperty. Here are some examples of interactive use:\n\n>>> product = Product(\"101110110\", \"8mm Stapler\") >>> product.barcode, product.description ('101110110', '8mm Stapler') >>> product.description = \"8mm Stapler (long)\" >>> product.barcode, product.description ('101110110', '8mm Stapler (long)')\n\nIf we attempt to assign to the bar code an AttributeError exception is raised with the error text “can’t set attribute”.\n\nIf we look at the Product class’s attributes (e.g., using dir()), the only public ones to be found are barcode and description. The get_name() and set_name() methods are no longer there—they have been replaced with the name property. And the variables holding the bar code and description are also private (__bar- code and __description), and have been added as slots to minimize the class’s memory use. This is all done by the AutoSlotProperties metaclass which is im- plemented in a single method:\n\nclass AutoSlotProperties(type):\n\ndef __new__(mcl, classname, bases, dictionary):\n\nslots = list(dictionary.get(\"__slots__\", []))\n\n393\n\n394\n\nChapter 8. Advanced Programming Techniques\n\nfor getter_name in [key for key in dictionary\n\nif key.startswith(\"get_\")]:\n\nif isinstance(dictionary[getter_name],\n\ncollections.Callable):\n\nname = getter_name[4:] slots.append(\"__\" + name) getter = dictionary.pop(getter_name) setter_name = \"set_\" + name setter = dictionary.get(setter_name, None) if (setter is not None and\n\nisinstance(setter, collections.Callable)): del dictionary[setter_name]\n\ndictionary[name] = property(getter, setter)\n\ndictionary[\"__slots__\"] = tuple(slots) return super().__new__(mcl, classname, bases, dictionary)\n\nA metaclass’s__new__() classmethod iscalled with the metaclass,and theclass name, base classes, and dictionary of the class that is to be created. We must use a reimplementation of __new__() rather than __init__() because we want to change the dictionary before the class is created.\n\nWe begin by copying the __slots__ collection, creating an empty one if none is present, and making sure we have a list rather than a tuple so that we can modify it. For every attribute in the dictionary we pick out those that begin with \"get_\" and that are callable, that is, those that are getter methods. For each getter we add a private name to the slots to store the corresponding data; for example,given getter get_name() we add __name to the slots. We then take a referenceto thegetter and deleteit fromthedictionary under itsoriginalname (this is done in one go using dict.pop()).We do the same for the setter if one is present, and then we create a new dictionary item with the desired property name as its key; for example, if the getter is get_name() the property name is name. We set the item’s value to be a property with the getter and setter (which might be None) that we have found and removed from the dictionary.\n\nAt the end we replace the original slots with the modiﬁed slots list which has a private slot for each property that was added,and call on the base classto ac- tually createtheclass,but using our modiﬁed dictionary. Note that in thiscase we must passthe metaclassexplicitly in the super() call;thisisalwaysthe case for calls to __new__() because it is a class method and not an instance method.\n\nFor thisexamplewedidn’tneed towritean __init__() methodbecausewehave done all the work in __new__(), but it is perfectly possible to reimplement both __new__() and __init__() doing different work in each.\n\nIf we consider hand-cranked drills to be analogous to aggregation and inher- itance and electric drills the analog of decorators and descriptors, then meta- classes are at the laser beam end of the scale when it comes to power and\n\nFurther Object-Oriented Programming\n\nversatility. Metaclasses are the last tool to reach for rather than the ﬁrst, ex- cept perhapsfor application framework developerswho need to provide power- fulfacilitiestotheir userswithoutmaking theusersgothroughhoopstorealize the beneﬁts on offer.\n\nFunctional-Style Programming\n\nFunctional-style programming is an approach to programming where com- putations are built up from combining functions that don’t modify their argu- ments and that don’t refer to or change the program’s state, and that provide their resultsas return values. One strong appeal of this kind of programming is that (in theory), it is much easier to develop functions in isolation and to de- bug functional programs. This is helped by the fact that functional programs don’t have state changes,so it is possible to reason about their functionsmath- ematically.\n\nThree concepts that are strongly associated with functional programming are mapping, ﬁltering, and reducing. Mapping involves taking a function and an iterable and producing a new iterable (or a list) where each item is the result of calling the function on the corresponding item in the original iterable. This is supported by the built-in map() function, for example:\n\nlist(map(lambda x: x ** 2, [1, 2, 3, 4]))\n\n# returns: [1, 4, 9, 16]\n\nThe map() function takes a function and an iterable as its arguments and for efﬁciency it returns an iterator rather than a list. Here we forced a list to be created to make the result clearer:\n\n[x ** 2 for x in [1, 2, 3, 4]]\n\n# returns: [1, 4, 9, 16]\n\nA generator expression can often be used in place of map(). Here we have used a list comprehension to avoid the need to use list(); to make it a generator we just have to change the outer brackets to parentheses.\n\nFiltering involves taking a function and an iterable and producing a new it- erable where each item is from the original iterable—providing the function returns True when called on the item. The built-in filter() function sup- ports this:\n\nlist(filter(lambda x: x > 0, [1, -2, 3, -4])) # returns: [1, 3]\n\nThe filter() function takes a function and an iterable as its arguments and returns an iterator.\n\n[x for x in [1, -2, 3, -4] if x > 0]\n\n# returns: [1, 3]\n\n395\n\n|||\n\n396\n\nChapter 8. Advanced Programming Techniques\n\nThe filter() function can always be replaced with a generator expression or with a list comprehension.\n\nReducing involves taking a function and an iterable and producing a single result value. The way this works is that the function is called on the iterable’s ﬁrst two values, then on the computed result and the third value, then on the computed result and the fourth value,and so on, until all the values have been used. The functools module’s functools.reduce() function supports this. Here are two lines of code that do the same computation:\n\nfunctools.reduce(lambda x, y: x * y, [1, 2, 3, 4]) # returns: 24 # returns: 24 functools.reduce(operator.mul, [1, 2, 3, 4])\n\nThe operator module has functions for all of Python’s operators speciﬁcally to make functional-style programming easier. Here, in the second line, we have used the operator.mul() function rather than having to create a multiplication function using lambda as we did in the ﬁrst line.\n\nPython also provides some built-in reducing functions: all(), which given an iterable, returns True if all the iterable’s items return True when bool() is ap- plied to them; any(), which returns True if any of the iterable’s items is True; max(), which returns the largest item in the iterable; min(), which returns the smallest item in the iterable; and sum(), which returns the sum of the iter- able’s items.\n\nNow that we have covered the key concepts,let uslook at a few more examples. We will start with a couple of ways to get the total size of all the ﬁles in list files:\n\nfunctools.reduce(operator.add, (os.path.getsize(x) for x in files)) functools.reduce(operator.add, map(os.path.getsize, files))\n\nUsing map() is often shorter than the equivalent list comprehension or genera- tor expression except where there is a condition. We’ve used operator.add() as the addition function instead of lambda x, y: x + y.\n\nIf we only wanted to count the .py ﬁle sizes we can ﬁlter out non-Python ﬁles. Here are three ways to do this:\n\nfunctools.reduce(operator.add, map(os.path.getsize,\n\nfilter(lambda x: x.endswith(\".py\"), files)))\n\nfunctools.reduce(operator.add, map(os.path.getsize,\n\n(x for x in files if x.endswith(\".py\"))))\n\nfunctools.reduce(operator.add, (os.path.getsize(x)\n\nfor x in files if x.endswith(\".py\")))\n\nArguably, the second and third versions are better because they don’t require us to create a lambda function, but the choice between using generator expres-\n\nop- erator. attrget- ter() 369➤\n\nFunctional-StyleProgramming\n\nsions (or list comprehensions) and map() and filter() is most often purely a matter of personal programming style.\n\nUsing map(), filter(), and functools.reduce() often leads to the elimination of loops, as the examples we have seen illustrate. These functions are useful when converting code written in a functional language, but in Python we can usually replace map() with a list comprehension and filter() with a list comprehension with a condition, and many cases of functools.reduce() can be eliminated by using one of Python’sbuilt-in functional functionssuch as all(), any(), max(), min(), and sum(). For example:\n\nsum(os.path.getsize(x) for x in files if x.endswith(\".py\"))\n\nThis achieves the same thing as the previous three examples, but is much more compact.\n\noperator module In addition to providing functions for Python’s operators, the also provides the operator.attrgetter() and operator.itemgetter() functions, the ﬁrst of which we brieﬂy met earlier in this chapter. Both of these return functions which can then be called to extract the speciﬁed attributes or items.\n\nWhereas slicing can be used to extract a sequence of part of a list, and slicing with striding can be used to extract a sequence of parts (say, every third item with L[::3]), operator.itemgetter() can be used to extract a sequence of arbi- trary parts, for example, operator.itemgetter(4, 5, 6, 11, 18)(L). The function returned by operator.itemgetter() does not have to be called immediately and thrown away as we have done here; it could be kept and passed as the function argument to map(), filter(), or functools.reduce(), or used in a dictionary, list, or set comprehension.\n\nWhen we want to sort we can specify a key function. This function can be any function, for example, a lambda function, a built-in function or method (such as str.lower()), or a function returned by operator.attrgetter(). For example, assuming list L holds objects with a priority attribute,we can sort the list into priority order like this: L.sort(key=operator.attrgetter(\"priority\")).\n\nIn addition to the functools and operator modulesalready mentioned,the iter- tools module can also be useful for functional-style programming. For exam- ple, although it is possible to iterate over two or more lists by concatenating them, an alternative is to use itertools.chain() like this:\n\nfor value in itertools.chain(data_list1, data_list2, data_list3):\n\ntotal += value\n\nThe itertools.chain() function returnsan iterator that givessuccessivevalues from the ﬁrst sequence it is given, then successive values from the second sequence, and so on until all the values from all the sequences are used. The itertools module hasmany other functions,and itsdocumentationgivesmany\n\n397\n\n398\n\nChapter 8. Advanced Programming Techniques\n\nsmall yet useful examples and is well worth reading. (Note also that a couple of new functions were added to the itertools module with Python 3.1.)\n\nPartial Function Application\n\nPartial function application is the creation of a function from an existing function and some arguments to produce a new function that does what the original function did, but with some arguments ﬁxed so that callers don’t have to pass them. Here’s a very simple example:\n\nenumerate1 = functools.partial(enumerate, start=1) for lino, line in enumerate1(lines):\n\nprocess_line(i, line)\n\nThe ﬁrst line creates a new function, enumerate1(), that wraps the given func- tion (enumerate()) and a keyword argument (start=1) so that when enumerate1() is called it calls the original function with the ﬁxed argument—and with any other arguments that are given at the time it is called, in this case lines. Here we have used the enumerate1() function to provide conventional line counting starting from line 1.\n\nUsing partial function application can simplify our code, especially when we want to call the same functionswith the same argumentsagain and again. For example, instead of specifying the mode and encoding arguments every time we call open() to process UTF-8 encoded text ﬁles, we could create a couple of functions with these arguments ﬁxed:\n\nreader = functools.partial(open, mode=\"rt\", encoding=\"utf8\") writer = functools.partial(open, mode=\"wt\", encoding=\"utf8\")\n\nNow we can open text ﬁles for reading by calling reader(filename) and for writing by calling writer(filename).\n\nOnevery commonusecasefor partialfunctionapplicationisin GUI(Graphical User Interface) programming (covered in Chapter 15), where it is often conve- nient to have one particular function called when any one of a set of buttons is pressed. For example:\n\nloadButton = tkinter.Button(frame, text=\"Load\",\n\ncommand=functools.partial(doAction, \"load\"))\n\nsaveButton = tkinter.Button(frame, text=\"Save\",\n\ncommand=functools.partial(doAction, \"save\"))\n\nThis example uses the tkinter GUI library that comes as standard with Python. The tkinter.Button class is used for buttons—here we have created two, both contained inside the same frame,and each with a text that indicates its purpose. Each button’s command argument is set to the function that tkinter\n\n||\n\nyield state- ment 341➤\n\nFunctional-StyleProgramming\n\nmust call when the button is pressed, in this case the doAction() function. We have used partial function application to ensure that the ﬁrst argument given to the doAction() function is a string that indicates which button called it so that doAction() is able to decide what action to perform.\n\nCoroutines\n\nCoroutines are functions whose processing can be suspended and resumed at speciﬁc points. So,typically,a coroutine will execute up to a certain statement, then suspend execution while waiting for some data. At this point other parts of the program can continue to execute (usually other coroutines that aren’t suspended). Once the data is received the coroutine resumes from the point it wassuspended,performsprocessing (presumably based on thedata it got),and possibly sending its results to another coroutine. Coroutines are said to have multiple entry and exit points,since they can have more than one place where they suspend and resume.\n\nCoroutines are useful when we want to apply multiple functions to the same pieces of data, or when we want to create data processing pipelines, or when we want to have a master function with slave functions. Coroutines can also be used to provide simpler and lower-overhead alternatives to threading. A fewcoroutine-basedpackagesthatprovidelightweightthreading areavailable from the Python Package Index, pypi.python.org/pypi.\n\nIn Python,a coroutineisa functionthattakesitsinput froma yield expression. It may also send results to a receiver function (which itself must be a corou- tine).Whenever a coroutine reaches a yield expression it suspends waiting for data; and once it receives data, it resumes execution from that point. A corou- tine can have more than one yield expression, although each of the coroutine examples we will review has only one.\n\nPerforming Independent Actions on Data\n\nIf we want to perform a set of independent operations on some data, the conventional approach is to apply each operation in turn. The disadvantageof this is that if one of the operations is slow, the program as a whole must wait for the operation to complete before going on to the next one. A solution to this is to use coroutines. We can implement each operation as a coroutine and then start them all off. If one is slow it won’t affect the others—at least not until they run out of data to process—since they all operate independently.\n\nFigure8.2illustratestheuseof coroutinesforconcurrentprocessing. Intheﬁg- ure, three coroutines (each presumably doing a different job) process the same two data items—and take different amounts of time to do their work. In the ﬁgure, coroutine1() works quite quickly, coroutine2() works slowly, and corou- tine3() varies. Once all three coroutines have been given their initial data\n\n399\n\n||\n\n|\n\n400\n\nChapter 8. Advanced Programming Techniques\n\nStep\n\nAction\n\ncoroutine1()\n\ncoroutine2()\n\ncoroutine3()\n\n1 Create coroutines\n\nWaiting\n\nWaiting\n\nWaiting\n\n2\n\ncoroutine1.send(\"a\") Process \"a\"\n\nWaiting\n\nWaiting\n\n3\n\ncoroutine2.send(\"a\") Process \"a\"\n\nProcess \"a\"\n\nWaiting\n\n4\n\ncoroutine3.send(\"a\") Waiting\n\nProcess \"a\"\n\nProcess \"a\"\n\n5\n\ncoroutine1.send(\"b\") Process \"b\"\n\nProcess \"a\"\n\nProcess \"a\"\n\n6\n\ncoroutine2.send(\"b\") Process \"b\"\n\nProcess \"a\" (\"b\" pending)\n\nProcess \"a\"\n\n7\n\ncoroutine3.send(\"b\") Waiting\n\nProcess \"a\" (\"b\" pending)\n\nProcess \"b\"\n\n8\n\nWaiting\n\nProcess \"b\"\n\nProcess \"b\"\n\n9\n\nWaiting\n\nProcess \"b\"\n\nWaiting\n\n10\n\nWaiting\n\nProcess \"b\"\n\nWaiting\n\n11\n\nWaiting\n\nWaiting\n\nWaiting\n\n12\n\ncoroutineN.close()\n\nFinished\n\nFinished\n\nFinished\n\nFigure 8.2 Sending two items of data to three coroutines\n\nto process, if one is ever waiting (because it ﬁnishes ﬁrst), the others continue to work, which minimizes processor idle time. Once we are ﬁnished using the coroutines we call close() on each of them; this stops them from waiting for more data, which means they won’t consume any more processor time.\n\nTo create a coroutine in Python, we simply create a function that has at least one yield expression—normally inside an inﬁnite loop. When a yield is reached the coroutine’sexecution issuspendedwaiting for data. Once thedata is received the coroutine resumes processing (from the yield expression on- ward),and when it has ﬁnished it loops back to the yield to wait for more data. While one or more coroutines are suspended waiting for data, another one can execute. Thiscanproducegreaterthroughputthansimply executing functions one after the other linearly.\n\nWe will show how performing independent operations works in practice by applying several regular expressions to the text in a set of HTML ﬁles. The purpose is to output each ﬁle’s URLs and level 1 and level 2 headings. We’ll start by looking at the regular expressions, then the creation of the coroutine “matchers”,and then we will look at the coroutines and how they are used.\n\nURL_RE = re.compile(r\"\"\"href=(?P<quote>['\"])(?P<url>[^\\1]+?)\"\"\"\n\nr\"\"\"(?P=quote)\"\"\", re.IGNORECASE)\n\nflags = re.MULTILINE|re.IGNORECASE|re.DOTALL H1_RE = re.compile(r\"<h1>(?P<h1>.+?)</h1>\", flags) H2_RE = re.compile(r\"<h2>(?P<h2>.+?)</h2>\", flags)",
      "page_number": 382
    },
    {
      "number": 40,
      "title": "Segment 40 (pages 390-401)",
      "start_page": 390,
      "end_page": 401,
      "detection_method": "topic_boundary",
      "content": "Genera- tors 341➤\n\nDecora- tors 356➤\n\nFunctional-StyleProgramming\n\nTheseregular expressions(“regexes”fromnow on)match an HTML href’sURL and the text contained in <h1> and <h2> header tags. (Regular expressions are covered in Chapter 13; understanding them is not essential to understanding this example.)\n\nreceiver = reporter() matchers = (regex_matcher(receiver, URL_RE),\n\nregex_matcher(receiver, H1_RE), regex_matcher(receiver, H2_RE))\n\nSince coroutines always have a yield expression, they are generators. So arecreating although herewe createa tupleof matcher coroutines,in effect we a tuple of generators. Each regex_matcher() isa coroutine that takesa receiver function (itself a coroutine) and a regex to match. Whenever the matcher matches it sends the match to the receiver.\n\n@coroutine def regex_matcher(receiver, regex):\n\nwhile True:\n\ntext = (yield) for match in regex.finditer(text):\n\nreceiver.send(match)\n\nThe matcher starts by entering an inﬁnite loop and immediately suspends execution waiting for the yield expression to return a text to apply the regex to. Once the text is received, the matcher iterates over every match it makes, sending each one to the receiver. Once the matching hasﬁnished the coroutine loops back to the yield and again suspends waiting for more text.\n\nThere is one tiny problem with the (undecorated) matcher—when it is ﬁrst created it should commence execution so that it advances to the yield ready to receive its ﬁrst text. We could do this by calling the built-in next() function on each coroutine we create before sending it any data. But for convenience we have created the @coroutine decorator to do this for us.\n\ndef coroutine(function):\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\ngenerator = function(*args, **kwargs) next(generator) return generator\n\nreturn wrapper\n\nThe @coroutine decorator takes a coroutine function, and calls the built-in next() function on it—this causes the function to be executed up to the ﬁrst yield expression, ready to receive data.\n\n401\n\n402\n\nChapter 8. Advanced Programming Techniques\n\nNow that we have seen the matcher coroutinewe will look at how thematchers are used, and then we will look at the reporter() coroutine that receives the matchers’ outputs.\n\ntry:\n\nfor file in sys.argv[1:]:\n\nprint(file) html = open(file, encoding=\"utf8\").read() for matcher in matchers:\n\nmatcher.send(html)\n\nfinally:\n\nfor matcher in matchers: matcher.close()\n\nreceiver.close()\n\nThe program reads the ﬁlenames listed on the command line, and for each one prints the ﬁlename and then reads the ﬁle’s entire text into the html variable using the UTF-8 encoding. Then the program iterates over all the matchers (three in this case), and sends the text to each of them. Each matcher then proceedsindependently,sending eachmatchit makestothereportercoroutine. At the end we call close() on each matcher and on the reporter—this termi- nates them, since otherwise they would continue (suspended) waiting for text (or matches in the case of the reporter) since they contain inﬁnite loops.\n\n@coroutine def reporter():\n\nignore = frozenset({\"style.css\", \"favicon.png\", \"index.html\"}) while True:\n\nmatch = (yield) if match is not None:\n\ngroups = match.groupdict() if \"url\" in groups and groups[\"url\"] not in ignore:\n\nprint(\"\n\nURL:\", groups[\"url\"])\n\nelif \"h1\" in groups:\n\nprint(\"\n\nH1: \", groups[\"h1\"])\n\nelif \"h2\" in groups:\n\nprint(\"\n\nH2: \", groups[\"h2\"])\n\nThe reporter() coroutine is used to output results. It was created by the state- ment receiver = reporter() which we saw earlier, and passed as the receiver argument to each of the matchers. The reporter() waits (is suspended) until a match is sent to it, then it prints the match’s details,and then it waits again, in an endless loop—stopping only if close() is called on it.\n\nUsing coroutines like this may produce performance beneﬁts, but does require us to adopt a somewhat different way of thinking about processing.\n\nCom- posing func- tions 395➤\n\nFunctional-StyleProgramming\n\nComposing Pipelines\n\nSometimes it is useful to create data processing pipelines. A pipeline is simply the composition of one or more functions where data items are sent to the ﬁrst function,which theneither discardstheitem(ﬁltersit out)or passesit on tothe next function (either as is or transformed in some way). The second function receives the item from the ﬁrst function and repeats the process, discarding or passing on the item (possibly transformed in a different way) to the next function, and so on. Items that reach the end are then output in some way.\n\nor Pipelines typically have several components, one that acquires data, one more that ﬁlter or transformdata,and one that outputsresults. Thisisexactly the functional-style approach to programming that we discussed earlier in the section when we looked at composing some of Python’s built-in functions,such as filter() and map().\n\nOne beneﬁt of using pipelines is that we can read data items incrementally, often one at a time, and have to give the pipeline only enough data items to ﬁll it (usually one or a few items per component). This can lead to signiﬁcant memory savings compared with, say, reading an entire data set into memory and then processing it all in one go.\n\nStep\n\nAction\n\nget_data()\n\nprocess()\n\nreporter()\n\n1\n\npipeline = get_data(\n\nWaiting\n\nWaiting\n\nWaiting\n\nprocess(reporter()))\n\n2\n\npipeline.send(\"a\")\n\nRead \"a\"\n\nWaiting\n\nWaiting\n\n3\n\npipeline.send(\"b\")\n\nRead \"b\"\n\nProcess \"a\" Waiting\n\n4\n\npipeline.send(\"c\")\n\nRead \"c\"\n\nProcess \"b\" Output \"a\"\n\n5\n\npipeline.send(\"d\")\n\nRead \"d\"\n\nProcess \"c\" Output \"b\"\n\n6\n\npipeline.send(\"e\")\n\nRead \"e\"\n\nDrop \"d\"\n\nOutput \"c\"\n\n7\n\npipeline.send(\"f\")\n\nRead \"f\"\n\nProcess \"e\" Waiting\n\n8\n\nWaiting\n\nProcess \"f\" Output \"e\"\n\n9\n\nWaiting\n\nWaiting\n\nOutput \"f\"\n\n10\n\nWaiting\n\nWaiting\n\nWaiting\n\n11 Close coroutines\n\nFinished\n\nFinished\n\nFinished\n\nFigure 8.3 A three-stepcoroutine pipeline processing six items of data\n\nFigure 8.3 illustrates a simple three component pipeline. The ﬁrst component of the pipeline (get_data()) acquires each data item to be processed in turn. Thesecondcomponent(process())processesthedata—andmaydropunwanted data items—there could be any number of other processing/ﬁltering compo- nents,of course. Thelastcomponent(reporter())outputsresults. Intheﬁgure,\n\n403\n\n|\n\n404\n\nChapter 8. Advanced Programming Techniques\n\nitems \"a\", \"b\", \"c\", \"e\", and \"f\" are processed and produce output, while item \"d\" is dropped.\n\nThe pipeline shown in Figure 8.3 is a ﬁlter, since each data item is passed through unchanged and is either dropped or output in its original form. The end points of pipelines tend to perform the same roles: acquiring data items and outputting results. But between these we can have as many components as necessary, each ﬁltering or transforming or both. And in some cases, com- posing the components in different orders can produce pipelines that do differ- ent things.\n\nWe will start out by looking at a theoretical example to get a better idea of how coroutine-based pipelines work, and then we will look at a real example.\n\nSuppose we have a sequence of ﬂoating-point numbers and we want to process them in a multicomponent pipeline such that we transform each number into an integer (by rounding),but drop any numbers that are out of range (< 0 or >= 10).If wehadthefour coroutinecomponents,acquire() (geta number),to_int() (transform a number by rounding and converting to an integer), check() (pass on a number that is in range;drop a number that is out of range),and output() (output a number), we could create the pipeline like this:\n\npipe = acquire(to_int(check(output())))\n\nWe would then send numbers into the pipeline by calling pipe.send(). We’ll look at the progressof the numbers4.3and 9.6asthey go through the pipeline, using a different visualization from the step-by-step ﬁgures used earlier:\n\npipe.send(4.3) → acquire(4.3) → to_int(4.3) → check(4) → output(4) pipe.send(9.6) → acquire(9.6) → to_int(9.6) → check(10)\n\nNotice that for 9.6 there is no output. This is because the check() coroutine received 10, which is out of range (>= 10), and so it was ﬁltered out.\n\nLet’s see what would happen if we created a different pipeline, but using the same components:\n\npipe = acquire(check(to_int(output())))\n\nThis simply performs the ﬁltering (check()) before the transforming (to_int()). Here is how it would work for 4.3 and 9.6:\n\npipe.send(4.3) → acquire(4.3) → check(4.3) → to_int(4.3) → output(4) pipe.send(9.6) → acquire(9.6) → check(9.6) → to_int(9.6) → output(10)\n\nHere we have incorrectly output 10, even though it is out of range. This is because we applied the check() component ﬁrst, and since this received an in-range value of 9.6, it simply passed it on. But the to_int() component rounds the numbers it gets.\n\nos. walk() 224➤\n\nFunctional-StyleProgramming\n\nWe will now review a concrete example—a ﬁle matcher that reads all the ﬁlenames given on the command line (including those in the directories given on thecommandline,recursively),andthat outputstheabsolutepathsof those ﬁles that meet certain criteria.\n\nWe will start by looking at how pipelines are composed, and then we will look at the coroutines that provide the pipeline components. Here is the sim- plest pipeline:\n\npipeline = get_files(receiver)\n\nThis pipeline prints every ﬁle it is given (or all the ﬁles in the directory it is given, recursively). The get_files() function is a coroutine that yields the ﬁlenames and the receiver is a reporter() coroutine—created by receiver = reporter()—that simply prints each ﬁlename it receives. This pipeline does little more than the os.walk() function (and in fact uses that function), but we can use its components to compose more sophisticated pipelines.\n\npipeline = get_files(suffix_matcher(receiver, (\".htm\", \".html\")))\n\nThis pipeline is created by composing the get_files() coroutine together with the suffix_matcher() coroutine. It prints only HTML ﬁles.\n\nCoroutines composed like this can quickly become difﬁcult to read, but there is nothing to stop us from composing a pipeline in stages—although for this approach we must create the components in last-to-ﬁrst order.\n\npipeline = size_matcher(receiver, minimum=1024 ** 2) pipeline = suffix_matcher(pipeline, (\".png\", \".jpg\", \".jpeg\")) pipeline = get_files(pipeline)\n\nThispipeline only matchesﬁlesthat are at least one megabyte in size,and that have a sufﬁx indicating that they are images.\n\nHow are these pipelines used? We simply feed them ﬁlenames or paths and they take care of the rest themselves.\n\nfor arg in sys.argv[1:]:\n\npipeline.send(arg)\n\nNotice that it doesn’t matter which pipeline we are using—it could be the one that prints all the ﬁles, or the one that prints HTML ﬁles, or the images one—they all work in the same way. And in this case,all three of the pipelines are ﬁlters—any ﬁlename they get is either passed on as is to the next compo- nent (and in the case of the reporter(), printed),or dropped because they don’t meet the criteria.\n\nBefore looking at the get_files() and the matcher coroutines, we will look at the trivial reporter() coroutine (passed as receiver) that outputs the results.\n\n405\n\n@corou- tine dec- orator 401➤\n\nos. walk() 224➤\n\n406\n\nChapter 8. Advanced Programming Techniques\n\n@coroutine def reporter(): while True:\n\nfilename = (yield) print(filename)\n\nWe have used the same @coroutine decorator that we created in the subsubsection.\n\nprevious\n\nThe get_files() coroutine is essentially a wrapper around the function and that expects to be given paths or ﬁlenames to work on.\n\nos.walk()\n\n@coroutine def get_files(receiver):\n\nwhile True:\n\npath = (yield) if os.path.isfile(path):\n\nreceiver.send(os.path.abspath(path))\n\nelse:\n\nfor root, dirs, files in os.walk(path):\n\nfor filename in files:\n\nreceiver.send(os.path.abspath(\n\nos.path.join(root, filename)))\n\nThiscoroutinehasthenow-familiarstructure:an inﬁniteloopin which wewait for the yield to return a value that we can process,and then we send the result to the receiver.\n\n@coroutine def suffix_matcher(receiver, suffixes):\n\nwhile True:\n\nfilename = (yield) if filename.endswith(suffixes): receiver.send(filename)\n\nThis coroutine looks simple—and it is—but notice that it sends only ﬁle- names that match the sufﬁxes, so any that don’t match are ﬁltered out of the pipeline.\n\n@coroutine def size_matcher(receiver, minimum=None, maximum=None):\n\nwhile True:\n\nfilename = (yield) size = os.path.getsize(filename) if ((minimum is None or size >= minimum) and\n\n(maximum is None or size <= maximum)): receiver.send(filename)\n\nDescrip- tors 372➤\n\nClass decora- tors 378➤\n\nFunctional-StyleProgramming\n\nThis coroutine is almost identical to suffix_matcher(), except that it ﬁlters out ﬁleswhosesize isnot in therequired range,rather than thosewhich don’t have a matching sufﬁx.\n\nThe pipeline we have created suffers from a couple of problems. One problem is that we never close any of the coroutines. In this case it doesn’t matter, since the program terminatesonce the processing is ﬁnished,but it is probably better to get into the habit of closing coroutines when we are ﬁnished with them. Another problem is that potentially we could be asking the operating system (under the hood) for different pieces of information about the same ﬁle in several partsof the pipeline—and this could be slow. A solution is to modify the get_files() coroutine so that it returns (filename, os.stat()) 2-tuples for each ﬁle rather than just ﬁlenames, and then pass these 2-tuples through the pipeline.★ This would mean that we acquire all the relevant information just once per ﬁle. You’ll get the chance to solve both of these problems, and to add additional functionality, in an exercise at the end of the chapter.\n\nCreating coroutines for use in pipelines requires a certain reorientation of thinking. However, it can pay off handsomely in terms of ﬂexibility, and for large data sets can help minimize the amount of data held in memory as well as potentially resulting in faster throughput.\n\nExample: Valid.py\n\nIn this section powerful mechanism for creating validated attributes.\n\nwe combine descriptors with class decorators to create a\n\nUp to now if we wantedto ensurethat an attributewasset to only a valid value wehaverelied on properties(or usedgetter andsetter methods).Thedisadvan- tage of such approachesisthat we must add validating codefor every attribute inevery classthatneedsit. Whatwouldbemuchmoreconvenientandeasierto maintain,is if we could add attributesto classes with the necessary validation built in. Here is an example of the syntax we would like to use:\n\n@valid_string(\"name\", empty_allowed=False) @valid_string(\"productid\", empty_allowed=False,\n\nregex=re.compile(r\"[A-Z]{3}\\d{4}\"))\n\n@valid_string(\"category\", empty_allowed=False, acceptable=\n\nfrozenset([\"Consumables\", \"Hardware\", \"Software\", \"Media\"]))\n\n@valid_number(\"price\", minimum=0, maximum=1e6) @valid_number(\"quantity\", minimum=1, maximum=1000) class StockItem:\n\n★ The os.stat() function takes a ﬁlename and returns a named tuple with various items of information about the ﬁle, including its size, mode, and last modiﬁed date/time.\n\n407\n\n|||\n\nClass decora- tors 378➤\n\n408\n\nChapter 8. Advanced Programming Techniques\n\ndef __init__(self, name, productid, category, price, quantity):\n\nself.name = name self.productid = productid self.category = category self.price = price self.quantity = quantity\n\nThe StockItem class’s attributes are all validated. For example, the productid attribute can be set only to a nonempty string that startswith three uppercase letters and ends with four digits, the category attribute can be set only to a nonempty string that is one of the speciﬁed values, and the quantity attribute can be set only to a number between 1 and 1000 inclusive. If we try to set an invalid value an exception is raised.\n\nThe validation is achieved by combining class decorators with descriptors. As single argument—the class we noted earlier, class decorators can take only a they are to decorate. So here we have used the technique shown when we ﬁrst discussed class decorators, and have the valid_string() and valid_number() functions take whatever arguments we want, and then return a decorator, which in turn takes the class and returns a modiﬁed version of the class.\n\nLet’s now look at the valid_string() function:\n\ndef valid_string(attr_name, empty_allowed=True, regex=None,\n\nacceptable=None):\n\ndef decorator(cls):\n\nname = \"__\" + attr_name def getter(self):\n\nreturn getattr(self, name)\n\ndef setter(self, value):\n\nassert isinstance(value, str), (attr_name +\n\n\" must be a string\")\n\nif not empty_allowed and not value:\n\nraise ValueError(\"{0} may not be empty\".format(\n\nattr_name))\n\nif ((acceptable is not None and value not in acceptable) or\n\n(regex is not None and not regex.match(value))): raise ValueError(\"{attr_name} cannot be set to \"\n\n\"{value}\".format(**locals()))\n\nsetattr(self, name, value)\n\nsetattr(cls, attr_name, GenericDescriptor(getter, setter)) return cls\n\nreturn decorator\n\nThefunctionstartsby creating a classdecoratorfunctionwhichtakesa classas itssole argument. The decorator addstwo attributesto the classit decorates:a private data attribute and a descriptor. For example, when the valid_string()\n\nRegular expres- sions ➤ 489\n\nExample: Valid.py\n\nfunction is called with the name “productid”, the StockItem class gains the attribute __productid which holds the product ID’s value, and the descrip- tor productid attribute which is used to access the value. For example, if we create an item using item = StockItem(\"TV\", \"TVA4312\", \"Electrical\", 500, 1), we can get the product ID using item.productid and set it using, for example, item.productid = \"TVB2100\".\n\nThe getter function created by the decorator simply uses the global getattr() function to return the value of the private data attribute. The setter function incorporates the validation, and at the end, uses setattr() to set the private data attribute to the new (and valid) value. In fact, the private data attribute is only created the ﬁrst time it is set.\n\nOnce the getter and setter functions have been created we use setattr() once again, this time to create a new class attribute with the given name (e.g., productid), and with its value set to be a descriptor of type GenericDescrip- tor. At the end, the decorator function returns the modiﬁed class, and the valid_string() function returns the decorator function.\n\nThe valid_number() function is structurally identical to the valid_string() function, only differing in the arguments it accepts and in the validation code in the setter, so we won’t show it here. (The complete source code is in the Valid.py module.)\n\nThe last thing we need to cover is the GenericDescriptor, and that turns out to be the easiest part:\n\nclass GenericDescriptor:\n\ndef __init__(self, getter, setter):\n\nself.getter = getter self.setter = setter\n\ndef __get__(self, instance, owner=None):\n\nif instance is None: return self\n\nreturn self.getter(instance)\n\ndef __set__(self, instance, value):\n\nreturn self.setter(instance, value)\n\nThe descriptor is used to hold the getter and setter functionsfor each attribute and simply passes on the work of getting and setting to those functions.\n\n409\n\n410\n\nChapter 8. Advanced Programming Techniques\n\nSummary\n\nIn this chapter we learned a lot more about Python’s support for procedural and object-oriented programming, and got a taste of Python’s support for functional-style programming.\n\nIn theﬁrstsectionwelearnedhowtocreategeneratorexpressions,andcovered generator functionsin moredepth. Wealsolearnedhow todynamically import modules and how to access functionality from such modules, as well as how to dynamically execute code. In this section we saw examples of how to create and use recursive functions and nonlocal variables. We also learned how to create custom function and method decorators,and how to write and make use of function annotations.\n\nIn the chapter’s second section we studied a variety of different and more ad- vanced aspects of object-oriented programming. First we learned more about attribute access, for example, using the __getattr__() special method. Then we learned about functorsand saw how we could use them to provide functions with state—something that can also be achieved by adding properties to func- tions or using closures, both covered in this chapter. We learned how to use the with statement with context managers and how to create custom context managers. Since Python’s ﬁle objects are also context managers, from now on we will do our ﬁle handling using try with …except structuresthat ensure that opened ﬁles are closed without the need for finally blocks.\n\nThe second section continued with coverage of more advanced object-oriented features,starting withdescriptors. Thesecanbeusedin a widevariety of ways and are the technology that underlies many of Python’s standard decorators such as @property and @classmethod. We learned how to create custom descrip- tors and saw three very different examples of their use. Next we studied class decorators and saw how we could modify a class in much the same way that a function decorator can modify a function.\n\nIn the last three subsections of the second section we learned about Python’s support for ABCs (abstract base classes),multiple inheritance,and metaclass- es. WelearnedhowtomakeourownclassesﬁtinwithPython’sstandardABCs and how to create our own ABCs. We also saw how to use multiple inheritance tounify thefeaturesof differentclassestogetherina singleclass. Andfromthe coverage of metaclasses we learned how to intervene when a class (as opposed to an instance of a class) is created and initialized.\n\nThe penultimate section introduced some of the functions and modules that Python provides to support functional-style programming. We learned how to use the common functional idiomsof mapping,ﬁltering,and reducing. We also learned how to create partial functions and how to create and use coroutines.\n\n|||\n\nSummary\n\nAndthelastsectionshowedhowtocombineclassdecoratorswithdescriptorsto provide a powerful and ﬂexible mechanism for creating validated attributes.\n\nThis chapter completes our coverage of the Python language itself. Not every feature of the language has been covered here and in the previous chapters, but those that have not are obscure and rarely used. None of the subsequent chapters introduces new language features, although all of them make use of modules from the standard library that have not been covered before, and some of them take techniques shown in this and earlier chapters further than we have seen so far. Furthermore, the programs shown in the following chaptershave none of the constraintsthat have applied previously (i.e.,to only use aspects of the language that had been covered up to the point they were introduced), so they are the book’s most idiomatic examples.\n\nExercises\n\nNone of the ﬁrst three exercisesdescribed here requireswriting a lot of code— although the fourth one does—and none of them are easy!\n\n1. Copy themagic-numbers.py programanddeleteitsget_function() functions, and all but one of its load_modules() functions. Add a GetFunction functor class that has two caches, one to hold functions that have been found and one to hold functions that could not be found (to avoid repeatedly looking for a function in a module that does not have the function).The only mod- iﬁcations to main() are to add get_function = GetFunction() before the loop, and to use a with statement to avoid the need for a finally block. Also, check that the module functions are callable using collections.Callable ratherthanusing hasattr().Theclasscanbewritteninabouttwenty lines. A solution is in magic-numbers_ans.py.\n\n2. Create a new module ﬁle and in it deﬁne three functions: is_ascii() that returns True if all the characters in the given string have code points less than 127; is_ascii_punctuation() that returns True if all the characters arein the string.punctuation string;and is_ascii_printable() that returns True if all the characters are in the string.printable string. The last two are structurally the same. Each function should be created using lambda and can be done in one or two lines using functional-style code. Be sure to add a docstring for each one with doctestsand to make the module run the doctests. Thefunctionsrequireonly threetoﬁvelinesfor allthreeof them, with the whole module fewer than 25 lines including doctests. A solution is given in Ascii.py.\n\n3. Create a new module ﬁle and in it deﬁne the Atomic context manager class. This class should work like the AtomicList class shown in this chapter, ex- cept that instead of working only with lists it should work with any mu- table collection type. The __init__() method should check the suitability\n\n411\n\n|||\n\n412\n\nChapter 8. Advanced Programming Techniques\n\nof the container, and instead of storing a shallow/deep copy ﬂag it should assign a suitable function to the self.copy attribute depending on the ﬂag and call the copy function in the __enter__() method. The __exit__() method is slightly more involved because replacing the contents of lists is different than for sets and dictionaries—and we cannot use assignment because that would not affect the original container. The class itself can be written in about thirty lines,although you should also include doctests. A solution is given in Atomic.py which is about one hundred ﬁfty lines in- cluding doctests.\n\n4. Createa programthatﬁndsﬁlesbasedon speciﬁedcriteria(ratherlikethe Unix find program). The usage should be find.py options files_or_paths. All the options are optional, and without them all the ﬁles listed on the command line and all the ﬁles in the directories listed on the command line (and in their directories, recursively) should be listed. The options should restrict which ﬁles are output as follows: -d or --days integer dis- cards any ﬁles older than the speciﬁed number of days; -b or --bigger in- teger discards any ﬁles smaller than the speciﬁed number of bytes; -s or --smaller integer discards any ﬁles bigger than the speciﬁed number of bytes; -o or --output what where what is “date”, “size”, or “date,size” (either way around) speciﬁeswhat should be output—ﬁlenamesshould alwaysbe output; -u or --suffix discards any ﬁles that don’t have a matching sufﬁx. (Multiple sufﬁxes can be given if comma-separated.) For both the bigger and smaller options,if the integer isfollowed by “k” it should be treated as kilobytes and multipled by 1024, and similarly if followed by “m” treated as megabytes and multiplied by 10242. For example, find.py -d1 -o date,size *.* will ﬁnd all ﬁles modiﬁed today (strictly, the past 24 hours), and output their name, date, and size. Simi- larly, find.py -b1m -u png,jpg,jpeg -o size *.* will ﬁnd all image ﬁles bigger than one megabyte and output their names and sizes.\n\nImplement the program’s logic by creating a pipeline using coroutines to provide matchers, similar to what we saw in the coroutines subsection, only this time pass (filename, os.stat()) 2-tuples for each ﬁle rather than just ﬁlenames. Also,try to close all the pipeline componentsat the end. In the solution provided, the biggest single function is the one that handles the command-line options. The rest is fairly straightforward, but not trivial. The find.py solution is around 170 lines.",
      "page_number": 390
    },
    {
      "number": 41,
      "title": "Segment 41 (pages 402-409)",
      "start_page": 402,
      "end_page": 409,
      "detection_method": "topic_boundary",
      "content": "9\n\nDebugging ● Unit Testing ● Proﬁling\n\nDebugging, Testing, and Proﬁling\n\nWriting programs is a mixture of art, craft, and science,and because it is done by humans, mistakes are made. Fortunately, there are techniques we can use to help avoid problems in the ﬁrst place, and techniques for identifying and ﬁxing mistakes when they become apparent.\n\nMistakes fall into several categories. The quickest to reveal themselves and the easiest to ﬁx are syntax errors, since these are usually due to typos. More challenging are logical errors—with these, the program runs, but some aspect of its behavior is not what we intended or expected. Many errors of this kind can be prevented from happening by using TDD (Test Driven Development), where when we want to add a new feature, we begin by writing a test for the feature—which will fail since we haven’t added the feature yet—and then im- plement the feature itself. Another mistake is to create a program that has needlessly poor performance. This is almost always due to a poor choice of al- gorithm or data structure or both. However, before attempting any optimiza- tion we should start by ﬁnding out exactly where the performance bottleneck lies—since it might not be where we expect—and then we should carefully de- cide what optimization we want to do, rather than working at random.\n\nIn this chapter’s ﬁrst section we will look at Python’s tracebacks to see how to spot and ﬁx syntax errors and how to deal with unhandled exceptions. Then we will see how to apply the scientiﬁc method to debugging to make ﬁnding errorsas fast and painlessas possible. We will also look at Python’sdebugging support. In the second section we will look at Python’ssupport for writing unit tests, and in particular the doctest module we saw earlier (in Chapter 5 and Chapter 6), and the unittest module. We will see how to use these modules to support TDD. In the chapter’s ﬁnal section we will brieﬂy look at proﬁling, to identify performance hot spotsso that we can properly target our optimization efforts.\n\n413\n\n||||\n\n414\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nDebugging\n\nIn this section we will begin by looking at what Python does when there is a syntax error,then at the tracebacksthat Python produceswhen unhandled ex- ceptionsoccur,andthenwewillseehowtoapply thescientiﬁcmethodtodebug- ging. But before all that we will brieﬂy discuss backups and version control.\n\nWhen editing a program to ﬁx a bug there is always the risk that we end up with a programthat hasthe originalbug plusnew bugs,that is,it iseven worse than it was when we started! And if we haven’t got any backups (or we have but they are several changes out of date), and we don’t use version control, it could be very hard to even get back to where we just had the original bug.\n\nMaking regular backups is an essential part of programming—no matter how reliable our machine and operating system are and how rare failures are—sincefailuresstilloccur. But backupstend tobecoarse-grained,with ﬁles hours or even days old.\n\nVersion control systems allow us to incrementally save changes at whatever level of granularity we want—every single change, or every set of related changes, or simply every so many minutes’ worth of work. Version control systems allow us to apply changes (e.g., to experiment with bugﬁxes), and if they don’t work out, we can revert the changes back to the last “good” version of the code. So before starting to debug,it is always best to check our code into the version control system so that we have a known position that we can revert to if we get into a mess.\n\nThere are many good cross-platform open source version control systems available—this book uses Bazaar (bazaar-vcs.org), but other popular ones include Mercurial (mercurial.selenic.com), Git (git-scm.com), and Subversion (subversion.tigris.org). Incidentally, both Bazaar and Mercurial are mostly writtenin Python. Noneof thesesystemsishardtouse(at least for thebasics), but using any one of them will help avoid a lot of unnecessary pain.\n\nDealing with Syntax Errors\n\nIf we try to run a program that has a syntax error, Python will stop execution and print the ﬁlename, line number, and offending line, with a caret (^) under- neath indicating exactly where the error was detected. Here’s an example:\n\nFile \"blocks.py\", line 383 if BlockOutput.save_blocks_as_svg(blocks, svg) ^ SyntaxError: invalid syntax\n\n|||\n\n||\n\nDebugging\n\nDid you see the error? We’ve forgotten to put a colon at the end of the if statement’s condition.\n\nHere is an example that comes up quite often, but where the problem isn’t at all obvious:\n\nFile \"blocks.py\", line 385 except ValueError as err: ^ SyntaxError: invalid syntax\n\nThere is no syntax error in the line indicated, so both the line number and the caret’s position are wrong. In general, when we are faced with an error that we are convinced is not in the speciﬁed line, in almost every case the error will be in an earlier line. Here’s the code from the try to the except where Python is reporting the error to be—see if you can spot the error before reading the explanation that follows the code:\n\ntry:\n\nblocks = parse(blocks) svg = file.replace(\".blk\", \".svg\") if not BlockOutput.save_blocks_as_svg(blocks, svg):\n\nprint(\"Error: failed to save {0}\".format(svg)\n\nexcept ValueError as err:\n\nDid you spot the problem? It is certainly easy to miss since it is on the line before the one that Python reports as having the error. We have closed the str.format() method’s parentheses,but not the print() function’sparentheses, that is, we are missing a closing parenthesis at the end of the line, but Python didn’t realize this until it reached the except keyword on the following line. Missing the last parenthesis on a line is quite common, especially when using print() with str.format(), but the error is usually reported on the following line. Similarly, if a list’s closing bracket, or a set or dictionary’s closing brace is missing,Python will normally report the problem as being on the next (non- blank) line. On the plus side, syntax errors like these are trivial to ﬁx.\n\nDealing with Runtime Errors\n\nIf an unhandled exception occurs at runtime, Python will stop executing our program and print a traceback. Here is an example of a traceback for an unhandled exception:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 381, in main\n\n415\n\n||\n\nFunc- tion ref- erences 340➤\n\n416\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nblocks = parse(blocks) File \"blocks.py\", line 174, in recursive_descent_parse return data.stack[1] IndexError: list index out of range\n\nTracebacks (also called backtraces) like this should be read from their last line back toward their ﬁrst line. The last line speciﬁes the unhandled exception that occurred. Above this line, the ﬁlename, line number, and function name, followed by the line that caused the exception, are shown (spread over two lines). If the function where the exception was raised was called by another function, that function’s ﬁlename, line number, function name, and calling line are shown above. And if that function was called by another function the same applies, all the way up to the beginning of the call stack. (Note that the ﬁlenames in tracebacks are given with their path, but in most cases we have omitted paths from the examples for the sake of clarity.)\n\nSo in this example, an IndexError occurred, meaning that data.stack is some kind of sequence, but has no item at position 1. The error occurred at line 174 in the blocks.py program’s recursive_descent_parse() function, and that line 381 in the main() function. (The reason that the function was called at function’s name is different at line 381, that is, parse() instead of recur- sive_descent_parse(),is that the parse variable is set to one of several different functions depending on the command-line arguments given to the program;in the common case thenamesalwaysmatch.) The call to main() wasmadeat line 392, and this is the statement at which program execution commenced.\n\nAlthough at ﬁrst sight the traceback looks intimidating, now that we under- stand its structure it is easy to see how useful it is. In this case it tells us ex- actly where to look for the problem, although of course we must work out for ourselves what the solution is.\n\nHere is another example traceback:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 383, in main if BlockOutput.save_blocks_as_svg(blocks, svg): File \"BlockOutput.py\", line 141, in save_blocks_as_svg widths, rows = compute_widths_and_rows(cells, SCALE_BY) File \"BlockOutput.py\", line 95, in compute_widths_and_rows width = len(cell.text) // cell.columns ZeroDivisionError: integer division or modulo by zero\n\nHere, the problem has occurred in a module (BlockOutput.py) that is called by the blocks.py program. This traceback leads us to where the problem became apparent, but not to where it occurred. The value of cell.columns is\n\nDebugging\n\nclearly 0 in the BlockOutput.py module’s compute_widths_and_rows() function on line 95—after all, that is what caused the ZeroDivisionError exception to be raised—but we must look at the preceding lines to ﬁnd where and why cell.columns was given this incorrect value.\n\nIn some cases the traceback reveals an exception that occurred in Python’s standard library or in a third-party library. Although thiscould mean a bug in the library, in almost every case it is due to a bug in our own code. Here is an example of such a traceback, using Python 3.0:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 379, in main blocks = open(file, encoding=\"utf8\").read() File \"/usr/lib/python3.0/lib/python3.0/io.py\", line 278, in __new__ return open(*args, **kwargs) File \"/usr/lib/python3.0/lib/python3.0/io.py\", line 222, in open closefd) File \"/usr/lib/python3.0/lib/python3.0/io.py\", line 619, in __init__ _fileio._FileIO.__init__(self, name, mode, closefd) IOError: [Errno 2] No such file or directory: 'hierarchy.blk'\n\nThe IOError exception at the end tells us clearly what the problem is. But the exception was raised in the standard library’s io module. In such cases it is best to keep reading upward until we ﬁnd the ﬁrst ﬁle listed that is our program’s ﬁle (or one of the modules we have created for it).So in this case we ﬁnd that the ﬁrst reference to our program is to ﬁle blocks.py, line 379, in the main() function. It looks like we have a call to open() but have not put the call inside a try … except block or used a with statement.\n\nPython 3.1 is a bit smarter than Python 3.0 and realizes that we want to ﬁnd the mistake in our own code,not in the standard library,so it produces a much more compact and helpful traceback. For example:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 379, in main blocks = open(file, encoding=\"utf8\").read() IOError: [Errno 2] No such file or directory: 'hierarchy.blk'\n\nThis eliminates all the irrelevant detail and makes it easy to see what the problem is (on the bottom line) and where it occurred (the lines above it).\n\nSo no matter how big the traceback is,the last line alwaysspeciﬁesthe unhan- dled exception, and we just have to work back until we ﬁnd our program’s ﬁle\n\n417\n\n3.0\n\n3.1\n\n418\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nor one of our own modules listed. The problem will almost certainly be on the line Python speciﬁes, or on an earlier line.\n\nThis particular example illustrates that we should modify the blocks.py pro- gram to cope gracefully when given the names of nonexistent ﬁles. This is a usability error,and it should also be classiﬁed asa logical error,sinceterminat- ing and printing a traceback cannot be considered to be acceptable program behavior.\n\nIn fact, as a matter of good policy and courtesy to our users, we should always catchallrelevantexceptions,identifying thespeciﬁconesthatweconsidertobe possible, such as EnvironmentError. In general, we should not use the catchalls of except: or except Exception:, although using the latter at the top level of our program to avoid crashes might be appropriate—but only if we always report any exceptions it catches so that they don’t go silently unnoticed.\n\nExceptions that we catch and cannot recover from should be reported in the form of error messages, rather than exposing our users to tracebacks which look scary to the uninitiated. For GUI programs the same applies,except that normally we would use a message box to notify the user of a problem. And for server programs that normally run unattended, we should write the error message to the server’s log.\n\nPython’s exception hierarchy was designed so that catching Exception doesn’t quitecoveralltheexceptions. Inparticular,it doesnotcatchthe KeyboardInter- rupt exception,soforconsoleapplicationsif theuserpressesCtrl+C,theprogram willterminate. If wechoosetocatchthisexception,thereisa risk thatwecould lock the user into a program that they cannot terminate. This arises because a bug in our exception handling code might prevent the program from termi- nating or the exception propagating. (Of course, even an “uninterruptible” program can have its process killed, but not all users know how.) So if we do catch the KeyboardInterrupt exception we must be extremely careful to do the minimum amount of saving and clean up that is necessary—and then termi- nate the program. And for programs that don’t need to save or clean up, it is best not to catch KeyboardInterrupt at all, and just let the program terminate.\n\nOne of Python 3’sgreat virtuesisthat it makesa clear distinctionbetween raw bytes and strings. However,this can sometimes lead to unexpected exceptions occurring when we pass a bytes object where a str is expected or vice versa. For example:\n\nTraceback (most recent call last): File \"program.py\", line 918, in <module> print(datetime.datetime.strptime(date, format)) TypeError: strptime() argument 1 must be str, not bytes\n\nWhen we hit a problem like this we can either perform the conversion—in this case,by passing date.decode(\"utf8\")—or carefully work back to ﬁnd out where\n\nDebugging\n\n419\n\nand why the variable is a bytes object rather than a str, and ﬁx the problem at its source.\n\nWhen we pass a string where bytes are expected the error message is what less obvious, and differs between Python 3.0 and 3.1. For Python 3.0:\n\nsome- example, in\n\nTraceback (most recent call last): File \"program.py\", line 2139, in <module> data.write(info) TypeError: expected an object with a buffer interface\n\nIn Python 3.1 the error message’s text has been slightly improved:\n\nTraceback (most recent call last): File \"program.py\", line 2139, in <module> data.write(info) TypeError: 'str' does not have the buffer interface\n\nIn both cases the problem is that we are passing a string when a bytes, byte- array, or similar object is expected. We can either perform the conversion—in thiscaseby passing info.encode(\"utf8\")—or work back toﬁndthesourceof the problem and ﬁx it there.\n\nPython 3.0 introduced support for exception chaining—this means that an ex- ceptionthatisraisedinresponsetoanotherexceptioncancontainthedetailsof the original exception. When a chained exception goesuncaught thetraceback includes not just the uncaught exception, but also the exception that caused it (providing it waschained).Theapproachtodebugging chainedexceptionsisal- most the same as before:We start at the end and work backward until we ﬁnd the problem in our own code. However, rather than doing this just for the last exception, we might then repeat the process for each chained exception above it, until we get to the problem’s true origin.\n\nWe can take advantage of exception chaining in our own code—for example,if we want to use a custom exception class but still want the underlying problem to be visible.\n\nclass InvalidDataError(Exception): pass\n\ndef process(data):\n\ntry:\n\ni = int(data) ...\n\nexcept ValueError as err:\n\nraise InvalidDataError(\"Invalid data received\") from err\n\nHere, if the int() conversion fails, a ValueError is raised and caught. We then raise our custom exception, but with from err, which creates a chained\n\n3.x\n\n3.0\n\n3.1\n\n420\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nexception, our own, plus the one in err. If the InvalidDataError exception is raised and not caught, the resulting traceback will look something like this:\n\nTraceback (most recent call last): File \"application.py\", line 249, in process i = int(data) ValueError: invalid literal for int() with base 10: '17.5 '\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last): File \"application.py\", line 288, in <module> print(process(line)) File \"application.py\", line 283, in process raise InvalidDataError(\"Invalid data received\") from err __main__.InvalidDataError: Invalid data received\n\nAt the bottom our custom exception and text explain what the problem is,with the lines above them showing where the exception was raised (line 283), and whereit wascaused(line288).But wecanalsogoback further,intothechained exception which gives more details about the speciﬁc error, and which shows the line that triggered the exception (249).For a detailed rationale and further information about chained exceptions, see PEP 3134.\n\nScientiﬁc Debugging\n\nIf our program runs but does not have the expected or desired behavior then we have a bug—a logical error—that we must eliminate. The best way to eliminate such errors is to prevent them from occurring in the ﬁrst place by using TDD (Test Driven Development). However, some bugs will always get through, so even with TDD, debugging is still a necessary skill to learn.\n\nIn this subsection we will outline an approach to debugging based on the sci- entiﬁc method. The approach is explained in sufﬁcient detail that it might ap- pear to be too much work for tackling a “simple” bug. However,by consciously following theprocesswewillavoid wasting timewith “random”debugging,and after awhile we will internalize the process so that we can do it unconsciously, and therefore very quickly.★\n\nTo be able to kill a bug we must be able to do the following.\n\n1. Reproduce the bug.\n\n2. Locate the bug.\n\n★The ideas used in this subsection were inspired by the Debugging chapter in the book Code Complete by Steve McConnell, ISBN 0735619670.\n\n||",
      "page_number": 402
    },
    {
      "number": 42,
      "title": "Segment 42 (pages 410-418)",
      "start_page": 410,
      "end_page": 418,
      "detection_method": "topic_boundary",
      "content": "Debugging\n\n3. Fix the bug.\n\n4. Test the ﬁx.\n\nReproducing the bug is sometimes easy—it always occurs on every run; and sometimes hard—it occurs intermittently. In either case we should try to reduce the bug’s dependencies, that is, ﬁnd the smallest input and the least amount of processing that can still produce the bug.\n\nOnce we are able to reproduce the bug, we have the data—the input data and options, and the incorrect results—that are needed so that we can apply the scientiﬁc method to ﬁnding and ﬁxing it. The method has three steps.\n\n1. Think up an explanation—a hypothesis—that reasonably accounts for the bug.\n\n2. Create an experiment to test the hypothesis.\n\n3. Run the experiment.\n\nRunning the experiment should help to locate the bug, and should also give us insightintoitssolution. (Wewillreturntohowtocreateandrunanexperiment shortly.) Once we have decided how to kill the bug—and have checked our code into our version control system so that we can revert the ﬁx if necessary—we can write the ﬁx.\n\nOnce theﬁx isin placewe must test it. Naturally,we must test to see if thebug it is intended to ﬁx has gone away. But this is not sufﬁcient; after all, our ﬁx may have solved the bug we were concerned about, but the ﬁx might also have introduced another bug, one that affects some other aspect of the program. So in addition to testing the bugﬁx, we must also run all of the program’s tests to increase our conﬁdence that the bugﬁx did not have any unwanted side effects.\n\nSome bugs have a particular structure, so whenever we ﬁx a bug it is always worth asking ourselves if there are other places in the program or its modules that might have similar bugs. If there are, we can check to see if we already have tests that would reveal the bugs if they were present, and if not, we should add such tests, and if that reveals bugs, then we must tackle them as described earlier.\n\nNow that we have a good overview of the debugging process, we will focus in on just how we create and run experiments to test our hypotheses. We begin with trying to isolate the bug. Depending on the nature of the program and of the bug, we might be able to write tests that exercise the program, for example, feeding it data that is known to be processed correctly and gradually changing the data so that we can ﬁnd exactly where processing fails. Once we have an idea of where the problem lies—either due to testing or based on reasoning—we can test our hypotheses.\n\n421\n\n422\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nWhat kind of hypothesis might we think up? Well, it could initially be as sim- pleasthesuspicionthata particularfunctionor methodisreturning erroneous data when certain input data and options are used. Then, if this hypothesis proves correct, we can reﬁne it to be more speciﬁc—for example, identifying a particular statement or suite in the function that we think is doing the wrong computation in certain cases.\n\nTo test our hypothesis we need to check the arguments that the function re- ceives and the values of its local variables and the return value, immediately before it returns. We can then run the program with data that we know pro- duces errorsand check the suspect function. If the argumentscoming into the function are not what we expect, then the problem is likely to be further up the call stack, so we would now begin the process again, this time suspecting the function that callsthe one we have been looking at. But if all the incoming arguments are always valid, then we must look at the local variables and the return value. If these are always correct then we need to come up with a new hypothesis, since the suspect function is behaving correctly. But if the return value is wrong, then we know that we must investigate the function further.\n\nIn practice, how do we conduct an experiment, that is, how do we test the hy- pothesis that a particular function is misbehaving? One way to start is to “execute” the function mentally—thisis possible for many small functionsand for larger ones with practice,and has the additional beneﬁt that it familiarizes us with the function’s behavior. At best, this can lead to an improved or more speciﬁc hypothesis—for example, that a particular statement or suite is the site of the problem. But to conduct an experiment properly we must instru- ment the program so that we can see what is going on when the suspect func- tion is called.\n\nThere aretwo waysto instrument a program—intrusively,by inserting print() statements;or (usually)non-intrusively,by using a debugger. Bothapproaches are used to achieve the same end and both are valid, but some programmers have a strong preference for one or the other. We’ll brieﬂy describe both approaches, starting with the use of print() statements.\n\nWhen using print() statements, we can start by putting a print() statement right at the beginning of the function and have it print the function’s argu- ments. Then, just before the (or each) return statement (or at the end of the function if there is no return statement), add print(locals(), \"\\n\"). The built- in locals() function returnsa dictionary whose keys are the names of the local variables and whose values are the variables’ values. We can of course simply print the variables we are speciﬁcally interested in instead. Notice that we added an extra newline—we should also do this in the ﬁrst print() statement so that a blank line appears between each set of variables to aid clarity. (An alternative to inserting print() statements directly is to use some kind of log- ging decorator such as the one we created in Chapter 8; 358 ➤.)\n\nDebugging\n\nIf when we run the instrumented program we ﬁnd that the arguments are correct but that the return value is in error, we know that we have located the source of the bug and can further investigatethe function. If looking carefully at the function doesn’t suggest where the problem lies, we can simply insert a new print(locals(), \"\\n\") statement right in the middle. After running the program again we should now know whether the problem arises in the ﬁrst or second half of the function, and can put a print(locals(), \"\\n\") statement in the middle of the relevant half, repeating the process until we ﬁnd the statement where the error is caused. This will very quickly get us to the point where the problem occurs—and in most cases locating the problem is half of the work needed to solve it.\n\nThe alternative to adding print() statements is to use a debugger. Python has two standard debuggers. One is supplied as a module (pdb), and can be used interactively in the console—for example, python3 -m pdb my_program.py. (On Windows, of course, we would replace python3 with something like C:\\Python31\\python.exe.) However, the easiest way to use it is to add import pdb in the program itself, and add the statement pdb.set_trace() as the ﬁrst state- ment of the function we want to examine. When the program is run, pdb stops it immediately after the pdb.set_trace() call,and allows us to step through the program, set breakpoints, and examine variables.\n\nHere is an example run of a program that has been instrumented by having the import pdb statement added to its imports, and by having pdb.set_trace() added as the ﬁrst statement inside its calculate_median() function. (What we have typed is shown in bold, although where we typed Enter is not indicated.)\n\npython3 statistics.py sum.dat > statistics.py(73)calculate_median() -> numbers = sorted(numbers) (Pdb) s > statistics.py(74)calculate_median() -> middle = len(numbers) // 2 (Pdb) > statistics.py(75)calculate_median() -> median = numbers[middle] (Pdb) > statistics.py(76)calculate_median() -> if len(numbers) % 2 == 0: (Pdb) > statistics.py(78)calculate_median() -> return median (Pdb) p middle, median, numbers (8, 5.0, [-17.0, -9.5, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.5, 6.0, 7.0, 7.0, 8.0, 9.0, 17.0]) (Pdb) c\n\n423\n\n424\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nCommands are given to pdb by entering their name and pressing Enter at the (Pdb) prompt. If we just press Enter on its own the last command is repeated. So here we typed s (which means step, i.e., execute the statement shown), and then repeated this (simply by pressing Enter), to step through the statements in the calculate_median() function. Once we reached the return statement we printed out the values that interested us using the p (print) command. And ﬁnally we continued to the end using the c (continue) command. This tiny example should give a ﬂavor of pdb, but of course the module has a lot more functionality than we have shown here.\n\nIt is much easier to use pdb on an instrumented program as we have done here than on an uninstrumented one. But since this requires us to add an import and a call to pdb.set_trace(), it would seem that using pdb is just as intrusive as using print() statements, although it does provide useful facilities such as breakpoints.\n\nThe other standard debugger is IDLE, and just like pdb, it supports single stepping, breakpoints, and the examination of variables. IDLE’s debugger window is shown in Figure 9.1, and its code editing window with breakpoints and the current line highlighted is shown in Figure 9.2.\n\nFigure 9.1 IDLE’s debugger window showing the call stack and the current local variables\n\nOne great advantage IDLE has over pdb is that there is no need to instrument our code—IDLE is smart enough to debug our code as it stands, so it isn’t intrusive at all.\n\nUnfortunately, at the time of this writing, IDLE is rather weak when it comes to running programs that require command-line arguments. The only way to do this appears to be to run IDLE from a console with the required arguments,\n\nDebugging\n\nFigure 9.2 An IDLE code editing window during debugging\n\nfor example, idle3 -d -r statistics.py sum.dat. The -d argument tells IDLE to start debugging immediately and the -r argument tells it to run the following program with any arguments that follow it. However, for programs that don’t require command-line arguments (or where we are willing to edit the code to put them in manually to make debugging easier), IDLE is quite powerful and convenient to use. (Incidentally,the code shown in Figure 9.2 does have a bug—middle + 1 should be middle - 1.)\n\nDebugging Python programs is no harder than debugging in any other language—and it is easier than for compiled languages since there is no build step to go through after making changes. And if we are careful to use the sci- entiﬁcmethoditisusually quitestraightforwardtolocatebugs,althoughﬁxing them isanother matter. Ideally,though,we want to avoid asmany bugsaspos- sible in the ﬁrst place. And apart from thinking deeply about our design and writing our code with care, one of the best ways to prevent bugs is to use TDD, a topic we will introduce in the next section.\n\nUnit Testing\n\nWriting tests for our programs—if done well—can help reduce the incidence of bugsand can increase our conﬁdence that our programsbehave as expected. But in general,testing cannot guarantee correctness,since for most nontrivial programs the range of possible inputs and the range of possible computations is so vast that only the tiniest fraction of them could ever be realistically tested. Nonetheless, by carefully choosing what we test we can improve the quality of our code.\n\nA variety of different kinds of testing can be done, such as usability testing, functional testing,and integration testing. But here we will concern ourselves\n\n425\n\n|||\n\n426\n\nChapter 9. Debugging,Testing,and Proﬁling\n\npurely with unit testing—testing individual functions, classes, and methods, to ensure that they behave according to our expectations.\n\nA key point of TDD,isthat when we want to add a feature—for example,a new method to a class—we ﬁrst write a test for it. And of course this test will fail since we haven’t written the method. Now we write the method, and once it passesthe test we can then rerun allthe teststo make sure our addition hasn’t had any unexpected side effects. Once all the tests run (including the one we added for the new feature),we can check in our code,reasonably conﬁdent that it does what we expect—providing of course that our test was adequate.\n\nFor example,if we want to write a function that insertsa string at a particular index position, we might start out using TDD like this:\n\ndef insert_at(string, position, insert):\n\n\"\"\"Returns a copy of string with insert inserted at the position\n\n>>> string = \"ABCDE\" >>> result = [] >>> for i in range(-2, len(string) + 2): ... >>> result[:5] ['ABC-DE', 'ABCD-E', '-ABCDE', 'A-BCDE', 'AB-CDE'] >>> result[5:] ['ABC-DE', 'ABCD-E', 'ABCDE-', 'ABCDE-'] \"\"\" return string\n\nresult.append(insert_at(string, i, \"-\"))\n\nForfunctionsormethodsthatdon’treturnanything (theyactuallyreturnNone), we normally give them a suite consisting of pass, and for those whose return value is used we either return a constant (say, 0) or one of the arguments, unchanged—which is what we have done here. (In more complex situations it may be more useful to return fake objects—third-party modules that provide “mock” objects are available for such cases.)\n\nWhen the doctest is run it will fail, listing each of the strings ('ABCD-EF', 'ABCDE-F', etc.) that it expected, and the strings it actually got (all of which are 'ABCDEF'). Once we are satisﬁed that the doctest is sufﬁcient and correct, we can write the body of the function, which in this case is simply return string[:position] + insert + string[position:]. (And if we wrote return string[:position] + insert, and then copied and pasted string[:position] at the end to save ourselves some typing, the doctest will immediately reveal the error.)\n\nPython’s standard library provides two unit testing modules, doctest, which we have already brieﬂy seen here and earlier (in Chapter 5; 202➤, and Chap- ter 6; 247 ➤), and unittest. In addition, there are third-party testing tools for\n\nUnit Testing\n\nPython. Two of the most notable are nose (code.google.com/p/python-nose), which aims to be more comprehensive and useful than the standard unit- test module, while still being compatible with it, and py.test (codespeak. net/py/dist/test/test.html)—this takes a somewhat different approach to unittest, and tries as much as possible to eliminate boilerplate test code. Both of these third-party tools support test discovery,so there is no need to write an overarching test program—since they will search for tests themselves. This makes it easy to test an entire tree of code or just a part of the tree (e.g., just those modules that have been worked on). For those serious about testing it is worth investigating both of these third-party modules (and any others that appeal), before deciding which testing tools to use.\n\nCreating doctests is straightforward: We write the tests in the module, func- tion,class,and methods’docstrings,and for modules,we simply add three lines at the end of the module:\n\nif __name__ == \"__main__\":\n\nimport doctest doctest.testmod()\n\nIf we want to use doctests inside programs,that is also possible. For example, the blocks.py program whose modules are covered later (in Chapter 14) has doctests for its functions, but it ends with this code:\n\nif __name__ == \"__main__\":\n\nmain()\n\nThis simply calls the program’s main() function, and does not execute the program’s doctests. To exercise the program’s doctests there are two ap- proaches we can take. One is to import the doctest module and then run the program—for example, at the console, python3 -m doctest blocks.py (on Win- dows, replacing python3 with something like C:\\Python31\\python.exe). If all the tests run ﬁne there is no output, so we might prefer to execute python3 -m doctest blocks.py -v instead, since this will list every doctest that is executed, and provide a summary of results at the end.\n\nAnother way to execute doctests is to create a separate test program using the unittest module. The unittest module is conceptually modeled on Java’s JUnit unit testing library and is used to create test suites that contain test cases. The unittest module can create test cases based on doctests, without having to know anything about what the program or module contains, apart from the fact that it has doctests. So to make a test suite for the blocks.py program, we can create the following simple program (which we have called test_blocks.py):\n\nimport doctest import unittest import blocks\n\n427\n\n428\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nsuite = unittest.TestSuite() suite.addTest(doctest.DocTestSuite(blocks)) runner = unittest.TextTestRunner() print(runner.run(suite))\n\nNote that there is an implicit restriction on the names of our programs if we take this approach: They must have names that are valid module names, so a program called convert-incidents.py cannot have a test like this written for it because import convert-incidents is not valid since hyphens are not legal in Python identiﬁers. (It is possible to get around this, but the easiest solution is to use program ﬁlenames that are also valid module names, for example, replacing hyphens with underscores.)\n\nThe structure shown here—create a test suite, add one or more test cases or test suites, run the overarching test suite, and output the results—is typical of unittest-based tests. When run, this particular example produces the following output:\n\n... ---------------------------------------------------------------------- Ran 3 tests in 0.244s\n\nOK <unittest._TextTestResult run=3 errors=0 failures=0>\n\nEach time a test case is executed a period is output (hence the three periods at the beginning of the output), then a line of hyphens, and then the test summary. (Naturally, there is a lot more output if any tests fail.)\n\nIf we are making the effort to have separate tests (typically one for each pro- gram and module we want to test), then rather than using doctests we might prefer to directly use the unittest module’sfeatures—especially if we are used to the JUnit approach to testing. The unittest modulekeepsour testsseparate from our code—thisis particularly useful for larger projectswhere test writers and developers are not necessarily the same people. Also, unittest unit tests are written as stand-alone Python modules,so they are not limited by what we can comfortably and sensibly write inside a docstring.\n\nThe unittest module deﬁnes four key concepts. A test ﬁxture is the term used to describe the code necessary to set up a test (and to tear it down, that is, clean up, afterward).Typical examples are creating an input ﬁle for the test to use and at the end deleting the input ﬁle and the resultant output ﬁle. A test suiteis a collection of test casesand a test caseis the basic unit of testing—test suites are collections of test cases or of other test suites—we’ll see practical examples of these shortly. A test runner is an object that executes one or more test suites.\n\nAtom- ic.py ex- ercise 411➤\n\nUnit Testing\n\nTypically, a test suite is made by creating a subclass of unittest.TestCase, where each method that has a name beginning with “test” is a test case. If we need any setup to be done, we can do it in a method called setUp(); similar- ly, for any cleanup we can implement a method called tearDown(). Within the tests there are a number of unittest.TestCase methods that we can make use of, including assertTrue(), assertEqual(), assertAlmostEqual() (useful for test- ing ﬂoating-point numbers), assertRaises(), and many more, including many inverses such as assertFalse(), assertNotEqual(), failIfEqual(), failUnlessE- qual(), and so on.\n\nThe unittest module iswell documentedand hasa lot of functionality,but here we will just give a ﬂavor of its use by reviewing a very simple test suite. The example we will use is the solution to one of the exercises given at the end of Chapter 8. The exercise was to create an Atomic module which could be used as a context manager to ensure that either all of a set of changes is applied to a list, set, or dictionary—or none of them are. The Atomic.py module provided as an example solution uses 30 lines of code to implement the Atomic class, and has about 100 lines of module doctests. We will create the test_Atomic.py module to replace the doctests with unittest tests so that we can then delete the doctests and leave Atomic.py free of any code except that needed to provide its functionality.\n\nBefore diving into writing the test module, we need to think about what tests are needed. We will need to test three different kinds of data type: lists, sets, and dictionaries. For lists we need to test appending and inserting an item, deleting an item, and changing an item’s value. For sets we must test adding and discarding an item. And for dictionaries we must test inserting an item, changing an item’s value, and deleting an item. Also, we must test that in the case of failure, none of the changes are applied.\n\nStructurally,testing the different data types is essentially the same,so we will only write the test cases for testing lists and leave the others as an exercise. The test_Atomic.py module must import both the unittest module and the Atomic module that it is designed to test.\n\nWhen creating unittest ﬁles,we usually create modulesrather than programs, and inside each module we deﬁne one or more unittest.TestCase subclasses. In the case of the test_Atomic.py module, it deﬁnes a single unittest.TestCase subclass,TestAtomic (whichwewillreviewshortly),andendswith thefollowing two lines:\n\nif __name__ == \"__main__\":\n\nunittest.main()\n\nThanks to these lines, the module can be run stand-alone. And of course, it could also be imported and run from another test program—something that makes sense if this is just one test suite among many.\n\n429",
      "page_number": 410
    },
    {
      "number": 43,
      "title": "Segment 43 (pages 419-426)",
      "start_page": 419,
      "end_page": 426,
      "detection_method": "topic_boundary",
      "content": "430\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nIf we want to run the test_Atomic.py module from another test program we can write a program that issimilar to the one we used to execute doctestsusing the unittest module. For example:\n\nimport unittest import test_Atomic\n\nsuite = unittest.TestLoader().loadTestsFromTestCase(\n\ntest_Atomic.TestAtomic)\n\nrunner = unittest.TextTestRunner() print(runner.run(suite))\n\nHere, we have created a single suite by telling the unittest module to read the test_Atomic module and to use each of its test*() methods(test_list_success() and test_list_fail() in this example, as we will see in a moment), as test cases.\n\nWe will now review the implementation of the TestAtomic class. Unusually for subclasses generally,although not for unittest.TestCase subclasses,there is no need to implement theinitializer. In thiscasewe will need a setupmethod,but not a teardown method. And we will implement two test cases.\n\ndef setUp(self):\n\nself.original_list = list(range(10))\n\nWe have used the unittest.TestCase.setUp() method to create a single piece of test data.\n\ndef test_list_succeed(self):\n\nitems = self.original_list[:] with Atomic.Atomic(items) as atomic:\n\natomic.append(1999) atomic.insert(2, -915) del atomic[5] atomic[4] = -782 atomic.insert(0, -9)\n\nself.assertEqual(items,\n\n[-9, 0, 1, -915, 2, -782, 5, 6, 7, 8, 9, 1999])\n\nThis test case is used to test that all of a set of changes to a list are correctly applied. The test performs an append,an insertion in the middle,an insertion at the beginning, a deletion, and a change of a value. While by no means comprehensive, the test does at least cover the basics.\n\nThe test should not raise an exception, but if it does the unittest.TestCase base class will handle it by turning it into an appropriate error message. At the end we expect the items list to equal the literal list included in the test rather than the original list. The unittest.TestCase.assertEqual() method can\n\nUnit Testing\n\ncompare any two Python objects, but its generality means that it cannot give particularly informative error messages.\n\nFrom Python 3.1, the unittest.TestCase class has many more methods, includ- ing many data-type-speciﬁc assertion methods. Here ishow we could writethe assertion using Python 3.1:\n\nself.assertListEqual(items,\n\n[-9, 0, 1, -915, 2, -782, 5, 6, 7, 8, 9, 1999])\n\nIf the lists are not equal, since the data types are known, the unittest module is able to give more precise error information, including where the lists differ.\n\ndef test_list_fail(self):\n\ndef process():\n\nnonlocal items with Atomic.Atomic(items) as atomic:\n\natomic.append(1999) atomic.insert(2, -915) del atomic[5] atomic[4] = -782 atomic.poop() # Typo\n\nitems = self.original_list[:] self.assertRaises(AttributeError, process) self.assertEqual(items, self.original_list)\n\nTo test the failure case,that is,where an exception israised while doing atomic processing, we must test that the list has not been changed and also that an appropriate exception has been raised. To check for an exception we use the unittest.TestCase.assertRaises() method, and in the case of Python 3.0, we passit the exception we expect to get and a callable object that should raise the exception. This forces us to encapsulate the code we want to test,which is why we had to create the process() inner function shown here.\n\nIn Python 3.1 the unittest.TestCase.assertRaises() method can be used as a context manager, so we are able to write our test in a much more natural way:\n\ndef test_list_fail(self):\n\nitems = self.original_list[:] with self.assertRaises(AttributeError):\n\nwith Atomic.Atomic(items) as atomic:\n\natomic.append(1999) atomic.insert(2, -915) del atomic[5] atomic[4] = -782 atomic.poop() # Typo\n\nself.assertListEqual(items, self.original_list)\n\n431\n\n3.1\n\n3.1\n\n432\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nHere we have written the test code directly in the test method without the need for an inner function,insteadusing unittest.TestCase.assertRaised() asa context manager that expectsthe code to raise an AttributeError.We have also used Python 3.1’s unittest.TestCase.assertListEqual() method at the end.\n\nAs we have seen, Python’s test modules are easy to use and are extremely use- ful, especially if we use TDD. They also have a lot more functionality and fea- tures than have been shown here—for example, the ability to skip tests which is useful to account for platform differences—and they are also well document- ed. One feature that is missing—and which nose and py.test provide—is test discovery,although this feature is expected to appear in a later Python version (perhaps as early as Python 3.2).\n\nProﬁling\n\nIf a program runs very slowly or consumes far more memory than we expect, the problem is most often due to our choice of algorithmsor data structures,or due to our doing an inefﬁcient implementation. Whatever the reason for the problem,it is best to ﬁnd out precisely where the problem lies rather than just inspecting our code and trying to optimize it. Randomly optimizing can cause us to introduce bugs or to speed up parts of our program that actually have no effect on the program’soverall performance because the improvementsare not in places where the interpreter spends most of its time.\n\nBefore going further into proﬁling, it is worth noting a few Python program- ming habits that are easy to learn and apply, and that are good for perfor- mance. None of the techniques is Python-version-speciﬁc, and all of them are perfectly sound Python programming style. First, prefer tuples to lists when a read–only sequence is needed. Second, use generators rather than creating large tuples or lists to iterate over. Third, use Python’s built-in data structures—dicts, lists, and tuples—rather than custom data structures implemented in Python, since the built-in ones are all very highly optimized. Fourth,when creating large strings out of lots of small strings,instead of con- catenating the small strings, accumulate them all in a list, and join the list of stringsintoa singlestring at theend. Fifthand ﬁnally,if an object(including a function or method) is accessed a large number of times using attribute access (e.g., when accessing a function in a module), or from a data structure, it may be better to create and use a local variable that refers to the object to provide faster access.\n\nPython’s standard library provides two modules that are particularly useful when we want to investigate the performance of our code. One of these is the timeit module—thisisusefulfor timing smallpiecesof Pythoncode,andcanbe used,for example,tocomparetheperformanceof twoor moreimplementations of a particular function or method. The other isthe cProfile module which can\n\n|||\n\n3.1\n\nProﬁling\n\nbe used to proﬁle a program’s performance—it provides a detailed breakdown of call counts and times and so can be used to ﬁnd performance bottlenecks.★\n\nTo give a ﬂavor of the timeit module,we will look at a small example. Suppose we have three functions, function_a(), function_b(), and function_c(), all of which perform the same computation, but each using a different algorithm. If we put all these functions into a module (or import them), we can run them using the timeit module to see how they compare. Here is the code that we would use at the end of the module:\n\nif __name__ == \"__main__\":\n\nrepeats = 1000 for function in (\"function_a\", \"function_b\", \"function_c\"):\n\nt = timeit.Timer(\"{0}(X, Y)\".format(function),\n\n\"from __main__ import {0}, X, Y\".format(function))\n\nsec = t.timeit(repeats) / repeats print(\"{function}() {sec:.6f} sec\".format(**locals()))\n\nThe ﬁrst argument given to the timeit.Timer() constructor is the code we want toexecuteandtime,intheformof a string. Here,theﬁrsttimearoundtheloop, the string is \"function_a(X, Y)\". The second argument is optional; again it is a string to be executed,thistime beforethe code to be timed so asto provide some setup. Here we have imported from the __main__ (i.e.,this)module the function we want to test, plus two variables that are passed as input data (X and Y), and that are available as global variables in the module. We could just as easily have imported the function and data from a different module.\n\nWhen the timeit.Timer object’s timeit() method is called, it will ﬁrst execute the constructor’s second argument—if there was one—to set things up, and then it will execute the constructor’s ﬁrst argument—and time how long the execution takes. The timeit.Timer.timeit() method’s return value is the time taken in seconds, as a float. By default, the timeit() method repeats 1 million times and returns the total seconds for all these executions, but in this partic- ular case we needed only 1000 repeatsto give us useful results,so we speciﬁed the repeat count explicitly. After timing each function we divide the total by the number of repeats to get its mean (average) execution time and print the function’s name and execution time on the console.\n\nfunction_a() 0.001618 sec function_b() 0.012786 sec function_c() 0.003248 sec\n\nIn this example, function_a() is clearly the fastest—at least with the input data that was used. In some situations—for example, where performance can\n\n★The cProfile module is usually availablefor CPython interpreters,but is not alwaysavailablefor others. All Python libraries should have the pure Python profile module which provides the same API as the cProfile module, and does the same job, only more slowly.\n\n433\n\n434\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nvary considerably depending on the input data—we might have to test each function with multiple sets of input data to cover a representative set of cases and then compare the total or average execution times.\n\nIt isn’t always convenient to instrument our code to get timings, and so the timeit module provides a way of timing code from the command line. For example, to time function_a() from the MyModule.py module, we would enter the following in the console: python3 -m timeit -n 1000 -s \"from MyModule import function_a, X, Y\" \"function_a(X, Y)\". (As usual, for Windows, we must replace python3 with something like C:\\Python31\\python.exe.) The -m option is for the Python interpreter and tells it to load the speciﬁed module (in this case timeit) and theother optionsarehandledby the timeit module. The -n optionspeciﬁes the repetition count, the -s option speciﬁes the setup, and the last argument is the code to execute and time. After the command has ﬁnished it prints its results on the console, for example:\n\n1000 loops, best of 3: 1.41 msec per loop\n\nWe can easily then repeat the timing for the other two functionsso that we can compare them all.\n\nThe cProfile module (or the profile module—we will refer to them both as the cProfile module) can also be used to compare the performance of functions and methods. And unlike the timeit module that just provides raw timings, the cProfile module shows precisely what is being called and how long each call takes. Here’s the code we would use to compare the same three functions as before:\n\nif __name__ == \"__main__\":\n\nfor function in (\"function_a\", \"function_b\", \"function_c\"):\n\ncProfile.run(\"for i in range(1000): {0}(X, Y)\"\n\n.format(function))\n\nWe must put the number of repeats inside the code we pass to the cPro- file.run() function, but we don’t need to do any setup since the module func- tion uses introspection to ﬁnd the functions and variables we want to use. There is no explicit print() statement since by default the cProfile.run() func- tion prints its output on the console. Here are the results for all the functions (with some irrelevant lines omitted and slightly reformatted to ﬁt the page):\n\n1003 function calls in 1.661 CPU seconds ncalls tottime percall cumtime percall filename:lineno(function) 1 0.003 0.003 1.661 1.661 <string>:1(<module>) 1000 1.658 0.002 1.658 0.002 MyModule.py:21(function_a) 1 0.000 0.000 1.661 1.661 {built-in method exec}\n\n5132003 function calls in 22.700 CPU seconds\n\nProﬁling\n\nncalls tottime percall cumtime percall filename:lineno(function) 1 0.487 0.487 22.700 22.700 <string>:1(<module>) 1000 0.011 0.000 22.213 0.022 MyModule.py:28(function_b) 5128000 7.048 0.000 7.048 0.000 MyModule.py:29(<genexpr>) 1000 0.005 0.000 0.005 0.000 {built-in method bisect_left} 1 0.000 0.000 22.700 22.700 {built-in method exec} 1000 0.001 0.000 0.001 0.000 {built-in method len} 1000 15.149 0.015 22.196 0.022 {built-in method sorted}\n\n5129003 function calls in 12.987 CPU seconds ncalls tottime percall cumtime percall filename:lineno(function) 1 0.205 0.205 12.987 12.987 <string>:1(<module>) 1000 6.472 0.006 12.782 0.013 MyModule.py:36(function_c) 5128000 6.311 0.000 6.311 0.000 MyModule.py:37(<genexpr>) 1 0.000 0.000 12.987 12.987 {built-in method exec}\n\nThe ncalls (“number of calls”) column lists the number of calls to the speciﬁed function (listed in the filename:lineno(function) column). Recall that we re- peated the calls 1000 times, so we must keep this in mind. The tottime (“total time”) column lists the total time spent in the function, but excluding time spent inside functions called by the function. The ﬁrst percall column lists the average time of each call to the function (tottime // ncalls). The cumtime (“cumulativetime”)columnliststhetimespentin thefunctionandincludesthe time spent inside functions called by the function. The second percall column lists the average time of each call to the function, including functions called by it.\n\nThisoutput isfar more enlightening than the timeit module’sraw timings. We can immediately see that both function_b() and function_c() use generators that are called more than 5000 times, making them both at least ten times slower than function_a(). Furthermore, function_b() calls more functions gen- erally,including a calltothebuilt-in sorted() function,andthismakesitalmost twice as slow as function_c().Of course,the timeit() module gave us sufﬁcient information to see these differences in timing, but the cProfile module allows us to see the details of why the differences are there in the ﬁrst place.\n\nJust as the timeit module allows us to time code without instrumenting it, so does the cProfile module. However, when using the cProfile module from the command line we cannot specify exactly what we want executed—it simply executes the given program or module and reports the timings of everything. The command line to use is python3 -m cProfile programOrModule.py, and the output produced is in the same format as we saw earlier; here is an extract slightly reformatted and with most lines omitted:\n\n435\n\n436\n\nChapter 9. Debugging,Testing,and Proﬁling\n\n10272458 function calls (10272457 primitive calls) in 37.718 CPU secs ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 37.718 37.718 <string>:1(<module>) 1 0.719 0.719 37.717 37.717 <string>:12(<module>) 1000 1.569 0.002 1.569 0.002 <string>:20(function_a) 1000 0.011 0.000 22.560 0.023 <string>:27(function_b) 5128000 7.078 0.000 7.078 0.000 <string>:28(<genexpr>) 1000 6.510 0.007 12.825 0.013 <string>:35(function_c) 5128000 6.316 0.000 6.316 0.000 <string>:36(<genexpr>)\n\nIn cProfile terminology, a primitive call is a nonrecursive function call.\n\nUsing the cProfile module in this way can be useful for identifying areas that are worth investigating further. Here, for example, we can clearly see that function_b() takes a long time. But how do we drill down into the details? We could instrument the programby replacing callsto function_b() with cProfile. run(\"function_b()\"). Or we could save the complete proﬁle data and analyze it using the pstats module. To save the proﬁle we must modify our command line slightly:python3 -m cProfile -o profileDataFile programOrModule.py.We can then analyze the proﬁle data, for example, by starting IDLE, importing the pstats module,and giving it the saved profileDataFile,or by using pstats interactive- ly at the console. Here’s a very short example console session that has been tidied up slightly to ﬁt on the page, and with our input shown in bold:\n\n$ python3 -m cProfile -o profile.dat MyModule.py $ python3 -m pstats Welcome to the profile statistics browser. % read profile.dat profile.dat% callers function_b Random listing order was used List reduced from 44 to 1 due to restriction <'function_b'> Function was called by... ncalls tottime cumtime <string>:27(function_b) <- 1000 0.011 22.251 <string>:12(<module>)\n\nprofile.dat% callees function_b Random listing order was used List reduced from 44 to 1 due to restriction <'function_b'> Function called... ncalls tottime cumtime <string>:27(function_b) -> 1000 0.005 0.005 built-in method bisect_left 1000 0.001 0.001 built-in method len 1000 15.297 22.234 built-in method sorted profile.dat% quit\n\nProﬁling\n\nType help to get the list of commands, and help followed by a command name for more information on the command. For example, help stats will list what arguments can be given to the stats command. Other tools are available that can provide a graphical visualization of the proﬁle data, for example, RunSnakeRun (www.vrplumber.com/programming/runsnakerun), which depends on the wxPython GUI library.\n\nUsing the timeit and cProfile modules we can identify areas of our code that might be taking more time than expected, and using the cProfile module, we can ﬁnd out exactly where the time is being taken.\n\nSummary\n\nIn general, Python’s reporting of syntax errors is very accurate, with the line and position in the line being correctly identiﬁed. The only cases where this doesn’t work well are when we forget a closing parenthesis, bracket, or brace, in which casetheerror isnormally reportedasbeing on thenext nonblank line. Fortunately, syntax errors are almost always easy to see and to ﬁx.\n\nIf an unhandled exception is raised,Python will terminate and output a trace- back. Such tracebacks can be intimidating for end-users, but provide useful information to us as programmers. Ideally, we should always handle every type of exception that we believe our program can raise, and where necessary present the problem to the user in the form of an error message, message box, or log message—but not as a raw traceback. However, we should avoid using the catchall except: exception handler—if we want to handle all exceptions (e.g.,at thetoplevel),thenwecanuse except Exception as err,andalwaysreport err, since silently handling exceptions can lead to programs failing in subtle and unnoticed ways (such as corrupting data) later on. And during develop- ment, it is probably best not to have a top-level exception handler at all and to simply have the program crash with a traceback.\n\nDebugging need not be—and should not be—a hit and miss affair. By narrow- ing down the input necessary to reproduce the bug to the bare minimum, by carefully hypothesizing what the problem is, and then testing the hypothesis by experiment—using print() statements or a debugger—we can often locate the source of the bug quite quickly. And if our hypothesis has successfully led us to the bug, it is likely to also be helpful in devising a solution.\n\nFor testing, both the doctest and the unittest modules have their own partic- ular virtues. Doctests tend to be particularly convenient and useful for small libraries and modules since well-chosen tests can easily both illustrate and exercise boundary as well as common cases, and of course, writing doctests is convenient and easy. On the other hand,since unit testsare not constrained to be written inside docstrings and are written as separate stand-alone modules, they are usually a better choice when it comes to writing more complex and\n\n437\n\n|||",
      "page_number": 419
    },
    {
      "number": 44,
      "title": "Segment 44 (pages 427-434)",
      "start_page": 427,
      "end_page": 434,
      "detection_method": "topic_boundary",
      "content": "438\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nsophisticated tests,especially teststhat require setup and teardown (cleanup). For larger projects, using the unittest module (or a third-party unit testing module) keeps the tests and tested programsand modules separate and is gen- erally more ﬂexible and powerful than using doctests.\n\nIf we hit performance problems, the cause is most often our own code, and in particular our choice of algorithmsand data structures,or some inefﬁciency in our implementation. When faced with such problems, it is always wise to ﬁnd out exactly where the performance bottleneck is, rather than to guess and end up spending time optimizing something that doesn’t actually improve perfor- mance. Python’s timeit module can be used to get raw timings of functions or arbitrary code snippets,and so is particularly useful for comparing alternative function implementations. And for in-depth analysis,the cProfile module pro- vides both timing and call count information so that we can identify not only which functions take the most time, but also what functions they in turn call.\n\nOverall, Python has excellent support for debugging, testing, and proﬁling, right out of the box. However, especially for large projects, it is worth consid- ering some of the third-party testing tools,since they may offer more function- ality and convenience than the standard library’s testing modules provide.\n\n10 ● Using the Multiprocessing Module\n\nUsing the Threading Module\n\nProcesses and Threading\n\nWith theadvent of multicoreprocessorsasthenorm rather than theexception, it is more tempting and more practical than ever before to want to spread the processing load so as to get the most out of all the available cores. There are two main approaches to spreading the workload. One is to use multiple processes and the other is to use multiple threads. This chapter shows how to use both approaches.\n\nUsing multiple processes, that is, running separate programs, has the advan- tage that each process runs independently. This leaves all the burden of han- dling concurrency to the underlying operating system. The disadvantage is that communication and data sharing between the invoking program and the separate processes it invokes can be inconvenient. On Unix systems this can be solved by using the exec and fork paradigm, but for cross-platform pro- grams other solutions must be used. The simplest, and the one shown here, is for the invoking program to feed data to the processes it runs and leave them to produce their output independently. A more ﬂexible approach that greatly simpliﬁes two-way communication is to use networking. Of course, in many situations such communication isn’t needed—we just need to run one or more other programs from one orchestrating program.\n\nAn alternative to handing off work to independent processes is to create a threaded program that distributes work to independent threads of execution. This has the advantage that we can communicate simply by sharing data (pro- viding weensurethat shareddata isaccessedonly by onethreadat a time),but leaves the burden of managing concurrency squarely with the programmer. Python provides good support for creating threaded programs,minimizing the work that we must do. Nonetheless, multithreaded programs are inherently more complex than single-threaded programs and require much more care in their creation and maintenance.\n\nIn this chapter’s ﬁrst section we will create two small programs. The ﬁrst pro- gram isinvoked by the user and the second program isinvoked by the ﬁrst pro-\n\n439\n\n||||\n\n440\n\nChapter 10. Processes and Threading\n\ngram, with the second program invoked once for each separate process that is required. In the second section we will begin by giving a bare-bones introduc- tion to threaded programming. Then we will create a threaded program that hasthe same functionality asthe two programsfrom the ﬁrst section combined so as to provide a contrast between the multiple processes and the multiple threadsapproaches. And then we will review another threaded program,more sophisticated than the ﬁrst, that both hands off work and gathers together all the results.\n\nUsing the Multiprocessing Module\n\nIn some situations we already have programs that have the functionality we need but we want to automate their use. We can do this by using Python’s sub- process module which provides facilities for running other programs, passing any command-line options we want, and if desired, communicating with them using pipes. We saw one very simple example of this in Chapter 5 when we used the subprocess.call() function to clear the console in a platform-speciﬁc way. But we can also use these facilities to create pairs of “parent–child” pro- grams, where the parent program is run by the user and this in turn runs as many instances of the child program as necessary,each with different work to do. It is this approach that we will cover in this section.\n\nIn Chapter 3 we showed a very simple program, grepword.py, that searches for a word speciﬁed on the command line in the ﬁles listed after the word. In this section we will develop a more sophisticated version that can recurse into subdirectories to ﬁnd ﬁles to read and that can delegate the work to as many separate child processes as we like. The output is just a list of ﬁlenames (with paths) for those ﬁles that contain the speciﬁed search word.\n\nThe parent program is grepword-p.py and the child program is grepword-p- child.py.The relationship between the two programs when they are being run is shown schematically in Figure 10.1.\n\nThe heart of grepword-p.py isencapsulatedby its main() function,which we will look at in three parts:\n\ndef main():\n\nchild = os.path.join(os.path.dirname(__file__),\n\n\"grepword-p-child.py\")\n\nopts, word, args = parse_options() filelist = get_files(args, opts.recurse) files_per_process = len(filelist) // opts.count start, end = 0, files_per_process + (len(filelist) % opts.count) number = 1\n\n|||\n\n442\n\nChapter 10. Processes and Threading\n\nthe Python interpreter,but we prefer thisapproach because it ensuresthat the child program uses the same Python interpreter as the parent program.\n\nOnce we have the command ready we create a subprocess.Popen object, speci- fying the command to execute (as a list of strings),and in this case requesting to write to the process’s standard input. (It is also possible to read a process’s standard output by setting a similar keyword argument.) We then write the search word followed by a newline and then every ﬁle in the relevant slice of the ﬁle list. The subprocess module reads and writes bytes,not strings,but the processes it creates always assume that the bytes received from sys.stdin are stringsin the local encoding—even if the byteswe have sent use a different en- coding,such as UTF-8 which we have used here. We will see how to get around this annoying problem shortly. Once the word and the list of ﬁles have been written to the child process, we close its standard input and move on.\n\nIt isnot strictly necessary to keep a referenceto each process(the pipe variable gets rebound to a new subprocess.Popen object each time through the loop), since each process runs independently,but we add each one to a list so that we can make them interruptible. Also, we don’t gather the results together, but instead we let each processwrite itsresultsto the console in itsown time. This means that the output from different processes could be interleaved. (You will get the chance to avoid interleaving in the exercises.)\n\nwhile pipes:\n\npipe = pipes.pop() pipe.wait()\n\nOncealltheprocesseshavestartedwewaitforeachchildprocesstoﬁnish. This isnot essential,but on Unix-like systemsit ensuresthat we are returned to the console prompt when all the processesare done(otherwise,we must pressEnter when they are all ﬁnished). Another beneﬁt of waiting is that if we interrupt the program (e.g., by pressing Ctrl+C), all the processes that are still running will be interrupted and will terminate with an uncaught KeyboardInterrupt exception—if wedidnot waitthemainprogramwouldﬁnish(andthereforenot beinterruptible),and thechild processeswould continue(unlesskilled by a kill program or a task manager).\n\nApart from the comments and imports, here is the complete grepword-p- child.py program. We will look at the program in two parts—with two ver- sions of the ﬁrst part, the ﬁrst for any Python 3.x version and the second for Python 3.1 or later\n\nversions:\n\nBLOCK_SIZE = 8000\n\nnumber = \"{0}: \".format(sys.argv[1]) if len(sys.argv) == 2 else \"\" stdin = sys.stdin.buffer.read() lines = stdin.decode(\"utf8\", \"ignore\").splitlines() word = lines[0].rstrip()\n\n3.x\n\n3.0\n\nUsing the Multiprocessing Module\n\nThe program begins by setting the number string to the given number or to an empty string if we are not debugging. Since the program is running as a child process and the subprocess module only reads and writes binary data and alwaysusesthe local encoding,we must read sys.stdin’sunderlying buffer of binary data and perform the decoding ourselves.★ Once we have read the binary data,we decode it into a Unicode string and split it into lines. The child process then reads the ﬁrst line, since this contains the search word.\n\nHere are the lines that are different for Python 3.1:\n\nsys.stdin = sys.stdin.detach() stdin = sys.stdin.read() lines = stdin.decode(\"utf8\", \"ignore\").splitlines()\n\nPython 3.1 provides the sys.stdin.detach() method that returns a binary ﬁle object. We then read in all the data, decode it into Unicode using the encoding of our choice, and then split the Unicode string into lines.\n\nfor filename in lines[1:]:\n\nfilename = filename.rstrip() previous = \"\" try:\n\nwith open(filename, \"rb\") as fh:\n\nwhile True:\n\ncurrent = fh.read(BLOCK_SIZE) if not current:\n\nbreak\n\ncurrent = current.decode(\"utf8\", \"ignore\") if (word in current or\n\nword in previous[-len(word):] +\n\ncurrent[:len(word)]):\n\nprint(\"{0}{1}\".format(number, filename)) break\n\nif len(current) != BLOCK_SIZE:\n\nbreak\n\nprevious = current\n\nexcept EnvironmentError as err:\n\nprint(\"{0}{1}\".format(number, err))\n\nAll the lines after the ﬁrst are ﬁlenames (with paths). For each one we open the relevant ﬁle,read it,and print its name if it contains the search word. It is possible that some of the ﬁles might be very large and this could be a problem, especially if there are 20 child processes running concurrently,all reading big\n\n★It is possible that a future version of Python will have a version of the subprocess module that allows encoding and errors arguments so that we can use our preferred encoding without having to access sys.stdin in binary mode and do the decoding ourselves. See bugs.python.org/issue6135.\n\n443\n\n3.1\n\nChar- acter encod- ings 91➤\n\n444\n\nChapter 10. Processes and Threading\n\nﬁles. We handle this by reading each ﬁle in blocks, keeping the previous block read to ensure that we don’t misscases when the only occurrence of the search word happens to fall across two blocks. Another beneﬁt of reading in blocks is that if the search word appears early in the ﬁle we can ﬁnish with the ﬁle without having read everything,since all we care about is whether the word is in the ﬁle, not where it appears within the ﬁle.\n\nThe ﬁles are read in binary mode,so we must convert each block to a string be- fore we can search it, since the search word is a string. We have assumed that all the ﬁlesuse the UTF-8encoding,but thisismost likely wrong in somecases. A more sophisticated program would try to determine the actual encoding and then close and reopen the ﬁle using the correct encoding. Aswe noted in Chap- ter 2,at least two Python packagesfor automatically detecting a ﬁle’sencoding are available from the Python Package Index, pypi.python.org/pypi. (It might be tempting to decode the search word into a bytes object and compare bytes with bytes, but that approach is not reliable since some characters have more than one valid UTF-8 representation.)\n\nThe subprocess module offers a lot more functionality than we have needed to use here, including the ability to provide equivalents to shell backquotes and shell pipelines, and to the os.system() and spawn functions.\n\nIn the next section we will see a threaded version of the grepword-p.py program so that we can compare it with the parent–child processes one. We will also look at a more sophisticated threaded program that delegates work and then gathers the results together to have more control over how they are output.\n\nUsing the Threading Module\n\nSetting up two or more separate threads of execution in Python is quite straightforward. The complexity arises when we want separate threads to share data. Imagine that we have two threads sharing a list. One thread might start iterating over the list using for x in L and then somewhere in the middleanotherthreadmightdeletesomeitemsinthelist. Atbestthiswilllead to obscure crashes, at worst to incorrect results.\n\nOne common solution is to use some kind of locking mechanism. For example, one thread might acquirea lock and thenstart iterating over the list;any other thread will then be blocked by the lock. In fact,thingsare not quite as clean as this. The relationship between a lock and the data it is locking exists purely in our imagination. If one thread acquires a lock and a second thread tries to acquire the same lock,the second thread will be blocked until the ﬁrst releases the lock. By putting access to shared data within the scope of acquired locks we can ensure that the shared data is accessed by only one thread at a time, even though the protection is indirect.\n\n|||\n\n446\n\nChapter 10. Processes and Threading\n\nwhen it is ready. No other threading.Thread methods may be reimplemented, although adding additional methods is ﬁne.\n\nExample: A Threaded Find Word Program\n\nIn this subsection we will review the code for the grepword-t.py program. This program does the same job as grepword-p.py, only it delegates the work to mul- tiple threads rather than to multiple processes. It is illustrated schematically in Figure 10.3.\n\nOne particularly interesting feature of the program is that it does not appear to use any locks at all. This is possible because the only shared data is a list of ﬁles, and for these we use the queue.Queue class. What makes queue.Queue special isthat it handlesall the locking itself internally,so whenever we access it to add or remove items, we can rely on the queue itself to serialize accesses. In the context of threading, serializing access to data means ensuring that only one thread at a time has access to the data. Another beneﬁt of using queue.Queue is that we don’t have to share out the work ourselves; we simply add items of work to the queue and leave the worker threads to pick up work whenever they are ready.\n\nThe queue.Queue class works on a ﬁrst in, ﬁrst out (FIFO) basis; the queue module also provides queue.LifoQueue for last in, ﬁrst out (LIFO) access, and queue.PriorityQueue which is given tuples such as the 2-tuple (priority, item), with items with the lowest priority numbers being processed ﬁrst. All the queuescanbecreatedwitha maximumsizeset;if themaximumsizeisreached the queue will block further attempts to add items until items have been removed.\n\nWe will look at the grepword-t.py program in three parts, starting with the complete main() function:\n\ndef main():\n\nopts, word, args = parse_options() filelist = get_files(args, opts.recurse) work_queue = queue.Queue() for i in range(opts.count):\n\nnumber = \"{0}: \".format(i + 1) if opts.debug else \"\" worker = Worker(work_queue, word, number) worker.daemon = True worker.start()\n\nfor filename in filelist:\n\nwork_queue.put(filename)\n\nwork_queue.join()\n\n||\n\nUsing the Threading Module\n\ngrepword-t.py\n\nmain thread\n\nthread #1\n\nthread #2\n\nthread #3\n\n…\n\nFigure 10.3 A multithreaded program\n\nGetting the user’soptionsand the ﬁle list are the same as before.Once we have thenecessary informationwecreatea queue.Queue and then loopasmany times as there are threads to be created;the default is 7. For each thread we prepare a number string for debugging (an empty string if we are not debugging) and then we create a Worker (a threading.Thread subclass) instance—we’ll come back to setting the daemon property in a moment. Next we start off the thread, although at this point it has no work to do because the work queue is empty,so the thread will immediately be blocked trying to get some work.\n\nWith all the threads created and ready for work we iterate over all the ﬁles, adding each one to the work queue. As soon as the ﬁrst ﬁle is added one of the threads could get it and start on it,and so on until all the threads have a ﬁle to work on. As soon as a thread ﬁnishes working on a ﬁle it can get another one, until all the ﬁles are processed.\n\nNotice that this differs from grepword-p.py where we had to allocate slices of the ﬁle list to each child process, and the child processes were started and given their lists sequentially. Using threads is potentially more efﬁcient in cases like this. For example, if the ﬁrst ﬁve ﬁles are very large and the rest are small, because each thread takes on one job at a time each large ﬁle will be processed by a separate thread, nicely spreading the work. But with the multipleprocessesapproachwetook inthe grepword-p.py program,allthelarge ﬁles would be given to the ﬁrst process and the small ﬁles given to the others, so theﬁrst processwould end updoing most of thework while theothersmight all ﬁnish quickly without having done much at all.\n\nThe program will not terminate while it has any threads running. This is a problem because once the worker threadshave done their work,although they have ﬁnished they are technically still running. The solution is to turn the threads into daemons. The effect of this is that the program will terminate as soon as the program has no nondaemon threads running. The main thread is not a daemon, so once the main thread ﬁnishes, the program will cleanly terminate each daemon thread and then terminate itself. Of course, this can now create the opposite problem—once the threads are up and running we must ensure that the main thread does not ﬁnish until all the work is done. This is achieved by calling queue.Queue.join()—this method blocks until the queue is empty.\n\nHere is the start of the Worker class:\n\n447",
      "page_number": 427
    },
    {
      "number": 45,
      "title": "Segment 45 (pages 435-445)",
      "start_page": 435,
      "end_page": 445,
      "detection_method": "topic_boundary",
      "content": "448\n\nChapter 10. Processes and Threading\n\nclass Worker(threading.Thread):\n\ndef __init__(self, work_queue, word, number):\n\nsuper().__init__() self.work_queue = work_queue self.word = word self.number = number\n\ndef run(self):\n\nwhile True: try:\n\nfilename = self.work_queue.get() self.process(filename)\n\nfinally:\n\nself.work_queue.task_done()\n\nThe __init__() method must call the base class __init__(). The work queue is the same queue.Queue shared by all the threads.\n\nWe have made the run() method an inﬁnite loop. This is common for daemon threads, and makes sense here because we don’t know how many ﬁles the threadmustprocess. At each iterationwecall queue.Queue.get() toget thenext ﬁle to work on. This call will block if the queue is empty, and does not have to be protected by a lock because queue.Queue handles that automatically for us. Once we have a ﬁle we process it, and afterward we must tell the queue that we have done that particular job—calling queue.Queue.task_done() is essential to the correct working of queue.Queue.join().\n\nWe have not shown the process() function,because apart from the def line, the code is the same as the code used in grepword-p-child.py from the previous = \"\" line to the end (443➤).\n\nOne ﬁnal point to note is that included with the book’s examples is grepword- m.py, a program that is almost identical to the grepword-t.py program reviewed here, but which uses the multiprocessing module rather than the threading module. The code has just three differences: ﬁrst, we import multiprocessing instead of queue and threading; second, the Worker class inherits multiprocess- ing.Process instead of threading.Thread; and third, the work queue is a multi- processing.JoinableQueue instead of a queue.Queue.\n\nThe multiprocessing module provides thread-like functionality using forking on systemsthat support it (Unix),and child processeson those that don’t (Win- dows), so locking mechanisms are not always required, and the processes will run on whateverprocessorcorestheoperating systemhasavailable. Thepack- age provides several ways of passing data between processes, including using a queue that can be used to provide work for processesjust like queue.Queue can be used to provide work for threads.\n\nUsing the Threading Module\n\nThe chief beneﬁt of the multiprocessing version is that it can potentially run faster on multicore machines than the threaded version since it can run its processes on as many cores as are available. Compare this with the standard Python interpreter (written in C, sometimes called CPython) which has a GIL (Global Interpreter Lock) that means that only one thread can execute Python code at any one time. Thisrestriction isan implementation detail and doesnot necessarily apply to other Python interpreters such as Jython.★\n\nExample: A Threaded Find Duplicate Files Program\n\nThe second threading example has a similar structure to the ﬁrst, but is more sophisticated in several ways. It uses two queues, one for work and one for results, and has a separate results processing thread to output results as soon as they are available. It also shows both a threading.Thread subclass and calling threading.Thread() with a function, and also uses a lock to serialize access to shared data (a dict).\n\nThe findduplicates-t.py program is a more advanced version of the finddup.py program from Chapter 5. It iterates over all the ﬁles in the current directory (or the speciﬁed path), recursively going into subdirectories. It compares the lengths of all the ﬁles with the same name (just like finddup.py), and for those ﬁles that have the same name and the same size it then uses the MD5 (Message Digest) algorithm to check whether the ﬁles are the same, reporting any that are.\n\nWe will start by looking at the main() function, split into four parts.\n\ndef main():\n\nopts, path = parse_options() data = collections.defaultdict(list) for root, dirs, files in os.walk(path):\n\nfor filename in files:\n\nfullname = os.path.join(root, filename) try:\n\nkey = (os.path.getsize(fullname), filename)\n\nexcept EnvironmentError:\n\ncontinue if key[0] == 0: continue\n\ndata[key].append(fullname)\n\n★For a brief explanationof why CPythonusesa GIL see www.python.org/doc/faq/library/#can-t-we- get-rid-of-the-global-interpreter-lock and docs.python.org/api/threads.html.\n\n449\n\n||\n\n450\n\nChapter 10. Processes and Threading\n\nEach key of the data default dictionary is a 2-tuple of (size, ﬁlename), where the ﬁlename does not include the path, and each value is a list of ﬁlenames (which do include their paths). Any items whose value list has more than one ﬁlename potentially has duplicates. The dictionary is populated by iterating over all the ﬁles in the given path,but skipping any ﬁles we cannot get the size of (perhapsdue to permissionsproblems,or because they are not normal ﬁles), and any that are of 0 size (since all zero length ﬁles are the same).\n\nwork_queue = queue.PriorityQueue() results_queue = queue.Queue() md5_from_filename = {} for i in range(opts.count):\n\nnumber = \"{0}: \".format(i + 1) if opts.debug else \"\" worker = Worker(work_queue, md5_from_filename, results_queue,\n\nnumber)\n\nworker.daemon = True worker.start()\n\nWith all the data in place we are ready to create the worker threads. We begin by creating a work queue and a results queue. The work queue is a priority queue, so it will always return the lowest-priority items (in our case the smallest ﬁles) ﬁrst. We also create a dictionary where each key is a ﬁlename (including its path) and where each value is the ﬁle’s MD5 digest value. The purpose of the dictionary is to ensure that we never compute the MD5 of the same ﬁle more than once (since the computation is expensive).\n\nWith the shared data collections in place we loop as many times as there are threads to create (by default, seven times). The Worker subclass is similar to the one we created before, only this time we pass both queues and the MD5 dictionary. As before, we start each worker straight away and each will be blocked until a work item becomes available.\n\nresults_thread = threading.Thread(\n\ntarget=lambda: print_results(results_queue))\n\nresults_thread.daemon = True results_thread.start()\n\nRather than creating a threading.Thread subclass to process the results we have created a function and we pass that to threading.Thread(). The return value is a custom thread that will call the given function once the thread is started. We pass the results queue (which is, of course, empty), so the thread will block immediately.\n\nAt thispoint we have createdall theworker threadsand theresultsthread and they are all blocked waiting for work.\n\nfor size, filename in sorted(data):\n\nUsing the Threading Module\n\nnames = data[size, filename] if len(names) > 1:\n\nwork_queue.put((size, names))\n\nwork_queue.join() results_queue.join()\n\nWe now iterate over the data, and for each (size, ﬁlename) 2-tuple that has a list of two or more potentially duplicateﬁles,we add the size and the ﬁlenames with paths as an item of work to the work queue. Since the queue is a class from the queue module we don’t have to worry about locking.\n\nFinally we join the work queue and resultsqueue to block until they are empty. This ensures that the program runs until all the work is done and all the results have been output, and then terminates cleanly.\n\ndef print_results(results_queue):\n\nwhile True: try:\n\nresults = results_queue.get() if results:\n\nprint(results)\n\nfinally:\n\nresults_queue.task_done()\n\nThis function is passed as an argument to threading.Thread() and is called when the thread it is given to is started. It has an inﬁnite loop because it is to be used as a daemon thread. All it does is get results (a multiline string), and if the string is nonempty, it prints it for as long as results are available.\n\nThe beginning of the Worker class is similar to what we had before:\n\nclass Worker(threading.Thread):\n\nMd5_lock = threading.Lock()\n\ndef __init__(self, work_queue, md5_from_filename, results_queue,\n\nnumber):\n\nsuper().__init__() self.work_queue = work_queue self.md5_from_filename = md5_from_filename self.results_queue = results_queue self.number = number\n\ndef run(self):\n\nwhile True: try:\n\nsize, names = self.work_queue.get() self.process(size, names)\n\n451\n\nContext man- agers 369➤\n\n452\n\nChapter 10. Processes and Threading\n\nfinally:\n\nself.work_queue.task_done()\n\nThe differences are that we have more shared data to keep track of and we call our custom process() function with different arguments. We don’t have to worry about the queues since they ensure that accesses are serialized, but for other data items,in this case the md5_from_filename dictionary,we must handle the serialization ourselves by providing a lock. We have made the lock a class attribute because we want every Worker instance to use the same lock so that if one instance holds the lock, all the other instances are blocked if they try to acquire it.\n\nWe will review the process() function in two parts.\n\ndef process(self, size, filenames):\n\nmd5s = collections.defaultdict(set) for filename in filenames: with self.Md5_lock:\n\nmd5 = self.md5_from_filename.get(filename, None)\n\nif md5 is not None:\n\nmd5s[md5].add(filename)\n\nelse:\n\ntry:\n\nmd5 = hashlib.md5() with open(filename, \"rb\") as fh:\n\nmd5.update(fh.read())\n\nmd5 = md5.digest() md5s[md5].add(filename) with self.Md5_lock:\n\nself.md5_from_filename[filename] = md5\n\nexcept EnvironmentError:\n\ncontinue\n\nWe start out with an empty default dictionary where each key is to be an MD5 digest value and where each value is to be a set of the ﬁlenames of the ﬁles that have the corresponding MD5 value. We then iterate over all the ﬁles,and for each one we retrieve its MD5if we have already calculated it,and calculate it otherwise.\n\nWhether we access the md5_from_filename dictionary to read it or to write to it, we put the access in the context of a lock. Instances of the threading.Lock() class are context managers that acquire the lock on entry and release the lock on exit. The with statementswillblock if another threadhasthe Md5_lock,until the lock is released. For the ﬁrst with statement when we acquire the lock we get the MD5 from the dictionary (or None if it isn’t there).If the MD5 is None we must compute it, in which case we store it in the md5_from_filename dictionary to avoid performing the computation more than once per ﬁle.\n\nGIL 449➤\n\nGIL 449➤\n\nUsing the Threading Module\n\nNotice that at all timeswe try to minimize the amount of work done within the scope of a lock to keep blocking to a minimum—in this case just one dictionary access each time.\n\nStrictly speaking, we do not need to use a lock at all if we are using CPython, since the GIL effectively synchronizes dictionary accesses for us. However,we havechosen toprogramwithoutrelying on theGILimplementationdetail,and so we use an explicit lock.\n\nfor filenames in md5s.values(): if len(filenames) == 1:\n\ncontinue\n\nself.results_queue.put(\"{0}Duplicate files ({1:n} bytes):\" \"\\n\\t{2}\".format(self.number, size, \"\\n\\t\".join(sorted(filenames))))\n\nAt the end we loop over the local md5s default dictionary, and for each set of names that contains more than one name we add a multiline string to the resultsqueue. Thestring containstheworker threadnumber (anempty string by default), the size of the ﬁle in bytes, and all the duplicate ﬁlenames. We don’t need to use a lock to access the results queue since it is a queue.Queue which will automatically handle the locking behind the scenes.\n\nThequeue module’sclassesgreatlysimplifythreadedapplications,andwhenwe need to use explicit locks the threading module offers many options. Here we used the simplest, threading.Lock, but others are available, including thread- ing.RLock (a lock that can be acquired again by the thread that already holds it), threading.Semaphore (a lock that can be used to protect a speciﬁc number of resources), and threading.Condition that provides a wait condition.\n\nUsing multiple threads can often lead to cleaner solutions than using the subprocess module, but unfortunately, threaded Python programs do not nec- essarily achieve the best possible performance compared with using multiple processes. As noted earlier, the problem afﬂicts the standard implementation of Python, since the CPython interpreter can execute Python code on only one processor at a time, even when using multiple threads.\n\nOne packagethat triesto solve thisproblem isthe multiprocessing module,and as we noted earlier, the grepword-m.py program is a multiprocessing version of the grepword-t.py program, with only three lines that are different. A similar transformation could be applied to the findduplicates-t.py program reviewed here, but in practice this is not recommended. Although the multiprocessing module offersan API (Application Programming Interface)that closely match- es the threading module’s API to ease conversion, the two APIs are not the same and have different trade-offs. Also, performing a mechanistic conver- sion from threading to multiprocessing is likely to be successful only on small, simple programs like grepword-t.py; it is too crude an approach to use for the\n\n453\n\n454\n\nChapter 10. Processes and Threading\n\nfindduplicates-t.py program,and in general it is best to design programsfrom thegroundupwith multiprocessing inmind. (Theprogramfindduplicates-m.py is provided with the book’s examples; it does the same job as findduplicates- t.py but works in a very different way and uses the multiprocessing module.)\n\nAnother solution being developed is a threading-friendly version of the CPython interpreter; see www.code.google.com/p/python-threadsafe for the lat- est project status.\n\nSummary\n\nThis chapter showed how to create programs that can execute other programs using the standard library’s subprocess module. Programs that are run using subprocess can be given command-line data, can be fed data to their standard input, and can have their standard output (and standard error) read. Using child processes allows us to take maximum advantage of multicore processors and leaves concurrency issues to be handled by the operating system. The downside is that if we need to share data or synchronize processes we must devise some kind of communication mechanism, for example, shared memory (e.g., using the mmap module), shared ﬁles, or networking, and this can require care to get right.\n\nThe chapter also showed how to createmultithreadedprograms. Unfortunate- ly,such programscannot takefull advantageof multiplecores(if run using the standardCPython interpreter),so for Python,using multipleprocessesisoften a more practical solution where performance is concerned. Nonetheless, we saw that the queue module and Python’s locking mechanisms, such as thread- ing.Lock, make threaded programming as straightforward as possible—and that for simple programs that only need to use queue objects like queue.Queue and queue.PriorityQueue, we may be able to completely avoid using explic- it locks.\n\nAlthough multithreaded programming is undoubtedly fashionable, it can be much more demanding to write, maintain, and debug multithreaded pro- grams than single-threaded ones. However,multithreaded programsallow for straightforwardcommunication,for example,using shared data (providing we use a queue class or use locking), and make it much easier to synchronize (e.g., to gather results) than using child processes. Threading can also be very use- ful in GUI (Graphical User Interface) programs that must carry out long-run- ning tasks while maintaining responsiveness, including the ability to cancel the task being worked on. But if a good communication mechanism between processes is used, such as shared memory, or the process-transparent queue offered by the multiprocessing package, using multiple processes can often be a viable alternative to multiple threads.\n\n|||\n\nSummary\n\nThe following chapter shows another example of a threaded program;a server that handles each client request in a separate thread, and that uses locks to protect shared data.\n\nExercises\n\n1. Copy and modify the grepword-p.py program so that instead of the child processes printing their output, the main program gathers the results, and after all the child processeshave ﬁnished,sortsand printsthe results. This only requires editing the main() function and changing three lines and adding three lines. The exercise does require some thought and care, and you will need to read the subprocess module’s documentation. A solu- tion is given in grepword-p_ans.py.\n\n2. Write a multithreaded program that reads the ﬁles listed on the com- mand line (and the ﬁles in any directories listed on the command line, recursively).For any ﬁle that is an XML ﬁle (i.e.,it beginswith the charac- ters “<?xml”), parse the ﬁle using an XML parser and produce a list of the unique tags used by the ﬁle or an error message if a parsing error occurs. Here is a sample of the program’s output from one particular run: ./data/dvds.xml is an XML file that uses the following tags: dvd dvds ./data/bad.aix is an XML file that has the following error: mismatched tag: line 7889, column 2 ./data/incidents.aix is an XML file that uses the following tags: airport incident incidents narrative\n\nThe easiest way to write the program is to modify a copy of the findduplicates-t.py program, although you can of course write the pro- gram entirely from scratch. Small changes will need to be made to the Worker class’s __init__() and run() methods,and the process() method will need to be rewritten entirely (but needs only around twenty lines). The program’s main() function will need several simpliﬁcationsand so will one line of the print_results() function. The usage message will also need to be modiﬁed to match the one shown here:\n\nUsage: xmlsummary.py [options] [path] outputs a summary of the XML files in path; path defaults to .\n\nOptions: -h, --help show this help message and exit\n\n455\n\n|||\n\n456\n\nChapter 10. Processes and Threading\n\nt COUNT, --threads=COUNT the number of threads to use (1..20) [default 7] -v, --verbose -d, --debug\n\nMakesureyou try running theprogramwith thedebug ﬂag set sothatyou can check that the threads are started up and that each one does its share of the work. A solution isprovided in xmlsummary.py,which isslightly more than 100 lines and uses no explicit locks.\n\n11 ● Creating a TCP Client\n\nCreating a TCP Server\n\nNetworking\n\nNetworking allows computer programs to communicate with each other, even if they are running on different machines. For programs such as web browsers, this is the essence of what they do, whereas for others networking adds additional dimensions to their functionality, for example, remote opera- tion or logging,or theability toretrieveor supply data toother machines. Most networking programs work on either a peer-to-peer basis (the same program runs on different machines), or more commonly, a client/server basis (client programs send requests to a server).\n\nIn this chapter we will create a basic client/server application. Such applica- tions are normally implemented as two separate programs:a server that waits for and responds to requests, and one or more clients that send requests to the server and read back the server’s response. For this to work, the clients must know where to connect to the server, that is, the server’s IP (Internet Proto- col) address and port number.★ Also, both clients and server must send and receive data using an agreed-upon protocol using data formats that they both understand.\n\nPython’s low-level socket module (on which all of Python’s higher-level net- working modules are based) supports both IPv4 and IPv6 addresses. It also supports the most commonly used networking protocols,including UDP (User DatagramProtocol),alightweightbutunreliableconnectionlessprotocolwhere data is sent as discrete packets (datagrams) but with no guarantee that they will arrive, and TCP (Transmission Control Protocol), a reliable connection- and stream-oriented protocol. With TCP, any amount of data can be sent and received—the socket is responsible for breaking the data into chunks that are small enough to send, and for reconstructing the data at the other end.\n\n★Machines can also connect using service discovery, for example, using the bonjour API; suitable modules are available from the Python Package Index, pypi.python.org/pypi.\n\n457\n\n||||\n\nPickles 292➤\n\n458\n\nChapter 11. Networking\n\nUDP is often used to monitor instruments that give continuous readings, and where the odd missed reading is not signiﬁcant, and it is sometimes used for audio or video streaming in cases where the occasional missed frame is ac- ceptable. Both the FTP and the HTTP protocols are built on top of TCP, and client/server applicationsnormally use TCP because they need connection-ori- ented communicationand thereliability that TCP provides. In thischapter we will develop a client/server program, so we use TCP.\n\nAnother decision that must be made is whether to send and receive data as lines of text or as blocks of binary data, and if the latter, in what form. In this chapter we use blocks of binary data where the ﬁrst four bytes are the length of the following data (encoded as an unsigned integer using the struct mod- ule), and where the following data is a binary pickle. The advantage of this approach is that we can use the same sending and receiving code for any ap- plication since we can store almost any arbitrary data in a pickle. The disad- thatbothclientandserver mustunderstandpickles,sothey mustbe vantageis written in Python or must be able to access Python, for example, using Jython in Java or Boost.Python in C++. And of course, the usual security considera- tions apply to the use of pickles.\n\nTheexamplewewill useisa car registrationprogram. Theserver holdsdetails of car registrations(licenseplate,seats,mileage,and owner).The client isused to retrieve car details, to change a car’s mileage or owner, or to create a new car registration. Any number of clients can be used and they won’t block each other,even if twoaccesstheserver at thesametime. Thisisbecausetheserver hands off each client’s request to a separate thread. (We will also see that it is just as easy to use separate processes.)\n\nFor the sake of the example, we will run the server and clients on the same machine; this means that we can use “localhost” as the IP address (although if the server is on another machine the client can be given its IP address on the command line and this will work as long as there is no ﬁrewall in the way).We have also chosen an arbitrary port number of 9653. The port number should be greater than 1023 and is normally between 5001 and 32767, although port numbers up to 65535 are normally valid.\n\nThe server can accept ﬁve kinds of requests: GET_CAR_DETAILS, CHANGE_MILEAGE, CHANGE_OWNER, NEW_REGISTRATION,and SHUTDOWN,witha correspondingresponse for each. The response is the requested data or conﬁrmation of the requested action, or an indication of an error.\n\nCreating a TCP Client\n\n|||\n\nThe client program is car_registration.py. Here is an example of interaction (with the server already running, and with the menu edited slightly to ﬁt on the page):",
      "page_number": 435
    },
    {
      "number": 46,
      "title": "Segment 46 (pages 446-457)",
      "start_page": 446,
      "end_page": 457,
      "detection_method": "topic_boundary",
      "content": "Branch- ing using dictio- naries 340➤\n\nCreating a TCP Client\n\n(C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: License: 024 hyr License: 024 HYR Seats: 2 Mileage: 97543 Owner: Jack Lemon (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: m License [024 HYR]: Mileage [97543]: 103491 Mileage successfully changed\n\nThe data entered by the user is shown in bold—where there is no visible input it means that the user pressed Enter to accept the default. Here the user has asked to see the details of a particular car and then updated its mileage.\n\nAs many clients as we like can be running, and when a user quits their partic- ular client the server is unaffected. But if the server is stopped, the client it wasstoppedin will quit and all theother clientswill get a “Connectionrefused” errorandwillterminatewhenthey nextattempttoaccesstheserver. Inamore sophisticated application,the ability to stop the server would be available only to certain users, perhaps on only particular machines, but we have included it in the client to show how it is done.\n\nWewillnowreviewthecode,starting withthe main() functionandthehandling of the user interface, and ﬁnishing with the networking code itself.\n\ndef main():\n\nif len(sys.argv) > 1:\n\nAddress[0] = sys.argv[1]\n\ncall = dict(c=get_car_details, m=change_mileage, o=change_owner,\n\nn=new_registration, s=stop_server, q=quit)\n\nmenu = (\"(C)ar Edit (M)ileage Edit (O)wner (N)ew car \"\n\n\"(S)top server (Q)uit\")\n\nvalid = frozenset(\"cmonsq\") previous_license = None while True:\n\naction = Console.get_menu_choice(menu, valid, \"c\", True) previous_license = call[action](previous_license)\n\nThe Address list is a global that holds the IP address and port number as a two-item list, [\"localhost\", 9653], with the IP address overridden if speciﬁed on the command line. The call dictionary maps menu options to functions.\n\nThe Console module is one supplied with this book and contains some use- ful functions for getting values from the user at the console, such as Con- sole.get_string() and Console.get_integer(); these are similar to functions\n\n459\n\n460\n\nChapter 11. Networking\n\ndevelopedinearlier chaptersandhavebeenput ina moduletomakethemeasy to reuse in different programs.\n\nAs a convenience for users, we keep track of the last license they entered so that it can be used as the default, since most commands start by asking for the license of the relevant car. Once the user makes a choice we call the corre- sponding function passing in the previouslicense,and expecting each function to return the license it used. Since the loop is inﬁnite the program must be ter- minated by one of the functions; we will see this further on.\n\ndef get_car_details(previous_license):\n\nlicense, car = retrieve_car_details(previous_license) if car is not None:\n\nprint(\"License: {0}\\nSeats:\n\n{seats}\\nMileage: {mileage}\\n\"\n\n\"Owner:\n\n{owner}\".format(license, **car._asdict()))\n\nreturn license\n\nThis function is used to get information about a particular car. Since most of the functions need to request a license from the user and often need some car-related data to work on, we have factored out this functionality into the retrieve_car_details() function—it returns a 2-tuple of the license entered by the user and a named tuple, CarTuple, that holds the car’s seats, mileage, and owner (or the previous license and None if they entered an unrecognized license). Here we just print the information retrieved and return the license to be used as the default for the next function that is called and that needs the license.\n\ndef retrieve_car_details(previous_license):\n\nlicense = Console.get_string(\"License\", \"license\",\n\nprevious_license)\n\nif not license:\n\nreturn previous_license, None\n\nlicense = license.upper() ok, *data = handle_request(\"GET_CAR_DETAILS\", license) if not ok:\n\nprint(data[0]) return previous_license, None\n\nreturn license, CarTuple(*data)\n\nThis is the ﬁrst function to make use of networking. It calls the handle_re- quest() function that we review further on. The handle_request() function takes whatever data it is given as arguments and sends it to the server, and then returns whatever the server replies. The handle_request() function does not know or care what data it sends or returns;it purely providesthe network- ing service.\n\nCreating a TCP Client\n\nIn the case of car registrations we have a protocol where we always send the name of the action we want the server to perform as the ﬁrst argument, fol- lowed by any relevant parameters—in this case, just the license. The proto- col for the reply is that the server always return a tuple whose ﬁrst item is a Boolean success/failure ﬂag. If the ﬂag is False, we have a 2-tuple and the sec- ond item is an error message. If the ﬂag is True, the tuple is either a 2-tuple with the second item being a conﬁrmation message,or an n-tuple with the sec- ond and subsequent items holding the data that was requested.\n\nSo here, if the license is unrecognized, ok is False and we print the error message in data[0] and return the previous license unchanged. Otherwise,we return the license (which will now become the previouslicense),and a CarTuple made from the data list, (seats, mileage, owner).\n\ndef change_mileage(previous_license):\n\nlicense, car = retrieve_car_details(previous_license) if car is None:\n\nreturn previous_license\n\nmileage = Console.get_integer(\"Mileage\", \"mileage\",\n\ncar.mileage, 0)\n\nif mileage == 0:\n\nreturn license\n\nok, *data = handle_request(\"CHANGE_MILEAGE\", license, mileage) if not ok:\n\nprint(data[0])\n\nelse:\n\nprint(\"Mileage successfully changed\")\n\nreturn license\n\nThis function follows a similar pattern to get_car_details(), except that once we have the details we update one aspect of them. There are in fact two networking calls,since retrieve_car_details() calls handle_request() to get the car’s details—we need to do this both to conﬁrm that the license is valid and to getthecurrentmileagetouseasthedefault. Herethereply isalwaysa 2-tuple, with either an error message or None as the second item.\n\nWe won’t review the change_owner() function since it isstructurally the same as change_mileage(), nor will we review new_registration() since it differs only in not retrieving car details at the start (since it is a new car being entered), and asking the user for all the details rather than just changing one detail,none of which is new to us or relevant to network programming.\n\ndef quit(*ignore): sys.exit()\n\n461\n\n462\n\nChapter 11. Networking\n\ndef stop_server(*ignore):\n\nhandle_request(\"SHUTDOWN\", wait_for_reply=False) sys.exit()\n\nIf the user chooses to quit the program we do a clean termination by calling sys.exit(). Every menu function is called with the previous license, but we don’t care about the argument in this particular case. We cannot write def quit(): because that would create a function that expectsno argumentsand so when the function was called with the previous license a TypeError exception would be raised saying that no arguments were expected but that one was giv- en. So instead we specify a parameter of *ignore which can take any number of positional arguments. The name ignore has no signiﬁcance to Python and is used purely to indicate to maintainers that the arguments are ignored.\n\nIf the user chooses to stop the server we use handle_request() to inform the server, and specify that we don’t want a reply. Once the data is sent, han- dle_request() returns without waiting for a reply, and we do a clean termina- tion using sys.exit().\n\ndef handle_request(*items, wait_for_reply=True):\n\nSizeStruct = struct.Struct(\"!I\") data = pickle.dumps(items, 3)\n\ntry:\n\nwith SocketManager(tuple(Address)) as sock:\n\nsock.sendall(SizeStruct.pack(len(data))) sock.sendall(data) if not wait_for_reply:\n\nreturn\n\nsize_data = sock.recv(SizeStruct.size) size = SizeStruct.unpack(size_data)[0] result = bytearray() while True:\n\ndata = sock.recv(4000) if not data: break\n\nresult.extend(data) if len(result) >= size:\n\nbreak\n\nreturn pickle.loads(result)\n\nexcept socket.error as err:\n\nprint(\"{0}: is the server running?\".format(err)) sys.exit(1)\n\nThis function provides all the client program’s network handling. It begins by creating a struct.Struct which holds one unsigned integer in network byte\n\nCreating a TCP Client\n\norder, and then it creates a pickle of whatever items it is passed. The function doesnot knowor carewhat theitemsare. Noticethat wehaveexplicitly set the pickle protocol version to 3—this is to ensure that both clients and server use the same pickle version,even if a client or server is upgraded to run a different version of Python.\n\nIf we wanted our protocol to be more future proof, we could version it (just as we do with binary disk formats).Thiscan be doneeither at thenetwork level or at the data level. At the network level we can version by passing two unsigned integers instead of one, that is, length and a protocol version number. At the data level we could follow the convention that the pickle is always a list (or always a dictionary) whose ﬁrst item (or “version” item) has a version number. (You will get the chance to version the protocol in the exercises.)\n\nThe SocketManager is a custom context manager that gives us a socket to use—we will review it shortly. The socket.socket.sendall() method sends all the data it is given—making multiple socket.socket.send() calls behind the scenes if necessary. We always send two items of data: the length of the pick- le and the pickle itself. If the wait_for_reply argument is False we don’t wait for a reply and return immediately—the context manager will ensure that the socket is closed before the function actually returns.\n\nAfter sending the data (and when we want a reply), we call the sock- et.socket.recv() method to get the reply. This method blocks until it receives data. For the ﬁrst call we request four bytes—thesize of the integer that holds the size of the reply pickle to follow. We use the struct.Struct to unpack the bytes into the size integer. We then create an empty bytearray and try to re- trieve the incoming pickle in blocks of up to 4000 bytes. Once we have read in size bytes (or if the data has run out before then), we break out of the loop and unpicklethedata using the pickle.loads() function(which takesa bytes or bytearray object),and return it. In this case we know that the data will always be a tuple since that is the protocol we have established with the car registra- tion server,but the handle_request() function doesnot know or care about what the data is.\n\nIf something goes wrong with the network connection,for example, the server isn’t running or the connection fails for some reason, a socket.error exception is raised. In such cases the exception is caught and the client program issues an error message and terminates.\n\nclass SocketManager:\n\ndef __init__(self, address):\n\nself.address = address\n\ndef __enter__(self):\n\nself.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) self.sock.connect(self.address)\n\n463\n\n464\n\nChapter 11. Networking\n\nreturn self.sock\n\ndef __exit__(self, *ignore):\n\nself.sock.close()\n\nThe address object is a 2-tuple (IP address, port number) and is set when the context manager is created. Once the context manager is used in a with state- ment it creates a socket and tries to make a connection—blocking until a con- nection is established or until a socket exception is raised. The ﬁrst argument to the socket.socket() initializer is the addressfamily;here we have used sock- et.AF_INET (IPv4),but othersare available,for example,socket.AF_INET6 (IPv6), socket.AF_UNIX,and socket.AF_NETLINK.The second argument isnormally either socket.SOCK_STREAM (TCP) as we have used here, or socket.SOCK_DGRAM (UDP).\n\nWhen the ﬂow of control leaves the with statement’s scope the context ob- ject’s __exit__() method is called. We don’t care whether an exception was raised or not (so we ignore the exception arguments), and just close the sock- et. Since the method returns None (in a Boolean context, False), any exceptions are propagated—this works well since we put a suitable except block in han- dle_request() to process any socket exceptions that occur.\n\nCreating a TCP Server\n\n|||\n\nSince the code for creating servers often follows the same design, rather than having to use the low-level socket module, we can use the high-level socket- server module which takes care of all the housekeeping for us. All we have to do is provide a request handler class with a handle() method which is used to read requests and write replies. The socketserver module handles the commu- nications for us, servicing each connection request, either serially or by pass- ing each request to its own separate thread or process—and it does all of this transparently so that we are insulated from the low-level details. For this application the server is car_registration_server.py.★ This program contains a very simple Car class that holds seats, mileage, and owner informa- tion as properties (the ﬁrst one read-only). The class does not hold car licenses because the cars are stored in a dictionary and the licenses are used for the dictionary’s keys.\n\nWe will begin by looking at the main() function, then brieﬂy review how the server’s data is loaded, then the creation of the custom server class, and ﬁnal- ly the implementation of the request handler class that handles the client requests.\n\n★The ﬁrst time the server is run on Windows a ﬁrewall dialog might pop up saying that Python is blocked—click Unblock to allow the server to operate.\n\nCreating a TCP Server\n\ndef main():\n\nfilename = os.path.join(os.path.dirname(__file__),\n\n\"car_registrations.dat\")\n\ncars = load(filename) print(\"Loaded {0} car registrations\".format(len(cars))) RequestHandler.Cars = cars server = None try:\n\nserver = CarRegistrationServer((\"\", 9653), RequestHandler) server.serve_forever()\n\nexcept Exception as err:\n\nprint(\"ERROR\", err)\n\nfinally:\n\nif server is not None:\n\nserver.shutdown() save(filename, cars) print(\"Saved {0} car registrations\".format(len(cars)))\n\nWe have stored the car registration data in the same directory as the program. The cars object is set to a dictionary whose keys are license strings and whose values are Car objects. Normally servers do not print anything since they are typically started and stopped automatically and run in the background, so usually they report on their status by writing logs (e.g., using the logging module).Here we have chosen to print a message at start-up and shutdown to make testing and experimenting easier.\n\nOur request handler class needs to be able to access the cars dictionary, but we cannot pass the dictionary to an instance because the server creates the instances for us—one to handle each request. So we set the dictionary to the RequestHandler.Cars class variable where it is accessible to all instances.\n\nWe create an instance of the server passing it the address and port it should operate on and the RequestHandler class object—not an instance. An empty string as the address indicates any accessible IPv4 address (including the current machine, localhost). Then we tell the server to serve requests forever. When the server shutsdown (we will see how thishappensfurther on),we save the cars dictionary since the data may have been changed by clients.\n\ndef load(filename):\n\ntry:\n\nwith contextlib.closing(gzip.open(filename, \"rb\")) as fh:\n\nreturn pickle.load(fh)\n\nexcept (EnvironmentError, pickle.UnpicklingError) as err: print(\"server cannot load data: {0}\".format(err)) sys.exit(1)\n\n465\n\nMultiple inheri- tance 388➤\n\n466\n\nChapter 11. Networking\n\nThe code for loading is easy because we have used a context manager from the standard library’s contextlib module to ensure that the ﬁle is closed irrespec- tive of whether an exception occurs. Another way of achieving the same effect is to use a custom context manager. For example:\n\nclass GzipManager:\n\ndef __init__(self, filename, mode):\n\nself.filename = filename self.mode = mode\n\ndef __enter__(self):\n\nself.fh = gzip.open(self.filename, self.mode) return self.fh\n\ndef __exit__(self, *ignore):\n\nself.fh.close()\n\nUsing the custom GzipManager, the with statement becomes:\n\nwith GzipManager(filename, \"rb\") as fh:\n\nThis context manager will work with any Python 3.x version. But if we only care about Python 3.1 or later, we can simply write, with gzip.open(...) as fh, since from Python 3.1 the gzip.open() function supports the context manager protocol.\n\nThe save() function (not shown)isstructurally the same asthe load() function, only we open the ﬁle in write binary mode, use pickle.dump() to save the data, and don’t return anything.\n\nclass CarRegistrationServer(socketserver.ThreadingMixIn, socketserver.TCPServer): pass\n\nThis is the complete custom server class. If we wanted to create a server that used processes rather than threads, the only change would be to inherit the socketserver.ForkingMixIn class instead of the socketserver.ThreadingMixIn class. The term mixin is often used to describe classes that are speciﬁcally designed to be multiply-inherited. The socketserver module’s classes can be used to create a variety of custom servers including UDP servers and Unix TCP and UDP servers, by inheriting the appropriate pair of base classes.\n\nNote that the socketserver mixin class we used must always be inherited ﬁrst. This is to ensure that the mixin class’s methods are used in preference to the second class’s methods for those methods that are provided by both, since Python looks for methods in the base classes in the order in which the base classes are speciﬁed, and uses the ﬁrst suitable method it ﬁnds.\n\n3.1\n\nGIL 449➤\n\nCreating a TCP Server\n\nThe socket server creates a request handler (using the class it was given) to handle each request. Our custom RequestHandler class provides a method for each kind of request it can handle, plus the handle() method that it must have since that is the only method used by the socket server. But before look- ing at the methods we will look at the class declaration and the class’s class variables.\n\nclass RequestHandler(socketserver.StreamRequestHandler):\n\nCarsLock = threading.Lock() CallLock = threading.Lock() Call = dict(\n\nGET_CAR_DETAILS=(\n\nlambda self, *args: self.get_car_details(*args)),\n\nCHANGE_MILEAGE=(\n\nlambda self, *args: self.change_mileage(*args)),\n\nCHANGE_OWNER=(\n\nlambda self, *args: self.change_owner(*args)),\n\nNEW_REGISTRATION=(\n\nlambda self, *args: self.new_registration(*args)),\n\nSHUTDOWN=lambda self, *args: self.shutdown(*args))\n\nWe have created a socketserver.StreamRequestHandler subclass since we are using a streaming (TCP) server. A corresponding socketserver.Datagram- RequestHandler is available for UDP servers, or we could inherit the socket- server.BaseRequestHandler class for lower-level access.\n\nThe RequestHandler.Cars dictionary is a class variable that was added in the main() function;it holds all the registration data. Adding additional attributes to objects (such as classes and instances) can be done outside the class (in this case in the main() function) without formality (as long as the object has a __dict__), and can be very convenient. Since we know that the class depends on this variable some programmers would have added Cars = None as a class variable to document the variable’s existence.\n\nAlmost every request-handling method needs access to the Cars data, but we mustensurethat thedata isnever accessedby twomethods(fromtwodifferent threads) at the same time; if it is, the dictionary may become corrupted, or the program might crash. To avoid this we have a lock class variable that we will use to ensure that only one thread at a time accesses the Cars dictionary.★ (Threading, including the use of locks, is covered in Chapter 10.)\n\nThe Call dictionary is another class variable. Each key is the name of an action that the server can perform and each value is a function for performing the action. We cannot use the methods directly as we did with the functions\n\n★The GIL (Global Interpreter Lock) ensures that accesses to the Cars dictionary are synchronized, but as noted earlier, we do not take advantage of this since it is a CPython implementation detail.\n\n467\n\nGIL 449➤\n\n468\n\nChapter 11. Networking\n\nin the client’s menu dictionary because there is no self available at the class level. The solution we have used is to provide wrapper functions that will get self when they are called, and which in turn call the appropriate method with the given self and any other arguments. An alternative solution would be to create the Call dictionary after all the methods. That would allow us to create entries such as GET_CAR_DETAILS=get_car_details, with Python able to ﬁnd the get_car_details() method because the dictionary is created after the method is deﬁned. We have used the ﬁrst approach since it is more explicit and does not impose an order dependency on where the dictionary is created.\n\nAlthough the Call dictionary is only ever read after the classis created,since it is mutable we have played it extra-safe and created a lock for it to ensure that no two threads access it at the same time. (Again, because of the GIL, the lock isn’t really needed for CPython.)\n\ndef handle(self):\n\nSizeStruct = struct.Struct(\"!I\") size_data = self.rfile.read(SizeStruct.size) size = SizeStruct.unpack(size_data)[0] data = pickle.loads(self.rfile.read(size))\n\ntry:\n\nwith self.CallLock:\n\nfunction = self.Call[data[0]] reply = function(self, *data[1:])\n\nexcept Finish: return\n\ndata = pickle.dumps(reply, 3) self.wfile.write(SizeStruct.pack(len(data))) self.wfile.write(data)\n\nWhenever a client makes a request a new thread is created with a new instance of the RequestHandler class,and then the instance’shandle() method is called. Insidethismethod thedata coming fromtheclient can be read fromthe self.rfile ﬁle object, and data can be sent back to the client by writing to the self.wfile object—both of these objects are provided by socketserver, opened and ready for use.\n\nThe struct.Struct isfor the integer bytecount that we need for the“length plus pickle” format we are using to exchange data between clients and the server.\n\nWe begin by reading four bytes and unpacking this as the size integer so that we know the size of the pickle we have been sent. Then we read size bytesand unpickle them into the data variable. The read will block until the data isread. In this case we know that data will always be a tuple, with the ﬁrst item being the requested action and the other itemsbeing the parameters,because that is the protocol we have established with the car registration clients.\n\nCreating a TCP Server\n\nInside the try block we get the lambda function that is appropriate to the re- quested action. We use a lock to protect access to the Call dictionary,although arguably we are being overly cautious. As always, we do as little as possible within the scope of the lock—in this case we just do a dictionary lookup to get a reference to a function. Once we have the function we call it, passing self as the ﬁrst argument and the rest of the data tuple as the other arguments. Here we are doing a function call, so no self is passed by Python. This does not matter since we pass self in ourselves, and inside the lambda the passed-in self is used to call the method in the normal way. The outcome is that the call, self.method(*data[1:]), is made, where method is the method corresponding to the action given in data[0].\n\nIf the action is to shut down, a custom Finish exception is raised in the shutdown() method;in which casewe know that theclient cannot expect a reply, so we just return. But for any other action we pickle the result of calling the action’s corresponding method (using pickle protocol version 3), and write the size of the pickle and then the pickled data itself.\n\ndef get_car_details(self, license):\n\nwith self.CarsLock:\n\ncar = copy.copy(self.Cars.get(license, None))\n\nif car is not None:\n\nreturn (True, car.seats, car.mileage, car.owner)\n\nreturn (False, \"This license is not registered\")\n\nThis method begins by trying to acquire the car data lock—and blocks until it gets the lock. It then uses the dict.get() method with a second argument of None to get the car with thegiven license—or to get None.The car isimmediately copied and the with statement is ﬁnished. This ensures that the lock is in force for the shortest possible time. Although reading does not change the data being read,because we are dealing with a mutable collection it is possible that another method in another thread wants to change the dictionary at the same timeaswewanttoreadit—using a lock preventsthisfromhappening. Outside the scope of the lock we now have a copy of the car object (or None) which we can deal with at our leisure without blocking any other threads.\n\nLike all the car registration action-handling methods,we return a tuple whose ﬁrst item isa Boolean success/failureﬂag and whose other itemsvary. None of these methods has to worry or even know how its data is returned to the client beyond the “tuple with a Boolean ﬁrst item” since all the network interaction is encapsulated in the handle() method.\n\ndef change_mileage(self, license, mileage):\n\nif mileage < 0:\n\nreturn (False, \"Cannot set a negative mileage\")\n\nwith self.CarsLock:\n\ncar = self.Cars.get(license, None)\n\n469\n\n470\n\nChapter 11. Networking\n\nif car is not None:\n\nif car.mileage < mileage: car.mileage = mileage return (True, None)\n\nreturn (False, \"Cannot wind the odometer back\")\n\nreturn (False, \"This license is not registered\")\n\nIn this method we can do one check without acquiring a lock at all. But if the mileage is non-negative we must acquire a lock and get the relevant car,and if we have a car (i.e., if the license is valid), we must stay within the scope of the lock to change the mileage as requested—or to return an error tuple. If no car has the given license (car is None),we drop out of the with statement and return an error tuple.\n\nIt would seem that if we did the validation in the client we could avoid some network trafﬁc entirely,for example,the client could give an error message (or simply prevent)negative mileages. Even though the client ought to do this,we must still have the check in the server since we cannot assume that the client is bug-free. And although the client gets the car’s mileage to use as the default mileage we cannot assume that the mileage entered by the user (even if it is greater than the current mileage) is valid, because some other client could have increased the mileage in the meantime. So we can only do the deﬁnitive validation at the server, and only within the scope of a lock.\n\nThe change_owner() method is very similar, so we won’t reproduce it here.\n\ndef new_registration(self, license, seats, mileage, owner):\n\nif not license:\n\nreturn (False, \"Cannot set an empty license\")\n\nif seats not in {2, 4, 5, 6, 7, 8, 9}:\n\nreturn (False, \"Cannot register car with invalid seats\")\n\nif mileage < 0:\n\nreturn (False, \"Cannot set a negative mileage\")\n\nif not owner:\n\nreturn (False, \"Cannot set an empty owner\")\n\nwith self.CarsLock:\n\nif license not in self.Cars:\n\nself.Cars[license] = Car(seats, mileage, owner) return (True, None)\n\nreturn (False, \"Cannot register duplicate license\")\n\nAgain we are able to do a lot of error checking before accessing the registration data, but if all the data is valid we acquire a lock. If the license is not in the RequestHandler.Cars dictionary (and it shouldn’t be since a new registration should have an unused license), we create a new Car object and store it in the dictionary. This must all be done within the scope of the same lock because we must not allow any other client to add a car with this license in the time be-",
      "page_number": 446
    },
    {
      "number": 47,
      "title": "Segment 47 (pages 458-465)",
      "start_page": 458,
      "end_page": 465,
      "detection_method": "topic_boundary",
      "content": "Creating a TCP Server\n\ntweenthecheck forthelicense’sexistenceinthe RequestHandler.Cars dictionary and adding the new car to the dictionary.\n\ndef shutdown(self, *ignore):\n\nself.server.shutdown() raise Finish()\n\nIf the action is to shut down we call the server’s shutdown() method—this will stop it from accepting any further requests, although it will continue running while it is still servicing any existing requests. We then raise a custom excep- tion to notify the handler() that we are ﬁnished—this causes the handler() to return without sending any reply to the client.\n\nSummary\n\nThis chapter showed that creating network clients and servers can be quite straightforward in Python thanks to the standard library’s networking mod- ules, and the struct and pickle modules.\n\nIn the ﬁrst section we developed a client program and gave it a single function, handle_request(), to send and receive arbitrary picklable data to and from a server using a generic data format of “length pluspickle”.In thesecondsection we saw how to create a server subclass using the classes from the socketserver module and how to implement a request handler class to service the server’s client requests. Here the heart of the network interaction was conﬁned to a single method, handle(), that can receive and send arbitrary picklable data from and to clients.\n\nThe socket and socketserver modules and many other modules in the standard library,such as asyncore, asynchat, and ssl, provide far more functionality than we have used here. But if the networking facilities provided by the standard library are not sufﬁcient, or are not high-level enough, it is worth looking at the third-party Twisted networking framework (www.twistedmatrix.com) as a possible alternative.\n\nExercises\n\nThe exercisesinvolve modifying the client and server programscovered in this chapter. The modiﬁcations don’t involve a lot of typing, but will need a little bit of care to get right.\n\n1. Copy car_registration_server.py and car_registration.py and modify them sothat they exchangedata using a protocolversionedat thenetwork level. Thiscouldbedone,forexample,by passing twointegersinthestruct (length, protocol version) instead of one.\n\n471\n\n|||\n\n|||\n\n472\n\nChapter 11. Networking\n\nThis involves adding or modifying about ten lines in the client program’s handle_request() function, and adding or modifying about sixteen lines in the server program’s handle() method—including code to handle the case where the protocol version read does not match the one expected.\n\nSolutions to this and to the following exercises are provided in car_reg- istration_ans.py and car_registration_server_ans.py.\n\n2. Copy the car_registration_server.py program (or use the one developed in Exercise 1), and modify it so that it offers a new action, GET_LICENSES_ STARTING_WITH. The action should accept a single parameter, a string. The method implementing the action should always return a 2-tuple of (True, list of licenses); there is no error (False) case, since no matches is not an error and simply results in True and an empty list being returned. Retrieve the licenses (the RequestHandler.Cars dictionary’s keys) within the scope of a lock, but do all the other work outside the lock to minimize blocking. One efﬁcient way to ﬁnd matching licenses is to sort the keys and then use the bisect module to ﬁnd the ﬁrst matching license and then iterate from there. Another possible approach is to iterate over the licenses, picking out those that start with the given string, perhaps using a list comprehension.\n\nApart from the additional import, the Call dictionary will need an ex- tra couple of lines for the action. The method to implement the ac- tion can be done in fewer than ten lines. This is not difﬁcult, although care is required. A solution that uses the bisect module is provided in car_registration_server _ans.py.\n\n3. Copy the car_registration.py program (or use the one developed in exer- cise 1), and modify it to take advantage of the new server (car_registra- tion_server_ans.py). This means changing the retrieve_car_details() function so that if the user enters an invalid license they get prompted to enter the start of a license and then get a list to choose from. Here is a sampleof interactionusing thenew function (with theserver already run- ning, with the menu edited slightly to ﬁt on the page, and with what the user types shown in bold): (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: License: da 4020 License: DA 4020 Seats: 2 Mileage: 97181 Owner: Jonathan Lynn (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: License [DA 4020]: z This license is not registered Start of license: z\n\nExercises\n\nNo licence starts with Z Start of license: a (1) A04 4HE (2) A37 4791 (3) ABK3035 Enter choice (0 to cancel): 3 License: ABK3035 Seats: 5 Mileage: 17719 Owner: Anthony Jay\n\nThe changeinvolvesdeleting oneline and adding about twenty morelines. It is slightly tricky because the user must be allowed to get out or to go on at each stage. Make sure that you test the new functionality for all cases (no license starts with the given string, one licence starts with it, and two or more start with it). A solution is provided in car_registration_ans.py.\n\n473\n\n12 ● DBM Databases\n\nSQL Databases\n\nDatabase Programming\n\nFor most software developers the term database is usually taken to mean an RDBMS(RelationalDatabaseManagementSystem).Thesesystemsusetables (spreadsheet-like grids) with rows equating to records and columns equating to ﬁelds. The tablesand the data they hold are created and manipulated using statements written in SQL (Structured Query Language).Python provides an API (Application Programming Interface) for working with SQL databases and it is normally distributed with the SQLite 3 database as standard.\n\nAnother kind of database is a DBM (Database Manager) that stores any number of key–value items. Python’s standard library comes with interfaces to several DBMs, including some that are Unix-speciﬁc. DBMs work just like Python dictionaries except that they are normally held on disk rather than in memory and their keysand values are always bytes objectsand may be subject to length constraints. The shelve module covered in this chapter’s ﬁrst section providesa convenient DBM interface that allows us to use string keys and any (picklable) objects as values.\n\nIf the available DBMs and the SQLite database are insufﬁcient, the Python Package Index, pypi.python.org/pypi, has a large number of database-related packages, including the bsddb DBM (“Berkeley DB”), and interfaces to popu- lar client/server databases such as DB2,Informix,Ingres,MySQL,ODBC,and PostgreSQL.\n\nUsing SQL databases requires knowledge of the SQL language and the ma- nipulation of strings of SQL statements. This is ﬁne for those experienced with SQL,but is not very Pythonic. There is another way to interact with SQL databases—use an ORM (Object Relational Mapper).Two of the most popular ORMsfor Pythonareavailableasthird-party libraries—they areSQLAlchemy (www.sqlalchemy.org) and SQLObject (www.sqlobject.org). One particularly nice feature of using an ORM is that it allows us to use Python syntax—creating objects and calling methods—rather than using raw SQL.\n\n475\n\n||||\n\nbytes 293➤\n\n476\n\nChapter 12. Database Programming\n\nIn this chapter we will implement two versions of a program that maintains a list of DVDs, and keeps track of each DVD’s title, year of release, length in minutes, and director. The ﬁrst version uses a DBM (via the shelve module) to store its data, and the second version uses the SQLite database. Both programs can also load and save a simple XML format, making it possible, for example, to export DVD data from one program and import it into the other. The SQL-based version offers slightly more functionality than the DBM one, and has a slightly cleaner data design.\n\nDBM Databases\n\nThe shelve moduleprovidesa wrapper arounda DBMthatallowsustointeract with the DBM as though it were a dictionary,providing that we use only string keys and picklable values. Behind the scenes the shelve module converts the keys and values to and from bytes objects.\n\nThe shelve module uses the best underlying DBM available, so it is possible thata DBMﬁlesavedon onemachinewon’tbereadableon another,if theother machine doesn’t have the same DBM. One solution is to provide XML import and export for ﬁles that must be transportable between machines—something we’ve done for this section’s DVD program, dvds-dbm.py.\n\nFor the keys we use the DVDs’ titles and for the values we use tuples holding the director, year, and duration. Thanks to the shelve module we don’t have to do any data conversion and can just treat the DBM object as a dictionary.\n\nSince the structure of the program is similar to interactive menu-driven programsthat we have seen before,we will focus just on those aspects that are speciﬁc to DBM programming. Here is an extract from the program’s main() function, with the menu handling omitted:\n\ndb = None try:\n\ndb = shelve.open(filename, protocol=pickle.HIGHEST_PROTOCOL)\n\n... finally:\n\nif db is not None: db.close()\n\nHere we have opened (or created if it does not exist) the speciﬁed DBM ﬁle for both reading and writing. Each item’s value is saved as a pickle using the speciﬁed pickle protocol; existing items can be read even if they were saved using a lower protocolsincePythoncan ﬁgureout thecorrectprotocoltousefor reading pickles. At the end the DBM is closed—this has the effect of clearing the DBM’s internal cache and ensuring that the disk ﬁle reﬂects any changes that have been made, as well as closing the ﬁle.\n\n|||\n\nDBM Databases\n\nThe program offers options to add, edit, list, remove, import, and export DVD data. We will skip importing and exporting the data from and to XML format since it is very similar to what we have done in Chapter 7. And apart from adding, we will omit most of the user interface code, again because we have seen it before in other contexts.\n\ndef add_dvd(db):\n\ntitle = Console.get_string(\"Title\", \"title\") if not title: return\n\ndirector = Console.get_string(\"Director\", \"director\") if not director:\n\nreturn\n\nyear = Console.get_integer(\"Year\", \"year\", minimum=1896,\n\nmaximum=datetime.date.today().year)\n\nduration = Console.get_integer(\"Duration (minutes)\", \"minutes\",\n\nminimum=0, maximum=60*48)\n\ndb[title] = (director, year, duration) db.sync()\n\nThisfunction,like all the functionscalled by the program’smenu,is passed the DBM object (db) as its sole parameter. Most of the function is concerned with getting the DVD’s details, and in the penultimate line we store the key–value item in the DBM ﬁle,with the DVD’stitle as the key and the director,year,and duration (pickled together by shelve) as the value.\n\nIn keeping with Python’s usual consistency, DBMs provide the same API as dictionaries,sowedon’thavetolearnany new syntax beyondthe shelve.open() function that we saw earlier and the shelve.Shelf.sync() method that is used to clear the shelve’sinternal cache and synchronize the disk ﬁle’sdata with the changes that have been applied—in this case just adding a new item.\n\ndef edit_dvd(db):\n\nold_title = find_dvd(db, \"edit\") if old_title is None:\n\nreturn\n\ntitle = Console.get_string(\"Title\", \"title\", old_title) if not title: return\n\ndirector, year, duration = db[old_title]\n\n...\n\ndb[title] = (director, year, duration) if title != old_title:\n\ndel db[old_title]\n\ndb.sync()\n\n477\n\n478\n\nChapter 12. Database Programming\n\nTo be able to edit a DVD, the user must ﬁrst choose the DVD to work on. This is just a matter of getting the title since titles are used as keys with the values holding the other data. Since the necessary functionality is needed elsewhere (e.g.,when removing a DVD),we have factoredit out into a separate find_dvd() function that we will look at next. If the DVD is found we get the user’s changes,using the existing values as defaults to speed up the interaction. (We have omitted most of the user interface code for this function since it is almost the same as that used when adding a DVD.) At the end we store the data just as we did when adding. If the title is unchanged this will have the effect of overwriting the associated value, and if the title is different this has the effect of creating a new key–value item, in which case we delete the original item.\n\ndef find_dvd(db, message):\n\nmessage = \"(Start of) title to \" + message while True:\n\nmatches = [] start = Console.get_string(message, \"title\") if not start:\n\nreturn None\n\nfor title in db:\n\nif title.lower().startswith(start.lower()):\n\nmatches.append(title)\n\nif len(matches) == 0:\n\nprint(\"There are no dvds starting with\", start) continue\n\nelif len(matches) == 1:\n\nreturn matches[0]\n\nelif len(matches) > DISPLAY_LIMIT:\n\nprint(\"Too many dvds start with {0}; try entering \"\n\n\"more of the title\".format(start))\n\ncontinue\n\nelse:\n\nmatches = sorted(matches, key=str.lower) for i, match in enumerate(matches):\n\nprint(\"{0}: {1}\".format(i + 1, match))\n\nwhich = Console.get_integer(\"Number (or 0 to cancel)\",\n\n\"number\", minimum=1, maximum=len(matches))\n\nreturn matches[which - 1] if which != 0 else None\n\nTo make ﬁnding a DVD as quick and easy as possible we require the user to type in only one or the ﬁrst few characters of its title. Once we have the start of the title we iterate over the DBM and create a list of matches. If there is one match we return it, and if there are several matches (but fewer than DISPLAY_LIMIT, an integer set elsewhere in the program) we display them all in case-insensitive order with a number beside each one so that the user\n\nDBM Databases\n\ncan choose the title just by entering its number. (The Console.get_integer() function accepts 0 even if the minimum is greater than zero so that 0 can be used as a cancelation value. This behavior can be switched off by passing al- low_zero=False.We can’t use Enter, that is, nothing, to mean cancel, since enter- ing nothing means accepting the default.)\n\ndef list_dvds(db): start = \"\" if len(db) > DISPLAY_LIMIT:\n\nstart = Console.get_string(\"List those starting with \"\n\n\"[Enter=all]\", \"start\")\n\nprint() for title in sorted(db, key=str.lower):\n\nif not start or title.lower().startswith(start.lower()):\n\ndirector, year, duration = db[title] print(\"{title} ({year}) {duration} minute{0}, by \"\n\n\"{director}\".format(Util.s(duration), **locals()))\n\nListing all the DVDs (or those whose title starts with a particular substring)is simply a matter of iterating over the DBM’s items.\n\nThe Util.s() function is simply s = lambda x: \"\" if x == 1 else \"s\"; so here it returns an “s” if the duration is not one minute.\n\ndef remove_dvd(db):\n\ntitle = find_dvd(db, \"remove\") if title is None:\n\nreturn\n\nans = Console.get_bool(\"Remove {0}?\".format(title), \"no\") if ans:\n\ndel db[title] db.sync()\n\nRemoving a DVD is a matter of ﬁnding the one the user wants to remove, asking for conﬁrmation, and if we get it, deleting the item from the DBM.\n\nWe have now seen how to open (or create) a DBM ﬁle using the shelve mod- ule, and how to add items to it, edit its items, iterate over its items, and re- move items.\n\nUnfortunately,there is a ﬂaw in our data design. Director names are duplicat- ed, and this could easily lead to inconsistencies; for example, director Danny DeVito might be entered as“Danny De Vito” for one movie and “Danny deVito” for another. One solution would be to have two DBM ﬁles, the main DVD ﬁle with title keys and (year, duration, director ID) values, and a director ﬁle with director ID (i.e., integer) keys and director name values. We avoid this ﬂaw in the next section’s SQL database version of the program by using two tables, one for DVDs and another for directors.\n\n479",
      "page_number": 458
    },
    {
      "number": 48,
      "title": "Segment 48 (pages 466-474)",
      "start_page": 466,
      "end_page": 474,
      "detection_method": "topic_boundary",
      "content": "480\n\nChapter 12. Database Programming\n\nSQL Databases\n\nInterfaces to most popular SQL databases are available from third-party modules, and out of the box Python comes with the sqlite3 module (and with the SQLite 3 database), so database programming can be started right away. SQLite is a lightweight SQL database, lacking many of the features of, say, PostgreSQL,but it isvery convenient for prototyping,and may provesufﬁcient in many cases.\n\nTo make it as easy as possible to switch between database backends, PEP 249 (Python Database API Speciﬁcation v2.0) provides an API speciﬁcation called DB-API 2.0 that database interfaces ought to honor—the sqlite3 module, for example, complies with the speciﬁcation, but not all the third-party modules do. There are two major objectsspeciﬁed by the API,the connection object and the cursor object,and theAPIsthey must supportareshown in Tables12.1and 12.2. In the case of the sqlite3 module, its connection and cursor objects both provide many additional attributes and methods beyond those required by the DB-API 2.0 speciﬁcation.\n\nThe SQL version of the DVDs program is dvds-sql.py. The program stores di- rectors separately from the DVD data to avoid duplication and offers one more menu option that lets the user list the directors. The two tables are shown in Figure 12.1. The program has slightly fewer than 300 lines, whereas the pre- vious section’s dvds-dbm.py program is slightly fewer than 200 lines, with most of the difference due to the fact that we must use SQL queries rather than perform simple dictionary-like operations, and because we must create the database’s tables the ﬁrst time the program runs.\n\ndvds\n\ndirectors\n\nid title year duration director_id\n\nid name\n\nFigure 12.1 The DVD program’s database design\n\nThe main() function is similar to before, only this time we call a custom connect() function to make the connection.\n\ndef connect(filename):\n\ncreate = not os.path.exists(filename) db = sqlite3.connect(filename) if create:\n\ncursor = db.cursor()\n\n|||\n\nSQL Databases\n\nTable 12.1 DB-API 2.0 Connection Object Methods\n\nSyntax\n\nDescription\n\ndb.close()\n\nClosestheconnectiontothedatabase(representedby the db object which is obtained by calling a connect() function)\n\ndb.commit()\n\nCommits any pending transaction to the database; does nothing for databases that don’t support transactions\n\ndb.cursor()\n\nReturnsa databasecursor object through which queriescan be executed\n\ndb.rollback() Rolls back any pending transaction to the state that existed\n\nbefore the transaction began; does nothing for databases that don’t support transactions\n\ncursor.execute(\"CREATE TABLE directors (\"\n\n\"id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL, \" \"name TEXT UNIQUE NOT NULL)\") cursor.execute(\"CREATE TABLE dvds (\"\n\n\"id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL, \" \"title TEXT NOT NULL, \" \"year INTEGER NOT NULL, \" \"duration INTEGER NOT NULL, \" \"director_id INTEGER NOT NULL, \" \"FOREIGN KEY (director_id) REFERENCES directors)\")\n\ndb.commit()\n\nreturn db\n\nThe sqlite3.connect() function returns a database object, having opened the database ﬁle it is given and created an empty database ﬁle if the ﬁle did not exist. In view of this, prior to calling sqlite3.connect(), we note whether the databaseisgoing to be created from scratch,becauseif it is,we must createthe tables that the program relies on. All queries are executed through a database cursor, available from the database object’s cursor() method.\n\nNotice that both tables are created with an ID ﬁeld that has an AUTOINCREMENT constraint—this means that SQLite will automatically populate the IDs with unique numbers, so we can leave these ﬁelds to SQLite when inserting new records.\n\nSQLite supports a limited range of data types—essentially just Booleans, numbers, and strings—but this can be extended using data “adaptors”, either the predeﬁned ones such as those for dates and datetimes,or custom ones that we can use to represent any data types we like. The DVDs program does not need this functionality, but if it were required, the sqlite3 module’s documen- tation explains the details. The foreign key syntax we have used may not be the same as the syntax for other databases, and in any case it is merely doc-\n\n481\n\n482\n\nChapter 12. Database Programming\n\nTable 12.2 DB-API 2.0 Cursor Object Attributes and Methods\n\nSyntax\n\nDescription\n\nc.arraysize\n\nThe (readable/writable) number of rows that fetch- many() will return if no size is speciﬁed\n\nc.close()\n\nCloses the cursor, c; this is done automatically when the cursor goes out of scope\n\nc.description\n\nA read-only sequence of 7-tuples (name, type_code, display_size, internal_size, precision, scale, null_ok), describing each successive column of cursor c\n\nc.execute(sql, params)\n\nExecutes the SQL query in string sql, replacing each placeholder with the corresponding parameter from the params sequence or mapping if given\n\nc.executemany(\n\nsql, seq_of_params)\n\nc.fetchall()\n\nc.fetchmany(size)\n\nExecutes the SQL query once for each item in the seq_of_params sequence of sequencesor mappings;this method should not be used for operations that create result sets (such as SELECT statements) Returns a sequence of all the rows that have not yet been fetched (which could be all of them) Returns a sequence of rows (each row itself being a sequence); size defaults to c.arraysize\n\nc.fetchone()\n\nReturns the next row of the query result set as a se- quence,or None whentheresultsareexhausted. Raises an exception if there is no result set.\n\nc.rowcount\n\nThe read-only row count for the last operation (e.g., SELECT, INSERT, UPDATE,or DELETE) or -1if not available or not applicable\n\numenting our intention, since SQLite, unlike many other databases, does not enforce relational integrity. (However, SQLite does have a workaround based on sqlite3’s .genfkey command.) One other sqlite3-speciﬁc quirk is that its default behavior istosupportimplicittransactions,sothereisnoexplicit“start transaction” method.\n\ndef add_dvd(db):\n\ntitle = Console.get_string(\"Title\", \"title\") if not title: return\n\ndirector = Console.get_string(\"Director\", \"director\") if not director:\n\nreturn\n\nyear = Console.get_integer(\"Year\", \"year\", minimum=1896,\n\nmaximum=datetime.date.today().year)\n\nSQL Databases\n\nduration = Console.get_integer(\"Duration (minutes)\", \"minutes\",\n\nminimum=0, maximum=60*48)\n\ndirector_id = get_and_set_director(db, director) cursor = db.cursor() cursor.execute(\"INSERT INTO dvds \"\n\n\"(title, year, duration, director_id) \" \"VALUES (?, ?, ?, ?)\", (title, year, duration, director_id))\n\ndb.commit()\n\nThis function starts with the same code as the equivalent function from the dvds-dbm.py program, but once we have gathered the data, it is quite different. The director the user entered may or may not be in the directors table, so we have a get_and_set_director() function that inserts the director if they are not already in the database, and in either case returns the director’s ID ready for it to be inserted into the dvds table. With all the data available we execute an SQL INSERT statement. We don’t need to specify a record ID since SQLite will automatically provide one for us.\n\nIn the query we have used question marksfor placeholders. Each ? is replaced by the corresponding value in the sequence that follows the string containing the SQL statement. Named placeholders can also be used as we will see when we look at editing a record. Although it is possible to avoid using placeholders and simply format the SQL string with the data embedded into it, we recom- mend always using placeholders and leaving the burden of correctly encoding and escaping the data items to the database module. Another beneﬁt of using placeholders is that they improve security since they prevent arbitrary SQL from being maliciously injected into a query.\n\ndef get_and_set_director(db, director):\n\ndirector_id = get_director_id(db, director) if director_id is not None: return director_id\n\ncursor = db.cursor() cursor.execute(\"INSERT INTO directors (name) VALUES (?)\",\n\n(director,))\n\ndb.commit() return get_director_id(db, director)\n\nThis function returns the ID of the given director, inserting a new direc- tor record if necessary. If a record is inserted we retrieve its ID using the get_director_id() function we tried in the ﬁrst place.\n\ndef get_director_id(db, director):\n\ncursor = db.cursor() cursor.execute(\"SELECT id FROM directors WHERE name=?\",\n\n(director,))\n\n483\n\n484\n\nChapter 12. Database Programming\n\nfields = cursor.fetchone() return fields[0] if fields is not None else None\n\nThe get_director_id() function returns the ID of the given director or None if there is no such director in the database. We use the fetchone() method be- cause there is either zero or one matching record. (We know that there are no duplicate directors because the directors table’s name ﬁeld has a UNIQUE con- straint, and in any case we always check for the existence of a director before adding a new one.) The fetch methods always return a sequence of ﬁelds (or None if there are no more records), even if, as here, we have asked to retrieve only a single ﬁeld.\n\ndef edit_dvd(db):\n\ntitle, identity = find_dvd(db, \"edit\") if title is None:\n\nreturn\n\ntitle = Console.get_string(\"Title\", \"title\", title) if not title: return\n\ncursor = db.cursor() cursor.execute(\"SELECT dvds.year, dvds.duration, directors.name \"\n\n\"FROM dvds, directors \" \"WHERE dvds.director_id = directors.id AND \" \"dvds.id=:id\", dict(id=identity))\n\nyear, duration, director = cursor.fetchone() director = Console.get_string(\"Director\", \"director\", director) if not director:\n\nreturn\n\nyear = Console.get_integer(\"Year\", \"year\", year, 1896, datetime.date.today().year)\n\nduration = Console.get_integer(\"Duration (minutes)\", \"minutes\",\n\nduration, minimum=0, maximum=60*48)\n\ndirector_id = get_and_set_director(db, director) cursor.execute(\"UPDATE dvds SET title=:title, year=:year, \"\n\n\"duration=:duration, director_id=:director_id \" \"WHERE id=:identity\", locals())\n\ndb.commit()\n\nTo edit a DVD record we must ﬁrst ﬁnd the record the user wants to work on. If a record is found we begin by giving the user the opportunity to change the title. Then we retrieve the other ﬁelds so that we can provide the existing values as defaults to minimize what the user must type since they can just press Enter to accept a default. Here we have used named placeholders (of the form :name), and must therefore provide the corresponding values using a mapping. For the SELECT statement we have used a freshly created dictionary, and for the UPDATE statement we have used the dictionary returned by locals().\n\nSQL Databases\n\nWe could use a fresh dictionary for both, in which case for the UPDATE we would pass dict(title=title, year=year, duration=duration, director_id=director_id, id=identity)) instead of locals().\n\nOnce we have all the ﬁelds and the user has entered any changes they want, we retrieve the corresponding director ID (inserting a new director record if necessary), and then update the database with the new data. We have taken the simplistic approach of updating all the record’s ﬁelds rather than only those which have actually been changed.\n\nWhen we used a DBM ﬁle the DVD title was used as the key, so if the title changed, we created a new key–value item and deleted the original. But here every DVD record has a unique ID which is set when the record is ﬁrst inserted, so we are free to change the value of any other ﬁeld with no further work necessary.\n\ndef find_dvd(db, message):\n\nmessage = \"(Start of) title to \" + message cursor = db.cursor() while True:\n\nstart = Console.get_string(message, \"title\") if not start:\n\nreturn (None, None)\n\ncursor.execute(\"SELECT title, id FROM dvds \"\n\n\"WHERE title LIKE ? ORDER BY title\", (start + \"%\",))\n\nrecords = cursor.fetchall() if len(records) == 0:\n\nprint(\"There are no dvds starting with\", start) continue\n\nelif len(records) == 1:\n\nreturn records[0]\n\nelif len(records) > DISPLAY_LIMIT:\n\nprint(\"Too many dvds ({0}) start with {1}; try entering \"\n\n\"more of the title\".format(len(records), start))\n\ncontinue\n\nelse:\n\nfor i, record in enumerate(records):\n\nprint(\"{0}: {1}\".format(i + 1, record[0]))\n\nwhich = Console.get_integer(\"Number (or 0 to cancel)\",\n\n\"number\", minimum=1, maximum=len(records))\n\nreturn records[which - 1] if which != 0 else (None, None)\n\nThis function performsthe same service as the find_dvd() function in the dvds- dbm.py program,and returnsa 2-tuple (title,DVD ID),or (None, None) depending on whether a record was found. Instead of iterating over all the data we have used the SQL wildcard operator (%), so only the relevant records are retrieved.\n\n485\n\n486\n\nChapter 12. Database Programming\n\nAnd sinceweexpect thenumber of matching recordstobesmall,wefetchthem all at once into a sequence of sequences. If there is more than one matching record and few enough to display, we print the records with a number beside each one so that the user can choose the one they want in much the same way as they could in the dvds-dbm.py program.\n\ndef list_dvds(db):\n\ncursor = db.cursor() sql = (\"SELECT dvds.title, dvds.year, dvds.duration, \"\n\n\"directors.name FROM dvds, directors \" \"WHERE dvds.director_id = directors.id\")\n\nstart = None if dvd_count(db) > DISPLAY_LIMIT:\n\nstart = Console.get_string(\"List those starting with \"\n\n\"[Enter=all]\", \"start\")\n\nsql += \" AND dvds.title LIKE ?\"\n\nsql += \" ORDER BY dvds.title\" print() if start is None:\n\ncursor.execute(sql)\n\nelse:\n\ncursor.execute(sql, (start + \"%\",))\n\nfor record in cursor:\n\nprint(\"{0[0]} ({0[1]}) {0[2]} minutes, by {0[3]}\".format(\n\nrecord))\n\nTo list the details of each DVD we do a SELECT query that joins the two tables, adding a second element to the WHERE clauseif thereare morerecords(returned by our dvd_count() function) than the display limit. We then execute the query and iterate over the results. Each record is a sequence whose ﬁelds are those matching the SELECT query.\n\ndef dvd_count(db):\n\ncursor = db.cursor() cursor.execute(\"SELECT COUNT(*) FROM dvds\") return cursor.fetchone()[0]\n\nWe factored these lines out into a separate function because we need them in several different functions.\n\nWe have omitted the code for the list_directors() function since it is struc- turally very similar to the list_dvds() function, only simpler because it lists only one ﬁeld (name).\n\ndef remove_dvd(db):\n\ntitle, identity = find_dvd(db, \"remove\") if title is None:\n\nSQL Databases\n\nreturn\n\nans = Console.get_bool(\"Remove {0}?\".format(title), \"no\") if ans:\n\ncursor = db.cursor() cursor.execute(\"DELETE FROM dvds WHERE id=?\", (identity,)) db.commit()\n\nThis function is called when the user asks to delete a record, and it is very similar to the equivalent function in the dvds-dbm.py program.\n\nWe have now completed our review of the dvds-sql.py program and seen how to create database tables, select records, iterate over the selected records, and insert,update,and delete records. Using the execute() method we can execute any arbitrary SQL statement that the underlying database supports.\n\nSQLite offers much more functionality than we needed here, including an auto-commit mode (and other kinds of transaction control), and the ability to create functions that can be executed inside SQL queries. It is also possible to provide a factory function to control what is returned for each fetched record (e.g., a dictionary or custom type instead of a sequence of ﬁelds).Additionally, it is possible to create in-memory SQLite databases by passing “:memory:” as the ﬁlename.\n\nSummary\n\nBack in Chapter 7 we saw several different ways of saving and loading data from disk, and in this chapter we have seen how to interact with data types that hold their data on disk rather than in memory.\n\nFor DBM ﬁlesthe shelve moduleisvery convenient sinceit storesstring–object items. If we want complete control we can of course use any of the underlying DBMs directly. One nice feature of the shelve module and of the DBMs generally is that they use the dictionary API, making it easy to retrieve, add, edit, and remove items, and to convert programs that use dictionaries to use DBMsinstead. Onesmallinconvenienceof DBMsisthatfor relationaldatawe must use a separate DBM ﬁle for each key–value table, whereas SQLite stores all the data in a single ﬁle.\n\nFor SQL databases, SQLite is useful for prototyping, and in many cases in its own right,and it hasthe advantageof being suppliedwith Python asstandard. We have seen how to obtain a database object using the connect() function and how to execute SQL queries (such as CREATE TABLE, SELECT, INSERT, UPDATE, and DELETE) using the database cursor’s execute() method.\n\nPython offers a complete range of choices for disk-based and in-memory data storage, from binary ﬁles, text ﬁles, XML ﬁles, and pickles, to DBMs and SQL\n\n487\n\n|||\n\n488\n\nChapter 12. Database Programming\n\ndatabases, and this makes it possible to choose exactly the right approach for any given situation.\n\nExercise\n\nWrite an interactive console program to maintain a list of bookmarks. For each bookmark keep two pieces of information: the URL and a name. Here is an example of the program in action:\n\nBookmarks (bookmarks.dbm) (1) Programming in Python 3........ http://www.qtrac.eu/py3book.html (2) PyQt........................... http://www.riverbankcomputing.com (3) Python......................... http://www.python.org (4) Qtrac Ltd...................... http://www.qtrac.eu (5) Scientific Tools for Python.... http://www.scipy.org\n\n(A)dd (E)dit (L)ist (R)emove (Q)uit [l]: e Number of bookmark to edit: 2 URL [http://www.riverbankcomputing.com]: Name [PyQt]: PyQt (Python bindings for GUI library)\n\nThe program should allow the user to add, edit, list, and remove bookmarks. To make identifying a bookmark for editing or removing as easy as possible, list the bookmarkswith numbersand ask the user to specify the number of the bookmark they want to edit or remove. Store the data in a DBM ﬁle using the shelve module and with names as keys and URLs as values. Structurally the program is very similar to dvds-dbm.py, except for the find_bookmark() function which is much simpler than find_dvd() since it only has to get an integer from the user and use that to ﬁnd the corresponding bookmark’s name.\n\nAs a courtesy to users, if no protocol is speciﬁed, prepend the URL the user adds or edits with http://.\n\nThe entire program can be written in fewer than 100 lines (assuming the use of the Console module for Console.get_string() and similar). A solution is provided in bookmarks.py.\n\n|||",
      "page_number": 466
    },
    {
      "number": 49,
      "title": "Segment 49 (pages 475-482)",
      "start_page": 475,
      "end_page": 482,
      "detection_method": "topic_boundary",
      "content": "13 ● Python’s Regular Expression\n\nLanguage\n\nThe Regular Expression Module\n\nRegular Expressions\n\n||||\n\nA regular expression is a compact notation for representing a collection of strings. What makes regular expressions so powerful is that a single regular expression can represent an unlimited number of strings—providing they meet the regular expression’s requirements. Regular expressions (which we will mostly call “regexes” from now on) are deﬁned using a mini-language that is completely different from Python—but Python includes the re module through which we can seamlessly create and use regexes.★\n\nRegexes are used for ﬁve main purposes:\n\nParsing: identifying and extracting pieces of text that match certain criteria—regexes are used for creating ad hoc parsers and also by tradi- tional parsing tools\n\nSearching: locating substrings that can have more than one form, for example, ﬁnding any of “pet.png”, “pet.jpg”, “pet.jpeg”, or “pet.svg” while avoiding “carpet.png” and similar\n\nSearching and replacing: replacing everywhere the regex matches with a string, for example, ﬁnding “bicycle” or “human powered vehicle” and replacing either with “bike”\n\nSplitting strings: splitting a string at each place the regex matches, for example, splitting everywhere colon-space or equals (“: ” or “=”) occurs\n\nValidation: checking whether a piece of text meets some criteria, for example, contains a currency symbol followed by digits\n\nThe regexes used for searching, splitting, and validation are often fairly small andunderstandable,makingthemidealforthesepurposes. However,although\n\n★A good book on regular expressions is Mastering Regular Expressions by Jeffrey E. F. Friedl, ISBN 0596528124.It does not explicitly cover Python, but Python’s re module offers very similar functionality to the Perl regular expression engine that the book covers in depth.\n\n489\n\nParsing XML ﬁles 312➤\n\n490\n\nChapter 13. Regular Expressions\n\nregexes are widely and successfully used to create parsers,they do have a lim- itation in that area:They are only able to deal with recursively structured text if the maximum level of recursion is known. Also, large and complex regexes can be difﬁcult to read and maintain. So apart from simple cases, for parsing the best approach is to use a tool designed for the purpose—for example, use a dedicated XML parser for XML. If such a parser isn’t available, then an al- ternative to using regexes is to use a generic parsing tool, an approach that is covered in Chapter 14.\n\nAt its simplest a regular expression is an expression (e.g., a literal character), optionally followed by a quantiﬁer. More complex regexes consist of any number of quantiﬁed expressions and may include assertions and may be inﬂuenced by ﬂags.\n\nThis chapter’s ﬁrst section introduces and explains all the key regular expres- sion concepts and shows pure regular expression syntax—it makes minimal reference to Python itself. Then the second section shows how to use regular expressionsin thecontextof Pythonprogramming,drawing on allthematerial covered in the earlier sections. Readersfamiliar with regular expressionswho just want to learn how they work in Python could skip to the second section (➤ 499).The chapter coversthe completeregex language offered by the re mod- ule, including all the assertions and ﬂags. We indicate regular expressions in the text using bold, show where they match using underlining, and show cap- tures using shading.\n\nPython’s Regular Expression Language\n\nIn this section we look at the regular expression language in four subsections. The ﬁrst subsection shows how to match individual characters or groups of characters,for example,match a,or match b,or match either aor b.The second subsection shows how to quantify matches, for example, match once, or match at least once, or match as many times as possible. The third subsection shows how to group subexpressions and how to capture matching text, and the ﬁnal subsection shows how to use the language’s assertions and ﬂags to affect how regular expressions work.\n\nCharacters and Character Classes\n\nThe simplest expressions are just literal characters, such as a or 5, and if no quantiﬁer is explicitly given it is taken to be “match one occurrence”. For example,the regex tune consistsof four expressions,each implicitly quantiﬁed to match once, so it matches one t followed by one u followed by one n followed by one e, and hence matches the strings tune and attuned.\n\n|||\n\n||\n\nString escapes 66➤\n\nPython’s Regular Expression Language\n\nAlthough most characters can be used as literals, some are “special charac- ters”—these are symbols in the regex language and so must be escaped by pre- ceding themwith a backslash(\\)touse themasliterals. Thespecialcharacters are \\.^$?+*{}[]()|. Most of Python’s standard string escapes can also be used within regexes, for example, \\n for newline and \\t for tab, as well as hexadeci- mal escapes for characters using the \\xHH, \\uHHHH, and \\UHHHHHHHH syntaxes.\n\nIn many cases, rather than matching one particular character we want to match any oneof a set of characters. Thiscan beachievedby using a character class—one or more characters enclosed in square brackets. (This has nothing to do with a Python class, and is simply the regex term for “set of characters”.) A character class is an expression,and like any other expression,if not explic- itly quantiﬁed it matches exactly one character (which can be any of the char- acters in the character class). For example, the regex r[ea]d matches both red and radar, but not read. Similarly, to match a single digit we can use the regex [0123456789]. For convenience we can specify a range of characters using a hy- phen,so the regex [0-9] also matchesa digit. It is possible to negate the mean- ing of a character classby following the opening bracket with a caret,so [^0-9] matches any character that is not a digit.\n\nNote that inside a character class, apart from \\, the special characters lose their special meaning, although in the case of ^ it acquires a new meaning (negation) if it is the ﬁrst character in the character class, and otherwise is simply a literal caret. Also, - signiﬁes a character range unless it is the ﬁrst character, in which case it is a literal hyphen.\n\nSince some sets of characters are required so frequently, several have short- hand forms—theseareshownin Table13.1.With oneexceptiontheshorthands can be used inside character sets,so for example,the regex [\\dA-Fa-f] matches any hexadecimal digit. The exception is . which is a shorthand outside a char- acter class but matches a literal . inside a character class.\n\nQuantiﬁers\n\nA quantiﬁer has the form {m,n} where m and n are the minimum and maximum times the expression the quantiﬁer applies to must match. For example, both e{1,1}e{1,1} and e{2,2} match feel, but neither matches felt.\n\nWriting a quantiﬁer after every expression would soon become tedious, and is certainly difﬁcult to read. Fortunately, the regex language supports several convenientshorthands. If only onenumberisgiveninthequantiﬁerit istaken to be both the minimum and the maximum, so e{2} is the same as e{2,2}. And as we noted in the preceding section, if no quantiﬁer is explicitly given, it is assumed to be one (i.e., {1,1} or {1}); therefore, ee is the same as e{1,1}e{1,1} and e{1}e{1}, so both e{2} and ee match feel but not felt.\n\n491\n\n||\n\n492\n\nChapter 13. Regular Expressions\n\nTable 13.1 Character Class Shorthands\n\nSymbol Meaning\n\n. Matches any character except newline; or any character at all with the re.DOTALL ﬂag; or inside a character class matches a literal .\n\n\\d Matches a Unicode digit; or [0-9] with the re.ASCII ﬂag\n\n\\D Matches a Unicode nondigit; or [^0-9] with the re.ASCII ﬂag\n\n\\s Matches a Unicode whitespace; or [ \\t\\n\\r\\f\\v] with the re.ASCII\n\nﬂag\n\n\\S Matches a Unicode nonwhitespace; or [^ \\t\\n\\r\\f\\v] with the\n\nre.ASCII ﬂag\n\n\\w Matches a Unicode “word” character; or [a-zA-Z0-9_] with the\n\nre.ASCII ﬂag\n\n\\W Matches a Unicode non-“word” character; or [^a-zA-Z0-9_] with the\n\nre.ASCII ﬂag\n\nHaving a different minimum and maximum is often convenient. For example, to match travelled and traveled (both legitimatespellings),we could use either travel{1,2}ed or travell{0,1}ed. The {0,1} quantiﬁcation is so often used that it has its own shorthand form, ?, so another way of writing the regex (and the one most likely to be used in practice) is travell?ed.\n\nTwoother quantiﬁcationshorthandsareprovided:+ which standsfor {1,n} (“at least one”)and * which standsfor {0,n} (“any number of”);in both cases n isthe maximum possible number allowed for a quantiﬁer,usually at least 32767.All the quantiﬁers are shown in Table 13.2.\n\nThe + quantiﬁer isvery useful. For example,tomatch integerswecould use \\d+ since this matches one or more digits. This regex could match in two places in the string 4588.91, for example, 4588.91 and 4588.91. Sometimes typos are the result of pressing a key too long. We could use the regex bevel+ed to match the legitimate beveled and bevelled, and the incorrect bevellled. If we wanted to standardize on the one l spelling, and match only occurrences that had two or more ls, we could use bevell+ed to ﬁnd them.\n\nThe * quantiﬁer is less useful, simply because it can so often lead to unex- pected results. For example, supposing that we want to ﬁnd lines that con- tain comments in Python ﬁles, we might try searching for #*. But this regex will match any line whatsoever, including blank lines because the meaning is “match any number of #s”—and that includes none. As a rule of thumb for those new to regexes, avoid using * at all, and if you do use it (or if you use ?), make sure there is at least one other expression in the regex that has a non- zero quantiﬁer—so at least one quantiﬁer other than * or ? since both of these can match their expression zero times.\n\nMean- ing of the ﬂags ➤ 496\n\nPython’s Regular Expression Language\n\nTable 13.2 Regular Expression Quantiﬁers\n\nSyntax\n\nMeaning\n\ne? or e{0,1} Greedily match zero or one occurrence of expression e\n\ne?? or e{0,1}? Nongreedily match zero or one occurrence of expression e\n\ne+ or e{1,}\n\nGreedily match one or more occurrences of expression e\n\ne+? or e{1,}? Nongreedily match one or more occurrences of expression e\n\ne* or e{0,}\n\nGreedily match zero or more occurrences of expression e\n\ne*? or e{0,}? Nongreedily match zero or more occurrences of expression e\n\ne{m}\n\nMatch exactly m occurrences of expression e\n\ne{m,}\n\nGreedily match at least m occurrences of expression e\n\ne{m,}?\n\nNongreedily match at least m occurrences of expression e\n\ne{,n}\n\nGreedily match at most n occurrences of expression e\n\ne{,n}?\n\nNongreedily match at most n occurrences of expression e\n\ne{m,n}\n\ne{m,n}?\n\nGreedily matchatleast m andatmost n occurrencesof expres- sion e Nongreedily match at least m and at most n occurrences of expression e\n\nIt is often possible to convert * uses to + uses and vice versa. For example, we could match “tasselled” with at least one l using tassell*ed or tassel+ed, and match those with two or more ls using tasselll*ed or tassell+ed.\n\nIf we use the regex \\d+ it will match 136. But why does it match all the digits, rather than just the ﬁrst one? By default, all quantiﬁers are greedy—they match asmany charactersasthey can. We can makeany quantiﬁer nongreedy (also called minimal) by following it with a ? symbol. (The question mark has two different meanings—on its own it is a shorthand for the {0,1} quantiﬁer, and when it follows a quantiﬁer it tells the quantiﬁer to be nongreedy.) For example, \\d+? can match the string 136 in three different places: 136, 136, and 136. Here is another example: \\d?? matches zero or one digits, but prefers to match none since it is nongreedy—on its own it suffers the same problem as * in that it will match nothing, that is, any text at all.\n\nNongreedy quantiﬁers can be useful for quick and dirty XML and HTML parsing. For example, to match all the image tags, writing <img.*> (match one “<”,then one “i”,then one “m”,then one “g”,then zero or more of any character apart from newline, then one “>”) will not work because the .* part is greedy and will match everything including the tag’s closing >, and will keep going until it reaches the last > in the entire text.\n\n493\n\n494\n\nChapter 13. Regular Expressions\n\nThree solutions present themselves (apart from using a proper parser). One is <img[^>]*> (match <img, then any number of non-> characters and then the tag’s closing > character),another is <img.*?> (match <img, then any number of characters,but nongreedily, so it will stop immediately before the tag’s closing >, and then the >), and a third combines both, as in <img[^>]*?>. None of them is correct, though, since they can all match <img>, which is not valid. Since we know that an image tag must have a src attribute, a more accurate regex is <img\\s+[^>]*?src=\\w+[^>]*?>. This matches the literal characters <img, then one or more whitespace characters,then nongreedily zero or more of anything except > (to skip any other attributes such as alt), then the src attribute (the literal characters src= then at least one “word” character), and then any other non-> characters (including none) to account for any other attributes, and ﬁnally the closing >.\n\nGrouping and Capturing\n\nIn practical applications we often need regexes that can match any one of two or more alternatives, and we often need to capture the match or some part of the match for further processing. Also, we sometimes want a quantiﬁer to apply to several expressions. All of these can be achieved by grouping with (), and in the case of alternatives using alternation with |.\n\nAlternation is especially useful when we want to match any one of several quite different alternatives. For example, the regex aircraft|airplane|jet will match any text that contains “aircraft” or “airplane” or “jet”. The same thing can be achieved using the regex air(craft|plane)|jet. Here, the parentheses are used to group expressions, so we have two outer expres- sions, air(craft|plane) and jet. The ﬁrst of these has an inner expression, craft|plane, and because this is preceded by air the ﬁrst outer expression can match only “aircraft” or “airplane”.\n\nParenthesesservetwodifferentpurposes—togroupexpressionsandtocapture the text that matches an expression. We will use the term group to refer to a grouped expression whether it captures or not, and capture and capture group to refer to a captured group. If we used the regex (aircraft|airplane|jet) it would not only match any of the three expressions, but would also capture whichever one was matched for later reference. Compare this with the regex (air(craft|plane)|jet) which has two captures if the ﬁrst expression matches (“aircraft” or “airplane” as the ﬁrst capture and “craft” or “plane” as the second capture), and one capture if the second expression matches (“jet”). We can switch off the capturing effect by following an opening parenthesis with ?:, so for example, (air(?:craft|plane)|jet) will have only one capture if it matches (“aircraft” or “airplane” or “jet”).\n\nA grouped expression is an expression and so can be quantiﬁed. Like any other expression the quantity is assumed to be one unless explicitly given. For\n\n||\n\nPython’s Regular Expression Language\n\nexample, if we have read a text ﬁle with lines of the form key=value, where each keyis alphanumeric,the regex (\\w+)=(.+) will match every line that hasa nonempty key and a nonempty value. (Recall that . matches anything except newlines.) And for every line that matches, two captures are made, the ﬁrst being the key and the second being the value.\n\nFor example, the key=value regular expression will match the entire line topic= physical geography with the two captures shown shaded. Notice that the second capture includes some whitespace, and that whitespace before the = is not accepted. We could reﬁne the regex to be more ﬂexible in accepting whitespace, and to strip off unwanted whitespace using a somewhat longer version:\n\n[ \\t]*(\\w+)[ \\t]*=[ \\t]*(.+)\n\nThis matches the same line as before and also lines that have whitespace around the = sign, but with the ﬁrst capture having no leading or trailing whitespace, and the second capture having no leading whitespace. For exam- ple: topic = physical geography. We have been careful to keep the whitespace matching parts outside the capturing parentheses, and to allow for lines that have no whitespace at all. We did not use \\s to match whitespace because that matches newlines (\\n) which could lead to incorrect matches that span lines (e.g., if the re.MULTILINE ﬂag is used). And for the value we did not use \\S to match nonwhitespace because we want to allow for values that contain whitespace (e.g., English sentences).To avoid the second capture having trail- ing whitespace we would need a more sophisticated regex; we will see this in the next subsection.\n\nCaptures can be referred to using backreferences, that is, by referring back to an earlier capture group.★ One syntax for backreferences inside regexes them- selves is \\i where i is the capture number. Captures are numbered starting from one and increasing by one going from left to right as each new (capturing) left parenthesisis encountered. For example,to simplistically match duplicat- ed wordswe can use the regex (\\w+)\\s+\\1 which matchesa “word”,then at least one whitespace, and then the same word as was captured. (Capture number 0 is created automatically without the need for parentheses;it holds the entire match, that is, what we show underlined.) We will see a more sophisticated way to match duplicate words later.\n\nIn long or complicated regexes it is often more convenient to use names rather than numbers for captures. This can also make maintenance easier since adding or removing capturing parentheses may change the numbers but won’t affect names. To name a capture we follow the opening parenthesis with ?P<name>.For example,(?P<key>\\w+)=(?P<value>.+) hastwo capturescalled \"key\" and \"value\". The syntax for backreferences to named captures inside a\n\n★Note that backreferences cannot be used inside character classes, that is, inside [].\n\n495\n\nRegex ﬂags ➤ 502\n\n496\n\nChapter 13. Regular Expressions\n\nregex is (?P=name). For example, (?P<word>\\w+)\\s+(?P=word) matches duplicate words using a capture called \"word\".\n\nAssertions and Flags\n\nOne problem that affects many of the regexes we have looked at so far is that they can match more or different text than we intended. For example, the regex aircraft|airplane|jet will match “waterjet” and “jetski” as well as “jet”. This kind of problem can be solved by using assertions. An assertion does not match any text, but instead says something about the text at the point where the assertion occurs.\n\nOne assertion is \\b (word boundary),which assertsthat the character that pre- cedes it must be a “word” (\\w) and the character that follows it must be a non- “word” (\\W),or vice versa. For example,although the regex jet can match twice in the text the jet and jetski are noisy, that is, the jet and jetski are noisy, the regex \\bjet\\b will match only once, the jet and jetski are noisy. In the context of the original regex, we could write it either as \\baircraft\\b|\\bair- plane\\b|\\bjet\\b or more clearly as \\b(?:aircraft|airplane|jet)\\b, that is, word boundary, noncapturing expression, word boundary.\n\nMany other assertions are supported, as shown in Table 13.3. We could use assertions to improve the clarity of a key=value regex, for example, by chang- ing it to ^(\\w+)=([^\\n]+) and setting the re.MULTILINE ﬂag to ensure that each key=value is taken from a single line with no possibility of spanning lines— providing no part of the regex matches a newline, so we can’t use, say, \\s. (The ﬂags are shown in Table 13.5;➤ 502;their syntaxesare described at the end of thissubsection,and examplesare given in the next section.) And if we want to strip whitespace from the ends and use named captures, the regex becomes:\n\n^[ \\t]*(?P<key>\\w+)[ \\t]*=[ \\t]*(?P<value>[^\\n]+)(?<![ \\t])\n\nEven though this regex is designed for a fairly simple task, it looks quite com- plicated. One way to make it more maintainable is to include comments in it. This can be done by adding inline comments using the syntax (?#the comment), but in practice comments like this can easily make the regex even more difﬁ- cult to read. A much nicer solution is to use the re.VERBOSE ﬂag—this allows us to freely use whitespace and normal Python comments in regexes, with the one constraint that if we need to match whitespace we must either use \\s or a character class such as [ ]. Here’s the key=value regex with comments:\n\n^[ \\t]* (?P<key>\\w+) [ \\t]*=[ \\t]* (?P<value>[^\\n]+) (?<![ \\t])\n\n# start of line and optional leading whitespace # the key text # the equals with optional surrounding whitespace # the value text # negative lookbehind to avoid trailing whitespace\n\n||\n\nRegex ﬂags ➤ 502",
      "page_number": 475
    },
    {
      "number": 50,
      "title": "Segment 50 (pages 483-495)",
      "start_page": 483,
      "end_page": 495,
      "detection_method": "topic_boundary",
      "content": "Raw strings 67➤\n\nPython’s Regular Expression Language\n\nTable 13.3 Regular Expression Assertions\n\nSymbo Meaning\n\n^ Matches at the start; also matches after each newline with\n\nthe\n\nre.MULTILINE ﬂag\n\n$ Matches at the end; also matches before each newline with the\n\nre.MULTILINE ﬂag\n\n\\A Matches at the start\n\n\\b Matches at a “word” boundary; inﬂuenced by the re.ASCII\n\nﬂag—inside a character class this is the escape for the backspace character\n\n\\B Matches at a non-“word” boundary; inﬂuenced by the re.ASCII ﬂag\n\n\\Z Matches at the end\n\n(?=e) Matches if the expression e matches at this assertion but does not\n\nadvance over it—called lookahead or positive lookahead\n\n(?!e) Matches if the expression e does not match at this assertion and\n\ndoes not advance over it—called negative lookahead\n\n(?<=e) Matches if the expression e matches immediately before this\n\nassertion—called positive lookbehind\n\n(?<!e) Matches if the expression e does not match immediately before this\n\nassertion—called negative lookbehind\n\nIn the context of a Python program we would normally write a regex like this inside a raw triple quoted string—raw so that we don’t have to double up the backslashes, and triple quoted so that we can spread it over multiple lines.\n\nIn addition to the assertions we have discussed so far, there are additional assertions which look at the text in front of (or behind) the assertion to see whether it matches (or does not match) an expression we specify. The expres- sions that can be used in lookbehind assertions must be of ﬁxed length (so the quantiﬁers ?, +, and * cannot be used, and numeric quantiﬁers must be of a ﬁxed size, for example, {3}).\n\nIn the case of the key=value regex, the negative lookbehind assertion means that at the point it occurs the preceding character must not be a space or a tab. Thishastheeffect of ensuring that thelast character capturedintothe \"value\" capture group is not a space or tab (yet without preventing spacesor tabs from appearing inside the captured text).\n\nLet’s consider another example. Suppose we are reading a multiline text that contains the names “Helen Patricia Sharman”, “Jim Sharman”, “Sharman Joshi”, “Helen Kelly”, and so on, and we want to match “Helen Patricia”, but only when referring to “Helen Patricia Sharman”. The easi-\n\n497\n\nRegex ﬂags ➤ 502\n\n498\n\nChapter 13. Regular Expressions\n\nest way is to use the regex \\b(Helen\\s+Patricia)\\s+Sharman\\b. But we could also achieve the same thing using a lookahead assertion, for example, \\b(Helen\\s+Patricia)(?=\\s+Sharman\\b). This will match “Helen Patricia” only if it is preceded by a word boundary and followed by whitespace and “Sharman” ending at a word boundary.\n\nTo capture the particular variation of the forenames that is used (“Helen”, “Helen P.”, or “Helen Patricia”), we could make the regex slightly more so- phisticated, for example, \\b(Helen(?:\\s+(?:P\\.|Patricia))?)\\s+(?=Sharman\\b). This matches a word boundary followed by one of the forename forms—but only if this is followed by some whitespace and then “Sharman” and a word boundary.\n\nNote that only two syntaxes perform capturing, (e) and (?P<name>e). None of the other parenthesized forms captures. This makes perfect sense for the lookahead and lookbehind assertions since they only make a statement about what follows or precedes them—they are not part of the match, but rather af- fect whether a match is made. It also makes sense for the last two parenthe- sized forms that we will now consider.\n\nWe saw earlier how we can backreference a capture inside a regex either by number (e.g., \\1) or by name (e.g., (?P=name)). It is also possible to match conditionally depending on whether an earlier match occurred. The syntaxes are (?(id)yes_exp) and (?(id)yes_exp|no_exp). The id is the name or number of an earlier capture that we are referring to. If the capture succeeded the yes_exp will be matched here. If the capture failed the no_exp will be matched if it is given.\n\nLet’s consider an example. Suppose we want to extract the ﬁlenames referred to by the src attribute in HTML img tags. We will begin just by trying to match the src attribute, but unlike our earlier attempt we will account for the three forms that the attribute’s value can take: single quoted, double quoted, and unquoted. Here is an initial attempt: src=([\"'])([^\"'>]+)\\1. The ([^\"'>]+) part captures a greedy match of at least one character that isn’t a quote or >. This regex works ﬁne for quoted ﬁlenames, and thanks to the \\1 matches only when the opening and closing quotes are the same. But it does not allow for unquoted ﬁlenames. To ﬁx this we must make the opening quote optional and therefore match only if it is present.\n\nHere is a revised regex: src=([\"'])?([^\"'>]+)(?(1)\\1). We did not provide a no_exp since there is nothing to match if no quote is given. Unfortunately,this doesn’t work quite right. It will work ﬁne for quoted ﬁlenames,but for unquot- ed ﬁlenamesit will work only if the src attributeisthe last attributein thetag; otherwise it will incorrectly match text into the next attribute. The solution is to treat the two cases (quoted and unquoted) separately, and to use alterna- tion: src=(([\"'])([^\\1>]+?)\\1|([^\"' >]+)). Now let’s see the regex in context, complete with named groups, nonmatching parentheses, and comments:\n\nPython’s Regular Expression Language\n\n<img\\s+ [^>]*? src= (?:\n\n# start of the tag # any attributes that precede the src # start of the src attribute\n\n|\n\n(?P<quote>[\"']) (?P<qimage>[^\\1>]+?) (?P=quote)\n\n(?P<uimage>[^\"' >]+)\n\n# opening quote # image filename # closing quote matching the opening quote # ---or alternatively--- # unquoted image filename\n\n) [^>]*? >\n\n# any attributes that follow the src # end of the tag\n\nThe indentation is just for clarity. The noncapturing parentheses are used for alternation. The ﬁrst alternative matches a quote (either single or double), then the image ﬁlename (which may contain any characters except for the quote that matched or >), and ﬁnally, another quote which must be the same as the matching quote. We also had to use minimal matching, +?, for the ﬁle- name, to ensure that the match doesn’t extend beyond the ﬁrst matching clos- ing quote. This means that a ﬁlename such as \"I'm here!.png\" will match correctly. Note also that to refer to the matching quote inside the character class we had to use a numbered backreference, \\1, instead of (?P=quote), since only numbered backreferences work inside character classes. The second al- ternative matches an unquoted ﬁlename—a string of characters that don’t include quotes, spaces, or >. Due to the alternation, the ﬁlename is captured in \"qimage\" (capture number 2) or in \"uimage\" (capture number 3,since (?P=quote) matches but doesn’t capture), so we must check for both.\n\nThe ﬁnal piece of regex syntax that Python’s regular expression engine offers is a means of setting the ﬂags. Usually the ﬂags are set by passing them as additional parameters when calling the re.compile() function, but sometimes it is more convenient to set them as part of the regex itself. The syntax is flags is one or more of a (the same as passing re.ASCII), simply (?flags) where i (re.IGNORECASE), m (re.MULTILINE), s (re.DOTALL), and x (re.VERBOSE).★ If the ﬂags are set this way they should be put at the start of the regex; they match nothing, so their effect on the regex is only to set the ﬂags.\n\nThe Regular Expression Module\n\nThe re module provides two ways of working with regexes. One is to use the functions listed in Table 13.4 (➤ 502), where each function is given a regex as itsﬁrstargument. Each functionconvertstheregex intoan internalformat—a\n\n★The letters used for the ﬂags are the same as the ones used by Perl’s regex engine, which is why s is used for re.DOTALL and x is used for re.VERBOSE.\n\n499\n\n|||\n\nRegex ﬂags ➤ 502\n\n500\n\nChapter 13. Regular Expressions\n\nprocess called compiling—and then does its work. This is very convenient for one-off uses, but if we need to use the same regex repeatedly we can avoid the cost of compiling it at each use by compiling it once using the re.compile() function. Wecan then callmethodson thecompiledregex object asmany times as we like. The compiled regex methods are listed in Table 13.6 (➤ 503).\n\nmatch = re.search(r\"#[\\dA-Fa-f]{6}\\b\", text)\n\nThis code snippet shows the use of an re module function. The regex matches HTML-style colors (such as #C0C0AB). If a match is found the re.search() func- tion returns a match object; otherwise, it returns None. The methods provided by match objects are listed in Table 13.7 (➤ 507).\n\nIf we were going to use thisregex repeatedly,we could compile it once and then use the compiled regex whenever we needed it:\n\ncolor_re = re.compile(r\"#[\\dA-Fa-f]{6}\\b\") match = color_re.search(text)\n\nAs we noted earlier, we use raw strings to avoid having to escape backslashes. Another way of writing this regex would be to use the character class [\\dA-F] and passthe re.IGNORECASE ﬂag as the last argument to the re.compile() call,or to use the regex (?i)#[\\dA-F]{6}\\b which starts with the ignore case ﬂag.\n\nIf morethanoneﬂag isrequiredthey canbecombinedusing the OR operator(|), for example, re.MULTILINE|re.DOTALL, or (?ms) if embedded in the regex itself.\n\nWe will round off this section by reviewing some examples,starting with some of the regexes shown in earlier sections, so as to illustrate the most commonly used functionality that the re module provides. Let’s start with a regex to spot duplicate words:\n\ndouble_word_re = re.compile(r\"\\b(?P<word>\\w+)\\s+(?P=word)(?!\\w)\",\n\nre.IGNORECASE)\n\nfor match in double_word_re.finditer(text):\n\nprint(\"{0} is duplicated\".format(match.group(\"word\")))\n\nThe regex is slightly more sophisticated than the version we made earlier. It starts at a word boundary (to ensure that each match starts at the beginning of a word), then greedily matches one or more “word” characters, then one or more whitespacecharacters,then the same word again—but only if the second occurrence of the word is not followed by a word character.\n\nIf the input text was “win in vain”, without the ﬁrst assertion there would be one match and one capture: win in vain. There aren’t two matches because while (?P<word>) matchesand captures,the \\s+ and (?P=word) partsonly match. The use of the word boundary assertion ensures that the ﬁrst word matched is a whole word, so we end up with no match or capture since there is no du-\n\nThe Regular Expression Module\n\nplicate whole word. Similarly, if the input text was “one and and two let’s say”, without the last assertion there would be two matches and two captures: one and and two let's say. The use of the lookahead assertion means that the second word matched is a whole word, so we end up with one match and one capture: one and and two let's say.\n\nThe for loop iterates over every match object returned by the finditer() method and we use the match object’s group() method to retrieve the cap- tured group’s text. We could just as easily (but less maintainably) have used group(1)—in which case we need not have named the capture group at all and just used the regex \\b(\\w+)\\s+\\1(?!\\w). Another point to note is that we could have used a word boundary \\b at the end, instead of (?!\\w).\n\nAnother example we presented earlier was a regex for ﬁnding the ﬁlenames in HTML image tags. Here is how we would compile the regex,adding ﬂags so that it is not case-sensitive, and allowing us to include comments:\n\nimage_re = re.compile(r\"\"\"\n\n<img\\s+ [^>]*? src= (?:\n\n# start of tag # non-src attributes # start of src attribute\n\n|\n\n(?P<quote>[\"']) (?P<qimage>[^\\1>]+?) (?P=quote)\n\n(?P<uimage>[^\"' >]+)\n\n# opening quote # image filename # closing quote # ---or alternatively--- # unquoted image filename\n\n) [^>]*? > \"\"\", re.IGNORECASE|re.VERBOSE)\n\n# non-src attributes # end of the tag\n\nimage_files = [] for match in image_re.finditer(text):\n\nimage_files.append(match.group(\"qimage\") or\n\nmatch.group(\"uimage\"))\n\nAgain we use the finditer() method to retrieve each match and the match object’s group() function to retrieve the captured texts. Each time a match is made we don’t know which of the image groups (\"qimage\" or \"uimage\") has matched,but using the or operator provides a neat solution for this. Since the case insensitivity applies only to img and src, we could drop the re.IGNORECASE ﬂag and use [Ii][Mm][Gg] and [Ss][Rr][Cc] instead. Although thiswould make the regex less clear, it might make it faster since it would not require the text being matched to be set to upper- (or lower-) case—but it is likely to make a difference only if the regex was being used on a very large amount of text.\n\n501\n\n502\n\nChapter 13. Regular Expressions\n\nTable 13.4 The Regular Expression Module’s Functions\n\nSyntax\n\nDescription\n\nre.compile(\n\nr, f)\n\nReturns compiled regex r with its ﬂags set to f if speciﬁed. (The ﬂags are described in Table 13.5.)\n\nre.escape(s) Returns string s with all nonalphanumeric characters\n\nbackslash-escaped—therefore,the returned string has no special regex characters\n\nre.findall(\n\nr, s, f)\n\nReturns all nonoverlapping matches of regex r in string s (inﬂuenced by the ﬂags f if given).If the regex has captures, each match is returned as a tuple of captures.\n\nre.finditer( r, s, f)\n\nReturns a match object for each nonoverlapping match of regex r in string s (inﬂuenced by the ﬂags f if given)\n\nre.match(\n\nr, s, f)\n\nre.search(\n\nr, s, f)\n\nre.split( r, s, m, f)\n\nReturns a match object if the regex r matches at the start of string s (inﬂuenced by the ﬂags f if given); otherwise, returns None Returns a match object if the regex r matches anywhere otherwise, in string s (inﬂuenced by the ﬂags f if given); returns None Returnsthe list of stringsthat resultsfrom splitting string s on every occurrenceof regex r doing upto m splits(or asmany as possible if no m is given, and for Python 3.1 inﬂuenced by ﬂags f if given).If the regex has captures,these are included in the list between the parts they split.\n\nre.sub(\n\nr, x, s, m, f)\n\nReturns a copy of string s with every (or up to m if given,and for Python 3.1inﬂuenced by ﬂags f if given)match of regex r replaced with x—this can be a string or a function; see text\n\nre.subn(\n\nr, x, s m, f)\n\nThe same as re.sub() except that it returns a 2-tuple of the resultant string and the number of substitutions that were made\n\nTable 13.5 The Regular Expression Module’s Flags\n\nFlag\n\nMeaning\n\nre.A or re.ASCII\n\nMakes \\b, \\B, \\s, \\S, \\w, and \\W assume that stringsare ASCII; the default is for these character class short- hands to depend on the Unicode speciﬁcation\n\nre.I or re.IGNORECASE Makes the regex match case-insensitively\n\nre.M or re.MULTILINE Makes ^ match at the start and after each newline\n\nre.S or re.DOTALL\n\nand $ match before each newline and at the end Makes . match every character including newlines\n\nre.X or re.VERBOSE\n\nAllows whitespace and comments to be included\n\n3.x\n\nThe Regular Expression Module\n\nTable 13.6 Regular Expression Object Methods\n\nSyntax\n\nDescription\n\nrx.findall(s\n\nstart, end)\n\nReturnsallnonoverlapping matchesof theregex instring s (or in the start:end slice of s).If the regex has captures, each match is returned as a tuple of captures.\n\nrx.finditer(s\n\nstart, end)\n\nReturnsa match object for each nonoverlapping match in string s (or in the start:end slice of s)\n\nrx.flags\n\nThe ﬂags that were set when the regex was compiled\n\nrx.groupindex\n\nrx.match(s,\n\nstart, end)\n\nrx.pattern\n\nA dictionary whose keys are capture group names and whose values are group numbers; empty if no names are used Returns a match object if the regex matches at the start of string s (or at the start of the start:end slice of s); otherwise, returns None The string from which the regex was compiled\n\nrx.search(s,\n\nstart, end)\n\nrx.split(s, m)\n\nReturns a match object if the regex matches anywhere in string s (or in the start:end slice of s); otherwise, returns None Returns the list of strings that results from splitting string s on every occurrence of the regex doing up to m splits (or as many as possible if no m is given).If the regex has captures, these are included in the list between the parts they split.\n\nrx.sub(x, s, m) Returns a copy of string s with every (or up to m if given) match replaced with x—this can be a string or a function; see text\n\nrx.subn(x, s m) The same as re.sub() except that it returns a 2-tuple of\n\nthe resultant string and the number of substitutionsthat were made\n\nOne common task is to take an HTML text and output just the plain text that it contains. Naturally we could do this using one of Python’s parsers, but a simple tool can be created using regexes. There are three tasksthat need to be done: delete any tags, replace entities with the characters they represent, and insert blank lines to separate paragraphs. Here is a function (taken from the html2text.py program) that does the job:\n\ndef html2text(html_text):\n\ndef char_from_entity(match):\n\ncode = html.entities.name2codepoint.get(match.group(1), 0xFFFD) return chr(code)\n\n503\n\n504\n\nChapter 13. Regular Expressions\n\ntext = re.sub(r\"<!--(?:.|\\n)*?-->\", \"\", html_text) text = re.sub(r\"<[Pp][^>]*?>\", \"\\n\\n\", text) text = re.sub(r\"<[^>]*?>\", \"\", text) text = re.sub(r\"&#(\\d+);\", lambda m: chr(int(m.group(1))), text) text = re.sub(r\"&([A-Za-z]+);\", char_from_entity, text) text = re.sub(r\"\\n(?:[ \\xA0\\t]+\\n)+\", \"\\n\", text) return re.sub(r\"\\n\\n+\", \"\\n\\n\", text.strip())\n\n#1 #2 #3\n\n#5 #6 #7\n\nThe ﬁrst regex, <!--(?:.|\\n)*?-->, matches HTML comments, including those with other HTML tags nested inside them. The re.sub() function replaces as many matches as it ﬁnds with the replacement—deleting the matches if the replacement is an empty string, as it is here. (We can specify a maximum number of matches by giving an additional integer argument at the end.)\n\nWe are careful to use nongreedy (minimal) matching to ensure that we delete one comment for each match; if we did not do this we would delete from the start of the ﬁrst comment to the end of the last comment.\n\nIn Python 3.0, the re.sub() function does not accept any ﬂags as arguments, and since . means “any character except newline”, we must look for . or \\n. And we must look for these using alternation rather than a character class, since inside a character class . has its literal meaning, that is, period. An alternative would be to begin the regex with the ﬂag embedded, for example, (?s)<!--.*?-->, or we could compile a regex object with the re.DOTALL ﬂag, in which case the regex would simply be <!--.*?-->.\n\nFrom Python 3.1, re.split(), re.sub(), and re.subn(), can all accept a ﬂags argument, so we could simply use <!--.*?--> and pass the re.DOTALL ﬂag.\n\nThe second regex, <[Pp][^>]*?>, matches opening paragraph tags (such as <P> or <p align=\"center\">). It matches the opening <p (or <P), then any attributes (using nongreedy matching), and ﬁnally the closing >. The second call to the re.sub() function uses this regex to replace opening paragraph tags with two newline characters (the standard way to delimit a paragraph in a plain text ﬁle).\n\nThe third regex,<[^>]*?>,matchesany tag and isused in thethird re.sub() call to delete all the remaining tags.\n\nHTML entities are a way of specifying non-ASCII characters using ASCII characters. They come in two forms: &name; where name is the name of the character—for example, &copy; for ©—and &#digits; where digits are deci- mal digits identifying the Unicode code point—for example, &#165; for ¥. The fourth call to re.sub() uses the regex &#(\\d+);, which matches the digits form and captures the digits into capture group 1. Instead of a literal replacement text we have passed a lambda function. When a function is passed to re.sub() it callsthefunction oncefor each timeit matches,passing thematch object asthe function’ssole argument. Inside the lambda function we retrieve the digits(asa\n\n3.0\n\n3.1\n\nThe Regular Expression Module\n\nstring),convert to an integer using the built-in int() function,and then use the built-in chr() function to obtain the Unicode character for the given code point. The function’s return value (or in the case of a lambda expression, the result of the expression) is used as the replacement text.\n\nThe ﬁfth re.sub() call uses the regex &([A-Za-z]+); to capture named entities. The standard library’s html.entities module contains dictionaries of entities, including name2codepoint whosekeysareentity namesand whosevaluesarein- teger codepoints. The re.sub() function callsthelocal char_from_entity() func- tionevery timeit hasa match. The char_from_entity() functionusesdict.get() with a default argument of 0xFFFD (the code point of the standard Unicode replacement character—often depicted as ?). This ensures that a code point is always retrieved and it is used with the chr() function to return a suitable character to replace the named entity with—using the Unicode replacement character if the entity name is invalid.\n\nThe sixth re.sub() call’s regex, \\n(?:[ \\xA0\\t]+\\n)+, is used to delete lines that contain only whitespace. The character class we have used contains a space, a nonbreaking space (which &nbsp; entities are replaced with in the preceding regex), and a tab. The regex matches a newline (the one at the end of a line that precedes one or more whitespace-only lines), then at least one (and as many aspossible)linesthat containonly whitespace. Sincethematchincludes the newline,from the line preceding the whitespace-only lineswe must replace the match with a single newline; otherwise, we would delete not just the whitespace-only lines but also the newline of the line that preceded them.\n\nThe result of the seventh and last re.sub() call is returned to the caller. This regex, \\n\\n+, is used to replace sequences of two or more newlines with exactly two newlines, that is, to ensure that each paragraph is separated by just one blank line.\n\nIn the HTML example none of the replacements were directly taken from the match (although HTML entity names and numbers were used), but in some situations the replacement might need to include all or some of the matching text. For example, if we have a list of names, each of the form Forename Mid- dlename1…MiddlenameN Surname, where there may be any number of mid- dle names (including none), and we want to produce a new version of the list witheachitemof theformSurname,ForenameMiddlename1…MiddlenameN, we can easily do so using a regex:\n\nnew_names = [] for name in names:\n\nname = re.sub(r\"(\\w+(?:\\s+\\w+)*)\\s+(\\w+)\", r\"\\2, \\1\", name) new_names.append(name)\n\nThe ﬁrst part of the regex, (\\w+(?:\\s+\\w+)*), matches the forename with the ﬁrst \\w+ expression and zero or more middle names with the (?:\\s+\\w+)* ex-\n\n505\n\n506\n\nChapter 13. Regular Expressions\n\npression. The middle name expression matches zero or more occurrences of whitespace followed by a word. The second part of the regex, \\s+(\\w+), match- es the whitespace that follows the forename (and middle names) and the surname.\n\nIf the regex looks a bit too much like line noise, we can use named capture groups to improve legibility and make it more maintainable:\n\nname = re.sub(r\"(?P<forenames>\\w+(?:\\s+\\w+)*)\"\n\nr\"\\s+(?P<surname>\\w+)\", r\"\\g<surname>, \\g<forenames>\", name)\n\nCaptured text can be referred to in a sub() or subn() function or method by using the syntax \\i or \\g<id> where i is the number of the capture group and id is the name or number of the capture group—so \\1 is the same as \\g<1>, and in this example, the same as \\g<forenames>.This syntax can also be used in the string passed to a match object’s expand() method.\n\nWhy doesn’t the ﬁrst part of the regex grab the entire name? After all, it is using greedy matching. In fact it will, but then the match will fail because although the middle names part can match zero or more times, the surname part must match exactly once, but the greedy middle names part has grabbed everything. Having failed, the regular expression engine will then backtrack, giving up the last “middle name” and thus allowing the surname to match. Although greedy matches match as much as possible, they stop if matching more would make the match fail.\n\nFor example,if thenameis“JohnleCarré”,theregex willﬁrstmatchtheentire name, that is, John le Carré.This satisﬁes the ﬁrst part of the regex but leaves nothing for the surname part to match,and since the surnameismandatory (it has an implicit quantiﬁer of 1), the regex has failed. Since the middle names part isquantiﬁedby *,it can matchzeroor moretimes(currently it ismatching twice,“ le” and “ Carré”),so the regular expression engine can make it give up some of its match without causing it to fail. Therefore, the regex backtracks, giving up the last \\s+\\w+ (i.e., “ Carré”), so the match becomes John le Carré with the match satisfying the whole regex and with the two match groups containing the correct texts.\n\nThere’s one weakness in the regex as written: It doesn’t cope correctly with forenames that are written using an initial, such as “James W. Loewen”, or “J.R.R.Tolkein”.Thisisbecause\\w matcheswordcharactersandthesedon’tin- clude period. One obvious—but incorrect—solutionisto change the forenames part of theregex’s\\w+ expressionto [\\w.]+,in both placesthat it occurs. A peri- od in a character class is taken to be a literal period,and character class short- hands retain their meaning inside character classes, so the new expression matches word characters or periods. But this would allow for names like “.”, “..”, “.A”, “.A.”, and so on. In view of this, a more subtle approach is required.\n\nThe Regular Expression Module\n\nTable 13.7 Match Object Attributes and Methods\n\nSyntax\n\nDescription\n\nm.end(g)\n\nReturns the end position of the match in the text for group g if given (or for group 0, the whole match); returns -1 if the group did not participate in the match\n\nm.endpos\n\nm.expand(s)\n\nThe search’send position (the end of the text or the end given to match() or search()) Returns string s with capture markers (\\1, \\2, \\g<name>, and similar) replaced by the corresponding captures\n\nm.group(g,\n\n...)\n\nReturns the numbered or named capture group g; if more than one is given a tuple of corresponding capture groups is returned (the whole match is group 0)\n\nm.groupdict( default)\n\nReturns a dictionary of all the named capture groups with the names as keys and the captures as values; if a default is given this is the value used for capture groups that did not participate in the match\n\nm.groups(\n\ndefault)\n\nReturnsa tuple of all the capture groupsstarting from 1;if a default is given this is the value used for capture groupsthat did not participate in the match\n\nm.lastgroup\n\nm.lastindex\n\nm.pos\n\nThe name of the highest numbered capturing group that matched or None if there isn’t one or if no names are used The number of the highest capturing group that matched or None if there isn’t one The start position to look from (the start of the text or the start given to match() or search())\n\nm.re\n\nThe regex object which produced this match object\n\nm.span(g)\n\nReturns the start and end positions of the match in the text for group g if given (or for group 0,the whole match);returns (-1, -1) if the group did not participate in the match\n\nm.start(g)\n\nReturns the start position of the match in the text for group g if given (or for group 0, the whole match); returns -1 if the group did not participate in the match\n\nm.string\n\nThe string that was passed to match() or search()\n\nname = re.sub(r\"(?P<forenames>\\w+\\.?(?:\\s+\\w+\\.?)*)\" r\"\\s+(?P<surname>\\w+)\", r\"\\g<surname>, \\g<forenames>\", name)\n\nHere we have changed the forenamespart of the regex (the ﬁrst line).The ﬁrst part of the forenames regex matches one or more word characters optionally followed by a period. The second part matches at least one whitespace charac-\n\n507\n\nCon- ditional match- ing 498➤\n\n508\n\nChapter 13. Regular Expressions\n\nter, then one or more word characters optionally followed by a period,with the whole of this second part itself matching zero or more times.\n\nWhen we use alternation (|) with two or more alternatives capturing,we don’t know which alternative matched, so we don’t know which capture group to retrieve the captured text from. We can of course iterate over all the groups to ﬁnd the nonempty one, but quite often in this situation the match object’s lastindex attribute can give us the number of the group we want. We will look at one last example to illustrate this and to give us a little bit more regex practice.\n\nSuppose we want to ﬁnd out what encoding an HTML, XML, or Python ﬁle is using. We could open the ﬁle in binary mode,and read,say,the ﬁrst 1000bytes into a bytes object. We could then close the ﬁle, look for an encoding in the bytes, and reopen the ﬁle in text mode using the encoding we found or using a fallback encoding (such as UTF-8). The regex engine expects regexes to be supplied as strings, but the text the regex is applied to can be a str, bytes, or bytearray object,and when bytes or bytearray objectsare used,all the functions and methods return bytes instead of strings,and the re.ASCII ﬂag is implicitly switched on.\n\nFor HTML ﬁles the encoding is normally speciﬁed in a <meta> tag (if speci- ﬁed at all), for example, <meta http-equiv='Content-Type' content='text/html; charset=ISO-8859-1'/>. XML ﬁles are UTF-8 by default, but this can be over- ridden, for example, <?xml version=\"1.0\" encoding=\"Shift_JIS\"?>. Python 3 ﬁles are also UTF-8 by default,but again this can be overridden by including a line such as # encoding: latin1 or # -*- coding: latin1 -*- immediately after the shebang line.\n\nHere is how we would ﬁnd the encoding,assuming that the variable binary is a bytes object containing the ﬁrst 1000 bytes of an HTML, XML, or Python ﬁle:\n\nmatch = re.search(r\"\"\"(?<![-\\w])\n\n(?:(?:en)?coding|charset) (?:=([\"'])?([-\\w]+)(?(1)\\1) |:\\s*([-\\w]+))\"\"\".encode(\"utf8\"),\n\n#1 #2 #3\n\nbinary, re.IGNORECASE|re.VERBOSE)\n\nencoding = match.group(match.lastindex) if match else b\"utf8\"\n\nTo search a bytes object we must specify a pattern that is also a bytes object. In this case we want the convenience of using a raw string, so we use one and convert it to a bytes object as the re.search() function’s ﬁrst argument.\n\nThe ﬁrst part of the regex itself is a lookbehind assertion that says that the match cannot be preceded by a hyphen or a word character. The second part matches “encoding”, “coding”, or “charset” and could have been written as (?:encoding|coding|charset). We have made the third part span two lines to emphasise the fact that it has two alternating parts, =([\"'])?([-\\w]+)(?(1)\\1)\n\nThe Regular Expression Module\n\nand :\\s*([-\\w]+), only one of which can match. The ﬁrst of these matches an equals sign followed by one or more word or hyphen characters (optionally en- closed in matching quotes using a conditional match),and the second matches a colon and then optional whitespace followed by one or more word or hyphen characters. (Recallthatahypheninsideacharacterclassistakentobealiteral hyphen if it isthe ﬁrst character;otherwise,it meansa range of characters,for example, [0-9].)\n\nWe have used the re.IGNORECASE ﬂag to avoid having to write (?:(?:[Ee][Nn])? [Cc][Oo][Dd][Ii][Nn][Gg]|[Cc][Hh][Aa][Rr][Ss][Ee][Tt]) and we have used the re.VERBOSE ﬂag so that we can lay out the regex neatly and include comments (in this case just numbers to make the parts easy to refer to in this text).\n\nThere are three capturing match groups, all in the third part: ([\"'])? which captures the optional opening quote, ([-\\w]+) which captures an encoding that follows an equals sign, and the second ([-\\w]+) (on the following line) that captures an encoding that follows a colon. We are only interested in the encoding, so we want to retrieve either the second or third capture group, only one of which can match since they are alternatives. The lastindex attribute holds the index of the last matching capture group (either 2 or 3 when a match occurs in this example), so we retrieve whichever matched, or use a default encoding if no match was made.\n\nWe have now seen all of the most frequently used re module functionality in action, so we will conclude this section by mentioning one last function. The re.split() function (or the regex object’s split() method) can split strings based on a regex. One common requirement is to split a text on whitespace to get a list of words. This can be done using re.split(r\"\\s+\", text) which re- turns a list of words (or more precisely a list of strings, each of which match- es \\S+). Regular expressions are very powerful and useful, and once they are learned, it is easy to see all text problems as requiring a regex solution. But sometimes using string methods is both sufﬁcient and more appropriate. For example, we can just as easily split on whitespace by using text.split() since the str.split() method’s default behavior (or with a ﬁrst argument of None) is to split on \\s+.\n\nSummary\n\nRegular expressions offer a powerful way of searching texts for strings that match a particular pattern, and for replacing such strings with other strings which themselves can depend on what was matched.\n\nIn this chapter we saw that most characters are matched literally and are implicitly quantiﬁed by {1}. We also learned how to specify character classes—setsof charactersto match—and how to negate such sets and include\n\n509\n\n|||",
      "page_number": 483
    },
    {
      "number": 51,
      "title": "Segment 51 (pages 496-507)",
      "start_page": 496,
      "end_page": 507,
      "detection_method": "topic_boundary",
      "content": "510\n\nChapter 13. Regular Expressions\n\nranges of characters in them without having to write each character individu- ally.\n\nWe learned how to quantify expressions to match a speciﬁc number of times or to match from a given minimum to a given maximum number of times, and how to use greedy and nongreedy matching. We also learned how to group one or more expressions together so that they can be quantiﬁed (and optionally captured) as a unit.\n\nThe chapter also showed how what ismatched can be affected by using various assertions, such as positive and negative lookahead and lookbehind, and by various ﬂags, for example, to control the interpretation of the period and whether to use case-insensitive matching.\n\nTheﬁnalsectionshowedhowtoput regexestousewithinthecontextof Python programs. In this section we learned how to use the functions provided by the re module, and the methods available from compiled regexes and from match objects. We also learned how to replace matches with literal strings, with literal strings that contain backreferences, and with the results of function calls or lambda expressions, and how to make regexes more maintainable by using named captures and comments.\n\nExercises\n\n1. In many contexts (e.g., in some web forms), users must enter a phone number, and some of these irritate users by accepting only a speciﬁc for- mat. Write a program that reads U.S.phone numbers with the three-digit area and seven-digit local codes accepted as ten digits, or separated into blocksusing hyphensor spaces,and with thearea codeoptionally enclosed in parentheses. For example, all of these are valid: 555-123-1234, (555) 1234567, (555) 123 1234, and 5551234567. Read the phone numbers from sys.stdin and for each one echo the number in the form “(999) 999 9999” or report an error for any that are invalid, or that don’t have exactly ten digits. The regex to match these phone numbers is about ten lines long (in ver- bosemode)andisquitestraightforward. A solutionisprovidedin phone.py, which is about twenty-ﬁve lines long.\n\n2. Write a small program that reads an XML or HTML ﬁle speciﬁed on the command line and for each tag that has attributes, outputs the name of the tag with its attributes shown underneath. For example, here is an ex- tract from the program’soutput when given one of the Python documenta- tion’s index.html ﬁles: html xmlns = http://www.w3.org/1999/xhtml\n\n|||\n\nExercises\n\nmeta http-equiv = Content-Type content = text/html; charset=utf-8 li class = right style = margin-right: 10px\n\nOne approach is to use two regexes, one to capture tags with their at- tributes and another to extract the name and value of each attribute. At- tributevaluesmightbequotedusing singleor doublequotes(inwhichcase they may contain whitespace and the quotes that are not used to enclose them),or they may be unquoted (in which case they cannot contain white- spaceor quotes).Itisprobably easiesttostartby creating a regex tohandle quoted and unquoted valuesseparately,and then merging the two regexes into a single regex to cover both cases. It is best to use named groups to make the regex more readable. This is not easy, especially since backref- erences cannot be used inside character classes.\n\nA solution is provided in extract_tags.py, which is less than 35 lines long. The tag and attributes regex is just one line. The attribute name–value regex is half a dozen lines and uses alternation, conditional matching (twice, with one nested inside the other), and both greedy and nongreedy quantiﬁers.\n\n511\n\nFile for- mats 219➤\n\nDynam- ic code execu- tion 344➤\n\n14 ● BNF Syntax and Parsing\n\nTerminology\n\nWriting Handcrafted Parsers ● Pythonic Parsing with PyParsing ● Lex/Yacc-Style Parsing with PLY\n\nIntroduction to Parsing\n\n||||\n\nParsing is a fundamental activity in many programs, and for all but the most trivial cases, it is a challenging topic. Parsing is often done when we need to read data that is stored in a custom format so that we can process it or per- form queries on it. Or we may be required to parse a DSL (Domain-Speciﬁc Language)—these are mini task-speciﬁc languages that appear to be growing in popularity. Whether we need to read data in a custom format or code writ- ten using a DSL, we will need to create a suitable parser. This can be done by handcrafting, or by using one of Python’s generic parsing modules.\n\nPython can be used to write parsers using any of the standard computer science techniques:using regexes,using ﬁnite state automata,using recursive descent parsers, and so on. All of these approaches can work quite well, but for data or DSLs that are complex—for example, recursively structured and featuring operators that have different precedences and associativities—they can be challenging to get right. Also, if we need to parse many different data formatsor DSLs,handcrafting each parser can be time-consuming and tedious to maintain.\n\nFortunately, for some data formats, we don’t have to write a parser at all. For example,when it comesto parsing XML,Python’sstandard library comeswith DOM, SAX, and element tree parsers, with other XML parsers available as third-party add-ons.\n\nIn fact, Python has built-in support for reading and writing a wide range of data formats, including delimiter-separated data with the csv module, Windows-style .ini ﬁles with the configparser module, JSON data with the json module, and also a few others, as mentioned in Chapter 5. Python does not provide any built-in support for parsing other languages, although it does the shlex module which can be used to create a lexer for Unix shell- provide like mini-languages (DSLs), and the tokenize module that provides a lexer for Python source code. And of course, Python can execute Python code using the built-in eval() and exec() functions.\n\n513\n\n514\n\nChapter 14. Introduction to Parsing\n\nIn general, if Python already has a suitable parser in the standard library, or as a third-party add-on, it is usually best to use it rather than to write our own.\n\nWhen it comes to parsing data formats or DSLs for which no parser is avail- able, rather than handcrafting a parser, we can use one of Python’s third-par- ty general-purpose parsing modules. In this chapter we will introduce two of the most popular third-party parsers. One of these is Paul McGuire’s PyPars- ing module, which takes a unique and very Pythonic approach. The other is David Beazley’sPLY (Python Lex Yacc),which isclosely modeled on the classic Unix lex and yacc tools, and that makes extensive use of regexes. Many other parsers are available, with many listed at www.dabeaz.com/ply (at the bottom of the page), and of course, in the Python Package Index, pypi.python.org/pypi.\n\nThis chapter’s ﬁrst section provides a brief introduction to the standard BNF (Backus–Naur Form) syntax used to describe the grammars of data formats and DSLs. In that section we will also explain the basic terminology. The remaining sections all cover parsing itself, with the second section covering handcrafted parsers, using regexes, and using recursive descent, as a natural follow-on from the regular expressions chapter. The third section introduces the PyParsing module. The initial examples are the same as those for which handcrafted parsers are created in the second section—this is to help learn the PyParsing approach, and also to provide the opportunity to compare and contrast. The section’s last example has a more ambitious grammar and is new in this section. The last section introduces the PLY module, and shows thesameexamplesweused in thePyParsing section,again for easeof learning and to provide a basis for comparison.\n\nNote that with one exception, the handcrafted parsers section is where each data format and DSL is described, its BNF given, and an example of the data or DSL shown, with the other sections providing backreferences to these where appropriate. The exception is the ﬁrst-order logic parser whose details are given in the PyParsing section, with corresponding backreferences in the PLY section.\n\nBNF Syntax and Parsing Terminology\n\nParsing is a means of transforming data that is in some structured format—whether the data representsactual data,or statementsin a program- ming language, or some mixture of both—into a representation that reﬂects the data’s structure and that can be used to infer the meaning that the data represents. The parsing process is most often done in two phases:lexing (also called lexicalanalysis,tokenizing,or scanning),and parsing proper (alsocalled syntactic analysis).\n\n|||\n\nBNF Syntax and Parsing Terminology\n\nFor example, given a sentence in the English language, such as “the dog barked”, we might transform the sentence into a sequence of (part-of-speech– word) 2-tuples, ((DEFINITE_ARTICLE, \"the\"), (NOUN, \"dog\"), (VERB, \"barked\")). We would then perform syntactic analysis to see if this is a valid English sen- tence. In this case it is, but our parser would have to reject, say, “the barked dog”.★\n\nThe lexing phase is used to convert the data into a stream of tokens. In typical cases,each token holds at least two pieces of information:the token’s type (the kind of data or language construct being represented), and the token’s value (which may be empty if the type stands for itself—for example, a keyword in a programming language).\n\nThe parsing phase is where a parser reads each token and performs some se- mantic action. The parser operates according to a predeﬁned set of grammar rules that deﬁne the syntax that the data is expected to follow. (If the data doesn’t follow the syntax rules the parser will correctly fail.) In multiphase parsers,the semantic action consistsof building up an internal representation of the input in memory (called an Abstract Syntax Tree—AST), which serves as input to the next phase. Once the AST has been constructed, it can be tra- versed, for example, to query the data, or to write the data out in a different format, or to perform computations that correspond to the meanings encoded in the data.\n\nData formats and DSLs (and programming languages generally) can be de- scribedusing agrammar—asetof syntaxrulesthatdeﬁnewhatisvalidsyntax for the data or language. Of course, just because a statement is syntactically valid doesn’t mean that it makes sense—for example, “the cat ate democracy” is syntactically valid English, but meaningless. Nonetheless,being able to de- ﬁne the grammar is very useful,so much so that there is a commonly used syn- tax for describing grammars—BNF (Backus–Naur Form). Creating a BNF is the ﬁrst step to creating a parser, and although not formally necessary, for all but the most trivial grammars it should be considered essential.\n\nHere we will describe a very simple subset of BNF syntax that is sufﬁcient for our needs.\n\nIn a BNF there are two kindsof item:terminalsand nonterminals. A terminal is an item which is in its ﬁnal form, for example, a literal number or string. A nonterminal is an item that is deﬁned in terms of zero or more other items (which themselves may be terminals or nonterminals). Every nonterminal must ultimately be deﬁned in terms of zero or more terminals. Figure 14.1 shows an example BNF that deﬁnes the syntax of a ﬁle of “attributes”, to put things into perspective.\n\n★In practice, parsing English and other natural languages is a very difﬁcult problem; see, for example, the Natural Language Toolkit (www.nltk.org) for more information.\n\n515\n\n516\n\nChapter 14. Introduction to Parsing\n\nATTRIBUTE_FILE ::= (ATTRIBUTE '\\n')+ ATTRIBUTE ::= NAME '=' VALUE NAME ::= [a-zA-Z]\\w* VALUE ::= 'true' | 'false' | \\d+ | [a-zA-Z]\\w*\n\nFigure 14.1 A BNF for a ﬁle of attributes\n\nThe symbol ::= means is deﬁned as. Nonterminals are written in uppercase italics (e.g., VALUE).Terminals are either literal strings enclosed in quotes (such as '=' and 'true') or regular expressions (such as \\d+). The deﬁnitions (on the right of the ::=) are made up of one or more terminals or nonterminals—these must be encountered in the sequence given to meet the deﬁnition. However, the vertical bar (|) is used to indicate alternatives, so instead of matching in sequence, matching any one of the alternatives is sufﬁcient to meet the deﬁ- nition. Terminals and nonterminals can be quantiﬁed with ? (zero or one, i.e., optional),+ (oneor more),or * (zeroor more);withoutanexplicitquantiﬁerthey arequantiﬁedtomatchexactly once. Parenthesescanbeusedfor grouping two or more terminalsor nonterminalsthat we want to treat asa unit,for example, to group alternatives or for quantiﬁcation.\n\nA BNF always has a “start symbol”—this is the nonterminal that must be matched by the entire input. We have adopted the convention that the ﬁrst nonterminal is always the start symbol.\n\nIn this example there are four nonterminals,ATTRIBUTE_FILE (the start symbol), ATTRIBUTE, NAME, and VALUE. An ATTRIBUTE_FILE is deﬁned as one or more of an ATTRIBUTE followed by a newline. An ATTRIBUTE is deﬁned as a NAME followed by a literal = (i.e., a terminal), followed by a VALUE. Since both the NAME and VALUE parts are nonterminals, they must themselves be deﬁned. The NAME is deﬁned by a regular expression (i.e., a terminal). The VALUE is deﬁned by any of four alternatives, two literals and two regular expressions (all of which are terminals).Since all the nonterminals are deﬁned in terms of terminals (or in terms of nonterminals which themselves are ultimately deﬁned in terms of terminals), the BNF is complete.\n\nThere is generally more than one way to write a BNF. Figure 14.2 shows an alternative version of the ATTRIBUTE_FILE BNF.\n\nATTRIBUTE_FILE ::= ATTRIBUTE+ ATTRIBUTE ::= NAME '=' VALUE '\\n' NAME ::= [a-zA-Z]\\w* VALUE ::= 'true' | 'false' | \\d+ | NAME\n\nFigure 14.2 An alternativeBNF for a ﬁle of attributes\n\nBNF Syntax and Parsing Terminology\n\nHere we have moved the newline to the end of the ATTRIBUTE nonterminal, thus simplifying the deﬁnition of ATTRIBUTE_FILE.We have also reused the NAME nonterminal in the VALUE—although this is a dubious change since it is mere coincidence that they can both match the same regex. Thisversion of the BNF should match exactly the same text as the ﬁrst one.\n\nOnce we have a BNF we can “test” it mentally or on paper. For example,given thetext“depth = 37\\n”,wecanwork throughtheBNFtoseeif thetextmatch- es,starting withtheﬁrstnonterminal,ATTRIBUTE_FILE.Thisnonterminalbegins by matching another nonterminal, ATTRIBUTE. And the ATTRIBUTE nonterminal begins by matching yet another nonterminal, NAME, which in turn must match the terminal regex, [a-zA-Z]\\w*. The regex does indeed match the beginning of the text, matching “depth”. The next thing that ATTRIBUTE must match is a terminal,theliteral =.And herethematch failsbecause“depth”isfollowedby a space. At thispoint theparser should reportthat thegiven text doesnot match thegrammar. Inthisparticularcasewemusteither ﬁx thedataby eliminating the space before and after the =, or opt to change the grammar—for example, changing the (ﬁrst) deﬁnition of ATTRIBUTE to NAME \\s* = \\s* VALUE. After doing a few paper tests and reﬁning the grammar like this we should have a much clearer idea of what our BNF will and won’t match.\n\nA BNF must be complete to be valid, but a valid BNF is not necessarily a correct one. One problem is with ambiguity—in the example shown here the literal value true matches the VALUE nonterminal’s ﬁrst alternative ('true'), and also itslast alternative([a-zA-Z]\\w*).Thisdoesn’t stopthe BNF frombeing valid, but it is something that a parser implementing the BNF must account for. And aswewill seelater in thischapter,BNFscan becomequitetricky since sometimeswedeﬁnethingsin termsof themselves. Thiscanbeanother source of ambiguity—and can result in unparseable grammars.\n\nPrecedence and associativity are used to decide the order in which operators should be applied in expressions that don’t have parentheses. Precedence is used when there are different operators, and associativity is used when the operators are the same.\n\nFor an example of precedence, the Python expression 3 + 4 * 5 evaluates to 23. This means that * has higher precedence in Python than + because the expression behaved as if it were written 3 + (4 * 5).Another way of saying this is “in Python, * binds more tightly than +”.\n\nFor an example of associativity, the expression 12 / 3 / 2 evaluates to 2. This means that / is left-associative, that is, when an expression contains two or more /s they will be evaluated from left to right. Here, 12 / 3 was evaluated ﬁrst to produce 4 and then 4 / 2 to produce 2. By contrast, the = operator is right-associative, which is why we can write x = y = 5. When there are two or more =s they are evaluated from right to left, so y = 5 is evaluated ﬁrst, giving y a value, and then x = y giving x a value. If = was not right-associative the\n\n517\n\n518\n\nChapter 14. Introduction to Parsing\n\nexpression would fail (assuming that y didn’t exist before) since it would start by trying to assign the value of nonexistent variable y to x.\n\nPrecedence and associativity can sometimes work together. For example, if two different operators have the same precedence (this is commonly the case with + and -), without the use of parentheses, their associativities are all that can be used to determine the evaluation order.\n\nExpressing precedence and associativity in a BNF can be done by composing factors into terms and terms into expressions. For example, the BNF in Figure 14.3 deﬁnes the four basic arithmetic operations over integers, as well asparenthesizedsubexpressions,and all with thecorrect precedencesand (left to right) associativities.\n\nINTEGER ::= \\d+ ADD_OPERATOR ::= '+' | '-' SCALE_OPERATOR ::= '*' | '/' EXPRESSION ::= TERM (ADD_OPERATOR TERM)* TERM ::= FACTOR (SCALE_OPERATOR FACTOR)* FACTOR ::= '-'? (INTEGER | '(' EXPRESSION ')')\n\nFigure 14.3 A BNF for arithmetic operations\n\nThe precedence relationships are set up by the way we combine expressions, terms, and factors,while the associativities are set up by the structure of each of the expression, term, and factor’s nonterminals’ deﬁnitions.\n\nIf we need right to left associativity, we can use the following structure:\n\nPOWER_EXPRESSION ::= FACTOR ('**' POWER_EXPRESSION)*\n\nThe recursive use of POWER_EXPRESSION forces the parser to work right to left.\n\nDealing with precedence and associativity can be avoided altogether: We can simply insist that the data or DSL uses parentheses to make all the relation- shipsexplicit. Although thisis easy to do,it isn’t doing any favorsfor the users of our data format or of our DSL, so we prefer to incorporate precedence and associativity where they are appropriate.★\n\nThere is a lot more to parsing than we have mentioned here—see,for example, the book Parsing Techniques:APracticalGuide,mentioned in thebibliography. Nonetheless,thischaptershouldbesufﬁcienttogetstarted,althoughaddition- al reading is recommended for those planning to create complex and sophisti- cated parsers.\n\n★Another way to avoid precedence and associativity—and which doesn’t require parentheses—is to use a Polish or Reverse Polish notation; see wikipedia.org/wiki/Polish_notation.\n\nBNF\n\nBNF Syntax and Parsing Terminology\n\nNow that we have a passing familiarity with BNF syntax and with some of the terminology used in parsing,we will writesome parsers,starting with ones written by hand.\n\nWriting Handcrafted Parsers\n\nIn this section we will develop three handcrafted parsers. The ﬁrst is little more than an extension of the key–value regex seen in the previous chapter, but shows the infrastructure needed to use such a regex. The second is also regex-based, but is actually a ﬁnite state automata since it has two states. Both the ﬁrst and second examples are data parsers. The third example is a parser for a DSL and uses recursive descent since the DSL allows expressions to be nested. In later sections we will develop new versions of these parsers using PyParsing and PLY, and for the DSL in particular we will see how much easier it is to use a generic parser generator than to handcraft a parser.\n\nSimple Key–Value Data Parsing\n\nprogram can The book’s examples include a program called playlists.py. This read a playlist in .m3u (extended Moving Picture Experts Group Audio Layer 3 Uniform Resource Locator) format,and output an equivalent playlist in .pls (Play List 2) format—or vice versa. In this subsection we will write a parser for .pls format, and in the following subsection we will write a parser for .m3u format. Both parsers are handcrafted and both use regexes.\n\nThe .pls format is essentially the same as Windows .ini format, so we ought to use thestandardlibrary’sconfigparser moduleto parseit. However,the .pls format is ideal for creating a ﬁrst data parser,since itssimplicity leavesusfree to focus on the parsing aspects, so for the sake of example we won’t use the configparser module in this case.\n\nWe will begin by looking at a tiny extract from a .pls ﬁle to get a feel for the data, then we will create a BNF, and then we will create a parser to read the data. The extract is shown in Figure 14.4.\n\nWe have omitted most of the data as indicated by the ellipsis (…). There is only one .ini-style header line, [playlist], with all the other entries in simple key=value format. One unusual aspect is that key names are repeated—but with numbers appended to keep them all unique. Three pieces of data are maintained for each song: the ﬁlename (in this example using Windows path separators), the title, and the duration (called “length”) in seconds. In this particular example, the ﬁrst song has a known duration, but the last entry’s duration is unknown, which is signiﬁed by a negative number.\n\n519\n\n|||\n\n||\n\nPyPars- ing key– value parser ➤ 539\n\nPLY key– value parser ➤ 555\n\nAt- tributes BNF 516➤\n\n520\n\nChapter 14. Introduction to Parsing\n\n[playlist] File1=Blondie\\Atomic\\01-Atomic.ogg Title1=Blondie - Atomic Length1=230 ... File18=Blondie\\Atomic\\18-I'm Gonna Love You Too.ogg Title18=Blondie - I'm Gonna Love You Too Length18=-1 NumberOfEntries=18 Version=2\n\nFigure 14.4 An extract from a .pls ﬁle\n\nThe BNF we have created can handle .pls ﬁles,and is actually generic enough to handle similar key–value formats too. The BNF is shown in Figure 14.5.\n\nPLS ::= (LINE '\\n')+ LINE ::= INI_HEADER | KEY_VALUE | COMMENT | BLANK INI_HEADER ::= '[' [^]]+ ']' KEY_VALUE ::= KEY \\s* '=' \\s* VALUE? KEY ::= \\w+ VALUE ::= .+ COMMENT ::= #.* BLANK ::= ^$\n\nFigure 14.5 A BNF for the .pls ﬁle format\n\nThe BNF deﬁnes a PLS as one or more of a LINE followed by newline. Each LINE canbean INI_HEADER,a KEY_VALUE,a COMMENT,or BLANK.The INI_HEADER isdeﬁnedto beanopenbracket,followedby oneor morecharacters(excluding a closebrack- et),followed by a close bracket—we will skip these. The KEY_VALUE is subtly dif- ferent from the ATTRIBUTE in the ATTRIBUTE_FILE example shown in the previous section in that the VALUE is optional; also, here we allow whitespace before and after the =. This means that a line such as “title5=\\n” is valid in this BNF, as well as the ones that we would expect to be valid such as “length=126\\n”.The KEY is a sequence of one or more alphanumeric characters,and the VALUE is any sequence of characters. Comments are Python-style and we will skip them; similarly, blank lines (BLANK) are allowed but will be skipped.\n\nThe purpose of our parser is to populate a dictionary with key–value items matching those in the ﬁle, but with lowercase keys. The playlists.py program uses the parser to obtain a dictionary of playlist data which it then outputs in the requested format. We won’t cover the playlists.py program itself since it\n\nKey– value regex 495➤\n\nenu- merate() function 139➤\n\nWriting Handcrafted Parsers\n\nisn’t relevant to parsing assuch,and in any case it can be downloaded from the book’s web site.\n\nThe parsing is done in a single function that accepts an open ﬁle object (file), and a Boolean (lowercase_keys) that has a default value of False. The function uses two regexes and populates a dictionary (key_values) that it returns. We will look at the regexes and then the code that parses the ﬁle’s lines and that populates the dictionary.\n\nINI_HEADER = re.compile(r\"^\\[[^]]+\\]$\")\n\nAlthough we want to ignore .ini headers we still need to identify them. The regex makes no allowance for leading or trailing whitespace—this is because we will be stripping whitespace from each line that is read so there will never be any. The regex itself matches the start of the line, then an open bracket, then one or more characters (but not close brackets), then a close bracket, and ﬁnally, the end of the line.\n\nKEY_VALUE_RE = re.compile(r\"^(?P<key>\\w+)\\s*=\\s*(?P<value>.*)$\")\n\nbut we only The KEY_VALUE_RE regex allows for whitespace around the = sign, capture the actual key and value. The value is quantiﬁed by * so can be empty. Also, we use named captures since these are clearer to read and easier to maintain because they are not affected by new capture groups being added or removed—something that would affect us if we used numbers to identify the capture groups.\n\nkey_values = {} for lino, line in enumerate(file, start=1):\n\nline = line.strip() if not line or line.startswith(\"#\"):\n\ncontinue\n\nkey_value = KEY_VALUE_RE.match(line) if key_value:\n\nkey = key_value.group(\"key\") if lowercase_keys:\n\nkey = key.lower()\n\nkey_values[key] = key_value.group(\"value\")\n\nelse:\n\nini_header = INI_HEADER.match(line) if not ini_header:\n\nprint(\"Failed to parse line {0}: {1}\".format(lino,\n\nline))\n\nWe process the ﬁle’s contents line by line, using the built-in enumerate() function to return 2-tuplesof the line number (starting from 1as is traditional whendealing with textﬁles),andthelineitself. Westripoff whitespacesothat\n\n521\n\n522\n\nChapter 14. Introduction to Parsing\n\nwecan immediately skipblank lines(and useslightly simpler regexes);wealso skip comment lines.\n\nSince we expect most lines to be key=value lines, we always try to match the KEY_VALUE_RE regex ﬁrst. If this succeedswe extract the key,and lowercase it if necessary. Then we add the key and the value to the dictionary.\n\nIf the line is not a key=value line, we try to match a .ini header—and if we get a match we simply ignore it and continue to the next line; otherwise we report an error. (It would be quite straightforward to create a dictionary whose keys are .ini headers and whose values are dictionaries of the headers’ key–values—but if we want to go that far, we really ought to use the config- parser module.)\n\nThe regexes and the code are quite straightforward—but they are dependent on each other. For example, if we didn’t strip whitespace from each line we would have to change the regexes to allow for leading and trailing whitespace. Here we found it more convenient to strip the whitespace, but there may be occasions where we do things the other way round—there is no one single correct approach.\n\nAt the end (not shown), we simply return the key_values dictionary. One dis- advantage of using a dictionary in this particular case is that every key–value pair is distinct, whereas in fact, items with keys that end in the same number (e.g., “title12”, “ﬁle12”, and “length12”) are logically related. The playlists.py program has a function (songs_from_dictionary(), not shown, but in the book’s source code) that reads in a key–value dictionary of the kind returned by the codeshown hereand returnsa list of song tuples—something wewill dodirect- ly in the next subsection.\n\nPlaylist Data Parsing\n\nread The playlists.py program mentioned in the previous subsection can and write .pls format ﬁles. In this subsection we will write a parser that can read ﬁles in .m3u format and that returns its results in the form of a list of collections.namedtuple() objects, each of which holds a title, a duration in seconds, and a ﬁlename.\n\nAs usual, we will begin by looking at an extract of the data we want to parse, then we will create a suitable BNF, and ﬁnally we will create a parser to parse the data. The data extract is shown in Figure 14.6.\n\nWe have omitted most of the data asindicated by the ellipsis(…).The ﬁle must begin with the line #EXTM3U. Each entry occupies two lines. The ﬁrst line of an entry starts with #EXTINF: and provides the duration in seconds and the title. The second line of an entry has the ﬁlename. Just like with .pls format, a negative duration signiﬁes that the duration is unknown.\n\n||\n\nPyPars- ing .m3u parser ➤ 541\n\nPLY .m3u parser ➤ 557",
      "page_number": 496
    },
    {
      "number": 52,
      "title": "Segment 52 (pages 508-517)",
      "start_page": 508,
      "end_page": 517,
      "detection_method": "topic_boundary",
      "content": "Named tuples 111➤\n\nWriting Handcrafted Parsers\n\n523\n\n#EXTM3U #EXTINF:230,Blondie - Atomic Blondie\\Atomic\\01-Atomic.ogg ... #EXTINF:-1,Blondie - I'm Gonna Love You Too Blondie\\Atomic\\18-I'm Gonna Love You Too.ogg\n\nFigure 14.6 An extract from a .m3u ﬁle\n\nThe BNF is shown in Figure 14.7. It deﬁnes a M3U as the literal text #EXTM3U followed by a newline and then one or more ENTRYs. Each ENTRY consists of an INFO followedby a newlinethena FILENAME followedby a newline. An INFO starts with theliteraltext #EXTINF: followed by thedurationspeciﬁedby SECONDS,then a comma, and then the TITLE. The SECONDS is deﬁned as an optional minus sign followed by one or more digits. Both the TITLE and FILENAME are loosely deﬁned as sequences of any characters except newlines.\n\nM3U ::= '#EXTM3U\\n' ENTRY+ ENTRY ::= INFO '\\n' FILENAME '\\n' INFO ::= '#EXTINF:' SECONDS ',' TITLE SECONDS ::= '-'? \\d+ TITLE ::= [^\\n]+ FILENAME ::= [^\\n]+\n\nFigure 14.7 A BNF for the .m3u format\n\nBefore reviewing the parser itself,we will ﬁrst look at the named will use to store each result:\n\ntuple that we\n\nSong = collections.namedtuple(\"Song\", \"title seconds filename\")\n\nThis is much more convenient than using a dictionary with keys like “ﬁle5”, “title17”,and so on,and where we have to write code to match up all those keys that end in the same number.\n\nWe will review the parser’s code in four very short parts for ease of expla- nation.\n\nif fh.readline() != \"#EXTM3U\\n\":\n\nprint(\"This is not a .m3u file\") return []\n\nsongs = [] INFO_RE = re.compile(r\"#EXTINF:(?P<seconds>-?\\d+),(?P<title>.+)\")\n\n524\n\nChapter 14. Introduction to Parsing\n\nWANT_INFO, WANT_FILENAME = range(2) state = WANT_INFO\n\nThe open ﬁle object is in variable fh. If the ﬁle doesn’t start with the correct text for a .m3u ﬁle we output an error message and return an empty list.\n\nThe Song namedtupleswillbestoredinthe songs list. Theregex isfor matching the BNF’s INFO nonterminal. The parser itself is always in one of two states, either WANT_INFO (the start state) or WANT_FILENAME. In the WANT_INFO state the parser tries to get the title and seconds, and in the WANT_FILENAME state the parser creates a new Song and adds it to the songs list.\n\nfor lino, line in enumerate(fh, start=2):\n\nline = line.strip() if not line: continue\n\nWe iterate over each line in the given open ﬁle object in a similar way to what we did for the .pls parser in the previous subsection, only this time we start the line numbers from 2 since we handle line 1 before entering the loop. We strip whitespace and skip blank lines, and do further processing depending on which state we are in.\n\nif state == WANT_INFO:\n\ninfo = INFO_RE.match(line) if info:\n\ntitle = info.group(\"title\") seconds = int(info.group(\"seconds\")) state = WANT_FILENAME\n\nelse:\n\nprint(\"Failed to parse line {0}: {1}\".format(\n\nlino, line))\n\nIf we are expecting an INFO line we attempt to match the INFO_RE regex to extract the title and the number of seconds. Then we change the parser’sstate so that it expectsthe next line to be the corresponding ﬁlename. We don’t have to check that the int() conversion works (e.g., by using a try … except), since the text used in the conversion always matches a valid integer because of the regex pattern (-?\\d+).\n\nelif state == WANT_FILENAME:\n\nsongs.append(Song(title, seconds, line)) title = seconds = None state = WANT_INFO\n\nIf we are expecting a FILENAME line we simply append a new Song with the previously set title and seconds, and with the current line as the ﬁlename.\n\nWriting Handcrafted Parsers\n\nWe then restore the parser’s state to its start state ready to parse another song’s details.\n\nAt the end (not shown),we return the songs list to the caller. And thanksto the use of named tuples, each song’s attributes can be conveniently accessed by name, for example, songs[12].title.\n\nKeeping track of state using a variable as we have done here works well in many simple cases. But in general this approach is insufﬁcient for dealing with data or DSLs that can contain nested expressions. In the next subsection we will see how to maintain state in the face of nesting.\n\nParsing the Blocks Domain-Speciﬁc Language\n\nThe blocks.py program is provided as one of the book’s examples. It reads one format—blocks format, a made-up or more .blk ﬁles that use a custom text language—that are speciﬁed on the command line, and for each one creates an SVG (Scalable Vector Graphics) ﬁle with the same name, but with its sufﬁx changed to .svg. While the rendered SVG ﬁles could not be accused of being pretty, they provide a good visual representation that makes it easy to see mistakesin the .blk ﬁles,aswellasshowing thepotentiality thateven a simple DSL can make possible.\n\n[] [lightblue: Director] // [] [lightgreen: Secretary] // [Minion #1] [] [Minion #2]\n\nFigure 14.8 The hierarchy.blkﬁle\n\nFigure 14.8 shows the complete hierarchy.blk ﬁle, and Figure 14.9 shows how the hierarchy.svg ﬁle that the blocks.py program produces is rendered.\n\nThe blocks format has essentially two elements: blocks and new row markers. Blocks are enclosed in brackets. Blocks may be empty, in which case they are used as spacers occupying one cell of a notional grid. Blocks may also contain text and optionally a color. New row markers are forward slashes and they indicate where a new row should begin. In Figure 14.8 two new row markers are used each time and this is what creates the two blank rows that are visible in Figure 14.9.\n\nThe blocks format also allows blocks to be nested inside one another, simply by including blocks and new row markers inside a block’s brackets, after the block’s text.\n\n525\n\n||\n\nPy- Parsing blocks parser ➤ 543\n\nPLY blocks parser ➤ 559\n\n526\n\nChapter 14. Introduction to Parsing\n\nFigure 14.9 The hierarchy.svg ﬁle\n\nFigure 14.10showsthe complete messagebox.blk ﬁle in which blocksare nested, and Figure 14.11 shows how the messagebox.svg ﬁle is rendered.\n\n[#00CCDE: MessageBox Window [lightgray: Frame [] [white: Message text] // [goldenrod: OK Button] [] [#ff0505: Cancel Button] / [] ] ]\n\nFigure 14.10 The messagebox.blk ﬁle\n\nColors can be speciﬁed using the names supported by the SVG format, or as hexadecimal values (indicated by a leading #). The blocks ﬁle shown in Figure 14.10 has one outer block (“MessageBox Window”), an inner block (“Frame”),and severalblocksand newrowmarkersinsidetheinner block. The whitespace is used purely to make the structureclearer to human readers;it is ignored by the blocks format.\n\nFigure 14.11 The messagebox.svg ﬁle\n\nWriting Handcrafted Parsers\n\nNow that we have seen a couple of blocks ﬁles, we will look at the blocks BNF to more formally understand what constitutes a valid blocks ﬁle and as prepa- ration for parsing this recursive format. The BNF is shown in Figure 14.12.\n\nBLOCKS ::= NODES+ NODES ::= NEW_ROW* \\s* NODE+ NODE ::= '[' \\s* (COLOR ':')? \\s* NAME? \\s* NODES* \\s* ']' COLOR ::= '#' [\\dA-Fa-f]{6} | [a-zA-Z]\\w* NAME ::= [^][/]+ NEW_ROW ::= '/'\n\nFigure 14.12 A BNF for the .blk format\n\nThe BNF deﬁnes a BLOCKS ﬁle as having one or more NODES. A NODES consists of zero or more NEW_ROWs followed by one or more NODEs. A NODE is a left bracket followed by an optional COLOR followed by an optional NAME followed by zero or more NODES followed by a right square bracket. The COLOR is simply a hash (pound)symbolfollowed by six hexadecimaldigitsand a colon,or a sequenceof oneor morealphanumericcharactersthat beginswith an alphabeticcharacter, and followedby a colon. The NAME isa sequenceof any charactersbut excluding brackets or forward slashes. A NEW_ROW is a literal forward slash. As the many occurrencesof \\s* suggest,whitespaceisallowed anywherebetween terminals and nonterminals and is of no signiﬁcance.\n\nThe deﬁnition of the NODE nonterminal is recursive because it contains the NODES nonterminal which itself is deﬁned in terms of the NODE nonterminal. Recursive deﬁnitions like this are easy to get wrong and can lead to parsers that loop endlessly, so it might be worthwhile doing some paper-based testing to make sure the grammar does terminate, that is, that given a valid input the grammar will reach all terminals rather than endlessly looping from one nonterminal to another.\n\nPreviously, once we had a BNF, we have dived straight into creating a parser and doing the processing as we parse. This isn’t practical for recursive gram- mars because of the potential for elements to be nested. What we will need to do is to create a class to represent each block (or new row) and that can hold a list of nested child blocks,which themselvesmight contain children,and so on. We can then retrieve the parser’sresultsas a list (which will contain listswith- in lists as necessary to represent nested blocks), and we can convert this list into a tree with an “empty” root block and all the other blocks as its children.\n\nIn the case of the hierarchy.blk example, the root block has a list of new rows and of child blocks (including empty blocks),none of which have any children. This is illustrated in Figure 14.13—the hierarchy.blk ﬁle was shown earlier (525 ➤). The messagebox.blk example has a root block that has one child block (the “MessageBox Window”), which itself has one child block (the “Frame”),\n\n527\n\nLambda func- tions 182➤\n\nWriting Handcrafted Parsers\n\nblock has no name and the color white. The children list contains Blocks and Nones—the latter representing new row markers. Rather than rely on users of the Block class remembering all of these conventions, we have provided some module methods to abstract them away.\n\nclass Block:\n\ndef __init__(self, name, color=\"white\"):\n\nself.name = name self.color = color self.children = []\n\ndef has_children(self):\n\nreturn bool(self.children)\n\nThe Block class is very simple. The has_children() method is provided as a convenience for the BlockOutput.py module. We haven’t provided any explicit API for adding children, since clients are expected to work directly with the children list attribute.\n\nget_root_block = lambda: Block(None, None) get_empty_block = lambda: Block(\"\") get_new_row = lambda: None is_new_row = lambda x: x is None\n\nThese four tiny helper functions provide abstractions for the Block class’s conventions. They mean that programmersusing the Block module don’t have to remember the conventions, just the functions,and also give us a little bit of wiggle room should we decide to change the conventions later on.\n\nNow that we have the Block class and supporting functions (all deﬁned in the Block.py module ﬁle imported by the blocks.py program that containsthe pars- er),we are ready to write a .blk parser. The parser will create a root block and populate it with children (and children’schildren,etc.),to represent the parsed .blk ﬁle,and which can then be passed to the BlockOutput.save_blocks_as_svg() function.\n\nThe parser is a recursive descent parser—this is necessary because the blocks format can contain nested blocks. The parser consists of a Data class that is initialized with the text of the ﬁle to be parsed and that keeps track of the current parse position and provides methods for advancing through the text. In addition, the parser has a group of parse functions that operate on an instance of the Data class, advancing through the data and populating a stack of Blocks. Some of these functions call each other recursively, reﬂecting the recursive nature of the data which is also reﬂected in the BNF.\n\n529\n\n530\n\nChapter 14. Introduction to Parsing\n\nWe will begin by looking at the Data class,then we will see how the classisused and the parsing started, and then we will review each parsing function as we encounter it.\n\nclass Data:\n\ndef __init__(self, text): self.text = text self.pos = 0 self.line = 1 self.column = 1 self.brackets = 0 self.stack = [Block.get_root_block()]\n\nThe Data class holds the text of the ﬁle we are parsing, the position we are up to (self.pos),and the(1-based)line and column thisposition represents. It also keepstrack of the brackets(adding one to the count for every open bracket and subtracting one for every close bracket).The stack is a list of Blocks,initialized with an empty root block. At theendwewillreturntheroot block—if theparse was successful this block will have child blocks (which may have their own child blocks, etc.), representing the blocks data.\n\ndef location(self):\n\nreturn \"line {0}, column {1}\".format(self.line,\n\nself.column)\n\nThis is a tiny convenience method to return the current location as a string containing the line and column numbers.\n\ndef advance_by(self, amount):\n\nfor x in range(amount):\n\nself._advance_by_one()\n\nThe parser needs to advance through the text as it parses. For convenience, several advancing methods are provided; this one advances by the given number of characters.\n\ndef _advance_by_one(self):\n\nself.pos += 1 if (self.pos < len(self.text) and self.text[self.pos] == \"\\n\"): self.line += 1 self.column = 1\n\nelse:\n\nself.column += 1\n\nWriting Handcrafted Parsers\n\nAll the advancing methods use this private method to actually advance the parser’s position. This means that the code to keep the line and column numbers up-to-date is kept in one place.\n\ndef advance_to_position(self, position):\n\nwhile self.pos < position: self._advance_by_one()\n\nThis method advances to a given index position in the text, again using the private _advance_by_one() method.\n\ndef advance_up_to(self, characters):\n\nwhile (self.pos < len(self.text) and\n\nself.text[self.pos] not in characters and self.text[self.pos].isspace()):\n\nself._advance_by_one()\n\nif not self.pos < len(self.text):\n\nreturn False\n\nif self.text[self.pos] in characters:\n\nreturn True\n\nraise LexError(\"expected '{0}' but got '{1}'\"\n\n.format(characters, self.text[self.pos]))\n\nThis method advances over whitespace until the character at the current position is one of those in the given string of characters. It differs from the other advancemethodsin that it can fail (sinceit might reach a nonwhitespace character that is not one of the expected characters); it returns a Boolean to indicate whether it succeeded.\n\nclass LexError(Exception): pass\n\nThisexception classisused internally by the parser. We prefer to use a custom exception rather than,say,ValueError,because it makesit easier to distinguish our own exceptions from Python’s when debugging.\n\ndata = Data(text) try:\n\nparse(data)\n\nexcept LexError as err:\n\nraise ValueError(\"Error {{0}}:{0}: {1}\".format(\n\ndata.location(), err))\n\nreturn data.stack[0]\n\nThe top-level parsing is quite simple. We create an instance of the Data class based on the text we want to parseand then we call the parse() function (which we will see in a moment) to perform the parsing. If an error occurs a custom LexError is raised; we simply convert this to a ValueError to insulate any caller\n\n531\n\n532\n\nChapter 14. Introduction to Parsing\n\nfrom the internal exceptionswe use. Unusually,the error message containsan escaped str.format() ﬁeld name—the caller is expected to use thisto insert the ﬁlename,something we cannot do herebecauseweareonly given theﬁle’stext, not the ﬁlename or ﬁle object.\n\nAt the end we return the root block, which should have children (and their children) representing the parsed blocks.\n\ndef parse(data):\n\nwhile data.pos < len(data.text):\n\nif not data.advance_up_to(\"[]/\"):\n\nbreak\n\nif data.text[data.pos] == \"[\":\n\ndata.brackets += 1 parse_block(data)\n\nelif data.text[data.pos] == \"/\":\n\nparse_new_row(data)\n\nelif data.text[data.pos] == \"]\":\n\ndata.brackets -= 1 data.advance_by(1)\n\nelse:\n\nraise LexError(\"expecting '[', ']', or '/'; \"\n\n\"but got '{0}'\".format(data.text[data.pos]))\n\nif data.brackets:\n\nraise LexError(\"ran out of text when expecting '{0}'\"\n\n.format(']' if data.brackets > 0 else '['))\n\nThis function is the heart of the recursive descent parser. It iterates over the text looking for the start or end of a block or a new row marker. If it reaches the start of a block it increments the brackets count and calls parse_block(); if it reaches a new row marker it calls parse_new_row(); and if it reaches the end of a block it decrementsthe bracketscount and advancesto the next character. If any other character is encountered it is an error and is reported accordingly. Similarly, when all the data has been parsed, if the brackets count is not zero the function reports the error.\n\ndef parse_block(data): data.advance_by(1) nextBlock = data.text.find(\"[\", data.pos) endOfBlock = data.text.find(\"]\", data.pos) if nextBlock == -1 or endOfBlock < nextBlock:\n\nparse_block_data(data, endOfBlock)\n\nelse:\n\nblock = parse_block_data(data, nextBlock)\n\nWriting Handcrafted Parsers\n\ndata.stack.append(block) parse(data) data.stack.pop()\n\nThis function begins by advancing by one character (to skip the start-of-block open bracket).It then looksfor thenext startof block and thenext end of block. If there is no following block or if the next end of block is before the start of another block then thisblock doesnot haveany nested blocks,sowecan simply call parse_block_data() and give it an end position of the end of this block.\n\nIf this block does have one or more nested blocks inside it we parse this block’s data up to where its ﬁrst nested block begins. We then push this block onto the stack of blocksand recursively call the parse() function to parse the nested block (or blocks—andtheir nestedblocks,etc.).Andat theendwepopthisblock off the stack since all the nesting has been handled by the recursive calls.\n\ndef parse_block_data(data, end):\n\ncolor = None colon = data.text.find(\":\", data.pos) if -1 < colon < end:\n\ncolor = data.text[data.pos:colon] data.advance_to_position(colon + 1)\n\nname = data.text[data.pos:end].strip() data.advance_to_position(end) if not name and color is None:\n\nblock = Block.get_empty_block()\n\nelse:\n\nblock = Block.Block(name, color)\n\ndata.stack[-1].children.append(block) return block\n\nThisfunction isused to parse one block’sdata—upto the given end point in the text—and to add a corresponding Block object to the stack of blocks.\n\nWe start by trying to ﬁnd a color, and if we ﬁnd one, we advance over it. Next we try to ﬁnd the block’s text (its name), although this can legitimately be empty. If we have a block with no name or color we create an empty Block; otherwise we create a Block with the given name and color.\n\nOncethe Block hasbeen createdweaddit asthelastchildof thestack of block’s top block. (Initially the top block is the root block,but if we have nested blocks it could besomeother block that hasbeen pushedon top.) At theend wereturn the block so that it can be pushed onto the stack of blocks—something we do only if the block has other blocks nested inside it.\n\ndef parse_new_row(data):\n\ndata.stack[-1].children.append(Block.get_new_row()) data.advance_by(1)\n\n533",
      "page_number": 508
    },
    {
      "number": 53,
      "title": "Segment 53 (pages 518-525)",
      "start_page": 518,
      "end_page": 525,
      "detection_method": "topic_boundary",
      "content": "534\n\nChapter 14. Introduction to Parsing\n\nThis is the easiest of the parsing functions. It simply adds a new row as the last child of the stack of block’stop block,and advancesover the new row char- acter.\n\nThis completes the review of the blocks recursive descent parser. The parser does not require a huge amount of code, fewer than 100 lines, but that’s still more than 50 percent more lines than the PyParsing version needs, and about 33 percent more lines than the PLY version needs. And as we will see, using PyParsing or PLY is much easier than handcrafting a recursive descent parser—and they also lead to parsers that are much easier to maintain.\n\nThe conversion into an SVG ﬁle using the BlockOutput.save_blocks_as_svg() function is the same for all the blocks parsers, since they all produce the same root block and children structures. We won’t review the function’s code since it isn’t relevant to parsing as such—it is in the BlockOutput.py module ﬁle that comes with the book’s examples.\n\nWe have now ﬁnished reviewing the handcrafted parsers. In the following two sections we will show PyParsing and PLY versions of these parsers. In addi- tion, we will show a parser for a DSL that would need a quite sophisticated recursive descent parser if we did it by hand,and that really showsthat as our needs grow, using a generic parser scales much better than a handcrafted so- lution.\n\nPythonic Parsing with PyParsing\n\nWriting recursive descent parsers by hand can be quite tricky to get right,and if we need to create many parsers it can soon become tedious both to write them and especially to maintain them. One obvioussolution isto use a generic parsing module, and those experienced with BNFs or with the Unix lex and yacc tools will naturally gravitate to similar tools. In the section following this one we cover PLY (Python Lex Yacc), a tool that exempliﬁes this classic approach. But in this section we will look at a very different kind of parsing tool: PyParsing.\n\nPyParsingisdescribedby itsauthor,PaulMcGuire,as“analternativeapproach to creating and executing simple grammars, vs. the traditional lex/yacc ap- proach, or the use of regular expressions”. (Although in fact, regexes can be used with PyParsing.) For those used to the traditional approach, PyParsing requires some reorientation in thinking. The payback is the ability to develop parsersthat do not require a lot of code—thanksto PyParsing providing many high-level elementsthatcan matchcommonconstructs—andwhich areeasy to understand and maintain.\n\nPyParsing is available under an open source license and can be used in both noncommercial and commercial contexts. However, PyParsing is not\n\n|||\n\nPythonic Parsing with PyParsing\n\nincluded in Python’s standard library, so it must be downloaded and in- stalled separately—although for Linux users it is almost certainly available through the package management system. It can be obtained from pypars- ing.wikispaces.com—click the page’s Download link. It comes in the form of an executable installation program for Windows and in source form for Unix-like systems such as Linux and Mac OS X. The download page explains how to in- stall it. PyParsing is contained in a single module ﬁle, pyparsing_py3.py, so it can easily be distributed with any program that uses it.\n\nA Quick Introduction to PyParsing\n\nPyParsing makes no real distinction between lexing and parsing. Instead, it providesfunctionsand classestocreateparser elements—oneelement for each thing tobematched. Someparserelementsareprovidedpredeﬁnedby PyPars- ing,otherscanbecreatedby calling PyParsingfunctionsorby instantiatingPy- Parsing classes. Parserelementscanalsobecreatedby combiningotherparser elementstogether—forexample,concatenating themwith + toforma sequence of parser elements, or OR-ing them with | to form a set of parser element al- ternatives. Ultimately,a PyParsing parser is simply a collection of parser ele- ments (which themselves may be made up of parser elements, etc.), composed together.\n\nIf we want to processwhat we parse,we can processthe resultsthat PyParsing returns, or we can add parse actions (code snippets) to particular parser elements, or some combination of both.\n\nPyParsing provides a wide range of parser elements, of which we will brieﬂy describe some of the most commonly used. The Literal() parser element matches the literal text it is given, and CaselessLiteral() does the same thing but ignores case. If we are not interested in some part of the grammar we can use Suppress(); this matches the literal text (or parser element) it is given, but does not add it to the results.\n\nThe Keyword() element is almost the same as Literal() except that it must be followed by a nonkeyword character—this prevents a match where a keyword is a preﬁx of something else. For example, given the data text, “ﬁlename”, Literal(\"file\") will match filename, with the name part left for the next parser element to match, but Keyword(\"file\") won’t match at all.\n\nAnother important parser element is Word(). This element is given a string that it treats as a set of characters,and will match any sequence of any of the given characters. For example, given the data text, “abacus”, Word(\"abc\") will match abacus. If the Word() element is given two strings, the ﬁrst is taken to contain those charactersthat are valid for the ﬁrst character of the match and the second to contain those characters that are valid for the remaining char- acters. This is typically used to match identiﬁers—for example, Word(alphas,\n\n535\n\n||\n\n536\n\nChapter 14. Introduction to Parsing\n\nalphanums) matches text that starts with an alphabetic character and that is followed by zero or more alphanumeric characters. (Both alphas and alphanums are predeﬁned strings of characters provided by the PyParsing module.)\n\nA lessfrequently used alternativeto Word() is CharsNotIn().Thiselement isgiv- en a string that it treats as a set of characters, and will match all the charac- ters from the current parse position onward until it reaches a character from the given set of characters. It does not skip whitespace and it will fail if the current parse character is in the given set, that is, if there are no characters to accumulate. Two other alternatives to Word() are also used. One is Skip- To(); this is similar to CharsNotIn() except that it skips whitespace and it al- ways succeeds—even if it accumulates nothing (an empty string).The other is Regex() which is used to specify a regex to match.\n\nPyParsing also has various predeﬁned parser elements, including restOfLine that matches any characters from the point the parser has reached until the end of the line, pythonStyleComment which matches a Python-style comment, quotedString that matches a string that’s enclosed in single or double quotes (with the start and end quotes matching), and many others.\n\nThere are also many helper functions provided to cater for common cases. For example,the delimitedList() function returnsa parser element that matchesa list of itemswith a given delimiter,and makeHTMLTags() returnsa pair of parser elements to match a given HTML tag’s start and end, and for the start also matches any attributes the tag may have.\n\nParsing elements can be quantiﬁed in a similar way to regexes, using Option- al(), ZeroOrMore(), OneOrMore(), and some others. If no quantiﬁer is speciﬁed, the quantity defaults to 1. Elements can be grouped using Group() and com- bined using Combine()—we’ll see what these do further on.\n\nOnce we have speciﬁed all of our individual parser elements and their quan- tities, we can start to combine them to make a parser. We can specify parser elements that must follow each other in sequence by creating a new parser el- ement that concatenates two or more existing parser elements together—for example, if we have parser elements key and value we can create a key_value parser element by writing key_value = key + Suppress(\"=\") + value.We can spec- ify parser elements that can match any one of two or more alternatives by creating a new parser element that ORs two or more existing parser elements together—forexample,if wehaveparserelementstrue and false wecancreate a boolean parser element by writing boolean = true | false.\n\nNotice that for the key_value parser element we did not need to say anything about whitespace around the =. By default, PyParsing will accept any amount of whitespace (including none) between parser elements, so for example, PyParsing treats the BNF deﬁnition KEY '=' VALUE as if it were written \\s* KEY \\s* '=' \\s* VALUE \\s*. (This default behavior can be switched off, of course.)\n\nPythonic Parsing with PyParsing\n\nNote that here and in the subsections that follow, we import each PyParsing name that we need individually. For example:\n\nfrom pyparsing_py3 import (alphanums, alphas, CharsNotIn, Forward,\n\nGroup, hexnums, OneOrMore, Optional, ParseException, ParseSyntaxException, Suppress, Word, ZeroOrMore)\n\nThis avoids using the import * syntax which can pollute our namespace with unwanted names, but at the same time affords us the convenience to write alphanums and Word() rather than pyparsing_py3.alphanums and pypars- ing_py3.Word(), and so on.\n\nBefore we ﬁnish this quick introduction to PyParsing and look at the examples in the following subsections, it is worth noting a couple of important ideas relating to how we translate a BNF into a PyParsing parser.\n\nPyParsing has many predeﬁned elements that can match common constructs. We should always use these elements wherever possible to ensure the best possible performance. Also, translating BNFs directly into PyParsing syntax is not always the right approach. PyParsing has certain idiomatic ways of handling particular BNF constructs, and we should always follow these to ensure that our parser runs efﬁciently. Here we’ll very brieﬂy review a few of the predeﬁned elements and idioms.\n\nOne common BNF deﬁnition is where we have an optional item. For example:\n\nOPTIONAL_ITEM ::= ITEM | EMPTY\n\nIf we translated this directly into PyParsing we would write:\n\noptional_item = item | Empty() # WRONG!\n\nThis assumes that item is some parser element deﬁned earlier. The Empty() class provides a parser element that can match nothing. Although syntacti- cally correct, this goes against the grain of how PyParsing works. The correct PyParsing idiom is much simpler and involves using a predeﬁned element:\n\noptional_item = Optional(item)\n\nSome BNF statementsinvolvedeﬁning an item in termsof itself. For example, to represent a list of variables(perhapsthe argumentsto a function),we might have the BNF:\n\nVAR_LIST ::= VARIABLE | VARIABLE ',' VAR_LIST VARIABLE ::= [a-zA-Z]\\w*\n\nAt ﬁrst sight we might be tempted to translate this directly into PyParsing syntax:\n\n537\n\nBNF\n\nBNF\n\n538\n\nChapter 14. Introduction to Parsing\n\nvariable = Word(alphas, alphanums) var_list = variable | variable + Suppress(\",\") + var_list # WRONG!\n\nThe problem seems to be simply a matter of Python syntax—we can’t refer to var_list before we have deﬁned it. PyParsing offers a solution to this: We can create an “empty” parser element using Forward(), and then later on we can append parse elements—including itself—to it. So now we can try again.\n\nvar_list = Forward() var_list << (variable | variable + Suppress(\",\") + var_list) # WRONG!\n\nThis second version is syntactically valid, but again, it goes against the grain of how PyParsing works—and as part of a larger parser its use could lead to a parser that is very slow, or that simply doesn’t work. (Note that we must use parentheses to ensure that the whole right-hand expression is appended and not just the ﬁrst part because << has a higher precedence level than |,that is, it binds more tightly than |.) Although its use is not appropriate here, the Forward() class is very useful in other contexts,and we will use it in a couple of the examples in the following subsections.\n\nInstead of using Forward() in situations like this, there are alternative coding patterns that go with the PyParsing grain. Here is the simplest and most literal version:\n\nvar_list = variable + ZeroOrMore(Suppress(\",\") + variable)\n\nThis pattern is ideal for handling binary operators, for example:\n\nplus_expression = operand + ZeroOrMore(Suppress(\"+\") + operand)\n\nBoth of these kindsof usage are so common that PyParsing offersconvenience functions that provide suitable parser elements. We will look at the operator- Precedence() function that is used to create parser elements for unary, binary, and ternary operators in the example in the last of the following subsections. For delimited lists, the convenience function to use is delimitedList(), which we will show now, and which we will use in an example in the following sub- sections:\n\nvar_list = delimitedList(variable)\n\nThe delimitedList() function takes a parser element and an optional delimiter—we didn’t need to specify the delimiter in this case because the de- fault is comma, the delimiter we happen to be using.\n\nSo far thediscussionhasbeen fairly abstract. In thefollowing four subsections wewillcreatefour parsers,each of increasing sophistication,thatdemonstrate how to make the best use of the PyParsing module. The ﬁrst three parsers are PyParsing versions of the handcrafted parsers we created in the previous\n\nHand- crafted key– value parser 519➤\n\nFunc- tional- style pro- gramm- ing 395➤\n\nPythonic Parsing with PyParsing\n\nsection;the fourth parser is new and much more complex,and is shown in this section, and in lex/yacc form in the following section.\n\nSimple Key–Value Data Parsing\n\nregex-based In the previous section’sﬁrst subsection we created a handcrafted key–value parser that was used by the playlists.py program to read .pls ﬁles. In thissubsectionwe will createa parser to do the samejob,but thistimeusing the PyParsing module.\n\nAs before,the purpose of our parser is to populate a dictionary with key–value items matching those in the ﬁle, but with lowercase keys. An extract from a .pls ﬁle is shown in Figure 14.4 (520 ➤), and the BNF is shown in Figure 14.5 (520➤).Since PyParsing skips whitespace by default,we can ignore the BNF’s BLANK nonterminal and optional whitespace (\\s*).\n\nWe will look at the code in three parts: ﬁrst, the creation of the parser itself; second, a helper function used by the parser; and third, the call to the parser to parse a .pls ﬁle. All the code is quoted from the ReadKeyValue.py module ﬁle that is imported by the playlists.py program.\n\nkey_values = {} left_bracket, right_bracket, equals = map(Suppress, \"[]=\") ini_header = left_bracket + CharsNotIn(\"]\") + right_bracket key_value = Word(alphanums) + equals + restOfLine key_value.setParseAction(accumulate) comment = \"#\" + restOfLine parser = OneOrMore(ini_header | key_value) parser.ignore(comment)\n\nFor this particular parser, instead of reading the results at the end we will accumulate results as we go, populating the key_values dictionary with each key=value we encounter.\n\nThe left and right bracketsand the equals signs are important elements of the grammar, but are of no interest in themselves. So for each of them we create a Suppress() parser element—this will match the appropriate character, but won’t include the character in the results. (We could have written each of them individually, for example, as left_bracket = Suppress(\"[\"), and so on, but using the built-in map() function is more convenient.)\n\nThe deﬁnition of the ini_header parser element follows quite naturally from the BNF: a left bracket, then any characters except a right bracket, and then a right bracket. We haven’t deﬁned a parse action for this parser element, so although the parser will match any occurrences that it encounters, nothing will be done with them, which is what we want.\n\n539\n\n||\n\nPLY key– value parser ➤ 555\n\n540\n\nChapter 14. Introduction to Parsing\n\nThekey_valueparserelementistheonewearereallyinterestedin. Thismatch- es a “word”—a sequence of alphanumeric characters, followed by an equals sign, followed by the rest of the line (which may be empty). The restOfLine is a predeﬁned parser element supplied by PyParsing. Since we want to ac- cumulate results as we go we add a parse action (a function reference) to the key_value parser element—this function will be called for every key=value that is matched.\n\nAlthough PyParsing provides a predeﬁned pythonStyleComment parser element, here we prefer the simpler Literal(\"#\") followed by the rest of the line. (And thanks to PyParsing’s smart operator overloading we were able to write the literal # as a string because when we concatenated it with another parser element to producethe comment parser element,PyParsing promoted the # to be a Literal().)\n\nThe parser itself is a parser element that matches one or more ini_header or key_value parser elements, and that ignores comment parser elements.\n\ndef accumulate(tokens): key, value = tokens key = key.lower() if lowercase_keys else key key_values[key] = value\n\nThis function is called once for each key=value match. The tokens parameter is a tuple of the matched parser elements. In this case we would have expected the tuple to have the key,the equals sign,and the value,but since we used Sup- press() on the equals sign we get only the key and the value, which is exactly what we want. The lowercase_keys variable is a Boolean created in an outer scope and that for .pls ﬁles is set to True.(Note that for ease of explanation we have shown this function after the creation of the parser, although in fact it must be deﬁned before we create the parser since the parser refers to it.)\n\ntry:\n\nparser.parseFile(file) except ParseException as err:\n\nprint(\"parse error: {0}\".format(err)) return {} return key_values\n\nWith the parser set up we are ready to call the parseFile() method, which in thisexampletakesthe name of a .pls ﬁle and attemptsto parseit. If theparse fails we output a simple error message based on what PyParsing tells us. At the end we return the key_values dictionary—or an empty dictionary if the parsing failed—and we ignore the parseFile() method’s return value since we did all our processing in the parse action.\n\nHand- crafted .m3u parser 522➤\n\nSong named tuple 523➤\n\nPythonic Parsing with PyParsing\n\nPlaylist Data Parsing\n\nIn the previous section’s second subsection we created a handcrafted regex- based parser for .m3u ﬁles. In this subsection we will create a parser to do the same thing, but this time using the PyParsing module. An extract from a .m3u ﬁle is shown in Figure 14.6 (523 ➤), and the BNF is shown in Figure 14.7 (523➤).\n\nAs we did when reviewing the previoussubsection’s .pls parser,we will review the .m3u parser in three parts: ﬁrst the creation of the parser, then the helper function,and ﬁnally the call to the parser. Just as with the .pls parser,we are ignoring the parser’s return value and instead populating our data structure as the parsing progresses. (In the following two subsections we will create parsers whose return values are used.)\n\nsongs = [] title = restOfLine(\"title\") filename = restOfLine(\"filename\") seconds = Combine(Optional(\"-\") + Word(nums)).setParseAction(\n\nlambda tokens: int(tokens[0]))(\"seconds\")\n\ninfo = Suppress(\"#EXTINF:\") + seconds + Suppress(\",\") + title entry = info + LineEnd() + filename + LineEnd() entry.setParseAction(add_song) parser = Suppress(\"#EXTM3U\") + OneOrMore(entry)\n\nWe begin by creating an empty list that will hold the Song named\n\ntuples.\n\nAlthough the BNF is quite simple, some of the parser elements are more com- plex than those we have seen so far. Notice also that we create the parser ele- ments in reverse order to the order used in the BNF.This is because in Python we can only refer to things that already exist,so for example,we cannot create a parser element for an ENTRY before we have created one for an INFO since the former refers to the latter.\n\nThe title and filename parser elements are ones that match every character from the parse position where they are tried until the end of the line. This means that they can match any characters, including whitespace—but not including newline which is where they stop. We also give these parser el- ements names, for example, “title”—this allows us to conveniently access them by name as an attribute of the tokens object that is given to parse action functions.\n\nThe seconds parser element matches an optional minus sign followed by digits; (nums is a predeﬁned PyParsing string that contains the digits). We use Combine() to ensure that the sign (if present)and digitsare returned asa single string. (It is possible to specify a separator for Combine(), but there is no need in thiscase,since the default of an empty string isexactly what we want.) The\n\n541\n\n||\n\nPLY .m3u parser ➤ 557",
      "page_number": 518
    },
    {
      "number": 54,
      "title": "Segment 54 (pages 526-540)",
      "start_page": 526,
      "end_page": 540,
      "detection_method": "topic_boundary",
      "content": "Map- ping unpack- ing 179➤\n\n542\n\nChapter 14. Introduction to Parsing\n\nparse action is so simple that we have used a lambda. The Combine() ensures that there is alwaysprecisely one token in the tokens tuple,and we use int() to convert thisto an integer. If a parseaction returnsa value,that value becomes the value associatedwith the token rather than the text that wasmatched. We have also given a name to the token for convenience of access later on.\n\nThe info parse action consists of the literal string that indicates an entry, followed by the seconds, followed by a comma, followed by the title—and all this is deﬁned very simply and naturally in a way that matches the BNF. Noticealsothat weuse Suppress() for theliteral string and for thecomma since although both are essential for the grammar, they are of no interest to us in terms of the data itself.\n\nThe entry parser element is very easy to deﬁne: simply an info followed by a newline, then a filename followed by a newline—the LineEnd() is a predeﬁned PyParsing parser element to match a newline. And since we are populating our list of songs as we parse rather than at the end, we give the entry parser element a parse action that will be called whenever an ENTRY is matched.\n\nThe parser itself is a parser element that matches the literal string that indicates a .m3u ﬁle, followed by one or more ENTRYs.\n\ndef add_song(tokens):\n\nsongs.append(Song(tokens.title, tokens.seconds,\n\ntokens.filename))\n\nThe add_song() function is simple, especially since we named the parser ele- ments we are interested in and are therefore able to access them as attributes of the tokens object. And of course, we could have written the function even more compactly by converting the tokens to a dictionary and using mapping unpacking—for example, songs.append(Song(**tokens.asDict())).\n\ntry:\n\nparser.parseFile(fh) except ParseException as err:\n\nprint(\"parse error: {0}\".format(err)) return []\n\nreturn songs\n\nThe code for calling ParserElement.parseFile() is almost identical to the code we used for the .pls parser,although in this case instead of passing a ﬁlename we opened a ﬁle in text mode and passed in the io.TextIOWrapper returned by the built-in open() function as the fh (“ﬁle handle”) variable.\n\nWe have now ﬁnished reviewing two simplePyParsing parsers,and seen many of the most commonly used parts of the PyParsing API. In the following two subsections we will look at more complex parsers,both of which are recursive, that is, they have nonterminals whose deﬁnition includes themselves, and in\n\nHand- crafted blocks parser 525➤\n\nPythonic Parsing with PyParsing\n\nthe ﬁnal example we will also see how to handle operators and their prece- dences and associativities.\n\nParsing the Blocks Domain-Speciﬁc Language\n\nparser In theprevioussection’sthirdsubsectionwecreateda recursivedescent for .blk ﬁles. Inthissubsectionwewillcreatea PyParsing implementationof a blocks parser that should be easier to understand and be more maintainable.\n\nTwo example .blk ﬁles are shown in Figures 14.8 (525 ➤) and 14.10 (526 ➤). The BNF for the blocks format is shown in Figure 14.12 (527 ➤).\n\nWe will look at the creation of the parser elements in two parts, then we will look at the helper function, and then we will see how the parser is called. And at the end we will see how theparser’sresultsare transformedinto a root block with child blocks (which themselves may contain child blocks, etc.), that is our required output.\n\nleft_bracket, right_bracket = map(Suppress, \"[]\") new_rows = Word(\"/\")(\"new_rows\").setParseAction(\n\nlambda tokens: len(tokens.new_rows))\n\nname = CharsNotIn(\"[]/\\n\")(\"name\").setParseAction( lambda tokens: tokens.name.strip())\n\ncolor = (Word(\"#\", hexnums, exact=7) |\n\nWord(alphas, alphanums))(\"color\")\n\nempty_node = (left_bracket + right_bracket).setParseAction(\n\nlambda: EmptyBlock)\n\nAsalwayswithPyParsingparsers,wecreateparserelementstomatchtheBNF fromlast toﬁrst sothat for every parser element wecreatethat dependson one or more other parser elements, the elements it depends on already exist.\n\nThe brackets are an important part of the BNF, but are of no interest to us for the results, so we create suitable Suppress() parser elements for them.\n\nFor the new_rows parser element it might be tempting to use Literal(\"/\")—but that must match the given text exactly whereas we want to match as many /s as are present. Having created the new_rows parser element,we give a name to its results and add a parsing action that replaces the string of one or more /s with an integer count of how many /s there were. Notice also that because we gave a name to the result, we can access the result (i.e., the matched text), by using the name as an attribute of the tokens object in the lambda.\n\nThe name parser element is slightly different from that speciﬁed in the BNF in that we have chosen to disallow not only bracketsand forward slashes,but also newlines. Again, we give the result a name. We also set a parse action, this\n\n543\n\n||\n\nPLY blocks parser ➤ 559\n\n544\n\nChapter 14. Introduction to Parsing\n\ntime to strip whitespace since whitespace (apart from newlines) is allowed as part of a name, yet we don’t want any leading or trailing whitespace.\n\nFor the color parser element we have speciﬁed that the ﬁrst character must be a # followed by exactly six hexadecimal digits (seven characters in all), or a sequence of alphanumeric characters with the ﬁrst character alphabetic.\n\nWe have chosen to handle empty nodes specially. We deﬁne an empty node as a left bracket followed by a right bracket, and replace the brackets with the value EmptyBlock which earlier in the ﬁle is deﬁned as EmptyBlock = 0. This means that in the parser’s results list we represent empty blocks with 0, and as noted earlier, we represent new rows by an integer row count (which will always be > 0).\n\nnodes = Forward() node_data = Optional(color + Suppress(\":\")) + Optional(name) node_data.setParseAction(add_block) node = left_bracket - node_data + nodes + right_bracket nodes << Group(ZeroOrMore(Optional(new_rows) +\n\nOneOrMore(node | empty_node)))\n\nWe deﬁne nodes to be a Forward() parser element,since we need to use it before we specify what it matches. We have also introduced a new parser element that isn’t in the BNF, node_data, which matches the optional color and optional name. We give this parser element a parse action that will create a new Block, so each time a node_data is encountered a Block will be added to the parser’s results list.\n\nThe node parser element is deﬁned very naturally as a direct translation of the BNF.Notice that both the node_data and nodes parser elementsare optional (the former consisting of two optional elements, the latter quantiﬁed by zero or more), so empty nodes are correctly allowed.\n\nFinally,we can deﬁne the nodes parser element. Since it wasoriginally created as a Forward() we must append parser elementsto it using <<.Here we have set nodes to be zero or more of an optional new row and one or more nodes. Notice that we put node before empty_node—since PyParsing matches left to right we normally order parser elements that have common preﬁxes from longest to shortest matching.\n\nWe have also grouped the nodes parser element’s results using Group()—this ensures that each nodes is created as a list in its own right. This means that a node that contains nodes will be represented by a Block for the node,and by a list for the contained nodes—and which in turn may contain Blocks, or integers for empty nodes or new rows, and so on. It is because of this recursive structure that we had to create nodes as a Forward(), and also why we must use the << operator (which in PyParsing is used to append), to add the Group() parser element and the elements it contains to the nodes element.\n\nPythonic Parsing with PyParsing\n\nOne important but subtle point to note is that we used the - operator rather than the + operator in the deﬁnition of the node parser element. We could just as easily have used +, since both + (ParserElement.__add__()) and - (Parser- Element.__sub__()) do the same job—they return a parser element that represents the concatenation of the two parser elements that are the opera- tor’s operands.\n\nThe reason we chose to use - rather than + is due to a subtle but important difference between them. The - operator will stop parsing and raise a Parse- SyntaxException as soon as an error is encountered,something that the + opera- tor doesn’t do. If we had used + all errors would have a line number of 1 and a column of 1; but by using -, any errors have the correct line and column num- bers. In general,using + istheright approach,but if our testsshow that we are getting incorrect error locations, then we can start to change +s into -s as we have done here—and in this case only a single change was necessary.\n\ndef add_block(tokens):\n\nreturn Block.Block(tokens.name, tokens.color if tokens.color\n\nelse \"white\")\n\nWhenever a node_data is parsed instead of the text being returned and added to the parser’s results list, we create and return a Block.We also always set the color to white unless a color is explicitly speciﬁed.\n\nIn the previous examples we parsed a ﬁle and an open ﬁle handle (an opened io.TextIOWrapper); here we will parse a string. It makes no difference to Py- Parsing whether we give it a string or a ﬁle, so long as we use ParserElement. parseFile() or ParserElement.parseString() as appropriate. In fact, PyParsing offers other parsing methods, including ParserElement.scanString() which searches a string for matches, and ParserElement.transformString() which re- turns a copy of the string it is given, but with matched texts transformed into new texts by returning new text from parse actions.\n\nstack = [Block.get_root_block()] try:\n\nresults = nodes.parseString(text, parseAll=True) assert len(results) == 1 items = results.asList()[0] populate_children(items, stack)\n\nexcept (ParseException, ParseSyntaxException) as err:\n\nraise ValueError(\"Error {{0}}: syntax error, line \"\n\n\"{0}\".format(err.lineno))\n\nreturn stack[0]\n\nThis is the ﬁrst PyParsing parser where we have used the parser’s results rather than created the data structures ourselves during the parsing process. We expect the results to be returned as a list containing a single ParseResults\n\n545\n\nThe hierar- chy.blk ﬁle 525➤\n\nThe message- box.blk ﬁle 526➤\n\n546\n\nChapter 14. Introduction to Parsing\n\nobject. Weconvertthisobjectintoa standardPythonlist,sonowwehavea list containing a single item—a list of our results—which we assign to the items variable, and that we then further process via the populate_children() call.\n\nBefore discussing the handling of the results, we will brieﬂy mention the error handling. If the parser fails it will raise an exception. We don’t want PyParsing’sexceptionsto leak out to clients since we may choose to change the parser generator later on. So,if an exception occurs,we catch it and then raise our own exception (a ValueError) with the relevant details.\n\nIn the case of a successful parse of the hierarchy.blk example, the items list looks like this (with occurrences of <Block.Block object at 0x8f52acd> and similar, replaced with Block for clarity):\n\n[0, Block, [], 2, 0, Block, [], 2, Block, [], 0, Block, []]\n\nWhenever we parsed an empty block we returned 0 to the parser’s results list; whenever we parsed new rowswe returned the number of rows;and whenever we encountered a node_data, we created a Block to represent it. In the case of Blocks they always have an empty child list (i.e.,the children attribute is set to []), since at this point we don’t know if the block will have children or not.\n\nSo here the outer list represents the root block, the 0s represent empty blocks, theother integers(all 2sinthiscase)representnewrows,andthe []sareempty child lists since none of the hierarchy.blk ﬁle’s blocks contain other blocks.\n\nThe messagebox.blk example’s items list (pretty printed to and again using Block for clarity) is:\n\nreveal its structure,\n\n[Block,\n\n[Block,\n\n[0, Block, [], 2, Block, [], 0, Block, [], 1, 0]\n\n]\n\n]\n\nHere we can see that the outer list (representing the root block) contains a block that has a child list of one block that contains its own child list, and where these children are blocks (with their own empty child lists),new rows (2 and 1), and empty blocks (0s).\n\nOne problem with the list results representation is that every Block’s children list is empty—each block’s children are in a list that follows the block in the parser’s results list. We need to convert this structure into a single root block with child blocks. To this end we have created a stack—a list containing a single root Block. We then call the populate_children() function that takes the list of items returned by the parser and a list with a root block, and populates the root block’s children (and their children, and so on, as appropriate) with the items.\n\nPythonic Parsing with PyParsing\n\nThe populate_children() function is quite short, but also rather subtle.\n\ndef populate_children(items, stack):\n\nfor item in items:\n\nif isinstance(item, Block.Block):\n\nstack[-1].children.append(item)\n\nelif isinstance(item, list) and item:\n\nstack.append(stack[-1].children[-1]) populate_children(item, stack) stack.pop()\n\nelif isinstance(item, int):\n\nif item == EmptyBlock:\n\nstack[-1].children.append(Block.get_empty_block())\n\nelse:\n\nfor x in range(item):\n\nstack[-1].children.append(Block.get_new_row())\n\nWe iterate over every item in the results list. If the item is a Block we append it to the stack’s last (top) Block’s child list. (Recall that the stack is initialized with a single root Block item.) If the item is a nonempty list, then it is a child list that belongs to the previous block. So we append the previous block (i.e., the top Block’s last child) to the stack to make it the top of the stack, and then recursively call populate_children() on the list item and the stack. This ensures that the list item (i.e., its child items) is appended to the correct item’s child list. Once the recursive call is ﬁnished,we pop the top of the stack,ready for the next item.\n\nIf the item is an integer then it is either an empty block (0, i.e., EmptyBlock) or a count of new rows. If it is an empty block we append an empty block to the stack’s top Block’s list of children. If the item is a new row count, we append that number of new rows to the stack’s top Block’s list of children.\n\nIf the item is an empty list this signiﬁes an empty child list and we do nothing, since by default all Blocks are initialized to have an empty child list.\n\nAt the end the stack’s top item is still the root Block, but now it has children (which may have their own children, and so on). For the hierarchy.blk exam- ple, the populate_children() function produces the structure illustrated in Fig- ure 14.13 (528 ➤). And for the messagebox.blk example, the function produces the structure illustrated in Figure 14.14 (528 ➤).\n\nThe conversion into an SVG ﬁle using the BlockOutput.save_blocks_as_svg() function is the same for all the blocks parsers, since they all produce the same root block and children structures.\n\n547\n\n548\n\nChapter 14. Introduction to Parsing\n\nParsing First-Order Logic\n\nIn this last PyParsing subsection we will create a parser for a DSL for express- ing formulas in ﬁrst-order logic. This has the most complex BNF of all the examples in the chapter, and the implementation requires us to handle oper- ators, including their precedences and associativities, something we have not needed to do so far. There is no handcrafted version of this parser—once we have reached thislevel of complexity it is better to use a parser generator. But in addition to the PyParsing version shown here, in the following section’s last subsection there is an equivalent PLY parser for comparison.\n\nHere are a few examples of the kind of ﬁrst-order logical formulas that we want to be able to parse:\n\na = b forall x: a = b exists y: a -> b ~ true | true & true -> forall x: exists y: true (forall x: exists y: true) -> true & ~ true -> true true & forall x: x = x true & (forall x: x = x) forall x: x = x & true (forall x: x = x) & true\n\nWe have opted to use ASCII charactersrather than the proper logical operator symbols, to avoid any distraction from the parser itself. So, we have used forall for ∀, exists for ∃, -> for ⇒ (implies), | for ∨ (logical OR), & for ∧ (logical AND),and ~ for ¬(logical NOT).SincePythonstringsareUnicodeit would beeasy to use the real symbols—or we could adapt the parser to accept both the ASCII forms shown here and the real symbols.\n\nIn the formulas shown here, the parentheses make a difference in the last two formulas—so those formulas are different—but not for the two above them (those starting with true), which are the same despite the parentheses. Naturally, the parser must get these details right.\n\nOne surprising aspect of ﬁrst-order logic is that not (~) has a lower precedence than equals (=), so ~ a = b is actually ~ (a = b). This is why logicians usually put a space after ~.\n\nA BNF for our ﬁrst-order logic DSL is given in Figure 14.15. For the sake of clarity the BNF does not include any explicit mention of whitespace (no \\n or \\s* elements), but we will assume that whitespace is allowed between all terminals and nonterminals.\n\nAlthough our subset of BNF syntax hasnoprovisionfor expressing precedence or associativity, we have added comments to indicate associativities for the\n\n||\n\nPLY ﬁrst-or- der logic parser ➤ 562\n\nFor- mulas\n\nMemoiz- ing 351➤\n\nPythonic Parsing with PyParsing\n\nFORMULA ::= ('forall' | 'exists') SYMBOL ':' FORMULA | FORMULA '->' FORMULA # right associative | FORMULA '|' FORMULA # left associative | FORMULA '&' FORMULA # left associative | '~' FORMULA | '(' FORMULA ')' | TERM '=' TERM | 'true' | 'false' TERM ::= SYMBOL | SYMBOL '(' TERM_LIST ')' TERM_LIST ::= TERM | TERM ',' TERM_LIST SYMBOL ::= [a-zA-Z]\\w*\n\nFigure 14.15 A BNF for ﬁrst-order logic\n\nbinary operators. As for precedence, the order is from lowest to highest in the order shown in the BNF for the ﬁrst few alternatives; that is, forall and exists have the lowest precedence, then ->, then |, then &. And the remaining alternatives all have higher precedence than those mentioned here.\n\nBefore looking at the parser itself, we will look at the import and the line that follows it since they are different than before.\n\nfrom pyparsing_py3 import (alphanums, alphas, delimitedList, Forward, Group, Keyword, Literal, opAssoc, operatorPrecedence, ParserElement, ParseException, ParseSyntaxException, Suppress, Word)\n\nParserElement.enablePackrat()\n\nThe import brings in some things we haven’t seen before and that we will cov- er when we encounter them in the parser. The enablePackrat() call is used to switch on an optimization (based on memoizing) that can produce a consider- able speedup when parsing deep operator hierarchies.★ If we do this at all it is best to do it immediately after importing the pyparsing_py3 module—and be- fore creating any parser elements.\n\nAlthough the parser is short, we will review it in three parts for ease of expla- nation, and then we will see how it is called. We don’t have any parser actions since all we want to do is to get an AST (Abstract Syntax Tree)—a list repre- senting what we have parsed—that we can post-process later on if we wish.\n\nleft_parenthesis, right_parenthesis, colon = map(Suppress, \"():\") forall = Keyword(\"forall\")\n\n★For more on packrat parsing, see Bryan Ford’s master’s thesis at pdos.csail.mit.edu/~baford/ packrat/.\n\n549\n\n550\n\nChapter 14. Introduction to Parsing\n\nexists = Keyword(\"exists\") implies = Literal(\"->\") or_ = Literal(\"|\") and_ = Literal(\"&\") not_ = Literal(\"~\") equals = Literal(\"=\") boolean = Keyword(\"false\") | Keyword(\"true\") symbol = Word(alphas, alphanums)\n\nAll the parser elements created here are straightforward, although we had to add underscores to the end of a few names to avoid conﬂicts with Python keywords. If we wanted to give users the choice of using ASCII or the proper Unicode symbols, we could change some of the deﬁnitions. For example:\n\nforall = Keyword(\"forall\") | Literal(\"∀\")\n\nIf we are using a non-Unicode editor we could use the appropriate escaped Unicode code point, such as Literal(\"\\u2200\"), instead of the symbol.\n\nterm = Forward() term << (Group(symbol + Group(left_parenthesis +\n\ndelimitedList(term) + right_parenthesis)) | symbol)\n\nA term is deﬁned in terms of itself, which is why we begin by creating it as a Forward(). And rather than using a straight translation of the BNF we use one of PyParsing’s coding patterns. Recall that the delimitedList() function returns a parser element that can match a list of one or more occurrences of the given parser element, separated by commas (or by something else if we explicitly specify the separator). So here we have deﬁned the term parser element asbeing either a symbol followed by a comma-separatedlist of termsor a symbol—and since both start with the same parser element we must put the one with the longest potential match ﬁrst.\n\nformula = Forward() forall_expression = Group(forall + symbol + colon + formula) exists_expression = Group(exists + symbol + colon + formula) operand = forall_expression | exists_expression | boolean | term formula << operatorPrecedence(operand, [\n\n(equals, 2, opAssoc.LEFT), (not_, 1, opAssoc.RIGHT), (and_, 2, opAssoc.LEFT), (or_, 2, opAssoc.LEFT), (implies, 2, opAssoc.RIGHT)])\n\nAlthough the formula looks quite complicated in the BNF, it isn’t so bad in PyParsing syntax. First we deﬁne formula as a Forward() since it is deﬁned in terms of itself. The forall_expression and exists_expression parser elements\n\nPythonic Parsing with PyParsing\n\nare straightforward to deﬁne; we’ve just used Group() to make them sublists within the results list to keep their components together and at the same time distinct as a unit.\n\nThe operatorPrecedence() function (which really ought to have been called something like createOperators()) creates a parser element that matches one or more unary, binary, and ternary operators. Before calling it, we ﬁrst specify what our operands are—in this case a forall_expression or an ex- ists_expression or a boolean or a term. The operatorPrecedence() function takes a parser element that matches valid operands, and then a list of parser ele- ments that must be treated as operators, along with their arities (how many operandstheytake),andtheirassociativities. Theresultantparserelement(in this case, formula) will match the speciﬁed operators and their operands.\n\nEach operator is speciﬁed as a three- or four-item tuple. The ﬁrst item is the operator’sparser element,the second is the operator’sarity as an integer (1for a unary operator,2for a binary operator,and3for a ternary operator),thethird is the associativity, and the fourth is an optional parse action.\n\nPyParsing infers the operators’ order of precedence from their relative posi- tions in the list given to the operatorPrecedence() function, with the ﬁrst oper- ator having the highest precedence and the last the lowest, so the order of the itemsin the list we passis important. In thisexample,= hasthe highest prece- dence (and has no associativity,so we have made it left-associative),and -> has the lowest precedence and is right-associative.\n\nThis completes the parser, so we can now look at how it is called.\n\ntry:\n\nresult = formula.parseString(text, parseAll=True) assert len(result) == 1 return result[0].asList()\n\nexcept (ParseException, ParseSyntaxException) as err: print(\"Syntax error:\\n{0.line}\\n{1}^\".format(err,\n\n\" \" * (err.column - 1)))\n\nThis code is similar to what we used for the blocks example in the previous subsection, only here we have tried to give more sophisticated error handling. In particular,if an error occurs we print the line that had the error and on the line below it we print spaces followed by a caret (^) to indicate where the error wasdetected. For example,if we parsethe invalid formula,forall x: = x & true, we will get:\n\nSyntax error: forall x: = x & true\n\n^\n\n551\n\n552\n\nChapter 14. Introduction to Parsing\n\nIn this case the error location is slightly off—the error is that = x should have the form y = x, but it is still pretty good.\n\nIn the case of a successfulparse we get a list of ParseResults which hasa single result—as before we convert this to a Python list.\n\nEarlier we saw some example formulas; now we will look at some of them again, this time with the result lists produced by the parser, pretty printed to help reveal their structure.\n\nWe mentioned before that the ~ operator has a lower precedence than the = operator—so let’s see if this is handled correctly by the parser.\n\n# ~true -> ~b = c [ ['~', 'true'], '->', ['~', ['b', '=', 'c'] ] ]\n\n# ~true -> ~(b = c) [ ['~', 'true'], '->', ['~', ['b', '=', 'c'] ] ]\n\nHere we get exactly the same results for both formulas, which demonstrates that = has higher precedence than ~.Of course,we would need to write several more test formulas to check all the cases, but this at least looks promising.\n\nTwo of the formulasthat we saw earlier were forall x: x = x & true and (forall x: x = x) & true, and we pointed out that although the only difference between them is the parentheses, this is sufﬁcient to make them different formulas. Here are the lists the parser produces for them:\n\n# forall x: x = x & true [ 'forall', 'x', [ ['x', '=', 'x'], '&', 'true' ] ]\n\n# (forall x: x = x) & true [ [ 'forall', 'x', ['x', '=', 'x'] ], '&', 'true' ]\n\nThe parser is clearly able to distinguish between these two formulas, and creates quite different parse trees (nested lists). Without the parentheses, forall’s formula is everything right of the colon, but with the parentheses, forall’s scope is limited to within the parentheses.\n\nBut what about the two formulas that again are different only in that one has parentheses, but where the parentheses don’t matter, so that the formulas are\n\nPythonic Parsing with PyParsing\n\nactually the same? These two formulas are true & forall x: x = x and true & (forall x: x = x), and fortunately, when parsed they both produce exactly the same list:\n\n[ 'true', '&', [ 'forall', 'x', ['x', '=', 'x'] ] ]\n\nThe parentheses don’t matter here because only one valid parse is possible.\n\nWe have now completed the PyParsing ﬁrst-order logic parser, and in fact, all of the book’s PyParsing examples. If PyParsing is of interest, the PyParsing web site (pyparsing.wikispaces.com) has many other examples and extensive documentation, and there is also an active Wiki and mailing list.\n\nIn the next section we will look at the same examples as we covered in this section,but thistimeusing thePLY parser which worksin a very differentway from PyParsing.\n\nLex/Yacc-Style Parsing with PLY\n\nPLY (Python Lex Yacc) is a pure Python implementation of the classic Unix tools, lex and yacc. Lex is a tool that creates lexers, and yacc is a tool that cre- atesparsers—oftenusing a lexer createdby lex. PLY isdescribedby itsauthor, David Beazley, as “reasonably efﬁcient and well suited for larger grammars. [It]provides most of the standard lex/yacc features including support for emp- ty productions, precedence rules, error recovery, and support for ambiguous grammars. PLY is straightforward to use and provides very extensive error checking.”\n\nPLY is available under the LGPL open source license and so can be used in most contexts. Like PyParsing, PLY is not included in Python’s standard li- brary, so it must be downloaded and installed separately—although for Linux usersitisalmostcertainlyavailablethroughthepackagemanagementsystem. And fromPLY version 3.0,thesamePLY moduleswork with both Python2and Python 3.\n\nIf it is necessary to obtain and install PLY manually,it is available as a tarball from www.dabeaz.com/ply. On Unix-like systems such as Linux and Mac OS X, the tarball can be unpacked by executing tar xvfz ply-3.2.tar.gz in a console. (Of course, the exact PLY version may be different.) Windows users can use\n\n553\n\n|||\n\n554\n\nChapter 14. Introduction to Parsing\n\nthe untar.py example program that comes with this book’s examples. For in- stance, assuming the book’s examples are located in C:\\py3eg, the command to execute in the console is C:\\Python31\\python.exe C:\\py3eg\\untar.py ply- 3.2.tar.gz.\n\nOnce the tarball is unpacked, change directory to PLY’s directory—this direc- tory should contain a ﬁle called setup.py and a subdirectory called ply.PLY can be installed automatically or manually. To do it automatically, in the console execute python setup.py install,or on Windows execute C:\\Python31\\python.exe setup.py install.Alternatively, just copy or move the ply directory and its con- tentsto Python’s site-packages directory (or to your local site-packages directo- ry). Once installed, PLY’s modules are available as ply.lex and ply.yacc.\n\nPLY makesa clear distinctionbetweenlexing (tokenizing)and parsing. Andin fact, PLY’s lexer is so powerful that it is sufﬁcient on its own to handle all the examplesshown in thischapter except for the ﬁrst-order logic parser for which we use both the ply.lex and ply.yacc modules.\n\nWhen we discussed the PyParsing module we began by ﬁrst reviewing various PyParsing-speciﬁc concepts, and in particular how to convert certain BNF constructs into PyParsing syntax. This isn’t necessary with PLY since it is designed to work directly with regexes and BNFs, so rather than give any conceptual overview, we will summarize a few key PLY conventions and then dive straight into the examples and explain the details as we go along.\n\nPLY makes extensive use of naming conventions and introspection, so it is important to be aware of these when we create lexers and parsers using PLY.\n\nEvery PLY lexer and parser depends on a variable called tokens. This variable must hold a tuple or list of token names—they are usually uppercase strings corresponding to nonterminals in the BNF. Every token must have a corre- sponding variableor function whosenameisof theform t_TOKEN_NAME.If a vari- able is deﬁned it must be set to a string containing a regex—so normally a raw string is used for convenience;if a function is deﬁned it must have a docstring thatcontainsa regex,againusually using a rawstring. Ineithercasetheregex speciﬁes a pattern that matches the corresponding token.\n\nOne name that is special to PLY is t_error(); if a lexing error occurs and a function with this name is deﬁned, it will be called.\n\nIf we want the lexer to match a token but discard it from the results (e.g., a comment in a programming language), we can do this in one of two ways. If we are using a variable then we make its name t_ignore_TOKEN_NAME; if we are using a function then we use the normal name t_TOKEN_NAME, but ensure that it returns None.\n\nThe PLY parser follows a similar convention to the lexer in that for each BNF rule we create a function with the preﬁx p_, and whose docstring contains the BNF rule we’re matching (only with ::= replaced with :). Whenever a\n\nHand- crafted key– value parser 519➤\n\nPyPars- ing key– value parser 539➤\n\n.pls BNF 520➤\n\nLex/Yacc-Style Parsing with PLY\n\nrule matches its corresponding function is called with a parameter (called p, following the PLY documentation’s examples); this parameter can be indexed with p[0] corresponding to the nonterminal that the rule deﬁnes,and p[1] and so on, corresponding to the parts on the right-hand side of the BNF.\n\nPrecedenceand associativity canbeset by creating a variablecalled precedence and giving it a tuple of tuples—in precedence order—that indicate the tokens’ associativities.\n\nSimilarly to the lexer,if there isa parsing error and we have created a function called p_error(), it will be called.\n\nWe will make use of all the conventions described here, and more, when we review the examples.\n\nTo avoid duplicating information from earlier in the chapter,the examplesand explanations given here focus purely on parsing with PLY. It is assumed that you are familiar with the formats to be parsed and their contexts of use. This means that either you have read at least this chapter’s second section and the ﬁrst-order logic parser from the third section’slast subsection,or that you skip back using the backreferences provided when necessary.\n\nSimple Key–Value Data Parsing\n\nﬁles. Every PLY’s lexer is sufﬁcient to handle the key–value data held in .pls PLY lexer (and parser) has a list of tokens which must be stored in the tokens variable. PLY makes extensive use of introspection,so the names of variables and functions, and even the contents of docstrings, must follow PLY’s conven- tions. Here are the tokens and their regexes and functions for the PLY .pls parser:\n\ntokens = (\"INI_HEADER\", \"COMMENT\", \"KEY\", \"VALUE\")\n\nt_ignore_INI_HEADER = r\"\\[[^]]+\\]\" t_ignore_COMMENT = r\"\\#.*\"\n\ndef t_KEY(t): r\"\\w+\" if lowercase_keys:\n\nt.value = t.value.lower()\n\nreturn t\n\ndef t_VALUE(t): r\"=.*\" t.value = t.value[1:].strip() return t\n\n555\n\n||\n\n556\n\nChapter 14. Introduction to Parsing\n\nBoth the INI_HEADER and COMMENT tokens’ matchers are simple regexes, and since both use the t_ignore_ preﬁx, both will be correctly matched—and then discarded. An alternative approach to ignoring matches is to deﬁne a function that just uses the t_ preﬁx (e.g., t_COMMENT()), and that has a suite of pass (or return None), since if the return value is None the token is discarded.\n\nFor the KEY and VALUE tokens we have used functions rather than regexes. In such cases the regex to match must be speciﬁed in the function’s docstring— and here the docstrings are raw strings since that is our practice for regexes, and it meanswe don’t have to escape backslashes. When a function is used the token is passed as token object t (following the PLY examples’ naming conven- tions) of type ply.lex.LexToken. The matched text is held in the ply.lex.Lex- Token.value attribute, and we are permitted to change this if we wish. We must always return t from the function if we want the token included in the results.\n\nIn the case of the t_KEY() function, we lowercase the matching key if the lowercase_keys variable (from an outer scope) is True. And for the t_VALUE() function, we strip off the = and any leading or trailing whitespace.\n\nIn addition to our own custom tokens, it is conventional to deﬁne a couple of PLY-speciﬁc functions to provide error reporting.\n\ndef t_newline(t):\n\nr\"\\n+\" t.lexer.lineno += len(t.value)\n\ndef t_error(t):\n\nline = t.value.lstrip() i = line.find(\"\\n\") line = line if i == -1 else line[:i] print(\"Failed to parse line {0}: {1}\".format(t.lineno + 1,\n\nline))\n\nThe token’s lexer attribute (of type ply.lex.Lexer) provides access to the lexer itself. Here we have updated the lexer’s lineno attribute by the number of newlines that have been matched.\n\nNotice that we don’t have to speciﬁcally account for blank lines since the t_newline() matching function effectively does that for us.\n\nIf an error occurs the t_error() function is called. We print an error message and at most one line of the input. We add 1 to the line number since PLY’s lexer.lineno attribute starts counting from 0.\n\nWith all the token deﬁnitionsin place we are ready to lex some data and create a corresponding key–value dictionary.",
      "page_number": 526
    },
    {
      "number": 55,
      "title": "Segment 55 (pages 541-554)",
      "start_page": 541,
      "end_page": 554,
      "detection_method": "topic_boundary",
      "content": "Hand- crafted .m3u parser 522➤\n\nPyPars- ing .m3u parser 541➤\n\n.m3u BNF 523➤\n\nLex/Yacc-Style Parsing with PLY\n\nkey_values = {} lexer = ply.lex.lex() lexer.input(file.read()) key = None for token in lexer:\n\nif token.type == \"KEY\":\n\nkey = token.value\n\nelif token.type == \"VALUE\":\n\nif key is None:\n\nprint(\"Failed to parse: value '{0}' without key\"\n\n.format(token.value))\n\nelse:\n\nkey_values[key] = token.value key = None\n\nThe lexer reads the entire input text and can be used as an iterator that produces one token at each iteration. The token.type attribute holds the name of the current token—this is one of the names from the tokens list—and the token.value holds the matched text—or whatever we replaced it with.\n\nFor each token, if the token is a KEY we hold it and wait for its value, and if it is a VALUE we add it using the current key to the key_values dictionary. At the end (not shown), we return the dictionary to the caller just as we did with the playlists.py .pls regex and PyParsing parsers.\n\nPlaylist Data Parsing\n\nformat. And just In this subsection we will develop a PLY parser for the .m3u as we did in the previous implementations,the parser will return its results in the form of a list of Song (collections.namedtuple()) objects,each of which holds a title, a duration in seconds, and a ﬁlename.\n\nSince the format is so simple, PLY’s lexer is sufﬁcient to do all the parsing. As before we will create a list of tokens, each one corresponding to a nonterminal in the BNF:\n\ntokens = (\"M3U\", \"INFO\", \"SECONDS\", \"TITLE\", \"FILENAME\")\n\nWe haven’t got an ENTRY token—thisnonterminal is made up of a SECONDS and a TITLE.Instead we deﬁne two states,called entry and filename.When the lexer is in the entry state we will try to read the SECONDS and the TITLE,that is,an ENTRY, and when the lexer is in the filename state we will try to read the FILENAME. To make PLY understand states we must create a states variable that is set to a list of one or more 2-tuples. The ﬁrst item in each of the tuples is a state name and the second item is the state’s type, either inclusive (i.e., this state is in addition to the current state) or exclusive (i.e., this state is the only active\n\n557\n\n||\n\n558\n\nChapter 14. Introduction to Parsing\n\nstate). PLY predeﬁnes the INITIAL state which all lexers start in. Here is the deﬁnition of the states variable for the PLY .m3u parser:\n\nstates = ((\"entry\", \"exclusive\"), (\"filename\", \"exclusive\"))\n\nNow that we have deﬁned our tokens and our states we can deﬁne the regexes and functions to match the BNF.\n\nt_M3U = r\"\\#EXTM3U\"\n\ndef t_INFO(t):\n\nr\"\\#EXTINF:\" t.lexer.begin(\"entry\") return None\n\ndef t_entry_SECONDS(t):\n\nr\"-?\\d+,\" t.value = int(t.value[:-1]) return t\n\ndef t_entry_TITLE(t):\n\nr\"[^\\n]+\" t.lexer.begin(\"filename\") return t\n\ndef t_filename_FILENAME(t):\n\nr\"[^\\n]+\" t.lexer.begin(\"INITIAL\") return t\n\nBy default, the tokens, regexes, and functions operate in the INITIAL state. However,we can specify that they areactivein only oneparticular stateby em- bedding the state’sname after the t_ preﬁx. So in thiscase the t_M3U regex and the t_INFO() functionwillmatchonly in the INITIAL state,the t_entry_SECONDS() and t_entry_TITLE() functions will match only in the entry state, and the t_filename_FILENAME() function will match only in the filename state.\n\nThe lexer’s state is changed by calling the lexer object’s begin() method with the new state’s name as its argument. So in this example, when we match the INFO token we switch to the entry state; now only the SECONDS and TITLE tokens can match. Once we have matched a TITLE we switch to the filename state,and once we have matched a FILENAME we switch back to the INITIAL state ready to match the next INFO token.\n\nNotice that in the case of the t_INFO() function we return None;this means that the token will be discarded, which is correct since although we must match #EXTINF: for each entry, we don’t need that text. For the t_entry_SECONDS() function,we stripoff the trailing comma and replacethe token’svalue with the integer number of seconds.\n\nHand- crafted blocks parser 525➤\n\nLex/Yacc-Style Parsing with PLY\n\nIn this parser we want to ignore spurious whitespace that may occur between tokens,and we want to do so regardlessof the state the lexer is in. This can be achieved by creating a t_ignore variable, and by giving it a state of ANY which means it is active in any state:\n\nt_ANY_ignore = \" \\t\\n\"\n\nThiswillensurethatany whitespacebetweentokensissafely andconveniently ignored.\n\nWe have also deﬁned two functions, t_ANY_newline() and t_ANY_error(); these have exactly the same bodies as the t_newline() and t_error() functions deﬁned in the previous subsection (556 ➤)—so neither are shown here—but include the state of ANY in their names so that they are active no matter what state the lexer is in.\n\nsongs = [] title = seconds = None lexer = ply.lex.lex() lexer.input(fh.read()) for token in lexer:\n\nif token.type == \"SECONDS\":\n\nseconds = token.value\n\nelif token.type == \"TITLE\": title = token.value\n\nelif token.type == \"FILENAME\":\n\nif title is not None and seconds is not None:\n\nsongs.append(Song(title, seconds, token.value)) title = seconds = None\n\nelse:\n\nprint(\"Failed, filename '{0}' without title/duration\"\n\n.format(token.value))\n\nWe use the lexer in the same way as we did for the .pls lexer, iterating over the tokens, accumulating values (for the seconds and title), and whenever we get a ﬁlename to go with the seconds and title, adding a new song to the song list. As before, at the end (not shown), we return the key_values dictionary to the caller.\n\nParsing the Blocks Domain-Speciﬁc Language\n\nThe blocks format is more sophisticated than the key–value-based .pls format or the .m3u format since it allows blocks to be nested inside each other. This presents no problems to PLY, and in fact the deﬁnitions of the tokens can be done wholly using regexes without requiring any functions or states at all.\n\n559\n\n||\n\nPy- Parsing blocks parser 543➤\n\n.blk BNF 527➤\n\n560\n\nChapter 14. Introduction to Parsing\n\ntokens = (\"NODE_START\", \"NODE_END\", \"COLOR\", \"NAME\", \"NEW_ROWS\",\n\n\"EMPTY_NODE\")\n\nt_NODE_START = r\"\\[\" t_NODE_END = r\"\\]\" t_COLOR = r\"(?:\\#[\\dA-Fa-f]{6}|[a-zA-Z]\\w*):\" t_NAME = r\"[^][/\\n]+\" t_NEW_ROWS = r\"/+\" t_EMPTY_NODE = r\"\\[\\]\"\n\nThe regexes are taken directly from the BNF, except that we have chosen to disallow newlines in names. In addition, we have deﬁned a t_ignore regex to skip spaces and tabs, and t_newline() and t_error() functions that are the same as before except that t_error() raises a custom LexError with its error message rather than printing the error message.\n\nWith the tokens set up, we are ready to prepare for lexing and then to do the lexing.\n\nstack = [Block.get_root_block()] block = None brackets = 0 lexer = ply.lex.lex() try:\n\nlexer.input(text) for token in lexer:\n\nAs with the previous blocks parsers we begin by creating a stack (a list) with an empty root Block. This will be populated with child blocks (and the child blocks with child blocks, etc.) to reﬂect the blocks that are parsed; at the end we will return the root block with all its children. The block variable is used to hold a reference to the block that is currently being parsed so that it can be updated as we go. We also keep a count of the brackets purely to improve the error reporting.\n\nOne difference from before is that we do the lexing and the parsing of the tokens inside a try … except suite—this is so that we can catch any LexError exceptions and convert them to ValueErrors.\n\nif token.type == \"NODE_START\":\n\nbrackets += 1 block = Block.get_empty_block() stack[-1].children.append(block) stack.append(block)\n\nelif token.type == \"NODE_END\":\n\nbrackets -= 1 if brackets < 0:\n\nraise LexError(\"too many ']'s\")\n\nLex/Yacc-Style Parsing with PLY\n\nblock = None stack.pop()\n\nWhenever we start a new node we increment the brackets count and create a new empty block. This block is added as the last child of the stack’stop block’s list of children and is itself pushed onto the stack. If the block has a color or name we will be able to set it because we keep a reference to the block in the block variable.\n\nThe logic used here is slightly different from the logic used in the recursive de- scent parser—there we pushed new blocks onto the stack only if we knew that they had nested blocks. Here we always push new blocks onto the stack, safe in the knowledge that they’ll be popped straight off again if they don’t contain any nested blocks. This also makes the code simpler and more regular.\n\nWhen we reach the end of a block we decrement the brackets count—and if it is negative we know that we have had too many close brackets and can report the error immediately. Otherwise, we set block to None since we now have no current block and pop the top of the stack (which should never be empty).\n\nelif token.type == \"COLOR\":\n\nif block is None or Block.is_new_row(block):\n\nraise LexError(\"syntax error\")\n\nblock.color = token.value[:-1]\n\nelif token.type == \"NAME\":\n\nif block is None or Block.is_new_row(block):\n\nraise LexError(\"syntax error\")\n\nblock.name = token.value\n\nIf we get a color or a name, we set the corresponding attribute of the current block which should refer to a Block rather than being None or denoting a new row.\n\nelif token.type == \"EMPTY_NODE\":\n\nstack[-1].children.append(Block.get_empty_block())\n\nelif token.type == \"NEW_ROWS\":\n\nfor x in range(len(token.value)):\n\nstack[-1].children.append(Block.get_new_row())\n\nIf we get an empty node or one or more new rows,we add them as the last child of the stack’s top block’s list of children.\n\nif brackets:\n\nraise LexError(\"unbalanced brackets []\")\n\nexcept LexError as err:\n\nraise ValueError(\"Error {{0}}:line {0}: {1}\".format(\n\ntoken.lineno + 1, err))\n\n561\n\nPyPars- ing ﬁrst- order logic parser 548➤\n\nFirst-or- der logic BNF 549➤\n\n562\n\nChapter 14. Introduction to Parsing\n\nOnce lexing has ﬁnished we check that the brackets have balanced, and if not we raise a LexError. If a LexError occurred during lexing, parsing, or when we checked the brackets, we raise a ValueError that contains an escaped str.format() ﬁeld name—the caller is expected to use this to insert the ﬁle- name, something we cannot do here because we are given only the ﬁle’s text, not the ﬁlename or ﬁle object.\n\nAt the end (not shown), we return stack[0]; this is the root Block that should now have children (and which in turn might have children), representing the .blk ﬁle we have parsed. This block is suitable for passing to the BlockOut- put.save_blocks_as_svg() function, just as we did with the recursive descent and PyParsing blocks parsers.\n\nParsing First-Order Logic\n\nIn the last PyParsing subsection we created a parser for ﬁrst-order logic. In this subsection we will create a PLY version that is designed to produce identical output to the PyParsing version.\n\nSetting up the lexer is very similar to what we did earlier. The only novel aspect is that we keep a dictionary of “keywords” which we check whenever we have matched a SYMBOL (the equivalent to an identiﬁer in a programming language). Here is the lexer code, complete except for the t_ignore regex and the t_newline() and t_error() functions which are not shown because they are the same as ones we have seen before.\n\nkeywords = {\"exists\": \"EXISTS\", \"forall\": \"FORALL\",\n\n\"true\": \"TRUE\", \"false\": \"FALSE\"} tokens = ([\"SYMBOL\", \"COLON\", \"COMMA\", \"LPAREN\", \"RPAREN\",\n\n\"EQUALS\", \"NOT\", \"AND\", \"OR\", \"IMPLIES\"] +\n\nlist(keywords.values()))\n\ndef t_SYMBOL(t):\n\nr\"[a-zA-Z]\\w*\" t.type = keywords.get(t.value, \"SYMBOL\") return t\n\nt_EQUALS = r\"=\" t_NOT = r\"~\" t_AND = r\"&\" t_OR = r\"\\|\" t_IMPLIES = r\"->\" t_COLON = r\":\" t_COMMA = r\",\" t_LPAREN = r\"\\(\" t_RPAREN = r\"\\)\"\n\n||\n\ndict type 126➤\n\nSe- quence types 107➤\n\nLex/Yacc-Style Parsing with PLY\n\nThe t_SYMBOL() function is used to match both symbols (identiﬁers) and key- words. If the key given to dict.get() isn’t in the dictionary the default value (in this case \"SYMBOL\") is returned; otherwise the key’s corresponding token name is returned. Notice also that unlike in previous lexers, we don’t change the ply.lex.LexToken’s value attribute,but we do change its type attribute to be either \"SYMBOL\" or the appropriate keyword token name. All the other tokens arematchedby simpleregexes—allof whichhappentomatchoneor twoliteral characters.\n\nIn all the previous PLY examples the lexer alone has been sufﬁcient for our parsing needs. But for the ﬁrst-order logic BNF we need to use PLY’s pars- er as well as its lexer to do the parsing. Setting up a PLY parser is quite straightforward—andunlike PyParsing we don’t have to reformulateour BNF to match certain patterns but can use the BNF directly.\n\nFor each BNF deﬁnition, we create a function with a name preﬁxed by p_ and whose docstring contains the BNF statement the function is designed to pro- cess. As the parser parses, it calls the function with the matching BNF state- ment and passes it a single argument of type ply.yacc.YaccProduction. The argument is given the name p (following the PLY examples’ naming conven- tions).When a BNF statementincludesalternatives,it ispossibleto createjust one function to handle them all, although in most cases it is clearer to create one function per alternativeor set of structurally similar alternatives. We will look at each of the parser functions, starting with the one for handling quan- tiﬁers.\n\ndef p_formula_quantifier(p):\n\n\"\"\"FORMULA : FORALL SYMBOL COLON FORMULA\n\n| EXISTS SYMBOL COLON FORMULA\"\"\"\n\np[0] = [p[1], p[2], p[4]]\n\nThe docstring contains the BNF statement that the function corresponds to, but using : rather than ::= to mean is deﬁned by. Note that the words in the BNF are either tokens that the lexer matches or nonterminals (e.g., FORMULA) that the BNF matches. One PLY quirk to be aware of is that if we have alter- natives as we have here, each one must be on a separate line in the docstring.\n\nThe BNF’s deﬁnition of the FORMULA nonterminal involves many alternatives, but here we have used just the parts that are concerned with quantiﬁers—we will handle the other alternatives in other functions. The argument p of type supports Python’s sequence API, with each item cor- ply.yacc.YaccProduction responding to an item in the BNF. So in all cases, p[0] corresponds to the nonterminal that is being deﬁned (in this case FORMULA), with the other items matching the partson the right-hand side. Here, p[1] matches one of the sym- bols \"exists\" or \"forall\", p[2] matches the quantiﬁed identiﬁer (typically, x or y), p[3] matchesthe COLON token (a literal : which we ignore),and p[4] matches the formula that is quantiﬁed. This is a recursive deﬁnition, so the p[4] item\n\n563\n\n564\n\nChapter 14. Introduction to Parsing\n\nis itself a formula which may contain formulas and so on. We don’t have to concern ourselves with whitespace between tokens since we created a t_ignore regex which told the lexer to ignore (i.e., skip) whitespace.\n\nIn this example, we could just as easily have created two separate functions, say, p_formula_forall() and p_formula_exists(), giving them one alternative of the BNF each and the samesuite. We choseto combinethem—andsome of the others—simply because they have the same suites.\n\nFormulas in the BNF have three binary operators involving formulas. Since these can be handled by the same suite, we have chosen to parse them using a single function and a BNF with alternatives.\n\ndef p_formula_binary(p):\n\n\"\"\"FORMULA : FORMULA IMPLIES FORMULA\n\n| FORMULA OR FORMULA | FORMULA AND FORMULA\"\"\"\n\np[0] = [p[1], p[2], p[3]]\n\nThe result, that is, the FORMULA stored in p[0], is simply a list containing the left operand,the operator,and the right operand. Thiscode saysnothing about precedence and associativity—and yet we know that IMPLIES is right-associa- tive and that the other two are left-associative, and that IMPLIES has lower precedence than the others. We will see how to handle these aspects once we have ﬁnished reviewing the parser’s functions.\n\ndef p_formula_not(p):\n\n\"FORMULA : NOT FORMULA\" p[0] = [p[1], p[2]]\n\ndef p_formula_boolean(p): \"\"\"FORMULA : FALSE\n\n| TRUE\"\"\"\n\np[0] = p[1]\n\ndef p_formula_group(p):\n\n\"FORMULA : LPAREN FORMULA RPAREN\" p[0] = p[2]\n\ndef p_formula_symbol(p):\n\n\"FORMULA : SYMBOL\" p[0] = p[1]\n\nAll these FORMULA alternatives are unary, but even though the suites for p_formula_boolean() and p_formula_symbol() are the same, we have given each one its own function since they are all logically different from each other. One slightly surprising aspect of the p_formula_group() function is that we set its value to be p[1] rather than [p[1]]. This works because we already use lists to\n\nLex/Yacc-Style Parsing with PLY\n\nembody all the operators,so while it would be harmless to use a list here—and might be essential for other parsers—in this example it isn’t necessary.\n\ndef p_formula_equals(p):\n\n\"FORMULA : TERM EQUALS TERM\" p[0] = [p[1], p[2], p[3]]\n\nThis is the part of the BNF that relates formulas and terms. The implementa- tion is straightforward,and we could have included this with the other binary operators since the function’s suite is the same. We chose to handle this sepa- rately purely because it is logically different from the other binary operators.\n\ndef p_term(p):\n\n\"\"\"TERM : SYMBOL LPAREN TERMLIST RPAREN\n\n| SYMBOL\"\"\"\n\np[0] = p[1] if len(p) == 2 else [p[1], p[3]]\n\ndef p_termlist(p):\n\n\"\"\"TERMLIST : TERM COMMA TERMLIST | TERM\"\"\"\n\np[0] = p[1] if len(p) == 2 else [p[1], p[3]]\n\nTerms can either be a single symbol or a symbol followed by a parenthesized term list (a comma-separated list of terms), and these two functions between them handle both cases.\n\ndef p_error(p):\n\nif p is None:\n\nraise ValueError(\"Unknown error\")\n\nraise ValueError(\"Syntax error, line {0}: {1}\".format(\n\np.lineno + 1, p.type))\n\nIf a parser error occurs the p_error() function is called. Although we have treated the ply.yacc.YaccProduction argument as a sequence up to now, it also has attributes, and here we have used the lineno attribute to indicate where the problem occurred.\n\nprecedence = ((\"nonassoc\", \"FORALL\", \"EXISTS\"),\n\n(\"right\", \"IMPLIES\"), (\"left\", \"OR\"), (\"left\", \"AND\"), (\"right\", \"NOT\"), (\"nonassoc\", \"EQUALS\"))\n\nTo set the precedences and associativities of operators in a PLY parser, we must create a precedence variable and give it a list of tuples where each tu- ple’s ﬁrst item is the required associativity and where each tuple’s second and subsequent items are the tokens concerned. PLY will honor the speciﬁed as-\n\n565\n\n566\n\nChapter 14. Introduction to Parsing\n\nsociativities and will set the precedences from lowest (ﬁrst tuple in the list) to highest(lasttupleinthelist).★For unary operators,associativityisn’treally an issue for PLY (although it can be for PyParsing), so for NOT we could have used \"nonassoc\" and the parsing results would not be affected.\n\nAt this point we have the tokens, the lexer’s functions, the parser’s functions, and the precedence variable all set up. Now we can create a PLY lexer and parser and parse some text.\n\nlexer = ply.lex.lex() parser = ply.yacc.yacc() try:\n\nreturn parser.parse(text, lexer=lexer)\n\nexcept ValueError as err:\n\nprint(err) return []\n\nThis code parses the formula it is given and returns a list that has exactly the sameformatasthe listsreturnedby thePyParsing version. (See theend of the subsectionon thePyParsing ﬁrst-orderlogic parser toseeexamplesof thekind of lists that the parser returns; 552➤.)\n\nPLY triesvery hardtogiveusefulandcomprehensiveerrormessages,although in some cases it can be overzealous—for example, when PLY creates the ﬁrst- order logic parser for the ﬁrst time, it warns that there are “6 shift/reduce conﬂicts”.Inpractice,PLY defaultstoshifting insuchcases,sincethat’susually the right thing to do, and is certainly the right action for the ﬁrst-order logic parser. The PLY documentation explains this and many other issues that can arise, and the parser’s parser.out ﬁle which is produced whenever a parser is created contains all the information necessary to analyze what is going on. As a rule of thumb, shift/reduce warnings may be benign, but any other kind of warning should be eliminated by correcting the parser.\n\nWe havenow completedour coverageof thePLY examples. ThePLY documen- tation (www.dabeaz.com/ply) provides much more information than we have had space to convey here, including complete coverage of all of PLY’s features in- cluding many that were not needed for this chapter’s examples.\n\nSummary\n\nFor the simplest situations and for nonrecursive grammars, using regexes is a good choice—at least for those who are comfortable with regex syntax. Another approach isto create a ﬁnite state automata—for example,by reading the text character by character,and maintaining one or more state variables—\n\n★In PyParsing,precedences are set the other way up, from highest to lowest.\n\n|||\n\nSummary\n\nalthough thiscan lead to if statementswith lotsof elifsand nested if …elifs that can be difﬁcult to maintain. For more complex grammars,and those that are recursive,PyParsing,PLY,and other generic parser generatorsare a better choice than using regexes or ﬁnite state automata, or doing a handcrafted recursive descent parser.\n\nOf all the approaches, PyParsing seems to require the least amount of code, although it can be tricky to get recursive grammars right, at least at ﬁrst. PyParsing works at its best when we take full advantage of its predeﬁned functionality—of which there is quite a lot more than we covered in this chapter—and use the programming patterns that suit it. This means that in more complex cases we cannot simply translate a BNF directly into PyParsing syntax, but must adapt the implementation of the BNF to ﬁt in with the Py- Parsing philosophy. PyParsing is an excellent module, and it is used in many programming projects.\n\nPLY not only supports the direct translation of BNFs, it requires that we do this, at least for the ply.yacc module. It also has a powerful and ﬂexible lex- er which is sufﬁcient in its own right for handling many simple grammars. PLY also has excellent error reporting. PLY uses a table-driven algorithm that makes its speed independent of the size or complexity of the grammar, so it tends to run faster than parsers that use recursive descent such as Py- Parsing. One aspect of PLY that may take some getting used to is its heavy reliance on introspection,where both docstrings and function names have sig- niﬁcance. Nonetheless, PLY is an excellent module, and has been used to cre- ate some complex parsers,including ones for the C and ZXBasic programming languages.\n\nAlthough it is generally straightforward to create a parser that accepts valid input, creating one that accepts all valid input and rejects all invalid input can be quite a challenge. For example, do the ﬁrst-order logic parsers in this chapter’slast section accept all valid formulasand reject all invalid ones? And even if we do manage to reject invalid input,do we provideerror messagesthat correctlyidentify whattheproblemisandwhereit occurred? Parsing isa large and fascinating topic,and this chapter is designed to introduce the very basics, so further reading and practical experience are essential for those wanting to go further.\n\nOne other point that this chapter hints at is that as large and wide-rang- ing as Python’s standard library is, many high-quality, third-party pack- ages and modules that provide very useful additional functionality are also available. Most of these are available through the Python Package Index, pypi.python.org/pypi, but some can only be discovered using a search engine. In general, when you have some specialized need that is not met by Python’s standard library, it is always worth looking for a third-party solution before writing your own.\n\n567\n\n568\n\nChapter 14. Introduction to Parsing\n\nExercise\n\nCreate a suitable BNF and then write a simple program for parsing basic BIBTEX book references, and that produces output in the form of a dictionary of dictionaries. For example, given input like this:\n\n@Book{blanchette+summerfield08, author = \"Jasmin Blanchette and Mark Summerfield\", title = \"C++ GUI Programming with Qt 4, Second Edition\", year = 2008, publisher = \"Prentice Hall\" }\n\nthe expected output would be a dictionary like this (here, pretty printed):\n\n{'blanchette+summerfield08': { 'author': 'Jasmin Blanchette and Mark Summerfield', 'publisher': 'Prentice Hall', 'title': 'C++ GUI Programming with Qt 4, Second Edition', 'year': 2008 } }\n\nEach book has an identiﬁer and this should be used as the key for the outer dictionary. The value should itself be a dictionary of key–value items.\n\nEach book’s identiﬁer can contain any characters except whitespace, and each key=value ﬁeld’svalue caneither beanintegeror a double-quotedstring. String values can include arbitrary whitespace including newlines, so replace every internal sequence of whitespace (including newlines) with a single space, and of course strip whitespace from the ends. Note that the last key=value for a given book is not followed by a comma.\n\nCreate the parser using either PyParsing or PLY. If using PyParsing, the Regex() classwill beusefulfor theidentiﬁer and the QuotedString() classwill be useful when deﬁning the value. Use the delimitedList() function for handling the list of key=values. If using PLY, the lexer is sufﬁcient, providing you use separate tokens for integer and string values.\n\nA solution using PyParsing should take around 30 lines, while one using PLY might take about 60 lines. A solution that includes both PyParsing and PLY functions is provided in BibTeX.py.\n\n|||\n\n15 ● Dialog-Style Programs\n\nMain-Window-Style Programs\n\nIntroduction to GUI Programming\n\nPython has no native support for GUI (Graphical User Interface) program- ming, but this isn’t a problem since many GUI libraries written in other lan- guages can be used by Python programmers. This is possible because many GUIlibrarieshavePythonwrappersor bindings—thesearepackagesandmod- ules that are imported and used like any other Python packages and modules but which access functionality that is in non-Python libraries under the hood.\n\nPython’sstandard library includesTcl/Tk—Tcl is an almost syntax-free script- ing language and Tk is a GUI library written in Tcl and C. Python’s tkinter module provides Python bindings for the Tk GUI library. Tk has three advan- tages compared with the other GUI libraries that are available for Python. First, it is installed as standard with Python, so it is always available; second, it is small (even including Tcl); and third, it comes with IDLE which is very useful for experimenting with Python and for editing and debugging Python programs.\n\nUnfortunately,prior to Tk 8.5, Tk had a very dated look and a very limited set of widgets (“controls” or “containers” in Windows-speak). Although it is fairly easy to create custom widgets in Tk by composing other widgets together in a layout, Tk does not provide any direct way of creating custom widgets from scratchwith theprogrammerabletodrawwhateverthey want. AdditionalTk- compatible widgets are available using the Ttk library (only with Python 3.1 and Tk 8.5and later)and the Tix library—these are also part of Python’sstan- dard library. Note that Tix is not always provided on non-Windows platforms, most notably Ubuntu, which at the time of this writing offers it only as an unsupported add-on, so for maximum portability it is best to avoid using Tix altogether. The Python-oriented documentation for Tk, Ttk, and Tix is rather sparse—mostof thedocumentationfor theselibrariesiswrittenfor Tcl/Tk pro- grammers and may not be easy for non-Tcl programmers to decipher.\n\n569\n\n||||\n\n3.x\n\n570\n\nChapter 15. Introduction to GUI Programming\n\nFor developing GUI programs that must run on any or all Python desktop platforms(e.g.,Windows,Mac OS X,and Linux),using only a standard Python installation with no additional libraries, there is just one choice: Tk.\n\nIf it is possible to use third-party libraries the number of options opens up considerably. One route is to get the WCK (Widget Construction Kit, www.effbot.org/zone/wck.htm) which provides additional Tk-compatible func- tionality including the ability to create custom widgets whose contents are drawn in code.\n\nThe other choices don’t use Tk and fall into two categories, those that are spe- ciﬁc to a particular platform and those that are cross-platform. Platform-spe- ciﬁc GUI libraries can give us access to platform-speciﬁc features, but at the price of locking us in to the platform. The three most well-established cross- platform GUI libraries with Python bindings are PyGtk (www.pygtk.org), PyQt (www.riverbankcomputing.com/software/pyqt), and wxPython (www.wxpython.org). All three of these offer far more widgets than Tk, produce better-looking GUIs (although the gap has narrowed with Tk 8.5 and even more with Ttk), and makeit possibleto createcustomwidgetsdrawn in code. All of them areeasier to learn and use than Tk and all have more and much better Python-oriented documentation than Tk. And in general, programs that use PyGtk, PyQt, or wxPython need lesscode and produce better resultsthan programswritten us- ing Tk. (At the time of thiswriting,PyQt had already been ported to Python 3, but the ports of both wxPython and PyGtk were still being done.)\n\nYet despite its limitations and frustrations,Tk can be used to build useful GUI programs—IDLE being the most well known in the Python world. Further- more, Tk development seems to have picked up lately, with Tk 8.5 offering theming which makes Tk programs look much more native,as well as the wel- come addition of many new widgets.\n\nThe purpose of this chapter is to give just a ﬂavor of Tk programming—for serious GUI development it is best to skip this chapter (since it shows the vintage Tk approach to GUI programming), and to use one of the alternative libraries. But if Tk is your only option—for example,if your users have only a standard Python installation and cannot or will not install a third-party GUI library—then realistically you will need to learn enough of the Tcl language to be able to read Tk’s documentation.★\n\nIn the following sections we will use Tk to create two GUI programs. The ﬁrst is a very small dialog-style program that does compound interest calculations. The second is a more elaborate main-window-style program that manages a list of bookmarks (names and URLs). By using such simple data we can\n\n★The only Python/Tk book known to the author is Python and Tkinter Programming by John Grayson,ISBN 1884777813,published in 2000;it is out of date in some areas. A good Tcl/Tk book is Practical Programming in Tcl and Tkby Brent Welch and Ken Jones,ISBN 0130385603.All the Tcl/Tk documentation is online at www.tcl.tk, and tutorials can be found at www.tkdocs.com.",
      "page_number": 541
    },
    {
      "number": 56,
      "title": "Segment 56 (pages 555-568)",
      "start_page": 555,
      "end_page": 568,
      "detection_method": "topic_boundary",
      "content": "Chapter 15. Introduction to GUI Programming\n\nInvoke\n\nInvoke\n\nRead Input\n\nCreate GUI\n\nProcess\n\nStart Event Loop\n\nWrite Output\n\nNo\n\nEvent to\n\nProcess?\n\nTerminate\n\nYes\n\nClassic console program\n\nRequest to\n\nTerminate?\n\nNo\n\nProcess\n\nYes\n\nTerminate\n\nClassic GUI program\n\nFigure 15.1 Console programs versus GUI programs\n\nconcentrate on the GUI programming aspects without distraction. In the coverage of the bookmarks program we will see how to create a custom dialog, and how to create a main window with menus and toolbars, as well as how to combine them all together to create a complete working program.\n\nBoth of the example programs use pure Tk, making no use of the Ttk and Tix libraries, so as to ensure compatibility with Python 3.0. It isn’t difﬁcult to convertthemtouseTtk,but at thetimeof thiswriting,someof theTtk widgets provide less support for keyboard users than their Tk cousins, so while Ttk programs might look better, they may also be less convenient to use.\n\nBut before diving into the code, we must review some of the basics of GUI programming since it is a bit different from writing console programs.\n\nPython console programs and module ﬁles always have a .py extension, but for Python GUI programswe use a .pyw extension (module ﬁles always use .py, though). Both .py and .pyw work ﬁne on Linux, but on Windows, .pyw ensures that Windows uses the pythonw.exe interpreter instead of python.exe, and this in turn ensures that when we execute a Python GUI program,no unnecessary console window will appear. Mac OS X works similarly to Windows, using the .pyw extension for GUI programs.\n\n571\n\n572\n\nChapter 15. Introduction to GUI Programming\n\nWhen a GUI program is run it normally begins by creating its main window and all of the main window’s widgets, such as the menu bar, toolbars, the cen- tral area, and the status bar. Once the window has been created, like a server program,theGUIprogramsimply waits. Whereasa server waitsfor clientpro- grams to connect to it,a GUI program waitsfor user interaction such as mouse clicks and key presses. This is illustrated in contrast to console programs in Figure 15.1. The GUI program does not wait passively; it runs an event loop, which in pseudocode looks like this:\n\nwhile True:\n\nevent = getNextEvent() if event:\n\nif event == Terminate:\n\nbreak\n\nprocessEvent(event)\n\nWhen the user interacts with the program,or when certain other things occur, such as a timer timing out or the program’s window being activated (maybe because another program was closed), an event is generated inside the GUI library and added to the event queue. The program’s event loop continuously checks to see whether there is an event to process, and if there is, it processes it (or passes it on to the event’s associated function or method for processing).\n\nAs GUI programmers we can rely on the GUI library to provide the event loop. Our responsibility is to create classes that represent the windows and widgets our program needs and to provide them with methods that respond appropriately to user interactions.\n\nDialog-Style Programs\n\nThe ﬁrst program we will look at is the Interest program. Thisis a dialog-style program (i.e., it has no menus), which the user can use to perform compound interest calculations. The program is shown in Figure 15.2.\n\nIn most object-oriented GUI programs, a custom class is used to represent a single main window or dialog, with most of the widgets it contains being instances of standard widgets, such as buttons or checkboxes, supplied by the library. Like most cross-platform GUI libraries, Tk doesn’t really make a distinction between a window and a widget—a window is simply a widget that has no widget parent (i.e., it is not contained inside another widget). Widgets that don’t have a widget parent (windows) are automatically supplied with a frame and window decorations (such as a title bar and close button), and they usually contains other widgets.\n\nMost widgets are created as children of another widget (and are contained insidetheir parent),whereaswindowsarecreatedaschildren of the tkinter.Tk\n\n|||\n\nDialog-Style Programs\n\nFigure 15.2 The Interest program\n\nobject—an object that conceptually represents the application,and something we will return to later on. In addition to distinguishing between widgets and windows (also called top-level widgets), the parent–child relationships help ensure that widgets are deleted in the right order and that child widgets are automatically deleted when their parent is deleted.\n\nThe initializer is where the user interface is created (the widgets added and laid out, the mouse and keyboard bindings made), and the other methods are used to respond to user interactions. Tk allows us to create custom widgets either by subclassing a predeﬁned widget such as tkinter.Frame,or by creating an ordinary class and adding widgets to it as attributes. Here we have used subclassing—in the next example we will show both approaches.\n\nSince the Interest program has just one main window it is implemented in a single class. We will start by looking at the class’s initializer, broken into ﬁve parts since it is rather long.\n\nclass MainWindow(tkinter.Frame):\n\ndef __init__(self, parent):\n\nsuper().__init__(parent) self.parent = parent self.grid(row=0, column=0)\n\nWe begin by initializing the base class, and we keep a copy of the parent for later use. Rather than using absolute positions and sizes, widgets are laid out inside other widgets using layout managers. The call to grid() lays out the frame using the grid layout manager. Every widget that is shown must be laid out, even top-level ones. Tk has several layout managers, but the grid is the easiest to understand and use, although for top-level layouts where there is only one widget to lay out we could use the packer layout manager by calling pack() instead of grid(row=0, column=0) to achieve the same effect.\n\nself.principal = tkinter.DoubleVar() self.principal.set(1000.0)\n\n573\n\n574\n\nChapter 15. Introduction to GUI Programming\n\nself.rate = tkinter.DoubleVar() self.rate.set(5.0) self.years = tkinter.IntVar() self.amount = tkinter.StringVar()\n\nTk allowsustocreatevariablesthatareassociatedwithwidgets. If avariable’s value is changed programmatically, the change is reﬂected in its associated widget,andsimilarly,if theuser changesthevaluein thewidgettheassociated variable’svalueischanged. Herewehavecreatedtwo“double”variables(these hold float values), an integer variable, and a string variable, and have set ini- tial values for two of them.\n\nprincipalLabel = tkinter.Label(self, text=\"Principal $:\",\n\nanchor=tkinter.W, underline=0) principalScale = tkinter.Scale(self, variable=self.principal, command=self.updateUi, from_=100, to=10000000, resolution=100, orient=tkinter.HORIZONTAL)\n\nrateLabel = tkinter.Label(self, text=\"Rate %:\", underline=0,\n\nanchor=tkinter.W)\n\nrateScale = tkinter.Scale(self, variable=self.rate,\n\ncommand=self.updateUi, from_=1, to=100, resolution=0.25, digits=5, orient=tkinter.HORIZONTAL)\n\nyearsLabel = tkinter.Label(self, text=\"Years:\", underline=0,\n\nanchor=tkinter.W)\n\nyearsScale = tkinter.Scale(self, variable=self.years, command=self.updateUi, from_=1, to=50, orient=tkinter.HORIZONTAL)\n\namountLabel = tkinter.Label(self, text=\"Amount $\",\n\nanchor=tkinter.W)\n\nactualAmountLabel = tkinter.Label(self,\n\ntextvariable=self.amount, relief=tkinter.SUNKEN, anchor=tkinter.E)\n\nThis part of the initializer is where we create the widgets. The tkinter.Label widget is used to display read-only text to the user. Like all widgets it is cre- ated with a parent (in this case—and as usual—the parent is the containing widget), and then keyword arguments are used to set various other aspects of thewidget’sbehaviorandappearance. WehavesettheprincipalLabel’stextap- propriately,and set its anchor to tkinter.W, which means that the label’s text is aligned west (left).The underline parameter is used to specify which character in the label should be underlined to indicate a keyboard accelerator (e.g.,Alt+P); further on we will see how to make the accelerator work. (A keyboard acceler- ator is a key sequence of the form Alt+letter where letter is an underlined letter andwhichresultsinthekeyboardfocusbeing switchedtothewidgetassociated with the accelerator, most commonly the widget to the right or below the label that has the accelerator.)\n\nDialog-Style Programs\n\nFor the tkinter.Scale widgets we give them a parent of self as usual, and as- sociate a variable with each one. In addition,we give a function (or in thiscase a method) object reference as their command—this method will be called au- tomatically whenever the scale’s value is changed,and set its minimum (from_, with a trailing underscore since plain from is a keyword) and maximum (to) values, and a horizontal orientation. For some of the scales we set a resolu- tion (step size) and for the rateScale the number of digits it must be able to display.\n\nThe actualAmountLabel is also associated with a variable so that we can easily change the text the label displays later on. We have also given this label a sunken relief so that it ﬁts in better visually with the scales.\n\nprincipalLabel.grid(row=0, column=0, padx=2, pady=2,\n\nsticky=tkinter.W)\n\nprincipalScale.grid(row=0, column=1, padx=2, pady=2,\n\nsticky=tkinter.EW)\n\nrateLabel.grid(row=1, column=0, padx=2, pady=2, sticky=tkinter.W) rateScale.grid(row=1, column=1, padx=2, pady=2, sticky=tkinter.EW) yearsLabel.grid(row=2, column=0, padx=2, pady=2, sticky=tkinter.W) yearsScale.grid(row=2, column=1, padx=2, pady=2,\n\nsticky=tkinter.EW) amountLabel.grid(row=3, column=0, padx=2, pady=2,\n\nsticky=tkinter.W)\n\nactualAmountLabel.grid(row=3, column=1, padx=2, pady=2,\n\nsticky=tkinter.EW)\n\nHaving created the widgets, we must now lay them out. The grid layout we have used is illustrated in Figure 15.3.\n\nprincipalLabel\n\nprincipalScale\n\nrateLabel\n\nrateScale\n\nyearsLabel\n\nyearsScale\n\namountLabel\n\nactualAmountLabel\n\nFigure 15.3 The Interest program’s layout\n\nEvery widget supports the grid() method (and some other layout methods such as pack()). Calling grid() lays out the widget within its parent, making it occupy the speciﬁed row and column. We can set widgets to span multiple columns and multiple rows using additional keyword arguments (rowspan and columnspan), and we can add some margin around them using the padx (left and\n\n575\n\n576\n\nChapter 15. Introduction to GUI Programming\n\nright margin) and pady (top and bottom margin) keyword arguments giving integer pixel amounts as arguments. If a widget is allocated more space than it needs, the sticky option is used to determine what should be done with the space; if not speciﬁed the widget will occupy the middle of its allocated space. We have set all of the ﬁrst column’s labels to be sticky tkinter.W (west) and all of the second column’s widgets to be sticky tkinter.EW (east and west), which makes them stretch to ﬁll the entire width available to them.\n\nAll of the widgets are held in local variables, but they don’t get scheduled for garbage collection because the parent–child relationships ensure that they are not deleted when they go out of scope at the end of the initializer, since all of them have the main window as their parent. Sometimes widgets are created as instance variables, for example, if we need to refer to them outside the initializer, but in this case we used instance variables for the variables associated with the widgets (self.principal, self.rate, and self.years), so it is these we will use outside the initializer.\n\nprincipalScale.focus_set() self.updateUi() parent.bind(\"<Alt-p>\", lambda *ignore: principalScale.focus_set()) parent.bind(\"<Alt-r>\", lambda *ignore: rateScale.focus_set()) parent.bind(\"<Alt-y>\", lambda *ignore: yearsScale.focus_set()) parent.bind(\"<Control-q>\", self.quit) parent.bind(\"<Escape>\", self.quit)\n\nAt the end of the initializer we give the keyboard focus to the principalScale widget so that as soon as the program starts the user is able to set the initial amount of money. We then call the self.updateUi() method to calculate the initial amount.\n\nNext,weset upa fewkey bindings. (Unfortunately,binding hasthreedifferent meanings—variable binding is where a name, that is, an object reference, is boundtoanobject;a key binding iswherea keyboardactionsuch asa key press or releaseisassociatedwitha functionor methodtocallwhentheactionoccurs; and bindings for a library is the glue code that makes a library written in a languageother than Python availableto Python programmersthrough Python modules.) Key bindings are essential for some disabled users who have difﬁ- culty with or are unable to use the mouse,and they are a great convenience for fast typists who want to avoid using the mouse because it slows them down.\n\nThe ﬁrst three key bindings are used to move the keyboard focus to a scale widget. For example, the principalLabel’s text is set to Principal $: and its underline to 0, so the label appears as Principal $:, and with the ﬁrst keyboard binding in place when the user types Alt+Pthe keyboard focuswill switch to the principleScale widget. The same applies to the other two bindings. Note that we do not bind the focus_set() method directly. Thisisbecausewhen functions or methodsarecalled astheresult of an event binding they aregiven theevent\n\nDialog-Style Programs\n\nthatinvokedthemastheir ﬁrstargument,andwedon’twantthisevent. So,we use a lambda function that accepts but ignores the event and calls the method without the unwanted argument.\n\nWe have also created two keyboard shortcuts—these are key combinationsthat invoke a particular action. Here we have set Ctrl+Q and Esc and bound them both to the self.quit() method that cleanly terminates the program.\n\nIt is possible to create keyboard bindings for individual widgets, but here we have set them all on the parent (the application), so they all work no matter where the keyboard focus is.\n\nTk’s bind() method can be used to bind both mouse clicks and key presses,and also programmer-deﬁnedevents. Special keyslike Ctrland Esc haveTk-speciﬁc names (Control and Escape), and ordinary letters stand for themselves. Key sequences are created by putting the parts in angle brackets and separating them with hyphens.\n\nHaving created and laid out the widgets, and set up the key bindings, the ap- pearance and basic behavior of the program are in place. Now we will review themethodsthatrespondtouseractionstocompletetheimplementationof the program’s behavior.\n\ndef updateUi(self, *ignore):\n\namount = self.principal.get() * (\n\n(1 + (self.rate.get() / 100.0)) ** self.years.get())\n\nself.amount.set(\"{0:.2f}\".format(amount))\n\nThis method is called whenever the user changes the principal,the rate,or the years since it is the command associated with each of the scales. All it does is retrieve the value from each scale’sassociated variable,perform the compound interest calculation,and store the result (asa string)in the variable associated with the actual amount label. As a result, the actual amount label always shows an up-to-date amount.\n\ndef quit(self, event=None):\n\nself.parent.destroy()\n\nIf theuser choosesto quit (by pressing Ctrl+Qor Esc,or by clicking thewindow’s close button) this method is called. Since there is no data to save we just tell the parent (which is the application object) to destroy itself. The parent will destroy all of its children—all of the windows,which in turn will destroy all of their widgets—so a clean termination takes place.\n\napplication = tkinter.Tk() path = os.path.join(os.path.dirname(__file__), \"images/\") if sys.platform.startswith(\"win\"):\n\nicon = path + \"interest.ico\"\n\n577\n\n578\n\nChapter 15. Introduction to GUI Programming\n\nelse:\n\nicon = \"@\" + path + \"interest.xbm\"\n\napplication.iconbitmap(icon) application.title(\"Interest\") window = MainWindow(application) application.protocol(\"WM_DELETE_WINDOW\", window.quit) application.mainloop()\n\nAfter deﬁning theclassfor themain (and in thiscaseonly)window,wehavethe code that startsthe program running. We begin by creating an object to repre- senttheapplicationasawhole. TogivetheprogramanicononWindowsweuse an .ico ﬁle and pass the name of the ﬁle (with its full path) to the iconbitmap() method. But for Unix platformswe must provide a bitmap (i.e.,a monochrome image). Tk has several built-in bitmaps, so to distinguish one that comes from the ﬁle system we must precede its name with an @ symbol. Next we give the application a title (which will appear in the title bar),and then we create an in- stanceof our MainWindow classgiving the applicationobject asitsparent. At the end we call the protocol() method to say what should happen if the user clicks the close button—we have said that the MainWindow.quit() method should be called, and ﬁnally we start the event loop—it is only when we reach this point that the window is displayed and is able to respond to user interactions.\n\nMain-Window-Style Programs\n\nAlthough dialog-style programs are often sufﬁcient for simple tasks, as the range of functionality a program offers grows it often makes sense to create a complete main-window-style application with menus and toolbars. Such applications are usually easier to extend than dialog-style programs since we canaddextra menusor menuoptionsandtoolbarbuttonswithoutaffecting the main window’s layout.\n\nIn this section we will review the bookmarks-tk.pyw program shown in Fig- ure 15.4. The program maintains a set of bookmarks as pairs of (name, URL) strings and has facilities for the user to add, edit, and remove bookmarks, and to open their web browser at a particular bookmarked web page.\n\nThe program has two windows: the main window with the menu bar, toolbar, list of bookmarks, and status bar; and a dialog window for adding or editing bookmarks.\n\nCreating a Main Window\n\nThe main window is similar to a dialog in that it has widgets that must be cre- ated and laid out. And in addition we must add the menu bar, menus, toolbar, and status bar, as well as methods to perform the actions the user requests.\n\n|||\n\n||\n\nMain-Window-StylePrograms\n\nFigure 15.4 The Bookmarks program\n\nThe user interface is all set up in the main window’s initializer, which we will review in ﬁve parts because it is fairly long.\n\nclass MainWindow:\n\ndef __init__(self, parent): self.parent = parent\n\nself.filename = None self.dirty = False self.data = {}\n\nmenubar = tkinter.Menu(self.parent) self.parent[\"menu\"] = menubar\n\nFor this window, instead of inheriting a widget as we did in the preceding ex- ample, we have just created a normal Python class. If we inherit we can reim- plement the methods of the class we have inherited, but if we don’t need to do that we can simply use composition as we have done here. The appearance is provided by creating widget instance variables, all contained within a tkin- ter.Frame as we will see in a moment.\n\nWe need to keep track of four pieces of information: the parent (application) object, the name of the current bookmarks ﬁle, a dirty ﬂag (if True this means that changeshave been madeto the data that have not been saved to disk),and the data itself,a dictionary whose keys are bookmark namesand whose values are URLs.\n\nTo create a menu bar we must create a tkinter.Menu object whose parent is the window’sparent,and we must tell the parent that it hasa menu. (It may seem strange that a menu bar isa menu,but Tk hashad a very long evolution which\n\n579\n\n580\n\nChapter 15. Introduction to GUI Programming\n\nhas left it with some odd corners.) Menu bars created like this do not need to be laid out; Tk will do that for us.\n\nfileMenu = tkinter.Menu(menubar) for label, command, shortcut_text, shortcut in (\n\n(\"New...\", self.fileNew, \"Ctrl+N\", \"<Control-n>\"), (\"Open...\", self.fileOpen, \"Ctrl+O\", \"<Control-o>\"), (\"Save\", self.fileSave, \"Ctrl+S\", \"<Control-s>\"), (None, None, None, None), (\"Quit\", self.fileQuit, \"Ctrl+Q\", \"<Control-q>\")):\n\nif label is None:\n\nfileMenu.add_separator()\n\nelse:\n\nfileMenu.add_command(label=label, underline=0,\n\ncommand=command, accelerator=shortcut_text)\n\nself.parent.bind(shortcut, command)\n\nmenubar.add_cascade(label=\"File\", menu=fileMenu, underline=0)\n\nEach menubar menuiscreatedin thesameway. Firstwecreatea tkinter.Menu object that isa child of the menu bar,and then we add separatorsor commands tothemenu. (NotethatanacceleratorinTk terminologyisactuallyakeyboard shortcut, and that all the accelerator option sets is the text of the shortcut; it does not actually set up a key binding.) The underline indicateswhich charac- ter is underlined,in this case the ﬁrst one of every menu option,and thisletter becomes the menu option’s keyboard accelerator.\n\nIn addition to adding a menu option (called a command), we also provide a keyboard shortcut by binding a key sequence to the same command as that invoked when the corresponding menu option is chosen. At the end the menu is added to the menu bar using the add_cascade() method.\n\nWe have omitted the edit menu since it is structurally identical to the ﬁle menu’s code.\n\nframe = tkinter.Frame(self.parent) self.toolbar_images = [] toolbar = tkinter.Frame(frame) for image, command in (\n\n(\"images/filenew.gif\", self.fileNew), (\"images/fileopen.gif\", self.fileOpen), (\"images/filesave.gif\", self.fileSave), (\"images/editadd.gif\", self.editAdd), (\"images/editedit.gif\", self.editEdit), (\"images/editdelete.gif\", self.editDelete), (\"images/editshowwebpage.gif\", self.editShowWebPage)):\n\nimage = os.path.join(os.path.dirname(__file__), image) try:\n\nMain-Window-StylePrograms\n\nimage = tkinter.PhotoImage(file=image) self.toolbar_images.append(image) button = tkinter.Button(toolbar, image=image,\n\ncommand=command)\n\nbutton.grid(row=0, column=len(self.toolbar_images) -1)\n\nexcept tkinter.TclError as err:\n\nprint(err)\n\ntoolbar.grid(row=0, column=0, columnspan=2, sticky=tkinter.NW)\n\nWe begin by creating a frame in which all of the window’s widgets will be contained. Then we create another frame, toolbar, to contain a horizontal row of buttons that have images instead of texts, to serve as toolbar buttons. We lay out each toolbar button one after the other in a grid that has one row and as many columnsas there are buttons. At the end we lay out the toolbar frame itself as the main window frame’sﬁrst row,making it north west sticky so that it will always cling to the top left of the window. (Tk automatically puts the menu bar above all the widgets laid out in the window.)\n\nThe layout is illustrated in Figure 15.5, with the menu bar laid out by Tk shown with a white background, and our layouts shown with gray back- grounds.\n\nmenubar\n\ntoolbar\n\nself.listBox\n\nscrollbar\n\nself.statusbar\n\nFigure 15.5 The Bookmarks program’s main window layouts\n\nWhen an image is added to a button it is added as a weak reference,so once the image goes out of scope it is scheduled for garbage collection. We must avoid this because we want the buttons to show their images after the initializer has ﬁnished, so we create an instance variable, self.toolbar_images, simply to hold references to the images to keep them alive for the program’s lifetime.\n\nOut of the box, Tk can read only a few image ﬁle formats, so we have had to use .gif images.★ If any image is not found a tkinter.TclError exception is raised, so we must be careful to catch this to avoid the program terminating just because of a missing image.\n\nNotice that we have not made all of the actions available from the menus available as toolbar buttons—this is common practice.\n\n★ If the Python Imaging Library’s Tk extension is installed, all of the modern image formats become supported. See www.pythonware.com/products/pil/for details.\n\n581\n\n582\n\nChapter 15. Introduction to GUI Programming\n\nscrollbar = tkinter.Scrollbar(frame, orient=tkinter.VERTICAL) self.listBox = tkinter.Listbox(frame,\n\nyscrollcommand=scrollbar.set)\n\nself.listBox.grid(row=1, column=0, sticky=tkinter.NSEW) self.listBox.focus_set() scrollbar[\"command\"] = self.listBox.yview scrollbar.grid(row=1, column=1, sticky=tkinter.NS)\n\nself.statusbar = tkinter.Label(frame, text=\"Ready...\",\n\nanchor=tkinter.W)\n\nself.statusbar.after(5000, self.clearStatusBar) self.statusbar.grid(row=2, column=0, columnspan=2,\n\nsticky=tkinter.EW)\n\nframe.grid(row=0, column=0, sticky=tkinter.NSEW)\n\nThe main window’s central area (the area between the toolbar and the status bar)isoccupiedby a list box and an associatedscrollbar. The list box islaid out to be sticky in all directions, and the scrollbar is sticky only north and south (vertically).Both widgets are added to the window frame’s grid, side by side.\n\nWe must ensure that if the user scrollsthe list box by tabbing into it and using the up and down arrow keys, or if they scroll the scrollbar, both widgets are kept in sync. This is achieved by setting the list box’s yscrollcommand to the scrollbar’s set() method (so that user navigation in the list box results in the scrollbar being moved if necessary), and by setting the scrollbar’s command to the listbox’s yview() method (so that scrollbar movements result in the list box being moved correspondingly).\n\nThestatusbar isjust a label. The after() methodisa singleshottimer (a timer that times out once after the given interval) whose ﬁrst argument is a timeout in milliseconds and whose second argument is a function or method to call when the timeout is reached. This means that when the program startsup the status bar will show the text “Ready…” for ﬁve seconds, and then the status bar will be cleared. The statusbar islaid out asthe last row and ismade sticky west and east (horizontally).\n\nAt the end we lay out the window’s frame itself. We have now completed the creation and layout of the main window’s widgets, but as things stand the widgets will assume a ﬁxed default size, and if the window is resized the widgets will not change size to shrink or grow to ﬁt. The next piece of code solves this problem and completes the initializer.\n\nframe.columnconfigure(0, weight=999) frame.columnconfigure(1, weight=1) frame.rowconfigure(0, weight=1) frame.rowconfigure(1, weight=999) frame.rowconfigure(2, weight=1)\n\nMain-Window-StylePrograms\n\nwindow = self.parent.winfo_toplevel() window.columnconfigure(0, weight=1) window.rowconfigure(0, weight=1)\n\nself.parent.geometry(\"{0}x{1}+{2}+{3}\".format(400, 500,\n\n0, 50))\n\nself.parent.title(\"Bookmarks - Unnamed\")\n\nThe columnconfigure() and rowconfigure() methods allow us to give weightings to a grid. We begin with the window frame, giving all the weight to the ﬁrst column and the second row (which is occupied by the list box),so if the frame is resizedany excessspaceisgiventothelist box. On itsownthisisnotsufﬁcient; we must also make the top-level window that containsthe frameresizable,and we do this by getting a reference to the window using the wininfo_toplevel() method, and then making the window resizable by setting its row and column weights to 1.\n\nAt the end of the initializer we set an initial window size and position using a string of the form widthxheight+x+y. (If we wanted to set only the size we could use the form widthxheight instead.) Finally, we set the window’s title, thereby completing the window’s user interface.\n\nIf the user clicks a toolbar button or chooses a menu option a method is called to carry out the required action. And some of these methods rely on helper methods. We will now review all the methods in turn,starting with one that is called ﬁve seconds after the program starts.\n\ndef clearStatusBar(self):\n\nself.statusbar[\"text\"] = \"\"\n\nThe status bar is a simple tkinter.Label. We could have used a lambda expres- sion in the after() method call to clear it, but since we need to clear the status bar from more than one place we have created a method to do it.\n\ndef fileNew(self, *ignore):\n\nif not self.okayToContinue():\n\nreturn\n\nself.listBox.delete(0, tkinter.END) self.dirty = False self.filename = None self.data = {} self.parent.title(\"Bookmarks - Unnamed\")\n\nIf the user wants to create a new bookmarks ﬁle we must ﬁrst give them the chance to save any unsaved changes in the existing ﬁle if there is one. This is factored out into the MainWindow.okayToContinue() method since it is used in a few different places. The method returns True if it is okay to continue, and False otherwise. If continuing, we clear the list box by deleting all its entries\n\n583\n\n584\n\nChapter 15. Introduction to GUI Programming\n\nfrom the ﬁrst to the last—tkinter.END isa constant used to signify the last item in contextswhere a widget can contain multipleitems. Then we clear the dirty ﬂag, ﬁlename, and data, since the ﬁle is new and unchanged, and we set the window title to reﬂect the fact that we have a new but unsaved ﬁle.\n\nThe ignore variable holds a sequence of zero or more positional arguments that we don’t care about. In the case of methods invoked as a result of menu options choices or toolbar button presses there are no ignored arguments, but if a keyboard shortcut is used (e.g., Ctrl+N), then the invoking event is passed, and since we don’t care how the user invoked the action, we ignore the event that requested it.\n\ndef okayToContinue(self): if not self.dirty: return True\n\nreply = tkinter.messagebox.askyesnocancel(\n\n\"Bookmarks - Unsaved Changes\", \"Save unsaved changes?\", parent=self.parent)\n\nif reply is None:\n\nreturn False\n\nif reply:\n\nreturn self.fileSave()\n\nreturn True\n\nIf the user wants to perform an action that will clear the list box (creating or opening a new ﬁle, for example), we must give them a chance to save any unsaved changes. If the ﬁle isn’t dirty there are no changes to save, so we return True right away. Otherwise, we pop up a standard message box with Yes, No, and Cancelbuttons. If the user cancels the reply is None; we take this to mean that they don’t want to continue the action they started and don’t want to save, so we just return False. If the user says yes, reply is True, so we give them the chance to save and return True if they saved and False otherwise. And if the user says no, reply is False, telling us not to save, but we still return True because they want to continue the action they started, abandoning their unsaved changes.\n\nTk’s standard dialogs are not imported by import tkinter, so in addition to that import we must do import tkinter.messagebox, and for the following method, import tkinter.filedialog. On Windows and Mac OS X the standard native dialogs are used, whereas on other platforms Tk-speciﬁc dialogs are used. We always give the parent to standard dialogs since this ensures that they are automatically centered over the parent window when they pop up.\n\nAll thestandarddialogsaremodal,which meansthat onceonepopsup,it isthe only window in the program that the user can interact with,so they must close it (by clicking OK, Open, Cancel, or a similar button) before they can interact with the rest of the program. Modal dialogs are easiest for programmers to",
      "page_number": 555
    },
    {
      "number": 57,
      "title": "Segment 57 (pages 569-580)",
      "start_page": 569,
      "end_page": 580,
      "detection_method": "topic_boundary",
      "content": "Main-Window-StylePrograms\n\nwork with since the user cannot change the program’sstate behind the dialog’s back, and because they block until they are closed. The blocking means that when we create or invoke a modal dialog the statement that follows will be executed only when the dialog is closed.\n\ndef fileSave(self, *ignore):\n\nif self.filename is None:\n\nfilename = tkinter.filedialog.asksaveasfilename(\n\ntitle=\"Bookmarks - Save File\", initialdir=\".\", filetypes=[(\"Bookmarks files\", \"*.bmf\")], defaultextension=\".bmf\", parent=self.parent)\n\nif not filename: return False\n\nself.filename = filename if not self.filename.endswith(\".bmf\"):\n\nself.filename += \".bmf\"\n\ntry:\n\nwith open(self.filename, \"wb\") as fh:\n\npickle.dump(self.data, fh, pickle.HIGHEST_PROTOCOL)\n\nself.dirty = False self.setStatusBar(\"Saved {0} items to {1}\".format(\n\nlen(self.data), self.filename))\n\nself.parent.title(\"Bookmarks - {0}\".format(\n\nos.path.basename(self.filename)))\n\nexcept (EnvironmentError, pickle.PickleError) as err:\n\ntkinter.messagebox.showwarning(\"Bookmarks - Error\", \"Failed to save {0}:\\n{1}\".format( self.filename, err), parent=self.parent)\n\nreturn True\n\nIf there is no current ﬁle we must ask the user to choose a ﬁlename. If they cancelwereturn False toindicatethattheentireoperationshouldbecancelled. Otherwise, we make sure that the given ﬁlename has the right extension. Using the existing or new ﬁlename we save the pickled self.data dictionary into the ﬁle. After saving the bookmarks we clear the dirty ﬂag since there are now no unsaved changes, and put a message on the status bar (which will time out as we will see in a moment), and we update the window’s title bar to include the ﬁlename (without the path).If we could not save the ﬁle,we pop up a warning messagebox (which will automatically have an OK button)to inform the user.\n\ndef setStatusBar(self, text, timeout=5000):\n\nself.statusbar[\"text\"] = text if timeout:\n\n585\n\n586\n\nChapter 15. Introduction to GUI Programming\n\nself.statusbar.after(timeout, self.clearStatusBar)\n\nThis method sets the status bar label’s text, and if there is a timeout (a ﬁve- second timeout is the default), the method sets up a single shot timer to clear the status bar after the timeout period.\n\ndef fileOpen(self, *ignore):\n\nif not self.okayToContinue():\n\nreturn\n\ndir = (os.path.dirname(self.filename)\n\nif self.filename is not None else \".\")\n\nfilename = tkinter.filedialog.askopenfilename( title=\"Bookmarks - Open File\", initialdir=dir, filetypes=[(\"Bookmarks files\", \"*.bmf\")], defaultextension=\".bmf\", parent=self.parent)\n\nif filename:\n\nself.loadFile(filename)\n\nThis method starts off the same as MainWindow.fileNew() to give the user the chance to save any unsaved changes or to cancel the ﬁle open action. If the user chooses to continue we want to give them a sensible starting directory,so we use the directory of the current ﬁle if there is one, and the current working directory otherwise. The filetypes argument isa list of (description,wildcard) 2-tuples that the ﬁle dialog should show. If the user chose a ﬁlename, we set the current ﬁlename to the one they chose and call the loadFile() method to do the actual ﬁle reading.\n\nSeparating out the loadFile() method is common practice to make it easier to loada ﬁlewithouthaving toprompttheuser. For example,someprogramsload the last used ﬁle at start-up,and some programshave recently used ﬁles listed in a menu so that when the user chooses one the loadFile() method is called directly with the menu option’s associated ﬁlename.\n\ndef loadFile(self, filename):\n\nself.filename = filename self.listBox.delete(0, tkinter.END) self.dirty = False try:\n\nwith open(self.filename, \"rb\") as fh:\n\nself.data = pickle.load(fh)\n\nfor name in sorted(self.data, key=str.lower): self.listBox.insert(tkinter.END, name)\n\nself.setStatusBar(\"Loaded {0} bookmarks from {1}\".format(\n\nself.listBox.size(), self.filename))\n\nself.parent.title(\"Bookmarks - {0}\".format(\n\nos.path.basename(self.filename)))\n\nMain-Window-StylePrograms\n\nexcept (EnvironmentError, pickle.PickleError) as err:\n\ntkinter.messagebox.showwarning(\"Bookmarks - Error\", \"Failed to load {0}:\\n{1}\".format( self.filename, err), parent=self.parent)\n\nWhen this method is called we know that any unsaved changes have been saved or abandoned, so we are free to clear the list box. We set the current ﬁlename to the one passed in, clear the list box and the dirty ﬂag, and then attempt to open the ﬁle and unpickle it into the self.data dictionary. Once we have the data we iterate over all the bookmark names and append each one to the list box. Finally, we give an informative message in the status bar and update the window’s title bar. If we could not read the ﬁle or if we couldn’t unpickle it, we pop up a warning message box to inform the user.\n\ndef fileQuit(self, event=None):\n\nif self.okayToContinue(): self.parent.destroy()\n\nThis is the last ﬁle menu option method. We give the user the chance to save any unsaved changes;if they cancel we do nothing and the program continues; otherwise,we tell the parent to destroy itself and this leads to a clean program termination. If we wanted to save user preferences we would do so here, just before the destroy() call.\n\ndef editAdd(self, *ignore):\n\nform = AddEditForm(self.parent) if form.accepted and form.name:\n\nself.data[form.name] = form.url self.listBox.delete(0, tkinter.END) for name in sorted(self.data, key=str.lower): self.listBox.insert(tkinter.END, name)\n\nself.dirty = True\n\nIf the user asks to add a new bookmark (by clicking Edit→Add, or by clicking toolbar button,or by pressing the Ctrl+A keyboard shortcut),thismethod the is called. The AddEditForm is a custom dialog covered in the next subsection; all that we need to know to use it is that it has an accepted ﬂag which is set to True if the user clicked OK, and to False if they clicked Cancel, and two data attributes,name and url,that hold the name and URL of the bookmark the user has added or edited.\n\nWe create a new AddEditForm which immediately pops up as a modal dialog—and therefore blocks, so the if form.accepted … statement is not exe- cuted until the dialog has closed.\n\nIf the user clicked OK in the AddEditForm dialog and they gave the bookmark a name, we add the new bookmark’s name and URL to the self.data dictionary.\n\n587\n\n588\n\nChapter 15. Introduction to GUI Programming\n\nThen we clear the list box and reinsert all the data in sorted order. It would be more efﬁcient to simply insert the new bookmark in the right place, but even with hundreds of bookmarks the difference would hardly be noticeable on a modern machine. At the end we set the dirty ﬂag since we now have an unsaved change.\n\ndef editEdit(self, *ignore):\n\nindexes = self.listBox.curselection() if not indexes or len(indexes) > 1:\n\nreturn\n\nindex = indexes[0] name = self.listBox.get(index) form = AddEditForm(self.parent, name, self.data[name]) if form.accepted and form.name:\n\nself.data[form.name] = form.url if form.name != name:\n\ndel self.data[name] self.listBox.delete(0, tkinter.END) for name in sorted(self.data, key=str.lower): self.listBox.insert(tkinter.END, name)\n\nself.dirty = True\n\nEditing is slightly more involved than adding because ﬁrst we must ﬁnd the bookmark the user wants to edit. The curselection() method returns a (possibly empty) list of index positions for all its selected items. If exactly one item is selected we retrieve its text since that is the name of the bookmark the user wantsto edit (and also the key to the self.data dictionary).We then create a new AddEditForm passing the name and URL of the bookmark the user wants to edit.\n\nAfter the form has been closed, if the user clicked OK and set a nonempty bookmark name we update the self.data dictionary. If the new name and the old name are the same we can just set the dirty ﬂag and we are ﬁnished (in thiscasepresumably theuser editedtheURL),but if thebookmark’snamehas changed we delete the dictionary item whose key is the old name, clear the list box, and then repopulate the list box with the bookmarks just as we did after adding a bookmark.\n\ndef editDelete(self, *ignore):\n\nindexes = self.listBox.curselection() if not indexes or len(indexes) > 1:\n\nreturn\n\nindex = indexes[0] name = self.listBox.get(index) if tkinter.messagebox.askyesno(\"Bookmarks - Delete\",\n\n\"Delete '{0}'?\".format(name)):\n\nMain-Window-StylePrograms\n\nself.listBox.delete(index) self.listBox.focus_set() del self.data[name] self.dirty = True\n\nTo delete a bookmark we must ﬁrst ﬁnd out which bookmark the user has cho- sen, so this method begins with the same lines that the MainWindow.editEdit() method starts with. If exactly one bookmark is selected we pop up a message box asking the user whether they really want to delete it. If they say yes the message box function returns True and we delete the bookmark from the list box and from the self.data dictionary, and set the dirty ﬂag. We also set the keyboard focus back to the list box.\n\ndef editShowWebPage(self, *ignore):\n\nindexes = self.listBox.curselection() if not indexes or len(indexes) > 1:\n\nreturn\n\nindex = indexes[0] url = self.data[self.listBox.get(index)] webbrowser.open_new_tab(url)\n\nIf the user invokes this method we ﬁnd the bookmark they have selected and retrievethecorrespondingURLfromthe self.data dictionary. Thenweusethe webbrowser module’s webbrowser.open_new_tab() function to open the user’s web browser with the given URL.If the web browser is not already running, it will be launched.\n\napplication = tkinter.Tk() path = os.path.join(os.path.dirname(__file__), \"images/\") if sys.platform.startswith(\"win\"):\n\nicon = path + \"bookmark.ico\" application.iconbitmap(icon, default=icon)\n\nelse:\n\napplication.iconbitmap(\"@\" + path + \"bookmark.xbm\")\n\nwindow = MainWindow(application) application.protocol(\"WM_DELETE_WINDOW\", window.fileQuit) application.mainloop()\n\nThe last lines of the program are similar to those used for the interest-tk.pyw program we saw earlier, but with three differences. One difference is that if the user clicks the program window’s close box a different method is called for the Bookmarks program than the one used for the Interest program. An- other difference is that on Windows the iconbitmap() method has an addi- tional argument which allows us to specify a default icon for all the program’s windows—this is not needed on Unix platforms since this happens automati- cally. And the last difference is that we set the application’s title (in the title\n\n589\n\n590\n\nChapter 15. Introduction to GUI Programming\n\nbar) in the MainWindow class’s methods rather than here. For the Interest pro- gram the title never changed,so it needed to be set only once,but for the Book- marks program we change the title text to include the name of the bookmarks ﬁle being worked on.\n\nNow that we have seen the implementationof the main window’sclassand the code that initializes the program and starts off the event loop, we can turn our attention to the AddEditForm dialog.\n\nCreating a Custom Dialog\n\nThe AddEditForm dialog provides a means by which users can add and edit bookmark names and URLs. It is shown in Figure 15.6 where it is being used to edit an existing bookmark (hence the “Edit” in the title). The same dialog can also be used for adding bookmarks. We will begin by reviewing thedialog’s initializer, broken into four parts.\n\nFigure 15.6 The Bookmarks program’s Add/Edit dialog\n\nclass AddEditForm(tkinter.Toplevel):\n\ndef __init__(self, parent, name=None, url=None):\n\nsuper().__init__(parent) self.parent = parent self.accepted = False self.transient(self.parent) self.title(\"Bookmarks - \" + (\n\n\"Edit\" if name is not None else \"Add\"))\n\nself.nameVar = tkinter.StringVar() if name is not None:\n\nself.nameVar.set(name)\n\nself.urlVar = tkinter.StringVar() self.urlVar.set(url if url is not None else \"http://\")\n\nWe have chosen to inherit tkinter.TopLevel, a bare widget designed to serve as a base class for widgets used as top-level windows. We keep a reference to the parent and create a self.accepted attribute and set it to False. The call to the transient() method is done to inform the parent window that this window must always appear on top of the parent. The title is set to indicate adding or editing depending on whether a name and URL have been passed in. Two\n\n||\n\nMain-Window-StylePrograms\n\ntkinter.StringVars are created to keep track of the bookmark’sname and URL, and both are initialized with the passed-in values if the dialog is being used for editing.\n\nnameLabel\n\nnameEntry\n\nurlLabel\n\nurlEntry\n\nokButton\n\ncancelButton\n\nFigure 15.7 The Bookmarks program’s Add/Edit dialog’s layout\n\nframe = tkinter.Frame(self) nameLabel = tkinter.Label(frame, text=\"Name:\", underline=0) nameEntry = tkinter.Entry(frame, textvariable=self.nameVar) nameEntry.focus_set() urlLabel = tkinter.Label(frame, text=\"URL:\", underline=0) urlEntry = tkinter.Entry(frame, textvariable=self.urlVar) okButton = tkinter.Button(frame, text=\"OK\", command=self.ok) cancelButton = tkinter.Button(frame, text=\"Cancel\",\n\ncommand=self.close)\n\nnameLabel.grid(row=0, column=0, sticky=tkinter.W, pady=3,\n\npadx=3)\n\nnameEntry.grid(row=0, column=1, columnspan=3,\n\nsticky=tkinter.EW, pady=3, padx=3)\n\nurlLabel.grid(row=1, column=0, sticky=tkinter.W, pady=3,\n\npadx=3)\n\nurlEntry.grid(row=1, column=1, columnspan=3,\n\nsticky=tkinter.EW, pady=3, padx=3)\n\nokButton.grid(row=2, column=2, sticky=tkinter.EW, pady=3,\n\npadx=3)\n\ncancelButton.grid(row=2, column=3, sticky=tkinter.EW, pady=3,\n\npadx=3)\n\nThe widgets are created and laid out in a grid, as illustrated in Figure 15.7. The name and URL text entry widgets are associated with the correspond- ing tkinter.StringVars and the two buttons are set to call the self.ok() and self.close() methods shown further on.\n\nframe.grid(row=0, column=0, sticky=tkinter.NSEW) frame.columnconfigure(1, weight=1) window = self.winfo_toplevel() window.columnconfigure(0, weight=1)\n\nIt only makes sense for the dialog to be resized horizontally, so we make the window frame’s second column horizontally resizable by setting its column weight to 1—this means that if the frame is horizontally stretched the widgets\n\n591\n\n592\n\nChapter 15. Introduction to GUI Programming\n\nin column 1 (the name and URL text entry widgets) will grow to take advan- tage of the extra space. Similarly, we make the window’s column horizontally resizable by setting its weight to 1. If the user changes the dialog’s height, the widgetswill keep their relative positionsand all of them will be centered with- in the window; but if the user changes the dialog’s width, the name and URL text entry widgets will shrink or grow to ﬁt the available horizontal space.\n\nself.bind(\"<Alt-n>\", lambda *ignore: nameEntry.focus_set()) self.bind(\"<Alt-u>\", lambda *ignore: urlEntry.focus_set()) self.bind(\"<Return>\", self.ok) self.bind(\"<Escape>\", self.close)\n\nself.protocol(\"WM_DELETE_WINDOW\", self.close) self.grab_set() self.wait_window(self)\n\nWe created two labels, Name: and URL:,which indicate that they have keyboard accelerators Alt+Nand Alt+U,which when clicked will give the keyboard focus to their corresponding text entry widgets. To make this work we have provided the necessary keyboard bindings. We use lambda functions rather than pass the focus_set() methodsdirectly sothatwecanignoretheevent argument. We have also provided the standard keyboard bindings (Enter and Esc) for the OK and Cancel buttons.\n\nWe usethe protocol() methodtospecify themethodto callif theuser closesthe dialog by clicking the close button. The calls to grab_set() and wait_window() are both needed to turn the window into a modal dialog.\n\ndef ok(self, event=None):\n\nself.name = self.nameVar.get() self.url = self.urlVar.get() self.accepted = True self.close()\n\nIf the user clicks OK (or presses Enter), this method is called. The texts from the tkinter.StringVars are copied to correponding instance variables (which are only now created), the self.accepted variable is set to True, and we call self.close() to close the dialog.\n\ndef close(self, event=None):\n\nself.parent.focus_set() self.destroy()\n\nThis method is called from the self.ok() method, or if the user clicks the win- dow’sclose box or if the user clicks Cancel(or presses Esc).It givesthe keyboard focusback to the parent and makesthe dialog destroy itself. In thiscontext de- stroy justmeansthatthewindowanditswidgetsaredestroyed;theAddEditForm instance continues to exist because the caller has a reference to it.\n\nMain-Window-StylePrograms\n\nAfter the dialog has been closed the caller checks the accepted variable, and if True, retrieves the name and URL that were added or edited. Then, once the MainWindow.editAdd() or MainWindow.editEdit() method has ﬁnished, the AddEditForm object goes out of scope and is scheduled for garbage collection.\n\nSummary\n\nThis chapter gave you a ﬂavor of GUI programming using the Tk GUI library. Tk’s big advantage is that it comes as standard with Python. But it has many drawbacks, not the least of which is that it is a vintage library that works somewhat differently than most of the more modern alternatives.\n\nIf you are new to GUI programming, keep in mind that the major cross-plat- form competitors to Tk—PyGtk, PyQt, and wxPython—are all much easier to learn and use than Tk, and all can achieve better results using less code. Furthermore, these Tk competitors all have more and better Python-speciﬁc documentation, far more widgets, and a better look and feel, and allow us to create widgets from scratch with complete control over their appearance and behavior.\n\nAlthough Tk is useful for creating very small programsor for situationswhere only Python’s standard library is available, in all other circumstances any one of the other cross-platform libraries is a much better choice.\n\nExercises\n\nThe ﬁrst exercise involves copying and modifying the Bookmarks program shown in this chapter; the second exercise involves creating a GUI program from scratch.\n\n1. Copy the bookmarks-tk.pyw program and modify it so that it can import and export the DBM ﬁles that the bookmarks.py console program (created as an exercise in Chapter 12) uses. Provide two new menu options in the File menu, Import and Export.Make sure you provide keyboard shortutsfor both (keep in mind that Ctrl+E is already in use for Edit→Edit). Similarly, create two corresponding toolbar buttons. This involves adding about ﬁve lines of code to the main window’s initializer. Two methods to provide the functionality will be required, fileImport() and fileExport(), between them fewer than 60 lines of code including error handling. For importing you can decide whether to merge imported bookmarks,or toreplacetheexisting bookmarkswiththoseimported. The code is not difﬁcult, but does require quite a bit of care. A solution (that merges imported bookmarks) is provided in bookmarks-tk_ans.py.\n\n593\n\n|||\n\n|||\n\n594\n\nChapter 15. Introduction to GUI Programming\n\nNote that while on Unix-like systems a ﬁle sufﬁx of .dbm is ﬁne, on Win- dows each DBM “ﬁle” is actually three ﬁles. So for Windows ﬁle dialogs the pattern should be *.dbm.dat and the default extension *.dbm.dat—but the actual ﬁlename should have a sufﬁx of .dbm,so the last four characters must be chopped off the ﬁlename.\n\n2. In Chapter 13 we saw how to create and use regular expressions to match text. Create a dialog-style GUI program that can be used to enter and test regexes, as shown in Figure 15.8.\n\nFigure 15.8 The Regex program\n\nYou will need to read the re module’s documentation since the program must behave correctly in the face of invalid regexesor when iterating over the match groups,since in most casesthe regex won’t have as many match groups as there are labels to show them. Make sure the program has full support for keyboard users—with navigation to the text entry widgets us- ing Alt+R and Alt+T, control of the checkboxes with Alt+I and Alt+D, program termination on Ctrl+Qand Esc,and recalculationif the user pressesand re- leases a key in either of the text entry widgets, and whenever a checkbox is checked or unchecked.\n\nThe program is not too difﬁcult to write, although the code for displaying the matches and the group numbers (and names where speciﬁed) is a tiny bit tricky—a solution is provided in regex-tk.pyw, which is about one hundred forty lines.\n\nEpilogue\n\nIf you’ve read at least the ﬁrst six chapters and either done the exercises or written your own Python 3 programs independently, you should be in a good position to build up your experienceand programming skillsasfar asyou want to go—Python won’t hold you back!\n\nTo improve and deepen your Python language skills, if you read only the ﬁrst six chapters, make sure you are familiar with the material in Chapter 7, and that you read and experiment with at least some of the material in Chapter 8, and in particular the with statement and context managers. It is also worth reading at least Chapter 9’s section on testing.\n\nKeep in mind, though, that apart from the pleasure and learning aspects of developing everything from scratch, doing so is rarely necessary in Python. We have already mentioned the standard library and the Python Package Index, pypi.python.org/pypi, both of which provide a huge amount of func- tionality. In addition, the online Python Cookbook at code.activestate.com/ recipes/langs/python/ offers a large number of tricks,tips,and ideas,although it is Python 2-oriented at the time of this writing.\n\nIt is also possible to create modules for Python in other languages (any lan- guage that can export C functions, as most can). These can be developed to work cooperatively with Python using Python’s C API.Shared libraries (DLLs on Windows), whether created by us or obtained from a third party, can be ac- cessed from Python using the ctypes module, giving us virtually unlimited ac- cess to the vast amount of functionality available over the Internet thanks to the skill and generosity of open source programmers worldwide.\n\nAnd if you want to participate in the Python community, a good place to start is www.python.org/community where you will ﬁnd Wikis and many general and special-interest mailing lists.\n\n595\n\n||||\n\nSelected Bibliography\n\nThisisa small selected annotatedbibliography of programming-relatedbooks. Most of thebookslisted arenot Python-speciﬁc,but all of them areinteresting, useful—and accessible.\n\nClean Code\n\nRobert C. Martin (Prentice Hall, 2009, ISBN 0132350882) This book addressesmany “tactical” issuesin programming:good naming, function design, refactoring, and similar. The book has many interesting and useful ideas that should help any programmer improve their coding style and make their programs more maintainable. (The book’s examples are in Java.)\n\nCode Complete: A Practical Handbook of Software Construction,Second Edition\n\nSteve McConnell (Microsoft Press, 2004, ISBN 0735619670) This book shows how to build solid software, going beyond the language speciﬁcs into the realms of ideas, principles, and practices. The book is packed with ideas that will make any programmer think more deeply about their programming. (The book’s examples are mostly in C++, Java, and Visual Basic.)\n\nDomain-Driven Design\n\nEric Evans (Addison-Wesley, 2004, ISBN 0321125215) A very interesting book on software design, particularly useful for large, multiperson projects. At itsheart it is about creating and reﬁning domain models that represent what the system is designed to do, and about creating a ubiquitous language through which all those involved with the system—not just software engineers—can communicate their ideas. (The book’s examples are in Java.)\n\nDesign Patterns\n\nErich Gamma, Richard Helm, Ralph Johnson, John Vlissides (Addison- Wesley, 1998, ISBN 0201633612) Deservedly one of the most inﬂuential programming books of modern times. The design patterns are fascinating and of great practical use in everyday programming. (The book’s examples are in C++.)\n\nMastering Regular Expressions,Third Edition\n\nJeffrey E. F. Friedl (O’Reilly, 2006, ISBN 0596528124) This is the standard text on regular expressions—a very interesting and useful book. Most of the coverage is understandably devoted to\n\n597\n\n||||",
      "page_number": 569
    },
    {
      "number": 58,
      "title": "Segment 58 (pages 581-597)",
      "start_page": 581,
      "end_page": 597,
      "detection_method": "topic_boundary",
      "content": "598\n\nSelected Bibliography\n\nPerl—which probably has more regular expression features than any oth- er tool. However, since Python supports a large subset of what Perl pro- vides (plus Python’s own ?P extensions), the book is still useful to Python programmers.\n\nParsing Techniques: A Practical Guide,Second Edition\n\nDick Grune, Ceriel J. H. Jacobs (Springer, 2007, ISBN 038720248X) This book provides comprehensive and in-depth coverage of parsing. The ﬁrst edition can be downloaded in PDF format from www.cs.vu.nl/~dick/ PTAPG.html.\n\nPython Cookbook,Second Edition\n\nAlex Martelli, Anna Ravenscroft, David Ascher ISBN 0596007973) This book is full of interesting—and practical—ideas covering all aspects of Python programming. The second edition is based on Python 2.4, so it might be worthwhile waiting and hoping for a Python 3-speciﬁc edition to appear.\n\n(O’Reilly, 2005,\n\nPython Essential Reference,Fourth Edition\n\nDavid M. Beazley (Addison-Wesley, 2009, ISBN 0672329786) The book’s title is an accurate description. The fourth edition has been updated to cover both Python 2.6 and Python 3.0. There is a little overlap with this book, but most of the Essential Reference is devoted to Python’s standard library as well as covering more advanced features such as extending Python with C libraries and embedding the Python interpreter into other programs.\n\nRapid GUI Programming with Python and Qt\n\nMark Summerﬁeld (Prentice Hall, 2007, ISBN 0132354187) This book (by this book’s author) teaches PyQt4 programing. PyQt4 (built on top of Nokia’s C++/Qt GUI toolkit) is probably the easiest-to-use cross- platform GUI library, and the one that arguably produces the best user interfaces—especially compared with tkinter. The book uses Python 2.5, although Python 3 versions of the examples are available from the book’s web site.\n\nIndex\n\nAll functions and methods are listed under their class or module, and in most casesalsoastop-leveltermsin their own right.For modulesthat containclasses, look under the class for its methods. Where a method or function name is close enough to a concept, the concept is not usually listed. For example, there is no entry for “splitting strings”,but there are entries for the str.split() method.\n\nSymbols\n\n!= (not equal operator), 23, 241, 242,\n\n259, 379\n\n# comment character, 10 % (modulus/remainder operator), 55,\n\n253\n\n%= (modulusaugmented assignment\n\noperator), 253\n\n& (bitwise AND operator),57,122,123,\n\n130, 253\n\n+ (addition operator, concatenation operator), 55, 108, 114, 140, 253 += (addition augmented assignment operator, append/extend opera- tor), 108, 114, 115, 144, 253\n\n(subtraction operator, negation operator), 55, 122, 123, 253 -= (subtraction augmented assign- ment operator), 123, 253 / (division operator), 31, 55, 253 /= (division augmented assignment\n\n&= (bitwise AND augmented assign- ment operator), 123, 253 () (tuple creation operator, func-\n\noperator), 253\n\n// (truncating division operator),55,\n\n253, 330\n\ntion and method call operator, expression operator), 341, 377, 383\n\n//= (truncating division augmented assignment operator), 253 < (less than operator), 123, 145, 242,\n\n(multiplication operator, replica- tion operator,sequence unpack- er, from … import operator), 55, 72, 90, 108, 110, 114, 140, 197, 200–201, 253, 336, 379, 460\n\n(multiplication operator, replica- tion operator,sequence unpack- er, from … import operator), 55, 72, 90, 108, 110, 114, 140, 197, 200–201, 253, 336, 379, 460\n\n<< (int shift left operator), 57, 253 <<= (int shift left augmented assign-\n\nment operator), 253\n\n<= (less than or equal to operator),\n\n= (multiplication augmented as- signment operator, replication augmented assignment opera- tor), 72, 108, 114, 253\n\n= (multiplication augmented as- signment operator, replication augmented assignment opera- tor), 72, 108, 114, 253\n\n= (name binding operator,object ref- erencecreationandassignment operator), 16, 146\n\n** (power/exponentiation operator,\n\n== (equal to operator), 23, 241, 242,\n\nmapping unpacker), 55, 179, 253, 304, 379\n\n254, 259, 379\n\n> (greater than operator), 123, 242,\n\n**= (power/exponentiation aug-\n\n259, 379\n\nmented assignment operator), 253\n\n>= (greater than or equal to opera-\n\ntor), 123, 242, 259, 379\n\n>> (int shift right operator), 57, 253\n\n599\n\n600\n\n>>= (int shift right augmented as- signment operator), 253 @ (decorator operator), 246–248 [] (indexing operator, item access operator, slicing operator), 69, 108,110,113,114,116,117,262, 264, 273, 274, 278, 279, 293\n\n\\n (newline character, statement\n\nterminator), 66\n\n^ (bitwise XOR operator),57,122,123,\n\n253\n\n^= (bitwise XOR augmented assign- ment operator), 123, 253\n\n_ (underscore), 53 | (bitwise OR operator), 57, 122, 123,\n\n253\n\n|= (bitwise OR augmented assign- ment operator), 123, 253 ~ (bitwise NOT operator), 57, 253\n\nA\n\nabc module\n\nABCMeta type, 381, 384, 387 @abstractmethod(), 384, 387 abstractproperty(), 384, 387\n\n__abs__(), 253 abs() (built-in), 55, 56, 96, 145, 253 abspath() (os.path module), 223, 406 abstract base class (ABC), 269,\n\n380–388\n\nsee also collections and numbers\n\nmodules\n\nAbstract.py (example), 386 Abstract Syntax Tree (AST), 515 @abstractmethod() (abc module), 384,\n\n387\n\nabstractproperty() (abc module),\n\n384, 387\n\naccelerator, keyboard, 574, 580, 592 access control, 238, 249, 270, 271 acos() (math module), 60 acosh() (math module), 60 __add__() (+), 55, 253\n\nIndex\n\nadd() (set type), 123 aggregating data, 111 aggregation, 269 aifc module, 219 algorithm, for searching, 217, 272 algorithm, for sorting, 145, 282 algorithm, MD5, 449, 452 __all__ (attribute), 197, 200, 201 all() (built-in), 140, 184, 396, 397 alternation, regex, 494–495 __and__() (&), 57, 251, 253, 257 and (logical operator), 58 annotations, 360–363 __annotations__ (attribute), 360 anonymous functions; see lambda\n\nstatement\n\nany() (built-in), 140, 205, 396, 397 append()\n\nbytearray type, 299 list type, 115, 117, 118, 271\n\narchive ﬁles, 219 arguments, command-line, 215 arguments, function, 379 default, 173, 174, 175 immutable, 175 keyword, 174–175, 178, 179, 188,\n\n189, 362 mutable, 175 positional, 173–175, 178, 179,\n\n189, 362\n\nunpacking, 177–180\n\narguments, interpreter, 185, 198,\n\n199\n\nargv list (sys module), 41, 343 array module, 218 arraysize attribute (cursor object),\n\n482\n\nas_integer_ratio() (float type), 61 as (binding operator), 163, 196, 369 ascii() (built-in), 68, 83 ASCII encoding, 9, 68, 91–94, 220,\n\n293, 504\n\nsee also character encodings\n\nasin() (math module), 60 asinh() (math module), 60\n\nIndex\n\naskopenfilename() (tkin-\n\nter.filedialog module), 586\n\nasksaveasfilename() (tkin-\n\nter.filedialog module), 585 askyesno() (tkinter.messagebox mod-\n\nule), 589\n\naskyesnocancel() (tkin-\n\nter.messagebox module), 584 assert (statement), 184–185, 205,\n\n208, 247\n\nAssertionError (exception), 184 assertions, regex, 496–499 associativity, 517–518, 551, 565 AST (Abstract Syntax Tree), 515 asynchat module, 225 asyncore module, 225 atan() (math module), 60 atan2() (math module), 60 atanh() (math module), 60 attrgetter() (operator module), 369,\n\n397 attribute\n\n__all__, 197, 200, 201 __annotations__, 360 __call__, 271, 350, 392 __class__, 252, 364, 366 __dict__, 348, 363, 364 __doc__, 357 __file__, 441 __module__, 243 __name__, 206, 252, 357, 362, 377 private, 238, 249, 270, 271, 366 __slots__, 363, 373, 375, 394 attribute access methods, table of,\n\n365\n\nAttributeError (exception), 240, 241,\n\n275, 350, 364, 366 attributes, 197, 200, 201,\n\n206, 246–248, 252, 271, 351, 363–367\n\nattributes, mutable and immutable,\n\n264\n\naudio-related modules, 219 audioop module, 219\n\naugmented assignment, 31–33, 56,\n\n108, 114\n\nB\n\nB option, interpreter, 199 backreferences,regex, 495 backtrace; see traceback backups, 414 base64 module, 219, 220–221 basename() (os.path module), 223 Berkeley DB, 475 bigdigits.py (example), 39–42 BikeStock.py (example), 332–336 bin() (built-in), 55, 253 binary data, 220 binary ﬁles, 295–304, 324–336 binary numbers, 56 binary search, 272 bindings, event, 576 bindings, keyboard, 576 bisect module, 217, 272 bit_length() (int type), 57 bitwise operators, table of, 57 block structure, using indentation,\n\n27\n\nblocks.py (example), 525–534,\n\n543–547, 559–562 BNF (Backus–Naur Form),\n\n515–518\n\nbookmarks-tk.pyw (example),\n\n578–593\n\n__bool__(), 250, 252, 258 bool() (built-in), 250 bool type, 58\n\nbool() (built-in), 58, 250, 309 conversion, 58\n\nBoolean expressions, 26, 54 branching; see if statement branching, with dictionaries,\n\n340–341\n\nbreak (statement), 161, 162\n\n601\n\n602\n\nbuilt-in\n\nabs(), 55, 56, 96, 145, 253 all(), 140, 184, 396, 397 any(), 140, 205, 396, 397 ascii(), 68, 83 bin(), 55, 253 bool(), 58, 250, 309 chr(), 67, 90, 504 @classmethod(), 257, 278 compile(), 349 complex(), 63, 253 delattr(), 349 dict(), 127, 147 dir(), 52, 172, 349, 365 divmod(), 55, 253 enumerate(), 139–141, 398, 524 eval(), 242, 243, 258, 266, 275,\n\n344, 349, 379\n\nexec(), 260, 345–346, 348, 349,\n\n351\n\nfilter(), 395, 397 float(), 61, 154, 253 format(), 250, 254 frozenset(), 125 getattr(),349,350,364,368,374,\n\n391, 409\n\nglobals(), 345, 349 hasattr(), 270, 349, 350, 391 hash(), 241, 250, 254 help(), 61, 172 hex(), 55, 253 id(), 254 __import__(), 349, 350 input(), 34, 96 int(), 55, 61, 136, 253, 309 isinstance(), 170, 216, 242, 270,\n\n382, 390, 391 issubclass(), 390 iter(), 138, 274, 281 len(), 71, 114, 122, 140, 265, 275 list(), 113, 147 locals(), 81, 82, 97, 154, 188, 189,\n\n190, 345, 349, 422, 423, 484\n\nmap(), 395, 397, 539 max(), 140, 154, 396, 397\n\nIndex\n\nbuilt-in (cont.)\n\nmin(), 140, 396, 397 next(), 138, 343, 401 oct(), 55, 253 ord(), 67, 90, 364 pow(), 55 print(), 11, 180, 181, 214, 422 @property(), 246–248, 376, 385,\n\n394\n\nrange(), 115, 118, 119, 140,\n\n141–142, 365 repr(), 242, 250 reversed(), 72, 140, 144, 265, 274 round(), 55, 56, 61, 252, 253, 258 set(), 122, 147 setattr(), 349, 379, 409 sorted(), 118, 133, 140, 144–146,\n\n270\n\n@staticmethod(), 255 str(), 65, 136, 243, 250 sum(), 140, 396, 397 super(), 241, 244, 256, 276, 282,\n\n381, 385 tuple(), 108 type(), 18, 348, 349 vars(), 349 zip(), 127, 140, 143–144, 205,\n\n389\n\nbuiltins module, 364 Button type (tkinter module), 581,\n\n591 byte-code, 198 byte order, 297 bytearray type, 293, 301, 383,\n\n418–419, 462\n\nappend(), 299 capitalize(), 299 center(), 299 count(), 299 decode(), 93, 94, 299, 326, 336,\n\n443\n\nendswith(), 299 expandtabs(), 299 extend(), 299, 301, 462 find(), 299\n\nIndex\n\nbytearray type (cont.) fromhex(), 293, 299 index(), 299 insert(), 293, 299 isalnum(), 299 isalpha(), 299 isdigit(), 299 islower(), 299 isspace(), 299 istitle(), 300 isupper(), 300 join(), 300 ljust(), 300 lower(), 300 lstrip(), 300 methods, table of, 299, 300, 301 partition(), 300 pop(), 293, 300 remove(), 300 replace(), 293, 300 reverse(), 300 rfind(), 299 rindex(), 299 rjust(), 300 rpartition(), 300 rsplit(), 300 rstrip(), 300 split(), 300 splitlines(), 300 startswith(), 300 strip(), 300 swapcase(), 300 title(), 300 translate(), 300 upper(), 293, 301 zfill(), 301\n\nbytes type, 93, 293, 297, 383,\n\n418–419\n\ncapitalize(), 299 center(), 299 count(), 299 decode(), 93, 94, 226, 228, 299,\n\n302, 326, 336, 418, 443\n\nendswith(), 299 expandtabs(), 299\n\nbytes type (cont.) find(), 299 fromhex(), 293, 299 index(), 299 isalnum(), 299 isalpha(), 299 isdigit(), 299 islower(), 299 isspace(), 299 istitle(), 300 isupper(), 300 join(), 300 literal, 93, 220 ljust(), 300 lower(), 300 lstrip(), 300 methods, table of, 299, 300, 301 partition(), 300 replace(), 293, 300 rfind(), 299 rindex(), 299 rjust(), 300 rpartition(), 300 rsplit(), 300 rstrip(), 300 split(), 300 splitlines(), 300 startswith(), 300 strip(), 300 swapcase(), 300 title(), 300 translate(), 300 upper(), 293, 301 zfill(), 301\n\n.bz2 (extension), 219 bz2 module, 219\n\nC\n\nc option, interpreter, 198 calcsize() (struct module), 297 calendar module, 216 __call__ (attribute), 271, 350, 392 __call__(), 367, 368\n\n603\n\n604\n\ncall() (subprocess module), 209 callable; see functions and methods Callable ABC (collections module),\n\n383, 391\n\ncallable objects, 271, 367 capitalize()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\ncaptures, regex, 494–495, 506 car_registration_server.py (exam-\n\nple), 464–471\n\ncar_registration.py (example),\n\n458–464\n\ncase statement; see dictionary\n\nbranching\n\ncategory() (unicodedata module),\n\n361\n\nceil() (math module), 60 center()\n\nbytearray type, 299 bytes type, 299 str type, 73 cgi module, 225 cgitb module, 225 chaining exceptions, 419–420 changing dictionaries, 128 changing lists, 115 character class, regex, 491 character encodings, 9, 91–94, 314\n\nsee also ASCII encoding, Latin 1\n\nencoding, Unicode\n\nCharGrid.py (example), 207–212 chdir() (os module), 223 checktags.py (example), 169 choice() (random module), 142 chr() (built-in), 67, 90, 504 class (statement), 238, 244, 378,\n\n407\n\n__class__ (attribute), 252, 364, 366 class, mixin, 466 class decorators, 378–380, 407–409 class methods, 257 class variables, 255, 465 classes, immutable, 256, 261\n\nIndex\n\n@classmethod(), 257, 278 clear()\n\ndict type, 129 set type, 123\n\nclose()\n\nconnection object, 481 coroutines, 399, 401, 402 cursor object, 482 ﬁle object, 131, 167, 325\n\nclosed attribute (ﬁle object), 325 closures, 367, 369 cmath module, 63 code comments, 10 collation order (Unicode), 68–69 collections; see dict, list, set, and\n\ntuple types\n\ncollections, copying, 146–148 collections module, 217–219, 382\n\nCallable ABC, 383, 391 classes, table of, 383 Container ABC, 383 defaultdict type, 135–136, 153,\n\n183, 450\n\ndeque type, 218, 383 Hashable ABC, 383 Iterable ABC, 383 Iterator ABC, 383 Mapping ABC, 383 MutableMapping ABC, 269, 383 MutableSequence ABC, 269, 383 MutableSet ABC, 383 namedtuple type, 111–113, 234,\n\n365, 523\n\nOrderedDict type, 136–138, 218 Sequence ABC, 383 Set ABC, 383 Sized ABC, 383\n\ncombining functions, 395–397,\n\n403–407\n\ncommand-line arguments; see\n\nsys.argv list\n\ncomment character (#), 10 commit() (connection object), 481,\n\n483\n\ncomparing ﬁles and directories, 223\n\nIndex\n\ncomparing objects, 23, 242 comparing strings, 68–69 comparisons; see <, <=, ==, !=, >, and\n\n>= operators\n\ncompile()\n\nbuilt-in, 349 re module, 310, 400, 500, 501,\n\n502, 521, 524 __complex__(), 253 complex() (built-in), 253 Complex ABC (numbers module), 381 complex type, 62–63, 381\n\ncomplex() (built-in), 63, 253 conjugate(), 62 imag attribute, 62 real attribute, 62\n\ncomposing functions, 395–397,\n\n403–407 composition, 269 comprehensions; see under dict,\n\nlist, and set types compressing ﬁles, 219 concatenation of lists, 114 of strings, 71 of tuples, 108\n\nconcepts, object-oriented, 235 conditional branching; see if state-\n\nment\n\nconditional expression, 160, 176,\n\n189\n\nconfigparser module, 220, 519 conﬁguration ﬁles, 220 conjugate() (complex type), 62 connect() (sqlite3 module), 481 connection object close(), 481 commit(), 481, 483 cursor(), 481, 483 methods, table of, 481 rollback(), 481 see also cursor object\n\nconstant set; see frozenset type constants, 149, 180, 364–365\n\n605\n\nContainer ABC(collections module),\n\n383\n\n__contains__(), 265, 274 context managers, 369–372, 452,\n\n464, 466\n\ncontextlib module, 370, 466 continue (statement), 161, 162 conversions, 57\n\ndate and time, 217 float to int, 61 int to character, 67 int to float, 61 to bool, 58 to complex, 63 to dict, 127 to float, 59, 154 to int, 15, 55 to list, 113, 139 to set, 122 to str, 15, 65 to tuple, 108, 139\n\nconvert-incidents.py (example),\n\n289–323\n\nCoordinated Universal Time (UTC),\n\n216\n\n__copy__(), 275 copy()\n\ncopy module, 147, 275, 282, 469 dict type, 129, 147 frozenset type, 123 set type, 123, 147\n\ncopy module, 245\n\ncopy(), 147, 275, 282, 469 deepcopy(), 148\n\ncopying collections, 146–148 copying objects, 245 copysign() (math module), 60 coroutines, 399–407\n\nclose(), 399, 401, 402 decorator, 401 send(), 401, 402, 405, 406\n\ncos() (math module), 60 cosh() (math module), 60 count()\n\nbytearray type, 299\n\n606\n\ncount() (cont.)\n\nbytes type, 299 list type, 115 str type, 73, 75 tuple type, 108\n\ncProfile module, 360, 432, 434–437 CREATE TABLE (SQL statement), 481 creation, of objects, 240 .csv (extension), 220 csv module, 220 csv2html.py (example), 97–102 csv2html2_opt.py (example), 215 ctypes module, 229 currying; see partial function appli-\n\ncation\n\ncursor() (connection object), 481,\n\n483 cursor object\n\narraysize attribute, 482 close(), 482 description attribute, 482 execute(), 481, 482, 483, 484, 485,\n\n486, 487\n\nexecutemany(), 482 fetchall(), 482, 485 fetchmany(), 482 fetchone(), 482, 484, 486 methods, table of, 482 rowcount attribute, 482 see also connection object custom exceptions, 168–171, 208 custom functions; see functions custom modules and packages,\n\n195–202\n\nD\n\ndaemon threads, 447, 448, 451 data persistence, 220 data structures;see dict, list, set,\n\nand tuple types\n\ndata type conversion; see conver-\n\nsions\n\nIndex\n\ndatabase connection; see connection\n\nobject\n\ndatabase cursor; see cursor object datetime.date type (datetime mod-\n\nule), 306\n\nfromordinal(), 301, 304 today(), 187, 477 toordinal(), 301\n\ndatetime.datetime type (datetime\n\nmodule) now(), 217 strptime(), 309 utcnow(), 217\n\ndatetime module, 186, 216 date type, 301, 309 datetime type, 309\n\nDB-API; see connection object and\n\ncursor object\n\ndeadlock, 445 __debug__ constant, 360 debug (normal) mode; see PYTHONOP-\n\nTIMIZE\n\ndebuggers; see IDLE and pdb mod-\n\nule\n\ndecimal module, 63–65\n\nDecimal(), 64 Decimal type, 63–65, 381\n\ndecode()\n\nbytearray type, 93, 94, 299, 326,\n\n336, 443\n\nbytes type, 93, 94, 226, 228, 299,\n\n302, 326, 336, 418, 443\n\nDecorate, Sort, Undecorate (DSU),\n\n140, 145\n\ndecorating methods and functions,\n\n356–360\n\ndecorator\n\nclass, 378–380, 407–409 @classmethod(), 257, 278 @functools.wraps(), 357 @property(), 246–248, 376, 385,\n\n394\n\n@staticmethod(), 255\n\ndedent() (textwrap module), 307\n\nIndex\n\ndeep copying; see copying collec-\n\ntions\n\ndeepcopy() (copy module), 148 def (statement), 37, 173–176, 209,\n\n238\n\ndefault arguments, 173, 174, 175 defaultdict type (collections mod- ule), 135–136, 153, 183, 450\n\ndegrees() (math module), 60 del (statement), 116, 117, 127, 250,\n\n265, 273, 365\n\n__del__(), 250 __delattr__(), 364, 365 delattr() (built-in), 349 delegation, 378 DELETE (SQL statement), 487 __delitem__() ([]),265,266,273,279,\n\n329, 334\n\ndeque type (collections module),\n\n218, 383\n\ndescription attribute(cursor object),\n\n482\n\ndescriptors, 372–377, 407–409 detach() (stdin ﬁle object), 443 development environment (IDLE),\n\n13–14, 364, 424–425 dialogs, modal, 584, 587, 592 __dict__ (attribute), 348, 363, 364 dict type, 126–135, 383\n\nchanging, 128 clear(), 129 comparing, 126 comprehensions, 134–135 copy(), 129, 147 dict() (built-in), 127, 147 fromkeys(), 129 get(), 129, 130, 264, 351, 374,\n\n469\n\ninverting, 134 items(), 128, 129 keys(), 128, 129, 277 methods, table of, 129 pop(), 127, 129, 265 popitem(), 129 setdefault(), 129, 133, 374\n\ndict type (cont.)\n\nupdate(), 129, 188, 276, 295 updating, 128 values(), 128, 129 view, 129 see also collections.defaultdict, collections.OrderedDict, and SortedDict.py\n\ndictionary, inverting, 134 dictionary branching, 340–341 dictionary comprehensions,\n\n134–135, 278 dictionary keys, 135 difference_update() (set type), 123 difference()\n\nfrozenset type, 123 set type, 122, 123 difflib module, 213 digit_names.py (example), 180 __dir__(), 365 dir() (built-in), 52, 172, 349, 365 directories, comparing, 223 directories, temporary, 222 directory handling, 222–225 dirname() (os.path module), 223, 348 discard() (set type), 123, 124 __divmod__(), 253 divmod() (built-in), 55, 253 __doc__ (attribute), 357 docstrings, 176–177, 202, 204, 210,\n\n211, 247\n\nsee also doctest module\n\ndoctest module, 206–207, 211, 228,\n\n426–428\n\ndocumentation, 172 DOM (Document Object Model); see\n\nxml.dom module\n\nDomain-Speciﬁc Language (DSL),\n\n513\n\nDoubleVar type (tkinter module),\n\n574\n\nDSL (Domain-Speciﬁc Language),\n\n513\n\nDSU (Decorate, Sort, Undecorate),\n\n140, 145\n\n607\n\n608\n\nduck typing; see dynamic typing dump() (pickle module), 267, 294 dumps() (pickle module), 462 duplicates, eliminating, 122 dvds-dbm.py (example), 476–479 dvds-sql.py (example), 480–487 dynamic code execution, 260,\n\n344–346\n\ndynamic functions, 209 dynamic imports, 346–351 dynamic typing, 17, 237, 382\n\nE\n\ne (constant) (math module), 60 editor (IDLE), 13–14, 364, 424–425 element trees; see xml.etree pack-\n\nage\n\nelif (statement);see if statement else (statement);see for loop, if\n\nstatement, and while loop\n\nemail module, 226 encode() (str type), 73, 92, 93, 296,\n\n336, 419, 441\n\nencoding attribute (ﬁle object), 325 encoding errors, 167 encodings, 91–94 encodings, XML, 314 end() (match object), 507 END constant (tkinter module), 583,\n\n587, 588 endianness, 297 endpos attribute (match object), 507 endswith()\n\nbytearray type, 299 bytes type, 299 str type, 73, 75, 76 __enter__(), 369, 371, 372 entities, HTML, 504 Entry type (tkinter module), 591 enumerate() (built-in), 139–141, 398,\n\n524\n\nenums; see namedtuple type environ mapping (os module), 223\n\nIndex\n\nenvironment variable\n\nLANG, 87 PATH, 12, 13 PYTHONDONTWRITEBYTECODE, 199 PYTHONOPTIMIZE, 185, 199, 359,\n\n362\n\nPYTHONPATH, 197, 205\n\nEnvironmentError (exception), 167 EOFError (exception), 100 epsilon; see sys.float_info.epsilon\n\nattribute\n\n__eq__() (==), 241, 242, 244, 252, 254,\n\n259, 379\n\nerror handling; see exception han-\n\ndling\n\nerror-handling policy, 208 escape()\n\nre module, 502 xml.sax.saxutils module, 186,\n\n226, 320\n\nescapes, HTML and XML, 186, 316 escapes, string, 66, 67 escaping, newlines, 67 eval() (built-in), 242, 243, 258, 266,\n\n275, 344, 349, 379\n\nevent bindings, 576 event loop, 572, 578, 590 example\n\nAbstract.py, 386 bigdigits.py, 39–42 BikeStock.py, 332–336 BinaryRecordFile.py, 324–332 blocks.py, 525–534, 543–547,\n\n559–562\n\nbookmarks-tk.pyw, 578–593 car_registration_server.py,\n\n464–471\n\ncar_registration.py, 458–464 CharGrid.py, 207–212 checktags.py, 169 convert-incidents.py, 289–323 csv2html.py, 97–102 csv2html2_opt.py, 215 digit_names.py, 180 dvds-dbm.py, 476–479\n\nIndex\n\nexample (cont.)\n\ndvds-sql.py, 480–487 external_sites.py, 132 ExternalStorage.py, 375 finddup.py, 224 findduplicates-t.py, 449–453 first-order-logic.py, 548–553,\n\n562–566\n\nFuzzyBool.py, 249–255 FuzzyBoolAlt.py, 256–261 generate_grid.py, 42–44 generate_test_names1.py, 142 generate_test_names2.py, 143 generate_usernames.py, 149–152 grepword-m.py, 448 grepword-p.py, 440–442 grepword.py, 139 grepword-t.py, 446–448 html2text.py, 503 Image.py, 261–269 IndentedList.py, 352–356 interest-tk.pyw, 572–578 magic-numbers.py, 346–351 make_html_skeleton.py, 185–191 noblanks.py, 166 playlists.py, 519–525, 539–543,\n\n555–559\n\nprint_unicode.py, 88–91 Property.py, 376 quadratic.py, 94–96 Shape.py, 238–245 ShapeAlt.py, 246–248 SortedDict.py, 276–283 SortedList.py, 270–275 SortKey.py, 368 statistics.py, 152–156 TextFilter.py, 385 TextUtil.py, 202–207 uniquewords1.py, 130 uniquewords2.py, 136 untar.py, 221 Valid.py, 407–409 XmlShadow.py, 373\n\nexcept (statement);see try state-\n\nment\n\n609\n\nexception\n\nAssertionError, 184 AttributeError, 240, 241, 275,\n\n350, 364, 366\n\ncustom, 168–171, 208 EnvironmentError, 167 EOFError, 100 Exception, 164, 165, 360, 418 ImportError, 198, 221, 350 IndexError, 69, 211, 273 IOError, 167 KeyboardInterrupt, 190, 418, 442 KeyError, 135, 164, 279 LookupError, 164 NameError, 116 NotImplementedError, 258, 381,\n\n385\n\nOSError, 167 StopIteration, 138, 279 SyntaxError, 54, 348, 414–415 TypeError, 57, 135, 138, 146, 167, 173,179,197,242,258,259,274, 364, 380\n\nUnicodeDecodeError, 167 UnicodeEncodeError, 93 ValueError, 57, 272, 279 ZeroDivisionError, 165, 416 Exception (exception), 164, 165, 360 exception handling, 163–171, 312\n\nsee also try statement exceptions, chaining, 419–420 exceptions, custom, 168–171, 208 exceptions, propagating, 370 exec() (built-in), 260, 345–346, 348,\n\n349, 351\n\nexecutable attribute (sys module),\n\n441\n\nexecute() (cursor object), 481, 482,\n\n483, 484, 485, 486, 487 executemany() (cursor object), 482 exists() (os.path module), 224, 327,\n\n481\n\n__exit__(), 369, 371, 372 exit() (sys module), 141, 215 exp() (math module), 60\n\n610\n\nexpand() (match object), 507 expandtabs()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nexpat XML parser, 315, 317, 318 expression, conditional, 160, 176,\n\n189\n\nexpressions, Boolean, 54 extend()\n\nbytearray type, 299, 301, 462 list type, 115, 116\n\nextending lists, 114 extension\n\n.bz2, 219 .csv, 220 .gz, 219, 228 .ini, 220, 519 .m3u, 522, 541, 557 .pls, 519, 539, 555 .py, 9, 195, 571 .pyc and .pyo, 199 .pyw, 9, 571 .svg, 525 .tar, .tar.gz, .tar.bz2, 219, 221 .tgz, 219, 221 .wav, 219 .xpm, 268 .zip, 219\n\nexternal_sites.py (example), 132 ExternalStorage.py (example), 375\n\nF\n\nfabs() (math module), 60 factorial() (math module), 60 factory functions, 136 False (built-in constant); see bool\n\ntype\n\nfetchall() (cursor object), 482, 485 fetchmany() (cursor object), 482 fetchone() (cursor object), 482, 484,\n\n486\n\n__file__ (attribute), 441\n\nFile associations, Windows, 11 ﬁle extension; see extension ﬁle globbing, 343 ﬁle handling, 222–225 ﬁle object, 370\n\nclose(), 131, 167, 325 closed attribute, 325 encoding attribute, 325 fileno(), 325 flush(), 325, 327 isatty(), 325 methods, table of, 325, 326 mode attribute, 325 name attribute, 325 newlines attribute, 325 __next__(), 325 open(), 131, 141, 167, 174, 267, 268, 327, 347, 369, 398, 443\n\npeek(), 325 read(), 131, 295, 302, 325, 347,\n\n443\n\nreadable(), 325 readinto(), 325 readline(), 325 readlines(), 131, 325 seek(), 295, 325, 327, 329 seekable(), 326 stderr (sys module), 184, 214 stdin (sys module), 214 stdin.detach(), 443 stdout (sys module), 181, 214 tell(), 326, 329 truncate(), 326, 331 writable(), 326 write(), 131, 214, 301, 326, 327 writelines(), 326 ﬁle sufﬁx; see extension ﬁle system interaction, 222–225 File Transfer Protocol (FTP), 226 filecmp module, 223 fileinput module, 214 fileno() (ﬁle object), 325 ﬁles; see ﬁle object and open() ﬁles, archive, 219 ﬁles, binary, 295–304, 324–336\n\nIndex\n\nIndex\n\nﬁles, comparing, 223 ﬁles, compressing and uncompress-\n\ning, 219\n\nﬁles, format comparison, 288–289 ﬁles, random access; see binary ﬁles ﬁles, temporary, 222 ﬁles, text, 305–312 ﬁles, XML, 312–323 filter() (built-in), 395, 397 ﬁltering, 395, 403–407 finally (statement);see try state-\n\nment\n\nfind()\n\nbytearray type, 299 bytes type, 299 str type, 72–75, 133, 532\n\nfindall()\n\nre module, 502 regex object, 503\n\nfinddup.py (example), 224 findduplicates-t.py (example),\n\n449–453\n\nfinditer()\n\nre module, 311, 502 regex object, 401, 500, 501, 503\n\nfirst-order-logic.py (example),\n\n548–553, 562–566\n\nflags attribute (regex object), 503 __float__(), 252, 253 float_info.epsilon attribute (sys\n\nmodule), 61, 96, 343\n\nfloat() (built-in), 253 float type, 59–62, 381\n\nas_integer_ratio(), 61 float() (built-in), 61, 154, 253 fromhex(), 61 hex(), 61 is_integer(), 61\n\nfloor() (math module), 60 __floordiv__() (//), 55, 253 flush() (ﬁle object), 325, 327 fmod() (math module), 60 focus, keyboard, 574, 576, 577, 589,\n\n592\n\nfor loop, 120, 138, 141, 143, 162–163\n\n611\n\nforeign functions, 229 __format__(), 250, 254 format()\n\nbuilt-in, 250, 254 str type, 73, 78–88, 152, 156, 186,\n\n189, 249, 306, 531\n\nformat speciﬁcations, for strings,\n\n83–88\n\nformatting strings; see str.format() Fraction type (fractions module),\n\n381\n\nFrame type (tkinter module), 573,\n\n581, 591\n\nfrexp() (math module), 60 from (statement);seechaining excep- tions and import statement\n\nfromhex()\n\nbytearray type, 293, 299 bytes type, 293, 299 float type, 61\n\nfromkeys() (dict type), 129 fromordinal() (datetime.date type),\n\n301, 304\n\nfrozenset type, 125–126, 383\n\ncopy(), 123 difference(), 123 frozenset() (built-in), 125 intersection(), 123 isdisjoint(), 123 issubset(), 123 issuperset(), 123 methods, table of, 123 symmetric_difference(), 123\n\nfsum() (math module), 60 FTP (File Transfer Protocol), 226 ftplib module, 226 functions, 171–185\n\nannotations, 360–363 anonymous; see lambda state-\n\nment\n\ncomposing, 395–397, 403–407 decorating, 246–248, 356–360 dynamic, 209 factory, 136 foreign, 229\n\n612\n\nfunctions (cont.)\n\nlambda; see lambda statement local, 296, 319, 351–356 module, 256 object reference to, 136, 270, 341 parameters;seearguments,func-\n\ntion\n\nrecursive, 351–356 see also functors\n\nfunctions, introspection-related, ta-\n\nble of, 349\n\nfunctions, iterator, table of, 140 functions, nested; see local func-\n\ntions\n\nfunctions, table of (math module),\n\n60, 61\n\nfunctions, table of (re module), 502 functools module partial(), 398 reduce(), 396, 397 @wraps(), 357\n\nfunctors, 367–369, 385 FuzzyBool.py (example), 249–255 FuzzyBoolAlt.py (example), 256–261\n\nG\n\ngarbage collection, 17, 116, 218, 576,\n\n581, 593\n\n__ge__() (>=), 242, 259, 379 generate_grid.py (example), 42–44 generate_test_names1.py (example),\n\n142\n\ngenerate_test_names2.py (example),\n\n143\n\ngenerate_usernames.py (example),\n\n149–152 generator object send(), 343\n\ngenerators, 279, 342–344, 395, 396,\n\n401\n\n__get__(), 374, 375, 376, 377 get() (dict type), 129, 130, 264, 351,\n\n374, 469\n\nIndex\n\n__getattr__(), 365, 366 getattr() (built-in), 349, 350, 364,\n\n368, 374, 391, 409 __getattribute__(), 365, 366 getcwd() (os module), 223 __getitem__() ([]),264,265,273,328,\n\n334\n\ngetmtime() (os.path module), 224 getopt module; see optparse module getrecursionlimit() (sys module),\n\n352\n\ngetsize() (os.path module),134,224,\n\n407\n\ngettempdir() (tempfile module), 360 GIL (Global Interpreter Lock), 449 glob module, 344 global (statement), 210 global functions; see functions Global Interpreter Lock (GIL), 449 global variables, 180 globals() (built-in), 345, 349 globbing, 343 GMT; see Coordinated Universal\n\nTime grammar, 515 greedy regexes, 493 grepword-m.py (example), 448 grepword-p.py (example), 440–442 grepword.py (example), 139 grepword-t.py (example), 446–448 grid layout, 573, 575, 591 group() (match object),311,500,501,\n\n504, 507, 508, 521, 524\n\ngroupdict() (match object), 402, 507 groupindex attribute (regex object),\n\n503\n\ngroups() (match object), 507 groups, regex, 494–495, 506 __gt__() (>), 242, 259, 379 .gz (extension), 219, 228 gzip module, 219\n\nopen(), 228, 294 write(), 301\n\nIndex\n\nH\n\nhasattr() (built-in), 270, 349, 350,\n\n391\n\n__hash__(), 250, 254 hash() (built-in), 241, 250, 254 Hashable ABC (collections module),\n\n383\n\nhashable objects, 121, 126, 130, 135,\n\n241, 254\n\nheapq module, 217, 218–219 help() (built-in), 61, 172 hex()\n\nbuilt-in, 55, 253 float type, 61\n\nhexadecimal numbers, 56 html.entities module, 504, 505 HTML escapes, 186 html.parser module, 226 html2text.py (example), 503 http package, 225 hypot() (math module), 60\n\nI\n\n__iadd__() (+=), 253 __iand__() (&=), 251, 253, 257 id() (built-in), 254 identiﬁers, 51–54, 127 identity testing;see is identity oper-\n\nator\n\nIDLE (programming environment),\n\n13–14, 364, 424–425 if (statement), 159–161 __ifloordiv__() (//=), 253 __ilshift__() (<<=), 253 Image.py (example), 261–269 IMAP4 (Internet Message Access\n\nProtocol), 226\n\nimaplib module, 226 immutable arguments, 175 immutable attributes, 264 immutable classes, 256, 261 immutable objects, 15, 16, 108, 113,\n\n126\n\n__imod__() (%=), 253 import (statement), 196–202, 348 __import__() (built-in), 349, 350 import order policy, 196 ImportError (exception), 198, 221,\n\n350\n\nimports, dynamic, 346–351 imports, relative, 202 __imul__() (*=), 253 in (membership operator), 114, 118,\n\n122, 140, 265, 274\n\nindentation, for block structure, 27 IndentedList.py (example), 352–356 __index__(), 253 index()\n\nbytearray type, 299 bytes type, 299 list type, 115, 118 str type, 72–75 tuple type, 108\n\nIndexError (exception), 69, 211, 273 indexing operator ([]), 273, 274 inﬁnite loop, 399, 406 inheritance, 243–245 inheritance, multiple, 388–390, 466 .ini (extension), 220, 519 __init__(), 241, 244, 249, 250, 270,\n\n276\n\ntype type, 391, 392\n\n__init__.py package ﬁle, 199, 200 initialization, of objects, 240 input() (built-in), 34, 96 INSERT (SQL statement), 483 insert()\n\nbytearray type, 293, 299 list type, 115, 117, 271\n\ninspect module, 362 installing Python, 4–6 instance variables, 241 __int__(), 252, 253, 258 int() (built-in), 253 int type, 54–57, 381 bit_length(), 57 bitwise operators, table of, 57 conversions, table of, 55\n\n613\n\n614\n\nint type (cont.)\n\nint() (built-in), 55, 61, 136, 253,\n\n309\n\nIntegral ABC (numbers module), 381 interest-tk.pyw (example), 572–578 internationalization, 86 Internet Message Access Protocol\n\n(IMAP4), 226\n\ninterpreter options, 185, 198, 199 intersection_update() (set type),\n\n123 intersection()\n\nfrozenset type, 123 set type, 122, 123\n\nintrospection, 350, 357, 360, 362 IntVar type (tkinter module), 574 __invert__() (~), 57, 250, 253, 257 inverting, a dictionary, 134 io module\n\nStringIO type, 213–214, 228 see also ﬁle object and open()\n\nIOError (exception), 167 __ior__() (|=), 253 IP address, 457, 458, 464 __ipow__() (**=), 253 __irshift__() (>>=), 253 is_integer() (float type), 61 is (identity operator), 22, 254 isalnum()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nisalpha()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nisatty() (ﬁle object), 325 isdecimal() (str type), 73 isdigit()\n\nbytearray type, 299 bytes type, 299 str type, 73, 76\n\nisdir() (os.path module), 224 isdisjoint()\n\nfrozenset type, 123\n\nIndex\n\nisdisjoint() (cont.) set type, 123\n\nisfile() (os.path module), 134, 224,\n\n344, 406\n\nisidentifier() (str type), 73, 348 isinf() (math module), 60 isinstance() (built-in),170,216,242,\n\n270, 382, 390, 391\n\nislower()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nisnan() (math module), 60 isnumeric() (str type), 74 isprintable() (str type), 74 isspace()\n\nbytearray type, 299 bytes type, 299 str type, 74, 531\n\nissubclass() (built-in), 390 issubset()\n\nfrozenset type, 123 set type, 123\n\nissuperset()\n\nfrozenset type, 123 set type, 123\n\nistitle()\n\nbytearray type, 300 bytes type, 300 str type, 74 __isub__() (-=), 253 isupper()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nitem access operator ([]), 262, 264,\n\n273, 274, 278, 279, 293\n\nitemgetter() (operator module), 397 items() (dict type), 128, 129 __iter__(), 265, 274, 281, 335 iter() (built-in), 138, 274, 281 iterable; see iterators Iterable ABC (collections module),\n\n383",
      "page_number": 581
    },
    {
      "number": 59,
      "title": "Segment 59 (pages 598-607)",
      "start_page": 598,
      "end_page": 607,
      "detection_method": "topic_boundary",
      "content": "Index\n\nIterator ABC (collections module),\n\n383\n\niterators, 138–146\n\nfunctions and operators, table\n\nof, 140\n\nitertools module, 397 __ixor__() (^=), 253\n\nJ\n\njoin()\n\nbytearray type, 300 bytes type, 300 os.path module, 223, 224 str type, 71, 72, 189\n\njson module, 226\n\nK\n\nkey bindings, 576 keyboard accelerators, 574, 580,\n\n592\n\nkeyboard focus, 574, 576, 577, 589,\n\n592\n\nkeyboard shortcuts, 577, 580 KeyboardInterrupt (exception), 190,\n\n418, 442\n\nKeyError (exception), 135, 164, 279 keys() (dict type), 128, 129, 277 keyword arguments, 174–175, 178,\n\n179, 188, 189, 362 keywords, table of, 52\n\nL\n\nLabel type (tkinter module), 574,\n\n582, 583, 591\n\nlambda (statement), 182–183, 379, 380, 388, 396, 467, 504 LANG (environment variable), 87 lastgroup attribute (match object),\n\n507\n\nlastindex attribute (match object),\n\n507, 508\n\n615\n\nLatin 1 encoding, 91, 93 layouts, 573, 575, 591 lazy evaluation, 342 ldexp() (math module), 60 __le__() (<=), 242, 259, 379 __len__(), 265, 330 len() (built-in), 71, 114, 122, 140,\n\n265, 275\n\nlexical analysis, 514 library, standard, 212–229 LifoQueue type (queue module), 446 linear search, 272 list comprehensions, 118–120, 189,\n\n210, 396\n\nlist type, 113–120, 383\n\nappend(), 115, 117, 118, 271 changing, 115 comparing, 113, 114 comprehensions, 118–120, 396 count(), 115 extend(), 115, 116 index(), 115, 118 insert(), 115, 117, 271 list() (built-in), 113, 147 methods, table of, 115 pop(), 115, 117, 118 remove(), 115, 117, 118 replication (*, *=), 114, 118 reverse(), 115, 118 slicing, 113, 114, 116–118 sort(), 115, 118, 182, 368, 397 updating, 115 see also SortedList.py\n\nListbox type (tkinter module), 582,\n\n583, 587, 588, 589\n\nlistdir() (os module), 134, 223, 224,\n\n348 ljust()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nload() (pickle module), 268, 295 loads() (pickle module), 462 local functions, 296, 319, 351–356 local variables, 163\n\n616\n\nlocale module, 86\n\nsetlocale(), 86, 87\n\nlocalization, 86 locals() (built-in), 81, 82, 97, 154,\n\n188,189,190,345,349,422,423, 484\n\nlocaltime() (time module), 217 Lock type (threading module), 452,\n\n467\n\nlog() (math module), 60 log10() (math module), 60 log1p() (math module), 60 logging module, 229, 360 logic, short-circuit, 25, 58 logical operators; see and, or, and\n\nnot\n\nLookupError (exception), 164 looping, see for loop and while loop,\n\n161 lower()\n\nbytearray type, 300 bytes type, 300 str type, 74, 76\n\n__lshift__() (<<), 57, 253 lstrip()\n\nbytearray type, 300 bytes type, 300 str type, 75, 76\n\n__lt__() (<), 242, 252, 259, 379\n\nM\n\n.m3u (extension), 522, 541, 557 magic number, 294 magic-numbers.py (example),\n\n346–351\n\nmailbox module, 226 make_html_skeleton.py (example),\n\n185–191\n\nmakedirs() (os module), 223 maketrans() (str type), 74, 77–78 mandatory parameters, 174 map() (built-in), 395, 397, 539 mapping, 395\n\nIndex\n\nMapping ABC (collections module),\n\n383\n\nmapping types; see dict and collec-\n\ntions.defaultdict\n\nmapping unpacking (**), 179, 187,\n\n304 match()\n\nre module, 502, 521, 524 regex object, 503\n\nmatch object end(), 507 endpos attribute, 507 expand(), 507 group(), 311, 500, 501, 504, 507,\n\n508, 521, 524\n\ngroupdict(), 402, 507 groups(), 507 lastgroup attribute, 507 lastindex attribute, 507, 508 methods, table of, 507 pos attribute, 507 re attribute, 507 span(), 507 start(), 507 string attribute, 507 see also re module and regex ob-\n\nject\n\nmath module, 62 acos(), 60 acosh(), 60 asin(), 60 asinh(), 60 atan(), 60 atan2(), 60 atanh(), 60 ceil(), 60 copysign(), 60 cos(), 60 cosh(), 60 degrees(), 60 e (constant), 60 exp(), 60 fabs(), 60 factorial(), 60 floor(), 60\n\nIndex\n\nmath module (cont.)\n\nfmod(), 60 frexp(), 60 fsum(), 60 functions, table of, 60, 61 hypot(), 60 isinf(), 60 isnan(), 60 ldexp(), 60 log(), 60 log10(), 60 log1p(), 60 modf(), 60 pi (constant), 61 pow(), 61 radians(), 61 sin(), 61 sinh(), 61 sqrt(), 61, 96 tan(), 61 tanh(), 61 trunc(), 61\n\nmax() (built-in), 140, 154, 396, 397 maxunicode attribute (sys module),\n\n90, 92\n\nMD5 (Message Digest algorithm),\n\n449, 452\n\nmembership testing; see in opera-\n\ntor\n\nmemoizing, 351 memory management; see garbage\n\ncollection\n\nMenu type (tkinter module), 579, 580 Message Digest algorithm (MD5),\n\n449, 452\n\nmetaclasses, 381, 384, 390–395 methods\n\nattribute access, table of, 365 bytearray type, table of, 299, 300,\n\n301\n\nbytes type, table of, 299, 300,\n\n301\n\nclass, 257\n\nmethods (cont.)\n\nconnection object, table of, 481 cursor object, table of, 482 decorating, 246–248, 356–360 dict type, table of, 129 ﬁle object, table of, 325, 326 frozenset type, table of, 123 list type, table of, 115 match object, table of, 507 object reference to, 377 regex object, table of, 503 set type, table of, 123 static, 257 str type, table of, 73, 74, 75 unimplementing, 258–261 see also special method\n\nmimetypes module, 224 min() (built-in), 140, 396, 397 minimal regexes, 493, 504 missing dictionary keys, 135 mixin class, 466 mkdir() (os module), 223 __mod__() (%), 55, 253 modal dialogs, 584, 587, 592 mode attribute (ﬁle object), 325 modf() (math module), 60 __module__ (attribute), 243 module functions, 256 modules, 195–202, 348 modules attribute (sys module), 348 __mul__() (*), 55, 253 multiple inheritance, 388–390, 466 multiprocessing module, 448, 453 mutable arguments, 175 mutable attributes, policy, 264 mutable objects; see immutable ob-\n\njects\n\nMutableMapping ABC (collections\n\nmodule), 269, 383\n\nMutableSequence ABC (collections\n\nmodule), 269, 383\n\nMutableSet ABC (collections mod-\n\nule), 383\n\n617\n\n618\n\nN\n\n__name__ (attribute), 206, 252, 357,\n\n362, 377\n\nname() (unicodedata module), 90 name attribute (ﬁle object), 325 name conﬂicts, avoiding, 198, 200 name mangling, 366, 379 namedtuple type (collections mod-\n\nule), 111–113, 234, 365, 523\n\nNameError (exception), 116 names, qualiﬁed, 196 namespace, 236 naming policy, 176–177 __ne__() (!=), 241, 242, 259, 379 __neg__() (-), 55, 253 nested collections;see dict, list, set,\n\nand tuple types\n\nnested functions; see local functions Network News Transfer Protocol\n\n(NNTP), 226\n\n__new__(), 250\n\nobject type, 256 type type, 392, 394 newline escaping, 67 newlines attribute (ﬁle object), 325 __next__(), 325, 343 next() (built-in), 138, 343, 401 NNTP (Network News Transfer\n\nProtocol), 226\n\nnntplib module, 226 noblanks.py (example), 166 None object, 22, 23, 26, 173 nongreedy regexes, 493, 504 nonlocal (statement), 355, 379 nonterminal, 515 normal (debug) mode; see PYTHONOP-\n\nTIMIZE\n\nnormalize() (unicodedata module),\n\n68\n\nnot (logical operator), 58 NotImplemented object, 242, 258, 259 NotImplementedError (exception),\n\n258, 381, 385\n\nnow() (datetime.datetime type), 217\n\nIndex\n\nNumber ABC (numbers module), 381 numbers module, 216, 382 classes, table of, 381 Complex ABC, 381 Integral ABC, 381 Number ABC, 381 Rational ABC, 381 Real ABC, 381\n\nnumeric operators and functions,\n\ntable of, 55\n\nO\n\nO option, interpreter, 185, 199, 359, 362\n\nobject creation and initialization,\n\n240\n\nobject-oriented concepts and termi-\n\nnology, 235\n\nobject references, 16–18, 19, 110,\n\n116,126,136,142,146,250,254, 281, 340, 345, 356, 367, 377, 576\n\nobject type, 380\n\n__new__(), 256 __repr__(), 266\n\nobjects, comparing, 23, 242 obtaining Python, 4–6 oct() (built-in), 55, 253 octal numbers, 56 open()\n\nﬁle object,131,141,167,174,267,\n\n268, 327, 347, 369, 398, 443\n\ngzip module, 228, 294 shelve module, 476 operator module, 396\n\nattrgetter(), 369, 397 itemgetter(), 397\n\noperators, iterator, table of, 140 optimized mode; see PYTHONOPTIMIZE optional parameters, 174 options, for interpreter, 185, 198,\n\n199, 359, 362 optparse module, 215 __or__() (|), 57, 253\n\nIndex\n\nor (logical operator), 58 ord() (built-in), 67, 90, 364 ordered collections; see list and tu-\n\nple types\n\nOrderedDict type (collections mod-\n\nule), 136–138, 218\n\nos module, 223, 224–225\n\nchdir(), 223 environ mapping, 223 getcwd(), 223 listdir(), 134, 223, 224, 348 makedirs(), 223 mkdir(), 223 remove(), 223, 332 removedirs(), 223 rename(), 223, 332 rmdir(), 223 sep attribute, 142 stat(), 223, 407 system(), 444 walk(), 223, 224, 406\n\nos.path module, 197, 223, 224–225\n\nabspath(), 223, 406 basename(), 223 dirname(), 223, 348 exists(), 224, 327, 481 getmtime(), 224 getsize(), 134, 224, 407 isdir(), 224 isfile(), 134, 224, 344, 406 join(), 223, 224 split(), 223 splitext(), 223, 268, 348\n\nOSError (exception), 167\n\nP\n\npack() (struct module), 296, 297,\n\n301, 336\n\npackage directories, 205 packages, 195–202 packrat parsing, 549 parameters; see arguments, func-\n\ntion\n\nparameters, unpacking, 177–180 parent–child relationships, 572,\n\n576 parsing\n\ncommand-line arguments, 215 dates and times, 216 text ﬁles, 307–310 with PLY, 553–566 with PyParsing, 534–553 with regexes, 310–312, 519–525 XML (with DOM), 317–319 XML (with SAX), 321–323 XML (with xml.etree), 315–316 partial() (functools module), 398 partial function application,\n\n398–399\n\npartition()\n\nbytearray type, 300 bytes type, 300 str type, 74, 76\n\npass (statement), 26, 160, 381, 385 PATH (environment variable), 12, 13 path attribute (sys module), 197 paths, Unix-style, 142 pattern attribute (regex object), 503 pdb module, 423–424 peek() (ﬁle object), 325 PEP 249 (Python Database API Speciﬁcation v2.0), 480\n\nPEP 3107 (Function Annotations),\n\n363\n\nPEP 3119 (Introducing Abstract\n\nBase Classes), 380\n\nPEP 3131 (Supporting Non-ASCII\n\nIdentiﬁers), 52\n\nPEP 3134 (Exception Chaining and Embedded Tracebacks), 420\n\npersistence, of data, 220 PhotoImage type (tkinter module),\n\n581\n\npi (constant) (math module), 61 pickle module, 292–295 dump(), 267, 294 dumps(), 462 load(), 268, 295\n\n619\n\n620\n\npickle module (cont.)\n\nloads(), 462\n\npickles, 266, 292–295, 476 pipelines, 403–407 pipes; see subprocess module placeholders, SQL, 483, 484 platform attribute (sys module), 160,\n\n209, 344\n\nplaylists.py (example), 519–525,\n\n539–543, 555–559\n\n.pls (extension), 519, 539, 555 PLY\n\np_error(), 555 precedence variable, 555, 565 states variable, 557–558 t_error(), 554, 556 t_ignore variable, 559 t_newline(), 556 tokens variable, 554, 555, 557\n\npointers; see object references policy, error handling, 208 policy, import order, 196 policy, mutable attributes, 264 policy, naming, 176–177 polymorphism, 243–245 pop()\n\nbytearray type, 293, 300 dict type, 127, 129, 265 list type, 115, 117, 118 set type, 123\n\nPOP3 (Post Ofﬁce Protocol), 226 Popen() (subprocess module), 441 popitem() (dict type), 129 poplib module, 226 __pos__() (+), 55, 253 pos attribute (match object), 507 positional arguments, 173–175, 178,\n\n179, 189, 362\n\nPost Ofﬁce Protocol (POP3), 226 __pow__() (**), 55, 253 pow()\n\nbuilt-in, 55 math module, 61 pprint module, 229, 355 precedence, 517–518, 551, 565\n\nIndex\n\nprint_unicode.py (example), 88–91 print() (built-in), 11, 180, 181, 214,\n\n422\n\nPriorityQueue type (queue module),\n\n446, 450\n\nprivate attributes, 238, 249, 270,\n\n271, 366\n\nprocessing pipelines, 403–407 processor endianness, 297 profile module, 432, 434–437 propagating exceptions, 370 properties, 246–248 @property(), 246–248, 376, 385, 394 Property.py (example), 376 .py (extension), 9, 195, 571 .pyc and .pyo (extension), 199 PyGtk, 570, 593 PyParsing\n\n+ (concatenation operator), 536, 539, 541, 543, 544, 545, 550 - (concatenation operator), 544,\n\n545\n\n<< (append operator), 538, 544,\n\n550\n\n| (OR operator),536,539,541,543,\n\n544, 550\n\nalphanums, 535 alphas, 535 CaselessLiteral(), 535 CharsNotIn(), 536, 539, 543 Combine(), 541 delimitedList(), 536, 538, 550 Empty(), 537 Forward(), 538, 544, 550 Group(), 544, 550, 551 Keyword(), 535, 550 LineEnd(), 541, 542 Literal(), 535, 540, 550 makeHTMLTags(), 536 nums, 541 OneOrMore(), 536, 539, 541, 544 operatorPrecedence(), 550–551 Optional(), 536, 537, 541, 544 pythonStyleComment, 536 quotedString, 536\n\nIndex\n\nPyParsing (cont.) Regex(), 536 restOfLine, 536, 539, 541 SkipTo(), 536 Suppress(), 535, 536, 539, 541 Word(), 535, 539, 541, 543 ZeroOrMore(), 536, 538, 544\n\nPyQt, 570, 593 PYTHONDONTWRITEBYTECODE (environ-\n\nment variable), 199\n\nPython enhancement proposals; see\n\nPEPs\n\nPython Shell (IDLE or interpreter),\n\n13\n\nPYTHONOPTIMIZE (environment vari- able), 185, 199, 359, 362\n\nPYTHONPATH (environment variable),\n\n197, 205\n\n.pyw (extension), 9, 571\n\nQ\n\nquadratic.py (example), 94–96 qualiﬁed names, 196 quantiﬁers, regex, 491–494 queue module\n\nLifoQueue type, 446 PriorityQueue type, 446, 450 Queue type, 446, 447, 450\n\nQueue type (queue module), 446, 447,\n\n450\n\nquopri module, 219 quoteattr() (xml.sax.saxutils mod-\n\nule), 226, 320\n\nR\n\n__radd__() (+), 253 radians() (math module), 61 raise (statement), 167, 211, 350,\n\n360\n\nsee also try statement\n\n__rand__() (&), 253 random access ﬁles; see binary ﬁles\n\n621\n\nrandom module\n\nchoice(), 142 sample(), 143\n\nrange() (built-in), 115, 118, 119, 140,\n\n141–142, 365\n\nRational ABC (numbers module), 381 raw binary data; see binary ﬁles raw strings, 67, 204, 310, 500, 556 __rdivmod__(), 253 re attribute (match object), 507 re module, 499–509\n\ncompile(), 310, 400, 500, 501, 502,\n\n521, 524 escape(), 502 findall(), 502 finditer(), 311, 502 functions, table of, 502 match(), 502, 521, 524 search(), 500, 502, 508 split(), 502, 509 sub(), 502, 504, 505 subn(), 502 see also match object and regex\n\nobject\n\nread() (ﬁleobject),131,295,302,325,\n\n347, 443\n\nreadable() (ﬁle object), 325 readinto() (ﬁle object), 325 readline() (ﬁle object), 325 readlines() (ﬁle object), 131, 325 Real ABC (numbers module), 381 records; see struct module recursive descent parser, 529 recursive functions, 351–356 recv() (socket module), 462, 463 reduce() (functools module), 396,\n\n397 reducing, 395 references; see object references regex\n\nalternation, 494–495 assertions, 496–499 backreferences, 495 captures, 494–495, 506 character classes, 491\n\n622\n\nregex (cont.)\n\nﬂags, 400, 499, 500 greedy, 493, 504 groups, 494–495, 506 match; see match object nongreedy, 493, 504 quantiﬁers, 491–494 special characters, 491\n\nregex object\n\nfindall(), 503 finditer(), 401, 500, 501, 503 flags attribute, 503 groupindex attribute, 503 match(), 503 methods, table of, 503 pattern attribute, 503 search(), 500, 503 split(), 503, 509 sub(), 503 subn(), 503 see also re module and match ob-\n\nject\n\nrelational integrity, 481 relative imports, 202 remove()\n\nbytearray type, 300 list type, 115, 117, 118 os module, 223, 332 set type, 123\n\nremovedirs() (os module), 223 rename() (os module), 223, 332 replace()\n\nbytearray type, 293, 300 bytes type, 293, 300 str type, 74, 77, 101\n\nreplication (*, *=)\n\nof lists, 114, 118 of strings, 72, 90 of tuples, 108\n\n__repr__(), 242, 244, 250, 252, 258,\n\n281\n\nobject type, 266\n\nrepr() (built-in), 242, 250 representational form, 82–83 resizable windows, 582–583, 591\n\nIndex\n\nreturn (statement), 161, 162, 173 reverse()\n\nbytearray type, 300 list type, 115, 118 __reversed__(), 265, 274 reversed() (built-in), 72, 140, 144,\n\n265\n\nreversing strings, 71, 72 rfind()\n\nbytearray type, 299 bytes type, 299 str type, 73, 75, 76 __rfloordiv__() (//), 253 rindex()\n\nbytearray type, 299 bytes type, 299 str type, 73, 75\n\nrjust()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\n__rlshift__() (<<), 253 rmdir() (os module), 223 __rmod__() (%), 253 __rmul__() (*), 253 rollback() (connection object), 481 __ror__() (|), 253 __round__(), 253 round() (built-in),55,56,61,252,253,\n\n258\n\nrowcount attribute (cursor object),\n\n482 rpartition()\n\nbytearray type, 300 bytes type, 300 str type, 74, 76 __rpow__() (**), 253 __rrshift__() (>>), 253 __rshift__() (>>), 57, 253 rsplit()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nrstrip()\n\nbytearray type, 300\n\nIndex\n\nrstrip() (cont.)\n\nbytes type, 300 str type, 75, 76 __rsub__() (-), 253 __rtruediv__() (/), 253 run() (Thread type), 445, 448 __rxor__() (^), 253\n\nS\n\nsample() (random module), 143 SAX (Simple API for XML); see\n\nxml.sax module\n\nScalable Vector Graphics (SVG),\n\n525\n\nScale type (tkinter module), 574,\n\n575 scanning, 514 Scrollbar type (tkinter module),\n\n582 search()\n\nre module, 500, 502, 508 regex object, 500, 503\n\nsearching, 272 seek() (ﬁle object), 295, 325, 327,\n\n329\n\nseekable() (ﬁle object), 326 SELECT (SQL statement), 484, 485,\n\n486\n\nself object, 239, 257, 469 send()\n\ncoroutines, 401, 402, 405, 406 generator object, 343 socket module, 463\n\nsendall() (socket module), 462, 463 sep attribute (os module), 142 Sequence ABC (collections module),\n\n383\n\nsequence types; see bytearray, bytes, list, str, and tuple types sequence unpacking (*), 110,\n\n114–115, 141, 162, 178, 336, 460\n\nserialized data access, for threads,\n\n446\n\n623\n\nserializing; see pickles __set__(), 375, 377 Set ABC (collections module), 383 set comprehensions, 125 set type, 121–125, 130, 383\n\nadd(), 123 clear(), 123 comprehensions, 125 copy(), 123, 147 difference_update(), 123 difference(), 122, 123 discard(), 123, 124 intersection_update(), 123 intersection(), 122, 123 isdisjoint(), 123 issubset(), 123 issuperset(), 123 methods, table of, 123 pop(), 123 remove(), 123 set() (built-in), 122, 147 symmetric_difference_update(),\n\n123\n\nsymmetric_difference(), 122, 123 union(), 122, 123 update(), 123\n\nset types; see frozenset and set\n\ntypes\n\n__setattr__(), 364, 365 setattr() (built-in), 349, 379, 409 setdefault() (dict type), 129, 133,\n\n374\n\n__setitem__() ([]), 265, 274, 278,\n\n327\n\nsetlocale() (locale module), 86, 87 setrecursionlimit() (sys module),\n\n352\n\nshallow copying; see copying collec-\n\ntions\n\nShape.py (example), 238–245 ShapeAlt.py (example), 246–248 shebang (shell execute), 12 Shell, Python (IDLE or interpreter),\n\n13\n\nshell execute (#!), 12\n\n624\n\nshelve module, 220, 476\n\nopen(), 476 sync(), 477\n\nshort-circuit logic, 25, 58 shortcut, keyboard, 577, 580 showwarning() (tkinter.messagebox\n\nmodule), 585, 587\n\nshutil module, 222 Simple API for XML (SAX); see\n\nxml.sax module\n\nSimple Mail Transfer Protocol\n\n(SMTP), 226 sin() (math module), 61 single shot timer, 582, 586 sinh() (math module), 61 site-packages directory, 205 Sized ABC (collections module),\n\n383 slicing ([])\n\nbytes, 293 lists, 113, 114, 116–118 operator, 69, 110, 116, 273, 274,\n\n397\n\nstrings, 69–71, 151 tuples, 108\n\n__slots__ (attribute), 363, 373, 375,\n\n394\n\nSMTP (Simple Mail Transfer Proto-\n\ncol), 226 smtpd module, 226 smtplib module, 226 sndhdr module, 219 socket module, 225, 457 recv(), 462, 463 send(), 463 sendall(), 462, 463 socket(), 464\n\nsocketserver module, 225, 464, 466 sort() (list type),115, 118,182,368,\n\n397\n\nsort algorithm, 145, 282 sorted() (built-in), 118, 133, 140,\n\n144–146, 270\n\nSortedDict.py (example), 276–283 SortedList.py (example), 270–275\n\nIndex\n\nSortKey.py (example), 368 sound-related modules, 219 span() (match object), 507 special characters, regex, 491 special method, 235, 239\n\n__abs__(), 253 __add__() (+), 55, 253 __and__() (&), 57, 251, 253, 257 bitwise and numeric methods,\n\ntable of, 253\n\n__bool__(), 250, 252, 258 __call__(), 367, 368 collection methods, table of, 265 comparison methods, table of,\n\n242\n\n__complex__(), 253 __contains__(), 265, 274 __copy__(), 275 __del__(), 250 __delattr__(), 364, 365 __delitem__() ([]), 265, 266, 273,\n\n279, 329, 334 __dir__(), 365 __divmod__(), 253 __enter__(), 369, 371, 372 __eq__() (==), 241, 242, 244, 252,\n\n254, 259, 379\n\n__exit__(), 369, 371, 372 __float__(), 252, 253 __floordiv__() (//), 55, 253 __format__(), 250, 254 fundamental methods, table of,\n\n250\n\n__ge__() (>=), 242, 259, 379 __get__(), 374, 375, 376, 377 __getattr__(), 365, 366 __getattribute__(), 365, 366 __getitem__() ([]), 264, 265, 273,\n\n328, 334\n\n__gt__() (>), 242, 259, 379 __hash__(), 250, 254 __iadd__() (+=), 253 __iand__() (&=), 251, 253, 257 __ifloordiv__() (//=), 253 __ilshift__() (<<=), 253",
      "page_number": 598
    },
    {
      "number": 60,
      "title": "Segment 60 (pages 608-615)",
      "start_page": 608,
      "end_page": 615,
      "detection_method": "topic_boundary",
      "content": "Index\n\nspecial method (cont.) __imod__() (%=), 253 __imul__() (*=), 253 __index__(), 253 __init__(), 241, 244, 249, 250,\n\n270, 276, 391, 392\n\n__int__(), 252, 253, 258 __invert__() (~), 57, 250, 253, 257 __ior__() (|=), 253 __ipow__() (**=), 253 __irshift__() (>>=), 253 __isub__() (-=), 253 __iter__(), 265, 274, 281, 335 __ixor__() (^=), 253 __le__() (<=), 242, 259, 379 __len__(), 265, 330 __lshift__() (<<), 57, 253 __lt__() (<), 242, 252, 259, 379 __mod__() (%), 55, 253 __mul__() (*), 55, 253 __ne__() (!=), 241, 242, 259, 379 __neg__() (-), 55, 253 __new__(), 250, 256, 392 __next__(), 325, 343 __or__() (|), 57, 253 __pos__() (+), 55, 253 __pow__() (**), 55, 253 __radd__() (+), 253 __rand__() (&), 253 __rdivmod__(), 253 __repr__(), 242, 244, 250, 252,\n\n258, 281\n\n__reversed__(), 265, 274 __rfloordiv__() (//), 253 __rlshift__() (<<), 253 __rmod__() (%), 253 __rmul__() (*), 253 __ror__() (|), 253 __round__(), 253 __rpow__() (**), 253 __rrshift__() (>>), 253 __rshift__() (>>), 57, 253 __rsub__() (-), 253 __rtruediv__() (/), 253 __rxor__() (^), 253\n\nspecial method (cont.) __set__(), 375, 377 __setattr__(), 364, 365 __setitem__() ([]), 265, 274, 278,\n\n327\n\n__str__(), 243, 244, 250, 252 __sub__() (-), 55, 253 __truediv__() (/), 31, 55, 253 __xor__() (^), 57, 253\n\nsplit()\n\nbytearray type, 300 bytes type, 300 os.path module, 223 re module, 502, 509 regex object, 503, 509 str type, 74, 77, 509\n\nsplitext() (os.path module), 223,\n\n268, 348 splitlines()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nSQL databases, 475, 480 SQL placeholders, 483, 484 SQL statement\n\nCREATE TABLE, 481 DELETE, 487 INSERT, 483 SELECT, 484, 485, 486 UPDATE, 484\n\nsqlite3 module, 480, 481\n\nconnect(), 481\n\nsqrt() (math module), 61, 96 ssl module, 225 standard library, 212–229 starred arguments, 114, 460 starred expressions; see sequence\n\nunpacking\n\nstart()\n\nmatch object, 507 Thread type, 445\n\nstart symbol, 516 startswith()\n\nbytearray type, 300 bytes type, 300\n\n625\n\n626\n\nstartswith() (cont.)\n\nstr type, 74, 75, 76\n\nstat() (os module), 223, 407 statement\n\nassert, 184–185, 205, 208, 247 break, 161, 162 class, 238, 244, 378, 407 continue, 161, 162 def, 37, 173–176, 209, 238 del, 116, 117, 127, 250, 265, 273,\n\n365\n\nglobal, 210 if, 159–161 import, 196–202, 348 lambda, 182–183, 379, 380, 388,\n\n396, 467, 504 nonlocal, 355, 379 pass, 26, 160, 381, 385 raise, 167, 211, 350, 360 return, 161, 162, 173 try, 163–171, 360 with, 369–372, 389 yield, 279, 281, 342–344,\n\n399–407\n\nsee also for loop and while loop\n\nstatement terminator (\\n), 66 static methods, 257 static variables, 255 @staticmethod(), 255 statistics.py (example), 152–156 stderr ﬁle object (sys module), 184,\n\n214\n\nstdin ﬁle object (sys module), 214 __stdout__ ﬁle object (sys module),\n\n214\n\nstdout ﬁle object (sys module), 181,\n\n214\n\nStopIteration (exception), 138, 279 __str__(), 243, 244, 250, 252 str type, 65–94, 383, 418–419\n\ncapitalize(), 73 center(), 73 comparing, 68–69 count(), 73, 75\n\nIndex\n\nstr type (cont.)\n\nencode(), 73, 92, 93, 296, 336, 419,\n\n441\n\nendswith(), 73, 75, 76 escapes, 66, 67 expandtabs(), 73 find(), 72–75, 133, 532 format(),73, 78–88,152, 156,186,\n\n189, 249, 306, 531\n\nformat speciﬁcations, 83–88 index(), 72–75 isalnum(), 73 isalpha(), 73 isdecimal(), 73 isdigit(), 73, 76 isidentifier(), 73, 348 islower(), 73 isnumeric(), 74 isprintable(), 74 isspace(), 74, 531 istitle(), 74 isupper(), 74 join(), 71, 72, 74, 189 literal concatenation, 78 ljust(), 74 lower(), 74, 76 lstrip(), 75, 76 maketrans(), 74, 77–78 methods, table of, 73, 74, 75 partition(), 74, 76 raw strings, 67, 204, 310, 500,\n\n556\n\nreplace(), 74, 77, 101 replication (*, *=), 72, 90 reversing, 71, 72 rfind(), 73, 75, 76 rindex(), 73, 75 rjust(), 74 rpartition(), 74, 76 rsplit(), 74 rstrip(), 75, 76 slicing, 69–71 slicing operator ([]), 69 split(), 74, 77, 509 splitlines(), 74\n\nIndex\n\nstr type (cont.)\n\nstartswith(), 74, 75, 76 strip(), 75, 76 str() (built-in), 65, 136, 243, 250 swapcase(), 75 title(), 75, 90 translate(), 75, 77–78 triple quoted, 65, 156, 204 upper(), 75 zfill(), 75 striding; see slicing string attribute (match object), 507 string form, 82–83 string handling, 213–214 string literal concatenation, 78 string module, 130, 213 StringIO type (io module), 213–214,\n\n228\n\nstrings; see str type StringVar type (tkinter module),\n\n574, 590, 592\n\nstrip()\n\nbytearray type, 300 bytes type, 300 str type, 75, 76 strong typing, 17 strptime() (datetime.datetime type),\n\n309\n\nstruct module, 213, 296–298\n\ncalcsize(), 297 pack(), 296, 297, 301, 336 Struct type, 297, 302, 324, 336,\n\n462\n\nunpack(), 297, 302, 336\n\n__sub__() (-), 55, 253 sub()\n\nre module, 502, 504, 505 regex object, 503\n\nsubn()\n\nre module, 502 regex object, 503\n\n627\n\nsubprocess module, 440–442\n\ncall(), 209 Popen(), 441 sufﬁx; see extension sum() (built-in), 140, 396, 397 super() (built-in), 241, 244, 256, 276,\n\n282, 381, 385 .svg (extension), 525 SVG (Scalable Vector Graphics),\n\n525 swapcase()\n\nbytearray type, 300 bytes type, 300 str type, 75\n\nswitch statement; see dictionary\n\nbranching\n\nsymmetric_difference_update() (set\n\ntype), 123\n\nsymmetric_difference() frozenset type, 123 set type, 122, 123\n\nsync() (shelve module), 477 syntactic analysis, 514 syntax rules, 515 SyntaxError (exception), 54, 348,\n\n414–415\n\nsys module\n\nargv list, 41, 343 executable attribute, 441 exit(), 141, 215 float_info.epsilon attribute, 61,\n\n96, 343\n\ngetrecursionlimit(), 352 maxunicode attribute, 90, 92 modules attribute, 348 path attribute, 197 platform attribute, 160, 209, 344 setrecursionlimit(), 352 stderr ﬁle object, 184, 214 stdin ﬁle object, 214 __stdout__ ﬁle object, 214 stdout ﬁle object, 181, 214\n\nsystem() (os module), 444\n\n628\n\nT\n\ntan() (math module), 61 tanh() (math module), 61 tarfile module, 219, 221–222 .tar, .tar.gz, .tar.bz2 (extension),\n\n219, 221\n\nTcl/Tk, 569 TCP (Transmission Control Proto-\n\ncol), 225, 457\n\nTDD (Test Driven Development),\n\n426\n\ntell() (ﬁle object), 326, 329 telnetlib module, 226 tempfile module, 222 gettempdir(), 360\n\ntemporary ﬁles and directories, 222 terminal, 515 terminology, object-oriented, 235 Test Driven Development (TDD),\n\n426\n\ntestmod() (doctest module), 206 text ﬁles, 131, 305–312 TextFilter.py (example), 385 TextUtil.py (example), 202–207 textwrap module, 213 dedent(), 307 TextWrapper type, 306 wrap(), 306, 320\n\n.tgz (extension), 219, 221 this; see self object Thread type (threading module), 445,\n\n448, 450, 451, 452\n\nrun(), 445, 448 start(), 445\n\nthreading module, 445–453\n\nLock type, 452, 467 Thread type, 445, 448, 450, 451,\n\n452\n\ntime module, 216\n\nlocaltime(), 217 time(), 217\n\ntimeit module, 432–434 timer, single shot, 582, 586\n\nIndex\n\ntitle()\n\nbytearray type, 300 bytes type, 300 str type, 75, 90\n\nTk type (tkinter module), 572, 578,\n\n589\n\ntkinter.filedialog module askopenfilename(), 586 asksaveasfilename(), 585 tkinter.messagebox module\n\naskyesno(), 589 askyesnocancel(), 584 showwarning(), 585, 587\n\ntkinter module, 569\n\nButton type, 581, 591 DoubleVar type, 574 END constant, 583, 587, 588 Entry type, 591 Frame type, 573, 581, 591 IntVar type, 574 Label type, 574, 582, 583, 591 Listbox type, 582, 583, 587, 588,\n\n589\n\nMenu type, 579, 580 PhotoImage type, 581 Scale type, 574, 575 Scrollbar type, 582 StringVar type, 574, 590, 592 Tk type, 572, 578, 589 TopLevel type, 590\n\ntoday() (datetime.date type), 187,\n\n477\n\ntokenizing, 514 toordinal() (datetime.date type),\n\n301\n\nTopLevel type (tkinter module), 590 trace module, 360 traceback, 415–420 translate()\n\nbytearray type, 300 bytes type, 300 str type, 75, 77–78\n\nTransmission Control Protocol\n\n(TCP), 225, 457\n\ntriple quoted strings, 65, 156, 204\n\nIndex\n\nTrue (built-in constant); see bool\n\ntype\n\n__truediv__() (/), 31, 55, 253 trunc() (math module), 61 truncate() (ﬁle object), 326, 331 truth values; see bool type try (statement), 163–171, 360\n\nsee also exceptions and exception\n\nhandling\n\ntuple type, 108–111, 383\n\ncomparing, 108 count(), 108 index(), 108 parentheses policy, 109 replication (*, *=), 108 slicing, 108 tuple() (built-in), 108\n\ntype() (built-in), 18 type checking, 361 type conversion; see conversions type type, 391\n\n__init__(), 391, 392 __new__(), 392, 394 type() (built-in), 348, 349\n\nTypeError (exception), 57, 135, 138,\n\n146,167,173,179,197,242,258, 259, 274, 364, 380 typing; see dynamic typing\n\nU\n\nUCS-2/4 encoding (Unicode), 92 UDP (UserDatagramProtocol),225,\n\n457\n\nuncompressing ﬁles, 219 underscore (_), 53 unescape() (xml.sax.saxutils mod-\n\nule), 226\n\nunhandled exception; see traceback Unicode, 9, 91–94, 505\n\ncollation order, 68–69 identiﬁers, 53 strings; see str type, 65–94 UCS-2/4 encoding, 92\n\n629\n\nUnicode (cont.)\n\nUTF-8/16/32 encoding, 92, 94,\n\n228\n\nsee also character encodings\n\nunicodedata module, 68 category(), 361 name(), 90 normalize(), 68\n\nUnicodeDecodeError (exception), 167 UnicodeEncodeError (exception), 93 unimplementing methods, 258–261 union() (set type), 122, 123 uniquewords1.py (example), 130 uniquewords2.py (example), 136 unittest module, 228, 426–432 Unix-style paths, 142 unordered collections; see dict, frozenset, and set types unpack() (struct module), 297, 302,\n\n336\n\nunpacking (* and **), 110, 114–115, 162, 177–180, 187, 268, 304, 336\n\nuntar.py (example), 221 UPDATE (SQL statement), 484 update()\n\ndict type, 129, 188, 276, 295 set type, 123\n\nupdating dictionaries, 128 updating lists, 115 upper()\n\nbytearray type, 293, 301 bytes type, 293, 301 str type, 75 urllib package, 226 User DatagramProtocol(UDP),225,\n\n457\n\nUTC (Coordinated Universal Time),\n\n216\n\nutcnow() (datetime.datetime type),\n\n217\n\nUTF-8/16/32encoding (Unicode),92,\n\n94, 228 uu module, 219\n\n630\n\nV\n\nValid.py (example), 407–409 ValueError (exception), 57, 272, 279 values() (dict type), 128, 129 variables; see object references variables,callable;seefunctionsand\n\nmethods\n\nvariables, class, 255, 465 variables, global, 180 variables, instance, 241 variables, local, 163 variables, names; see identiﬁers variables, static, 255 vars() (built-in), 349 version control, 414 view (dict type), 129 virtual subclasses, 391\n\nW\n\nwalk() (os module), 223, 224, 406 .wav (extension), 219 wave module, 219 weak reference, 581 weakref module, 218 Web Server Gateway Interface\n\n(WSGI), 225 webbrowser module, 589 while loop, 141, 161–162 wildcard expansion, 343 Windows, ﬁle association, 11 windows, resizable, 582–583, 591 with (statement), 369–372, 389 wrap() (textwrap module), 306, 320 @wraps() (functools module), 357 writable() (ﬁle object), 326 write()\n\nﬁle object, 131, 214, 301, 326, 327 gzip module, 301\n\nwritelines() (ﬁle object), 326 WSGI (Web Server Gateway Inter-\n\nface), 225\n\nwsgiref package, 225 wxPython, 570, 593\n\nIndex\n\nX\n\nxdrlib module, 219 xml.dom.minidom module, 226 xml.dom module, 226, 316–319 XML encoding, 314 XML escapes, 186, 316 xml.etree.ElementTree module, 227,\n\n227–228\n\nxml.etree package, 313–316 XML ﬁle format, 94 XML ﬁles, 312–323 XML parsers, expat, 315, 317, 318 xml.parsers.expat module, 227 xml.sax module, 226, 321–323 xml.sax.saxutils module, 186, 226\n\nescape(), 186, 226, 320 quoteattr(), 226, 320 unescape(), 226 xmlrpc package, 226 XmlShadow.py (example), 373 __xor__() (^), 57, 253 .xpm (extension), 268\n\nY\n\nyield (statement), 279, 281, 342–344, 399–407\n\nZ\n\nZeroDivisionError (exception), 165,\n\n416 zfill()\n\nbytearray type, 301 bytes type, 301 str type, 75\n\n.zip (extension), 219 zip() (built-in), 127, 140, 143–144,\n\n205, 389\n\nzipfile module, 219",
      "page_number": 608
    },
    {
      "number": 61,
      "title": "Segment 61 (pages 616-623)",
      "start_page": 616,
      "end_page": 623,
      "detection_method": "topic_boundary",
      "content": "",
      "page_number": 616
    },
    {
      "number": 62,
      "title": "Segment 62 (pages 624-631)",
      "start_page": 624,
      "end_page": 631,
      "detection_method": "topic_boundary",
      "content": "",
      "page_number": 624
    },
    {
      "number": 63,
      "title": "Segment 63 (pages 632-636)",
      "start_page": 632,
      "end_page": 636,
      "detection_method": "topic_boundary",
      "content": "",
      "page_number": 632
    }
  ],
  "pages": [
    {
      "page_number": 2,
      "content": "Programming in Python 3\n\nA Complete Introduction to the Python Language\n\nSecond Edition\n\nMark Summerﬁeld\n\nUpper Saddle River, NJ · Boston · Indianapolis· San Francisco New York · Toronto · Montreal · London · Munich · Paris· Madrid Capetown · Sydney · Tokyo · Singapore· Mexico City",
      "content_length": 282,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 3,
      "content": "Many of the designationsused by manufacturersand sellerstodistinguish their productsareclaimed as trademarks. Where those designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed with initial capital letters or in all capitals.\n\nThe author and publisher have taken care in the preparation of this book, but make no expressed or implied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.\n\nThe publisher offers excellent discounts on this book when ordered in quantity for bulk purchases or special sales, which may include electronic versions and/or custom covers and content particular to your business, training goals, marketing focus, and branding interests. For more information, please contact:\n\nU.S.Corporate and Government Sales (800) 382-3419 corpsales@pearsontechgroup.com\n\nFor sales outside the United States, please contact:\n\nInternational Sales international@pearsoned.com\n\nVisit us on the Web:informit.com/aw\n\nLibrary of Congress Cataloging-in-Publication Data\n\nSummerﬁeld,Mark. Programming in Python 3:a complete introduction to the Python language / Mark Summerﬁeld.—2nd ed. p. cm. Includes bibliographical referencesand index. ISBN 978-0-321-68056-3 (pbk. : alk. paper) 1. Python (Computer program language) 2. Object-oriented programming (Computer science) I. Title.\n\nQA76.73.P98S86 2010 005.13’3—dc22\n\n2009035430\n\nCopyright © 2010 Pearson Education,Inc.\n\nAll rights reserved. Printed in the United States of America. This publication is protected by copyright,and permission must be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording,or likewise. For information regarding permissions, write to:\n\nPearson Education,Inc. Rights and Contracts Department 501Boylston Street,Suite 900 Boston, MA 02116 Fax:(617) 671-3447\n\nISBN-13: 978-0-321-68056-3 ISBN-10: 0-321-68056-1 Text printed in the United States on recycled paper at RR Donnelley in Crawfordsville,Indiana. First printing, November 2009",
      "content_length": 2292,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 4,
      "content": "Contents at a Glance\n\nList of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 1. Rapid Introduction to Procedural Programming . . .\n\nChapter 2. Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n\nChapter 3. Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n\nChapter 4. Control Structures and Functions . . . . . . . . . . . . . . . . . . . 159\n\nChapter 5. Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n\nChapter 6. Object-Oriented Programming . . . . . . . . . . . . . . . . . . . . . . 233\n\nChapter 7. File Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\n\nChapter 8. Advanced Programming Techniques . . . . . . . . . . . . . . . . 339\n\nChapter 9. Debugging, Testing, and Proﬁling . . . . . . . . . . . . . . . . . . . 413\n\nChapter 10. Processes and Threading . . . . . . . . . . . . . . . . . . . . . . . . . . . 439\n\nChapter 11. Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 457\n\nChapter 12. Database Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 475\n\nChapter 13. Regular Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489\n\nChapter 14. Introduction to Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 513\n\nChapter 15. Introduction to GUI Programming . . . . . . . . . . . . . . . . . 569\n\nEpilogue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595\n\nSelected Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 597\n\nIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 599\n\nwww.qtrac.eu/py3book.html\n\n1\n\n9",
      "content_length": 2121,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 5,
      "content": "Contents\n\nList of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 1. Rapid Introduction to Procedural Programming . . . Creating and Running Python Programs . . . . . . . . . . . . . . . . . . . . . . . . Python’s “Beautiful Heart” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #1: Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #2: Object References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #3: Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #4: Logical Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #5: Control Flow Statements . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #6: Arithmetic Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #7: Input/Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Piece #8: Creating and Calling Functions . . . . . . . . . . . . . . . . . . . . Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bigdigits.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . generate_grid.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 2. Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Identiﬁers and Keywords . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Integral Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Integers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Booleans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Floating-Point Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Floating-Point Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Decimal Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Comparing Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Slicing and Striding Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . String Operators and Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nix\n\nxv\n\n1\n\n9 9 14 14 16 18 21 26 30 33 36 39 39 42 44 47\n\n51 51 54 54 58 58 59 62 63 65 68 69 71",
      "content_length": 3247,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 6,
      "content": "String Formatting with the str.format() Method . . . . . . . . . . . . . . Character Encodings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . quadratic.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . csv2html.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 3. Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Sequence Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Named Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Set Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Frozen Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mapping Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Default Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ordered Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Iterating and Copying Collections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Iterators and Iterable Operations and Functions . . . . . . . . . . . . . Copying Collections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . generate_usernames.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . statistics.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 4. Control Structures and Functions . . . . . . . . . . . . . . . . . . . Control Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Conditional Branching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Looping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exception Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Catching and Raising Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . Custom Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Custom Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Names and Docstrings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Argument and Parameter Unpacking . . . . . . . . . . . . . . . . . . . . . . .\n\nx\n\n78 91 94 94 97 102 104\n\n107 107 108 111 113 120 121 125 126 126 135 136 138 138 146 148 149 152 156 158\n\n159 159 159 161 163 163 168 171 176 177",
      "content_length": 3995,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 7,
      "content": "Accessing Variables in the Global Scope . . . . . . . . . . . . . . . . . . . . . Lambda Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Assertions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Example:make_html_skeleton.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 5. Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Modules and Packages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Packages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Custom Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Overview of Python’s Standard Library . . . . . . . . . . . . . . . . . . . . . . . . . . String Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Command-Line Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mathematics and Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Times and Dates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Algorithms and Collection Data Types . . . . . . . . . . . . . . . . . . . . . . . File Formats, Encodings, and Data Persistence . . . . . . . . . . . . . . . File, Directory, and Process Handling . . . . . . . . . . . . . . . . . . . . . . . . Networking and Internet Programming . . . . . . . . . . . . . . . . . . . . . XML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Other Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 6. Object-Oriented Programming . . . . . . . . . . . . . . . . . . . . . . The Object-Oriented Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Object-Oriented Concepts and Terminology . . . . . . . . . . . . . . . . . . Custom Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Attributes and Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Inheritance and Polymorphism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Using Properties to Control Attribute Access . . . . . . . . . . . . . . . . Creating Complete Fully Integrated Data Types . . . . . . . . . . . . . Custom Collection Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating Classes That Aggregate Collections . . . . . . . . . . . . . . . . Creating Collection Classes Using Aggregation . . . . . . . . . . . . . . Creating Collection Classes Using Inheritance . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxi\n\n180 182 183 185 191 192\n\n195 195 199 202 212 213 214 216 216 217 219 222 225 226 228 230 231\n\n233 234 235 238 238 243 246 248 261 261 269 276 283 285",
      "content_length": 3705,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 8,
      "content": "Chapter 7. File Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Writing and Reading Binary Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Pickles with Optional Compression . . . . . . . . . . . . . . . . . . . . . . . . . . Raw Binary Data with Optional Compression . . . . . . . . . . . . . . . Writing and Parsing Text Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Writing Text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing Text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing Text Using Regular Expressions . . . . . . . . . . . . . . . . . . . . Writing and Parsing XML Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Element Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DOM (Document Object Model) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Manually Writing XML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing XML with SAX (Simple API for XML) . . . . . . . . . . . . . . . Random Access Binary Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A Generic BinaryRecordFile Class . . . . . . . . . . . . . . . . . . . . . . . . . . Example:The BikeStock Module’s Classes . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 8. Advanced Programming Techniques . . . . . . . . . . . . . . . . Further Procedural Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Branching Using Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Generator Expressions and Functions . . . . . . . . . . . . . . . . . . . . . . . Dynamic Code Execution and Dynamic Imports . . . . . . . . . . . . . . Local and Recursive Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Function and Method Decorators . . . . . . . . . . . . . . . . . . . . . . . . . . . . Function Annotations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Further Object-Oriented Programming . . . . . . . . . . . . . . . . . . . . . . . . . . Controlling Attribute Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Context Managers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Descriptors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Class Decorators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Abstract Base Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Multiple Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Metaclasses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Functional-Style Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Partial Function Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxii\n\n287 292 292 295 305 305 307 310 312 313 316 319 321 324 324 332 336 337\n\n339 340 340 341 344 351 356 360 363 363 367 369 372 378 380 388 390 395 398",
      "content_length": 3637,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 9,
      "content": "Coroutines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Example:Valid.py . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 9. Debugging, Testing, and Proﬁling . . . . . . . . . . . . . . . . . . . Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dealing with Syntax Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dealing with Runtime Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Scientiﬁc Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Unit Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proﬁling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 10. Processes and Threading . . . . . . . . . . . . . . . . . . . . . . . . . . . Using the Multiprocessing Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Using the Threading Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Example:A Threaded Find Word Program . . . . . . . . . . . . . . . . . . . Example:A Threaded Find Duplicate Files Program . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 11. Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a TCP Client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a TCP Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 12. Database Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DBM Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . SQL Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 13. Regular Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Python’s Regular Expression Language . . . . . . . . . . . . . . . . . . . . . . . . . . Characters and Character Classes . . . . . . . . . . . . . . . . . . . . . . . . . . Quantiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Grouping and Capturing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Assertions and Flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The Regular Expression Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxiii\n\n399 407 410 411\n\n413 414 414 415 420 425 432 437\n\n439 440 444 446 449 454 455\n\n457 458 464 471 471\n\n475 476 480 487 488\n\n489 490 490 491 494 496 499",
      "content_length": 3860,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 10,
      "content": "Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 14. Introduction to Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . BNF Syntax and Parsing Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . Writing Handcrafted Parsers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Simple Key–Value Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . Playlist Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing the Blocks Domain-Speciﬁc Language . . . . . . . . . . . . . . . Pythonic Parsing with PyParsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A Quick Introduction to PyParsing . . . . . . . . . . . . . . . . . . . . . . . . . . Simple Key–Value Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . Playlist Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing the Blocks Domain-Speciﬁc Language . . . . . . . . . . . . . . . Parsing First-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Lex/Yacc-Style Parsing with PLY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Simple Key–Value Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . Playlist Data Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parsing the Blocks Domain-Speciﬁc Language . . . . . . . . . . . . . . . Parsing First-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nChapter 15. Introduction to GUI Programming . . . . . . . . . . . . . . . . . Dialog-Style Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Main-Window-Style Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a Main Window . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Creating a Custom Dialog . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nEpilogue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nSelected Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxiv\n\n509 510\n\n513 514 519 519 522 525 534 535 539 541 543 548 553 555 557 559 562 566 568\n\n569 572 578 578 590 593 593\n\n595\n\n597\n\n599",
      "content_length": 3194,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 11,
      "content": "List of Tables\n\n2.1. Python’s Keywords . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 2.2. Numeric Operators and Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 55 2.3.\n\nInteger Conversion Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Integer Bitwise Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 2.5. The Math Module’s Functions and Constants #1 . . . . . . . . . . . . . . 60 2.6. The Math Module’s Functions and Constants #2 . . . . . . . . . . . . . . 61 2.7. Python’s String Escapes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 2.8. String Methods #1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 2.9. String Methods #2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 2.10. String Methods #3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 3.1. List Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 3.2. Set Methods and Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 3.3. Dictionary Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 3.4. Common Iterable Operators and Functions . . . . . . . . . . . . . . . . . . . 140 6.1. Comparison Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 6.2. Fundamental Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250 6.3. Numeric and Bitwise Special Methods . . . . . . . . . . . . . . . . . . . . . . . 253 6.4. Collection Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265 7.1. Bytes and Bytearray Methods #1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299 7.2. Bytes and Bytearray Methods #2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300 7.3. Bytes and Bytearray Methods #3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301 7.4. File Object Attributes and Methods #1 . . . . . . . . . . . . . . . . . . . . . . . 325 7.5. File Object Attributes and Methods #2 . . . . . . . . . . . . . . . . . . . . . . . 326 8.1. Dynamic Programming and Introspection Functions . . . . . . . . . . 349 8.2. Attribute Access Special Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365 8.3. The Numbers Module’s Abstract Base Classes . . . . . . . . . . . . . . . . 381 8.4. The Collections Module’s Main Abstract Base Classes . . . . . . . . . 383 12.1. DB-API 2.0 Connection Object Methods . . . . . . . . . . . . . . . . . . . . . . 481 12.2. DB-API 2.0 Cursor Object Attributes and Methods . . . . . . . . . . . 482 13.1. Character Class Shorthands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492\n\n2.4.\n\nxv",
      "content_length": 2921,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 12,
      "content": "13.2. Regular Expression Quantiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 493 13.3. Regular Expression Assertions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 497 13.4. The Regular Expression Module’s Functions . . . . . . . . . . . . . . . . . 502 13.5. The Regular Expression Module’s Flags . . . . . . . . . . . . . . . . . . . . . . 502 13.6. Regular Expression Object Methods . . . . . . . . . . . . . . . . . . . . . . . . . 503 13.7. Match Object Attributes and Methods . . . . . . . . . . . . . . . . . . . . . . . . 507\n\nxvi",
      "content_length": 568,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 13,
      "content": "Introduction\n\nPython is probably the easiest-to-learn and nicest-to-use programming lan- guage in widespread use. Python code is clear to read and write, and it is con- cise without being cryptic. Python is a very expressive language,which means thatwecanusually writefar fewer linesof Pythoncodethanwouldberequired for an equivalent application written in, say, C++ or Java.\n\nPython is a cross-platformlanguage:In general,the same Python program can be run on Windows and Unix-like systems such as Linux, BSD, and Mac OS X, simply by copying the ﬁle or ﬁles that make up the program to the target machine, with no “building” or compiling necessary. It is possible to create Python programs that use platform-speciﬁc functionality, but this is rarely necessary since almost all of Python’s standard library and most third-party libraries are fully and transparently cross-platform.\n\nOne of Python’sgreat strengthsis that it comeswith a very complete standard library—this allows us to do such things as download a ﬁle from the Internet, unpack a compressed archive ﬁle, or create a web server, all with just one or a few lines of code. And in addition to the standard library, thousands of third- party libraries are available, some providing more powerful and sophisticat- ed facilities than the standard library—for example, the Twisted networking library and the NumPy numeric library—while others provide functionality that is too specialized to be included in the standard library—for example, the SimPy simulationpackage. Mostof thethird-partylibrariesareavailablefrom the Python Package Index, pypi.python.org/pypi.\n\nPython can be used to program in procedural, object-oriented, and to a lesser extent, in functional style, although at heart Python is an object-oriented language. This book shows how to write both procedural and object-oriented programs, and also teaches Python’s functional programming features.\n\nThe purpose of this book is to show you how to write Python programs in good idiomatic Python 3style,and to be a useful referencefor thePython 3language aftertheinitialreading. AlthoughPython3isanevolutionary ratherthanrev- olutionary advanceonPython2,someolder practicesarenolonger appropriate or necessary in Python 3, and new practices have been introduced to take ad- vantage of Python 3 features. Python 3is a better language than Python 2—it builds on the many years of experience with Python 2 and adds lots of new features(and omitsPython 2’smisfeatures),to makeit even moreof a pleasure to use than Python 2, as well as more convenient, easier, and more consistent.\n\n1",
      "content_length": 2600,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 14,
      "content": "2\n\nIntroduction\n\nThe book’s aim is to teach the Python language, and although many of the standard Python libraries are used, not all of them are. This is not a problem, because once you have read the book, you will have enough Python knowledge to be able to make use of any of the standard libraries, or any third-party Python library, and be able to create library modules of your own.\n\nThe book is designed to be useful to several different audiences,including self- taught and hobbyist programmers, students, scientists, engineers, and others who need to program as part of their work, and of course, computing profes- sionals and computer scientists. To be of use to such a wide range of people without boring the knowledgeable or losing the less-experienced, the book as- sumes at least some programming experience (in any language). In particu- lar, it assumes a basic knowledge of data types (such as numbers and strings), collection data types (such as sets and lists), control structures (such as if and while statements), and functions. In addition, some examples and exercises assumea basic knowledgeof HTML markup,and some of the morespecialized chapters at the end assume a basic knowledge of their subject area; for exam- ple, the databases chapter assumes a basic knowledge of SQL.\n\nThe book is structured in such a way as to make you as productive as possible as quickly as possible. By the end of the ﬁrst chapter you will be able to write small but useful Python programs. Each successive chapter introduces new topics, and often both broadens and deepens the coverage of topics introduced in earlier chapters. This means that if you read the chapters in sequence, you can stop at any point and you’ll be able to write complete programs with what you have learned up to that point, and then, of course, resume reading to learn more advanced and sophisticated techniques when you are ready. For this reason, some topics are introduced in one chapter, and then are explored further in one or more later chapters.\n\nTwo key problems arise when teaching a new programming language. The ﬁrst is that sometimes when it is necessary to teach one particular concept, that conceptdependson another concept,which in turndependseither directly or indirectly on the ﬁrst. The second is that, at the beginning, the reader may know little or nothing of the language, so it is very difﬁcult to present inter- esting or useful examples and exercises. In this book, we seek to solve both of these problems,ﬁrst by assuming some prior programming experience,and secondby presenting Python’s“beautifulheart”in Chapter 1—eight key pieces of Python that are sufﬁcient on their own to write decent programs. One con- sequence of this approach is that in the early chapters some of the examples are a bit artiﬁcial in style, since they use only what has been taught up to the point wherethey arepresented;thiseffect diminisheschapter by chapter,until by theendof Chapter7,alltheexamplesarewrittenin completely naturaland idiomatic Python 3 style.\n\nThe book’s approach is wholly practical,and you are encouraged to try out the examples and exercises for yourself to get hands-on experience. Wherever",
      "content_length": 3193,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 15,
      "content": "Introduction\n\npossible, small but complete programs and modules are used as examples to provide realistic use cases. The examples, exercise solutions, and the book’s errata are available online at www.qtrac.eu/py3book.html.\n\nTwo sets of examples are provided. The standard examples work with any Python 3.x version—use these if you care about Python 3.0 compatibility. The “eg31” examples work with Python 3.1 or later—use these if you don’t need to support Python 3.0 because your programs’ users have Python 3.1or later. All of the examples have been tested on Windows, Linux, and Mac OS X.\n\nWhile it is best to use the most recent version of Python 3, this is not always possible if your users cannot or will not upgrade. Every example in this book works with Python 3.0 except where stated, and those examples and features that are speciﬁc to Python 3.1 are clearly indicated as such.\n\nAlthough it is possible to use this book to develop software that uses only Python 3.0, for those wanting to produce software that is expected to be in use for many years and that is expected to be compatible with later Python 3.x re- leases, it is best to use Python 3.1 as the oldest Python 3 version that you sup- port. This is partly because Python 3.1 has some very nice new features, but mostly because the Python developers strongly recommend using Python 3.1 (or later). The developers have decided that Python 3.0.1 will be the last Python 3.0.y release,and that there will be no more Python 3.0.y releaseseven if bugs or security problems are discovered. Instead, they want all Python 3 users to migrate to Python 3.1 (or to a later version), which will have the usu- al bugﬁx and security maintenance releases that Python versions normal- ly have.\n\nThe Structure of the Book\n\nChapter 1 presents eight key pieces of Python that are sufﬁcient for writing complete programs. It also describes some of the Python programming environmentsthatareavailableandpresentstwotiny exampleprograms,both built using the eight key pieces of Python covered earlier in the chapter.\n\nChapters 2 through 5 introduce Python’s procedural programming features, including its basic data types and collection data types,and many useful built- in functions and control structures, as well as very simple text ﬁle handling. Chapter 5 shows how to create custom modules and packages and provides an overview of Python’s standard library so that you will have a good idea of the functionality that Python provides out of the box and can avoid reinventing the wheel.\n\nChapter 6 provides a thorough introduction to object-oriented programming with Python. All of the material on procedural programming that you learned in earlier chapters is still applicable, since object-oriented programming is\n\n3",
      "content_length": 2769,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 16,
      "content": "4\n\nIntroduction\n\nbuilt on procedural foundations—for example, making use of the same data types, collection data types, and control structures.\n\nChapter 7 covers writing and reading ﬁles. For binary ﬁles, the coverage in- cludescompression and random access,and for text ﬁles,the coverage includes parsing manually and with regular expressions. This chapter also shows how to write and read XML ﬁles, including using element trees, DOM (Document Object Model), and SAX (Simple API for XML).\n\nChapter8revisitsmaterialcoveredinsomeearlierchapters,exploring manyof Python’smore advanced featuresin the areas of data typesand collection data types, control structures, functions, and object-oriented programming. This chapteralsointroducesmany newfunctions,classes,andadvancedtechniques, including functional-style programming and the use of coroutines—the mate- rial it covers is both challenging and rewarding.\n\nChapter9isdifferentfromalltheother chaptersin thatit discussestechniques and libraries for debugging, testing, and proﬁling programs, rather than introducing new Python features.\n\nTheremaining chapterscovervariousadvancedtopics. Chapter10showstech- niques for spreading a program’s workload over multiple processes and over multiple threads. Chapter 11 shows how to write client/server applications using Python’sstandardnetworking support. Chapter 12coversdatabasepro- gramming (both simple key–value “DBM” ﬁles and SQL databases).\n\nChapter13explainsandillustratesPython’sregularexpressionmini-language andcoverstheregularexpressionsmodule. Chapter14followsonfromthereg- ularexpressionschapterbyshowingbasicparsingtechniquesusingregularex- pressions,and also using twothird-party modules,PyParsing and PLY.Finally, Chapter 15introducesGUI (GraphicalUser Interface)programming using the tkinter module that is part of Python’s standard library. In addition,the book has a very brief epilogue, a selected bibliography, and of course, an index.\n\nMost of the book’s chapters are quite long to keep all the related material together in one place for ease of reference. However, the chapters are broken down into sections, subsections, and sometimes subsubsections,so it is easy to read at a pace that suits you;for example,by reading one section or subsection at a time.\n\nObtaining and Installing Python 3\n\nIf you have a modern and up-to-date Mac or other Unix-like system you may already have Python 3 installed. You can check by typing python -V (note the capital V) in a console (Terminal.app on Mac OS X)—if the version is 3.x you’ve already got Python 3 and don’t have to install it yourself. If Python wasn’t found at all it may be that it has a name which includesa version number. Try",
      "content_length": 2698,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 17,
      "content": "Introduction\n\ntyping python3 -V,andif that doesnot work try python3.0 -V,andfailing thattry python3.1 -V.If any of these work you now know that you already have Python installed,whatversionit is,andwhat it iscalled. (Inthisbook weusethename python3, but use whatever name worked for you,for example, python3.1.) If you don’t have any version of Python 3 installed, read on.\n\nFor Windows and Mac OS X, easy-to-use graphical installer packages are pro- vided that take you step-by-step through the installation process. These are available from www.python.org/download.For Windows,download the “Windows x86 MSI Installer”,unless you know for sure that your machine has a different processor for which a separate installer is supplied—for example, if you have an AMD64, get the “Windows AMD64 MSI Installer”. Once you’ve got the in- staller, just run it and follow the on-screen instructions.\n\nFor Linux, BSD, and other Unixes (apart from Mac OS X for which a .dmg in- stallation ﬁle is provided),the easiest way to install Python is to use your oper- ating system’spackagemanagement system. In most casesPython isprovided in several separate packages. For example, in Ubuntu (from version 8), there is python3.0 for Python, idle-python3.0 for IDLE (a simple development envi- ronment), and python3.0-doc for the documentation—as well as many other packages that provide add-ons for even more functionality than that provided by the standard library. (Naturally, the package names will start with python- 3.1 for the Python 3.1 versions, and so on.)\n\nIf no Python 3 packages are available for your operating system you will need to download the source from www.python.org/download and build Python from scratch. Get either of the source tarballs and unpack it using tar xvfz Python-3.1.tgz if you got the gzipped tarball or tar xvfj Python-3.1.tar.bz2 if you got the bzip2 tarball. (The version numbers may be different,for example, Python-3.1.1.tgz or Python-3.1.2.tar.bz2,in which casesimply replace 3.1 with your actual version number throughout.) The conﬁguration and building are standard. First, change into the newly created Python-3.1 directory and run ./configure. (You can use the --prefix option if you want to do a local install.) Next, run make.\n\nIt is possible that you may get some messages at the end saying that not all modules could be built. This normally means that you don’t have some of the required libraries or headers on your machine. For example, if the readline module could not be built, use the package management system to install the corresponding development library; for example, readline-devel on Fedora- based systems and readline-dev on Debian-based systems such as Ubuntu. Another module that may not build straight away is the tkinter module—this depends on both the Tcl and Tk development libraries, tcl-devel and tk-devel on Fedora-based systems, and tcl8.5-dev and tk8.5-dev on Debian-based sys- tems (and where the minor version may not be 5). Unfortunately, the relevant package names are not always so obvious, so you might need to ask for help on\n\n5",
      "content_length": 3091,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 18,
      "content": "6\n\nIntroduction\n\nPython’smailing list. Oncethemissing packagesareinstalled,run ./configure and make again.\n\nAfter successfully making, you could run make test to see that everything is okay, although this is not necessary and can take many minutes to complete.\n\nIf you used --prefix to do a local installation, just run make install. For Python 3.1,if you installed into,say,~/local/python31,then by adding the ~/lo- cal/python31/bin directory to your PATH, you will be able to run Python using python3 andIDLEusing idle3.Alternatively,if you already havea localdirecto- ry for executables that is already in your PATH (such as ~/bin),you might prefer to add soft links instead of changing the PATH. For example, if you keep exe- cutablesin ~/bin andyou installedPythonin ~/local/python31,you couldcreate suitable links by executing ln -s ~/local/python31/bin/python3 ~/bin/python3, and ~/local/python31/bin/idle3 ~/bin/idle3.For this book we did a local install and added soft links on Linux and Mac OS X exactly as described here—and on Windows we used the binary installer.\n\nIf you did not use --prefix and have root access, log in as root and do make in- stall. On sudo-based systems like Ubuntu, do sudo make install. If Python 2 is on the system, /usr/bin/python won’t be changed, and Python 3 will be avail- able as python3.0 (or python3.1 depending on the version installed) and from Python 3.1, in addition, as python3. Python 3.0’s IDLE is installed as idle, so if access to Python 2’s IDLE is still required the old IDLE will need to be renamed—for example,to /usr/bin/idle2—beforedoing the install. Python 3.1 installs IDLE as idle3 and so does not conﬂict with Python 2’s IDLE.\n\nAcknowledgments\n\nI would ﬁrst like to acknowledge with thanks the feedback I have received from readers of the ﬁrst edition, who gave corrections, or made suggestions, or both.\n\nMy next acknowledgments are of the book’s technical reviewers, starting with Jasmin Blanchette, a computer scientist, programmer, and writer with whom I have cowritten two C++/Qt books. Jasmin’s involvement with chapter planning andhissuggestionsandcriticismsregarding alltheexamples,aswell as his careful reading, have immensely improved the quality of this book.\n\nGeorg Brandl is a leading Python developer and documentor responsible for creating Python’s new documentation tool chain. Georg spotted many sub- tle mistakes and very patiently and persistently explained them until they were understood and corrected. He also made many improvements to the ex- amples.",
      "content_length": 2537,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 19,
      "content": "Introduction\n\nPhil Thompson is a Python expert and the creator of PyQt, probably the best Python GUI library available. Phil’s sharp-eyed and sometimes challenging feedback led to many clariﬁcations and corrections.\n\nTrenton Schulz is a senior software engineer at Nokia’s Qt Software (formerly Trolltech) who has been a valuable reviewer of all my previous books, and has once again come to my aid. Trenton’s careful reading and the numerous sug- gestions that he made helped clarify many issues and have led to considerable improvements to the text.\n\nIn addition to the aforementioned reviewers, all of whom read the whole book, David Boddie, a senior technical writer at Nokia’s Qt Software and an experiencedPythonpractitionerandopensourcedeveloper,hasreadandgiven valuable feedback on portions of it.\n\nFor this second edition, I would also like to thank Paul McGuire (author of the PyParsing module), who was kind enough to review the PyParsing examples that appear in thenew chapter on parsing,and who gave me a lot of thoughtful and useful advice. And for the same chapter, David Beazley (author of the PLY module) reviewed the PLY examples and provided valuable feedback. In addition, Jasmin, Trenton, Georg, and Phil read most of this second edition’s new material, and provided very valuable feedback.\n\nThanks are also due to Guido van Rossum, creator of Python, as well as to the wider Python community who have contributed so much to make Python, and especially its libraries, so useful and enjoyable to use.\n\nAs always, thanks to Jeff Kingston, creator of the Lout typesetting language that I have used for more than a decade.\n\nSpecial thanks to my editor, Debra Williams Cauley, for her support, and for once again making the entire process as smooth as possible. Thanks also to Anna Popick, who managed the production process so well, and to the proof- reader, Audrey Doyle, who did such ﬁne work once again. And for this second edition I also want to thank Jennifer Lindner for helping me keep the new ma- terial understandable,and theﬁrst edition’sJapanesetranslator TakahiroNa- gao ,for spotting some subtle mistakeswhich I’ve been able to correct in this edition.\n\nLast but not least, I want to thank my wife, Andrea, both for putting up with the 4 a.m. wake-ups when book ideas and code corrections often arrived and insisted upon being noted or tested there and then, and for her love, loyalty, and support.\n\n7",
      "content_length": 2431,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 20,
      "content": "1\n\nCreating and Running Python Programs\n\nPython’s “Beautiful Heart”\n\nRapid Introduction to Procedural Programming\n\nThis chapter provides enough information to get you started writing Python programs. We strongly recommend that you install Python if you have not already done so,so that you can get hands-on experience to reinforce what you learn here. (The Introduction explains how to obtain and install Python on all major platforms; 4 ➤.)\n\nThis chapter’s ﬁrst section shows you how to create and execute Python pro- grams. You can use your favorite plain text editor to write your Python code, but the IDLEprogramming environment discussed in thissection providesnot only a code editor, but also additional functionality, including facilities for ex- perimenting with Python code, and for debugging Python programs.\n\nThe second section presents eight key pieces of Python that on their own are sufﬁcient to write useful programs. These pieces are all covered fully in later chapters, and as the book progresses they are supplemented by all of the rest of Python so that by the end of the book, you will have covered the whole language and will be able to use all that it offers in your programs.\n\nThe chapter’sﬁnal section introducestwo short programswhich use the subset of Python features introduced in the second section so that you can get an immediate taste of Python programming.\n\nCreating and Running Python Programs\n\nPython code can be written using any plain text editor that can load and save encoding. By de- text using either the ASCII or the UTF-8 Unicode character fault, Python ﬁles are assumed to use the UTF-8 character encoding, a super- set of ASCII that can represent pretty well every character in every language. Pythonﬁlesnormally haveanextensionof .py,althoughonsomeUnix-likesys-\n\n9\n\n||||\n\n|||\n\nChar- acter encod- ings ➤ 91",
      "content_length": 1850,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 21,
      "content": "10\n\nChapter 1. Rapid Introduction to Procedural Programming\n\ntems (e.g., Linux and Mac OS X) some Python applications have no extension, and Python GUI (Graphical User Interface) programs usually have an exten- sion of .pyw,particularlyon WindowsandMac OSX.In thisbook wealwaysuse an extension of .py for Python console programsand Python modules,and .pyw for GUI programs. All the examples presented in this book run unchanged on all platforms that have Python 3 available.\n\nJust to make sure that everything is set up correctly, and to show the clas- sical ﬁrst example, create a ﬁle called hello.py in a plain text editor (Win- dows Notepad is ﬁne—we’ll use a better editor shortly), with the following contents:\n\n#!/usr/bin/env python3\n\nprint(\"Hello\", \"World!\")\n\nTheﬁrstlineisacomment. InPython,commentsbeginwitha # andcontinueto the end of the line. (We will explain the rather cryptic comment in a moment.) The second line is blank—outside quoted strings, Python ignores blank lines, but they are often useful to humans to break up large blocks of code to make them easier to read. The third line is Python code. Here, the print() function is called with two arguments, each of type str (string; i.e., a sequence of char- acters).\n\nEach statement encountered in a .py ﬁle is executed in turn, starting with the ﬁrst one and progressing line by line. This is different from some other languages, for example, C++ and Java, which have a particular function or method with a special name where they start from. The ﬂow of control can of course be diverted as we will see when we discuss Python’s control structures in the next section.\n\nWe will assume that Windows users keep their Python code in the C:\\py3eg directory and that Unix (i.e.,Unix,Linux,and Mac OS X) userskeep their code in the $HOME/py3eg directory. Save hello.py into the py3eg directory and close the text editor.\n\nNow that we have a program, we can run it. Python programs are executed by the Python interpreter, and normally this is done inside a console window. On Windows the console is called “Console”, or “DOS Prompt”, or “MS-DOS Prompt”, or something similar, and is usually available from Start→All Pro- grams→Accessories.On Mac OSX the console isprovided by the Terminal.apppro- gram (located in Applications/Utilities by default),available using Finder,and on other Unixes,we can use an xterm or the console provided by the windowing environment, for example, konsole or gnome-terminal.\n\nStart up a console, and on Windows enter the following commands (which assume that Python is installed in the default location)—the console’s output is shown in lightface; what you type is shown in bold:",
      "content_length": 2673,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 22,
      "content": "Creating and Running Python Programs\n\nC:\\>cd c:\\py3eg C:\\py3eg\\>c:\\python31\\python.exe hello.py\n\nSince the cd (change directory) command has an absolute path, it doesn’t matter which directory you start out from.\n\nUnix users enter this instead (assuming that Python 3 is in the PATH):★\n\n$ cd $HOME/py3eg $ python3 hello.py\n\nIn both cases the output should be the same:\n\nHello World!\n\nNote that unless stated otherwise, Python’s behavior on Mac OS X is the same as that on any other Unix system. In fact, whenever we refer to “Unix” it can be taken to mean Linux, BSD, Mac OS X, and most other Unixes and Unix-like systems.\n\nAlthough the program hasjust one executable statement,by running it we can infer some information about the print() function. For one thing, print() is a built-in part of the Python language—we didn’t need to “import” or “include” it from a library to make use of it. Also, it separates each item it prints with a single space, and prints a newline after the last item is printed. These are default behaviors that can be changed, as we will see later. Another thing worth noting about print() is that it can take as many or as few arguments as we care to give it.\n\nTyping such command lines to invoke our Python programs would quickly become tedious. Fortunately, on both Windows and Unix we can use more convenient approaches. Assuming we are in the py3eg directory, on Windows we can simply type:\n\nC:\\py3eg\\>hello.py\n\nWindows uses its registry of ﬁle associations to automatically call the Python interpreter when a ﬁlename with extension .py is entered in a console.\n\nUnfortunately, this convenience does not always work, since some versions of Windows have a bug that sometimes affects the execution of interpreted programs that are invoked as the result of a ﬁle association. This isn’t speciﬁc to Python; other interpreters and even some .bat ﬁles are affected by the bug too. If this problem arises, simply invoke Python directly rather than relying on the ﬁle association.\n\nIf the output on Windows is:\n\n★The Unix prompt may well be different from the $ shown here; it does not matter what it is.\n\n11\n\nprint() ➤ 181",
      "content_length": 2147,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 23,
      "content": "12\n\nChapter 1. Rapid Introduction to Procedural Programming\n\n('Hello', 'World!')\n\nthen it means that Python 2 is on the system and is being invoked instead of Python 3. One solution to this is to change the .py ﬁle association from Python 2 to Python 3. The other (less convenient, but safer) solution is to put the Python 3 interpreter in the path (assuming it is installed in the default lo- cation),andexecuteit explicitly each time. (ThisalsogetsaroundtheWindows ﬁle association bug mentioned earlier.) For example:\n\nC:\\py3eg\\>path=c:\\python31;%path% C:\\py3eg\\>python hello.py\n\nIt might be more convenient to create a py3.bat ﬁle with the single line path=c:\\python31;%path% and to save this ﬁle in the C:\\Windows directory. Then, whenever you start a console for running Python 3 programs, begin by exe- cuting py3.bat. Or alternatively you can have py3.bat executed automatically. To do this, change the console’s properties (ﬁnd the console in the Start menu, then right-click it to pop up its Properties dialog), and in the Shortcut tab’s Target string, append the text “ /u /k c:\\windows\\py3.bat” (note the space before, between, and after the “/u” and “/k” options, and be sure to add this at the end after “cmd.exe”).\n\nOn Unix, we must ﬁrst make the ﬁle executable, and then we can run it:\n\n$ chmod +x hello.py $ ./hello.py\n\nWe need to run the chmod command only once of course; after that we can simply enter ./hello.py and the program will run.\n\nOn Unix,when a program is invoked in the console,the ﬁle’s ﬁrst two bytesare read.★ If thesebytesaretheASCIIcharacters#!,theshell assumesthat theﬁle is to be executed by an interpreter and that the ﬁle’s ﬁrst line speciﬁes which interpreter to use. This line is called the shebang (shell execute) line, and if present must be the ﬁrst line in the ﬁle.\n\nThe shebang line is commonly written in one of two forms, either:\n\n#!/usr/bin/python3\n\nor:\n\n#!/usr/bin/env python3\n\nIf written using the ﬁrst form, the speciﬁed interpreter is used. This form may be necessary for Python programs that are to be run by a web server,\n\n★Theinteractionbetween theuser andtheconsoleishandledby a “shell”program. Thedistinction between the console and the shell does not concern us here, so we use the terms interchangeably.",
      "content_length": 2263,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 24,
      "content": "Obtain- ing and install- ing Python 4➤\n\nCreating and Running Python Programs\n\nalthough the speciﬁc path may be different from the one shown. If written using the second form, the ﬁrst python3 interpreter found in the shell’s current environment is used. The second form is more versatile because it allows for the possibility that the Python 3 interpreter is not located in /usr/bin (e.g., it could be in /usr/local/bin or installed under $HOME). The shebang line is not needed (but is harmless) under Windows; all the examples in this book have a shebang line of the second form, although we won’t show it.\n\nNote that for Unix systems we assume that the name of Python 3’s executable (or a soft link to it) in the PATH is python3. If this is not the case, you will need to change the shebang line in the examples to use the correct name (or correct name and path if you use the ﬁrst form),or create a soft link from the Python 3 executable to the name python3 somewhere in the PATH.\n\nMany powerful plain text editors, such as Vim and Emacs, come with built-in typicallyinvolvesproviding supportforeditingPythonprograms. Thissupport color syntax highlighting and correctly indenting or unindenting lines. An al- ternative is to use the IDLE Python programming environment. On Windows and Mac OS X, IDLE is installed by default. On Unixes IDLE is built along with the Python interpreter if you build from the tarball,but if you use a pack- age manager, IDLE is usually provided as a separate package as described in the Introduction.\n\nAs the screenshot in Figure 1.1shows,IDLEhas a rather retro look that harks back to the days of Motif on Unix and Windows 95. This is because it uses the Tk-based Tkinter GUI library (covered in Chapter 15) rather than one of the more powerful modern GUI libraries such as PyGtk, PyQt, or wxPython. The reasons for the use of Tkinter are a mixture of history, liberal license condi- tions, and the fact that Tkinter is much smaller than the other GUI libraries. On the plus side, IDLE comes as standard with Python and is very simple to learn and use.\n\nIDLE provides three key facilities: the ability to enter Python expressions and code and to see the results directly in the Python Shell; a code editor that provides Python-speciﬁc color syntax highlighting and indentation support; and a debugger that can be used to step through code to help identify and kill bugs. The Python Shell is especially useful for trying out simple algorithms, snippets of code, and regular expressions, and can also be used as a very powerful and ﬂexible calculator.\n\nSeveral other Python development environments are available, but we recom- mend that you use IDLE, at least at ﬁrst. An alternative is to create your pro- grams in the plain text editor of your choice and debug using calls to print().\n\nIt is possible to invoke the Python interpreter without specifying a Python program. If this is done the interpreter starts up in interactive mode. In this mode it is possible to enter Python statements and see the results exactly the same as when using IDLE’s Python Shell window, and with the same >>>\n\n13",
      "content_length": 3127,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 25,
      "content": "14\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nFigure 1.1 IDLE’s Python Shell\n\nprompts. But IDLE is much easier to use, so we recommend using IDLE for experimenting with code snippets. The short interactive examples we show are all assumed to be entered in an interactive Python interpreter or in IDLE’s Python Shell.\n\nWe now know how to create and run Python programs,but clearly we won’t get very far knowing only a single function. In the next section we will consider- ably increaseour Python knowledge. Thiswill makeusableto createshort but useful Python programs, something we will do in this chapter’s last section.\n\nPython’s “Beautiful Heart”\n\nIn this section we will learn about eight key pieces of Python, and in the next section we will show how these piecescan be used to writea coupleof small but realistic programs. There is much more to say about all of the things covered in this section, so if as you read it you feel that Python is missing something or that things are sometimes done in a long-winded way, peek ahead using the forward references or using the table of contents or index, and you will almost certainly ﬁnd that Python hasthe feature you want and often hasmore concise forms of expression than we show here—and a lot more besides.\n\nPiece #1: Data Types\n\nOne fundamental thing that any programming language must be able to do is represent items of data. Python provides several built-in data types, but we will concern ourselves with only two of them for now. Python represents\n\n|||\n\n||",
      "content_length": 1531,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 26,
      "content": "Python’s “Beautiful Heart”\n\nintegers (positive and negative whole numbers) using the int type, and it represents strings (sequences of Unicode characters) using the str type. Here are some examples of integer and string literals:\n\n973 210624583337114373395836055367340864637790190801098222508621955072 0 \"Infinitely Demanding\" 'Simon Critchley' 'positively αβγ ÷©' ''\n\nIncidentally, the second number shown is 2217—the size of Python’s integers is limited only by machine memory, not by a ﬁxed number of bytes. Strings can be delimited by double or single quotes, as long as the same kind are used at both ends, and since Python uses Unicode, strings are not limited to ASCII characters, as the penultimate string shows. An empty string is simply one with nothing between the delimiters.\n\nPython uses square brackets ([]) to access an item from a sequence such as a string. For example, if we are in a Python Shell (either in the interactive interpreter,or in IDLE) we can enter the following—the Python Shell’s output is shown in lightface; what you type is shown in bold:\n\n>>> \"Hard Times\"[5] 'T' >>> \"giraffe\"[0] 'g'\n\nTraditionally, Python Shells use >>> as their prompt, although this can be changed. The square brackets syntax can be used with data items of any data type that is a sequence, such as strings and lists. This consistency of syntax is one of the reasons that Python is so beautiful. Note that all Python index positions start at 0.\n\nIn Python, both str and the basic numeric types such as int are im- mutable—that is,once set,their value cannot be changed. At ﬁrst thisappears to be a rather strange limitation,but Python’ssyntax means that this is a non- issuein practice. Theonly reason for mentioning it isthat although wecan use square brackets to retrieve the character at a given index position in a string, we cannot use them to set a new character. (Note that in Python a character is simply a string of length 1.)\n\nTo convert a data item from one type to another we can use the syntax datatype(item). For example:\n\n>>> int(\"45\") 45\n\n15",
      "content_length": 2063,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 27,
      "content": "16\n\nChapter 1. Rapid Introduction to Procedural Programming\n\n>>> str(912) '912'\n\nThe int() conversion is tolerant of leading and trailing whitespace, so int(\" 45 \") would have worked just as well. The str() conversion can be applied to almost any data item. We can easily make our own custom data types support str() conversion, and also int() or other conversions if they make sense, as we will see in Chapter 6. If a conversion fails, an exception is raised—we brieﬂy introduce exception-handling in Piece #5, and fully cover exceptions in Chapter 4.\n\nStrings and integers are fully covered in Chapter 2, along with other built-in data types and some data types from Python’s standard library. That chapter also covers operations that can be applied to immutable sequences, such as strings.\n\nPiece #2: Object References\n\nOnce we have some data types, the next thing we need are variables in which to store them. Python doesn’t have variables as such, but instead has object references. When it comes to immutable objects like ints and strs, there is no discernable difference between a variable and an object reference. As for mutable objects,there is a difference,but it rarely mattersin practice. We will use the terms variable and object reference interchangeably.\n\nLet’s look at a few tiny examples, and then discuss some of the details.\n\nx = \"blue\" y = \"green\" z = x\n\nThe syntax is simply objectReference = value. There is no need for predecla- ration and no need to specify the value’s type. When Python executes the ﬁrst statement it creates a str object with the text “blue”, and creates an object ref- erence called x that refers to the str object. For all practical purposes we can say that “variable x has been assigned the ‘blue’ string”.The second statement is similar. The third statement createsa new object reference called z and sets it to refer to the same object that the x object reference refers to (in this case the str containing the text “blue”).\n\nThe = operator is not the same as the variable assignment operator in some other languages. The = operator binds an object reference to an object in memory. If the object reference already exists,it is simply re-bound to refer to the object on the right of the = operator;if the object reference does not exist it is created by the = operator.\n\n||\n\nShallow and deep copying ➤ 146",
      "content_length": 2353,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 29,
      "content": "18\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nroute = \"North\" print(route, type(route)) # prints: North <class 'str'>\n\nHere we create a new object reference called route and set it to refer to a new int of value 866.At thispoint we could use / with route since division is a valid operation for integers. Then we reuse the route object reference to refer to a new str of value “North”,and the int object is scheduled for garbage collection sincenow no object referencerefersto it. At thispoint using / with route would cause a TypeError to be raised since / is not a valid operation for a string.\n\nThe type() function returns the data type (also known as the “class”) of the data item it is given—this function can be very useful for testing and debug- ging, but would not normally appear in production code, since there is a better alternative as we will see in Chapter 6.\n\nIf we are experimenting with Python code inside the interactive interpreter or in a Python Shell such as the one provided by IDLE, simply typing the name of an object reference is enough to have Python print its value. For example:\n\n>>> x = \"blue\" >>> y = \"green\" >>> z = x >>> x 'blue' >>> x, y, z ('blue', 'green', 'blue')\n\nThis is much more convenient than having to call the print() function all the time, but works only when using Python interactively—any programs and modules that we write must use print() or similar functions to produce output. Notice that Python displayedthe last output in parenthesesseparated by commas—this signiﬁes a tuple, that is, an ordered immutable sequence of objects. We will cover tuples in the next piece.\n\nPiece #3: Collection Data Types\n\nIt is often convenient to hold entire collections of data items. Python provides several collection data types that can hold items, including associative arrays andsets. But herewewillintroducejust two:tuple and list.Pythontuplesand lists can be used to hold any number of data items of any data types. Tuples are immutable, so once they are created we cannot change them. Lists are mutable, so we can easily insert items and remove items whenever we want.\n\nTuples are created using commas (,), as these examples show—and note that here, and from now on, we don’t use bold to distinguish what you type:\n\n>>> \"Denmark\", \"Finland\", \"Norway\", \"Sweden\" ('Denmark', 'Finland', 'Norway', 'Sweden')\n\n||\n\nisin- stance() ➤ 242",
      "content_length": 2386,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 30,
      "content": "Python’s “Beautiful Heart”\n\n19\n\n>>> \"one\", ('one',)\n\nPythonoutputsa tupleit enclosesitinparentheses. Many programmers When emulate this and always enclose the tuple literals they write in parentheses. If we have a one-item tuple and want to use parentheses, we must still use the comma—for example, (1,). An empty tuple is created by using empty parentheses, (). The comma is also used to separate arguments in function calls,so if we want to pass a tuple literal as an argument we must enclose it in parentheses to avoid confusion.\n\nHere are some example lists:\n\n[1, 4, 9, 16, 25, 36, 49] ['alpha', 'bravo', 'charlie', 'delta', 'echo'] ['zebra', 49, -879, 'aardvark', 200] []\n\nOne way to create a list is to use square brackets ([]) as we have later on we will see other ways. The fourth list shown is an empty list.\n\ndone here;\n\nUnder the hood, lists and tuples don’t store data items at all, but rather object references. When lists and tuples are created (and when items are inserted in the case of lists), they take copies of the object references they are given. In the case of literal itemssuch asintegersor strings,an object of theappropriate data type is created in memory and suitably initialized, and then an object reference referring to the object is created, and it is this object reference that is put in the list or tuple.\n\ncan nest Like everything else in Python,collection data typesare objects,so we collection data types inside other collection data types, for example, to create lists of lists, without formality. In some situations the fact that lists, tuples, and most of Python’s other collection data types hold object references rather than objects makes a difference—this is covered in Chapter 3.\n\nIn procedural programming we call functions and often pass in data items as arguments. For example, we have already seen the print() function. Another frequently used Python function is len(), which takes a single data item as its argument and returns the “length” of the item as an int. Here are a few calls to len():\n\n>>> len((\"one\",)) 1 >>> len([3, 5, 1, 2, \"pause\", 5]) 6 >>> len(\"automatically\") 13\n\ntuple type ➤ 108\n\nCreat- ing and calling func- tions ➤ 36\n\nlist type ➤ 113\n\nShallow and deep copying ➤ 146",
      "content_length": 2236,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 31,
      "content": "20\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nTuples, lists, and strings are “sized”, that is, they are data types that have a notion of size, and data items of any such data type can be meaningfully passed to the len() function. (An exception is raised if a nonsized data item is passed to len().)\n\nAll Python data items are objects (also called instances) of a particular data type (also called a class).We will use the termsdatatypeand classinterchange- ably. One key difference between an object, and the plain items of data that some other languages provide (e.g., C++ or Java’s built-in numeric types), is that an object can have methods. Essentially, a method is simply a function that iscalled for a particular object. For example,the list typehasan append() method, so we can append an object to a list like this:\n\n>>> x = [\"zebra\", 49, -879, \"aardvark\", 200] >>> x.append(\"more\") >>> x ['zebra', 49, -879, 'aardvark', 200, 'more']\n\nThe x object knows that it is a list (all Python objects know what their own data type is), so we don’t need to specify the data type explicitly. In the im- plementation of the append() method the ﬁrst argument will be the x object itself—this is done automatically by Python as part of its syntactic support for methods.\n\nThe append() method mutates, that is, changes, the original list. This is possi- ble becauselistsare mutable. It isalso potentially more efﬁcient than creating a new list with the original items and the extra item and then rebinding the object reference to the new list, particularly for very long lists.\n\nIn a procedural language the same thing could be achieved by using the list’s append() like this (which is perfectly valid Python syntax):\n\n>>> list.append(x, \"extra\") >>> x ['zebra', 49, -879, 'aardvark', 200, 'more', 'extra']\n\nHere we specify the data type and the data type’s method, and give as the ﬁrst argument the data item of the data type we want to call the method on, followed by any additional arguments. (In the face of inheritance there is a subtle semantic difference between the two syntaxes; the ﬁrst form is the one that is most commonly used in practice. Inheritance is covered in Chapter 6.)\n\nIf you are unfamiliar with object-oriented programming this may seem a bit strange at ﬁrst. For now, just accept that Python has conventional functions called like this: functionName(arguments); and methods which are called like this: objectName.methodName(arguments). (Object-oriented programming is cov- ered in Chapter 6.)\n\nSized ➤ 383",
      "content_length": 2537,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 32,
      "content": "Python’s “Beautiful Heart”\n\nThe dot (“access attribute”) operator is used to access an object’s attributes. An attribute can be any kind of object, although so far we have shown only method attributes. Since an attribute can be an object that has attributes, which in turn can have attributes,and so on,we can use as many dot operators as necessary to access the particular attribute we want.\n\nThe list type has many other methods, including insert() which is used to insert an item at a given index position,and remove() which removesan item at a given index position. As noted earlier, Python indexes are always 0-based.\n\nWe saw before that we can get characters from strings using the square brackets operator, and noted at the time that this operator could be used with any sequence. Lists are sequences, so we can do things like this:\n\n>>> x ['zebra', 49, -879, 'aardvark', 200, 'more', 'extra'] >>> x[0] 'zebra' >>> x[4] 200\n\nTuples are also sequences, so if x had been a tuple we could retrieve items us- ing square bracketsin exactly the same way as we have done for the x list. But sincelistsaremutable(unlikestringsandtupleswhich areimmutable),wecan also use the square brackets operator to set list elements. For example:\n\n>>> x[1] = \"forty nine\" >>> x ['zebra', 'forty nine', -879, 'aardvark', 200, 'more', 'extra']\n\nIf wegiveanindex positionthatisoutof range,anexceptionwillberaised—we brieﬂy introduce exception-handling in Piece #5, and fully cover exceptions in Chapter 4.\n\nWe have used the term sequencea few timesnow,relying on an informal under- standing of itsmeaning,and will continuetodoso for thetimebeing. However, Python deﬁnesprecisely what featuresa sequencemust support,and similarly deﬁnes what features a sized object must support, and so on for various other categories that a data type might belong to, as we will see in Chapter 8.\n\nLists, tuples, and Python’s other built-in collection data types are covered in Chapter 3.\n\nPiece #4: Logical Operations\n\nOne of the fundamental features of any programming language is its logical operations. Python provides four sets of logical operations,and we will review the fundamentals of all of them here.\n\n21\n\n||",
      "content_length": 2186,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 33,
      "content": "22\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nThe Identity Operator\n\nSince all Python variables are really object references, it sometimes makes sense to ask whether two or more object references are referring to the same object. The is operator isa binary operator that returnsTrue if itsleft-handob- ject reference is referring to the same object as its right-hand object reference. Here are some examples:\n\n>>> a = [\"Retention\", 3, None] >>> b = [\"Retention\", 3, None] >>> a is b False >>> b = a >>> a is b True\n\nNote that it usually doesnot make sense to use is for comparing ints, strs,and most other data typessincewealmost invariably want tocomparetheir values. In fact, using is to compare data items can lead to unintuitive results, as we can see in the preceding example, where although a and b are initially set to the same list values, the lists themselves are held as separate list objects and so is returns False the ﬁrst time we use it.\n\nOne beneﬁt of identity comparisons is that they are very fast. This is because the objectsreferred to do not have to be examined themselves. The is operator needs to compare only the memory addressesof the objects—the same address means the same object.\n\nThe most common use case for is is to compare a data item with the built-in null object, None, which is often used as a place-marking value to signify “unknown” or “nonexistent”:\n\n>>> a = \"Something\" >>> b = None >>> a is not None, b is None (True, True)\n\nTo invert the identity test we use is not.\n\nThe purpose of the identity operator is to see whether two object references refer to the same object, or to see whether an object is None. If we want to compare object values we should use a comparison operator instead.\n\nComparison Operators\n\nPython provides the standard set of binary comparison operators, with the expected semantics: < less than, <= less than or equal to, == equal to, != not\n\n|\n\n|",
      "content_length": 1925,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 34,
      "content": "Python’s “Beautiful Heart”\n\nequal to, >= greater than or equal to, and > greater than. These operators compare object values,that is,the objectsthat the object referencesused in the comparison refer to. Here are a few examples typed into a Python Shell:\n\n>>> a = 2 >>> b = 6 >>> a == b False >>> a < b True >>> a <= b, a != b, a >= b, a > b (True, True, False, False)\n\nEverything is as we would expect with integers. Similarly, strings appear to compare properly too:\n\n>>> a = \"many paths\" >>> b = \"many paths\" >>> a is b False >>> a == b True\n\nAlthough a and b are different objects (have different identities), they have though, that because the same values, so they compare equal. Be aware, Python uses Unicode for representing strings, comparing strings that contain non-ASCII characters can be a lot subtler and more complicated than it might at ﬁrst appear—we will fully discuss this issue in Chapter 2.\n\nIn some cases,comparing the identity of two stringsor numbers—for example, using a is b—will return True, even if each has been assigned separately as we did here. This is because some implementationsof Python will reuse the same object (since the value is the same and is immutable) for the sake of efﬁciency. The moral of this is to use == and != when comparing values, and to use is and is not only when comparing with None or when we really do want to see if two object references, rather than their values, are the same.\n\nOneparticularlynicefeatureof Python’scomparisonoperatorsisthatthey can be chained. For example:\n\n>>> a = 9 >>> 0 <= a <= 10 True\n\nThis is a nicer way of testing that a given data item is in range than having to do two separate comparisons joined by logical and, as most other languages require. It also has the additional virtue of evaluating the data item only once (since it appears once only in the expression), something that could make a\n\n23\n\nCom- paring strings ➤ 68",
      "content_length": 1910,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 35,
      "content": "24\n\nChapter 1. Rapid Introduction to Procedural Programming\n\ndifference if computing the data item’s value is expensive, or if accessing the data item causes side effects.\n\nThanks to the “strong” aspect of Python’s dynamic typing, comparisons that don’t make sense will cause an exception to be raised. For example:\n\n>>> \"three\" < 4 Traceback (most recent call last): ... TypeError: unorderable types: str() < int()\n\nWhen an exception is raised and not handled, Python outputs a traceback along with the exception’s error message. For clarity, we have omitted the traceback part of the output,replacing it with an ellipsis.★ The same TypeError exception would occur if we wrote \"3\" < 4 because Python does not try to guess our intentions—the right approach is either to explicitly convert, for example, int(\"3\") < 4, or to use comparable types, that is, both integers or both strings.\n\nPython makes it easy for us to create custom data types that will integrate nicely so that, for example, we could create our own custom numeric type which would be able to participate in comparisons with the built-in int type, and with other built-in or custom numeric types, but not with strings or other non-numeric types.\n\nThe Membership Operator\n\nFor data types that are sequences or collections such as strings, lists, and tu- ples,wecan test for membershipusing the in operator,and for nonmembership using the not in operator. For example:\n\n>>> p = (4, \"frog\", 9, -33, 9, 2) >>> 2 in p True >>> \"dog\" not in p True\n\nFor lists and tuples, the in operator uses a linear search which can be slow for very large collections (tens of thousands of items or more).On the other hand, in is very fast when used on a dictionary or a set; both of these collection data types are covered in Chapter 3. Here is how in can be used with a string:\n\n>>> phrase = \"Wild Swans by Jung Chang\" >>> \"J\" in phrase True\n\n★A traceback (sometimes called a backtrace)is a list of all the calls made from the point where the unhandled exception occurred back to the top of the call stack.\n\n|\n\nDealing with runtime errors ➤ 415\n\nAlter- native Fuzzy- Bool ➤ 256",
      "content_length": 2123,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 36,
      "content": "Python’s “Beautiful Heart”\n\n>>> \"han\" in phrase True\n\nConveniently, in the case of strings, the membership operator can be used to test for substrings of any length. (As noted earlier, a character is just a string of length 1.)\n\nLogical Operators\n\nPython provides three logical operators: and, or, and not. Both and and or use short-circuit logic and return the operand that determined the result—they do not return a Boolean (unless they actually have Boolean operands). Let’s see what this means in practice:\n\n>>> five = 5 >>> two = 2 >>> zero = 0 >>> five and two 2 >>> two and five 5 >>> five and zero 0\n\nIf the expression occurs in a Boolean context, the result is evaluated as a Boolean, so the preceding expressions would come out as True, True, and False in, say, an if statement.\n\n>>> nought = 0 >>> five or two 5 >>> two or five 2 >>> zero or five 5 >>> zero or nought 0\n\nThe or operator is similar; here the results in a Boolean context would be True, True, True, and False.\n\nThe not unary operator evaluates its argument in a Boolean context and always returns a Boolean result, so to continue the earlier example, not (zero or nought) would produce True, and not two would produce False.\n\n25\n\n|",
      "content_length": 1207,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 37,
      "content": "26\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nPiece #5: Control Flow Statements\n\nWe mentioned earlier that each statement encountered in a .py ﬁle is executed in turn, starting with the ﬁrst one and progressing line by line. The ﬂow of control can be diverted by a function or method call or by a control structure, such asa conditionalbranch or a loop statement. Controlisalsodivertedwhen an exception is raised.\n\nIn this subsection we will look at Python’s if statement and its while and for loops, deferring consideration of functions to Piece #8, and methods to Chap- ter 6. We will also look at the very basics of exception-handling; we cover the subject fully in Chapter 4. But ﬁrst we will clarify a couple of items of termi- nology.\n\nA Boolean expression is anything that can be evaluated to produce a Boolean value (True or False). In Python, such an expression evaluates to False if it is the predeﬁned constant False, the special object None, an empty sequence or collection (e.g., an empty string, list, or tuple), or a numeric data item of value 0; anything else is considered to be True. When we create our own custom data types (e.g., in Chapter 6), we can decide for ourselves what they should return in a Boolean context.\n\nIn Python-speak a block of code,that is,a sequence of one or more statements, is called a suite. Because some of Python’s syntax requires that a suite be present, Python provides the keyword pass which is a statement that does nothing and that can be used where a suite is required (or where we want to indicate that we have considered a particular case) but where no processing is necessary.\n\nThe if Statement\n\nThe general syntax for Python’s if statement is this:★\n\nif boolean_expression1:\n\nsuite1\n\nelif boolean_expression2:\n\nsuite2\n\n... elif boolean_expressionN:\n\nsuiteN\n\nelse:\n\nelse_suite\n\n★In this book, ellipses (…) are used to indicate lines that are not shown.\n\n||\n\n|",
      "content_length": 1930,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 38,
      "content": "Python’s “Beautiful Heart”\n\nThere can be zero or more elif clauses,and the ﬁnal else clause is optional. If we want to account for a particular case,but want to do nothing if it occurs,we can use pass as that branch’s suite.\n\nThe ﬁrst thing that stands out to programmers used to C++ or Java is that there are no parentheses and no braces. The other thing to notice is the colon: This is part of the syntax and is easy to forget at ﬁrst. Colons are used with else, elif, and essentially in any other place where a suite is to follow.\n\nUnlike most other programming languages,Python usesindentationtosignify its block structure. Some programmers don’t like this, especially before they have tried it, and some get quite emotional about the issue. But it takes just a few daysto get used to,and after a few weeks or months,brace-free code seems much nicer and less cluttered to read than code that uses braces.\n\nSince suites are indicated using indentation, the question that naturally aris- es is, “What kind of indentation?” The Python style guidelines recommend four spaces per level of indentation, and only spaces (no tabs). Most modern text editors can be set up to handle this automatically (IDLE’s editor does of course,and so do most other Python-aware editors).Python will work ﬁne with any number of spaces or with tabs or with a mixture of both, providing that the indentation used is consistent. In this book, we follow the ofﬁcial Python guidelines.\n\nHere is a very simple if statement example:\n\nif x:\n\nprint(\"x is nonzero\")\n\nIn thiscase,if the condition (x)evaluatesto True,the suite (the print() function call) will be executed.\n\nif lines < 1000:\n\nprint(\"small\")\n\nelif lines < 10000: print(\"medium\")\n\nelse:\n\nprint(\"large\")\n\nThisisa slightly more elaborate if statement that printsa word that describes the value of the lines variable.\n\nThe while Statement\n\nThe while statement is used to execute a suite zero or more times, the number of times depending on the state of the while loop’s Boolean expression. Here’s the syntax:\n\n27\n\n|",
      "content_length": 2046,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 39,
      "content": "28\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nwhile boolean_expression:\n\nsuite\n\nActually,the while loop’s full syntax is more sophisticated than this,since both break and continue are supported,and also an optional else clause that we will discuss in Chapter 4. The break statement switches control to the statement following the innermost loop in which the break statement appears—that is, it breaks out of the loop. The continue statement switches control to the start of the loop. Both break and continue are normally used inside if statementsto conditionally change a loop’s behavior.\n\nwhile True:\n\nitem = get_next_item() if not item: break\n\nprocess_item(item)\n\nThis while loop has a very typical structure and runs as long as there are items to process. (Both get_next_item() and process_item() are assumed to be custom functions deﬁned elsewhere.) In this example, the while statement’s suite contains an if statement, which itself has a suite—as it must—in this case consisting of a single break statement.\n\nThe for … in Statement\n\nPython’s for loop reuses the in keyword (which in other contexts is the mem- bership operator), and has the following syntax:\n\nfor variable in iterable:\n\nsuite\n\nJust like the while loop, the for loop supports both break and continue, and also has an optional else clause. The variable is set to refer to each object in the iterable in turn. An iterable is any data type that can be iterated over, and includes strings (where the iteration is character by character), lists, tuples, and Python’s other collection data types.\n\nfor country in [\"Denmark\", \"Finland\", \"Norway\", \"Sweden\"]:\n\nprint(country)\n\nHere we take a very simplistic approach to printing a list of countries. In practice it is much more common to use a variable:\n\ncountries = [\"Denmark\", \"Finland\", \"Norway\", \"Sweden\"] for country in countries:\n\nprint(country)\n\n|",
      "content_length": 1882,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 40,
      "content": "Python’s “Beautiful Heart”\n\nIn fact, an entire list (or tuple) can be printed using the print() function directly, for example, print(countries), but we often prefer to print collections using a for loop (or a list comprehension,covered later), to achieve full control over the formatting.\n\nfor letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n\nif letter in \"AEIOU\":\n\nprint(letter, \"is a vowel\")\n\nelse:\n\nprint(letter, \"is a consonant\")\n\nIn this snippet the ﬁrst use of the in keyword is part of a for statement, with the variable letter taking on the values \"A\", \"B\", and so on up to \"Z\", changing at each iteration of the loop. On the snippet’s second line we use in again, but this time as the membership testing operator. Notice also that this example shows nested suites. The for loop’s suite is the if … else statement, and both the if and the else branches have their own suites.\n\nBasic Exception Handling\n\nMany of Python’s functions and methods indicate errors or other important eventsby raising an exception. An exceptionisan object like any other Python object, and when converted to a string (e.g., when printed), the exception produces a message text. A simple form of the syntax for exception handlers is this:\n\ntry:\n\ntry_suite\n\nexcept exception1 as variable1:\n\nexception_suite1\n\n… except exceptionN as variableN:\n\nexception_suiteN\n\nNote that the as variable part is optional; we may care only that a particular exception was raised and not be interested in its message text.\n\nThe full syntax is more sophisticated; for example, each except clause can handle multiple exceptions, and there is an optional else clause. All of this is covered in Chapter 4.\n\nThe logic works like this. If the statements in the try block’s suite all execute without raising an exception, the except blocks are skipped. If an exception is raised inside the try block, control is immediately passed to the suite corre- sponding to the ﬁrst matching exception—this means that any statements in the suite that follow the one that caused the exception will not be executed. If\n\n29\n\n|\n\nList compre- hen- sions ➤ 118",
      "content_length": 2093,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 41,
      "content": "30\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nthis occurs and if the as variable part is given, then inside the exception-han- dling suite, variable refers to the exception object.\n\nIf an exception occurs in the handling except block, or if an exception is raised that does not match any of the except blocks in the ﬁrst place,Python looks for a matching except block in the next enclosing scope. The search for a suitable outward in scope and up the call stack until either exception handler works a match is found and the exception is handled, or no match is found, in which case the program terminates with an unhandled exception. In the case of an unhandled exception, Python prints a traceback as well as the exception’s message text.\n\nHere is an example:\n\ns = input(\"enter an integer: \") try:\n\ni = int(s) print(\"valid integer entered:\", i)\n\nexcept ValueError as err:\n\nprint(err)\n\nIf the user enters “3.5”, the output will be:\n\ninvalid literal for int() with base 10: '3.5'\n\nBut if they were to enter “13”, the output will be:\n\nvalid integer entered: 13\n\nMany books consider exception-handling to be an advanced topic and defer it aslateaspossible. Butraisingandespeciallyhandlingexceptionsisfundamen- tal to the way Python works, so we make use of it from the beginning. And as we shall see, using exception handlers can make code much more readable, by separating the “exceptional” cases from the processing we are really interest- ed in.\n\nPiece #6: Arithmetic Operators\n\nPython provides a full set of arithmetic operators, including binary operators for thefourbasicmathematicaloperations:+ addition,- subtraction,* multipli- cation, and / division. In addition, many Python data types can be used with augmented assignment operators such as += and *=. The +, -, and * operators all behave as expected when both of their operands are integers:\n\n>>> 5 + 6 11\n\n||\n\nDeal- ing with runtime errors ➤ 415",
      "content_length": 1921,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 42,
      "content": "Python’s “Beautiful Heart”\n\n>>> 3 - 7 -4 >>> 4 * 8 32\n\nNotice that - can be used both as a unary operator (negation) and as a binary operator (subtraction),as is common in most programming languages. Where Python differs from the crowd is when it comes to division:\n\n>>> 12 / 3 4.0 >>> 3 / 2 1.5\n\nThe division operator produces a ﬂoating-point value, not an integer; many other languages will produce an integer, truncating any fractional part. If we need an integer result, we can always convert using int() (or use the truncating division operator //, discussed later).\n\n>>> a = 5 >>> a 5 >>> a += 8 >>> a 13\n\nAt ﬁrst sight the preceding statements are unsurprising, particularly to those familiar with C-like languages. In such languages, augmented assignment is shorthand for assigning the results of an operation—for example, a += 8 is es- sentially thesameasa = a + 8.However,therearetwoimportantsubtletieshere, one Python-speciﬁc and one to do with augmented operators in any language.\n\nThe ﬁrst point to remember is that the int data type is immutable—that is, once assigned, an int’s value cannot be changed. So, what actually happens behind the scenes when an augmented assignment operator is used on an immutable object is that the operation is performed,and an object holding the result is created;and then the target object reference isre-bound to refer to the result object rather than the object it referred to before. So, in the preceding case when the statement a += 8 is encountered, Python computes a + 8, stores the result in a new int object, and then rebinds a to refer to this new int. (And if the original object a was referring to has no more object references referring to it, it will be scheduled for garbage collection.) Figure 1.3 illustrates this point.\n\nThe second subtlety is that a operator= b is not quite the same as a = a operator b.The augmented version looksup a’svalue only once,so it ispotentially faster. Also, if a is a complex expression (e.g., a list element with an index position calculation such as items[offset + index]), using the augmented version may\n\n31\n\nNumer- ic opera- tors and func- tions ➤ 55",
      "content_length": 2149,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 44,
      "content": "Python’s “Beautiful Heart”\n\n33\n\ner hand, mutable types can be more convenient to use. Where the distinction matters,we will discuss it—for example,in Chapter 4 when we discuss setting default arguments for custom functions, in Chapter 3 when we discuss lists, sets, and some other data types, and again in Chapter 6 when we show how to create custom data types.\n\nThe right-hand operand for the list += operator must be an iterable; an exception is raised:\n\nif it is not\n\n>>> seeds += 5 Traceback (most recent call last): ... TypeError: 'int' object is not iterable\n\nThe correct way to extend a list is to use an iterable object, such as a list:\n\n>>> seeds += [5] >>> seeds ['sesame', 'sunflower', 'pumpkin', 5]\n\nAnd of course, the iterable object used to extend the list can itself have more than one item:\n\n>>> seeds += [9, 1, 5, \"poppy\"] >>> seeds ['sesame', 'sunflower', 'pumpkin', 5, 9, 1, 5, 'poppy']\n\nAppending aplainstring—forexample,\"durian\"—ratherthanalistcontaining a string, [\"durian\"], leads to a logical but perhaps surprising result:\n\n>>> seeds = [\"sesame\", \"sunflower\", \"pumpkin\"] >>> seeds += \"durian\" >>> seeds ['sesame', 'sunflower', 'pumpkin', 'd', 'u', 'r', 'i', 'a', 'n']\n\nThe list += operator extends the list by appending each item of the iterable it is provided with; and since a string is an iterable, this leads to each character in the string being appended individually. If we use the list append() method, the argument is always added as a single item.\n\nPiece #7: Input/Output\n\n||\n\nTo be able to write genuinely useful programs we must be able to read input—for example, from the user at the console, and from ﬁles—and produce output, either to the console or to ﬁles. We have already made use of Python’s built-in print() function,although we will defer covering it further until Chap-\n\nDeal- ing with runtime errors ➤ 415",
      "content_length": 1852,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 45,
      "content": "Book’s exam- ples 3➤\n\n34\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nter 4. In this subsection we will concentrate on console I/O, and use shell redi- rection for reading and writing ﬁles.\n\nPython provides the built-in input() function to accept input from the user. This function takes an optional string argument (which it prints on the con- sole); it then waits for the user to type in a response and to ﬁnish by pressing Enter (or Return).If the user doesnot type any text but just presses Enter,the in- put() function returns an empty string; otherwise, it returns a string contain- ing what the user typed, without any line terminator.\n\nHere is our ﬁrst complete “useful” program; it draws on many of the previous pieces—the only new thing it shows is the input() function:\n\nprint(\"Type integers, each followed by Enter; or just Enter to finish\")\n\ntotal = 0 count = 0\n\nwhile True:\n\nline = input(\"integer: \") if line: try:\n\nnumber = int(line) except ValueError as err:\n\nprint(err) continue total += number count += 1\n\nelse:\n\nbreak\n\nif count:\n\nprint(\"count =\", count, \"total =\", total, \"mean =\", total / count)\n\nThe program (in ﬁle sum1.py in the book’s examples) has just 17 lines. Here is what a typical run looks like:\n\nexecutable\n\nType integers, each followed by Enter; or just Enter to finish number: 12 number: 7 number: 1x invalid literal for int() with base 10: '1x' number: 15 number: 5 number: count = 4 total = 39 mean = 9.75\n\nAlthough the program is very short, it is fairly robust. If the user enters a string that cannot be converted to an integer, the problem is caught by an",
      "content_length": 1608,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 46,
      "content": "Win- dows ﬁle associa- tion bug 11➤\n\nPython’s “Beautiful Heart”\n\nexception handler that prints a suitable message and switches control to the start of the loop (“continues the loop”).And the last if statement ensures that if the user doesn’t enter any numbers at all, the summary isn’t output, and division by zero is avoided.\n\nFile handling is fully covered in Chapter 7;but right now we can create ﬁles by redirecting the print() functions’ output from the console. For example:\n\nC:\\>test.py > results.txt\n\nwill cause the output of plain print() function calls made in the ﬁctitious test.py program to be written to the ﬁle results.txt. This syntax works in the Windows console (usually) and in Unix consoles. For Windows, we must write C:\\Python31\\python.exe test.py > results.txt if Python 2 is the machine’s de- fault Python version or if the console exhibits the ﬁle association bug; other- wise, assuming Python 3 is in the PATH, python test.py > results.txt should be sufﬁcient, if plain test.py > results.txt doesn’t work. For Unixes we must make the program executable (chmod +x test.py) and then invoke it by typing ./test.py unless the directory it is in happens to be in the PATH, in which case invoking it by typing test.py is sufﬁcient.\n\nReading data can be achieved by redirecting a ﬁle of data as input in an analogous way to redirecting output. However, if we used redirection with sum1.py, the program would fail. This is because the input() function raises an exception if it receives an EOF (end of ﬁle) character. Here is a more robust version (sum2.py) that can accept input from the user typing at the keyboard,or via ﬁle redirection:\n\nprint(\"Type integers, each followed by Enter; or ^D or ^Z to finish\")\n\ntotal = 0 count = 0\n\nwhile True: try:\n\nline = input() if line:\n\nnumber = int(line) total += number count += 1 except ValueError as err:\n\nprint(err) continue except EOFError:\n\nbreak\n\nif count:\n\nprint(\"count =\", count, \"total =\", total, \"mean =\", total / count)\n\n35",
      "content_length": 1994,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 47,
      "content": "36\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nGiven the command line sum2.py < data\\sum2.dat (where the sum2.dat ﬁle con- tains a list of numbers one per line and is in the examples’ data subdirectory), the output to the console is:\n\nType integers, each followed by Enter; or ^D or ^Z to finish count = 37 total = 1839 mean = 49.7027027027\n\nWe have made several small changes to make the program more suitable for use both interactively and using redirection. First, we have changed the termination from being a blank line to the EOF character (Ctrl+D on Unix, Ctrl+Z, Enter on Windows). This makes the program more robust when it comes to handling input ﬁles that contain blank lines. We have stopped printing a prompt for each number since it doesn’t make sense to have one for redirected input. And we have also used a single try block with two exception handlers.\n\nNotice that if an invalid integer is entered (either via the keyboard or due to a “bad” line of data in a redirected input ﬁle), the int() conversion will raise a ValueError exceptionandtheﬂowof controlwillimmediately switchtotherele- vant except block—thismeansthat neither total nor count will be incremented when invalid data is encountered, which is exactly what we want.\n\nWe could just as easily have used two separate exception-handling try blocks instead:\n\nwhile True: try:\n\nline = input() if line: try:\n\nnumber = int(line) except ValueError as err:\n\nprint(err) continue total += number count += 1\n\nexcept EOFError:\n\nbreak\n\nBut we preferred to group the exceptions together at the end to keep the main processing as uncluttered as possible.\n\nPiece #8: Creating and Calling Functions\n\nIt isperfectly possibletowriteprogramsusing thedata typesandcontrolstruc- tures that we have covered in the preceding pieces. However, very often we want to do essentially the same processing repeatedly, but with a small differ- ence, such as a different starting value. Python provides a means of encapsu-\n\n||",
      "content_length": 1985,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 48,
      "content": "Python’s “Beautiful Heart”\n\nlating suites as functions which can be parameterized by the arguments they are passed. Here is the general syntax for creating a function:\n\ndef functionName(arguments):\n\nsuite\n\nThe arguments are optional and multiple argumentsmust be comma-separated. Every Pythonfunctionhasareturnvalue;thisdefaults toNone unlesswereturn fromthefunctionusing thesyntax return value,inwhich casevalue isreturned. The return value can be just one value or a tuple of values. The return value can be ignored by the caller, in which case it is simply thrown away.\n\nNote that def is a statement that works in a similar way to the assignment operator. When def is executed a function object is created and an object reference with the speciﬁed name is created and set to refer to the function object. Since functions are objects, they can be stored in collection data types and passed as arguments to other functions, as we will see in later chapters.\n\nOne frequent need when writing interactive console applications is to obtain an integer from the user. Here is a function that does just that:\n\ndef get_int(msg):\n\nwhile True: try:\n\ni = int(input(msg)) return i\n\nexcept ValueError as err:\n\nprint(err)\n\nThisfunction takesone argument,msg.Insidethe while loop the user isprompt- ed to enter an integer. If they enter something invalid a ValueError exception will be raised,the error message will be printed,and the loop will repeat. Once a valid integer is entered, it is returned to the caller. Here is how we would call it:\n\nage = get_int(\"enter your age: \")\n\nIn this example the single argument is mandatory because we have provided no default value. In fact, Python supports a very sophisticated and ﬂexible syntax for function parameters that supports default argument values and positional and keyword arguments. All of the syntax is covered in Chapter 4.\n\nAlthough creating our own functions can be very satisfying, in many cases it is not necessary. This is because Python has a lot of functions built in, and a great many more functions in the modules in its standard library, so what we want may well already be available.\n\n37\n\nreturn state- ment ➤ 173",
      "content_length": 2168,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 49,
      "content": "Dot (.) operator 21➤\n\nshebang (#!) line 12➤\n\n38\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nA Python module is just a .py ﬁle that contains Python code, such as custom function and class (custom data type) deﬁnitions,and sometimesvariables. To access the functionality in a module we must import it. For example:\n\nimport sys\n\nTo import a module we use the import statement followed by the name of the .py ﬁle, but omitting the extension.★ Once a module has been imported,we can access any functions, classes, or variables that it contains. For example:\n\nprint(sys.argv)\n\nThe sys module provides the argv variable—a list whose ﬁrst item is the name under which the program was invoked and whose second and subsequent items are the program’scommand-line arguments. The two previously quoted lines constitute the entire echoargs.py program. If the program is invoked with the command line echoargs.py -v,it will print ['echoargs.py', '-v'] on the console. (On Unix the ﬁrst entry may be './echoargs.py'.)\n\nIn general, the syntax for using a function from a module is moduleName.func- tionName(arguments). It makes use of the dot (“access attribute”) operator we introduced in Piece #3. The standard library contains lots of modules, and we will make use of many of them throughout the book. The standard modules all have lowercase names, so some programmers use title-case names (e.g., My- Module) for their own modules to keep them distinct.\n\nLet us look at just one example, the random module (in the standard library’s random.py ﬁle), which provides many useful functions:\n\nimport random x = random.randint(1, 6) y = random.choice([\"apple\", \"banana\", \"cherry\", \"durian\"])\n\nAfter these statements have been executed, x will contain an integer between 1 and 6 inclusive, and y will contain one of the strings from the list passed to the random.choice() function.\n\nIt is conventional to put all the import statements at the beginning of .py ﬁles, documentation. (Document- after the shebang line, and after the module’s ing modules is covered in Chapter 5.) We recommend importing standard li- brary modules ﬁrst, then third-party library modules, and ﬁnally your own modules.\n\n★The sys module, some other built-in modules, and modules implemented in C don’t necessarily have corresponding .py ﬁles—but they are used in just the same way as those that do.",
      "content_length": 2366,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 50,
      "content": "Examples\n\nExamples\n\nIn the preceding section we learned enough Python to write real programs. In this section we will study two complete programs that use only the Python covered earlier. This is both to show what is possible, and to help consolidate what has been learned so far.\n\nIn subsequent chapters we will increasingly cover more of Python’s language and library,so that we will be able to write programsthat are more concise and more robust than those shown here—but ﬁrst we must have the foundations on which to build.\n\nbigdigits.py\n\nThe ﬁrst program we will review is quite short, although it has some subtle aspects, including a list of lists. Here is what it does: Given a number on the command line, the program outputs the same number onto the console using “big” digits.\n\nAt sites where lots of users share a high-speed line printer, it used to be common practice for each user’s print job to be preceded by a cover page that showed their username and some other identifying details printed using this kind of technique.\n\nWe will review the code in three parts: the import, the creation of the lists holding the data the program uses, and the processing itself. But ﬁrst, let’s look at a sample run:\n\nbigdigits.py 41072819 * * *** ***** *** *** * **** ** ** * * * * * * * ** * * * * * * * * * * * * * * * * * * * * * * *** * **** ****** * * * * * * * * * * * * * * * * * * * * *** *** * ***** *** *** *\n\nWe have not shown the console prompt (or the leading ./ for Unix users); we will take them for granted from now on.\n\nimport sys\n\nSince we must read in an argument from the command line (the number to output), we need to access the sys.argv list, so we begin by importing the sys module.\n\nWe represent each number as a list of strings. For example, here is zero:\n\n39\n\n|||\n\n||",
      "content_length": 1793,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 51,
      "content": "40\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nZero = [\" *** \", * \", \" * *\", \"* *\", \"* *\", \"* \" * * \", \" *** \"]\n\nOne detail to note is that the Zero list of strings is spread over multiple lines. Python statements normally occupy a single line, but they can span multiple lines if they are a parenthesized expression, a list, set, or dictionary literal, a function call argument list, or a multiline statement where every end-of-line character except the last is escaped by preceding it with a backslash (\\). In all these cases any number of lines can be spanned and indentation does not matter for the second and subsequent lines.\n\nEach list representing a number has seven strings, all of uniform width, although what this width is differs from number to number. The lists for the other numbers follow the same pattern as for zero, although they are laid out for compactness rather than for clarity:\n\nOne = [\" * \", \"** \", \" * \", \" * \", \" * \", \" * \", \"***\"] Two = [\" *** \", \"* # ... Nine = [\" ****\", \"*\n\n\", \"* * \", \" * \", \" *\n\n\", \"*\n\n\", \"*\n\n\", \" ****\", \"\n\n\", \"\n\n\", \"*****\"]\n\n\", \"\n\n\"]\n\nThe last piece of data we need is a list of all the lists of digits:\n\nDigits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]\n\nWe could have created the Digits lists directly, and avoided creating the extra variables. For example:\n\nDigits = [\n\n[\" *** \", \" *\n\n\", \"*\n\n\", \"*\n\n\", \"*\n\n\",\n\n\" *\n\n\", \" *** \"], # Zero\n\n[\" * \", \"** \", \" * \", \" * \", \" * \", \" * \", \"***\"], # One # ... [\" ****\", \"* *\", \"* *\", \" ****\", \" *\", \" *\", \" *\"] # Nine ]\n\nWe preferred to use a separate variable for each number both for ease of understanding and because it looks neater using the variables.\n\nWe will quote the rest of the code in one go so that you can try to ﬁgure out how it works before reading the explanation that follows.\n\nset type ➤ 121\n\ndict type ➤ 126",
      "content_length": 1853,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 52,
      "content": "Examples\n\ntry:\n\ndigits = sys.argv[1] row = 0 while row < 7:\n\nline = \"\" column = 0 while column < len(digits):\n\nnumber = int(digits[column]) digit = Digits[number] line += digit[row] + \" \" column += 1\n\nprint(line) row += 1\n\nexcept IndexError:\n\nprint(\"usage: bigdigits.py <number>\")\n\nexcept ValueError as err:\n\nprint(err, \"in\", digits)\n\nThe whole code is wrapped in an exception handler that can catch the two things that can go wrong. We begin by retrieving the program’scommand-line argument. The sys.argv list is 0-based like all Python lists; the item at index position 0 is the name the program was invoked as, so in a running program this list always starts out with at least one item. If no argument was given we will be trying to access the second item in a one-item list and this will cause an IndexError exception to be raised. If this occurs,the ﬂow of control is imme- diately switched to the corresponding exception-handling block, and there we simply print the program’s usage. Execution then continues after the end of the try block; but there is no more code, so the program simply terminates.\n\nIf no IndexError occurs, the digits string holds the command-line argument, which wehopeisa sequenceof digit characters. (RememberfromPiece#2that identiﬁersarecase-sensitive,so digits and Digits aredifferent.) Each big digit is represented by seven strings, and to output the number correctly we must output the top row of every digit, then the next row, and so on, until all seven rows have been output. We use a while loop to iterate over each row. We could just as easily have done this instead: for row in (0, 1, 2, 3, 4, 5, 6): and later on we will see a much better way using the built-in range() function.\n\nWe usethe line string tohold therowstringsfromall thedigitsinvolved. Then we loop by column, that is, by each successive character in the command-line argument. We retrieve each character with digits[column] and convert the digit to an integer called number. If the conversion fails a ValueError exception is raised and the ﬂow of control immediately switches to the corresponding exception handler. In thiscase we print an error message,and controlresumes after the try block. As noted earlier, since there is no more code at this point, the program will simply terminate.\n\n41\n\nrange() ➤ 141",
      "content_length": 2315,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 53,
      "content": "random. rand- int() 38➤\n\n42\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nIf the conversion succeeds, we use number as an index into the Digits list, from which we extract the digit list of strings. We then add the row-th string from this list to the line we are building up,and also append two spacesto give some horizontal separation between each digit.\n\nEach time the inner while loop ﬁnishes, we print the line that has been built up. The key to understanding this program is where we append each digit’s row string to the current row’s line. Try running the program to get a feel for how it works. We will return to this program in the exercises to improve its output slightly.\n\ngenerate_grid.py\n\nOnefrequently occurring need isthegenerationof test data. Thereisnosingle generic program for doing this, since test data varies enormously. Python is often used to producetest data because it isso easy to writeand modify Python programs. In this subsection we will create a program that generates a grid of random integers; the user can specify how many rows and columns they want and over what range the integers should span. We’ll start by looking at a sample run:\n\ngenerate_grid.py rows: 4x invalid literal for int() with base 10: '4x' rows: 4 columns: 7 minimum (or Enter for 0): -100 maximum (or Enter for 1000): 554 720 550 217 810 649 912 -24 908 742 -65 -74 724 825 711 968 824 505 741 55 723 180 -60 794 173 487 4 -35\n\nThe program worksinteractively,and at the beginning we made a typing error when entering the number of rows. The program responded by printing an error message and then asking us to enter the number of rows again. For the maximum we just pressed Enter to accept the default.\n\nWe will review the code in four parts: the import, the deﬁnition of a get_int() function (a more sophisticated version than the one shown in Piece #8), the user interaction to get the values to use, and the processing itself.\n\nimport random\n\nWe need the random module to give us access to the random.randint()\n\nfunction.\n\n||",
      "content_length": 2043,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 54,
      "content": "Examples\n\ndef get_int(msg, minimum, default):\n\nwhile True: try:\n\nline = input(msg) if not line and default is not None:\n\nreturn default\n\ni = int(line) if i < minimum:\n\nprint(\"must be >=\", minimum)\n\nelse:\n\nreturn i except ValueError as err:\n\nprint(err)\n\nThis function requires three arguments: a message string, a minimum value, and a default value. If the user just pressesEnter there are two possibilities. If default is None, that is, no default value has been given, the ﬂow of control will drop through to the int() line. There the conversion will fail (since '' cannot be converted to an integer), and a ValueError exception will be raised. But if default is not None, then it is returned. Otherwise, the function will attempt to convert the text the user entered into an integer, and if the conversion is successful,it will then check that the integer is at least equal to the minimum that has been speciﬁed.\n\nSo, the function will always return either default (if the user just pressed Enter), or a valid integer that is greater than or equal to the speciﬁed minimum.\n\nrows = get_int(\"rows: \", 1, None) columns = get_int(\"columns: \", 1, None) minimum = get_int(\"minimum (or Enter for 0): \", -1000000, 0)\n\ndefault = 1000 if default < minimum:\n\ndefault = 2 * minimum\n\nmaximum = get_int(\"maximum (or Enter for \" + str(default) + \"): \",\n\nminimum, default)\n\nOur get_int() function makes it easy to obtain the number of rows and columns and the minimum random value that the user wants. For rows and columns we give a default value of None, meaning no default, so the user must enter an integer. In the case of the minimum, we supply a default value of 0, and for the maximum we give a default value of 1000, or twice the minimum if the minimum is greater than or equal to 1000.\n\nAs we noted in the previous example, function call argument lists can span any number of lines, and indentation is irrelevant for their second and subse- quent lines.\n\n43",
      "content_length": 1951,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 55,
      "content": "44\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nOnce we know how many rows and columns the user requires and the mini- mum and maximum values of the random numbersthey want,we are ready to do the processing.\n\nrow = 0 while row < rows: line = \"\" column = 0 while column < columns:\n\ni = random.randint(minimum, maximum) s = str(i) while len(s) < 10: s = \" \" + s\n\nline += s column += 1\n\nprint(line) row += 1\n\nTo generate the grid we use three while loops, the outer one working by rows, the middle one by columns, and the inner one by characters. In the middle loop we obtain a random number in the speciﬁed range and then convert it to a string. The inner while loop is used to pad the string with leading spaces so that each number is represented by a string 10 characters wide. We use the line string to accumulate the numbers for each row, and print the line after each column’s numbers have been added. This completes our second example.\n\nPython provides very sophisticated string formatting functionality, as well as excellent support for for … in loops, so more realistic versions of both bigdigits.py and generate_grid.py would have used for … in loops, and gener- ate_grid.py would have used Python’s string formatting capabilities rather than crudely padding with spaces. But we have limited ourselves to the eight pieces of Python introduced in this chapter, and they are quite sufﬁcient for writing complete and useful programs. In each subsequent chapter we will learn new Python features, so as we progress through the book the programs we will see and be capable of writing will grow in sophistication.\n\nSummary\n\nIn this chapter we learned how to edit and run Python programsand reviewed a few small but complete programs. But most of the chapter’s pages were devoted to the eight pieces of Python’s “beautiful heart”—enough of Python to write real programs.\n\nWe began with two of Python’smost basic data types,int and str.Integer liter- als are written just as they are in most other programming languages. String\n\n|||\n\nstr. format() ➤ 78",
      "content_length": 2064,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 56,
      "content": "Summary\n\nliterals are written using single or double quotes; it doesn’t matter which as long as the same kind of quote is used at both ends. We can convert between strings and integers, for example, int(\"250\") and str(125). If an integer con- version fails a ValueError exception is raised; whereas almost anything can be converted to a string.\n\nStrings are sequences,so those functions and operations that can be used with sequences can be used with strings. For example, we can access a particular character using the item access operator ([]), concatenate strings using +, and append one string to another using +=. Since strings are immutable, behind the scenes, appending creates a new string that is the concatenation of the given strings,and rebindsthe left-hand string object reference to the resultant string. Wecanalsoiterateovera string characterby characterusing a for …in loop. And we can use the built-in len() function to report how many characters are in a string.\n\nFor immutable objects like strings, integers, and tuples, we can write our code as though an object reference is a variable, that is, as though an object refer- ence is the object it refers to. We can also do this for mutable objects,although any change made to a mutable object will affect all occurrences of the object (i.e., all object references to the object); we will cover this issue in Chapter 3.\n\nPythonprovidesseveralbuilt-incollectiondatatypesandhassomeothersinits standard library. We learned about the list and tuple types,and in particular howtocreatetuplesandlistsfromliterals,for example,even = [2, 4, 6, 8].Lists, like everything else in Python,are objects,so we can call methodson them—for example, even.append(10) will add an extra item to the list. Like strings, lists and tuples are sequences, so we can iterate over them item by item using a for …in loop, and ﬁnd out how many items they have using len().We can also retrieve a particular item in a list or tuple using the item access operator ([]), concatenate two lists or tuples using +, and append one to another using +=. If we want to append a single item to a list we must either use list.append() or use += with the item made into a single-item list—for example, even += [12]. Since lists are mutable, we can use [] to change individual items, for example, even[1] = 16.\n\nThe fast is and is not identity operators can be used to check whether two ob- ject references refer to the same thing—this is particularly useful when check- ing against the unique built-in None object. All the usual comparison operators are available (<, <=, ==, !=, >=, >),but they can be used only with compatible data types, and then only if the operations are supported. The data types we have seen so far—int, str, list, and tuple—all support the complete set of compar- ison operators. Comparing incompatible types,for example, comparing an int with a str or list, will quite sensibly produce a TypeError exception.\n\nPython supports the standard logical operators and, or, and not. Both and and or are short-circuit operators that return the operand that determined their\n\n45",
      "content_length": 3117,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 57,
      "content": "46\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nresult—and this may not be a Boolean (although it can be converted to a Boolean); not always returns either True or False.\n\nWe can test for membership of sequence types, including strings, lists, and tu- ples, using the in and not in operators. Membership testing uses a slow linear search on lists and tuples, and a potentially much faster hybrid algorithm for strings, but performance is rarely an issue except for very long strings, lists, and tuples. In Chapter 3 we will learn about Python’s associative array and set collection data types, both of which provide very fast membership testing. It is also possible to ﬁnd out an object variable’stype (i.e.,the type of object the object referencerefersto)using type()—but thisfunction isnormally used only for debugging and testing.\n\nPython provides several control structures, including conditional branching with if … elif … else, conditional looping with while, looping over sequences with for … in, and exception-handling with try … except blocks. Both while and for … in loops can be prematurely terminated using a break statement, and both can switch control to the beginning using continue.\n\nThe usual arithmetic operatorsare supported,including +, -, *,and /,although Python isunusual in that / alwaysproducesa ﬂoating-point result even if both its operandsare integers. (The truncating division that many other languages use is also available in Python as //.) Python also provides augmented assign- ment operators such as += and *=; these create new objects and rebind behind the scenes if their left-hand operand is immutable. The arithmetic operators are overloaded by the str and list types as we noted earlier.\n\nConsole I/O can be achieved using input() and print(); and using ﬁle redi- rection in the console, we can use these same built-in functions to read and write ﬁles.\n\nIn addition to Python’s rich built-in functionality, its extensive standard library isalso available,with modulesaccessibleonce they have been imported using the import statement. One commonly imported module is sys, which holds the sys.argv list of command-line arguments. And when Python doesn’t have the function we need we can easily create one that does what we want using the def statement.\n\nBy making use of the functionality described in this chapter it is possible to write short but useful Python programs. In the following chapter we will learn more about Python’s data types, going into more depth for ints and strs and introducing some entirely new data types. In Chapter 3 we will learn more about tuples and lists, and also about some of Python’s other collection data types. Then, in Chapter 4 we will cover Python’s control structures in much more detail, and will learn how to create our own functions so that we can package up functionality to avoid code duplication and promote code reuse.",
      "content_length": 2914,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 58,
      "content": "Book’s exam- ples 3➤\n\nExercises\n\nExercises\n\nThepurposeof theexerciseshere,andthroughoutthebook,isto encourageyou to experiment with Python, and to get hands-on experience to help you absorb each chapter’s material. The examples and exercises cover both numeric and text processing to appeal to as wide an audience as possible, and they are kept fairly small so that the emphasis is on thinking and learning rather than just typing code. Every exercise has a solution provided with the book’s examples.\n\n1. One nice variation of the bigdigits.py program is where instead of printing *s, the relevant digit is printed instead. For example:\n\nbigdigits_ans.py 719428306 77777 1 9999 4 222 888 333 000 666 7 11 9 9 44 2 2 8 8 3 3 0 0 6 7 1 9 9 4 4 2 2 8 8 3 0 0 6 7 1 9999 4 4 2 888 33 0 0 6666 7 1 9 444444 2 8 8 3 0 0 6 6 7 1 9 4 2 8 8 3 3 0 0 6 6 7 111 9 4 22222 888 333 000 666\n\nTwo approaches can be taken. The easiest is to simply change the *s in the lists. But this isn’t very versatile and is not the approach you should take. Instead,change the processing code so that rather than adding each digit’s row string to the line in one go, you add character by character,and whenever a * is encountered you use the relevant digit.\n\nThis can be done by copying bigdigits.py and changing about ﬁve lines. It isn’t hard, but it is slightly subtle. A solution is provided as bigdig- its_ans.py.\n\n2. IDLE can be used as a very powerful and ﬂexible calculator, but some- times it is useful to have a task-speciﬁc calculator. Create a program that prompts the user to enter a number in a while loop, gradually building up a list of the numbers entered. When the user has ﬁnished (by simply pressing Enter),print out the numbersthey entered,the count of numbers, the sum of the numbers,the lowest and highest numbers entered,and the mean of the numbers (sum / count).Here is a sample run: average1_ans.py enter a number or Enter to finish: 5 enter a number or Enter to finish: 4 enter a number or Enter to finish: 1 enter a number or Enter to finish: 8 enter a number or Enter to finish: 5 enter a number or Enter to finish: 2 enter a number or Enter to finish:\n\n47\n\n|||",
      "content_length": 2162,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 59,
      "content": "48\n\nChapter 1. Rapid Introduction to Procedural Programming\n\nnumbers: [5, 4, 1, 8, 5, 2] count = 6 sum = 25 lowest = 1 highest = 8 mean = 4.16666666667\n\nIt will take about four lines to initialize the necessary variables (an empty list is simply []), and less than 15 lines for the while loop, including basic error handling. Printing out at the end can be done in just a few lines, so the whole program,including blank lines for the sake of clarity, should be about 25 lines.\n\n3. In some situationswe need to generate test text—for example,to populate a web site design before the real content is available, or to provide test content whendeveloping a reportwriter. Tothisend,writea programthat generates awful poems (the kind that would make a Vogon blush). Create some lists of words, for example, articles (“the”, “a”, etc.), subjects (“cat”,“dog”,“man”,“woman”), verbs(“sang”,“ran”,“jumped”),andadverbs (“loudly”, “quietly”, “well”, “badly”). Then loop ﬁve times, and on each it- eration use the random.choice() function to pick an article, subject, verb, and adverb. Use random.randint() to choose between two sentence struc- tures: article, subject, verb, and adverb, or just article, subject, and verb, and print the sentence. Here is an example run:\n\n3. In some situationswe need to generate test text—for example,to populate a web site design before the real content is available, or to provide test content whendeveloping a reportwriter. Tothisend,writea programthat generates awful poems (the kind that would make a Vogon blush). Create some lists of words, for example, articles (“the”, “a”, etc.), subjects (“cat”,“dog”,“man”,“woman”), verbs(“sang”,“ran”,“jumped”),andadverbs (“loudly”, “quietly”, “well”, “badly”). Then loop ﬁve times, and on each it- eration use the random.choice() function to pick an article, subject, verb, and adverb. Use random.randint() to choose between two sentence struc- tures: article, subject, verb, and adverb, or just article, subject, and verb, and print the sentence. Here is an example run:\n\nawfulpoetry1_ans.py another boy laughed badly the woman jumped a boy hoped a horse jumped another man laughed rudely\n\nYou will need to import the random module. The lists can be done in about 4–10 lines depending on how many words you put in them, and the loop itself requires less than ten lines, so with some blank lines the whole program can be done in about 20 lines of code. A solution is provided as awfulpoetry1_ans.py.\n\n4. To make the awful poetry program more versatile, add some code to it so that if the user enters a number on the command line (between 1 and 10 inclusive), the program will output that many lines. If no command-line argument is given, default to printing ﬁve lines as before. You’ll need to change the main loop (e.g., to a while loop). Keep in mind that Python’s comparison operators can be chained, so there’s no need to use logical and whenchecking thattheargumentisinrange. Theadditionalfunctionality can be done by adding about ten lines of code. A solution is provided as awfulpoetry2_ans.py.\n\n5. It would be nice to be able to calculate the median (middle value) as well as the mean for the averagesprogram in Exercise 2,but to do thiswe must sort the list. In Python a list can easily be sorted using the list.sort()",
      "content_length": 3296,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 60,
      "content": "Exercises\n\nmethod, but we haven’t covered that yet, so we won’t use it here. Ex- tend the averages program with a block of code that sorts the list of numbers—efﬁciency is of no concern, just use the easiest approach you can think of. Once the list is sorted, the median is the middle value if the list has an odd number of items, or the average of the two middle values if the list has an even number of items. Calculate the median and output that along with the other information.\n\nThis is rather tricky, especially for inexperienced programmers. If you have somePython experience,you might stillﬁnd it challenging,at least if you keep to the constraint of using only the Python we have covered so far. The sorting can be done in about a dozen lines and the median calculation (whereyoucan’tusethemodulusoperator,sinceit hasn’tbeencoveredyet) in four lines. A solution is provided in average2_ans.py.\n\n49",
      "content_length": 906,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 61,
      "content": "Object refer- ences 16➤\n\n2\n\nIdentiﬁers and Keywords ● Integral Types ● Floating-Point Types ● Strings\n\nData Types\n\nIn this chapter we begin to take a much more detailed look at the Python lan- guage. We start with a discussion of the rules governing the names we give to object references, and provide a list of Python’s keywords. Then we look at all of Python’smost important data types—excluding collection data types,which are covered in Chapter 3. The data types considered are all built-in, except for one which comesfrom the standard library. The only difference between built- in data types and library data types is that in the latter case,we must ﬁrst im- port the relevant module and we must qualify the data type’s name with the name of the module it comes from—Chapter 5 covers importing in depth.\n\nIdentiﬁers and Keywords\n\nWhen we create a data item we can either assign it to a variable, or insert it we assign in into a collection. (As we noted in the preceding chapter, when Python, what really happens is that we bind an object reference to refer to the object in memory that holds the data.) The names we give to our object references are called identiﬁers or just plain names.\n\nA valid Python identiﬁer is a nonempty sequence of characters of any length that consistsof a “start character” and zero or more “continuation characters”. Such an identiﬁer must obey a couple of rules and ought to follow certain con- ventions.\n\nThe ﬁrst rule concerns the start and continuation characters. The start char- acter can beanything thatUnicodeconsiderstobea letter,including theASCII letters (“a”, “b”, …, “z”, “A”, “B”, …, “Z”), the underscore (“_”), as well as the let- ters from most non-English languages. Each continuation character can be any character that is permitted as a start character, or pretty well any non- whitespace character, including any character that Unicode considers to be a digit,such as (“0”,“1”,…,“9”),or the Catalan character “·”.Identiﬁersare case-\n\n51\n\n||||\n\n|||",
      "content_length": 2003,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 62,
      "content": "52\n\nChapter 2. Data Types\n\nsensitive,so for example, TAXRATE, Taxrate, TaxRate, taxRate, and taxrate are ﬁve different identiﬁers.\n\nThe precise set of characters that are permitted for the start and continuation are describedin thedocumentation(Python language reference,Lexical analy- sis,Identiﬁersandkeywordssection),andinPEP 3131(Supporting Non-ASCII Identiﬁers).★\n\nThe second rule isthat no identiﬁer can have the same nameasone of Python’s keywords, so we cannot use any of the names shown in Table 2.1.\n\nTable 2.1 Python’s Keywords\n\nand\n\ncontinue\n\nexcept\n\nglobal\n\nlambda\n\npass\n\nwhile\n\nas\n\ndef\n\nFalse\n\nif\n\nNone\n\nraise\n\nwith\n\nassert\n\ndel\n\nfinally\n\nimport\n\nnonlocal\n\nreturn\n\nyield\n\nbreak\n\nelif\n\nfor\n\nin\n\nnot\n\nTrue\n\nclass\n\nelse\n\nfrom\n\nis\n\nor\n\ntry\n\nWe already met most of these keywords in the preceding chapter, although 11 of them—assert, class, del, finally, from, global, lambda, nonlocal, raise, with, and yield—have yet to be discussed.\n\nThe ﬁrst conventionis:Don’t use thenamesof any of Python’spredeﬁnediden- tiﬁers for your own identiﬁers. So, avoid using NotImplemented and Ellipsis, and the name of any of Python’s built-in data types (such as int, float, list, str, and tuple), and any of Python’s built-in functions or exceptions. How can we tell whether an identiﬁer falls into one of these categories? Python has a built-in function called dir() that returnsa list of an object’sattributes. If it is called with no argumentsit returnsthe list of Python’sbuilt-in attributes. For example:\n\n>>> dir() # Python 3.1's list has an extra item, '__package__' ['__builtins__', '__doc__', '__name__']\n\nThe __builtins__ attribute is, in effect, a module that holds all of Python’s built-in attributes. We can use it as an argument to the dir() function:\n\n>>> dir(__builtins__) ['ArithmeticError', 'AssertionError', 'AttributeError', ... 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n\n★A “PEP” is a Python Enhancement Proposal. If someone wants to change or extend Python, providingthey get enoughsupportfromthePythoncommunity,they submita PEP withthedetails of their proposal so that it can be formally considered, and in some cases such as with PEP 3131, accepted and implemented. All the PEPs are accessible from www.python.org/dev/peps/.",
      "content_length": 2249,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 63,
      "content": "import 38➤\n\nIdentiﬁers and Keywords\n\nThere are about 130 namesin the list,so we have omitted most of them. Those that begin with a capital letter are the names of Python’s built-in exceptions; the rest are function and data type names.\n\nThe second convention concerns the use of underscores (_). Names that begin and end with two underscores (such as __lt__) should not be used. Python deﬁnes various special methods and variables that use such names (and in the case of special methods, we can reimplement them, that is, make our own ver- sions of them), but we should not introduce new names of this kind ourselves. We will cover such namesin Chapter 6.Namesthat begin with one or two lead- ing underscores(andthat don’tendwith twounderscores)aretreatedspecially in some contexts. We will show when to use names with a single leading un- derscore in Chapter 5, and when to use those with two leading underscores in Chapter 6.\n\nA single underscore on its own can be used as an identiﬁer, and inside an interactiveinterpreteror Python Shell,_ holdstheresult of thelast expression that was evaluated. In a normal running program no _ exists,unless we use it explicitly in our code. Some programmers like to use _ in for … in loops when they don’t care about the items being looped over. For example:\n\nfor _ in (0, 1, 2, 3, 4, 5):\n\nprint(\"Hello\")\n\nBe aware, however, that those who write programs that are international- ized often use _ as the name of their translation function. They do this so that instead of writing gettext.gettext(\"Translate me\"), they can write _(\"Translate me\"). (For this code to work we must have ﬁrst imported the get- text module so that we can access the module’s gettext() function.)\n\nLet’s look at some valid identiﬁers in a snippet of code written by a Spanish- speaking programmer. The code assumes we have done import math and that the variables radio and vieja_área have been created earlier in the program:\n\nπ = math.pi ε = 0.0000001 nueva_área = π * radio * radio if abs(nueva_área - vieja_área) < ε: print(\"las áreas han convergido\")\n\nWe’ve used the math module, set epsilon (ε) to be a very small ﬂoating-point number, and used the abs() function to get the absolute value of the difference between the areas—we cover all of these later in this chapter. What we are concerned with here is that we are free to use accented characters and Greek letters for identiﬁers. We could just as easily create identiﬁers using Arabic, Chinese,Hebrew,Japanese,and Russian characters,or indeed charactersfrom any other language supported by the Unicode character set.\n\n53\n\nimport ➤ 196",
      "content_length": 2609,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 64,
      "content": "54\n\nChapter 2. Data Types\n\nThe easiest way to check whether something is a valid identiﬁer is to try to assign to it in an interactive Python interpreter or in IDLE’s Python Shell window. Here are some examples:\n\n>>> stretch-factor = 1 SyntaxError: can't assign to operator (...) >>> 2miles = 2 SyntaxError: invalid syntax (...) >>> str = 3 # Legal but BAD >>> l'impôt31 = 4 SyntaxError: EOL while scanning single-quoted string (...) >>> l_impôt31 = 5 >>>\n\nWhen aninvalididentiﬁerisusedit causesa SyntaxError exceptiontoberaised. In each case the part of the error message that appears in parentheses varies, so we have replaced it with an ellipsis. The ﬁrst assignment fails because “-” is not a Unicode letter, digit, or underscore. The second one fails because the start character is not a Unicode letter or underscore; only continuation characters can be digits. No exception is raised if we create an identiﬁer that is valid—even if the identiﬁer is the name of a built-in data type, exception, or function—so the third assignment works, although it is ill-advised. The fourth fails because a quote is not a Unicode letter, digit, or underscore. The ﬁfth is ﬁne.\n\nIntegral Types\n\n|||\n\nPython provides two built-in integral types, int and bool.★ Both integers and Booleans are immutable, but thanks to Python’s augmented assignment oper- ators this is rarely noticeable. When used in Boolean expressions, 0 and False are False, and any other integer and True are True. When used in numerical expressions True evaluates to 1 and False to 0. This means that we can write somerather odd things—for example,wecan incrementan integer,i,using the expression i += True. Naturally, the correct way to do this is i += 1.\n\nIntegers\n\n||\n\nThe size of an integer is limited only by the machine’s memory, so integers hundreds of digits long can easily be created and worked with—although they will be slower to use than integers that can be represented natively by the machine’s processor.\n\n★The standard library also provides the fractions.Fraction type (unlimited precision rationals) which may be useful in some specialized mathematical and scientiﬁc contexts.\n\nDeal- ing with syntax errors ➤ 414",
      "content_length": 2189,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 65,
      "content": "Tuples 18➤\n\nIntegral Types\n\nTable 2.2 Numeric Operators and Functions\n\nSyntax\n\nDescription\n\nx + y\n\nAdds number x and number y\n\nx - y\n\nSubtracts y from x\n\nx * y\n\nMultiplies x by y\n\nx / y\n\nDivides x by y; always produces a float (or a complex if x or y is complex)\n\nx // y\n\nDivides x by y; truncates any fractional part so always pro- duces an int result; see also the round() function\n\nx % y\n\nProduces the modulus (remainder) of dividing x by y\n\nx ** y\n\nRaises x to the power of y; see also the pow() functions\n\nx\n\nNegates x; changes x’s sign if nonzero, does nothing if zero\n\n+x\n\nDoes nothing; is sometimes used to clarify code\n\nabs(x)\n\nReturns the absolute value of x\n\ndivmod(x, y) Returns the quotient and remainder of dividing\n\nx by y as a\n\ntuple of two ints\n\npow(x, y)\n\nRaises x to the power of y; the same as the ** operator\n\npow(x, y, z) A faster alternative to (x ** y) % z\n\nround(x, n)\n\nReturns x rounded to n integral digits if n is a negative int or returns x rounded to n decimal places if n is a positive int; the returned value has the same type as x; see the text\n\nTable 2.3 Integer Conversion Functions\n\nSyntax\n\nDescription\n\nbin(i)\n\nhex(i)\n\nint(x)\n\nReturns the binary representation of int i as a string, e.g., bin(1980) == '0b11110111100' Returnsthe hexadecimal representation of i as a string,e.g., hex(1980) == '0x7bc' Converts object x to an integer; raises ValueError on failure—or TypeError if x’sdata type doesnot support integer conversion. If x is a ﬂoating-point number it is truncated.\n\nint(s, base) Converts str s to an integer; raises ValueError on failure. If the optional base argument is given it should be an integer between 2 and 36 inclusive. Returns the octal representation of i as a string, e.g., oct(1980) == '0o3674'\n\noct(i)\n\n55\n\nTuples ➤ 108",
      "content_length": 1781,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 66,
      "content": "56\n\nChapter 2. Data Types\n\nInteger literals are written using base 10 (decimal) by default, but other number bases can be used when this is convenient:\n\n>>> 14600926 14600926 >>> 0b110111101100101011011110 14600926 >>> 0o67545336 14600926 >>> 0xDECADE 14600926\n\n# decimal\n\n# binary\n\n# octal\n\n# hexadecimal\n\nBinary numbers are written with a leading 0b, octal numbers with a leading 0o,★ and hexadecimal numbers with a leading 0x. Uppercase letters can also be used.\n\nAll the usual mathematical functions and operators can be used with integers, as Table 2.2 shows. Some of the functionality is provided by built-in functions like abs()—for example, abs(i) returns the absolute value of integer i—and other functionality is provided by int operators—for example,i + j returnsthe sum of integers i and j.\n\nWewillmentionjust oneof thefunctionsfromTable2.2,sincealltheothersare sufﬁciently explained in the table itself. While for floats, the round() function works in the expected way—for example, round(1.246, 2) produces 1.25—for ints, using a positive rounding value has no effect and results in the same number being returned,sincetherearenodecimaldigitstowork on. But when a negativerounding valueisused a subtleand usefulbehavior isachieved—for example, round(13579, -3) produces 14000, and round(34.8, -1) produces 30.0.\n\nAll the binary numeric operators (+, -, /, //, %, and **) have augmented assign- ment versions (+=, -=, /=, //=, %=,and **=) where x op= y is logically equivalent to x = xop y in the normal case when reading x’s value has no side effects.\n\nObjects can be created by assigning literals to variables, for example, x = 17, or by calling the relevant data type as a function, for example, x = int(17). Some objects (e.g., those of type decimal.Decimal) can be created only by using the data type since they have no literal representation. When an object is created using its data type there are three possible use cases.\n\nThe ﬁrst use case is when a data type is called with no arguments. In this case an object with a default value is created—for example, x = int() creates an integer of value 0. All the built-in types can be called with no arguments.\n\nThe second use case is when the data type is called with a single argument. If an argument of the same type is given, a new object which is a shallow copy of\n\n★Usersof C-stylelanguagesnote that a singleleading 0 isnot sufﬁcient to specify an octal number; 0o (zero, letter o) must be used in Python.",
      "content_length": 2476,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 67,
      "content": "Integral Types\n\nthe original object is created. (Shallow copying is covered in Chapter 3.) If an argument of a different type is given, a conversion is attempted. This use is shown for the int type in Table 2.3. If the argument is of a type that supports conversions to the given type and the conversion fails, a ValueError exception is raised; otherwise, the resultant object of the given type is returned. If the argument’sdata type does not support conversion to the given type a TypeError exception is raised. The built-in float and str types both provide integer conversions; it is also possible to provide integer and other conversions for our own custom data types as we will see in Chapter 6.\n\nThe third use case is where two or more arguments are given—not all types support this, and for those that do the argument types and their meanings vary. For the int type two arguments are permitted where the ﬁrst is a string that represents an integer and the second is the number base of the string representation. For example, int(\"A4\", 16) creates an integer of value 164. This use is shown in Table 2.3.\n\nThe bitwise operators are shown in Table 2.4. All the binary bitwise operators (|, ^, &, <<, and >>) have augmented assignment versions (|=, ^=, &=, <<=, and >>=) where i op= j is logically equivalent to i = i op j in the normal case when reading i’s value has no side effects.\n\nFrom Python 3.1, the int.bit_length() method is available. This returns the number of bits required to represent the int it is called on. For example, (2145).bit_length() returns 12. (The parentheses are required if a literal inte- ger is used, but not if we use an integer variable.)\n\nIf many true/falseﬂagsneed tobeheld,onepossibility istousea singleinteger, and to test individual bits using the bitwise operators. The same thing can be achieved less compactly, but more conveniently, using a list of Booleans.\n\nTable 2.4 Integer Bitwise Operators\n\nSyntax Description\n\ni | j\n\nBitwise OR of int i and int j; negative numbers are assumed to be represented using 2’s complement\n\ni ^ j\n\nBitwise XOR (exclusive or) of i and j\n\ni & j\n\nBitwise AND of i and j\n\ni << j Shifts i left by j bits; like i * (2 ** j) without overﬂow checking\n\ni >> j Shifts i right by j bits; like i // (2 ** j) without overﬂow checking\n\n~i\n\nInverts i’s bits\n\n57\n\nCopying collec- tions ➤ 146\n\nType conver- sions ➤ 252\n\n3.1",
      "content_length": 2385,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 68,
      "content": "Logical opera- tors 25➤\n\n58\n\nChapter 2. Data Types\n\nBooleans\n\n||\n\nThere are two built-in Boolean objects: True and False. Like all other Python data types (whether built-in, library, or custom), the bool data type can be called asa function—with no argumentsit returnsFalse,with a bool argument it returns a copy of the argument, and with any other argument it attempts to convert the given object to a bool. All the built-in and standard library data types can be converted to produce a Boolean value, and it is easy to provide Boolean conversions for custom data types. Here are a couple of Boolean assignments and a couple of Boolean expressions:\n\n>>> t = True >>> f = False >>> t and f False >>> t and True True\n\nPython provides three logical operators: and, or, and not. As we noted earlier, Both and and or use short-circuit logic and return the operand that determined the result, whereas not always returns either True or False.\n\nProgrammers who have been using older versions of Python sometimes use 1 and 0 instead of True and False; this almost always works ﬁne, but new code should use the built-in Boolean objects when a Boolean value is required.\n\nFloating-Point Types\n\n|||\n\nPython provides three kinds of ﬂoating-point values: the built-in float and complex types,and the decimal.Decimal typefromthestandardlibrary. Allthree are immutable. Type float holds double-precision ﬂoating-point numbers whose range depends on the C (or C# or Java) compiler Python was built with; they have limited precision and cannot reliably be compared for equality. Numbers of type float are written with a decimal point, or using exponential notation, for example, 0.0, 4., 5.7, -2.5, -2e9, 8.9e-4.\n\nComputers natively represent ﬂoating-point numbers using base 2—this means that some decimals can be represented exactly (such as 0.5), but others only approximately(suchas0.1and0.2).Furthermore,therepresentationuses a ﬁxed number of bits, so there is a limit to the number of digits that can be held. Here is a salutary example typed into IDLE:\n\n>>> 0.0, 5.4, -2.5, 8.9e-4 (0.0, 5.4000000000000004, -2.5, 0.00088999999999999995)\n\n3.0",
      "content_length": 2131,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 69,
      "content": "Floating-Point Types\n\nThe inexactness is not a problem speciﬁc to Python—all programming lan- guages have this problem with ﬂoating-point numbers.\n\nPython 3.1 produces much more sensible-looking output:\n\n>>> 0.0, 5.4, -2.5, 8.9e-4 (0.0, 5.4, -2.5, 0.00089)\n\nWhen Python 3.1 outputs a ﬂoating-point number, in most cases it uses David Gay’s algorithm. This outputs the fewest possible digits without losing any accuracy. Although this produces nicer output, it doesn’t change the fact that computers (no matter what computer language is used) effectively store ﬂoating-point numbers as approximations.\n\nIf we need really high precision there are two approaches we can take. One approach is to use ints—for example, working in terms of pennies or tenths of a penny or similar—and scale the numbers when necessary. This requires us to be quite careful, especially when dividing or taking percentages. The other approach is to use Python’s decimal.Decimal numbers from the decimal module. Theseperformcalculationsthatareaccuratetothelevelof precisionwespecify (by default, to 28 decimal places) and can represent periodic numbers like 0.1 exactly; but processing is a lot slower than with floats. Because of their accu- racy, decimal.Decimal numbers are suitable for ﬁnancial calculations.\n\nMixed mode arithmetic is supported such that using an int and a float pro- duces a float,and using a float and a complex producesa complex.Because dec- imal.Decimals are of ﬁxed precision they can be used only with other decimal. Decimals and with ints, in the latter case producing a decimal.Decimal result. If an operation is attempted using incompatible types, a TypeError exception is raised.\n\nFloating-Point Numbers\n\nAll the numeric operators and functions in Table 2.2 (55 ➤) can be used with floats,including the augmented assignment versions. The float data typecan be called as a function—with no arguments it returns 0.0, with a float argu- ment it returns a copy of the argument, and with any other argument it at- temptstoconvertthegivenobjecttoa float.Whenusedforconversionsa string argument can be given, either using simple decimal notation or using expo- nential notation. It is possible that NaN (“not a number”) or “inﬁnity” may be produced by a calculation involving floats—unfortunately the behavior is not consistent across implementations and may differ depending on the system’s underlying math library.\n\nHere is a simple function for comparing floats for equality to the limit of the machine’s accuracy:\n\n59\n\n||\n\n3.1",
      "content_length": 2527,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 70,
      "content": "Tuples 18➤\n\n60\n\nChapter 2. Data Types\n\nTable 2.5 The Math Module’s Functions and Constants #1\n\nSyntax\n\nDescription\n\nmath.acos(x)\n\nReturns the arc cosine of x in radians\n\nmath.acosh(x)\n\nReturns the arc hyperbolic cosine of x in radians\n\nmath.asin(x)\n\nReturns the arc sine of x in radians\n\nmath.asinh(x)\n\nReturns the arc hyperbolic sine of x in radians\n\nmath.atan(x)\n\nReturns the arc tangent of x in radians\n\nmath.atan2(y, x)\n\nReturns the arc tangent of y / x in radians\n\nmath.atanh(x)\n\nReturns the arc hyperbolic tangent of x in radians\n\nmath.ceil(x)\n\nReturns ⎡x⎤ , i.e., the smallest integer greater than or equal to x as an int; e.g., math.ceil(5.4) == 6\n\nmath.copysign(x,y) Returns x with y’s sign\n\nmath.cos(x)\n\nReturns the cosine of x in radians\n\nmath.cosh(x)\n\nReturns the hyperbolic cosine of x in radians\n\nmath.degrees(r)\n\nConverts float r from radians to degrees\n\nmath.e\n\nmath.exp(x)\n\nmath.fabs(x)\n\nmath.factorial(x)\n\nmath.floor(x)\n\nThe constant e; approximately 2.7182818284590451 Returns ex, i.e., math.e ** x Returns | x |, i.e., the absolute value of x as a float Returns x! Returns ⎣x⎦ ,i.e.,the largest integer less than or equal to x as an int; e.g., math.floor(5.4) == 5\n\nmath.fmod(x, y)\n\nProduces the modulus (remainder) of dividing x by y; this produces better results than % for floats\n\nmath.frexp(x)\n\nmath.fsum(i)\n\nmath.hypot(x, y)\n\nmath.isinf(x)\n\nmath.isnan(x)\n\nReturns a 2-tuple with the mantissa (as a m × 2 ; see math.ldexp() the exponent (as an int) so, x = Returns the sum of the values in iterable i as a float Returns√ 2x + 2y Returns True if float x is ± inf (± ∞) Returns True if float x is nan (“not a number”)\n\nfloat) and\n\ne\n\nmath.ldexp(m, e)\n\nmath.log(x, b)\n\nmath.log10(x)\n\nmath.log1p(x)\n\nmath.modf(x)\n\ne\n\nm × 2 ; effectively the inverse of math.frexp()\n\nReturns Returns logbx; b is optional and defaults to math.e Returns log10x Returns loge Returns x’s fractional and whole parts as two floats\n\n(1+ x); accurate even when x is close to 0\n\nTuples ➤ 108",
      "content_length": 1984,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 71,
      "content": "Floating-Point Types\n\nTable 2.6 The Math Module’s Functions and Constants #2\n\nSyntax\n\nDescription The constant π; approximately 3.1415926535897931 Returns yx as a float math.radians(d) Converts float d from degrees to radians\n\nmath.pi\n\nmath.pow(x, y)\n\nmath.sin(x)\n\nReturns the sine of x in radians\n\nmath.sinh(x)\n\nmath.sqrt(x)\n\nmath.tan(x)\n\nReturns the hyperbolic sine of x in radians Returns√x Returns the tangent of x in radians\n\nmath.tanh(x)\n\nReturns the hyperbolic tangent of x in radians\n\nmath.trunc(x)\n\nReturns the whole part of x as an int; same as int(x)\n\ndef equal_float(a, b):\n\nreturn abs(a - b) <= sys.float_info.epsilon\n\nThis requiresus to import the sys module. The sys.float_info object hasmany attributes;sys.float_info.epsilon iseffectively thesmallestdifferencethatthe machine can distinguish between two ﬂoating-point numbers. On one of the author’s 32-bit machines it is just over 0.0000000000000002. (Epsilon is the traditional name for this number.) Python floats normally provide reliable accuracy for up to 17 signiﬁcant digits.\n\nIf you type sys.float_info into IDLE, all its attributes will be displayed; these include the minimum and maximum ﬂoating-point numbers the machine can represent. And typing help(sys.float_info) will print some information about the sys.float_info object.\n\nFloating-point numbers can be converted to integers using the int() func- tion which returns the whole part and throws away the fractional part, or using round() which accounts for the fractional part, or using math.floor() or math.ceil() which convert down to or up to the nearest integer. The float.is_integer() method returns True if a ﬂoating-point number’s frac- tional part is 0, and a float’s fractional representation can be obtained using the float.as_integer_ratio() method. For example, given x = 2.75, the call x.as_integer_ratio() returns (11, 4). Integers can be converted to ﬂoating- point numbers using float().\n\nFloating-point numbers can also be represented as strings in hexadecimal format using the float.hex() method. Such strings can be converted back to ﬂoating-point numbers using the float.fromhex() method. For example:\n\ns = 14.25.hex()\n\n# str s == '0x1.c800000000000p+3'\n\n61",
      "content_length": 2210,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 72,
      "content": "62\n\nChapter 2. Data Types\n\nf = float.fromhex(s) t = f.hex()\n\n# float f == 14.25 # str t == '0x1.c800000000000p+3'\n\nThe exponent is indicated using p (“power”) rather than e since e is a valid hexadecimal digit.\n\nIn addition to the built-in ﬂoating-point functionality,the math moduleprovides many more functions that operate on floats, as shown in Tables 2.5 and 2.6. Here are some code snippets that show how to make use of the module’s func- tionality:\n\n>>> import math >>> math.pi * (5 ** 2) # Python 3.1 outputs: 78.53981633974483 78.539816339744831 >>> math.hypot(5, 12) 13.0 >>> math.modf(13.732) # Python 3.1 outputs: (0.7319999999999993, 13.0) (0.73199999999999932, 13.0)\n\nThe math.hypot() function calculates the distance from the origin to the point (x, y) and produces the same result as math.sqrt((x ** 2) + (y ** 2)).\n\nThe math moduleisvery dependenton theunderlying mathlibrary thatPython was compiled against. This means that some error conditions and boundary cases may behave differently on different platforms.\n\nComplex Numbers\n\nThe complex data type is an immutable type that holds a pair of floats, one representing the real part and the other the imaginary part of a complex number. Literal complex numbers are written with the real and imaginary partsjoined by a + or - sign,and with the imaginary part followed by a j.★ Here are some examples: 3.5+2j, 0.5j, 4+0j, -1-3.7j. Notice that if the real part is 0, we can omit it entirely.\n\nThe separate parts of a complex are available as attributes real and imag. For example:\n\n>>> z = -89.5+2.125j >>> z.real, z.imag (-89.5, 2.125)\n\nExcept for //, %, divmod(), and the three-argument pow(), all the numeric operators and functions in Table 2.2 (55➤) can be used with complex numbers, and so can the augmented assignment versions. In addition, complex numbers\n\n★Mathematicians use i to signify √ − 1, but Python follows the engineering tradition and uses j.\n\n||\n\n3.x",
      "content_length": 1934,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 73,
      "content": "Floating-Point Types\n\nhave a method, conjugate(), which changes the sign of the imaginary part. For example:\n\n>>> z.conjugate() (-89.5-2.125j) >>> 3-4j.conjugate() (3+4j)\n\nNoticethatherewehavecalleda methodon a literal complex number. In gener- al, Python allows us to call methods or access attributes on any literal, as long as the literal’sdata type providesthe called method or the attribute—however, this does not apply to special methods, since these always have corresponding operatorssuch as + that should be used instead. For example,4j.real produces 0.0, 4j.imag produces 4.0, and 4j + 3+2j produces 3+6j.\n\nThe complex data type can be called as a function—with no arguments it returns 0j, with a complex argument it returns a copy of the argument, and with any other argument it attempts to convert the given object to a complex. When used for conversions complex() accepts either a single string argument, or one or two floats. If just one float is given, the imaginary part is taken to be 0j.\n\nThe functions in the math module do not work with complex numbers. This is a deliberate design decision that ensures that users of the math module get exceptions rather than silently getting complex numbers in some situations.\n\nUsers of complex numbers can import the cmath module, which provides com- plex number versions of most of the trigonometric and logarithmic functions that are in the math module,plus some complex number-speciﬁc functions such as cmath.phase(), cmath.polar(), and cmath.rect(), and also the cmath.pi and cmath.e constants which hold the same float values as their math module coun- terparts.\n\nDecimal Numbers\n\nIn many applications the numerical inaccuracies that can occur when using floats don’t matter, and in any case are far outweighed by the speed of calcu- lation that floats offer. But in some cases we prefer the opposite trade-off,and wantcompleteaccuracy,evenatthecostof speed. The decimal moduleprovides immutable Decimal numbers that are as accurate as we specify. Calculations involving Decimals are slower than those involving floats, but whether this is noticeable will depend on the application.\n\nTo create a Decimal we must import the decimal module. For example:\n\n>>> import decimal >>> a = decimal.Decimal(9876)\n\n63\n\n||",
      "content_length": 2272,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 74,
      "content": "64\n\nChapter 2. Data Types\n\n>>> b = decimal.Decimal(\"54321.012345678987654321\") >>> a + b Decimal('64197.012345678987654321')\n\nDecimal numbers are created using the decimal.Decimal() function. This functioncantakean integeror a string argument—butnot a float,since floats are held inexactly whereas decimals are represented exactly. If a string is used it can use simple decimal notation or exponential notation. In addition to providing accuracy,the exact representation of decimal.Decimals means that they can be reliably compared for equality.\n\nFrom Python 3.1 it is possible to convert floats to decimals using the deci- mal.Decimal.from_float() function. This function takes a float as argument and returnsthe decimal.Decimal that is closest to the number the float approx- imates.\n\nAll the numeric operators and functions listed in Table 2.2 (55 ➤), including the augmented assignment versions, can be used with decimal.Decimals, but with a couple of caveats. If the ** operator has a decimal.Decimal left-hand operand, its right-hand operand must be an integer. Similarly, if the pow() function’s ﬁrst argument is a decimal.Decimal, then its second and optional third arguments must be integers.\n\nThe math and cmath modules are not suitable for use with decimal.Decimals, but some of the functions provided by the math module are provided as deci- mal.Decimal methods. For example, to calculate xe where x is a float, we write math.exp(x), but where x is a decimal.Decimal, we write x.exp(). From the dis- cussion in Piece #3 (20 ➤), we can see that x.exp() is, in effect, syntactic sugar for decimal.Decimal.exp(x).\n\nThe decimal.Decimal data type also provides ln() which calculates the natural (base e)logarithm(just like math.log() with one argument),log10(),and sqrt(), along with many other methods speciﬁc to the decimal.Decimal data type.\n\nNumbers of type decimal.Decimal work within the scope of a context; the context is a collection of settings that affect how decimal.Decimals behave. The context speciﬁes the precision that should be used (the default is 28 decimal places), the rounding technique, and some other details.\n\nIn some situations the difference in accuracy between floats and decimal. Decimals becomes obvious:\n\n>>> 23 / 1.05 21.904761904761905 >>> print(23 / 1.05) 21.9047619048 >>> print(decimal.Decimal(23) / decimal.Decimal(\"1.05\")) 21.90476190476190476190476190\n\n3.1",
      "content_length": 2402,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 75,
      "content": "Floating-Point Types\n\n>>> decimal.Decimal(23) / decimal.Decimal(\"1.05\") Decimal('21.90476190476190476190476190')\n\nAlthough the division using decimal.Decimals is more accurate than the one involving floats, in this case (on a 32-bit machine) the difference only shows up in the ﬁfteenth decimal place. In many situations this is insigniﬁcant—for example, in this book, all the examples that need ﬂoating-point numbers use floats.\n\nOne other point to note is that the last two of the preceding examples reveal for the ﬁrst time that printing an object involves some behind-the-scenes for- matting. When we call print() on the result of decimal.Decimal(23) / deci- mal.Decimal(\"1.05\") the bare number is printed—this output is in string form. If we simply enter theexpressionwe get a decimal.Decimal output—thisoutput is in representational form. All Python objects have two output forms. String form is designed to be human-readable. Representational form is designed to produce output that if fed to a Python interpreter would (when possible) re- produce the represented object. We will return to this topic in the next section where we discuss strings, and again in Chapter 6 when we discuss providing string and representational forms for our own custom data types.\n\nThe Library Reference’s decimal module documentation provides all the details that are too obscure or beyond our scope to cover; it also provides more examples, and a FAQ list.\n\nStrings\n\nStringsarerepresentedby theimmutablestr datatypewhichholdsasequence of Unicode characters. The str data type can be called as a function to create string objects—with no arguments it returns an empty string, with a non- string argument it returns the string form of the argument, and with a string argument it returns a copy of the string. The str() function can also be used as a conversion function, in which case the ﬁrst argument should be a string or something convertable to a string,with up to two optional string arguments being passed, one specifying the encoding to use and the other specifying how to handle encoding errors.\n\nEarlier we mentioned that string literalsare created using quotes,and that we are free to use single or double quotes providing we use the same at both ends. In addition,we can use a triplequoted string—thisis Python-speak for a string that begins and ends with three quote characters(either three single quotes or three double quotes). For example:\n\ntext = \"\"\"A triple quoted string like this can include 'quotes' and \"quotes\" without formality. We can also escape newlines \\ so this particular string is actually only two lines long.\"\"\"\n\n65\n\n|||\n\nChar- acter encod- ings ➤ 91",
      "content_length": 2670,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 76,
      "content": "66\n\nChapter 2. Data Types\n\nTable 2.7 Python’s String Escapes\n\nEscape\n\nMeaning\n\n\\newline\n\nEscape (i.e., ignore) the newline\n\n\\\\\n\nBackslash (\\)\n\n\\'\n\nSingle quote (’)\n\n\\\"\n\nDouble quote (\")\n\n\\a\n\nASCII bell (BEL)\n\n\\b\n\nASCII backspace (BS)\n\n\\f\n\nASCII formfeed (FF)\n\n\\n\n\nASCII linefeed (LF)\n\n\\N{name}\n\nUnicode character with the given name\n\n\\ooo\n\nCharacter with the given octal value\n\n\\r\n\nASCII carriage return (CR)\n\n\\t\n\nASCII tab (TAB)\n\n\\uhhhh\n\nUnicode character with the given 16-bit hexadecimal value\n\n\\Uhhhhhhhh Unicode character with the given 32-bit hexadecimal value\n\n\\v\n\nASCII vertical tab (VT)\n\n\\xhh\n\nCharacter with the given 8-bit hexadecimal value\n\nIf we want to use quotes inside a normal quoted string we can do so without formality if they are different from the delimiting quotes; otherwise, we must escape them:\n\na = \"Single 'quotes' are fine; \\\"doubles\\\" must be escaped.\" b = 'Single \\'quotes\\' must be escaped; \"doubles\" are fine.'\n\nPython uses newline as its statement terminator, except inside parentheses (()), square brackets ([]), braces ({}), or triple quoted strings. Newlines can be used without formality in triple quoted strings, and we can include newlines in any string literal using the \\n escape sequence. All of Python’s escape se- quencesareshownin Table2.7.In somesituations—forexample,whenwriting regular expressions—we need to create stringswith lots of literal backslashes. (Regular expressions are the subject of Chapter 13.) This can be inconvenient since each one must be escaped:\n\nimport re phone1 = re.compile(\"^((?:[(]\\\\d+[)])?\\\\s*\\\\d+(?:-\\\\d+)?)$\")",
      "content_length": 1587,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 77,
      "content": "Strings\n\nThe solution is to use raw strings. These are quoted or triple quoted strings whose ﬁrst quote is preceded by the letter r. Inside such strings all characters are taken to be literals, so no escaping is necessary. Here is the phone regular expression using a raw string:\n\nphone2 = re.compile(r\"^((?:[(]\\d+[)])?\\s*\\d+(?:-\\d+)?)$\")\n\nIf we want to write a long string literal spread over two or more lines but with- out using a triple quoted string there are a couple of approaches we can take:\n\nt = \"This is not the best way to join two long strings \" + \\ \"together since it relies on ugly newline escaping\"\n\ns = (\"This is the nice way to join two long strings \"\n\n\"together; it relies on string literal concatenation.\")\n\nNotice that in the second case we must use parentheses to create a single expression—without them, s would be assigned only to the ﬁrst string, and the second string would cause an IndentationError exception to be raised. The Python documentation’s “Idioms and Anti-Idioms” HOWTO document recom- mends always using parentheses to spread statements of any kind over mul- tiple lines rather than escaping newlines; a recommendation we endeavor to follow.\n\nSince .py ﬁles default to using the UTF-8 Unicode encoding, we can write any Unicode characters in our string literals without formality. We can also put any Unicode characters inside strings using hexadecimal escape sequences or using Unicode names. For example:\n\n>>> euros = \" >>> print(euros)\n\n\\N{euro sign} \\u20AC \\U000020AC\"\n\nIn this case we could not use a hexadecimal escape because they are limited to two digits, so they cannot exceed 0xFF. Note that Unicode character names are not case-sensitive, and spaces inside them are optional.\n\nIf we want to know the Unicode code point (the integer assigned to the charac- ter in the Unicode encoding) for a particular character in a string, we can use the built-in ord() function. For example:\n\n>>> ord(euros[0]) 8364 >>> hex(ord(euros[0])) '0x20ac'\n\nSimilarly, we can convert any integer that represents a valid code point into the corresponding Unicode character using the built-in chr() function:\n\n67\n\nChar- acter encod- ings ➤ 91",
      "content_length": 2168,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 78,
      "content": "68\n\nChapter 2. Data Types\n\n>>> s = \"anarchists are \" + chr(8734) + chr(0x23B7) >>> s 'anarchists are ∞√' >>> ascii(s) \"'anarchists are \\u221e\\u23b7'\"\n\nIf we enter s on itsown in IDLE,it isoutput in itsstring form,which for strings means the characters are output enclosed in quotes. If we want only ASCII characters,wecanusethebuilt-in ascii() functionwhichreturnstherepresen- tational form of itsargument using 7-bit ASCII characterswhere possible,and using the shortest form of \\xhh, \\uhhhh,or \\Uhhhhhhhh escape otherwise. We will see how to achieve precise control of string output later in this chapter.\n\nComparing Strings\n\nStrings support the usual comparison operators <, <=, ==, !=, >, and >=. These operators compare strings byte by byte in memory. Unfortunately, two prob- lems arise when performing comparisons, such as when sorting lists of strings. Both problemsafﬂict every programming language that uses Unicode strings—neither is speciﬁc to Python.\n\nThe ﬁrst problem is that some Unicode characters can be represented by two or more different byte sequences. For example, the character Å (Unicode code point 0x00C5) can be represented in UTF-8 encoded bytes in three different ways: [0xE2, 0x84, 0xAB], [0xC3, 0x85], and [0x41, 0xCC, 0x8A]. Fortunately, we can solve this problem. If we import the unicodedata module and call unicode- data.normalize() with \"NFKC\" as the ﬁrst argument (this is a normalization method—three others are also available, \"NFC\", \"NFD\", and \"NFKD\"), and a string containing the Å character using any of its valid byte sequences, the function will return a string that when represented as UTF-8 encoded byteswill always be the byte sequence [0xC3, 0x85].\n\nThe second problem is that the sorting of some charactersis language-speciﬁc. Oneexampleisthat in Swedishäissortedafter z,whereasin German,äissort- ed as if though were spelled ae. Another example is that although in English we sort ø as if it were o, in Danish and Norwegian it is sorted after z. There are lots of problems along these lines, and they can be complicated by the fact thatsometimesthesameapplicationisusedby peopleof differentnationalities (who therefore expect different sorting orders),and sometimes strings are in a mixtureof languages(e.g.,someSpanish,othersEnglish),andsomecharacters (such as arrows,dingbats,and mathematical symbols) don’t really have mean- ingful sort positions.\n\nAs a matter of policy—to prevent subtle mistakes—Python does not make guesses. In the case of string comparisons, it compares using the strings’ in- memory byte representation. This gives a sort order based on Unicode code\n\n||\n\nstr. format() ➤ 78\n\nChar- acter encod- ings ➤ 91",
      "content_length": 2677,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 79,
      "content": "Piece #3 18➤\n\nStrings\n\npoints which gives ASCII sorting for English. Lower- or uppercasing all the stringscomparedproducesamorenaturalEnglishlanguageordering. Normal- izing is unlikely to be needed unless the strings are from external sources like ﬁles or network sockets, but even in these cases it probably shouldn’t be done unless there is evidence that it is needed. We can of course customize Python’s sort methods as we will see in Chapter 3. The whole issue of sorting Unicode strings is explained in detail in the Unicode Collation Algorithm document (unicode.org/reports/tr10).\n\nSlicing and Striding Strings\n\nWe know from Piece #3 that individual items in a sequence, and therefore in- dividual charactersin a string,can be extracted using the item accessoperator ([]).In fact,this operator is much more versatile and can be used to extract not just one item or character,but an entire slice (subsequence)of itemsor charac- ters, in which context it is referred to as the slice operator.\n\nFirst we will begin by looking at extracting individual characters. Index positions into a string begin at 0 and go up to the length of the string minus 1. But it is also possible to use negative index positions—these count from the last character back toward the ﬁrst. Given the assignment s = \"Light ray\", Figure 2.1 shows all the valid index positions for string s.\n\ns[-9]\n\ns[-8]\n\ns[-7]\n\ns[-6]\n\ns[-5]\n\ns[-4]\n\ns[-3]\n\ns[-2]\n\ns[-1]\n\nL\n\ni g h t\n\nr a y\n\ns[0]\n\ns[1]\n\ns[2]\n\ns[3]\n\ns[4]\n\ns[5]\n\ns[6]\n\ns[7]\n\ns[8]\n\nFigure 2.1 String index positions\n\nNegative indexes are surprisingly useful, especially -1 which always gives us the last character in a string. Accessing an out-of-range index (or any index in an empty string) will cause an IndexError exception to be raised.\n\nThe slice operator has three syntaxes:\n\nseq[start] seq[start:end] seq[start:end:step]\n\nThe seq can be any sequence,such as a list,string,or tuple. The start, end,and step values must all be integers (or variables holding integers). We have used the ﬁrst syntax already: It extracts the start-th item from the sequence. The second syntax extracts a slice from and including the start-th item, up to and excluding the end-th item. We’ll discuss the third syntax shortly.\n\n69\n\n||",
      "content_length": 2241,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 82,
      "content": "72\n\nChapter 2. Data Types\n\noffers a better solution. The method takes a sequence as an argument (e.g., a list or tuple of strings), and joins them together into a single string with the string the method was called on between each one. For example:\n\n>>> treatises = [\"Arithmetica\", \"Conics\", \"Elements\"] >>> \" \".join(treatises) 'Arithmetica Conics Elements' >>> \"-<>-\".join(treatises) 'Arithmetica-<>-Conics-<>-Elements' >>> \"\".join(treatises) 'ArithmeticaConicsElements'\n\nThe ﬁrst exampleisperhapsthe most common, joining with a single character, in this case a space. The third example is pure concatenation thanks to the empty string which meansthat thesequenceof stringsarejoined with nothing in between.\n\nThe str.join() method can also be used with the built-in reversed() function, to reversea string,for example,\"\".join(reversed(s)),although thesameresult can be achieved more concisely by striding, for example, s[::-1].\n\nThe * operator provides string replication:\n\n>>> s = \"=\" * 5 >>> print(s) ===== >>> s *= 10 >>> print(s) ==================================================\n\nAs the example shows, we can also use the augmented assignment version of the replication operator.★\n\nWhen applied to strings, the in membership operator returns True if its left- hand string argument is a substring of, or equal to, its right-hand string ar- gument.\n\nIn cases where we want to ﬁnd the position of one string inside another, we have two methods to choose from. One is the str.index() method; this returns the index position of the substring, or raises a ValueError exception on failure. The other is the str.find() method; this returns the index position of the sub- string, or -1 on failure. Both methods take the string to ﬁnd as their ﬁrst ar- gument,and can accept a couple of optional arguments. The second argument is the start position in the string being searched,and the third argument isthe end position in the string being searched.\n\n★Stringsalso support the % operator for formatting. Thisoperator is deprecated and provided only to ease conversion from Python 2 to Python 3. It is not used in any of the book’s examples.",
      "content_length": 2136,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 83,
      "content": "Identi- ﬁers and key- words 51➤\n\nStrings\n\nTable 2.8 String Methods #1\n\nSyntax\n\nDescription\n\ns.capitalize()\n\ns.center(width,\n\nchar)\n\nReturns a copy of str s with the ﬁrst letter capitalized; see also the str.title() method Returns a copy of s centered in a string of length width padded with spaces or optionally with char (a string of length 1); see str.ljust(), str.rjust(), and str.format()\n\ns.count(t,\n\nstart, end)\n\ns.encode(\n\nencoding, err)\n\nReturnsthe number of occurrencesof str t in str s (or in the start:end slice of s) Returns a bytes object that represents the string using the default encoding or using the speciﬁed encoding and handling errors according to the optional err argument\n\ns.endswith(x,\n\nstart, end)\n\ns.expandtabs( size)\n\nReturnsTrue if s (or the start:end sliceof s)endswith str x or with any of the strings in tuple x; otherwise,returns False. See also str.startswith(). Returns a copy of s with tabs replaced with spaces in multiples of 8 or of size if speciﬁed\n\ns.find(t,\n\nstart, end)\n\nReturnstheleftmostpositionof t in s (or in the start:end slice of s) or -1 if not found. Use str.rfind() to ﬁnd the rightmost position. See also str.index().\n\ns.format(...)\n\ns.index(t,\n\nstart, end)\n\nReturns a copy of s arguments. This method and its arguments are covered in the next subsection. Returns the leftmost position of t in s (or in the start:end sliceof s)or raisesValueError if not found. Use str.rindex() to search from the right. See str.find().\n\nformatted according to the given\n\ns.isalnum()\n\nReturns True if s is nonempty and every character in s is alphanumeric\n\ns.isalpha()\n\nReturns True if s is nonempty and every character in s is alphabetic\n\ns.isdecimal()\n\nReturns True if s is nonempty and every character in s is a Unicode base 10 digit\n\ns.isdigit()\n\nReturns True if s is nonempty and every character in s is an ASCII digit\n\ns.isidentifier() Returns True if s is nonempty and is\n\na valid identiﬁer\n\ns.islower()\n\nReturns True if s has at least one lowercaseable charac- ter and all its lowercaseable characters are lowercase; see also str.isupper()\n\n73\n\nbytes type ➤ 293\n\nChar- acter encod- ings ➤ 91\n\nstr. format() ➤ 78",
      "content_length": 2156,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 84,
      "content": "74\n\nChapter 2. Data Types\n\nTable 2.9 String Methods #2\n\nSyntax\n\nDescription\n\ns.isnumeric()\n\nReturns True if s is nonempty and every character in s is a numeric Unicode character such as a digit or fraction\n\ns.isprintable() Returns True if s is empty or if every character in s is con- sidered to be printable, including space, but not newline\n\ns.isspace()\n\nReturns True if s is nonempty and every character in s is a whitespace character\n\ns.istitle()\n\ns.isupper()\n\ns.join(seq)\n\nReturns True if s is a nonempty title-cased string; see also str.title() Returns True if str s has at least one uppercaseable char- acter and all its uppercaseable characters are uppercase; see also str.islower() Returns the concatenation of every item in the sequence seq, with str s (which may be empty) between each one\n\ns.ljust(\n\nwidth, char)\n\ns.lower()\n\nReturnsa copy of s left-aligned in a string of length width padded with spaces or optionally with char (a string of length 1). Use str.rjust() to right-align and str.center() to center. See also str.format(). Returns a lowercased copy of s; see also str.upper()\n\ns.maketrans()\n\nCompanion of str.translate(); see text for details\n\ns.partition(\n\nt)\n\nReturns a tuple of three strings—the part of str s before the leftmost str t,t,and thepart of s after t;or if t isn’t in s returns s and two empty strings. Use str.rpartition() to partition on the rightmost occurrence of t.\n\ns.replace(t, u, n)\n\nReturns a copy of s with every (or a maximum of n if given) occurrences of str t replaced with str u\n\ns.split(t, n)\n\nReturns a list of strings splitting at most n times on str t; if n isn’t given, splits as many times as possible; if t isn’t given,splitson whitespace. Use str.rsplit() to split from the right—thismakesa difference only if n is given and is less than the maximum number of splits possible.\n\ns.splitlines(\n\nf)\n\nReturns the list of lines produced by splitting s on line terminators, stripping the terminators unless f is True\n\ns.startswith( x, start, end)\n\nReturns True if s (or the start:end slice of s) starts with str x or with any of the strings in tuple x; otherwise, returns False. See also str.endswith().",
      "content_length": 2157,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 85,
      "content": "Strings\n\nTable 2.10 String Methods #3\n\nSyntax\n\nDescription\n\ns.strip(chars) Returns a copy of s with leading and trailing whitespace\n\n(or thecharactersin str chars)removed;str.lstrip() strips only at the start, and str.rstrip() strips only at the end\n\ns.swapcase()\n\nReturns a copy of s with uppercase characters lowercased and lowercase characters uppercased; see also str.lower() and str.upper()\n\ns.title()\n\ns.translate()\n\nReturns a copy of s where the ﬁrst letter of each word is uppercased and all other letters are lowercased; see str.istitle() Companion of str.maketrans(); see text for details\n\ns.upper()\n\nReturns an uppercased copy of s; see also str.lower()\n\ns.zfill(w)\n\nReturns a copy of s, which if shorter than w is padded with leading zeros to make it w characters long\n\nWhich search method we use is purely a matter of taste and circumstance, although if we are looking for multiple index positions, using the str.index() method often produces cleaner code, as the following two equivalent functions illustrate:\n\ndef extract_from_tag(tag, line): opener = \"<\" + tag + \">\" closer = \"</\" + tag + \">\" try:\n\ni = line.index(opener) start = i + len(opener) j = line.index(closer, start) return line[start:j]\n\ndef extract_from_tag(tag, line): opener = \"<\" + tag + \">\" closer = \"</\" + tag + \">\" i = line.find(opener) if i != -1:\n\nstart = i + len(opener) j = line.find(closer, start) if j != -1:\n\nexcept ValueError: return None\n\nreturn line[start:j]\n\nreturn None\n\nBoth versions of the extract_from_tag() function have exactly the same be- havior. For example, extract_from_tag(\"red\", \"what a <red>rose</red> this is\") returns the string “rose”.The exception-handling version on the left separates out the code that doeswhat we want from the code that handleserrors,and the error return value version on the right intersperses what we want with error handling.\n\nThe methods str.count(), str.endswith(), str.find(), str.rfind(), str.index(), str.rindex(), and str.startswith() all accept up to two optional arguments: a start position and an end position. Here are a couple of equivalences to put this in context, assuming that s is a string:\n\n75",
      "content_length": 2146,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 86,
      "content": "76\n\nChapter 2. Data Types\n\ns.count(\"m\", 6) == s[6:].count(\"m\") s.count(\"m\", 5, -3) == s[5:-3].count(\"m\")\n\nAs we can see,the string methodsthat accept start and end indexesoperate on the slice of the string speciﬁed by those indexes.\n\nNow we will look at another equivalence, this time to help clarify the behavior of str.partition()—although we’ll actually use a str.rpartition() example:\n\ni = s.rfind(\"/\") if i == -1:\n\nresult = \"\", \"\", s\n\nelse:\n\nresult = s.rpartition(\"/\")\n\nresult = s[:i], s[i], s[i + 1:]\n\nThe left- and right-hand code snippets are not quite equivalent because the one on the right also createsa new variable, i.Notice that we can assign tuples without formality, and that in both cases we looked for the rightmost occur- rence of /.If s isthe string \"/usr/local/bin/firefox\",both snippetsproducethe same result: ('/usr/local/bin', '/', 'firefox').\n\nWe can use str.endswith() (and str.startswith()) with a single string argu- ment, for example, s.startswith(\"From:\"), or with a tuple of strings. Here is a statement that uses both str.endswith() and str.lower() to print a ﬁlename if it is a JPEG ﬁle:\n\nif filename.lower().endswith((\".jpg\", \".jpeg\")):\n\nprint(filename, \"is a JPEG image\")\n\nThe is*() methods such as isalpha() and isspace() return True if the string they are called on has at least one character,and every character in the string meets the criterion. For example:\n\n>>> \"917.5\".isdigit(), \"\".isdigit(), \"-2\".isdigit(), \"203\".isdigit() (False, False, False, True)\n\nThe is*() methods work on the basis of Unicode character classiﬁcations, so for example, calling str.isdigit() on the strings \"\\N{circled digit two}03\" and \"➁03\" returns True for both of them. For this reason we cannot assume that a string can be converted to an integer when isdigit() returns True.\n\nWhen we receive strings from external sources (other programs,ﬁles, network connections,and especially interactive users),the strings may have unwanted leading and trailing whitespace. We can strip whitespace from the left using str.lstrip(), from the right using str.rstrip(), or from both ends using str.strip(). We can also give a string as an argument to the strip methods, in which case every occurrence of every character given will be stripped from the appropriate end or ends. For example:",
      "content_length": 2295,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 87,
      "content": "Strings\n\n>>> s = \"\\t no parking \" >>> s.lstrip(), s.rstrip(), s.strip() ('no parking ', '\\t no parking', 'no parking') >>> \"<[unbracketed]>\".strip(\"[](){}<>\") 'unbracketed'\n\nWe can also replace strings within strings using the str.replace() method. This method takes two string arguments, and returns a copy of the string it is called on with every occurrence of the ﬁrst string replaced with the second. If the second argument is an empty string the effect is to delete every occurrence of the ﬁrst string. We will see examplesof str.replace() and some other string methodsin the csv2html.py example in the Examplessection toward the end of the chapter.\n\nOne frequent requirement is to split a string into a list of strings. For exam- ple,we might have a text ﬁle of data with one record per line and each record’s ﬁelds separated by asterisks. This can be done using the str.split() method and passing in the string to split on as its ﬁrst argument, and optionally the maximum number of splits to make as the second argument. If we don’t spec- ify the second argument, as many splits are made as possible. Here is an ex- ample:\n\n>>> record = \"Leo Tolstoy*1828-8-28*1910-11-20\" >>> fields = record.split(\"*\") >>> fields ['Leo Tolstoy', '1828-8-28', '1910-11-20']\n\nNow we can use str.split() again on the date of birth and date of death to calculate how long he lived (give or take a year):\n\n>>> born = fields[1].split(\"-\") >>> born ['1828', '8', '28'] >>> died = fields[2].split(\"-\") >>> print(\"lived about\", int(died[0]) - int(born[0]), \"years\") lived about 82 years\n\nWe had touse int() to convert theyearsfromstringstointegers,but other than that the snippet is straightforward. We could have gotten the years directly from the fields list, for example, year_born = int(fields[1].split(\"-\")[0]).\n\nThe two methods that we did not summarize in Tables 2.8, 2.9, and 2.10 are str.maketrans() and str.translate(). The str.maketrans() method is used to create a translation table which maps charactersto characters. It acceptsone, two, or three arguments, but we will show only the simplest (two argument) callwheretheﬁrstargumentisastring containing characterstotranslatefrom and the second argument is a string containing the characters to translate to.\n\n77\n\ncsv2- html.py example ➤ 97",
      "content_length": 2284,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 88,
      "content": "78\n\nChapter 2. Data Types\n\nBoth arguments must be the same length. The str.translate() method takes a translation table as an argument and returns a copy of its string with the characterstranslated according to the translation table. Here is how we could translate strings that might contain Bengali digits to English digits:\n\ntable = \"\".maketrans(\"\\N{bengali digit zero}\"\n\n\"\\N{bengali digit one}\\N{bengali digit two}\" \"\\N{bengali digit three}\\N{bengali digit four}\" \"\\N{bengali digit five}\\N{bengali digit six}\" \"\\N{bengali digit seven}\\N{bengali digit eight}\" \"\\N{bengali digit nine}\", \"0123456789\")\n\nprint(\"20749\".translate(table)) print(\"\\N{bengali digit two}07\\N{bengali digit four}\" \"\\N{bengali digit nine}\".translate(table))\n\n# prints: 20749\n\n# prints: 20749\n\nNotice that we have taken advantage of Python’s string literal concatenation inside the str.maketrans() call and inside the second print() call to spread strings over multiple lines without having to escape newlines or use explicit concatenation.\n\nWe called str.maketrans() on an empty string because it doesn’t matter what string it is called on; it simply processes its arguments and returns a transla- tion table. The str.maketrans() and str.translate() methods can also be used to delete charactersby passing a string containing the unwanted charactersas the third argument to str.maketrans(). If more sophisticated character trans- lations are required, we could create a custom codec—see the codecs module documentation for more about this.\n\nPython has a few other library modules that provide string-related function- ality. We’ve already brieﬂy mentioned the unicodedata module, and we’ll show it in use in the next subsection. Other modules worth looking up are difflib which can be used to show differences between ﬁles or between strings, the io module’s io.StringIO class which allows us to read from or write to strings as though they were ﬁles, and the textwrap module which provides facilities for wrapping and ﬁlling strings. There is also a string module that has a few use- ful constants such as ascii_letters and ascii_lowercase. We will see examples of some of these modules in use in Chapter 5.In addition,Python provides ex- cellent support for regular expressions in the re module—Chapter 13 is dedi- cated to this topic.\n\nString Formatting with the str.format() Method\n\nThe str.format() method providesa very ﬂexible and powerful way of creating strings. Using str.format() iseasy for simplecases,butfor complex formatting we need to learn the formatting syntax the method requires.\n\n||",
      "content_length": 2577,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 89,
      "content": "Strings\n\nThe str.format() method returns a new string with the replacement ﬁelds in its string replaced with its arguments suitably formatted. For example:\n\n>>> \"The novel '{0}' was published in {1}\".format(\"Hard Times\", 1854) \"The novel 'Hard Times' was published in 1854\"\n\nEach replacement ﬁeld is identiﬁed by a ﬁeld name in braces. If the ﬁeld name is a simple integer, it is taken to be the index position of one of the arguments passed to str.format(). So in this case, the ﬁeld whose name was 0 was replaced by the ﬁrst argument, and the one with name 1 was replaced by the second argument.\n\nIf we need to include braces inside format strings, we can do so by doubling them up. Here is an example:\n\n>>> \"{{{0}}} {1} ;-}}\".format(\"I'm in braces\", \"I'm not\") \"{I'm in braces} I'm not ;-}\"\n\nIf we try to concatenate a string and a number, Python will quite rightly raise a TypeError. But we can easily achieve what we want using str.format():\n\n>>> \"{0}{1}\".format(\"The amount due is $\", 200) 'The amount due is $200'\n\nWe can also concatenate strings using str.format() (although the str.join() method is best for this):\n\n>>> x = \"three\" >>> s =\"{0} {1} {2}\" >>> s = s.format(\"The\", x, \"tops\") >>> s 'The three tops'\n\nHere we have used a couple of string variables, but in most of this section we’ll use string literals for str.format() examples, simply for the sake of convenience—just keep in mind that any example that uses a string literal could use a string variable in exactly the same way.\n\nThe replacement ﬁeld can have any of the following general syntaxes:\n\n{field_name} {field_name!conversion} {field_name:format_specification} {field_name!conversion:format_specification}\n\nOne other point to note is that replacement ﬁelds can contain replacement ﬁelds. Nested replacement ﬁelds cannot have any formatting;their purpose is to allow for computed formatting speciﬁcations. We will see an example of this\n\n79",
      "content_length": 1920,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 90,
      "content": "80\n\nChapter 2. Data Types\n\nwhen we take a detailed look at format speciﬁcations. We will now study each part of the replacement ﬁeld in turn, starting with ﬁeld names.\n\nField Names\n\nA ﬁeld name can be either an integer corresponding to one of the str.format() method’s arguments, or the name of one of the method’s keyword arguments. We discuss keyword arguments in Chapter 4, but they are not difﬁcult, so we will provide a couple of examples here for completeness:\n\n>>> \"{who} turned {age} this year\".format(who=\"She\", age=88) 'She turned 88 this year' >>> \"The {who} was {0} last week\".format(12, who=\"boy\") 'The boy was 12 last week'\n\nThe ﬁrst example uses two keyword arguments, who and age, and the second example uses one positional argument (the only kind we have used up to now) and one keyword argument. Notice that in an argument list, keyword argumentsalwayscomeafter positionalarguments;andof coursewecanmake use of any arguments in any order inside the format string.\n\nField names may refer to collection data types—for example, lists. In such cases we can include an index (not a slice!) to identify a particular item:\n\n>>> stock = [\"paper\", \"envelopes\", \"notepads\", \"pens\", \"paper clips\"] >>> \"We have {0[1]} and {0[2]} in stock\".format(stock) 'We have envelopes and notepads in stock'\n\nThe 0 refers to the positional argument, so {0[1]} is the stock list argument’s second item, and {0[2]} is the stock list argument’s third item.\n\nLater on wewill learn about Pythondictionaries. Thesestorekey–valueitems, and since they can be used with str.format(), we’ll just show a quick example here. Don’t worry if it doesn’t make sense; it will once you’ve read Chapter 3.\n\n>>> d = dict(animal=\"elephant\", weight=12000) >>> \"The {0[animal]} weighs {0[weight]}kg\".format(d) 'The elephant weighs 12000kg'\n\nJust asweaccesslist and tupleitemsusing an integer positionindex,weaccess dictionary items using a key.\n\nWecanalsoaccessnamedattributes. Assuming wehaveimportedthe math and sys modules, we can do this:\n\n>>> \"math.pi=={0.pi} sys.maxunicode=={1.maxunicode}\".format(math, sys) 'math.pi==3.14159265359 sys.maxunicode==65535'\n\n|\n\ndict type ➤ 126",
      "content_length": 2152,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 91,
      "content": "Strings\n\nSo in summary, the ﬁeld name syntax allows us to refer to positional and key- word argumentsthat are passed to the str.format() method. If the arguments are collection data typeslike lists or dictionaries,or have attributes,we can ac- cess the part we want using [] or . notation. This is illustrated in Figure 2.5.\n\npositional argument index\n\n{0}\n\n{1[5]}\n\n{2[capital]}\n\n{3.rate}\n\nindex\n\nkey\n\nattribute\n\n{title}\n\n{color[12]}\n\n{point[y]}\n\n{book.isbn}\n\nkeyword argument name\n\nFigure 2.5 Annotated format speciﬁer ﬁeld name examples\n\nFrom effect put them in for us, using numbers starting from 0. For example:\n\nPython 3.1it is possible to omit ﬁeld names,in which case Python will in\n\n>>> \"{} {} {}\".format(\"Python\", \"can\", \"count\") 'Python can count'\n\nIf we are using Python 3.0, the format string used here would have to be \"{0} {1} {2}\". Using this technique is convenient for formatting one or two items, but the approach we will look at next is more convenient when several items are involved, and works just as well with Python 3.0.\n\nBefore ﬁnishing our discussion of string format ﬁeld names, it is worth men- tioning a rather different way to get values into a format string. This involves using an advanced technique,but one useful to learn as soon as possible, since it is so convenient.\n\nThe local variables that are currently in scope are available from the built-in locals() function. This function returns a dictionary whose keys are local variable names and whose values are references to the variables’ values. Now we can use mapping unpacking to feed this dictionary into the str.format() method. The mapping unpacking operator is ** and it can be applied to a mapping (such as a dictionary)to produce a key–value list suitable for passing to a function. For example:\n\n>>> element = \"Silver\" >>> number = 47 >>> \"Element {number} is {element}\".format(**locals()) 'Element 47 is Silver'\n\n81\n\n3.1\n\nMap- ping unpack- ing ➤ 179",
      "content_length": 1946,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 92,
      "content": "Decimal num- bers 63➤\n\n82\n\nChapter 2. Data Types\n\nThe syntax may seem weird enough to make a Perl programmer feel at home, but don’t worry—it is explained in Chapter 4. All that matters for now is that we can use variable names in format strings and leave Python to ﬁll in their values simply by unpacking the dictionary returned by locals()—or some other dictionary—intothe str.format() method. For example,wecould rewrite the “elephant” example we saw earlier to have a much nicer format string with simpler ﬁeld names.\n\n>>> \"The {animal} weighs {weight}kg\".format(**d) 'The elephant weighs 12000kg'\n\nUnpacking a dictionary into the str.format() method allows us to use the dictionary’s keys as ﬁeld names. This makes string formats much easier to understand, and also easier to maintain, since they are not dependent on the order of the arguments. Note, however, that if we want to pass more than one argument to str.format(), only the last one can use mapping unpacking.\n\nConversions\n\n|\n\nWhen we discussed decimal.Decimal numbers we noticed that such are output in one of two ways. For example:\n\nnumbers\n\n>>> decimal.Decimal(\"3.4084\") Decimal('3.4084') >>> print(decimal.Decimal(\"3.4084\")) 3.4084\n\nThe ﬁrst way that the decimal.Decimal is shown is in its representational form. The purpose of this form is to provide a string which if interpreted by Python would re-create the object it represents. Python programs can evaluate snip- pets of Python code or entire programs, so this facility can be useful in some situations. Not all objects can provide a reproducing representation, in which case they provide a string enclosed in angle brackets. For example, the repre- sentational form of the sys module is the string \"<module 'sys' (built-in)>\".\n\nThe second way that decimal.Decimal isshown isin itsstring form. Thisform is aimed at human readers,sotheconcern istoshowsomething that makessense to people. If a data type doesn’t have a string form and a string is required, Python will use the representational form.\n\nPython’s built-in data types know about str.format(), and when passed as an argument to this method they return a suitable string to display themselves. It is also straightforward to add str.format() support to custom data types as we will see in Chapter 6. In addition, it is possible to override the data type’s normal behavior and force it to provide either its string or its representational form. Thisisdoneby adding a conversionspeciﬁertotheﬁeld. Currentlythere are three such speciﬁers:sto forcestring form,r to force representationalform,\n\nParame- ter unpack- ing ➤ 177\n\neval() ➤ 344",
      "content_length": 2615,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 93,
      "content": "Strings\n\nand a to force representational form but only using ASCII characters. Here is an example:\n\n>>> \"{0} {0!s} {0!r} {0!a}\".format(decimal.Decimal(\"93.4\")) \"93.4 93.4 Decimal('93.4') Decimal('93.4')\"\n\nIn this case, decimal.Decimal’s string form produces the same string as the string it provides for str.format() which is what commonly happens. Also, in this particular example, there is no difference between the representational and ASCII representational forms since both use only ASCII characters.\n\nHere is another example, this time concerning a string that contains the ti- tle of a movie, \" \", held in the variable movie. If we print the string using \"{0}\".format(movie) the string will be output unchanged, but if we want to avoid non-ASCII characters we can use either ascii(movie) or \"{0!a}\".format(movie), both of which will produce the string '\\u7ffb\\u8a33 \\u3067\\u5931\\u308f\\u308c\\u308b'.\n\nSo far we have seen how to put the valuesof variablesinto a format string,and how to force string or representational forms to be used. Now we are ready to consider the formatting of the values themselves.\n\nFormat Speciﬁcations\n\nThe default formatting of integers,ﬂoating-point numbers,and stringsisoften perfectly satisfactory. But if we want to exercise ﬁne control, we can easily do sousing formatspeciﬁcations. Wewilldealseparately withformatting strings, integers, and ﬂoating-point numbers, to make learning the details easier. The the general syntax that covers all of them is shown in Figure 2.6.\n\nFor strings,the things that we can control are the ﬁll character,the alignment within the ﬁeld, and the minimum and maximum ﬁeld widths.\n\nA string format speciﬁcation is introduced with a colon (:) and this is followed by an optional pair of characters—a ﬁll character (which may not be }) and an alignment character (< for left align, ^ for center, > for right align).Then comes an optional minimum width integer, and if we want to specify a maximum width, this comes last as a period followed by an integer.\n\nNote that if we specify a ﬁll character we must also specify an alignment. We omit the sign and type parts of the format speciﬁcation because they have no effect on strings. It is harmless (but pointless) to have a colon without any of the optional elements.\n\nLet’s see some examples:\n\n>>> s = \"The sword of truth\" >>> \"{0}\".format(s) 'The sword of truth'\n\n# default formatting\n\n83\n\n|",
      "content_length": 2408,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 94,
      "content": "84\n\nChapter 2. Data Types\n\n:\n\nﬁll\n\nAny char- acter except }\n\nalign\n\n< left > right ^ center = pad between sign and digits for numbers\n\nsign + force sign; - sign if needed; “ ” space or - as appro- priate\n\n#\n\np r e ﬁ x\n\ni n t s w\n\ni t h 0 b , 0 o , o r\n\n0 width\n\n0 - p a d n u m b e r s\n\nMini- mum ﬁeld width\n\n, . precision type\n\nu s e c o m m a s f o r g r o u p n g ★\n\ni\n\nMaximum ﬁeld width for strings; number of decimal places for ﬂoating- point numbers\n\nints b,c,d, n,o,x, X; floats e,E,f, g,G,n, %\n\n0 x\n\nFigure 2.6 The general form of a format speciﬁcation\n\n>>> \"{0:25}\".format(s) 'The sword of truth >>> \"{0:>25}\".format(s) # right align, minimum width 25 ' >>> \"{0:^25}\".format(s) # center align, minimum width 25 ' >>> \"{0:-^25}\".format(s) # - fill, center align, minimum width 25 '---The sword of truth----' >>> \"{0:.<25}\".format(s) # . fill, left align, minimum width 25 'The sword of truth.......' >>> \"{0:.10}\".format(s) # maximum width 10 'The sword '\n\n# minimum width 25\n\n'\n\nThe sword of truth'\n\nThe sword of truth\n\n'\n\nIn the penultimate example we had to specify the left alignment (even though this is the default). If we left out the <, we would have :.25, and this simply means a maximum ﬁeld width of 25 characters.\n\nAs we noted earlier,it is possible to have replacement ﬁeldsinside format spec- iﬁcations. Thismakesit possibletohavecomputedformats. Here,for example, are two ways of setting a string’s maximum width using a maxwidth variable:\n\n>>> maxwidth = 12 >>> \"{0}\".format(s[:maxwidth]) 'The sword of' >>> \"{0:.{1}}\".format(s, maxwidth) 'The sword of'\n\nThe ﬁrst approach uses standard string slicing; the second uses an inner replacement ﬁeld.\n\n★The grouping comma was introduced with Python 3.1.",
      "content_length": 1723,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 95,
      "content": "Strings\n\nFor integers, the format speciﬁcation allows us to control the ﬁll character,the alignment within the ﬁeld, the sign, whether to use a nonlocale-aware comma separator to group digits (from Python 3.1), the minimum ﬁeld width, and the number base.\n\nAn integer format speciﬁcation begins with a colon, after which we can have an optional pair of characters—a ﬁll character (which may not be }) and an alignment character (< for left align, ^ for center, > for right align, and = for the ﬁlling to be done between the sign and the number). Next is an optional sign character: + forces the output of the sign, - outputs the sign only for negative numbers, and a space outputs a space for positive numbers and a - sign for negative numbers. Then comes an optional minimum width integer—this can be preceded by a # character to get the base preﬁx output (for binary,octal,and hexadecimal numbers), and by a 0 to get 0-padding. Then, from Python 3.1, comes an optional comma—if present this will cause the number’s digits to be grouped into threes with a comma separating each group. If we want the out- put in a base other than decimal we must add a type character—b for binary, o for octal, x for lowercase hexadecimal, and X for uppercase hexadecimal, al- though for completeness, d for decimal integer is also allowed. There are two other type characters: c, which means that the Unicode character correspond- ing to the integer should be output, and n, which outputs numbers in a locale- sensitive way. (Note that if n is used, using , doesn’t make sense.)\n\nWe can get 0-padding in two different ways:\n\n>>> \"{0:0=12}\".format(8749203) # 0 fill, minimum width 12 '000008749203' >>> \"{0:0=12}\".format(-8749203) # 0 fill, minimum width 12 '-00008749203' >>> \"{0:012}\".format(8749203) '000008749203' >>> \"{0:012}\".format(-8749203) # 0-pad and minimum width 12 '-00008749203'\n\n# 0-pad and minimum width 12\n\nThe ﬁrst two examples have a ﬁll character of 0 and ﬁll between the sign and the number itself (=). The second two examples have a minimum width of 12 and 0-padding.\n\nHere are some alignment examples:\n\n>>> \"{0:*<15}\".format(18340427) # * fill, left align, min width 15 '18340427*******' >>> \"{0:*>15}\".format(18340427) # * fill, right align, min width 15 '*******18340427' >>> \"{0:*^15}\".format(18340427) # * fill, center align, min width 15 '***18340427****' >>> \"{0:*^15}\".format(-18340427) # * fill, center align, min width 15 '***-18340427***'\n\n85\n\n3.x",
      "content_length": 2464,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 96,
      "content": "86\n\nChapter 2. Data Types\n\nHere are some examples that show the effects of the sign characters:\n\n>>> \"[{0: }] [{1: }]\".format(539802, -539802) # space or - sign '[ 539802] [-539802]' >>> \"[{0:+}] [{1:+}]\".format(539802, -539802) # force sign '[+539802] [-539802]' >>> \"[{0:-}] [{1:-}]\".format(539802, -539802) # - sign if needed '[539802] [-539802]'\n\nAnd here are two examples that use some of the type characters:\n\n>>> \"{0:b} {0:o} {0:x} {0:X}\".format(14613198) '110111101111101011001110 67575316 deface DEFACE' >>> \"{0:#b} {0:#o} {0:#x} {0:#X}\".format(14613198) '0b110111101111101011001110 0o67575316 0xdeface 0XDEFACE'\n\nIt isnot possible to specify a maximum ﬁeld width for integers. Thisisbecause doing so might require digits to be chopped off, thereby rendering the integer meaningless.\n\nIf we are using Python 3.1 and use a comma in the format speciﬁcation, the integer will use commas for grouping. For example:\n\n>>> \"{0:,} {0:*>13,}\".format(int(2.39432185e6)) '2,394,321 ****2,394,321'\n\nBoth ﬁelds have grouping applied, and in addition, the second ﬁeld is padded with *s, right aligned, and given a minimum width of 13 characters. This is very convenient for many scientiﬁcand ﬁnancialprograms,but it doesnot take into account the current locale. For example, many Continental Europeans would expect the thousands separator to be . and the decimal separator to be ,.\n\nThe last format character available for integers(and which isalso available for ﬂoating-point numbers) is n. This has the same effect as d when given an inte- ger andthesameeffectasg whengivena ﬂoating-point number. What makesn special is that it respectsthe current locale,and will use the locale-speciﬁc dec- imal separator and grouping separator in the output it produces. The default locale is called the C locale, and for this the decimal and grouping characters are a period and an empty string. We can respect the user’s locale by starting our programs with the following two lines as the ﬁrst executable statements:★\n\nimport locale locale.setlocale(locale.LC_ALL, \"\")\n\n★In multithreadedprogramsit isbest to call locale.setlocale()only once,at programstart-up,and before any additional threads have been started, since the function is not usually thread-safe.\n\n3.1",
      "content_length": 2249,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 97,
      "content": "Strings\n\nPassing an empty string as the locale tells Python to try to automatically determine the user’s locale (e.g.,by examining the LANG environment variable), with a fallback of the C locale. Here are some examples that show the effects of different locales on an integer and a ﬂoating-point number:\n\nx, y = (1234567890, 1234.56) locale.setlocale(locale.LC_ALL, \"C\") c = \"{0:n} {1:n}\".format(x, y) locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\") en = \"{0:n} {1:n}\".format(x, y) locale.setlocale(locale.LC_ALL, \"de_DE.UTF-8\") de = \"{0:n} {1:n}\".format(x, y)\n\n# c == \"1234567890 1234.56\"\n\n# en == \"1,234,567,890 1,234.56\"\n\n# de == \"1.234.567.890 1.234,56\"\n\nAlthough n is very useful for integers, it is of more limited use with ﬂoating- point numbers because as soon as they become large they are output using ex- ponential form.\n\nFor ﬂoating-point numbers, the format speciﬁcation gives us control over the ﬁll character, the alignment within the ﬁeld, the sign, whether to use a non- locale aware comma separator to group digits (from Python 3.1), the mini- mum ﬁeld width, the number of digits after the decimal place, and whether to present the number in standard or exponential form, or as a percentage.\n\nThe format speciﬁcation for ﬂoating-point numbers is the same as for integers, exceptfor twodifferencesat theend. After theoptionalminimumwidth—from Python 3.1, after the optional grouping comma—we can specify the number of digitsafterthedecimalplaceby writing a periodfollowedby aninteger. Wecan also add a type character at the end: e for exponential form with a lowercase e, E for exponential form with an uppercase E, f for standard ﬂoating-point form, g for “general” form—this is the same as f unless the number is very large, in which case it is the same as e—and G, which is almost the same as g, but uses either f or E.Also availableis %—thisresultsin the number being multipliedby 100 with the resultant number output in f format with a % symbol appended.\n\nHere are a few examples that show exponential and standard forms:\n\n>>> amount = (10 ** 3) * math.pi >>> \"[{0:12.2e}] [{0:12.2f}]\".format(amount) '[ >>> \"[{0:*>12.2e}] [{0:*>12.2f}]\".format(amount) '[****3.14e+03] [*****3141.59]' >>> \"[{0:*>+12.2e}] [{0:*>+12.2f}]\".format(amount) '[***+3.14e+03] [****+3141.59]'\n\n3.14e+03] [\n\n3141.59]'\n\nThe ﬁrst example has a minimum width of 12 charactersand has 2 digits after the decimal point. The second example builds on the ﬁrst, and adds a * ﬁll character. If we use a ﬁll character we must also have an alignment character, so we have speciﬁed align right (even though that is the default for numbers).\n\n87\n\n3.x",
      "content_length": 2632,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 98,
      "content": "88\n\nChapter 2. Data Types\n\nThe third example builds on the previous two, and adds the + sign character to force the output of the sign.\n\nIn Python 3.0, decimal.Decimal numbers are treated by str.format() as strings rather than asnumbers. Thismakesit quite tricky to get nicely formattedout- put. From Python 3.1, decimal.Decimal numbers can be formatted as floats,in- cluding support for , to get comma-separated groups. Here is an example—we have omitted the ﬁeld name since we don’t need it for Python 3.1:\n\n>>> \"{:,.6f}\".format(decimal.Decimal(\"1234567890.1234567890\")) '1,234,567,890.123457'\n\nIf we omitted the f format character (or used the g format character), the number would be formatted as '1.23457E+9'.\n\nPython 3.0 does not provide any direct support for formatting complex numbers—support was added with Python 3.1. However, we can easily solve this by formatting the real and imaginary parts as individual ﬂoating-point numbers. For example:\n\n>>> \"{0.real:.3f}{0.imag:+.3f}j\".format(4.75917+1.2042j) '4.759+1.204j' >>> \"{0.real:.3f}{0.imag:+.3f}j\".format(4.75917-1.2042j) '4.759-1.204j'\n\nWe accesseach attributeof the complex number individually,and format them both as ﬂoating-point numbers, in this case with three digits after the decimal place. We have also forced the sign to be output for the imaginary part; we must add on the j ourselves.\n\nPython 3.1supportsformatting complex numbersusing the same syntax asfor floats:\n\n>>> \"{:,.4f}\".format(3.59284e6-8.984327843e6j) '3,592,840.0000-8,984,327.8430j'\n\nOne slight drawback of this approach is that exactly the same formatting is applied to both the real and the imaginary parts; but we can always use the Python 3.0 technique of accessing the complex number’sattributesindividual- ly if we want to format each one differently.\n\nExample: print_unicode.py\n\nIntheprecedingsubsubsectionswecloselyexaminedthestr.format()method’s format speciﬁcations, and we have seen many code snippets that show partic- ular aspects. In this subsubsection we will review a small yet useful example that makes use of str.format() so that we can see format speciﬁcations in a\n\n|\n\n3.1\n\n3.1",
      "content_length": 2137,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 99,
      "content": "Strings\n\nrealistic context. The example also uses some of the string methods we saw in the previous section, and introduces a function from the unicodedata module.★\n\nThe program has just 25 lines of executable code. It imports two modules, sys and unicodedata, and deﬁnes one custom function, print_unicode_table(). We’ll begin by looking at a sample run to see what it does, then we will look at the code at the end of the program where processing really starts, and ﬁnally we will look at the custom function.\n\nprint_unicode.py spoked hex decimal ------- ----- --- ---------------------------------------- 2722 ✢ Four Teardrop-Spoked Asterisk 2723 ✣ Four Balloon-Spoked Asterisk 2724 ✤ Heavy Four Balloon-Spoked Asterisk 2725 ✥ Four Club-Spoked Asterisk 2733 ✳ Eight Spoked Asterisk 273B Teardrop-Spoked Asterisk 273C ✼ Open Centre Teardrop-Spoked Asterisk Heavy Teardrop-Spoked Asterisk 273D 2743 ❃ Heavy Teardrop-Spoked Pinwheel Asterisk 2749 ❈ Balloon-Spoked Asterisk 274A ❊ Eight Teardrop-Spoked Propeller Asterisk 274B ❋ Heavy Eight Teardrop-Spoked Propeller Asterisk\n\nchr\n\nname\n\n10018 10019 10020 10021 10035 10043 10044 10045 10051 10057 10058 10059\n\n✽\n\n✽\n\nIf run with no arguments, the program produces a table of every Unicode character,starting from the spacecharacter and going up to the character with the highest available code point. If an argument is given, as in the example, only those rows in the table where the lowercased Unicode character name contains the argument are printed.\n\nword = None if len(sys.argv) > 1:\n\nif sys.argv[1] in (\"-h\", \"--help\"):\n\nprint(\"usage: {0} [string]\".format(sys.argv[0])) word = 0\n\nelse:\n\nword = sys.argv[1].lower()\n\nif word != 0:\n\nprint_unicode_table(word)\n\n★ This program assumes that the console uses the Unicode UTF-8 encoding. Unfortunate- ly, the Windows console has poor UTF-8 support. As a workaround, the examples include print_unicode_uni.py, a version of the program that writes its output to a ﬁle which can then be opened using a UTF-8-savvy editor, such as IDLE.\n\n89\n\nChapter 7 (File Han- dling) ➤ 287",
      "content_length": 2067,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 100,
      "content": "90\n\nChapter 2. Data Types\n\nAfter the imports and the creation of the print_unicode_table() function, exe- cution reaches the code shown here. We begin by assuming that the user has not given a word to match on the command line. If a command-line argument is given and is -h or --help, we print the program’s usage information and set word to 0 as a ﬂag to indicate that we are ﬁnished. Otherwise, we set the word to a lowercase copy of the argument the user typed in. If the word is not 0,then we print the table.\n\nWhen we print the usage information we use a format speciﬁcation that just has the format name—in this case, the position number of the argument. We could have written the line like this instead:\n\nprint(\"usage: {0[0]} [string]\".format(sys.argv))\n\nUsing this approach the ﬁrst 0 is the index position of the argument we want to use,and [0] is the index withinthe argument,and it worksbecause sys.argv is a list.\n\ndef print_unicode_table(word):\n\nprint(\"decimal print(\"------- ----- --- {0:-<40}\".format(\"\"))\n\nhex\n\nchr {0:^40}\".format(\"name\"))\n\ncode = ord(\" \") end = sys.maxunicode\n\nwhile code < end: c = chr(code) name = unicodedata.name(c, \"*** unknown ***\") if word is None or word in name.lower():\n\nprint(\"{0:7} {0:5X} {0:^3c} {1}\".format(\n\ncode, name.title()))\n\ncode += 1\n\nWe’ve used a couple of blank lines for the sake of clarity. The ﬁrst two lines of the function’s suite print the title lines. The ﬁrst str.format() prints the text “name” centered in a ﬁeld 40 characters wide, whereas the second one prints an empty string in a ﬁeld 40 characters wide, using a ﬁll character of “-”, and aligned left. (We must give an alignment if we specify a ﬁll character.) An alternative approach for the second line is this:\n\nprint(\"------- ----- --- {0}\".format(\"-\" * 40))\n\nHerewehaveused thestring replicationoperator (*)to createa suitablestring, and simply inserted it into the format string. A third alternative would be to simply type in 40 “-”s and use a literal string.\n\nWe keep track of Unicode code points in the code variable, initializing it to the code point for a space (0x20). We set the end variable to be the highest",
      "content_length": 2144,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 101,
      "content": "Strings\n\nUnicode code point available—this will vary depending on whether Python was compiled to use the UCS-2 or the UCS-4 character encoding.\n\nInside the while loop we get the Unicode character that correspondsto the code point using the chr() function. The unicodedata.name() function returns the Unicode character name for the given Unicode character; its optional second argument is the name to use if no character name is deﬁned.\n\nIf the user didn’t specify a word (word is None), or if they did and it is in a low- ercased copy of the Unicode character name, then we print the correspond- ing row.\n\nAlthough we pass the code variable to the str.format() method only once, it is used three times in the format string, ﬁrst to print the code as an integer in a ﬁeld 7 characters wide (the ﬁll character defaults to space, so we did not need to specify it), second to print the code as an uppercase hexadecimal number in a ﬁeld 5 characters wide, and third to print the Unicode character that corresponds to the code—using the “c” format speciﬁer, and centered in a ﬁeld with a minimum width of three characters. Notice that we did not have to specify the type “d” in the ﬁrst format speciﬁcation; this is because it is the defaultfor integerarguments. Thesecondargumentisthecharacter’sUnicode character name, printed using “title” case, that is, with the ﬁrst letter of each word uppercased, and all other letters lowercased.\n\nNow that we are familiar with the versatile str.format() method,we will make great use of it throughout the rest of the book.\n\nCharacter Encodings\n\nUltimately, computers can store only bytes, that is, 8-bit values which, if un- signed,range from 0x00 to 0xFF.Every character must somehow be represented intermsof bytes. Intheearly daysof computingthepioneersdevisedencoding schemesthatassigneda particularcharactertoa particularbyte. Forexample, using the ASCII encoding,A is represented by 0x41,Bby 0x42,and so on. In the U.S. and Western Europe the Latin-1 encoding was often used; its characters in the range 0x20–0x7E are the same as the corresponding characters in 7-bit ASCII,with those in the range 0xA0–0xFF used for accented charactersand oth- er symbols needed by those using non-English Latin alphabets. Many other encodings have been devised over the years, and now there are lots of them in use—however, development has ceased for many of them, in favor of Unicode.\n\nHaving all these different encodings has proved very inconvenient, especially when writing internationalized software. One solution that has been almost universally adopted is the Unicode encoding. Unicode assigns every charac- ter to an integer—called a code point in Unicode-speak—just like the earlier encodings. But Unicode is not limited to using one byte per character, and is thereforeabletorepresentevery characterin every languagein a singleencod-\n\n91\n\n||",
      "content_length": 2876,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 102,
      "content": "92\n\nChapter 2. Data Types\n\ning, so unlike other encodings, Unicode can handle characters from a mixture of languages, rather than just one.\n\nBut how is Unicode stored? Currently, slightly more than 100000 Unicode characters are deﬁned, so even using signed numbers, a 32-bit integer is more than adequate to store any Unicode code point. So the simplest way to store Unicode characters is as a sequence of 32-bit integers, one integer per charac- ter. This sounds very convenient since it should produce a one to one mapping of characters to 32-bit integers, which would make indexing to a particular character very fast. However, in practice things aren’t so simple, since some Unicode characters can be represented by one or by two code points—for ex- ample,é can be represented by the single code point 0xE9 or by two code points, 0x65 and 0x301 (e and a combining acute accent).\n\nNowadays, Unicode is usually stored both on disk and in memory using UTF- 8, UTF-16, or UTF-32. The ﬁrst of these, UTF-8, is backward compatible with 7-bit ASCII since its ﬁrst 128 code points are represented by single-byte val- ues that are the same as the 7-bit ASCII character values. To represent all the other Unicode characters, UTF-8 uses two, three, or more bytes per character. This makes UTF-8 very compact for representing text that is all or mostly En- glish. TheGtk library (usedby theGNOMEwindowing system,among others) uses UTF-8, and it seems that UTF-8 is becoming the de facto standard format for storing Unicode text in ﬁles—for example, UTF-8 is the default format for XML, and many web pages these days use UTF-8.\n\nA lot of other software, such as Java, uses UCS-2 (which in modern form is the same as UTF-16).This representation uses two or four bytes per character, with the most common characters represented by two bytes. The UTF-32 rep- resentation (also called UCS-4) uses four bytes per character. Using UTF-16 or UTF-32for storing Unicode in ﬁlesor for sending over a network connection has a potential pitfall:If the data is sent as integers then the endianness mat- ters. One solution to this is to precede the data with a byte order mark so that readers can adapt accordingly. This problem doesn’t arise with UTF-8, which is another reason why it is so popular.\n\nPython represents Unicode using either UCS-2 (UTF-16) format, or UCS-4 (UTF-32) format. In fact,when using UCS-2, Python uses a slightly simpliﬁed versionthatalwaysusestwobytesper characterandsocanonly representcode points up to 0xFFFF. When using UCS-4, Python can represent all the Unicode code points. The maximum code point is stored in the read-only sys.maxunicode attribute—if its value is 65535, then Python was compiled to use UCS-2; if larger, then Python is using UCS-4.\n\nThe str.encode() method returns a sequence of bytes—actually a bytes object, covered in Chapter 7—encoded according to the encoding argument we supply. Using this method we can get some insight into the difference between encod- ings, and why making incorrect encoding assumptions can lead to errors:",
      "content_length": 3061,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 103,
      "content": "Strings\n\n>>> artist = \"Tage Åsén\" >>> artist.encode(\"Latin1\") b'Tage \\xc5s\\xe9n' >>> artist.encode(\"CP850\") b'Tage \\x8fs\\x82n' >>> artist.encode(\"utf8\") b'Tage \\xc3\\x85s\\xc3\\xa9n' >>> artist.encode(\"utf16\") b'\\xff\\xfeT\\x00a\\x00g\\x00e\\x00 \\x00\\xc5\\x00s\\x00\\xe9\\x00n\\x00'\n\nA b before an opening quote signiﬁes a bytes literal rather than a string literal. As a convenience,when creating bytes literals we can use a mixture of printable ASCII characters and hexadecimal escapes.\n\nWe cannot encode Tage Åsén’s name using the ASCII encoding because it does not have the Å character or any accented characters, so attempting to do so will result in a UnicodeEncodeError exception being raised. The Latin-1 encod- ing (also known as ISO-8859-1) is an 8-bit encoding that has all the necessary characters for this name. On the other hand, artist Erno″ Bánk would be less fortunate since the o″ character is not a Latin-1 character and so could not be successfully encoded. Both names can be successfully encoded using Uni- code encodings, of course. Notice, though, that for UTF-16, the ﬁrst two bytes are the byte order mark—these are used by the decoding function to detect whether the data is big- or little-endian so that it can adapt accordingly.\n\nIt is worth noting a couple more points about the str.encode() method. The ﬁrst argument (the encoding name) is case-insensitive, and hyphens and un- derscores in the name are treated as equivalent, so “us-ascii” and “US_ASCII” are considered the same. There are also many aliases—for example, “latin”, “latin1”, “latin_1”, “ISO-8859-1”, “CP819”, and some others are all “Latin-1”. Themethodcanalsoacceptan optionalsecondargumentwhich isusedtotellit how to handle errors. For example, we can encode any string into ASCII if we pass a second argument of “ignore” or “replace”—at the price of losing data,of course—or losslessly if we use “backslashreplace” which replaces non-ASCII characters with \\x, \\u, and \\U escapes. For example, artist.encode(\"ascii\", \"ignore\") will produce b'Tage sn' and artist.encode(\"ascii\", \"replace\") will produce b'Tage ?s?n', whereas artist.encode(\"ascii\", \"backslashreplace\") will produce b'Tage \\xc5s\\xe9n'. (We can also get an ASCII string using \"{0!a}\".format(artist), which produces 'Tage \\xc5s\\xe9n'.)\n\nThe complement of str.encode() is bytes.decode() (and bytearray.decode()) which returns a string with the bytes decoded using the given encoding. For example:\n\n>>> print(b\"Tage \\xc3\\x85s\\xc3\\xa9n\".decode(\"utf8\"))\n\nTage Åsén\n\n93",
      "content_length": 2511,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 104,
      "content": "94\n\nChapter 2. Data Types\n\n>>> print(b\"Tage \\xc5s\\xe9n\".decode(\"latin1\"))\n\nTage Åsén\n\nThe differences between the 8-bit Latin-1, CP850 (an IBM PC encoding), and UTF-8 encodings make it clear that guessing encodings is not likely to be a successful strategy. Fortunately, UTF-8 is becoming the de facto standard for plain text ﬁles, so later generations may not even know that other encodings ever existed.\n\nPython .py ﬁles use UTF-8, so Python always knows the encoding to use with string literals. This means that we can type any Unicode characters into our strings—providing our editor supports this.★\n\nWhen Python readsdata from external sourcessuch as sockets,it cannot know what encoding is used,so it returnsbytes which we can then decode according- ly. For textﬁlesPythontakesa softerapproach,using thelocalencoding unless we specify an encoding explicitly.\n\nFortunately, some ﬁle formats specify their encoding. For example, we can as- sumethat an XML ﬁle usesUTF-8,unlessthe <?xml?> directiveexplicitly speci- ﬁes a different encoding. So when reading XML we might extract,say,the ﬁrst 1000 bytes, look for an encoding speciﬁcation, and if found, decode the ﬁle us- ing thespeciﬁedencoding,otherwisefalling backtodecodingusing UTF-8.This approach should work for any XML or plain text ﬁle that uses any of the sin- gle byte encodings supported by Python, except for EBCDIC-based encodings (CP424,CP500)and a fewothers(CP037,CP864,CP865,CP1026,CP1140,HZ, SHIFT-JIS-2004, SHIFT-JISX0213). Unfortunately, this approach won’t work for multibyte encodings (such as UTF-16 and UTF-32). At least two Python packages for automatically detecting a ﬁle’s encoding are available from the Python Package Index, pypi.python.org/pypi.\n\nExamples\n\n|||\n\nIn this section we will draw on what we have covered in this chapter and the one before, to present two small but complete programs to help consolidate what we have learned so far. The ﬁrst program is a bit mathematical,but it is quite short at around 35 lines. The second is concerned with text processing and is more substantial, with seven functions in around 80 lines of code.\n\nquadratic.py\n\n||\n\nQuadratic equations are equations of the form 2ax + bx + c = 0 where a ≠ 0 describe parabolas. The roots of such equations are derived from the formula\n\n★It is possible to use other encodings. See the Python Tutorial’s “Source Code Encoding” topic.",
      "content_length": 2394,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 105,
      "content": "Examples\n\nx = −b±√ 2 2 b −4ac b − 4ac part of the formula is called the discriminant—if it 2a is positive there are two real roots,if it is zero there is one real root, and if it is negative there are two complex roots. We will writea programthat acceptsthe a, b, and c factors from the user (with the b and c factors allowed to be 0), and then calculates and outputs the root or roots.★\n\n. The\n\nFirst we will look at a sample run, and then we will review the code.\n\nquadratic.py ax² + bx + c = 0 enter a: 2.5 enter b: 0 enter c: -7.25 2.5x² + 0.0x + -7.25 = 0 → x = 1.70293863659 or x = -1.70293863659\n\nWith factors 1.5, -3, and 6, the output (with some digits trimmed) is:\n\n1.5x² + -3.0x + 6.0 = 0 → x = (1+1.7320508j) or x = (1-1.7320508j)\n\nThe output isn’t quite as tidy as we’d like—for example, rather than + -3.0x it would be nicer to have - 3.0x, and we would prefer not to have any 0 factors shown at all. You will get the chance to ﬁx these problems in the exercises.\n\nNow we will turn to the code, which begins with three imports:\n\nimport cmath import math import sys\n\nWe need both the float and the complex math libraries since the square root functions for real and complex numbers are different, and we need sys for sys.float_info.epsilon which we need to compare ﬂoating-point numbers with 0.\n\nWe also need a function that can get a ﬂoating-point number from the user:\n\ndef get_float(msg, allow_zero):\n\nx = None while x is None:\n\ntry:\n\nx = float(input(msg)) if not allow_zero and abs(x) < sys.float_info.epsilon:\n\nprint(\"zero is not allowed\") x = None\n\n★Since the Windows console has poor UTF-8 support, there are problems with a couple of the characters(² and →) that quadratic.pyuses. We have provided quadratic_uni.pywhich displaysthe correct symbols on Linux and Mac OS X, and alternatives (^2 and ->) on Windows.\n\n95",
      "content_length": 1836,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 106,
      "content": "96\n\nChapter 2. Data Types\n\nexcept ValueError as err:\n\nprint(err)\n\nreturn x\n\nThisfunctionwillloopuntiltheuser entersa validﬂoating-pointnumber (such as 0.5, -9, 21, 4.92), and will accept 0 only if allow_zero is True.\n\nOnce the get_float() function is deﬁned,the rest of the code is executed. We’ll look at it in three parts, starting with the user interaction:\n\nprint(\"ax\\N{SUPERSCRIPT TWO} + bx + c = 0\") a = get_float(\"enter a: \", False) b = get_float(\"enter b: \", True) c = get_float(\"enter c: \", True)\n\nThanksto the get_float() function,getting the a,b,and c factorsissimple. The Boolean second argument says whether 0 is acceptable.\n\nx1 = None x2 = None discriminant = (b ** 2) - (4 * a * c) if discriminant == 0:\n\nx1 = -(b / (2 * a))\n\nelse:\n\nif discriminant > 0:\n\nroot = math.sqrt(discriminant)\n\nelse: # discriminant < 0\n\nroot = cmath.sqrt(discriminant)\n\nx1 = (-b + root) / (2 * a) x2 = (-b - root) / (2 * a)\n\nThe code looks a bit different to the formula because we begin by calculating the discriminant. If the discriminant is 0, we know that we have one real solution and so we calculate it directly. Otherwise,we take the real or complex square root of the discriminant and calculate the two roots.\n\nequation = (\"{0}x\\N{SUPERSCRIPT TWO} + {1}x + {2} = 0\"\n\n\" \\N{RIGHTWARDS ARROW} x = {3}\").format(a, b, c, x1)\n\nif x2 is not None:\n\nequation += \" or x = {0}\".format(x2)\n\nprint(equation)\n\nWehaven’tdoneany fancy formatting sincePython’sdefaultsfor ﬂoating-point numbers are ﬁne for this example, but we have used Unicode character names for a couple of special characters.",
      "content_length": 1578,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 107,
      "content": "Us- ing str. format() with map- ping un- packing 81➤\n\nExamples\n\nA more robust alternative to using positional argumentswith their index posi- tions as ﬁeld names, is to use the dictionary returned by locals(), a technique we saw earlier in the chapter.\n\nequation = (\"{a}x\\N{SUPERSCRIPT TWO} + {b}x + {c} = 0\"\n\n\" \\N{RIGHTWARDS ARROW} x = {x1}\").format(**locals())\n\nAnd if weareusing Python3.1,wecouldomit theﬁeldnamesandleavePython to populate the ﬁelds using the positional arguments passed to str.format().\n\nequation = (\"{}x\\N{SUPERSCRIPT TWO} + {}x + {} = 0\"\n\n\" \\N{RIGHTWARDS ARROW} x = {}\").format(a, b, c, x1)\n\nThis is convenient, but not as robust as using named parameters, nor as versatile if we needed to use format speciﬁcations. Nonetheless, for many simple cases this syntax is both easy and useful.\n\ncsv2html.py\n\nOne common requirement is to take a data set and present it using HTML. In this subsection we will develop a program that reads a ﬁle that uses a simple CSV (Comma Separated Value)format and outputsan HTML tablecontaining the ﬁle’s data. Python comes with a powerful and sophisticated module for handling CSV and similar formats—the csv module—but here we will write all the code by hand.\n\nThe CSV format we will support has one record per line, with each record divided into ﬁelds by commas. Each ﬁeld can be either a string or a number. Strings must be enclosed in single or double quotes and numbers should be unquoted unless they contain commas. Commas are allowed inside strings, and must not be treated as ﬁeld separators. We assume that the ﬁrst record contains ﬁeld labels. The output we will produce is an HTML table with text left-aligned (the default in HTML) and numbers right-aligned, with one row per record and one cell per ﬁeld.\n\nThe programmust output theHTMLtable’sopening tag,then read each lineof data and for each one output an HTML row, and at the end output the HTML table’s closing tag. We want the background color of the ﬁrst row (which will display the ﬁeld labels) to be light green, and the background of the data rows to alternate between white and light yellow. We must also make sure that the special HTML characters(“&”,“<”,and “>”) are properly escaped,and we want strings to be tidied up a bit.\n\nHere’s a tiny piece of sample data:\n\n\"COUNTRY\",\"2000\",\"2001\",2002,2003,2004 \"ANTIGUA AND BARBUDA\",0,0,0,0,0\n\n97\n\n||\n\n3.1",
      "content_length": 2376,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 108,
      "content": "98\n\nChapter 2. Data Types\n\n\"ARGENTINA\",37,35,33,36,39 \"BAHAMAS, THE\",1,1,1,1,1 \"BAHRAIN\",5,6,6,6,6\n\nAssuming the sample data is in the ﬁle data/co2-sample.csv, and given the command csv2html.py < data/co2-sample.csv > co2-sample.html, the ﬁle co2-sample.html will have contents similar to this:\n\n<table border='1'><tr bgcolor='lightgreen'> <td>Country</td><td align='right'>2000</td><td align='right'>2001</td> <td align='right'>2002</td><td align='right'>2003</td> <td align='right'>2004</td></tr> ... <tr bgcolor='lightyellow'><td>Argentina</td> <td align='right'>37</td><td align='right'>35</td> <td align='right'>33</td><td align='right'>36</td> <td align='right'>39</td></tr> ... </table>\n\nWe’ve tidied the output slightly and omitted some lines where indicated by ellipses. We have used a very simple version of HTML—HTML 4 transitional, with no style sheet. Figure 2.7 shows what the output looks like in a web browser.\n\nFigure 2.7 A csv2html.py table in a web browser\n\nNow that we’ve seen how the program is used and what it does, we are ready to review the code. The program begins with the import of the sys module; we won’t show this, or any other imports from now on, unless they are unusual or warrant discussion. And the last statement in the program is a single function call:\n\nmain()\n\nAlthough Python does not need an entry point as some languages require, it is quite common in Python programs to create a function called main() and to call it to start off processing. Since no function can be called before it has been created, we must make sure we call main() after the functions it relies on have",
      "content_length": 1616,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 109,
      "content": "Examples\n\nbeen deﬁned. The order in which the functionsappear in the ﬁle (i.e.,the order in which they are created) does not matter.\n\nIn the csv2html.py program, the ﬁrst function we call is main() which in turn calls print_start() and then print_line(). And print_line() calls extract_ fields() and escape_html(). The program structure we have used is shown in Figure 2.8.\n\nimport sys\n\ndef main():\n\ndef print_start():\n\ndef print_line():\n\ncalls\n\ndef extract_fields():\n\ncalls\n\ncalls\n\ndef escape_html():\n\ndef print_end():\n\nmain()\n\nFigure 2.8 The csv2html.py program’s structure\n\nWhen Python reads a ﬁle it begins at the top. So for this example, it starts by performing the import, then it creates the main() function, and then it creates the other functionsin the order in which they appear in the ﬁle. When Python ﬁnally reaches the call to main() at the end of the ﬁle, all the functions that main() will call (and all the functions that those functions will call) now exist. Execution as we normally think of it begins where the call to main() is made.\n\nWe will look at each function in turn, starting with main().\n\ndef main():\n\nmaxwidth = 100 print_start() count = 0 while True: try:\n\nline = input() if count == 0:\n\ncolor = \"lightgreen\"\n\nelif count % 2:\n\ncolor = \"white\"\n\nelse:\n\ncolor = \"lightyellow\"\n\n99",
      "content_length": 1307,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 110,
      "content": "100\n\nChapter 2. Data Types\n\nprint_line(line, color, maxwidth) count += 1\n\nexcept EOFError:\n\nbreak\n\nprint_end()\n\nThe maxwidth variable is used to constrain the number of characters in a cell—if a ﬁeld is bigger than this we will truncate it and signify this by adding an ellipsis to the truncated text. We’ll look at the print_start(), print_line(), and print_end() functions in a moment. The while loop iterates over each line of input—this could come from the user typing at the keyboard, but we expect it to be a redirected ﬁle. We set the color we want to use and call print_line() to output the line as an HTML table row.\n\ndef print_start():\n\nprint(\"<table border='1'>\")\n\ndef print_end():\n\nprint(\"</table>\")\n\nWe could have avoided creating these two functions and simply put the rel- evant print() function calls in main(). But we prefer to separate out the logic since this is more ﬂexible, even though it doesn’t really matter in this small example.\n\ndef print_line(line, color, maxwidth):\n\nprint(\"<tr bgcolor='{0}'>\".format(color)) fields = extract_fields(line) for field in fields: if not field:\n\nprint(\"<td></td>\")\n\nelse:\n\nnumber = field.replace(\",\", \"\") try:\n\nx = float(number) print(\"<td align='right'>{0:d}</td>\".format(round(x)))\n\nexcept ValueError:\n\nfield = field.title() field = field.replace(\" And \", \" and \") if len(field) <= maxwidth:\n\nfield = escape_html(field)\n\nelse:\n\nfield = \"{0} ...\".format(\n\nescape_html(field[:maxwidth]))\n\nprint(\"<td>{0}</td>\".format(field))\n\nprint(\"</tr>\")",
      "content_length": 1499,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 111,
      "content": "Examples\n\nWe cannot use str.split(\",\") to split each line into ﬁelds because commas can occur inside quoted strings. So we have farmed this work out to the extract_fields() function. Once we have a list of the ﬁelds (as strings,with no surrounding quotes), we iterate over them, creating a table cell for each one.\n\nIf a ﬁeld is empty, we output an empty cell. If a ﬁeld is quoted, it could be a string or it could be a number that has been quoted to allow for internal commas, for example, \"1,566\". To account for this, we make a copy of the ﬁeld with commasremovedandtry toconverttheﬁeldtoa float.If theconversionis successful we output a right-aligned cell with the ﬁeld rounded to the nearest whole number and output it asan integer. If theconversionfailswe output the ﬁeld asa string. In thiscaseweuse str.title() toneaten thecaseof theletters and we replace the word And with and as a correction to str.title()’s effect. If the ﬁeld isn’t too long we use all of it, otherwise we truncate it to maxwidth characters and add an ellipsis to signify the truncation, and in either case we escape any special HTML characters the ﬁeld might contain.\n\ndef extract_fields(line):\n\nfields = [] field = \"\" quote = None for c in line:\n\nif c in \"\\\"'\":\n\nif quote is None: # start of quoted string\n\nquote = c\n\nelif quote == c: # end of quoted string\n\nquote = None\n\nelse:\n\nfield += c\n\n# other quote inside quoted string\n\ncontinue\n\nif quote is None and c == \",\": # end of a field\n\nfields.append(field) field = \"\"\n\nelse:\n\nfield += c\n\n# accumulating a field\n\nif field:\n\nfields.append(field) # adding the last field\n\nreturn fields\n\nThis function reads the line it is given character by character, accumulating a list of ﬁelds—each one a string without any enclosing quotes. The function copes with ﬁelds that are unquoted,and with ﬁelds that are quoted with single or double quotes, and correctly handles commas and quotes (single quotes in double quoted strings, double quotes in single quoted strings).\n\n101",
      "content_length": 1993,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 112,
      "content": "102\n\nChapter 2. Data Types\n\ndef escape_html(text):\n\ntext = text.replace(\"&\", \"&amp;\") text = text.replace(\"<\", \"&lt;\") text = text.replace(\">\", \"&gt;\") return text\n\nThis function straightforwardly replaces each special HTML character with the appropriate HTML entity. We must of course replace ampersands ﬁrst, although the order doesn’t matter for the angle brackets. Python’s standard library includes a slightly more sophisticated version of this function—you’ll get the chance to use it in the exercises, and will see it again in Chapter 7.\n\nSummary\n\n|||\n\nThischapter began by showing the list of Python’skeywordsand describedthe rules that Python applies to identiﬁers. Thanks to Python’s Unicode support, identiﬁers are not limited to a subset of characters from a small character set like ASCII or Latin-1.\n\nWe also described Python’s int data type, which differs from similar types in mostotherlanguagesinthatithasnointrinsicsizelimitation. Pythonintegers canbeaslargeasthemachine’smemory willallow,andit isperfectlyfeasibleto work with numbersthat arehundredsof digitslong. All of Python’smostbasic data types are immutable, but this is rarely noticable since the augmented as- signment operators(+=,*=,-=,/=,and others)meansthat we can use a very nat- ural syntax while behind the scenes Python creates result objects and rebinds ourvariablestothem. Literalintegersareusuallywrittenasdecimalnumbers, but we can write binary literals using the 0b preﬁx, octal literals using the 0o preﬁx, and hexadecimal literals using the 0x preﬁx.\n\nWhen two integers are divided using /, the result is always a float. This is different from many other widely used languages, but helps to avoid some quite subtle bugs that can occur when division silently truncates. (And if we want integer division we can use the // operator.)\n\nPython has a bool data type which can hold either True or False. Python has three logical operators, and, or, and not, of which the two binary operators (and and or) use short-circuit logic.\n\nThree kinds of ﬂoating-point numbers are available: float, complex, and dec- imal.Decimal. The most commonly used is float; this is a double-precision ﬂoating-point number whose exact numerical characteristics depend on the underlying C, C#, or Java library that Python was built with. Complex num- bersare representedastwo floats,one holding the real value and the other the imaginary value. The decimal.Decimal type is provided by the decimal module.",
      "content_length": 2468,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 113,
      "content": "Summary\n\nThese numbersdefault to having 28 decimal placesof accuracy,but this can be increased or decreased to suit our needs.\n\nAll three ﬂoating-point types can be used with the appropriate built-in math- ematical operators and functions. And in addition,the math module provides a varietyof trigonometric,hyperbolic,andlogarithmicfunctionsthatcanbeused with floats,and the cmath moduleprovidesa similar set of functionsfor complex numbers.\n\nMost of the chapter was devoted to strings. Python string literals can be created using single quotes or double quotes, or using a triple quoted string if we want to include newlines and quotes without formality. Various escape sequences can be used to insert special characterssuch as tab (\\t) and newline (\\n), and Unicode characters both using hexadecimal escapes and Unicode character names. Although strings support the same comparison operators as other Python types, we noted that sorting strings that contain non-English characters can be problematic.\n\nSince strings are sequences, the slicing operator ([]) can be used to slice and stride strings with a very simple yet powerful syntax. Strings can also be concatenated with the + operator and replicated with the * operator, and we can also use the augmented assignment versions of these operators (+= and *=), although the str.join() method is more commonly used for concatenation. Stringshave many other methods,including some for testing string properties (e.g.,str.isspace() and str.isalpha()),somefor changing case(e.g.,str.lower() and str.title()), some for searching (e.g., str.find() and str.index()), and many others.\n\nPython’s string support is really excellent, enabling us to easily ﬁnd and extract or compare whole strings or parts of strings, to replace characters or substrings, and to split strings into a list of substrings and to join lists of strings into a single string.\n\nProbably the most versatile string method is str.format().Thismethod is used tocreatestringsusing replacementﬁeldsandvariablestogointhoseﬁelds,and format speciﬁcations to precisely deﬁne the characteristicsof each ﬁeld which isreplacedwitha value. Thereplacementﬁeldnamesyntax allowsustoaccess the method’s arguments by position or by name (for keyword arguments),and to use an index,key,or attributename to accessan argument item or attribute. The format speciﬁcations allow us to specify the ﬁll character, the alignment, and the minimum ﬁeld width. Furthermore, for numbers we can also control how the sign is output,and for ﬂoating-point numbers we can specify the num- ber of digits after the decimal point and whether to use standard or exponen- tial notation.\n\nWe also discussedthethorny issueof character encodings. Python .py ﬁlesuse the Unicode UTF-8 encoding by default and so can have comments,identiﬁers, and data written in just about any human language. We can convert a string\n\n103",
      "content_length": 2893,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 114,
      "content": "104\n\nChapter 2. Data Types\n\ninto a sequence of bytes using a particular encoding using the str.encode() method,and we can convert a sequence of bytesthat use a particular encoding back to a string using the bytes.decode() method. The wide variety of charac- ter encodings currently in use can be very inconvenient, but UTF-8 is fast be- coming the de facto standard for plain text ﬁles (and is already the default for XML ﬁles), so this problem should diminish in the coming years.\n\nIn addition to the data typescovered in thischapter,Python providestwo other built-in data types,bytes and bytearray,both of which arecoveredin Chapter7. Python also provides several collection data types, some built-in and others in the standard library. In the next chapter we will look at Python’s most important collection data types.\n\nExercises\n\n|||\n\n1. Modify the print_unicode.py program so that the user can enter several separate words on the command line, and print rows only where the Unicode character name contains all the words the user has speciﬁed. This means that we can type commands like this: print_unicode_ans.py greek symbol\n\nOne way of doing this is to replace the word variable (which held 0, None, or a string), with a words list. Don’t forget to update the usage informa- tion as well as the code. The changes involve adding less than ten lines of code, and changing less than ten more. A solution is provided in ﬁle print_unicode_ans.py. (Windows and cross-platform users should modify print_unicode_uni.py; a solution is provided in print_unicode_uni_ans.py.)\n\n2. Modify quadratic.py so that 0.0factorsare not output,and so that negative factors are output as - n rather than as + -n. This involves replacing the last ﬁve lines with about ﬁfteen lines. A solution is provided in quadrat- ic_ans.py. (Windows and cross-platform users should modify quadrat- ic_uni.py; a solution is provided in quadratic_uni_ans.py.)\n\n3. Delete the escape_html() function from csv2html.py, and use the xml.sax. saxutils.escape()functionfromthexml.sax.saxutilsmoduleinstead. This is easy,requiring one new line (the import),ﬁve deleted lines (the unwant- ed function), and one changed line (to use xml.sax.saxutils.escape() in- stead of escape_html()). A solution is provided in csv2html1_ans.py.\n\n4. Modify csv2html.py again, this time adding a new function called pro- cess_options(). This function should be called from main() and should return a tuple of two values: maxwidth (an int) and format (a str). When process_options() is called it should set a default maxwidth of 100, and a default format of “.0f”—this will be used as the format speciﬁer when out- putting numbers.",
      "content_length": 2672,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 115,
      "content": "Exercises\n\nIf theuser hastyped“-h”or “--help”on thecommandline,a usagemessage should be output and (None, None) returned. (In this case main() should do nothing.) Otherwise, the function should read any command-line arguments that are given and perform the appropriate assignments. For example, setting maxwidth if “maxwidth=n” is given, and similarly setting format if “format=s” is given. Here is a run showing the usage output:\n\ncsv2html2_ans.py -h usage: csv2html.py [maxwidth=int] [format=str] < infile.csv > outfile.html\n\nmaxwidth is an optional integer; if specified, it sets the maximum number of characters that can be output for string fields, otherwise a default of 100 characters is used.\n\nformat is the format to use for numbers; if not specified it defaults to \".0f\".\n\nAnd here is a command line with both options set:\n\ncsv2html2_ans.py maxwidth=20 format=0.2f < mydata.csv > mydata.html\n\nDon’t forget to modify print_line() to make use of the format for out- putting numbers—you’ll need to pass in an extra argument, add one line, and modify another line. And this will slightly affect main() too. The pro- cess_options() function should be about twenty-ﬁve lines (including about nine for the usage message).This exercise may prove challenging for inex- perienced programmers.\n\nTwo ﬁlesof test data are provided:data/co2-sample.csv and data/co2-from- fossilfuels.csv. A solution is provided in csv2html2_ans.py. In Chapter 5 we will see how to use Python’s optparse module to simplify command-line processing.\n\n105",
      "content_length": 1530,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 116,
      "content": "3\n\nSequence Types ● Set Types ● Mapping Types ● Iterating and Copying Collections\n\nCollection Data Types\n\n||||\n\nIn the preceding chapter we learned about Python’s most important funda- mental data types. In this chapter we will extend our programming options by learning how to gather data items together using Python’s collection data types. We will cover tuples and lists, and also introduce new collection data types, including sets and dictionaries, and cover all of them in depth.★\n\nIn addition to collections, we will also see how to create data items that are aggregates of other data items (like C or C++ structs or Pascal records)—such items can be treated as a single unit when this is convenient for us, while the items they contain remain individually accessible. Naturally, we can put aggregated items in collections just like any other items.\n\nHaving data items in collections makes it much easier to perform operations that must be applied to all of the items, and also makes it easier to handle col- lections of items read in from ﬁles. We’ll cover the very basics of text ﬁle han- dling in this chapter as we need them, deferring most of the detail (including error handling) to Chapter 7.\n\nAfter covering the individual collection data types, we will look at how to it- erate over collections, since the same syntax is used for all of Python’s collec- tions, and we will also explore the issues and techniques involved in copying collections.\n\nSequence Types\n\n|||\n\nA sequence type is one that supports the membership operator (in), the size function (len()), slices ([]), and is iterable. Python provides ﬁve built-in se- quence types: bytearray, bytes, list, str, and tuple—the ﬁrst two are covered\n\n★The deﬁnitions of what constitutes a sequence type, a set type, or a mapping type given in this chapter are practical but informal. More formal deﬁnitions are given in Chapter 8.\n\n107",
      "content_length": 1903,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 117,
      "content": "Strings 65➤\n\nString slicing and striding 69➤\n\n108\n\nChapter 3. Collection Data Types\n\nseparately in Chapter 7. Some other sequence types are provided in the stan- dard library, most notably, collections.namedtuple. When iterated, all of these sequences provide their items in order.\n\nWe covered strings in the preceding chapter. tuples, named tuples, and lists.\n\nIn this section we will cover\n\nTuples\n\nA tuple is an ordered sequence of zero or more object references. Tuples strings. This makes it easy to support the same slicing and striding syntax as extract items from a tuple. Like strings, tuples are immutable, so we cannot replace or delete any of their items. If we want to be able to modify an ordered sequence, we simply use a list instead of a tuple; or if we already have a tuple but want to modify it, we can convert it to a list using the list() conversion function and then apply the changes to the resultant list.\n\nThe tuple data type can be called as a function, tuple()—with no arguments it returns an empty tuple, with a tuple argument it returns a shallow copy of the argument, and with any other argument it attempts to convert the given object to a tuple. It does not accept more than one argument. Tuples can also be created without using the tuple() function. An empty tuple iscreated using empty parentheses,(),and a tupleof oneor moreitemscan becreatedby using commas. Sometimestuplesmust be enclosed in parenthesesto avoid syntactic ambiguity. For example, to pass the tuple 1, 2, 3 to a function, we would write function((1, 2, 3)).\n\nFigure 3.1 shows the tuple t = \"venus\", -28, \"green\", \"21\", 19.74, and the index positions of the items inside the tuple. Strings are indexed in the same way, but whereas strings have a character at every position, tuples have an object reference at each position.\n\nt[-5]\n\nt[-4]\n\nt[-3]\n\nt[-2]\n\nt[-1]\n\n'venus'\n\n28\n\n'green'\n\n'21'\n\n19.74\n\nt[0]\n\nt[1]\n\nt[2]\n\nt[3]\n\nt[4]\n\nFigure 3.1 Tuple index positions\n\nTuples provide just two methods, t.count(x), which returns the number of timesobject x occursintuplet,and t.index(x),whichreturnstheindex position of the leftmost occurrence of object x in tuple t—or raises a ValueError excep- tion if there is no x in the tuple. (These methods are also available for lists.)\n\nIn addition, tuples can be used with the operators + (concatenation), * (repli- cation), and [] (slice), and with in and not in to test for membership. The += and *= augmented assignment operators can be used even though tuples are\n\n||\n\nShallow and deep copying ➤ 146",
      "content_length": 2539,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 118,
      "content": "Sequence Types\n\nimmutable—behind the scenes Python creates a new tuple to hold the result and sets the left-hand object reference to refer to it;the same technique is used when these operatorsare applied to strings. Tuplescan be compared using the standard comparison operators (<, <=, ==, !=, >=, >), with the comparisons being applied item by item (and recursively for nested items such as tuples inside tuples).\n\nLet’s look at a few slicing examples, starting with extracting one item, and a slice of items:\n\n>>> hair = \"black\", \"brown\", \"blonde\", \"red\" >>> hair[2] 'blonde' >>> hair[-3:] # same as: hair[1:] ('brown', 'blonde', 'red')\n\nThese work the same for strings, lists, and any other sequence type.\n\n>>> hair[:2], \"gray\", hair[2:] (('black', 'brown'), 'gray', ('blonde', 'red'))\n\nHerewetriedtocreatea new 5-tuple,but ended upwith a 3-tuplethat contains two 2-tuples. This happened because we used the comma operator with three items (a tuple,a string,and a tuple).To get a single tuple with all the items we must concatenate tuples:\n\n>>> hair[:2] + (\"gray\",) + hair[2:] ('black', 'brown', 'gray', 'blonde', 'red')\n\nTo make a 1-tuple the comma is essential, but in this case, if we had just put in the comma we would get a TypeError (since Python would think we were trying to concatenate a string and a tuple), so here we must have the comma and parentheses.\n\nIn this book (from this point on), we will use a particular coding style when writing tuples. When we have tupleson the left-hand side of a binary operator or on the right-hand side of a unary statement, we will omit the parentheses, and in all other cases we will use parentheses. Here are a few examples:\n\na, b = (1, 2)\n\n# left of binary operator\n\ndel a, b\n\n# right of unary statement\n\ndef f(x):\n\nreturn x, x ** 2\n\n# right of unary statement\n\nfor x, y in ((1, 1), (2, 4), (3, 9)): # left of binary operator\n\nprint(x, y)\n\n109",
      "content_length": 1896,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 119,
      "content": "110\n\nChapter 3. Collection Data Types\n\nThere is no obligation to follow this coding style; some programmers prefer to alwaysuseparentheses—whichisthesameasthetuplerepresentationalform, whereas others use them only if they are strictly necessary.\n\n>>> eyes = (\"brown\", \"hazel\", \"amber\", \"green\", \"blue\", \"gray\") >>> colors = (hair, eyes) >>> colors[1][3:-1] ('green', 'blue')\n\nHere we have nested two tuplesinside another tuple. Nested collectionsto any level of depth can be created like this without formality. The slice operator [] can be applied to a slice, with as many used as necessary. For example:\n\n>>> things = (1, -7.5, (\"pea\", (5, \"Xyz\"), \"queue\")) >>> things[2][1][1][2] 'z'\n\nLet’s look at this piece by piece, beginning with things[2] which gives us the third item in the tuple (since the ﬁrst item has index 0), which is itself a tu- ple, (\"pea\", (5, \"Xyz\"), \"queue\"). The expression things[2][1] gives us the second item in the things[2] tuple, which is again a tuple, (5, \"Xyz\"). And things[2][1][1] givesus the second item in thistuple,which is the string \"Xyz\". Finally,things[2][1][1][2] givesusthethirditem(character)inthestring,that is, \"z\".\n\nTuples are able to hold any items of any data type, including collection types such as tuples and lists, since what they really hold are object references. Using complex nested data structures like this can easily become confusing. One solution is to give names to particular index positions. For example:\n\n>>> MANUFACTURER, MODEL, SEATING = (0, 1, 2) >>> MINIMUM, MAXIMUM = (0, 1) >>> aircraft = (\"Airbus\", \"A320-200\", (100, 220)) >>> aircraft[SEATING][MAXIMUM] 220\n\nThis is certainly more meaningful than writing aircraft[2][1], but it involves creating lots of variables and is rather ugly. We will see an alternative in the next subsection.\n\nIn the ﬁrst two lines of the “aircraft” code snippet, we assigned to tuples in both statements. When we have a sequence on the right-hand side of an assignment (here we have tuples), and we have a tuple on the left-hand side, we say that the right-hand side has been unpacked. Sequence unpacking can be used to swap values, for example:\n\na, b = (b, a)",
      "content_length": 2161,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 120,
      "content": "Sequence Types\n\nStrictly speaking,the parenthesesare not needed on the right,but as we noted earlier, the coding style used in this book is to omit parentheses for left-hand operands of binary operators and right-hand operands of unary statements, but to use parentheses in all other cases.\n\nWe have already seen examples of sequence unpacking in the context of for … in loops. Here is a reminder:\n\nfor x, y in ((-3, 4), (5, 12), (28, -45)):\n\nprint(math.hypot(x, y))\n\nHere we loop over a tuple of 2-tuples, unpacking each 2-tuple into variables x and y.\n\nNamed Tuples\n\nA named tuple behaves just like a plain tuple, and has the same performance characteristics. What it adds is the ability to refer to items in the tuple by name as well as by index position, and this allows us to create aggregates of data items.\n\nThe collections module provides the namedtuple() function. This function is used to create custom tuple data types. For example:\n\nSale = collections.namedtuple(\"Sale\",\n\n\"productid customerid date quantity price\")\n\nThe ﬁrst argument to collections.namedtuple() isthename of the customtuple data typethat wewant tobecreated. Thesecondargumentisa string of space- separated names, one for each item that our custom tuples will take. The ﬁrst argument, and the names in the second argument, must all be valid Python identiﬁers. The function returns a custom class (data type) that can be used to create named tuples. So, in this case, we can treat Sale just like any other Python class (such as tuple), and create objects of type Sale.(In object-oriented terms, every class created this way is a subclass of tuple; object-oriented pro- gramming, including subclassing, is covered in Chapter 6.)\n\nHere is an example:\n\nsales = [] sales.append(Sale(432, 921, \"2008-09-14\", 3, 7.99)) sales.append(Sale(419, 874, \"2008-09-15\", 1, 18.49))\n\nHere we have created a list of two Sale items,that is,of two custom tuples. We can refer to itemsin the tuplesusing index positions—for example,the price of the ﬁrst sale item is sales[0][-1] (i.e.,7.99)—but we can also use names,which makes things much clearer:\n\n111\n\n||",
      "content_length": 2116,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 121,
      "content": "Us- ing str. format() with map- ping un- packing 81➤\n\n112\n\nChapter 3. Collection Data Types\n\ntotal = 0 for sale in sales:\n\ntotal += sale.quantity * sale.price\n\nprint(\"Total ${0:.2f}\".format(total)) # prints: Total $42.46\n\nThe clarity and convenience that named tuples provide are often useful. For example, here is the “aircraft” example from the previous subsection (110 ➤) done the nice way:\n\n>>> Aircraft = collections.namedtuple(\"Aircraft\", ... >>> Seating = collections.namedtuple(\"Seating\", \"minimum maximum\") >>> aircraft = Aircraft(\"Airbus\", \"A320-200\", Seating(100, 220)) >>> aircraft.seating.maximum 220\n\n\"manufacturer model seating\")\n\nWhen it comes to extracting named tuple items for use in strings there are three main approaches we can take.\n\n>>> print(\"{0} {1}\".format(aircraft.manufacturer, aircraft.model)) Airbus A320-200\n\nHere we have accessed each of the tuple’s items that we are interested in using named tuple attribute access. This gives us the shortest and simplest format string. (And in Python 3.1 we could reduce this format string to just \"{} {}\".) But this approach means that we must look at the arguments passed to str.format() to see what the replacement textswill be. Thisseemslessclear than using named ﬁelds in the format string.\n\n\"{0.manufacturer} {0.model}\".format(aircraft)\n\nHere we have used a single positional argument and used named tuple at- tribute names as ﬁeld names in the format string. This is much clearer than just using positional arguments alone, but it is a pity that we must speci- fy the positional value (even when using Python 3.1). Fortunately, there is a nicer way.\n\nNamed tuples have a few private methods—that is, methods whose name begins with a leading underscore. One of them—namedtuple._asdict()—is so useful that we will show it in action.★\n\n\"{manufacturer} {model}\".format(**aircraft._asdict())\n\nThe private namedtuple._asdict() method returns a mapping of key–value pairs,where each key is the name of a tuple element and each value is the cor-\n\n★Private methods such as namedtuple._asdict()are not guaranteed to be availablein all Python 3.x versions; although the namedtuple._asdict()method is available in both Python 3.0 and 3.1.",
      "content_length": 2203,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 122,
      "content": "String slicing and striding 69➤\n\nSequence Types\n\nresponding value. We have used mapping unpacking to convert the mapping into key–value arguments for the str.format() method.\n\nAlthough named tuples can be very convenient, in Chapter 6 we introduce object-oriented programming, and there we will go beyond simple named tuplesand learn how to create custom data typesthat hold data itemsand that also have their own custom methods.\n\nLists\n\nA list is an ordered sequence of zero or more object references. Lists support the same slicing and striding syntax as strings and tuples. This makes it easy to extract items from a list. Unlike strings and tuples, lists are mutable, so we can replace and delete any of their items. It is also possible to insert, replace, and delete slices of lists.\n\nThe list data type can be called as a function, list()—with no arguments it returns an empty list, with a list argument it returns a shallow copy of the argument,and with any other argument it attemptsto convert thegiven object to a list.It does not accept more than one argument. Lists can also be created without using the list() function. An empty list iscreated using empty brack- ets, [], and a list of one or more items can be created by using a comma-sepa- rated sequence of itemsinside brackets. Another way of creating listsisto use a list comprehension—a topic we will cover later in this subsection.\n\nSince all the items in a list are really object references, lists, like tuples, can hold items of any data type, including collection types such as lists and tuples. Listscan be comparedusing thestandardcomparisonoperators(<,<=,==,!=,>=, >),with the comparisonsbeing applied item by item (and recursively for nested items such as lists or tuples inside lists).\n\nGiven the assignment L = [-17.5, \"kilo\", 49, \"V\", [\"ram\", 5, \"echo\"], 7],we get the list shown in Figure 3.2.\n\nL[-6]\n\nL[-5]\n\nL[-4]\n\nL[-3]\n\nL[-2]\n\nL[-1]\n\n17.5\n\n'kilo'\n\n49\n\n'V'\n\n['ram', 5, 'echo']\n\n7\n\nL[0]\n\nL[1]\n\nL[2]\n\nL[3]\n\nL[4]\n\nL[5]\n\nFigure 3.2 List index positions\n\nAnd given this list, L, we can use the slice operator—repeatedly if neces- sary—to access items in the list, as the following equalities show:\n\nL[0] == L[-6] == -17.5 L[1] == L[-5] == 'kilo' L[1][0] == L[-5][0] == 'k'\n\n113\n\n||\n\nShallow and deep copying ➤ 146\n\nList compre- hen- sions ➤ 118",
      "content_length": 2321,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 123,
      "content": "114\n\nChapter 3. Collection Data Types\n\nL[4][2] == L[4][-1] == L[-2][2] == L[-2][-1] == 'echo' L[4][2][1] == L[4][2][-3] == L[-2][-1][1] == L[-2][-1][-3] == 'c'\n\nLists can be nested, iterated over, and sliced, the same as tuples. In fact, all the tuple examples presented in the preceding subsection would work exactly the same if we used lists instead of tuples. Lists support membership testing with in and not in, concatenation with +,extending with += (i.e.,the appending of all the items in the right-hand operand),and replication with * and *=.Lists can also be used with the built-in len() function, and with the del statement discussed here and described in the sidebar “Deleting Items Using the del Statement” (➤ 116). In addition, lists provide the methods shown in Table 3.1.\n\nAlthough we can use the slice operator to access items in a list, in some situa- tions we want to take two or more pieces of a list in one go. This can be done by sequenceunpacking. Any iterable(lists,tuples,etc.) canbeunpackedusing thesequenceunpacking operator,anasterisk or star(*).Whenusedwithtwoor morevariableson theleft-hand sideof an assignment,oneof which ispreceded by *,itemsare assigned to the variables,with all those left over assigned to the starred variable. Here are some examples:\n\n>>> first, *rest = [9, 2, -4, 8, 7] >>> first, rest (9, [2, -4, 8, 7]) >>> first, *mid, last = \"Charles Philip Arthur George Windsor\".split() >>> first, mid, last ('Charles', ['Philip', 'Arthur', 'George'], 'Windsor') >>> *directories, executable = \"/usr/local/bin/gvim\".split(\"/\") >>> directories, executable (['', 'usr', 'local', 'bin'], 'gvim')\n\nWhen the sequence unpacking operator is used like this, the expression *rest, and similar expressions, are called starred expressions.\n\nPython also has a related concept called starred arguments.For example,if we have the following function that requires three arguments:\n\ndef product(a, b, c):\n\nreturn a * b * c #here, * is the multiplication operator\n\nwe can call it with three arguments, or by using starred arguments:\n\n>>> product(2, 3, 5) 30 >>> L = [2, 3, 5] >>> product(*L) 30 >>> product(2, *L[1:]) 30",
      "content_length": 2145,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 124,
      "content": "Sequence Types\n\n115\n\nTable 3.1 List Methods\n\nSyntax\n\nDescription\n\nL.append(x)\n\nAppends item x to the end of list L\n\nL.count(x)\n\nReturns the number of times item x occurs in list L\n\nL.extend(m) L += m\n\nAppends all of iterable m’s items to the end of list L; the operator += does the same thing\n\nL.index(x, start, end)\n\nReturns the index position of the leftmost occurrence of item x in list L (or in the start:end slice of L); otherwise, raises a ValueError exception\n\nL.insert(i, x)\n\nInserts item x into list L at index position int i\n\nL.pop()\n\nReturns and removes the rightmost item of list L\n\nL.pop(i)\n\nReturns and removes the item at index position int i in L\n\nL.remove(x)\n\nRemoves the leftmost occurrence of item x from list L, or raises a ValueError exception if x is not found\n\nL.reverse()\n\nReverses list L in-place\n\nL.sort(...)\n\nSorts list L in-place;this method accepts reverse optional arguments as the built-in sorted()\n\nthe same key and\n\nIn the ﬁrst call we provide the three arguments normally. In the second call we use a starred argument—what happens here is that the three-item list is unpackedby the * operator,soasfar asthefunctionisconcernedit hasreceived the three arguments it is expecting. We could have achieved the same thing using a3-tuple. Andinthethirdcallwepasstheﬁrstargumentconventionally, and the other two argumentsby unpacking a two-item slice of the L list. Func- tions and argument passing are covered fully in Chapter 4.\n\nThere is never any syntactic ambiguity regarding whether operator * is the multiplication or the sequence unpacking operator. When it appears on the left-hand side of an assignment it is the unpacking operator, and when it appears elsewhere (e.g., in a function call) it is the unpacking operator when used as a unary operator and the multiplication operator when used as a binary operator.\n\nWe have already seen that we can iterate over the items in a list using the syntax for item in L:. If we want to change the items in a list the idiom to use is:\n\nfor i in range(len(L)):\n\nL[i] = process(L[i])\n\nThe built-in range() function returns an iterator that provides integers. With one integer argument, n, the iterator range() returns, producing 0, 1, …, n - 1.\n\nsorted() ➤ 140, 144\n\nrange() ➤ 141",
      "content_length": 2253,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 125,
      "content": "116\n\nChapter 3. Collection Data Types\n\nDeleting Items Using the del Statement\n\nAlthough the name of the del statement is reminiscent of the word delete, it does not necessarily delete any data. When applied to an object reference that refers to a data item that is not a collection, the del statement unbinds the object reference from the data item and deletes the object reference. For example:\n\n>>> x = 8143 # object ref. 'x' created; int of value 8143 created >>> x 8143 >>> del x # object ref. 'x' deleted; int ready for garbage collection >>> x Traceback (most recent call last): ... NameError: name 'x' is not defined\n\nWhen an object reference is deleted, Python schedules the data item to which it referredto be garbage-collected if no other object referencesrefer to thedataitem. When,orevenif,garbagecollectiontakesplacemay benonde- terministic (depending on the Python implementation),so if any cleanup is required we must handle it ourselves. Python provides two solutions to the nondeterminism. One is to use a try …finally block to ensure that cleanup is done, and another is to use a with statement as we will see in Chapter 8.\n\nWhen del is used on a collection data type such as a tuple or a list, only the object referenceto the collection isdeleted. The collection and itsitems(and for those items that are themselves collections, for their items, recursively) are scheduled for garbage collection if no other object references refer to the collection.\n\nFor mutable collections such as lists, del can be applied to individual items or slices—in both cases using the slice operator, []. If the item or items referred to are removed from the collection, and if there are no other object references referring to them, they are scheduled for garbage collection.\n\nWe could use this technique to increment all the numbers in a list of integers. For example:\n\nfor i in range(len(numbers)):\n\nnumbers[i] += 1\n\nSince lists support slicing, in several cases the same effect can be achieved using either slicing or one of thelist methods. For example,given thelist woods = [\"Cedar\", \"Yew\", \"Fir\"], we can extend the list in either of two ways:\n\nwoods += [\"Kauri\", \"Larch\"]\n\nwoods.extend([\"Kauri\", \"Larch\"])",
      "content_length": 2211,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 126,
      "content": "Slicing and striding 69➤\n\nSequence Types\n\nIn either case the result is the list ['Cedar', 'Yew', 'Fir', 'Kauri', 'Larch'].\n\nIndividual items can be added at the end of a list using list.append(). Items can be inserted at any index position within the list using list.insert(), or by assigning to a slice of length 0. For example, given the list woods = [\"Cedar\", \"Yew\", \"Fir\", \"Spruce\"], we can insert a new item at index position 2 (i.e., as the list’s third item) in either of two ways:\n\nwoods[2:2] = [\"Pine\"]\n\nwoods.insert(2, \"Pine\")\n\nIn both cases the result is the list ['Cedar', 'Yew', 'Pine', 'Fir', 'Spruce'].\n\nIndividual items can be replaced in a list by assigning to a particular index position, for example, woods[2] = \"Redwood\". Entire slices can be replaced by assigning an iterable to a slice, for example, woods[1:3] = [\"Spruce\", \"Sugi\", \"Rimu\"].Thesliceandtheiterabledon’thavetobethesamelength. In allcases, the slice’s items are removed and the iterable’s items are inserted. This makes the list shorter if the iterable has fewer items than the slice it replaces, and longer if the iterable has more items than the slice.\n\nTo make what happens when assigning an iterable to a slice really clear, we will consider one further example. Imagine that we have the list L = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"], and that we assign an iterable (in this case, a list) to a slice of it with the code L[2:5] = [\"X\", \"Y\"]. First, the slice is removed, so behind the scenes the list becomes ['A', 'B', 'F']. And then all the iterable’s items are inserted at the slice’s start position, so the resultant list is ['A', 'B', 'X', 'Y', 'F'].\n\nItems can be removed in a number of other ways. We can use list.pop() with no arguments to remove the rightmost item in a list—the removed item is also returned. Similarly we can use list.pop() with an integer index argument to remove (and return) an item at a particular index position. Another way of removing an item is to call list.remove() with the item to be removed as the argument. The del statementcan also be used to removeindividualitems—for example, del woods[4]—or to remove slicesof items. Slicescan also be removed by assigning an empty list to a slice, so these two snippets are equivalent:\n\nwoods[2:4] = []\n\ndel woods[2:4]\n\nIn the left-hand snippet we have assigned an iterable (an empty list) to a slice, so ﬁrst the slice is removed, and since the iterable to insert is empty, no insertion takes place.\n\nWhen we ﬁrst covered slicing and striding, we did so in the context of strings where striding wasn’t very interesting. But in the case of lists,striding allows us to access every n-th item which can often be useful. For example, suppose we have the list, x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], and we want to set every odd-indexed item (i.e., x[1], x[3],etc.) to 0.We can access every second item by\n\n117",
      "content_length": 2864,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 127,
      "content": "118\n\nChapter 3. Collection Data Types\n\nstriding, for example, x[::2]. But this will give us the items at index positions 0, 2, 4, and so on. We can ﬁx this by giving an initial starting index, so now we have x[1::2], and this gives us a slice of the items we want. To set each item in the slice to 0, we need a list of 0s, and this list must have exactly the same number of 0s as there are items in the slice.\n\nHere is the complete solution: x[1::2] = [0] * len(x[1::2]). Now list x is [1, 0, 3, 0, 5, 0, 7, 0, 9, 0].We used the replication operator *,to produce a list consisting of the number of 0s we needed based on the length (i.e.,the number of items)of the slice. The interesting aspect isthat when we assign the list [0, 0, 0, 0, 0] to the strided slice, Python correctly replaces x[1]’s value with the ﬁrst 0, x[3]’s value with the second 0, and so on.\n\nLists can be reversed and sorted in the same way as any other iterable using the built-in reversed() and sorted() functionscovered in the Iteratorsand Iter- able Operations and Functions subsection (➤ 138). Lists also have equivalent methods, list.reverse() and list.sort(), both of which work in-place (so they don’t return anything), the latter accepting the same optional arguments as sorted(). One common idiom is to case-insensitively sort a list of strings—for example, we could sort the woods list like this: woods.sort(key=str.lower). The key argument is used to specify a function which is applied to each item, and whose return value is used to perform the comparisons used when sorting. As we noted in the previous chapter’s section on string comparisons (68 ➤), for languages other than English, sorting strings in a way that is meaningful to humans can be quite challenging.\n\nFor inserting items,listsperform best when itemsare added or removed at the end (list.append(), list.pop()).The worst performance occurs when we search for items in a list, for example, using list.remove() or list.index(), or using in for membership testing. If fast searching or membership testing is required, a set or a dict (both covered later in this chapter) may be a more suitable collectionchoice. Alternatively,listscan providefast searching if they arekept in order by sorting them—Python’ssort algorithm is especially well optimized for sorting partially sorted lists—and using a binary search (provided by the bisect module), to ﬁnd items. (In Chapter 6 we will create an intrinsically sorted custom list class.)\n\nList Comprehensions\n\nSmall lists are often created using list literals, but longer lists are usually createdprogrammatically. For a listof integerswecanuse list(range(n)),or if we just need an integer iterator, range() is sufﬁcient,but for other lists using a for …in loopisvery common. Suppose,for example,thatwewantedtoproduce a list of the leap years in a given range. We might start out like this:\n\nleaps = [] for year in range(1900, 1940):\n\n|\n\nsorted() ➤ 140, 144",
      "content_length": 2946,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 128,
      "content": "Sequence Types\n\n119\n\nif (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n\nleaps.append(year)\n\nWhen the built-in range() function is given two integer arguments, the iterator it returns produces the integers n, n + 1, …, m - 1.\n\nn and m,\n\nOf course,if we knew the exact range beforehand we could use a list literal,for example, leaps = [1904, 1908, 1912, 1916, 1920, 1924, 1928, 1932, 1936].\n\nA list comprehension is an expression and a loop with an optional condition enclosed in brackets where the loop is used to generate items for the list, and where the condition can ﬁlter out unwanted items. The simplest form of a list comprehension is this:\n\n[item for item in iterable]\n\nThis will return a list of every item in the iterable, and is semantically no different from list(iterable).Two things that make list comprehensionsmore interesting and powerful are that we can use expressions,and we can attach a condition—this takes us to the two general syntaxes for list comprehensions:\n\n[expression for item in iterable] [expression for item in iterable if condition]\n\nThe second syntax is equivalent to:\n\ntemp = [] for item in iterable: if condition:\n\ntemp.append(expression)\n\nNormally, the expression will either be or involve the item. Of course, the list comprehension does not need the temp variable needed by the for … in loop version.\n\nNow we can rewrite the code to generate the leaps list using a list comprehen- sion. We will developthe codein threestages. First we will generatea list that has all the years in the given range:\n\nleaps = [y for y in range(1900, 1940)]\n\nThis could also be done using leaps = list(range(1900, 1940)). Now we’ll add a simple condition to get every fourth year:\n\nleaps = [y for y in range(1900, 1940) if y % 4 == 0]\n\nFinally, we have the complete version:\n\nleaps = [y for y in range(1900, 1940)\n\nif (y % 4 == 0 and y % 100 != 0) or (y % 400 == 0)]\n\nrange() ➤ 141",
      "content_length": 1911,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 129,
      "content": "120\n\nChapter 3. Collection Data Types\n\nUsing a list comprehension in this case reduced the code from four lines to two—a small savings, but one that can add up quite a lot in large projects.\n\nSince list comprehensions produce lists,that is, iterables,and since the syntax for list comprehensions requires an iterable, it is possible to nest list compre- hensions. This is the equivalent of having nested for …in loops. For example, if we wanted to generate all the possible clothing label codes for given sets of sexes, sizes, and colors, but excluding labels for the full-ﬁgured females whom the fashion industry routinely ignores, we could do so using nested for … in loops:\n\ncodes = [] for sex in \"MF\":\n\nfor size in \"SMLX\":\n\n# Male, Female # Small, Medium, Large, eXtra large\n\nif sex == \"F\" and size == \"X\":\n\ncontinue\n\nfor color in \"BGW\": # Black, Gray, White codes.append(sex + size + color)\n\nThis producesthe 21item list, ['MSB', 'MSG', …, 'FLW'].The same thing can be achieved in just a couple of lines using a list comprehension:\n\ncodes = [s + z + c for s in\"MF\" for z in \"SMLX\" for c in \"BGW\"\n\nif not (s == \"F\" and z == \"X\")]\n\nHere,each item in the list is produced by the expression s + z + c.Also,we have used subtly different logic for the list comprehension where we skip invalid sex/size combinationsin the innermost loop,whereasthe nested for …in loops version skips invalid combinations in its middle loop. Any list comprehension can be rewritten using one or more for … in loops.\n\nIf thegeneratedlist isvery large,it may bemoreefﬁcient to generateeach item as it is needed rather than produce the whole list at once. Thiscan be achieved by using a generator rather than a list comprehension. We discuss this later, in Chapter 8.\n\nSet Types\n\nA set type is a collection data type that supportsthe membership operator (in), the size function (len()), and is iterable. In addition, set types at least provide a set.isdisjoint() method, and support for comparisons, as well as support for the bitwise operators (which in the context of sets are used for union, intersection,etc.).Python provides two built-in set types:the mutable set type and the immutable frozenset. When iterated, set types provide their items in an arbitrary order.\n\n|||\n\nGenera- tors ➤ 341",
      "content_length": 2272,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 130,
      "content": "Set Types\n\nOnly hashable objects may be added to a set. Hashable objects are objects which have a __hash__() special method whose return value is alwaysthe same throughout the object’slifetime,and which can be compared for equality using the __eq__() special method. (Special methods—methods whose name begins and ends with two underscores—are covered in Chapter 6.)\n\nAll the built-in immutable data types, such as float, frozenset, int, str, and tuple, are hashable and can be added to sets. The built-in mutable data types, such as dict, list, and set, are not hashable since their hash value changes depending on the items they contain, so they cannot be added to sets.\n\nSet types can be compared using the standard comparison operators (<, <=, ==, !=, >=, >). Note that although == and != have their usual meanings, with the comparisonsbeing applied item by item (and recursively for nested itemssuch as tuples or frozen sets inside sets), the other comparison operators perform subset and superset comparisons, as we will see shortly.\n\nSets\n\nA set is an unordered collection of zero or more object references that refer to hashable objects. Sets are mutable, so we can easily add or remove items, but since they are unordered they have no notion of index position and so cannot be sliced or strided. Figure 3.3 illustrates the set created by the following code snippet:\n\nS = {7, \"veil\", 0, -29, (\"x\", 11), \"sun\", frozenset({8, 4, 7}), 913}\n\n29\n\n913\n\nfrozenset({8, 4, 7})\n\n'veil'\n\n('x', 11)\n\n0\n\n'sun'\n\n7\n\nFigure 3.3 A set is an unordered collection of unique items.\n\narguments it The set data type can be called as a function, set()—with no returns an empty set, with a set argument it returns a shallow copy of the argument,and with any other argument it attemptsto convert thegiven object to a set. It does not accept more than one argument. Nonempty sets can also be created without using the set() function,but the empty set must be created\n\n121\n\n||\n\nShallow and deep copying ➤ 146",
      "content_length": 1989,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 132,
      "content": "Set Types\n\nTable 3.2 Set Methods and Operators\n\nSyntax\n\nDescription\n\ns.add(x)\n\nAdds item x to set s if it is not already in s\n\ns.clear()\n\ns.copy()\n\nRemoves all the items from set s ❄ s\n\nReturns a shallow copy of set\n\ns.difference(t) s - t\n\ns.difference_update(t) s -= t s.discard(x)\n\ns.intersection(t) s & t\n\ns.intersection_update(t) s &= t\n\ns.isdisjoint(t)\n\ns.issubset(t) s <= t\n\ns.issuperset(t) s >= t\n\ns.pop()\n\nReturns a new set that has every item that is in set s that is not in set t❄ Removes every item that is in set t from set s\n\nRemoves item x from set s if it is in s; see also set.remove() Returns a new set that has each item that is in both set s and set Makes set s contain the intersection of itself and set t Returns True if sets s and t have no items in ❄ common ReturnsTrue if set s isequal to or a subset of set t; use s < t to test whether s is a proper subset of ❄ t Returns True if set s is equal to or a superset of set t; use s > t to test whether s is a proper superset of ❄ t Returns and removes a random item from set s, or raises a KeyError exception if s is empty\n\n❄ t\n\ns.remove(x)\n\nRemoves item x from set s, or raises a KeyError exception if x is not in s; see also set.discard()\n\ns.symmetric_ difference(t) s ^ t\n\nReturns a new set that has every item that is in set s and every item that is in set t, but exclud- ing items that are in both\n\n❄ sets\n\ns.symmetric_ difference_update(t) s ^= t s.union(t) s | t\n\ns.update(t) s |= t\n\nMakes set s contain the symmetric difference of itself and set t\n\nReturns a new set that has all the items in set s ❄ and all the items in set t that are not in set s Adds every item in set t that is not in set s, to set s\n\n❄This method and its operator (if it has one) can also be used with frozensets.\n\n123\n\nShallow and deep copying ➤ 146",
      "content_length": 1802,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 133,
      "content": "124\n\nChapter 3. Collection Data Types\n\nprocessing,once for each unique address. Assuming that the IP addresses are hashable and are in iterable ips, and that the function we want called for each one is called process_ip() and is already deﬁned, the following code snippets will do what we want, although with subtly different behavior:\n\nseen = set() for ip in ips:\n\nif ip not in seen:\n\nseen.add(ip) process_ip(ip)\n\nfor ip in set(ips):\n\nprocess_ip(ip)\n\nFor the left-hand snippet,if we haven’t processedthe IP addressbefore,we add it tothe seen setandprocessit;otherwise,weignoreit. For theright-handsnip- pet, we only ever get each unique IP address to process in the ﬁrst place. The differencesbetween thesnippetsareﬁrst that theleft-hand snippet createsthe seen set which the right-hand snippet doesn’t need, and second that the left- hand snippet processes the IP addresses in the order they are encountered in the ips iterable while the right-hand snippet processes them in an arbitrary order.\n\nThe right-hand approach is easier to code, but if the ordering of the ips iterable is important we must either use the left-hand approach or change the right-hand snippet’s ﬁrst line to something like for ip in sorted(set(ips)): if this is sufﬁcient to get the required order. In theory the right-hand approach might be slower if the number of items in ips is very large, since it creates the set in one go rather than incrementally.\n\nSets are also used to eliminate unwanted items. For example,if we have a list of ﬁlenames but don’t want any makeﬁles included (perhaps because they are generated rather than handwritten), we might write:\n\nfilenames = set(filenames) for makefile in {\"MAKEFILE\", \"Makefile\", \"makefile\"}:\n\nfilenames.discard(makefile)\n\nThis code will remove any makeﬁle that is in the list using any of the standard capitalizations. It will do nothing if no makeﬁle is in the ﬁlenames list. The same thing can be achieved in one line using the set difference (-) operator:\n\nfilenames = set(filenames) - {\"MAKEFILE\", \"Makefile\", \"makefile\"}\n\nWe can also use set.remove() to remove items, although this method raises a KeyError exception if the item it is asked to remove is not in the set.",
      "content_length": 2202,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 134,
      "content": "Set Types\n\nSet Comprehensions\n\nIn additiontocreating setsby calling set(),or by using a set literal,wecanalso createsetsusing setcomprehensions.A set comprehensionisan expressionand a loop with an optional condition enclosed in braces. Like list comprehensions, two syntaxes are supported:\n\n{expression for item in iterable} {expression for item in iterable if condition}\n\nWe can use these to achieve a ﬁltering effect (providing the order doesn’t matter).Here is an example:\n\nhtml = {x for x in files if x.lower().endswith((\".htm\", \".html\"))}\n\nGiven a list of ﬁlenames in files, this set comprehension makes the set html hold only those ﬁlenames that end in .htm or .html, regardless of case.\n\nJust like list comprehensions, the iterable used in a set comprehension can itself be a set comprehension (or any other kind of comprehension), so quite sophisticated set comprehensions can be created.\n\nFrozen Sets\n\nA frozen set is a set that, once created, cannot be changed. We can of course rebindthevariablethat referstoa frozen set torefer tosomething else,though. Frozen sets can only be created using the frozenset data type called as a function. With no arguments, frozenset() returns an empty frozen set, with a frozenset argument it returns a shallow copy of the argument, and with any other argument it attempts to convert the given object to a frozenset. It does not accept more than one argument.\n\nSince frozen sets are immutable, they support only those methods and oper- ators that produce a result without affecting the frozen set or sets to which they are applied. Table 3.2 (123 ➤) lists all the set methods—frozen sets sup- port frozenset.copy(), frozenset.difference() (-), frozenset.intersection() (&), frozenset.isdisjoint(), frozenset.issubset() (<=; also < for proper subsets), frozenset.issuperset() (>=; also > for proper supersets), frozenset.union() (|), and frozenset.symmetric_difference() (^), all of which are indicated by a in the table.\n\nIf a binary operator is used with a set and a frozen set, the data type of the result is the same as the left-hand operand’s data type. So if f is a frozen set and s is a set, f & s will produce a frozen set and s & f will produce a set. In the case of the == and != operators, the order of the operands does not matter, and f == s will produce True if both sets contain the same items.\n\n125\n\n|\n\n||\n\n❄\n\nShallow and deep copying ➤ 146",
      "content_length": 2400,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 135,
      "content": "Hash- able objects 121➤\n\n126\n\nChapter 3. Collection Data Types\n\nAnother consequence of the immutability of frozen sets is that they meet the hashable criterion for set items, so sets and frozen sets can contain frozen sets.\n\nWe will see more examples of set use in the next section, and also in the chapter’s Examples section.\n\nMapping Types\n\nA mapping type is one that supports the membership operator (in) and the size function (len()), and is iterable. Mappings are collections of key–value items and provide methods for accessing items and their keys and values. When iterated, unordered mapping types provide their items in an arbitrary order. Python 3.0 provides two unordered mapping types, the built-in dict type and the standard library’s collections.defaultdict type. A new, ordered mapping type,collections.OrderedDict,wasintroduced with Python 3.1;thisis a dictionary that has the same methods and properties (i.e., the same API) as the built-in dict, but stores its items in insertion order.★ We will use the term dictionary to refer to any of these types when the difference doesn’t matter.\n\nOnly hashableobjectsmay beused asdictionary keys,soimmutable data types such as float, frozenset, int, str, and tuple can be used as dictionary keys, but mutable typessuch as dict,list,and set cannot. On the other hand,each key’s associated value can be an object reference referring to an object of any type, including numbers, strings, lists, sets, dictionaries, functions, and so on.\n\nDictionary types can be compared using the standard equality comparison op- erators(== and !=),withthecomparisonsbeing applieditemby item(andrecur- sively for nested items such as tuples or dictionariesinside dictionaries).Com- parisons using the other comparison operators (<, <=, >=, >) are not supported since they don’t make sense for unordered collections such as dictionaries.\n\nDictionaries\n\nA dict is an unordered collection of zero or more key–value pairs whose keys are object referencesthat refer to hashableobjects,and whosevaluesareobject referencesreferring to objectsof any type. Dictionariesare mutable,so we can easily add or remove items, but since they are unordered they have no notion of index position and so cannot be sliced or strided.\n\n★API stands for Application Programming Interface, a generic term used to refer to the public methods and propertiesthat classes provide,and to the parametersand return valuesof functions and methods. For example, Python’s documentation documents the APIs that Python provides.\n\n|||\n\n||\n\n3.x",
      "content_length": 2545,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 136,
      "content": "Mapping Types\n\nThe dict data type can be called as a function, dict()—with no arguments it returns an empty dictionary, and with a mapping argument it returns a dic- tionary based on the argument; for example, returning a shallow copy if the argument is a dictionary. It is also possible to use a sequence argument, pro- viding that each item in the sequence is itself a sequence of two objects, the ﬁrst of which is used as a key and the second of which is used as a value. Alternatively,for dictionarieswhere the keysare valid Python identiﬁers,key- word argumentscan be used,with the key as the keyword and the value as the key’s value. Dictionaries can also be created using braces—empty braces, {}, createanemptydictionary;nonemptybracesmustcontainoneormorecomma- items, each of which consists of a key, a literal colon, and a value. separated Another way of creating dictionaries is to use a dictionary comprehension—a topic we will cover later in this subsection.\n\nHere are some examples to illustrate the various syntaxes—they all produce the same dictionary:\n\nd1 = dict({\"id\": 1948, \"name\": \"Washer\", \"size\": 3}) d2 = dict(id=1948, name=\"Washer\", size=3) d3 = dict([(\"id\", 1948), (\"name\", \"Washer\"), (\"size\", 3)]) d4 = dict(zip((\"id\", \"name\", \"size\"), (1948, \"Washer\", 3))) d5 = {\"id\": 1948, \"name\": \"Washer\", \"size\": 3}\n\nDictionary d1 is created using a dictionary literal. Dictionary d2 is created us- ing keyword arguments. Dictionaries d3 and d4 are created from sequences, and dictionary d5 is created from a dictionary literal. The built-in zip() func- tionthatisusedtocreatedictionary d4 returnsa listof tuples,theﬁrstof which hastheﬁrstitemsof eachof the zip() function’siterablearguments,thesecond of which hasthe second items,and so on. The keyword argument syntax (used to create dictionary d2) is usually the most compact and convenient, providing the keys are valid identiﬁers.\n\nFigure 3.5 illustrates the dictionary created by the following code snippet:\n\nd = {\"root\": 18, \"blue\": [75, \"R\", 2], 21: \"venus\", -14: None,\n\n\"mars\": \"rover\", (4, 11): 18, 0: 45}\n\nDictionary keys are unique, so if we add a key–value item whose key is the same as an existing key,the effect is to replace that key’s value with a new val- ue. Brackets are used to access individual values—for example, d[\"root\"] re- turns 18,d[21] returnsthestring \"venus\",and d[91] causesa KeyError exception to be raised, given the dictionary shown in Figure 3.5.\n\nBrackets can also be used to add and delete dictionary items. To add an item we use the = operator, for example, d[\"X\"] = 59. And to delete an item we use the del statement—for example, del d[\"mars\"] will delete the item whose key is “mars” from the dictionary, or raise a KeyError exception if no item has that\n\n127\n\nShallow and deep copying ➤ 146\n\nKey- word argu- ments ➤ 174\n\nDic- tionary compre- hen- sions ➤ 134\n\nzip() ➤ 143",
      "content_length": 2878,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 137,
      "content": "128\n\nChapter 3. Collection Data Types\n\n'mars'\n\n21\n\n(4, 11)\n\n18\n\n'rover'\n\n'venus'\n\n0\n\n'blue'\n\n14\n\n45\n\n[75, 'R', 2]\n\n'root'\n\nNone\n\n18\n\nFigure 3.5 A dictionary is an unsorted collection of (key,value) items with unique keys.\n\nkey. Items can also be removed (and returned) from the dictionary using the dict.pop() method.\n\nDictionaries support the built-in len() function, and for their keys, fast membershiptesting with in and not in.All the dictionary methodsare listed in Table 3.3.\n\nBecause dictionaries have both keys and values,we might want to iterate over a dictionary by (key, value) items, by values, or by keys. For example, here are two equivalent approaches to iterating by (key, value) pairs:\n\nfor item in d.items():\n\nfor key, value in d.items():\n\nprint(item[0], item[1])\n\nprint(key, value)\n\nIterating over a dictionary’s values is very similar:\n\nfor value in d.values():\n\nprint(value)\n\nTo iterate over a dictionary’s keys we can use dict.keys(), or we can simply treat the dictionary as an iterable that iterates over its keys, as these two equivalent code snippets illustrate:\n\nfor key in d:\n\nfor key in d.keys():\n\nprint(key)\n\nprint(key)\n\nIf we want to change the values in a dictionary, the idiom to use is to iterate over the keys and change the values using the bracketsoperator. For example, here is how we would increment every value in dictionary d, assuming that all the values are numbers:\n\nfor key in d:\n\nd[key] += 1",
      "content_length": 1437,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 138,
      "content": "Mapping Types\n\nTable 3.3 Dictionary Methods\n\nSyntax\n\nDescription\n\nd.clear()\n\nRemoves all items from dict d\n\nd.copy()\n\nReturns a shallow copy of dict d\n\nd.fromkeys(\n\ns, v)\n\nReturns a dict whose keys are the items in sequence s and whose values are None or v if v is given\n\nd.get(k)\n\nReturns key k’s associated value, or None if k isn’t in dict d\n\nd.get(k, v)\n\nd.items()\n\nReturns key k’s associated value, or v if k isn’t in dict d Returns a view★ of all the (key, value) pairs in dict d\n\nd.keys()\n\nReturns a view\n\n★\n\nof all the keys in dict d\n\nd.pop(k)\n\nReturns key k’s associated value and removes the item whose key is k, or raises a KeyError exception if k isn’t in d\n\nd.pop(k, v)\n\nReturns key k’s associated value and removes the item whose key is k, or returns v if k isn’t in dict d\n\nd.popitem()\n\nReturns and removes an arbitrary (key, value) pair from dict d, or raises a KeyError exception if d is empty\n\nd.setdefault( k, v)\n\nThe same as the dict.get() method,except that if the key is not in dict d,a new item is inserted with the key k,and with a value of None or of v if v is given\n\nd.update(a)\n\nAdds every (key, value) pair from a that isn’t in dict d to d, and for every key that is in both d and a, replaces the corre- sponding value in d with the one in a—a can be a dictionary, an iterable of (key, value) pairs, or keyword arguments\n\nd.values()\n\nReturns a view\n\n★\n\nof all the values in dict d\n\nThe dict.items(), dict.keys(), and dict.values() methods all return dictionary views. A dictionary view is effectively a read-only iterable object that appears to hold the dictionary’sitems or keys or values,depending on the view we have asked for.\n\nIn general, we can simply treat views as iterables. However, two things make a view different from a normal iterable. One is that if the dictionary the view refers to is changed, the view reﬂects the change. The other is that key and item views support some set-like operations. Given dictionary view v and set or dictionary view x, the supported operations are:\n\nv & x v | x\n\n# Intersection # Union\n\n★Dictionary views can be thought of—and used as—iterables; they are discussed in the text.\n\n129\n\nShallow and deep copying ➤ 146",
      "content_length": 2188,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 139,
      "content": "130\n\nChapter 3. Collection Data Types\n\nv - x v ^ x\n\n# Difference # Symmetric difference\n\nWe can use the membership operator, in, to see whether a particular key is in a dictionary,for example,x in d.And we can use the intersection operator to see which keys from a given set are in a dictionary. For example:\n\nd = {}.fromkeys(\"ABCD\", 3) # d == {'A': 3, 'B': 3, 'C': 3, 'D': 3} s = set(\"ACX\") matches = d.keys() & s\n\n# s == {'A', 'C', 'X'} # matches == {'A', 'C'}\n\nNote that in the snippet’s comments we have used alphabetical order—this is purely for ease of reading since dictionaries and sets are unordered.\n\nDictionaries are often used to keep counts of unique items. One such example of this is counting the number of occurrences of each unique word in a ﬁle. Here is a complete program (uniquewords1.py) that lists every word and the number of times it occurs in alphabetical order for all the ﬁles listed on the command line:\n\nimport string import sys\n\nwords = {} strip = string.whitespace + string.punctuation + string.digits + \"\\\"'\" for filename in sys.argv[1:]:\n\nfor line in open(filename):\n\nfor word in line.lower().split(): word = word.strip(strip) if len(word) > 2:\n\nwords[word] = words.get(word, 0) + 1\n\nfor word in sorted(words):\n\nprint(\"'{0}' occurs {1} times\".format(word, words[word]))\n\nWe begin by creating an empty dictionary called words.Then we create a string that contains all those characters that we want to ignore, by concatenating some useful strings provided by the string module. We iterate over each ﬁle- name given on the command line, and over each line in each ﬁle. See the side- bar “Reading and Writing Text Files” (➤ 131) for an explanation of the open() function. We don’t specify an encoding (because we don’t know what each ﬁle’s encoding will be),so we let Python open each ﬁle using the default local encod- ing. We split each lowercased line into words,and then strip off the characters that we want to ignore from both ends of each word. If the resultant word is at least three characters long we need to update the dictionary.\n\nWe cannot use the syntax words[word] += 1 because this will raise a KeyError exception the ﬁrst time a new word is encountered—after all, we can’t incre- ment the value of an item that does not yet exist in the dictionary. So we use",
      "content_length": 2304,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 140,
      "content": "Char- acter encod- ings 91➤\n\nMapping Types\n\nReading and Writing Text Files\n\nFiles are opened using the built-in open() function, which returns a “ﬁle object” (of type io.TextIOWrapper for text ﬁles).The open() function takesone mandatory argument—the ﬁlename, which may include a path—and up to six optional arguments, two of which we brieﬂy cover here. The second argumentisthemode—thisisused tospecify whether theﬁleistobetreated as a text ﬁle or as a binary ﬁle, and whether the ﬁle is to be opened for reading, writing, appending, or a combination of these.\n\nFor text ﬁles, Python uses an encoding that is platform-dependent. Where possible it is best to specify the encoding using open()’s encoding argument, so the syntaxes we normally use for opening ﬁles are these:\n\nfin = open(filename, encoding=\"utf8\") # for reading text fout = open(filename, \"w\", encoding=\"utf8\") # for writing text\n\nBecause open()’smodedefaultsto“readtext”,andby using a keywordrather thana positionalargumentfor the encoding argument,wecanomit theother optional positional arguments when opening for reading. And similarly, when opening to write we need to give only the argumentswe actually want to use. (Argument passing is covered in depth in Chapter 4.)\n\nOnce a ﬁle isopened for reading in text mode,we can read the whole ﬁle into a single string using the ﬁle object’s read() method, or into a list of strings using the ﬁle object’s readlines() method. A very common idiom for reading line by line is to treat the ﬁle object as an iterator:\n\nfor line in open(filename, encoding=\"utf8\"):\n\nprocess(line)\n\nThis works because a ﬁle object can be iterated over, just like a sequence, with each successive item being a string containing the next line from the ﬁle. The lines we get back include the line termination character, \\n.\n\nIf we specify a mode of “w”,the ﬁle is opened in “write text” mode. We write to a ﬁle using the ﬁle object’s write() method, which takes a single string as its argument. Each line written should end with a \\n.Python automatically translates between \\n and the underlying platform’s line termination characters when reading and writing.\n\nOncewehaveﬁnishedusing a ﬁleobjectwecancallitsclose() method—this will cause any outstanding writes to be ﬂushed. In small Python programs it is very common not to bother calling close(), since Python does this automatically when the ﬁle object goes out of scope. If a problem occurs, it will be indicated by an exception being raised.\n\n131\n\nChap- ter 7 (File Han- dling) ➤ 287",
      "content_length": 2526,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 141,
      "content": "132\n\nChapter 3. Collection Data Types\n\na subtler approach. We call dict.get() with a default value of 0. If the word is already in the dictionary, dict.get() will return the associated number, and this value plus 1 will be set as the item’s new value. If the word is not in the dictionary, dict.get() will return the supplied default of 0, and this value plus 1 (i.e., 1) will be set as the value of a new item whose key is the string held by word.To clarify,here are two code snippetsthat do the same thing,although the code using dict.get() is more efﬁcient:\n\nif word not in words:\n\nwords[word] = 0\n\nwords[word] = words.get(word, 0) + 1\n\nwords[word] += 1\n\nIn the next subsection where we cover default dictionaries, we will see an alternative solution.\n\nOnce we have accumulated the dictionary of words, we iterate over its keys (the words) in sorted order, and print each word and the number of times it occurs.\n\nUsing dict.get() allows us to easily update dictionary values, providing the valuesaresingleitemslike numbersor strings. But what if each value isitself a collection? To demonstrate how to handle this we will look at a program that reads HTML ﬁles given on the command line and prints a list of each unique Web site that is referred to in the ﬁles with a list of the referring ﬁles listed indented below the name of each Web site. Structurally, the program (external_sites.py) is very similar to the unique words program we have just reviewed. Here is the main part of the code:\n\nsites = {} for filename in sys.argv[1:]:\n\nfor line in open(filename):\n\ni = 0 while True:\n\nsite = None i = line.find(\"http://\", i) if i > -1:\n\ni += len(\"http://\") for j in range(i, len(line)):\n\nif not (line[j].isalnum() or line[j] in \".-\"):\n\nsite = line[i:j].lower() break\n\nif site and \".\" in site:\n\nsites.setdefault(site, set()).add(filename)\n\ni = j\n\nelse:\n\nbreak",
      "content_length": 1859,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 142,
      "content": "Mapping Types\n\nWe begin by creating an empty dictionary. Then we iterate over each ﬁle listed on the command line and each line within each ﬁle. We must account for the fact that each line may refer to any number of Web sites,which is why we keep calling str.find() until it fails. If we ﬁnd the string “http://”, we increment i (our starting index position)by the length of “http://”,and then we look at each succeeding character until we reach one that isn’t valid for a Web site’s name. If we ﬁnd a site (and as a simply sanity check, only if it contains a period), we add it to the dictionary.\n\nWe cannot use the syntax sites[site].add(filename) because this will raise a KeyError exception the ﬁrst time a new site is encountered—after all, we can’t add to a set that is the value of an item that doesnot yet exist in the dictionary. Sowemustusea differentapproach. The dict.setdefault() methodreturnsan object reference to the item in the dictionary that has the given key (the ﬁrst argument). If there is no such item, the method creates a new item with the key and sets its value either to None, or to the given default value (the second argument).In this case we pass a default value of set(), that is, an empty set. So the call to dict.setdefault() always returns an object reference to a value, either one that existed before or a new one. (Of course, if the given key is not hashable a TypeError exception will be raised.)\n\nIn this example, the returned object reference always refers to a set (an empty set the ﬁrst time any particular key, that is, site, is encountered), and we then add the ﬁlename that refers to the site to the site’s set of ﬁlenames. By using a set we ensure that even if a ﬁle refers to a site repeatedly, we record the ﬁlename only once for the site.\n\nTo make the dict.setdefault() method’s functionality clear, here are two equivalent code snippets:\n\nif site not in sites:\n\nsites[site] = set()\n\nsites.setdefault(site, set()).add(fname)\n\nsites[site].add(fname)\n\nFor the sake of completeness, here is the rest of the program:\n\nfor site in sorted(sites):\n\nprint(\"{0} is referred to in:\".format(site)) for filename in sorted(sites[site], key=str.lower): {0}\".format(filename))\n\nprint(\"\n\nunder- Each Web site is printed with the ﬁles that refer to it printed indented neath. The sorted() call in the outer for … in loop sorts all the dictionary’s keys—whenever a dictionary is used in a context that requires an iterable it is the keys that are used. If we want the iterable to be the (key, value) items or the values, we can use dict.items() or dict.values(). The inner for … in loop iterates over the sorted ﬁlenames from the current site’s set of ﬁlenames.\n\n133\n\nsorted() ➤ 140, 144",
      "content_length": 2718,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 143,
      "content": "Us- ing str. format() with map- ping un- packing 81➤\n\n134\n\nChapter 3. Collection Data Types\n\nAlthough a dictionary of web sites is likely to contain a lot of items, many other dictionaries have only a few items. For small dictionaries, we can print their contents using their keys as ﬁeld names and using mapping unpacking to convert the dictionary’s key–value items into key–value arguments for the str.format() method.\n\n>>> greens = dict(green=\"#0080000\", olive=\"#808000\", lime=\"#00FF00\") >>> print(\"{green} {olive} {lime}\".format(**greens)) #0080000 #808000 #00FF00\n\nHere, using mapping unpacking (**) has exactly the same effect as writing .format(green=greens.green, olive=greens.olive, lime=greens.lime), but is eas- ier to write and arguably clearer. Note that it doesn’t matter if the dictionary has more keys than we need, since only those keys whose names appear in the format string are used.\n\nDictionary Comprehensions\n\nA dictionary comprehension is an expression and a loop with an optional condition enclosed in braces,very similar to a set comprehension. Likelist and set comprehensions, two syntaxes are supported:\n\n{keyexpression: valueexpression for key, value in iterable} {keyexpression: valueexpression for key, value in iterable if condition}\n\nHere is how we could use a dictionary comprehension to create a dictionary where each key is the name of a ﬁle in the current directory and each value is the size of the ﬁle in bytes:\n\nfile_sizes = {name: os.path.getsize(name) for name in os.listdir(\".\")}\n\nThe os (“operating system”) module’s os.listdir() function returns a list of the ﬁles and directories in the path it is passed, although it never includes “.” or “..” in the list. The os.path.getsize() function returns the size of the given ﬁle in bytes. We can avoid directoriesand other nonﬁle entriesby adding a condition:\n\nfile_sizes = {name: os.path.getsize(name) for name in os.listdir(\".\")\n\nif os.path.isfile(name)}\n\nThe os.path module’s os.path.isfile() function returns True if the path passed to it is that of a ﬁle, and False otherwise—that is, for directories, links, and so on.\n\nA dictionary comprehension can also be used to create an inverted dictionary. For example, given dictionary d, we can produce a new dictionary whose keys are d’s values and whose values are d’s keys:\n\n|\n\nMap- ping unpack- ing ➤ 177\n\nos and os.path modules ➤ 224",
      "content_length": 2376,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 144,
      "content": "unique- words1. py 130➤\n\nMapping Types\n\ninverted_d = {v: k for k, v in d.items()}\n\nThe resultant dictionary can be inverted back to the original dictionary if all the original dictionary’s values are unique—but the inversion will fail with a TypeError being raised if any value is not hashable.\n\nJust like list and set comprehensions, the iterable in a dictionary comprehen- sion can be another comprehension,so all kinds of nested comprehensions are possible.\n\nDefault Dictionaries\n\nDefault dictionariesare dictionaries—they have all the operatorsand methods that dictionaries provide. What makes default dictionaries different from plain dictionaries is the way they handle missing keys; in all other respects they behave identically to dictionaries. (In object-oriented terms, defaultdict is a subclass of dict; object-oriented programming, including subclassing, is covered in Chapter 6.)\n\nIf we use a nonexistent (“missing”)key when accessing a dictionary,a KeyError is raised. This is useful because we often want to know whether a key that we expected to be present is absent. But in some cases we want every key we use to be present, even if it means that an item with the key is inserted into the dictionary at the time we ﬁrst access it.\n\nFor example, if we have a dictionary d which does not have an item with key m, the code x = d[m] will raise a KeyError exception. But if d is a suitably created default dictionary,if an item with key m is in the default dictionary,the corresponding value is returned the same as for a dictionary—but if m is not a key in the default dictionary, a new item with key m is created with a default value, and the newly created item’s value is returned.\n\nEarlier we wrote a small program that counted the unique words in the ﬁles it was given on the command line. The dictionary of words was created like this:\n\nwords = {}\n\nEach key in the words dictionary was a word and each value an integer holding the number of times the word had occurred in all the ﬁles that were read. Here’s how we incremented whenever a suitable word was encountered:\n\nwords[word] = words.get(word, 0) + 1\n\nWe had to use dict.get() to account for when the word was encountered the ﬁrst time (where we needed to create a new item with a count of 1) and for when thewordwasencounteredsubsequently (whereweneeded toadd 1tothe word’s existing count).\n\n135\n\n||",
      "content_length": 2374,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 145,
      "content": "136\n\nChapter 3. Collection Data Types\n\nWhenadefaultdictionaryiscreated,wecanpassina factoryfunction.A factory function is a function that, when called, returns an object of a particular type. All of Python’sbuilt-in data typescan beused asfactory functions,for example, data type str can be called as str()—and with no argument it returns an emp- ty string object. The factory function passed to a default dictionary is used to create default values for missing keys.\n\nNote that the name of a function is an object reference to the function—so when we want to pass functions as parameters, we just pass the name. When we use a function with parentheses, the parentheses tell Python that the function should be called.\n\nThe program uniquewords2.py has one more line than the original unique- words1.py program(import collections),and the linesfor creating and updating the dictionary are written differently. Here is how the default dictionary is created:\n\nwords = collections.defaultdict(int)\n\nThe words default dictionary will never raise a KeyError. If we were to write x = words[\"xyz\"] and there was no item with key \"xyz\", when the access is attempted and the key isn’t found, the default dictionary will immediately create a new item with key \"xyz\" and value 0 (by calling int()), and this value is what will be assigned to x.\n\nwords[word] += 1\n\nNow we no longer need to use dict.get(); instead we can simply increment the item’s value. The very ﬁrst time a word is encountered, a new item is created with value 0 (to which 1 is immediately added), and on every subsequent access, 1 is added to whatever the current value happens to be.\n\nWe have now completed our review of all of Python’s built-in collection data types, and a couple of the standard library’s collection data types. In the next section we will look at some issuesthat are common to all of the collection data types.\n\nOrdered Dictionaries\n\nThe ordered dictionaries type—collections.OrderedDict—was introduced with Python 3.1 in fulﬁllment of PEP 372. Ordered dictionaries can be used as drop-in replacements for unordered dicts because they provide the same API. The difference between the two is that ordered dictionariesstore their itemsin the order in which they were inserted—a feature that can be very convenient.\n\nNote that if an ordered dictionary is passed an unordered dict or keyword ar- gumentswhen it is created,the item order will be arbitrary;this is because un- der the hood Python passes keyword arguments using a standard unordered\n\n||\n\n3.1",
      "content_length": 2529,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 146,
      "content": "Mapping Types\n\ndict. A similar effect occurs with the use of the update() method. For these reasons, passing keyword arguments or an unordered dict when creating an ordereddictionaryor using update() ononeisbestavoided. However,if wepass a list or tuple of key–value 2-tuples when creating an ordered dictionary, the ordering is preserved (since they are passed as a single item—a list or tuple).\n\nHere’s how to create an ordered dictionary using a list of 2-tuples:\n\nd = collections.OrderedDict([('z', -4), ('e', 19), ('k', 7)])\n\nBecause we used a single list as argument the key ordering is preserved. It is probably more common to create ordered dictionaries incrementally, like this:\n\ntasks = collections.OrderedDict() tasks[8031] = \"Backup\" tasks[4027] = \"Scan Email\" tasks[5733] = \"Build System\"\n\nIf we had created unordered dicts the same way and asked for their keys, the order of the returned keys would be arbitrary. But for ordered dictionaries,we can rely on the keys to be returned in the same order they were inserted. So for theseexamples,if wewrote list(d.keys()),weareguaranteedtoget thelist ['z', 'e', 'k'], and if we wrote list(tasks.keys()), we are guaranteed to get the list [8031, 4027, 5733].\n\nOne other nice feature of ordered dictionaries is that if we change an item’s value—that is, if we insert an item with the same key as an existing key—the order is not changed. So if we did tasks[8031] = \"Daily backup\", and then asked for the list of keys,we would get exactly the same list in exactly the same order as before.\n\nIf we want to move an item to the end, we must delete it and then reinsert it. We can also call popitem() to remove and return the last key–value item in the ordered dictionary; or we can call popitem(last=False), in which case the ﬁrst item will be removed and returned.\n\nAnother, slightly more specialized use for ordered dictionaries is to produce sorted dictionaries. Given a dictionary, d, we can convert it into a sorted dictionary like this:d = collections.OrderedDict(sorted(d.items())).Note that if we were to insert any additional keys they would be inserted at the end, so after any insertion,to preservethe sorted order,we would have to re-createthe dictionary by executing the same code we used to create it in the ﬁrst place. Doing insertions and re-creating isn’t quite as inefﬁcient as it sounds, since Python’s sorting algorithm is highly optimized, especially for partially sorted data, but it is still potentially expensive.\n\nIn general, using an ordered dictionary to produce a sorted dictionary makes sense only if we expect to iterate over the dictionary multiple times, and if we do not expect to do any insertions (or very few), once the sorted dictionary has\n\n137\n\n3.1",
      "content_length": 2739,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 147,
      "content": "138\n\nChapter 3. Collection Data Types\n\nbeen created. ly maintains its keys in sorted order is presented in Chapter 6; ➤ 276.)\n\n(An implementationof a real sorted dictionary that automatical-\n\nIterating and Copying Collections\n\nOnce we have collections of data items, it is natural to want to iterate over all the itemsthey contain. In thissection’sﬁrst subsection we will introducesome of Python’s iterators and the operators and functions that involve iterators.\n\nAnother commonrequirementistocopy a collection. Therearesomesubtleties involved here because of Python’s use of object references (for the sake of efﬁciency), so in this section’s second subsection, we will examine how to copy collections and get the behavior we want.\n\nIterators and Iterable Operations and Functions\n\nAn iterabledata typeisone that can return each of itsitemsone at a time. Any object that hasan __iter__() method,or any sequence (i.e.,an object that hasa __getitem__() method taking integer arguments starting from 0) is an iterable and can provide an iterator. An iterator is an object that provides a __next__() method which returns each successive item in turn,and raises a StopIteration exception when there are no more items. Table 3.4 lists the operators and functions that can be used with iterables.\n\nThe order in which items are returned depends on the underlying iterable. In the case of lists and tuples, items are normally returned in sequential order starting from the ﬁrst item (index position 0), but some iterators return the items in an arbitrary order—for example, dictionary and set iterators.\n\nThe built-in iter() function has two quite different behaviors. When given a collection data type or a sequence it returns an iterator for the object it is passed—or raises a TypeError if the object cannot be iterated. This use arises when creating custom collection data types, but is rarely needed in other con- texts. The second iter() behavior occurswhen thefunction ispasseda callable (a function or method),and a sentinel value. In thiscasethefunction passedin iscalled onceat each iteration,returning thefunction’sreturn value each time, or raising a StopIteration exception if the return value equals the sentinel.\n\nWhen we use a for item in iterable loop, Python in effect calls iter(iterable) to get an iterator. This iterator’s __next__() method is then called at each loop iteration to get the next item, and when the StopIteration exception is raised, it is caught and the loop is terminated. Another way to get an iterator’s next item is to call the built-in next() function. Here are two equivalent pieces of code (multiplying the values in a list), one using a for … in loop and the other using an explicit iterator:\n\n|||\n\n||\n\n3.1\n\n__iter- __() ➤ 274",
      "content_length": 2764,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 148,
      "content": "Iterating and Copying Collections\n\nproduct = 1 i = iter([1, 2, 4, 8]) while True: try:\n\nproduct = 1 for i in [1, 2, 4, 8]:\n\nproduct *= next(i)\n\nexcept StopIteration:\n\nproduct *= i\n\nbreak\n\nprint(product) # prints: 64\n\nprint(product) # prints: 64\n\nAny (ﬁnite) iterable, i, can be converted into a tuple by calling tuple(i), or can be converted into a list by calling list(i).\n\nThe all() and any() functions can be used on iterators and are often used in functional-styleprogramming. Here are a couple of usage examplesthat show all(), any(), len(), min(), max(), and sum():\n\n>>> x = [-2, 9, 7, -4, 3] >>> all(x), any(x), len(x), min(x), max(x), sum(x) (True, True, 5, -4, 9, 13) >>> x.append(0) >>> all(x), any(x), len(x), min(x), max(x), sum(x) (False, True, 6, -4, 9, 13)\n\nOf these little functions, len() is probably the most frequently used.\n\nThe enumerate() function takes an iterator and returns an enumerator object. This object can be treated like an iterator, and at each iteration it returns a 2-tuple with the tuple’s ﬁrst item the iteration number (by default starting from 0), and the second item the next item from the iterator enumerate() was called on. Let’s look at enumerate()’s use in the context of a tiny but complete program.\n\nThe grepword.py program takes a word and one or more ﬁlenames on the command line and outputs the ﬁlename, line number, and line whenever the line contains the given word.★ Here’s a sample run:\n\ngrepword.py Dom data/forenames.txt data/forenames.txt:615:Dominykas data/forenames.txt:1435:Dominik data/forenames.txt:1611:Domhnall data/forenames.txt:3314:Dominic\n\nData ﬁles data/forenames.txt and data/surnames.txt contain unsorted lists of names, one per line.\n\n★In Chapter 10 will see two other implementations of this program, grepword-p.py and grepword- t.py, which spread the work over multiple processes and multiple threads.\n\n139\n\nFunc- tional- style pro- gram- ming ➤ 395",
      "content_length": 1923,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 149,
      "content": "140\n\nChapter 3. Collection Data Types\n\nTable 3.4 Common Iterable Operators and Functions\n\nSyntax\n\nDescription\n\ns + t\n\ns * n\n\nReturns a sequence that is the concatenation of sequences s and t Returns a sequence that is int n concatenations of sequence s\n\nx in i\n\nall(i)\n\nReturns True if item x is in iterable i; use not in to reverse the test Returns True if every item in iterable i evaluates to True\n\nany(i)\n\nReturns True if any item in iterable i evaluates to True\n\nenumerate(i,\n\nstart)\n\nNormally used in for …in loops to provide a sequence of (in- dex, item) tuples with indexes starting at 0 or start; see text\n\nlen(x)\n\nReturns the “length” of x. If x is a collection it is the number of items; if x is a string it is the number of characters.\n\nmax(i, key) Returns the biggest item in iterable i or the item with the\n\nbiggest key(item) value if a key function is given\n\nmin(i, key) Returns the smallest item in iterable i or the item with the\n\nsmallest key(item) value if a key function is given\n\nrange(\n\nstart, stop, step)\n\nReturns an integer iterator. With one argument (stop), the it- erator goes from 0 to stop - 1; with two arguments (start, stop) the iterator goes from start to stop - 1; with three arguments it goes from start to stop - 1 in steps of step.\n\nreversed(i) Returns an iterator that returns the items from iterator i in\n\nsorted(i,\n\nkey, reverse)\n\nreverse order Returns a list of the items from iterator i in sorted order; key is used to provide DSU (Decorate, Sort, Undecorate) sorting. If reverse is True the sorting is done in reverse order.\n\nsum(i,\n\nstart)\n\nReturns the sum of the items in iterable i plus start (which defaults to 0); i may not contain strings\n\nzip(i1,\n\n..., iN)\n\nReturns an iterator of tuples using the iterators i1 to iN; see text\n\nApart from the sys import, the program is just ten lines long:\n\nif len(sys.argv) < 3:\n\nprint(\"usage: grepword.py word infile1 [infile2 [... infileN]]\") sys.exit()\n\nword = sys.argv[1] for filename in sys.argv[2:]:\n\nfor lino, line in enumerate(open(filename), start=1):\n\nif word in line:",
      "content_length": 2063,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 150,
      "content": "Read- ing and writing text ﬁles sidebar 131➤\n\nIterating and Copying Collections\n\nprint(\"{0}:{1}:{2:.40}\".format(filename, lino, line.rstrip()))\n\nWe begin by checking that there are at least two command-line arguments. If there are not, we print a usage message and terminate the program. The sys.exit()functionperformsanimmediatecleantermination,closinganyopen ﬁles. It accepts an optional int argument which is passed to the calling shell.\n\nWe assume that the ﬁrst argument is the word the user is looking for and that the other argumentsare the namesof the ﬁles to look in. We have deliberately called open() without specifying an encoding—the user might use wildcards to specify any number of ﬁles, each potentially with a different encoding,so in this case we leave Python to use the platform-dependent encoding.\n\nThe ﬁle object returned by the open() function in text mode can be used as an iterator, returning one line of the ﬁle on each iteration. By passing the iter- ator to enumerate(), we get an enumerator iterator that returns the iteration number (in variable lino, “line number”) and a line from the ﬁle, on each itera- tion. If the word the user islooking for isin the line,we print the ﬁlename,line number, and the ﬁrst 40 characters of the line with trailing whitespace (e.g., \\n) stripped. The enumerate() function accepts an optional keyword argument, start,which defaultsto 0;wehave used thisargument set to1,sinceby conven- tion, text ﬁle line numbers are counted from 1.\n\nQuite often we don’t need an enumerator, but rather an iterator that returns successive integers. This is exactly what the range() function provides. If we need a list or tuple of integers,we can convert the iterator returned by range() by using the appropriate conversion function. Here are a few examples:\n\n>>> list(range(5)), list(range(9, 14)), tuple(range(10, -11, -5)) ([0, 1, 2, 3, 4], [9, 10, 11, 12, 13], (10, 5, 0, -5, -10))\n\nThe range() function is most commonly used for two purposes:to create lists or tuples of integers,and to provide loop counting in for …in loops. For example, these two equivalent examples ensure that list x’s items are all non-negative:\n\ni = 0 while i < len(x):\n\nfor i in range(len(x)): x[i] = abs(x[i])\n\nx[i] = abs(x[i]) i += 1\n\nIn both cases, if list x was originally, say, [11, -3, -12, 8, -1], afterward it will be [11, 3, 12, 8, 1].\n\nSince we can unpack an iterable using the * operator, we can unpack the iterator returned by the range() function. For example, if we have a function called calculate() that takesfour arguments,here are some ways we could call it with arguments, 1, 2, 3, and 4:\n\n141",
      "content_length": 2636,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 151,
      "content": "Tuple unpack- ing 110➤\n\n142\n\nChapter 3. Collection Data Types\n\ncalculate(1, 2, 3, 4) t = (1, 2, 3, 4) calculate(*t) calculate(*range(1, 5))\n\nInallthreecalls,fourargumentsarepassed. Thesecondcallunpacksa4-tuple, and the third call unpacks the iterator returned by the range() function.\n\nWe will now look at a small but complete program to consolidate some of the things we have covered so far, and for the ﬁrst time to explicitly write to a ﬁle. The generate_test_names1.py program reads in a ﬁle of forenames and a ﬁle of surnames, creating two lists, and then creates the ﬁle test-names1.txt and writes 100 random names into it.\n\nWe will use the random.choice() function which takes a random item from a sequence, so it is possible that some duplicate names might occur. First we’ll look at the function that returns the lists of names, and then we will look at the rest of the program.\n\ndef get_forenames_and_surnames():\n\nforenames = [] surnames = [] for names, filename in ((forenames, \"data/forenames.txt\"),\n\n(surnames, \"data/surnames.txt\")):\n\nfor name in open(filename, encoding=\"utf8\"):\n\nnames.append(name.rstrip())\n\nreturn forenames, surnames\n\nIn the outer for …in loop,we iterate over two 2-tuples, unpacking each 2-tuple into two variables. Even though the two lists might be quite large, returning them from a function is efﬁcient because Python uses object references, so the only thing that is really returned is a tuple of two object references.\n\nInside Python programs it is convenient to always use Unix-style paths, since they canbetypedwithouttheneedfor escaping,andthey work on allplatforms (including Windows). If we have a path we want to present to the user in, say, variable path, we can always import the os module and call path.replace(\"/\", os.sep) to replace forward slashes with the platform-speciﬁc directory sepa- rator.\n\nforenames, surnames = get_forenames_and_surnames() fh = open(\"test-names1.txt\", \"w\", encoding=\"utf8\") for i in range(100):\n\nline = \"{0} {1}\\n\".format(random.choice(forenames),\n\nrandom.choice(surnames))\n\nfh.write(line)",
      "content_length": 2067,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 152,
      "content": "Read- ing and writing text ﬁles sidebar 131➤\n\nIterating and Copying Collections\n\nHaving retrieved the two lists we open the output ﬁle for writing, and keep the ﬁle object in variable fh (“ﬁle handle”).We then loop 100 times,and in each iteration we create a line to be written to the ﬁle, remembering to include a newline at the end of every line. We make no use of the loop variable i; it is needed purely tosatisfy the for …in loop’ssyntax. Thepreceding codesnippet, the get_forenames_and_surnames() function,and an import statement constitute the entire program.\n\nIn the generate_test_names1.py program we paired items from two separate lists together into strings. Another way of combining items from two or more lists (or other iterables) is to use the zip() function. The zip() function takes one or more iterables and returns an iterator that returns tuples. The ﬁrst tuple has the ﬁrst item from every iterable, the second tuple the second item from every iterable, and so on, stopping as soon as one of the iterables is exhausted. Here is an example:\n\n>>> for t in zip(range(4), range(0, 10, 2), range(1, 10, 2)): ... (0, 0, 1) (1, 2, 3) (2, 4, 5) (3, 6, 7)\n\nprint(t)\n\nAlthough the iterators returned by the second and third range() calls can produce ﬁve items each, the ﬁrst can produce only four, so that limits the number of items zip() can return to four tuples.\n\nHere is a modiﬁed version of the program to generate test names, this time with each name occupying 25 characters and followed by a random year. The program is called generate_test_names2.py and outputs the ﬁle test-names2.txt. We have not shown the get_forenames_and_surnames() function or the open() call since, apart from the output ﬁlename, they are the same as before.\n\nlimit = 100 years = list(range(1970, 2013)) * 3 for year, forename, surname in zip(\n\nrandom.sample(years, limit), random.sample(forenames, limit), random.sample(surnames, limit)):\n\nname = \"{0} {1}\".format(forename, surname) fh.write(\"{0:.<25}.{1}\\n\".format(name, year))\n\nWe begin by setting a limit on how many nameswe want to generate. Then we create a list of years by making a list of the years from 1970 to 2012 inclusive, and then replicating this list three times so that the ﬁnal list has three occur- rences of each year. This is necessary because the random.sample() function that we are using (instead of random.choice()) takes both an iterable and how\n\n143",
      "content_length": 2420,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 153,
      "content": "Tuple unpack- ing 110➤\n\nstr. format() 78➤\n\n144\n\nChapter 3. Collection Data Types\n\nmany items it is to produce—a number that cannot be less than the number of items the iterable can return. The random.sample() function returns an iter- ator that will produce up to the speciﬁed number of items from the iterable it is given—with no repeats. So this version of the program will always produce unique names.\n\nzip() function. We In the for … in loop we unpack each tuple returned by the want to limit the length of each name to 25 characters,and to do this we must ﬁrst create a string with the complete name,and then set the maximum width for that string when we call str.format() the second time. We left-align each name,and for namesshorter than 25characterswe ﬁll with periods. The extra period ensures that names that occupy the full ﬁeld width are still separated from the year by a period.\n\nWe will conclude this subsection by mentioning two other iterable-related functions, sorted() and reversed(). The sorted() function returns a list with the items sorted, and the reversed() function simply returns an iterator that iterates in the reverse order to the iterator it is given as its argument. Here is an example of reversed():\n\n>>> list(range(6)) [0, 1, 2, 3, 4, 5] >>> list(reversed(range(6))) [5, 4, 3, 2, 1, 0]\n\nThe sorted() function is more sophisticated,as these examples show:\n\n>>> x = [] >>> for t in zip(range(-10, 0, 1), range(0, 10, 2), range(1, 10, 2)): ... >>> x [-10, 0, 1, -9, 2, 3, -8, 4, 5, -7, 6, 7, -6, 8, 9] >>> sorted(x) [-10, -9, -8, -7, -6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> sorted(x, reverse=True) [9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -6, -7, -8, -9, -10] >>> sorted(x, key=abs) [0, 1, 2, 3, 4, 5, 6, -6, -7, 7, -8, 8, -9, 9, -10]\n\nx += t\n\nIn the preceding snippet, the zip() function returns 3-tuples, (-10, 0, 1), (-9, 2, 3), and so on. The += operator extends a list,that is, it appends each item in the sequence it is given to the list.\n\nThe ﬁrst call to sorted() returns a copy of the list using the conventional sort order. The second call returns a copy of the list in the reverse of the conven- tional sort order. The last call to sorted() speciﬁes a “key” function which we will come back to in a moment.",
      "content_length": 2236,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 154,
      "content": "Iterating and Copying Collections\n\n145\n\nNotice that since Python functions are objects like any other, they can be passed as arguments to other functions, and stored in collections without formality. Recall that a function’snameisan object referenceto thefunction;it is the parentheses that follow the name that tell Python to call the function.\n\nWhen a key function is passed (in this case the abs() function), it is called once for every item in the list (with the item passed as the function’s sole parameter), to create a “decorated” list. Then the decorated list is sorted, and the sorted list without the decoration is returned as the result. We are free to use our own custom function as the key function, as we will see shortly.\n\nFor example, we can case-insensitively sort a list of strings by passing the str.lower() method as a key. If we have the list, x, of [\"Sloop\", \"Yawl\", \"Cutter\", \"schooner\", \"ketch\"], we can sort it case-insensitively using DSU (Decorate, Sort, Undecorate) with a single line of code by passing a key func- tion, or do the DSU explicitly, as these two equivalent code snippets show:\n\ntemp = [] for item in x:\n\ntemp.append((item.lower(), item))\n\nx = [] for key, value in sorted(temp):\n\nx = sorted(x, key=str.lower)\n\nx.append(value)\n\nBoth snippets produce a new list: [\"Cutter\", \"ketch\", \"schooner\", \"Sloop\", \"Yawl\"], although the computationsthey perform are not identical because the right-hand snippet creates the temp list variable.\n\nPython’s sort algorithm is an adaptive stable mergesort that is both fast and smart, and it is especially well optimized for partially sorted lists—a very common case.★ The “adaptive” part means that the sort algorithm adapts to circumstances—for example, taking advantage of partially sorted data. The “stable” part means that items that sort equally are not moved in relation to each other (after all, there is no need), and the “mergesort” part is the generic name for the sorting algorithm used. When sorting collections of integers, strings, or other simple types their “less than” operator (<) is used. Python can sort collections that contain collections, working recursively to any depth. For example:\n\n>>> x = list(zip((1, 3, 1, 3), (\"pram\", \"dorie\", \"kayak\", \"canoe\"))) >>> x [(1, 'pram'), (3, 'dorie'), (1, 'kayak'), (3, 'canoe')] >>> sorted(x) [(1, 'kayak'), (1, 'pram'), (3, 'canoe'), (3, 'dorie')]\n\n★The algorithm was created by Tim Peters. An interesting explanation and discussion of the algorithm is in the ﬁle listsort.txt which comes with Python’s source code.",
      "content_length": 2552,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 155,
      "content": "Object refer- ences 16➤\n\n146\n\nChapter 3. Collection Data Types\n\nPython has sorted the list of tuples by comparing the ﬁrst item of each tuple, and when these are the same, by comparing the second item. This gives a sort order based on the integers, with the strings being tiebreakers. We can force the sort to be based on the strings and use the integers as tiebreakers by deﬁning a simple key function:\n\ndef swap(t):\n\nreturn t[1], t[0]\n\nThe swap() function takes a 2-tuple and returns a new 2-tuple with the argu- ments swapped. Assuming that we have entered the swap() function in IDLE, we can now do this:\n\n>>> sorted(x, key=swap) [(3, 'canoe'), (3, 'dorie'), (1, 'kayak'), (1, 'pram')]\n\nListscan also be sorted in-place using the list.sort() method,which takesthe same optional arguments as sorted().\n\nSorting can be applied only to collections where all the items can be compared with each other:\n\nsorted([3, 8, -7.5, 0, 1.3]) sorted([3, \"spanner\", -7.5, 0, 1.3]) # raises a TypeError\n\n# returns: [-7.5, 0, 1.3, 3, 8]\n\nAlthough the ﬁrst list has numbers of different types (int and float), these types can be compared with each other so that sorting a list containing them works ﬁne. But the second list has a string and this cannot be sensibly com- pared with a number,and so a TypeError exception is raised. If we want to sort a list that has integers, ﬂoating-point numbers, and strings that contain num- bers, we can give float() as the key function:\n\nsorted([\"1.3\", -7.5, \"5\", 4, \"-2.4\", 1], key=float)\n\nThisreturnsthelist [-7.5, '-2.4', 1, '1.3', 4, '5'].Noticethatthelist’svalues are not changed, so strings remain strings. If any of the strings cannot be converted to a number (e.g., “spanner”), a ValueError exception will be raised.\n\nCopying Collections\n\nSince Python uses object references,when we use the assignment operator (=), literal such as a string no copying takes place. If the right-hand operand is a or a number,the left-hand operand isset to be an object referencethat refersto the in-memory object that holds the literal’s value. If the right-hand operand isan object reference,the left-hand operand isset to be an object referencethat refers to the same object as the right-hand operand. One consequence of this is that assignment is very efﬁcient.\n\n||",
      "content_length": 2282,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 156,
      "content": "Iterating and Copying Collections\n\nWhen we assign large collections, such as long lists, the savings are very apparent. Here is an example:\n\n>>> songs = [\"Because\", \"Boys\", \"Carol\"] >>> beatles = songs >>> beatles, songs (['Because', 'Boys', 'Carol'], ['Because', 'Boys', 'Carol'])\n\nHere, a new object reference (beatles) has been created, and both object references refer to the same list—no copying has taken place.\n\nSince lists are mutable, we can apply a change. For example:\n\n>>> beatles[2] = \"Cayenne\" >>> beatles, songs (['Because', 'Boys', 'Cayenne'], ['Because', 'Boys', 'Cayenne'])\n\nWe applied the change using the beatles variable—but this is an object refer- ence referring to the same list as songs refers to. So any change made through either object reference is visible to the other. This is most often the behavior wewant,sincecopying largecollectionsispotentially expensive. It alsomeans, for example,that we can pass a list or other mutable collection data type as an argumenttoa function,modify thecollectioninthefunction,andknowthatthe modiﬁed collection will be accessible after the function call has completed.\n\nHowever,in somesituations,wereally dowant a separatecopy of thecollection (or other mutable object). For sequences, when we take a slice—for example, songs[:2]—the slice is always an independent copy of the items copied. So to copy an entire sequence we can do this:\n\n>>> songs = [\"Because\", \"Boys\", \"Carol\"] >>> beatles = songs[:] >>> beatles[2] = \"Cayenne\" >>> beatles, songs (['Because', 'Boys', 'Cayenne'], ['Because', 'Boys', 'Carol'])\n\nFor dictionaries and sets, copying can be achieved using dict.copy() and set.copy(). In addition, the copy module provides the copy.copy() function that returns a copy of the object it is given. Another way to copy the built-in collec- tion types is to use the type as a function with the collection to be copied as its argument. Here are some examples:\n\ncopy_of_dict_d = dict(d) copy_of_list_L = list(L) copy_of_set_s = set(s)\n\nNote, though, that all of these copying techniques are shallow—that is, only object references are copied and not the objects themselves. For immutable\n\n147",
      "content_length": 2161,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 157,
      "content": "148\n\nChapter 3. Collection Data Types\n\ndata typeslike numbersand stringsthishasthe same effect as copying (except that it is more efﬁcient), but for mutable data types such as nested collections this means that the objects they refer to are referred to both by the original collection and by the copied collection. The following snippet illustrates this:\n\n>>> x = [53, 68, [\"A\", \"B\", \"C\"]] >>> y = x[:] # shallow copy >>> x, y ([53, 68, ['A', 'B', 'C']], [53, 68, ['A', 'B', 'C']]) >>> y[1] = 40 >>> x[2][0] = 'Q' >>> x, y ([53, 68, ['Q', 'B', 'C']], [53, 40, ['Q', 'B', 'C']])\n\nWhen list x is shallow-copied, the reference to the nested list [\"A\", \"B\", \"C\"] is copied. This means that both x and y have as their third item an object refer- ence that refers to this list, so any changes to the nested list are seen by both x and y.If we really need independent copiesof arbitrarily nested collections,we can deep-copy:\n\n>>> import copy >>> x = [53, 68, [\"A\", \"B\", \"C\"]] >>> y = copy.deepcopy(x) >>> y[1] = 40 >>> x[2][0] = 'Q' >>> x, y ([53, 68, ['Q', 'B', 'C']], [53, 40, ['A', 'B', 'C']])\n\nHere, lists x and y, and the list items they contain, are completely inde- pendent.\n\nNote that from now on we will use the terms copy and shallow copy interchangeably—if we mean deep copy, we will say so explicitly.\n\nExamples\n\nWe have now completed our review of Python’s built-in collection data types, and three of the standard library collection types (collections.namedtuple, collections.defaultdict, and collections.OrderedDict). Python also provides the collections.deque type, a double-ended queue, and many other collection types are available from third parties and from the Python Package Index, pypi.python.org/pypi.But now we will look at a couple of slightly longer exam- ples that draw together many of the things covered in this chapter, and in the preceding one.\n\n|||",
      "content_length": 1875,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 158,
      "content": "Examples\n\nThe ﬁrst programisabout seventy lineslong and involvestext processing. The second program is around ninety lines long and is mathematical in ﬂavor. Be- tween them, the programs make use of dictionaries, lists, named tuples, and sets, and both make great use of the str.format() method from the preceding chapter.\n\ngenerate_usernames.py\n\nImagine we are setting up a new computer system and need to generate user- names for all of our organization’s staff. We have a plain text data ﬁle (UTF- 8 encoding) where each line represents a record and ﬁelds are colon-delimited. Each record concerns one member of the staff and the ﬁelds are their unique staff ID, forename, middle name (which may be an empty ﬁeld), surname, and department name. Here is an extract of a few lines from an example data/users.txt data ﬁle:\n\n1601:Albert:Lukas:Montgomery:Legal 3702:Albert:Lukas:Montgomery:Sales 4730:Nadelle::Landale:Warehousing\n\nThe program must read in all the data ﬁles given on the command line,and for every line (record) must extract the ﬁelds and return the data with a suitable username. Each username must be unique and based on the person’s name. The output must be text sent to the console, sorted alphabetically by surname and forename, for example:\n\nName ID Username -------------------------------- ------ --------- Landale, Nadelle................ (4730) nlandale Montgomery, Albert L............ (1601) almontgo Montgomery, Albert L............ (3702) almontgo1\n\nEach record has exactly ﬁve ﬁelds, and although we could refer to them by number, we prefer to use names to keep our code clear:\n\nID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)\n\nIt is a Python convention that identiﬁers written in all uppercase characters are to be treated as constants.\n\nWe also need to create a named tuple type for holding the data on each user:\n\nUser = collections.namedtuple(\"User\",\n\n\"username forename middlename surname id\")\n\nWe will see how the constantsand the User named tuple are used when we look at the rest of the code.\n\n149\n\n||",
      "content_length": 2047,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 159,
      "content": "150\n\nChapter 3. Collection Data Types\n\nThe program’s overall logic is captured in the main() function:\n\ndef main():\n\nif len(sys.argv) == 1 or sys.argv[1] in {\"-h\", \"--help\"}:\n\nprint(\"usage: {0} file1 [file2 [... fileN]]\".format(\n\nsys.argv[0]))\n\nsys.exit()\n\nusernames = set() users = {} for filename in sys.argv[1:]:\n\nfor line in open(filename, encoding=\"utf8\"):\n\nline = line.rstrip() if line:\n\nuser = process_line(line, usernames) users[(user.surname.lower(), user.forename.lower(),\n\nuser.id)] = user\n\nprint_users(users)\n\nIf the user doesn’t provide any ﬁlenames on the command line, or if they type “-h” or “--help” on the command line, we simply print a usage message and terminate the program.\n\nFor each line read, we strip off any trailing whitespace (e.g., \\n) and process only nonempty lines. Thismeansthat if the data ﬁle containsblank linesthey will be safely ignored.\n\nWe keeptrack of all theallocated usernamesin the usernames set to ensurethat we don’t create any duplicates. The data itself is held in the users dictionary, with each user (member of the staff) stored as a dictionary item whose key is a tuple of the user’s surname, forename, and ID, and whose value is a named tupleof typeUser.Using a tupleof theuser’ssurname,forename,andIDfor the dictionary’s keys means that if we call sorted() on the dictionary, the iterable returned will be in the order we want (i.e.,surname,forename,ID),without us having to provide a key function.\n\ndef process_line(line, usernames):\n\nfields = line.split(\":\") username = generate_username(fields, usernames) user = User(username, fields[FORENAME], fields[MIDDLENAME],\n\nfields[SURNAME], fields[ID])\n\nreturn user\n\nSince the data format for each record is so simple, and because we’ve already stripped the trailing whitespace from the line, we can extract the ﬁelds simply by splitting on the colons. We pass the ﬁelds and the usernames set to the generate_username() function,andthenwecreateaninstanceof the User named",
      "content_length": 1971,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 160,
      "content": "Examples\n\ntuple type which we then return to the caller (main()), which inserts the user into the users dictionary, ready for printing.\n\nIf we had not created suitable constants to hold the index positions, we would be reduced to using numeric indexes, for example:\n\nuser = User(username, fields[1], fields[2], fields[3], fields[0])\n\nAlthough this is certainly shorter, it is poor practice. First it isn’t clear to future maintainers what each ﬁeld is, and second it is vulnerable to data ﬁle format changes—if the order or number of ﬁelds in a record changes,this code will break everywhere it is used. But by using named constants in the face of changes to the record struture,we would have to change only the values of the constants, and all uses of the constants would continue to work.\n\ndef generate_username(fields, usernames):\n\nusername = ((fields[FORENAME][0] + fields[MIDDLENAME][:1] +\n\nfields[SURNAME]).replace(\"-\", \"\").replace(\"'\", \"\"))\n\nusername = original_name = username[:8].lower() count = 1 while username in usernames:\n\nusername = \"{0}{1}\".format(original_name, count) count += 1\n\nusernames.add(username) return username\n\nWe make a ﬁrst attempt at creating a username by concatenating the ﬁrst let- ter of theforename,theﬁrstletter of themiddlename,andthewholesurname, and deleting any hyphens or single quotes from the resultant string. The code for getting the ﬁrst letter of the middle name is quite subtle. If we had used fields[MIDDLENAME][0] we would get an IndexError exception for empty middle names. But by using a slice we get the ﬁrst letter if there is one, or an empty string otherwise.\n\nNext wemaketheusernamelowercaseandnomorethan eight characterslong. If the username is in use (i.e., it is in the usernames set), we try the username with a “1” tacked on at the end, and if that is in use we try with a “2”, and so on until we get one that isn’t in use. Then we add the username to the set of usernames and return the username to the caller.\n\ndef print_users(users): namewidth = 32 usernamewidth = 9\n\nprint(\"{0:<{nw}} {1:^6} {2:{uw}}\".format(\n\n\"Name\", \"ID\", \"Username\", nw=namewidth, uw=usernamewidth))\n\nprint(\"{0:-<{nw}} {0:-<6} {0:-<{uw}}\".format(\n\n\"\", nw=namewidth, uw=usernamewidth))\n\n151",
      "content_length": 2225,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 161,
      "content": "str. format() 78➤\n\n152\n\nChapter 3. Collection Data Types\n\nfor key in sorted(users): user = users[key] initial = \"\" if user.middlename:\n\ninitial = \" \" +user.middlename[0]\n\nname = \"{0.surname}, {0.forename}{1}\".format(user, initial) print(\"{0:.<{nw}} ({1.id:4}) {1.username:{uw}}\".format( name, user, nw=namewidth, uw=usernamewidth))\n\nOnce all the records have been processed, the print_users() function is called, with the users dictionary passed as its parameter.\n\nThe ﬁrst print() statement prints the column titles, and the second print() statement prints hyphens under each title. This second statement’s str. format() call isslightly subtle. Thestring we give to beprintedis \"\",that is,the empty string—we get the hyphens by printing the empty string padded with hyphens to the given widths.\n\nNext we use a for … in loop to print the details of each user, extracting the key for each user’s dictionary item in sorted order. For convenience we create the user variable so that we don’t have to keep writing users[key] throughout the rest of the function. In the loop’s ﬁrst call to str.format() we set the name variable to the user’s name in surname, forename (and optional initial) form. We access items in the user named tuple by name. Once we have the user’s name as a single string we print the user’s details, constraining each column, (name, ID, username) to the widths we want.\n\nThe complete program (which differs from what we have reviewed only in that it has some initial comment lines and some imports) is in gener- ate_usernames.py. The program’s structure—read in a data ﬁle, process each record, write output—is one that is very frequently used, and we will meet it again in the next example.\n\nstatistics.py\n\nSuppose we have a bunch of data ﬁles containing numbers relating to some processing we have done, and we want to produce some basic statistics to give us some kind of overview of the data. Each ﬁle uses plain text (ASCII encoding) with one or more numbers per line (whitespace-separated).\n\nHere is an example of the kind of output we want to produce:\n\ncount = 183 mean = 130.56 median = 43.00 mode = [5.00, 7.00, 50.00] std. dev. = 235.01\n\n||",
      "content_length": 2168,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 162,
      "content": "Examples\n\nHere, we read 183 numbers, with 5, 7, and 50 occurring most frequently, and with a sample standard deviation of 235.01.\n\nThe statistics themselves are held in a named tuple called Statistics:\n\nStatistics = collections.namedtuple(\"Statistics\",\n\n\"mean mode median std_dev\")\n\nThe main() function also serves as an overview of the program’s structure:\n\ndef main():\n\nif len(sys.argv) == 1 or sys.argv[1] in {\"-h\", \"--help\"}:\n\nprint(\"usage: {0} file1 [file2 [... fileN]]\".format(\n\nsys.argv[0]))\n\nsys.exit()\n\nnumbers = [] frequencies = collections.defaultdict(int) for filename in sys.argv[1:]:\n\nread_data(filename, numbers, frequencies)\n\nif numbers:\n\nstatistics = calculate_statistics(numbers, frequencies) print_results(len(numbers), statistics)\n\nelse:\n\nprint(\"no numbers found\")\n\nWe store all the numbers from all the ﬁles in the numbers list. To calculate the mode(“mostfrequently occurring”)numbers,we need toknow how many times each number occurs, so we create a default dictionary using the int() factory function, to keep track of the counts.\n\nWe iterateover each ﬁlename and read in itsdata. We passthe list and default dictionary as additional parameters so that the read_data() function can update them. Once we have read all the data, assuming some numbers were successfully read, we call calculate_statistics(). This returns a named tuple of type Statistics which we then use to print the results.\n\ndef read_data(filename, numbers, frequencies):\n\nfor lino, line in enumerate(open(filename, encoding=\"ascii\"),\n\nstart=1):\n\nfor x in line.split():\n\ntry:\n\nnumber = float(x) numbers.append(number) frequencies[number] += 1\n\nexcept ValueError as err:\n\nprint(\"{filename}:{lino}: skipping {x}: {err}\".format(\n\n**locals()))\n\n153",
      "content_length": 1734,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 163,
      "content": "Us- ing str. format() with map- ping un- packing 81➤\n\n154\n\nChapter 3. Collection Data Types\n\nWe split every line on whitespace,and for each item we attempt to convert it to a float. If a conversion succeeds—as it will for integers and for ﬂoating-point numbers in both decimal and exponential notations—we add the number to the numbers list and update the frequencies default dictionary. (If we had used a plain dict, the update code would have been frequencies[number] = frequen- cies.get(number, 0) + 1.)\n\nIf a conversion fails, we output the line number (starting from line 1 as is tra- ditional for text ﬁles), the text we attempted to convert, and the ValueError exception’s error text. Rather than using positional arguments (e.g., .for- mat(filename, lino, etc.,or explicitlynamedarguments,.format(filename=file- name, lino=lino, etc.), we have retrieved the names and values of the local variables by calling locals() and used mapping unpacking to pass these as key–value named arguments to the str.format() method.\n\ndef calculate_statistics(numbers, frequencies):\n\nmean = sum(numbers) / len(numbers) mode = calculate_mode(frequencies, 3) median = calculate_median(numbers) std_dev = calculate_std_dev(numbers, mean) return Statistics(mean, mode, median, std_dev)\n\nThis function is used to gather all the statistics together. Because the mean (“average”)issoeasy tocalculate,wedosodirectlyhere. Fortheotherstatistics we call dedicated functions,and at the end we return a Statistics named tuple object that contains the four statistics we have calculated.\n\ndef calculate_mode(frequencies, maximum_modes):\n\nhighest_frequency = max(frequencies.values()) mode = [number for number, frequency in frequencies.items()\n\nif frequency == highest_frequency]\n\nif not (1 <= len(mode) <= maximum_modes):\n\nmode = None\n\nelse:\n\nmode.sort()\n\nreturn mode\n\nThere may be more than one most-frequently-occurring number, so in ad- dition to the dictionary of frequencies, this function also requires the caller to specify the maximum number of modes that are acceptable. (The cal- culate_statistics() function is the caller, and it speciﬁed a maximum of three modes.)\n\nThe max() function is used to ﬁnd the highest value in the frequencies dictio- nary. Then, we use a list comprehension to create a list of those modes whose frequency equals the highest value. We can compare using operator == since all the frequencies are integers.",
      "content_length": 2420,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 164,
      "content": "Examples\n\nIf the number of modes is 0 or greater than the maximum modes that are acceptable, a mode of None is returned; otherwise, a sorted list of the modes is returned.\n\ndef calculate_median(numbers):\n\nnumbers = sorted(numbers) middle = len(numbers) // 2 median = numbers[middle] if len(numbers) % 2 == 0:\n\nmedian = (median + numbers[middle - 1]) / 2\n\nreturn median\n\nThe median (“middle value”) is the value that occurs in the middle if the numbers are arranged in order—except when the number of numbers is even, in which case themiddlefallsbetween twonumbers,so in that casethemedian is the mean of the two middle numbers.\n\nWebeginby sorting thenumbersintoascending order. Then weusetruncating (integer) division to ﬁnd the index position of the middle number, which we extract and store as the median. If the number of numbers is even, we make the median the mean of the two middle numbers.\n\ndef calculate_std_dev(numbers, mean):\n\ntotal = 0 for number in numbers:\n\ntotal += ((number - mean) ** 2)\n\nvariance = total / (len(numbers) - 1) return math.sqrt(variance)\n\nThe sample standard deviation is a measure of dispersion,that is, how far the numbers differ from the mean. This function calculates the sample standard deviation using the formula s =√∑(x − −x 2) n− 1 , where x is each number, −x is the mean, and n is the number of numbers.\n\ndef print_results(count, statistics):\n\nreal = \"9.2f\"\n\nif statistics.mode is None:\n\nmodeline = \"\"\n\nelif len(statistics.mode) == 1:\n\nmodeline = \"mode\n\n= {0:{fmt}}\\n\".format(\n\nstatistics.mode[0], fmt=real)\n\nelse:\n\nmodeline = (\"mode\n\n= [\" +\n\n\", \".join([\"{0:.2f}\".format(m) for m in statistics.mode]) + \"]\\n\")\n\nprint(\"\"\"\\\n\n155",
      "content_length": 1668,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 165,
      "content": "str. format() 78➤\n\nNamed tuple 111➤\n\nUs- ing str. format() with map- ping un- packing 81➤\n\n156\n\nChapter 3. Collection Data Types\n\ncount mean median {1}\\ std. dev. = {std_dev:{fmt}}\"\"\".format(\n\n= {0:6} = {mean:{fmt}} = {median:{fmt}}\n\ncount, modeline, fmt=real, **statistics._asdict()))\n\nMost of thisfunction isconcerned with formatting the modeslist into the mode- line string. If there are no modes, the mode line is not printed at all. If there is one mode, the mode list has just one item (mode[0]) which is printed using the same format as is used for the other statistics. If there are several modes, we print them as a list with each one formatted appropriately. This is done by using a list comprehension to produce a list of mode strings, and then joining all the strings in the list together with “, ” in between each one. The printing at the end is easy thanksto our use of a named tuple and its _asdict() method, in conjunction with mapping unpacking. This lets us access the statistics in the statistics object using names rather than numeric indexes, and thanks to Python’striple-quoted stringswe can lay out the text to be printed in an under- standable way. Recall that if we use mapping unpacking to pass argumentsto the str.format() method, it may be done only once and only at the end.\n\nThere is one subtle point to note. The modes are printed as format item {1}, which is followed by a backslash. The backslash escapes the newline, so if the mode is the empty string no blank line will appear. And it is because we have escaped the newline that we must put \\n at the end of the modeline string if it is not empty.\n\nSummary\n\nIn this chapter we covered all of Python’s built-in collection types, and also a couple of collection types from the standard library. We covered the collection sequence types, tuple, collections.namedtuple, and list, which support the same slicing and striding syntax as strings. The use of the sequence unpack- ing operator (*) was also covered,and brief mention was made of starred argu- ments in function calls. We also covered the set types, set and frozenset, and the mapping types, dict and collections.defaultdict.\n\nWe saw how to use the named tuples provided by Python’s standard library to create simple custom tuple data types whose items can be accessed by index position,or more conveniently,by name. We also saw how to create“constants” by using variables with all uppercase names.\n\nIn the coverage of lists we saw that everything that can be done to tuples can be done to lists. And thanks to lists being mutable they offer considerably more functionality than tuples. This includes methods that modify the list\n\n|||",
      "content_length": 2674,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 166,
      "content": "Summary\n\n(e.g., list.pop()), and the ability to have slices on the left-hand side of an as- signment, to provide insertion, replacement, and deletion of slices. Lists are ideal for holding sequences of items, especially if we need fast access by index position.\n\nWhen we discussed the set and frozenset types, we noted that they may contain only hashable items. Sets provide fast membership testing and are useful for ﬁltering out duplicate data.\n\nDictionaries are in some ways similar to sets—for example, their keys must be hashable and are unique just like the items in a set. But dictionaries hold key–value pairs, whose values can be of any type. The dictionary coverage included the dict.get() and dict.setdefault() methods, and the coverage of default dictionaries showed an alternative to using these methods. Like sets, dictionaries provide very fast membership testing and fast access by key.\n\nLists,sets,and dictionariesall offer compact comprehension syntaxesthat can be used to create collections of these types from iterables (which themselves can be comprehensions),and with conditionsattached if required. The range() and zip() functions are frequently used in the creation of collections, both in conventional for … in loops and in comprehensions.\n\nItems can be deleted from the mutable collection types using the relevant methods, such as list.pop() and set.discard(), or using del, for example, del d[k] to delete an item with key k from dictionary d.\n\nPython’s use of object references makes assignment extremely efﬁcient, but it also means that objects are not copied when the assignment operator (=) is used. We saw the differences between shallow and deep copying, and later on sawhowlistscanbeshallow-copiedusing a sliceof theentirelist,L[:],andhow dictionariescanbeshallow-copiedusing the dict.copy() method. Any copyable object can be copied using functions from the copy module, with copy.copy() performing a shallow copy, and copy.deepcopy() performing a deep copy.\n\nWe introduced Python’s highly optimized sorted() function. This function is used a lot in Python programming, since Python doesn’t provide any intrinsi- cally ordered collection data types, so when we need to iterate over collections in sorted order, we use sorted().\n\nPython’s built-in collection data types—tuples, lists, sets, frozen sets, and dictionaries—are sufﬁcient in themselves for all purposes. Nonetheless,a few additional collection types are available in the standard library, and many more are available from third parties.\n\nWe often need to read in collections from ﬁles, or write collections to ﬁles. In this chapter we focused just on reading and writing lines of text in our very brief coverage of text ﬁle handling. Full coverage of ﬁle handling is given in Chapter 7, and additional means of providing data persistence is covered in Chapter 12.\n\n157",
      "content_length": 2865,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 167,
      "content": "158\n\nChapter 3. Collection Data Types\n\nIn the next chapter, we will look more closely at Python’s control structures, andintroduceonethatwehavenot seenbefore. Wewillalsolook inmoredepth at exception-handling and at some additional statements, such as assert, that we have not yet covered. In addition,we will cover the creation of customfunc- tions,and in particular we will look at Python’sincredibly versatile argument- handling facilities.\n\nExercises\n\n1. Modify the external_sites.py program to use a default dictionary. This is an easy change requiring an additional import, and changes to just two other lines. A solution is provided in external_sites_ans.py.\n\n2. Modify the uniquewords2.py program so that it outputs the words in fre- quency of occurrence order rather than in alphabetical order. You’ll need to iterate over the dictionary’s items and create a tiny two-line function to extract each item’s value and pass this function as sorted()’s key func- tion. Also, the call to print() will need to be changed appropriately. This isn’t difﬁcult, but it is slightly subtle. A solution is provided in unique- words_ans.py.\n\n3. Modify the generate_usernames.py program so that it prints the details of two users per line, limiting names to 17 characters and outputting a form feed character after every 64 lines, with the column titles printed at the start of every page. Here’s a sample of the expected output: Name ID Username Name ID Username ----------------- ------ --------- ----------------- ------ --------- Aitkin, Shatha... (2370) saitkin Alderson, Nicole. (8429) nalderso Allison, Karma... (8621) kallison Alwood, Kole E... (2095) kealwood Annie, Neervana.. (2633) nannie Apperson, Lucyann (7282) leappers\n\nThis is challenging. You’ll need to keep the column titles in variables so that they can be printed when needed,and you’ll need to tweak the format speciﬁcations to accommodate the narrower names. One way to achieve pagination is to write all the output items to a list and then iterate over thelist using striding toget theleft-and right-handitems,and using zip() to pair them up. A solution is provided in generate_usernames_ans.py and a longer sample data ﬁle is provided in data/users2.txt.\n\n|||",
      "content_length": 2226,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 168,
      "content": "4\n\nControl Structures ● Exception Handling ● Custom Functions\n\nControl Structures and Functions\n\nThis chapter’s ﬁrst two sections cover Python’s control structures, with the ﬁrst section dealing with branching and looping and the second section cov- ering exception-handling. Most of the control structures and the basics of exception-handling were introduced in Chapter 1, but here we give more com- plete coverage, including additional control structure syntaxes, and how to raise exceptions and create custom exceptions.\n\nThe third and largest section is devoted to creating custom functions, with detailed coverageof Python’sextremely versatileargument handling. Custom functionsallow us to package up and parameterizefunctionality—thisreduces the size of our code by eliminating code duplication and provides code reuse. (In the following chapter we will see how to create custom modules so that we can make use of our custom functions in multiple programs.)\n\nControl Structures\n\nPython provides conditional branching with if statements and looping with while and for …in statements. Python also has a conditional expression—this is a kind of if statement that is Python’s answer to the ternary operator (?:) used in C-style languages.\n\nConditional Branching\n\nAs we saw in Chapter 1, this is the general syntax for Python’s conditional branch statement:\n\nif boolean_expression1:\n\nsuite1\n\n159\n\n||||\n\n|||\n\n||",
      "content_length": 1411,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 170,
      "content": "Control Structures\n\nThe parentheses also make things clearer for human readers.\n\nConditional expressions can be used to improve messages printed for users. For example, when reporting the number of ﬁles processed, instead of print- ing “0 ﬁle(s)”, “1 ﬁle(s)”, and similar, we could use a couple of conditional ex- pressions:\n\nprint(\"{0} file{1}\".format((count if count != 0 else \"no\"),\n\n(\"s\" if count != 1 else \"\")))\n\nThis will print “no ﬁles”,“1ﬁle”,“2 ﬁles”,and similar,which gives a much more professional impression.\n\nLooping\n\nPython provides a while loop and a for … in loop, both of which have a more sophisticated syntax than the basics we showed in Chapter 1.\n\nwhile Loops\n\nHere is the complete general syntax of the while loop:\n\nwhile boolean_expression:\n\nwhile_suite\n\nelse:\n\nelse_suite\n\nThe else clause is optional. As long as the boolean_expression is True, the while block’s suite is executed. If the boolean_expression is or becomes False, the loop terminates,and if the optional else clause is present,its suite is executed. Inside the while block’s suite, if a continue statement is executed, control is immediately returned to the top of the loop, and the boolean_expression is evaluated again. If the loop does not terminate normally, any optional else clause’s suite is skipped.\n\nThe optional else clause is rather confusingly named since the else clause’s suite is always executed if the loop terminates normally. If the loop is broken out of due to a break statement, or a return statement (if the loop is in a function or method), or if an exception is raised, the else clause’s suite is not executed. (If an exception occurs, Python skips the else clause and looks for a suitable exception handler—this is covered in the next section.) On the plus side, the behavior of the else clause is the same for while loops, for …in loops, and try … except blocks.\n\nLet’s look at an example of the else clause in action. The str.index() and list.index() methods return the index position of a given string or item, or raise a ValueError exception if the string or item is not found. The str.find()\n\n161\n\n||\n\n|",
      "content_length": 2121,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 171,
      "content": "enumer- ate() 139➤\n\n162\n\nChapter 4. Control Structures and Functions\n\nmethod does the same thing, but on failure, instead of raising an exception it returnsan index of -1.Thereisno equivalent methodfor lists,but if wewanted a function that did this, we could create one using a while loop:\n\ndef list_find(lst, target):\n\nindex = 0 while index < len(lst):\n\nif lst[index] == target:\n\nbreak\n\nindex += 1\n\nelse:\n\nindex = -1\n\nreturn index\n\nThis function searches the given list looking for the target. If the target is found, the break statement terminates the loop, causing the appropriate index position to be returned. If the target is not found, the loop runs to completion and terminatesnormally. After normal termination,the else suite isexecuted, and the index position is set to -1 and returned.\n\nfor Loops\n\nLike a while loop, the full syntax of the for … in loop also includes an optional else clause:\n\nfor expression in iterable:\n\nfor_suite\n\nelse:\n\nelse_suite\n\nThe expression is normally either a single variable or a sequence of variables, usually in the form of a tuple. If a tuple or list is used for the expression, each item is unpacked into the expression’s items.\n\nIf a continue statement is executed inside the for … in loop’s suite, control is immediately passed to the top of the loop and the next iteration begins. If the loop runs to completion it terminates, and any else suite is executed. If the loop isbroken out of due to a break statement,or a return statement (if the loop is in a function or method), or if an exception is raised, the else clause’s suite is not executed. (If an exception occurs,Python skips the else clause and looks for a suitable exception handler—this is covered in the next section.)\n\nHere is a for … in loop version of the list_find() loop version, it shows the else clause in action:\n\nfunction, and like the while\n\ndef list_find(lst, target):\n\nfor index, x in enumerate(lst):\n\n|",
      "content_length": 1925,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 172,
      "content": "Control Structures\n\nif x == target:\n\nbreak\n\nelse:\n\nindex = -1\n\nreturn index\n\nAsthiscode snippet implies,the variablescreated in the for …in loop’s expres- sion continue to exist after the loop has terminated. Like all local variables, they cease to exist at the end of their enclosing scope.\n\nException Handling\n\nPython indicates errors and exceptional conditions by raising exceptions, al- though some third-party Python libraries use more old-fashioned techniques, such as “error” return values.\n\nCatching and Raising Exceptions\n\nExceptions are caught using try … except blocks, whose general syntax is:\n\ntry:\n\ntry_suite\n\nexcept exception_group1 as variable1:\n\nexcept_suite1\n\n… except exception_groupN as variableN:\n\nexcept_suiteN\n\nelse:\n\nelse_suite\n\nfinally:\n\nfinally_suite\n\nThere must be at least one except block, but both the else and the finally blocksareoptional. The else block’ssuiteisexecutedwhenthe try block’ssuite has ﬁnished normally—but it is not executed if an exception occurs. If there is a finally block, it is always executed at the end.\n\nEach except clause’s exception group can be a single exception or a parenthe- sized tuple of exceptions. For each group, the as variable part is optional; if used,the variable contains the exception that occurred,and can be accessed in the exception block’s suite.\n\nIf an exception occurs in the try block’s suite, each except clause is tried in turn. If the exception matches an exception group, the corresponding suite is executed. Tomatchan exceptiongroup,theexceptionmust beof thesametype\n\n163\n\n|||\n\n||",
      "content_length": 1566,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 175,
      "content": "166\n\nChapter 4. Control Structures and Functions\n\nHere is a ﬁnal version of the list_find() function, this time using exception- handling:\n\ndef list_find(lst, target):\n\ntry:\n\nindex = lst.index(target)\n\nexcept ValueError: index = -1\n\nreturn index\n\nHere, we have effectively used the try … except block to turn an exception into a return value; the same approach can also be used to catch one kind of exception and raise another instead—a technique we will see shortly.\n\nPython also offers a simpler try … finally block which is sometimes useful:\n\ntry:\n\ntry_suite\n\nfinally:\n\nfinally_suite\n\nNo matter what happens in the try block’s suite (apart from the computer or program crashing!), the finally block’s suite will be executed. The with statement used with a context manager (both covered in Chapter 8) can be used to achieve a similar effect to using a try … finally block.\n\nOne common pattern of use for try … except … finally blocks is for handling ﬁle errors. For example, the noblanks.py program reads a list of ﬁlenames on the command line, and for each one produces another ﬁle with the same name, but with its extension changed to .nb,and with the same contentsexcept for no blank lines. Here’s the program’s read_data() function:\n\ndef read_data(filename):\n\nlines = [] fh = None try:\n\nfh = open(filename, encoding=\"utf8\") for line in fh:\n\nif line.strip():\n\nlines.append(line)\n\nexcept (IOError, OSError) as err:\n\nprint(err) return []\n\nfinally:\n\nif fh is not None: fh.close()\n\nreturn lines",
      "content_length": 1495,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 176,
      "content": "Exception Handling\n\nWe set the ﬁle object, fh, to None because it is possible that the open() call will fail, in which case nothing will be assigned to fh (so it will stay as None), and an exception will be raised. If one of the exceptions we have speciﬁed occurs (IOError or OSError), after printing the error message we return an empty list. But note that beforereturning,the finally block’s suite will be executed,so the ﬁle will be safely closed—if it had been successfully opened in the ﬁrst place.\n\nNotice also that if an encoding error occurs, even though we don’t catch the relevant exception (UnicodeDecodeError), the ﬁle will still be safely closed. In such casesthe finally block’ssuiteisexecutedand then theexceptionispassed up the call stack—there is no return value since the function ﬁnishes as a result of the unhandled exception. And in this case, since there is no suitable except block to catch encoding error exceptions, the program will terminate and print a traceback.\n\nWe could have written the except clause slightly less verbosely:\n\nexcept EnvironmentError as err:\n\nprint(err) return []\n\nThis works because EnvironmentError is the base class for both IOError and OSError.\n\nIn Chapter 8we will show a are safely closed, that does not require a finally block.\n\nslightly more compact idiom for ensuring that ﬁles\n\nRaising Exceptions\n\nExceptions provide a useful means of changing the ﬂow of control. We can take advantage of this either by using the built-in exceptions, or by creating our own, raising either kind when we want to. There are three syntaxes for raising exceptions:\n\nraise exception(args) raise exception(args) from original_exception raise\n\nWhen the ﬁrst syntax is used the exception that is speciﬁed should be either one of the built-in exceptions, or a custom exception that is derived from Exception. If we give the exception some text as its argument, this text will be output if the exception is printed when it is caught. The second syntax is a exception is raised as a chained exception (covered variation of the ﬁrst—the in Chapter 9) that includes the original_exception exception, so this syntax is used inside except suites. When the third syntax is used, that is, when no exception is speciﬁed, raise will reraise the currently active exception—and if there isn’t one it will raise a TypeError.\n\n167\n\n|\n\nDeal- ing with runtime errors ➤ 415\n\nContext man- agers ➤ 369\n\nChained excep- tions ➤ 419",
      "content_length": 2443,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 177,
      "content": "168\n\nChapter 4. Control Structures and Functions\n\nCustom Exceptions\n\nCustom exceptions are custom data types (classes).Creating classes is covered in Chapter 6, but since it is easy to create simple custom exception types, we will show the syntax here:\n\nclass exceptionName(baseException): pass\n\nThe base class should be Exception or a class that inherits from Exception.\n\nOne use of custom exceptions is to break out of deeply nested loops. For example, if we have a table object that holds records (rows), which hold ﬁelds (columns),which have multiple values(items),we could search for a particular value with code like this:\n\nfound = False for row, record in enumerate(table):\n\nfor column, field in enumerate(record):\n\nfor index, item in enumerate(field):\n\nif item == target:\n\nfound = True break\n\nif found: break\n\nif found: break\n\nif found:\n\nprint(\"found at ({0}, {1}, {2})\".format(row, column, index))\n\nelse:\n\nprint(\"not found\")\n\nThe 15lines of code are complicated by the fact that we must break out of each loop separately. An alternative solution is to use a custom exception:\n\nclass FoundException(Exception): pass\n\ntry:\n\nfor row, record in enumerate(table):\n\nfor column, field in enumerate(record):\n\nfor index, item in enumerate(field):\n\nif item == target:\n\nraise FoundException()\n\nexcept FoundException:\n\nprint(\"found at ({0}, {1}, {2})\".format(row, column, index))\n\nelse:\n\nprint(\"not found\")\n\n||",
      "content_length": 1407,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 178,
      "content": "Exception Handling\n\nThis cuts the code down to ten lines, or 11 including deﬁning the exception, and is much easier to read. If the item is found we raise our custom exception and the except block’s suite is executed—and the else block is skipped. And if the item is not found,no exception is raised and so the else suite is executed at the end.\n\nLet’s look at another example to see some of the different ways that exception- handling can be done. All of the snippets are taken from the checktags.py pro- gram, a program that reads all the HTML ﬁles it is given on the command line and performssome simple tests to verify that tags begin with “<” and end with “>”, and that entities are correctly formed. The program deﬁnes four custom exceptions:\n\nclass InvalidEntityError(Exception): pass class InvalidNumericEntityError(InvalidEntityError): pass class InvalidAlphaEntityError(InvalidEntityError): pass class InvalidTagContentError(Exception): pass\n\nThe second and third exceptions inherit from the ﬁrst; we will see why this is useful when we discussthe code that usesthe exceptions. The parse() function that uses the exceptions is more than 70 lines long, so we will show only those parts that are relevant to exception-handling.\n\nfh = None try:\n\nfh = open(filename, encoding=\"utf8\") errors = False for lino, line in enumerate(fh, start=1):\n\nfor column, c in enumerate(line, start=1):\n\ntry:\n\nThe code begins conventionally enough, setting the ﬁle object to None and putting all the ﬁle handling in a try block. The program reads the ﬁle line by line and reads each line character by character.\n\nNotice that we have two try blocks; the outer one is used to handle ﬁle object exceptions, and the inner one is used to handle parsing exceptions.\n\n... elif state == PARSING_ENTITY:\n\nif c == \";\":\n\nif entity.startswith(\"#\"):\n\nif frozenset(entity[1:]) - HEXDIGITS: raise InvalidNumericEntityError()\n\nelif not entity.isalpha():\n\n...\n\nraise InvalidAlphaEntityError()\n\n169",
      "content_length": 1968,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 179,
      "content": "set type 121➤\n\n170\n\nChapter 4. Control Structures and Functions\n\nThe function has various states, for example, after reading an ampersand (&), it enters the PARSING_ENTITY state, and stores the characters between (but excluding) the ampersand and semicolon in the entity string.\n\nThe part of the code shown here handles the case when a semicolon has been found while reading an entity. If the entity is numeric (of the form “&#”, with we convert the hexadecimal digits, and then “;”, for example, “&#20AC;”), numeric part of it into a set and take away from the set all the hexadecimal digits; if anything is left at least one invalid character was present and we raise a custom exception. If the entity is alphabetic (of the form “&”, with letters, and then“;”, for example, “&copy;”), we raise a custom exception if any of its letters is not alphabetic.\n\n... except (InvalidEntityError,\n\nInvalidTagContentError) as err:\n\nif isinstance(err, InvalidNumericEntityError):\n\nerror = \"invalid numeric entity\"\n\nelif isinstance(err, InvalidAlphaEntityError):\n\nerror = \"invalid alphabetic entity\"\n\nelif isinstance(err, InvalidTagContentError):\n\nerror = \"invalid tag\"\n\nprint(\"ERROR {0} in {1} on line {2} column {3}\"\n\n.format(error, filename, lino, column))\n\nif skip_on_first_error:\n\nraise\n\n...\n\nIf a parsing exception is raised we catch it in this except block. By using the InvalidEntityError base class, we catch both InvalidNumericEntityError and InvalidAlphaEntityError exceptions. We then use isinstance() to check which type of exception occurred, and to set the error message accordingly. The built-in isinstance() functionreturnsTrue if itsﬁrst argumentisthesametype as the type (or one of that type’s base types) given as its second argument.\n\nWe could have used a separate except block for each of the three custom parsing exceptions, but in this case combining them means that we avoided repeating the last four lines (from the print() call to raise), in each one.\n\nThe program has two modes of use. If skip_on_first_error is False, the pro- gram continues checking a ﬁle even after a parsing error has occurred; this can lead to multiple error messages being output for each ﬁle. If skip_on_first_error is True, once a parsing error has occurred, after the (one and only) error message is printed, raise is called to reraise the parsing excep- tion and the outer (per-ﬁle) try block is left to catch it.\n\nisin- stance() ➤ 242",
      "content_length": 2429,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 180,
      "content": "Exception Handling\n\n... elif state == PARSING_ENTITY:\n\n...\n\nraise EOFError(\"missing ';' at end of \" + filename)\n\nAt theendof parsing a ﬁle,weneedtocheck toseewhether wehavebeenleftin the middleof an entity. If we have,we raise an EOFError,the built-in end-of-ﬁle exception,but give it our own messagetext. We could just aseasily haveraised a custom exception.\n\nexcept (InvalidEntityError, InvalidTagContentError):\n\npass # Already handled\n\nexcept EOFError as err:\n\nprint(\"ERROR unexpected EOF:\", err)\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nfinally:\n\nif fh is not None: fh.close()\n\nFor the outer try block we have used separate except blocks since the behavior wewantvaries. If wehavea parsing exception,weknowthatanerrormessage has already been output and the purpose is simply to break out of reading the ﬁle and to move on to the next ﬁle, so we don’t need to do anything in the ex- ception handler. If we get an EOFError it could be caused by a genuine prema- ture end of ﬁle or it could be the result of us raising the exception ourselves. In either case, we print an error message, and the exception’s text. If an Envi- ronmentError occurs (i.e.,if an IOError or an OSError occurs),we simply print its message. And ﬁnally, no matter what, if the ﬁle was opened, we close it.\n\nCustom Functions\n\nFunctionsarea meansby which wecanpackageupandparameterizefunction- ality. Four kinds of functions can be created in Python: global functions, local functions, lambda functions, and methods.\n\nEvery function we have created so far has been a global function. Global objects (including functions) are accessible to any code in the same module (i.e.,the same .py ﬁle) in which the object is created. Global objects can also be accessed from other modules, as we will see in the next chapter.\n\nLocal functions (also called nested functions) are functions that are deﬁned inside other functions. These functions are visible only to the function where they are deﬁned; they are especially useful for creating small helper functions that have no use elsewhere. We ﬁrst show them in Chapter 7.\n\n171\n\n|||",
      "content_length": 2099,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 181,
      "content": "172\n\nChapter 4. Control Structures and Functions\n\nOnline Documentation\n\nAlthough this book provides solid coverage of the Python 3 language and the built-in functions and most commonly used modules in the standard library, Python’s online documentation provides a considerable amount of reference documentation, both on the language, and particularly on Python’s extensive standard library. The documentation is available online at docs.python.org and is also provided with Python itself.\n\nOn Windowsthe documentation is supplied in the Windowshelp ﬁle format. Click Start→All Programs→Python 3.x→Python Manuals to launch the Windows help browser. Thistool has both an Index and a Search function that makes ﬁnding documentation easy. Unix users have the documentation in HTML format. In addition to the hyperlinks,there are various index pages. There isalsoa very convenient Quick Searchfunction availableon theleft-handside of each page.\n\nThe most frequently used online document for new users is the Library Reference, and for experienced users the Global Module Index. Both of these have links to pages covering Python’s entire standard library—and in the case of the Library Reference, links to pages covering all of Python’s built-in functionality as well.\n\nIt is well worth skimming through the documentation, particularly the Li- brary Reference or the Global Module Index, to see what Python’s standard library offers, and clicking through to the documentation of whichever top- icsareof interest. Thisshouldprovideaninitialimpressionof whatisavail- able and should also help you to establish a mental pictureof where you can ﬁnd the documentation you are interested in. (A brief summary of Python’s standard library is provided in Chapter 5.)\n\nHelp is also available from the interpreter itself. If you call the built- in help() function with no arguments, you will enter the online help system—simply follow the instructions to get the information you want, and type “q” or “quit” to return to the interpreter. If you know what module or data type you want help on, you can call help() with the module or data typeasitsargument. Forexample,help(str) providesinformationonthestr data type, including all of its methods, help(dict.update) provides informa- tion on the dict collection data type’supdate() method,and help(os) displays information about the os module (providing it has been imported).\n\nOnce familiar with Python, it is often sufﬁcient to just be reminded about what attributes(e.g.,what methods) a data type provides. This information is available using the dir() function—for example, dir(str) lists all the string methods,and dir(os) lists all the os module’sconstantsand functions (again, providing the module has been imported).",
      "content_length": 2756,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 182,
      "content": "Custom Functions\n\nLambdafunctions are expressions,so they can be created at their point of use; however, they are much more limited than normal functions.\n\nMethods are functions that are associated with a particular data type and can be used only in conjunction with the data type—they are introduced in Chapter 6 when we cover object-oriented programming.\n\nPython provides many built-in functions, and the standard library and third- party libraries add hundreds more (thousands if we count all the methods),so in many casesthe function we want has already been written. For this reason, it is always worth checking Python’s online documentation to see what is al- ready available. See the sidebar “Online Documentation” (172➤).\n\nThe general syntax for creating a (global or local) function is:\n\ndef functionName(parameters):\n\nsuite\n\nTheparametersareoptional,andif thereismorethanonethey arewrittenasa sequence of comma-separated identiﬁers,or as a sequence of identifier=value pairs as we will discussshortly. For example,here is a function that calculates the area of a triangle using Heron’s formula:\n\ndef heron(a, b, c):\n\ns = (a + b + c) / 2 return math.sqrt(s * (s - a) * (s - b) * (s - c))\n\nInside the function, each parameter, a, b, and c, is initialized with the corre- sponding value that was passed as an argument. When the function is called, we must supply all of the arguments,for example,heron(3, 4, 5).If we give too few or too many arguments, a TypeError exception will be raised. When we do a call like thiswe are said to be using positionalarguments,because each argu- ment passed is set as the value of the parameter in the corresponding position. So in this case, a is set to 3, b to 4, and c to 5, when the function is called.\n\nEvery function in Python returns a value, although it is perfectly acceptable (and common) to ignore the return value. The return value is either a single value or a tuple of values, and the values returned can be collections, so there are no practical limitations on what we can return. We can leave a function at any point by using the return statement. If we use return with no arguments, or if we don’t have a return statement at all, the function will return None. (In Chapter 6 we will cover the yield statement which can be used instead of return in certain kinds of functions.)\n\nSome functionshave parametersfor which there can be a sensible default. For example, here is a function that counts the letters in a string,defaulting to the ASCII letters:\n\n173",
      "content_length": 2514,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 183,
      "content": "174\n\nChapter 4. Control Structures and Functions\n\ndef letter_count(text, letters=string.ascii_letters):\n\nletters = frozenset(letters) count = 0 for char in text:\n\nif char in letters: count += 1\n\nreturn count\n\nWe have speciﬁed a default value for the letters parameter by using the parameter=default syntax. This allows us to call letter_count() with just one argument, for example, letter_count(\"Maggie and Hopey\"). Here, inside the function, letters will be the string that was given as the default value. But we can still change the default, for example, using an extra positional argument, letter_count(\"Maggie and Hopey\", \"aeiouAEIOU\"), or using a keyword argument (covered next), letter_count(\"Maggie and Hopey\", letters=\"aeiouAEIOU\").\n\nThe parameter syntax does not permit us to follow parameters with default values with parameters that don’t have defaults, so def bad(a, b=1, c): won’t work. On the other hand, we are not forced to pass our arguments in the order they appear in the function’s deﬁnition—instead, we can use keyword arguments, passing each argument in the form name=value.\n\nHere is a tiny function that returns the string it is given, or if it is longer than the speciﬁed length, it returns a shortened version with an indicator added:\n\ndef shorten(text, length=25, indicator=\"...\"):\n\nif len(text) > length:\n\ntext = text[:length - len(indicator)] + indicator\n\nreturn text\n\nHere are a few example calls:\n\n# returns: 'The Silkie' shorten(\"The Silkie\") # returns: 'The ...' shorten(length=7, text=\"The Silkie\") shorten(\"The Silkie\", indicator=\"&\", length=7) # returns: 'The Si&' # returns: 'The Si&' shorten(\"The Silkie\", 7, \"&\")\n\nBecause both length and indicator have default values, either or both can be omitted entirely, in which case the default is used—this is what happens in the ﬁrst call. In the second call we use keyword arguments for both of the speciﬁed parameters, so we can order them as we like. The third call mixes both positional and keyword arguments. We used a positional ﬁrst argument (positionalargumentsmustalwaysprecedekeywordarguments),andthentwo keyword arguments. The fourth call simply uses positional arguments.\n\nThe difference between a mandatory parameter and an optional parameter is that a parameter with a default is optional (because Python can use the default), and a parameter with no default is mandatory (because Python can-",
      "content_length": 2386,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 185,
      "content": "176\n\nChapter 4. Control Structures and Functions\n\nUsing a conditional expression we can save a line of code for each parameter that has a mutable default argument.\n\nNames and Docstrings\n\nUsing good names for a function and its parameters goes a long way toward making the purpose and use of the function clear to other programmers—and to ourselvessome timeafter we have createdthe function. Hereare a few rules of thumb that you might like to consider.\n\nUse a naming scheme, and use it consistently. In this book we use UP- PERCASE for constants, TitleCase for classes (including exceptions), camel- Case for GUI (Graphical User Interface) functions and methods (covered in Chapter 15), and lowercase or lowercase_with_underscores for every- thing else.\n\nFor all names,avoid abbreviations,unless they are both standardized and widely used.\n\nBe proportional with variable and parameter names: x is a perfectly good name for an x-coordinate and i is ﬁne for a loop counter,but in general the name should be long enough to be descriptive. The name should describe thedata’smeaning rather than itstype(e.g.,amount_due rather than money), unless the use is generic to a particular type—see, for example, the text parameter in the shorten() example (➤ 177).\n\nFunctions and methods should have names that say what they do or what they return (depending on their emphasis), but never how they do it—since that might change.\n\nHere are a few naming examples:\n\ndef find(l, s, i=0): def linear_search(l, s, i=0): def first_index_of(sorted_name_list, name, start=0): # GOOD\n\n# BAD # BAD\n\nAll three functions return the index position of the ﬁrst occurrence of a name in a list of names, starting from the given starting index and using an algorithm that assumes the list is already sorted.\n\nThe ﬁrst one is bad because the name gives no clue as to what will be found, and its parameters (presumably) indicate the required types (list, string, inte- ger) without indicating what they mean. The second one is bad because the function name describes the algorithm originally used—it might have been changed since. This may not matter to users of the function, but it will proba- bly confuse maintainersif the name implies a linear search,but the algorithm implemented has been changed to a binary search. The third one is good be-\n\n||",
      "content_length": 2318,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 186,
      "content": "Se- quence unpack- ing 114➤\n\nCustom Functions\n\ncausethefunctionnamesayswhatisreturned,andtheparameternamesclear- ly indicate what is expected.\n\nNone of the functions have any way of indicating what happens if the name isn’t found—do they return, say, -1, or do they raise an exception? Somehow such information needs to be documented for users of the function.\n\nWe can add documentationto any function by using a docstring—thisissimply a string that comes immediately after the def line, and before the function’s code proper begins. For example,here is the shorten() function we saw earlier, but this time reproduced in full:\n\ndef shorten(text, length=25, indicator=\"...\"):\n\n\"\"\"Returns text or a truncated copy with the indicator added\n\ntext is any string; length is the maximum length of the returned string (including any indicator); indicator is the string added at the end to indicate that the text has been shortened\n\n>>> shorten(\"Second Variety\") 'Second Variety' >>> shorten(\"Voices from the Street\", 17) 'Voices from th...' >>> shorten(\"Radio Free Albemuth\", 10, \"*\") 'Radio Fre*' \"\"\" if len(text) > length:\n\ntext = text[:length - len(indicator)] + indicator\n\nreturn text\n\nIt isnot unusualfor a functionor method’sdocumentationtobelonger thanthe function itself. One convention is to make the ﬁrst line of the docstring a brief one-line description, then have a blank line followed by a full description, and thentoreproducesomeexamplesasthey wouldappearif typedininteractively. In Chapter 5 and Chapter 9 we will see how examples in function documenta- tion can be used to provide unit tests.\n\nArgument and Parameter Unpacking\n\nWe saw in the previous chapter that we can use the sequence unpacking oper- ator (*) to supply positional arguments. For example,if we wanted to compute the area of a triangle and had the lengths of the sides in a list, we could make the call like this, heron(sides[0], sides[1], sides[2]),or simply unpack the list and do the much simpler call, heron(*sides).And if the list (or other sequence) has more items than the function has parameters,we can use slicing to extract exactly the right number of arguments.\n\n177\n\n||",
      "content_length": 2159,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 187,
      "content": "178\n\nChapter 4. Control Structures and Functions\n\nWe can also use the sequence unpacking operator in a function’s parameter list. This is useful when we want to create functions that can take a variable number of positional arguments. Here is a product() function that computes the product of the arguments it is given:\n\ndef product(*args): result = 1 for arg in args:\n\nresult *= arg\n\nreturn result\n\nThis function has one parameter called args. Having the * in front means that inside the function the args parameter will be a tuple with its items set to however many positional arguments are given. Here are a few example calls:\n\nproduct(1, 2, 3, 4) product(5, 3, 8) product(11)\n\n# args == (1, 2, 3, 4); returns: 24 # args == (5, 3, 8); returns: 120 # args == (11,); returns: 11\n\nWe can have keyword arguments following positional arguments, as this function to calculate the sum of its arguments, each raised to the given pow- er, shows:\n\ndef sum_of_powers(*args, power=1):\n\nresult = 0 for arg in args:\n\nresult += arg ** power\n\nreturn result\n\nThe function can be called with just positional arguments, for example, sum_of_powers(1, 3, 5), or with both positional and keyword arguments,for ex- ample, sum_of_powers(1, 3, 5, power=2).\n\nIt is also possible to use * as a “parameter” in its own right. This is used to signify thattherecanbenopositionalargumentsafter the *,althoughkeyword arguments are allowed. Here is a modiﬁed version of the heron() function. This time the function takes exactly three positional arguments, and has one optional keyword argument.\n\ndef heron2(a, b, c, *, units=\"square meters\"):\n\ns = (a + b + c) / 2 area = math.sqrt(s * (s - a) * (s - b) * (s - c)) return \"{0} {1}\".format(area, units)\n\nHere are a few example calls:\n\nheron2(25, 24, 7) heron2(41, 9, 40, units=\"sq. inches\") # returns: '180.0 sq. inches'\n\n# returns: '84.0 square meters'",
      "content_length": 1871,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 188,
      "content": "Custom Functions\n\nheron2(25, 24, 7, \"sq. inches\")\n\n# WRONG! raises TypeError\n\nIn the third call we have attempted to pass a fourth positional argument, but the * does not allow this and causes a TypeError to be raised.\n\nBy making the * the ﬁrst parameter we can prevent any positional arguments from being used, and force callers to use keyword arguments. Here is such a (ﬁctitious) function’s signature:\n\ndef print_setup(*, paper=\"Letter\", copies=1, color=False):\n\nWe can call print_setup() with no arguments, and accept the defaults. Or we can change some or all of the defaults, for example, print_setup(paper=\"A4\", color=True). But if we attempt to use positional arguments, for example, print_setup(\"A4\"), a TypeError will be raised.\n\nJust as we can unpack a sequence to populate a function’s positional argu- ments, we can also unpack a mapping using the mapping unpacking operator, asterisk asterisk (**).★ We can use ** to pass a dictionary to the print_setup() function. For example:\n\noptions = dict(paper=\"A4\", color=True) print_setup(**options)\n\nHere the options dictionary’s key–value pairs are unpacked with each key’s value being assigned to the parameter whose name is the same as the key. If the dictionary contains a key for which there is no corresponding parameter, a TypeError is raised. Any argument for which the dictionary has no corre- sponding item is set to its default value—but if there is no default,a TypeError is raised.\n\nWecanalsousethemapping unpacking operatorwithparameters. Thisallows us to create functions that will accept as many keyword arguments as are giv- en. Hereisan add_person_details() functionthattakesSocialSecuritynumber and surname positional arguments, and any number of keyword arguments:\n\ndef add_person_details(ssn, surname, **kwargs):\n\nprint(\"SSN =\", ssn) print(\" for key in sorted(kwargs):\n\nsurname =\", surname)\n\nprint(\"\n\n{0} = {1}\".format(key, kwargs[key]))\n\nThis function could be called with just the two positional arguments, or with additional information, for example, add_person_details(83272171, \"Luther\", forename=\"Lexis\", age=47). This provides us with a lot of ﬂexibility. And we\n\n★As we saw in Chapter 2, when used as a binary operator, ** is the pow() operator.\n\n179",
      "content_length": 2236,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 189,
      "content": "180\n\nChapter 4. Control Structures and Functions\n\ncan of course accept both a variable number of positional arguments and a variable number of keyword arguments:\n\ndef print_args(*args, **kwargs):\n\nfor i, arg in enumerate(args):\n\nprint(\"positional argument {0} = {1}\".format(i, arg))\n\nfor key in kwargs:\n\nprint(\"keyword argument {0} = {1}\".format(key, kwargs[key]))\n\nThis function just prints the arguments it is given. It can be called with no arguments, or with any number of positional and keyword arguments.\n\nAccessing Variables in the Global Scope\n\nIt is sometimes convenient to have a few global variables that are accessed by various functions in the program. This is usually okay for “constants”, but is not a good practice for variables, although for short one-off programs it isn’t always unreasonable.\n\nThe digit_names.py program takes an optional language (“en” or “fr”) and a number on the command line and outputs the names of each of the digits it is given. So if it is invoked with “123” on the command line, it will output “one two three”.The program has three global variables:\n\nLanguage = \"en\"\n\nENGLISH = {0: \"zero\", 1: \"one\", 2: \"two\", 3: \"three\", 4: \"four\",\n\n5: \"five\", 6: \"six\", 7: \"seven\", 8: \"eight\", 9: \"nine\"}\n\nFRENCH = {0: \"zéro\", 1: \"un\", 2: \"deux\", 3: \"trois\", 4: \"quatre\", 5: \"cinq\", 6: \"six\", 7: \"sept\", 8: \"huit\", 9: \"neuf\"}\n\nWe have followed the convention that all uppercase variable names indicate constants, and have set the default language to English. (Python does not provide a direct way to create constants, instead relying on programmers to respect the convention.) Elsewhere in the program we access the Language variable, and use it to choose the appropriate dictionary to use:\n\ndef print_digits(digits):\n\ndictionary = ENGLISH if Language == \"en\" else FRENCH for digit in digits:\n\nprint(dictionary[int(digit)], end=\" \")\n\nprint()\n\nWhen Python encounters the Language variable in this function it looks in the local (function) scope and doesn’t ﬁnd it. So it then looks in the global (.py ﬁle) scope,and ﬁndsit there. The end keyword argument used with theﬁrst print() call is explained in the sidebar “The print() Function” (➤ 181).\n\n||",
      "content_length": 2178,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 191,
      "content": "sorted()\n\n140, 144➤\n\n182\n\nChapter 4. Control Structures and Functions\n\n“fr”,but the global Language variable used in the print_digits() function would remain unchanged as “en”.\n\nFor nontrivial programs it is best not to use global variables except as con- stants, in which case there is no need to use the global statement.\n\nLambda Functions\n\nLambda functions are functions created using the following syntax:\n\nlambda parameters: expression\n\nThe parameters are optional, and if supplied they are normally just comma- separatedvariablenames,thatis,positionalarguments,althoughthecomplete argumentsyntaxsupportedby def statementscanbeused. Theexpressioncan- not contain branches or loops (although conditional expressions are allowed), and cannot have a return (or yield) statement. The result of a lambda expres- sion isan anonymousfunction. When a lambda function iscalled it returnsthe result of computing the expression as its result. If the expression is a tuple it should be enclosed in parentheses.\n\nHereisa simplelambda functionfor adding an s(or not)depending on whether its argument is 1:\n\ns = lambda x: \"\" if x == 1 else \"s\"\n\nThe lambda expression returns an anonymous function which we assign to the variable s.Any (callable)variable can be called using parentheses,so given the count of ﬁles processed in some operation we could output a message using the s() function like this: print(\"{0} file{1} processed\".format(count, s(count))).\n\nLambda functions are often used as the key function for the built-in sorted() function and for the list.sort() method. Suppose we have a list of elements as 3-tuplesof (group,number,name),and we wanted to sort this list in various ways. Here is an example of such a list:\n\nelements = [(2, 12, \"Mg\"), (1, 11, \"Na\"), (1, 3, \"Li\"), (2, 4, \"Be\")]\n\nIf we sort this list, we get this result:\n\n[(1, 3, 'Li'), (1, 11, 'Na'), (2, 4, 'Be'), (2, 12, 'Mg')]\n\nprovide a We saw earlier when we covered the sorted() function that we can key function to alter the sort order. For example, if we wanted to sort the list by number and name, rather than the natural ordering of group, number, and name, we could write a tiny function, def ignore0(e): return e[1], e[2], which could be provided as the key function. Creating lots of little functions like this can be inconvenient, so a frequently used alternative is a lambda function:\n\n||\n\nGenera- tor func- tions ➤ 279",
      "content_length": 2398,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 192,
      "content": "Default dictio- naries 135➤\n\nCustom Functions\n\nelements.sort(key=lambda e: (e[1], e[2]))\n\nHere the key function is lambda e: (e[1], e[2]) with e being each 3-tuple ele- ment in the list. The parentheses around the lambda expression are required when the expression is a tuple and the lambda function is created as a func- tion’s argument. We could use slicing to achieve the same effect:\n\nelements.sort(key=lambda e: e[1:3])\n\nA slightly more elaborate version gives us sorting in case-insensitive name, number order:\n\nelements.sort(key=lambda e: (e[2].lower(), e[1]))\n\nHere are two equivalent ways to create a function that calculates the area of a triangle using the conventional 1 2\n\n× base × height formula:\n\ndef area(b, h):\n\narea = lambda b, h: 0.5 * b * h\n\nreturn 0.5 * b * h\n\nWe can call area(6, 5), whether we created the function using a lambda expres- sion or using a def statement, and the result will be the same.\n\nAnother neat use of lambda functionsis when we want to create default dictio- naries. Recall from the previous chapter that if we access a default dictionary using a nonexistent key,a suitable item is created with the given key and with a default value. Here are a few examples:\n\nminus_one_dict = collections.defaultdict(lambda: -1) point_zero_dict = collections.defaultdict(lambda: (0, 0)) message_dict = collections.defaultdict(lambda: \"No message available\")\n\nIf weaccessthe minus_one_dict with a nonexistentkey,a new itemwill becreat- ed with the given key and with a value of -1. Similarly for the point_zero_dict where the value will be the tuple (0, 0),and for the message_dict where the val- ue will be the “No message available” string.\n\nAssertions\n\nWhat happens if a function receives arguments with invalid data? What happens if we make a mistake in the implementation of an algorithm and performanincorrectcomputation? Theworstthing thatcanhappenisthatthe program executes without any (apparent)problem and no one is any the wiser. One way to help avoid such insidiousproblemsis to write tests—something we will brieﬂy look at in Chapter 5. Another way is to state the preconditions and postconditions and to indicate an error if any of these are not met. Ideally, we should use tests and also state preconditions and postconditions.\n\n183\n\n||",
      "content_length": 2280,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 193,
      "content": "184\n\nChapter 4. Control Structures and Functions\n\nPreconditions and postconditions can be speciﬁed using assert statements, which have the syntax:\n\nassert boolean_expression, optional_expression\n\nIf the boolean_expression evaluates to False an AssertionError exception is raised. If the optional optional_expression is given, it is used as the argument to the AssertionError exception—this is useful for providing error messages. Note, though, that assertions are designed for developers, not end-users. Problems that occur in normal program use such as missing ﬁles or invalid command-lineargumentsshouldbehandledby other means,such asproviding an error or log message.\n\nHere are two new versions of the product() function. Both versions are equiv- alent in that they require that all the arguments passed to them are nonzero, and consider a call with a 0 argument to be a coding error.\n\ndef product(*args): # pessimistic\n\ndef product(*args): # optimistic\n\nassert all(args), \"0 argument\" result = 1 for arg in args:\n\nresult = 1 for arg in args:\n\nresult *= arg\n\nresult *= arg\n\nreturn result\n\nassert result, \"0 argument\" return result\n\nThe “pessimistic”version on the left checksall the arguments(or up to the ﬁrst 0 argument)on every call. The “optimistic”version on the right just checksthe result; after all, if any argument was 0, then the result will be 0.\n\nIf one of these product() functions is called with a 0 argument an Assertion- Error exception will be raised, and output similar to the following will be writ- ten to the error stream (sys.stderr, usually the console):\n\nTraceback (most recent call last): File \"program.py\", line 456, in <module> x = product(1, 2, 0, 4, 8) File \"program.py\", line 452, in product assert result, \"0 argument\" AssertionError: 0 argument\n\nPython automatically provides a traceback that gives the ﬁlename, function, and line number, as well as the error message we speciﬁed.\n\nOncea programisready for publicrelease(andof coursepassesallitstestsand does not violate any assertions), what do we do about the assert statements? We can tell Python not to execute assert statements—in effect, to throw them away at runtime. This can be done by running the program at the command line with the -O option, for example, python -O program.py. Another approach is to set the PYTHONOPTIMIZE environment variable to O. If the docstrings are of",
      "content_length": 2372,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 194,
      "content": "Custom Functions\n\nno use to our users (and normally they wouldn’t be), we can use the -OO option which in effect strips out both assert statements and docstrings: Note that there is no environment variable for setting this option. Some developerstake a simpler approach:They producea copy of their programwith all assert state- ments commented out, and providing this passes their tests, they release the assertion-free version.\n\nExample: make_html_skeleton.py\n\nIn thissection we draw together some of the techniquescovered in thischapter and show them in the context of a complete example program.\n\nVery small Web sites are often created and maintained by hand. One way to make this slightly more convenient is to have a program that can gener- ate skeleton HTML ﬁles that can later be ﬂeshed out with content. The make_html_skeleton.py programisaninteractiveprogramthatpromptstheuser forvariousdetailsandthencreatesaskeletonHTMLﬁle. Theprogram’smain() function has a loop so that users can create skeleton after skeleton, and it re- tainscommon data (e.g.,copyright information)so that usersdon’t have to type it in more than once. Here is a transcript of a typical interaction:\n\nmake_html_skeleton.py\n\nMake HTML Skeleton\n\nEnter your name (for copyright): Harold Pinter Enter copyright year [2008]: 2009 Enter filename: career-synopsis Enter title: Career Synopsis Enter description (optional): synopsis of the career of Harold Pinter Enter a keyword (optional): playwright Enter a keyword (optional): actor Enter a keyword (optional): activist Enter a keyword (optional): Enter the stylesheet filename (optional): style Saved skeleton career-synopsis.html\n\nCreate another (y/n)? [y]:\n\nMake HTML Skeleton\n\nEnter your name (for copyright) [Harold Pinter]: Enter copyright year [2009]: Enter filename: Cancelled\n\nCreate another (y/n)? [y]: n\n\n185\n\n|||",
      "content_length": 1851,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 195,
      "content": "str. format() 78➤\n\n186\n\nChapter 4. Control Structures and Functions\n\nNotice that for the second skeleton the name and year had as their defaults the values entered previously, so they did not need to be retyped. But no default for the ﬁlename is provided, so when that was not given the skeleton was cancelled.\n\nNow that we have seen how the program is used, we are ready to study the code. The program begins with two imports:\n\nimport datetime import xml.sax.saxutils\n\nThe datetime module provides some simple functions for creating date- time.date and datetime.time objects. The xml.sax.saxutils module has a useful xml.sax.saxutils.escape() function that takes a string and returns an equiv- alent string with the special HTML characters (“&”, “<”, and “>”) in their es- caped forms (“&amp;”, “&lt;”, and “&gt;”).\n\nThree global strings are deﬁned; these are used as templates.\n\nCOPYRIGHT_TEMPLATE = \"Copyright (c) {0} {1}. All rights reserved.\"\n\nSTYLESHEET_TEMPLATE = ('<link rel=\"stylesheet\" type=\"text/css\" '\n\n'media=\"all\" href=\"{0}\" />\\n')\n\nHTML_TEMPLATE = \"\"\"<?xml version=\"1.0\"?> <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \\ \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"> <html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"> <head> <title>{title}</title> <!-- {copyright} --> <meta name=\"Description\" content=\"{description}\" /> <meta name=\"Keywords\" content=\"{keywords}\" /> <meta equiv=\"content-type\" content=\"text/html; charset=utf-8\" /> {stylesheet}\\ </head> <body>\n\n</body> </html> \"\"\"\n\nThese strings will be used as templates in conjunction with the str.format() method. In the case of HTML_TEMPLATE we have used names rather than index positions for the ﬁeld names, for example, {title}. We will see shortly that we must use keyword arguments to provide values for these.\n\nclass CancelledError(Exception): pass",
      "content_length": 1858,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 196,
      "content": "Example: make_html_skeleton.py\n\nOne custom exception is deﬁned; we will see it in use when we look at a couple of the program’s functions.\n\nThe program’s main() function is used to set up some initial information, and to provide a loop. On each iteration the user has the chance to enter some information for the HTML page they want generated, and after each one they are given the chance to ﬁnish.\n\ndef main():\n\ninformation = dict(name=None, year=datetime.date.today().year,\n\nfilename=None, title=None, description=None, keywords=None, stylesheet=None)\n\nwhile True: try:\n\nprint(\"\\nMake HTML Skeleton\\n\") populate_information(information) make_html_skeleton(**information)\n\nexcept CancelledError: print(\"Cancelled\")\n\nif (get_string(\"\\nCreate another (y/n)?\", default=\"y\").lower()\n\nnot in {\"y\", \"yes\"}): break\n\nThe datetime.date.today() functionreturnsa datetime.date objectthatholdsto- day’s date. We want just the year attribute. All the other items of information are set to None since there are no sensible defaults that can be set.\n\nInside the while loop the program prints a title, then calls the populate_infor- mation() function with the information dictionary. This dictionary is updated inside the populate_information() function. Next, the make_html_skeleton() function iscalled—thisfunction takesa number of arguments,but rather than give explicit values for each one we have simply unpacked the information dic- tionary.\n\nIf the user cancels, for example, by not providing mandatory information, the program prints out “Cancelled”. At the end of each iteration (whether cancelled or not), the user is asked whether they want to create another skeleton—if they don’t, we break out of the loop and the program terminates.\n\ndef populate_information(information):\n\nname = get_string(\"Enter your name (for copyright)\", \"name\",\n\ninformation[\"name\"])\n\nif not name:\n\nraise CancelledError()\n\nyear = get_integer(\"Enter copyright year\", \"year\",\n\ninformation[\"year\"], 2000, datetime.date.today().year + 1, True)\n\n187",
      "content_length": 2016,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 198,
      "content": "str. format() 78➤\n\nUs- ing str. format() with map- ping un- packing 81➤\n\nExample: make_html_skeleton.py\n\ntitle = xml.sax.saxutils.escape(title) description = xml.sax.saxutils.escape(description) keywords = \",\".join([xml.sax.saxutils.escape(k)\n\nfor k in keywords]) if keywords else \"\"\n\nstylesheet = (STYLESHEET_TEMPLATE.format(stylesheet)\n\nif stylesheet else \"\")\n\nhtml = HTML_TEMPLATE.format(**locals())\n\nTo get the copyright text we call str.format() on the COPYRIGHT_TEMPLATE, sup- plying the year and name (suitably HTML-escaped) as positional arguments to replace {0} and {1}.For the title and description we produce HTML-escaped copies of their texts.\n\nFor the HTML keywords we have two cases to deal with, and we distinguish them using a conditionalexpression. If no keywordshave been entered, we set the keywords string to be the empty using. Otherwise,we use a list comprehen- sion to iterate over all the keywords to produce a new list of strings,with each one being HTML-escaped. This list is then joined into a single string with a comma separating each item using str.join().\n\nThe stylesheet text is created in a similar way to the copyright text,but within the context of a conditional expression so that the text is the empty string if no stylesheet is speciﬁed.\n\narguments used The html text is created from the HTML_TEMPLATE, with keyword to provide the data for the replacement ﬁelds rather than the positional argu- ments used for the other template strings. Rather than pass each argument explicitly using key=value syntax, we have used mapping unpacking on the mapping returned by locals() to do this for us. (The alternative would be to write the format() call as .format(title=title, copyright=copyright, etc.)\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") fh.write(html)\n\nexcept EnvironmentError as err:\n\nprint(\"ERROR\", err)\n\nelse:\n\nprint(\"Saved skeleton\", filename)\n\nfinally:\n\nif fh is not None: fh.close()\n\nOnce the HTML has been prepared we write it to the ﬁle with the given ﬁlename. We inform theuser that the skeleton hasbeen saved—or of theerror message if something went wrong. As usual we use a finally clause to ensure that the ﬁle is closed if it was opened.\n\n189",
      "content_length": 2209,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 199,
      "content": "Us- ing str. format() with map- ping un- packing 81➤\n\n190\n\nChapter 4. Control Structures and Functions\n\ndef get_string(message, name=\"string\", default=None, minimum_length=0, maximum_length=80):\n\nmessage += \": \" if default is None else \" [{0}]: \".format(default) while True: try:\n\nline = input(message) if not line:\n\nif default is not None: return default if minimum_length == 0:\n\nreturn \"\"\n\nelse:\n\nraise ValueError(\"{0} may not be empty\".format(\n\nname)) if not (minimum_length <= len(line) <= maximum_length):\n\nraise ValueError(\"{name} must have at least \"\n\n\"{minimum_length} and at most \" \"{maximum_length} characters\".format( **locals()))\n\nreturn line\n\nexcept ValueError as err:\n\nprint(\"ERROR\", err)\n\nThis function has one mandatory argument, message, and four optional argu- ments. If a default value is given we include it in the message string so that the user can see the default they would get if they just press Enter without typ- ing any text. The rest of the function is enclosed in an inﬁnite loop. The loop can be broken out of by the user entering a valid string—or by accepting the default (if given) by just pressing Enter. If the user makes a mistake, an error message is printed and the loop continues. As usual,rather than explicitly us- ing key=value syntax topasslocalvariablesto str.format() with a formatstring that uses named ﬁelds, we have simply used mapping unpacking on the map- ping returned by locals() to do this for us.\n\nThe user could also break out of the loop,and indeed out of the entire program, by typing Ctrl+C—this would cause a KeyboardInterrupt exception to be raised, and sincethisisnot handledby any of theprogram’sexceptionhandlers,would cause the program to terminate and print a traceback. Should we leave such a “loophole”? If we don’t,and there is a bug in our program,we could leave the user stuck in an inﬁnite loop with no way out except to kill the process. Unless there is a very strong reason to prevent Ctrl+C from terminating a program, it should not be caught by any exception handler.\n\nNotice that this function is not speciﬁc to the make_html_skeleton.py program—it could be reused in many interactive programs of this type. Such reuse could be achieved by copying and pasting, but that would lead to main-",
      "content_length": 2266,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 200,
      "content": "Example: make_html_skeleton.py\n\ntenance headaches—in the next chapter we will see how to create custom mod- ules with functionality that can be shared across any number of programs.\n\ndef get_integer(message, name=\"integer\", default=None, minimum=0,\n\nmaximum=100, allow_zero=True):\n\n...\n\nThis function is so similar in structure to the get_string() function that it would add nothing to reproduce it here. (It is included in the source code that accompanies the book, of course.) The allow_zero parameter can be useful when 0 is not a valid value but where we want to permit one invalid value to signify that the user has cancelled. Another approach would be to pass an invalid default value, and if that is returned, take it to mean that the user has cancelled.\n\nThe last statement in the program is simply a call to main(). Overall the pro- gram is slightly more than 150 lines and shows several features of the Python language introduced in this chapter and the previous ones.\n\nSummary\n\nThischapter covered the complete syntax for all of Python’scontrol structures. It also showed how to raise and catch exceptions, and how to create custom exception types.\n\nMost of the chapter was devoted to custom functions. We saw how to create functions and presented some rules of thumb for naming functions and their parameters. Wealsosawhowtoprovidedocumentationforfunctions. Python’s versatile parameter syntax and argument passing were covered in detail, in- cluding both ﬁxedand variablenumbersof positionaland keywordarguments, and default values for arguments of both immutable and mutable data types. We also brieﬂy recapped sequence unpacking with * and showed how to do mapping unpacking with **. Mapping unpacking is particularly useful when applied to a dictionary (or other mapping), or to the mapping returned by lo- cals(), for passing key–value arguments to a str.format() format string that uses named ﬁelds.\n\nIf we need to assign a new value to a global variable inside a function, we can do so by declaring that the variable is global, thereby preventing Python from creating a local variable and assigning to that. In general,though,it is best to use global variables only for constants.\n\nLambda functions are often used as key functions, or in other contexts where functions must be passed as parameters. This chapter showed how to create lambda functions, both as anonymous functions and as a means of creating small named one-line functions by assigning them to a variable.\n\n191\n\n|||",
      "content_length": 2498,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 201,
      "content": "192\n\nChapter 4. Control Structures and Functions\n\nThe chapter also covered the use of the assert statement. This statement is very useful for specifying the preconditions and postconditions that we expect to be true on every use of a function, and can be a real aid to robust programming and bug hunting.\n\nIn this chapter we covered all the fundamentals of creating functions, but many other techniques are available to us. These include creating dynamic functions (creating functions at runtime, possibly with implementations that differ depending on circumstances), covered in Chapter 5; local (nested) func- tions, covered in Chapter 7; and recursive functions, generator functions, and so on, covered in Chapter 8.\n\nAlthough Python has a considerable amount of built-in functionality, and a very extensive standard library, it is still likely that we will write some func- tions that would be useful in many of the programs we develop. Copying and pasting such functions would lead to maintenance nightmares, but fortunate- ly Python provides a clean easy-to-use solution: custom modules. In the next chapter we will learn how to create our own modules with our own functions inside them. We will also see how to import functionality from the standard library and from our own modules, and will brieﬂy review what the standard library has to offer so that we can avoid reinventing the wheel.\n\nExercise\n\nWrite an interactive program that maintains lists of strings in ﬁles.\n\nWhen the program is run it should create a list of all the ﬁles in the current directory that have the .lst extension. Use os.listdir(\".\") to get all the ﬁles andﬁlter out thosethatdon’thavethe .lst extension. If therearenomatching ﬁles the program should prompt the user to enter a ﬁlename—adding the .lst extension if the user doesn’t enter it. If there are one or more .lst ﬁles they should be printed as a numbered list starting from 1.The user should be asked toenter thenumber of theﬁlethey want toload,or 0,in which casethey should be asked to give a ﬁlename for a new ﬁle.\n\nIf an existing ﬁle was speciﬁed its items should be read. If the ﬁle is empty,or if a new ﬁle was speciﬁed, the program should show a message, “no items are in the list”.\n\nIf there are no items, two options should be offered: “Add” and “Quit”. Once the list has one or more items, the list should be shown with each item num- bered from 1, and the options offered should be “Add”, “Delete”, “Save” (unless already saved), and “Quit”. If the user chooses “Quit” and there are unsaved changes they should be given the chance to save. Here is a transcript of a ses- sion with the program (with most blank lines removed, and without the “List Keeper” title shown above the list each time):\n\n|||",
      "content_length": 2750,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 202,
      "content": "Exercise\n\nChoose filename: movies\n\n-- no items are in the list -- [A]dd [Q]uit [a]: a Add item: Love Actually\n\n1: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: a Add item: About a Boy\n\n1: About a Boy 2: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: Add item: Alien\n\n1: About a Boy 2: Alien 3: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: k ERROR: invalid choice--enter one of 'AaDdSsQq' Press Enter to continue... [A]dd [D]elete [S]ave [Q]uit [a]: d Delete item number (or 0 to cancel): 2\n\n1: About a Boy 2: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: s Saved 2 items to movies.lst Press Enter to continue...\n\n1: About a Boy 2: Love Actually [A]dd [D]elete [Q]uit [a]: Add item: Four Weddings and a Funeral\n\n1: About a Boy 2: Four Weddings and a Funeral 3: Love Actually [A]dd [D]elete [S]ave [Q]uit [a]: q Save unsaved changes (y/n) [y]: Saved 3 items to movies.lst\n\nKeep the main() function fairly small (less than 30 lines) and use it to provide the program’s main loop. Write a function to get the new or existing ﬁlename (and in the latter case to load the items), and a function to present the op- tions and get the user’s choice of option. Also write functions to add an item, delete an item, print a list (of either items or ﬁlenames), load the list, and save the list. Either copy the get_string() and get_integer() functions from make_html_skeleton.py, or write your own versions.\n\n193",
      "content_length": 1406,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 203,
      "content": "194\n\nChapter 4. Control Structures and Functions\n\nWhen printing the list or the ﬁlenames, print the item numbers using a ﬁeld width of 1if there are less than ten items,of 2 if there are less than 100 items, and of 3 otherwise.\n\nKeep the items in case-insensitive alphabetical order, and keep track of whether the list is “dirty” (has unsaved changes). Offer the “Save” option only if the list is dirty and ask the user whether they want to save unsaved changes when they quit only if the list is dirty. Adding or deleting an item will make the list dirty; saving the list will make it clean again.\n\nA model solution is provided in listkeeper.py; it is less than 200 lines of code.",
      "content_length": 681,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 204,
      "content": "Online doc- umenta- tion 172➤\n\n5\n\nModules and Packages ● Overview of Python’s Standard Library\n\nModules\n\nWhereas functions allow us to parcel up pieces of code so that they can be reused throughout a program, modules provide a means of collecting sets of functions (and as we will see in the next chapter, custom data types) together so that they can be used by any number of programs. Python also hasfacilities for creating packages—these are sets of modules that are grouped together, usually because their modules provide related functionality or because they depend on each other.\n\nThis chapter’s ﬁrst section describes the syntaxes for importing functionality from modules and packages—whether from the standard library, or from our own custom modules and packages. The section then goes on to show how to create custom packages and custom modules. Two custom module examples are shown, the ﬁrst introductory and the second illustrating how to handle many of the practical issues that arise, such as platform independence and testing.\n\nThe second section providesa brief overview of Python’sstandard library. It is important to be aware of what the library has to offer, since using predeﬁned functionality makes programming much faster than creating everything from scratch. Also, many of the standard library’s modules are widely used, well tested, and robust. In addition to the overview, a few small examples are used to illustrate some common use cases. And cross-references are provided for modules covered in other chapters.\n\nModules and Packages\n\nA Python module, simply put, is a .py ﬁle. A module can contain any Python code we like. All the programswe have written so far have been contained in a single .py ﬁle,and so they are modulesaswell asprograms. The key difference\n\n195\n\n||||\n\n|||",
      "content_length": 1804,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 205,
      "content": "196\n\nChapter 5. Modules\n\nis that programs are designed to be run, whereas modules are designed to be imported and used by programs.\n\nNot all modules have associated .py ﬁles—for example, the sys module is built into Python, and some modules are written in other languages (most com- monly, C). However, much of Python’s library is written in Python, so, for ex- ample, if we write import collections we can create named tuples by calling collections.namedtuple(), and the functionality we are accessing is in the col- lections.py module ﬁle. It makes no difference to our programs what lan- guage a module is written in, since all modules are imported and used in the same way.\n\nSeveral syntaxes can be used when importing. For example:\n\nimport importable import importable1, importable2, ..., importableN import importable as preferred_name\n\nHere importable isusually a modulesuch as collections,but could bea package or a module in a package, in which case each part is separated with a dot (.), for example, os.path. The ﬁrst two syntaxes are the ones we use throughout this book. They are the simplest and also the safest because they avoid the possibility of having name conﬂicts, since they force us to always use fully qualiﬁed names.\n\nThe third syntax allows us to give a name of our choice to the package or mod- ule we are importing—theoretically this could lead to name clashes, but in practice the as syntax is used to avoid them. Renaming is particularly useful when experimenting with different implementations of a module. For ex- ample, if we had two modules MyModuleA and MyModuleB that had the same API (ApplicationProgramming Interface),wecouldwrite import MyModuleA as MyMod- ule in a program, and later on seamlessly switch to using import MyModuleB as MyModule.\n\nWhere should import statementsgo? It iscommon practiceto put all the import statements at the beginning of .py ﬁles, after the shebang line, and after the module’s documentation. And as we said back in Chapter 1, we recommend importing standard library modules ﬁrst, then third-party library modules, and ﬁnally our own modules.\n\nHere are some other import syntaxes:\n\nfrom importable import object as preferred_name from importable import object1, object2, ..., objectN from importable import (object1, object2, object3, object4, object5,\n\nobject6, ..., objectN)\n\nfrom importable import *\n\nPack- ages ➤ 199",
      "content_length": 2391,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 206,
      "content": "Modules and Packages\n\nThese syntaxes can cause name conﬂicts since they make the imported objects (variables, functions, data types, or modules) directly accessible. If we want to use the from … import syntax to import lots of objects, we can use multiple lines either by escaping each newline except the last,or by enclosing the object names in parentheses, as the third syntax illustrates.\n\nIn thelast syntax,the * means“importeverything thatisnot private”,which in practicaltermsmeanseither thatevery objectin themoduleisimportedexcept for those whose names begin with a leading underscore, or, if the module has a global __all__ variable that holds a list of names, that all the objects named in the __all__ variable are imported.\n\nHere are a few import examples:\n\nimport os print(os.path.basename(filename))\n\n# safe fully qualified access\n\nimport os.path as path print(path.basename(filename)) # risk of name collision with path\n\nfrom os import path print(path.basename(filename)) # risk of name collision with path\n\nfrom os.path import basename print(basename(filename))\n\n# risk of name collision with basename\n\nfrom os.path import * print(basename(filename))\n\n# risk of many name collisions\n\nThe from importable import * syntax imports all the objects from the module (or all the modules from the package)—this could be hundreds of names. In the case of from os.path import *, almost 40 names are imported,including dirname, exists, and split, any of which might be names we would prefer to use for our own variables or functions.\n\nFor example, if we write from os.path import dirname, we can conveniently call dirname() without qualiﬁcation. But if further on in our code we write dirname = \".\",the object reference dirname will now be bound to the string \".\" instead of to the dirname() function, so if we try calling dirname() we will get a TypeError exception because dirname now refers to a string and strings are not callable.\n\nIn view of the potential for name collisions the import * syntax creates, some programming teams specify in their guidelines that only the import importable syntax may be used. However, certain large packages, particularly GUI (Graphical User Interface) libraries, are often imported this way because they have large numbers of functions and classes (custom data types) that can be tedious to type out by hand.\n\nA question that naturally arises is, how does Python know where to look for the modules and packages that are imported? The built-in sys module has a\n\n197\n\n__all__ ➤ 200",
      "content_length": 2522,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 208,
      "content": "Modules and Packages\n\nAt every subsequent import of the module Python will detect that the module has already been imported and will do nothing.\n\nWhen Python needs a module’s byte-code compiled code, it generates it automatically—this differs from, say, Java, where compiling to byte code must be done explicitly. First Python looks for a ﬁle with the same name as the module’s .py ﬁle but with the extension .pyo—this is an optimized byte-code compiled version of the module. If there is no .pyo ﬁle (or if it is older than the .py ﬁle, that is, if it is out of date), Python looks for a ﬁle with the exten- sion .pyc—this is a nonoptimized byte-code compiled version of the module. If Python ﬁnds an up-to-date byte-code compiled version of the module, it loads it; otherwise, Python loads the .py ﬁle and compiles a byte-code compiled ver- sion. Either way,Python endsupwith themodulein memory in byte-codecom- piled form.\n\nIf Python had to byte-compile the .py ﬁle, it saves a .pyc version (or .pyo if -O wasspeciﬁedon Python’scommand line,or isset in the PYTHONOPTIMIZE environ- ment variable), providing the directory is writable. Saving the byte code can be avoided by using the -B command-line option, or by setting the PYTHONDONT- WRITEBYTECODE environment variable.\n\nUsing byte-code compiled ﬁles leads to faster start-up times since the inter- preter only has to load and run the code, rather than load, compile, (save if possible),and run the code;runtimesare not affected,though. When Python is installed,the standard library modules are usually byte-code compiled as part of the installation process.\n\nPackages\n\nA package is simply a directory that contains a set of modules and a ﬁle called __init__.py. Suppose, for example, that we had a ﬁctitious set of module ﬁles for reading and writing various graphics ﬁle formats, such as Bmp.py, Jpeg.py, Png.py, Tiff.py, and Xpm.py, all of which provided the functions load(), save(), and so on.★ We could keep the modules in the same directory as our program, but for a large program that uses scores of custom modules the graphics modules will be dispersed. By putting them in their own subdirectory, say, Graphics, they can be kept together. And if we put an empty __init__.py ﬁle in the Graphics directory along with them, the directory will become a package:\n\nGraphics/ __init__.py Bmp.py Jpeg.py\n\n★Extensive support for handling graphics ﬁles is provided by a variety of third-party modules, most notably the Python Imaging Library (www.pythonware.com/products/pil).\n\n199\n\n||",
      "content_length": 2540,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 209,
      "content": "200\n\nChapter 5. Modules\n\nPng.py Tiff.py Xpm.py\n\nAslong asthe Graphics directory isa subdirectory inside our program’sdirecto- ry or is in the Python path, we can import any of these modules and make use of them. We must be careful to ensure that our top-level module name (Graph- ics) is not the same as any top-level name in the standard library so as to avoid name conﬂicts. (On Unix this is easily done by starting with an uppercase let- ter since all of the standard library’s modules have lowercase names.) Here’s how we can import and use our module:\n\nimport Graphics.Bmp image = Graphics.Bmp.load(\"bashful.bmp\")\n\nFor short programs some programmers prefer to use shorter names, and Python makes this possible using two slightly different approaches.\n\nimport Graphics.Jpeg as Jpeg image = Jpeg.load(\"doc.jpeg\")\n\nHere we have imported the Jpeg module from the Graphics package and told Python that we want to refer to it simply as Jpeg rather than using its fully qualiﬁed name, Graphics.Jpeg.\n\nfrom Graphics import Png image = Png.load(\"dopey.png\")\n\nThis code snippet imports the Png module directly from the Graphics package. This syntax (from … import) makes the Png module directly accessible.\n\nWe are not obliged to use the original package names in our code. For ex- ample:\n\nfrom Graphics import Tiff as picture image = picture.load(\"grumpy.tiff\")\n\nHere we are using the Tiff module, but have in effect renamed it inside our program as the picture module.\n\nIn some situations it is convenient to load in all of a package’s modules using a single statement. To do this we must edit the package’s __init__.py ﬁle to contain a statement which speciﬁes which modules we want loaded. This statement must assign a list of module names to the special variable __all__. For example, here is the necessary line for the Graphics/__init__.py ﬁle:\n\n__all__ = [\"Bmp\", \"Jpeg\", \"Png\", \"Tiff\", \"Xpm\"]",
      "content_length": 1895,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 210,
      "content": "Modules and Packages\n\nThat isall that isrequired,although wearefreetoput any other codewelikein the __init__.py ﬁle. Now we can write a different kind of import statement:\n\nfrom Graphics import * image = Xpm.load(\"sleepy.xpm\")\n\nThe from package import * syntax directly imports all the modules named in the __all__ list. So,after thisimport,not only isthe Xpm module directly accessible, but so are all the others.\n\nAsnoted earlier,thissyntax can also be applied to a module,that is,from module import *, in which case all the functions,variables, and other objects deﬁned in the module (apart from those whose names begin with a leading underscore) will be imported. If we want to control exactly what is imported when the from module import * syntax isused,we can deﬁne an __all__ list in the module itself, in which case doing from module import * will import only those objects named in the __all__ list.\n\nSo far we have shown only one level of nesting, but Python allows us to nest packages as deeply as we like. So we could have a subdirectory inside the Graphics directory,say, Vector, with module ﬁles inside that,such as Eps.py and Svg.py:\n\nGraphics/ __init__.py Bmp.py Jpeg.py Png.py Tiff.py Vector/ __init__.py Eps.py Svg.py Xpm.py\n\nFor the Vector directory to be a package it must have an __init__.py ﬁle, and as noted, this can be empty or could have an __all__ list as a convenience for programmers who want to import using from Graphics.Vector import *.\n\nTo access a nested package we just build on the syntax we have already used:\n\nimport Graphics.Vector.Eps image = Graphics.Vector.Eps.load(\"sneezy.eps\")\n\nThe fully qualiﬁed name is rather long,so some programmerstry to keep their module hierarchies fairly ﬂat to avoid this.\n\n201",
      "content_length": 1748,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 211,
      "content": "202\n\nChapter 5. Modules\n\nimport Graphics.Vector.Svg as Svg image = Svg.load(\"snow.svg\")\n\nWe can always use our own short name for a module, as we have done here, although this does increase the risk of having a name conﬂict.\n\nAll the imports we have used so far (and that we will use throughout the rest of the book) are absolute imports—this means that every module we import is in one of sys.path’s directories (or subdirectories if the import name included one or more periodswhich effectively serve as path separators).When creating large multimodule multidirectory packages it is often useful to import other modules that are part of the same package. For example, in Eps.py or Svg.py we could get access to the Png module using a conventional import, or using a relative import:\n\nimport Graphics.Png as Png\n\nfrom ..Graphics import Png\n\nThesetwocodesnippetsareequivalent;they bothmakethe Png moduledirectly available inside the module where they are used. But note that relative im- ports, that is, imports that use the from module import syntax with leading dots in front of the module name (each dot representing stepping up one directory), can be used only in modules that are inside a package. Using relative imports makes it easier to rename the top-level package and prevents accidentally im- porting standard modules rather than our own inside packages.\n\nCustom Modules\n\nSince modules are just .py ﬁles they can be created without formality. In this section we will look at two custom modules. The ﬁrst module, TextUtil (in ﬁle TextUtil.py), contains just three functions: is_balanced() which returns True if the string it is passed has balanced parentheses of various kinds, shorten() (shown earlier; 177 ➤), and simplify(), a function that can strip spurious whitespace and other characters from a string. In the coverage of this module we will also see how to execute the code in docstrings as unit tests.\n\nThe second module,CharGrid (in ﬁle CharGrid.py),holdsa grid of charactersand allows us to “draw” lines, rectangles, and text onto the grid and to render the grid on the console. Thismodule showssome techniquesthat we have not seen before and is more typical of larger, more complex modules.\n\nThe TextUtil Module\n\nThe structure of this module (and most others) differs little from that of a program. The ﬁrst line is the shebang line, and then we have some comments (typically the copyright and license information). Next it is common to have a\n\n||\n\n|",
      "content_length": 2472,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 212,
      "content": "short- en() 177➤\n\nModules and Packages\n\ntriple quoted string that provides an overview of the module’s contents, often including some usage examples—this is the module’s docstring. Here is the start of the TextUtil.py ﬁle (but with the license comment lines omitted):\n\n#!/usr/bin/env python3 # Copyright (c) 2008-9 Qtrac Ltd. All rights reserved. \"\"\" This module provides a few string manipulation functions.\n\n>>> is_balanced(\"(Python (is (not (lisp))))\") True >>> shorten(\"The Crossing\", 10) 'The Cro...' >>> simplify(\" some 'some text with spurious whitespace' \"\"\"\n\ntext\n\nwith spurious whitespace \")\n\nimport string\n\nThismodule’sdocstring isavailabletoprograms(or other modules)thatimport the module as TextUtil.__doc__. After the module docstring come the imports, in this case just one, and then the rest of the module.\n\nWe have already seen the shorten() function reproduced in full, so we will not repeat it here. And since our focus is on modules rather than on functions, although we will show the simplify() function in full, including its docstring, we will show only the code for is_balanced().\n\nThis is the simplify() function, broken into two parts:\n\ndef simplify(text, whitespace=string.whitespace, delete=\"\"):\n\nr\"\"\"Returns the text with multiple spaces reduced to single spaces\n\nThe whitespace parameter is a string of characters, each of which is considered to be a space. If delete is not empty it should be a string, in which case any characters in the delete string are excluded from the resultant string.\n\n>>> simplify(\" this 'this and that too' >>> simplify(\" Washington 'Washington D.C.' >>> simplify(\" Washington 'Washington DC' >>> simplify(\" disemvoweled \", delete=\"aeiou\") 'dsmvwld' \"\"\"\n\nand\\n that\\t too\")\n\nD.C.\\n\")\n\nD.C.\\n\", delete=\",;:.\")\n\n203",
      "content_length": 1771,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 213,
      "content": "Raw strings 67➤\n\n204\n\nChapter 5. Modules\n\nAfter the def line comes the function’s docstring, laid out conventionally with a single line description, a blank line, further description, and then some examples written as though they were typed in interactively. Because the quoted strings are inside a docstring we must either escape the backslashes inside them, or do what we have done here and use a raw triple quoted string.\n\nresult = [] word = \"\" for char in text:\n\nif char in delete:\n\ncontinue\n\nelif char in whitespace:\n\nif word:\n\nresult.append(word) word = \"\"\n\nelse:\n\nword += char\n\nif word:\n\nresult.append(word) return \" \".join(result)\n\nThe result list is used to hold “words”—strings that have no whitespace or deleted characters. The given text isiterated over character by character,with deleted characters skipped. If a whitespace character is encountered and a wordisin themaking,thewordisaddedtotheresultlist andset tobeanempty string; otherwise, the whitespace is skipped. Any other character is added to the word being built up. At the end a single string is returned consisting of all the words in the result list joined with a single space between each one.\n\nThe is_balanced() function follows the same pattern of having a def line, then a docstring with a single-line description, a blank line, further description, and some examples, and then the code itself. Here is the code without the docstring:\n\ndef is_balanced(text, brackets=\"()[]{}<>\"):\n\ncounts = {} left_for_right = {} for left, right in zip(brackets[::2], brackets[1::2]):\n\nassert left != right, \"the bracket characters must differ\" counts[left] = 0 left_for_right[right] = left\n\nfor c in text:\n\nif c in counts:\n\ncounts[c] += 1\n\nelif c in left_for_right:\n\nleft = left_for_right[c]",
      "content_length": 1755,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 214,
      "content": "Modules and Packages\n\nif counts[left] == 0: return False\n\ncounts[left] -= 1\n\nreturn not any(counts.values())\n\nThe function builds two dictionaries. The counts dictionary’s keys are the opening characters (“(”, “[”, “{”, and “<”), and its values are integers. The left_for_right dictionary’skeys are the closing characters(“)”,“]”,“}”,and “>”), and itsvaluesarethecorresponding opening characters. Oncethedictionaries areset upthefunctioniteratescharacterby characterover thetext. Whenever an opening character is encountered, its corresponding count is incremented. Similarly,when a closing character is encountered,the function ﬁnds out what the corresponding opening character is. If the count for that character is 0 it means we have reached one closing character too many so can immediately return False; otherwise, the relevant count is decremented. At the end every count should be 0 if all the pairsare balanced,so if any one of them is not 0 the function returns False; otherwise, it returns True.\n\nUptothispointeverything hasbeenmuchlikeany other .py ﬁle. If TextUtil.py wasa programtherewould presumably be somemorefunctions,and at theend we would have a single call to one of those functionsto start off the processing. But since this is a module that is intended to be imported,deﬁning functionsis sufﬁcient. And now,any program or module can import TextUtil and make use of it:\n\nimport TextUtil\n\ntext = \" a text = TextUtil.simplify(text) # text == 'a puzzling conundrum'\n\npuzzling conundrum \"\n\nIf we want the TextUtil module to be available to a particular program, we just need to put TextUtil.py in the same directory as the program. If we want TextUtil.py to be available to all our programs,there are a few approachesthat can be taken. One approach is to put the module in the Python distribution’s site-packages subdirectory—this is usually C:\\Python31\\Lib\\site-packages on Windows, but it varies on Mac OS X and other Unixes. This directory is in the Python path, so any module that is here will always be found. A second approach is to create a directory speciﬁcally for the custom modules we want to use for all our programs, and to set the PYTHONPATH environment variable to this directory. A third approach is to put the module in the local site-packages subdirectory—this is %APPDATA%\\Python\\Python31\\site-packages on Windows and ~/.local/lib/python3.1/site-packages on Unix (including Mac OS X) and is in the Python path. The second and third approacheshave the advantage of keeping our own code separate from the ofﬁcial installation.\n\nHaving the TextUtil module is all very well, but if we end up with lots of pro- grams using it we might want to be more conﬁdent that it works as advertised.\n\n205",
      "content_length": 2724,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 215,
      "content": "206\n\nChapter 5. Modules\n\nOne really simple way to do this is to execute the examples in the docstrings and make sure that they produce the expected results. This can be done by adding just three lines at the end of the module’s .py ﬁle:\n\nif __name__ == \"__main__\":\n\nimport doctest doctest.testmod()\n\nWhenever a module is imported Python creates a variable for the module called __name__ and stores the module’s name in this variable. A module’s name is simply the name of its .py ﬁle but without the extension. So in this example,when the module is imported __name__ will have the value \"TextUtil\", and the if condition will not be met, so the last two lines will not be executed. This means that these last three lines have virtually no cost when the module is imported.\n\nWhenever a .py ﬁle is run Python creates a variable for the program called __name__ and sets it to the string \"__main__\". So if we were to run TextUtil.py as though it were a program, Python will set __name__ to \"__main__\" and the if condition will evaluate to True and the last two lines will be executed.\n\nThe doctest.testmod() functionusesPython’sintrospectionfeaturestodiscover all the functions in the module and their docstrings, and attempts to execute all the docstring code snippets it ﬁnds. Running a module like this produces outputonly if thereareerrors. Thiscanbedisconcertingatﬁrstsinceitdoesn’t look like anything happened at all, but if we pass a command-line ﬂag of -v, we will get output like this:\n\nTrying:\n\nis_balanced(\"(Python (is (not (lisp))))\")\n\nExpecting:\n\nTrue\n\nok ... Trying:\n\nsimplify(\" disemvoweled \", delete=\"aeiou\")\n\nExpecting:\n\n'dsmvwld'\n\nok 4 items passed all tests: 3 tests in __main__ 5 tests in __main__.is_balanced 3 tests in __main__.shorten 4 tests in __main__.simplify\n\n15 tests in 4 items. 15 passed and 0 failed. Test passed.",
      "content_length": 1840,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 216,
      "content": "Modules and Packages\n\nWe have used an ellipsis to indicate a lot of lines that have been omitted. If therearefunctions(or classesor methods)thatdon’thavetests,thesearelisted when the -v option is used. Notice that the doctest module found the tests in the module’s docstring as well as those in the functions’ docstrings.\n\nExamples in docstrings that can be executed as tests are called doctests. Note that when we write doctests, we are able to call simplify() and the other func- tions unqualiﬁed (since the doctests occur inside the module itself). Outside the module,assuming we have done import TextUtil, we must use the qualiﬁed names, for example, TextUtil.is_balanced().\n\nIn thenext subsectionwewillseehowtodomorethoroughtests—inparticular, testing caseswhereweexpectfailures,for example,invaliddatacausing excep- tions. (Testing is covered more fully in Chapter 9.) We will also address some other issuesthat arisewhen creating modules,including moduleinitialization, accounting for platform differences,and ensuring that if the from module import * syntax is used, only the objects we want to be made public are actually im- ported into the importing program or module.\n\nThe CharGrid Module\n\nThe CharGrid module holds a grid of characters in memory. It provides func- tionsfor “drawing”lines,rectangles,and text on the grid,and for rendering the grid onto the console. Here are the module’s docstring’s doctests:\n\n>>> resize(14, 50) >>> add_rectangle(0, 0, *get_size()) >>> add_vertical_line(5, 10, 13) >>> add_vertical_line(2, 9, 12, \"!\") >>> add_horizontal_line(3, 10, 20, \"+\") >>> add_rectangle(0, 0, 5, 5, \"%\") >>> add_rectangle(5, 7, 12, 40, \"#\", True) >>> add_rectangle(7, 9, 10, 38, \" \") >>> add_text(8, 10, \"This is the CharGrid module\") >>> add_text(1, 32, \"Pleasantville\", \"@\") >>> add_rectangle(6, 42, 11, 46, fill=True) >>> render(False)\n\nThe CharGrid.add_rectangle() function takes at least four arguments, the top- left corner’s row and column and the bottom-right corner’s row and column. The character used to draw the outline can be given as a ﬁfth argument,and a Boolean indicating whether the rectangle should be ﬁlled (with the same char- acter as the outline) as a sixth argument. The ﬁrst time we call it we pass the third and fourth argumentsby unpacking the 2-tuple(width,height),returned by the CharGrid.get_size() function.\n\n207\n\n|",
      "content_length": 2367,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 217,
      "content": "208\n\nChapter 5. Modules\n\nBy default,the CharGrid.render() function clearsthe screen before printing the grid, but this can be prevented by passing False as we have done here. Here is the grid that results from the preceding doctests:\n\n%%%%%********************************************* % % @@@@@@@@@@@@@@@ * % % @Pleasantville@ * % % ++++++++++ @@@@@@@@@@@@@@@ * %%%%% * * ################################# * * ################################# **** * * ## ## **** * * ## This is the CharGrid module ## **** * * ! ## ## **** * * ! | ################################# **** * * ! | ################################# * * | * **************************************************\n\nThe module begins in the same way as the TextUtil module, with a shebang line, copyright and license comments, and a module docstring that describes the module and has the doctests quoted earlier. Then the code proper begins with twoimports,oneof the sys moduleandtheother of the subprocess module. The subprocess module is covered more fully in Chapter 10.\n\nThe module has two error-handling policies in place. Several functions have a char parameter whose actual argument must always be a string containing exactly one character;a violation of thisrequirement isconsideredto be a fatal coding error, so assert statements are used to verify the length. But passing out-of-range row or column numbers is considered erroneous but normal, so custom exceptions are raised when this happens.\n\nWe will now review some illustrative and key parts of the module’s code, beginning with the custom exceptions:\n\nclass RangeError(Exception): pass class RowRangeError(RangeError): pass class ColumnRangeError(RangeError): pass\n\nNone of the functions in the module that raise an exception ever raise a RangeError; they always raise the speciﬁc exception depending on whether an out-of-range row or column was given. But by using a hierarchy,we give users of the module the choice of catching the speciﬁc exception,or to catch either of them by catching their RangeError baseclass. Note also that inside docteststhe exception names are used as they appear here, but if the module is imported with import CharGrid, the exception names are, of course, CharGrid.RangeError, CharGrid.RowRangeError, and CharGrid.ColumnRangeError.",
      "content_length": 2284,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 218,
      "content": "Modules and Packages\n\n_CHAR_ASSERT_TEMPLATE = (\"char must be a single character: '{0}' \"\n\n\"is too long\")\n\n_max_rows = 25 _max_columns = 80 _grid = [] _background_char = \" \"\n\nHere we deﬁne some private data for internal use by the module. We use leading underscores so that if the module is imported using from CharGrid import *, none of these variables will be imported. (An alternative approach would be to set an __all__ list.) The _CHAR_ASSERT_TEMPLATE is a string for use with the str.format() function; we will see it used to give an error message in assert statements. We will discuss the other variables as we encounter them.\n\nif sys.platform.startswith(\"win\"):\n\ndef clear_screen():\n\nsubprocess.call([\"cmd.exe\", \"/C\", \"cls\"])\n\nelse:\n\ndef clear_screen():\n\nsubprocess.call([\"clear\"])\n\nclear_screen.__doc__ = \"\"\"Clears the screen using the underlying \\ window system's clear screen command\"\"\"\n\nThe means of clearing the console screen is platform-dependent. On Windows we must execute the cmd.exe program with appropriate arguments and on most Unix systems we execute the clear program. The subprocess module’s subprocess.call() function lets us run an external program, so we can use it to clear the screen in the appropriate platform-speciﬁc way. The sys.platform string holds the name of the operating system the program is running on, for example, “win32” or “linux2”.So one way of handling the platform differences would be to have a single clear_screen() function like this:\n\ndef clear_screen():\n\ncommand = ([\"clear\"] if not sys.platform.startswith(\"win\") else\n\n[\"cmd.exe\", \"/C\", \"cls\"])\n\nsubprocess.call(command)\n\nThe disadvantage of this approach is that even though we know the platform cannot change while the program is running, we perform the check every time the function is called.\n\nTo avoid checking which platform the program is being run on every time the clear_screen() function is called, we have created a platform-speciﬁc clear_screen() function once when the module is imported, and from then on we always use it. This is possible because the def statement is a Python state- ment like any other; when the interpreter reaches the if it executes either the ﬁrst or the second def statement, dynamically creating one or the other\n\n209",
      "content_length": 2258,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 219,
      "content": "List compre- hen- sions 118➤\n\n210\n\nChapter 5. Modules\n\nclear_screen() function. Since the function is not deﬁned inside another func- tion (or inside a class as we will see in the next chapter),it is still a global func- tion, accessible like any other function in the module.\n\nAfter creating the function we explicitly set itsdocstring;this avoidsus having to write the same docstring in two places, and also illustrates that a docstring is simply one of the attributes of a function. Other attributes include the function’s module and its name.\n\ndef resize(max_rows, max_columns, char=None):\n\n\"\"\"Changes the size of the grid, wiping out the contents and changing the background if the background char is not None \"\"\" assert max_rows > 0 and max_columns > 0, \"too small\" global _grid, _max_rows, _max_columns, _background_char if char is not None:\n\nassert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char) _background_char = char\n\n_max_rows = max_rows _max_columns = max_columns _grid = [[_background_char for column in range(_max_columns)]\n\nfor row in range(_max_rows)]\n\nThis function uses an assert statement to enforce the policy that it is a coding error to attemptto resizethe grid smaller than 1× 1.If a backgroundcharacter is speciﬁed an assert is used to guarantee that it is a string of exactly one character;if it isnot,the assertion error messageisthe _CHAR_ASSERT_TEMPLATE’s text with the {0} replaced with the given char string.\n\nUnfortunately,we must use the global statement because we need to update a number of global variables inside this function. This is something that using an object-oriented approach can help us to avoid, as we will see in Chapter 6.\n\ncomprehension. The _grid is created using a list comprehension inside a list Using list replication such as [[char] *columns ] *rows will not work because the inner list will be shared (shallow-copied).We could have used nested for … in loops instead:\n\n_grid = [] for row in range(_max_rows):\n\n_grid.append([]) for column in range(_max_columns):\n\n_grid[-1].append(_background_char)\n\nThis code is arguably trickier to understand than the list comprehension, and is much longer.",
      "content_length": 2154,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 220,
      "content": "Modules and Packages\n\nWe will review just one of the drawing functions to give a ﬂavor of how the drawing is done, since our primary concern is with the implementation of the module. Here is the add_horizontal_line() function, split into two parts:\n\ndef add_horizontal_line(row, column0, column1, char=\"-\"):\n\n\"\"\"Adds a horizontal line to the grid using the given char\n\n>>> add_horizontal_line(8, 20, 25, \"=\") >>> char_at(8, 20) == char_at(8, 24) == \"=\" True >>> add_horizontal_line(31, 11, 12) Traceback (most recent call last): ... RowRangeError \"\"\"\n\nThe docstring has two tests, one that is expected to work and another that is expected to raise an exception. When dealing with exceptions in doctests the pattern is to specify the “Traceback” line, since that is always the same and tells the doctest module an exception is expected, then to use an ellipsis to standfor theintervening lines(whichvary),andending with theexceptionline weexpecttoget. The char_at() functionisoneof thoseprovidedby themodule; it returns the character at the given row and column position in the grid.\n\nassert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char) try:\n\nfor column in range(column0, column1):\n\n_grid[row][column] = char\n\nexcept IndexError:\n\nif not 0 <= row <= _max_rows: raise RowRangeError()\n\nraise ColumnRangeError()\n\nThe code begins with the same character length check that is used in the re- size() function. Rather than explicitly checking the row and column argu- ments, the function works by assuming that the arguments are valid. If an IndexError exception occurs because a nonexistent row or column is accessed, we catch the exception and raise the appropriate module-speciﬁc exception in its place. This style of programming is known colloquially as “it’seasier to ask forgivenessthan permission”,and is generally considered more Pythonic(good Pythonprogrammingstyle)than“look beforeyouleap”,wherechecksaremade in advance. Relying onexceptionstoberaisedratherthanchecking inadvance is more efﬁcient when exceptions are rare. (Assertions don’t count as “look before you leap” because they should never occur—and are often commented out—in deployed code.)\n\n211",
      "content_length": 2163,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 221,
      "content": "212\n\nChapter 5. Modules\n\nAlmost at the end of the module, after all the functions have been deﬁned, there is a single call to resize():\n\nresize(_max_rows, _max_columns)\n\nThis call initializes the grid to the default size (25 × 80) and ensures that code that imports the module can safely make use of it immediately. Without this call, every time the module was imported, the importing program or module would have to call resize() to initialize the grid, forcing programmers to remember that fact and also leading to multiple initializations.\n\nif __name__ == \"__main__\":\n\nimport doctest doctest.testmod()\n\nThe last three lines of the module are the standard ones for modules that use the doctest module to check their doctests. (Testing is covered more fully in Chapter 9.)\n\nThe CharGrid module hasan important failing:It supportsonly a single charac- ter grid. One solution to this would be to hold a collection of grids in the mod- ule,but that would mean that users of the module would have to provide a key or index with every function call to identify which grid they were referring to. In caseswhere multiple instancesof an object are required,a better solution is to create a module that deﬁnes a class (a custom data type), since we can cre- ate as many class instances (objectsof the data type) as we like. An additional beneﬁt of creating a class is that we should be able to avoid using the global statementby storing class(static)data. Wewill seehow to createclassesin the next chapter.\n\nOverview of Python’s Standard Library\n\n|||\n\nPython’s standard library is generally described as “batteries included”, and certainly a wide range of functionality is available, spread over around two hundred packages and modules.\n\nIn fact,so many high-quality moduleshave been developed for Python over the years,that to include them all in the standard library would probably increase the size of the Python distribution packagesby at least an order of magnitude. So those modules that are in the library are more a reﬂection of Python’s his- tory and of the interests of its core developers than of any concerted or sys- tematic effort to create a “balanced” library. Also, some modules have proved very difﬁcult to maintain within the library—most notably the Berkeley DB module—and so have been taken out of the library and are now maintained independently. This means many excellent third-party modules are available for Pythonthat—despitetheir quality and usefulness—arenot in thestandard",
      "content_length": 2493,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 222,
      "content": "Overviewof Python’s Standard Library\n\nlibrary. (We will look at two such modules later on: the PyParsing and PLY modules that are used to create parsers in Chapter 14.)\n\nIn this section we present a broad overview of what is on offer, taking a thematic approach,but excluding those packagesand modulesthat are of very specialized interest and those which are platform-speciﬁc. In many cases a small example is shown to give a ﬂavor of some of the packages and modules; cross-referencesare provided for those packages and modules that are covered elsewhere in the book.\n\nString Handling\n\nThe string module provides some useful constants such as string.ascii_let- ters and string.hexdigits.It also provides the string.Formatter class which we can subclass to provide custom string formatters.★ The textwrap module can be used to wrap lines of text to a speciﬁed width, and to minimize indentation.\n\nThe struct module provides functions for packing and unpacking numbers, Booleans, and strings to and from bytes objects using their binary representa- tions. Thiscan be usefulwhen handling data tobesent to or receivedfromlow- level libraries written in C. The struct and textwrap modules are used by the convert-incidents.py program covered in Chapter 7.\n\nThe difflib module provides classes and methods for comparing sequences, such as strings, and is able to produce output both in standard “diff” formats and in HTML.\n\nPython’s most powerful string handling module is the re (regular expression) module. This is covered in Chapter 13.\n\nThe io.StringIO class can provide a string-like object that behaves like an in-memory text ﬁle. This can be convenient if we want to use the same code that writes to a ﬁle to write to a string.\n\nExample: The io.StringIO Class\n\nPython provides two different ways of writing text to ﬁles. One way is to use a ﬁle object’s write() method, and the other is to use the print() function with the file keyword argument set to a ﬁle object that is open for writing. For example:\n\nprint(\"An error message\", file=sys.stdout) sys.stdout.write(\"Another error message\\n\")\n\n★The term subclassing (or specializing) is used for when we create a custom data type (a class) based on another class. Chapter 6 gives full coverage of this topic.\n\n213\n\n||\n\n|\n\nbytes type ➤ 293\n\nThe struct module ➤ 297",
      "content_length": 2315,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 223,
      "content": "214\n\nChapter 5. Modules\n\nBoth lines of text are printed to sys.stdout, a ﬁle object that represents the “standard output stream”—this is normally the console and differs from sys.stderr, the “error output stream” only in that the latter is unbuffered. (Python automatically creates and opens sys.stdin, sys.stdout, and sys.stderr at programstart-up.) The print() functionaddsa newlineby default,although we can stop this by giving the end keyword argument set to an empty string.\n\nIn some situations it is useful to be able to capture into a string the output that is intended to go to a ﬁle. This can be achieved using the io.StringIO class which providesan object that can be used just like a ﬁle object,but which holds any data written to it in a string. If the io.StringIO object is given an initial string, it can also be read as though it were a ﬁle.\n\nWecanaccessio.StringIO if wedo import io,andwecanuseit tocaptureoutput destined for a ﬁle object such as sys.stdout:\n\nsys.stdout = io.StringIO()\n\nIf this line is put at the beginning of a program, after the imports but before any use is made of sys.stdout, any text that is sent to sys.stdout will actually be sent to the io.StringIO ﬁle-like object which this line has created and which has replaced the standard sys.stdout ﬁle object. Now, when the print() and sys.stdout.write() lines shown earlier are executed, their output will go to the io.StringIO object instead of the console. (At any time we can restore the original sys.stdout with the statement sys.stdout = sys.__stdout__.)\n\nWe can obtain all the strings that have been written to the io.StringIO ob- ject by calling the io.StringIO.getvalue() function, in this case by calling sys.stdout.getvalue()—thereturnvalueisa string containing allthelinesthat have been written. This string could be printed, or saved to a log or sent over a network connection like any other string. We will see another example of io.StringIO use a bit further on (➤ 227).\n\nCommand-Line Programming\n\nIf we need a program to be able to process text that may have been redirected in the console or that may be in ﬁles listed on the command line, we can use the fileinput module’s fileinput.input() function. This function iterates over all the lines redirected from the console (if any) and over all the lines in the ﬁles listed on the command line, as one continuous sequence of lines. The module can report the current ﬁlename and line number at any time using fileinput.filename() and fileinput.lineno(), and can handle some kinds of compressed ﬁles.\n\nTwo separate modules are provided for handling command-line options, optparse and getopt. The getopt module is popular because it is simple to use\n\n||",
      "content_length": 2701,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 224,
      "content": "csv2- html.py example 97➤\n\nOverviewof Python’s Standard Library\n\nand has been in the library for a long time. The optparse module is newer and more powerful.\n\nExample: The optparse Module\n\nBack in Chapter 2 we described the csv2html.py program. In that chapter’sex- ercises we proposed extending the program to accept the command-line argu- ments, “maxwidth” taking an integer and “format” taking a string. The mod- el solution (csv2html2_ans.py) has a 26-line function to process the arguments. Here is the start of the main() function for csv2html2_opt.py, a version of the programthat usesthe optparse module to handle thecommand-line arguments rather than a custom function:\n\ndef main():\n\nparser = optparse.OptionParser() parser.add_option(\"-w\", \"--maxwidth\", dest=\"maxwidth\", type=\"int\",\n\nhelp=(\"the maximum number of characters that can be \" \"output to string fields [default: %default]\"))\n\nparser.add_option(\"-f\", \"--format\", dest=\"format\",\n\nhelp=(\"the format used for outputting numbers \"\n\n\"[default: %default]\"))\n\nparser.set_defaults(maxwidth=100, format=\".0f\") opts, args = parser.parse_args()\n\nOnly nine lines of code are needed, plus the import optparse statement. Fur- thermore, we do not need to explicitly provide -h and --help options; these are handled by the optparse module to produce a suitable usage message using the texts from the help keyword arguments,and with any “%default” text replaced with the option’s default value.\n\nNoticealsothat theoptionsnow usetheconventionalUnix styleof having both short and long option names that start with a hyphen. Short names are con- venient for interactiveuse at theconsole;long namesaremoreunderstandable when used in shell scripts. For example, to set the maximum width to 80 we can use any of -w80, -w 80, --maxwidth=80, or --maxwidth 80. After the command line is parsed, the options are available using the dest names, for example, opts.maxwidth and opts.format. Any command-line arguments that have not been processed (usually ﬁlenames) are in the args list.\n\nIf an error occurs when parsing the command line, the optparse parser will call sys.exit(2). This leads to a clean program termination and returns 2 to the operating system as the program’s result value. Conventionally, a return value of 2 signiﬁes a usage error, 1 signiﬁes any other kind of error, and 0 meanssuccess. When sys.exit() iscalled with no argumentsit returns0tothe operating system.\n\n215\n\n|",
      "content_length": 2433,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 225,
      "content": "216\n\nChapter 5. Modules\n\nMathematics and Numbers\n\nIn addition to the built-in int, float, and complex numbers,the library provides the decimal.Decimal and fractions.Fraction numbers. Three numeric libraries are available: math for the standard mathematical functions, cmath for complex number mathematicalfunctions,and random whichprovidesmany functionsfor random number generation; these modules were introduced in Chapter 2.\n\nPython’s numeric abstract base classes (classes that can be inherited from but that cannot be used directly) are in the numbers module. They are useful for checking that an object, say, x, is any kind of number using isinstance(x, numbers.Number), or is a speciﬁc kind of number, for example, isinstance(x, numbers.Rational) or isinstance(x, numbers.Integral).\n\nThose involved in scientiﬁc and engineering programming will ﬁnd the third- party NumPy package to be useful. This module provides highly efﬁcient n-di- mensional arrays, basic linear algebra functions and Fourier transforms, and tools for integration with C, C++, and Fortran code. The SciPy package incor- porates NumPy and extends it to include modules for statistical computations, signal and image processing, genetic algorithms, and a great deal more. Both are freely available from www.scipy.org.\n\nTimes and Dates\n\nThe calendar and datetime modules provide functions and classes for date and time handling. However, they are based on an idealized Gregorian calendar, so they are not suitable for dealing with pre-Gregorian dates. Time and date handling is a very complex topic—the calendars in use have varied in differ- ent places and at different times, a day is not precisely 24 hours, a year is not exactly 365 days, and daylight saving time and time zones vary. The date- time.datetime class (but not the datetime.date class) has provisions for han- dling time zones, but does not do so out of the box. Third-party modules are available to make good this deﬁciency, for example, dateutil from www.labix. org/python-dateutil, and mxDateTime from www.egenix.com/products/python/mx- Base/mxDateTime.\n\nThe time modulehandlestimestamps. Thesearesimply numbersthat hold the number of seconds since the epoch (1970-01-01T00:00:00 on Unix). This mod- ule can be used to get a timestamp of the machine’s current time in UTC (Co- ordinated Universal Time),or as a local time that accounts for daylight saving time,and to create date,time,and date/timestringsformatted in variousways. It can also parse strings that have dates and times.\n\n||\n\n||",
      "content_length": 2536,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 226,
      "content": "Overviewof Python’s Standard Library\n\nExample: The calendar, datetime, and time Modules\n\nObjects of type datetime.datetime are usually created programmatically, whereas objects that hold UTC date/times are usually received from external sources, such as ﬁle timestamps. Here are some examples:\n\nimport calendar, datetime, time moon_datetime_a = datetime.datetime(1969, 7, 20, 20, 17, 40) moon_time = calendar.timegm(moon_datetime_a.utctimetuple()) moon_datetime_b = datetime.datetime.utcfromtimestamp(moon_time) moon_datetime_a.isoformat() moon_datetime_b.isoformat() time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(moon_time))\n\n# returns: '1969-07-20T20:17:40' # returns: '1969-07-20T20:17:40'\n\nThe moon_datetime_a variable is of type datetime.datetime and holds the date and time that Apollo 11 landed on the moon. The moon_time variable is of type int and holds the number of seconds since the epoch to the moon landing—this number is provided by the calendar.timegm() function which takes a time_struct object returned by the datetime.datetime.utctimetuple() function, and returns the number of seconds that the time_struct represents. (Since the moon landing occurred before the Unix epoch, the number is nega- tive.) The moon_datetime_b variable is of type datetime.datetime and is created from the moon_time integer to show the conversion from the number of seconds since the epoch to a datetime.datetime object.★ The last three lines all return identical ISO 8601-format date/time strings.\n\nThe current UTCdate/timeisavailable asa datetime.datetime object by calling datetime.datetime.utcnow(), and as the number of seconds since the epoch by calling time.time(). For the local date/time, use datetime.datetime.now() or time.mktime(time.localtime()).\n\nAlgorithms and Collection Data Types\n\nThe bisect module provides functions for searching sorted sequences such as sorted lists, and for inserting items while preserving the sort order. This module’s functions use the binary search algorithm,so they are very fast. The heapq module provides functions for turning a sequence such as a list into a heap—a collection data type where the ﬁrst item (at index position 0) isalways the smallest item, and for inserting and removing items while keeping the sequence as a heap.\n\n★Unfortunately for Windowsusers,the datetime.datetime.utcfromtimestamp()function can’t handle negative timestamps, that is, timestamps for dates prior to January 1, 1970.\n\n217\n\n|\n\n||",
      "content_length": 2460,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 227,
      "content": "Default dictio- nary 135➤\n\nNamed tuple 111➤\n\nOrdered dictio- nary 136➤\n\n218\n\nChapter 5. Modules\n\nThe collections package provides the collections.defaultdict dictionary and the collections.namedtuple collection data types that we have previously dis- cussed. In addition, this package provides the collections.UserList and col- lections.UserDict types, although subclassing the built-in list and dict types is probably more common than using these types. Another type is collec- tions.deque, which is similar to a list, but whereas a list is very fast for adding and removing items at the end, a collections.deque is very fast for adding and removing items both at the beginning and at the end.\n\nPython 3.1introducedthe collections.OrderedDict and the collections.Counter classes. OrderedDicts have the same API as normal dicts, although when iterated the items are always returned in insertion order (i.e.,from ﬁrst to last inserted), and the popitem() method always returns the most recently added (i.e., last) item. The Counter class is a dict subclass used to provide a fast and easy way of keeping various counts. Given an iterable or a mapping (such as a dictionary), a Counter instance can, for example, return a list of the unique elements or a list of the most common elements as (element, count) 2-tuples.\n\nPython’snon-numeric abstract base classes(classesthat can be inherited from but that cannot be used directly)are also in the collections package. They are discussed in Chapter 8.\n\nThe array module provides the array.array sequence type that can store num- bers or charactersin a very space-efﬁcient way. It has similar behavior to lists except that the type of object it can store is ﬁxed when it is created, so unlike lists it cannot store objects of different types. The third-party NumPy package mentioned earlier also provides efﬁcient arrays.\n\nThe weakref moduleprovidesfunctionality for creating weak references—these behave like normal object references,except that if the only reference to an ob- ject is a weak reference,the object can still be scheduled for garbage collection. Thispreventsobjectsfrombeing kept in memory simply becausewe have a ref- erence to them. Naturally, we can check whether the object a weak reference refers to still exists, and can access the object if it does.\n\nExample: The heapq Module\n\nThe heapq module provides functions for converting a list into a heap and for adding and removing items from the heap while preserving the heap property. A heap is a binary tree that respects the heap property, which is that the ﬁrst item (at index position 0) is always the smallest item.★ Each of a heap’s subtrees is also a heap, so they too respect the heap property. Here is how a heap could be created from scratch:\n\n★Strictly speaking,the heapq module provides a min heap; heaps where the ﬁrst item is always the largest are max heaps.\n\n|\n\n3.1",
      "content_length": 2894,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 228,
      "content": "Char- acter encod- ings 91➤\n\nOverviewof Python’s Standard Library\n\nimport heapq heap = [] heapq.heappush(heap, (5, \"rest\")) heapq.heappush(heap, (2, \"work\")) heapq.heappush(heap, (4, \"study\"))\n\nIf we already have a list, we can turn it into a heap with heapq.heapify(alist); this will do any necessary reordering in-place. The smallest item can be removed from the heap using heapq.heappop(heap).\n\nfor x in heapq.merge([1, 3, 5, 8], [2, 4, 7], [0, 1, 6, 8, 9]):\n\nprint(x, end=\" \") # prints: 0 1 1 2 3 4 5 6 7 8 8 9\n\nThe heapq.merge() function takesany number of sorted iterablesas arguments and returns an iterator that iterates over all the items from all the iterables in order.\n\nFile Formats, Encodings, and Data Persistence\n\nThe standard library has extensive support for a variety of standard ﬁle for- mats and encodings. The base64 module has functions for reading and writing using the Base16, Base32, and Base64 encodings speciﬁed in RFC 3548.★ The quopri module has functions for reading and writing “quoted-printable” for- mat. This format is deﬁned in RFC 1521 and is used for MIME (Multipurpose Internet Mail Extensions) data. The uu module has functions for reading and writing uuencoded data. RFC 1832 deﬁnes the External Data Representation Standard and module xdrlib provides functions for reading and writing data in this format.\n\nModules are also provided for reading and writing archive ﬁles in the most popularformats. The bz2 modulecanhandle .bz2 ﬁles,thegzip modulehandles .gz ﬁles,the tarfile module handles .tar, .tar.gz (also .tgz),and .tar.bz2 ﬁles, and the zipfile module handles .zip ﬁles. We will see an example of using the tarfile modulein thissubsection,and later on (➤227)thereisa smallexample that uses the gzip module; we will also see the gzip module in action again in Chapter 7.\n\nSupport is also provided for handling some audio formats, with the aifc mod- ule for AIFF (Audio Interchange File Format) and the wave module for (uncom- pressed) .wav ﬁles. Some forms of audio data can be manipulated using the audioop module,and the sndhdr module providesa couple of functionsfor deter- mining what kind of sound data is stored in a ﬁle and some of its properties, such as the sampling rate.\n\n★ RFC (Request for Comments) documents are used to specify various Internet technologies. Each one has a unique identiﬁcation number and many of them have become ofﬁcially adopted standards.\n\n219\n\n||",
      "content_length": 2428,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 229,
      "content": "220\n\nChapter 5. Modules\n\nA format for conﬁguration ﬁles (similar to old-style Windows .ini ﬁles) is speciﬁed in RFC 822, and the configparser module provides functions for reading and writing such ﬁles.\n\nMany applications, for example, Excel, can read and write CSV (Comma Separated Value)data,or variantssuch astab-delimited data. The csv module can read and write these formats, and can account for the idiosyncracies that prevent CSV ﬁles from being straightforward to handle directly.\n\nIn addition to its support of various ﬁle formats, the standard library also has packages and modules that provide data persistence. The pickle module is used to store and retrieve arbitrary Python objects (including entire collec- tions) to and from disk; this module is covered in Chapter 7. The library also supports DBM ﬁles of various kinds—these are like dictionaries except that their items are stored on disk rather than in memory, and both their keys and their values must be bytes objects or strings. The shelve module, covered in Chapter 12, can be used to provide DBM ﬁles with string keys and arbitrary Python objects as values—the module seamlessly converts the Python ob- jects to and from bytes objects behind the scenes. The DBM modules,Python’s database API, and using the built-in SQLite database are all covered in Chap- ter 12.\n\nExample: The base64 Module\n\nThe base64 module ismostly used for handling binary data that isembedded in emails as ASCII text. It can also be used to store binary data inside .py ﬁles. The ﬁrst step is to get the binary data into Base64 format. Here we assume that the base64 module has been imported and that the path and ﬁlename of a .png ﬁle are in the variable left_align_png:\n\nbinary = open(left_align_png, \"rb\").read() ascii_text = \"\" for i, c in enumerate(base64.b64encode(binary)):\n\nif i and i % 68 == 0:\n\nascii_text += \"\\\\\\n\"\n\nascii_text += chr(c)\n\nleft_align.png\n\nThis code snippet reads the ﬁle in binary mode and converts it to a Base64 string of ASCII characters. Every sixty-eighth character a backslash-newline combination is added. This limits the width of the lines of ASCII characters to 68,but ensures that when the data is read back the newlines will be ignored (becausethebackslashwill escapethem).TheASCIItext obtainedlikethiscan be stored as a bytes literal in a .py ﬁle, for example:\n\nLEFT_ALIGN_PNG = b\"\"\"\\ iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABGdBTUEAALGPC/xhBQAA\\\n\n|\n\nbytes type ➤ 293",
      "content_length": 2461,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 230,
      "content": "Overviewof Python’s Standard Library\n\n... bmquu8PAmVT2+CwVV6rCyA9UfFMCkI+bN6p18tCWqcUzrDOwBh2zVCR+JZVeAAAAAElF\\ TkSuQmCC\"\"\"\n\nWe’ve omitted most of the lines as indicated by the ellipsis.\n\nThe data can be converted back to its original binary form like this:\n\nbinary = base64.b64decode(LEFT_ALIGN_PNG)\n\nThe binary data could be written to a ﬁle using open(filename, \"wb\").write( binary). Keeping binary data in .py ﬁles is much less compact than keeping it in its original form, but can be useful if we want to provide a program that requires some binary data as a single .py ﬁle.\n\nExample: The tarﬁle Module\n\nMost versions of Windows don’t come with support for the .tar format that is so widely used on Unix systems. This inconvenient omission can easily be rectiﬁed using Python’s tarfile module,which can create and unpack .tar and .tar.gz archives (known as tarballs), and with the right libraries installed, .tar.bz2 archives. The untar.py programcan unpack tarballsusing the tarfile module;herewewill just showsomekey extracts,starting with theﬁrst import statement:\n\nBZ2_AVAILABLE = True try:\n\nimport bz2 except ImportError:\n\nBZ2_AVAILABLE = False\n\nThe bz2 module is used to handle the bzip2 compression format,but importing it will fail if Python was built without access to the bzip2 library. (The Python binary for Windows is always built with bzip2 compression built-in; it is only on some Unix builds that it might be absent.) We account for the possibility that the module isnot available using a try …except block,and keep a Boolean variable that we can refer to later (although we don’t quote the code that uses it).\n\nUNTRUSTED_PREFIXES = tuple([\"/\", \"\\\\\"] +\n\n[c + \":\" for c in string.ascii_letters])\n\nThis statement creates the tuple ('/', '\\', 'A:', 'B:', …, 'Z:', 'a:', 'b:', …, 'z:'). Any ﬁlename in the tarball being unpacked that begins with one of these is suspect—tarballs should not use absolute paths since then they risk overwriting system ﬁles, so as a precaution we will not unpack any ﬁle whose name starts with one of these preﬁxes.\n\n221\n\n|",
      "content_length": 2070,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 231,
      "content": "222\n\nChapter 5. Modules\n\ndef untar(archive): tar = None try:\n\ntar = tarfile.open(archive) for member in tar.getmembers():\n\nif member.name.startswith(UNTRUSTED_PREFIXES):\n\nprint(\"untrusted prefix, ignoring\", member.name)\n\nelif \"..\" in member.name:\n\nprint(\"suspect path, ignoring\", member.name)\n\nelse:\n\ntar.extract(member) print(\"unpacked\", member.name)\n\nexcept (tarfile.TarError, EnvironmentError) as err:\n\nerror(err)\n\nfinally:\n\nif tar is not None: tar.close()\n\nEach ﬁle in a tarball is called a member. The tarfile.getmembers() function returns a list of tarfile.TarInfo objects, one for each member. The member’s ﬁlename, including its path, is in the tarfile.TarInfo.name attribute. If the name begins with an untrusted preﬁx, or contains .. in its path, we output an error message;otherwise,we call tarfile.extract() to savethemember todisk. The tarfile modulehasitsown set of customexceptions,but wehavetakenthe simplistic approach that if any exception occurs we output the error message and ﬁnish.\n\ndef error(message, exit_status=1):\n\nprint(message) sys.exit(exit_status)\n\nWe have just quoted the error() function for completeness. The (unquoted) main() function prints a usage message if -h or --help is given; otherwise, it performs some basic checks before calling untar() with the tarball’s ﬁlename.\n\nFile, Directory, and Process Handling\n\nThe shutil moduleprovideshigh-levelfunctionsfor ﬁleanddirectory handling, including shutil.copy() and shutil.copytree() for copying ﬁles and entire directory trees, shutil.move() for moving directory trees, and shutil.rmtree() for removing entire directory trees, including nonempty ones.\n\nTemporary ﬁles and directories should be created using the tempfile module which provides the necessary functions, for example, tempfile.mkstemp(), and creates the temporaries in the most secure manner possible.\n\n||",
      "content_length": 1855,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 232,
      "content": "Overviewof Python’s Standard Library\n\nThe filecmp module can be used to compare ﬁles with the filecmp.cmp() func- tion and to compare entire directories with the filecmp.cmpfiles() function.\n\nOne very powerful and effective use of Python programs is to orchestrate the running of other programs. This can be done using the subprocess mod- ule which can start other processes, communicate with them using pipes, and retrieve their results. This module is covered in Chapter 10. An even more powerful alternative is to use the multiprocessing module which provides ex- tensivefacilitiesforofﬂoadingworktomultipleprocessesandforaccumulating results, and can often be used as an alternative to multithreading.\n\nThe os moduleprovidesplatform-independent accessto operating systemfunc- tionality. The os.environ variable holds a mapping object whose items are en- vironment variable names and their values. The program’s working directory is provided by os.getcwd() and can be changed using os.chdir(). The module also provides functions for low-level ﬁle-descriptor-based ﬁle handling. The os.access() function can be used to determine whether a ﬁle exists or whether it is readable or writable, and the os.listdir() function returns a list of the entries (e.g.,the ﬁles and directories,but excluding the . and .. entries),in the directory it is given. The os.stat() function returns various items of informa- tion about a ﬁle or directory, such as its mode, access time, and size.\n\nDirectories can be created using os.mkdir(), or if intermediate directories need to be created, using os.makedirs(). Empty directories can be removed using os.rmdir(), and directory trees that contain only empty directories can be removed using os.removedirs(). Files or directories can be removed using os.remove(), and can be renamed using os.rename().\n\nThe os.walk() function iterates over an entire directory tree, retrieving the name of every ﬁle and directory in turn.\n\nThe os module also provides many low-level platform-speciﬁc functions, for example, to work with ﬁle descriptors, and to fork (only on Unix systems), spawn, and exec.\n\nWhereas the os module provides functions for interacting with the operating system, especially in the context of the ﬁle system, the os.path module pro- vides a mixture of string manipulation (of paths), and some ﬁle system con- venience functions. The os.path.abspath() function returns the absolute path of its argument, with redundant path separators and .. elements removed. The os.path.split() function returns a 2-tuple with the ﬁrst element con- taining the path and the second the ﬁlename (which will be empty if a path with no ﬁlename was given). These two parts are also available directly using os.path.basename() and os.path.dirname(). A ﬁlename can also be split into two parts, name and extension, using os.path.splitext(). The os.path.join() function takes any number of path strings and returns a single path using the platform-speciﬁc path separator.\n\n223",
      "content_length": 2994,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 233,
      "content": "224\n\nChapter 5. Modules\n\nIf we need several pieces of information about a ﬁle or directory we can use os.stat(), but if we need just one piece, we can use the relevant os.path function,for example, os.path.exists(), os.path.getsize(), os.path.isfile(),or os.path.isdir().\n\nThe mimetypes module has the mimetypes.guess_type() function that tries to guess the given ﬁle’s MIME type.\n\nExample: The os and os.path Modules\n\nHere is how we can use the os and os.path modules to create a dictionary where each key is a ﬁlename (including its path) and where each value is the timestamp (seconds since the epoch) when the ﬁle was last modiﬁed, for those ﬁles in the given path:\n\ndate_from_name = {} for name in os.listdir(path):\n\nfullname = os.path.join(path, name) if os.path.isfile(fullname):\n\ndate_from_name[fullname] = os.path.getmtime(fullname)\n\nThis code is pretty straightforward, but can be used only for the ﬁles in a single directory. If we need to traverse an entire directory tree we can use the os.walk() function.\n\nHere is a code snippet taken from the finddup.py program.★ The code creates a dictionary where each key is a 2-tuple (ﬁle size, ﬁlename) where the ﬁlename excludes the path, and where each value is a list of the full ﬁlenames that match their key’s ﬁlename and have the same ﬁle size:\n\ndata = collections.defaultdict(list)\n\nfor root, dirs, files in os.walk(path):\n\nfor filename in files:\n\nfullname = os.path.join(root, filename) key = (os.path.getsize(fullname), filename) data[key].append(fullname)\n\nFor each directory,os.walk() returnsthe root and two lists,one of the subdirec- tories in the directory and the other of the ﬁles in the directory. To get the full path for a ﬁlename we need to combine just the root and the ﬁlename. Notice thatwedonothavetorecurseintothesubdirectoriesourselves—os.walk() does that for us. Once the data has been gathered,we can iterate over it to produce a report of possible duplicate ﬁles:\n\n★A much more sophisticated ﬁnd duplicates program, findduplicates-t.py, which uses multiple threads and MD5 checksums, is covered in Chapter 10.\n\n|",
      "content_length": 2096,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 234,
      "content": "Overviewof Python’s Standard Library\n\nfor size, filename in sorted(data):\n\nnames = data[(size, filename)] if len(names) > 1:\n\nprint(\"{filename} ({size} bytes) may be duplicated \" \"({0} files):\".format(len(names), **locals()))\n\nfor name in names:\n\nprint(\"\\t{0}\".format(name))\n\nBecause the dictionary keys are (size, ﬁlename) tuples, we don’t need to use a key function to get the data sorted in size order. If any (size, ﬁlename) tuple has more than one ﬁlename in its list, these might be duplicates.\n\n... shell32.dll (8460288 bytes) may be duplicated (2 files): \\windows\\system32\\shell32.dll \\windows\\system32\\dllcache\\shell32.dll\n\nThis is the last item taken from the 3282 lines of output produced by running finddup.py \\windows on a Windows XP system.\n\nNetworking and Internet Programming\n\nPackages and modules for networking and Internet programming are a major part of Python’s standard library. At the lowest level, the socket module pro- vides the most fundamental network functionality,with functions for creating sockets,doing DNS(DomainNameSystem)lookups,andhandling IP (Internet Protocol) addresses. Encrypted and authenticated sockets can be set up using the ssl module. The socketserver module providesTCP (TransmissionControl Protocol) and UDP (User Datagram Protocol) servers. These servers can han- dle requestsdirectly,or can create a separate process(by forking)or a separate thread to handle each request. Asynchronous client and server socket han- dling can be achieved using the asyncore module and the higher-level asynchat module that is built on top of it.\n\nPython has deﬁned the WSGI (Web Server Gateway Interface) to provide a standard interface between web servers and web applications written in Python. In support of the standard the wsgiref package provides a reference implementation of WSGI that has modules for providing WSGI-compliant HTTP servers, and for handling response header and CGI (Common Gateway Interface)scripts. In addition,the http.server module providesan HTTP serv- er which can be given a request handler (a standard one is provided), to run CGI scripts. The http.cookies and http.cookiejar modules provide functions for managing cookies, and CGI script support is provided by the cgi and cgitb modules.\n\n225\n\n||",
      "content_length": 2263,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 235,
      "content": "226\n\nChapter 5. Modules\n\nClientaccesstoHTTPrequestsisprovidedby thehttp.client module,although the higher-level urllib package’s modules, urllib.parse, urllib.request, url- lib.response, urllib.error, and urllib.robotparser, provide easier and more convenient access to URLs. Grabbing a ﬁle from the Internet is as simple as:\n\nfh = urllib.request.urlopen(\"http://www.python.org/index.html\") html = fh.read().decode(\"utf8\")\n\nThe urllib.request.urlopen() function returns an object that behaves much like a ﬁle object opened in read binary mode. Here we retrieve the Python Web site’s index.html ﬁle (as a bytes object), and store it as a string in the html variable. It is also possible to grab ﬁles and store them in local ﬁles with the urllib.request.urlretrieve() function.\n\nHTML and XHTML documents can be parsed using the html.parser module, URLscan be parsedand createdusing the urllib.parse module,and robots.txt ﬁlescan be parsed with the urllib.robotparser module. Data that isrepresent- ed using JSON (JavaScript Object Notation)can be read and written using the json module.\n\nIn addition to HTTP server and client support,the library provides XML-RPC (Remote Procedure Call) support with the xmlrpc.client and xmlrpc.server modules. Additional client functionality is provided for FTP (File Transfer Protocol) by the ftplib module, for NNTP (Network News Transfer Protocol) by the nntplib module, and for TELNET with the telnetlib module.\n\nThe smtpd module provides an SMTP (Simple Mail Transfer Protocol) server, and the email client modules are smtplib for SMTP, imaplib for IMAP4 (Inter- net Message Access Protocol),and poplib for POP3 (Post Ofﬁce Protocol).Mail- boxes in various formatscan be accessed using the mailbox module. Individual messages (including multipart messages) can be created and manipulated us- ing the email module.\n\nIf the standard library’s packages and modules are insufﬁcient in this area, Twisted (www.twistedmatrix.com) provides a comprehensive third-par- ty networking library. Many third-party web programming libraries are also available, including Django (www.djangoproject.com) and Turbogears (www.turbogears.org) for creating web applications, and Plone (www.plone.org) and Zope (www.zope.org) which provide complete web frameworks and content management systems. All of these libraries are written in Python.\n\nXML\n\nThere are two widely used approaches to parsing XML documents. One is the DOM (Document Object Model) and the other is SAX (Simple API for XML). Two DOM parsers are provided, one by the xml.dom module and the other by the xml.dom.minidom module. A SAX parser is provided by the xml.sax mod-\n\n||",
      "content_length": 2658,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 236,
      "content": "Overviewof Python’s Standard Library\n\nule. We have already used the xml.sax.saxutils module for its xml.sax.sax- utils.escape() function (to XML-escape “&”, “<”, and “>”). There is also an xml.sax.saxutils.quoteattr() function that does the same thing but addi- tionally escapes quotes (to make the text suitable for a tag’s attribute), and xml.sax.saxutils.unescape() to do the opposite conversion.\n\nTwo other parsers are available. The xml.parsers.expat module can be used to parse XML documentswith expat,providing the expat library isavailable,and the xml.etree.ElementTree can be used to parse XML documents using a kind of dictionary/list interface. (By default, the DOM and element tree parsers themselves use the expat parser under the hood.)\n\nWriting XML manually and writing XML using DOM and element trees, and parsing XML using the DOM, SAX, and element tree parsers, is covered in Chapter 7.\n\nThere is also a third-party library, lxml (www.codespeak.net/lxml), that claims to be “the most feature-rich and easy-to-use library for working with XML and HTML in the Python language.” This library provides an interface that is essentially a superset of what the element tree module provides, as well as many additional features such as support for XPath, XSLT, and many other XML technologies.\n\nExample: The xml.etree.ElementTree Module\n\nPython’s DOM and SAX parsers provide the APIs that experienced XML programmers are used to, and the xml.etree.ElementTree module offers a more Pythonic approach to parsing and writing XML. The element tree module is a fairly recent addition to the standard library,★ and so may not be familiar to some readers. In view of this,we will present a very short examplehereto give a ﬂavor of it—Chapter 7 provides a more substantial example and provides comparative code using DOM and SAX.\n\nThe U.S.government’sNOAA (NationalOceanic and AtmosphericAdministra- tion) Web site provides a wide variety of data, including an XML ﬁle that lists the U.S.weather stations. The ﬁle is more than 20000 lines long and contains details of around two thousand stations. Here is a typical entry:\n\n<station> <station_id>KBOS</station_id> <state>MA</state> <station_name>Boston, Logan International Airport</station_name> ... <xml_url>http://weather.gov/data/current_obs/KBOS.xml</xml_url> </station>\n\n★The xml.etree.ElementTree module ﬁrst appeared in Python 2.5.\n\n227\n\n|",
      "content_length": 2399,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 237,
      "content": "io. StringIO 213➤\n\n228\n\nChapter 5. Modules\n\nWe have cut out a few lines and reduced the indentation that is present in the ﬁle. The ﬁle is about 840K in size, so we have compressed it using gzip to a more manageable 72K. Unfortunately, the element tree parser requires either a ﬁlenameor a ﬁleobject toread,but wecannotgiveit thecompressedﬁlesince that will just appear to be random binary data. We can solve thisproblemwith two initial steps:\n\nbinary = gzip.open(filename).read() fh = io.StringIO(binary.decode(\"utf8\"))\n\nThe gzip module’s gzip.open() function is similar to the built-in open() except that it reads gzip-compressed ﬁles (those with extension .gz) as raw binary data. We need the data available as a ﬁle that the element tree parser can work with,so we use the bytes.decode() method to convert the binary data to a string using UTF-8 encoding (which is what the XML ﬁle uses), and we create a ﬁle-like io.StringIO object with the string containing the entire XML ﬁle as its data.\n\ntree = xml.etree.ElementTree.ElementTree() root = tree.parse(fh) stations = [] for element in tree.getiterator(\"station_name\"):\n\nstations.append(element.text)\n\nHerewecreatea new xml.etree.ElementTree.ElementTree object and give it a ﬁle object from which to read the XML we want it to parse. As far as the element tree parser is concerned it has been passed a ﬁle object open for reading, although in fact it is reading a string inside an io.StringIO object. We want to extract the names of all the weather stations,and this is easily achieved using the xml.etree.ElementTree.ElementTree.getiterator() method which returnsan iterator that returns all the xml.etree.ElementTree.Element objects that have the given tag name. We just use the element’s text attribute to retrieve the text. Like os.walk(), we don’t have to do any recursion ourselves; the iterator method does that for us. Nor do we have to specify a tag—in which case the iterator will return every element in the entire XML document.\n\nOther Modules\n\nWe don’t have the space to cover the nearly 200 packagesand modulesthat are available in the standard library. Nonetheless, this general overview should be sufﬁcient to get a ﬂavor of what the library provides and some of the key packages in the major areas it serves. In this section’s ﬁnal subsection we discuss just a few more areas of interest.\n\nIn the previous section we saw how easy it is to create tests in docstrings and to run them using the doctest module. The library also has a unit-testing\n\n||\n\nbytes type ➤ 293",
      "content_length": 2536,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 238,
      "content": "Shallow and deep copying 146➤\n\nOverviewof Python’s Standard Library\n\n229\n\nframework provided by the unittest module—this is a Python version of the Java JUnit test framework. The doctest module also provides some basic in- tegration with the unittest module. (Testing is covered more fully in Chap- ter 9.) Several third-party testing frameworks are also available, for example, py.test from codespeak.net/py/dist/test/test.html and nose from code.google. com/p/python-nose.\n\nNoninteractive applications such as servers often report problems by writing to log ﬁles. The logging module provides a uniform interface for logging, and in addition to being able to log to ﬁles, it can log using HTTP GET or POST requests, or using email or sockets.\n\nThe library provides many modules for introspection and code manipulation, and although most of them are beyond the scope of thisbook,one that is worth mentioning is pprint which has functions for “pretty printing” Python objects, including collection data types, which is sometimes useful for debugging. We will see a simple use of the inspect module that introspects live objects in Chapter 8.\n\nThe threading module provides support for creating threaded applications, and the queue module provides three different kinds of thread-safe queues. Threading is covered in Chapter 10.\n\nPython has no native support for GUI programming,but several GUI libraries can be used by Python programs. The Tk library is available using the tkinter module,and is usually installed as standard. GUI programming is introduced in Chapter 15.\n\nThe abc (Abstract Base Class) module provides the functions necessary for creating abstract base classes. This module is covered in Chapter 8.\n\nThe copy module provides the copy.copy() and copy.deepcopy() were discussed in Chapter 3.\n\nfunctions that\n\nAccessto foreignfunctions,that is,to functionsin shared libraries (.dll ﬁles on Windows, .dylib ﬁles on Mac OS X, and .so ﬁles on Linux), is available using the ctypes module. Python also provides a C API, so it is possible to create custom data types and functions in C and make these available to Python. Both the ctypes module and Python’s C API are beyond the scope of this book.\n\nIf none of the packages and modules mentioned in this section provides the functionality you need, before writing anything from scratch it is worth checking the Python documentation’s Global Module Index to see whether a suitable module is available, since we have not been able to mention ev- ery one here. And failing that, try looking at the Python Package Index (pypi.python.org/pypi) which contains several thousand Python add-ons rang- ing from small one-ﬁle modules all the way up to large library and framework packages containing anything from scores to hundreds of modules.",
      "content_length": 2791,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 239,
      "content": "230\n\nChapter 5. Modules\n\nSummary\n\n|||\n\nThe chapter began by introducing the various syntaxes that can be used for importing packages, modules, and objects inside modules. We noted that many programmers only use the import importable syntax so as to avoid name clashes,and that we must be careful not to give a program or module the same name as a top-level Python module or directory.\n\nAlso discussed were Python packages. These are simply directories with an __init__.py ﬁle and one or more .py modules inside them. The __init__.py ﬁle can be empty, but to support the from importable import * syntax, we can create an __all__ special variable in the __init__.py ﬁle set to a list of module names. We can also put any common initialization code in the __init__.py ﬁle. It wasnoted that packagescan benestedsimply by creating subdirectoriesand having each of these contain its own __init__.py ﬁle.\n\nTwo custom modules were described. The ﬁrst just provided a few functions and had very simple doctests. The second was more elaborate with its own exceptions, the use of dynamic function creation to create a function with a platform-speciﬁcimplementation,privateglobaldata,a calltoaninitialization function, and more elaborate doctests.\n\nAbout half the chapter was devoted to a high-level overview of Python’s stan- dard library. Several string handling modules were mentioned and a couple of io.StringIO examples were presented. One example showed how to write text to a ﬁle using either the built-in print() function or a ﬁle object’s write() method,and how to use an io.StringIO object in place of a real ﬁle. In previous chapters we handled command-line options by reading sys.argv ourselves, but in the coverage of the library’s support for command-line programming we in- troducedtheoptparsemodulewhichgreatlysimpliﬁescommand-lineargument handling—we will use this module extensively from now on.\n\nMention wasmade of Python’sexcellent support for numbers,and the library’s numeric types and its three modules of mathematical functions, as well as the support for scientiﬁc and engineering mathematics provided by the SciPy project. Both library and third-party date/time handling classes were brieﬂy described and examples of how to obtain the current date/time and how to convert between datetime.datetime and the number of seconds since the epoch were shown. Also discussed were the additional collection data types and the algorithms for working with ordered sequences that the standard library provides, along with some examples of using the heapq module’s functions.\n\nThe modules that support various ﬁle encodings (besides character encodings) were discussed, as well as the modules for packing and unpacking the most popular archiveformats,and thosethat have supportfor audiodata. An exam- pleshowing howtousetheBase64encoding tostorebinary datain .py ﬁleswas given,andalsoa programtounpack tarballs. Considerablesupportisprovided",
      "content_length": 2942,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 240,
      "content": "Summary\n\nfor handling directories and ﬁles—and all of this is abstracted into platform- independent functions. Examples were shown for creating a dictionary with ﬁlename keys and last modiﬁed timestamp values, and for doing a recursive search of a directory to identify possible duplicate ﬁles based on their name and size.\n\nA largepartof thelibrary isdevotedtonetworking andInternetprogramming. We very brieﬂy surveyed what is available, from raw sockets (including encrypted sockets),to TCP and UDP servers, to HTTP servers and support for the WSGI.Also mentioned were the modules for handling cookies,CGI scripts, and HTTP data, and for parsing HTML, XHTML, and URLs. Other modules that were mentioned included those for handling XML-RPC and for handling higher-level protocols such as FTP and NNTP, as well as the email client and server support using SMTP and client support for IMAP4 and POP3.\n\nThe library’s comprehensive support for XML writing and parsing was also mentioned, including the DOM, SAX, and element tree parsers, and the expat module. And an example was given using the element tree module. Mention was also made of some of the many other packages and modules that the library provides.\n\nPython’s standard library represents an extremely useful resource that can save enormous amounts of time and effort, and in many cases allows us to write much smaller programs by relying on the functionality that the library provides. Inaddition,literally thousandsof third-party packagesareavailable to ﬁll any gaps the standard library may have. All of this predeﬁned function- ality allows us to focus much more on what we want our programs to do, while leaving the library modules to take care of most of the details.\n\nThis chapter brings us to the end of the fundamentals of procedural program- ming. Later chapters, and particularly Chapter 8, will look at more advanced and specialized procedural techniques, and the following chapter introduces object-orientedprogramming. UsingPythonasapurelyprocedurallanguageis both possibleand practical—especiallyfor small programs—butfor mediumto largeprograms,for custompackagesand modules,and for long-termmaintain- ability, the object-oriented approach usually wins out. Fortunately,all that we have covered up to now is both useful and relevant in object-oriented program- ming, so the subsequent chapters will continue to build up our Python knowl- edge and skills based on the foundations that have now been laid.\n\nExercise\n\nWrite a program to show directory listings, rather like the dir command in Windows or ls in Unix. The beneﬁt of creating our own listing program is that we can build in the defaults we prefer and can use the same program on\n\n231\n\n|||",
      "content_length": 2721,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 241,
      "content": "locale. set- locale() 86➤\n\n232\n\nChapter 5. Modules\n\nall platforms without having to remember the differences between dir and ls. Create a program that supports the following interface:\n\nUsage: ls.py [options] [path1 [path2 [... pathN]]] The paths are optional; if not given . is used. Options: -h, --help show this help message and exit -H, --hidden show hidden files [default: off] -m, --modified show last modified date/time [default: off] -o ORDER, --order=ORDER order by ('name', 'n', 'modified', 'm', 'size', 's') [default: name] -r, --recursive recurse into subdirectories [default: off] -s, --sizes show sizes [default: off]\n\n(The output has been modiﬁed slightly to ﬁt the book’s page.)\n\nHere is an example of output on a small directory using the command line ls.py -ms -os misc/:\n\n2008-02-11 14:17:03 12,184 misc/abstract.pdf 2008-02-05 14:22:38 109,788 misc/klmqtintro.lyx 2007-12-13 12:01:14 1,359,950 misc/tracking.pdf misc/phonelog/ 3 files, 1 directory\n\nWe used option grouping in the command line (optparse handlesthisautomati- cally for us),but the same could have been achieved using separate options,for example, ls.py -m -s -os misc/, or by even more grouping, ls.py -msos misc/, or by using long options, ls.py --modified --sizes --order=size misc/, or any com- bination of these. Note that we deﬁne a “hidden” ﬁle or directory as one whose name begins with a dot (.).\n\nThe exercise is quite challenging. You will need to read the optparse documen- tation to see how to provide options that set a True value, and how to offer a ﬁxed list of choices. If the user sets the recursive option you will need to pro- cess the ﬁles (but not the directories) using os.walk(); otherwise, you will have to use os.listdir() and process both ﬁles and directories yourself.\n\nOne rather tricky aspect is avoiding hidden directories when recursing. They can be cut out of os.walk()’s dirs list—and therefore skipped by os.walk()—by modifying that list. But be carefulnot to assign to the dirs variableitself,since that won’t change the list it refers to but will simply (and uselessly) replace it; the approach used in the model solution is to assign to a slice of the whole list, that is, dirs[:] = [dir for dir in dirs if not dir.startswith(\".\")].\n\nThe best way to get grouping characters in the ﬁle sizes is to import the locale module, call locale.setlocale() to get the user’s default locale, and use the n format character. Overall, ls.py is about 130 lines split over four functions.",
      "content_length": 2495,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 242,
      "content": "6\n\nThe Object-Oriented Approach ● Custom Classes ● Custom Collection Classes\n\nObject-Oriented Programming\n\nIn all the previous chapters we used objects extensively, but our style of programming has been strictly procedural. Python is a multiparadigm language—it allowsusto programin procedural,object-oriented,and function- al style,or in any mixture of styles,since it does not force us to program in any one particular way.\n\nIt is perfectly possible to write any program in procedural style, and for very smallprograms(upto,say,500lines),doing soisrarely a problem. Butfor most programs,and especially for medium-size and large programs,object-oriented programming offers many advantages.\n\nThis chapter covers all the fundamental concepts and techniques for doing object-orientedprogramminginPython. Theﬁrstsectionisespeciallyforthose who arelessexperiencedand for thosecoming froma proceduralprogramming background (such as C or Fortran). The section starts by looking at some of the problemsthat can arise with proceduralprogramming that object-oriented programming can solve. Then it brieﬂy describes Python’s approach to object- oriented programming and explains the relevant terminology. After that, the chapter’s two main sections begin.\n\nThe second section covers the creation of custom data types that hold sin- gle items (although the items themselves may have many attributes), and the third section covers the creation of custom collection data types that can hold any number of objects of any types. These sections cover most aspects of object-oriented programming in Python, although we defer some more ad- vanced material to Chapter 8.\n\n233\n\n||||",
      "content_length": 1662,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 243,
      "content": "234\n\nChapter 6. Object-Oriented Programming\n\nThe Object-Oriented Approach\n\nIn this section we will look at some of the problems of a purely procedural ap- proach by considering a situation where we need to represent circles, poten- tially lots of them. The minimum data required to represent a circle is its (x,y) position and its radius. One simple approach is to use a 3-tuple for each circle. For example:\n\ncircle = (11, 60, 8)\n\nOne drawback of this approach is that it isn’t obvious what each element of the tuple represents. We could mean (x, y, radius) or, just as easily, (ra- dius, x, y). Another drawback is that we can access the elements by index position only. If we have two functions, distance_from_origin(x, y) and edge_distance_from_origin(x, y, radius),we would need to use tuple unpacking to call them with a circle tuple:\n\ndistance = distance_from_origin(*circle[:2]) distance = edge_distance_from_origin(*circle)\n\nBoth of these assume that the circle tuples are of the form (x, y, radius). We can solve the problem of knowing the element order and of using tuple unpacking by using a named tuple:\n\nimport collections Circle = collections.namedtuple(\"Circle\", \"x y radius\") circle = Circle(13, 84, 9) distance = distance_from_origin(circle.x, circle.y)\n\nThis allows us to create Circle 3-tuples with named attributes which makes function calls much easier to understand, since to access elements we can use their names. Unfortunately, problems remain. For example, there is nothing to stop an invalid circle from being created:\n\ncircle = Circle(33, 56, -5)\n\nIt doesn’t make sense to have a circle with a negative radius, but the circle named tuple is created here without raising an exception—just as it would be if the radius was given as a variable that held a negative number. The error will be noticed only if we call the edge_distance_from_origin() function—and then only if that function actually checks for a negative radius. This inability to validate when creating an object is probably the worst aspect of taking a purely procedural approach.\n\nIf we want circles to be mutable so that we can move them by changing their coordinates or resize them by changing their radius, we can do so by using the private collections.namedtuple._replace() method:\n\n|||",
      "content_length": 2282,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 244,
      "content": "The Object-Oriented Approach\n\ncircle = circle._replace(radius=12)\n\nJust as when we create a Circle, there is nothing to stop us from (or warn us about) setting invalid data.\n\nIf the circles were going to need lots of changes,we might opt to use a mutable data type such as a list, for the sake of convenience:\n\ncircle = [36, 77, 8]\n\nThis doesn’t give us any protection from putting in invalid data, and the best we can doabout accessing elementsby nameistocreatesomeconstantssothat we can write things like circle[RADIUS] = 5. But using a list brings additional problems—for example, we can legitimately call circle.sort()! Using a dictio- nary might be an alternative, for example, circle = dict(x=36, y=77, radius=8), but again there is no way to ensure a valid radius and no way to prevent inap- propriate methods from being called.\n\nObject-Oriented Concepts and Terminology\n\nWhat we need is some way to package up the data that is needed to represent a circle, and some way to restrict the methods that can be applied to the data so that only valid operationsare possible. Both of these thingscan be achieved by creating a custom Circle data type. We will see how to create a Circle data type in later in this section, but ﬁrst we need to cover some preliminaries and explainsometerminology. Don’tworry if theterminology isunfamiliarat ﬁrst; it will become much clearer once we reach the examples.\n\nWe use the terms class, type, and data type interchangeably. In Python we can create custom classes that are fully integrated and that can be used just like the built-in data types. We have already encountered many classes, for example, dict, int, and str. We use the term object, and occasionally the term instance, to refer to an instance of a particular class. For example, 5 is an int object and \"oblong\" is a str object.\n\nMost classesencapsulateboth data andthemethodsthatcanbeappliedtothat data. For example,the str classholdsa string of Unicodecharactersasitsdata and supportsmethodssuch as str.upper().Many classesalso support addition- al features;for example,we can concatenatetwostrings(or any twosequences) using the + operator and ﬁnd a sequence’s length using the built-in len() func- tion. Such features are provided by special methods—these are like normal methods except that their names always begin and end with two underscores, and are predeﬁned. For example, if we want to create a class that supports concatenation using the + operator and also the len() function,we can do so by implementing the __add__() and __len__() special methods in our class. Con- versely, we should never deﬁne any method with a name that begins and ends with two underscores unless it is one of the predeﬁned special methods and is\n\n235\n\n||",
      "content_length": 2742,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 245,
      "content": "236\n\nChapter 6. Object-Oriented Programming\n\nappropriateto our class. This will ensure that we never get conﬂictswith later versions of Python even if they introduce new predeﬁned special methods.\n\nObjects usually have attributes—methods are callable attributes, and other attributes are data. For example, a complex object has imag and real attributes and lots of methods, including special methods like __add__() and __sub__ (to support the binary + and - operators), and normal methods like conjugate(). Data attributes (often referred to simply as “attributes”) are normally imple- mented as instance variables, that is, variables that are unique to a particular object. We will see examples of this, and also examples of how to provide data attributesasproperties.A propertyisanitemof objectdatathatisaccessedlike aninstancevariablebutwheretheaccessesarehandledby methodsbehindthe scenes. As we will see, using properties makes it easy to do data validation.\n\nInside a method (which is just a function whose ﬁrst argument is the instance onwhichitiscalledtooperate),severalkindsof variablesarepotentiallyacces- sible. The object’s instance variables can be accessed by qualifying their name withtheinstanceitself. Localvariablescanbecreatedinsidethemethod;these are accessed without qualiﬁcation. Class variables (sometimes called static variables) can be accessed by qualifying their name with the class name, and global variables, that is, module variables, are accessed without qualiﬁcation.\n\nSomeof thePythonliteratureusestheconceptof a namespace,a mapping from names to objects. Modules are namespaces—for example, after the statement import math we can access objects in the math module by qualifying them with their namespace name (e.g., math.pi and math.sin()). Similarly, classes and ob- jects are also namespaces; for example, if we have z = complex(1, 2), the z ob- ject’s namespace has two attributes which we can access (z.real and z.imag).\n\nOne of the advantages of object orientation is that if we have a class, we can specialize it. This means that we make a new class that inherits all the at- tributes (data and methods) from the original class,usually so that we can add or replace methods or add more instance variables. We can subclass (another term for specialize), any Python class, whether built-in or from the standard library, or one of our own custom classes.★ The ability to subclass is one of the great advantages offered by object-oriented programming since it makes it straightforward to use an existing class that has tried and tested functional- ity as the basis for a new class that extends the original, adding new data at- tributes or new functionality in a very clean and direct way. Furthermore, we can pass objects of our new class to functions and methods that were written for the original class and they will work correctly.\n\nWe use the term base class to refer to a class that is inherited; a base class may be the immediate ancestor, or may be further up the inheritance tree. Another term for base class is super class. We use the term subclass, derived\n\n★Some library classes that are implemented in C cannot be subclassed;such classes specify this in their documentation.",
      "content_length": 3223,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 247,
      "content": "238\n\nChapter 6. Object-Oriented Programming\n\nSome object-oriented languages have two features that Python does not pro- vide. The ﬁrst is overloading,that is,having methods with the same name but with different parameter lists in the same class. Thanks to Python’s versatile argument-handling capabilities this is never a limitation in practice. The sec- ond is access control—there are no bulletproof mechanisms for enforcing data privacy. However, if we create attributes (instance variables or methods) that begin with two leading underscores,Python will prevent unintentional access- essothatthey canbeconsideredtobeprivate. (Thisisdoneby namemangling; we will see an example in Chapter 8.)\n\nJust aswe use an uppercaseletter asthe ﬁrst letter of custom modules,we will do the same thing for customclasses. We can deﬁne asmany classesaswe like, either directly in a program or in modules—class names don’t have to match module names, and modules may contain as many class deﬁnitions as we like.\n\nNow that we have seen some of the problemsthat classescan solve,introduced the necessary terminology, and covered some background matters, we can begin to create some custom classes.\n\nCustom Classes\n\nIn earlier chapterswecreatedcustomclasses:customexceptions. Herearetwo new syntaxes for creating custom classes:\n\nclass className:\n\nsuite\n\nclass className(base_classes):\n\nsuite\n\nSince the exception subclasses we created did not add any new attributes (no instance data or methods) we used a suite of pass (i.e., nothing added), and since the suite was just one statement we put it on the same line as the class statement itself. Note that just like def statements, class is a statement, so we can create classes dynamically if we want to. A class’smethodsare created using def statementsin the class’ssuite. Classinstancesare created by calling the class with any necessary arguments;for example, x = complex(4, 8) creates a complex number and sets x to be an object reference to it.\n\nAttributes and Methods\n\nLet’s start with a very simple class, Point, that holds an (x, y) coordinate. The classisin ﬁle Shape.py,and itscompleteimplementation (excluding docstrings) is show here:\n\nclass Point:\n\n|||\n\n||",
      "content_length": 2202,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 248,
      "content": "Custom Classes\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\ndef distance_from_origin(self):\n\nreturn math.hypot(self.x, self.y)\n\ndef __eq__(self, other):\n\nreturn self.x == other.x and self.y == other.y\n\ndef __repr__(self):\n\nreturn \"Point({0.x!r}, {0.y!r})\".format(self)\n\ndef __str__(self):\n\nreturn \"({0.x!r}, {0.y!r})\".format(self)\n\nSince no base classes are speciﬁed, Point is a direct subclass of object, just as though we had written class Point(object). Before we discuss each of the methods, let’s see some examples of their use:\n\nimport Shape a = Shape.Point() repr(a) b = Shape.Point(3, 4) str(b) b.distance_from_origin() b.x = -19 str(b) a == b, a != b\n\n# returns: 'Point(0, 0)'\n\n# returns: '(3, 4)' # returns: 5.0\n\n# returns: '(-19, 4)' # returns: (False, True)\n\nThe Point class has two data attributes, self.x and self.y, and ﬁve methods (not counting inherited methods), four of which are special methods; they are illustrated in Figure 6.2. Once the Shape module is imported, the Point class can be used like any other. The data attributes can be accessed directly (e.g., y = a.y), and the class integrates nicely with all of Python’s other classes by providing support for the equality operator (==) and for producing strings in representational and string forms. And Python is smart enough to supply the inequality operator (!=) based on the equality operator. (It is also possible to specify each operator individually if we want total control,for example,if they are not exact opposites of each other.)\n\nPython automatically supplies the ﬁrst argument in method calls—it is an object reference to the object itself (called this in C++ and Java). We must in- clude this argument in the parameter list, and by convention the parameter is called self.All object attributes(data and methodattributes)must bequaliﬁed by self. This requires a little bit more typing compared with some other lan- guages, but has the advantage of providing absolute clarity: we always know that we are accessing an object attribute if we qualify with self.\n\n239",
      "content_length": 2062,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 249,
      "content": "240\n\nChapter 6. Object-Oriented Programming\n\nobject\n\n__new__() __init__() __eq__() __repr__() __str__() ...\n\nKey inherited implemented reimplemented\n\nPoint x y\n\n__new__() __init__() distance_from_origin() __eq__() __repr__() __str__() ...\n\nFigure 6.2 The Point class’s inheritancehierarchy\n\nTo create an object,two steps are necessary. First a raw or uninitialized object must be created, and then the object must be initialized, ready for use. Some object-oriented languages (such as C++ and Java) combine these two steps into one, but Python keeps them separate. When an object is created (e.g., p = Shape.Point()), ﬁrst the special method __new__() is called to create the object, and then the special method __init__() is called to initialize it.\n\nIn practice almost every Python class we create will require us to reimple- method is al- ment only the __init__() method, since the object.__new__() most always sufﬁcient and is automatically called if we don’t provide our own __new__() method. (Later in this chapter we will show a rare example where we do need to reimplement __new__().) Not having to reimplement methods in a subclass is another beneﬁt of object-oriented programming—if the base class method is sufﬁcient we don’t have to reimplement it in our subclass. This works because if we call a method on an object and the object’s class does not have an implementation of that method, Python will automatically go through the object’s base classes, and their base classes, and so on, until it ﬁnds the method—and if the method is not found an AttributeError exception is raised.\n\nFor example, if we execute p = Shape.Point(), Python begins by looking for the method Point.__new__(). Since we have not reimplemented this method, Python looks for the method in Point’s base classes. In this case there is only one base class, object, and this has the required method, so Python calls ob- ject.__new__() and creates a raw uninitialized object. Then Python looks for the initializer, __init__(), and since we have reimplemented it, Python doesn’t need to look further and calls Point.__init__(). Finally, Python sets p to be an object reference to the newly created and initialized object of type Point.\n\nBecause they are so short and a few pages away, for convenience we will show each method again before discussing it.\n\nAlter- native Fuzzy- Bool ➤ 256",
      "content_length": 2365,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 250,
      "content": "Custom Classes\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\nThe two instance variables, self.x and self.y, are created in the initializer, and assigned the values of the x and y parameters. Since Python will ﬁnd this initializer when we create a new Point object, the object.__init__() method will not be called. This is because as soon as Python has found the required method it calls it and doesn’t look further.\n\nObject-oriented purists might start the method off with a call to the base class __init__() method by calling super().__init__(). The effect of calling the super() function like this is to call the base class’s __init__() method. For classes that directly inherit object there is no need to do this, and in this book we call base class methods only when necessary—for example, when creating classes that are designed to be subclassed, or when creating classes that don’t directly inherit object. This is to some extent a matter of coding style—it is perfectly reasonable to always call super().__init__() at the start of a custom class’s __init__() method.\n\ndef distance_from_origin(self):\n\nreturn math.hypot(self.x, self.y)\n\nThis is a conventional method that performs a computation based on the object’s instance variables. It is quite common for methods to be fairly short and to have only the object they are called on as an argument, since often all the data the method needs is available inside the object.\n\ndef __eq__(self, other):\n\nreturn self.x == other.x and self.y == other.y\n\nMethods should not have names that begin and end with two under- scores—unless they are one of the predeﬁned special methods. Python pro- vides special methods for all the comparison operators as shown in Table 6.1.\n\nAll instances of custom classes support == by default, and the comparison returns False—unless we compare a custom object with itself. We can override this behavior by reimplementing the __eq__() special method as we have done here. Python will supply the __ne__() (not equal) inequality operator (!=) automatically if we implement __eq__() but don’t implement __ne__().\n\nBy default,all instancesof custom classesare hashable,so hash() can be called on them and they can be used as dictionary keys and stored in sets. But if we reimplement __eq__(),instancesare no longer hashable. We will see how to ﬁx this when we discuss the FuzzyBool class later on.\n\nBy implementing this special method we can compare Point objects, but if we were to try to compare a Point with an object of a different type—say, int—we\n\n241\n\nFuzzy- Bool ➤ 254",
      "content_length": 2564,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 251,
      "content": "str. format() 78➤\n\n242\n\nChapter 6. Object-Oriented Programming\n\nTable 6.1 Comparison Special Methods\n\nSpecial Method\n\nUsage Description\n\n__lt__(self, other)\n\nx < y Returns True if x is less than y\n\n__le__(self, other)\n\nx <= y Returns True if x is less than or equal to y\n\n__eq__(self, other)\n\nx == y Returns True if x is equal to y\n\n__ne__(self, other)\n\nx != y Returns True if x is not equal to y\n\n__ge__(self, other)\n\nx >= y Returns True if x is greater than or equal to y\n\n__gt__(self, other)\n\nx > y Returns True if x is greater than y\n\nwould get an AttributeError exception (since ints don’t have an x attribute). On the other hand, we can compare Point objects with other objects that coincidentally just happen to have an x attribute (thanks to Python’s duck typing), but this may lead to surprising results.\n\nIf we want to avoid inappropriate comparisons there are a few approaches we can take. One is to use an assertion, for example, assert isinstance(other, Point).Another isto raisea TypeError to indicatethat comparisonsbetween the twotypesarenot supported,for example,if not isinstance(other, Point): raise TypeError().The third way (which is also the most Pythonically correct)is to do this: if not isinstance(other, Point): return NotImplemented. In this third case, if NotImplemented isreturned,Python will then try calling other.__eq__(self) to see whether the other type supportsthe comparison with the Point type,and if there is no such method or if that method also returns NotImplemented, Python willgiveupandraisea TypeErrorexception. (Notethatonly reimplementations of the comparisonspecial methodslisted in Table 6.1may return NotImplement- ed.)\n\nThe built-in isinstance() function takes an object and a class (or a tuple of classes),andreturnsTrue if theobjectisof thegivenclass(or of oneof thetuple of classes), or of one of the class’s (or one of the tuple of classes’) base classes.\n\ndef __repr__(self):\n\nreturn \"Point({0.x!r}, {0.y!r})\".format(self)\n\nThe built-in repr() function calls the __repr__() special method for the object it is given and returns the result. The string returned is one of two kinds. One kind is where the string returned can be evaluated using the built-in eval() function to produce an object equivalent to the one repr() was called on. The other kind is used where this is not possible; we will see an example later on. Here is how we can go from a Point object to a string and back to a Point object:",
      "content_length": 2456,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 252,
      "content": "import 195➤\n\nCustom Classes\n\np = Shape.Point(3, 9) repr(p) q = eval(p.__module__ + \".\" + repr(p)) repr(q)\n\n# returns: 'Point(3, 9)'\n\n# returns: 'Point(3, 9)'\n\nWe must give the module name when eval()-ing if we used import Shape. (This import differently,for example,from would not be necessary if we had done the Shape import Point.) Python provides every object with a few private attributes, one of which is __module__, a string that holds the object’s module name, which in this example is \"Shape\".\n\nq, both with the At the end of this snippet we have two Point objects, p and same attribute values, so they compare as equal. The eval() function returns the result of executing the string it is given—which must contain a valid Python statement.\n\ndef __str__(self):\n\nreturn \"({0.x!r}, {0.y!r})\".format(self)\n\nThe built-in str() function works like the repr() function, except that it calls the object’s __str__() special method. The result is intended to be understand- able to human readers and is not expected to be suitable for passing to the eval() function. Continuing the previous example, str(p) (or str(q)) would re- turn the string '(3, 9)'.\n\nWe have now covered the simple Point class—and also covered a lot of behind- the-scenes details that are important to know but which can mostly be left in thebackground. The Point classholdsan (x,y)coordinate—a fundamentalpart of what we need to represent a circle, as we discussed at the beginning of the chapter. In the next subsection we will see how to create a custom Circle class, inheriting from Point so that we don’t have to duplicate the code for the x and y attributes or for the distance_from_origin() method.\n\nInheritance and Polymorphism\n\nThe Circle class builds on the Point class using inheritance. The Circle class adds one additional data attribute (radius), and three new methods. It also reimplements a few of Point’s methods. Here is the complete class deﬁnition:\n\nclass Circle(Point):\n\ndef __init__(self, radius, x=0, y=0):\n\nsuper().__init__(x, y) self.radius = radius\n\ndef edge_distance_from_origin(self):\n\nreturn abs(self.distance_from_origin() - self.radius)\n\n243\n\n||\n\nDynam- ic code execu- tion ➤ 344",
      "content_length": 2181,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 254,
      "content": "Shallow and deep copying 146➤\n\nCustom Classes\n\nof its computation. Since the Circle class does not provide an implementa- tion of the distance_from_origin() method, the one provided by the Point base class will be found and used. Contrast this with the reimplementation of the __eq__() method. This method compares this circle’s radius with the other cir- cle’sradius,andif they areequalit thenexplicitly callsthebaseclass’s__eq__() method using super(). If we did not use super() we would have inﬁnite recur- sion, since Circle.__eq__() would then just keep calling itself. Notice also that we don’t have to pass the self argument in the super() calls since Python au- tomatically passes it for us.\n\nHere are a couple of usage examples:\n\np = Shape.Point(28, 45) c = Shape.Circle(5, 28, 45) p.distance_from_origin() c.distance_from_origin()\n\n# returns: 53.0 # returns: 53.0\n\nWe can call the distance_from_origin() method on a Point or on a Circle, since Circles can stand in for Points.\n\nPolymorphism means that any object of a given class can be used as though it were an object of any of its class’s base classes. This is why when we create a subclass we need to implement only the additional methods we require and have to reimplement only those existing methods we want to replace. And when reimplementing methods, we can use the base class’s implementation if necessary by using super() inside the reimplementation.\n\nIn the Circle’s case we have implemented additional methods, such as area() and circumference(), and reimplemented methods we needed to change. The reimplementations of __repr__() and __str__() are necessary because without them the base class methods will be used and the strings returned will be of Points instead of Circles. The reimplementations of __init__() and __eq__() are necessary because we must account for the fact that Circles have an addi- tional attribute, and in both cases we make use of the base class implementa- tions of the methods to minimize the work we must do.\n\nThe Point and Circle classes are as complete as we need them to be. We could provide additional methods, such as other comparison special methods if we wanted to be able to order Points or Circles. Another thing that we might want to do for which no method is provided is to copy a Point or Circle. Most Python classes don’t provide a copy() method (exceptions being dict.copy() and set.copy()). If we want to copy a Point or Circle we can easily do so by importing the copy module and using the copy.copy() function. (There is no need to use copy.deepcopy() for Point and Circle objects since they contain only immutable instance variables.)\n\n245",
      "content_length": 2657,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 255,
      "content": "246\n\nChapter 6. Object-Oriented Programming\n\nUsing Properties to Control Attribute Access\n\nIn the previous subsection the Point class included a distance_from_origin() method, and the Circle class had the area(), circumference(), and edge_dis- tance_from_origin() methods. All these methodsreturn a single float value,so from the point of view of a user of these classes they could just as well be data attributes, but read-only, of course. In the ShapeAlt.py ﬁle alternative imple- mentations of Point and Circle are provided, and all the methods mentioned here are provided as properties. This allows us to write code like this:\n\ncircle = Shape.Circle(5, 28, 45) # assumes: import ShapeAlt as Shape circle.radius circle.edge_distance_from_origin # returns: 48.0\n\n# returns: 5\n\nHere are the implementations of the getter methods for the ShapeAlt.Circle class’s area and edge_ distance_from_origin properties:\n\n@property def area(self):\n\nreturn math.pi * (self.radius ** 2)\n\n@property def edge_distance_from_origin(self):\n\nreturn abs(self.distance_from_origin - self.radius)\n\nIf we provide only getters as we have done here, the properties are read-only. The code for the area property is the same as for the previous area() method. The edge_distance_from_origin’scode isslightly different from beforebecauseit now accesses the base class’s distance_from_origin property instead of calling a distance_from_origin() method. The most notable difference to both is the property decorator. A decorator is a function that takes a function or method as its argument and returns a “decorated” version, that is, a version of the function or method that is modiﬁed in some way. A decorator is indicated by preceding its name with an at symbol (@). For now, just treat decorators as syntax—in Chapter 8 we will see how to create custom decorators.\n\nThe property() decorator function is built-in and takes up to four arguments:a getter function, a setter function, a deleter function, and a docstring. The effect of using @property isthesame ascalling the property() function with just one argument, the getter function. We could have created the area property like this:\n\ndef area(self):\n\nreturn math.pi * (self.radius ** 2)\n\narea = property(area)\n\nWe rarely use this syntax, since using a decorator is shorter and clearer.\n\n||",
      "content_length": 2317,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 256,
      "content": "Custom Classes\n\nIn the previous subsection we noted that no validation is performed on the Circle’s radius attribute. We can provide validation by making radius into a property. This does not require any changes to the Circle.__init__() method, and any code that accesses the Circle.radius attribute will continue to work unchanged—only now the radius will be validated whenever it is set.\n\nPython programmers normally use properties rather than the explicit getters and setters (e.g., getRadius() and setRadius()) that are so commonly used in other object-oriented languages. This is because it is so easy to change a data attribute into a property without affecting the use of the class.\n\nToturnan attributeintoa readable/writableproperty wemust createa private attributewherethedata isactually held and supply getter and setter methods. Here is the radius’s getter, setter, and docstring in full:\n\n@property def radius(self):\n\n\"\"\"The circle's radius\n\n>>> circle = Circle(-2) Traceback (most recent call last): ... AssertionError: radius must be nonzero and non-negative >>> circle = Circle(4) >>> circle.radius = -1 Traceback (most recent call last): ... AssertionError: radius must be nonzero and non-negative >>> circle.radius = 6 \"\"\" return self.__radius\n\n@radius.setter def radius(self, radius):\n\nassert radius > 0, \"radius must be nonzero and non-negative\" self.__radius = radius\n\nWe use an assert to ensure a nonzero and non-negative radius and store the radius’svalue in the private attribute self.__radius.Notice that the getter and setter (and deleter if we needed one) all have the same name—it is the decora- tors that distinguish them, and the decorators rename them appropriately so that no name conﬂicts occur.\n\nThe decorator for the setter may look strange at ﬁrst sight. Every property that is created has a getter, setter, and deleter attribute, so once the radius property is created using @property, the radius.getter, radius.setter, and radius.deleter attributes become available. The radius.getter is set to the\n\n247",
      "content_length": 2040,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 257,
      "content": "248\n\nChapter 6. Object-Oriented Programming\n\ngetter method by the @property decorator. The other two are set up by Python so that they donothing (sotheattributecannot bewrittento or deleted),unless they are used as decorators, in which case they in effect replace themselves with the method they are used to decorate.\n\nThe Circle’sinitializer,Circle.__init__(),includesthe statement self.radius = radius; this will call the radius property’s setter, so if an invalid radius is given when a Circle is created an AssertionError exception will be raised. Similarly, if an attempt is made to set an existing Circle’s radius to an invalid value, again the setter will be called and an exception raised. The docstring includes doctests to test that the exception is correctly raised in these cases. (Testing is covered more fully in Chapter 9.)\n\nBoth the Point and Circle types are custom data types that have sufﬁcient functionality to be useful. Most of the data types that we are likely to create are like this, but occasionally it is necessary to create a custom data type that is complete in every respect. We will see examples of this in the next sub- section.\n\nCreating Complete Fully Integrated Data Types\n\nWhen creating a complete data type two possibilities are open to us. One is to create the data type from scratch. Although the data type will inherit object (as all Python classes do), every data attribute and method that the data type requires (apart from __new__()) must be provided. The other possibility is to inherit from an existing data type that is similar to the one we want to create. In this case the work usually involves reimplementing those methodswe want to behave differently and “unimplementing” those methods we don’t want at all.\n\nIn the following subsubsection we will implement a FuzzyBool data type from scratch, and in the subsubsection after that we will implement the same type but will use inheritance to reduce the work we must do. The built-in bool type is two-valued (True and False), but in some areas of AI (Artiﬁcial Intelligence), fuzzy Booleansareused,which havevaluescorresponding to“true”and“false”, and also to intermediates between them. In our implementations we will use ﬂoating-point values with 0.0 denoting False and 1.0 denoting True. In this system, 0.5 means 50 percent true, and 0.25 means 25 percent true, and so on. Here are some usage examples (they work the same with either implemen- tation):\n\na = FuzzyBool.FuzzyBool(.875) b = FuzzyBool.FuzzyBool(.25) a >= b bool(a), bool(b) ~a\n\n# returns: True # returns: (True, False) # returns: FuzzyBool(0.125)\n\n||",
      "content_length": 2614,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 258,
      "content": "Shape- Alt. Circle. radius proper- ty 247➤\n\nCustom Classes\n\na & b b |= FuzzyBool.FuzzyBool(.5) \"a={0:.1%} b={1:.0%}\".format(a, b)\n\n# returns: FuzzyBool(0.25) # b is now: FuzzyBool(0.5) # returns: 'a=87.5% b=50%'\n\nWe want the FuzzyBool type to support the complete set of comparison oper- ators (<, <=, ==, !=, >=, >), and the three basic logical operations, not (~), and (&), and or (|). In addition to the logical operations we want to provide a couple of other logical methods, conjunction() and disjunction(), that take as many FuzzyBools as we like and return the appropriate resultant FuzzyBool. And to complete the data type we want to provide conversionsto types bool, int, float, andstr,andhaveaneval()-ablerepresentationalform. Theﬁnalrequirements are that FuzzyBool supports str.format() format speciﬁcations, that FuzzyBools can be used as dictionary keys or as members of sets, and that FuzzyBools are immutable—but with the provision of augmented assignment operators (&= and |=) to ensure that they are convenient to use.\n\nTable 6.1 (242 ➤) lists the comparison special methods, Table 6.2 (➤ 250) lists the fundamental special methods, and Table 6.3 (➤ 253) lists the numeric spe- cial methods—these include the bitwise operators(~, &,and |) which FuzzyBools use for their logical operators, and also arithmetic operators such as + and - which FuzzyBool does not implement because they are inappropriate.\n\nCreating Data Types from Scratch\n\nTo create the FuzzyBool type from scratch means that we must provide an attribute to hold the FuzzyBool’s value and all the methods that we require. Here are the class line and the initializer, taken from FuzzyBool.py:\n\nclass FuzzyBool:\n\ndef __init__(self, value=0.0):\n\nself.__value = value if 0.0 <= value <= 1.0 else 0.0\n\nWe have madethevalue attributeprivatebecausewe want FuzzyBool to behave like immutables,soallowing accessto theattributewould be wrong. Also,if an out-of-range value is given we force it to take a fail-safe value of 0.0 (false). In theprevioussubsection’sShapeAlt.Circle classwe used a stricterpolicy,raising an exception if an invalid radius value was used when creating a new Circle object. The FuzzyBool’s inheritance tree is shown in Figure 6.4.\n\nThe simplest logical operator is logical NOT, for which we have coopted the bitwise inversion operator (~):\n\ndef __invert__(self):\n\nreturn FuzzyBool(1.0 - self.__value)\n\n249\n\n|",
      "content_length": 2405,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 260,
      "content": "Custom Classes\n\nobject\n\nFuzzyBool\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() ...\n\nKey inherited implemented reimplemented\n\n__value\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() __bool__() __float__() __invert__() __and__() __iand__() conjunction() # static ...\n\nFigure 6.4 The FuzzyBool class’s inheritancehierarchy\n\ndef __iand__(self, other):\n\nself.__value = min(self.__value, other.__value) return self\n\nThe bitwise AND operator returns a new FuzzyBool based on this one and the other one, whereas the augmented assignment (in-place) version updates the private value. Strictly speaking, this is not immutable behavior, but it does match the behavior of some other Python immutables, such as int, where, for example, using += looks like the left-hand operand is being changed but in fact it is re-bound to refer to a new int object that holds the result of the addition. In this case no rebinding is needed because we really do change the FuzzyBool itself. And we return self to support the chaining of operations.\n\nWe could also implement __rand__().Thismethod iscalled when self and other are of different types and the __and__() method is not implemented for that particular pair of types. This isn’t needed for the FuzzyBool class. Most of the special methods for binary operators have both “i” (in-place) and “r” (reﬂect, that is, swap operands) versions.\n\nWehavenot shown theimplementationfor __or__() which providesthebitwise | operator, or for __ior__() which provides the in-place |= operator, since both are the same as the equivalent AND methodsexcept that we take the maximum value instead of the minimum value of self and other.\n\ndef __repr__(self):\n\nreturn (\"{0}({1})\".format(self.__class__.__name__,\n\nself.__value))\n\n251",
      "content_length": 1800,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 261,
      "content": "252\n\nChapter 6. Object-Oriented Programming\n\nWe have created an eval()-able representational form. For example, given f = FuzzyBool.FuzzyBool(.75); repr(f) will produce the string 'FuzzyBool(0.75)'.\n\nAll objects have some special attributes automatically supplied by Python, one of which is called __class__, a reference to the object’s class. All classes have a private __name__ attribute,again provided automatically. We have used these attributes to provide the class name used for the representation form. This means that if the FuzzyBool class is subclassed just to add extra methods, the inherited __repr__() method will work correctly without needing to be reimplemented, since it will pick up the subclass’s class name.\n\ndef __str__(self):\n\nreturn str(self.__value)\n\nFor the string form we just return the ﬂoating-point value formatted as a string. We don’t have to use super() to avoid inﬁnite recursion because we call str() on the self.__value attribute, not on the instance itself.\n\ndef __bool__(self):\n\nreturn self.__value > 0.5\n\ndef __int__(self):\n\nreturn round(self.__value)\n\ndef __float__(self):\n\nreturn self.__value\n\nThe __bool__() specialmethod convertstheinstanceto a Boolean,so it must al- waysreturn either True or False.The __int__() specialmethod providesinteger conversion. We have used the built-in round() function because int() simply truncates(so would return 0 for any FuzzyBool value except 1.0).Floating-point conversion is easy because the value is already a ﬂoating-point number.\n\ndef __lt__(self, other):\n\nreturn self.__value < other.__value\n\ndef __eq__(self, other):\n\nreturn self.__value == other.__value\n\nTo provide the complete set of comparisons (<, <=, ==, !=, >=, >) it is necessary to implement at least three of them, <, <=, and ==, since Python can infer > from <, != from ==, and >= from <=. We have shown only two representative methods here since all of them are very similar.★\n\ndef __hash__(self):\n\nreturn hash(id(self))\n\n★ In fact, we implemented only the __lt__() and __eq__() methods quoted here—the other comparison methods were automatically generated; we will see how in Chapter 8.\n\nCom- plete compar- isons ➤ 379",
      "content_length": 2166,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 262,
      "content": "Custom Classes\n\nTable 6.3 Numeric and Bitwise Special Methods\n\nSpecial Method\n\nUsage\n\nSpecial Method\n\n__abs__(self)\n\nabs(x)\n\n__complex__(self)\n\n__float__(self)\n\nfloat(x)\n\n__int__(self)\n\n__index__(self)\n\nbin(x) oct(x) hex(x)\n\n__round__(self,\n\ndigits)\n\n__pos__(self)\n\n+x\n\n__neg__(self)\n\n__add__(self, other)\n\nx + y\n\n__sub__(self, other)\n\n__iadd__(self, other)\n\nx += y\n\n__isub__(self, other)\n\n__radd__(self, other)\n\ny + x\n\n__rsub__(self, other)\n\n__mul__(self, other)\n\nx * y\n\n__mod__(self, other)\n\n__imul__(self, other)\n\nx *= y\n\n__imod__(self, other)\n\n__rmul__(self, other)\n\ny * x\n\n__rmod__(self, other)\n\n__floordiv__(self,\n\nx // y\n\n__truediv__(self,\n\nother)\n\nother)\n\n__ifloordiv__(self,\n\nx //= y\n\n__itruediv__(self,\n\nother)\n\nother)\n\n__rfloordiv__(self,\n\ny // x\n\n__rtruediv__(self,\n\nother)\n\nother)\n\n__divmod__(self,\n\ndivmod(x, y)\n\n__rdivmod__(self,\n\nother)\n\nother)\n\n__pow__(self, other)\n\nx ** y\n\n__and__(self, other)\n\n__ipow__(self, other)\n\nx **= y\n\n__iand__(self, other)\n\n__rpow__(self, other)\n\ny ** x\n\n__rand__(self, other)\n\n__xor__(self, other)\n\nx ^ y\n\n__or__(self, other)\n\n__ixor__(self, other)\n\nx ^= y\n\n__ior__(self, other)\n\n__rxor__(self, other)\n\ny ^ x\n\n__ror__(self, other)\n\n__lshift__(self,\n\nx << y\n\n__rshift__(self,\n\nother)\n\nother)\n\n__ilshift__(self,\n\nx <<= y\n\n__irshift__(self,\n\nother)\n\nother)\n\n__rlshift__(self,\n\ny << x\n\n__rrshift__(self,\n\nother)\n\nother)\n\n__invert__(self)\n\n253\n\nUsage\n\ncomplex(x)\n\nint(x)\n\nround(x,\n\ndigits)\n\nx\n\nx - y\n\nx -= y\n\ny - x\n\nx % y\n\nx %= y\n\ny % x\n\nx / y\n\nx /= y\n\ny / x\n\ndivmod(y, x)\n\nx & y\n\nx &= y\n\ny & x\n\nx | y\n\nx |= y\n\ny | x\n\nx >> y\n\nx >>= y\n\ny >> x\n\n~x",
      "content_length": 1586,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 263,
      "content": "Fuzzy- Bool usage exam- ples 248➤\n\n254\n\nChapter 6. Object-Oriented Programming\n\nBy default, instances of custom classes support operator == (which always re- turns False), and are hashable (so can be dictionary keys and can be added to sets). But if we reimplement the __eq__() special method to provide proper equality testing,instancesare no longer hashable. Thiscan be ﬁxed by provid- ing a __hash__() special method as we have done here.\n\nPython provides hash functions for strings, numbers, frozen sets, and other classes. Here we have simply used the built-in hash() function (which can operate on any type which has a __hash__() special method), and given it the object’s unique ID from which to calculate the hash. (We can’t use the private self.__value since that can change as a result of augmented assignment, whereas an object’s hash value must never change.)\n\nThe built-in id() function returns a unique integer for the object it is given as its argument. This integer is usually the object’s address in memory, but all that we can assume is that no two objects have the same ID. Behind the scenes the is operator uses the id() function to determine whether two object references refer to the same object.\n\ndef __format__(self, format_spec):\n\nreturn format(self.__value, format_spec)\n\nThebuilt-in format() functionisonly really neededin classdeﬁnitions. It takes a single object and an optional format speciﬁcation and returns a string with the object suitably formatted.\n\nWhen an object is used in a format string the object’s __format__() method is called with the object and the format speciﬁcation as arguments. The method returns the instance suitably formatted as we saw earlier.\n\nAll the built-in classes already have suitable __format__() methods; here we make use of the float.__format__() method by passing the ﬂoating-point value and the format string we have been given. We could have achieved exactly the same thing like this:\n\ndef __format__(self, format_spec):\n\nreturn self.__value.__format__(format_spec)\n\nUsing the format() functionrequiresa tiny bitlesstyping andisclearertoread. Nothing forcesusto use the format() function at all,so we could invent our own format speciﬁcation language and interpret it inside the __format__() method, as long as we return a string.\n\n@staticmethod def conjunction(*fuzzies):\n\nreturn FuzzyBool(min([float(x) for x in fuzzies]))",
      "content_length": 2392,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 264,
      "content": "Custom Classes\n\nThe built-in staticmethod() function is designed to be used as a decorator as we have done here. Static methodsare simply methodsthat do not get self or any other ﬁrst argument specially passed by Python.\n\nThe & operator can be chained, so given FuzzyBool’s f, g, and h, we can get the conjunction of all of them by writing f & g & h. This works ﬁne for small num- bers of FuzzyBools, but if we have a dozen or more it starts to become rather inefﬁcient since each & represents a function call. With the method given here we can achieve the same thing using a single function call of Fuzzy- Bool.FuzzyBool.conjunction(f, g, h). This can be written more concisely us- ing a FuzzyBool instance, but since static methods don’t get self, if we call one using an instance and we want to process that instance we must pass it ourselves—for example, f.conjunction(f, g, h).\n\nWe have not shown the corresponding disjunction() method since it differs only in its name and that it uses max() rather than min().\n\nSomePythonprogrammersconsider theuseof staticmethodstobeun-Python- ic, and use them only if they are converting code from another language (such as C++ or Java), or if they have a method that does not use self. In Python, ratherthanusing staticmethodsitisusually bettertocreateamodulefunction instead, as we will see in the next subsubsection, or a class method, as we will see in the last section.\n\nIn a similar vein, creating a variable inside a class deﬁnition but outside any method creates a static (class) variable. For constants it is usually more convenient to use private module globals, but class variables can often be useful for sharing data among all of a class’s instances.\n\nWe have now completed the implementation of the FuzzyBool class “from scratch”. We have had to reimplement 15 methods (17 if we had done the minimum of all four comparison operators), and have implemented two static methods. In the following subsubsection we will show an alternative imple- mentation, this time based on the inheritance of float. It involves the reim- plementations of just eight methods and the implementation of two module functions—and the “unimplementation” of 32 methods.\n\nIn most object-oriented languages inheritance is used to create new classes that have all the methods and attributes of the classes they inherit, as well as the additional methods and attributes that we want the new class to have. Python fully supportsthis,allowing us to add new methods,or to reimplement inherited methods so as to modify their behavior. But in addition, Python allows us to effectively unimplement methods, that is, to make the new class behave as though it does not have some of the methods that it inherits. Doing this might not appeal to object-oriented purists since it breaks polymorphism, but in Python at least, it can occasionally be a useful technique.\n\n255",
      "content_length": 2887,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 265,
      "content": "256\n\nChapter 6. Object-Oriented Programming\n\nCreating Data Types from Other Data Types\n\nThe FuzzyBool implementation in this subsubsection is in the ﬁle Fuzzy- BoolAlt.py.One immediate difference from the previous version is that instead of providing static methods for conjunction() and disjunction(), we have pro- vided them as module functions. For example:\n\ndef conjunction(*fuzzies):\n\nreturn FuzzyBool(min(fuzzies))\n\nThe code for this is much simpler than before because FuzzyBoolAlt.FuzzyBool objects are float subclasses, and so can be used directly in place of a float without needing any conversion. (The inheritancetree isshown in Figure6.5.) Accessing the function is also cleaner than before. Instead of having to specify both the module and the class (or using an instance), having done import FuzzyBoolAlt we can just write FuzzyBoolAlt.conjunction().\n\nobject\n\nfloat\n\nFuzzyBool\n\n__new__() __init__() __eq__() __repr__() __str__() ...\n\nKey inherited implemented reimplemented\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() ...\n\n__new__() __init__() __eq__() __repr__() __str__() __hash__() __format__() __bool__() __invert__() __and__() __iand__() ...\n\nFigure 6.5 The alternativeFuzzyBool class’s inheritancehierarchy\n\nHere is the FuzzyBool’s class line and its __new__() method:\n\nclass FuzzyBool(float):\n\ndef __new__(cls, value=0.0):\n\nreturn super().__new__(cls,\n\nvalue if 0.0 <= value <= 1.0 else 0.0)\n\nWhen wecreatea newclassit isusually mutableandrelieson object.__new__() to create the raw uninitialized object. But in the case of immutable classes we need to do the creation and initialization in one step since once an immutable object has been created it cannot be changed.\n\n|",
      "content_length": 1726,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 266,
      "content": "Custom Classes\n\nThe __new__() method is called before any object has been created (since object creation is what __new__() does), so it cannot have a self object passed to it since one doesn’t yet exist. In fact, __new__() is a class method—these are similar to normal methods except that they are called on the class rather than on an instance and Python supplies as their ﬁrst argument the class they are called on. The variable name cls for classis just a convention,in the same way that self is the conventional name for the object itself.\n\nSo when we write f = FuzzyBool(0.7), under the hood Python calls Fuzzy- Bool.__new__(FuzzyBool, 0.7) to create a new object—say, fuzzy—and then calls fuzzy.__init__() to do any further initialization, and ﬁnally returns an object reference to the fuzzy object—it is this object reference that f is set to. Most of __new__()’s work is passed on to the base class implementation, ob- ject.__new__(); all we do is make sure that the value is in range.\n\nClass methods are set up by using the built-in classmethod() function used as a decorator. But as a convenience we don’t have to bother writing @classmethod before def __new__() because Python already knows that this method is always a classmethod. Wedo need to usethedecorator if we want to createother class methods, though, as we will see in the chapter’s ﬁnal section.\n\nNow that we have seen a class method we can clarify the different kinds of methods that Python provides. Class methods have their ﬁrst argument added by Python and it is the method’s class; normal methods have their ﬁrst argument addedby Python and it istheinstancethemethodwascalled on;and static methodshave no ﬁrst argument added. And all the kindsof methodsget any arguments we pass to them (as their second and subsequent arguments in the case of class and normal methods, and as their ﬁrst and subsequent arguments for static methods).\n\ndef __invert__(self):\n\nreturn FuzzyBool(1.0 - float(self))\n\nThis method is used to provide support for the bitwise NOT operator (~) just the same as before. Notice that instead of accessing a private attribute that holds the FuzzyBool’s value we use self directly. This is thanks to inher- iting float which means that a FuzzyBool can be used wherever a float is expected—providing none of the FuzzyBool’s “unimplemented” methods are used, of course.\n\ndef __and__(self, other):\n\nreturn FuzzyBool(min(self, other))\n\ndef __iand__(self, other):\n\nreturn FuzzyBool(min(self, other))\n\nThe logic for these is also the same as before (although the code is subtly different),and just like the __invert__() method we can use both self and other\n\n257",
      "content_length": 2651,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 267,
      "content": "258\n\nChapter 6. Object-Oriented Programming\n\ndirectly as though they were floats. We have omitted the OR versions since they differ only in their names(__or__() and __ior__()) and that they use max() rather than min().\n\ndef __repr__(self):\n\nreturn (\"{0}({1})\".format(self.__class__.__name__,\n\nsuper().__repr__()))\n\nWe must reimplement the __repr__() method since the base class version float.__repr__() justreturnsthenumberasa string,whereasweneedtheclass name to make the representation eval()-able. For the str.format()’ssecond ar- gument we cannot just pass self since that will result in an inﬁnite recursion of calls to this __repr__() method, so instead we call the base class implemen- tation.\n\nWe don’t have to reimplement the __str__() method because the base class version, float.__str__(), is sufﬁcient and will be used in the absence of a FuzzyBool.__str__() reimplementation.\n\ndef __bool__(self):\n\nreturn self > 0.5\n\ndef __int__(self):\n\nreturn round(self)\n\nWhen a float is used in a Boolean context it is False if its value is 0.0 and True otherwise. This is not the appropriate behavior for FuzzyBools, so we have had toreimplementthismethod. Similarly,using int(self) would simply truncate, turning everything but 1.0into 0,so herewe use round() to produce0for values up to 0.5 and 1 for values up to and including the maximum of 1.0.\n\nWe have not reimplemented the __hash__() method, the __format__() method, or any of the methods that are used to provide the comparison operators,since all those provided by the float base class work correctly for FuzzyBools.\n\nThe methods we have reimplemented provide a complete implementation of the FuzzyBool class—and have required far less code than the implementation presented in the previous subsubsection. However, this new FuzzyBool class has inherited more than 30 methods which don’t make sense for FuzzyBools. For example,none of the basic numeric and bitwise shift operators(+, -, *, /, <<, >>, etc.) can sensibly be applied to FuzzyBools. Here is how we could begin to “unimplement” addition:\n\ndef __add__(self, other):\n\nraise NotImplementedError()\n\nWe would also have to write the same code for the __iadd__() and __radd__() methods to completely prevent addition. (Note that NotImplementedError is a standardexceptionand isdifferentfromthebuilt-in NotImplemented object.) An",
      "content_length": 2342,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 268,
      "content": "Custom Classes\n\nalternative to raising a NotImplementedError exception, especially if we want to more closely mimic the behavior of Python’s built-in classes, is to raise a TypeError. Here is how we can make FuzzyBool.__add__() behave just like built-in classes that are faced with an invalid operation:\n\ndef __add__(self, other):\n\nraise TypeError(\"unsupported operand type(s) for +: \"\n\n\"'{0}' and '{1}'\".format(\n\nself.__class__.__name__, other.__class__.__name__))\n\nFor unary operations, we want to unimplement in a way that mimics the behavior of built-in types, the code is slightly easier:\n\ndef __neg__(self):\n\nraise TypeError(\"bad operand type for unary -: '{0}'\".format(\n\nself.__class__.__name__))\n\nFor comparison operators, there is a much simpler idiom. For example, to unimplement ==, we would write:\n\ndef __eq__(self, other):\n\nreturn NotImplemented\n\nIf a method implementing a comparison operator (<, <=, ==, !=, >=, >), returns the built-in NotImplemented object and an attempt is made to use the method, Python will ﬁrst try the reverse comparison by swapping the operands (in case the other object has a suitable comparison method since the self object does not), and if that doesn’t work Python raises a TypeError exception with a message that explains that the operation is not supported for operands of the types used. But for all noncomparison methods that we don’t want, we must raise either a NotImplementedError or a TypeError exception as we did for the __add__() and __neg__() methods shown earlier.\n\nIt would be tedious to unimplement every method we don’t want as we have done here, although it does work and has the virtue of being easy to under- stand. Here we will look at a more advanced technique for unimplementing methods—it is used in the FuzzyBoolAlt module—but it is probably best to skip to the next section (➤ 261) and return here only if the need arises in practice.\n\nHere is the code for unimplementing the two unary operations we don’t want:\n\nfor name, operator in ((\"__neg__\", \"-\"),\n\n(\"__index__\", \"index()\")):\n\nmessage = (\"bad operand type for unary {0}: '{{self}}'\"\n\n.format(operator))\n\nexec(\"def {0}(self): raise TypeError(\\\"{1}\\\".format(\"\n\n\"self=self.__class__.__name__))\".format(name, message))\n\n259",
      "content_length": 2244,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 269,
      "content": "260\n\nChapter 6. Object-Oriented Programming\n\nThebuilt-in exec() functiondynamically executesthecodepassedto it fromthe object it is given. In this case we have given it a string,but it is also possible to passsomeother kindsof objects. By default,thecodeisexecutedin thecontext of the enclosing scope, in this case within the deﬁnition of the FuzzyBool class, so the def statements that are executed create FuzzyBool methods which is what we want. The code is executed just once, when the FuzzyBoolAlt module is imported. Here is the code that is generated for the ﬁrst tuple (\"__neg__\", \"-\"):\n\ndef __neg__(self):\n\nraise TypeError(\"bad operand type for unary -: '{self}'\"\n\n.format(self=self.__class__.__name__))\n\nWe have made the exception and error message match those that Python uses for its own types. The code for handling binary methods and n-ary functions (suchaspow())followsa similarpatternbutwitha differenterrormessage. For completeness, here is the code we have used:\n\nfor name, operator in ((\"__xor__\", \"^\"), (\"__ixor__\", \"^=\"),\n\n(\"__add__\", \"+\"), (\"__iadd__\", \"+=\"), (\"__radd__\", \"+\"), (\"__sub__\", \"-\"), (\"__isub__\", \"-=\"), (\"__rsub__\", \"-\"), (\"__mul__\", \"*\"), (\"__imul__\", \"*=\"), (\"__rmul__\", \"*\"), (\"__pow__\", \"**\"), (\"__ipow__\", \"**=\"), (\"__rpow__\", \"**\"), (\"__floordiv__\", \"//\"), (\"__ifloordiv__\", \"//=\"), (\"__rfloordiv__\", \"//\"), (\"__truediv__\", \"/\"), (\"__itruediv__\", \"/=\"), (\"__rtruediv__\", \"/\"), (\"__divmod__\", \"divmod()\"), (\"__rdivmod__\", \"divmod()\"), (\"__mod__\", \"%\"), (\"__imod__\", \"%=\"), (\"__rmod__\", \"%\"), (\"__lshift__\", \"<<\"), (\"__ilshift__\", \"<<=\"), (\"__rlshift__\", \"<<\"), (\"__rshift__\", \">>\"), (\"__irshift__\", \">>=\"), (\"__rrshift__\", \">>\")):\n\nmessage = (\"unsupported operand type(s) for {0}: \"\n\n\"'{{self}}'{{join}} {{args}}\".format(operator))\n\nexec(\"def {0}(self, *args):\\n\"\n\n\" \"for arg in args]\\n\" \" \"self=self.__class__.__name__, \" \"join=(\\\" and\\\" if len(args) == 1 else \\\",\\\"),\" \"args=\\\", \\\".join(types)))\".format(name, message))\n\ntypes = [\\\"'\\\" + arg.__class__.__name__ + \\\"'\\\" \"\n\nraise TypeError(\\\"{1}\\\".format(\"\n\nThiscodeisslightly morecomplicatedthan beforebecausefor binary operators we must output messages where the two types are listed as type1 and type2, but for three or more types we must list them as type1, type2, type3 to mimic\n\nDynam- ic pro- gram- ming ➤ 349",
      "content_length": 2306,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 270,
      "content": "Custom Classes\n\nthe built-in behavior. Here is the code that is generated for the ﬁrst tuple (\"__xor__\", \"^\"):\n\ndef __xor__(self, *args):\n\ntypes = [\"'\" + arg.__class__.__name__ + \"'\" for arg in args] raise TypeError(\"unsupported operand type(s) for ^: \"\n\n\"'{self}'{join} {args}\".format( self=self.__class__.__name__, join=(\" and\" if len(args) == 1 else \",\"), args=\", \".join(types)))\n\nThe two for … in loop blocks we have used here can be simply cut and pasted, and then we can add or remove unary operators and methods from the ﬁrst one and binary or n-ary operators and methods from the second one to unim- plement whatever methods are not required.\n\nWith this last piece of code in place,if we had two FuzzyBools, f and g,and tried to add them using f + g, we would get a TypeError exception with the message “unsupported operand type(s) for +: 'FuzzyBool' and 'FuzzyBool'”, which is exactly the behavior we want.\n\nCreating classes the way we did for the ﬁrst FuzzyBool implementation is much more common and is sufﬁcient for almost every purpose. However, if we need to create an immutable class, the way to do it is to reimplement ob- ject.__new__() having inherited one of Python’s immutable types such as float, int, str, or tuple, and then implement all the other methods we need. The disadvantage of doing this is that we may need to unimplement some methods—thisbreakspolymorphism,so in most casesusing aggregation aswe did in the ﬁrst FuzzyBool implementation is a much better approach.\n\nCustom Collection Classes\n\nIn this section’ssubsectionswe will look at custom classesthat are responsible for largeamountsof data. The ﬁrst classwe will review,Image,isone that holds imagedata. Thisclassistypicalof many data-holding customclassesin that it not only providesin-memory accessto itsdata,but also hasmethodsfor saving and loading the data to and from disk. The second and third classes we will study, SortedList and SortedDict, are designed to ﬁll a rare and surprising gap in Python’s standard library for intrinsically sorted collection data types.\n\nCreating Classes That Aggregate Collections\n\nA simple way of representing a 2D color image is as a two-dimensional array with each array element being a color. So to represent a 100 × 100 image we must store 10000 colors. For the Image class (in ﬁle Image.py), we will take a\n\n261\n\n|||\n\n||",
      "content_length": 2352,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 271,
      "content": "262\n\nChapter 6. Object-Oriented Programming\n\npotentially more efﬁcient approach. An Image stores a single background color, plus the colors of those points in the image that differ from the background color. Thisisdoneby using a dictionaryasa kindof sparsearray,witheachkey being an (x, y) coordinate and the corresponding value being the color of that point. If we had a 100× 100image and half itspointsarethebackgroundcolor, we would need to store only 5000 + 1 colors, a considerable saving in memory.\n\nThe Image.py module follows what should now be a familiar pattern: It starts with a shebang line, then copyright information in comments, then a module docstring with some doctests, and then the imports, in this case of the os and pickle modules. We will brieﬂy cover the use of the pickle module when we cover saving and loading images. After the imports we create some custom exception classes:\n\nclass ImageError(Exception): pass class CoordinateError(ImageError): pass\n\nWe have shown only the ﬁrst two exception classes; the others (LoadError, SaveError, ExportError, and NoFilenameError) are all created the same way and all inherit from ImageError. Users of the Image class can choose to test for any of the speciﬁc exceptions, or just for the base class ImageError exception.\n\nThe rest of the module consists of the Image class and at the end the standard three lines for running the module’s doctests. Before looking at the class and its methods, let’s look at how it can be used:\n\nborder_color = \"#FF0000\" square_color = \"#0000FF\" width, height = 240, 60 midx, midy = width // 2, height // 2 image = Image.Image(width, height, \"square_eye.img\") for x in range(width):\n\n# red # blue\n\nfor y in range(height):\n\nif x < 5 or x >= width - 5 or y < 5 or y >= height - 5:\n\nimage[x, y] = border_color\n\nelif midx - 20 < x < midx + 20 and midy - 20 < y < midy + 20:\n\nimage[x, y] = square_color\n\nimage.save() image.export(\"square_eye.xpm\")\n\nNotice that we can use the item access operator ([]) for setting colors in the image. Brackets can also be used for getting or deleting (effectively setting to thebackgroundcolor)thecolorata particular(x,y)coordinate. Thecoordinates are passed as a single tuple object (thanksto the comma operator),the same as if we wrote image[(x, y)]. Achieving this kind of seamless syntax integration iseasy in Python—wejust have to implement theappropriatespecialmethods,\n\nPickles ➤ 292",
      "content_length": 2418,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 272,
      "content": "Custom Collection Classes\n\nwhich in the case of the item access operator are __getitem__(), __setitem__(), and __delitem__().\n\nThe Image class uses HTML-style hexadecimal strings to represent colors. The background color must be set when the image is created;otherwise,it defaults to white. The Image class saves and loads images in its own custom format, but it can also export in the .xpm format which is understood by many image processing applications. The .xpm imageproducedby thecodesnippet isshown in Figure 6.6.\n\nFigure 6.6 The square_eye.xpm image\n\nWe will now review the Image class’s methods, starting with the class line and the initializer:\n\nclass Image:\n\ndef __init__(self, width, height, filename=\"\",\n\nbackground=\"#FFFFFF\"):\n\nself.filename = filename self.__background = background self.__data = {} self.__width = width self.__height = height self.__colors = {self.__background}\n\nWhen an Image is created, the user (i.e., the class’s user) must provide a width and height, but the ﬁlename and background color are optional since defaults areprovided. Theself.__data dictionary’skeysare(x,y)coordinatesanditsval- ues are color strings. The self.__colors set is initialized with the background color; it is used to keep track of the unique colors used by the image.\n\nAll the data attributes are private except for the ﬁlename, so we must provide a means by which users of the class can access them. This is easily done using properties.★\n\n@property def background(self):\n\nreturn self.__background\n\n★In Chapter 8 we will see a completely different approach to providing attribute access, using special methods such as __getattr__() and __setattr__(), that is useful in some circumstances.\n\n263",
      "content_length": 1705,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 273,
      "content": "Copying collec- tions 146➤\n\n264\n\nChapter 6. Object-Oriented Programming\n\n@property def width(self):\n\nreturn self.__width\n\n@property def height(self):\n\nreturn self.__height\n\n@property def colors(self):\n\nreturn set(self.__colors)\n\nWhenreturning a data attributefromanobjectweneedtobeawareof whether theattributeisof an immutableor mutabletype. It isalwayssafetoreturnim- mutable attributes since they can’t be changed, but for mutable attributes we must consider some trade-offs. Returning a reference to a mutable attribute is very fast and efﬁcient because no copying takes place—but it also means that the caller now has access to the object’s internal state and might change it in a way that invalidates the object. One policy to consider is to always return a copy of mutable data attributes, unless proﬁling shows a signiﬁcant negative effect on performance. (In thiscase,an alternativeto keeping theset of unique colors would be to return set(self.__data.values()) | {self.__background} whenever the set of colors was needed; we will return to this theme shortly.)\n\ndef __getitem__(self, coordinate):\n\nassert len(coordinate) == 2, \"coordinate should be a 2-tuple\" if (not (0 <= coordinate[0] < self.width) or not (0 <= coordinate[1] < self.height)): raise CoordinateError(str(coordinate))\n\nreturn self.__data.get(tuple(coordinate), self.__background)\n\nThis method returns the color for a given coordinate using the item access operator ([]).The special methodsfor the item accessoperatorsand some other collection-relevant special methods are listed in Table 6.4.\n\nWe have chosen to apply two policies for item access. The ﬁrst policy is that a precondition for using an item accessmethod is that the coordinate it ispassed is a sequence of length 2 (usually a 2-tuple),and we use an assertion to ensure this. The second policy is that any coordinatevaluesare accepted,but if either is out of range, we raise a custom exception.\n\nWe have used the dict.get() method with a default value of the background color toretrievethecolorfor thegivencoordinate. Thisensuresthatif thecolor hasnever beenset for thecoordinatethebackgroundcolor iscorrectlyreturned instead of a KeyError exception being raised.",
      "content_length": 2202,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 274,
      "content": "Custom Collection Classes\n\nTable 6.4 Collection Special Methods\n\nSpecial Method\n\nUsage\n\nDescription\n\n__contains__(self, x)\n\nx in y\n\nReturns True if x is in sequence y or if x is a key in mapping y\n\n__delitem__(self, k)\n\ndel y[k]\n\nDeletes the k-th item of sequence y or the item with key k in mapping y\n\n__getitem__(self, k)\n\ny[k]\n\nReturnsthe k-th item of sequence y or the value for key k in mapping y\n\n__iter__(self)\n\nfor x in y: pass\n\nReturns an iterator for sequence y’s items or mapping y’s keys\n\n__len__(self)\n\nlen(y)\n\nReturns the number of items in y\n\n__reversed__(self)\n\nreversed(y) Returns a backward iterator for se- quence y’s items or mapping y’s keys\n\n__setitem__(self, k, v) y[k] = v\n\nSetsthe k-th item of sequence y or the value for key k in mapping y, to v\n\ndef __setitem__(self, coordinate, color):\n\nassert len(coordinate) == 2, \"coordinate should be a 2-tuple\" if (not (0 <= coordinate[0] < self.width) or not (0 <= coordinate[1] < self.height)): raise CoordinateError(str(coordinate))\n\nif color == self.__background:\n\nself.__data.pop(tuple(coordinate), None)\n\nelse:\n\nself.__data[tuple(coordinate)] = color self.__colors.add(color)\n\nIf the user sets a coordinate’s value to the background color we can simply delete the corresponding dictionary item since any coordinate not in the dic- tionary is assumed to have the background color. We must use dict.pop() and give a dummy second argument rather than use del because doing so avoids a KeyError being raised if the key (coordinate) is not in the dictionary.\n\nIf the color is different from the background color, we set it for the given coordinate and add it to the set of the unique colors used by the image.\n\ndef __delitem__(self, coordinate):\n\nassert len(coordinate) == 2, \"coordinate should be a 2-tuple\" if (not (0 <= coordinate[0] < self.width) or not (0 <= coordinate[1] < self.height)): raise CoordinateError(str(coordinate))\n\nself.__data.pop(tuple(coordinate), None)\n\n265",
      "content_length": 1948,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 275,
      "content": "266\n\nChapter 6. Object-Oriented Programming\n\nIf a coordinate’s color is deleted the effect is to make that coordinate’s color the background color. Again we use dict.pop() to remove the item since it will work correctly whether or not an item with the given coordinate is in the dictionary.\n\nBoth __setitem__() and __delitem__() have the potential to make the set of colors contain more colors than the image actually uses. For example, if a unique nonbackground color is deleted at a certain pixel, the color remains in the color set even though it is no longer used. Similarly,if a pixel has a unique nonbackground color and is set to the background color, the unique color is no longer used, but remains in the color set. This means that, at worst, the color set could contain more colors than are actually used by the image (but never less).\n\nWe have chosen to accept the trade-off of potentially having more colors in the color set than are actually used for the sake of better performance, that is, to make setting and deleting a color as fast as possible—especially since storing a few more colors isn’t usually a problem. Of course, if we wanted to ensure that the set of colors was in sync we could either create an additional method that could be called whenever we wanted, or accept the overhead and do the computationautomatically when it wasneeded. In either case,thecodeisvery simple (and is used when a new image is loaded):\n\nself.__colors = (set(self.__data.values()) |\n\n{self.__background})\n\nThis simply overwrites the set of colors with the set of colors actually used in the image unioned with the background color.\n\nWe have not provided a __len__() implementation since it does not make sense for a two-dimensional object. Also, we cannot provide a representational form since an Image cannot be created fully formed just by calling Image(), so we do not provide __repr__() (or __str__()) implementations either. If a user calls repr() or str() on an Image object, the object.__repr__() base class imple- mentation will return a suitable string, for example, '<Image.Image object at 0x9c794ac>'. This is a standard format used for non-eval()-able objects. The hexadecimal number is the object’s ID—this is unique (normally it is the ob- ject’s address in memory), but transient.\n\nWe want users of the Image class to be able to save and load their image data, so we have provided two methods, save() and load(), to carry out these tasks.\n\nWe have chosen to save the data by pickling it. In Python-speak pickling is a way of serializing (converting into a sequence of bytes, or into a string) a Python object. What is so powerful about pickling is that the pickled object can be a collection data type, such as a list or a dictionary, and even if the pickled object has other objects inside it (including other collections, which",
      "content_length": 2847,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 277,
      "content": "268\n\nChapter 6. Object-Oriented Programming\n\nwe had to open the ﬁle in binary mode. When reading pickles no protocol is speciﬁed—the pickle.load() function is smart enough to work out the protocol for itself.\n\ndef load(self, filename=None):\n\nif filename is not None:\n\nself.filename = filename\n\nif not self.filename:\n\nraise NoFilenameError()\n\nfh = None try:\n\nfh = open(self.filename, \"rb\") data = pickle.load(fh) (self.__width, self.__height, self.__background,\n\nself.__data) = data\n\nself.__colors = (set(self.__data.values()) |\n\n{self.__background})\n\nexcept (EnvironmentError, pickle.UnpicklingError) as err:\n\nraise LoadError(str(err))\n\nfinally:\n\nif fh is not None: fh.close()\n\nThis function starts off the same as the save() function to get the ﬁlename of the ﬁle to load. The ﬁle must be opened in read binary mode, and the data is read using the single statement, data = pickle.load(fh). The data object is an exact reconstruction of the one we saved, so in this case it is a list with the width and height integers, the background color string, and the dictionary of coordinate–color items. We use tuple unpacking to assign each of the data list’s items to the appropriate variable, so any previously held image data is (correctly) lost.\n\nThe set of unique colorsisreconstructedby making a set of all the colorsin the coordinate–color dictionary and then adding the background color.\n\ndef export(self, filename):\n\nif filename.lower().endswith(\".xpm\"):\n\nself.__export_xpm(filename)\n\nelse:\n\nraise ExportError(\"unsupported export format: \" + os.path.splitext(filename)[1])\n\nWe have provided one generic export method that uses the ﬁle extension to determine which private method to call—or raisesan exception for ﬁle formats that cannot be exported. In this case we only support saving to .xpm ﬁles (and then only for images with fewer than 8930 colors). We haven’t quoted the",
      "content_length": 1877,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 278,
      "content": "Custom Collection Classes\n\n__export_xpm() method because it isn’t really relevant to this chapter’s theme, but it is in the book’s source code, of course.\n\nWe have now completed our coverage of the custom Image class. This class is typical of those used to hold program-speciﬁc data, providing access to the data items it contains, the ability to save and load all its data to and from disk, and with only the essential methods it needs provided. In the next two subsections we will see how to create two generic custom collection types that offer complete APIs.\n\nCreating Collection Classes Using Aggregation\n\nIn thissubsection we will develop a completecustom collection data type,Sort- edList, that holds a list of items in sorted order. The items are sorted using their less than operator (<), provided by the __lt__() special method, or by us- ing a key function if one is given. The class tries to match the API of the built- in list class to make it as easy to learn and use as possible, but some methods cannot sensibly beprovided—forexample,using theconcatenationoperator (+) could result in items being out of order, so we do not implement it.\n\nAs always when creating custom classes, we are faced with the choices of inheriting a classthat issimilar to the one we want to make,or creating a class from scratch and aggregating instances of any other classes we need inside it, or doing a mixtureof both. For thissubsection’sSortedList we use aggregation (and implicitly inherit object, of course), and for the following subsection’s SortedDict we will use both aggregation and inheritance (inheriting dict).\n\nIn Chapter 8 we will see that classes can make promises about the API they offer. For example, a list provides the MutableSequence API which means that it supportsthe in operator,the iter() and len() built-in functions,and the item access operator ([]) for getting, setting, and deleting items, and an insert() method. The SortedList class implemented here does not support item setting and does not have an insert() method, so it does not provide a MutableSequence API. If we were to create SortedList by inheriting list, the resultant class would claim to be a mutable sequence but would not have the complete API. In view of this the SortedList does not inherit list and so makes no promises about its API. On the other hand, the next subsection’s SortedDict class sup- ports the complete MutableMapping API that the dict class provides, so we can make it a dict subclass.\n\nHere are some basic examples of using a SortedList:\n\nletters = SortedList.SortedList((\"H\", \"c\", \"B\", \"G\", \"e\"), str.lower) # str(letters) == \"['B', 'c', 'e', 'G', 'H']\" letters.add(\"G\") letters.add(\"f\") letters.add(\"A\")\n\n269\n\n||",
      "content_length": 2724,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 279,
      "content": "Lambda func- tions 182➤\n\n270\n\nChapter 6. Object-Oriented Programming\n\n# str(letters) == \"['A', 'B', 'c', 'e', 'f', 'G', 'G', 'H']\" letters[2] # returns: 'c'\n\nA SortedList object aggregates (is composed of) two private attributes; a func- tion, self.__key() (held as object reference self.__key), and a list, self.__list.\n\nThe key function is passed as the second argument (or using the key keyword speciﬁed the argument if no initial sequence is given). If no key function is following private module function is used:\n\n_identity = lambda x: x\n\nThis is the identity function: It simply returns its argument unchanged, so when it isused asa SortedList’skey functionit meansthat thesort key for each object in the list is the object itself.\n\nThe SortedList type does not allow the item access operator ([]) to change an item (so it does not implement the __setitem__() special method), nor does it provide the append() or extend() method since these might invalidate the ordering. The only way to add items is to pass a sequence when the SortedList iscreatedor toaddthemlater using the SortedList.add() method. Ontheother hand, we can safely use the item access operator for getting or deleting the item at a given index position since neither operation affects the ordering, so both the __getitem__() and __delitem__() special methods are implemented.\n\nWe will now review the class method by method, starting as usual with the class line and the initializer:\n\nclass SortedList:\n\ndef __init__(self, sequence=None, key=None):\n\nself.__key = key or _identity assert hasattr(self.__key, \"__call__\") if sequence is None: self.__list = []\n\nelif (isinstance(sequence, SortedList) and\n\nsequence.key == self.__key): self.__list = sequence.__list[:]\n\nelse:\n\nself.__list = sorted(list(sequence), key=self.__key)\n\nSince a function’s name is an object reference (to its function), we can hold functions in variables just like any other object reference. Here the private self.__key variable holds a reference to the key function that was passed in, or totheidentity function. Themethod’sﬁrststatementrelieson thefact that the or operator returns its ﬁrst operand if it is True in a Boolean context (which a not-None key function is),or itssecond operand otherwise. A slightly longer but",
      "content_length": 2271,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 280,
      "content": "Custom Collection Classes\n\nmore obvious alternative would have been self.__key = key if key is not None else _identity.\n\nOnce we have the key function, we use an assert to ensure that it is callable. The built-in hasattr() function returns True if the object passed as its ﬁrst ar- gument hasthe attributewhose name is passed as itssecond argument. There are corresponding setattr() and delattr() functions—these functions are cov- ered in Chapter 8. All callable objects, for example, functions and methods, have a __call__ attribute.\n\nTo make the creation of SortedLists as similar as possible to the creation of lists we have an optional sequence argument that corresponds to the single optional argument that list() accepts. The SortedList class aggregates a list collection in the private variable self.__list and keeps the items in the aggregated list in sorted order using the given key function.\n\nThe elif clause uses type testing to see whether the given sequence is a Sort- edList and if that is the case whether it has the same key function as this sort- ed list. If these conditions are met we simply shallow-copy the sequence’s list without needing to sort it. If most key functions are created on the ﬂy using lambda, even though two may have the same code they will not compare as equal, so the efﬁciency gain may not be realized in practice.\n\n@property def key(self):\n\nreturn self.__key\n\nOnce a sorted list is created its key function is ﬁxed, so we keep it as a private variable to prevent users from changing it. But some users may want to get a reference to the key function (as we will see in the next subsection), and so we have made it accessible by providing the read-only key property.\n\ndef add(self, value):\n\nindex = self.__bisect_left(value) if index == len(self.__list): self.__list.append(value)\n\nelse:\n\nself.__list.insert(index, value)\n\nWhen this method is called the given value must be inserted into the private self.__list in the correct position to preserve the list’s order. The private SortedList.__bisect_left() method returns the required index position as we will see in a moment. If the new value islarger than any other value in the list it must go at the end,so the index position will be equal to the list’s length (list index positions go from 0 to len(L) - 1)—if this is the case we append the new value. Otherwise, we insert the new value at the given index position—which will be at index position 0 if the new value is smaller than any other value in the list.\n\n271",
      "content_length": 2512,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 281,
      "content": "272\n\nChapter 6. Object-Oriented Programming\n\ndef __bisect_left(self, value): key = self.__key(value) left, right = 0, len(self.__list) while left < right:\n\nmiddle = (left + right) // 2 if self.__key(self.__list[middle]) < key:\n\nleft = middle + 1\n\nelse:\n\nright = middle\n\nreturn left\n\nThis private method calculates the index position where the given value be- longsin the list,that is,the index position where the value is(if it isin the list), or where it should go (if it isn’t in the list). It computes the comparison key for the given value using the sorted list’s key function, and compares the com- parison key with the computed comparison keys of the items that the method examines. The algorithm used is binarysearch(also called binarychop),which has excellent performance even on very large lists—for example, at most, 21 comparisons are required to ﬁnd a value’s position in a list of 1000000 items.★ Comparethiswith a plain unsorted list which useslinear search and needsan average of 500000 comparisons, and at worst 1000000 comparisons, to ﬁnd a value in a list of 1000000 items.\n\ndef remove(self, value):\n\nindex = self.__bisect_left(value) if index < len(self.__list) and self.__list[index] == value:\n\ndel self.__list[index]\n\nelse:\n\nraise ValueError(\"{0}.remove(x): x not in list\".format(\n\nself.__class__.__name__))\n\nThis method is used to remove the ﬁrst occurrence of the given value. It uses the SortedList.__bisect_left() method to ﬁnd the index position where the value belongs and then tests to see whether that index position is within the list and that the item at that position is the same as the given value. If the conditions are met the item is removed; otherwise, a ValueError exception is raised (which is what list.remove() does in the same circumstances).\n\ndef remove_every(self, value):\n\ncount = 0 index = self.__bisect_left(value) while (index < len(self.__list) and\n\nself.__list[index] == value):\n\n★Python’s bisect module provides the bisect.bisect_left() function and some others, but at the time of this writing none of the bisect module’s functions can work with a key function.",
      "content_length": 2113,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 282,
      "content": "Custom Collection Classes\n\ndel self.__list[index] count += 1\n\nreturn count\n\nThis method is similar to the SortedList.remove() method, and is an extension of the list API. It starts off by ﬁnding the index position where the ﬁrst occurrence of the value belongs in the list, and then loops as long as the index position is within the list and the item at the index position is the same as the given value. The code is slightly subtle since at each iteration the matching item is deleted,and as a consequence,after each deletion the item at the index position is the item that followed the deleted item.\n\ndef count(self, value):\n\ncount = 0 index = self.__bisect_left(value) while (index < len(self.__list) and\n\nself.__list[index] == value):\n\nindex += 1 count += 1\n\nreturn count\n\nThis method returns the number of times the given value occurs in the list (which could be 0). It uses a very similar algorithm to SortedList.remove_ every(), only here we must increment the index position in each iteration.\n\ndef index(self, value):\n\nindex = self.__bisect_left(value) if index < len(self.__list) and self.__list[index] == value:\n\nreturn index\n\nraise ValueError(\"{0}.index(x): x not in list\".format(\n\nself.__class__.__name__))\n\nSincea SortedList isorderedwecan usea fast binary searchtoﬁnd (or not ﬁnd) the value in the list.\n\ndef __delitem__(self, index): del self.__list[index]\n\nThe __delitem__() special method provides support for the del L[n] syntax, where L is a sorted list and n is an integer index position. We don’t test for an out-of-range index since if one is given the self.__list[index] call will raise an IndexError exception, which is the behavior we want.\n\ndef __getitem__(self, index): return self.__list[index]\n\nThis method provides support for the x =L [n] syntax, where L is a sorted list and n is an integer index position.\n\n273",
      "content_length": 1844,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 283,
      "content": "274\n\nChapter 6. Object-Oriented Programming\n\ndef __setitem__(self, index, value):\n\nraise TypeError(\"use add() to insert a value and rely on \"\n\n\"the list to put it in the right place\")\n\nWe don’t want the user to change an item at a given index position (so L[n] = x is disallowed); otherwise, the sorted list’s order might be invalidated. The TypeError exceptionistheoneused tosignify that an operationisnot supported by a particular data type.\n\ndef __iter__(self):\n\nreturn iter(self.__list)\n\nThis method is easy to implement since we can just return an iterator to the private list using the built-in iter() function. This method is used to support the for value in iterable syntax.\n\nNote that if a sequence is required it is this method that is used. So to convert a SortedList, L, to a plain list we can call list(L), and behind the scenes Python will call SortedList.__iter__(L) to provide the sequence that the list() function requires.\n\ndef __reversed__(self):\n\nreturn reversed(self.__list)\n\nThis provides support for the built-in reversed() function so that we can write, for example, for value in reversed(iterable).\n\ndef __contains__(self, value):\n\nindex = self.__bisect_left(value) return (index < len(self.__list) and self.__list[index] == value)\n\nThe __contains__() method providessupport for the in operator.Once again we are able to use a fast binary search rather than the slow linear search used by a plain list.\n\ndef clear(self):\n\nself.__list = []\n\ndef pop(self, index=-1):\n\nreturn self.__list.pop(index)\n\ndef __len__(self):\n\nreturn len(self.__list)\n\ndef __str__(self):\n\nreturn str(self.__list)",
      "content_length": 1610,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 284,
      "content": "Custom Collection Classes\n\nThe SortedList.clear() method discardsthe existing list and replacesit with a new empty list. The SortedList.pop() method removes and returnsthe item at the given index position,or raises an IndexError exception if the index is out of range. For the pop(), __len__(), and __str__() methods, we simply pass on the work to the aggregated self.__list object.\n\nWe do not reimplement the __repr__() special method, so the base class ob- ject.__repr__() will be called when the user writes repr(L) and L is a Sort- edList. This will produce a string such as '<SortedList.SortedList object at 0x97e7cec>', although the hexadecimal ID will vary, of course. We cannot provide a sensible __repr__() implementation because we would need to give the key function and we cannot represent a function object reference as an eval()-able string.\n\nWe have not implemented the insert(), reverse(), or sort() method because none of them is appropriate. If any of them are called an AttributeError exception will be raised.\n\nIf we copy a sorted list using the L[:] idiom we will get a plain list object, rather than a SortedList. The easiest way to get a copy is to import the copy moduleand usethe copy.copy() function—thisissmartenough tocopy a sorted list (and instances of most other custom classes) without any help. However, we have decided to provide an explicit copy() method:\n\ndef copy(self):\n\nreturn SortedList(self, self.__key)\n\nBy passing self as the ﬁrst argument we ensure that self.__list is simply shallow-copied rather than being copied and re-sorted. (This is thanks to the __init__() method’s type-testing elif clause.) The theoretical performance advantage of copying this way is not available to the copy.copy() function, but we can easily make it available by adding this line:\n\n__copy__ = copy\n\nWhen copy.copy() is called it triesto use the object’s __copy__() special method, falling back to its own code if one isn’t provided. With this line in place copy.copy() will now use the SortedList.copy() method for sorted lists. (It is also possible to provide a __deepcopy__() special method, but this is slightly more involved—the copy module’s online documentation has the details.)\n\nWe have now completed the implementation of the SortedList class. In the next subsection we will make use of a SortedList to providea sorted list of keys for the SortedDict class.\n\n275",
      "content_length": 2396,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 285,
      "content": "collec- tions. Ordered- Dict 136➤\n\n276\n\nChapter 6. Object-Oriented Programming\n\nCreating Collection Classes Using Inheritance\n\nThe SortedDict class shown in this subsection attempts to mimic a dict as closely as possible. The major difference is that a SortedDict’s keys are always ordered based on a speciﬁed key function or on the identity function. Sorted- Dict providesthesameAPIas dict (except for having a non-eval()-able repr()), plus two extra methods that make sense only for an ordered collection.★ (Note that Python 3.1 introduced the collections.OrderedDict class—this class is dif- ferent from SortedDict since it is insertion-ordered rather than key-ordered.)\n\nHere are a few examples of use to give a ﬂavor of how SortedDict works:\n\nd = SortedDict.SortedDict(dict(s=1, A=2, y=6), str.lower) d[\"z\"] = 4 d[\"T\"] = 5 del d[\"y\"] d[\"n\"] = 3 d[\"A\"] = 17 str(d) # returns: \"{'A': 17, 'n': 3, 's': 1, 'T': 5, 'z': 4}\"\n\nThe SortedDict implementation uses both aggregation and inheritance. The sortedlistof keysisaggregatedasaninstancevariable,whereastheSortedDict class itself inherits the dict class. We will start our code review by looking at the class line and the initializer,and then we will look at all of the other meth- ods in turn.\n\nclass SortedDict(dict):\n\ndef __init__(self, dictionary=None, key=None, **kwargs):\n\ndictionary = dictionary or {} super().__init__(dictionary) if kwargs:\n\nsuper().update(kwargs)\n\nself.__keys = SortedList.SortedList(super().keys(), key)\n\nThe dict base class is speciﬁed in the class line. The initializer tries to mimic the dict() function, but adds a second argument for the key function. The super().__init__() call is used to initialize the SortedDict using the base class dict.__init__() method. Similarly, if keyword arguments have been used, we use the base class dict.update() method to add them to the dictionary. (Note that only one occurrence of any keyword argument is accepted, so none of the keys in the kwargs keyword arguments can be “dictionary” or “key”.)\n\n★The SortedDict class presented here is different from the one in Rapid GUI Programming with Python and Qt by this author, ISBN 0132354187,and from the one in the Python Package Index.\n\n||",
      "content_length": 2208,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 286,
      "content": "Custom Collection Classes\n\nWe keep a copy of all the dictionary’s keys in a sorted list stored in the self.__keys variable. We pass the dictionary’s keys to initialize the sorted list using the base class’s dict.keys() method—we must not use SortedDict.keys() because that relies on the self.__keys variable which will exist only after the SortedList of keys has been created.\n\ndef update(self, dictionary=None, **kwargs):\n\nif dictionary is None:\n\npass\n\nelif isinstance(dictionary, dict): super().update(dictionary)\n\nelse:\n\nfor key, value in dictionary.items():\n\nsuper().__setitem__(key, value)\n\nif kwargs:\n\nsuper().update(kwargs)\n\nself.__keys = SortedList.SortedList(super().keys(),\n\nself.__keys.key)\n\nThis method is used to update one dictionary’s items with another dictionary’s items, or with keyword arguments, or both. Items which exist only in the other dictionary are added to thisone,and for itemswhose keysappear in both dictionaries, the other dictionary’s value replaces the original value. We have had toextendthebehavior slightly in thatwekeeptheoriginaldictionary’skey function, even if the other dictionary is a SortedDict.\n\nThe updating is done in two phases. First we update the dictionary’sitems. If the given dictionary is a dict subclass (which includes SortedDict, of course), we use the base class dict.update() to perform the update—using the base class version is essential to avoid calling SortedDict.update() recursively and going into an inﬁnite loop. If the dictionary is not a dict we iterate over the dictionary’s items and set each key–value pair individually. (If the dictionary object is not a dict and does not have an items() method an AttributeError exception will quite rightly be raised.) If keyword arguments have been used we again call the base class update() method to incorporate them.\n\nA consequence of the updating is that the self.__keys list becomes out of date, so we replace it with a new SortedList with the dictionary’s keys (again obtained from the base class, since the SortedDict.keys() method relies on the self.__keys list which we are in the process of updating),and with the original sorted list’s key function.\n\n@classmethod def fromkeys(cls, iterable, value=None, key=None):\n\nreturn cls({k: value for k in iterable}, key)\n\n277",
      "content_length": 2287,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 287,
      "content": "278\n\nChapter 6. Object-Oriented Programming\n\nThe dict API includes the dict.fromkeys() class method. This method is used to create a new dictionary based on an iterable. Each element in the iterable becomes a key, and each key’s value is either None or the speciﬁed value.\n\nBecause this is a class method the ﬁrst argument is provided automatically by Python and is the class. For a dict the class will be dict,and for a SortedDict it is SortedDict. The return value is a dictionary of the given class. For example:\n\nclass MyDict(SortedDict.SortedDict): pass d = MyDict.fromkeys(\"VEINS\", 3) str(d) d.__class__.__name__\n\n# returns: \"{'E': 3, 'I': 3, 'N': 3, 'S': 3, 'V': 3}\"\n\n# returns: 'MyDict'\n\nSo when inherited class methods are called, their cls variable is set to the correct class, just like when normal methods are called and their self variable is set to the current object. This is different from and better than using a static method because a static method is tied to a particular class and does not know whether it is being executed in the context of its original class or that of a subclass.\n\ndef __setitem__(self, key, value):\n\nif key not in self:\n\nself.__keys.add(key)\n\nreturn super().__setitem__(key, value)\n\nThis method implements the d[key] = value syntax. If the key isn’t in the dictionary we add it to the list of keys,relying on the SortedList to put it in the right place. Then we call the base class method, and return its result to the caller to support chaining, for example, x = d[key] = value.\n\nNotice that in the if statement we check to see whether the key already exists in the SortedDict by using not in self. Because SortedDict inherits dict, a SortedDict can be used wherever a dict is expected, and in this case self is a SortedDict. When we reimplement dict methods in SortedDict, if we need to call the base class implementation to get it to do some of the work for us, we must be careful to call the method using super(), as we do in this method’s last statement;doing so preventsthe reimplementation of the method from calling itself and going into inﬁnite recursion.\n\nWe do not reimplement the __getitem__() method since the base class version works ﬁne and has no effect on the ordering of the keys.\n\ndef __delitem__(self, key):\n\ntry:\n\nself.__keys.remove(key)\n\nexcept ValueError:\n\nraise KeyError(key)\n\nreturn super().__delitem__(key)",
      "content_length": 2374,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 288,
      "content": "Custom Collection Classes\n\nGenerator Functions\n\nA generator function or generator method is one which contains a yield ex- pression. When a generator function is called it returns an iterator. Values areextractedfromtheiteratoroneat a timeby calling its__next__() method. At each call to __next__() the generator function’s yield expression’s value (None if none is speciﬁed) is returned. If the generator function ﬁnishes or executes a return a StopIteration exception is raised.\n\nIn practice we rarely call __next__() or catch a StopIteration. Instead, we just use a generator like any other iterable. Here are two almost equivalent functions. The one on the left returns a list and the one on the right returns a generator.\n\n# Build and return a list def letter_range(a, z):\n\nresult = [] while ord(a) < ord(z):\n\n# Return each value on demand def letter_range(a, z):\n\nresult.append(a) a = chr(ord(a) + 1)\n\nreturn result\n\nwhile ord(a) < ord(z):\n\nyield a a = chr(ord(a) + 1)\n\nWe can iterate over the result produced by either function using a for loop, for example, for letter in letter_range(\"m\", \"v\"):. But if we want a list of the resultant letters,although calling letter_range(\"m\", \"v\") issufﬁcient for the left-hand function, for the right-hand generator function we must use list(letter_range(\"m\", \"v\")).\n\nGenerator functions and methods (and generator expressions) are covered more fully in Chapter 8.\n\nThis method provides the del d[key] syntax. If the key is not present the Sort- edList.remove() call will raise a ValueError exception. If this occurs we catch the exception and raise a KeyError exception instead so as to match the dict class’sAPI.Otherwise,we return the result of calling the base classimplemen- tation to delete the item with the given key from the dictionary itself.\n\ndef setdefault(self, key, value=None):\n\nif key not in self:\n\nself.__keys.add(key)\n\nreturn super().setdefault(key, value)\n\nThis method returns the value for the given key if the key is in the dictionary; otherwise, it creates a new item with the given key and value and returns the value. For the SortedDict we must make sure that the key is added to the keys list if the key is not already in the dictionary.\n\n279",
      "content_length": 2212,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 289,
      "content": "280\n\nChapter 6. Object-Oriented Programming\n\ndef pop(self, key, *args): if key not in self:\n\nif len(args) == 0:\n\nraise KeyError(key)\n\nreturn args[0] self.__keys.remove(key) return super().pop(key, args)\n\nIf the given key is in the dictionary this method returns the corresponding value and removes the key–value item from the dictionary. The key must also be removed from the keys list.\n\nThe implementation is quite subtle because the pop() method must support twodifferentbehaviorstomatch dict.pop().Theﬁrstisd.pop(k);herethevalue for key k is returned, or if there is no key k, a KeyError is raised. The second is d.pop(k, value);herethevalue for key k isreturned,or if there isno key k,value (which could be None)isreturned. In all cases,if key k exists,thecorresponding item is removed.\n\ndef popitem(self):\n\nitem = super().popitem() self.__keys.remove(item[0]) return item\n\nThe dict.popitem() method removes and returns a random key–value item from the dictionary. We must call the base class version ﬁrst since we don’t know in advance which item will be removed. We remove the item’s key from the keys list, and then return the item.\n\ndef clear(self):\n\nsuper().clear() self.__keys.clear()\n\nHere we clear all the dictionary’s items and all the keys list’s items.\n\ndef values(self):\n\nfor key in self.__keys: yield self[key]\n\ndef items(self):\n\nfor key in self.__keys:\n\nyield (key, self[key])\n\ndef __iter__(self):\n\nreturn iter(self.__keys)\n\nkeys = __iter__",
      "content_length": 1458,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 290,
      "content": "Custom Collection Classes\n\nDictionarieshave four methodsthat return iterators:dict.values() for the dic- tionary’s values, dict.items() for the dictionary’s key–value items, dict.keys() for the keys, and the __iter__() special method that provides support for the iter(d) syntax, and operates on the keys. (Actually, the base class versions of these methods return dictionary views, but for most purposes the behavior of the iterators implemented here is the same.)\n\nSince the __iter__() method and the keys() method have identical behavior, instead of implementing keys(), we simply create an object reference called keys and set it to refer to the __iter__() method. With this in place, users of SortedDict cancall d.keys() or iter(d) togetaniteratorovera dictionary’skeys, just the same as they can call d.values() to get an iterator over the dictionary’s values.\n\nThe values() and items() methods are generator methods—see the sidebar “Generator Functions” (279 ➤) for a brief explanation of generator methods. In both cases they iterate over the sorted keys list, so they always return iter- ators that iterate in key order (with the key order depending on the key func- tion given to the initializer). For the items() and values() methods, the values are looked up using the d[k] syntax (which uses dict.__getitem__() under the hood), since we can treat self as a dict.\n\ndef __repr__(self):\n\nreturn object.__repr__(self)\n\ndef __str__(self):\n\nreturn (\"{\" + \", \".join([\"{0!r}: {1!r}\".format(k, v)\n\nfor k, v in self.items()]) + \"}\")\n\nWe cannot provide an eval()-able representation of a SortedDict because we can’t produce an eval()-able representation of the key function. So for the __repr__() reimplementation we bypass dict.__repr__(), and instead call the ultimate base class version, object.__repr__(). This produces a string of the kind used for non-eval()-able representations, for example, '<Sorted- Dict.SortedDict object at 0xb71fff5c>'.\n\nWe have implemented the SortedDict.__str__() method ourselves because we want the output to show the items in key sorted order. The method could have been written like this instead:\n\nitems = [] for key, value in self.items():\n\nitems.append(\"{0!r}: {1!r}\".format(key, value))\n\nreturn \"{\" + \", \".join(items) + \"}\"\n\nUsing a list comprehension is shorter and avoids the need for the temporary items variable.\n\n281\n\nGenera- tors ➤ 341",
      "content_length": 2382,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 291,
      "content": "282\n\nChapter 6. Object-Oriented Programming\n\nThe base class methods dict.get(), dict.__getitem__() (for the v = d[k] syntax), dict.__len__() (for len(d)), and dict.__contains__() (for x in d) all work ﬁne as they are and don’t affect the key ordering, so we have not needed to reimple- ment them.\n\nThe last dict method that we must reimplement is copy().\n\ndef copy(self):\n\nd = SortedDict() super(SortedDict, d).update(self) d.__keys = self.__keys.copy() return d\n\nThe easiest reimplementation is simply def copy(self): return SortedDict( self). We’ve chosen a slightly more complicated solution that avoids re-sort- ing the already sorted keys. We create an empty sorted dictionary, then up- date it with the items in the original sorted dictionary using the base class dict.update() to avoid the SortedDict.update() reimplementation, and re- place the dictionary’s self.__keys SortedList with a shallow copy of the origi- nal one.\n\nWhen super() is called with no arguments it works on the base class and the self object. But we can make it work on any class and any object by passing in a class and an object explicitly. Using this syntax, the super() call works on the immediate base class of the class it is given,so in this case the code has the same effect as (and could be written as) dict.update(d, self).\n\nIn view of the fact that Python’s sort algorithm is very fast,and is particularly well optimized for partially sorted lists, the efﬁciency gain is likely to be little or nothing except for huge dictionaries. However, the implementation shows that at least in principle, a custom copy() method can be more efﬁcient than using the copy_of_x = ClassOfX(x) idiom that Python’s built-in types support. And just as we did for SortedList, we have set __copy__ = copy so that the copy.copy() function uses our custom copy method rather than its own code.\n\ndef value_at(self, index):\n\nreturn self[self.__keys[index]]\n\ndef set_value_at(self, index, value):\n\nself[self.__keys[index]] = value\n\nThesetwomethodsrepresentanextensiontothedict API.Since,unlikea plain dict, a SortedDict is ordered, it follows that the concept of key index positions isapplicable. For example,theﬁrstitemin thedictionaryisat index position0, and the last at position len(d) - 1.Both of these methods operate on the dictio- nary item whose key is at the index-th position in the sorted keys list. Thanks toinheritance,wecan look upvaluesin the SortedDict using theitemaccessop-",
      "content_length": 2456,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 292,
      "content": "Custom Collection Classes\n\nerator ([]) applied directly to self, since self is a dict. If an out-of-range index is given the methods raise an IndexError exception.\n\nWe have now completed the implementation of the SortedDict class. It is not often that we need to create complete generic collection classes like this, but when we do, Python’s special methods allow us to fully integrate our class so that its users can treat it like any of the built-in or standard library classes.\n\nSummary\n\nThischaptercoveredallthefundamentalsof Python’ssupportforobject-orient- ed programming. We began by showing some of the disadvantagesof a purely procedural approach and how these could be avoided by using object orienta- tion. We then described some of the most common terminology used in object- oriented programming, including many “duplicate” terms such as base class and super class.\n\nWe saw how to create simple classes with data attributesand custom methods. We also saw how to inherit classes and how to add additional data attributes and additional methods, and how methods can be “unimplemented”.Unimple- menting is needed when we inherit a class but want to restrict the methods that our subclass provides, but it should be used with care since it breaks the expectation that a subclass can be used wherever one of its base classes can be used, that is, it breaks polymorphism.\n\nCustom classes can be seamlessly integrated so that they support the same syntaxes as Python’s built-in and library classes. This is achieved by imple- menting special methods. We saw how to implement special methods to sup- portcomparisons,howtoproviderepresentationalandstring forms,andhowto provideconversionstoother typessuch as int and float when it makessenseto do so. We also saw how to implement the __hash__() method to make a custom class’s instances usable as dictionary keys or as members of a set.\n\nData attributes by themselves provide no mechanism for ensuring that they are set to valid values. We saw how easy it is to replace data attributes with properties—this allows us to create read-only properties, and for writable properties makes it easy to provide validation.\n\nMost of theclasseswe createare“incomplete”sincewe tend to provideonly the methods that we actually need. This works ﬁne in Python,but in addition it is possible to create complete custom classesthat provide every relevant method. We saw how to do this for single valued classes, both by using aggregation and more compactly by using inheritance. We also saw how to do this for multivalued (collection) classes. Custom collection classes can provide the same facilities as the built-in collection classes,including support for in, len(), iter(), reversed(), and the item access operator ([]).\n\n283\n\n|||",
      "content_length": 2770,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 293,
      "content": "284\n\nChapter 6. Object-Oriented Programming\n\nWe learned that object creation and initialization are separate operations and that Python allows us to control both, although in almost every case we only need to customize initialization. We also learned that although it is always safe to return an object’s immutable data attributes, we should normally only ever return copies of an object’s mutable data attributes to avoid the object’s internal state leaking out and being accidentally invalidated.\n\nPython provides normal methods, static methods, class methods, and module functions. We saw that most methodsare normal methods,with classmethods being occasionally useful. Static methods are rarely used,since class methods or module functions are almost always better alternatives.\n\nThe built-in repr() method calls an object’s __repr__() special method. Where possible, eval(repr(x)) == x, and we saw how to support this. When an eval()-able representation string cannot be produced we use the base class ob- ject.__repr__() method to produce a non-eval()-able representation in a stan- dard format.\n\nType testing using the built-in isinstance() function can provide some efﬁcien- cy beneﬁts, although object-oriented purists would almost certainly avoid its use. Accessing base class methods is achieved by calling the built-in super() function,and isessentialtoavoid inﬁniterecursionwhen weneed to call a base class method inside a subclass’s reimplementation of that method.\n\nGenerator functions and methods do lazy evaluation, returning (via the yield expression) each value one at a time on request and raising a StopIteration when (and if) they run out of values. Generators can be used wherever an iterator is expected, and for ﬁnite generators, all their values can be extracted into a tuple or list by passing the iterator returned by the generator to tuple() or list().\n\nThe object-oriented approach almost invariably simpliﬁescode compared with a purely proceduralapproach. Withcustomclasseswecanguaranteethatonly valid operationsare available (since we implement only appropriatemethods), and that no operation can put an object into an invalid state (e.g., by using propertiesto apply validation).Once we start using object orientation our style of programming is likely to change from being about global data structures and the global functions that are applied to the data, to creating classes and implementing the methods that are applicable to them. Object orientation makes it possible to package up data and those methods that make sense for thedata. Thishelpsusavoidmixing upallourdataandfunctionstogether,and makes it easier to produce maintainable programs since functionality is kept separated out into individual classes.",
      "content_length": 2747,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 294,
      "content": "Exercises\n\nExercises\n\nThe ﬁrst two exercises involve modifying classes we covered in this chapter, and the last two exercises involve creating new classes from scratch.\n\n1. Modify the Point class (from Shape.py or ShapeAlt.py), to support the following operations, where p, q, and r are Points and n is a number:\n\np = q + r p += q p = q - r p -= q p = q * n p *= n p = q / n p /= n p = q // n #Point.__floordiv__() p //= n\n\n#Point.__add__() # Point.__iadd__() #Point.__sub__() # Point.__isub__() #Point.__mul__() # Point.__imul__() #Point.__truediv__() # Point.__itruediv__()\n\n# Point.__ifloordiv__()\n\nThe in-place methods are all four lines long, including the def line, and the other methods are each just two lines long, including the def line, and of course they are all very similar and quite simple. With a minimal description and a doctest for each it adds up to around one hundred thirty new lines. A model solution is provided in Shape_ans.py; the same code is also in ShapeAlt_ans.py.\n\n2. Modify the Image.py classto providea resize(width, height) method. If the new width or height is smaller than the current value, any colors outside the new boundariesmust be deleted. If either width or height is None then use the existing width or height. At the end, make sure you regenerate the self.__colors set. Return a Boolean to indicate whether a change was made or not. The method can be implemented in fewer than 20 lines (fewer than 35 including a docstring with a simple doctest). A solution is provided in Image_ans.py.\n\n3. Implement a Transaction class that takes an amount, a date, a curren- cy (default “USD”—U.S. dollars), a USD conversion rate (default 1), and a description (default None). All of the data attributes must be pri- vate. Provide the following read-only properties: amount, date, curren- cy, usd_conversion_rate, description, and usd (calculated from amount * usd_conversion_rate). This class can be implemented in about sixty lines including somesimpledoctests. A modelsolutionfor thisexercise(andthe next one) is in ﬁle Account.py.\n\n4. Implement an Account class that holds an account number, an account name, and a list of Transactions. The number should be a read-only prop-\n\n285\n\n|||",
      "content_length": 2220,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 295,
      "content": "286\n\nChapter 6. Object-Oriented Programming\n\nerty;the name should be a read-write property with an assertion to ensure that the name is at least four characters long. The class should support the built-in len() function (returning the number of transactions), and should provide two calculated read-only properties: balance which should return the account’s balance in USD and all_usd which should return True if all the transactions are in USD and False otherwise. Three other methods should be provided: apply() to apply (add) a transaction, save(), and load(). The save() and load() methods should use a binary pickle with the ﬁlename being the account number with extension .acc; they should save and load the account number, the name, and all the trans- actions. This class can be implemented in about ninety lines with some simple doctests that include saving and loading—use code such as name = os.path.join(tempfile.gettempdir(), account_name) to provide a suitable temporary ﬁlename,and make sure you delete the temporary ﬁle after the tests have ﬁnished. A model solution is in ﬁle Account.py.",
      "content_length": 1103,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 296,
      "content": "7\n\nWriting and Reading Binary Data ● Writing and Parsing Text Files ● Writing and Parsing XML Files ● Random Access Binary Files\n\nFile Handling\n\n||||\n\nMost programs need to save and load information, such as data or state information, to and from ﬁles. Python provides many different ways of doing this. We already brieﬂy discussed handling text ﬁles in Chapter 3 and pickles in the preceding chapter. In this chapter we will cover ﬁle handling in much more depth.\n\nAll the techniques presented in this chapter are platform-independent. This means that a ﬁle saved using one of the example programs on one operating system/processorarchitecturecombinationcan beloaded by thesameprogram on a machine with a different operating system/processor architecture com- bination. And this can be true of your programs too if you use the same tech- niques as the example programs.\n\nThe chapter’sﬁrst three sections cover the common case of saving and loading anentiredatacollectiontoandfromdisk. Theﬁrstsectionshowshowtodothis using binary ﬁle formats, with one subsection using (optionally compressed) pickles, and the other subsection showing how to do the work manually. The second section showshow to handle text ﬁles. Writing text is easy,but reading it back can be tricky if we need to handle nontextual data such as numbers and dates. We show two approaches to parsing text, doing it manually and using regular expressions. Thethirdsectionshowshow toread and writeXML ﬁles. This section covers writing and parsing using element trees,writing and parsing using the DOM (Document Object Model), and writing manually and parsing using SAX (Simple API for XML).\n\nThe fourth section shows how to handle random access binary ﬁles. This is useful when each data item is the same size and where we have more items than we want in (or can ﬁt into) memory.\n\nWhich is the best ﬁle format to use for holding entire collections—binary,text, or XML? Which isthe best way to handle each format? These questionsare too context-dependentto have a single deﬁnitiveanswer,especially since thereare\n\n287",
      "content_length": 2080,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 297,
      "content": "288\n\nChapter 7. File Handling\n\nName\n\nData Type Notes\n\nreport_id\n\nstr\n\nMinimum length 8 and no whitespace\n\ndate\n\ndatetime.date\n\nairport\n\nstr\n\nNonempty and no newlines\n\naircraft_id\n\nstr\n\nNonempty and no newlines\n\naircraft_type\n\nstr\n\nNonempty and no newlines\n\npilot_percent_hours_on_type\n\nfloat\n\nRange 0.0 to 100.0\n\npilot_total_hours\n\nint\n\nPositive and nonzero\n\nmidair\n\nbool\n\nnarrative\n\nstr\n\nMultiline\n\nFigure 7.1 Aircraft incident record\n\npros and cons for each format and for each way of handling them. We show all of them to help you make an informed decision on a case-by-case basis.\n\nBinary formats are usually very fast to save and load and they can be very compact. Binary data doesn’tneed parsing sinceeach data typeisstoredusing itsnaturalrepresentation. Binary data isnot human readableor editable,and without knowing the format in detail it is not possible to create separate tools to work with binary data.\n\nText formats are human readable and editable, and this can make text ﬁles easier to process with separate tools or to change using a text editor. Text formats can be tricky to parse and it is not always easy to give good error messages if a text ﬁle’s format is broken (e.g., by careless editing).\n\nXML formats are human readable and editable, although they tend to be verboseandcreatelargeﬁles. Liketextformats,XMLformatscanbeprocessed using separate tools. Parsing XML is straightforward (providing we use an XML parser rather than do it manually), and some parsers have good error reporting. XML parsers can be slow, so reading very large XML ﬁles can take a lot more time than reading an equivalent binary or text ﬁle. XML includes metadata such as the character encoding (either implicitly or explicitly) that is not often provided in text ﬁles, and this can make XML more portable than text ﬁles.\n\nText formats are usually the most convenient for end-users, but sometimes performance issues are such that a binary format is the only reasonable choice. However, it is always useful to provide import/export for XML since this makes it possible to process the ﬁle format with third-party tools without preventing the most optimal text or binary format being used by the program for normal processing.",
      "content_length": 2221,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 298,
      "content": "Chapter 7. File Handling\n\n289\n\nFormat\n\nReader/Writer\n\nReader + Writer Lines of Code\n\nTotal Lines of Code\n\nOutput File Size (~KB)\n\nBinary\n\nPickle (gzip compressed)\n\n20 + 16\n\n=\n\n36\n\n160\n\nBinary\n\nPickle\n\n20 + 16\n\n=\n\n36\n\n416\n\nBinary\n\nManual (gzip compressed)\n\n60 + 34\n\n=\n\n94\n\n132\n\nBinary\n\nManual\n\n60 + 34\n\n=\n\n94\n\n356\n\nPlain text Regex reader/manual writer\n\n39 + 28\n\n=\n\n67\n\n436\n\nPlain text Manual\n\n53 + 28\n\n=\n\n81\n\n436\n\nXML\n\nElement tree\n\n37 + 27\n\n=\n\n64\n\n460\n\nXML\n\nDOM\n\n44 + 36\n\n=\n\n80\n\n460\n\nXML\n\nSAX reader/manual writer\n\n55 + 37\n\n=\n\n92\n\n464\n\nFigure 7.2 Aircraft incident ﬁle format reader/writer comparison\n\nThis chapter’s ﬁrst three sections all use the same data collection: a set of air- craft incident records. Figure 7.1 shows the names, data types, and validation constraints that apply to aircraft incident records. It doesn’t really matter what data we are processing. The important thing is that we learn to process thefundamentaldatatypesincluding strings,integers,ﬂoating-pointnumbers, Booleans,and dates,sinceif we can handle these we can handle any other kind of data.\n\nBy using the same set of aircraft incident data for binary, text, and XML formats,it makesit possible to compare and contrast the different formatsand the code necessary for handling them. Figure 7.2showsthe number of lines of code for reading and writing each format, and the totals.\n\nThe ﬁle sizesare approximateand based on a particular sample of 596 aircraft incident records.★ Compressed binary ﬁle sizes for the same data saved under different ﬁlenames may vary by a few bytes since the ﬁlename is included in the compressed data and ﬁlename lengths vary. Similarly, the XML ﬁle sizes vary slightly since some XML writersuse entities (&quot; for \" and &apos; for ') for quotes inside text data, and others don’t.\n\nThe ﬁrst three sections all quote code from the same program: convert-inci- dents.py.This program is used to read aircraft incident data in one format and to writeit in another format. Hereistheprogram’sconsolehelptext. (Wehave reformatted the output slightly to ﬁt the book’s page width.)\n\nUsage: convert-incidents.py [options] infile outfile\n\n★ThedataweusedisbasedonrealaircraftincidentdataavailablefromtheFAA (U.S.government’s Federal Aviation Administration, www.faa.gov).",
      "content_length": 2274,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 299,
      "content": "290\n\nChapter 7. File Handling\n\nReads aircraft incident data from infile and writes the data to outfile. The data formats used depend on the file extensions: .aix is XML, .ait is text (UTF-8 encoding), .aib is binary, .aip is pickle, and .html is HTML (only allowed for the outfile). All formats are platform-independent.\n\nOptions: -h, --help show this help message and exit -f, --force write the outfile even if it exists [default: off] -v, --verbose report results [default: off] -r READER, --reader=READER reader (XML): 'dom', 'd', 'etree', 'e', 'sax', 's' reader (text): 'manual', 'm', 'regex', 'r' [default: etree for XML, manual for text] -w WRITER, --writer=WRITER writer (XML): 'dom', 'd', 'etree', 'e', 'manual', 'm' [default: manual] -z, --compress compress .aib/.aip outfile [default: off] -t, --test execute doctests and exit (use with -v for verbose)\n\nThe options are more complex than would normally be required since an end-user will not care which reader or writer we use for any particular format. In a more realistic version of the program the reader and writer options would not exist and we would implement just one reader and one writer for each format. Similarly, the test option exists to help us test the code and would not be present in a production version.\n\nThe program deﬁnes one custom exception:\n\nclass IncidentError(Exception): pass\n\nAircraft incidents are held as Incident objects. Here is the class line and the initializer:\n\nclass Incident:\n\ndef __init__(self, report_id, date, airport, aircraft_id,\n\naircraft_type, pilot_percent_hours_on_type, pilot_total_hours, midair, narrative=\"\"):\n\nassert len(report_id) >= 8 and len(report_id.split()) == 1, \\\n\n\"invalid report ID\"\n\nself.__report_id = report_id self.date = date self.airport = airport self.aircraft_id = aircraft_id self.aircraft_type = aircraft_type self.pilot_percent_hours_on_type = pilot_percent_hours_on_type",
      "content_length": 1902,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 300,
      "content": "Chapter 7. File Handling\n\nself.pilot_total_hours = pilot_total_hours self.midair = midair self.narrative = narrative\n\nThe report ID is validated when the Incident is created and is available as the read-only report_id property. All the other data attributes are read/write properties. For example, here is the date property’s code:\n\n@property def date(self):\n\nreturn self.__date\n\n@date.setter def date(self, date):\n\nassert isinstance(date, datetime.date), \"invalid date\" self.__date = date\n\nAll the other properties follow the same pattern, differing only in the details of their assertions, so we won’t reproduce them here. Since we have used assertions, the program will fail if an attempt is made to create an Incident with invalid data,or to set one of an existing incident’sread/writepropertiesto an invalid value. We have chosen this uncompromising approach because we want to be sure that the data we save and load is alwaysvalid,and if it isn’t we want the program to terminate and complain rather than silently continue.\n\nThe collection of incidents is held as an IncidentCollection. This class is a dict subclass, so we get a lot of functionality, such as support for the item access operator ([]) to get, set, and delete incidents, by inheritance. Here is the class line and a few of the class’s methods:\n\nclass IncidentCollection(dict):\n\ndef values(self):\n\nfor report_id in self.keys(): yield self[report_id]\n\ndef items(self):\n\nfor report_id in self.keys():\n\nyield (report_id, self[report_id])\n\ndef __iter__(self):\n\nfor report_id in sorted(super().keys()):\n\nyield report_id\n\nkeys = __iter__\n\nWe have not needed to reimplement the initializer since dict.__init__() is sufﬁcient. The keys are report IDs and the values are Incidents. We have reimplementedthe values(),items(),and keys() methodssothattheir iterators\n\n291",
      "content_length": 1830,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 302,
      "content": "str. trans- late() 77➤\n\nWriting and Reading Binary Data\n\nThe Bytes and Bytearray Data Types\n\nPython provides two data types for handling raw bytes: bytes which is im- mutable,and bytearray whichismutable. Bothtypesholda sequenceof zero or more 8-bit unsigned integers (bytes) with each byte in the range 0…255.\n\nBoth types are very similar to strings and provide many of the same methods, including support for slicing. In addition, bytearrays also provide some mutating list-like methods. All their methods are listed in Tables 7.1 (➤ 299) and\n\n7.2 (➤ 300).\n\nWhereas a slice of a bytes or bytearray returns an object of the same type, accessing a single byte using the item access operator ([]) returns an int—the value of the speciﬁed byte. For example:\n\nword = b\"Animal\" x = b\"A\" # returns: False word[0] == x word[:1] == x # returns: True word[0] == x[0] # returns: True\n\n# word[0] == 65; x == b\"A\" # word[:1] == b\"A\"; x == b\"A\" # word[0] == 65;\n\nx[0] == 65\n\nHere are some other bytes and bytearray examples:\n\ndata = b\"5 Hills \\x35\\x20\\x48\\x69\\x6C\\x6C\\x73\" data.upper() data.replace(b\"ill\", b\"at\") bytes.fromhex(\"35 20 48 69 6C 6C 73\") # returns: b'5 Hills' # returns: b'5 Hills' bytes.fromhex(\"352048696C6C73\") # data is now a bytearray data = bytearray(data) # returns: 72 (ord(\"H\")) data.pop(10) # data == b'5 Hills 5 Bills' data.insert(10, ord(\"B\"))\n\n# returns: b'5 HILLS 5 HILLS' # returns: b'5 Hats 5 Hats'\n\nMethods that make sense only for strings, such as bytes.upper(), assume that the bytes are encoded using ASCII. The bytes.fromhex() class method ignoreswhitespaceandinterpretseachtwo-digitsubstringasahexadecimal number, so \"35\" is taken to be a byte of value 0x35, and so on.\n\npickle.dump(self, fh, pickle.HIGHEST_PROTOCOL) return True\n\nexcept (EnvironmentError, pickle.PicklingError) as err:\n\nprint(\"{0}: export error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nfinally:\n\nif fh is not None: fh.close()\n\n293",
      "content_length": 1948,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 303,
      "content": "294\n\nChapter 7. File Handling\n\nIf compression has been requested, we use the gzip module’s gzip.open() function to open the ﬁle; otherwise, we use the built-in open() function. We must use “write binary” mode (\"wb\") when pickling data in binary format. In Python 3.0 and 3.1, pickle.HIGHEST_PROTOCOL is protocol 3, a compact binary pickle format. This is the best protocol to use for data shared among Python 3 programs.★\n\nFor error handling we have chosen to report errors to the user as soon as they occur, and to return a Boolean to the caller indicating success or failure. And wehaveuseda finally block toensurethattheﬁleisclosedat theend,whether there was an error or not. In Chapter 8 we will use a more compact idiom to ensure that ﬁles are closed that avoids the need for a finally block.\n\nThis code is very similar to what we saw in the preceding chapter, but there is one subtle point to note. The pickled data is self, a dict. But the dictionary’s valuesare Incident objects,thatis,objectsof a customclass. Thepicklemodule is smart enough to be able to save objects of most custom classes without us needing to intervene.\n\nIn general, Booleans, numbers, and strings can be pickled, as can instances of __dict__ is picklable. classes including custom classes, providing their private In addition, any built-in collection types (tuples, lists, sets, dictionaries) can be pickled, providing they contain only picklable objects (including collection types, so recursive structures are supported).It is also possible to pickle other kinds of objects or instances of custom classes that can’t normally be pickled (e.g., because they have a nonpicklable attribute), either by giving some help to the pickle module or by implementing custom pickle and unpickle functions. All the relevant details are provided in the pickle module’s online documen- tation.\n\nToreadback thepickleddataweneedtodistinguishbetweena compressedand an uncompressed pickle. Any ﬁle that is compressed using gzip compression begins with a particular magic number. A magic number is a sequence of one or more bytes at the beginning of a ﬁle that is used to indicate the ﬁle’s type. For gzip ﬁles the magic number is the two bytes 0x1F 0x8B, which we store in a bytes variable:\n\nGZIP_MAGIC = b\"\\x1F\\x8B\"\n\nFor more about the bytes data type, see the sidebar “The Bytes and Bytearray Data Types” (293 ➤), and Tables 7.1, 7.2, and 7.3 (➤ 299–301), which list their methods.\n\nHere is the code for reading an incidents pickle ﬁle:\n\n★Protocol 3isPython3-speciﬁc. If wewant picklesthat arereadableandwritableby both Python2 and Python 3 programs,we must use protocol 2 instead. Note,though,that protocol 2 ﬁles written by Python 3.1 can be read by Python 3.1 and Python 2.x, but not by Python 3.0!\n\nContext man- agers ➤ 369\n\n__dict__ ➤ 363\n\n3.x",
      "content_length": 2813,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 304,
      "content": "Writing and Reading Binary Data\n\ndef import_pickle(self, filename):\n\nfh = None try:\n\nfh = open(filename, \"rb\") magic = fh.read(len(GZIP_MAGIC)) if magic == GZIP_MAGIC:\n\nfh.close() fh = gzip.open(filename, \"rb\")\n\nelse:\n\nfh.seek(0)\n\nself.clear() self.update(pickle.load(fh)) return True\n\nexcept (EnvironmentError, pickle.UnpicklingError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nfinally:\n\nif fh is not None: fh.close()\n\nWe don’t know whether the given ﬁle is compressed. In either case we begin by opening the ﬁle in “read binary” mode,and then we read the ﬁrst two bytes. If these bytes are the same as the gzip magic number we close the ﬁle and create a new ﬁle object using the gzip.open() function. And if the ﬁle is not compressed we use the ﬁle object returned by open(), calling its seek() method to restore the ﬁle pointer to the beginning so that the next read (made inside the pickle.load() function) will be from the start.\n\nWe can’t assign to self since that would wipe out the IncidentCollection object that isin use,soinsteadweclear alltheincidentstomakethedictionary empty and then use dict.update() to populate the dictionary with all the incidents from the IncidentCollection dictionary loaded from the pickle.\n\nNote that it does not matter whether the processor’s byte ordering is big- or little-endian, because for the magic number we read individual bytes, and for the data the pickle module handles endianness for us.\n\nRaw Binary Data with Optional Compression\n\nWriting our own code to handle raw binary data gives us complete control over our ﬁle format. It should also be safer than using pickles, since mali- ciously invalid data will be handled by our code rather than executed by the interpreter.\n\n295\n\n||",
      "content_length": 1789,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 305,
      "content": "Char- acter encod- ings 91➤\n\n296\n\nChapter 7. File Handling\n\nWhen creating custom binary ﬁle formats it is wise to create a magic number to identify your ﬁle type, and a version number to identify the version of the ﬁle format in use. Here are the deﬁnitions used in the convert-incidents.py program:\n\nMAGIC = b\"AIB\\x00\" FORMAT_VERSION = b\"\\x00\\x01\"\n\nWe have used four bytes for the magic number and two for the version. Endianness is not an issue because these will be written as individual bytes, not as the byte representations of integers, so they will always be the same on any processor architecture.\n\nTo write and read raw binary data we must have some means of converting Python objects to and from suitable binary representations. Most of the func- tionality weneedisprovidedby thestruct module,brieﬂy describedintheside- bar “The Struct Module” (➤ 297), and by the bytes and bytearray data types, brieﬂy describedin the sidebar “TheBytesand Bytearray Data Types”(293➤). The bytes and bytearray classes’ methods are listed in Tables 7.1 (➤ 299) and 7.2 (➤ 300).\n\nUnfortunately,the struct module can handle stringsonly of a speciﬁed length, and we need variable length strings for the report and aircraft IDs, as well as for the airport,the aircraft type,and the narrative texts. To meet this need we havecreateda function,pack_string(),which takesa string andreturnsa bytes object which containstwo components:The ﬁrst isan integer length count,and the second isa sequenceof length count UTF-8encoded bytesrepresenting the string’s text.\n\nSince the only place the pack_string() function is needed is inside the ex- port_binary() function, we have put the deﬁnition of pack_string() inside the export_binary() function. This means that pack_string() is not visible outside the export_binary() function,and makesclear that it is just a local helper func- tion. Here is the start of the export_binary() function,and the completenested pack_string() function:\n\ndef export_binary(self, filename, compress=False):\n\ndef pack_string(string):\n\ndata = string.encode(\"utf8\") format = \"<H{0}s\".format(len(data)) return struct.pack(format, len(data), data)\n\nThe str.encode() method returnsa bytes object with the string encoded accord- ing to the speciﬁed encoding. UTF-8 is a very convenient encoding because it can represent any Unicode character and is especially compact when repre- senting ASCII characters(just one byte each).The format variable isset to hold a struct format based on the string’s length. For example, given the string\n\nLocal func- tions ➤ 351",
      "content_length": 2561,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 306,
      "content": "Writing and Reading Binary Data\n\nThe Struct Module\n\nThe struct module provides struct.pack(), struct.unpack(), and some other functions, and the struct.Struct() class. The struct.pack() function takes a struct format string and one or more values and returns a bytes object that holds all the values represented in accordance with the format. The struct.unpack() function takes a format and a bytes or bytearray object and returns a tuple of the values that were originally packed using the format. For example:\n\ndata = struct.pack(\"<2h\", 11, -9) items = struct.unpack(\"<2h\", data) # items == (11, -9)\n\n# data == b'\\x0b\\x00\\xf7\\xff'\n\nFormatstringsconsistof oneor morecharacters. Mostcharactersrepresent a value of a particular type. If we need more than one value of a type we can either write the character as many times as there are values of the type (\"hh\"), or precede the character with a count as we have done here (\"2h\").\n\nMany format characters are described in the struct module’s online docu- mentation, including “b” (8-bit signed integer), “B” (8-bit unsigned integer), “h” (16-bit signed integer—used in the examples here),“H” (16-bit unsigned integer), “i” (32-bit signed integer), “I” (32-bit unsigned integer), “q” (64-bit signed integer), “Q” (64-bit unsigned integer), “f” (32-bit ﬂoat), “d” (64-bit ﬂoat—this corresponds to Python’s float type), “?” (Boolean), “s” (bytes or bytearray object—byte strings), and many others.\n\nFor some data types such as multibyte integers, the processor’s endianness makes a difference to the byte order. We can force a particular byte order to be used regardless of the processor architecture by starting the format string with an endianness character. In this book we always use “<”, which means little-endian since that’s the native endianness for the widely used Intel and AMD processors. Big-endian (also called network byte order) is signiﬁedby “>”(or by “!”).If noendiannessisspeciﬁedthemachine’sendian- ness is used. We recommend always specifying the endianness even if it is the same as the machine being used since doing so keeps the data portable.\n\nThe struct.calcsize() function takes a format and returns how many bytes a structusing theformatwilloccupy. A formatcanalsobestoredby creating a struct.Struct() object giving it the format as its argument, with the size of the struct.Struct() object given by its size attribute. For example:\n\nTWO_SHORTS = struct.Struct(\"<2h\") data = TWO_SHORTS.pack(11, -9) items = TWO_SHORTS.unpack(data)\n\n# data == b'\\x0b\\x00\\xf7\\xff' # items == (11, -9)\n\nIn both examples,11 is0x000b,but thisistransformedintothebytes0x0b 0x00 because we have used little-endian byte ordering.\n\n297",
      "content_length": 2681,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 307,
      "content": "298\n\nChapter 7. File Handling\n\n“en.wikipedia.org”, the format will be \"<H16s\" (little-endian byte order, 2-byte unsigned integer,16-bytebytestring),and the bytes object that isreturnedwill be b'\\x10\\x00en.wikipedia.org'. Conveniently, Python shows bytes objects in a compact form using printable ASCII characters where possible, and hexadeci- mal escapes (and some special escapes like \\t and \\n) otherwise.\n\nThe pack_string() function can handle strings of up to 65535 UTF-8 charac- ters. We could easily switch to using a different kind of integer for the byte count; for example, a 4-byte signed integer (format “i”) would allow for strings of up to 231-1 (more than 2 billion) characters.\n\nThe struct module does provide a similar built-in format,“p”,that stores a sin- gle byte as a character count followed by up to 255 characters. For packing, the code using “p” format is slightly simpler than doing all the work ourselves. But “p” format restricts us to a maximum of 255 UTF-8 characters and pro- videsalmost no beneﬁt when unpacking. (For thesakeof comparison,versions of pack_string() and unpack_string() that use “p” format are included in the convert-incidents.py source ﬁle.)\n\nWe can now turn our attention to the rest of the code in the export_binary() method.\n\nfh = None try:\n\nif compress:\n\nfh = gzip.open(filename, \"wb\")\n\nelse:\n\nfh = open(filename, \"wb\")\n\nfh.write(MAGIC) fh.write(FORMAT_VERSION) for incident in self.values():\n\ndata = bytearray() data.extend(pack_string(incident.report_id)) data.extend(pack_string(incident.airport)) data.extend(pack_string(incident.aircraft_id)) data.extend(pack_string(incident.aircraft_type)) data.extend(pack_string(incident.narrative.strip())) data.extend(NumbersStruct.pack(\n\nincident.date.toordinal(), incident.pilot_percent_hours_on_type, incident.pilot_total_hours, incident.midair))\n\nfh.write(data)\n\nreturn True",
      "content_length": 1874,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 308,
      "content": "Char- acter encod- ings 91➤\n\nWriting and Reading Binary Data\n\nTable 7.1 Bytes and Bytearray Methods #1\n\nSyntax\n\nDescription\n\nba.append(i)\n\nAppends int i (in range 0…255) to bytearray ba\n\nb.capitalize()\n\nReturns a copy of bytes/bytearray b with the ﬁrst charac- ter capitalized (if it is an ASCII letter)\n\nb.center(width,\n\nbyte)\n\nReturns a copy of b centered in length width padded with spaces or optionally with the given byte\n\nb.count(x,\n\nstart, end)\n\nReturnsthenumber of occurrencesof bytes/bytearray x in bytes/bytearray b (or in the start:end slice of b)\n\nb.decode(\n\nencoding, error)\n\nReturns a str object that represents the bytes using the UTF-8 encoding or using the speciﬁed encoding and han- dling errors according to the optional error argument\n\nb.endswith(x,\n\nstart, end)\n\nReturns True if b (or the start:end slice of b) ends with bytes/bytearray x or with any of the bytes/bytearrays in tuple x; otherwise, returns False\n\nb.expandtabs( size)\n\nReturns a copy of bytes/bytearray b with tabs replaced with spaces in multiples of 8 or of size if speciﬁed\n\nba.extend(seq)\n\nExtends bytearray ba with all the ints in sequence seq; all the ints must be in the range 0…255\n\nb.find(x,\n\nstart, end)\n\nReturns the leftmost position of bytes/bytearray x in b (or in the start:end slice of b) or -1 if not found. Use the rfind() method to ﬁnd the rightmost position.\n\nb.fromhex(h)\n\nReturns a bytes object with bytes corresponding to the hexadecimal integers in str h\n\nb.index(x,\n\nstart, end)\n\nReturns the leftmost position of x in b (or in the start:end slice of b) or raises ValueError if not found. Use the rindex() method to ﬁnd the rightmost position.\n\nba.insert(p, i)\n\nInserts integer i (in range 0…255) at position p in ba\n\nb.isalnum()\n\nReturns True if bytes/bytearray b is nonempty and every character in b is an ASCII alphanumeric character\n\nb.isalpha()\n\nReturns True if bytes/bytearray b is nonempty and every character in b is an ASCII alphabetic character\n\nb.isdigit()\n\nReturns True if bytes/bytearray b is nonempty and every character in b is an ASCII digit\n\nb.islower()\n\nb.isspace()\n\nReturns True if bytes/bytearray b has at least one lower- caseable ASCII character and all its lowercaseable char- acters are lowercase Returns True if bytes/bytearray b is nonempty and every character in b is an ASCII whitespace character\n\n299",
      "content_length": 2338,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 309,
      "content": "300\n\nChapter 7. File Handling\n\nTable 7.2 Bytes and Bytearray Methods #2\n\nSyntax\n\nDescription\n\nb.istitle()\n\nReturns True if b is nonempty and title-cased\n\nb.isupper()\n\nReturnsTrue if b hasat least one uppercaseableASCIIchar- acter and all its uppercaseable characters are uppercase\n\nb.join(seq)\n\nReturns the concatenation of every bytes/bytearray in se- quence seq, with b (which may be empty) between each one\n\nb.ljust(\n\nwidth, byte)\n\nReturns a copy of bytes/bytearray b left-aligned in length width padded with spaces or optionally with the given byte. Use the rjust() method to right-align.\n\nb.lower()\n\nReturns an ASCII-lowercased copy of bytes/bytearray b\n\nb.partition( sep)\n\nReturns a tuple of three bytes objects—the part of b before the leftmost bytes/bytearray sep, sep itself, and the part of b after sep; or if sep isn’t in b returns b and two empty bytes objects. Use the rpartition() method to partition on the rightmost occurrence of sep.\n\nba.pop(p)\n\nRemoves and returns the int at index position p in ba\n\nba.remove(i)\n\nRemoves the ﬁrst occurrence of int i from bytearray ba\n\nb.replace(x, y, n)\n\nReturns a copy of b with every (or a maximum of n if given) occurrence of bytes/bytearray x replaced with y\n\nba.reverse()\n\nReverses bytearray ba’s bytes in-place\n\nb.split(x, n) Returnsa list of bytes splitting atmost n timeson x.If n isn’t\n\ngiven, splits everywhere possible; if x isn’t given, splits on whitespace. Use rsplit() to split from the right.\n\nb.splitlines(\n\nf)\n\nReturns the list of lines produced by splitting b on line terminators, stripping the terminators unless f is True\n\nb.startswith( x, start, end)\n\nReturns True if bytes/bytearray b (or the start:end slice of b) starts with bytes/bytearray x or with any of the bytes/bytearrays in tuple x; otherwise, returns False\n\nb.strip(x)\n\nReturnsa copy of b with leading and trailing whitespace(or the bytes in bytes/bytearray x) removed; lstrip() strips only at the start, and rstrip() strips only at the end\n\nb.swapcase()\n\nReturnsa copy of b with uppercase ASCII characterslower- cased and lowercase ASCII characters uppercased\n\nb.title()\n\nReturnsa copy of b wheretheﬁrstASCIIletterof eachword is uppercased and all other ASCII letters are lowercased\n\nb.translate(\n\nbt, d)\n\nReturnsa copy of b that hasno bytesfrom d,and whereeach other byte is replaced by the byte-th byte from bytes bt",
      "content_length": 2356,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 310,
      "content": "Writing and Reading Binary Data\n\nTable 7.3 Bytes and Bytearray Methods #3\n\nSyntax\n\nDescription\n\nb.upper()\n\nReturns an ASCII-uppercased copy of bytes/bytearray b\n\nb.zfill(w) Returns a copy of b, which if shorter than w is padded with\n\nleading zeros (0x30 characters) to make it w bytes long\n\nWe have omitted the except and finally blocks since they are the same as the ones shown in the preceding subsection, apart from the particular exceptions that the except block catches.\n\nWe begin by opening the ﬁle in “write binary” mode, either a normal ﬁle or a gzip compressed ﬁle depending on the compress ﬂag. We then write the 4-byte magicnumber that is(hopefully)uniquetoour program,andthe2-byteversion number.★ Using a version number makes it easier to change the format in the future—when we read the version number we can use it to determine which code to use for reading.\n\nNext we iterate over all the incidents, and for each one we create a bytearray. We add each item of data to the byte array, starting with the variable length strings. The date.toordinal() method returns a single integer representing the stored date; the date can be restored by passing this integer to the date- time.date.fromordinal() method. The NumbersStruct is deﬁned earlier in the program with this statement:\n\nNumbersStruct = struct.Struct(\"<Idi?\")\n\nThis format speciﬁes little-endian byte order, an unsigned 32-bit integer (for the date ordinal), a 64-bit ﬂoat (for the percentage hours on type), a 32-bit in- teger (for the total hours ﬂown), and a Boolean (for whether the incident was midair).The structure of an entire aircraft incident record is shown schemati- cally in Figure 7.3.\n\nOnce the bytearray has all the data for one incident, we write it to disk. And once all the incidents have been written we return True (assuming no error oc- curred).The finally block ensures that the ﬁle is closed just before we return.\n\nReading back the data is not as straightforward as writing it—for one thing we have more error checking to do. Also, reading back variable length strings is slightly tricky. Here is the start of the import_binary() method and the complete nested unpack_string() function that we use to read back the variable length strings:\n\n★There is no central repository for magic numbers like there is for domain names,so we can never guarantee uniqueness.\n\n301",
      "content_length": 2359,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 311,
      "content": "302\n\nChapter 7. File Handling\n\nd i _ t r o p e r\n\nstring\n\nt r o p r i a\n\nstring\n\nd i _ t f a r c r i a\n\nstring\n\ne p y t _ t f a r c r i a\n\nstring\n\ne v i t a r r a n\n\nstring\n\ne t a d\n\nuint32\n\n_ t n e c r e p _ t o l i p\n\ne p y t _ n o _ s r u o h float64\n\n_ l a t o t _ t o l i p\n\ns r u o h int32\n\nr i a d i m\n\nbool\n\nuint16\n\nUTF-8 encoded bytes...\n\nFigure 7.3 The structure of a binary aircraft incident record\n\ndef import_binary(self, filename):\n\ndef unpack_string(fh, eof_is_error=True):\n\nuint16 = struct.Struct(\"<H\") length_data = fh.read(uint16.size) if not length_data:\n\nif eof_is_error:\n\nraise ValueError(\"missing or corrupt string size\")\n\nreturn None\n\nlength = uint16.unpack(length_data)[0] if length == 0:\n\nreturn \"\"\n\ndata = fh.read(length) if not data or len(data) != length:\n\nraise ValueError(\"missing or corrupt string\")\n\nformat = \"<{0}s\".format(length) return struct.unpack(format, data)[0].decode(\"utf8\")\n\nSince each incident record beginswith itsreport IDstring,when we attempt to read this string and we succeed, we are at the start of a new record. But if we fail, we’ve reached the end of the ﬁle and can ﬁnish. We set the eof_is_error ﬂag to False when attempting to read a report ID since if there is no data, it just meanswe have ﬁnished. For all other stringswe accept the default of True because if any other string has no data, it is an error. (Even an empty string will be preceded by a 16-bit unsigned integer length.)\n\nWe begin by attempting to read the string’s length. If this fails we return None to signify end of ﬁle (if we are attempting to read a new incident), or we raise a ValueError exceptiontoindicatecorruptor missing data. The struct.unpack() function and the struct.Struct.unpack() method always return a tuple, even if it contains only a single value. We unpack the length data and store the number it representsin the length variable. Now we know how many byteswe",
      "content_length": 1905,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 312,
      "content": "Writing and Reading Binary Data\n\nmust read to get the string. If the length is zero we simply return an empty string. Otherwise, we attempt to read the speciﬁed number of bytes. If we don’t get any data or if the data is not the size we expected (i.e., it is too little), we raise a ValueError exception.\n\nIf we have the right number of bytes we create a suitable format string for the struct.unpack() function,and we return thestring that resultsfromunpacking the data and decoding the bytes as UTF-8. (In theory, we could replace the last two lines with return data.decode(\"utf8\"), but we prefer to go through the unpacking process since it is possible—though unlikely—that the “s” format performs some transformation on our data which must be reversed when reading back.)\n\nWe will now look at therest of the import_binary() method,breaking it intotwo parts for ease of explanation.\n\nfh = None try:\n\nfh = open(filename, \"rb\") magic = fh.read(len(GZIP_MAGIC)) if magic == GZIP_MAGIC:\n\nfh.close() fh = gzip.open(filename, \"rb\")\n\nelse:\n\nfh.seek(0)\n\nmagic = fh.read(len(MAGIC)) if magic != MAGIC:\n\nraise ValueError(\"invalid .aib file format\")\n\nversion = fh.read(len(FORMAT_VERSION)) if version > FORMAT_VERSION:\n\nraise ValueError(\"unrecognized .aib file version\")\n\nself.clear()\n\nThe ﬁle may or may not be compressed, so we use the same technique that we used for reading pickles to open the ﬁle using gzip.open() or the built-in open() function.\n\nOnce the ﬁle is open and we are at the beginning, we read the ﬁrst four bytes (len(MAGIC)). If these don’t match our magic number we know that it isn’t a binary aircraft incident data ﬁle and so we raise a ValueError exception. Next we read in the 2-byte version number. It is at this point that we would use different reading code depending on the version. Here we just check that the version isn’t a later one than this program is able to read.\n\nIf the magic number is correct and the version is one we can handle, we are ready to read in the data, so we begin by clearing out all the existing incidents so that the dictionary is empty.\n\n303",
      "content_length": 2088,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 313,
      "content": "Map- ping unpack- ing 179➤\n\n304\n\nChapter 7. File Handling\n\nwhile True:\n\nreport_id = unpack_string(fh, False) if report_id is None:\n\nbreak data = {} data[\"report_id\"] = report_id for name in (\"airport\", \"aircraft_id\",\n\n\"aircraft_type\", \"narrative\"):\n\ndata[name] = unpack_string(fh)\n\nother_data = fh.read(NumbersStruct.size) numbers = NumbersStruct.unpack(other_data) data[\"date\"] = datetime.date.fromordinal(numbers[0]) data[\"pilot_percent_hours_on_type\"] = numbers[1] data[\"pilot_total_hours\"] = numbers[2] data[\"midair\"] = numbers[3] incident = Incident(**data) self[incident.report_id] = incident\n\nreturn True\n\nThe while block loopsuntilwerunoutof data. Westartby trying togeta report ID.If weget None we’vereachedtheendof theﬁleand canbreak out of theloop. Otherwise, we create a dictionary called data to hold the data for one incident and attempt to get the rest of the incident’s data. For the strings we use the unpack_string() method, and for the other data we read it all in one go using the NumbersStruct struct. Since we stored the date as an ordinal we must do the reverse conversion to get a date back. But for the other items, we can just use the unpacked data—no validation or conversion is required since we wrote the correct data typesin the ﬁrst place and have read back the same data types using the format held in the NumbersStruct struct.\n\nIf any error occurs, for example, if we fail to unpack all the numbers, an exception will be raised and will be handled in the except block. (We haven’t shown the except and finally blocks because they are structurally the same as those shown in the preceding subsection for the import_pickle() method.)\n\nToward the end we make use of the convenient mapping unpacking create an Incident object which we then store in the incidents dictionary.\n\nsyntax to\n\nApart from the handling of variable length strings, the struct module makes it very easy to save and load data in binary format. And for variable length strings the pack_string() and unpack_string() methods shown here should serve most purposes perfectly well.",
      "content_length": 2076,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 314,
      "content": "Writing and Parsing Text Files\n\nWriting and Parsing Text Files\n\nWriting text is easy, but reading it back can be problematic, so we need to choose the structure carefully so that it is not too difﬁcult to parse.★ Figure 7.4 shows an example aircraft incident record in the text format we are going to use. When we write the incident records to a ﬁle we will follow each one with a blank line, but when we parse the ﬁle we will accept zero or more blank lines between incident records.\n\nWriting Text\n\nEach incident record beginswith the report IDenclosed in brackets([]).Thisis followedby alltheone-linedataitemswritteninkey=valueform. Forthemulti- line narrative text we precede the text with a start marker (.NARRATIVE_START.) and follow it with an end marker (.NARRATIVE_END.), and we indent all the text in between to ensure that no line of text could be confused with a start or end marker.\n\n[20070927022009C] date=2007-09-27 aircraft_id=1675B aircraft_type=DHC-2-MK1 airport=MERLE K (MUDHOLE) SMITH pilot_percent_hours_on_type=46.1538461538 pilot_total_hours=13000 midair=0 .NARRATIVE_START. ACCORDING TO THE PILOT, THE DRAG LINK FAILED DUE TO AN OVERSIZED TAIL WHEEL TIRE LANDING ON HARD SURFACE. .NARRATIVE_END.\n\nFigure 7.4 An example text format aircraft incident record\n\nHere is the code for the export_text() function, but excluding the except and finally blocks since they are the same as ones we have seen before, except for the exceptions handled:\n\ndef export_text(self, filename):\n\nwrapper = textwrap.TextWrapper(initial_indent=\"\n\n\",\n\nsubsequent_indent=\"\n\n\")\n\n★Chapter 14 introducesvariousparsing techniques,including two third-party open source parsing modules that make parsing tasks much easier.\n\n305\n\n|||\n\n||",
      "content_length": 1726,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 315,
      "content": "datetime module 216➤\n\nstr. format() 78➤\n\n__for- mat__() 254➤\n\n306\n\nChapter 7. File Handling\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") for incident in self.values():\n\nnarrative = \"\\n\".join(wrapper.wrap(\n\nincident.narrative.strip()))\n\nfh.write(\"[{0.report_id}]\\n\" \"date={0.date!s}\\n\" \"aircraft_id={0.aircraft_id}\\n\" \"aircraft_type={0.aircraft_type}\\n\" \"airport={airport}\\n\" \"pilot_percent_hours_on_type=\" \"{0.pilot_percent_hours_on_type}\\n\" \"pilot_total_hours={0.pilot_total_hours}\\n\" \"midair={0.midair:d}\\n\" \".NARRATIVE_START.\\n{narrative}\\n\" \".NARRATIVE_END.\\n\\n\".format(incident,\n\nairport=incident.airport.strip(), narrative=narrative))\n\nreturn True\n\nThe line breaks in the narrative text are not signiﬁcant, so we can wrap the text as we like. Normally we would use the textwrap module’s textwrap.wrap() function, but here we need to both indent and wrap, so we begin by creating a textwrap.TextWrap object, initialized with the indentation we want to use (four spaces for the ﬁrst and subsequent lines).By default,the object will wrap lines to a width of 70 characters, although we can change this by passing another keyword argument.\n\nWe could have written this using a triple quoted string, but we prefer to put in the newlines manually. The textwrap.TextWrapper object provides a wrap() method that takesa string asinput,in thiscase the narrativetext,and returns a list of strings with suitable indentation and each no longer than the wrap width. We then join this list of lines into a single string using newline as the separator.\n\nheld as a datetime.date object;we have forced str.format() The incident date is to use the string representation when writing the date—this very conve- niently produces the date in ISO 8601, YYYY-MM-DD format. We have told str.format() to write the midair bool as an integer—this produces 1 for True and 0 for False.In general,using str.format() makeswriting text very easy be- cause it handles all of Python’s data types (and custom types if we implement the __str__() or __format__() special method) automatically.",
      "content_length": 2072,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 316,
      "content": "Writing and Parsing Text Files\n\n307\n\nParsing Text\n\n||\n\nThe method for reading and parsing text format aircraft incident records is longer and more involved than the one used for writing. When reading the ﬁle we could be in one of several states. We could be in the middle of reading narrative lines; we could be at a key=value line; or we could be at a report ID line at the start of a new incident. We will look at the import_text_manual() method in ﬁve parts.\n\ndef import_text_manual(self, filename):\n\nfh = None try:\n\nfh = open(filename, encoding=\"utf8\") self.clear() data = {} narrative = None\n\nThe method begins by opening the ﬁle in “read text” mode. Then we clear the dictionary of incidents and create the data dictionary to hold the data for a single incident in the same way as we did when reading binary incident records. The narrative variable is used for two purposes: as a state indicator and to store the current incident’s narrative text. If narrative is None it means that we are not currently reading a narrative; but if it is a string (even an empty one) it means we are in the process of reading narrative lines.\n\nfor lino, line in enumerate(fh, start=1):\n\nline = line.rstrip() if not line and narrative is None:\n\ncontinue\n\nif narrative is not None:\n\nif line == \".NARRATIVE_END.\":\n\ndata[\"narrative\"] = textwrap.dedent(\n\nnarrative).strip()\n\nif len(data) != 9:\n\nraise IncidentError(\"missing data on \"\n\n\"line {0}\".format(lino))\n\nincident = Incident(**data) self[incident.report_id] = incident data = {} narrative = None\n\nelse:\n\nnarrative += line + \"\\n\"\n\nSince we are reading line by line we can keep track of the current line number and use this to provide more informative error messagesthan is possible when reading binary ﬁles. We begin by stripping off any trailing whitespace from",
      "content_length": 1801,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 317,
      "content": "308\n\nChapter 7. File Handling\n\nthe line, and if this leaves us with an empty line (and providing we are not in the middleof a narrative),we simply skipto the next line. Thismeansthat the number of blank lines between incidents doesn’t matter, but that we preserve any blank lines that are in narrative texts.\n\nIf the narrative is not None we know that we are in a narrative. If the line is the narrative end marker we know that we have not only ﬁnished reading the narrative, but also ﬁnished reading all the data for the current incident. In this case we put the narrative text into the data dictionary (having removed the indentation with the textwrap.dedent() function), and providing we have the nine pieces of data we need, we create a new incident and store it in the dictionary. Then we clear the data dictionary and reset the narrative variable ready for the next record. On the other hand, if the line isn’t the narrative end marker, we append it to the narrative—including the newline that was stripped off at the beginning.\n\nelif (not data and line[0] == \"[\"\n\nand line[-1] == \"]\"):\n\ndata[\"report_id\"] = line[1:-1]\n\nIf the narrative is None then we are at either a new report ID or are reading some other data. We could be at a new report ID only if the data dictionary is empty (because it starts that way and because we clear it after reading each incident), and if the line begins with [ and ends with ]. If this is the case we put the report ID into the data dictionary. This means that this elif condition will not be True again until the data dictionary is next cleared.\n\nelif \"=\" in line:\n\nkey, value = line.split(\"=\", 1) if key == \"date\":\n\ndata[key] = datetime.datetime.strptime(value,\n\n\"%Y-%m-%d\").date()\n\nelif key == \"pilot_percent_hours_on_type\":\n\ndata[key] = float(value) elif key == \"pilot_total_hours\":\n\ndata[key] = int(value)\n\nelif key == \"midair\":\n\ndata[key] = bool(int(value))\n\nelse:\n\ndata[key] = value elif line == \".NARRATIVE_START.\":\n\nnarrative = \"\"\n\nelse:\n\nraise KeyError(\"parsing error on line {0}\".format(\n\nlino))",
      "content_length": 2046,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 318,
      "content": "Writing and Parsing Text Files\n\nIf we are not in a narrative and are not reading a new report ID there are only three more possibilities:We are reading key=valueitems,we are at a narrative start marker, or something has gone wrong.\n\nIn the case of reading a line of key=value data, we split the line on the ﬁrst = character, specifying a maximum of one split—this means that the value can safely include = characters. All the data read is in the form of Unicode strings,so for date,numeric,and Boolean data typeswe must convert thevalue string accordingly.\n\nFor dates we use the datetime.datetime.strptime() function (“string parse time”) which takes a format string and returns a datetime.datetime ob- ject. We have used a format string that matches the ISO 8601 date format, and we use datetime.datetime.date() to retrieve a datetime.date object from the resultant datetime.datetime object, since we want only a date and not a date/time. We rely on Python’s built-in type functions, float() and int(), for the numeric conversions. Note, though that, for example, int(\"4.0\") will raise a ValueError; if we want to be more liberal in accepting integers, we could use int(float(\"4.0\")), or if we wanted to round rather than truncate, round(float(\"4.0\")). To get a bool is slightly subtler—for example, bool(\"0\") returns True (a nonempty string is True), so we must ﬁrst convert the string to an int.\n\nInvalid, missing, or out-of-range values will always cause an exception to be raised. If any of the conversions fail they raise a ValueError exception. And if any values are out of range an IncidentError exception will be raised when the data is used to create a corresponding Incident object.\n\nIf the line doesn’t contain an = character, we check to see whether we’ve read the narrative start marker. If we have, we set the narrative variable to be an empty string. Thismeansthat theﬁrst if condition will be True for subsequent lines, at least until the narrative end marker is read.\n\nIf none of the if or elif conditions is True then an error has occurred,so in the ﬁnal else clause we raise a KeyError exception to signify this.\n\nreturn True\n\nexcept (EnvironmentError, ValueError, KeyError,\n\nIncidentError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nfinally:\n\nif fh is not None: fh.close()\n\nAfter reading all the lines, we return True to the caller—unless an exception occurred, in which case the except block catches the exception, prints an error\n\n309",
      "content_length": 2515,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 319,
      "content": "raw strings 67➤\n\n310\n\nChapter 7. File Handling\n\nmessage for the user, and returns False. And no matter what, if the ﬁle was opened, it is closed at the end.\n\nParsing Text Using Regular Expressions\n\nReaders unfamiliar with regular expressions (“regexes”) are recommended to read Chapter 13 before reading this section—or to skip ahead to the following section (➤ 312), and return here later if desired.\n\nUsing regular expressions to parse text ﬁles can often produce shorter code than doing everything by hand as we did in the previous subsection, but it can be more difﬁcult to provide good error reporting. We will look at the im- port_text_regex() method in two parts,ﬁrst looking at the regular expressions and then at the parsing—but omitting the except and finally blockssince they have nothing new to teach us.\n\ndef import_text_regex(self, filename):\n\nincident_re = re.compile(\n\nr\"\\[(?P<id>[^]]+)\\](?P<keyvalues>.+?)\" r\"^\\.NARRATIVE_START\\.$(?P<narrative>.*?)\" r\"^\\.NARRATIVE_END\\.$\", re.DOTALL|re.MULTILINE) key_value_re = re.compile(r\"^\\s*(?P<key>[^=]+?)\\s*=\\s*\"\n\nr\"(?P<value>.+?)\\s*$\", re.MULTILINE)\n\nThe regular expressions are written as raw strings. This saves us from hav- ing to double each backslash (writing each \\ as \\\\)—for example, without us- ing raw strings the second regular expression would have to be written as \"^\\\\s*(?P<key>[^=]+?)\\\\s*=\\\\s*(?P<value>.+?)\\\\s*$\". In this book we always use raw strings for regular expressions.\n\nThe ﬁrst regular expression, incident_re, is used to capture an entire inci- dent record. One effect of this is that any spurious text between records will not be noticed. This regular expression really has two parts. The ﬁrst is \\[(?P<id>[^]]+)\\](?P<keyvalues>.+?) which matchesa [,then matchesand cap- tures into the id match group as many non-] characters as it can, then match- es a ] (so this gives us the report ID), and then matches as few—but at least one—of any characters(including newlines because of the re.DOTALL ﬂag),into the keyvalues match group. The characters matched for the keyvalues match group are the minimum necessary to take us to the second part of the regular expression.\n\nThe second part of the ﬁrst regular expression is ^\\.NARRATIVE_START\\.$ (?P<narrative>.*?)^\\.NARRATIVE_END\\.$ and this matches the literal text .NAR- RATIVE_START., then as few characters as possible which are captured into the narrative match group, and then the literal text .NARRATIVE_END., at the end of\n\n||",
      "content_length": 2465,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 320,
      "content": "Writing and Parsing Text Files\n\nthe incident record. The re.MULTILINE ﬂag means that in this regular expres- sion ^ matches at the start of every line (rather than just at the start of the string), and $ matches at the end of every line (rather than just at the end of the string), so the narrative start and end markers are matched only at the start of lines.\n\nThe second regular expression,key_value_re,isused to capturekey=valuelines, and it matchesat the start of every line in the text it is given to match against, where the line begins with any amount of whitespace (including none), fol- lowed by non-= characters which are captured into the key match group, fol- lowed by an = character, followed by all the remaining characters in the line (excluding any leading or trailing whitespace),and capturesthemintothe val- ue match group.\n\nThe fundamental logic used to parse the ﬁle is the same as we used for the manual text parser that we covered in the previous subsection, only this time we extract incident records and incident data within those records using regular expressions rather than reading line by line.\n\nfh = None try:\n\nfh = open(filename, encoding=\"utf8\") self.clear() for incident_match in incident_re.finditer(fh.read()):\n\ndata = {} data[\"report_id\"] = incident_match.group(\"id\") data[\"narrative\"] = textwrap.dedent(\n\nincident_match.group(\"narrative\")).strip()\n\nkeyvalues = incident_match.group(\"keyvalues\") for match in key_value_re.finditer(keyvalues):\n\ndata[match.group(\"key\")] = match.group(\"value\")\n\ndata[\"date\"] = datetime.datetime.strptime(\n\ndata[\"date\"], \"%Y-%m-%d\").date()\n\ndata[\"pilot_percent_hours_on_type\"] = (\n\nfloat(data[\"pilot_percent_hours_on_type\"]))\n\ndata[\"pilot_total_hours\"] = int(\n\ndata[\"pilot_total_hours\"]) data[\"midair\"] = bool(int(data[\"midair\"])) if len(data) != 9:\n\nraise IncidentError(\"missing data\")\n\nincident = Incident(**data) self[incident.report_id] = incident\n\nreturn True\n\nThe re.finditer() method returns an iterator which produces each nonover- lapping match in turn. We create a data dictionary to hold one incident’s data as we have done before, but this time we get the report ID and narrative text\n\n311",
      "content_length": 2166,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 321,
      "content": "312\n\nChapter 7. File Handling\n\nfrom each match of the incident_re regular expression. We then extract all the key=value strings in one go using the keyvalues match group, and apply the key_value_re regular expression’sre.finditer() methodto iterateover each individual key=valueline. For each (key,value) pair found,we put them in the data dictionary—soall the valuesgo in asstrings. Then,for those valueswhich should not be strings, we replace them with a value of the appropriate type using the same string conversions that we used when parsing the text manu- ally.\n\nWe have added a check to ensure that the data dictionary has nine items be- cause if an incident record is corrupt, the key_value.finditer() iterator might match too many or too few key=valuelines. The end is the same as before—we create a new Incident object and put it in the incidents dictionary, then return True. If anything went wrong, the except suite will issue a suitable error mes- sage and return False, and the finally suite will close the ﬁle.\n\nOne of the things that makes both the manual and the regular expression text parsers as short and straightforward as they are is Python’s exception- handling. The parsers don’t have to check any of the conversions of strings to dates,numbers,or Booleans,and they don’t have to do any range checking (the Incident classdoesthat).If any of these thingsfail,an exception will be raised, and we handle all the exceptions neatly in one place at the end. Another ben- eﬁt of using exception-handling rather than explicit checking is that the code scales well—even if the record format changes to include more data items, the error handling code doesn’t need to grow any larger.\n\nWriting and Parsing XML Files\n\n|||\n\nSome programs use an XML ﬁle format for all the data they handle, whereas others use XML as a convenient import/export format. The ability to import and export XML is useful and is always worth considering even if a program’s main format is a text or binary format.\n\nOut of the box, Python offers three ways of writing XML ﬁles: manually writ- ing the XML, creating an element tree and using its write() method, and cre- ating a DOM and using its write() method. Similarly,for reading and parsing XML ﬁles there are four out-of-the-box approaches that can be used:manually reading and parsing the XML (not recommended and not covered here—it can be quite difﬁcult to handle some of the more obscure and advanced details cor- rectly), or using an element tree, DOM, or SAX parser. In addition, there are also third-party XML librariesavailable,such asthe lxml library mentioned in Chapter 5 (227 ➤), that are well worth investigating.\n\nThe aircraftincident XML format isshown in Figure 7.5.In thissection we will show how to write this format manually and how to write it using an element treeanda DOM,aswellashowtoread andparsethisformatusing theelement",
      "content_length": 2889,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 322,
      "content": "Writing and Parsing XML Files\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?> <incidents> <incident report_id=\"20070222008099G\" date=\"2007-02-22\" aircraft_id=\"80342\" aircraft_type=\"CE-172-M\" pilot_percent_hours_on_type=\"9.09090909091\" pilot_total_hours=\"440\" midair=\"0\"> <airport>BOWERMAN</airport> <narrative> ON A GO-AROUND FROM A NIGHT CROSSWIND LANDING ATTEMPT THE AIRCRAFT HIT A RUNWAY EDGE LIGHT DAMAGING ONE PROPELLER. </narrative> </incident> <incident> ... </incident> : </incidents>\n\nFigure 7.5 An example XML format aircraft incident record in context\n\ntree, DOM, and SAX parsers. If you don’t care which approach is used to read or write the XML, you could just read the Element Trees subsection that follows, and then skip to the chapter’s ﬁnal section (Random Access Binary Files; ➤ 324).\n\nElement Trees\n\nWriting the data using an element tree is done in two phases:First an element tree representing the data must be created, and second the tree must be written to a ﬁle. Some programs might use the element tree as their data structure, in which case they already have the tree and can simply write out the data. We will look at the export_xml_etree() method in two parts:\n\ndef export_xml_etree(self, filename):\n\nroot = xml.etree.ElementTree.Element(\"incidents\") for incident in self.values():\n\nelement = xml.etree.ElementTree.Element(\"incident\",\n\nreport_id=incident.report_id, date=incident.date.isoformat(), aircraft_id=incident.aircraft_id, aircraft_type=incident.aircraft_type, pilot_percent_hours_on_type=str(\n\nincident.pilot_percent_hours_on_type),\n\npilot_total_hours=str(incident.pilot_total_hours),\n\n313\n\n||",
      "content_length": 1623,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 323,
      "content": "314\n\nChapter 7. File Handling\n\nmidair=str(int(incident.midair)))\n\nairport = xml.etree.ElementTree.SubElement(element,\n\n\"airport\")\n\nairport.text = incident.airport.strip() narrative = xml.etree.ElementTree.SubElement(element,\n\n\"narrative\")\n\nnarrative.text = incident.narrative.strip() root.append(element)\n\ntree = xml.etree.ElementTree.ElementTree(root)\n\nWe begin by creating the root element (<incidents>). Then we iterate over all theincident records. For each onewe createan element (<incident>)tohold the data for theincident,andusekeywordargumentstoprovidetheattributes. All the attributes must be text, so we convert the date, numeric,and Boolean data items accordingly. We don’t have to worry about escaping “&”, “<”, and “>” (or about quotesin attributevalues),since the element tree module (and the DOM and SAX modules) automatically take care of these details.\n\nEach <incident> has two subelements, one holding the airport name and the other the narrative text. When subelements are created we must provide the parent element and the tag name. An element’s read/write text attribute is used to hold its text.\n\nOnce the <incident> has been created with all its attributes and its <airport> and <narrative> subelements, we add the incident to the hierarchy’s root (<in- cidents>)element. Attheendwehavea hierarchy of elementsthatcontainsall the incident record data, which we then trivially convert into an element tree.\n\ntry:\n\ntree.write(filename, \"UTF-8\")\n\nexcept EnvironmentError as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nreturn True\n\nWriting the XML to represent an entire element tree is simply a matter of telling the tree to write itself to the given ﬁle using the given encoding.\n\nUp to now when we have speciﬁed an encoding we have almost always used the string \"utf8\". This works ﬁne for Python’s built-in open() function which can accept a wide range of encodings and a variety of names for them, such as “UTF-8”, “UTF8”, “utf-8”, and “utf8”.But for XML ﬁles the encoding name can be only one of the ofﬁcial names, so \"utf8\" is not acceptable, which is why we have used \"UTF-8\".★\n\n★ See www.w3.org/TR/2006/REC-xml11-20060816/#NT-EncodingDecl and www.iana.org/assignments/char- acter-sets for information about XML encodings.",
      "content_length": 2301,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 324,
      "content": "Writing and Parsing XML Files\n\nReading an XML ﬁle using an element tree is not much harder than writing one. Again there are two phases: First we read and parse the XML ﬁle, and then we traverse the resultant element tree to read off the data to populate the incidents dictionary. Again this second phase is not necessary if the el- ement tree itself is being used as the in-memory data store. Here is the im- port_xml_etree() method, split into two parts.\n\ndef import_xml_etree(self, filename):\n\ntry:\n\ntree = xml.etree.ElementTree.parse(filename)\n\nexcept (EnvironmentError,\n\nxml.parsers.expat.ExpatError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nBy default,the element tree parser uses the expat XML parser under the hood which is why we must be ready to catch expat exceptions.\n\nself.clear() for element in tree.findall(\"incident\"):\n\ntry:\n\ndata = {} for attribute in (\"report_id\", \"date\", \"aircraft_id\",\n\n\"aircraft_type\", \"pilot_percent_hours_on_type\", \"pilot_total_hours\", \"midair\"): data[attribute] = element.get(attribute)\n\ndata[\"date\"] = datetime.datetime.strptime(\n\ndata[\"date\"], \"%Y-%m-%d\").date()\n\ndata[\"pilot_percent_hours_on_type\"] = (\n\nfloat(data[\"pilot_percent_hours_on_type\"]))\n\ndata[\"pilot_total_hours\"] = int(\n\ndata[\"pilot_total_hours\"]) data[\"midair\"] = bool(int(data[\"midair\"])) data[\"airport\"] = element.find(\"airport\").text.strip() narrative = element.find(\"narrative\").text data[\"narrative\"] = (narrative.strip()\n\nif narrative is not None else \"\")\n\nincident = Incident(**data) self[incident.report_id] = incident\n\nexcept (ValueError, LookupError, IncidentError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nreturn True\n\n315",
      "content_length": 1760,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 325,
      "content": "316\n\nChapter 7. File Handling\n\nOnce we have the element tree we can iterate over every <incident> using the xml.etree.ElementTree.findall() method. Each incident is returned as an xml.etree.Element object. We use the same technique for handling the element attributesaswedid in theprevioussection’simport_text_regex() method—ﬁrst we store all the values in the data dictionary, and then we convert those val- ues which are dates, numbers, or Booleans to the correct type. For the airport and narrative subelements we use the xml.etree.Element.find() method to ﬁnd them and read their text attributes. If a text element has no text its text attribute will be None, so we must account for this when reading the narrative text element since it might be empty. In all cases, the attribute values and text returned to us do not contain XML escapes since they are automatically unescaped.\n\nAs with all the XML parsers used to process aircraft incident data, an excep- tion will occur if the aircraft or narrative element is missing, or if one of the attributesis missing,or if one of the conversionsfails,or if any of the numeric data is out of range—this ensures that invalid data will cause parsing to stop andforanerrormessagetobeoutput. Thecodeattheendforcreatingandstor- ing incidents and for handling exceptions is the same as we have seen before.\n\nDOM (Document Object Model)\n\nThe DOM is a standard API for representing and manipulating an XML document in memory. The code for creating a DOM and writing it to a ﬁle, and for parsing an XML ﬁle using a DOM, is structurally very similar to the element tree code, only slightly longer.\n\nWe will begin by reviewing the export_xml_dom() method in two parts. This method works in two phases: First a DOM is created to reﬂect the incident data, and then the DOM is written out to a ﬁle. Just as with an element tree, some programsmight use the DOM as their data structure,in which case they can simply write out the data.\n\ndef export_xml_dom(self, filename):\n\ndom = xml.dom.minidom.getDOMImplementation() tree = dom.createDocument(None, \"incidents\", None) root = tree.documentElement for incident in self.values():\n\nelement = tree.createElement(\"incident\") for attribute, value in (\n\n(\"report_id\", incident.report_id), (\"date\", incident.date.isoformat()), (\"aircraft_id\", incident.aircraft_id), (\"aircraft_type\", incident.aircraft_type), (\"pilot_percent_hours_on_type\",\n\nstr(incident.pilot_percent_hours_on_type)),\n\n||",
      "content_length": 2463,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 326,
      "content": "XML encod- ing 314➤\n\nWriting and Parsing XML Files\n\n(\"pilot_total_hours\",\n\nstr(incident.pilot_total_hours)),\n\n(\"midair\", str(int(incident.midair)))):\n\nelement.setAttribute(attribute, value)\n\nfor name, text in ((\"airport\", incident.airport),\n\n(\"narrative\", incident.narrative)):\n\ntext_element = tree.createTextNode(text) name_element = tree.createElement(name) name_element.appendChild(text_element) element.appendChild(name_element)\n\nroot.appendChild(element)\n\nThe method begins by getting a DOM implementation. By default, the imple- mentation is provided by the expat XML parser. The xml.dom.minidom module provides a simpler and smaller DOM implementation than that provided by the xml.dom module, although the objects it uses are from the xml.dom module. Once we have a DOM implementation we can create a document. The ﬁrst ar- gument to xml.dom.DOMImplementation.createDocument() is the namespace URI which we don’t need, so we pass None; the second argument is a qualiﬁed name (the tag name for the root element), and the third argument is the document type, and again we pass None since we don’t have a document type. Having gotten the tree that representsthe document,we retrieve the root element and then proceed to iterate over all the incidents.\n\nFor each incident we create an <incident> element, and for each attribute we want the incident to have we call setAttribute() with the attribute’sname and value. Just as with the element tree, we don’t have to worry about escaping “&”, “<”, and “>” (or about quotes in attribute values). For the airport and nar- rative text elements we must create a text element to hold the text and a nor- mal element (with the appropriatetag name) as the text element’sparent—we then add the normal element (and the text element it contains) to the current incident element. With the incident element complete, we add it to the root.\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") tree.writexml(fh, encoding=\"UTF-8\") return True\n\nWe have omitted the except and finally blocks since they are the same as ones we have already seen. What this piece of code makes clear is the difference between the encoding string used for the built-in open() function and the encoding string used for XML ﬁles, as we discussed earlier.\n\nImporting an XML document into a DOM is similar to importing into an el- ement tree, but like exporting, it requires more code. We will look at the im-\n\n317",
      "content_length": 2432,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 327,
      "content": "318\n\nChapter 7. File Handling\n\nport_xml_dom() function in threeparts,starting with the def line and thenested get_text() function.\n\ndef import_xml_dom(self, filename):\n\ndef get_text(node_list):\n\ntext = [] for node in node_list:\n\nif node.nodeType == node.TEXT_NODE:\n\ntext.append(node.data)\n\nreturn \"\".join(text).strip()\n\nThe get_text() function iterates over a list of nodes (e.g., a node’s child nodes), and for each one that is a text node, it extracts the node’s text and appends it to a list of texts. At the end the function returns all the text it has gathered as a single string, with whitespace stripped from both ends.\n\ntry:\n\ndom = xml.dom.minidom.parse(filename)\n\nexcept (EnvironmentError,\n\nxml.parsers.expat.ExpatError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nParsing anXMLﬁleintoa DOMiseasy sincethemoduledoesallthehardwork for us, but we must be ready to handle expat errors since just like an element tree, the expat XML parser is the default parser used by the DOM classes under the hood.\n\nself.clear() for element in dom.getElementsByTagName(\"incident\"):\n\ntry:\n\ndata = {} for attribute in (\"report_id\", \"date\", \"aircraft_id\",\n\n\"aircraft_type\", \"pilot_percent_hours_on_type\", \"pilot_total_hours\", \"midair\"):\n\ndata[attribute] = element.getAttribute(attribute)\n\ndata[\"date\"] = datetime.datetime.strptime(\n\ndata[\"date\"], \"%Y-%m-%d\").date()\n\ndata[\"pilot_percent_hours_on_type\"] = (\n\nfloat(data[\"pilot_percent_hours_on_type\"]))\n\ndata[\"pilot_total_hours\"] = int(\n\ndata[\"pilot_total_hours\"]) data[\"midair\"] = bool(int(data[\"midair\"])) airport = element.getElementsByTagName(\"airport\")[0]",
      "content_length": 1655,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 328,
      "content": "Writing and Parsing XML Files\n\ndata[\"airport\"] = get_text(airport.childNodes) narrative = element.getElementsByTagName(\n\n\"narrative\")[0]\n\ndata[\"narrative\"] = get_text(narrative.childNodes) incident = Incident(**data) self[incident.report_id] = incident\n\nexcept (ValueError, LookupError, IncidentError) as err:\n\nprint(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nreturn True\n\nOnce the DOM exists we clear the current incidents data and iterate over all the incident tags. For each one we extract the attributes,and for date, numer- ic, and Booleans we convert them to the correct types in exactly the same way as we did when using an element tree. The only really signiﬁcant difference between using a DOM and an element tree is in the handling of text nodes. We use the xml.dom.Element.getElementsByTagName() method to get the child el- ements with the given tag name—in the cases of <airport> and <narrative> we know there is always one of each, so we take the ﬁrst (and only) child element of each type. Then we use the nested get_text() function to iterate over these tags’ child nodes to extract their texts.\n\nAs usual, if any error occurs we catch the relevant exception, print an error message for the user, and return False.\n\nThe differences in approach between DOM and element tree are not great, and since they both use the same expat parser under the hood, they’re both reasonably fast.\n\nManually Writing XML\n\nWriting a preexisting element tree or DOM as an XML document can be done with a single method call. But if our data is not already in one of these forms we must create an element tree or DOM ﬁrst, in which case it may be more convenient to simply write out our data directly.\n\nWhen writing XML ﬁles we must make sure that we properly escape text and attribute values, and that we write a well-formed XML document. Here is the export_xml_manual() method for writing out the incidents in XML:\n\ndef export_xml_manual(self, filename):\n\nfh = None try:\n\nfh = open(filename, \"w\", encoding=\"utf8\") fh.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n') fh.write(\"<incidents>\\n\")\n\n319\n\n||\n\nLocal func- tions ➤ 351",
      "content_length": 2163,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 329,
      "content": "320\n\nChapter 7. File Handling\n\nfor incident in self.values():\n\nfh.write('<incident report_id={report_id} '\n\n'date=\"{0.date!s}\" ' 'aircraft_id={aircraft_id} ' 'aircraft_type={aircraft_type} ' 'pilot_percent_hours_on_type=' '\"{0.pilot_percent_hours_on_type}\" ' 'pilot_total_hours=\"{0.pilot_total_hours}\" ' 'midair=\"{0.midair:d}\">\\n' '<airport>{airport}</airport>\\n' '<narrative>\\n{narrative}\\n</narrative>\\n' '</incident>\\n'.format(incident, report_id=xml.sax.saxutils.quoteattr(\n\nincident.report_id),\n\naircraft_id=xml.sax.saxutils.quoteattr(\n\nincident.aircraft_id),\n\naircraft_type=xml.sax.saxutils.quoteattr(\n\nincident.aircraft_type),\n\nairport=xml.sax.saxutils.escape(incident.airport), narrative=\"\\n\".join(textwrap.wrap(\n\nxml.sax.saxutils.escape(\n\nincident.narrative.strip()), 70))))\n\nfh.write(\"</incidents>\\n\") return True\n\nAs we have often done in this chapter, we have omitted the except and finally blocks.\n\nWe writetheﬁle using theUTF-8encoding and must specify thisto thebuilt-in open() function. Strictly speaking,we don’t have to specify the encoding in the <?xml?> declaration since UTF-8 is the default encoding, but we prefer to be explicit. We have chosen to quote all the attribute values using double quotes (\"), and so for convenience have used single quotes to quote the string we put the incidents in to avoid the need to escape the quotes.\n\nThe sax.saxutils.quoteattr() function is similar to the sax.saxutils.escape() function we use for XML text in that it properly escapes “&”, “<”, and “>” characters. In addition, it escapes quotes (if necessary), and returns a string that has quotes around it ready for use. This is why we have not needed to put quotes around the report ID and other string attribute values.\n\nThe newlines we have inserted and the text wrapping for the narrative are purely cosmetic. They are designed to make the ﬁle easier for humans to read and edit, but they could just as easily be omitted.\n\nWriting thedata in HTMLformatisnot much differentfromwriting XML.The convert-incidents.py program includes the export_html() function as a simple",
      "content_length": 2084,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 330,
      "content": "Writing and Parsing XML Files\n\nexampleof this,althoughwewon’treviewit herebecauseit doesn’treally show anything new.\n\nParsing XML with SAX (Simple API for XML)\n\nUnlike the element tree and DOM, which represent an entire XML document in memory, SAX parsers work incrementally, which can potentially be both faster and lessmemory-hungry. A performanceadvantagecannot be assumed, however, especially since both the element tree and DOM use the fast expat parser.\n\nSAX parsers work by announcing “parsing events” when they encounter start tags, end tags, and other XML elements. To be able to handle those events that we are interested in we must create a suitable handler class, and provide certain predeﬁned methods which are called when matching parsing events take place. The most commonly implemented handler is a content handler, although it is possible to provide error handlers and other handlers if we want ﬁner control.\n\nHere is the complete import_xml_sax() method. It is very short because most of the work is done by the custom IncidentSaxHandler class:\n\ndef import_xml_sax(self, filename):\n\nfh = None try:\n\nhandler = IncidentSaxHandler(self) parser = xml.sax.make_parser() parser.setContentHandler(handler) parser.parse(filename) return True\n\nexcept (EnvironmentError, ValueError, IncidentError,\n\nxml.sax.SAXParseException) as err: print(\"{0}: import error: {1}\".format(\n\nos.path.basename(sys.argv[0]), err))\n\nreturn False\n\nWe createthe one handler we want to use and then we createa SAX parser and setitscontenthandlertobetheonewehavecreated. Thenwegivetheﬁlename to the parser’s parse() method and return True if no parsing errors occurred.\n\nWe pass self (i.e., this IncidentCollection dict subclass) to the custom Inci- dentSaxHandler class’sinitializer. Thehandlerclearstheoldincidentsaway and then builds up a dictionary of incidents as the ﬁle is parsed. Once the parse is complete the dictionary contains all the incidents that have been read.\n\n321\n\n||",
      "content_length": 1969,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 331,
      "content": "322\n\nChapter 7. File Handling\n\nclass IncidentSaxHandler(xml.sax.handler.ContentHandler):\n\ndef __init__(self, incidents):\n\nsuper().__init__() self.__data = {} self.__text = \"\" self.__incidents = incidents self.__incidents.clear()\n\nCustom SAX handler classes must inherit the appropriate base class. This ensures that for any methods we don’t reimplement (because we are not interested in the parsing events they handle), the base class version will be called—and will safely do nothing.\n\nWe start by calling the base class’s initializer. This is generally good practice for all subclasses,although it is not necessary (though harmless) for direct ob- ject subclasses. The self.__data dictionary is used to keep one incident’sdata, the self.__text string is used to keep the text of an airport name or of a nar- rative depending on which we are reading,and the self.__incidents dictionary is an object reference to the IncidentCollection dictionary which the handler updates directly. (An alternative design would be to have an independent dic- tionary inside the handler and to copy it to the IncidentCollection at the end using dict.clear() and then dict.update().)\n\ndef startElement(self, name, attributes):\n\nif name == \"incident\":\n\nself.__data = {} for key, value in attributes.items():\n\nif key == \"date\":\n\nself.__data[key] = datetime.datetime.strptime(\n\nvalue, \"%Y-%m-%d\").date()\n\nelif key == \"pilot_percent_hours_on_type\":\n\nself.__data[key] = float(value)\n\nelif key == \"pilot_total_hours\":\n\nself.__data[key] = int(value)\n\nelif key == \"midair\":\n\nself.__data[key] = bool(int(value))\n\nelse:\n\nself.__data[key] = value\n\nself.__text = \"\"\n\nWhenever a start tag and its attributes are read the xml.sax.handler.Content- Handler.startElement() method is called with the tag name and the tag’s attributes. In the case of an aircraft incidents XML ﬁle, the start tags are <incidents>, which we ignore; <incident>, whose attributes we use to populate some of the self.__data dictionary; and <airport> and <narrative>, both of",
      "content_length": 2016,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 332,
      "content": "Writing and Parsing XML Files\n\nwhich we ignore. We always clear the self.__text string when we get a start tag because no text tags are nested in the aircraft incident XML ﬁle format.\n\nWe don’t do any exception-handling in the IncidentSaxHandler class. If an ex- ception occursit will be passedupto thecaller,in thiscasethe import_xml_sax() method, which will catch it and output a suitable error message.\n\ndef endElement(self, name):\n\nif name == \"incident\":\n\nif len(self.__data) != 9:\n\nraise IncidentError(\"missing data\")\n\nincident = Incident(**self.__data) self.__incidents[incident.report_id] = incident\n\nelif name in frozenset({\"airport\", \"narrative\"}):\n\nself.__data[name] = self.__text.strip()\n\nself.__text = \"\"\n\nWhen an end tag is read the xml.sax.handler.ContentHandler.endElement() method is called. If we have reached the end of an incident we should have all the necessary data, so we create a new Incident object and add it to the incidents dictionary. If we have reached the end of a text element, we add an item to the self.__data dictionary with the text that has been accumulated so far. At the end we clear the self.__text string ready for its next use. (Strictly speaking,we don’t have to clear it,since we clear it when we get a start tag,but clearing it could make a difference in some XML formats, for example, where tags can be nested.)\n\ndef characters(self, text): self.__text += text\n\nWhen the SAX parser reads text it calls the xml.sax.handler.ContentHand- ler.characters() method. Thereisnoguaranteethat thismethodwill becalled just once with all the text; the text might come in chunks. This is why we simply use the method to accumulate text, and actually put the text into the dictionary only when the relevant end tag is reached. (A more efﬁcient imple- mentation would have self.__text be a list with the body of this method being self.__text.append(text), and with the other methods adapted accordingly.)\n\nUsing the SAX API is very different from using element tree or DOM, but it is just as effective. We can provide other handlers, and can reimplement additional methods in the content handler to get as much control as we like. The SAX parser itself does not maintain any representation of the XML document—this makes SAX ideal for reading XML into our own custom data collections, and also means that there is no SAX “document” to write out as XML, so for writing XML we must use one of the approaches described earlier in this section.\n\n323",
      "content_length": 2476,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 333,
      "content": "324\n\nChapter 7. File Handling\n\nRandom Access Binary Files\n\n|||\n\nIn the earlier sections we worked on the basis that all of a program’s data was read into memory in one go, processed, and then all written out in one go. Modern computers have so much RAM that this is a perfectly viable approach, even for large data sets. However, in some situations holding the data on disk and just reading the bits we need and writing back changes might be a better solution. The disk-based random access approach is most easily done using a key–value database (a “DBM”), or a full SQL database—both are covered in Chapter 12—but in thissection we will show how to handle random accessﬁles by hand.\n\nWe will ﬁrst present the BinaryRecordFile.BinaryRecordFile class. Instances of this class represent a generic readable/writable binary ﬁle, structured as a sequence of ﬁxed length records. We will then look at the BikeStock.BikeStock class which holds a collection of BikeStock.Bike objects as records in a Bina- ryRecordFile.BinaryRecordFile to see how to make use of binary random ac- cess ﬁles.\n\nA Generic BinaryRecordFile Class\n\n||\n\nThe BinaryRecordFile.BinaryRecordFile class’sAPI is similar to a list in that we canget/set/deletearecordatagivenindexposition. Whenarecordisdeleted,it issimply marked“deleted”;thissaveshaving tomovealltherecordsthatfollow it up to ﬁll the gap, and also means that after a deletion all the original index positions remain valid. Another beneﬁt is that a record can be undeleted sim- ply by unmarking it. The price we pay for this is that deleting records doesn’t save any disk space. We will solve this by providing methods to “compact” the ﬁle, eliminating deleted records (and invalidating index positions).\n\nBefore reviewing the implementation, let’s look at some basic usage:\n\nContact = struct.Struct(\"<15si\") contacts = BinaryRecordFile.BinaryRecordFile(filename, Contact.size)\n\nHere we create a struct (little-endian byte order, a 15-byte byte string, and a 4-byte signed integer) that we will use to represent each record. Then we create a BinaryRecordFile.BinaryRecordFile instance with a ﬁlename and with a recordsize to match thestruct we are using. If theﬁle existsit will be opened with its contents left intact; otherwise, it will be created. In either case it will be opened in binary read/write mode, and once open, we can write data to it:\n\ncontacts[4] = Contact.pack(\"Abe Baker\".encode(\"utf8\"), 762) contacts[5] = Contact.pack(\"Cindy Dove\".encode(\"utf8\"), 987)",
      "content_length": 2499,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 334,
      "content": "Random Access Binary Files\n\nTable 7.4 File Object Attributes and Methods #1\n\nSyntax\n\nDescription\n\nf.close()\n\nCloses ﬁle object f and sets attribute f.closed to True\n\nf.closed\n\nf.encoding\n\nReturns True if the ﬁle is closed The encoding used for bytes ↔ str conversions\n\nf.fileno()\n\nReturns the underlying ﬁle’s ﬁle descriptor. (Available only for ﬁle objects that have ﬁle descriptors.)\n\nf.flush()\n\nFlushes the ﬁle object f\n\nf.isatty()\n\nReturns True if the ﬁle object is associated with a console. (Available only for ﬁle objects that refer to actual ﬁles.)\n\nf.mode\n\nThe mode ﬁle object f was opened with\n\nf.name\n\nFile object f’s ﬁlename (if it has one)\n\nf.newlines\n\nThe kinds of newline strings encountered in text ﬁle f\n\nf.__next__()\n\nReturns the next line from ﬁle object f. In most cases, this method is used implicitly, for example, for line in f.\n\nf.peek(n)\n\nReturns n bytes without moving the ﬁle pointer position\n\nf.read(count) Reads at most count bytes from ﬁle object f. If count is not speciﬁed then every byte is read from the current ﬁle posi- tion to the end. Returns a bytes object when reading in bi- nary mode and a str when reading in text mode. If there is no more to read (end of ﬁle), an empty bytes or str is returned. Returns True if f was opened for reading\n\nf.readable()\n\nf.readinto( ba)\n\nReads at most len(ba) bytes into bytearray ba and returns the number of bytesread—thisis0at end of ﬁle. (Available only in binary mode.)\n\nf.readline(\n\ncount)\n\nReads the next line (or up to count bytes if count is speciﬁed and reached before the \\n character), including the \\n\n\nf.readlines(\n\nsizehint)\n\nReads all the lines to the end of the ﬁle and returnsthem as a list. If sizehint is given, then reads approximately up to sizehint bytes if the underlying ﬁle object supports this.\n\nf.seek(\n\noffset, whence)\n\nMovesthe ﬁle pointer position (wherethe next read or write will take place) to the given offset if whence is not given or is os.SEEK_SET.Movesthe ﬁle pointer to the given offset (which may be negative) relative to the current position if whence is os.SEEK_CUR or relative to the end if whence is os.SEEK_END. Writes are always done at the end in append \"a\" mode no matter where the ﬁle pointer is. In text mode only the re- turn value of tell() method calls should be used as offsets.\n\n325",
      "content_length": 2313,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 335,
      "content": "326\n\nChapter 7. File Handling\n\nTable 7.5 File Object Attributes and Methods #2\n\nSyntax\n\nDescription\n\nf.seekable()\n\nReturns True if f supports random access\n\nf.tell()\n\nf.truncate(\n\nsize)\n\nReturnsthecurrent ﬁle pointer position relativeto thestart of the ﬁle Truncates the ﬁle to the current ﬁle pointer position, or to the given size if size is speciﬁed\n\nf.writable()\n\nReturns True if f was opened for writing\n\nf.write(s)\n\nWrites bytes/bytearray object s to the ﬁle if opened in binary mode or a str object s to the ﬁle if opened in text mode\n\nf.writelines( seq)\n\nWrites the sequence of objects (strings for text ﬁles, byte strings for binary ﬁles) to the ﬁle\n\nWe can treat the ﬁle like a list using the item access operator ([]); here we assign two byte strings (bytes objects, each containing an encoded string and an integer) at two record index positions in the ﬁle. These assignments will overwrite any existing content;and if the ﬁle doesn’t already have six records, the earlier records will be created with every byte set to 0x00.\n\ncontact_data = Contact.unpack(contacts[5]) contact_data[0].decode(\"utf8\").rstrip(chr(0)) # returns: 'Cindy Dove'\n\nSince the string “Cindy Dove” is shorter than the 15 UTF-8 characters in the struct, when it is packed it is padded with 0x00 bytes at the end. So when we retrieve the record, the contact_data will hold the 2-tuple (b'Cindy Dove\\x00\\x00\\x00\\x00\\x00', 987).To get the name,we must decode the UTF-8 to produce a Unicode string, and strip off the 0x00 padding bytes.\n\nNow that we’ve had a glimpse of the class in action, we are ready to review the code. The BinaryRecordFile.BinaryRecordFile class is in ﬁle BinaryRecord- File.py. After the usual preliminaries the ﬁle begins with the deﬁnitions of a couple of private byte values:\n\n_DELETED = b\"\\x01\" _OKAY = b\"\\x02\"\n\nEach record starts with a “state” byte which is either _DELETED or _OKAY (or b\"\\x00\" in the case of blank records).\n\nHere is the class line and the initializer:\n\nclass BinaryRecordFile:\n\ndef __init__(self, filename, record_size, auto_flush=True):\n\nself.__record_size = record_size + 1",
      "content_length": 2103,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 336,
      "content": "Random Access Binary Files\n\nmode = \"w+b\" if not os.path.exists(filename) else \"r+b\" self.__fh = open(filename, mode) self.auto_flush = auto_flush\n\nThere are two different record sizes. The BinaryRecordFile.record_size is the one set by the user and is the record size from the user’s point of view. The private BinaryRecordFile.__record_size is the real record size and includes the state byte.\n\nWe are careful not to truncate the ﬁle when we open it if it already exists (by using a mode of \"r+b\"), and to create it if it does not exist (by using a mode of \"w+b\")—the \"+\" partof themodestring iswhatsigniﬁesreading andwriting. If the BinaryRecordFile.auto_flush Boolean is True, the ﬁle is ﬂushed before every read and after every write.\n\n@property def record_size(self):\n\nreturn self.__record_size - 1\n\n@property def name(self):\n\nreturn self.__fh.name\n\ndef flush(self):\n\nself.__fh.flush()\n\ndef close(self):\n\nself.__fh.close()\n\nWe have made the record size and ﬁlename into read-only properties. The record size we report to the user is the one they requested and matches their records. The ﬂush and close methods simply delegate to the ﬁle object.\n\ndef __setitem__(self, index, record):\n\nassert isinstance(record, (bytes, bytearray)), \\\n\n\"binary data required\"\n\nassert len(record) == self.record_size, (\n\n\"record must be exactly {0} bytes\".format( self.record_size))\n\nself.__fh.seek(index * self.__record_size) self.__fh.write(_OKAY) self.__fh.write(record) if self.auto_flush:\n\nself.__fh.flush()\n\nThis method supportsthe brf[i] =data syntax where brf is a binary record ﬁle, i a record index position, and data a byte string. Notice that the record must be the same size asthe size isspeciﬁed when the binary record ﬁle wascreated.\n\n327",
      "content_length": 1739,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 337,
      "content": "328\n\nChapter 7. File Handling\n\nIf the arguments are okay, we move the ﬁle position pointer to the ﬁrst byte of the record—notice that here we use the real record size, that is, we account for the state byte. The seek() method moves the ﬁle pointer to an absolute byte position by default. A second argument can be given to make the movement relative to the current position or to the end. (The attributes and methods provided by ﬁle objects are listed in Tables 7.4 and 7.5.)\n\nSince the item is being set it obviously hasn’t been deleted, so we write the _OKAY state byte, and then we write the user’s binary record data. The binary record ﬁle does not know or care about the record structure that is being used—only that records are of the right size.\n\nWe do not check whether the index is in range. If the index is beyond the end of the ﬁle the record will be written in the correct position and every byte between the previous end of the ﬁle and the new record will automatically be set to b\"\\x00\". Such blank records are neither _OKAY nor _DELETED, so we can distinguish them when we need to.\n\ndef __getitem__(self, index):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY: return None\n\nreturn self.__fh.read(self.record_size)\n\nWhen retrieving a record there are four cases that we must account for: The record doesn’t exist, that is, the given index is beyond the end; the record is blank;the record hasbeen deleted;and the record is okay. If the record doesn’t exist the private __seek_to_index() method will raise an IndexError exception. Otherwise,it will seek to the byte where the record begins and we can read the state byte. If the state is not _OKAY the record must either be blank or be delet- ed,inwhichcasewereturnNone;otherwise,wereadandreturntherecord. (An- otherstrategywouldbetoraiseacustomexceptionforblank ordeletedrecords, say, BlankRecordError or DeletedRecordError, instead of returning None.)\n\ndef __seek_to_index(self, index):\n\nif self.auto_flush:\n\nself.__fh.flush()\n\nself.__fh.seek(0, os.SEEK_END) end = self.__fh.tell() offset = index * self.__record_size if offset >= end:\n\nraise IndexError(\"no record at index position {0}\".format(\n\nindex))\n\nself.__fh.seek(offset)",
      "content_length": 2219,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 338,
      "content": "Random Access Binary Files\n\nThis is a private supporting method used by some of the other methods to move the ﬁle position pointer to the ﬁrst byte of the record at the given index position. We begin by checking to see whether the given index is in range. We do this by seeking to the end of the ﬁle (byte offset of 0 from the end), and using the tell() method to retrieve the byte position we have seeked to.★ If the record’s offset (index position × real record size) is at or after the end then the index is out of range and we raise a suitable exception. Otherwise, we seek to the offset position ready for the next read or write.\n\ndef __delitem__(self, index):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY:\n\nreturn\n\nself.__fh.seek(index * self.__record_size) self.__fh.write(_DELETED) if self.auto_flush:\n\nself.__fh.flush()\n\nFirst we move the ﬁle position pointer to the right place. If the index is in range (i.e., if no IndexError exception has occurred), and providing the record isn’t blank or already deleted,wedeletetherecordby overwriting itsstatebyte with _DELETED.\n\ndef undelete(self, index):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state == _DELETED:\n\nself.__fh.seek(index * self.__record_size) self.__fh.write(_OKAY) if self.auto_flush:\n\nself.__fh.flush()\n\nreturn True\n\nreturn False\n\nThis method begins by ﬁnding the record and reading its state byte. If the record is deleted we overwrite the state byte with _OKAY and return True to the caller to indicate success; otherwise (for blank or nondeleted records), we return False.\n\ndef __len__(self):\n\nif self.auto_flush:\n\nself.__fh.flush()\n\nself.__fh.seek(0, os.SEEK_END)\n\n★Both convenience, Python 3.1 also has these constants in its io module (e.g., io.SEEK_SET).\n\nPython 3.0 and 3.1 have the seek constants os.SEEK_SET, os.SEEK_CUR, and os.SEEK_END. For\n\n329\n\n3.x",
      "content_length": 1877,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 339,
      "content": "330\n\nChapter 7. File Handling\n\nend = self.__fh.tell() return end // self.__record_size\n\nThis method reports how many records are in the binary record ﬁle. It does this by dividing the end byte position (i.e., how many bytes are in the ﬁle) by the size of a record.\n\nWe have now covered all the basic functionality offered by the BinaryRecord- File.BinaryRecordFile class. There is one last matter to consider: compacting the ﬁle to eliminate blank and deleted records. There are essentially two ap- proaches we can take to this. One approach is to overwrite blank or deleted records with records that have higher record index positions so that there are no gaps,and truncating the ﬁle if there are any blank or deleted recordsat the end. The inplace_compact() method does this. The other approach is to copy the nonblank nondeleted records to a temporary ﬁle and then to rename the temporary to the original. Using a temporary ﬁle is particularly convenient if we also want to make a backup. The compact() method does this.\n\nWe will start by looking at the inplace_compact() method, in two parts.\n\ndef inplace_compact(self):\n\nindex = 0 length = len(self) while index < length:\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY:\n\nfor next in range(index + 1, length):\n\nself.__seek_to_index(next) state = self.__fh.read(1) if state == _OKAY:\n\nself[index] = self[next] del self[next] break\n\nelse:\n\nbreak\n\nindex += 1\n\nWe iterate over every record,reading the state of each one in turn. If we ﬁnd a blank or deleted record we look for the next nonblank nondeleted record in the ﬁle. If we ﬁnd one we replace the blank or deleted record with the nonblank nondeleted one and delete the original nonblank nondeleted one; otherwise, we break out of the while loop entirely since we have run out of nonblank nondeleted records.\n\nself.__seek_to_index(0) state = self.__fh.read(1)",
      "content_length": 1891,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 340,
      "content": "Random Access Binary Files\n\nif state != _OKAY:\n\nself.__fh.truncate(0)\n\nelse:\n\nlimit = None for index in range(len(self) - 1, 0, -1):\n\nself.__seek_to_index(index) state = self.__fh.read(1) if state != _OKAY:\n\nlimit = index\n\nelse:\n\nbreak if limit is not None:\n\nself.__fh.truncate(limit * self.__record_size)\n\nself.__fh.flush()\n\nIf the ﬁrst record is blank or deleted, then they must all be blank or deleted since the previous code moved all nonblank nondeleted records to the begin- ning of the ﬁle and blank and deleted ones to the end. In this case we can sim- ply truncate the ﬁle to 0 bytes.\n\nIf there is at least one nonblank nondeleted record we iterate from the last record backwardtoward the ﬁrst since we know that blank and deleted records have been moved to the end. The limit variable is set to the earliest blank or deleted record (or left as None if there are no blank or deleted records),and the ﬁle is truncated accordingly.\n\nAn alternativetodoing thecompacting in-placeistodoit by copying toanother ﬁle—this is useful if we want to make a backup, as the compact() method that we will review next shows.\n\ndef compact(self, keep_backup=False):\n\ncompactfile = self.__fh.name + \".$$$\" backupfile = self.__fh.name + \".bak\" self.__fh.flush() self.__fh.seek(0) fh = open(compactfile, \"wb\") while True:\n\ndata = self.__fh.read(self.__record_size) if not data: break\n\nif data[:1] == _OKAY: fh.write(data)\n\nfh.close() self.__fh.close()\n\nos.rename(self.__fh.name, backupfile) os.rename(compactfile, self.__fh.name)\n\n331",
      "content_length": 1522,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 341,
      "content": "Bytes and bytear- ray sidebar 293➤\n\n332\n\nChapter 7. File Handling\n\nif not keep_backup:\n\nos.remove(backupfile)\n\nself.__fh = open(self.__fh.name, \"r+b\")\n\nThis method creates two ﬁles, a compacted ﬁle and a backup copy of the original ﬁle. The compacted ﬁle starts out with the same name as the original but with .$$$ tackedon to theend of theﬁlename,and similarly thebackupﬁle has the original ﬁlename with .bak tacked on to the end. We read the existing ﬁle record by record, and for those records that are nonblank and nondeleted we write them to the compacted ﬁle. (Notice that we write the real record,that is, the state byte plus the user record, each time.)\n\nThe line if data[:1] == _OKAY: isquite subtle. Both the data object and the _OKAY object are of type bytes. We want to compare the ﬁrst byte of the data object to the (1 byte) _OKAY object. If we take a slice of a bytes object, we get a bytes object,but if we take a single byte,say,data[0],we get an int—the byte’svalue. So here we compare the 1 byte slice of data (its ﬁrst byte, the state byte) with the 1 byte _OKAY object. (Another way of doing it would be to write if data[0] == _OKAY[0]: which would compare the two int values.)\n\nAt theendwerenametheoriginalﬁleasthebackupandrenamethecompacted ﬁle as the original. We then remove the backup if keep_backup is False (the default). Finally, we open the compacted ﬁle (which now has the original ﬁlename), ready to be read or written.\n\nThe BinaryRecordFile.BinaryRecordFile class is quite low-level, but it can serve asthebasisof higher-levelclassesthat need randomaccessto ﬁlesof ﬁxed-size records, as we will see in the next subsection.\n\nExample: The BikeStock Module’s Classes\n\nThe BikeStock module uses a BinaryRecordFile.BinaryRecordFile to provide a simple stock control class. The stock items are bicycles, each represented by a BikeStock.Bike instance, and the entire stock of bikes is held in a Bike- Stock.BikeStock instance. The BikeStock.BikeStock class aggregates a dictio- nary whose keysare bike IDsand whose valuesare record index positions,into a BinaryRecordFile.BinaryRecordFile.Here isa brief exampleof use to get a feel for how these classes work:\n\nbicycles = BikeStock.BikeStock(bike_file) value = 0.0 for bike in bicycles:\n\nvalue += bike.value\n\nbicycles.increase_stock(\"GEKKO\", 2) for bike in bicycles:\n\nif bike.identity.startswith(\"B4U\"):\n\n||",
      "content_length": 2383,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 342,
      "content": "Random Access Binary Files\n\nif not bicycles.increase_stock(bike.identity, 1):\n\nprint(\"stock movement failed for\", bike.identity)\n\nThis snippet opens a bike stock ﬁle and iterates over all the bicycle records it contains to ﬁnd the total value (sum of price × quantity) of the bikes held. It then increases the number of “GEKKO” bikes in stock by two and increments thestock heldfor allbikeswhosebikeIDbeginswith“B4U”by one. Allof these actions take place on disk, so any other process that reads the bike stock ﬁle will always get the most current data.\n\nAlthough the BinaryRecordFile.BinaryRecordFile works in terms of indexes, the BikeStock.BikeStock class works in terms of bike IDs. This is managed by the BikeStock.BikeStock instance holding a dictionary that relates bike IDs to indexes.\n\nWe will begin by looking at the BikeStock.Bike class’s class line and initializ- er, then we will look at a few selected BikeStock.BikeStock methods, and ﬁnal- ly we will look at the code that provides the bridge between BikeStock.Bike objects and the binary records used to represent them in a BinaryRecord- File.BinaryRecordFile. (All the code is in the BikeStock.py ﬁle.)\n\nclass Bike:\n\ndef __init__(self, identity, name, quantity, price):\n\nassert len(identity) > 3, (\"invalid bike identity '{0}'\"\n\n.format(identity))\n\nself.__identity = identity self.name = name self.quantity = quantity self.price = price\n\nAll of a bike’s attributes are available as properties—the bike ID (self.__iden- tity)astheread-only Bike.identity property and theothersasread/writeprop- ertieswithsomeassertionsforvalidation. Inaddition,theBike.value read-only property returnsthe quantity multiplied by the price. (We have not shown the implementation of the properties since we have seen similar code before.)\n\nThe BikeStock.BikeStock class provides its own methods for manipulating bike objects, and they in turn use the writable bike properties.\n\nclass BikeStock:\n\ndef __init__(self, filename):\n\nself.__file = BinaryRecordFile.BinaryRecordFile(filename,\n\n_BIKE_STRUCT.size)\n\nself.__index_from_identity = {} for index in range(len(self.__file)):\n\nrecord = self.__file[index] if record is not None:\n\n333",
      "content_length": 2178,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 343,
      "content": "334\n\nChapter 7. File Handling\n\nbike = _bike_from_record(record) self.__index_from_identity[bike.identity] = index\n\nThe BikeStock.BikeStock class is a custom collection class that aggregates a binary record ﬁle (self.__file) and a dictionary (self.__index_from_identity) whose keys are bike IDs and whose values are record index positions.\n\nOnce the ﬁle has been opened (and created if it didn’t already exist),we iterate over its contents (if any). Each bike is retrieved and converted from a bytes object to a BikeStock.Bike using the private _bike_from_record() function, and the bike’s identity and index are added to the self.__index_from_identity dic- tionary.\n\ndef append(self, bike):\n\nindex = len(self.__file) self.__file[index] = _record_from_bike(bike) self.__index_from_identity[bike.identity] = index\n\nAppending a new bike is a matter of ﬁnding a suitable index position and setting the record at that position to the bike’s binary representation. We also take care to update the self.__index_from_identity dictionary.\n\ndef __delitem__(self, identity):\n\ndel self.__file[self.__index_from_identity[identity]]\n\nDeleting a bike record is easy; we just ﬁnd its record index position from its identity and delete the record at that index position. In the case of the Bike- Stock.BikeStock class we have not made use of the BinaryRecordFile.Binary- RecordFile’s undeletion capability.\n\ndef __getitem__(self, identity):\n\nrecord = self.__file[self.__index_from_identity[identity]] return None if record is None else _bike_from_record(record)\n\nBike records are retrieved by bike ID. If there is no such ID the lookup in the self.__index_from_identity dictionary will raise a KeyError exception, and if therecordisblank or deletedthe BinaryRecordFile.BinaryRecordFilewillreturn None. But if a record is retrieved we return it as a BikeStock.Bike object.\n\ndef __change_stock(self, identity, amount):\n\nindex = self.__index_from_identity[identity] record = self.__file[index] if record is None:\n\nreturn False\n\nbike = _bike_from_record(record) bike.quantity += amount self.__file[index] = _record_from_bike(bike) return True",
      "content_length": 2121,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 344,
      "content": "Random Access Binary Files\n\n335\n\nincrease_stock = (lambda self, identity, amount:\n\nself.__change_stock(identity, amount))\n\ndecrease_stock = (lambda self, identity, amount:\n\nself.__change_stock(identity, -amount))\n\nThe private __change_stock() method provides an implementation for the in- crease_stock() and decrease_stock() methods. The bike’s index position is found and the raw binary record is retrieved. Then the data is converted to a BikeStock.Bike object, the change is applied to the bike, and then the record in the ﬁle is overwritten with the binary representation of the updated bike ob- ject. (There is also a __change_bike() method that provides an implementation for the change_name() and change_price() methods,but none of these are shown because they are very similar to what’s shown here.)\n\ndef __iter__(self):\n\nfor index in range(len(self.__file)):\n\nrecord = self.__file[index] if record is not None:\n\nyield _bike_from_record(record)\n\nThismethod ensuresthat BikeStock.BikeStock objectscan be iterated over, just like a list,with a BikeStock.Bike object returned at each iteration,and skipping blank and deleted records.\n\nrecord0\n\nrecord1\n\nrecord2\n\n...\n\nrecordN\n\n8 × UTF-8 encoded bytes\n\n30 × UTF-8 encoded bytes\n\nint32\n\nfloat64\n\nidentity\n\nname\n\nquantity\n\nprice\n\nFigure 7.6 The logical structure of a bike record ﬁle\n\nThe private _bike_from_record() and _record_from_bike() functions isolate the binary representation of the BikeStock.Bike class from the BikeStock.BikeStock class that holds a collection of bikes. The logical structure of a bike record ﬁle isshown in Figure7.6.The physicalstructureisslightly different becauseeach record is preceded by a state byte.\n\n_BIKE_STRUCT = struct.Struct(\"<8s30sid\")\n\ndef _bike_from_record(record):\n\nID, NAME, QUANTITY, PRICE = range(4) parts = list(_BIKE_STRUCT.unpack(record)) parts[ID] = parts[ID].decode(\"utf8\").rstrip(\"\\x00\") parts[NAME] = parts[NAME].decode(\"utf8\").rstrip(\"\\x00\")",
      "content_length": 1948,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 345,
      "content": "Se- quence unpack- ing 114➤\n\n336\n\nChapter 7. File Handling\n\nreturn Bike(*parts)\n\ndef _record_from_bike(bike):\n\nreturn _BIKE_STRUCT.pack(bike.identity.encode(\"utf8\"),\n\nbike.name.encode(\"utf8\"), bike.quantity, bike.price)\n\nWhen we convert a binary record into a BikeStock.Bike we ﬁrst convert the tuple returned by unpack() into a list. This allows us to modify elements, in this case to convert UTF-8 encoded bytes into strings with padding 0x00 bytes stripped off. We then use the sequence unpacking operator (*) to feed the parts to the BikeStock.Bike initializer. Packing the data is much simpler; we just have to make sure that we encode the strings as UTF-8 bytes.\n\nFor modern desktop systems the need for application programs to use random accessbinary datadecreasesasRAMsizesanddiskspeedsincrease. Andwhen such functionality is needed, it is often easiest to use a DBM ﬁle or an SQL database. Nonetheless, there are systems where the functionality shown here may be useful, for example, on embedded and other resource limited systems.\n\nSummary\n\n|||\n\nThis chapter showed the most widely used techniques for saving and loading collections of data to and from ﬁles. We have seen how easy pickles are to use, and how we can handle both compressed and uncompressed ﬁles without knowing in advance whether compression has been used.\n\nWe saw how writing and reading binary data requires care, and saw that the code can be quite long if we need to handle variablelength strings. But we also learned that using binary ﬁlesusually resultsin the smallest possibleﬁle sizes and the fastest writing and reading times. We learned too that it is important to use a magic number to identify our ﬁle type and to use a version number to make it practical to change the format later on.\n\nIn thischapter wesawthat plain text istheeasiest formatfor userstoreadand that if the data is structured well it can be straightforward for additional tools to be created to manipulate the data. However,parsing text data can be tricky. We saw how to read text data both manually and using regular expressions.\n\nXML is a very popular data interchange format and it is generally useful to be able to at least import and export XML even when the normal format is a bina- ry or textone. WesawhowtowriteXMLmanually—including howtocorrectly escapeattributevaluesandtextualdata—andhowtowriteit using anelement tree and a DOM. We also learned how to parse XML using the element tree, DOM, and SAX parsers that Python’s standard library provides.",
      "content_length": 2512,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 346,
      "content": "Summary\n\nIn the chapter’s ﬁnal section we saw how to create a generic class to handle random accessbinary ﬁlesthat hold recordsof a ﬁxed size,and then how to use the generic class in a speciﬁc context.\n\nThis chapter brings us to the end of all the fundamentals of Python program- ming. It is possible to stop reading right here and to write perfectly good Python programsbased on everything you have learned so far. But it would be a shame to stop now—Python has so much more to offer, from neat techniques that can shorten and simplify code, to some mind-bending advanced facilities that are at least nice to know about, even if they are not often needed. In the next chapter we will go further with procedural and object-oriented program- ming, and we will also get a taste of functional programming. Then, in the following chapters we will focus more on broader programming techniques including threading,networking,database programming,regular expressions, and GUI (Graphical User Interface) programming.\n\nExercises\n\nThe ﬁrst exercise is to create a simpler binary record ﬁle module than the one presented in this chapter—one whose record size is exactly the same as what the user speciﬁes. The second exercise is to modify the BikeStock module to use your new binary record ﬁle module. The third exercise asks you to create a program from scratch—the ﬁle handling is quite straightforward, but some of the output formatting is rather challenging.\n\n1. Make a new, simpler version of the BinaryRecordFile module—one that does not use a state byte. For this version the record size speciﬁed by the user is the record size actually used. New records must be added us- ing a new append() method that simply moves the ﬁle pointer to the end and writes the given record. The __setitem__() method should only allow existing records to be replaced; one easy way of doing this is to use the __seek_to_index() method. With no state byte, __getitem__() is reduced to a mere three lines. The __delitem__() method will need to be completely rewritten since it must move all the records up to ﬁll the gap; this can be done in just over half a dozen lines, but does require some thought. The undelete() method must be removed since it is not supported,and the com- pact() and inplace_compact() methods must be removed because they are no longer needed. All told, the changes amount to fewer than 20 new or changed lines and at least 60 deleted lines compared with the original, and not counting doctests. A solution is provided in BinaryRecordFile_ans.py.\n\n2. Once you are conﬁdent that your simpler BinaryRecordFile class works, copy the BikeStock.py ﬁle and modify it to work with your BinaryRecordFile\n\n337\n\n|||",
      "content_length": 2703,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 347,
      "content": "338\n\nChapter 7. File Handling\n\nclass. Thisinvolveschanging only a handful of lines. A solution isprovid- ed in BikeStock_ans.py.\n\n3. Debugging binary formats can be difﬁcult, but a tool that can help is one that can do a hex dump of a binary ﬁle’s contents. Create a program that has the following console help text:\n\nUsage: xdump.py [options] file1 [file2 [... fileN]]\n\nOptions: -h, --help show this help message and exit -b BLOCKSIZE, --blocksize=BLOCKSIZE block size (8..80) [default: 16] -d, --decimal decimal block numbers [default: hexadecimal] -e ENCODING, --encoding=ENCODING encoding (ASCII..UTF-32) [default: UTF-8]\n\nUsing this program, if we have a BinaryRecordFile that is storing records with the structure \"<i10s\" (little-endian, 4-byte signed integer, 10-byte byte string),by setting the block size to match one record (15 bytes includ- ing the state byte), we can get a clear picture of what’s in the ﬁle. For ex- ample:\n\nxdump.py -b15 test.dat Block Bytes UTF-8 characters -------- --------------------------------- ---------------- 00000000 02000000 00416C70 68610000 000000 .....Alpha..... 00000001 01140000 00427261 766F0000 000000 .....Bravo..... 00000002 02280000 00436861 726C6965 000000 .(...Charlie... 00000003 023C0000 0044656C 74610000 000000 .<...Delta.....\n\nEach byte is represented by a two-digit hexadecimal number; the spacing between each set of four bytes (i.e., between each group of eight hexadec- imal digits) is purely to improve readability. Here we can see that the sec- ond record (“Bravo”) has been deleted since its state byte is 0x01 rather than the 0x02 used to indicate nonblank nondeleted records.\n\nUse the optparse module to handle the command-line options. (By specify- ing an option’s “type” you can get optparse to handle the string-to-integer conversion for the block size.) It can be quite tricky to get the headings to line up correctly for any given block size and to line up the characters correctly for the last block, so make sure you test with various block sizes (e.g.,8, 9, 10,…, 40).Also,don’t forget that in variable length ﬁles,the last block may be short. As the example illustrates, use periods to stand for nonprintable characters.\n\nThe program can be written in fewer than 70 lines spread over two functions. A solution is given in xdump.py.",
      "content_length": 2309,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 348,
      "content": "8\n\nFurther Procedural Programming ● Further Object-Oriented Programming\n\nFunctional-Style Programming\n\nAdvanced Programming Techniques\n\n||||\n\nIn this chapter we will look at a wide variety of different programming tech- niques and introduce many additional,often more advanced,Python syntaxes. Some of thematerialin thischapter isquitechallenging,but keepin mind that the most advanced techniques are rarely needed and you can always skim the ﬁrst time to get an idea of what can be done and read more carefully when the need arises.\n\nThe chapter’s ﬁrst section digs more deeply into Python’s procedural features. It starts by showing how to use what we already covered in a novel way, and then returns to the theme of generators that we only touched on in Chapter 6. Thesectionthenintroducesdynamicprogramming—loadingmodulesby name at runtimeand executing arbitrary codeat runtime. The section returnsto the theme of local (nested) functions,but in addition covers the use of the nonlocal keyword and recursive functions. Earlier we saw how to use Python’s prede- ﬁned decorators—in this section we learn how to create our own decorators. The section concludes with coverage of function annotations.\n\nThe secondsectioncoversall new materialrelating toobject-orientedprogram- ming. It begins by introducing __slots__, a mechanism for minimizing the memory usedby eachobject. Itthenshowshowtoaccessattributeswithoutus- ing properties. The section also introduces functors (objects that can be called like functions),and context managers—these are used in conjunction with the with keyword,and in many cases(e.g.,ﬁle handling)they can beused toreplace try … except … finally constructs with simpler try … except constructs. The section also shows how to create custom context managers, and introduces ad- ditional advanced object-oriented features,including classdecorators,abstract base classes, multiple inheritance, and metaclasses.\n\nThe third section introduces some fundamental concepts of functional pro- gramming,and introducessome useful functionsfrom the functools, itertools,\n\n339",
      "content_length": 2088,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 349,
      "content": "340\n\nChapter 8. Advanced Programming Techniques\n\nand operator modules. This section also shows how to use partial function ap- plication to simplify code, and how to create and use coroutines.\n\nAll the previous chapters put together have provided us with the “standard Python toolbox”. This chapter takes everything that we have already covered and turns it into the “deluxe Python toolbox”, with all the original tools (tech- niques and syntaxes), plus many new ones that can make our programming easier,shorter,and more effective. Some of the tools can have interchangeable uses, for example, some jobs can be done using either a class decorator or a metaclass,whereasothers,such as descriptors,can be used in multiple waysto achieve different effects. Some of the tools covered here, for example, context managers, we will use all the time, and others will remain ready at hand for those particular situations for which they are the perfect solution.\n\nFurther Procedural Programming\n\nMost of this section deals with additional facilities relating to procedural programming and functions,but the very ﬁrst subsection is different in that it presents a useful programming technique based on what we already covered without introducing any new syntax.\n\nBranching Using Dictionaries\n\nAs we noted earlier, functions are objects like everything else in Python, and a function’s name is an object reference that refers to the function. If we write a function’s name without parentheses, Python knows we mean the object reference, and we can pass such object references around just like any others. We can use thisfact to replace if statementsthat have lotsof elif clauseswith a single function call.\n\nIn Chapter12wewillreviewaninteractiveconsoleprogramcalled dvds-dbm.py, that has the following menu:\n\n(A)dd (E)dit (L)ist (R)emove (I)mport e(X)port (Q)uit\n\nThe program has a function that gets the user’s choice and which will return only a valid choice, in this case one of “a”, “e”, “l”, “r”, “i”, “x”, and “q”. Here are two equivalent code snippets for calling the relevant function based on the user’s choice:\n\nif action == \"a\":\n\nadd_dvd(db) elif action == \"e\": edit_dvd(db)\n\n|||\n\n||",
      "content_length": 2183,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 350,
      "content": "Genera- tor func- tions 279➤\n\nFurther Procedural Programming\n\n341\n\nelif action == \"l\":\n\nlist_dvds(db)\n\nelif action == \"r\":\n\nremove_dvd(db)\n\nelif action == \"i\": import_(db) elif action == \"x\": export(db) elif action == \"q\":\n\nfunctions = dict(a=add_dvd, e=edit_dvd,\n\nl=list_dvds, r=remove_dvd, i=import_, x=export, q=quit)\n\nquit(db)\n\nfunctions[action](db)\n\nThe choice is held as a one-character string in the action variable, and the database to be used is held in the db variable. The import_() function has a trailing underscore to keep it distinct from the built-in import statement.\n\nIn the right-hand code snippet we create a dictionary whose keys are the valid menu choices, and whose values are function references. In the second state- ment we retrieve the function reference corresponding to the given action and call the function referred to using the call operator, (), and in this example, passing the db argument. Not only is the code on the right-hand side much shorter than the code on the left, but also it can scale (have far more dictio- nary items) without affecting its performance,unlike the left-hand code whose speed depends on how many elifs must be tested to ﬁnd the appropriate func- tion to call.\n\nThe convert-incidents.py program from the preceding chapter uses this technique in its import_() method, as this extract from the method shows:\n\ncall = {(\".aix\", \"dom\"): self.import_xml_dom,\n\n(\".aix\", \"etree\"): self.import_xml_etree, (\".aix\", \"sax\"): self.import_xml_sax, (\".ait\", \"manual\"): self.import_text_manual, (\".ait\", \"regex\"): self.import_text_regex, (\".aib\", None): self.import_binary, (\".aip\", None): self.import_pickle}\n\nresult = call[extension, reader](filename)\n\nThe complete method is 13 lines long; the extension parameter is computed in the method,and the reader is passed in. The dictionary keys are 2-tuples,and the values are methods. If we had used if statements, the code would be 22 lines long, and would not scale as well.\n\nGenerator Expressions and Functions\n\n||\n\nintroduced generator functions and methods. It is Back in Chapter 6 we also possible to create generator expressions. These are syntactically almost",
      "content_length": 2160,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 351,
      "content": "342\n\nChapter 8. Advanced Programming Techniques\n\nidentical to list comprehensions,the difference being that they are enclosed in parentheses rather than brackets. Here are their syntaxes:\n\n(expression for item in iterable) (expression for item in iterable if condition)\n\nIn the preceding chapter we created some iterator methods using yield expressions. Herearetwoequivalentcodesnippetsthatshowhowa simple for … in loop containing a yield expression can be coded as a generator:\n\ndef items_in_key_order(d):\n\ndef items_in_key_order(d):\n\nfor key in sorted(d): yield key, d[key]\n\nreturn ((key, d[key])\n\nfor key in sorted(d))\n\nBoth functions return a generator that produces a list of key–value items for the given dictionary. If we need all the items in one go we can pass the generator returned by the functions to list() or tuple(); otherwise, we can iterate over the generator to retrieve items as we need them.\n\nGenerators provide a means of performing lazy evaluation, which means that they compute only the values that are actually needed. This can be more efﬁ- cient than,say,computing a very large list in one go. Some generatorsproduce as many values as we ask for—without any upper limit. For example:\n\ndef quarters(next_quarter=0.0):\n\nwhile True:\n\nyield next_quarter next_quarter += 0.25\n\nThis function will return 0.0,0.25,0.5,and so on,forever. Here is how we could use the generator:\n\nresult = [] for x in quarters(): result.append(x) if x >= 1.0: break\n\nThe break statement isessential—without it the for …in loop will never ﬁnish. At the end the result list is [0.0, 0.25, 0.5, 0.75, 1.0].\n\nEvery time we call quarters() we get back a generator that starts at 0.0 and increments by 0.25; but what if we want to reset the generator’s current value? It is possible to pass a value into a generator,as this new version of the generator function shows:\n\ndef quarters(next_quarter=0.0):\n\nwhile True:",
      "content_length": 1907,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 352,
      "content": "Further Procedural Programming\n\nreceived = (yield next_quarter) if received is None:\n\nnext_quarter += 0.25\n\nelse:\n\nnext_quarter = received\n\nThe yield expression returns each value to the caller in turn. In addition, if the caller calls the generator’s send() method, the value sent is received in the generator function as the result of the yield expression. Here is how we can use the new generator function:\n\nresult = [] generator = quarters() while len(result) < 5:\n\nx = next(generator) if abs(x - 0.5) < sys.float_info.epsilon:\n\nx = generator.send(1.0)\n\nresult.append(x)\n\nWe create a variable to refer to the generator and call the built-in next() func- tion which retrieves the next item from the generator it is given. (The same effect can be achieved by calling the generator’s __next__() special method, in thiscase,x = generator.__next__().)If thevalueisequalto0.5wesendthevalue 1.0intothegenerator(whichimmediately yieldsthisvalueback).Thistimethe result list is [0.0, 0.25, 1.0, 1.25, 1.5].\n\nIn the next subsection we will review the magic-numbers.py program which pro- cesses ﬁles given on the command line. Unfortunately,the Windows shell pro- gram(cmd.exe)doesnotprovidewildcardexpansion(alsocalledﬁleglobbing),so if a programisrunon Windowswith theargument *.*,theliteraltext “*.*”will go intothe sys.argv list instead of all theﬁlesin thecurrentdirectory. Wesolve this problem by creating two different get_files() functions, one for Windows and the other for Unix, both of which use generators. Here’s the code:\n\nif sys.platform.startswith(\"win\"):\n\ndef get_files(names):\n\nfor name in names:\n\nif os.path.isfile(name):\n\nyield name\n\nelse:\n\nfor file in glob.iglob(name):\n\nif not os.path.isfile(file):\n\ncontinue\n\nyield file\n\nelse:\n\ndef get_files(names):\n\nreturn (file for file in names if os.path.isfile(file))\n\n343",
      "content_length": 1827,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 353,
      "content": "344\n\nChapter 8. Advanced Programming Techniques\n\nIn either case the function is expected to be called with a list of ﬁlenames, for example, sys.argv[1:], as its argument.\n\nOn Windowsthe function iteratesover all the nameslisted. For each ﬁlename, the function yields the name, but for nonﬁles (usually directories), the glob module’s glob.iglob() function isused to return an iterator to the namesof the ﬁlesthat thenamerepresentsafter wildcardexpansion. For an ordinary name like autoexec.bat an iterator that produces one item (the name) is returned, and for a name that uses wildcards like *.txt an iterator that produces all the matching ﬁles (in this case those with extension .txt) is returned. (There is also a glob.glob() function that returns a list rather than an iterator.)\n\nOn Unix the shell does wildcard expansion for us, so we just need to return a generator for all the ﬁles whose names we have been given.★\n\nGenerator functions can also be used as coroutines, if we structure them correctly. Coroutines are functions that can be suspended in mid-execution (at the yield expression), waiting for the yield to provide a result to work on, and once received they continue processing. As we will see in the coroutines subsection later in this chapter (➤ 399), coroutines can be used to distribute work and to create processing pipelines.\n\nDynamic Code Execution and Dynamic Imports\n\nThere are some occasions when it is easier to write a piece of code that gen- erates the code we need than to write the needed code directly. And in some contexts it is useful to let users enter code (e.g., functions in a spreadsheet), and to let Python execute the entered code for us rather than to write a parser and handle it ourselves—although executing arbitrary code like this is a po- tential security risk, of course. Another use case for dynamic code execution is to provide plug-ins to extend a program’s functionality. Using plug-ins has the disadvantage that all the necessary functionality is not built into the pro- gram (which can make the program more difﬁcult to deploy and runs the risk of plug-ins getting lost),but has the advantages that plug-ins can be upgraded individually and can be provided separately,perhapsto provide enhancements that were not originally envisaged.\n\nDynamic Code Execution\n\nThe easiest way to execute an expression is to use the built-in eval() function we ﬁrst saw in Chapter 6. For example:\n\nx = eval(\"(2 ** 31) - 1\")\n\n# x == 2147483647\n\n★The glob.glob() functions are not as powerful as, say, the Unix bash shell, since although they support the *, ?, and [] syntaxes, they don’t support the {} syntax.\n\n||\n\n|",
      "content_length": 2655,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 354,
      "content": "Further Procedural Programming\n\nThis is ﬁne for user-entered expressions, but what if we need to create a function dynamically? For that we can use the built-in exec() function. For example, the user might give us a formula such as 4π 2r and the name “area of sphere”, which they want turned into a function. Assuming that we replace π with math.pi, the function they want can be created like this:\n\nimport math code = ''' def area_of_sphere(r):\n\nreturn 4 * math.pi * r ** 2\n\n''' context = {} context[\"math\"] = math exec(code, context)\n\nWemustuseproperindentation—afterall,thequotedcodeisstandardPython. (Although in this case we could have written it all on a single line because the suite is just one line.)\n\nIf exec() is called with some code as its only argument there is no way to access any functions or variables that are created as a result of the code being executed. Furthermore, exec() cannot access any imported modules or any of the variables, functions, or other objects that are in scope at the point of the call. Bothof theseproblemscanbesolvedby passing a dictionaryasthesecond argument. The dictionary providesa place where object referencescan be kept for accessing after the exec() call has ﬁnished. For example, the use of the context dictionary meansthat after the exec() call,the dictionary hasan object reference to the area_of_sphere() function that was created by exec(). In this example we needed exec() to be able to access the math module, so we inserted an item into the context dictionary whose key is the module’s name and whose value is an object reference to the corresponding module object. This ensures that inside the exec() call, math.pi is accessible.\n\nIn some cases it is convenient to provide the entire global context to exec(). This can be done by passing the dictionary returned by the globals() function. One disadvantageof thisapproach isthat any objectscreated in the exec() call would be added to the global dictionary. A solution isto copy the global context into a dictionary,for example,context = globals().copy().This still gives exec() access to imported modules and the variables and other objects that are in scope,and because we have copied,any changes to the context made inside the exec() callarekeptinthe context dictionaryandarenotpropagatedtotheglob- al environment. (It would appear to be more secure to use copy.deepcopy(),but if security is a concern it is best to avoid exec() altogether.) We can also pass the local context, for example, by passing locals() as a third argument—this makes objects in the local scope accessible to the code executed by exec().\n\n345",
      "content_length": 2629,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 355,
      "content": "346\n\nChapter 8. Advanced Programming Techniques\n\nAfter the exec() call the context dictionary contains a key called \"area_of_ sphere\" whose value is the area_of_sphere() function. Here is how we can access and call the function:\n\narea_of_sphere = context[\"area_of_sphere\"] area = area_of_sphere(5)\n\n# area == 314.15926535897933\n\nThe area_of_sphere object isan object referenceto the function we have dynam- ically created and can be used just like any other function. And although we created only a single function in the exec() call, unlike eval(), which can oper- ate on only a single expression, exec() can handle as many Python statements as we like, including entire modules, as we will see in the next subsubsection.\n\nDynamically Importing Modules\n\nPython provides three straightforward mechanisms that can be used to create plug-ins, all of which involve importing modules by name at runtime. And once we have dynamically imported additional modules, we can use Python’s introspection functions to check the availability of the functionality we want, and to access it as required.\n\nIn this subsubsection we will review the magic-numbers.py program. This program reads the ﬁrst 1000 bytes of each ﬁle given on the command line and for each one outputs the ﬁle’s type (or the text “Unknown”), and the ﬁlename. Here is an example command line and an extract from its output:\n\nC:\\Python31\\python.exe magic-numbers.py c:\\windows\\*.* ... XML.................c:\\windows\\WindowsShell.Manifest Unknown.............c:\\windows\\WindowsUpdate.log Windows Executable..c:\\windows\\winhelp.exe Windows Executable..c:\\windows\\winhlp32.exe Windows BMP Image...c:\\windows\\winnt.bmp ...\n\nThe program tries to load in any module that is in the same directory as the programandwhosenamecontainsthetext“magic”.Suchmodulesareexpected to provide a single public function, get_file_type(). Two very simple example modules, StandardMagicNumbers.py and WindowsMagicNumbers.py, that each have a get_file_type() function are provided with the book’s examples.\n\nWe will review the program’s main() function in two parts.\n\ndef main():\n\nmodules = load_modules() get_file_type_functions = [] for module in modules:\n\n|",
      "content_length": 2189,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 356,
      "content": "Further Procedural Programming\n\nget_file_type = get_function(module, \"get_file_type\") if get_file_type is not None:\n\nget_file_type_functions.append(get_file_type)\n\nIn a moment, we will the load_modules() functionwhich returnsa (possibly empty)list of moduleobjects, and we will look at the get_function() function further on. For each module found we try to retrieve a get_file_type() function,and add any we get to a list of such functions.\n\nlook at three different implementations of\n\nfor file in get_files(sys.argv[1:]):\n\nfh = None try:\n\nfh = open(file, \"rb\") magic = fh.read(1000) for get_file_type in get_file_type_functions:\n\nfiletype = get_file_type(magic,\n\nos.path.splitext(file)[1])\n\nif filetype is not None:\n\nprint(\"{0:.<20}{1}\".format(filetype, file)) break\n\nelse:\n\nprint(\"{0:.<20}{1}\".format(\"Unknown\", file))\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nfinally:\n\nif fh is not None: fh.close()\n\nThis loop iterates over every ﬁle listed on the command line and for each one reads its ﬁrst 1000 bytes. It then tries each get_file_type() function in turn to see whether it can determine the current ﬁle’s type. If the ﬁle type is deter- mined,the detailsare printed and the inner loop is broken out of,with process- ing continuing with thenext ﬁle. If no function can determinetheﬁle type—or if no get_file_type() functions were found—an “Unknown” line is printed.\n\nWe will now review three different (but equivalent) ways of dynamically importing modules,starting with thelongestandmostdifﬁcultapproach,since it shows every step explicitly:\n\ndef load_modules(): modules = [] for name in os.listdir(os.path.dirname(__file__) or \".\"):\n\nif name.endswith(\".py\") and \"magic\" in name.lower():\n\nfilename = name name = os.path.splitext(name)[0] if name.isidentifier() and name not in sys.modules:\n\n347",
      "content_length": 1805,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 357,
      "content": "348\n\nChapter 8. Advanced Programming Techniques\n\nfh = None try:\n\nfh = open(filename, \"r\", encoding=\"utf8\") code = fh.read() module = type(sys)(name) sys.modules[name] = module exec(code, module.__dict__) modules.append(module)\n\nexcept (EnvironmentError, SyntaxError) as err:\n\nsys.modules.pop(name, None) print(err)\n\nfinally:\n\nif fh is not None: fh.close()\n\nreturn modules\n\nWe begin by iterating over all the ﬁles in the program’sdirectory. If this is the current directory,os.path.dirname(__file__) will return an empty string which would cause os.listdir() to raise an exception, so we pass \".\" if necessary. For each candidate ﬁle (ends with .py and contains the text “magic”), we get the module name by chopping off the ﬁle extension. If the name is a valid identiﬁer it is a viable module name, and if it isn’t already in the global list of modules maintained in the sys.modules dictionary we can try to import it.\n\nWe read the text of the ﬁle into the code string. The next line, module = type(sys)(name), is quite subtle. When we call type() it returns the type object of the object it is given. So if we called type(1) we would get int back. If we print the type object we just get something human readable like “int”, but if we call the type object as a function, we get an object of that type back. For example, we can get the integer 5 in variable x by writing x = 5, or x = int(5), or x = type(0)(5), or int_type = type(0); x = int_type(5). In this case we’ve used type(sys) and sys isa module,sowegetback themoduletypeobject(essentially the same as a class object), and can use it to create a new module with the giv- en name. Just as with the int example where it didn’t matter what integer we used to get the int typeobject,it doesn’t matter what module we use (aslong as it is one that exists, that is, has been imported) to get the module type object.\n\nOnce we have a new (empty) module, we add it to the global list of modules to prevent the module from being accidentally reimported. This is done before calling exec() to more closely mimic the behavior of the import statement. Then we call exec() to execute the code we have read—and we use the module’s dictionary as the code’s context. At the end we add the module to the list of moduleswe will passback. And if a problem arises,we delete the module from the global modulesdictionary if it hasbeen added—it will not have been added to the list of modules if an error occurred. Notice that exec() can handle any",
      "content_length": 2482,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 358,
      "content": "Further Procedural Programming\n\nTable 8.1 Dynamic Programming and Introspection Functions\n\nSyntax\n\nDescription\n\n__import__(...)\n\nImports a module by name; see text\n\ncompile(source,\n\nfile, mode)\n\nReturns the code object that results from compiling the source text; file should be the ﬁlename, or \"<string>\"; mode must be “single”, “eval”, or “exec”\n\ndelattr(obj,\n\nDeletes the attribute called name from object obj\n\nname)\n\ndir(obj)\n\nReturns the list of names in the local scope, or if obj is given then obj’s names (e.g., its attributes and methods)\n\neval(source,\n\nglobals, locals)\n\nexec(obj,\n\nglobals, locals)\n\nReturns the result of evaluating the single expression in source;if supplied,globals istheglobal contextand locals is the local context (as dictionaries) Evaluatesobject obj,which can bea string or a codeobject from compile(), and returns None; if supplied, globals is the global context and locals is the local context\n\ngetattr(obj,\n\nname, val)\n\nReturns the value of the attribute called name from object obj, or val if given and there is no such attribute\n\nglobals()\n\nReturns a dictionary of the current global context\n\nhasattr(obj, name)\n\nReturns True if object obj has an attribute called name\n\nlocals()\n\nReturns a dictionary of the current local context\n\nsetattr(obj,\n\nname, val)\n\nSetstheattributecalled name tothevalue val for theobject obj, creating the attribute if necessary\n\ntype(obj)\n\nReturns object obj’s type object\n\nvars(obj)\n\nReturns object obj’s context as a dictionary; or the local context if obj is not given\n\namount of code (whereas eval() evaluates a single expression—see Table 8.1), and raises a SyntaxError exception if there’s a syntax error.\n\nHere’s the second way to dynamically load a module at runtime—the code shown here replaces the ﬁrst approach’s try … except block:\n\ntry:\n\nexec(\"import \" + name) modules.append(sys.modules[name])\n\nexcept SyntaxError as err:\n\nprint(err)\n\n349",
      "content_length": 1918,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 359,
      "content": "350\n\nChapter 8. Advanced Programming Techniques\n\nOne theoretical problem with this approach is that it is potentially insecure. The name variable could begin with sys; and be followed by some destruc- tive code.\n\nAnd hereisthethirdapproach,againjust showing thereplacementfor theﬁrst approach’s try … except block:\n\ntry:\n\nmodule = __import__(name) modules.append(module)\n\nexcept (ImportError, SyntaxError) as err:\n\nprint(err)\n\nThis is the easiest way to dynamically import modules and is slightly safer than using exec(), although like any dynamic import, it is by no means secure because we don’t know what is being executed when the module is imported.\n\nNone of the techniques shown here handles packages or modules in different paths,but it isnot difﬁcult to extend the code to accommodatethese—although it is worth reading the online documentation, especially for __import__(), if more sophistication is required.\n\nHaving imported the module we need to be able to access the functionality it provides. This can be achieved using Python’sbuilt-in introspection functions, getattr() and hasattr(). Here’s how we have used them to implement the get_function() function:\n\ndef get_function(module, function_name):\n\nfunction = get_function.cache.get((module, function_name), None) if function is None:\n\ntry:\n\nfunction = getattr(module, function_name) if not hasattr(function, \"__call__\"):\n\nraise AttributeError()\n\nget_function.cache[module, function_name] = function\n\nexcept AttributeError: function = None\n\nreturn function get_function.cache = {}\n\nIgnoring the cache-related code for a moment, what the function does is call getattr() on the module object with the name of the function we want. If there is no such attribute an AttributeError exception is raised, but if there is such an attribute we use hasattr() to check that the attribute itself has the __call__ attribute—something that all callables (functions and methods) have. (Further on we will see a nicer way of checking whether an attribute is\n\ncollec- tions. Callable ➤ 392",
      "content_length": 2037,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 361,
      "content": "352\n\nChapter 8. Advanced Programming Techniques\n\nOne common use case for local functions is when we want to use recursion. In these cases, the enclosing function is called, sets things up, and then makes the ﬁrst call to a local recursive function. Recursive functions(or methods)are ones that call themselves. Structurally, all directly recursive functions can be seen as having two cases:the base case and the recursivecase. The base case is used to stop the recursion.\n\nRecursive functions can be computationally expensive because for every re- cursive call another stack frame is used; however, some algorithms are most naturally expressed using recursion. Most Python implementations have a ﬁxed limit to how many recursive calls can be made. The limit is returned by sys.getrecursionlimit() and can be changed by sys.setrecursionlimit(), al- though increasing the limit is most often a sign that the algorithm being used is inappropriate or that the implementation has a bug.\n\nThe classic example of a recursive function is one that is used to calculate factorials.★ For example, factorial(5) will calculate 5! and return 120, that is, 1 × 2 × 3 × 4 × 5:\n\ndef factorial(x): if x <= 1:\n\nreturn 1\n\nreturn x * factorial(x - 1)\n\nThis is not an efﬁcient solution,but it does show the two fundamental features of recursive functions. If the given number, x, is 1 or less, 1 is returned and no recursion occurs—this is the base case. But if x is greater than 1 the value returned is x * factorial(x - 1), and this is the recursive case because here the factorial function calls itself. The function is guaranteed to terminate because if the initial x is less than or equal to 1 the base case will be used and the function will ﬁnish immediately, and if x is greater than 1, each recursive call will be on a number one less than before and so will eventually be 1.\n\nTo see both local functions and recursive functions in a meaningful context we will study the indented_list_sort() function from module ﬁle IndentedList.py. This function takes a list of strings that use indentation to create a hierarchy, and a string that holds one level of indent, and returns a list with the same strings but where all the strings are sorted in case-insensitive alphabetical order, with indented items sorted under their parent item, recursively, as the before and after lists shown in Figure 8.1 illustrate.\n\nGiven the before list, the after list is produced by this call: after = Indent- edList.indented_list_sort(before).The default indent value is four spaces,the same as the indent used in the before list, so we did not need to set it explic- itly.\n\n★Python’s math module provides a much more efﬁcient math.factorial() function.",
      "content_length": 2718,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 362,
      "content": "Further Procedural Programming\n\nbefore = [\"Nonmetals\", \" \" \" \" \"Inner Transitionals\", Lanthanides\", \" \" \" \" \" \" \" \"Alkali Metals\", \" \" \"\n\nHydrogen\", Carbon\", Nitrogen\", Oxygen\",\n\nCerium\", Europium\",\n\nActinides\",\n\nUranium\", Curium\", Plutonium\",\n\nLithium\", Sodium\", Potassium\"]\n\nafter = [\"Alkali Metals\",\n\n\" \" \" \"Inner Transitionals\", \" Actinides\", \" \" \" \" \" \" \"Nonmetals\", \" \" \" \"\n\nLithium\", Potassium\", Sodium\",\n\nCurium\", Plutonium\", Uranium\", Lanthanides\",\n\nCerium\", Europium\",\n\nCarbon\", Hydrogen\", Nitrogen\", Oxygen\"]\n\nFigure 8.1 Before and after sorting an indented list\n\nWe will begin by looking at the indented_list_sort() function as a whole, and then we will look at its two local functions.\n\ndef indented_list_sort(indented_list, indent=\"\n\n\"):\n\nKEY, ITEM, CHILDREN = range(3)\n\ndef add_entry(level, key, item, children):\n\n...\n\ndef update_indented_list(entry):\n\n...\n\nentries = [] for item in indented_list:\n\nlevel = 0 i = 0 while item.startswith(indent, i):\n\ni += len(indent) level += 1\n\nkey = item.strip().lower() add_entry(level, key, item, entries)\n\nindented_list = [] for entry in sorted(entries):\n\nupdate_indented_list(entry)\n\nreturn indented_list\n\n353",
      "content_length": 1163,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 363,
      "content": "354\n\nChapter 8. Advanced Programming Techniques\n\nThe code begins by creating three constantsthat are used to provide names for index positions used by the local functions. Then we deﬁne the two local func- tions which we will review in a moment. The sorting algorithm works in two stages. In the ﬁrst stage we create a list of entries,each a 3-tuple consisting of a “key” that will be used for sorting,the original string,and a list of the string’s child entries. The key is just a lowercased copy of the string with whitespace strippedfromboth ends. Thelevelistheindentationlevel,0for top-levelitems, 1for children of top-level items,and so on. In the second stage we create a new indented list and add each string from the sorted entries list,and each string’s child strings, and so on, to produce a sorted indented list.\n\ndef add_entry(level, key, item, children):\n\nif level == 0:\n\nchildren.append((key, item, []))\n\nelse:\n\nadd_entry(level - 1, key, item, children[-1][CHILDREN])\n\nThis function is called for each string in the list. The children argument is the list to which new entries must be added. When called from the outer function (indented_list_sort()), this is the entries list. This has the effect of turning a list of strings into a list of entries, each of which has a top-level (unindented) string and a (possibly empty) list of child entries.\n\nIf the level is 0 (top-level), we add a new 3-tuple to the entries list. This holds the key (for sorting), the original item (which will go into the resultant sorted list), and an empty children list. This is the base case since no recursion takes place. If the level is greater than 0, the item is a child (or descendant) of the last item in the children list. In thiscase we recursively call add_entry() again, reducing thelevel by 1and passing thechildren list’slast item’schildren list as the list to add to. If the level is 2 or more, more recursive calls will take place, until eventually the level is 0 and the children list is the right one for the entry to be added to.\n\nFor example, when the “Inner Transitionals” string is reached, the outer func- tion calls add_entry() with a level of 0,a key of “inner transitionals”,an item of “Inner Transitionals”,and the entries list asthechildrenlist. Sincethelevel is 0, a new item will be appended to the children list (entries), with the key, item, and an empty children list. The next string is“ Lanthanides”—thisisindent- ed, so it is a child of the “Inner Transitionals” string. The add_entry() call this time has a level of 1, a key of “lanthanides”, an item of “ Lanthanides”, and the entries list asthechildren list. Sincethelevel is1,the add_entry() function calls itself recursively,this time with level 0 (1 - 1), the same key and item,but with the children list being the children list of the last item,that is,the “Inner Transitionals” item’s children list.\n\nHereiswhat the entries list lookslike onceall thestringshave been added,but before the sorting has been done:",
      "content_length": 2996,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 364,
      "content": "Further Procedural Programming\n\n[('nonmetals', 'Nonmetals', [('hydrogen', ' Hydrogen', []), ('carbon', ' Carbon', []), ('nitrogen', ' Nitrogen', []), ('oxygen', ' Oxygen', [])]), ('inner transitionals', 'Inner Transitionals', [('lanthanides', ' Lanthanides', [('cerium', ' Cerium', []), ('europium', ' Europium', [])]), ('actinides', ' Actinides', [('uranium', ' Uranium', []), ('curium', ' Curium', []), ('plutonium', ' Plutonium', [])])]), ('alkali metals', 'Alkali Metals', [('lithium', ' Lithium', []), ('sodium', ' Sodium', []), ('potassium', ' Potassium', [])])]\n\nThe output was produced using the pprint (“pretty print”) module’s pprint. pprint() function. Noticethat the entries list hasonly threeitems(allof which are 3-tuples), and that each 3-tuple’s last element is a list of child 3-tuples (or is an empty list).\n\nThe add_entry() function isboth a local function and a recursivefunction. Like all recursive functions, it has a base case (in this function, when the level is 0) that ends the recursion, and a recursive case.\n\nThe function could be written in a slightly different way:\n\ndef add_entry(key, item, children):\n\nnonlocal level if level == 0:\n\nchildren.append((key, item, []))\n\nelse:\n\nlevel -= 1 add_entry(key, item, children[-1][CHILDREN])\n\nHere, instead of passing level as a parameter, we use a nonlocal statement to accessa variable in an outer enclosing scope. If we did not change level inside the function we would not need the nonlocal statement—in such a situation, Python would not ﬁnd it in the local (inner function) scope, and would look at the enclosing scope and ﬁnd it there. But in this version of add_entry() we\n\n355",
      "content_length": 1656,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 365,
      "content": "356\n\nChapter 8. Advanced Programming Techniques\n\nneed to change level’s value, and just as we need to tell Python that we want to change global variables using the global statement (to prevent a new local variable from being created rather than the global variable updated),the same appliesto variablesthat we want to change but which belong to an outer scope. Although it is often best to avoid using global altogether, it is also best to use nonlocal with care.\n\ndef update_indented_list(entry):\n\nindented_list.append(entry[ITEM]) for subentry in sorted(entry[CHILDREN]):\n\nupdate_indented_list(subentry)\n\nIn the algorithm’s ﬁrst stage we build up a list of entries, each a (key, item, children) 3-tuple, in the same order as they are in the original list. In the algorithm’s second stage we begin with a new empty indented list and iterate over the sorted entries, calling update_indented_list() for each one to build up the new indented list. The update_indented_list() function is recursive. For each top-level entry it adds an item to the indented_list, and then calls itself for each of the item’s child entries. Each child is added to the indented_list, and then the function callsitself for each child’schildren—andso on. The base case (when the recursion stops) is when an item, or child, or child of a child, and so on has no children of its own.\n\nPython looks for indented_list in the local (inner function) scope and doesn’t ﬁnd it,so it then looks in the enclosing scope and ﬁndsit there. But notice that inside the function we append items to the indented_list even though we have not used nonlocal.Thisworksbecause nonlocal (and global) are concerned with object references, not with the objects they refer to. In the second version of add_entry() we had to use nonlocal for level because the += operator applied to a number rebinds the object reference to a new object—what really happens is level = level + 1,so level isset torefer toa newinteger object. But whenwecall list.append() on the indented_list, it modiﬁes the list itself and no rebinding takes place, and therefore nonlocal is not necessary. (For the same reason, if we have a dictionary,list,or other global collection,we can add or removeitems from it without using a global statement.)\n\nFunction and Method Decorators\n\nA decorator is a function that takes a function or method as its sole argument and returnsa new function or method that incorporatesthe decoratedfunction We have already made or method with some additional functionality added. use of some predeﬁned decorators,for example, @property and @classmethod. In this subsection we will learn how to create our own function decorators, and later in this chapter we will see how to create class decorators.\n\n||\n\nClass decora- tors ➤ 378",
      "content_length": 2777,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 366,
      "content": "Further Procedural Programming\n\nFor our ﬁrst decorator example, let us suppose that we have many functions that perform calculations,and that some of these must always produce a posi- tive result. We could add an assertion to each of these,but using a decorator is easier and clearer. Here’s a function decorated with the @positive_result deco- rator that we will create in a moment:\n\n@positive_result def discriminant(a, b, c):\n\nreturn (b ** 2) - (4 * a * c)\n\nThanks to the decorator, if the result is ever less than 0, an AssertionError ex- ception will be raised and the program will terminate. And of course, we can use the decorator on as many functions as we like. Here’s the decorator’s im- plementation:\n\ndef positive_result(function):\n\ndef wrapper(*args, **kwargs):\n\nresult = function(*args, **kwargs) assert result >= 0, function.__name__ + \"() result isn't >= 0\" return result\n\nwrapper.__name__ = function.__name__ wrapper.__doc__ = function.__doc__ return wrapper\n\nDecorators deﬁne a new local function that calls the original function. Here, the local function is wrapper(); it calls the original function and stores the result, and it uses an assertion to guarantee that the result is positive (or that the program will terminate). The wrapper ﬁnishes by returning the result computedby thewrappedfunction. Aftercreating thewrapper,wesetitsname and docstring to those of the original function. This helps with introspection, since we want error messagesto mention thename of theoriginal function,not the wrapper. Finally, we return the wrapper function—it is this function that will be used in place of the original.\n\ndef positive_result(function): @functools.wraps(function) def wrapper(*args, **kwargs):\n\nresult = function(*args, **kwargs) assert result >= 0, function.__name__ + \"() result isn't >= 0\" return result\n\nreturn wrapper\n\nHere is a slightly cleaner version of the @positive_result decorator. The wrap- per itself is wrapped using the functools module’s @functools.wraps decorator, which ensures that the wrapper() function has the name and docstring of the original function.\n\n357",
      "content_length": 2108,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 367,
      "content": "358\n\nChapter 8. Advanced Programming Techniques\n\nIn some cases it would be useful to be able to parameterize a decorator, but at ﬁrst sight this does not seem possible since a decorator takes just one argu- ment, a function or method. But there is a neat solution to this. We can call a function with the parameters we want and that returns a decorator which can then decorate the function that follows it. For example:\n\n@bounded(0, 100) def percent(amount, total):\n\nreturn (amount / total) * 100\n\nHere, the bounded() function is called with two arguments, and returns a deco- ratorthatisusedtodecoratethe percent() function. Thepurposeof thedecora- tor in thiscase isto guarantee that the number returned is alwaysin the range 0 to 100 inclusive. Here’s the implementation of the bounded() function:\n\ndef bounded(minimum, maximum):\n\ndef decorator(function):\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\nresult = function(*args, **kwargs) if result < minimum:\n\nreturn minimum elif result > maximum: return maximum\n\nreturn result\n\nreturn wrapper\n\nreturn decorator\n\nThe function creates a decorator function, that itself creates a wrapper func- tion. The wrapper performsthe calculation and returns a result that is within the bounded range. The decorator() function returns the wrapper() function, and the bounded() function returns the decorator.\n\nOne further point to note is that each time a wrapper is created inside the bounded() function, the particular wrapper uses the minimum and maximum values that were passed to bounded().\n\nThelast decoratorwewill createin thissubsectionisa bit morecomplex. It isa logging function that records the name, arguments,and result of any function it is used to decorate. For example:\n\n@logged def discounted_price(price, percentage, make_integer=False):\n\nresult = price * ((100 - percentage) / 100) if not (0 < result <= price):\n\nraise ValueError(\"invalid price\")\n\nreturn result if not make_integer else int(round(result))",
      "content_length": 1976,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 368,
      "content": "Further Procedural Programming\n\nIf Python is run in debug mode (the normal mode), every time the discount- ed_price() function is called a log message will be added to the ﬁle logged.log in the machine’s local temporary directory, as this log ﬁle extract illustrates:\n\ncalled: discounted_price(100, 10) -> 90.0 called: discounted_price(210, 5) -> 199.5 called: discounted_price(210, 5, make_integer=True) -> 200 called: discounted_price(210, 14, True) -> 181 called: discounted_price(210, -8) <type 'ValueError'>: invalid price\n\nIf Python is run in optimized mode (using the -O command-line option or if the PYTHONOPTIMIZE environment variable is set to -O), then no logging will take place. Here’s the code for setting up logging and for the decorator:\n\nif __debug__:\n\nlogger = logging.getLogger(\"Logger\") logger.setLevel(logging.DEBUG) handler = logging.FileHandler(os.path.join(\n\ntempfile.gettempdir(), \"logged.log\"))\n\nlogger.addHandler(handler)\n\ndef logged(function):\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\nlog = \"called: \" + function.__name__ + \"(\" log += \", \".join([\"{0!r}\".format(a) for a in args] +\n\n[\"{0!s}={1!r}\".format(k, v)\n\nfor k, v in kwargs.items()])\n\nresult = exception = None try:\n\nresult = function(*args, **kwargs) return result\n\nexcept Exception as err: exception = err\n\nfinally:\n\nlog += ((\") -> \" + str(result)) if exception is None\n\nelse \") {0}: {1}\".format(type(exception),\n\nexception))\n\nlogger.debug(log) if exception is not None:\n\nraise exception\n\nreturn wrapper\n\nelse:\n\ndef logged(function):\n\nreturn function\n\n359",
      "content_length": 1559,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 369,
      "content": "Dic- tionary compre- hen- sions 134➤\n\n360\n\nChapter 8. Advanced Programming Techniques\n\nIn debug mode the global variable __debug__ is True.If this is the case we set up logging using the logging module, and then create the @logged decorator. The logging module is very powerful and ﬂexible—it can log to ﬁles, rotated ﬁles, emails, network connections, HTTP servers, and more. Here we’ve used only the most basic facilities by creating a logging object, setting its logging level (several levels are supported),and choosing to use a ﬁle for the output.\n\nThe wrapper’scode beginsby setting upthe log string with thefunction’sname and arguments. We then try calling the function and storing its result. If any exception occurs we store it. In all cases the finally block is executed, and there we add the return value (or exception) to the log string and write to the log. If no exception occurred, the result is returned; otherwise, we reraise the exception to correctly mimic the original function’s behavior.\n\nIf Python is running in optimized mode, __debug__ is False; in this case we deﬁne the logged() function to simply return the function it is given, so apart from the tiny overhead of this indirection when the function is ﬁrst created, there is no runtime overhead at all.\n\nNote that the standard library’s trace and cProfile modules can run and anal- yse programs and modules to produce various tracing and proﬁling reports. Both use introspection,so unlike the @logged decorator we have used here,nei- ther trace nor cProfile requires any source code changes.\n\nFunction Annotations\n\nFunctionsand methodscan be deﬁned with annotations—expressionsthat can be used in a function’s signature. Here’s the general syntax:\n\ndef functionName(par1 : exp1, par2 : exp2, ..., parN : expN) -> rexp:\n\nsuite\n\nEvery colon expression part (: expX) is an optional annotation, and so is the arrow return expression part (-> rexp). The last (or only) positional parameter (if present) can be of the form *args, with or without an annotation; similarly, the last (or only) keyword parameter (if present) can be of the form **kwargs, again with or without an annotation.\n\nIf annotationsare present they are added to the function’s __annotations__ dic- tionary; if they are not present this dictionary is empty. The dictionary’s keys are the parameter names, and the values are the corresponding expressions. The syntax allows us to annotate all, some, or none of the parameters and to annotate the return value or not. Annotations have no special signiﬁcance to Python. The only thing that Python does in the face of annotations is to put them in the __annotations__ dictionary;any other action is up to us. Here is an example of an annotated function that is in the Util module:\n\n||",
      "content_length": 2773,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 370,
      "content": "Further Procedural Programming\n\ndef is_unicode_punctuation(s : str) -> bool:\n\nfor c in s:\n\nif unicodedata.category(c)[0] != \"P\":\n\nreturn False\n\nreturn True\n\nEvery Unicode character belongs to a particular category and each category is identiﬁedby a two-characteridentiﬁer. Allthecategoriesthatbeginwith P are punctuation characters.\n\nHere we have used Python data types as the annotation expressions. But they have no particular meaning for Python, as these calls should make clear:\n\nUtil.is_unicode_punctuation(\"zebr\\a\") Util.is_unicode_punctuation(s=\"!@#?\") Util.is_unicode_punctuation((\"!\", \"@\"))\n\n# returns: False # returns: True # returns: True\n\nThe ﬁrst call uses a positional argument and the second call a keyword argu- ment, just to show that both kinds work as expected. The last call passes a tuple rather than a string,and thisisaccepted since Python doesnothing more than record the annotations in the __annotations__ dictionary.\n\nIf we want to give meaning to annotations, for example, to provide type check- ing, one approach is to decorate the functions we want the meaning to apply to with a suitable decorator. Here is a very basic type-checking decorator:\n\ndef strictly_typed(function):\n\nannotations = function.__annotations__ arg_spec = inspect.getfullargspec(function)\n\nassert \"return\" in annotations, \"missing type for return value\" for arg in arg_spec.args + arg_spec.kwonlyargs:\n\nassert arg in annotations, (\"missing type for parameter '\" +\n\narg + \"'\")\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\nfor name, arg in (list(zip(arg_spec.args, args)) +\n\nlist(kwargs.items())):\n\nassert isinstance(arg, annotations[name]), (\n\n\"expected argument '{0}' of {1} got {2}\".format( name, annotations[name], type(arg)))\n\nresult = function(*args, **kwargs) assert isinstance(result, annotations[\"return\"]), (\n\n\"expected return of {0} got {1}\".format( annotations[\"return\"], type(result)))\n\nreturn result\n\nreturn wrapper\n\n361",
      "content_length": 1947,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 371,
      "content": "362\n\nChapter 8. Advanced Programming Techniques\n\nThis decorator requires that every argument and the return value must be annotated with the expected type. It checksthat the function’sargumentsand return type are all annotated with their types when the function it is passed is created,and at runtime it checksthat the typesof the actual argumentsmatch those expected.\n\nThe inspect module provides powerful introspection services for objects. Here, we have made use of only a small part of the argument speciﬁcation object it returns, to get the names of each positional and keyword argument—in the correct order in the case of the positional arguments. These names are then used in conjunction with the annotations dictionary to ensure that every parameter and the return value are annotated.\n\nThe wrapper function created inside the decorator begins by iterating over every name–argument pair of the given positional and keyword arguments. Since zip() returns an iterator and dictionary.items() returns a dictionary view wecannot concatenatethemdirectly,soﬁrst weconvertthemboth tolists. If any actual argument has a different type from its corresponding annotation the assertion will fail; otherwise, the actual function is called and the type of thevaluereturnedischecked,and if it isof theright type,it isreturned. At the end of the strictly_typed() function,we return the wrapped function as usual. Notice that the checking is done only in debug mode (which is Python’sdefault mode—controlled by the -O command-line option and the PYTHONOPTIMIZE envi- ronment variable).\n\nIf we decorate the is_unicode_punctuation() function with the @strictly_typed decorator,and try thesameexamplesasbeforeusing thedecoratedversion,the annotations are acted upon:\n\nis_unicode_punctuation(\"zebr\\a\") is_unicode_punctuation(s=\"!@#?\") is_unicode_punctuation((\"!\", \"@\"))\n\n# returns: False # returns: True # raises AssertionError\n\nNow the argument types are checked, so in the last case an AssertionError is raised because a tuple is not a string or a subclass of str.\n\nNow we will look at a completely different use of annotations. Here’s a small functionthat hasthesamefunctionality asthebuilt-in range() function,except that it always returns floats:\n\ndef range_of_floats(*args) -> \"author=Reginald Perrin\":\n\nreturn (float(x) for x in range(*args))\n\nNouseismadeof theannotationby thefunctionitself,butit iseasy toenvisage a tool that imported all of a project’s modules and produced a list of function names and author names, extracting each function’s name from its __name__ attribute, and the author names from the value of the __annotations__ dictio- nary’s \"return\" item.",
      "content_length": 2663,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 372,
      "content": "At- tribute access func- tions 349➤\n\nFurther Procedural Programming\n\nAnnotations are a very new feature of Python, and because Python does not impose any predeﬁned meaning on them, the uses they can be put to are lim- ited only by our imagination. Further ideas for possible uses, and some useful links, are available from PEP 3107 “Function Annotations”, www.python.org/ dev/peps/pep-3107.\n\nFurther Object-Oriented Programming\n\nIn this section we will look more deeply into Python’s support for object orientation, learning many techniques that can reduce the amount of code we must write, and that expand the power and capabilities of the programming features that are available to us. But we will begin with one very small and simple new feature. Here is the start of the deﬁnition of a Point class that has exactly the same behavior as the versions we created in Chapter 6:\n\nclass Point:\n\n__slots__ = (\"x\", \"y\")\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\nscenesPython When a class is created without the use of __slots__,behind the creates a private dictionary called __dict__ for each instance, and this dic- tionary holds the instance’s data attributes. This is why we can add or re- move attributes from objects. (For example, we added a cache attribute to the get_function() function earlier in this chapter.)\n\nIf we only need objects where we access the original attributes and don’t need to add or remove attributes, we can create classes that don’t have a __dict__. This is achieved simply by deﬁning a class attribute called __slots__ whose value is a tuple of attribute names. Each object of such a class will have attributesof the speciﬁed namesand no __dict__;no attributescan be added or removed from such classes. These objectsconsume lessmemory and are faster than conventional objects, although this is unlikely to make much difference unlesslargenumbersof objectsarecreated. If weinheritfroma classthatuses __slots__ wemustdeclareslotsin our subclass,even if empty,such as__slots__ = (); or the memory and speed savings will be lost.\n\nControlling Attribute Access\n\nIt issometimesconvenient to havea classwhereattributevaluesarecomputed on the ﬂy rather than stored. Here’s the complete implementation of such a class:\n\n363\n\n|||\n\n||",
      "content_length": 2263,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 373,
      "content": "364\n\nChapter 8. Advanced Programming Techniques\n\nclass Ord:\n\ndef __getattr__(self, char):\n\nreturn ord(char)\n\nWith the Ord class available, we can create an instance, ord = Ord(), and then have an alternative to the built-in ord() function that works for any character that is a valid identiﬁer. For example, ord.a returns 97, ord.Z returns 90, and ord.å returns 229. (But ord.! and similar are syntax errors.)\n\nNotethat if wetypedthe Ord classintoIDLEit would not work if wethentyped ord = Ord().Thisisbecausetheinstancehasthesamenameasthebuilt-in ord() function that the Ord class uses, so the ord() call would actually become a call to the ord instance and result in a TypeError exception. The problem would not ariseif weimportedamodulecontaining theOrd classbecausetheinteractively created ord object and the built-in ord() function used by the Ord classwould be in two separate modules,so one would not displace the other. If we really need tocreatea classinteractivelyandtoreusethenameof a built-inwecandosoby ensuring thattheclasscallsthebuilt-in—inthiscaseby importing thebuiltins module which provides unambiguous access to all the built-in functions, and calling builtins.ord() rather than plain ord().\n\nHere’sanothertiny yetcompleteclass. Thisoneallowsustocreate“constants”. It isn’t difﬁcult to change the values behind the class’s back, but it can at least prevent simple mistakes.\n\nclass Const:\n\ndef __setattr__(self, name, value):\n\nif name in self.__dict__:\n\nraise ValueError(\"cannot change a const attribute\")\n\nself.__dict__[name] = value\n\ndef __delattr__(self, name):\n\nif name in self.__dict__:\n\nraise ValueError(\"cannot delete a const attribute\") raise AttributeError(\"'{0}' object has no attribute '{1}'\"\n\n.format(self.__class__.__name__, name))\n\nWith this classwe can create a constant object,say, const = Const(),and set any attributes we like on it, for example, const.limit = 591. But once an attribute’s value has been set, although it can be read as often as we like, any attempt to change or delete it will result in a ValueError exception being raised. We have not reimplemented __getattr__() because the base class object.__getattr__() method does what we want—returns the given attribute’s value or raises an AttributeError exception if there is no such attribute. In the __delattr__() method we mimic the __getattr__() method’s error message for nonexistent attributes,and to do this we must get the name of the classwe are in as well as",
      "content_length": 2467,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 374,
      "content": "Image.py 261➤\n\nFurther Object-Oriented Programming\n\nTable 8.2 Attribute Access Special Methods\n\nSpecial Method\n\nUsage Description\n\n__delattr__(self, name)\n\ndel x.n Deletes object x’s n attribute\n\n__dir__(self)\n\ndir(x) Returns a list of x’s attribute\n\nnames\n\n__getattr__(self, name)\n\nv = x.n Returns the value of object x’s n\n\nattribute if it isn’t found directly\n\n__getattribute__(self, name)\n\nv = x.n Returns the value of object x’s n\n\nattribute; see text\n\n__setattr__(self, name,\n\nx.n = v Sets object x’s n attribute’s value\n\nvalue)\n\nto v\n\nthe name of the nonexistent attribute. The class works because we are using the object’s __dict__ which is what the base class __getattr__(), __setattr__(), and __delattr__() methods use, although here we have used only the base class’s __getattr__() method. All the special methods used for attribute access are listed in Table 8.2.\n\nThere is another way of getting constants:We can use named tuples. Here are a couple of examples:\n\nConst = collections.namedtuple(\"_\", \"min max\")(191, 591) Const.min, Const.max Offset = collections.namedtuple(\"_\", \"id name description\")(*range(3)) Offset.id, Offset.name, Offset.description # returns: (0, 1, 2)\n\n# returns: (191, 591)\n\nIn both cases we have just used a throwaway name for the named tuple be- cause we want just one named tuple instance each time, not a tuple subclass for creating instances of a named tuple. Although Python does not support an enum data type,we can use named tuplesaswe have done here to get a similar effect.\n\nFor our last look at attribute access special methods we will return to an example we ﬁrst saw in Chapter 6. In that chapter we created an Image class whose width, height, and background color are ﬁxed when an Image is created (although they are changed if an image is loaded).We provided access to them using read-only properties. For example, we had:\n\n@property def width(self):\n\nreturn self.__width\n\nThis is easy to code but could become tedious if there are a lot of read-only properties. Here is a different solution that handles all the Image class’s read-only properties in a single method:\n\n365",
      "content_length": 2125,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 375,
      "content": "366\n\nChapter 8. Advanced Programming Techniques\n\ndef __getattr__(self, name): if name == \"colors\":\n\nreturn set(self.__colors)\n\nclassname = self.__class__.__name__ if name in frozenset({\"background\", \"width\", \"height\"}): return self.__dict__[\"_{classname}__{name}\".format(\n\n**locals())]\n\nraise AttributeError(\"'{classname}' object has no \"\n\n\"attribute '{name}'\".format(**locals()))\n\nIf we attempt to access an object’s attribute and the attribute is not found, Python will call the __getattr__() method (providing it is implemented, and that we have not reimplemented __getattribute__()), with the name of the attribute as a parameter. Implementations of __getattr__() must raise an AttributeError exception if they do not handle the given attribute.\n\nFor example,if we have the statement image.colors,Python will look for a col- ors attributeandhaving failedtoﬁndit,willthencall Image.__getattr__(image, \"colors\"). In this case the __getattr__() method handles a \"colors\" attribute name and returns a copy of the set of colors that the image is using.\n\nThe other attributes are immutable, so they are safe to return directly to the caller. We could have written separate elif statements for each one like this:\n\nelif name == \"background\":\n\nreturn self.__background\n\nBut instead we have chosen a more compact approach. Since we know that under thehoodallof an object’snonspecialattributesareheldin self.__dict__, we have chosen to access them directly. For private attributes (those whose name begins with two leading underscores), the name is mangled to have the form _className__attributeName, so we must account for this when retrieving the attribute’s value from the object’s private dictionary.\n\nFor the name mangling needed to look up private attributesand to provide the standard AttributeError error text, we need to know the name of the class we are in. (It may not be Image because the object might be an instance of an Image subclass.) Every object has a __class__ special attribute, so self.__class__ is always available inside methods and can safely be accessed by __getattr__() without risking unwanted recursion.\n\nNote that there is a subtle difference in that using __getattr__() and self.__class__ provides access to the attribute in the instance’s class (which may be a subclass), but accessing the attribute directly uses the class the at- tribute is deﬁned in.\n\nOne special method that we have not covered is __getattribute__(). Where- as the __getattr__() method is called last when looking for (nonspecial) at-",
      "content_length": 2531,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 377,
      "content": "368\n\nChapter 8. Advanced Programming Techniques\n\ndef make_strip_function(characters): def strip_function(string):\n\nreturn string.strip(characters)\n\nreturn strip_function\n\nstrip_punctuation = make_strip_function(\",;:.!?\") strip_punctuation(\"Land ahoy!\")\n\n# returns: 'Land ahoy'\n\nThe make_strip_function() function takes the characters to be stripped as its sole argument and returns a function, strip_function(), that takes a string argument and which strips the characters that were given at the time the closure was created. So just as we can create as many instances of the Strip class as we want, each with its own characters to strip, we can create as many strip functions with their own characters as we like.\n\nThe classic use case for functors is to provide key functions for sort routines. Here is a generic SortKey functor class (from ﬁle SortKey.py):\n\nclass SortKey:\n\ndef __init__(self, *attribute_names):\n\nself.attribute_names = attribute_names\n\ndef __call__(self, instance):\n\nvalues = [] for attribute_name in self.attribute_names:\n\nvalues.append(getattr(instance, attribute_name))\n\nreturn values\n\nWhen a SortKey object is created it keeps a tuple of the attribute names it was initialized with. When the object is called it creates a list of the attribute values for the instance it is passed—in the order they were speciﬁed when the SortKey was initialized. For example, imagine we have a Person class:\n\nclass Person:\n\ndef __init__(self, forename, surname, email):\n\nself.forename = forename self.surname = surname self.email = email\n\nSuppose we have a list of Person objects in the people list. We can sort the list by surnames like this: people.sort(key=SortKey(\"surname\")). If there are a lot of people there are bound to be some surname clashes, so we can sort by surname, and then by forename within surname, like this: peo- ple.sort(key=SortKey(\"surname\", \"forename\")). And if we had people with the same surname and forename we could add the email attribute too. And of",
      "content_length": 1988,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 378,
      "content": "Further Object-Oriented Programming\n\ncourse, we could sort by forename and then surname by changing the order of the attribute names we give to the SortKey functor.\n\nAnother way of achieving thesamething,but without needing tocreatea func- tor at all, is to use the operator module’s operator.attrgetter() function. For example, to sort by surname we could write: people.sort(key=operator.attr- getter(\"surname\")). And similarly, to sort by surname and forename: people.sort(key=operator.attrgetter(\"surname\", \"forename\")). The operator. attrgetter() function returnsa function (a closure) that,when called on an ob- ject,returnsthose attributesof the object that were speciﬁed when the closure was created.\n\nFunctors are probably used rather less frequently in Python than in other languages that support them because Python has other means of doing the same things—for example, using closures or item and attribute getters.\n\nContext Managers\n\nContext managers allow us to simplify code by ensuring that certain opera- tionsareperformedbeforeand after a particular block of codeisexecuted. The behavior is achieved because context managers deﬁne two special methods, __enter__() and __exit__(), that Python treats specially in the scope of a with statement. When a context manager is created in a with statement its __en- ter__() methodisautomaticallycalled,andwhenthecontextmanagergoesout of scope after its with statement its __exit__() method is automatically called.\n\nWe can create our own custom context managers or use predeﬁned ones—as we will see later in this subsection, the ﬁle objects returned by the built-in open() function are context managers. The syntax for using context managers is this:\n\nwith expression as variable:\n\nsuite\n\nThe expression must be or must produce a context manager object; if the optional as variable part is speciﬁed, the variable is set to refer to the object returned by the context manager’s __enter__() method (and this is often the context manager itself). Because a context manager is guaranteed to execute its “exit” code (even in the face of exceptions),context managers can be used to eliminate the need for finally blocks in many situations.\n\nSome of Python’s types are context managers—for example, all the ﬁle objects that open() can return—so we can eliminate finally blocks when doing ﬁle handling asthese equivalent code snippetsillustrate(assuming that process() is a function deﬁned elsewhere):\n\n369\n\n||",
      "content_length": 2459,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 379,
      "content": "370\n\nChapter 8. Advanced Programming Techniques\n\nfh = None try:\n\nfh = open(filename) for line in fh:\n\nprocess(line)\n\ntry:\n\nexcept EnvironmentError as err:\n\nwith open(filename) as fh:\n\nprint(err)\n\nfor line in fh:\n\nfinally:\n\nprocess(line)\n\nif fh is not None: fh.close()\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nA ﬁle object is a context manager whose exit code always closes the ﬁle if it was opened. The exit code is executed whether or not an exception occurs, but in the latter case, the exception is propagated. This ensures that the ﬁle gets closed and we still get the chance to handle any errors,in this case by printing a message for the user.\n\nIn fact, context managers don’t have to propagate exceptions, but not doing so effectively hides any exceptions, and this would almost certainly be a coding error. All the built-in and standard library context managers propagate ex- ceptions.\n\nSometimes we need to use more than one context manager at the same time. For example:\n\ntry:\n\nwith open(source) as fin:\n\nwith open(target, \"w\") as fout:\n\nfor line in fin:\n\nfout.write(process(line))\n\nexcept EnvironmentError as err:\n\nprint(err)\n\nHere we read lines from the source ﬁle and write processed versionsof them to the target ﬁle.\n\nUsing nested with statements can quickly lead to a lot of indentation. Fortu- nately, the standard library’s contextlib module provides some additional sup- port for context managers, including the contextlib.nested() function which allowstwo or more context managersto be handled in the same with statement rather than having to nest with statements. Here is a replacement for the code just shown, but omitting most of the lines that are identical to before:\n\ntry:\n\nwith contextlib.nested(open(source), open(target, \"w\")) as (\n\nfin, fout):\n\nfor line in fin:",
      "content_length": 1796,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 380,
      "content": "Further Object-Oriented Programming\n\nIt is only necessary to use contextlib.nested() for Python 3.0; from Python 3.1 this function is deprecated because Python 3.1 can handle multiple context managers in a single with statement. Here is the same example—again omitting irrelevant lines—but this time for Python 3.1:\n\ntry:\n\nwith open(source) as fin, open(target, \"w\") as fout:\n\nfor line in fin:\n\nUsing this syntax keeps context managers and the variables they are associ- ated with together,making the with statement much more readable than if we were to nest them or to use contextlib.nested().\n\nIt isn’t only ﬁle objects that are context managers. For example, several threading-related classes used for locking are context managers. Context managers can also be used with decimal.Decimal numbers; this is useful if we want to perform some calculations with certain settings (such as a particular precision) in effect.\n\nIf we want to create a custom context manager we must create a class that provides two methods:__enter__() and __exit__().Whenever a with statement is used on an instance of such a class, the __enter__() method is called and the return value is used for the as variable (or thrown away if there isn’t one). When control leaves the scope of the with statement the __exit__() method is called (with details of an exception if one has occurred passed as arguments).\n\nSuppose we want to perform several operations on a list in an atomic manner—that is, we either want all the operations to be done or none of them so that the resultant list is always in a known state. For example, if we have a list of integers and want to append an integer, delete an integer, and change a couple of integers, all as a single operation, we could write code like this:\n\ntry:\n\nwith AtomicList(items) as atomic:\n\natomic.append(58289) del atomic[3] atomic[8] = 81738 atomic[index] = 38172\n\nexcept (AttributeError, IndexError, ValueError) as err:\n\nprint(\"no changes applied:\", err)\n\nIf no exception occurs,all the operations are applied to the original list (items), but if an exception occurs, no changes are made at all. Here is the code for the AtomicList context manager:\n\nclass AtomicList:\n\ndef __init__(self, alist, shallow_copy=True):\n\n371\n\n3.1\n\nThread- ing ➤ 439",
      "content_length": 2267,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 381,
      "content": "Shallow and deep copying 146➤\n\n372\n\nChapter 8. Advanced Programming Techniques\n\nself.original = alist self.shallow_copy = shallow_copy\n\ndef __enter__(self):\n\nself.modified = (self.original[:] if self.shallow_copy\n\nelse copy.deepcopy(self.original))\n\nreturn self.modified\n\ndef __exit__(self, exc_type, exc_val, exc_tb):\n\nif exc_type is None:\n\nself.original[:] = self.modified\n\nWhen the AtomicList object is created we keep a reference to the original list and note whether shallow copying is to be used. (Shallow copying is ﬁne for lists of numbers or strings; but for lists that contain lists or other collections, shallow copying is not sufﬁcient.)\n\nThen, when the AtomicList context manager object is used in the with state- ment its __enter__() method is called. At this point we copy the original list and return the copy so that all the changes can be made on the copy.\n\nOnce we reach the end of the with statement’s scope the __exit__() method is called. If no exception occurred the exc_type (“exception type”)will be None and we know that we can safely replace the original list’sitemswith the itemsfrom the modiﬁed list. (We cannot do self.original = self.modified because that would just replace one object reference with another and would not affect the original list at all.) But if an exception occurred,we do nothing to the original list and the modiﬁed list is discarded.\n\nThe return value of __exit__() is used to indicate whether any exception that occurred should be propagated. A True value means that we have handled any exception and so no propagation should occur. Normally we always return False or something that evaluates to False in a Boolean context to allow any exception that occurred to propagate. By not giving an explicit return value, our __exit__() returns None which evaluates to False and correctly causes any exception to propagate.\n\nCustom context managers are used in Chapter 11 to ensure that socket connections and gzipped ﬁles are closed, and some of the threading modules contextmanagersareusedin Chapter10toensurethatmutualexclusionlocks are unlocked. You’ll also get the chance to create a more generic atomic contex manager in this chapter’s exercises.\n\nDescriptors\n\nDescriptors are classes which provide access control for the attributes of other classes. Any class that implements one or more of the descriptor special\n\n||",
      "content_length": 2370,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 382,
      "content": "Further Object-Oriented Programming\n\nmethods, __get__(), __set__(), and __delete__(), is called (and can be used as) a descriptor.\n\nThe built-in property() and classmethod() functions are implemented using descriptors. The key to understanding descriptors is that although we create an instance of a descriptor in a class as a class attribute, Python accesses the descriptor through the class’s instances.\n\nTo make things clear, let’s imagine that we have a class whose instances hold some strings. We want to access the strings in the normal way, for example, as a property, but we also want to get an XML-escaped version of the strings whenever we want. One simple solution would be that whenever a string is set we immediately create an XML-escaped copy. But if we had thousands of strings and only ever read the XML version of a few of them, we would be wasting a lot of processing and memory for nothing. So we will create a descriptor that will provide XML-escaped strings on demand without storing them. We will start with the beginning of the client (owner) class, that is, the class that uses the descriptor:\n\nclass Product:\n\n__slots__ = (\"__name\", \"__description\", \"__price\")\n\nname_as_xml = XmlShadow(\"name\") description_as_xml = XmlShadow(\"description\")\n\ndef __init__(self, name, description, price):\n\nself.__name = name self.description = description self.price = price\n\nThe only code we have not shown are the properties; the name is a read-only property and the description and price are readable/writableproperties,all set up in the usual way. (All the code is in the XmlShadow.py ﬁle.) We have used the __slots__ variable to ensure that the class has no __dict__ and can store only the three speciﬁed private attributes;this is not related to or necessary for our use of descriptors. The name_as_xml and description_as_xml classattributesare set to be instancesof the XmlShadow descriptor. Although no Product object hasa name_as_xml attributeor a description_as_xml attribute,thankstothedescriptor we can write code like this (here quoting from the module’s doctests):\n\n>>> product = Product(\"Chisel <3cm>\", \"Chisel & cap\", 45.25) >>> product.name, product.name_as_xml, product.description_as_xml ('Chisel <3cm>', 'Chisel &lt;3cm&gt;', 'Chisel &amp; cap')\n\nThis works because when we try to access, for example, the name_as_xml attribute, Python ﬁnds that the Product class has a descriptor with that name,\n\n373",
      "content_length": 2428,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 383,
      "content": "374\n\nChapter 8. Advanced Programming Techniques\n\nand so usesthe descriptor to get the attribute’svalue. Here’sthe completecode for the XmlShadow descriptor class:\n\nclass XmlShadow:\n\ndef __init__(self, attribute_name):\n\nself.attribute_name = attribute_name\n\ndef __get__(self, instance, owner=None): return xml.sax.saxutils.escape(\n\ngetattr(instance, self.attribute_name))\n\nWhen the name_as_xml and description_as_xml objects are created we pass the name of the Product class’s corresponding attribute to the XmlShadow initializ- er so that the descriptor knows which attribute to work on. Then, when the name_as_xml or description_as_xml attribute is looked up, Python calls the de- scriptor’s __get__() method. The self argument is the instance of the descrip- tor, the instance argument is the Product instance (i.e., the product’s self), and the owner argument is the owning class (Product in this case).We use the getat- tr() function to retrieve the relevant attribute from the product (in this case the relevant property), and return an XML-escaped version of it.\n\nIf the use case was that only a small proportion of the products were accessed for their XML strings, but the strings were often long and the same ones were frequently accessed, we could use a cache. For example:\n\nclass CachedXmlShadow:\n\ndef __init__(self, attribute_name):\n\nself.attribute_name = attribute_name self.cache = {}\n\ndef __get__(self, instance, owner=None):\n\nxml_text = self.cache.get(id(instance)) if xml_text is not None: return xml_text\n\nreturn self.cache.setdefault(id(instance),\n\nxml.sax.saxutils.escape(\n\ngetattr(instance, self.attribute_name)))\n\nWestoretheuniqueidentity of theinstanceasthekey ratherthantheinstance itself because dictionary keys must be hashable (which IDs are), but we don’t want to impose that as a requirement on classes that use the CachedXmlShad- ow descriptor. The key is necessary because descriptors are created per class rather than per instance. (The dict.setdefault() method conveniently returns the value for the given key,or if no item with that key is present,createsa new item with the given key and value and returns the value.)",
      "content_length": 2151,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 384,
      "content": "Further Object-Oriented Programming\n\nHaving seen descriptors used to generate data without necessarily storing it, we will now look at a descriptor that can be used to store all of an object’s at- tribute data, with the object not needing to store anything itself. In the exam- ple,we will just use a dictionary,but in a more realistic context,the data might be stored in a ﬁle or a database. Here’s the start of a modiﬁed version of the Point class that makes use of the descriptor (from the ExternalStorage.py ﬁle):\n\nclass Point:\n\n__slots__ = () x = ExternalStorage(\"x\") y = ExternalStorage(\"y\")\n\ndef __init__(self, x=0, y=0):\n\nself.x = x self.y = y\n\nBy setting __slots__ to an empty tuple we ensure that the class cannot store any data attributes at all. When self.x is assigned to, Python ﬁnds that there isa descriptorwith thename“x”,and sousesthedescriptor’s__set__() method. The rest of the class isn’t shown, but is the same as the original Point class shown in Chapter 6. Here is the complete ExternalStorage descriptor class:\n\nclass ExternalStorage:\n\n__slots__ = (\"attribute_name\",) __storage = {}\n\ndef __init__(self, attribute_name):\n\nself.attribute_name = attribute_name\n\ndef __set__(self, instance, value):\n\nself.__storage[id(instance), self.attribute_name] = value\n\ndef __get__(self, instance, owner=None):\n\nif instance is None: return self\n\nreturn self.__storage[id(instance), self.attribute_name]\n\nEach ExternalStorage object has a single data attribute, attribute_name, which holds the name of the owner class’s data attribute. Whenever an attribute is set we store its value in the private class dictionary, __storage. Similarly, whenever an attribute is retrieved we get it from the __storage dictionary.\n\nAs with all descriptor methods,self is the instance of the descriptor object and instance is the self of the object that contains the descriptor,so here self is an ExternalStorage object and instance is a Point object.\n\n375",
      "content_length": 1948,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 385,
      "content": "376\n\nChapter 8. Advanced Programming Techniques\n\nAlthough __storage is a class attribute,we can access it as self.__storage (just as we can call methods using self.method()), because Python will look for it as an instanceattribute,and not ﬁnding it will then look for it asa classattribute. The one (theoretical) disadvantage of this approach is that if we have a class attribute and an instance attribute with the same name, one would hide the other. (If thiswerereally a problemwecould alwaysrefer totheclassattribute using the class, that is, ExternalStorage.__storage. Although hard-coding the class does not play well with subclassing in general, it doesn’t really matter for private attributes since Python name-mangles the class name into them anyway.)\n\nThe implementation of the __get__() special method is slightly more sophisti- cated than before because we provide a means by which the ExternalStorage instance itself can be accessed. For example,if we have p = Point(3, 4), we can access the x-coordinate with p.x, and we can access the ExternalStorage object that holds all the xs with Point.x.\n\nTo complete our coverage of descriptors we will create the Property descriptor that mimicsthe behavior of the built-in property() function,at least for setters and getters. The code is in Property.py. Here is the complete NameAndExtension class that makes use of it:\n\nclass NameAndExtension:\n\ndef __init__(self, name, extension):\n\nself.__name = name self.extension = extension\n\n@Property def name(self):\n\n# Uses the custom Property descriptor\n\nreturn self.__name\n\n@Property def extension(self):\n\n# Uses the custom Property descriptor\n\nreturn self.__extension\n\n@extension.setter def extension(self, extension):\n\n# Uses the custom Property descriptor\n\nself.__extension = extension\n\nThe usage is just the same as for the built-in @property decorator and for the @propertyName.setter decorator. Here is the start of the Property descriptor’s implementation:\n\nclass Property:\n\ndef __init__(self, getter, setter=None):\n\nself.__getter = getter",
      "content_length": 2045,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 386,
      "content": "Further Object-Oriented Programming\n\nself.__setter = setter self.__name__ = getter.__name__\n\nThe class’s initializer takes one or two functions as arguments. If it is used as a decorator, it will get just the decorated function and this becomes the getter, while the setter is set to None.We use the getter’s name as the property’sname. So for each property, we have a getter, possibly a setter, and a name.\n\ndef __get__(self, instance, owner=None):\n\nif instance is None: return self\n\nreturn self.__getter(instance)\n\nWhen a property is accessed we return the result of calling the getter func- tion where we have passed the instance as its ﬁrst parameter. At ﬁrst sight, self.__getter() looks like a method call, but it is not. In fact, self.__getter is an attribute, one that happens to hold an object reference to a method that was passed in. So what happens is that ﬁrst we retrieve the attribute (self.__getter), and then we call it as a function (). And because it is called as a function rather than as a method we must pass in the relevant self object explicitly ourselves. And in the case of a descriptor the self object (from the class that is using the descriptor)is called instance (since self is the descriptor object).The same applies to the __set__() method.\n\ndef __set__(self, instance, value):\n\nif self.__setter is None:\n\nraise AttributeError(\"'{0}' is read-only\".format(\n\nself.__name__))\n\nreturn self.__setter(instance, value)\n\nIf no setter has been speciﬁed, we raise an AttributeError; otherwise, we call the setter with the instance and the new value.\n\ndef setter(self, setter):\n\nself.__setter = setter return self.__setter\n\nThis method is called when the interpreter reaches, for example, @exten- sion.setter, with the function it decorates as its setter argument. It stores the setter method it has been given (which can now be used in the __set__() method),and returns the setter,since decorators should return the function or method they decorate.\n\nWe have now looked at three quite different uses of descriptors. Descriptors are a very powerful and ﬂexible feature that can be used to do lots of under- the-hood work while appearing to be simple attributes in their client (own- er) class.\n\n377",
      "content_length": 2219,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 387,
      "content": "Sorted- List 269➤\n\n378\n\nChapter 8. Advanced Programming Techniques\n\nClass Decorators\n\nJust as we can create decorators for functions and methods, we can also create decorators for entire classes. Class decorators take a class object (the result of the class statement), and should return a class—normally a modiﬁed version of theclassthey decorate. In thissubsection we will study twoclassdecorators to see how they can be implemented.\n\nIn Chapter 6 we created the SortedList custom collection classthat aggregated a plain list as the private attribute self.__list. Eight of the SortedList meth- odssimply passedon their work to theprivateattribute. For example,hereare how the SortedList.clear() and SortedList.pop() methods were implemented:\n\ndef clear(self):\n\nself.__list = []\n\ndef pop(self, index=-1):\n\nreturn self.__list.pop(index)\n\nThere is nothing we can do about the clear() method since there is no corre- sponding methodfor the list type,but for pop(),andtheother six methodsthat SortedList delegates,we can simply call the list class’scorresponding method. This can be done by using the @delegate class decorator from the book’s Util module. Here is the start of a new version of the SortedList class:\n\n@Util.delegate(\"__list\", (\"pop\", \"__delitem__\", \"__getitem__\",\n\n\"__iter__\", \"__reversed__\", \"__len__\", \"__str__\"))\n\nclass SortedList:\n\nThe ﬁrst argument is the name of the attribute to delegate to, and the second argument is a sequence of one or more methods that we want the delegate() decorator to implement for us so that we don’t have to do the work ourselves. The SortedList class in the SortedListDelegate.py ﬁle uses this approach and therefore does not have any code for the methods listed, even though it fully supports them. Here is the class decorator that implements the methods:\n\ndef delegate(attribute_name, method_names):\n\ndef decorator(cls):\n\nnonlocal attribute_name if attribute_name.startswith(\"__\"):\n\nattribute_name = \"_\" + cls.__name__ + attribute_name\n\nfor name in method_names:\n\nsetattr(cls, name, eval(\"lambda self, *a, **kw: \"\n\n\"self.{0}.{1}(*a, **kw)\".format( attribute_name, name)))\n\nreturn cls\n\nreturn decorator\n\n||",
      "content_length": 2156,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 388,
      "content": "Fuzzy- Bool 248➤\n\nFurther Object-Oriented Programming\n\nWe could not use a plain decorator because we want to pass arguments to the decorator,so we have instead created a function that takes our argumentsand that returns a class decorator. The decorator itself takes a single argument, a class (just as a function decorator takes a single function or method as its argument).\n\nWe must use nonlocal so that the nested function uses the attribute_name from the outer scope rather than attempting to use one from its own scope. And we must be able to correct the attribute name if necessary to take account of the name mangling of private attributes. The decorator’s behavior is quite simple: It iterates over all the method names that the delegate() function has been given,and for each one createsa new method which it setsasan attribute on the class with the given method name.\n\nWe have used eval() to create each of the delegated methods since it can be used to execute a single statement,and a lambda statement produces a method or function. For example, the code executed to produce the pop() method is:\n\nlambda self, *a, **kw: self._SortedList__list.pop(*a, **kw)\n\nWe use the * and ** argument forms to allow for any arguments even though the methods being delegated to have speciﬁc argument lists. For example, list.pop() accepts a single index position (or nothing,in which case it defaults to the last item). This is okay because if the wrong number or kinds of argu- ments are passed, the list method that is called to do the work will raise an appropriate exception.\n\nThe second class decorator we will review was also used in Chapter 6. When we implemented the FuzzyBool class we mentioned that we had supplied only the __lt__() and __eq__() special methods (for < and ==), and had generated all the other comparison methods automatically. What we didn’t show was the complete start of the class deﬁnition:\n\n@Util.complete_comparisons class FuzzyBool:\n\nThe other four comparison operators were provided by the complete_compar- isons() classdecorator. Given a classthat deﬁnes only < (or < and ==),the deco- rator producesthe missing comparisonoperatorsby using the following logical equivalences:\n\nx = y ⇔ ¬ (x < y ∨ y < x) x ≠ y ⇔ ¬ (x = y) x > y ⇔ y < x x ≤ y ⇔ ¬ (y < x) x ≥ y ⇔ ¬ (x < y)\n\nIf the class to be decorated has < and ==, the decorator will use them both, falling back to doing everything in terms of < if that is the only operator\n\n379",
      "content_length": 2459,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 389,
      "content": "380\n\nChapter 8. Advanced Programming Techniques\n\nsupplied. (In fact, Python automatically produces > if < is supplied, != if == is supplied, and >= if <= is supplied, so it is sufﬁcient to just implement the three operators <, <=, and == and to leave Python to infer the others. However, using the class decorator reduces the minimum that we must implement to just <. This is convenient, and also ensures that all the comparison operators use the same consistent logic.)\n\ndef complete_comparisons(cls):\n\nassert cls.__lt__ is not object.__lt__, (\n\n\"{0} must define < and ideally ==\".format(cls.__name__))\n\nif cls.__eq__ is object.__eq__:\n\ncls.__eq__ = lambda self, other: (not\n\n(cls.__lt__(self, other) or cls.__lt__(other, self)))\n\ncls.__ne__ = lambda self, other: not cls.__eq__(self, other) cls.__gt__ = lambda self, other: cls.__lt__(other, self) cls.__le__ = lambda self, other: not cls.__lt__(other, self) cls.__ge__ = lambda self, other: not cls.__lt__(self, other) return cls\n\nOne problem that the decorator faces is that class object from which every other class is ultimately derived deﬁnes all six comparison operators, all of which raise a TypeError exception if used. So we need to know whether < and == havebeen reimplemented(and arethereforeusable).Thiscan easily bedone by comparing the relevant special methods in the class being decorated with those in object.\n\nIf the decorated class does not have a custom < the assertion fails because that is the decorator’s minimum requirement. And if there is a custom == we use it; otherwise, we create one. Then all the other methods are created and the decorated class, now with all six comparison methods, is returned.\n\nUsing class decorators is probably the simplest and most direct way of Meta- classes changing classes. Another approach isto use metaclasses,a topic we will cover ➤ 390 later in this chapter.\n\nAbstract Base Classes\n\n||\n\nAn abstract base class (ABC) is a class that cannot be used to create objects. Instead, the purpose of such classes is to deﬁne interfaces, that is, to in effect list the methodsand propertiesthat classesthat inherit the abstract base class must provide. This is useful because we can use an abstract base class as a kind of promise—a promise that any derived class will provide the methods and properties that the abstract base class speciﬁes.★\n\n★ Python’s abstract base classes are described in PEP 3119 (www.python.org/dev/peps/pep-3119), which also includes a very useful rationale and is well worth reading.",
      "content_length": 2512,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 390,
      "content": "Further Object-Oriented Programming\n\n381\n\nTable 8.3 The Numbers Module’s Abstract Base Classes\n\nABC\n\nInherits\n\nAPI\n\nExamples\n\nNumber\n\nComplex\n\nReal\n\nobject\n\nNumber\n\nComplex\n\n==, !=, +, -, *, /, abs(), bool(), complex(), conjugate(); also real and imag properties\n\n<, <=, ==, !=, >=, >, +, -, *, /, //, %, abs(), bool(), complex(), conjugate(), divmod(), float(), math.ceil(), math.floor(), round(), trunc(); also real and imag properties\n\ncomplex, decimal.Decimal, float, fractions.Fraction, int complex, decimal.Decimal, float, fractions.Fraction, int decimal.Decimal, float, fractions.Fraction, int\n\nRational\n\nReal\n\n<, <=, ==, !=, >=, >, +, -, *, /, //, %, abs(), bool(), complex(), conjugate(), divmod(), float(), math.ceil(), math.floor(), round(), trunc(); also real, imag, numerator, and denominator properties\n\nfractions.Fraction, int\n\nIntegral\n\nRational <, <=, ==, !=, >=, >, +, -, *, /, //,\n\nint\n\n%, <<, >>, ~, &, ^, |, abs(), bool(), complex(), conjugate(), divmod(), float(), math.ceil(), math.floor(), pow(), round(), trunc(); also real, imag, numerator, and denominator properties\n\nAbstract base classes are classes that have at least one abstract method or property. Abstract methods can be deﬁned with no implementation (i.e., their suite is pass, or if we want to force reimplementation in a subclass, raise NotImplementedError()), or with an actual (concrete) implementation that can be invoked from subclasses, for example, when there is a common case. They can also have other concrete (i.e., nonabstract) methods and properties.\n\nClasses that derive from an ABC can be used to create instances only if they reimplement all the abstract methodsand abstract propertiesthey have inher- ited. For those abstract methods that have concrete implementations (even if it is only pass), the derived class could simply use super() to use the ABC’s ver-",
      "content_length": 1862,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 391,
      "content": "382\n\nChapter 8. Advanced Programming Techniques\n\nsion. Any concrete methodsor propertiesare available through inheritance as usual. All ABCs must have a metaclass of abc.ABCMeta (from the abc module), or from one of its subclasses. We cover metaclasses a bit further on.\n\nPython provides two groups of abstract base classes, one in the collections module and the other in the numbers module. They allow us to ask questions about an object; for example, given a variable x, we can see whether it is a se- quence using isinstance(x, collections.MutableSequence) or whether it is a whole number using isinstance(x, numbers.Integral). This is particularly use- ful in view of Python’s dynamic typing where we don’t necessarily know (or care) what an object’s type is, but want to know whether it supports the oper- ations we want to apply to it. The numeric and collection ABCs are listed in Tables8.3and 8.4.The other major ABCis io.IOBase from which all the ﬁle and stream-handling classes derive.\n\nTo fully integrate our own custom numeric and collection classes we ought to make them ﬁt in with the standard ABCs. For example,the SortedList class is a sequence, but as it stands, isinstance(L, collections.Sequence) returns False if L is a SortedList. One easy way to ﬁx this is to inherit the relevant ABC:\n\nclass SortedList(collections.Sequence):\n\nBy making collections.Sequence the base class, the isinstance() test will now return True. Furthermore, we will be required to implement __init__() (or __new__()), __getitem__(), and __len__() (which we do). The collec- tions.Sequence ABC also provides concrete (i.e., nonabstract) implementations for __contains__(), __iter__(), __reversed__(), count(), and index(). In the case of SortedList, we reimplement them all, but we could have used the ABC ver- sions if we wanted to, simply by not reimplementing them. We cannot make SortedList a subclass of collections.MutableSequence even though the list is mutable because SortedList does not have all the methods that a collec- tions.MutableSequence must provide, such as __setitem__() and append(). (The code for this SortedList is in SortedListAbc.py. We will see an alternative ap- proach to making a SortedList into a collections.Sequence in the Metaclasses subsection.)\n\nNow that we have seen how to make a custom class ﬁt in with the standard ABCs, we will turn to another use of ABCs: to provide an interface promise for our own custom classes. We will look at three rather different examples to cover different aspects of creating and using ABCs.\n\nWe will start with a very simple example that shows how to handle read- able/writable properties. The class is used to represent domestic appliances. Every appliancethat iscreatedmust have a read-only modelstring and a read- able/writable price. We also want to ensure that the ABC’s __init__() is reim- plemented. Here’s the ABC (from Appliance.py); we have not shown the import\n\nMeta- classes ➤ 390\n\nMeta- classes ➤ 390",
      "content_length": 2977,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 392,
      "content": "Further Object-Oriented Programming\n\nTable 8.4 The Collections Module’s Main Abstract Base Classes\n\nABC\n\nInherits\n\nAPI\n\nExamples\n\nCallable\n\nContainer\n\nHashable\n\nIterable\n\nobject\n\nobject\n\nobject\n\nobject\n\n()\n\nin\n\nhash()\n\niter()\n\nAll functions, methods, and lambdas bytearray, bytes, dict, frozenset, list, set, str, tuple bytes, frozenset, str, tuple bytearray, bytes, collections.deque, dict, frozenset, list, set, str, tuple\n\nIterator\n\nIterable\n\niter(), next()\n\nSized\n\nobject\n\nlen()\n\nbytearray, bytes, collections.deque, dict, frozenset, list, set, str, tuple\n\nMapping\n\nMutable- Mapping\n\nSequence\n\nMutable- Sequence\n\nSet\n\nMutableSet\n\nContainer, Iterable, Sized\n\nMapping\n\nContainer, Iterable, Sized Container, Iterable, Sized\n\nContainer, Iterable, Sized Set\n\n==, !=, [], len(), iter(), in, get(), items(), keys(), values() ==, !=, [], del, len(), iter(), in, clear(), get(), items(), keys(), pop(), popitem(), setdefault(), update(), values() [], len(), iter(), reversed(), in, count(), index()\n\n[], +=, del, len(), iter(), reversed(), in, append(), count(), extend(), index(), insert(), pop(), remove(), reverse() <, <=, ==, !=, =>, >, &, |, ^, len(), iter(), in, isdisjoint()\n\n<, <=, ==, !=, =>, >, &, |, ^, &=, |=, ^=, -=, len(), iter(), in, add(), clear(), discard(), isdisjoint(), pop(), remove()\n\ndict\n\ndict\n\nbytearray, bytes, list, str, tuple\n\nbytearray, list\n\nfrozenset, set\n\nset\n\n383",
      "content_length": 1391,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 393,
      "content": "384\n\nChapter 8. Advanced Programming Techniques\n\nabc statement which is needed for the abstractmethod() and abstractproperty() functions, both of which can be used as decorators:\n\nclass Appliance(metaclass=abc.ABCMeta):\n\n@abc.abstractmethod def __init__(self, model, price):\n\nself.__model = model self.price = price\n\ndef get_price(self):\n\nreturn self.__price\n\ndef set_price(self, price): self.__price = price\n\nprice = abc.abstractproperty(get_price, set_price)\n\n@property def model(self):\n\nreturn self.__model\n\nWe have set the class’s metaclass to be abc.ABCMeta since this is a requirement for ABCs; any abc.ABCMeta subclass can be used instead, of course. We have made __init__() an abstract method to ensure that it is reimplemented, and we have also provided an implementation which we expect (but can’t force) inheritors to call. To make an abstract readable/writable property we cannot use decorator syntax; also we have not used private names for the getter and setter since doing so would be inconvenient for subclasses.\n\nThe price property isabstract(sowecannotusethe @property decorator),andis readable/writable. Here we follow a common pattern for when we have private readable/writable data (e.g., __price) as a property: We initialize the property in the __init__() method rather than setting the private data directly—this ensures that the setter is called (and may potentially do validation or other work, although it doesn’t in this particular example).\n\nThe model property is not abstract, so subclasses don’t need to reimplement it, and we can make it a property using the @property decorator. Here we follow a common pattern for when we have private read–only data (e.g., __model) as a property:We set the private __model data once in the __init__() method, and provide read access via the read–only model property.\n\nNote that no Appliance objects can be created, because the class contains abstract attributes. Here is an example subclass:",
      "content_length": 1959,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 394,
      "content": "Further Object-Oriented Programming\n\nclass Cooker(Appliance):\n\ndef __init__(self, model, price, fuel): super().__init__(model, price) self.fuel = fuel\n\nprice = property(lambda self: super().price,\n\nlambda self, price: super().set_price(price))\n\nThe Cooker class must reimplement the __init__() method and the price property. For theproperty wehavejust passedon allthework tothebaseclass. The model read-only property is inherited. We could create many more classes based on Appliance, such as Fridge, Toaster, and so on.\n\nThe next ABC we will look at is even shorter; it is an ABC for text-ﬁltering functors (in ﬁle TextFilter.py):\n\nclass TextFilter(metaclass=abc.ABCMeta):\n\n@abc.abstractproperty def is_transformer(self):\n\nraise NotImplementedError()\n\n@abc.abstractmethod def __call__(self):\n\nraise NotImplementedError()\n\nThe TextFilter ABC provides no functionality at all; it exists purely to deﬁne an interface,in thiscase an is_transformer read-only property and a __call__() method, that all its subclasses must provide. Since the abstract property and method have no implementations we don’t want subclasses to call them, so instead of using an innocuous pass statement we raise an exception if they are used (e.g., via a super() call).\n\nHere is one simple subclass:\n\nclass CharCounter(TextFilter):\n\n@property def is_transformer(self):\n\nreturn False\n\ndef __call__(self, text, chars):\n\ncount = 0 for c in text:\n\nif c in chars: count += 1\n\nreturn count\n\n385",
      "content_length": 1462,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 395,
      "content": "386\n\nChapter 8. Advanced Programming Techniques\n\nThis text ﬁlter is not a transformer because rather than transforming the text it is given, it simply returns a count of the speciﬁed characters that occur in the text. Here is an example of use:\n\nvowel_counter = CharCounter() vowel_counter(\"dog fish and cat fish\", \"aeiou\")\n\n# returns: 5\n\nTwo other text ﬁlters are provided,both of which are transformers:RunLength- Encode and RunLengthDecode. Here is how they are used:\n\nrle_encoder = RunLengthEncode() rle_text = rle_encoder(text) ... rle_decoder = RunLengthDecode() original_text = rle_decoder(rle_text)\n\nThe run length encoder converts a string into UTF-8 encoded bytes, and replaces 0x00 bytes with the sequence 0x00, 0x01, 0x00, and any sequence of threeto 255repeatedbyteswith thesequence 0x00,count,byte.If thestring has lots of runs of four or more identical consecutive charactersthis can produce a shorter byte string than the raw UTF-8encoded bytes. The run length decoder takes a run length encoded byte string and returnsthe original string. Here is the start of the RunLengthDecode class:\n\nclass RunLengthDecode(TextFilter):\n\n@property def is_transformer(self):\n\nreturn True\n\ndef __call__(self, rle_bytes):\n\n...\n\nWe have omitted the body of the __call__() method, although it is in the source that accompanies this book. The RunLengthEncode class has exactly the same structure.\n\nThe last ABC we will look at provides an Application Programming Interface (API) and a default implementation for an undo mechanism. Here is the complete ABC (from ﬁle Abstract.py):\n\nclass Undo(metaclass=abc.ABCMeta):\n\n@abc.abstractmethod def __init__(self):\n\nself.__undos = []",
      "content_length": 1672,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 396,
      "content": "Further Object-Oriented Programming\n\n@abc.abstractproperty def can_undo(self):\n\nreturn bool(self.__undos)\n\n@abc.abstractmethod def undo(self):\n\nassert self.__undos, \"nothing left to undo\" self.__undos.pop()(self)\n\ndef add_undo(self, undo):\n\nself.__undos.append(undo)\n\nThe __init__() and undo() methods must be reimplemented since they are both abstract; and so must the read-only can_undo property. Subclasses don’t have to reimplement the add_undo() method, although they are free to do so. The undo() method is slightly subtle. The self.__undos list is expected to hold object references to methods. Each method must cause the corresponding action to be undone if it is called—this will be clearer when we look at an Undo subclass in a moment. So to perform an undo we pop the last undo method off the self.__undos list,and then call the method as a function,passing self as an argument. (Wemust passself becausethemethodisbeing called asa function and not as a method.)\n\nHere is the beginning of the Stack class; it inherits Undo, so any actions per- formed on it can be undone by calling Stack.undo() with no arguments:\n\nclass Stack(Undo):\n\ndef __init__(self):\n\nsuper().__init__() self.__stack = []\n\n@property def can_undo(self):\n\nreturn super().can_undo\n\ndef undo(self):\n\nsuper().undo()\n\ndef push(self, item):\n\nself.__stack.append(item) self.add_undo(lambda self: self.__stack.pop())\n\ndef pop(self):\n\nitem = self.__stack.pop() self.add_undo(lambda self: self.__stack.append(item)) return item\n\n387",
      "content_length": 1502,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 397,
      "content": "388\n\nChapter 8. Advanced Programming Techniques\n\nWe have omitted Stack.top() and Stack.__str__() since neither adds anything new and neither interacts with the Undo base class. For the can_undo property and the undo() method, we simply pass on the work to the base class. If these two were not abstract we would not need to reimplement them at all and the same effect would be achieved; but in this case we wanted to force subclasses to reimplement them to encourage undo to be taken account of in the subclass. For push() and pop() we perform the operation and also add a function to the undo list which will undo the operation that has just been performed.\n\nAbstract base classes are most useful in large-scale programs, libraries, and application frameworks, where they can help ensure that irrespective of implementation details or author, classes can work cooperatively together because they provide the APIs that their ABCs specify.\n\nMultiple Inheritance\n\nMultipleinheritanceiswhereoneclassinheritsfromtwoor moreother classes. Although Python (and, for example, C++) fully supports multiple inheritance, some languages—most notably, Java—don’t allow it. One problem is that multiple inheritancecan lead to the same classbeing inherited more than once (e.g.,if twoof thebaseclassesinherit fromthesameclass),andthismeansthat the version of a method that is called, if it is not in the subclass but is in two or more of the base classes (or their base classes, etc.), depends on the method resolutionorder,whichpotentially makesclassesthatusemultipleinheritance somewhat fragile.\n\nMultiple inheritance can generally be avoided by using single inheritance(one base class), and setting a metaclass if we want to support an additional API, since as we will see in the next subsection, a metaclass can be used to give the promise of an API without actually inheriting any methodsor data attributes. An alternative is to use multiple inheritance with one concrete class and one or more abstract base classes for additional APIs. And another alternative is to use single inheritance and aggregate instances of other classes.\n\nNonetheless,in somecases,multipleinheritancecan providea very convenient solution. For example, suppose we want to create a new version of the Stack class from the previous subsection, but want the class to support loading and saving using a pickle. We might well want to add the loading and saving functionality to several classes, so we will implement it in a class of its own:\n\nclass LoadSave:\n\ndef __init__(self, filename, *attribute_names):\n\nself.filename = filename self.__attribute_names = [] for name in attribute_names:\n\nif name.startswith(\"__\"):\n\n||",
      "content_length": 2682,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 398,
      "content": "Further Object-Oriented Programming\n\nname = \"_\" + self.__class__.__name__ + name\n\nself.__attribute_names.append(name)\n\ndef save(self):\n\nwith open(self.filename, \"wb\") as fh:\n\ndata = [] for name in self.__attribute_names:\n\ndata.append(getattr(self, name))\n\npickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)\n\ndef load(self):\n\nwith open(self.filename, \"rb\") as fh:\n\ndata = pickle.load(fh) for name, value in zip(self.__attribute_names, data):\n\nsetattr(self, name, value)\n\nThe class has two attributes: filename, which is public and can be changed at any time, and __attribute_names, which is ﬁxed and can be set only when the instance is created. The save() method iterates over all the attribute names and creates a list called data that holds the value of each attribute to be saved; it then saves the data into a pickle. The with statement ensures that the ﬁle is closed if it wassuccessfully opened,and any ﬁleor pickleexceptionsarepassed up to the caller. The load() method iterates over the attribute names and the corresponding data items that have been loaded and sets each attribute to its loaded value.\n\nHere is the start of the FileStack class that multiply-inherits the Undo class from the previous subsection and this subsection’s LoadSave class:\n\nclass FileStack(Undo, LoadSave):\n\ndef __init__(self, filename):\n\nUndo.__init__(self) LoadSave.__init__(self, filename, \"__stack\") self.__stack = []\n\ndef load(self):\n\nsuper().load() self.clear()\n\nThe rest of the class is just the same as the Stack class, so we have not repro- duced it here. Instead of using super() in the __init__() method we must spec- ify the base classesthat we initialize since super() cannot guessour intentions. For the LoadSave initialization we pass the ﬁlename to use and also the names of the attributes we want saved; in this case just one, the private __stack. (We don’t want to save the __undos; and nor could we in this case since it is a list of methods and is therefore unpicklable.)\n\n389",
      "content_length": 1977,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 399,
      "content": "390\n\nChapter 8. Advanced Programming Techniques\n\nThe FileStack classhasallthe Undo methods,andalsothe LoadSave class’ssave() and load() methods. We have not reimplemented save() since it works ﬁne, but for load() we must clear the undo stack after loading. This is necessary becausewemight doa save,then dovariouschanges,and then a load. Theload wipes out what went before, so any undos no longer make sense. The original Undo class did not have a clear() method, so we had to add one:\n\ndef clear(self):\n\n# In class Undo\n\nself.__undos = []\n\nIn the Stack.load() method we have used super() to call LoadSave.load() be- cause there is no Undo.load() method to cause ambiguity. If both base class- es had had a load() method, the one that would get called would depend on Python’s method resolution order. We prefer to use super() only when there is no ambiguity, and to use the appropriate base name otherwise, so we never rely on the method resolution order. For the self.clear() call,again there isno ambiguity since only the Undo class has a clear() method, and we don’t need to use super() since (unlike load()) FileStack does not have a clear() method.\n\nWhat would happen if, later on, a clear() method was added to the FileStack class? It would break the load() method. One solution would be to call su- per().clear() inside load() instead of plain self.clear(). This would result in the ﬁrst super-class’s clear() method that was found being used. To protect against such problemswe could make it a policy to use hard-coded base classes when using multipleinheritance(in thisexample,calling Undo.clear(self)).Or we could avoid multiple inheritance altogether and use aggregation,for exam- ple, inheriting the Undo class and creating a LoadSave class designed for aggre- gation.\n\nWhat multiple inheritance has given us here is a mixture of two rather dif- ferent classes, without the need to implement any of the undo or the loading and saving ourselves,relying instead on the functionality provided by the base classes. Thiscan be very convenient and worksespecially well when theinher- ited classes have no overlapping APIs.\n\nMetaclasses\n\nA metaclass is to a class what a class is to an instance; that is, a metaclass is used to create classes, just as classes are used to create instances. And just as we can ask whether an instance belongs to a class by using isinstance(), we can ask whether a classobject (such as dict,int,or SortedList)inheritsanother class using issubclass().\n\nThe simplest use of metaclasses is to make custom classes ﬁt into Python’s standard ABC hierarchy. For example, to make SortedList a collections.\n\n||",
      "content_length": 2638,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 400,
      "content": "Further Object-Oriented Programming\n\nSequence, instead of inheriting the ABC (as we showed earlier), we can simply register the SortedList as a collections.Sequence:\n\nclass SortedList:\n\n...\n\ncollections.Sequence.register(SortedList)\n\nAfter the classis deﬁned normally,we register it with the collections.Sequence ABC. Registering a class like this makes it a virtual subclass.★ A virtual sub- classreportsthat it isa subclassof theclassor classesit isregisteredwith (e.g., using isinstance() or issubclass()), but does not inherit any data or methods from any of the classes it is registered with.\n\nRegistering a class like this provides a promise that the class provides the API of the classes it is registered with, but does not provide any guarantee that it will honor itspromise. One use of metaclassesisto provideboth a promiseand a guarantee about a class’s API. Another use is to modify a class in some way (like a class decorator does). And of course, metaclasses can be used for both purposes at the same time.\n\nSuppose we want to create a group of classesthat all provide load() and save() methods. We can do this by creating a class that when used as a metaclass, checks that these methods are present:\n\nclass LoadableSaveable(type):\n\ndef __init__(cls, classname, bases, dictionary):\n\nsuper().__init__(classname, bases, dictionary) assert hasattr(cls, \"load\") and \\\n\nisinstance(getattr(cls, \"load\"),\n\ncollections.Callable), (\"class '\" +\n\nclassname + \"' must provide a load() method\")\n\nassert hasattr(cls, \"save\") and \\\n\nisinstance(getattr(cls, \"save\"),\n\ncollections.Callable), (\"class '\" +\n\nclassname + \"' must provide a save() method\")\n\nClasses that are to serve as metaclasses must inherit from the ultimate metaclass base class, type, or one of its subclasses.\n\nNote that this class is called when classes that use it are instantiated, in all probability not very often, so the runtime cost is extremely low. Notice also that we must perform the checks after the class has been created (using the super() call), since only then will the class’s attributes be available in the class itself. (The attributesare in the dictionary,but we prefer to work on the actual initialized class when doing checks.)\n\n★In Python terminology, virtual does not mean the same thing as it does in C++ terminology.\n\n391",
      "content_length": 2312,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 401,
      "content": "col- lections ABCs 383➤\n\n392\n\nChapter 8. Advanced Programming Techniques\n\nWe could have checked that the load and save attributes are callable using hasattr() to check that they have the __call__ attribute, but we prefer to check whether they are instancesof collections.Callable instead. The collec- tions.Callable abstractbaseclassprovidesthepromise(butnoguarantee)that instances of its subclasses (or virtual subclasses) are callable.\n\nOnce the class has been created (using type.__new__() or a reimplementation of __new__()), the metaclass is initialized by calling its __init__() method. The arguments given to __init__() are cls, the class that’s just been created; classname, the class’s name (also available from cls.__name__); bases, a list of the class’s base classes (excluding object, and therefore possibly empty); and dictionary that holds the attributes that became class attributes when the cls class was created, unless we intervened in a reimplementation of the meta- class’s __new__() method.\n\nHere are a couple of interactive examples that show what happens when we create classes using the LoadableSaveable metaclass:\n\n>>> class Bad(metaclass=Meta.LoadableSaveable): ... Traceback (most recent call last): ... AssertionError: class 'Bad' must provide a load() method\n\ndef some_method(self): pass\n\nThemetaclassspeciﬁesthat classesusing it must providecertainmethods,and when they don’t, as in this case, an AssertionError exception is raised.\n\n>>> class Good(metaclass=Meta.LoadableSaveable): ... ... >>> g = Good()\n\ndef load(self): pass def save(self): pass\n\nThe Good classhonorsthe metaclass’sAPI requirements,even if it doesn’t meet our informal expectations of how it should behave.\n\nWe can also use metaclassesto change the classesthat use them. If thechange involves the name, base classes, or dictionary of the class being created (e.g., its slots), then we need to reimplement the metaclass’s __new__() method; but for other changes, such as adding methods or data attributes,reimplementing __init__() issufﬁcient,although thiscan also be donein __new__().We will now look at a metaclass that modiﬁes the classes it is used with purely through its __new__() method.\n\nAs an alternative to using the @property and @name.setter decorators, we could create classeswhere we use a simple naming convention to identify properties. For example, if a class has methods of the form get_name() and set_name(), we would expect the class to have a private __name property accessed using",
      "content_length": 2501,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 402,
      "content": "Further Object-Oriented Programming\n\ninstance.name for getting and setting. This can all be done using a metaclass. Here is an example of a class that uses this convention:\n\nclass Product(metaclass=AutoSlotProperties):\n\ndef __init__(self, barcode, description):\n\nself.__barcode = barcode self.description = description\n\ndef get_barcode(self):\n\nreturn self.__barcode\n\ndef get_description(self):\n\nreturn self.__description\n\ndef set_description(self, description):\n\nif description is None or len(description) < 3:\n\nself.__description = \"<Invalid Description>\"\n\nelse:\n\nself.__description = description\n\nWe must assign to the private __barcode property in the initializer since there is no setter for it; another consequence of this is that barcode is a read-only property. On the other hand,description isa readable/writableproperty. Here are some examples of interactive use:\n\n>>> product = Product(\"101110110\", \"8mm Stapler\") >>> product.barcode, product.description ('101110110', '8mm Stapler') >>> product.description = \"8mm Stapler (long)\" >>> product.barcode, product.description ('101110110', '8mm Stapler (long)')\n\nIf we attempt to assign to the bar code an AttributeError exception is raised with the error text “can’t set attribute”.\n\nIf we look at the Product class’s attributes (e.g., using dir()), the only public ones to be found are barcode and description. The get_name() and set_name() methods are no longer there—they have been replaced with the name property. And the variables holding the bar code and description are also private (__bar- code and __description), and have been added as slots to minimize the class’s memory use. This is all done by the AutoSlotProperties metaclass which is im- plemented in a single method:\n\nclass AutoSlotProperties(type):\n\ndef __new__(mcl, classname, bases, dictionary):\n\nslots = list(dictionary.get(\"__slots__\", []))\n\n393",
      "content_length": 1874,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 403,
      "content": "394\n\nChapter 8. Advanced Programming Techniques\n\nfor getter_name in [key for key in dictionary\n\nif key.startswith(\"get_\")]:\n\nif isinstance(dictionary[getter_name],\n\ncollections.Callable):\n\nname = getter_name[4:] slots.append(\"__\" + name) getter = dictionary.pop(getter_name) setter_name = \"set_\" + name setter = dictionary.get(setter_name, None) if (setter is not None and\n\nisinstance(setter, collections.Callable)): del dictionary[setter_name]\n\ndictionary[name] = property(getter, setter)\n\ndictionary[\"__slots__\"] = tuple(slots) return super().__new__(mcl, classname, bases, dictionary)\n\nA metaclass’s__new__() classmethod iscalled with the metaclass,and theclass name, base classes, and dictionary of the class that is to be created. We must use a reimplementation of __new__() rather than __init__() because we want to change the dictionary before the class is created.\n\nWe begin by copying the __slots__ collection, creating an empty one if none is present, and making sure we have a list rather than a tuple so that we can modify it. For every attribute in the dictionary we pick out those that begin with \"get_\" and that are callable, that is, those that are getter methods. For each getter we add a private name to the slots to store the corresponding data; for example,given getter get_name() we add __name to the slots. We then take a referenceto thegetter and deleteit fromthedictionary under itsoriginalname (this is done in one go using dict.pop()).We do the same for the setter if one is present, and then we create a new dictionary item with the desired property name as its key; for example, if the getter is get_name() the property name is name. We set the item’s value to be a property with the getter and setter (which might be None) that we have found and removed from the dictionary.\n\nAt the end we replace the original slots with the modiﬁed slots list which has a private slot for each property that was added,and call on the base classto ac- tually createtheclass,but using our modiﬁed dictionary. Note that in thiscase we must passthe metaclassexplicitly in the super() call;thisisalwaysthe case for calls to __new__() because it is a class method and not an instance method.\n\nFor thisexamplewedidn’tneed towritean __init__() methodbecausewehave done all the work in __new__(), but it is perfectly possible to reimplement both __new__() and __init__() doing different work in each.\n\nIf we consider hand-cranked drills to be analogous to aggregation and inher- itance and electric drills the analog of decorators and descriptors, then meta- classes are at the laser beam end of the scale when it comes to power and",
      "content_length": 2637,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 404,
      "content": "Further Object-Oriented Programming\n\nversatility. Metaclasses are the last tool to reach for rather than the ﬁrst, ex- cept perhapsfor application framework developerswho need to provide power- fulfacilitiestotheir userswithoutmaking theusersgothroughhoopstorealize the beneﬁts on offer.\n\nFunctional-Style Programming\n\nFunctional-style programming is an approach to programming where com- putations are built up from combining functions that don’t modify their argu- ments and that don’t refer to or change the program’s state, and that provide their resultsas return values. One strong appeal of this kind of programming is that (in theory), it is much easier to develop functions in isolation and to de- bug functional programs. This is helped by the fact that functional programs don’t have state changes,so it is possible to reason about their functionsmath- ematically.\n\nThree concepts that are strongly associated with functional programming are mapping, ﬁltering, and reducing. Mapping involves taking a function and an iterable and producing a new iterable (or a list) where each item is the result of calling the function on the corresponding item in the original iterable. This is supported by the built-in map() function, for example:\n\nlist(map(lambda x: x ** 2, [1, 2, 3, 4]))\n\n# returns: [1, 4, 9, 16]\n\nThe map() function takes a function and an iterable as its arguments and for efﬁciency it returns an iterator rather than a list. Here we forced a list to be created to make the result clearer:\n\n[x ** 2 for x in [1, 2, 3, 4]]\n\n# returns: [1, 4, 9, 16]\n\nA generator expression can often be used in place of map(). Here we have used a list comprehension to avoid the need to use list(); to make it a generator we just have to change the outer brackets to parentheses.\n\nFiltering involves taking a function and an iterable and producing a new it- erable where each item is from the original iterable—providing the function returns True when called on the item. The built-in filter() function sup- ports this:\n\nlist(filter(lambda x: x > 0, [1, -2, 3, -4])) # returns: [1, 3]\n\nThe filter() function takes a function and an iterable as its arguments and returns an iterator.\n\n[x for x in [1, -2, 3, -4] if x > 0]\n\n# returns: [1, 3]\n\n395\n\n|||",
      "content_length": 2251,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 405,
      "content": "396\n\nChapter 8. Advanced Programming Techniques\n\nThe filter() function can always be replaced with a generator expression or with a list comprehension.\n\nReducing involves taking a function and an iterable and producing a single result value. The way this works is that the function is called on the iterable’s ﬁrst two values, then on the computed result and the third value, then on the computed result and the fourth value,and so on, until all the values have been used. The functools module’s functools.reduce() function supports this. Here are two lines of code that do the same computation:\n\nfunctools.reduce(lambda x, y: x * y, [1, 2, 3, 4]) # returns: 24 # returns: 24 functools.reduce(operator.mul, [1, 2, 3, 4])\n\nThe operator module has functions for all of Python’s operators speciﬁcally to make functional-style programming easier. Here, in the second line, we have used the operator.mul() function rather than having to create a multiplication function using lambda as we did in the ﬁrst line.\n\nPython also provides some built-in reducing functions: all(), which given an iterable, returns True if all the iterable’s items return True when bool() is ap- plied to them; any(), which returns True if any of the iterable’s items is True; max(), which returns the largest item in the iterable; min(), which returns the smallest item in the iterable; and sum(), which returns the sum of the iter- able’s items.\n\nNow that we have covered the key concepts,let uslook at a few more examples. We will start with a couple of ways to get the total size of all the ﬁles in list files:\n\nfunctools.reduce(operator.add, (os.path.getsize(x) for x in files)) functools.reduce(operator.add, map(os.path.getsize, files))\n\nUsing map() is often shorter than the equivalent list comprehension or genera- tor expression except where there is a condition. We’ve used operator.add() as the addition function instead of lambda x, y: x + y.\n\nIf we only wanted to count the .py ﬁle sizes we can ﬁlter out non-Python ﬁles. Here are three ways to do this:\n\nfunctools.reduce(operator.add, map(os.path.getsize,\n\nfilter(lambda x: x.endswith(\".py\"), files)))\n\nfunctools.reduce(operator.add, map(os.path.getsize,\n\n(x for x in files if x.endswith(\".py\"))))\n\nfunctools.reduce(operator.add, (os.path.getsize(x)\n\nfor x in files if x.endswith(\".py\")))\n\nArguably, the second and third versions are better because they don’t require us to create a lambda function, but the choice between using generator expres-",
      "content_length": 2481,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 406,
      "content": "op- erator. attrget- ter() 369➤\n\nFunctional-StyleProgramming\n\nsions (or list comprehensions) and map() and filter() is most often purely a matter of personal programming style.\n\nUsing map(), filter(), and functools.reduce() often leads to the elimination of loops, as the examples we have seen illustrate. These functions are useful when converting code written in a functional language, but in Python we can usually replace map() with a list comprehension and filter() with a list comprehension with a condition, and many cases of functools.reduce() can be eliminated by using one of Python’sbuilt-in functional functionssuch as all(), any(), max(), min(), and sum(). For example:\n\nsum(os.path.getsize(x) for x in files if x.endswith(\".py\"))\n\nThis achieves the same thing as the previous three examples, but is much more compact.\n\noperator module In addition to providing functions for Python’s operators, the also provides the operator.attrgetter() and operator.itemgetter() functions, the ﬁrst of which we brieﬂy met earlier in this chapter. Both of these return functions which can then be called to extract the speciﬁed attributes or items.\n\nWhereas slicing can be used to extract a sequence of part of a list, and slicing with striding can be used to extract a sequence of parts (say, every third item with L[::3]), operator.itemgetter() can be used to extract a sequence of arbi- trary parts, for example, operator.itemgetter(4, 5, 6, 11, 18)(L). The function returned by operator.itemgetter() does not have to be called immediately and thrown away as we have done here; it could be kept and passed as the function argument to map(), filter(), or functools.reduce(), or used in a dictionary, list, or set comprehension.\n\nWhen we want to sort we can specify a key function. This function can be any function, for example, a lambda function, a built-in function or method (such as str.lower()), or a function returned by operator.attrgetter(). For example, assuming list L holds objects with a priority attribute,we can sort the list into priority order like this: L.sort(key=operator.attrgetter(\"priority\")).\n\nIn addition to the functools and operator modulesalready mentioned,the iter- tools module can also be useful for functional-style programming. For exam- ple, although it is possible to iterate over two or more lists by concatenating them, an alternative is to use itertools.chain() like this:\n\nfor value in itertools.chain(data_list1, data_list2, data_list3):\n\ntotal += value\n\nThe itertools.chain() function returnsan iterator that givessuccessivevalues from the ﬁrst sequence it is given, then successive values from the second sequence, and so on until all the values from all the sequences are used. The itertools module hasmany other functions,and itsdocumentationgivesmany\n\n397",
      "content_length": 2798,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 407,
      "content": "398\n\nChapter 8. Advanced Programming Techniques\n\nsmall yet useful examples and is well worth reading. (Note also that a couple of new functions were added to the itertools module with Python 3.1.)\n\nPartial Function Application\n\nPartial function application is the creation of a function from an existing function and some arguments to produce a new function that does what the original function did, but with some arguments ﬁxed so that callers don’t have to pass them. Here’s a very simple example:\n\nenumerate1 = functools.partial(enumerate, start=1) for lino, line in enumerate1(lines):\n\nprocess_line(i, line)\n\nThe ﬁrst line creates a new function, enumerate1(), that wraps the given func- tion (enumerate()) and a keyword argument (start=1) so that when enumerate1() is called it calls the original function with the ﬁxed argument—and with any other arguments that are given at the time it is called, in this case lines. Here we have used the enumerate1() function to provide conventional line counting starting from line 1.\n\nUsing partial function application can simplify our code, especially when we want to call the same functionswith the same argumentsagain and again. For example, instead of specifying the mode and encoding arguments every time we call open() to process UTF-8 encoded text ﬁles, we could create a couple of functions with these arguments ﬁxed:\n\nreader = functools.partial(open, mode=\"rt\", encoding=\"utf8\") writer = functools.partial(open, mode=\"wt\", encoding=\"utf8\")\n\nNow we can open text ﬁles for reading by calling reader(filename) and for writing by calling writer(filename).\n\nOnevery commonusecasefor partialfunctionapplicationisin GUI(Graphical User Interface) programming (covered in Chapter 15), where it is often conve- nient to have one particular function called when any one of a set of buttons is pressed. For example:\n\nloadButton = tkinter.Button(frame, text=\"Load\",\n\ncommand=functools.partial(doAction, \"load\"))\n\nsaveButton = tkinter.Button(frame, text=\"Save\",\n\ncommand=functools.partial(doAction, \"save\"))\n\nThis example uses the tkinter GUI library that comes as standard with Python. The tkinter.Button class is used for buttons—here we have created two, both contained inside the same frame,and each with a text that indicates its purpose. Each button’s command argument is set to the function that tkinter\n\n||",
      "content_length": 2354,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 408,
      "content": "yield state- ment 341➤\n\nFunctional-StyleProgramming\n\nmust call when the button is pressed, in this case the doAction() function. We have used partial function application to ensure that the ﬁrst argument given to the doAction() function is a string that indicates which button called it so that doAction() is able to decide what action to perform.\n\nCoroutines\n\nCoroutines are functions whose processing can be suspended and resumed at speciﬁc points. So,typically,a coroutine will execute up to a certain statement, then suspend execution while waiting for some data. At this point other parts of the program can continue to execute (usually other coroutines that aren’t suspended). Once the data is received the coroutine resumes from the point it wassuspended,performsprocessing (presumably based on thedata it got),and possibly sending its results to another coroutine. Coroutines are said to have multiple entry and exit points,since they can have more than one place where they suspend and resume.\n\nCoroutines are useful when we want to apply multiple functions to the same pieces of data, or when we want to create data processing pipelines, or when we want to have a master function with slave functions. Coroutines can also be used to provide simpler and lower-overhead alternatives to threading. A fewcoroutine-basedpackagesthatprovidelightweightthreading areavailable from the Python Package Index, pypi.python.org/pypi.\n\nIn Python,a coroutineisa functionthattakesitsinput froma yield expression. It may also send results to a receiver function (which itself must be a corou- tine).Whenever a coroutine reaches a yield expression it suspends waiting for data; and once it receives data, it resumes execution from that point. A corou- tine can have more than one yield expression, although each of the coroutine examples we will review has only one.\n\nPerforming Independent Actions on Data\n\nIf we want to perform a set of independent operations on some data, the conventional approach is to apply each operation in turn. The disadvantageof this is that if one of the operations is slow, the program as a whole must wait for the operation to complete before going on to the next one. A solution to this is to use coroutines. We can implement each operation as a coroutine and then start them all off. If one is slow it won’t affect the others—at least not until they run out of data to process—since they all operate independently.\n\nFigure8.2illustratestheuseof coroutinesforconcurrentprocessing. Intheﬁg- ure, three coroutines (each presumably doing a different job) process the same two data items—and take different amounts of time to do their work. In the ﬁgure, coroutine1() works quite quickly, coroutine2() works slowly, and corou- tine3() varies. Once all three coroutines have been given their initial data\n\n399\n\n||\n\n|",
      "content_length": 2835,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 409,
      "content": "400\n\nChapter 8. Advanced Programming Techniques\n\nStep\n\nAction\n\ncoroutine1()\n\ncoroutine2()\n\ncoroutine3()\n\n1 Create coroutines\n\nWaiting\n\nWaiting\n\nWaiting\n\n2\n\ncoroutine1.send(\"a\") Process \"a\"\n\nWaiting\n\nWaiting\n\n3\n\ncoroutine2.send(\"a\") Process \"a\"\n\nProcess \"a\"\n\nWaiting\n\n4\n\ncoroutine3.send(\"a\") Waiting\n\nProcess \"a\"\n\nProcess \"a\"\n\n5\n\ncoroutine1.send(\"b\") Process \"b\"\n\nProcess \"a\"\n\nProcess \"a\"\n\n6\n\ncoroutine2.send(\"b\") Process \"b\"\n\nProcess \"a\" (\"b\" pending)\n\nProcess \"a\"\n\n7\n\ncoroutine3.send(\"b\") Waiting\n\nProcess \"a\" (\"b\" pending)\n\nProcess \"b\"\n\n8\n\nWaiting\n\nProcess \"b\"\n\nProcess \"b\"\n\n9\n\nWaiting\n\nProcess \"b\"\n\nWaiting\n\n10\n\nWaiting\n\nProcess \"b\"\n\nWaiting\n\n11\n\nWaiting\n\nWaiting\n\nWaiting\n\n12\n\ncoroutineN.close()\n\nFinished\n\nFinished\n\nFinished\n\nFigure 8.2 Sending two items of data to three coroutines\n\nto process, if one is ever waiting (because it ﬁnishes ﬁrst), the others continue to work, which minimizes processor idle time. Once we are ﬁnished using the coroutines we call close() on each of them; this stops them from waiting for more data, which means they won’t consume any more processor time.\n\nTo create a coroutine in Python, we simply create a function that has at least one yield expression—normally inside an inﬁnite loop. When a yield is reached the coroutine’sexecution issuspendedwaiting for data. Once thedata is received the coroutine resumes processing (from the yield expression on- ward),and when it has ﬁnished it loops back to the yield to wait for more data. While one or more coroutines are suspended waiting for data, another one can execute. Thiscanproducegreaterthroughputthansimply executing functions one after the other linearly.\n\nWe will show how performing independent operations works in practice by applying several regular expressions to the text in a set of HTML ﬁles. The purpose is to output each ﬁle’s URLs and level 1 and level 2 headings. We’ll start by looking at the regular expressions, then the creation of the coroutine “matchers”,and then we will look at the coroutines and how they are used.\n\nURL_RE = re.compile(r\"\"\"href=(?P<quote>['\"])(?P<url>[^\\1]+?)\"\"\"\n\nr\"\"\"(?P=quote)\"\"\", re.IGNORECASE)\n\nflags = re.MULTILINE|re.IGNORECASE|re.DOTALL H1_RE = re.compile(r\"<h1>(?P<h1>.+?)</h1>\", flags) H2_RE = re.compile(r\"<h2>(?P<h2>.+?)</h2>\", flags)",
      "content_length": 2277,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 410,
      "content": "Genera- tors 341➤\n\nDecora- tors 356➤\n\nFunctional-StyleProgramming\n\nTheseregular expressions(“regexes”fromnow on)match an HTML href’sURL and the text contained in <h1> and <h2> header tags. (Regular expressions are covered in Chapter 13; understanding them is not essential to understanding this example.)\n\nreceiver = reporter() matchers = (regex_matcher(receiver, URL_RE),\n\nregex_matcher(receiver, H1_RE), regex_matcher(receiver, H2_RE))\n\nSince coroutines always have a yield expression, they are generators. So arecreating although herewe createa tupleof matcher coroutines,in effect we a tuple of generators. Each regex_matcher() isa coroutine that takesa receiver function (itself a coroutine) and a regex to match. Whenever the matcher matches it sends the match to the receiver.\n\n@coroutine def regex_matcher(receiver, regex):\n\nwhile True:\n\ntext = (yield) for match in regex.finditer(text):\n\nreceiver.send(match)\n\nThe matcher starts by entering an inﬁnite loop and immediately suspends execution waiting for the yield expression to return a text to apply the regex to. Once the text is received, the matcher iterates over every match it makes, sending each one to the receiver. Once the matching hasﬁnished the coroutine loops back to the yield and again suspends waiting for more text.\n\nThere is one tiny problem with the (undecorated) matcher—when it is ﬁrst created it should commence execution so that it advances to the yield ready to receive its ﬁrst text. We could do this by calling the built-in next() function on each coroutine we create before sending it any data. But for convenience we have created the @coroutine decorator to do this for us.\n\ndef coroutine(function):\n\n@functools.wraps(function) def wrapper(*args, **kwargs):\n\ngenerator = function(*args, **kwargs) next(generator) return generator\n\nreturn wrapper\n\nThe @coroutine decorator takes a coroutine function, and calls the built-in next() function on it—this causes the function to be executed up to the ﬁrst yield expression, ready to receive data.\n\n401",
      "content_length": 2032,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 411,
      "content": "402\n\nChapter 8. Advanced Programming Techniques\n\nNow that we have seen the matcher coroutinewe will look at how thematchers are used, and then we will look at the reporter() coroutine that receives the matchers’ outputs.\n\ntry:\n\nfor file in sys.argv[1:]:\n\nprint(file) html = open(file, encoding=\"utf8\").read() for matcher in matchers:\n\nmatcher.send(html)\n\nfinally:\n\nfor matcher in matchers: matcher.close()\n\nreceiver.close()\n\nThe program reads the ﬁlenames listed on the command line, and for each one prints the ﬁlename and then reads the ﬁle’s entire text into the html variable using the UTF-8 encoding. Then the program iterates over all the matchers (three in this case), and sends the text to each of them. Each matcher then proceedsindependently,sending eachmatchit makestothereportercoroutine. At the end we call close() on each matcher and on the reporter—this termi- nates them, since otherwise they would continue (suspended) waiting for text (or matches in the case of the reporter) since they contain inﬁnite loops.\n\n@coroutine def reporter():\n\nignore = frozenset({\"style.css\", \"favicon.png\", \"index.html\"}) while True:\n\nmatch = (yield) if match is not None:\n\ngroups = match.groupdict() if \"url\" in groups and groups[\"url\"] not in ignore:\n\nprint(\"\n\nURL:\", groups[\"url\"])\n\nelif \"h1\" in groups:\n\nprint(\"\n\nH1: \", groups[\"h1\"])\n\nelif \"h2\" in groups:\n\nprint(\"\n\nH2: \", groups[\"h2\"])\n\nThe reporter() coroutine is used to output results. It was created by the state- ment receiver = reporter() which we saw earlier, and passed as the receiver argument to each of the matchers. The reporter() waits (is suspended) until a match is sent to it, then it prints the match’s details,and then it waits again, in an endless loop—stopping only if close() is called on it.\n\nUsing coroutines like this may produce performance beneﬁts, but does require us to adopt a somewhat different way of thinking about processing.",
      "content_length": 1911,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 412,
      "content": "Com- posing func- tions 395➤\n\nFunctional-StyleProgramming\n\nComposing Pipelines\n\nSometimes it is useful to create data processing pipelines. A pipeline is simply the composition of one or more functions where data items are sent to the ﬁrst function,which theneither discardstheitem(ﬁltersit out)or passesit on tothe next function (either as is or transformed in some way). The second function receives the item from the ﬁrst function and repeats the process, discarding or passing on the item (possibly transformed in a different way) to the next function, and so on. Items that reach the end are then output in some way.\n\nor Pipelines typically have several components, one that acquires data, one more that ﬁlter or transformdata,and one that outputsresults. Thisisexactly the functional-style approach to programming that we discussed earlier in the section when we looked at composing some of Python’s built-in functions,such as filter() and map().\n\nOne beneﬁt of using pipelines is that we can read data items incrementally, often one at a time, and have to give the pipeline only enough data items to ﬁll it (usually one or a few items per component). This can lead to signiﬁcant memory savings compared with, say, reading an entire data set into memory and then processing it all in one go.\n\nStep\n\nAction\n\nget_data()\n\nprocess()\n\nreporter()\n\n1\n\npipeline = get_data(\n\nWaiting\n\nWaiting\n\nWaiting\n\nprocess(reporter()))\n\n2\n\npipeline.send(\"a\")\n\nRead \"a\"\n\nWaiting\n\nWaiting\n\n3\n\npipeline.send(\"b\")\n\nRead \"b\"\n\nProcess \"a\" Waiting\n\n4\n\npipeline.send(\"c\")\n\nRead \"c\"\n\nProcess \"b\" Output \"a\"\n\n5\n\npipeline.send(\"d\")\n\nRead \"d\"\n\nProcess \"c\" Output \"b\"\n\n6\n\npipeline.send(\"e\")\n\nRead \"e\"\n\nDrop \"d\"\n\nOutput \"c\"\n\n7\n\npipeline.send(\"f\")\n\nRead \"f\"\n\nProcess \"e\" Waiting\n\n8\n\nWaiting\n\nProcess \"f\" Output \"e\"\n\n9\n\nWaiting\n\nWaiting\n\nOutput \"f\"\n\n10\n\nWaiting\n\nWaiting\n\nWaiting\n\n11 Close coroutines\n\nFinished\n\nFinished\n\nFinished\n\nFigure 8.3 A three-stepcoroutine pipeline processing six items of data\n\nFigure 8.3 illustrates a simple three component pipeline. The ﬁrst component of the pipeline (get_data()) acquires each data item to be processed in turn. Thesecondcomponent(process())processesthedata—andmaydropunwanted data items—there could be any number of other processing/ﬁltering compo- nents,of course. Thelastcomponent(reporter())outputsresults. Intheﬁgure,\n\n403\n\n|",
      "content_length": 2346,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 413,
      "content": "404\n\nChapter 8. Advanced Programming Techniques\n\nitems \"a\", \"b\", \"c\", \"e\", and \"f\" are processed and produce output, while item \"d\" is dropped.\n\nThe pipeline shown in Figure 8.3 is a ﬁlter, since each data item is passed through unchanged and is either dropped or output in its original form. The end points of pipelines tend to perform the same roles: acquiring data items and outputting results. But between these we can have as many components as necessary, each ﬁltering or transforming or both. And in some cases, com- posing the components in different orders can produce pipelines that do differ- ent things.\n\nWe will start out by looking at a theoretical example to get a better idea of how coroutine-based pipelines work, and then we will look at a real example.\n\nSuppose we have a sequence of ﬂoating-point numbers and we want to process them in a multicomponent pipeline such that we transform each number into an integer (by rounding),but drop any numbers that are out of range (< 0 or >= 10).If wehadthefour coroutinecomponents,acquire() (geta number),to_int() (transform a number by rounding and converting to an integer), check() (pass on a number that is in range;drop a number that is out of range),and output() (output a number), we could create the pipeline like this:\n\npipe = acquire(to_int(check(output())))\n\nWe would then send numbers into the pipeline by calling pipe.send(). We’ll look at the progressof the numbers4.3and 9.6asthey go through the pipeline, using a different visualization from the step-by-step ﬁgures used earlier:\n\npipe.send(4.3) → acquire(4.3) → to_int(4.3) → check(4) → output(4) pipe.send(9.6) → acquire(9.6) → to_int(9.6) → check(10)\n\nNotice that for 9.6 there is no output. This is because the check() coroutine received 10, which is out of range (>= 10), and so it was ﬁltered out.\n\nLet’s see what would happen if we created a different pipeline, but using the same components:\n\npipe = acquire(check(to_int(output())))\n\nThis simply performs the ﬁltering (check()) before the transforming (to_int()). Here is how it would work for 4.3 and 9.6:\n\npipe.send(4.3) → acquire(4.3) → check(4.3) → to_int(4.3) → output(4) pipe.send(9.6) → acquire(9.6) → check(9.6) → to_int(9.6) → output(10)\n\nHere we have incorrectly output 10, even though it is out of range. This is because we applied the check() component ﬁrst, and since this received an in-range value of 9.6, it simply passed it on. But the to_int() component rounds the numbers it gets.",
      "content_length": 2483,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 414,
      "content": "os. walk() 224➤\n\nFunctional-StyleProgramming\n\nWe will now review a concrete example—a ﬁle matcher that reads all the ﬁlenames given on the command line (including those in the directories given on thecommandline,recursively),andthat outputstheabsolutepathsof those ﬁles that meet certain criteria.\n\nWe will start by looking at how pipelines are composed, and then we will look at the coroutines that provide the pipeline components. Here is the sim- plest pipeline:\n\npipeline = get_files(receiver)\n\nThis pipeline prints every ﬁle it is given (or all the ﬁles in the directory it is given, recursively). The get_files() function is a coroutine that yields the ﬁlenames and the receiver is a reporter() coroutine—created by receiver = reporter()—that simply prints each ﬁlename it receives. This pipeline does little more than the os.walk() function (and in fact uses that function), but we can use its components to compose more sophisticated pipelines.\n\npipeline = get_files(suffix_matcher(receiver, (\".htm\", \".html\")))\n\nThis pipeline is created by composing the get_files() coroutine together with the suffix_matcher() coroutine. It prints only HTML ﬁles.\n\nCoroutines composed like this can quickly become difﬁcult to read, but there is nothing to stop us from composing a pipeline in stages—although for this approach we must create the components in last-to-ﬁrst order.\n\npipeline = size_matcher(receiver, minimum=1024 ** 2) pipeline = suffix_matcher(pipeline, (\".png\", \".jpg\", \".jpeg\")) pipeline = get_files(pipeline)\n\nThispipeline only matchesﬁlesthat are at least one megabyte in size,and that have a sufﬁx indicating that they are images.\n\nHow are these pipelines used? We simply feed them ﬁlenames or paths and they take care of the rest themselves.\n\nfor arg in sys.argv[1:]:\n\npipeline.send(arg)\n\nNotice that it doesn’t matter which pipeline we are using—it could be the one that prints all the ﬁles, or the one that prints HTML ﬁles, or the images one—they all work in the same way. And in this case,all three of the pipelines are ﬁlters—any ﬁlename they get is either passed on as is to the next compo- nent (and in the case of the reporter(), printed),or dropped because they don’t meet the criteria.\n\nBefore looking at the get_files() and the matcher coroutines, we will look at the trivial reporter() coroutine (passed as receiver) that outputs the results.\n\n405",
      "content_length": 2374,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 415,
      "content": "@corou- tine dec- orator 401➤\n\nos. walk() 224➤\n\n406\n\nChapter 8. Advanced Programming Techniques\n\n@coroutine def reporter(): while True:\n\nfilename = (yield) print(filename)\n\nWe have used the same @coroutine decorator that we created in the subsubsection.\n\nprevious\n\nThe get_files() coroutine is essentially a wrapper around the function and that expects to be given paths or ﬁlenames to work on.\n\nos.walk()\n\n@coroutine def get_files(receiver):\n\nwhile True:\n\npath = (yield) if os.path.isfile(path):\n\nreceiver.send(os.path.abspath(path))\n\nelse:\n\nfor root, dirs, files in os.walk(path):\n\nfor filename in files:\n\nreceiver.send(os.path.abspath(\n\nos.path.join(root, filename)))\n\nThiscoroutinehasthenow-familiarstructure:an inﬁniteloopin which wewait for the yield to return a value that we can process,and then we send the result to the receiver.\n\n@coroutine def suffix_matcher(receiver, suffixes):\n\nwhile True:\n\nfilename = (yield) if filename.endswith(suffixes): receiver.send(filename)\n\nThis coroutine looks simple—and it is—but notice that it sends only ﬁle- names that match the sufﬁxes, so any that don’t match are ﬁltered out of the pipeline.\n\n@coroutine def size_matcher(receiver, minimum=None, maximum=None):\n\nwhile True:\n\nfilename = (yield) size = os.path.getsize(filename) if ((minimum is None or size >= minimum) and\n\n(maximum is None or size <= maximum)): receiver.send(filename)",
      "content_length": 1384,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 416,
      "content": "Descrip- tors 372➤\n\nClass decora- tors 378➤\n\nFunctional-StyleProgramming\n\nThis coroutine is almost identical to suffix_matcher(), except that it ﬁlters out ﬁleswhosesize isnot in therequired range,rather than thosewhich don’t have a matching sufﬁx.\n\nThe pipeline we have created suffers from a couple of problems. One problem is that we never close any of the coroutines. In this case it doesn’t matter, since the program terminatesonce the processing is ﬁnished,but it is probably better to get into the habit of closing coroutines when we are ﬁnished with them. Another problem is that potentially we could be asking the operating system (under the hood) for different pieces of information about the same ﬁle in several partsof the pipeline—and this could be slow. A solution is to modify the get_files() coroutine so that it returns (filename, os.stat()) 2-tuples for each ﬁle rather than just ﬁlenames, and then pass these 2-tuples through the pipeline.★ This would mean that we acquire all the relevant information just once per ﬁle. You’ll get the chance to solve both of these problems, and to add additional functionality, in an exercise at the end of the chapter.\n\nCreating coroutines for use in pipelines requires a certain reorientation of thinking. However, it can pay off handsomely in terms of ﬂexibility, and for large data sets can help minimize the amount of data held in memory as well as potentially resulting in faster throughput.\n\nExample: Valid.py\n\nIn this section powerful mechanism for creating validated attributes.\n\nwe combine descriptors with class decorators to create a\n\nUp to now if we wantedto ensurethat an attributewasset to only a valid value wehaverelied on properties(or usedgetter andsetter methods).Thedisadvan- tage of such approachesisthat we must add validating codefor every attribute inevery classthatneedsit. Whatwouldbemuchmoreconvenientandeasierto maintain,is if we could add attributesto classes with the necessary validation built in. Here is an example of the syntax we would like to use:\n\n@valid_string(\"name\", empty_allowed=False) @valid_string(\"productid\", empty_allowed=False,\n\nregex=re.compile(r\"[A-Z]{3}\\d{4}\"))\n\n@valid_string(\"category\", empty_allowed=False, acceptable=\n\nfrozenset([\"Consumables\", \"Hardware\", \"Software\", \"Media\"]))\n\n@valid_number(\"price\", minimum=0, maximum=1e6) @valid_number(\"quantity\", minimum=1, maximum=1000) class StockItem:\n\n★ The os.stat() function takes a ﬁlename and returns a named tuple with various items of information about the ﬁle, including its size, mode, and last modiﬁed date/time.\n\n407\n\n|||",
      "content_length": 2586,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 417,
      "content": "Class decora- tors 378➤\n\n408\n\nChapter 8. Advanced Programming Techniques\n\ndef __init__(self, name, productid, category, price, quantity):\n\nself.name = name self.productid = productid self.category = category self.price = price self.quantity = quantity\n\nThe StockItem class’s attributes are all validated. For example, the productid attribute can be set only to a nonempty string that startswith three uppercase letters and ends with four digits, the category attribute can be set only to a nonempty string that is one of the speciﬁed values, and the quantity attribute can be set only to a number between 1 and 1000 inclusive. If we try to set an invalid value an exception is raised.\n\nThe validation is achieved by combining class decorators with descriptors. As single argument—the class we noted earlier, class decorators can take only a they are to decorate. So here we have used the technique shown when we ﬁrst discussed class decorators, and have the valid_string() and valid_number() functions take whatever arguments we want, and then return a decorator, which in turn takes the class and returns a modiﬁed version of the class.\n\nLet’s now look at the valid_string() function:\n\ndef valid_string(attr_name, empty_allowed=True, regex=None,\n\nacceptable=None):\n\ndef decorator(cls):\n\nname = \"__\" + attr_name def getter(self):\n\nreturn getattr(self, name)\n\ndef setter(self, value):\n\nassert isinstance(value, str), (attr_name +\n\n\" must be a string\")\n\nif not empty_allowed and not value:\n\nraise ValueError(\"{0} may not be empty\".format(\n\nattr_name))\n\nif ((acceptable is not None and value not in acceptable) or\n\n(regex is not None and not regex.match(value))): raise ValueError(\"{attr_name} cannot be set to \"\n\n\"{value}\".format(**locals()))\n\nsetattr(self, name, value)\n\nsetattr(cls, attr_name, GenericDescriptor(getter, setter)) return cls\n\nreturn decorator\n\nThefunctionstartsby creating a classdecoratorfunctionwhichtakesa classas itssole argument. The decorator addstwo attributesto the classit decorates:a private data attribute and a descriptor. For example, when the valid_string()\n\nRegular expres- sions ➤ 489",
      "content_length": 2115,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 418,
      "content": "Example: Valid.py\n\nfunction is called with the name “productid”, the StockItem class gains the attribute __productid which holds the product ID’s value, and the descrip- tor productid attribute which is used to access the value. For example, if we create an item using item = StockItem(\"TV\", \"TVA4312\", \"Electrical\", 500, 1), we can get the product ID using item.productid and set it using, for example, item.productid = \"TVB2100\".\n\nThe getter function created by the decorator simply uses the global getattr() function to return the value of the private data attribute. The setter function incorporates the validation, and at the end, uses setattr() to set the private data attribute to the new (and valid) value. In fact, the private data attribute is only created the ﬁrst time it is set.\n\nOnce the getter and setter functions have been created we use setattr() once again, this time to create a new class attribute with the given name (e.g., productid), and with its value set to be a descriptor of type GenericDescrip- tor. At the end, the decorator function returns the modiﬁed class, and the valid_string() function returns the decorator function.\n\nThe valid_number() function is structurally identical to the valid_string() function, only differing in the arguments it accepts and in the validation code in the setter, so we won’t show it here. (The complete source code is in the Valid.py module.)\n\nThe last thing we need to cover is the GenericDescriptor, and that turns out to be the easiest part:\n\nclass GenericDescriptor:\n\ndef __init__(self, getter, setter):\n\nself.getter = getter self.setter = setter\n\ndef __get__(self, instance, owner=None):\n\nif instance is None: return self\n\nreturn self.getter(instance)\n\ndef __set__(self, instance, value):\n\nreturn self.setter(instance, value)\n\nThe descriptor is used to hold the getter and setter functionsfor each attribute and simply passes on the work of getting and setting to those functions.\n\n409",
      "content_length": 1954,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 419,
      "content": "410\n\nChapter 8. Advanced Programming Techniques\n\nSummary\n\nIn this chapter we learned a lot more about Python’s support for procedural and object-oriented programming, and got a taste of Python’s support for functional-style programming.\n\nIn theﬁrstsectionwelearnedhowtocreategeneratorexpressions,andcovered generator functionsin moredepth. Wealsolearnedhow todynamically import modules and how to access functionality from such modules, as well as how to dynamically execute code. In this section we saw examples of how to create and use recursive functions and nonlocal variables. We also learned how to create custom function and method decorators,and how to write and make use of function annotations.\n\nIn the chapter’s second section we studied a variety of different and more ad- vanced aspects of object-oriented programming. First we learned more about attribute access, for example, using the __getattr__() special method. Then we learned about functorsand saw how we could use them to provide functions with state—something that can also be achieved by adding properties to func- tions or using closures, both covered in this chapter. We learned how to use the with statement with context managers and how to create custom context managers. Since Python’s ﬁle objects are also context managers, from now on we will do our ﬁle handling using try with …except structuresthat ensure that opened ﬁles are closed without the need for finally blocks.\n\nThe second section continued with coverage of more advanced object-oriented features,starting withdescriptors. Thesecanbeusedin a widevariety of ways and are the technology that underlies many of Python’s standard decorators such as @property and @classmethod. We learned how to create custom descrip- tors and saw three very different examples of their use. Next we studied class decorators and saw how we could modify a class in much the same way that a function decorator can modify a function.\n\nIn the last three subsections of the second section we learned about Python’s support for ABCs (abstract base classes),multiple inheritance,and metaclass- es. WelearnedhowtomakeourownclassesﬁtinwithPython’sstandardABCs and how to create our own ABCs. We also saw how to use multiple inheritance tounify thefeaturesof differentclassestogetherina singleclass. Andfromthe coverage of metaclasses we learned how to intervene when a class (as opposed to an instance of a class) is created and initialized.\n\nThe penultimate section introduced some of the functions and modules that Python provides to support functional-style programming. We learned how to use the common functional idiomsof mapping,ﬁltering,and reducing. We also learned how to create partial functions and how to create and use coroutines.\n\n|||",
      "content_length": 2761,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 420,
      "content": "Summary\n\nAndthelastsectionshowedhowtocombineclassdecoratorswithdescriptorsto provide a powerful and ﬂexible mechanism for creating validated attributes.\n\nThis chapter completes our coverage of the Python language itself. Not every feature of the language has been covered here and in the previous chapters, but those that have not are obscure and rarely used. None of the subsequent chapters introduces new language features, although all of them make use of modules from the standard library that have not been covered before, and some of them take techniques shown in this and earlier chapters further than we have seen so far. Furthermore, the programs shown in the following chaptershave none of the constraintsthat have applied previously (i.e.,to only use aspects of the language that had been covered up to the point they were introduced), so they are the book’s most idiomatic examples.\n\nExercises\n\nNone of the ﬁrst three exercisesdescribed here requireswriting a lot of code— although the fourth one does—and none of them are easy!\n\n1. Copy themagic-numbers.py programanddeleteitsget_function() functions, and all but one of its load_modules() functions. Add a GetFunction functor class that has two caches, one to hold functions that have been found and one to hold functions that could not be found (to avoid repeatedly looking for a function in a module that does not have the function).The only mod- iﬁcations to main() are to add get_function = GetFunction() before the loop, and to use a with statement to avoid the need for a finally block. Also, check that the module functions are callable using collections.Callable ratherthanusing hasattr().Theclasscanbewritteninabouttwenty lines. A solution is in magic-numbers_ans.py.\n\n2. Create a new module ﬁle and in it deﬁne three functions: is_ascii() that returns True if all the characters in the given string have code points less than 127; is_ascii_punctuation() that returns True if all the characters arein the string.punctuation string;and is_ascii_printable() that returns True if all the characters are in the string.printable string. The last two are structurally the same. Each function should be created using lambda and can be done in one or two lines using functional-style code. Be sure to add a docstring for each one with doctestsand to make the module run the doctests. Thefunctionsrequireonly threetoﬁvelinesfor allthreeof them, with the whole module fewer than 25 lines including doctests. A solution is given in Ascii.py.\n\n3. Create a new module ﬁle and in it deﬁne the Atomic context manager class. This class should work like the AtomicList class shown in this chapter, ex- cept that instead of working only with lists it should work with any mu- table collection type. The __init__() method should check the suitability\n\n411\n\n|||",
      "content_length": 2814,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 421,
      "content": "412\n\nChapter 8. Advanced Programming Techniques\n\nof the container, and instead of storing a shallow/deep copy ﬂag it should assign a suitable function to the self.copy attribute depending on the ﬂag and call the copy function in the __enter__() method. The __exit__() method is slightly more involved because replacing the contents of lists is different than for sets and dictionaries—and we cannot use assignment because that would not affect the original container. The class itself can be written in about thirty lines,although you should also include doctests. A solution is given in Atomic.py which is about one hundred ﬁfty lines in- cluding doctests.\n\n4. Createa programthatﬁndsﬁlesbasedon speciﬁedcriteria(ratherlikethe Unix find program). The usage should be find.py options files_or_paths. All the options are optional, and without them all the ﬁles listed on the command line and all the ﬁles in the directories listed on the command line (and in their directories, recursively) should be listed. The options should restrict which ﬁles are output as follows: -d or --days integer dis- cards any ﬁles older than the speciﬁed number of days; -b or --bigger in- teger discards any ﬁles smaller than the speciﬁed number of bytes; -s or --smaller integer discards any ﬁles bigger than the speciﬁed number of bytes; -o or --output what where what is “date”, “size”, or “date,size” (either way around) speciﬁeswhat should be output—ﬁlenamesshould alwaysbe output; -u or --suffix discards any ﬁles that don’t have a matching sufﬁx. (Multiple sufﬁxes can be given if comma-separated.) For both the bigger and smaller options,if the integer isfollowed by “k” it should be treated as kilobytes and multipled by 1024, and similarly if followed by “m” treated as megabytes and multiplied by 10242. For example, find.py -d1 -o date,size *.* will ﬁnd all ﬁles modiﬁed today (strictly, the past 24 hours), and output their name, date, and size. Simi- larly, find.py -b1m -u png,jpg,jpeg -o size *.* will ﬁnd all image ﬁles bigger than one megabyte and output their names and sizes.\n\nImplement the program’s logic by creating a pipeline using coroutines to provide matchers, similar to what we saw in the coroutines subsection, only this time pass (filename, os.stat()) 2-tuples for each ﬁle rather than just ﬁlenames. Also,try to close all the pipeline componentsat the end. In the solution provided, the biggest single function is the one that handles the command-line options. The rest is fairly straightforward, but not trivial. The find.py solution is around 170 lines.",
      "content_length": 2568,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 422,
      "content": "9\n\nDebugging ● Unit Testing ● Proﬁling\n\nDebugging, Testing, and Proﬁling\n\nWriting programs is a mixture of art, craft, and science,and because it is done by humans, mistakes are made. Fortunately, there are techniques we can use to help avoid problems in the ﬁrst place, and techniques for identifying and ﬁxing mistakes when they become apparent.\n\nMistakes fall into several categories. The quickest to reveal themselves and the easiest to ﬁx are syntax errors, since these are usually due to typos. More challenging are logical errors—with these, the program runs, but some aspect of its behavior is not what we intended or expected. Many errors of this kind can be prevented from happening by using TDD (Test Driven Development), where when we want to add a new feature, we begin by writing a test for the feature—which will fail since we haven’t added the feature yet—and then im- plement the feature itself. Another mistake is to create a program that has needlessly poor performance. This is almost always due to a poor choice of al- gorithm or data structure or both. However, before attempting any optimiza- tion we should start by ﬁnding out exactly where the performance bottleneck lies—since it might not be where we expect—and then we should carefully de- cide what optimization we want to do, rather than working at random.\n\nIn this chapter’s ﬁrst section we will look at Python’s tracebacks to see how to spot and ﬁx syntax errors and how to deal with unhandled exceptions. Then we will see how to apply the scientiﬁc method to debugging to make ﬁnding errorsas fast and painlessas possible. We will also look at Python’sdebugging support. In the second section we will look at Python’ssupport for writing unit tests, and in particular the doctest module we saw earlier (in Chapter 5 and Chapter 6), and the unittest module. We will see how to use these modules to support TDD. In the chapter’s ﬁnal section we will brieﬂy look at proﬁling, to identify performance hot spotsso that we can properly target our optimization efforts.\n\n413\n\n||||",
      "content_length": 2055,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 423,
      "content": "414\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nDebugging\n\nIn this section we will begin by looking at what Python does when there is a syntax error,then at the tracebacksthat Python produceswhen unhandled ex- ceptionsoccur,andthenwewillseehowtoapply thescientiﬁcmethodtodebug- ging. But before all that we will brieﬂy discuss backups and version control.\n\nWhen editing a program to ﬁx a bug there is always the risk that we end up with a programthat hasthe originalbug plusnew bugs,that is,it iseven worse than it was when we started! And if we haven’t got any backups (or we have but they are several changes out of date), and we don’t use version control, it could be very hard to even get back to where we just had the original bug.\n\nMaking regular backups is an essential part of programming—no matter how reliable our machine and operating system are and how rare failures are—sincefailuresstilloccur. But backupstend tobecoarse-grained,with ﬁles hours or even days old.\n\nVersion control systems allow us to incrementally save changes at whatever level of granularity we want—every single change, or every set of related changes, or simply every so many minutes’ worth of work. Version control systems allow us to apply changes (e.g., to experiment with bugﬁxes), and if they don’t work out, we can revert the changes back to the last “good” version of the code. So before starting to debug,it is always best to check our code into the version control system so that we have a known position that we can revert to if we get into a mess.\n\nThere are many good cross-platform open source version control systems available—this book uses Bazaar (bazaar-vcs.org), but other popular ones include Mercurial (mercurial.selenic.com), Git (git-scm.com), and Subversion (subversion.tigris.org). Incidentally, both Bazaar and Mercurial are mostly writtenin Python. Noneof thesesystemsishardtouse(at least for thebasics), but using any one of them will help avoid a lot of unnecessary pain.\n\nDealing with Syntax Errors\n\nIf we try to run a program that has a syntax error, Python will stop execution and print the ﬁlename, line number, and offending line, with a caret (^) under- neath indicating exactly where the error was detected. Here’s an example:\n\nFile \"blocks.py\", line 383 if BlockOutput.save_blocks_as_svg(blocks, svg) ^ SyntaxError: invalid syntax\n\n|||\n\n||",
      "content_length": 2359,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 424,
      "content": "Debugging\n\nDid you see the error? We’ve forgotten to put a colon at the end of the if statement’s condition.\n\nHere is an example that comes up quite often, but where the problem isn’t at all obvious:\n\nFile \"blocks.py\", line 385 except ValueError as err: ^ SyntaxError: invalid syntax\n\nThere is no syntax error in the line indicated, so both the line number and the caret’s position are wrong. In general, when we are faced with an error that we are convinced is not in the speciﬁed line, in almost every case the error will be in an earlier line. Here’s the code from the try to the except where Python is reporting the error to be—see if you can spot the error before reading the explanation that follows the code:\n\ntry:\n\nblocks = parse(blocks) svg = file.replace(\".blk\", \".svg\") if not BlockOutput.save_blocks_as_svg(blocks, svg):\n\nprint(\"Error: failed to save {0}\".format(svg)\n\nexcept ValueError as err:\n\nDid you spot the problem? It is certainly easy to miss since it is on the line before the one that Python reports as having the error. We have closed the str.format() method’s parentheses,but not the print() function’sparentheses, that is, we are missing a closing parenthesis at the end of the line, but Python didn’t realize this until it reached the except keyword on the following line. Missing the last parenthesis on a line is quite common, especially when using print() with str.format(), but the error is usually reported on the following line. Similarly, if a list’s closing bracket, or a set or dictionary’s closing brace is missing,Python will normally report the problem as being on the next (non- blank) line. On the plus side, syntax errors like these are trivial to ﬁx.\n\nDealing with Runtime Errors\n\nIf an unhandled exception occurs at runtime, Python will stop executing our program and print a traceback. Here is an example of a traceback for an unhandled exception:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 381, in main\n\n415\n\n||",
      "content_length": 2019,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 425,
      "content": "Func- tion ref- erences 340➤\n\n416\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nblocks = parse(blocks) File \"blocks.py\", line 174, in recursive_descent_parse return data.stack[1] IndexError: list index out of range\n\nTracebacks (also called backtraces) like this should be read from their last line back toward their ﬁrst line. The last line speciﬁes the unhandled exception that occurred. Above this line, the ﬁlename, line number, and function name, followed by the line that caused the exception, are shown (spread over two lines). If the function where the exception was raised was called by another function, that function’s ﬁlename, line number, function name, and calling line are shown above. And if that function was called by another function the same applies, all the way up to the beginning of the call stack. (Note that the ﬁlenames in tracebacks are given with their path, but in most cases we have omitted paths from the examples for the sake of clarity.)\n\nSo in this example, an IndexError occurred, meaning that data.stack is some kind of sequence, but has no item at position 1. The error occurred at line 174 in the blocks.py program’s recursive_descent_parse() function, and that line 381 in the main() function. (The reason that the function was called at function’s name is different at line 381, that is, parse() instead of recur- sive_descent_parse(),is that the parse variable is set to one of several different functions depending on the command-line arguments given to the program;in the common case thenamesalwaysmatch.) The call to main() wasmadeat line 392, and this is the statement at which program execution commenced.\n\nAlthough at ﬁrst sight the traceback looks intimidating, now that we under- stand its structure it is easy to see how useful it is. In this case it tells us ex- actly where to look for the problem, although of course we must work out for ourselves what the solution is.\n\nHere is another example traceback:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 383, in main if BlockOutput.save_blocks_as_svg(blocks, svg): File \"BlockOutput.py\", line 141, in save_blocks_as_svg widths, rows = compute_widths_and_rows(cells, SCALE_BY) File \"BlockOutput.py\", line 95, in compute_widths_and_rows width = len(cell.text) // cell.columns ZeroDivisionError: integer division or modulo by zero\n\nHere, the problem has occurred in a module (BlockOutput.py) that is called by the blocks.py program. This traceback leads us to where the problem became apparent, but not to where it occurred. The value of cell.columns is",
      "content_length": 2608,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 426,
      "content": "Debugging\n\nclearly 0 in the BlockOutput.py module’s compute_widths_and_rows() function on line 95—after all, that is what caused the ZeroDivisionError exception to be raised—but we must look at the preceding lines to ﬁnd where and why cell.columns was given this incorrect value.\n\nIn some cases the traceback reveals an exception that occurred in Python’s standard library or in a third-party library. Although thiscould mean a bug in the library, in almost every case it is due to a bug in our own code. Here is an example of such a traceback, using Python 3.0:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 379, in main blocks = open(file, encoding=\"utf8\").read() File \"/usr/lib/python3.0/lib/python3.0/io.py\", line 278, in __new__ return open(*args, **kwargs) File \"/usr/lib/python3.0/lib/python3.0/io.py\", line 222, in open closefd) File \"/usr/lib/python3.0/lib/python3.0/io.py\", line 619, in __init__ _fileio._FileIO.__init__(self, name, mode, closefd) IOError: [Errno 2] No such file or directory: 'hierarchy.blk'\n\nThe IOError exception at the end tells us clearly what the problem is. But the exception was raised in the standard library’s io module. In such cases it is best to keep reading upward until we ﬁnd the ﬁrst ﬁle listed that is our program’s ﬁle (or one of the modules we have created for it).So in this case we ﬁnd that the ﬁrst reference to our program is to ﬁle blocks.py, line 379, in the main() function. It looks like we have a call to open() but have not put the call inside a try … except block or used a with statement.\n\nPython 3.1 is a bit smarter than Python 3.0 and realizes that we want to ﬁnd the mistake in our own code,not in the standard library,so it produces a much more compact and helpful traceback. For example:\n\nTraceback (most recent call last): File \"blocks.py\", line 392, in <module> main() File \"blocks.py\", line 379, in main blocks = open(file, encoding=\"utf8\").read() IOError: [Errno 2] No such file or directory: 'hierarchy.blk'\n\nThis eliminates all the irrelevant detail and makes it easy to see what the problem is (on the bottom line) and where it occurred (the lines above it).\n\nSo no matter how big the traceback is,the last line alwaysspeciﬁesthe unhan- dled exception, and we just have to work back until we ﬁnd our program’s ﬁle\n\n417\n\n3.0\n\n3.1",
      "content_length": 2360,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 427,
      "content": "418\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nor one of our own modules listed. The problem will almost certainly be on the line Python speciﬁes, or on an earlier line.\n\nThis particular example illustrates that we should modify the blocks.py pro- gram to cope gracefully when given the names of nonexistent ﬁles. This is a usability error,and it should also be classiﬁed asa logical error,sinceterminat- ing and printing a traceback cannot be considered to be acceptable program behavior.\n\nIn fact, as a matter of good policy and courtesy to our users, we should always catchallrelevantexceptions,identifying thespeciﬁconesthatweconsidertobe possible, such as EnvironmentError. In general, we should not use the catchalls of except: or except Exception:, although using the latter at the top level of our program to avoid crashes might be appropriate—but only if we always report any exceptions it catches so that they don’t go silently unnoticed.\n\nExceptions that we catch and cannot recover from should be reported in the form of error messages, rather than exposing our users to tracebacks which look scary to the uninitiated. For GUI programs the same applies,except that normally we would use a message box to notify the user of a problem. And for server programs that normally run unattended, we should write the error message to the server’s log.\n\nPython’s exception hierarchy was designed so that catching Exception doesn’t quitecoveralltheexceptions. Inparticular,it doesnotcatchthe KeyboardInter- rupt exception,soforconsoleapplicationsif theuserpressesCtrl+C,theprogram willterminate. If wechoosetocatchthisexception,thereisa risk thatwecould lock the user into a program that they cannot terminate. This arises because a bug in our exception handling code might prevent the program from termi- nating or the exception propagating. (Of course, even an “uninterruptible” program can have its process killed, but not all users know how.) So if we do catch the KeyboardInterrupt exception we must be extremely careful to do the minimum amount of saving and clean up that is necessary—and then termi- nate the program. And for programs that don’t need to save or clean up, it is best not to catch KeyboardInterrupt at all, and just let the program terminate.\n\nOne of Python 3’sgreat virtuesisthat it makesa clear distinctionbetween raw bytes and strings. However,this can sometimes lead to unexpected exceptions occurring when we pass a bytes object where a str is expected or vice versa. For example:\n\nTraceback (most recent call last): File \"program.py\", line 918, in <module> print(datetime.datetime.strptime(date, format)) TypeError: strptime() argument 1 must be str, not bytes\n\nWhen we hit a problem like this we can either perform the conversion—in this case,by passing date.decode(\"utf8\")—or carefully work back to ﬁnd out where",
      "content_length": 2845,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 428,
      "content": "Debugging\n\n419\n\nand why the variable is a bytes object rather than a str, and ﬁx the problem at its source.\n\nWhen we pass a string where bytes are expected the error message is what less obvious, and differs between Python 3.0 and 3.1. For Python 3.0:\n\nsome- example, in\n\nTraceback (most recent call last): File \"program.py\", line 2139, in <module> data.write(info) TypeError: expected an object with a buffer interface\n\nIn Python 3.1 the error message’s text has been slightly improved:\n\nTraceback (most recent call last): File \"program.py\", line 2139, in <module> data.write(info) TypeError: 'str' does not have the buffer interface\n\nIn both cases the problem is that we are passing a string when a bytes, byte- array, or similar object is expected. We can either perform the conversion—in thiscaseby passing info.encode(\"utf8\")—or work back toﬁndthesourceof the problem and ﬁx it there.\n\nPython 3.0 introduced support for exception chaining—this means that an ex- ceptionthatisraisedinresponsetoanotherexceptioncancontainthedetailsof the original exception. When a chained exception goesuncaught thetraceback includes not just the uncaught exception, but also the exception that caused it (providing it waschained).Theapproachtodebugging chainedexceptionsisal- most the same as before:We start at the end and work backward until we ﬁnd the problem in our own code. However, rather than doing this just for the last exception, we might then repeat the process for each chained exception above it, until we get to the problem’s true origin.\n\nWe can take advantage of exception chaining in our own code—for example,if we want to use a custom exception class but still want the underlying problem to be visible.\n\nclass InvalidDataError(Exception): pass\n\ndef process(data):\n\ntry:\n\ni = int(data) ...\n\nexcept ValueError as err:\n\nraise InvalidDataError(\"Invalid data received\") from err\n\nHere, if the int() conversion fails, a ValueError is raised and caught. We then raise our custom exception, but with from err, which creates a chained\n\n3.x\n\n3.0\n\n3.1",
      "content_length": 2048,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 429,
      "content": "420\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nexception, our own, plus the one in err. If the InvalidDataError exception is raised and not caught, the resulting traceback will look something like this:\n\nTraceback (most recent call last): File \"application.py\", line 249, in process i = int(data) ValueError: invalid literal for int() with base 10: '17.5 '\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last): File \"application.py\", line 288, in <module> print(process(line)) File \"application.py\", line 283, in process raise InvalidDataError(\"Invalid data received\") from err __main__.InvalidDataError: Invalid data received\n\nAt the bottom our custom exception and text explain what the problem is,with the lines above them showing where the exception was raised (line 283), and whereit wascaused(line288).But wecanalsogoback further,intothechained exception which gives more details about the speciﬁc error, and which shows the line that triggered the exception (249).For a detailed rationale and further information about chained exceptions, see PEP 3134.\n\nScientiﬁc Debugging\n\nIf our program runs but does not have the expected or desired behavior then we have a bug—a logical error—that we must eliminate. The best way to eliminate such errors is to prevent them from occurring in the ﬁrst place by using TDD (Test Driven Development). However, some bugs will always get through, so even with TDD, debugging is still a necessary skill to learn.\n\nIn this subsection we will outline an approach to debugging based on the sci- entiﬁc method. The approach is explained in sufﬁcient detail that it might ap- pear to be too much work for tackling a “simple” bug. However,by consciously following theprocesswewillavoid wasting timewith “random”debugging,and after awhile we will internalize the process so that we can do it unconsciously, and therefore very quickly.★\n\nTo be able to kill a bug we must be able to do the following.\n\n1. Reproduce the bug.\n\n2. Locate the bug.\n\n★The ideas used in this subsection were inspired by the Debugging chapter in the book Code Complete by Steve McConnell, ISBN 0735619670.\n\n||",
      "content_length": 2167,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 430,
      "content": "Debugging\n\n3. Fix the bug.\n\n4. Test the ﬁx.\n\nReproducing the bug is sometimes easy—it always occurs on every run; and sometimes hard—it occurs intermittently. In either case we should try to reduce the bug’s dependencies, that is, ﬁnd the smallest input and the least amount of processing that can still produce the bug.\n\nOnce we are able to reproduce the bug, we have the data—the input data and options, and the incorrect results—that are needed so that we can apply the scientiﬁc method to ﬁnding and ﬁxing it. The method has three steps.\n\n1. Think up an explanation—a hypothesis—that reasonably accounts for the bug.\n\n2. Create an experiment to test the hypothesis.\n\n3. Run the experiment.\n\nRunning the experiment should help to locate the bug, and should also give us insightintoitssolution. (Wewillreturntohowtocreateandrunanexperiment shortly.) Once we have decided how to kill the bug—and have checked our code into our version control system so that we can revert the ﬁx if necessary—we can write the ﬁx.\n\nOnce theﬁx isin placewe must test it. Naturally,we must test to see if thebug it is intended to ﬁx has gone away. But this is not sufﬁcient; after all, our ﬁx may have solved the bug we were concerned about, but the ﬁx might also have introduced another bug, one that affects some other aspect of the program. So in addition to testing the bugﬁx, we must also run all of the program’s tests to increase our conﬁdence that the bugﬁx did not have any unwanted side effects.\n\nSome bugs have a particular structure, so whenever we ﬁx a bug it is always worth asking ourselves if there are other places in the program or its modules that might have similar bugs. If there are, we can check to see if we already have tests that would reveal the bugs if they were present, and if not, we should add such tests, and if that reveals bugs, then we must tackle them as described earlier.\n\nNow that we have a good overview of the debugging process, we will focus in on just how we create and run experiments to test our hypotheses. We begin with trying to isolate the bug. Depending on the nature of the program and of the bug, we might be able to write tests that exercise the program, for example, feeding it data that is known to be processed correctly and gradually changing the data so that we can ﬁnd exactly where processing fails. Once we have an idea of where the problem lies—either due to testing or based on reasoning—we can test our hypotheses.\n\n421",
      "content_length": 2465,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 431,
      "content": "422\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nWhat kind of hypothesis might we think up? Well, it could initially be as sim- pleasthesuspicionthata particularfunctionor methodisreturning erroneous data when certain input data and options are used. Then, if this hypothesis proves correct, we can reﬁne it to be more speciﬁc—for example, identifying a particular statement or suite in the function that we think is doing the wrong computation in certain cases.\n\nTo test our hypothesis we need to check the arguments that the function re- ceives and the values of its local variables and the return value, immediately before it returns. We can then run the program with data that we know pro- duces errorsand check the suspect function. If the argumentscoming into the function are not what we expect, then the problem is likely to be further up the call stack, so we would now begin the process again, this time suspecting the function that callsthe one we have been looking at. But if all the incoming arguments are always valid, then we must look at the local variables and the return value. If these are always correct then we need to come up with a new hypothesis, since the suspect function is behaving correctly. But if the return value is wrong, then we know that we must investigate the function further.\n\nIn practice, how do we conduct an experiment, that is, how do we test the hy- pothesis that a particular function is misbehaving? One way to start is to “execute” the function mentally—thisis possible for many small functionsand for larger ones with practice,and has the additional beneﬁt that it familiarizes us with the function’s behavior. At best, this can lead to an improved or more speciﬁc hypothesis—for example, that a particular statement or suite is the site of the problem. But to conduct an experiment properly we must instru- ment the program so that we can see what is going on when the suspect func- tion is called.\n\nThere aretwo waysto instrument a program—intrusively,by inserting print() statements;or (usually)non-intrusively,by using a debugger. Bothapproaches are used to achieve the same end and both are valid, but some programmers have a strong preference for one or the other. We’ll brieﬂy describe both approaches, starting with the use of print() statements.\n\nWhen using print() statements, we can start by putting a print() statement right at the beginning of the function and have it print the function’s argu- ments. Then, just before the (or each) return statement (or at the end of the function if there is no return statement), add print(locals(), \"\\n\"). The built- in locals() function returnsa dictionary whose keys are the names of the local variables and whose values are the variables’ values. We can of course simply print the variables we are speciﬁcally interested in instead. Notice that we added an extra newline—we should also do this in the ﬁrst print() statement so that a blank line appears between each set of variables to aid clarity. (An alternative to inserting print() statements directly is to use some kind of log- ging decorator such as the one we created in Chapter 8; 358 ➤.)",
      "content_length": 3148,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 432,
      "content": "Debugging\n\nIf when we run the instrumented program we ﬁnd that the arguments are correct but that the return value is in error, we know that we have located the source of the bug and can further investigatethe function. If looking carefully at the function doesn’t suggest where the problem lies, we can simply insert a new print(locals(), \"\\n\") statement right in the middle. After running the program again we should now know whether the problem arises in the ﬁrst or second half of the function, and can put a print(locals(), \"\\n\") statement in the middle of the relevant half, repeating the process until we ﬁnd the statement where the error is caused. This will very quickly get us to the point where the problem occurs—and in most cases locating the problem is half of the work needed to solve it.\n\nThe alternative to adding print() statements is to use a debugger. Python has two standard debuggers. One is supplied as a module (pdb), and can be used interactively in the console—for example, python3 -m pdb my_program.py. (On Windows, of course, we would replace python3 with something like C:\\Python31\\python.exe.) However, the easiest way to use it is to add import pdb in the program itself, and add the statement pdb.set_trace() as the ﬁrst state- ment of the function we want to examine. When the program is run, pdb stops it immediately after the pdb.set_trace() call,and allows us to step through the program, set breakpoints, and examine variables.\n\nHere is an example run of a program that has been instrumented by having the import pdb statement added to its imports, and by having pdb.set_trace() added as the ﬁrst statement inside its calculate_median() function. (What we have typed is shown in bold, although where we typed Enter is not indicated.)\n\npython3 statistics.py sum.dat > statistics.py(73)calculate_median() -> numbers = sorted(numbers) (Pdb) s > statistics.py(74)calculate_median() -> middle = len(numbers) // 2 (Pdb) > statistics.py(75)calculate_median() -> median = numbers[middle] (Pdb) > statistics.py(76)calculate_median() -> if len(numbers) % 2 == 0: (Pdb) > statistics.py(78)calculate_median() -> return median (Pdb) p middle, median, numbers (8, 5.0, [-17.0, -9.5, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.5, 6.0, 7.0, 7.0, 8.0, 9.0, 17.0]) (Pdb) c\n\n423",
      "content_length": 2295,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 433,
      "content": "424\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nCommands are given to pdb by entering their name and pressing Enter at the (Pdb) prompt. If we just press Enter on its own the last command is repeated. So here we typed s (which means step, i.e., execute the statement shown), and then repeated this (simply by pressing Enter), to step through the statements in the calculate_median() function. Once we reached the return statement we printed out the values that interested us using the p (print) command. And ﬁnally we continued to the end using the c (continue) command. This tiny example should give a ﬂavor of pdb, but of course the module has a lot more functionality than we have shown here.\n\nIt is much easier to use pdb on an instrumented program as we have done here than on an uninstrumented one. But since this requires us to add an import and a call to pdb.set_trace(), it would seem that using pdb is just as intrusive as using print() statements, although it does provide useful facilities such as breakpoints.\n\nThe other standard debugger is IDLE, and just like pdb, it supports single stepping, breakpoints, and the examination of variables. IDLE’s debugger window is shown in Figure 9.1, and its code editing window with breakpoints and the current line highlighted is shown in Figure 9.2.\n\nFigure 9.1 IDLE’s debugger window showing the call stack and the current local variables\n\nOne great advantage IDLE has over pdb is that there is no need to instrument our code—IDLE is smart enough to debug our code as it stands, so it isn’t intrusive at all.\n\nUnfortunately, at the time of this writing, IDLE is rather weak when it comes to running programs that require command-line arguments. The only way to do this appears to be to run IDLE from a console with the required arguments,",
      "content_length": 1794,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 434,
      "content": "Debugging\n\nFigure 9.2 An IDLE code editing window during debugging\n\nfor example, idle3 -d -r statistics.py sum.dat. The -d argument tells IDLE to start debugging immediately and the -r argument tells it to run the following program with any arguments that follow it. However, for programs that don’t require command-line arguments (or where we are willing to edit the code to put them in manually to make debugging easier), IDLE is quite powerful and convenient to use. (Incidentally,the code shown in Figure 9.2 does have a bug—middle + 1 should be middle - 1.)\n\nDebugging Python programs is no harder than debugging in any other language—and it is easier than for compiled languages since there is no build step to go through after making changes. And if we are careful to use the sci- entiﬁcmethoditisusually quitestraightforwardtolocatebugs,althoughﬁxing them isanother matter. Ideally,though,we want to avoid asmany bugsaspos- sible in the ﬁrst place. And apart from thinking deeply about our design and writing our code with care, one of the best ways to prevent bugs is to use TDD, a topic we will introduce in the next section.\n\nUnit Testing\n\nWriting tests for our programs—if done well—can help reduce the incidence of bugsand can increase our conﬁdence that our programsbehave as expected. But in general,testing cannot guarantee correctness,since for most nontrivial programs the range of possible inputs and the range of possible computations is so vast that only the tiniest fraction of them could ever be realistically tested. Nonetheless, by carefully choosing what we test we can improve the quality of our code.\n\nA variety of different kinds of testing can be done, such as usability testing, functional testing,and integration testing. But here we will concern ourselves\n\n425\n\n|||",
      "content_length": 1798,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 435,
      "content": "426\n\nChapter 9. Debugging,Testing,and Proﬁling\n\npurely with unit testing—testing individual functions, classes, and methods, to ensure that they behave according to our expectations.\n\nA key point of TDD,isthat when we want to add a feature—for example,a new method to a class—we ﬁrst write a test for it. And of course this test will fail since we haven’t written the method. Now we write the method, and once it passesthe test we can then rerun allthe teststo make sure our addition hasn’t had any unexpected side effects. Once all the tests run (including the one we added for the new feature),we can check in our code,reasonably conﬁdent that it does what we expect—providing of course that our test was adequate.\n\nFor example,if we want to write a function that insertsa string at a particular index position, we might start out using TDD like this:\n\ndef insert_at(string, position, insert):\n\n\"\"\"Returns a copy of string with insert inserted at the position\n\n>>> string = \"ABCDE\" >>> result = [] >>> for i in range(-2, len(string) + 2): ... >>> result[:5] ['ABC-DE', 'ABCD-E', '-ABCDE', 'A-BCDE', 'AB-CDE'] >>> result[5:] ['ABC-DE', 'ABCD-E', 'ABCDE-', 'ABCDE-'] \"\"\" return string\n\nresult.append(insert_at(string, i, \"-\"))\n\nForfunctionsormethodsthatdon’treturnanything (theyactuallyreturnNone), we normally give them a suite consisting of pass, and for those whose return value is used we either return a constant (say, 0) or one of the arguments, unchanged—which is what we have done here. (In more complex situations it may be more useful to return fake objects—third-party modules that provide “mock” objects are available for such cases.)\n\nWhen the doctest is run it will fail, listing each of the strings ('ABCD-EF', 'ABCDE-F', etc.) that it expected, and the strings it actually got (all of which are 'ABCDEF'). Once we are satisﬁed that the doctest is sufﬁcient and correct, we can write the body of the function, which in this case is simply return string[:position] + insert + string[position:]. (And if we wrote return string[:position] + insert, and then copied and pasted string[:position] at the end to save ourselves some typing, the doctest will immediately reveal the error.)\n\nPython’s standard library provides two unit testing modules, doctest, which we have already brieﬂy seen here and earlier (in Chapter 5; 202➤, and Chap- ter 6; 247 ➤), and unittest. In addition, there are third-party testing tools for",
      "content_length": 2430,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 436,
      "content": "Unit Testing\n\nPython. Two of the most notable are nose (code.google.com/p/python-nose), which aims to be more comprehensive and useful than the standard unit- test module, while still being compatible with it, and py.test (codespeak. net/py/dist/test/test.html)—this takes a somewhat different approach to unittest, and tries as much as possible to eliminate boilerplate test code. Both of these third-party tools support test discovery,so there is no need to write an overarching test program—since they will search for tests themselves. This makes it easy to test an entire tree of code or just a part of the tree (e.g., just those modules that have been worked on). For those serious about testing it is worth investigating both of these third-party modules (and any others that appeal), before deciding which testing tools to use.\n\nCreating doctests is straightforward: We write the tests in the module, func- tion,class,and methods’docstrings,and for modules,we simply add three lines at the end of the module:\n\nif __name__ == \"__main__\":\n\nimport doctest doctest.testmod()\n\nIf we want to use doctests inside programs,that is also possible. For example, the blocks.py program whose modules are covered later (in Chapter 14) has doctests for its functions, but it ends with this code:\n\nif __name__ == \"__main__\":\n\nmain()\n\nThis simply calls the program’s main() function, and does not execute the program’s doctests. To exercise the program’s doctests there are two ap- proaches we can take. One is to import the doctest module and then run the program—for example, at the console, python3 -m doctest blocks.py (on Win- dows, replacing python3 with something like C:\\Python31\\python.exe). If all the tests run ﬁne there is no output, so we might prefer to execute python3 -m doctest blocks.py -v instead, since this will list every doctest that is executed, and provide a summary of results at the end.\n\nAnother way to execute doctests is to create a separate test program using the unittest module. The unittest module is conceptually modeled on Java’s JUnit unit testing library and is used to create test suites that contain test cases. The unittest module can create test cases based on doctests, without having to know anything about what the program or module contains, apart from the fact that it has doctests. So to make a test suite for the blocks.py program, we can create the following simple program (which we have called test_blocks.py):\n\nimport doctest import unittest import blocks\n\n427",
      "content_length": 2503,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 437,
      "content": "428\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nsuite = unittest.TestSuite() suite.addTest(doctest.DocTestSuite(blocks)) runner = unittest.TextTestRunner() print(runner.run(suite))\n\nNote that there is an implicit restriction on the names of our programs if we take this approach: They must have names that are valid module names, so a program called convert-incidents.py cannot have a test like this written for it because import convert-incidents is not valid since hyphens are not legal in Python identiﬁers. (It is possible to get around this, but the easiest solution is to use program ﬁlenames that are also valid module names, for example, replacing hyphens with underscores.)\n\nThe structure shown here—create a test suite, add one or more test cases or test suites, run the overarching test suite, and output the results—is typical of unittest-based tests. When run, this particular example produces the following output:\n\n... ---------------------------------------------------------------------- Ran 3 tests in 0.244s\n\nOK <unittest._TextTestResult run=3 errors=0 failures=0>\n\nEach time a test case is executed a period is output (hence the three periods at the beginning of the output), then a line of hyphens, and then the test summary. (Naturally, there is a lot more output if any tests fail.)\n\nIf we are making the effort to have separate tests (typically one for each pro- gram and module we want to test), then rather than using doctests we might prefer to directly use the unittest module’sfeatures—especially if we are used to the JUnit approach to testing. The unittest modulekeepsour testsseparate from our code—thisis particularly useful for larger projectswhere test writers and developers are not necessarily the same people. Also, unittest unit tests are written as stand-alone Python modules,so they are not limited by what we can comfortably and sensibly write inside a docstring.\n\nThe unittest module deﬁnes four key concepts. A test ﬁxture is the term used to describe the code necessary to set up a test (and to tear it down, that is, clean up, afterward).Typical examples are creating an input ﬁle for the test to use and at the end deleting the input ﬁle and the resultant output ﬁle. A test suiteis a collection of test casesand a test caseis the basic unit of testing—test suites are collections of test cases or of other test suites—we’ll see practical examples of these shortly. A test runner is an object that executes one or more test suites.",
      "content_length": 2478,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 438,
      "content": "Atom- ic.py ex- ercise 411➤\n\nUnit Testing\n\nTypically, a test suite is made by creating a subclass of unittest.TestCase, where each method that has a name beginning with “test” is a test case. If we need any setup to be done, we can do it in a method called setUp(); similar- ly, for any cleanup we can implement a method called tearDown(). Within the tests there are a number of unittest.TestCase methods that we can make use of, including assertTrue(), assertEqual(), assertAlmostEqual() (useful for test- ing ﬂoating-point numbers), assertRaises(), and many more, including many inverses such as assertFalse(), assertNotEqual(), failIfEqual(), failUnlessE- qual(), and so on.\n\nThe unittest module iswell documentedand hasa lot of functionality,but here we will just give a ﬂavor of its use by reviewing a very simple test suite. The example we will use is the solution to one of the exercises given at the end of Chapter 8. The exercise was to create an Atomic module which could be used as a context manager to ensure that either all of a set of changes is applied to a list, set, or dictionary—or none of them are. The Atomic.py module provided as an example solution uses 30 lines of code to implement the Atomic class, and has about 100 lines of module doctests. We will create the test_Atomic.py module to replace the doctests with unittest tests so that we can then delete the doctests and leave Atomic.py free of any code except that needed to provide its functionality.\n\nBefore diving into writing the test module, we need to think about what tests are needed. We will need to test three different kinds of data type: lists, sets, and dictionaries. For lists we need to test appending and inserting an item, deleting an item, and changing an item’s value. For sets we must test adding and discarding an item. And for dictionaries we must test inserting an item, changing an item’s value, and deleting an item. Also, we must test that in the case of failure, none of the changes are applied.\n\nStructurally,testing the different data types is essentially the same,so we will only write the test cases for testing lists and leave the others as an exercise. The test_Atomic.py module must import both the unittest module and the Atomic module that it is designed to test.\n\nWhen creating unittest ﬁles,we usually create modulesrather than programs, and inside each module we deﬁne one or more unittest.TestCase subclasses. In the case of the test_Atomic.py module, it deﬁnes a single unittest.TestCase subclass,TestAtomic (whichwewillreviewshortly),andendswith thefollowing two lines:\n\nif __name__ == \"__main__\":\n\nunittest.main()\n\nThanks to these lines, the module can be run stand-alone. And of course, it could also be imported and run from another test program—something that makes sense if this is just one test suite among many.\n\n429",
      "content_length": 2843,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 439,
      "content": "430\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nIf we want to run the test_Atomic.py module from another test program we can write a program that issimilar to the one we used to execute doctestsusing the unittest module. For example:\n\nimport unittest import test_Atomic\n\nsuite = unittest.TestLoader().loadTestsFromTestCase(\n\ntest_Atomic.TestAtomic)\n\nrunner = unittest.TextTestRunner() print(runner.run(suite))\n\nHere, we have created a single suite by telling the unittest module to read the test_Atomic module and to use each of its test*() methods(test_list_success() and test_list_fail() in this example, as we will see in a moment), as test cases.\n\nWe will now review the implementation of the TestAtomic class. Unusually for subclasses generally,although not for unittest.TestCase subclasses,there is no need to implement theinitializer. In thiscasewe will need a setupmethod,but not a teardown method. And we will implement two test cases.\n\ndef setUp(self):\n\nself.original_list = list(range(10))\n\nWe have used the unittest.TestCase.setUp() method to create a single piece of test data.\n\ndef test_list_succeed(self):\n\nitems = self.original_list[:] with Atomic.Atomic(items) as atomic:\n\natomic.append(1999) atomic.insert(2, -915) del atomic[5] atomic[4] = -782 atomic.insert(0, -9)\n\nself.assertEqual(items,\n\n[-9, 0, 1, -915, 2, -782, 5, 6, 7, 8, 9, 1999])\n\nThis test case is used to test that all of a set of changes to a list are correctly applied. The test performs an append,an insertion in the middle,an insertion at the beginning, a deletion, and a change of a value. While by no means comprehensive, the test does at least cover the basics.\n\nThe test should not raise an exception, but if it does the unittest.TestCase base class will handle it by turning it into an appropriate error message. At the end we expect the items list to equal the literal list included in the test rather than the original list. The unittest.TestCase.assertEqual() method can",
      "content_length": 1963,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 440,
      "content": "Unit Testing\n\ncompare any two Python objects, but its generality means that it cannot give particularly informative error messages.\n\nFrom Python 3.1, the unittest.TestCase class has many more methods, includ- ing many data-type-speciﬁc assertion methods. Here ishow we could writethe assertion using Python 3.1:\n\nself.assertListEqual(items,\n\n[-9, 0, 1, -915, 2, -782, 5, 6, 7, 8, 9, 1999])\n\nIf the lists are not equal, since the data types are known, the unittest module is able to give more precise error information, including where the lists differ.\n\ndef test_list_fail(self):\n\ndef process():\n\nnonlocal items with Atomic.Atomic(items) as atomic:\n\natomic.append(1999) atomic.insert(2, -915) del atomic[5] atomic[4] = -782 atomic.poop() # Typo\n\nitems = self.original_list[:] self.assertRaises(AttributeError, process) self.assertEqual(items, self.original_list)\n\nTo test the failure case,that is,where an exception israised while doing atomic processing, we must test that the list has not been changed and also that an appropriate exception has been raised. To check for an exception we use the unittest.TestCase.assertRaises() method, and in the case of Python 3.0, we passit the exception we expect to get and a callable object that should raise the exception. This forces us to encapsulate the code we want to test,which is why we had to create the process() inner function shown here.\n\nIn Python 3.1 the unittest.TestCase.assertRaises() method can be used as a context manager, so we are able to write our test in a much more natural way:\n\ndef test_list_fail(self):\n\nitems = self.original_list[:] with self.assertRaises(AttributeError):\n\nwith Atomic.Atomic(items) as atomic:\n\natomic.append(1999) atomic.insert(2, -915) del atomic[5] atomic[4] = -782 atomic.poop() # Typo\n\nself.assertListEqual(items, self.original_list)\n\n431\n\n3.1\n\n3.1",
      "content_length": 1840,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 441,
      "content": "432\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nHere we have written the test code directly in the test method without the need for an inner function,insteadusing unittest.TestCase.assertRaised() asa context manager that expectsthe code to raise an AttributeError.We have also used Python 3.1’s unittest.TestCase.assertListEqual() method at the end.\n\nAs we have seen, Python’s test modules are easy to use and are extremely use- ful, especially if we use TDD. They also have a lot more functionality and fea- tures than have been shown here—for example, the ability to skip tests which is useful to account for platform differences—and they are also well document- ed. One feature that is missing—and which nose and py.test provide—is test discovery,although this feature is expected to appear in a later Python version (perhaps as early as Python 3.2).\n\nProﬁling\n\nIf a program runs very slowly or consumes far more memory than we expect, the problem is most often due to our choice of algorithmsor data structures,or due to our doing an inefﬁcient implementation. Whatever the reason for the problem,it is best to ﬁnd out precisely where the problem lies rather than just inspecting our code and trying to optimize it. Randomly optimizing can cause us to introduce bugs or to speed up parts of our program that actually have no effect on the program’soverall performance because the improvementsare not in places where the interpreter spends most of its time.\n\nBefore going further into proﬁling, it is worth noting a few Python program- ming habits that are easy to learn and apply, and that are good for perfor- mance. None of the techniques is Python-version-speciﬁc, and all of them are perfectly sound Python programming style. First, prefer tuples to lists when a read–only sequence is needed. Second, use generators rather than creating large tuples or lists to iterate over. Third, use Python’s built-in data structures—dicts, lists, and tuples—rather than custom data structures implemented in Python, since the built-in ones are all very highly optimized. Fourth,when creating large strings out of lots of small strings,instead of con- catenating the small strings, accumulate them all in a list, and join the list of stringsintoa singlestring at theend. Fifthand ﬁnally,if an object(including a function or method) is accessed a large number of times using attribute access (e.g., when accessing a function in a module), or from a data structure, it may be better to create and use a local variable that refers to the object to provide faster access.\n\nPython’s standard library provides two modules that are particularly useful when we want to investigate the performance of our code. One of these is the timeit module—thisisusefulfor timing smallpiecesof Pythoncode,andcanbe used,for example,tocomparetheperformanceof twoor moreimplementations of a particular function or method. The other isthe cProfile module which can\n\n|||\n\n3.1",
      "content_length": 2944,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 442,
      "content": "Proﬁling\n\nbe used to proﬁle a program’s performance—it provides a detailed breakdown of call counts and times and so can be used to ﬁnd performance bottlenecks.★\n\nTo give a ﬂavor of the timeit module,we will look at a small example. Suppose we have three functions, function_a(), function_b(), and function_c(), all of which perform the same computation, but each using a different algorithm. If we put all these functions into a module (or import them), we can run them using the timeit module to see how they compare. Here is the code that we would use at the end of the module:\n\nif __name__ == \"__main__\":\n\nrepeats = 1000 for function in (\"function_a\", \"function_b\", \"function_c\"):\n\nt = timeit.Timer(\"{0}(X, Y)\".format(function),\n\n\"from __main__ import {0}, X, Y\".format(function))\n\nsec = t.timeit(repeats) / repeats print(\"{function}() {sec:.6f} sec\".format(**locals()))\n\nThe ﬁrst argument given to the timeit.Timer() constructor is the code we want toexecuteandtime,intheformof a string. Here,theﬁrsttimearoundtheloop, the string is \"function_a(X, Y)\". The second argument is optional; again it is a string to be executed,thistime beforethe code to be timed so asto provide some setup. Here we have imported from the __main__ (i.e.,this)module the function we want to test, plus two variables that are passed as input data (X and Y), and that are available as global variables in the module. We could just as easily have imported the function and data from a different module.\n\nWhen the timeit.Timer object’s timeit() method is called, it will ﬁrst execute the constructor’s second argument—if there was one—to set things up, and then it will execute the constructor’s ﬁrst argument—and time how long the execution takes. The timeit.Timer.timeit() method’s return value is the time taken in seconds, as a float. By default, the timeit() method repeats 1 million times and returns the total seconds for all these executions, but in this partic- ular case we needed only 1000 repeatsto give us useful results,so we speciﬁed the repeat count explicitly. After timing each function we divide the total by the number of repeats to get its mean (average) execution time and print the function’s name and execution time on the console.\n\nfunction_a() 0.001618 sec function_b() 0.012786 sec function_c() 0.003248 sec\n\nIn this example, function_a() is clearly the fastest—at least with the input data that was used. In some situations—for example, where performance can\n\n★The cProfile module is usually availablefor CPython interpreters,but is not alwaysavailablefor others. All Python libraries should have the pure Python profile module which provides the same API as the cProfile module, and does the same job, only more slowly.\n\n433",
      "content_length": 2731,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 443,
      "content": "434\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nvary considerably depending on the input data—we might have to test each function with multiple sets of input data to cover a representative set of cases and then compare the total or average execution times.\n\nIt isn’t always convenient to instrument our code to get timings, and so the timeit module provides a way of timing code from the command line. For example, to time function_a() from the MyModule.py module, we would enter the following in the console: python3 -m timeit -n 1000 -s \"from MyModule import function_a, X, Y\" \"function_a(X, Y)\". (As usual, for Windows, we must replace python3 with something like C:\\Python31\\python.exe.) The -m option is for the Python interpreter and tells it to load the speciﬁed module (in this case timeit) and theother optionsarehandledby the timeit module. The -n optionspeciﬁes the repetition count, the -s option speciﬁes the setup, and the last argument is the code to execute and time. After the command has ﬁnished it prints its results on the console, for example:\n\n1000 loops, best of 3: 1.41 msec per loop\n\nWe can easily then repeat the timing for the other two functionsso that we can compare them all.\n\nThe cProfile module (or the profile module—we will refer to them both as the cProfile module) can also be used to compare the performance of functions and methods. And unlike the timeit module that just provides raw timings, the cProfile module shows precisely what is being called and how long each call takes. Here’s the code we would use to compare the same three functions as before:\n\nif __name__ == \"__main__\":\n\nfor function in (\"function_a\", \"function_b\", \"function_c\"):\n\ncProfile.run(\"for i in range(1000): {0}(X, Y)\"\n\n.format(function))\n\nWe must put the number of repeats inside the code we pass to the cPro- file.run() function, but we don’t need to do any setup since the module func- tion uses introspection to ﬁnd the functions and variables we want to use. There is no explicit print() statement since by default the cProfile.run() func- tion prints its output on the console. Here are the results for all the functions (with some irrelevant lines omitted and slightly reformatted to ﬁt the page):\n\n1003 function calls in 1.661 CPU seconds ncalls tottime percall cumtime percall filename:lineno(function) 1 0.003 0.003 1.661 1.661 <string>:1(<module>) 1000 1.658 0.002 1.658 0.002 MyModule.py:21(function_a) 1 0.000 0.000 1.661 1.661 {built-in method exec}\n\n5132003 function calls in 22.700 CPU seconds",
      "content_length": 2522,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 444,
      "content": "Proﬁling\n\nncalls tottime percall cumtime percall filename:lineno(function) 1 0.487 0.487 22.700 22.700 <string>:1(<module>) 1000 0.011 0.000 22.213 0.022 MyModule.py:28(function_b) 5128000 7.048 0.000 7.048 0.000 MyModule.py:29(<genexpr>) 1000 0.005 0.000 0.005 0.000 {built-in method bisect_left} 1 0.000 0.000 22.700 22.700 {built-in method exec} 1000 0.001 0.000 0.001 0.000 {built-in method len} 1000 15.149 0.015 22.196 0.022 {built-in method sorted}\n\n5129003 function calls in 12.987 CPU seconds ncalls tottime percall cumtime percall filename:lineno(function) 1 0.205 0.205 12.987 12.987 <string>:1(<module>) 1000 6.472 0.006 12.782 0.013 MyModule.py:36(function_c) 5128000 6.311 0.000 6.311 0.000 MyModule.py:37(<genexpr>) 1 0.000 0.000 12.987 12.987 {built-in method exec}\n\nThe ncalls (“number of calls”) column lists the number of calls to the speciﬁed function (listed in the filename:lineno(function) column). Recall that we re- peated the calls 1000 times, so we must keep this in mind. The tottime (“total time”) column lists the total time spent in the function, but excluding time spent inside functions called by the function. The ﬁrst percall column lists the average time of each call to the function (tottime // ncalls). The cumtime (“cumulativetime”)columnliststhetimespentin thefunctionandincludesthe time spent inside functions called by the function. The second percall column lists the average time of each call to the function, including functions called by it.\n\nThisoutput isfar more enlightening than the timeit module’sraw timings. We can immediately see that both function_b() and function_c() use generators that are called more than 5000 times, making them both at least ten times slower than function_a(). Furthermore, function_b() calls more functions gen- erally,including a calltothebuilt-in sorted() function,andthismakesitalmost twice as slow as function_c().Of course,the timeit() module gave us sufﬁcient information to see these differences in timing, but the cProfile module allows us to see the details of why the differences are there in the ﬁrst place.\n\nJust as the timeit module allows us to time code without instrumenting it, so does the cProfile module. However, when using the cProfile module from the command line we cannot specify exactly what we want executed—it simply executes the given program or module and reports the timings of everything. The command line to use is python3 -m cProfile programOrModule.py, and the output produced is in the same format as we saw earlier; here is an extract slightly reformatted and with most lines omitted:\n\n435",
      "content_length": 2604,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 445,
      "content": "436\n\nChapter 9. Debugging,Testing,and Proﬁling\n\n10272458 function calls (10272457 primitive calls) in 37.718 CPU secs ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 37.718 37.718 <string>:1(<module>) 1 0.719 0.719 37.717 37.717 <string>:12(<module>) 1000 1.569 0.002 1.569 0.002 <string>:20(function_a) 1000 0.011 0.000 22.560 0.023 <string>:27(function_b) 5128000 7.078 0.000 7.078 0.000 <string>:28(<genexpr>) 1000 6.510 0.007 12.825 0.013 <string>:35(function_c) 5128000 6.316 0.000 6.316 0.000 <string>:36(<genexpr>)\n\nIn cProfile terminology, a primitive call is a nonrecursive function call.\n\nUsing the cProfile module in this way can be useful for identifying areas that are worth investigating further. Here, for example, we can clearly see that function_b() takes a long time. But how do we drill down into the details? We could instrument the programby replacing callsto function_b() with cProfile. run(\"function_b()\"). Or we could save the complete proﬁle data and analyze it using the pstats module. To save the proﬁle we must modify our command line slightly:python3 -m cProfile -o profileDataFile programOrModule.py.We can then analyze the proﬁle data, for example, by starting IDLE, importing the pstats module,and giving it the saved profileDataFile,or by using pstats interactive- ly at the console. Here’s a very short example console session that has been tidied up slightly to ﬁt on the page, and with our input shown in bold:\n\n$ python3 -m cProfile -o profile.dat MyModule.py $ python3 -m pstats Welcome to the profile statistics browser. % read profile.dat profile.dat% callers function_b Random listing order was used List reduced from 44 to 1 due to restriction <'function_b'> Function was called by... ncalls tottime cumtime <string>:27(function_b) <- 1000 0.011 22.251 <string>:12(<module>)\n\nprofile.dat% callees function_b Random listing order was used List reduced from 44 to 1 due to restriction <'function_b'> Function called... ncalls tottime cumtime <string>:27(function_b) -> 1000 0.005 0.005 built-in method bisect_left 1000 0.001 0.001 built-in method len 1000 15.297 22.234 built-in method sorted profile.dat% quit",
      "content_length": 2181,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 446,
      "content": "Proﬁling\n\nType help to get the list of commands, and help followed by a command name for more information on the command. For example, help stats will list what arguments can be given to the stats command. Other tools are available that can provide a graphical visualization of the proﬁle data, for example, RunSnakeRun (www.vrplumber.com/programming/runsnakerun), which depends on the wxPython GUI library.\n\nUsing the timeit and cProfile modules we can identify areas of our code that might be taking more time than expected, and using the cProfile module, we can ﬁnd out exactly where the time is being taken.\n\nSummary\n\nIn general, Python’s reporting of syntax errors is very accurate, with the line and position in the line being correctly identiﬁed. The only cases where this doesn’t work well are when we forget a closing parenthesis, bracket, or brace, in which casetheerror isnormally reportedasbeing on thenext nonblank line. Fortunately, syntax errors are almost always easy to see and to ﬁx.\n\nIf an unhandled exception is raised,Python will terminate and output a trace- back. Such tracebacks can be intimidating for end-users, but provide useful information to us as programmers. Ideally, we should always handle every type of exception that we believe our program can raise, and where necessary present the problem to the user in the form of an error message, message box, or log message—but not as a raw traceback. However, we should avoid using the catchall except: exception handler—if we want to handle all exceptions (e.g.,at thetoplevel),thenwecanuse except Exception as err,andalwaysreport err, since silently handling exceptions can lead to programs failing in subtle and unnoticed ways (such as corrupting data) later on. And during develop- ment, it is probably best not to have a top-level exception handler at all and to simply have the program crash with a traceback.\n\nDebugging need not be—and should not be—a hit and miss affair. By narrow- ing down the input necessary to reproduce the bug to the bare minimum, by carefully hypothesizing what the problem is, and then testing the hypothesis by experiment—using print() statements or a debugger—we can often locate the source of the bug quite quickly. And if our hypothesis has successfully led us to the bug, it is likely to also be helpful in devising a solution.\n\nFor testing, both the doctest and the unittest modules have their own partic- ular virtues. Doctests tend to be particularly convenient and useful for small libraries and modules since well-chosen tests can easily both illustrate and exercise boundary as well as common cases, and of course, writing doctests is convenient and easy. On the other hand,since unit testsare not constrained to be written inside docstrings and are written as separate stand-alone modules, they are usually a better choice when it comes to writing more complex and\n\n437\n\n|||",
      "content_length": 2896,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 447,
      "content": "438\n\nChapter 9. Debugging,Testing,and Proﬁling\n\nsophisticated tests,especially teststhat require setup and teardown (cleanup). For larger projects, using the unittest module (or a third-party unit testing module) keeps the tests and tested programsand modules separate and is gen- erally more ﬂexible and powerful than using doctests.\n\nIf we hit performance problems, the cause is most often our own code, and in particular our choice of algorithmsand data structures,or some inefﬁciency in our implementation. When faced with such problems, it is always wise to ﬁnd out exactly where the performance bottleneck is, rather than to guess and end up spending time optimizing something that doesn’t actually improve perfor- mance. Python’s timeit module can be used to get raw timings of functions or arbitrary code snippets,and so is particularly useful for comparing alternative function implementations. And for in-depth analysis,the cProfile module pro- vides both timing and call count information so that we can identify not only which functions take the most time, but also what functions they in turn call.\n\nOverall, Python has excellent support for debugging, testing, and proﬁling, right out of the box. However, especially for large projects, it is worth consid- ering some of the third-party testing tools,since they may offer more function- ality and convenience than the standard library’s testing modules provide.",
      "content_length": 1425,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 448,
      "content": "10 ● Using the Multiprocessing Module\n\nUsing the Threading Module\n\nProcesses and Threading\n\nWith theadvent of multicoreprocessorsasthenorm rather than theexception, it is more tempting and more practical than ever before to want to spread the processing load so as to get the most out of all the available cores. There are two main approaches to spreading the workload. One is to use multiple processes and the other is to use multiple threads. This chapter shows how to use both approaches.\n\nUsing multiple processes, that is, running separate programs, has the advan- tage that each process runs independently. This leaves all the burden of han- dling concurrency to the underlying operating system. The disadvantage is that communication and data sharing between the invoking program and the separate processes it invokes can be inconvenient. On Unix systems this can be solved by using the exec and fork paradigm, but for cross-platform pro- grams other solutions must be used. The simplest, and the one shown here, is for the invoking program to feed data to the processes it runs and leave them to produce their output independently. A more ﬂexible approach that greatly simpliﬁes two-way communication is to use networking. Of course, in many situations such communication isn’t needed—we just need to run one or more other programs from one orchestrating program.\n\nAn alternative to handing off work to independent processes is to create a threaded program that distributes work to independent threads of execution. This has the advantage that we can communicate simply by sharing data (pro- viding weensurethat shareddata isaccessedonly by onethreadat a time),but leaves the burden of managing concurrency squarely with the programmer. Python provides good support for creating threaded programs,minimizing the work that we must do. Nonetheless, multithreaded programs are inherently more complex than single-threaded programs and require much more care in their creation and maintenance.\n\nIn this chapter’s ﬁrst section we will create two small programs. The ﬁrst pro- gram isinvoked by the user and the second program isinvoked by the ﬁrst pro-\n\n439\n\n||||",
      "content_length": 2166,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 449,
      "content": "440\n\nChapter 10. Processes and Threading\n\ngram, with the second program invoked once for each separate process that is required. In the second section we will begin by giving a bare-bones introduc- tion to threaded programming. Then we will create a threaded program that hasthe same functionality asthe two programsfrom the ﬁrst section combined so as to provide a contrast between the multiple processes and the multiple threadsapproaches. And then we will review another threaded program,more sophisticated than the ﬁrst, that both hands off work and gathers together all the results.\n\nUsing the Multiprocessing Module\n\nIn some situations we already have programs that have the functionality we need but we want to automate their use. We can do this by using Python’s sub- process module which provides facilities for running other programs, passing any command-line options we want, and if desired, communicating with them using pipes. We saw one very simple example of this in Chapter 5 when we used the subprocess.call() function to clear the console in a platform-speciﬁc way. But we can also use these facilities to create pairs of “parent–child” pro- grams, where the parent program is run by the user and this in turn runs as many instances of the child program as necessary,each with different work to do. It is this approach that we will cover in this section.\n\nIn Chapter 3 we showed a very simple program, grepword.py, that searches for a word speciﬁed on the command line in the ﬁles listed after the word. In this section we will develop a more sophisticated version that can recurse into subdirectories to ﬁnd ﬁles to read and that can delegate the work to as many separate child processes as we like. The output is just a list of ﬁlenames (with paths) for those ﬁles that contain the speciﬁed search word.\n\nThe parent program is grepword-p.py and the child program is grepword-p- child.py.The relationship between the two programs when they are being run is shown schematically in Figure 10.1.\n\nThe heart of grepword-p.py isencapsulatedby its main() function,which we will look at in three parts:\n\ndef main():\n\nchild = os.path.join(os.path.dirname(__file__),\n\n\"grepword-p-child.py\")\n\nopts, word, args = parse_options() filelist = get_files(args, opts.recurse) files_per_process = len(filelist) // opts.count start, end = 0, files_per_process + (len(filelist) % opts.count) number = 1\n\n|||",
      "content_length": 2406,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 451,
      "content": "442\n\nChapter 10. Processes and Threading\n\nthe Python interpreter,but we prefer thisapproach because it ensuresthat the child program uses the same Python interpreter as the parent program.\n\nOnce we have the command ready we create a subprocess.Popen object, speci- fying the command to execute (as a list of strings),and in this case requesting to write to the process’s standard input. (It is also possible to read a process’s standard output by setting a similar keyword argument.) We then write the search word followed by a newline and then every ﬁle in the relevant slice of the ﬁle list. The subprocess module reads and writes bytes,not strings,but the processes it creates always assume that the bytes received from sys.stdin are stringsin the local encoding—even if the byteswe have sent use a different en- coding,such as UTF-8 which we have used here. We will see how to get around this annoying problem shortly. Once the word and the list of ﬁles have been written to the child process, we close its standard input and move on.\n\nIt isnot strictly necessary to keep a referenceto each process(the pipe variable gets rebound to a new subprocess.Popen object each time through the loop), since each process runs independently,but we add each one to a list so that we can make them interruptible. Also, we don’t gather the results together, but instead we let each processwrite itsresultsto the console in itsown time. This means that the output from different processes could be interleaved. (You will get the chance to avoid interleaving in the exercises.)\n\nwhile pipes:\n\npipe = pipes.pop() pipe.wait()\n\nOncealltheprocesseshavestartedwewaitforeachchildprocesstoﬁnish. This isnot essential,but on Unix-like systemsit ensuresthat we are returned to the console prompt when all the processesare done(otherwise,we must pressEnter when they are all ﬁnished). Another beneﬁt of waiting is that if we interrupt the program (e.g., by pressing Ctrl+C), all the processes that are still running will be interrupted and will terminate with an uncaught KeyboardInterrupt exception—if wedidnot waitthemainprogramwouldﬁnish(andthereforenot beinterruptible),and thechild processeswould continue(unlesskilled by a kill program or a task manager).\n\nApart from the comments and imports, here is the complete grepword-p- child.py program. We will look at the program in two parts—with two ver- sions of the ﬁrst part, the ﬁrst for any Python 3.x version and the second for Python 3.1 or later\n\nversions:\n\nBLOCK_SIZE = 8000\n\nnumber = \"{0}: \".format(sys.argv[1]) if len(sys.argv) == 2 else \"\" stdin = sys.stdin.buffer.read() lines = stdin.decode(\"utf8\", \"ignore\").splitlines() word = lines[0].rstrip()\n\n3.x\n\n3.0",
      "content_length": 2699,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 452,
      "content": "Using the Multiprocessing Module\n\nThe program begins by setting the number string to the given number or to an empty string if we are not debugging. Since the program is running as a child process and the subprocess module only reads and writes binary data and alwaysusesthe local encoding,we must read sys.stdin’sunderlying buffer of binary data and perform the decoding ourselves.★ Once we have read the binary data,we decode it into a Unicode string and split it into lines. The child process then reads the ﬁrst line, since this contains the search word.\n\nHere are the lines that are different for Python 3.1:\n\nsys.stdin = sys.stdin.detach() stdin = sys.stdin.read() lines = stdin.decode(\"utf8\", \"ignore\").splitlines()\n\nPython 3.1 provides the sys.stdin.detach() method that returns a binary ﬁle object. We then read in all the data, decode it into Unicode using the encoding of our choice, and then split the Unicode string into lines.\n\nfor filename in lines[1:]:\n\nfilename = filename.rstrip() previous = \"\" try:\n\nwith open(filename, \"rb\") as fh:\n\nwhile True:\n\ncurrent = fh.read(BLOCK_SIZE) if not current:\n\nbreak\n\ncurrent = current.decode(\"utf8\", \"ignore\") if (word in current or\n\nword in previous[-len(word):] +\n\ncurrent[:len(word)]):\n\nprint(\"{0}{1}\".format(number, filename)) break\n\nif len(current) != BLOCK_SIZE:\n\nbreak\n\nprevious = current\n\nexcept EnvironmentError as err:\n\nprint(\"{0}{1}\".format(number, err))\n\nAll the lines after the ﬁrst are ﬁlenames (with paths). For each one we open the relevant ﬁle,read it,and print its name if it contains the search word. It is possible that some of the ﬁles might be very large and this could be a problem, especially if there are 20 child processes running concurrently,all reading big\n\n★It is possible that a future version of Python will have a version of the subprocess module that allows encoding and errors arguments so that we can use our preferred encoding without having to access sys.stdin in binary mode and do the decoding ourselves. See bugs.python.org/issue6135.\n\n443\n\n3.1",
      "content_length": 2038,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 453,
      "content": "Char- acter encod- ings 91➤\n\n444\n\nChapter 10. Processes and Threading\n\nﬁles. We handle this by reading each ﬁle in blocks, keeping the previous block read to ensure that we don’t misscases when the only occurrence of the search word happens to fall across two blocks. Another beneﬁt of reading in blocks is that if the search word appears early in the ﬁle we can ﬁnish with the ﬁle without having read everything,since all we care about is whether the word is in the ﬁle, not where it appears within the ﬁle.\n\nThe ﬁles are read in binary mode,so we must convert each block to a string be- fore we can search it, since the search word is a string. We have assumed that all the ﬁlesuse the UTF-8encoding,but thisismost likely wrong in somecases. A more sophisticated program would try to determine the actual encoding and then close and reopen the ﬁle using the correct encoding. Aswe noted in Chap- ter 2,at least two Python packagesfor automatically detecting a ﬁle’sencoding are available from the Python Package Index, pypi.python.org/pypi. (It might be tempting to decode the search word into a bytes object and compare bytes with bytes, but that approach is not reliable since some characters have more than one valid UTF-8 representation.)\n\nThe subprocess module offers a lot more functionality than we have needed to use here, including the ability to provide equivalents to shell backquotes and shell pipelines, and to the os.system() and spawn functions.\n\nIn the next section we will see a threaded version of the grepword-p.py program so that we can compare it with the parent–child processes one. We will also look at a more sophisticated threaded program that delegates work and then gathers the results together to have more control over how they are output.\n\nUsing the Threading Module\n\nSetting up two or more separate threads of execution in Python is quite straightforward. The complexity arises when we want separate threads to share data. Imagine that we have two threads sharing a list. One thread might start iterating over the list using for x in L and then somewhere in the middleanotherthreadmightdeletesomeitemsinthelist. Atbestthiswilllead to obscure crashes, at worst to incorrect results.\n\nOne common solution is to use some kind of locking mechanism. For example, one thread might acquirea lock and thenstart iterating over the list;any other thread will then be blocked by the lock. In fact,thingsare not quite as clean as this. The relationship between a lock and the data it is locking exists purely in our imagination. If one thread acquires a lock and a second thread tries to acquire the same lock,the second thread will be blocked until the ﬁrst releases the lock. By putting access to shared data within the scope of acquired locks we can ensure that the shared data is accessed by only one thread at a time, even though the protection is indirect.\n\n|||",
      "content_length": 2888,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 455,
      "content": "446\n\nChapter 10. Processes and Threading\n\nwhen it is ready. No other threading.Thread methods may be reimplemented, although adding additional methods is ﬁne.\n\nExample: A Threaded Find Word Program\n\nIn this subsection we will review the code for the grepword-t.py program. This program does the same job as grepword-p.py, only it delegates the work to mul- tiple threads rather than to multiple processes. It is illustrated schematically in Figure 10.3.\n\nOne particularly interesting feature of the program is that it does not appear to use any locks at all. This is possible because the only shared data is a list of ﬁles, and for these we use the queue.Queue class. What makes queue.Queue special isthat it handlesall the locking itself internally,so whenever we access it to add or remove items, we can rely on the queue itself to serialize accesses. In the context of threading, serializing access to data means ensuring that only one thread at a time has access to the data. Another beneﬁt of using queue.Queue is that we don’t have to share out the work ourselves; we simply add items of work to the queue and leave the worker threads to pick up work whenever they are ready.\n\nThe queue.Queue class works on a ﬁrst in, ﬁrst out (FIFO) basis; the queue module also provides queue.LifoQueue for last in, ﬁrst out (LIFO) access, and queue.PriorityQueue which is given tuples such as the 2-tuple (priority, item), with items with the lowest priority numbers being processed ﬁrst. All the queuescanbecreatedwitha maximumsizeset;if themaximumsizeisreached the queue will block further attempts to add items until items have been removed.\n\nWe will look at the grepword-t.py program in three parts, starting with the complete main() function:\n\ndef main():\n\nopts, word, args = parse_options() filelist = get_files(args, opts.recurse) work_queue = queue.Queue() for i in range(opts.count):\n\nnumber = \"{0}: \".format(i + 1) if opts.debug else \"\" worker = Worker(work_queue, word, number) worker.daemon = True worker.start()\n\nfor filename in filelist:\n\nwork_queue.put(filename)\n\nwork_queue.join()\n\n||",
      "content_length": 2093,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 456,
      "content": "Using the Threading Module\n\ngrepword-t.py\n\nmain thread\n\nthread #1\n\nthread #2\n\nthread #3\n\n…\n\nFigure 10.3 A multithreaded program\n\nGetting the user’soptionsand the ﬁle list are the same as before.Once we have thenecessary informationwecreatea queue.Queue and then loopasmany times as there are threads to be created;the default is 7. For each thread we prepare a number string for debugging (an empty string if we are not debugging) and then we create a Worker (a threading.Thread subclass) instance—we’ll come back to setting the daemon property in a moment. Next we start off the thread, although at this point it has no work to do because the work queue is empty,so the thread will immediately be blocked trying to get some work.\n\nWith all the threads created and ready for work we iterate over all the ﬁles, adding each one to the work queue. As soon as the ﬁrst ﬁle is added one of the threads could get it and start on it,and so on until all the threads have a ﬁle to work on. As soon as a thread ﬁnishes working on a ﬁle it can get another one, until all the ﬁles are processed.\n\nNotice that this differs from grepword-p.py where we had to allocate slices of the ﬁle list to each child process, and the child processes were started and given their lists sequentially. Using threads is potentially more efﬁcient in cases like this. For example, if the ﬁrst ﬁve ﬁles are very large and the rest are small, because each thread takes on one job at a time each large ﬁle will be processed by a separate thread, nicely spreading the work. But with the multipleprocessesapproachwetook inthe grepword-p.py program,allthelarge ﬁles would be given to the ﬁrst process and the small ﬁles given to the others, so theﬁrst processwould end updoing most of thework while theothersmight all ﬁnish quickly without having done much at all.\n\nThe program will not terminate while it has any threads running. This is a problem because once the worker threadshave done their work,although they have ﬁnished they are technically still running. The solution is to turn the threads into daemons. The effect of this is that the program will terminate as soon as the program has no nondaemon threads running. The main thread is not a daemon, so once the main thread ﬁnishes, the program will cleanly terminate each daemon thread and then terminate itself. Of course, this can now create the opposite problem—once the threads are up and running we must ensure that the main thread does not ﬁnish until all the work is done. This is achieved by calling queue.Queue.join()—this method blocks until the queue is empty.\n\nHere is the start of the Worker class:\n\n447",
      "content_length": 2637,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 457,
      "content": "448\n\nChapter 10. Processes and Threading\n\nclass Worker(threading.Thread):\n\ndef __init__(self, work_queue, word, number):\n\nsuper().__init__() self.work_queue = work_queue self.word = word self.number = number\n\ndef run(self):\n\nwhile True: try:\n\nfilename = self.work_queue.get() self.process(filename)\n\nfinally:\n\nself.work_queue.task_done()\n\nThe __init__() method must call the base class __init__(). The work queue is the same queue.Queue shared by all the threads.\n\nWe have made the run() method an inﬁnite loop. This is common for daemon threads, and makes sense here because we don’t know how many ﬁles the threadmustprocess. At each iterationwecall queue.Queue.get() toget thenext ﬁle to work on. This call will block if the queue is empty, and does not have to be protected by a lock because queue.Queue handles that automatically for us. Once we have a ﬁle we process it, and afterward we must tell the queue that we have done that particular job—calling queue.Queue.task_done() is essential to the correct working of queue.Queue.join().\n\nWe have not shown the process() function,because apart from the def line, the code is the same as the code used in grepword-p-child.py from the previous = \"\" line to the end (443➤).\n\nOne ﬁnal point to note is that included with the book’s examples is grepword- m.py, a program that is almost identical to the grepword-t.py program reviewed here, but which uses the multiprocessing module rather than the threading module. The code has just three differences: ﬁrst, we import multiprocessing instead of queue and threading; second, the Worker class inherits multiprocess- ing.Process instead of threading.Thread; and third, the work queue is a multi- processing.JoinableQueue instead of a queue.Queue.\n\nThe multiprocessing module provides thread-like functionality using forking on systemsthat support it (Unix),and child processeson those that don’t (Win- dows), so locking mechanisms are not always required, and the processes will run on whateverprocessorcorestheoperating systemhasavailable. Thepack- age provides several ways of passing data between processes, including using a queue that can be used to provide work for processesjust like queue.Queue can be used to provide work for threads.",
      "content_length": 2240,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 458,
      "content": "Using the Threading Module\n\nThe chief beneﬁt of the multiprocessing version is that it can potentially run faster on multicore machines than the threaded version since it can run its processes on as many cores as are available. Compare this with the standard Python interpreter (written in C, sometimes called CPython) which has a GIL (Global Interpreter Lock) that means that only one thread can execute Python code at any one time. Thisrestriction isan implementation detail and doesnot necessarily apply to other Python interpreters such as Jython.★\n\nExample: A Threaded Find Duplicate Files Program\n\nThe second threading example has a similar structure to the ﬁrst, but is more sophisticated in several ways. It uses two queues, one for work and one for results, and has a separate results processing thread to output results as soon as they are available. It also shows both a threading.Thread subclass and calling threading.Thread() with a function, and also uses a lock to serialize access to shared data (a dict).\n\nThe findduplicates-t.py program is a more advanced version of the finddup.py program from Chapter 5. It iterates over all the ﬁles in the current directory (or the speciﬁed path), recursively going into subdirectories. It compares the lengths of all the ﬁles with the same name (just like finddup.py), and for those ﬁles that have the same name and the same size it then uses the MD5 (Message Digest) algorithm to check whether the ﬁles are the same, reporting any that are.\n\nWe will start by looking at the main() function, split into four parts.\n\ndef main():\n\nopts, path = parse_options() data = collections.defaultdict(list) for root, dirs, files in os.walk(path):\n\nfor filename in files:\n\nfullname = os.path.join(root, filename) try:\n\nkey = (os.path.getsize(fullname), filename)\n\nexcept EnvironmentError:\n\ncontinue if key[0] == 0: continue\n\ndata[key].append(fullname)\n\n★For a brief explanationof why CPythonusesa GIL see www.python.org/doc/faq/library/#can-t-we- get-rid-of-the-global-interpreter-lock and docs.python.org/api/threads.html.\n\n449\n\n||",
      "content_length": 2075,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 459,
      "content": "450\n\nChapter 10. Processes and Threading\n\nEach key of the data default dictionary is a 2-tuple of (size, ﬁlename), where the ﬁlename does not include the path, and each value is a list of ﬁlenames (which do include their paths). Any items whose value list has more than one ﬁlename potentially has duplicates. The dictionary is populated by iterating over all the ﬁles in the given path,but skipping any ﬁles we cannot get the size of (perhapsdue to permissionsproblems,or because they are not normal ﬁles), and any that are of 0 size (since all zero length ﬁles are the same).\n\nwork_queue = queue.PriorityQueue() results_queue = queue.Queue() md5_from_filename = {} for i in range(opts.count):\n\nnumber = \"{0}: \".format(i + 1) if opts.debug else \"\" worker = Worker(work_queue, md5_from_filename, results_queue,\n\nnumber)\n\nworker.daemon = True worker.start()\n\nWith all the data in place we are ready to create the worker threads. We begin by creating a work queue and a results queue. The work queue is a priority queue, so it will always return the lowest-priority items (in our case the smallest ﬁles) ﬁrst. We also create a dictionary where each key is a ﬁlename (including its path) and where each value is the ﬁle’s MD5 digest value. The purpose of the dictionary is to ensure that we never compute the MD5 of the same ﬁle more than once (since the computation is expensive).\n\nWith the shared data collections in place we loop as many times as there are threads to create (by default, seven times). The Worker subclass is similar to the one we created before, only this time we pass both queues and the MD5 dictionary. As before, we start each worker straight away and each will be blocked until a work item becomes available.\n\nresults_thread = threading.Thread(\n\ntarget=lambda: print_results(results_queue))\n\nresults_thread.daemon = True results_thread.start()\n\nRather than creating a threading.Thread subclass to process the results we have created a function and we pass that to threading.Thread(). The return value is a custom thread that will call the given function once the thread is started. We pass the results queue (which is, of course, empty), so the thread will block immediately.\n\nAt thispoint we have createdall theworker threadsand theresultsthread and they are all blocked waiting for work.\n\nfor size, filename in sorted(data):",
      "content_length": 2347,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 460,
      "content": "Using the Threading Module\n\nnames = data[size, filename] if len(names) > 1:\n\nwork_queue.put((size, names))\n\nwork_queue.join() results_queue.join()\n\nWe now iterate over the data, and for each (size, ﬁlename) 2-tuple that has a list of two or more potentially duplicateﬁles,we add the size and the ﬁlenames with paths as an item of work to the work queue. Since the queue is a class from the queue module we don’t have to worry about locking.\n\nFinally we join the work queue and resultsqueue to block until they are empty. This ensures that the program runs until all the work is done and all the results have been output, and then terminates cleanly.\n\ndef print_results(results_queue):\n\nwhile True: try:\n\nresults = results_queue.get() if results:\n\nprint(results)\n\nfinally:\n\nresults_queue.task_done()\n\nThis function is passed as an argument to threading.Thread() and is called when the thread it is given to is started. It has an inﬁnite loop because it is to be used as a daemon thread. All it does is get results (a multiline string), and if the string is nonempty, it prints it for as long as results are available.\n\nThe beginning of the Worker class is similar to what we had before:\n\nclass Worker(threading.Thread):\n\nMd5_lock = threading.Lock()\n\ndef __init__(self, work_queue, md5_from_filename, results_queue,\n\nnumber):\n\nsuper().__init__() self.work_queue = work_queue self.md5_from_filename = md5_from_filename self.results_queue = results_queue self.number = number\n\ndef run(self):\n\nwhile True: try:\n\nsize, names = self.work_queue.get() self.process(size, names)\n\n451",
      "content_length": 1573,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 461,
      "content": "Context man- agers 369➤\n\n452\n\nChapter 10. Processes and Threading\n\nfinally:\n\nself.work_queue.task_done()\n\nThe differences are that we have more shared data to keep track of and we call our custom process() function with different arguments. We don’t have to worry about the queues since they ensure that accesses are serialized, but for other data items,in this case the md5_from_filename dictionary,we must handle the serialization ourselves by providing a lock. We have made the lock a class attribute because we want every Worker instance to use the same lock so that if one instance holds the lock, all the other instances are blocked if they try to acquire it.\n\nWe will review the process() function in two parts.\n\ndef process(self, size, filenames):\n\nmd5s = collections.defaultdict(set) for filename in filenames: with self.Md5_lock:\n\nmd5 = self.md5_from_filename.get(filename, None)\n\nif md5 is not None:\n\nmd5s[md5].add(filename)\n\nelse:\n\ntry:\n\nmd5 = hashlib.md5() with open(filename, \"rb\") as fh:\n\nmd5.update(fh.read())\n\nmd5 = md5.digest() md5s[md5].add(filename) with self.Md5_lock:\n\nself.md5_from_filename[filename] = md5\n\nexcept EnvironmentError:\n\ncontinue\n\nWe start out with an empty default dictionary where each key is to be an MD5 digest value and where each value is to be a set of the ﬁlenames of the ﬁles that have the corresponding MD5 value. We then iterate over all the ﬁles,and for each one we retrieve its MD5if we have already calculated it,and calculate it otherwise.\n\nWhether we access the md5_from_filename dictionary to read it or to write to it, we put the access in the context of a lock. Instances of the threading.Lock() class are context managers that acquire the lock on entry and release the lock on exit. The with statementswillblock if another threadhasthe Md5_lock,until the lock is released. For the ﬁrst with statement when we acquire the lock we get the MD5 from the dictionary (or None if it isn’t there).If the MD5 is None we must compute it, in which case we store it in the md5_from_filename dictionary to avoid performing the computation more than once per ﬁle.",
      "content_length": 2105,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 462,
      "content": "GIL 449➤\n\nGIL 449➤\n\nUsing the Threading Module\n\nNotice that at all timeswe try to minimize the amount of work done within the scope of a lock to keep blocking to a minimum—in this case just one dictionary access each time.\n\nStrictly speaking, we do not need to use a lock at all if we are using CPython, since the GIL effectively synchronizes dictionary accesses for us. However,we havechosen toprogramwithoutrelying on theGILimplementationdetail,and so we use an explicit lock.\n\nfor filenames in md5s.values(): if len(filenames) == 1:\n\ncontinue\n\nself.results_queue.put(\"{0}Duplicate files ({1:n} bytes):\" \"\\n\\t{2}\".format(self.number, size, \"\\n\\t\".join(sorted(filenames))))\n\nAt the end we loop over the local md5s default dictionary, and for each set of names that contains more than one name we add a multiline string to the resultsqueue. Thestring containstheworker threadnumber (anempty string by default), the size of the ﬁle in bytes, and all the duplicate ﬁlenames. We don’t need to use a lock to access the results queue since it is a queue.Queue which will automatically handle the locking behind the scenes.\n\nThequeue module’sclassesgreatlysimplifythreadedapplications,andwhenwe need to use explicit locks the threading module offers many options. Here we used the simplest, threading.Lock, but others are available, including thread- ing.RLock (a lock that can be acquired again by the thread that already holds it), threading.Semaphore (a lock that can be used to protect a speciﬁc number of resources), and threading.Condition that provides a wait condition.\n\nUsing multiple threads can often lead to cleaner solutions than using the subprocess module, but unfortunately, threaded Python programs do not nec- essarily achieve the best possible performance compared with using multiple processes. As noted earlier, the problem afﬂicts the standard implementation of Python, since the CPython interpreter can execute Python code on only one processor at a time, even when using multiple threads.\n\nOne packagethat triesto solve thisproblem isthe multiprocessing module,and as we noted earlier, the grepword-m.py program is a multiprocessing version of the grepword-t.py program, with only three lines that are different. A similar transformation could be applied to the findduplicates-t.py program reviewed here, but in practice this is not recommended. Although the multiprocessing module offersan API (Application Programming Interface)that closely match- es the threading module’s API to ease conversion, the two APIs are not the same and have different trade-offs. Also, performing a mechanistic conver- sion from threading to multiprocessing is likely to be successful only on small, simple programs like grepword-t.py; it is too crude an approach to use for the\n\n453",
      "content_length": 2782,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 463,
      "content": "454\n\nChapter 10. Processes and Threading\n\nfindduplicates-t.py program,and in general it is best to design programsfrom thegroundupwith multiprocessing inmind. (Theprogramfindduplicates-m.py is provided with the book’s examples; it does the same job as findduplicates- t.py but works in a very different way and uses the multiprocessing module.)\n\nAnother solution being developed is a threading-friendly version of the CPython interpreter; see www.code.google.com/p/python-threadsafe for the lat- est project status.\n\nSummary\n\nThis chapter showed how to create programs that can execute other programs using the standard library’s subprocess module. Programs that are run using subprocess can be given command-line data, can be fed data to their standard input, and can have their standard output (and standard error) read. Using child processes allows us to take maximum advantage of multicore processors and leaves concurrency issues to be handled by the operating system. The downside is that if we need to share data or synchronize processes we must devise some kind of communication mechanism, for example, shared memory (e.g., using the mmap module), shared ﬁles, or networking, and this can require care to get right.\n\nThe chapter also showed how to createmultithreadedprograms. Unfortunate- ly,such programscannot takefull advantageof multiplecores(if run using the standardCPython interpreter),so for Python,using multipleprocessesisoften a more practical solution where performance is concerned. Nonetheless, we saw that the queue module and Python’s locking mechanisms, such as thread- ing.Lock, make threaded programming as straightforward as possible—and that for simple programs that only need to use queue objects like queue.Queue and queue.PriorityQueue, we may be able to completely avoid using explic- it locks.\n\nAlthough multithreaded programming is undoubtedly fashionable, it can be much more demanding to write, maintain, and debug multithreaded pro- grams than single-threaded ones. However,multithreaded programsallow for straightforwardcommunication,for example,using shared data (providing we use a queue class or use locking), and make it much easier to synchronize (e.g., to gather results) than using child processes. Threading can also be very use- ful in GUI (Graphical User Interface) programs that must carry out long-run- ning tasks while maintaining responsiveness, including the ability to cancel the task being worked on. But if a good communication mechanism between processes is used, such as shared memory, or the process-transparent queue offered by the multiprocessing package, using multiple processes can often be a viable alternative to multiple threads.\n\n|||",
      "content_length": 2703,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 464,
      "content": "Summary\n\nThe following chapter shows another example of a threaded program;a server that handles each client request in a separate thread, and that uses locks to protect shared data.\n\nExercises\n\n1. Copy and modify the grepword-p.py program so that instead of the child processes printing their output, the main program gathers the results, and after all the child processeshave ﬁnished,sortsand printsthe results. This only requires editing the main() function and changing three lines and adding three lines. The exercise does require some thought and care, and you will need to read the subprocess module’s documentation. A solu- tion is given in grepword-p_ans.py.\n\n2. Write a multithreaded program that reads the ﬁles listed on the com- mand line (and the ﬁles in any directories listed on the command line, recursively).For any ﬁle that is an XML ﬁle (i.e.,it beginswith the charac- ters “<?xml”), parse the ﬁle using an XML parser and produce a list of the unique tags used by the ﬁle or an error message if a parsing error occurs. Here is a sample of the program’s output from one particular run: ./data/dvds.xml is an XML file that uses the following tags: dvd dvds ./data/bad.aix is an XML file that has the following error: mismatched tag: line 7889, column 2 ./data/incidents.aix is an XML file that uses the following tags: airport incident incidents narrative\n\nThe easiest way to write the program is to modify a copy of the findduplicates-t.py program, although you can of course write the pro- gram entirely from scratch. Small changes will need to be made to the Worker class’s __init__() and run() methods,and the process() method will need to be rewritten entirely (but needs only around twenty lines). The program’s main() function will need several simpliﬁcationsand so will one line of the print_results() function. The usage message will also need to be modiﬁed to match the one shown here:\n\nUsage: xmlsummary.py [options] [path] outputs a summary of the XML files in path; path defaults to .\n\nOptions: -h, --help show this help message and exit\n\n455\n\n|||",
      "content_length": 2077,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 465,
      "content": "456\n\nChapter 10. Processes and Threading\n\nt COUNT, --threads=COUNT the number of threads to use (1..20) [default 7] -v, --verbose -d, --debug\n\nMakesureyou try running theprogramwith thedebug ﬂag set sothatyou can check that the threads are started up and that each one does its share of the work. A solution isprovided in xmlsummary.py,which isslightly more than 100 lines and uses no explicit locks.",
      "content_length": 400,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 466,
      "content": "11 ● Creating a TCP Client\n\nCreating a TCP Server\n\nNetworking\n\nNetworking allows computer programs to communicate with each other, even if they are running on different machines. For programs such as web browsers, this is the essence of what they do, whereas for others networking adds additional dimensions to their functionality, for example, remote opera- tion or logging,or theability toretrieveor supply data toother machines. Most networking programs work on either a peer-to-peer basis (the same program runs on different machines), or more commonly, a client/server basis (client programs send requests to a server).\n\nIn this chapter we will create a basic client/server application. Such applica- tions are normally implemented as two separate programs:a server that waits for and responds to requests, and one or more clients that send requests to the server and read back the server’s response. For this to work, the clients must know where to connect to the server, that is, the server’s IP (Internet Proto- col) address and port number.★ Also, both clients and server must send and receive data using an agreed-upon protocol using data formats that they both understand.\n\nPython’s low-level socket module (on which all of Python’s higher-level net- working modules are based) supports both IPv4 and IPv6 addresses. It also supports the most commonly used networking protocols,including UDP (User DatagramProtocol),alightweightbutunreliableconnectionlessprotocolwhere data is sent as discrete packets (datagrams) but with no guarantee that they will arrive, and TCP (Transmission Control Protocol), a reliable connection- and stream-oriented protocol. With TCP, any amount of data can be sent and received—the socket is responsible for breaking the data into chunks that are small enough to send, and for reconstructing the data at the other end.\n\n★Machines can also connect using service discovery, for example, using the bonjour API; suitable modules are available from the Python Package Index, pypi.python.org/pypi.\n\n457\n\n||||",
      "content_length": 2042,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 467,
      "content": "Pickles 292➤\n\n458\n\nChapter 11. Networking\n\nUDP is often used to monitor instruments that give continuous readings, and where the odd missed reading is not signiﬁcant, and it is sometimes used for audio or video streaming in cases where the occasional missed frame is ac- ceptable. Both the FTP and the HTTP protocols are built on top of TCP, and client/server applicationsnormally use TCP because they need connection-ori- ented communicationand thereliability that TCP provides. In thischapter we will develop a client/server program, so we use TCP.\n\nAnother decision that must be made is whether to send and receive data as lines of text or as blocks of binary data, and if the latter, in what form. In this chapter we use blocks of binary data where the ﬁrst four bytes are the length of the following data (encoded as an unsigned integer using the struct mod- ule), and where the following data is a binary pickle. The advantage of this approach is that we can use the same sending and receiving code for any ap- plication since we can store almost any arbitrary data in a pickle. The disad- thatbothclientandserver mustunderstandpickles,sothey mustbe vantageis written in Python or must be able to access Python, for example, using Jython in Java or Boost.Python in C++. And of course, the usual security considera- tions apply to the use of pickles.\n\nTheexamplewewill useisa car registrationprogram. Theserver holdsdetails of car registrations(licenseplate,seats,mileage,and owner).The client isused to retrieve car details, to change a car’s mileage or owner, or to create a new car registration. Any number of clients can be used and they won’t block each other,even if twoaccesstheserver at thesametime. Thisisbecausetheserver hands off each client’s request to a separate thread. (We will also see that it is just as easy to use separate processes.)\n\nFor the sake of the example, we will run the server and clients on the same machine; this means that we can use “localhost” as the IP address (although if the server is on another machine the client can be given its IP address on the command line and this will work as long as there is no ﬁrewall in the way).We have also chosen an arbitrary port number of 9653. The port number should be greater than 1023 and is normally between 5001 and 32767, although port numbers up to 65535 are normally valid.\n\nThe server can accept ﬁve kinds of requests: GET_CAR_DETAILS, CHANGE_MILEAGE, CHANGE_OWNER, NEW_REGISTRATION,and SHUTDOWN,witha correspondingresponse for each. The response is the requested data or conﬁrmation of the requested action, or an indication of an error.\n\nCreating a TCP Client\n\n|||\n\nThe client program is car_registration.py. Here is an example of interaction (with the server already running, and with the menu edited slightly to ﬁt on the page):",
      "content_length": 2821,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 468,
      "content": "Branch- ing using dictio- naries 340➤\n\nCreating a TCP Client\n\n(C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: License: 024 hyr License: 024 HYR Seats: 2 Mileage: 97543 Owner: Jack Lemon (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: m License [024 HYR]: Mileage [97543]: 103491 Mileage successfully changed\n\nThe data entered by the user is shown in bold—where there is no visible input it means that the user pressed Enter to accept the default. Here the user has asked to see the details of a particular car and then updated its mileage.\n\nAs many clients as we like can be running, and when a user quits their partic- ular client the server is unaffected. But if the server is stopped, the client it wasstoppedin will quit and all theother clientswill get a “Connectionrefused” errorandwillterminatewhenthey nextattempttoaccesstheserver. Inamore sophisticated application,the ability to stop the server would be available only to certain users, perhaps on only particular machines, but we have included it in the client to show how it is done.\n\nWewillnowreviewthecode,starting withthe main() functionandthehandling of the user interface, and ﬁnishing with the networking code itself.\n\ndef main():\n\nif len(sys.argv) > 1:\n\nAddress[0] = sys.argv[1]\n\ncall = dict(c=get_car_details, m=change_mileage, o=change_owner,\n\nn=new_registration, s=stop_server, q=quit)\n\nmenu = (\"(C)ar Edit (M)ileage Edit (O)wner (N)ew car \"\n\n\"(S)top server (Q)uit\")\n\nvalid = frozenset(\"cmonsq\") previous_license = None while True:\n\naction = Console.get_menu_choice(menu, valid, \"c\", True) previous_license = call[action](previous_license)\n\nThe Address list is a global that holds the IP address and port number as a two-item list, [\"localhost\", 9653], with the IP address overridden if speciﬁed on the command line. The call dictionary maps menu options to functions.\n\nThe Console module is one supplied with this book and contains some use- ful functions for getting values from the user at the console, such as Con- sole.get_string() and Console.get_integer(); these are similar to functions\n\n459",
      "content_length": 2095,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 469,
      "content": "460\n\nChapter 11. Networking\n\ndevelopedinearlier chaptersandhavebeenput ina moduletomakethemeasy to reuse in different programs.\n\nAs a convenience for users, we keep track of the last license they entered so that it can be used as the default, since most commands start by asking for the license of the relevant car. Once the user makes a choice we call the corre- sponding function passing in the previouslicense,and expecting each function to return the license it used. Since the loop is inﬁnite the program must be ter- minated by one of the functions; we will see this further on.\n\ndef get_car_details(previous_license):\n\nlicense, car = retrieve_car_details(previous_license) if car is not None:\n\nprint(\"License: {0}\\nSeats:\n\n{seats}\\nMileage: {mileage}\\n\"\n\n\"Owner:\n\n{owner}\".format(license, **car._asdict()))\n\nreturn license\n\nThis function is used to get information about a particular car. Since most of the functions need to request a license from the user and often need some car-related data to work on, we have factored out this functionality into the retrieve_car_details() function—it returns a 2-tuple of the license entered by the user and a named tuple, CarTuple, that holds the car’s seats, mileage, and owner (or the previous license and None if they entered an unrecognized license). Here we just print the information retrieved and return the license to be used as the default for the next function that is called and that needs the license.\n\ndef retrieve_car_details(previous_license):\n\nlicense = Console.get_string(\"License\", \"license\",\n\nprevious_license)\n\nif not license:\n\nreturn previous_license, None\n\nlicense = license.upper() ok, *data = handle_request(\"GET_CAR_DETAILS\", license) if not ok:\n\nprint(data[0]) return previous_license, None\n\nreturn license, CarTuple(*data)\n\nThis is the ﬁrst function to make use of networking. It calls the handle_re- quest() function that we review further on. The handle_request() function takes whatever data it is given as arguments and sends it to the server, and then returns whatever the server replies. The handle_request() function does not know or care what data it sends or returns;it purely providesthe network- ing service.",
      "content_length": 2193,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 470,
      "content": "Creating a TCP Client\n\nIn the case of car registrations we have a protocol where we always send the name of the action we want the server to perform as the ﬁrst argument, fol- lowed by any relevant parameters—in this case, just the license. The proto- col for the reply is that the server always return a tuple whose ﬁrst item is a Boolean success/failure ﬂag. If the ﬂag is False, we have a 2-tuple and the sec- ond item is an error message. If the ﬂag is True, the tuple is either a 2-tuple with the second item being a conﬁrmation message,or an n-tuple with the sec- ond and subsequent items holding the data that was requested.\n\nSo here, if the license is unrecognized, ok is False and we print the error message in data[0] and return the previous license unchanged. Otherwise,we return the license (which will now become the previouslicense),and a CarTuple made from the data list, (seats, mileage, owner).\n\ndef change_mileage(previous_license):\n\nlicense, car = retrieve_car_details(previous_license) if car is None:\n\nreturn previous_license\n\nmileage = Console.get_integer(\"Mileage\", \"mileage\",\n\ncar.mileage, 0)\n\nif mileage == 0:\n\nreturn license\n\nok, *data = handle_request(\"CHANGE_MILEAGE\", license, mileage) if not ok:\n\nprint(data[0])\n\nelse:\n\nprint(\"Mileage successfully changed\")\n\nreturn license\n\nThis function follows a similar pattern to get_car_details(), except that once we have the details we update one aspect of them. There are in fact two networking calls,since retrieve_car_details() calls handle_request() to get the car’s details—we need to do this both to conﬁrm that the license is valid and to getthecurrentmileagetouseasthedefault. Herethereply isalwaysa 2-tuple, with either an error message or None as the second item.\n\nWe won’t review the change_owner() function since it isstructurally the same as change_mileage(), nor will we review new_registration() since it differs only in not retrieving car details at the start (since it is a new car being entered), and asking the user for all the details rather than just changing one detail,none of which is new to us or relevant to network programming.\n\ndef quit(*ignore): sys.exit()\n\n461",
      "content_length": 2161,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 471,
      "content": "462\n\nChapter 11. Networking\n\ndef stop_server(*ignore):\n\nhandle_request(\"SHUTDOWN\", wait_for_reply=False) sys.exit()\n\nIf the user chooses to quit the program we do a clean termination by calling sys.exit(). Every menu function is called with the previous license, but we don’t care about the argument in this particular case. We cannot write def quit(): because that would create a function that expectsno argumentsand so when the function was called with the previous license a TypeError exception would be raised saying that no arguments were expected but that one was giv- en. So instead we specify a parameter of *ignore which can take any number of positional arguments. The name ignore has no signiﬁcance to Python and is used purely to indicate to maintainers that the arguments are ignored.\n\nIf the user chooses to stop the server we use handle_request() to inform the server, and specify that we don’t want a reply. Once the data is sent, han- dle_request() returns without waiting for a reply, and we do a clean termina- tion using sys.exit().\n\ndef handle_request(*items, wait_for_reply=True):\n\nSizeStruct = struct.Struct(\"!I\") data = pickle.dumps(items, 3)\n\ntry:\n\nwith SocketManager(tuple(Address)) as sock:\n\nsock.sendall(SizeStruct.pack(len(data))) sock.sendall(data) if not wait_for_reply:\n\nreturn\n\nsize_data = sock.recv(SizeStruct.size) size = SizeStruct.unpack(size_data)[0] result = bytearray() while True:\n\ndata = sock.recv(4000) if not data: break\n\nresult.extend(data) if len(result) >= size:\n\nbreak\n\nreturn pickle.loads(result)\n\nexcept socket.error as err:\n\nprint(\"{0}: is the server running?\".format(err)) sys.exit(1)\n\nThis function provides all the client program’s network handling. It begins by creating a struct.Struct which holds one unsigned integer in network byte",
      "content_length": 1790,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 472,
      "content": "Creating a TCP Client\n\norder, and then it creates a pickle of whatever items it is passed. The function doesnot knowor carewhat theitemsare. Noticethat wehaveexplicitly set the pickle protocol version to 3—this is to ensure that both clients and server use the same pickle version,even if a client or server is upgraded to run a different version of Python.\n\nIf we wanted our protocol to be more future proof, we could version it (just as we do with binary disk formats).Thiscan be doneeither at thenetwork level or at the data level. At the network level we can version by passing two unsigned integers instead of one, that is, length and a protocol version number. At the data level we could follow the convention that the pickle is always a list (or always a dictionary) whose ﬁrst item (or “version” item) has a version number. (You will get the chance to version the protocol in the exercises.)\n\nThe SocketManager is a custom context manager that gives us a socket to use—we will review it shortly. The socket.socket.sendall() method sends all the data it is given—making multiple socket.socket.send() calls behind the scenes if necessary. We always send two items of data: the length of the pick- le and the pickle itself. If the wait_for_reply argument is False we don’t wait for a reply and return immediately—the context manager will ensure that the socket is closed before the function actually returns.\n\nAfter sending the data (and when we want a reply), we call the sock- et.socket.recv() method to get the reply. This method blocks until it receives data. For the ﬁrst call we request four bytes—thesize of the integer that holds the size of the reply pickle to follow. We use the struct.Struct to unpack the bytes into the size integer. We then create an empty bytearray and try to re- trieve the incoming pickle in blocks of up to 4000 bytes. Once we have read in size bytes (or if the data has run out before then), we break out of the loop and unpicklethedata using the pickle.loads() function(which takesa bytes or bytearray object),and return it. In this case we know that the data will always be a tuple since that is the protocol we have established with the car registra- tion server,but the handle_request() function doesnot know or care about what the data is.\n\nIf something goes wrong with the network connection,for example, the server isn’t running or the connection fails for some reason, a socket.error exception is raised. In such cases the exception is caught and the client program issues an error message and terminates.\n\nclass SocketManager:\n\ndef __init__(self, address):\n\nself.address = address\n\ndef __enter__(self):\n\nself.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) self.sock.connect(self.address)\n\n463",
      "content_length": 2751,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 473,
      "content": "464\n\nChapter 11. Networking\n\nreturn self.sock\n\ndef __exit__(self, *ignore):\n\nself.sock.close()\n\nThe address object is a 2-tuple (IP address, port number) and is set when the context manager is created. Once the context manager is used in a with state- ment it creates a socket and tries to make a connection—blocking until a con- nection is established or until a socket exception is raised. The ﬁrst argument to the socket.socket() initializer is the addressfamily;here we have used sock- et.AF_INET (IPv4),but othersare available,for example,socket.AF_INET6 (IPv6), socket.AF_UNIX,and socket.AF_NETLINK.The second argument isnormally either socket.SOCK_STREAM (TCP) as we have used here, or socket.SOCK_DGRAM (UDP).\n\nWhen the ﬂow of control leaves the with statement’s scope the context ob- ject’s __exit__() method is called. We don’t care whether an exception was raised or not (so we ignore the exception arguments), and just close the sock- et. Since the method returns None (in a Boolean context, False), any exceptions are propagated—this works well since we put a suitable except block in han- dle_request() to process any socket exceptions that occur.\n\nCreating a TCP Server\n\n|||\n\nSince the code for creating servers often follows the same design, rather than having to use the low-level socket module, we can use the high-level socket- server module which takes care of all the housekeeping for us. All we have to do is provide a request handler class with a handle() method which is used to read requests and write replies. The socketserver module handles the commu- nications for us, servicing each connection request, either serially or by pass- ing each request to its own separate thread or process—and it does all of this transparently so that we are insulated from the low-level details. For this application the server is car_registration_server.py.★ This program contains a very simple Car class that holds seats, mileage, and owner informa- tion as properties (the ﬁrst one read-only). The class does not hold car licenses because the cars are stored in a dictionary and the licenses are used for the dictionary’s keys.\n\nWe will begin by looking at the main() function, then brieﬂy review how the server’s data is loaded, then the creation of the custom server class, and ﬁnal- ly the implementation of the request handler class that handles the client requests.\n\n★The ﬁrst time the server is run on Windows a ﬁrewall dialog might pop up saying that Python is blocked—click Unblock to allow the server to operate.",
      "content_length": 2534,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 474,
      "content": "Creating a TCP Server\n\ndef main():\n\nfilename = os.path.join(os.path.dirname(__file__),\n\n\"car_registrations.dat\")\n\ncars = load(filename) print(\"Loaded {0} car registrations\".format(len(cars))) RequestHandler.Cars = cars server = None try:\n\nserver = CarRegistrationServer((\"\", 9653), RequestHandler) server.serve_forever()\n\nexcept Exception as err:\n\nprint(\"ERROR\", err)\n\nfinally:\n\nif server is not None:\n\nserver.shutdown() save(filename, cars) print(\"Saved {0} car registrations\".format(len(cars)))\n\nWe have stored the car registration data in the same directory as the program. The cars object is set to a dictionary whose keys are license strings and whose values are Car objects. Normally servers do not print anything since they are typically started and stopped automatically and run in the background, so usually they report on their status by writing logs (e.g., using the logging module).Here we have chosen to print a message at start-up and shutdown to make testing and experimenting easier.\n\nOur request handler class needs to be able to access the cars dictionary, but we cannot pass the dictionary to an instance because the server creates the instances for us—one to handle each request. So we set the dictionary to the RequestHandler.Cars class variable where it is accessible to all instances.\n\nWe create an instance of the server passing it the address and port it should operate on and the RequestHandler class object—not an instance. An empty string as the address indicates any accessible IPv4 address (including the current machine, localhost). Then we tell the server to serve requests forever. When the server shutsdown (we will see how thishappensfurther on),we save the cars dictionary since the data may have been changed by clients.\n\ndef load(filename):\n\ntry:\n\nwith contextlib.closing(gzip.open(filename, \"rb\")) as fh:\n\nreturn pickle.load(fh)\n\nexcept (EnvironmentError, pickle.UnpicklingError) as err: print(\"server cannot load data: {0}\".format(err)) sys.exit(1)\n\n465",
      "content_length": 1993,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 475,
      "content": "Multiple inheri- tance 388➤\n\n466\n\nChapter 11. Networking\n\nThe code for loading is easy because we have used a context manager from the standard library’s contextlib module to ensure that the ﬁle is closed irrespec- tive of whether an exception occurs. Another way of achieving the same effect is to use a custom context manager. For example:\n\nclass GzipManager:\n\ndef __init__(self, filename, mode):\n\nself.filename = filename self.mode = mode\n\ndef __enter__(self):\n\nself.fh = gzip.open(self.filename, self.mode) return self.fh\n\ndef __exit__(self, *ignore):\n\nself.fh.close()\n\nUsing the custom GzipManager, the with statement becomes:\n\nwith GzipManager(filename, \"rb\") as fh:\n\nThis context manager will work with any Python 3.x version. But if we only care about Python 3.1 or later, we can simply write, with gzip.open(...) as fh, since from Python 3.1 the gzip.open() function supports the context manager protocol.\n\nThe save() function (not shown)isstructurally the same asthe load() function, only we open the ﬁle in write binary mode, use pickle.dump() to save the data, and don’t return anything.\n\nclass CarRegistrationServer(socketserver.ThreadingMixIn, socketserver.TCPServer): pass\n\nThis is the complete custom server class. If we wanted to create a server that used processes rather than threads, the only change would be to inherit the socketserver.ForkingMixIn class instead of the socketserver.ThreadingMixIn class. The term mixin is often used to describe classes that are speciﬁcally designed to be multiply-inherited. The socketserver module’s classes can be used to create a variety of custom servers including UDP servers and Unix TCP and UDP servers, by inheriting the appropriate pair of base classes.\n\nNote that the socketserver mixin class we used must always be inherited ﬁrst. This is to ensure that the mixin class’s methods are used in preference to the second class’s methods for those methods that are provided by both, since Python looks for methods in the base classes in the order in which the base classes are speciﬁed, and uses the ﬁrst suitable method it ﬁnds.\n\n3.1",
      "content_length": 2096,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 476,
      "content": "GIL 449➤\n\nCreating a TCP Server\n\nThe socket server creates a request handler (using the class it was given) to handle each request. Our custom RequestHandler class provides a method for each kind of request it can handle, plus the handle() method that it must have since that is the only method used by the socket server. But before look- ing at the methods we will look at the class declaration and the class’s class variables.\n\nclass RequestHandler(socketserver.StreamRequestHandler):\n\nCarsLock = threading.Lock() CallLock = threading.Lock() Call = dict(\n\nGET_CAR_DETAILS=(\n\nlambda self, *args: self.get_car_details(*args)),\n\nCHANGE_MILEAGE=(\n\nlambda self, *args: self.change_mileage(*args)),\n\nCHANGE_OWNER=(\n\nlambda self, *args: self.change_owner(*args)),\n\nNEW_REGISTRATION=(\n\nlambda self, *args: self.new_registration(*args)),\n\nSHUTDOWN=lambda self, *args: self.shutdown(*args))\n\nWe have created a socketserver.StreamRequestHandler subclass since we are using a streaming (TCP) server. A corresponding socketserver.Datagram- RequestHandler is available for UDP servers, or we could inherit the socket- server.BaseRequestHandler class for lower-level access.\n\nThe RequestHandler.Cars dictionary is a class variable that was added in the main() function;it holds all the registration data. Adding additional attributes to objects (such as classes and instances) can be done outside the class (in this case in the main() function) without formality (as long as the object has a __dict__), and can be very convenient. Since we know that the class depends on this variable some programmers would have added Cars = None as a class variable to document the variable’s existence.\n\nAlmost every request-handling method needs access to the Cars data, but we mustensurethat thedata isnever accessedby twomethods(fromtwodifferent threads) at the same time; if it is, the dictionary may become corrupted, or the program might crash. To avoid this we have a lock class variable that we will use to ensure that only one thread at a time accesses the Cars dictionary.★ (Threading, including the use of locks, is covered in Chapter 10.)\n\nThe Call dictionary is another class variable. Each key is the name of an action that the server can perform and each value is a function for performing the action. We cannot use the methods directly as we did with the functions\n\n★The GIL (Global Interpreter Lock) ensures that accesses to the Cars dictionary are synchronized, but as noted earlier, we do not take advantage of this since it is a CPython implementation detail.\n\n467",
      "content_length": 2557,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 477,
      "content": "GIL 449➤\n\n468\n\nChapter 11. Networking\n\nin the client’s menu dictionary because there is no self available at the class level. The solution we have used is to provide wrapper functions that will get self when they are called, and which in turn call the appropriate method with the given self and any other arguments. An alternative solution would be to create the Call dictionary after all the methods. That would allow us to create entries such as GET_CAR_DETAILS=get_car_details, with Python able to ﬁnd the get_car_details() method because the dictionary is created after the method is deﬁned. We have used the ﬁrst approach since it is more explicit and does not impose an order dependency on where the dictionary is created.\n\nAlthough the Call dictionary is only ever read after the classis created,since it is mutable we have played it extra-safe and created a lock for it to ensure that no two threads access it at the same time. (Again, because of the GIL, the lock isn’t really needed for CPython.)\n\ndef handle(self):\n\nSizeStruct = struct.Struct(\"!I\") size_data = self.rfile.read(SizeStruct.size) size = SizeStruct.unpack(size_data)[0] data = pickle.loads(self.rfile.read(size))\n\ntry:\n\nwith self.CallLock:\n\nfunction = self.Call[data[0]] reply = function(self, *data[1:])\n\nexcept Finish: return\n\ndata = pickle.dumps(reply, 3) self.wfile.write(SizeStruct.pack(len(data))) self.wfile.write(data)\n\nWhenever a client makes a request a new thread is created with a new instance of the RequestHandler class,and then the instance’shandle() method is called. Insidethismethod thedata coming fromtheclient can be read fromthe self.rfile ﬁle object, and data can be sent back to the client by writing to the self.wfile object—both of these objects are provided by socketserver, opened and ready for use.\n\nThe struct.Struct isfor the integer bytecount that we need for the“length plus pickle” format we are using to exchange data between clients and the server.\n\nWe begin by reading four bytes and unpacking this as the size integer so that we know the size of the pickle we have been sent. Then we read size bytesand unpickle them into the data variable. The read will block until the data isread. In this case we know that data will always be a tuple, with the ﬁrst item being the requested action and the other itemsbeing the parameters,because that is the protocol we have established with the car registration clients.",
      "content_length": 2419,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 478,
      "content": "Creating a TCP Server\n\nInside the try block we get the lambda function that is appropriate to the re- quested action. We use a lock to protect access to the Call dictionary,although arguably we are being overly cautious. As always, we do as little as possible within the scope of the lock—in this case we just do a dictionary lookup to get a reference to a function. Once we have the function we call it, passing self as the ﬁrst argument and the rest of the data tuple as the other arguments. Here we are doing a function call, so no self is passed by Python. This does not matter since we pass self in ourselves, and inside the lambda the passed-in self is used to call the method in the normal way. The outcome is that the call, self.method(*data[1:]), is made, where method is the method corresponding to the action given in data[0].\n\nIf the action is to shut down, a custom Finish exception is raised in the shutdown() method;in which casewe know that theclient cannot expect a reply, so we just return. But for any other action we pickle the result of calling the action’s corresponding method (using pickle protocol version 3), and write the size of the pickle and then the pickled data itself.\n\ndef get_car_details(self, license):\n\nwith self.CarsLock:\n\ncar = copy.copy(self.Cars.get(license, None))\n\nif car is not None:\n\nreturn (True, car.seats, car.mileage, car.owner)\n\nreturn (False, \"This license is not registered\")\n\nThis method begins by trying to acquire the car data lock—and blocks until it gets the lock. It then uses the dict.get() method with a second argument of None to get the car with thegiven license—or to get None.The car isimmediately copied and the with statement is ﬁnished. This ensures that the lock is in force for the shortest possible time. Although reading does not change the data being read,because we are dealing with a mutable collection it is possible that another method in another thread wants to change the dictionary at the same timeaswewanttoreadit—using a lock preventsthisfromhappening. Outside the scope of the lock we now have a copy of the car object (or None) which we can deal with at our leisure without blocking any other threads.\n\nLike all the car registration action-handling methods,we return a tuple whose ﬁrst item isa Boolean success/failureﬂag and whose other itemsvary. None of these methods has to worry or even know how its data is returned to the client beyond the “tuple with a Boolean ﬁrst item” since all the network interaction is encapsulated in the handle() method.\n\ndef change_mileage(self, license, mileage):\n\nif mileage < 0:\n\nreturn (False, \"Cannot set a negative mileage\")\n\nwith self.CarsLock:\n\ncar = self.Cars.get(license, None)\n\n469",
      "content_length": 2709,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 479,
      "content": "470\n\nChapter 11. Networking\n\nif car is not None:\n\nif car.mileage < mileage: car.mileage = mileage return (True, None)\n\nreturn (False, \"Cannot wind the odometer back\")\n\nreturn (False, \"This license is not registered\")\n\nIn this method we can do one check without acquiring a lock at all. But if the mileage is non-negative we must acquire a lock and get the relevant car,and if we have a car (i.e., if the license is valid), we must stay within the scope of the lock to change the mileage as requested—or to return an error tuple. If no car has the given license (car is None),we drop out of the with statement and return an error tuple.\n\nIt would seem that if we did the validation in the client we could avoid some network trafﬁc entirely,for example,the client could give an error message (or simply prevent)negative mileages. Even though the client ought to do this,we must still have the check in the server since we cannot assume that the client is bug-free. And although the client gets the car’s mileage to use as the default mileage we cannot assume that the mileage entered by the user (even if it is greater than the current mileage) is valid, because some other client could have increased the mileage in the meantime. So we can only do the deﬁnitive validation at the server, and only within the scope of a lock.\n\nThe change_owner() method is very similar, so we won’t reproduce it here.\n\ndef new_registration(self, license, seats, mileage, owner):\n\nif not license:\n\nreturn (False, \"Cannot set an empty license\")\n\nif seats not in {2, 4, 5, 6, 7, 8, 9}:\n\nreturn (False, \"Cannot register car with invalid seats\")\n\nif mileage < 0:\n\nreturn (False, \"Cannot set a negative mileage\")\n\nif not owner:\n\nreturn (False, \"Cannot set an empty owner\")\n\nwith self.CarsLock:\n\nif license not in self.Cars:\n\nself.Cars[license] = Car(seats, mileage, owner) return (True, None)\n\nreturn (False, \"Cannot register duplicate license\")\n\nAgain we are able to do a lot of error checking before accessing the registration data, but if all the data is valid we acquire a lock. If the license is not in the RequestHandler.Cars dictionary (and it shouldn’t be since a new registration should have an unused license), we create a new Car object and store it in the dictionary. This must all be done within the scope of the same lock because we must not allow any other client to add a car with this license in the time be-",
      "content_length": 2400,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 480,
      "content": "Creating a TCP Server\n\ntweenthecheck forthelicense’sexistenceinthe RequestHandler.Cars dictionary and adding the new car to the dictionary.\n\ndef shutdown(self, *ignore):\n\nself.server.shutdown() raise Finish()\n\nIf the action is to shut down we call the server’s shutdown() method—this will stop it from accepting any further requests, although it will continue running while it is still servicing any existing requests. We then raise a custom excep- tion to notify the handler() that we are ﬁnished—this causes the handler() to return without sending any reply to the client.\n\nSummary\n\nThis chapter showed that creating network clients and servers can be quite straightforward in Python thanks to the standard library’s networking mod- ules, and the struct and pickle modules.\n\nIn the ﬁrst section we developed a client program and gave it a single function, handle_request(), to send and receive arbitrary picklable data to and from a server using a generic data format of “length pluspickle”.In thesecondsection we saw how to create a server subclass using the classes from the socketserver module and how to implement a request handler class to service the server’s client requests. Here the heart of the network interaction was conﬁned to a single method, handle(), that can receive and send arbitrary picklable data from and to clients.\n\nThe socket and socketserver modules and many other modules in the standard library,such as asyncore, asynchat, and ssl, provide far more functionality than we have used here. But if the networking facilities provided by the standard library are not sufﬁcient, or are not high-level enough, it is worth looking at the third-party Twisted networking framework (www.twistedmatrix.com) as a possible alternative.\n\nExercises\n\nThe exercisesinvolve modifying the client and server programscovered in this chapter. The modiﬁcations don’t involve a lot of typing, but will need a little bit of care to get right.\n\n1. Copy car_registration_server.py and car_registration.py and modify them sothat they exchangedata using a protocolversionedat thenetwork level. Thiscouldbedone,forexample,by passing twointegersinthestruct (length, protocol version) instead of one.\n\n471\n\n|||\n\n|||",
      "content_length": 2211,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 481,
      "content": "472\n\nChapter 11. Networking\n\nThis involves adding or modifying about ten lines in the client program’s handle_request() function, and adding or modifying about sixteen lines in the server program’s handle() method—including code to handle the case where the protocol version read does not match the one expected.\n\nSolutions to this and to the following exercises are provided in car_reg- istration_ans.py and car_registration_server_ans.py.\n\n2. Copy the car_registration_server.py program (or use the one developed in Exercise 1), and modify it so that it offers a new action, GET_LICENSES_ STARTING_WITH. The action should accept a single parameter, a string. The method implementing the action should always return a 2-tuple of (True, list of licenses); there is no error (False) case, since no matches is not an error and simply results in True and an empty list being returned. Retrieve the licenses (the RequestHandler.Cars dictionary’s keys) within the scope of a lock, but do all the other work outside the lock to minimize blocking. One efﬁcient way to ﬁnd matching licenses is to sort the keys and then use the bisect module to ﬁnd the ﬁrst matching license and then iterate from there. Another possible approach is to iterate over the licenses, picking out those that start with the given string, perhaps using a list comprehension.\n\nApart from the additional import, the Call dictionary will need an ex- tra couple of lines for the action. The method to implement the ac- tion can be done in fewer than ten lines. This is not difﬁcult, although care is required. A solution that uses the bisect module is provided in car_registration_server _ans.py.\n\n3. Copy the car_registration.py program (or use the one developed in exer- cise 1), and modify it to take advantage of the new server (car_registra- tion_server_ans.py). This means changing the retrieve_car_details() function so that if the user enters an invalid license they get prompted to enter the start of a license and then get a list to choose from. Here is a sampleof interactionusing thenew function (with theserver already run- ning, with the menu edited slightly to ﬁt on the page, and with what the user types shown in bold): (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: License: da 4020 License: DA 4020 Seats: 2 Mileage: 97181 Owner: Jonathan Lynn (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: License [DA 4020]: z This license is not registered Start of license: z",
      "content_length": 2471,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 482,
      "content": "Exercises\n\nNo licence starts with Z Start of license: a (1) A04 4HE (2) A37 4791 (3) ABK3035 Enter choice (0 to cancel): 3 License: ABK3035 Seats: 5 Mileage: 17719 Owner: Anthony Jay\n\nThe changeinvolvesdeleting oneline and adding about twenty morelines. It is slightly tricky because the user must be allowed to get out or to go on at each stage. Make sure that you test the new functionality for all cases (no license starts with the given string, one licence starts with it, and two or more start with it). A solution is provided in car_registration_ans.py.\n\n473",
      "content_length": 564,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 483,
      "content": "12 ● DBM Databases\n\nSQL Databases\n\nDatabase Programming\n\nFor most software developers the term database is usually taken to mean an RDBMS(RelationalDatabaseManagementSystem).Thesesystemsusetables (spreadsheet-like grids) with rows equating to records and columns equating to ﬁelds. The tablesand the data they hold are created and manipulated using statements written in SQL (Structured Query Language).Python provides an API (Application Programming Interface) for working with SQL databases and it is normally distributed with the SQLite 3 database as standard.\n\nAnother kind of database is a DBM (Database Manager) that stores any number of key–value items. Python’s standard library comes with interfaces to several DBMs, including some that are Unix-speciﬁc. DBMs work just like Python dictionaries except that they are normally held on disk rather than in memory and their keysand values are always bytes objectsand may be subject to length constraints. The shelve module covered in this chapter’s ﬁrst section providesa convenient DBM interface that allows us to use string keys and any (picklable) objects as values.\n\nIf the available DBMs and the SQLite database are insufﬁcient, the Python Package Index, pypi.python.org/pypi, has a large number of database-related packages, including the bsddb DBM (“Berkeley DB”), and interfaces to popu- lar client/server databases such as DB2,Informix,Ingres,MySQL,ODBC,and PostgreSQL.\n\nUsing SQL databases requires knowledge of the SQL language and the ma- nipulation of strings of SQL statements. This is ﬁne for those experienced with SQL,but is not very Pythonic. There is another way to interact with SQL databases—use an ORM (Object Relational Mapper).Two of the most popular ORMsfor Pythonareavailableasthird-party libraries—they areSQLAlchemy (www.sqlalchemy.org) and SQLObject (www.sqlobject.org). One particularly nice feature of using an ORM is that it allows us to use Python syntax—creating objects and calling methods—rather than using raw SQL.\n\n475\n\n||||",
      "content_length": 2017,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 484,
      "content": "bytes 293➤\n\n476\n\nChapter 12. Database Programming\n\nIn this chapter we will implement two versions of a program that maintains a list of DVDs, and keeps track of each DVD’s title, year of release, length in minutes, and director. The ﬁrst version uses a DBM (via the shelve module) to store its data, and the second version uses the SQLite database. Both programs can also load and save a simple XML format, making it possible, for example, to export DVD data from one program and import it into the other. The SQL-based version offers slightly more functionality than the DBM one, and has a slightly cleaner data design.\n\nDBM Databases\n\nThe shelve moduleprovidesa wrapper arounda DBMthatallowsustointeract with the DBM as though it were a dictionary,providing that we use only string keys and picklable values. Behind the scenes the shelve module converts the keys and values to and from bytes objects.\n\nThe shelve module uses the best underlying DBM available, so it is possible thata DBMﬁlesavedon onemachinewon’tbereadableon another,if theother machine doesn’t have the same DBM. One solution is to provide XML import and export for ﬁles that must be transportable between machines—something we’ve done for this section’s DVD program, dvds-dbm.py.\n\nFor the keys we use the DVDs’ titles and for the values we use tuples holding the director, year, and duration. Thanks to the shelve module we don’t have to do any data conversion and can just treat the DBM object as a dictionary.\n\nSince the structure of the program is similar to interactive menu-driven programsthat we have seen before,we will focus just on those aspects that are speciﬁc to DBM programming. Here is an extract from the program’s main() function, with the menu handling omitted:\n\ndb = None try:\n\ndb = shelve.open(filename, protocol=pickle.HIGHEST_PROTOCOL)\n\n... finally:\n\nif db is not None: db.close()\n\nHere we have opened (or created if it does not exist) the speciﬁed DBM ﬁle for both reading and writing. Each item’s value is saved as a pickle using the speciﬁed pickle protocol; existing items can be read even if they were saved using a lower protocolsincePythoncan ﬁgureout thecorrectprotocoltousefor reading pickles. At the end the DBM is closed—this has the effect of clearing the DBM’s internal cache and ensuring that the disk ﬁle reﬂects any changes that have been made, as well as closing the ﬁle.\n\n|||",
      "content_length": 2385,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 485,
      "content": "DBM Databases\n\nThe program offers options to add, edit, list, remove, import, and export DVD data. We will skip importing and exporting the data from and to XML format since it is very similar to what we have done in Chapter 7. And apart from adding, we will omit most of the user interface code, again because we have seen it before in other contexts.\n\ndef add_dvd(db):\n\ntitle = Console.get_string(\"Title\", \"title\") if not title: return\n\ndirector = Console.get_string(\"Director\", \"director\") if not director:\n\nreturn\n\nyear = Console.get_integer(\"Year\", \"year\", minimum=1896,\n\nmaximum=datetime.date.today().year)\n\nduration = Console.get_integer(\"Duration (minutes)\", \"minutes\",\n\nminimum=0, maximum=60*48)\n\ndb[title] = (director, year, duration) db.sync()\n\nThisfunction,like all the functionscalled by the program’smenu,is passed the DBM object (db) as its sole parameter. Most of the function is concerned with getting the DVD’s details, and in the penultimate line we store the key–value item in the DBM ﬁle,with the DVD’stitle as the key and the director,year,and duration (pickled together by shelve) as the value.\n\nIn keeping with Python’s usual consistency, DBMs provide the same API as dictionaries,sowedon’thavetolearnany new syntax beyondthe shelve.open() function that we saw earlier and the shelve.Shelf.sync() method that is used to clear the shelve’sinternal cache and synchronize the disk ﬁle’sdata with the changes that have been applied—in this case just adding a new item.\n\ndef edit_dvd(db):\n\nold_title = find_dvd(db, \"edit\") if old_title is None:\n\nreturn\n\ntitle = Console.get_string(\"Title\", \"title\", old_title) if not title: return\n\ndirector, year, duration = db[old_title]\n\n...\n\ndb[title] = (director, year, duration) if title != old_title:\n\ndel db[old_title]\n\ndb.sync()\n\n477",
      "content_length": 1794,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 486,
      "content": "478\n\nChapter 12. Database Programming\n\nTo be able to edit a DVD, the user must ﬁrst choose the DVD to work on. This is just a matter of getting the title since titles are used as keys with the values holding the other data. Since the necessary functionality is needed elsewhere (e.g.,when removing a DVD),we have factoredit out into a separate find_dvd() function that we will look at next. If the DVD is found we get the user’s changes,using the existing values as defaults to speed up the interaction. (We have omitted most of the user interface code for this function since it is almost the same as that used when adding a DVD.) At the end we store the data just as we did when adding. If the title is unchanged this will have the effect of overwriting the associated value, and if the title is different this has the effect of creating a new key–value item, in which case we delete the original item.\n\ndef find_dvd(db, message):\n\nmessage = \"(Start of) title to \" + message while True:\n\nmatches = [] start = Console.get_string(message, \"title\") if not start:\n\nreturn None\n\nfor title in db:\n\nif title.lower().startswith(start.lower()):\n\nmatches.append(title)\n\nif len(matches) == 0:\n\nprint(\"There are no dvds starting with\", start) continue\n\nelif len(matches) == 1:\n\nreturn matches[0]\n\nelif len(matches) > DISPLAY_LIMIT:\n\nprint(\"Too many dvds start with {0}; try entering \"\n\n\"more of the title\".format(start))\n\ncontinue\n\nelse:\n\nmatches = sorted(matches, key=str.lower) for i, match in enumerate(matches):\n\nprint(\"{0}: {1}\".format(i + 1, match))\n\nwhich = Console.get_integer(\"Number (or 0 to cancel)\",\n\n\"number\", minimum=1, maximum=len(matches))\n\nreturn matches[which - 1] if which != 0 else None\n\nTo make ﬁnding a DVD as quick and easy as possible we require the user to type in only one or the ﬁrst few characters of its title. Once we have the start of the title we iterate over the DBM and create a list of matches. If there is one match we return it, and if there are several matches (but fewer than DISPLAY_LIMIT, an integer set elsewhere in the program) we display them all in case-insensitive order with a number beside each one so that the user",
      "content_length": 2153,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 487,
      "content": "DBM Databases\n\ncan choose the title just by entering its number. (The Console.get_integer() function accepts 0 even if the minimum is greater than zero so that 0 can be used as a cancelation value. This behavior can be switched off by passing al- low_zero=False.We can’t use Enter, that is, nothing, to mean cancel, since enter- ing nothing means accepting the default.)\n\ndef list_dvds(db): start = \"\" if len(db) > DISPLAY_LIMIT:\n\nstart = Console.get_string(\"List those starting with \"\n\n\"[Enter=all]\", \"start\")\n\nprint() for title in sorted(db, key=str.lower):\n\nif not start or title.lower().startswith(start.lower()):\n\ndirector, year, duration = db[title] print(\"{title} ({year}) {duration} minute{0}, by \"\n\n\"{director}\".format(Util.s(duration), **locals()))\n\nListing all the DVDs (or those whose title starts with a particular substring)is simply a matter of iterating over the DBM’s items.\n\nThe Util.s() function is simply s = lambda x: \"\" if x == 1 else \"s\"; so here it returns an “s” if the duration is not one minute.\n\ndef remove_dvd(db):\n\ntitle = find_dvd(db, \"remove\") if title is None:\n\nreturn\n\nans = Console.get_bool(\"Remove {0}?\".format(title), \"no\") if ans:\n\ndel db[title] db.sync()\n\nRemoving a DVD is a matter of ﬁnding the one the user wants to remove, asking for conﬁrmation, and if we get it, deleting the item from the DBM.\n\nWe have now seen how to open (or create) a DBM ﬁle using the shelve mod- ule, and how to add items to it, edit its items, iterate over its items, and re- move items.\n\nUnfortunately,there is a ﬂaw in our data design. Director names are duplicat- ed, and this could easily lead to inconsistencies; for example, director Danny DeVito might be entered as“Danny De Vito” for one movie and “Danny deVito” for another. One solution would be to have two DBM ﬁles, the main DVD ﬁle with title keys and (year, duration, director ID) values, and a director ﬁle with director ID (i.e., integer) keys and director name values. We avoid this ﬂaw in the next section’s SQL database version of the program by using two tables, one for DVDs and another for directors.\n\n479",
      "content_length": 2096,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 488,
      "content": "480\n\nChapter 12. Database Programming\n\nSQL Databases\n\nInterfaces to most popular SQL databases are available from third-party modules, and out of the box Python comes with the sqlite3 module (and with the SQLite 3 database), so database programming can be started right away. SQLite is a lightweight SQL database, lacking many of the features of, say, PostgreSQL,but it isvery convenient for prototyping,and may provesufﬁcient in many cases.\n\nTo make it as easy as possible to switch between database backends, PEP 249 (Python Database API Speciﬁcation v2.0) provides an API speciﬁcation called DB-API 2.0 that database interfaces ought to honor—the sqlite3 module, for example, complies with the speciﬁcation, but not all the third-party modules do. There are two major objectsspeciﬁed by the API,the connection object and the cursor object,and theAPIsthey must supportareshown in Tables12.1and 12.2. In the case of the sqlite3 module, its connection and cursor objects both provide many additional attributes and methods beyond those required by the DB-API 2.0 speciﬁcation.\n\nThe SQL version of the DVDs program is dvds-sql.py. The program stores di- rectors separately from the DVD data to avoid duplication and offers one more menu option that lets the user list the directors. The two tables are shown in Figure 12.1. The program has slightly fewer than 300 lines, whereas the pre- vious section’s dvds-dbm.py program is slightly fewer than 200 lines, with most of the difference due to the fact that we must use SQL queries rather than perform simple dictionary-like operations, and because we must create the database’s tables the ﬁrst time the program runs.\n\ndvds\n\ndirectors\n\nid title year duration director_id\n\nid name\n\nFigure 12.1 The DVD program’s database design\n\nThe main() function is similar to before, only this time we call a custom connect() function to make the connection.\n\ndef connect(filename):\n\ncreate = not os.path.exists(filename) db = sqlite3.connect(filename) if create:\n\ncursor = db.cursor()\n\n|||",
      "content_length": 2024,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 489,
      "content": "SQL Databases\n\nTable 12.1 DB-API 2.0 Connection Object Methods\n\nSyntax\n\nDescription\n\ndb.close()\n\nClosestheconnectiontothedatabase(representedby the db object which is obtained by calling a connect() function)\n\ndb.commit()\n\nCommits any pending transaction to the database; does nothing for databases that don’t support transactions\n\ndb.cursor()\n\nReturnsa databasecursor object through which queriescan be executed\n\ndb.rollback() Rolls back any pending transaction to the state that existed\n\nbefore the transaction began; does nothing for databases that don’t support transactions\n\ncursor.execute(\"CREATE TABLE directors (\"\n\n\"id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL, \" \"name TEXT UNIQUE NOT NULL)\") cursor.execute(\"CREATE TABLE dvds (\"\n\n\"id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL, \" \"title TEXT NOT NULL, \" \"year INTEGER NOT NULL, \" \"duration INTEGER NOT NULL, \" \"director_id INTEGER NOT NULL, \" \"FOREIGN KEY (director_id) REFERENCES directors)\")\n\ndb.commit()\n\nreturn db\n\nThe sqlite3.connect() function returns a database object, having opened the database ﬁle it is given and created an empty database ﬁle if the ﬁle did not exist. In view of this, prior to calling sqlite3.connect(), we note whether the databaseisgoing to be created from scratch,becauseif it is,we must createthe tables that the program relies on. All queries are executed through a database cursor, available from the database object’s cursor() method.\n\nNotice that both tables are created with an ID ﬁeld that has an AUTOINCREMENT constraint—this means that SQLite will automatically populate the IDs with unique numbers, so we can leave these ﬁelds to SQLite when inserting new records.\n\nSQLite supports a limited range of data types—essentially just Booleans, numbers, and strings—but this can be extended using data “adaptors”, either the predeﬁned ones such as those for dates and datetimes,or custom ones that we can use to represent any data types we like. The DVDs program does not need this functionality, but if it were required, the sqlite3 module’s documen- tation explains the details. The foreign key syntax we have used may not be the same as the syntax for other databases, and in any case it is merely doc-\n\n481",
      "content_length": 2221,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 490,
      "content": "482\n\nChapter 12. Database Programming\n\nTable 12.2 DB-API 2.0 Cursor Object Attributes and Methods\n\nSyntax\n\nDescription\n\nc.arraysize\n\nThe (readable/writable) number of rows that fetch- many() will return if no size is speciﬁed\n\nc.close()\n\nCloses the cursor, c; this is done automatically when the cursor goes out of scope\n\nc.description\n\nA read-only sequence of 7-tuples (name, type_code, display_size, internal_size, precision, scale, null_ok), describing each successive column of cursor c\n\nc.execute(sql, params)\n\nExecutes the SQL query in string sql, replacing each placeholder with the corresponding parameter from the params sequence or mapping if given\n\nc.executemany(\n\nsql, seq_of_params)\n\nc.fetchall()\n\nc.fetchmany(size)\n\nExecutes the SQL query once for each item in the seq_of_params sequence of sequencesor mappings;this method should not be used for operations that create result sets (such as SELECT statements) Returns a sequence of all the rows that have not yet been fetched (which could be all of them) Returns a sequence of rows (each row itself being a sequence); size defaults to c.arraysize\n\nc.fetchone()\n\nReturns the next row of the query result set as a se- quence,or None whentheresultsareexhausted. Raises an exception if there is no result set.\n\nc.rowcount\n\nThe read-only row count for the last operation (e.g., SELECT, INSERT, UPDATE,or DELETE) or -1if not available or not applicable\n\numenting our intention, since SQLite, unlike many other databases, does not enforce relational integrity. (However, SQLite does have a workaround based on sqlite3’s .genfkey command.) One other sqlite3-speciﬁc quirk is that its default behavior istosupportimplicittransactions,sothereisnoexplicit“start transaction” method.\n\ndef add_dvd(db):\n\ntitle = Console.get_string(\"Title\", \"title\") if not title: return\n\ndirector = Console.get_string(\"Director\", \"director\") if not director:\n\nreturn\n\nyear = Console.get_integer(\"Year\", \"year\", minimum=1896,\n\nmaximum=datetime.date.today().year)",
      "content_length": 1995,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 491,
      "content": "SQL Databases\n\nduration = Console.get_integer(\"Duration (minutes)\", \"minutes\",\n\nminimum=0, maximum=60*48)\n\ndirector_id = get_and_set_director(db, director) cursor = db.cursor() cursor.execute(\"INSERT INTO dvds \"\n\n\"(title, year, duration, director_id) \" \"VALUES (?, ?, ?, ?)\", (title, year, duration, director_id))\n\ndb.commit()\n\nThis function starts with the same code as the equivalent function from the dvds-dbm.py program, but once we have gathered the data, it is quite different. The director the user entered may or may not be in the directors table, so we have a get_and_set_director() function that inserts the director if they are not already in the database, and in either case returns the director’s ID ready for it to be inserted into the dvds table. With all the data available we execute an SQL INSERT statement. We don’t need to specify a record ID since SQLite will automatically provide one for us.\n\nIn the query we have used question marksfor placeholders. Each ? is replaced by the corresponding value in the sequence that follows the string containing the SQL statement. Named placeholders can also be used as we will see when we look at editing a record. Although it is possible to avoid using placeholders and simply format the SQL string with the data embedded into it, we recom- mend always using placeholders and leaving the burden of correctly encoding and escaping the data items to the database module. Another beneﬁt of using placeholders is that they improve security since they prevent arbitrary SQL from being maliciously injected into a query.\n\ndef get_and_set_director(db, director):\n\ndirector_id = get_director_id(db, director) if director_id is not None: return director_id\n\ncursor = db.cursor() cursor.execute(\"INSERT INTO directors (name) VALUES (?)\",\n\n(director,))\n\ndb.commit() return get_director_id(db, director)\n\nThis function returns the ID of the given director, inserting a new direc- tor record if necessary. If a record is inserted we retrieve its ID using the get_director_id() function we tried in the ﬁrst place.\n\ndef get_director_id(db, director):\n\ncursor = db.cursor() cursor.execute(\"SELECT id FROM directors WHERE name=?\",\n\n(director,))\n\n483",
      "content_length": 2194,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 492,
      "content": "484\n\nChapter 12. Database Programming\n\nfields = cursor.fetchone() return fields[0] if fields is not None else None\n\nThe get_director_id() function returns the ID of the given director or None if there is no such director in the database. We use the fetchone() method be- cause there is either zero or one matching record. (We know that there are no duplicate directors because the directors table’s name ﬁeld has a UNIQUE con- straint, and in any case we always check for the existence of a director before adding a new one.) The fetch methods always return a sequence of ﬁelds (or None if there are no more records), even if, as here, we have asked to retrieve only a single ﬁeld.\n\ndef edit_dvd(db):\n\ntitle, identity = find_dvd(db, \"edit\") if title is None:\n\nreturn\n\ntitle = Console.get_string(\"Title\", \"title\", title) if not title: return\n\ncursor = db.cursor() cursor.execute(\"SELECT dvds.year, dvds.duration, directors.name \"\n\n\"FROM dvds, directors \" \"WHERE dvds.director_id = directors.id AND \" \"dvds.id=:id\", dict(id=identity))\n\nyear, duration, director = cursor.fetchone() director = Console.get_string(\"Director\", \"director\", director) if not director:\n\nreturn\n\nyear = Console.get_integer(\"Year\", \"year\", year, 1896, datetime.date.today().year)\n\nduration = Console.get_integer(\"Duration (minutes)\", \"minutes\",\n\nduration, minimum=0, maximum=60*48)\n\ndirector_id = get_and_set_director(db, director) cursor.execute(\"UPDATE dvds SET title=:title, year=:year, \"\n\n\"duration=:duration, director_id=:director_id \" \"WHERE id=:identity\", locals())\n\ndb.commit()\n\nTo edit a DVD record we must ﬁrst ﬁnd the record the user wants to work on. If a record is found we begin by giving the user the opportunity to change the title. Then we retrieve the other ﬁelds so that we can provide the existing values as defaults to minimize what the user must type since they can just press Enter to accept a default. Here we have used named placeholders (of the form :name), and must therefore provide the corresponding values using a mapping. For the SELECT statement we have used a freshly created dictionary, and for the UPDATE statement we have used the dictionary returned by locals().",
      "content_length": 2171,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 493,
      "content": "SQL Databases\n\nWe could use a fresh dictionary for both, in which case for the UPDATE we would pass dict(title=title, year=year, duration=duration, director_id=director_id, id=identity)) instead of locals().\n\nOnce we have all the ﬁelds and the user has entered any changes they want, we retrieve the corresponding director ID (inserting a new director record if necessary), and then update the database with the new data. We have taken the simplistic approach of updating all the record’s ﬁelds rather than only those which have actually been changed.\n\nWhen we used a DBM ﬁle the DVD title was used as the key, so if the title changed, we created a new key–value item and deleted the original. But here every DVD record has a unique ID which is set when the record is ﬁrst inserted, so we are free to change the value of any other ﬁeld with no further work necessary.\n\ndef find_dvd(db, message):\n\nmessage = \"(Start of) title to \" + message cursor = db.cursor() while True:\n\nstart = Console.get_string(message, \"title\") if not start:\n\nreturn (None, None)\n\ncursor.execute(\"SELECT title, id FROM dvds \"\n\n\"WHERE title LIKE ? ORDER BY title\", (start + \"%\",))\n\nrecords = cursor.fetchall() if len(records) == 0:\n\nprint(\"There are no dvds starting with\", start) continue\n\nelif len(records) == 1:\n\nreturn records[0]\n\nelif len(records) > DISPLAY_LIMIT:\n\nprint(\"Too many dvds ({0}) start with {1}; try entering \"\n\n\"more of the title\".format(len(records), start))\n\ncontinue\n\nelse:\n\nfor i, record in enumerate(records):\n\nprint(\"{0}: {1}\".format(i + 1, record[0]))\n\nwhich = Console.get_integer(\"Number (or 0 to cancel)\",\n\n\"number\", minimum=1, maximum=len(records))\n\nreturn records[which - 1] if which != 0 else (None, None)\n\nThis function performsthe same service as the find_dvd() function in the dvds- dbm.py program,and returnsa 2-tuple (title,DVD ID),or (None, None) depending on whether a record was found. Instead of iterating over all the data we have used the SQL wildcard operator (%), so only the relevant records are retrieved.\n\n485",
      "content_length": 2029,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 494,
      "content": "486\n\nChapter 12. Database Programming\n\nAnd sinceweexpect thenumber of matching recordstobesmall,wefetchthem all at once into a sequence of sequences. If there is more than one matching record and few enough to display, we print the records with a number beside each one so that the user can choose the one they want in much the same way as they could in the dvds-dbm.py program.\n\ndef list_dvds(db):\n\ncursor = db.cursor() sql = (\"SELECT dvds.title, dvds.year, dvds.duration, \"\n\n\"directors.name FROM dvds, directors \" \"WHERE dvds.director_id = directors.id\")\n\nstart = None if dvd_count(db) > DISPLAY_LIMIT:\n\nstart = Console.get_string(\"List those starting with \"\n\n\"[Enter=all]\", \"start\")\n\nsql += \" AND dvds.title LIKE ?\"\n\nsql += \" ORDER BY dvds.title\" print() if start is None:\n\ncursor.execute(sql)\n\nelse:\n\ncursor.execute(sql, (start + \"%\",))\n\nfor record in cursor:\n\nprint(\"{0[0]} ({0[1]}) {0[2]} minutes, by {0[3]}\".format(\n\nrecord))\n\nTo list the details of each DVD we do a SELECT query that joins the two tables, adding a second element to the WHERE clauseif thereare morerecords(returned by our dvd_count() function) than the display limit. We then execute the query and iterate over the results. Each record is a sequence whose ﬁelds are those matching the SELECT query.\n\ndef dvd_count(db):\n\ncursor = db.cursor() cursor.execute(\"SELECT COUNT(*) FROM dvds\") return cursor.fetchone()[0]\n\nWe factored these lines out into a separate function because we need them in several different functions.\n\nWe have omitted the code for the list_directors() function since it is struc- turally very similar to the list_dvds() function, only simpler because it lists only one ﬁeld (name).\n\ndef remove_dvd(db):\n\ntitle, identity = find_dvd(db, \"remove\") if title is None:",
      "content_length": 1756,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 495,
      "content": "SQL Databases\n\nreturn\n\nans = Console.get_bool(\"Remove {0}?\".format(title), \"no\") if ans:\n\ncursor = db.cursor() cursor.execute(\"DELETE FROM dvds WHERE id=?\", (identity,)) db.commit()\n\nThis function is called when the user asks to delete a record, and it is very similar to the equivalent function in the dvds-dbm.py program.\n\nWe have now completed our review of the dvds-sql.py program and seen how to create database tables, select records, iterate over the selected records, and insert,update,and delete records. Using the execute() method we can execute any arbitrary SQL statement that the underlying database supports.\n\nSQLite offers much more functionality than we needed here, including an auto-commit mode (and other kinds of transaction control), and the ability to create functions that can be executed inside SQL queries. It is also possible to provide a factory function to control what is returned for each fetched record (e.g., a dictionary or custom type instead of a sequence of ﬁelds).Additionally, it is possible to create in-memory SQLite databases by passing “:memory:” as the ﬁlename.\n\nSummary\n\nBack in Chapter 7 we saw several different ways of saving and loading data from disk, and in this chapter we have seen how to interact with data types that hold their data on disk rather than in memory.\n\nFor DBM ﬁlesthe shelve moduleisvery convenient sinceit storesstring–object items. If we want complete control we can of course use any of the underlying DBMs directly. One nice feature of the shelve module and of the DBMs generally is that they use the dictionary API, making it easy to retrieve, add, edit, and remove items, and to convert programs that use dictionaries to use DBMsinstead. Onesmallinconvenienceof DBMsisthatfor relationaldatawe must use a separate DBM ﬁle for each key–value table, whereas SQLite stores all the data in a single ﬁle.\n\nFor SQL databases, SQLite is useful for prototyping, and in many cases in its own right,and it hasthe advantageof being suppliedwith Python asstandard. We have seen how to obtain a database object using the connect() function and how to execute SQL queries (such as CREATE TABLE, SELECT, INSERT, UPDATE, and DELETE) using the database cursor’s execute() method.\n\nPython offers a complete range of choices for disk-based and in-memory data storage, from binary ﬁles, text ﬁles, XML ﬁles, and pickles, to DBMs and SQL\n\n487\n\n|||",
      "content_length": 2398,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 496,
      "content": "488\n\nChapter 12. Database Programming\n\ndatabases, and this makes it possible to choose exactly the right approach for any given situation.\n\nExercise\n\nWrite an interactive console program to maintain a list of bookmarks. For each bookmark keep two pieces of information: the URL and a name. Here is an example of the program in action:\n\nBookmarks (bookmarks.dbm) (1) Programming in Python 3........ http://www.qtrac.eu/py3book.html (2) PyQt........................... http://www.riverbankcomputing.com (3) Python......................... http://www.python.org (4) Qtrac Ltd...................... http://www.qtrac.eu (5) Scientific Tools for Python.... http://www.scipy.org\n\n(A)dd (E)dit (L)ist (R)emove (Q)uit [l]: e Number of bookmark to edit: 2 URL [http://www.riverbankcomputing.com]: Name [PyQt]: PyQt (Python bindings for GUI library)\n\nThe program should allow the user to add, edit, list, and remove bookmarks. To make identifying a bookmark for editing or removing as easy as possible, list the bookmarkswith numbersand ask the user to specify the number of the bookmark they want to edit or remove. Store the data in a DBM ﬁle using the shelve module and with names as keys and URLs as values. Structurally the program is very similar to dvds-dbm.py, except for the find_bookmark() function which is much simpler than find_dvd() since it only has to get an integer from the user and use that to ﬁnd the corresponding bookmark’s name.\n\nAs a courtesy to users, if no protocol is speciﬁed, prepend the URL the user adds or edits with http://.\n\nThe entire program can be written in fewer than 100 lines (assuming the use of the Console module for Console.get_string() and similar). A solution is provided in bookmarks.py.\n\n|||",
      "content_length": 1729,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 497,
      "content": "13 ● Python’s Regular Expression\n\nLanguage\n\nThe Regular Expression Module\n\nRegular Expressions\n\n||||\n\nA regular expression is a compact notation for representing a collection of strings. What makes regular expressions so powerful is that a single regular expression can represent an unlimited number of strings—providing they meet the regular expression’s requirements. Regular expressions (which we will mostly call “regexes” from now on) are deﬁned using a mini-language that is completely different from Python—but Python includes the re module through which we can seamlessly create and use regexes.★\n\nRegexes are used for ﬁve main purposes:\n\nParsing: identifying and extracting pieces of text that match certain criteria—regexes are used for creating ad hoc parsers and also by tradi- tional parsing tools\n\nSearching: locating substrings that can have more than one form, for example, ﬁnding any of “pet.png”, “pet.jpg”, “pet.jpeg”, or “pet.svg” while avoiding “carpet.png” and similar\n\nSearching and replacing: replacing everywhere the regex matches with a string, for example, ﬁnding “bicycle” or “human powered vehicle” and replacing either with “bike”\n\nSplitting strings: splitting a string at each place the regex matches, for example, splitting everywhere colon-space or equals (“: ” or “=”) occurs\n\nValidation: checking whether a piece of text meets some criteria, for example, contains a currency symbol followed by digits\n\nThe regexes used for searching, splitting, and validation are often fairly small andunderstandable,makingthemidealforthesepurposes. However,although\n\n★A good book on regular expressions is Mastering Regular Expressions by Jeffrey E. F. Friedl, ISBN 0596528124.It does not explicitly cover Python, but Python’s re module offers very similar functionality to the Perl regular expression engine that the book covers in depth.\n\n489",
      "content_length": 1864,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 498,
      "content": "Parsing XML ﬁles 312➤\n\n490\n\nChapter 13. Regular Expressions\n\nregexes are widely and successfully used to create parsers,they do have a lim- itation in that area:They are only able to deal with recursively structured text if the maximum level of recursion is known. Also, large and complex regexes can be difﬁcult to read and maintain. So apart from simple cases, for parsing the best approach is to use a tool designed for the purpose—for example, use a dedicated XML parser for XML. If such a parser isn’t available, then an al- ternative to using regexes is to use a generic parsing tool, an approach that is covered in Chapter 14.\n\nAt its simplest a regular expression is an expression (e.g., a literal character), optionally followed by a quantiﬁer. More complex regexes consist of any number of quantiﬁed expressions and may include assertions and may be inﬂuenced by ﬂags.\n\nThis chapter’s ﬁrst section introduces and explains all the key regular expres- sion concepts and shows pure regular expression syntax—it makes minimal reference to Python itself. Then the second section shows how to use regular expressionsin thecontextof Pythonprogramming,drawing on allthematerial covered in the earlier sections. Readersfamiliar with regular expressionswho just want to learn how they work in Python could skip to the second section (➤ 499).The chapter coversthe completeregex language offered by the re mod- ule, including all the assertions and ﬂags. We indicate regular expressions in the text using bold, show where they match using underlining, and show cap- tures using shading.\n\nPython’s Regular Expression Language\n\nIn this section we look at the regular expression language in four subsections. The ﬁrst subsection shows how to match individual characters or groups of characters,for example,match a,or match b,or match either aor b.The second subsection shows how to quantify matches, for example, match once, or match at least once, or match as many times as possible. The third subsection shows how to group subexpressions and how to capture matching text, and the ﬁnal subsection shows how to use the language’s assertions and ﬂags to affect how regular expressions work.\n\nCharacters and Character Classes\n\nThe simplest expressions are just literal characters, such as a or 5, and if no quantiﬁer is explicitly given it is taken to be “match one occurrence”. For example,the regex tune consistsof four expressions,each implicitly quantiﬁed to match once, so it matches one t followed by one u followed by one n followed by one e, and hence matches the strings tune and attuned.\n\n|||\n\n||",
      "content_length": 2599,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 499,
      "content": "String escapes 66➤\n\nPython’s Regular Expression Language\n\nAlthough most characters can be used as literals, some are “special charac- ters”—these are symbols in the regex language and so must be escaped by pre- ceding themwith a backslash(\\)touse themasliterals. Thespecialcharacters are \\.^$?+*{}[]()|. Most of Python’s standard string escapes can also be used within regexes, for example, \\n for newline and \\t for tab, as well as hexadeci- mal escapes for characters using the \\xHH, \\uHHHH, and \\UHHHHHHHH syntaxes.\n\nIn many cases, rather than matching one particular character we want to match any oneof a set of characters. Thiscan beachievedby using a character class—one or more characters enclosed in square brackets. (This has nothing to do with a Python class, and is simply the regex term for “set of characters”.) A character class is an expression,and like any other expression,if not explic- itly quantiﬁed it matches exactly one character (which can be any of the char- acters in the character class). For example, the regex r[ea]d matches both red and radar, but not read. Similarly, to match a single digit we can use the regex [0123456789]. For convenience we can specify a range of characters using a hy- phen,so the regex [0-9] also matchesa digit. It is possible to negate the mean- ing of a character classby following the opening bracket with a caret,so [^0-9] matches any character that is not a digit.\n\nNote that inside a character class, apart from \\, the special characters lose their special meaning, although in the case of ^ it acquires a new meaning (negation) if it is the ﬁrst character in the character class, and otherwise is simply a literal caret. Also, - signiﬁes a character range unless it is the ﬁrst character, in which case it is a literal hyphen.\n\nSince some sets of characters are required so frequently, several have short- hand forms—theseareshownin Table13.1.With oneexceptiontheshorthands can be used inside character sets,so for example,the regex [\\dA-Fa-f] matches any hexadecimal digit. The exception is . which is a shorthand outside a char- acter class but matches a literal . inside a character class.\n\nQuantiﬁers\n\nA quantiﬁer has the form {m,n} where m and n are the minimum and maximum times the expression the quantiﬁer applies to must match. For example, both e{1,1}e{1,1} and e{2,2} match feel, but neither matches felt.\n\nWriting a quantiﬁer after every expression would soon become tedious, and is certainly difﬁcult to read. Fortunately, the regex language supports several convenientshorthands. If only onenumberisgiveninthequantiﬁerit istaken to be both the minimum and the maximum, so e{2} is the same as e{2,2}. And as we noted in the preceding section, if no quantiﬁer is explicitly given, it is assumed to be one (i.e., {1,1} or {1}); therefore, ee is the same as e{1,1}e{1,1} and e{1}e{1}, so both e{2} and ee match feel but not felt.\n\n491\n\n||",
      "content_length": 2912,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 500,
      "content": "492\n\nChapter 13. Regular Expressions\n\nTable 13.1 Character Class Shorthands\n\nSymbol Meaning\n\n. Matches any character except newline; or any character at all with the re.DOTALL ﬂag; or inside a character class matches a literal .\n\n\\d Matches a Unicode digit; or [0-9] with the re.ASCII ﬂag\n\n\\D Matches a Unicode nondigit; or [^0-9] with the re.ASCII ﬂag\n\n\\s Matches a Unicode whitespace; or [ \\t\\n\\r\\f\\v] with the re.ASCII\n\nﬂag\n\n\\S Matches a Unicode nonwhitespace; or [^ \\t\\n\\r\\f\\v] with the\n\nre.ASCII ﬂag\n\n\\w Matches a Unicode “word” character; or [a-zA-Z0-9_] with the\n\nre.ASCII ﬂag\n\n\\W Matches a Unicode non-“word” character; or [^a-zA-Z0-9_] with the\n\nre.ASCII ﬂag\n\nHaving a different minimum and maximum is often convenient. For example, to match travelled and traveled (both legitimatespellings),we could use either travel{1,2}ed or travell{0,1}ed. The {0,1} quantiﬁcation is so often used that it has its own shorthand form, ?, so another way of writing the regex (and the one most likely to be used in practice) is travell?ed.\n\nTwoother quantiﬁcationshorthandsareprovided:+ which standsfor {1,n} (“at least one”)and * which standsfor {0,n} (“any number of”);in both cases n isthe maximum possible number allowed for a quantiﬁer,usually at least 32767.All the quantiﬁers are shown in Table 13.2.\n\nThe + quantiﬁer isvery useful. For example,tomatch integerswecould use \\d+ since this matches one or more digits. This regex could match in two places in the string 4588.91, for example, 4588.91 and 4588.91. Sometimes typos are the result of pressing a key too long. We could use the regex bevel+ed to match the legitimate beveled and bevelled, and the incorrect bevellled. If we wanted to standardize on the one l spelling, and match only occurrences that had two or more ls, we could use bevell+ed to ﬁnd them.\n\nThe * quantiﬁer is less useful, simply because it can so often lead to unex- pected results. For example, supposing that we want to ﬁnd lines that con- tain comments in Python ﬁles, we might try searching for #*. But this regex will match any line whatsoever, including blank lines because the meaning is “match any number of #s”—and that includes none. As a rule of thumb for those new to regexes, avoid using * at all, and if you do use it (or if you use ?), make sure there is at least one other expression in the regex that has a non- zero quantiﬁer—so at least one quantiﬁer other than * or ? since both of these can match their expression zero times.\n\nMean- ing of the ﬂags ➤ 496",
      "content_length": 2502,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 501,
      "content": "Python’s Regular Expression Language\n\nTable 13.2 Regular Expression Quantiﬁers\n\nSyntax\n\nMeaning\n\ne? or e{0,1} Greedily match zero or one occurrence of expression e\n\ne?? or e{0,1}? Nongreedily match zero or one occurrence of expression e\n\ne+ or e{1,}\n\nGreedily match one or more occurrences of expression e\n\ne+? or e{1,}? Nongreedily match one or more occurrences of expression e\n\ne* or e{0,}\n\nGreedily match zero or more occurrences of expression e\n\ne*? or e{0,}? Nongreedily match zero or more occurrences of expression e\n\ne{m}\n\nMatch exactly m occurrences of expression e\n\ne{m,}\n\nGreedily match at least m occurrences of expression e\n\ne{m,}?\n\nNongreedily match at least m occurrences of expression e\n\ne{,n}\n\nGreedily match at most n occurrences of expression e\n\ne{,n}?\n\nNongreedily match at most n occurrences of expression e\n\ne{m,n}\n\ne{m,n}?\n\nGreedily matchatleast m andatmost n occurrencesof expres- sion e Nongreedily match at least m and at most n occurrences of expression e\n\nIt is often possible to convert * uses to + uses and vice versa. For example, we could match “tasselled” with at least one l using tassell*ed or tassel+ed, and match those with two or more ls using tasselll*ed or tassell+ed.\n\nIf we use the regex \\d+ it will match 136. But why does it match all the digits, rather than just the ﬁrst one? By default, all quantiﬁers are greedy—they match asmany charactersasthey can. We can makeany quantiﬁer nongreedy (also called minimal) by following it with a ? symbol. (The question mark has two different meanings—on its own it is a shorthand for the {0,1} quantiﬁer, and when it follows a quantiﬁer it tells the quantiﬁer to be nongreedy.) For example, \\d+? can match the string 136 in three different places: 136, 136, and 136. Here is another example: \\d?? matches zero or one digits, but prefers to match none since it is nongreedy—on its own it suffers the same problem as * in that it will match nothing, that is, any text at all.\n\nNongreedy quantiﬁers can be useful for quick and dirty XML and HTML parsing. For example, to match all the image tags, writing <img.*> (match one “<”,then one “i”,then one “m”,then one “g”,then zero or more of any character apart from newline, then one “>”) will not work because the .* part is greedy and will match everything including the tag’s closing >, and will keep going until it reaches the last > in the entire text.\n\n493",
      "content_length": 2390,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 502,
      "content": "494\n\nChapter 13. Regular Expressions\n\nThree solutions present themselves (apart from using a proper parser). One is <img[^>]*> (match <img, then any number of non-> characters and then the tag’s closing > character),another is <img.*?> (match <img, then any number of characters,but nongreedily, so it will stop immediately before the tag’s closing >, and then the >), and a third combines both, as in <img[^>]*?>. None of them is correct, though, since they can all match <img>, which is not valid. Since we know that an image tag must have a src attribute, a more accurate regex is <img\\s+[^>]*?src=\\w+[^>]*?>. This matches the literal characters <img, then one or more whitespace characters,then nongreedily zero or more of anything except > (to skip any other attributes such as alt), then the src attribute (the literal characters src= then at least one “word” character), and then any other non-> characters (including none) to account for any other attributes, and ﬁnally the closing >.\n\nGrouping and Capturing\n\nIn practical applications we often need regexes that can match any one of two or more alternatives, and we often need to capture the match or some part of the match for further processing. Also, we sometimes want a quantiﬁer to apply to several expressions. All of these can be achieved by grouping with (), and in the case of alternatives using alternation with |.\n\nAlternation is especially useful when we want to match any one of several quite different alternatives. For example, the regex aircraft|airplane|jet will match any text that contains “aircraft” or “airplane” or “jet”. The same thing can be achieved using the regex air(craft|plane)|jet. Here, the parentheses are used to group expressions, so we have two outer expres- sions, air(craft|plane) and jet. The ﬁrst of these has an inner expression, craft|plane, and because this is preceded by air the ﬁrst outer expression can match only “aircraft” or “airplane”.\n\nParenthesesservetwodifferentpurposes—togroupexpressionsandtocapture the text that matches an expression. We will use the term group to refer to a grouped expression whether it captures or not, and capture and capture group to refer to a captured group. If we used the regex (aircraft|airplane|jet) it would not only match any of the three expressions, but would also capture whichever one was matched for later reference. Compare this with the regex (air(craft|plane)|jet) which has two captures if the ﬁrst expression matches (“aircraft” or “airplane” as the ﬁrst capture and “craft” or “plane” as the second capture), and one capture if the second expression matches (“jet”). We can switch off the capturing effect by following an opening parenthesis with ?:, so for example, (air(?:craft|plane)|jet) will have only one capture if it matches (“aircraft” or “airplane” or “jet”).\n\nA grouped expression is an expression and so can be quantiﬁed. Like any other expression the quantity is assumed to be one unless explicitly given. For\n\n||",
      "content_length": 2985,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 503,
      "content": "Python’s Regular Expression Language\n\nexample, if we have read a text ﬁle with lines of the form key=value, where each keyis alphanumeric,the regex (\\w+)=(.+) will match every line that hasa nonempty key and a nonempty value. (Recall that . matches anything except newlines.) And for every line that matches, two captures are made, the ﬁrst being the key and the second being the value.\n\nFor example, the key=value regular expression will match the entire line topic= physical geography with the two captures shown shaded. Notice that the second capture includes some whitespace, and that whitespace before the = is not accepted. We could reﬁne the regex to be more ﬂexible in accepting whitespace, and to strip off unwanted whitespace using a somewhat longer version:\n\n[ \\t]*(\\w+)[ \\t]*=[ \\t]*(.+)\n\nThis matches the same line as before and also lines that have whitespace around the = sign, but with the ﬁrst capture having no leading or trailing whitespace, and the second capture having no leading whitespace. For exam- ple: topic = physical geography. We have been careful to keep the whitespace matching parts outside the capturing parentheses, and to allow for lines that have no whitespace at all. We did not use \\s to match whitespace because that matches newlines (\\n) which could lead to incorrect matches that span lines (e.g., if the re.MULTILINE ﬂag is used). And for the value we did not use \\S to match nonwhitespace because we want to allow for values that contain whitespace (e.g., English sentences).To avoid the second capture having trail- ing whitespace we would need a more sophisticated regex; we will see this in the next subsection.\n\nCaptures can be referred to using backreferences, that is, by referring back to an earlier capture group.★ One syntax for backreferences inside regexes them- selves is \\i where i is the capture number. Captures are numbered starting from one and increasing by one going from left to right as each new (capturing) left parenthesisis encountered. For example,to simplistically match duplicat- ed wordswe can use the regex (\\w+)\\s+\\1 which matchesa “word”,then at least one whitespace, and then the same word as was captured. (Capture number 0 is created automatically without the need for parentheses;it holds the entire match, that is, what we show underlined.) We will see a more sophisticated way to match duplicate words later.\n\nIn long or complicated regexes it is often more convenient to use names rather than numbers for captures. This can also make maintenance easier since adding or removing capturing parentheses may change the numbers but won’t affect names. To name a capture we follow the opening parenthesis with ?P<name>.For example,(?P<key>\\w+)=(?P<value>.+) hastwo capturescalled \"key\" and \"value\". The syntax for backreferences to named captures inside a\n\n★Note that backreferences cannot be used inside character classes, that is, inside [].\n\n495\n\nRegex ﬂags ➤ 502",
      "content_length": 2941,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 504,
      "content": "496\n\nChapter 13. Regular Expressions\n\nregex is (?P=name). For example, (?P<word>\\w+)\\s+(?P=word) matches duplicate words using a capture called \"word\".\n\nAssertions and Flags\n\nOne problem that affects many of the regexes we have looked at so far is that they can match more or different text than we intended. For example, the regex aircraft|airplane|jet will match “waterjet” and “jetski” as well as “jet”. This kind of problem can be solved by using assertions. An assertion does not match any text, but instead says something about the text at the point where the assertion occurs.\n\nOne assertion is \\b (word boundary),which assertsthat the character that pre- cedes it must be a “word” (\\w) and the character that follows it must be a non- “word” (\\W),or vice versa. For example,although the regex jet can match twice in the text the jet and jetski are noisy, that is, the jet and jetski are noisy, the regex \\bjet\\b will match only once, the jet and jetski are noisy. In the context of the original regex, we could write it either as \\baircraft\\b|\\bair- plane\\b|\\bjet\\b or more clearly as \\b(?:aircraft|airplane|jet)\\b, that is, word boundary, noncapturing expression, word boundary.\n\nMany other assertions are supported, as shown in Table 13.3. We could use assertions to improve the clarity of a key=value regex, for example, by chang- ing it to ^(\\w+)=([^\\n]+) and setting the re.MULTILINE ﬂag to ensure that each key=value is taken from a single line with no possibility of spanning lines— providing no part of the regex matches a newline, so we can’t use, say, \\s. (The ﬂags are shown in Table 13.5;➤ 502;their syntaxesare described at the end of thissubsection,and examplesare given in the next section.) And if we want to strip whitespace from the ends and use named captures, the regex becomes:\n\n^[ \\t]*(?P<key>\\w+)[ \\t]*=[ \\t]*(?P<value>[^\\n]+)(?<![ \\t])\n\nEven though this regex is designed for a fairly simple task, it looks quite com- plicated. One way to make it more maintainable is to include comments in it. This can be done by adding inline comments using the syntax (?#the comment), but in practice comments like this can easily make the regex even more difﬁ- cult to read. A much nicer solution is to use the re.VERBOSE ﬂag—this allows us to freely use whitespace and normal Python comments in regexes, with the one constraint that if we need to match whitespace we must either use \\s or a character class such as [ ]. Here’s the key=value regex with comments:\n\n^[ \\t]* (?P<key>\\w+) [ \\t]*=[ \\t]* (?P<value>[^\\n]+) (?<![ \\t])\n\n# start of line and optional leading whitespace # the key text # the equals with optional surrounding whitespace # the value text # negative lookbehind to avoid trailing whitespace\n\n||\n\nRegex ﬂags ➤ 502",
      "content_length": 2751,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 505,
      "content": "Raw strings 67➤\n\nPython’s Regular Expression Language\n\nTable 13.3 Regular Expression Assertions\n\nSymbo Meaning\n\n^ Matches at the start; also matches after each newline with\n\nthe\n\nre.MULTILINE ﬂag\n\n$ Matches at the end; also matches before each newline with the\n\nre.MULTILINE ﬂag\n\n\\A Matches at the start\n\n\\b Matches at a “word” boundary; inﬂuenced by the re.ASCII\n\nﬂag—inside a character class this is the escape for the backspace character\n\n\\B Matches at a non-“word” boundary; inﬂuenced by the re.ASCII ﬂag\n\n\\Z Matches at the end\n\n(?=e) Matches if the expression e matches at this assertion but does not\n\nadvance over it—called lookahead or positive lookahead\n\n(?!e) Matches if the expression e does not match at this assertion and\n\ndoes not advance over it—called negative lookahead\n\n(?<=e) Matches if the expression e matches immediately before this\n\nassertion—called positive lookbehind\n\n(?<!e) Matches if the expression e does not match immediately before this\n\nassertion—called negative lookbehind\n\nIn the context of a Python program we would normally write a regex like this inside a raw triple quoted string—raw so that we don’t have to double up the backslashes, and triple quoted so that we can spread it over multiple lines.\n\nIn addition to the assertions we have discussed so far, there are additional assertions which look at the text in front of (or behind) the assertion to see whether it matches (or does not match) an expression we specify. The expres- sions that can be used in lookbehind assertions must be of ﬁxed length (so the quantiﬁers ?, +, and * cannot be used, and numeric quantiﬁers must be of a ﬁxed size, for example, {3}).\n\nIn the case of the key=value regex, the negative lookbehind assertion means that at the point it occurs the preceding character must not be a space or a tab. Thishastheeffect of ensuring that thelast character capturedintothe \"value\" capture group is not a space or tab (yet without preventing spacesor tabs from appearing inside the captured text).\n\nLet’s consider another example. Suppose we are reading a multiline text that contains the names “Helen Patricia Sharman”, “Jim Sharman”, “Sharman Joshi”, “Helen Kelly”, and so on, and we want to match “Helen Patricia”, but only when referring to “Helen Patricia Sharman”. The easi-\n\n497\n\nRegex ﬂags ➤ 502",
      "content_length": 2311,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 506,
      "content": "498\n\nChapter 13. Regular Expressions\n\nest way is to use the regex \\b(Helen\\s+Patricia)\\s+Sharman\\b. But we could also achieve the same thing using a lookahead assertion, for example, \\b(Helen\\s+Patricia)(?=\\s+Sharman\\b). This will match “Helen Patricia” only if it is preceded by a word boundary and followed by whitespace and “Sharman” ending at a word boundary.\n\nTo capture the particular variation of the forenames that is used (“Helen”, “Helen P.”, or “Helen Patricia”), we could make the regex slightly more so- phisticated, for example, \\b(Helen(?:\\s+(?:P\\.|Patricia))?)\\s+(?=Sharman\\b). This matches a word boundary followed by one of the forename forms—but only if this is followed by some whitespace and then “Sharman” and a word boundary.\n\nNote that only two syntaxes perform capturing, (e) and (?P<name>e). None of the other parenthesized forms captures. This makes perfect sense for the lookahead and lookbehind assertions since they only make a statement about what follows or precedes them—they are not part of the match, but rather af- fect whether a match is made. It also makes sense for the last two parenthe- sized forms that we will now consider.\n\nWe saw earlier how we can backreference a capture inside a regex either by number (e.g., \\1) or by name (e.g., (?P=name)). It is also possible to match conditionally depending on whether an earlier match occurred. The syntaxes are (?(id)yes_exp) and (?(id)yes_exp|no_exp). The id is the name or number of an earlier capture that we are referring to. If the capture succeeded the yes_exp will be matched here. If the capture failed the no_exp will be matched if it is given.\n\nLet’s consider an example. Suppose we want to extract the ﬁlenames referred to by the src attribute in HTML img tags. We will begin just by trying to match the src attribute, but unlike our earlier attempt we will account for the three forms that the attribute’s value can take: single quoted, double quoted, and unquoted. Here is an initial attempt: src=([\"'])([^\"'>]+)\\1. The ([^\"'>]+) part captures a greedy match of at least one character that isn’t a quote or >. This regex works ﬁne for quoted ﬁlenames, and thanks to the \\1 matches only when the opening and closing quotes are the same. But it does not allow for unquoted ﬁlenames. To ﬁx this we must make the opening quote optional and therefore match only if it is present.\n\nHere is a revised regex: src=([\"'])?([^\"'>]+)(?(1)\\1). We did not provide a no_exp since there is nothing to match if no quote is given. Unfortunately,this doesn’t work quite right. It will work ﬁne for quoted ﬁlenames,but for unquot- ed ﬁlenamesit will work only if the src attributeisthe last attributein thetag; otherwise it will incorrectly match text into the next attribute. The solution is to treat the two cases (quoted and unquoted) separately, and to use alterna- tion: src=(([\"'])([^\\1>]+?)\\1|([^\"' >]+)). Now let’s see the regex in context, complete with named groups, nonmatching parentheses, and comments:",
      "content_length": 2996,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 507,
      "content": "Python’s Regular Expression Language\n\n<img\\s+ [^>]*? src= (?:\n\n# start of the tag # any attributes that precede the src # start of the src attribute\n\n|\n\n(?P<quote>[\"']) (?P<qimage>[^\\1>]+?) (?P=quote)\n\n(?P<uimage>[^\"' >]+)\n\n# opening quote # image filename # closing quote matching the opening quote # ---or alternatively--- # unquoted image filename\n\n) [^>]*? >\n\n# any attributes that follow the src # end of the tag\n\nThe indentation is just for clarity. The noncapturing parentheses are used for alternation. The ﬁrst alternative matches a quote (either single or double), then the image ﬁlename (which may contain any characters except for the quote that matched or >), and ﬁnally, another quote which must be the same as the matching quote. We also had to use minimal matching, +?, for the ﬁle- name, to ensure that the match doesn’t extend beyond the ﬁrst matching clos- ing quote. This means that a ﬁlename such as \"I'm here!.png\" will match correctly. Note also that to refer to the matching quote inside the character class we had to use a numbered backreference, \\1, instead of (?P=quote), since only numbered backreferences work inside character classes. The second al- ternative matches an unquoted ﬁlename—a string of characters that don’t include quotes, spaces, or >. Due to the alternation, the ﬁlename is captured in \"qimage\" (capture number 2) or in \"uimage\" (capture number 3,since (?P=quote) matches but doesn’t capture), so we must check for both.\n\nThe ﬁnal piece of regex syntax that Python’s regular expression engine offers is a means of setting the ﬂags. Usually the ﬂags are set by passing them as additional parameters when calling the re.compile() function, but sometimes it is more convenient to set them as part of the regex itself. The syntax is flags is one or more of a (the same as passing re.ASCII), simply (?flags) where i (re.IGNORECASE), m (re.MULTILINE), s (re.DOTALL), and x (re.VERBOSE).★ If the ﬂags are set this way they should be put at the start of the regex; they match nothing, so their effect on the regex is only to set the ﬂags.\n\nThe Regular Expression Module\n\nThe re module provides two ways of working with regexes. One is to use the functions listed in Table 13.4 (➤ 502), where each function is given a regex as itsﬁrstargument. Each functionconvertstheregex intoan internalformat—a\n\n★The letters used for the ﬂags are the same as the ones used by Perl’s regex engine, which is why s is used for re.DOTALL and x is used for re.VERBOSE.\n\n499\n\n|||\n\nRegex ﬂags ➤ 502",
      "content_length": 2516,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 508,
      "content": "500\n\nChapter 13. Regular Expressions\n\nprocess called compiling—and then does its work. This is very convenient for one-off uses, but if we need to use the same regex repeatedly we can avoid the cost of compiling it at each use by compiling it once using the re.compile() function. Wecan then callmethodson thecompiledregex object asmany times as we like. The compiled regex methods are listed in Table 13.6 (➤ 503).\n\nmatch = re.search(r\"#[\\dA-Fa-f]{6}\\b\", text)\n\nThis code snippet shows the use of an re module function. The regex matches HTML-style colors (such as #C0C0AB). If a match is found the re.search() func- tion returns a match object; otherwise, it returns None. The methods provided by match objects are listed in Table 13.7 (➤ 507).\n\nIf we were going to use thisregex repeatedly,we could compile it once and then use the compiled regex whenever we needed it:\n\ncolor_re = re.compile(r\"#[\\dA-Fa-f]{6}\\b\") match = color_re.search(text)\n\nAs we noted earlier, we use raw strings to avoid having to escape backslashes. Another way of writing this regex would be to use the character class [\\dA-F] and passthe re.IGNORECASE ﬂag as the last argument to the re.compile() call,or to use the regex (?i)#[\\dA-F]{6}\\b which starts with the ignore case ﬂag.\n\nIf morethanoneﬂag isrequiredthey canbecombinedusing the OR operator(|), for example, re.MULTILINE|re.DOTALL, or (?ms) if embedded in the regex itself.\n\nWe will round off this section by reviewing some examples,starting with some of the regexes shown in earlier sections, so as to illustrate the most commonly used functionality that the re module provides. Let’s start with a regex to spot duplicate words:\n\ndouble_word_re = re.compile(r\"\\b(?P<word>\\w+)\\s+(?P=word)(?!\\w)\",\n\nre.IGNORECASE)\n\nfor match in double_word_re.finditer(text):\n\nprint(\"{0} is duplicated\".format(match.group(\"word\")))\n\nThe regex is slightly more sophisticated than the version we made earlier. It starts at a word boundary (to ensure that each match starts at the beginning of a word), then greedily matches one or more “word” characters, then one or more whitespacecharacters,then the same word again—but only if the second occurrence of the word is not followed by a word character.\n\nIf the input text was “win in vain”, without the ﬁrst assertion there would be one match and one capture: win in vain. There aren’t two matches because while (?P<word>) matchesand captures,the \\s+ and (?P=word) partsonly match. The use of the word boundary assertion ensures that the ﬁrst word matched is a whole word, so we end up with no match or capture since there is no du-",
      "content_length": 2596,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 509,
      "content": "The Regular Expression Module\n\nplicate whole word. Similarly, if the input text was “one and and two let’s say”, without the last assertion there would be two matches and two captures: one and and two let's say. The use of the lookahead assertion means that the second word matched is a whole word, so we end up with one match and one capture: one and and two let's say.\n\nThe for loop iterates over every match object returned by the finditer() method and we use the match object’s group() method to retrieve the cap- tured group’s text. We could just as easily (but less maintainably) have used group(1)—in which case we need not have named the capture group at all and just used the regex \\b(\\w+)\\s+\\1(?!\\w). Another point to note is that we could have used a word boundary \\b at the end, instead of (?!\\w).\n\nAnother example we presented earlier was a regex for ﬁnding the ﬁlenames in HTML image tags. Here is how we would compile the regex,adding ﬂags so that it is not case-sensitive, and allowing us to include comments:\n\nimage_re = re.compile(r\"\"\"\n\n<img\\s+ [^>]*? src= (?:\n\n# start of tag # non-src attributes # start of src attribute\n\n|\n\n(?P<quote>[\"']) (?P<qimage>[^\\1>]+?) (?P=quote)\n\n(?P<uimage>[^\"' >]+)\n\n# opening quote # image filename # closing quote # ---or alternatively--- # unquoted image filename\n\n) [^>]*? > \"\"\", re.IGNORECASE|re.VERBOSE)\n\n# non-src attributes # end of the tag\n\nimage_files = [] for match in image_re.finditer(text):\n\nimage_files.append(match.group(\"qimage\") or\n\nmatch.group(\"uimage\"))\n\nAgain we use the finditer() method to retrieve each match and the match object’s group() function to retrieve the captured texts. Each time a match is made we don’t know which of the image groups (\"qimage\" or \"uimage\") has matched,but using the or operator provides a neat solution for this. Since the case insensitivity applies only to img and src, we could drop the re.IGNORECASE ﬂag and use [Ii][Mm][Gg] and [Ss][Rr][Cc] instead. Although thiswould make the regex less clear, it might make it faster since it would not require the text being matched to be set to upper- (or lower-) case—but it is likely to make a difference only if the regex was being used on a very large amount of text.\n\n501",
      "content_length": 2221,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 510,
      "content": "502\n\nChapter 13. Regular Expressions\n\nTable 13.4 The Regular Expression Module’s Functions\n\nSyntax\n\nDescription\n\nre.compile(\n\nr, f)\n\nReturns compiled regex r with its ﬂags set to f if speciﬁed. (The ﬂags are described in Table 13.5.)\n\nre.escape(s) Returns string s with all nonalphanumeric characters\n\nbackslash-escaped—therefore,the returned string has no special regex characters\n\nre.findall(\n\nr, s, f)\n\nReturns all nonoverlapping matches of regex r in string s (inﬂuenced by the ﬂags f if given).If the regex has captures, each match is returned as a tuple of captures.\n\nre.finditer( r, s, f)\n\nReturns a match object for each nonoverlapping match of regex r in string s (inﬂuenced by the ﬂags f if given)\n\nre.match(\n\nr, s, f)\n\nre.search(\n\nr, s, f)\n\nre.split( r, s, m, f)\n\nReturns a match object if the regex r matches at the start of string s (inﬂuenced by the ﬂags f if given); otherwise, returns None Returns a match object if the regex r matches anywhere otherwise, in string s (inﬂuenced by the ﬂags f if given); returns None Returnsthe list of stringsthat resultsfrom splitting string s on every occurrenceof regex r doing upto m splits(or asmany as possible if no m is given, and for Python 3.1 inﬂuenced by ﬂags f if given).If the regex has captures,these are included in the list between the parts they split.\n\nre.sub(\n\nr, x, s, m, f)\n\nReturns a copy of string s with every (or up to m if given,and for Python 3.1inﬂuenced by ﬂags f if given)match of regex r replaced with x—this can be a string or a function; see text\n\nre.subn(\n\nr, x, s m, f)\n\nThe same as re.sub() except that it returns a 2-tuple of the resultant string and the number of substitutions that were made\n\nTable 13.5 The Regular Expression Module’s Flags\n\nFlag\n\nMeaning\n\nre.A or re.ASCII\n\nMakes \\b, \\B, \\s, \\S, \\w, and \\W assume that stringsare ASCII; the default is for these character class short- hands to depend on the Unicode speciﬁcation\n\nre.I or re.IGNORECASE Makes the regex match case-insensitively\n\nre.M or re.MULTILINE Makes ^ match at the start and after each newline\n\nre.S or re.DOTALL\n\nand $ match before each newline and at the end Makes . match every character including newlines\n\nre.X or re.VERBOSE\n\nAllows whitespace and comments to be included\n\n3.x",
      "content_length": 2244,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 511,
      "content": "The Regular Expression Module\n\nTable 13.6 Regular Expression Object Methods\n\nSyntax\n\nDescription\n\nrx.findall(s\n\nstart, end)\n\nReturnsallnonoverlapping matchesof theregex instring s (or in the start:end slice of s).If the regex has captures, each match is returned as a tuple of captures.\n\nrx.finditer(s\n\nstart, end)\n\nReturnsa match object for each nonoverlapping match in string s (or in the start:end slice of s)\n\nrx.flags\n\nThe ﬂags that were set when the regex was compiled\n\nrx.groupindex\n\nrx.match(s,\n\nstart, end)\n\nrx.pattern\n\nA dictionary whose keys are capture group names and whose values are group numbers; empty if no names are used Returns a match object if the regex matches at the start of string s (or at the start of the start:end slice of s); otherwise, returns None The string from which the regex was compiled\n\nrx.search(s,\n\nstart, end)\n\nrx.split(s, m)\n\nReturns a match object if the regex matches anywhere in string s (or in the start:end slice of s); otherwise, returns None Returns the list of strings that results from splitting string s on every occurrence of the regex doing up to m splits (or as many as possible if no m is given).If the regex has captures, these are included in the list between the parts they split.\n\nrx.sub(x, s, m) Returns a copy of string s with every (or up to m if given) match replaced with x—this can be a string or a function; see text\n\nrx.subn(x, s m) The same as re.sub() except that it returns a 2-tuple of\n\nthe resultant string and the number of substitutionsthat were made\n\nOne common task is to take an HTML text and output just the plain text that it contains. Naturally we could do this using one of Python’s parsers, but a simple tool can be created using regexes. There are three tasksthat need to be done: delete any tags, replace entities with the characters they represent, and insert blank lines to separate paragraphs. Here is a function (taken from the html2text.py program) that does the job:\n\ndef html2text(html_text):\n\ndef char_from_entity(match):\n\ncode = html.entities.name2codepoint.get(match.group(1), 0xFFFD) return chr(code)\n\n503",
      "content_length": 2102,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 512,
      "content": "504\n\nChapter 13. Regular Expressions\n\ntext = re.sub(r\"<!--(?:.|\\n)*?-->\", \"\", html_text) text = re.sub(r\"<[Pp][^>]*?>\", \"\\n\\n\", text) text = re.sub(r\"<[^>]*?>\", \"\", text) text = re.sub(r\"&#(\\d+);\", lambda m: chr(int(m.group(1))), text) text = re.sub(r\"&([A-Za-z]+);\", char_from_entity, text) text = re.sub(r\"\\n(?:[ \\xA0\\t]+\\n)+\", \"\\n\", text) return re.sub(r\"\\n\\n+\", \"\\n\\n\", text.strip())\n\n#1 #2 #3\n\n#5 #6 #7\n\nThe ﬁrst regex, <!--(?:.|\\n)*?-->, matches HTML comments, including those with other HTML tags nested inside them. The re.sub() function replaces as many matches as it ﬁnds with the replacement—deleting the matches if the replacement is an empty string, as it is here. (We can specify a maximum number of matches by giving an additional integer argument at the end.)\n\nWe are careful to use nongreedy (minimal) matching to ensure that we delete one comment for each match; if we did not do this we would delete from the start of the ﬁrst comment to the end of the last comment.\n\nIn Python 3.0, the re.sub() function does not accept any ﬂags as arguments, and since . means “any character except newline”, we must look for . or \\n. And we must look for these using alternation rather than a character class, since inside a character class . has its literal meaning, that is, period. An alternative would be to begin the regex with the ﬂag embedded, for example, (?s)<!--.*?-->, or we could compile a regex object with the re.DOTALL ﬂag, in which case the regex would simply be <!--.*?-->.\n\nFrom Python 3.1, re.split(), re.sub(), and re.subn(), can all accept a ﬂags argument, so we could simply use <!--.*?--> and pass the re.DOTALL ﬂag.\n\nThe second regex, <[Pp][^>]*?>, matches opening paragraph tags (such as <P> or <p align=\"center\">). It matches the opening <p (or <P), then any attributes (using nongreedy matching), and ﬁnally the closing >. The second call to the re.sub() function uses this regex to replace opening paragraph tags with two newline characters (the standard way to delimit a paragraph in a plain text ﬁle).\n\nThe third regex,<[^>]*?>,matchesany tag and isused in thethird re.sub() call to delete all the remaining tags.\n\nHTML entities are a way of specifying non-ASCII characters using ASCII characters. They come in two forms: &name; where name is the name of the character—for example, &copy; for ©—and &#digits; where digits are deci- mal digits identifying the Unicode code point—for example, &#165; for ¥. The fourth call to re.sub() uses the regex &#(\\d+);, which matches the digits form and captures the digits into capture group 1. Instead of a literal replacement text we have passed a lambda function. When a function is passed to re.sub() it callsthefunction oncefor each timeit matches,passing thematch object asthe function’ssole argument. Inside the lambda function we retrieve the digits(asa\n\n3.0\n\n3.1",
      "content_length": 2845,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 513,
      "content": "The Regular Expression Module\n\nstring),convert to an integer using the built-in int() function,and then use the built-in chr() function to obtain the Unicode character for the given code point. The function’s return value (or in the case of a lambda expression, the result of the expression) is used as the replacement text.\n\nThe ﬁfth re.sub() call uses the regex &([A-Za-z]+); to capture named entities. The standard library’s html.entities module contains dictionaries of entities, including name2codepoint whosekeysareentity namesand whosevaluesarein- teger codepoints. The re.sub() function callsthelocal char_from_entity() func- tionevery timeit hasa match. The char_from_entity() functionusesdict.get() with a default argument of 0xFFFD (the code point of the standard Unicode replacement character—often depicted as ?). This ensures that a code point is always retrieved and it is used with the chr() function to return a suitable character to replace the named entity with—using the Unicode replacement character if the entity name is invalid.\n\nThe sixth re.sub() call’s regex, \\n(?:[ \\xA0\\t]+\\n)+, is used to delete lines that contain only whitespace. The character class we have used contains a space, a nonbreaking space (which &nbsp; entities are replaced with in the preceding regex), and a tab. The regex matches a newline (the one at the end of a line that precedes one or more whitespace-only lines), then at least one (and as many aspossible)linesthat containonly whitespace. Sincethematchincludes the newline,from the line preceding the whitespace-only lineswe must replace the match with a single newline; otherwise, we would delete not just the whitespace-only lines but also the newline of the line that preceded them.\n\nThe result of the seventh and last re.sub() call is returned to the caller. This regex, \\n\\n+, is used to replace sequences of two or more newlines with exactly two newlines, that is, to ensure that each paragraph is separated by just one blank line.\n\nIn the HTML example none of the replacements were directly taken from the match (although HTML entity names and numbers were used), but in some situations the replacement might need to include all or some of the matching text. For example, if we have a list of names, each of the form Forename Mid- dlename1…MiddlenameN Surname, where there may be any number of mid- dle names (including none), and we want to produce a new version of the list witheachitemof theformSurname,ForenameMiddlename1…MiddlenameN, we can easily do so using a regex:\n\nnew_names = [] for name in names:\n\nname = re.sub(r\"(\\w+(?:\\s+\\w+)*)\\s+(\\w+)\", r\"\\2, \\1\", name) new_names.append(name)\n\nThe ﬁrst part of the regex, (\\w+(?:\\s+\\w+)*), matches the forename with the ﬁrst \\w+ expression and zero or more middle names with the (?:\\s+\\w+)* ex-\n\n505",
      "content_length": 2810,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 514,
      "content": "506\n\nChapter 13. Regular Expressions\n\npression. The middle name expression matches zero or more occurrences of whitespace followed by a word. The second part of the regex, \\s+(\\w+), match- es the whitespace that follows the forename (and middle names) and the surname.\n\nIf the regex looks a bit too much like line noise, we can use named capture groups to improve legibility and make it more maintainable:\n\nname = re.sub(r\"(?P<forenames>\\w+(?:\\s+\\w+)*)\"\n\nr\"\\s+(?P<surname>\\w+)\", r\"\\g<surname>, \\g<forenames>\", name)\n\nCaptured text can be referred to in a sub() or subn() function or method by using the syntax \\i or \\g<id> where i is the number of the capture group and id is the name or number of the capture group—so \\1 is the same as \\g<1>, and in this example, the same as \\g<forenames>.This syntax can also be used in the string passed to a match object’s expand() method.\n\nWhy doesn’t the ﬁrst part of the regex grab the entire name? After all, it is using greedy matching. In fact it will, but then the match will fail because although the middle names part can match zero or more times, the surname part must match exactly once, but the greedy middle names part has grabbed everything. Having failed, the regular expression engine will then backtrack, giving up the last “middle name” and thus allowing the surname to match. Although greedy matches match as much as possible, they stop if matching more would make the match fail.\n\nFor example,if thenameis“JohnleCarré”,theregex willﬁrstmatchtheentire name, that is, John le Carré.This satisﬁes the ﬁrst part of the regex but leaves nothing for the surname part to match,and since the surnameismandatory (it has an implicit quantiﬁer of 1), the regex has failed. Since the middle names part isquantiﬁedby *,it can matchzeroor moretimes(currently it ismatching twice,“ le” and “ Carré”),so the regular expression engine can make it give up some of its match without causing it to fail. Therefore, the regex backtracks, giving up the last \\s+\\w+ (i.e., “ Carré”), so the match becomes John le Carré with the match satisfying the whole regex and with the two match groups containing the correct texts.\n\nThere’s one weakness in the regex as written: It doesn’t cope correctly with forenames that are written using an initial, such as “James W. Loewen”, or “J.R.R.Tolkein”.Thisisbecause\\w matcheswordcharactersandthesedon’tin- clude period. One obvious—but incorrect—solutionisto change the forenames part of theregex’s\\w+ expressionto [\\w.]+,in both placesthat it occurs. A peri- od in a character class is taken to be a literal period,and character class short- hands retain their meaning inside character classes, so the new expression matches word characters or periods. But this would allow for names like “.”, “..”, “.A”, “.A.”, and so on. In view of this, a more subtle approach is required.",
      "content_length": 2850,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 515,
      "content": "The Regular Expression Module\n\nTable 13.7 Match Object Attributes and Methods\n\nSyntax\n\nDescription\n\nm.end(g)\n\nReturns the end position of the match in the text for group g if given (or for group 0, the whole match); returns -1 if the group did not participate in the match\n\nm.endpos\n\nm.expand(s)\n\nThe search’send position (the end of the text or the end given to match() or search()) Returns string s with capture markers (\\1, \\2, \\g<name>, and similar) replaced by the corresponding captures\n\nm.group(g,\n\n...)\n\nReturns the numbered or named capture group g; if more than one is given a tuple of corresponding capture groups is returned (the whole match is group 0)\n\nm.groupdict( default)\n\nReturns a dictionary of all the named capture groups with the names as keys and the captures as values; if a default is given this is the value used for capture groups that did not participate in the match\n\nm.groups(\n\ndefault)\n\nReturnsa tuple of all the capture groupsstarting from 1;if a default is given this is the value used for capture groupsthat did not participate in the match\n\nm.lastgroup\n\nm.lastindex\n\nm.pos\n\nThe name of the highest numbered capturing group that matched or None if there isn’t one or if no names are used The number of the highest capturing group that matched or None if there isn’t one The start position to look from (the start of the text or the start given to match() or search())\n\nm.re\n\nThe regex object which produced this match object\n\nm.span(g)\n\nReturns the start and end positions of the match in the text for group g if given (or for group 0,the whole match);returns (-1, -1) if the group did not participate in the match\n\nm.start(g)\n\nReturns the start position of the match in the text for group g if given (or for group 0, the whole match); returns -1 if the group did not participate in the match\n\nm.string\n\nThe string that was passed to match() or search()\n\nname = re.sub(r\"(?P<forenames>\\w+\\.?(?:\\s+\\w+\\.?)*)\" r\"\\s+(?P<surname>\\w+)\", r\"\\g<surname>, \\g<forenames>\", name)\n\nHere we have changed the forenamespart of the regex (the ﬁrst line).The ﬁrst part of the forenames regex matches one or more word characters optionally followed by a period. The second part matches at least one whitespace charac-\n\n507",
      "content_length": 2238,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 516,
      "content": "Con- ditional match- ing 498➤\n\n508\n\nChapter 13. Regular Expressions\n\nter, then one or more word characters optionally followed by a period,with the whole of this second part itself matching zero or more times.\n\nWhen we use alternation (|) with two or more alternatives capturing,we don’t know which alternative matched, so we don’t know which capture group to retrieve the captured text from. We can of course iterate over all the groups to ﬁnd the nonempty one, but quite often in this situation the match object’s lastindex attribute can give us the number of the group we want. We will look at one last example to illustrate this and to give us a little bit more regex practice.\n\nSuppose we want to ﬁnd out what encoding an HTML, XML, or Python ﬁle is using. We could open the ﬁle in binary mode,and read,say,the ﬁrst 1000bytes into a bytes object. We could then close the ﬁle, look for an encoding in the bytes, and reopen the ﬁle in text mode using the encoding we found or using a fallback encoding (such as UTF-8). The regex engine expects regexes to be supplied as strings, but the text the regex is applied to can be a str, bytes, or bytearray object,and when bytes or bytearray objectsare used,all the functions and methods return bytes instead of strings,and the re.ASCII ﬂag is implicitly switched on.\n\nFor HTML ﬁles the encoding is normally speciﬁed in a <meta> tag (if speci- ﬁed at all), for example, <meta http-equiv='Content-Type' content='text/html; charset=ISO-8859-1'/>. XML ﬁles are UTF-8 by default, but this can be over- ridden, for example, <?xml version=\"1.0\" encoding=\"Shift_JIS\"?>. Python 3 ﬁles are also UTF-8 by default,but again this can be overridden by including a line such as # encoding: latin1 or # -*- coding: latin1 -*- immediately after the shebang line.\n\nHere is how we would ﬁnd the encoding,assuming that the variable binary is a bytes object containing the ﬁrst 1000 bytes of an HTML, XML, or Python ﬁle:\n\nmatch = re.search(r\"\"\"(?<![-\\w])\n\n(?:(?:en)?coding|charset) (?:=([\"'])?([-\\w]+)(?(1)\\1) |:\\s*([-\\w]+))\"\"\".encode(\"utf8\"),\n\n#1 #2 #3\n\nbinary, re.IGNORECASE|re.VERBOSE)\n\nencoding = match.group(match.lastindex) if match else b\"utf8\"\n\nTo search a bytes object we must specify a pattern that is also a bytes object. In this case we want the convenience of using a raw string, so we use one and convert it to a bytes object as the re.search() function’s ﬁrst argument.\n\nThe ﬁrst part of the regex itself is a lookbehind assertion that says that the match cannot be preceded by a hyphen or a word character. The second part matches “encoding”, “coding”, or “charset” and could have been written as (?:encoding|coding|charset). We have made the third part span two lines to emphasise the fact that it has two alternating parts, =([\"'])?([-\\w]+)(?(1)\\1)",
      "content_length": 2792,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 517,
      "content": "The Regular Expression Module\n\nand :\\s*([-\\w]+), only one of which can match. The ﬁrst of these matches an equals sign followed by one or more word or hyphen characters (optionally en- closed in matching quotes using a conditional match),and the second matches a colon and then optional whitespace followed by one or more word or hyphen characters. (Recallthatahypheninsideacharacterclassistakentobealiteral hyphen if it isthe ﬁrst character;otherwise,it meansa range of characters,for example, [0-9].)\n\nWe have used the re.IGNORECASE ﬂag to avoid having to write (?:(?:[Ee][Nn])? [Cc][Oo][Dd][Ii][Nn][Gg]|[Cc][Hh][Aa][Rr][Ss][Ee][Tt]) and we have used the re.VERBOSE ﬂag so that we can lay out the regex neatly and include comments (in this case just numbers to make the parts easy to refer to in this text).\n\nThere are three capturing match groups, all in the third part: ([\"'])? which captures the optional opening quote, ([-\\w]+) which captures an encoding that follows an equals sign, and the second ([-\\w]+) (on the following line) that captures an encoding that follows a colon. We are only interested in the encoding, so we want to retrieve either the second or third capture group, only one of which can match since they are alternatives. The lastindex attribute holds the index of the last matching capture group (either 2 or 3 when a match occurs in this example), so we retrieve whichever matched, or use a default encoding if no match was made.\n\nWe have now seen all of the most frequently used re module functionality in action, so we will conclude this section by mentioning one last function. The re.split() function (or the regex object’s split() method) can split strings based on a regex. One common requirement is to split a text on whitespace to get a list of words. This can be done using re.split(r\"\\s+\", text) which re- turns a list of words (or more precisely a list of strings, each of which match- es \\S+). Regular expressions are very powerful and useful, and once they are learned, it is easy to see all text problems as requiring a regex solution. But sometimes using string methods is both sufﬁcient and more appropriate. For example, we can just as easily split on whitespace by using text.split() since the str.split() method’s default behavior (or with a ﬁrst argument of None) is to split on \\s+.\n\nSummary\n\nRegular expressions offer a powerful way of searching texts for strings that match a particular pattern, and for replacing such strings with other strings which themselves can depend on what was matched.\n\nIn this chapter we saw that most characters are matched literally and are implicitly quantiﬁed by {1}. We also learned how to specify character classes—setsof charactersto match—and how to negate such sets and include\n\n509\n\n|||",
      "content_length": 2774,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 518,
      "content": "510\n\nChapter 13. Regular Expressions\n\nranges of characters in them without having to write each character individu- ally.\n\nWe learned how to quantify expressions to match a speciﬁc number of times or to match from a given minimum to a given maximum number of times, and how to use greedy and nongreedy matching. We also learned how to group one or more expressions together so that they can be quantiﬁed (and optionally captured) as a unit.\n\nThe chapter also showed how what ismatched can be affected by using various assertions, such as positive and negative lookahead and lookbehind, and by various ﬂags, for example, to control the interpretation of the period and whether to use case-insensitive matching.\n\nTheﬁnalsectionshowedhowtoput regexestousewithinthecontextof Python programs. In this section we learned how to use the functions provided by the re module, and the methods available from compiled regexes and from match objects. We also learned how to replace matches with literal strings, with literal strings that contain backreferences, and with the results of function calls or lambda expressions, and how to make regexes more maintainable by using named captures and comments.\n\nExercises\n\n1. In many contexts (e.g., in some web forms), users must enter a phone number, and some of these irritate users by accepting only a speciﬁc for- mat. Write a program that reads U.S.phone numbers with the three-digit area and seven-digit local codes accepted as ten digits, or separated into blocksusing hyphensor spaces,and with thearea codeoptionally enclosed in parentheses. For example, all of these are valid: 555-123-1234, (555) 1234567, (555) 123 1234, and 5551234567. Read the phone numbers from sys.stdin and for each one echo the number in the form “(999) 999 9999” or report an error for any that are invalid, or that don’t have exactly ten digits. The regex to match these phone numbers is about ten lines long (in ver- bosemode)andisquitestraightforward. A solutionisprovidedin phone.py, which is about twenty-ﬁve lines long.\n\n2. Write a small program that reads an XML or HTML ﬁle speciﬁed on the command line and for each tag that has attributes, outputs the name of the tag with its attributes shown underneath. For example, here is an ex- tract from the program’soutput when given one of the Python documenta- tion’s index.html ﬁles: html xmlns = http://www.w3.org/1999/xhtml\n\n|||",
      "content_length": 2401,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 519,
      "content": "Exercises\n\nmeta http-equiv = Content-Type content = text/html; charset=utf-8 li class = right style = margin-right: 10px\n\nOne approach is to use two regexes, one to capture tags with their at- tributes and another to extract the name and value of each attribute. At- tributevaluesmightbequotedusing singleor doublequotes(inwhichcase they may contain whitespace and the quotes that are not used to enclose them),or they may be unquoted (in which case they cannot contain white- spaceor quotes).Itisprobably easiesttostartby creating a regex tohandle quoted and unquoted valuesseparately,and then merging the two regexes into a single regex to cover both cases. It is best to use named groups to make the regex more readable. This is not easy, especially since backref- erences cannot be used inside character classes.\n\nA solution is provided in extract_tags.py, which is less than 35 lines long. The tag and attributes regex is just one line. The attribute name–value regex is half a dozen lines and uses alternation, conditional matching (twice, with one nested inside the other), and both greedy and nongreedy quantiﬁers.\n\n511",
      "content_length": 1127,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 520,
      "content": "File for- mats 219➤\n\nDynam- ic code execu- tion 344➤\n\n14 ● BNF Syntax and Parsing\n\nTerminology\n\nWriting Handcrafted Parsers ● Pythonic Parsing with PyParsing ● Lex/Yacc-Style Parsing with PLY\n\nIntroduction to Parsing\n\n||||\n\nParsing is a fundamental activity in many programs, and for all but the most trivial cases, it is a challenging topic. Parsing is often done when we need to read data that is stored in a custom format so that we can process it or per- form queries on it. Or we may be required to parse a DSL (Domain-Speciﬁc Language)—these are mini task-speciﬁc languages that appear to be growing in popularity. Whether we need to read data in a custom format or code writ- ten using a DSL, we will need to create a suitable parser. This can be done by handcrafting, or by using one of Python’s generic parsing modules.\n\nPython can be used to write parsers using any of the standard computer science techniques:using regexes,using ﬁnite state automata,using recursive descent parsers, and so on. All of these approaches can work quite well, but for data or DSLs that are complex—for example, recursively structured and featuring operators that have different precedences and associativities—they can be challenging to get right. Also, if we need to parse many different data formatsor DSLs,handcrafting each parser can be time-consuming and tedious to maintain.\n\nFortunately, for some data formats, we don’t have to write a parser at all. For example,when it comesto parsing XML,Python’sstandard library comeswith DOM, SAX, and element tree parsers, with other XML parsers available as third-party add-ons.\n\nIn fact, Python has built-in support for reading and writing a wide range of data formats, including delimiter-separated data with the csv module, Windows-style .ini ﬁles with the configparser module, JSON data with the json module, and also a few others, as mentioned in Chapter 5. Python does not provide any built-in support for parsing other languages, although it does the shlex module which can be used to create a lexer for Unix shell- provide like mini-languages (DSLs), and the tokenize module that provides a lexer for Python source code. And of course, Python can execute Python code using the built-in eval() and exec() functions.\n\n513",
      "content_length": 2264,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 521,
      "content": "514\n\nChapter 14. Introduction to Parsing\n\nIn general, if Python already has a suitable parser in the standard library, or as a third-party add-on, it is usually best to use it rather than to write our own.\n\nWhen it comes to parsing data formats or DSLs for which no parser is avail- able, rather than handcrafting a parser, we can use one of Python’s third-par- ty general-purpose parsing modules. In this chapter we will introduce two of the most popular third-party parsers. One of these is Paul McGuire’s PyPars- ing module, which takes a unique and very Pythonic approach. The other is David Beazley’sPLY (Python Lex Yacc),which isclosely modeled on the classic Unix lex and yacc tools, and that makes extensive use of regexes. Many other parsers are available, with many listed at www.dabeaz.com/ply (at the bottom of the page), and of course, in the Python Package Index, pypi.python.org/pypi.\n\nThis chapter’s ﬁrst section provides a brief introduction to the standard BNF (Backus–Naur Form) syntax used to describe the grammars of data formats and DSLs. In that section we will also explain the basic terminology. The remaining sections all cover parsing itself, with the second section covering handcrafted parsers, using regexes, and using recursive descent, as a natural follow-on from the regular expressions chapter. The third section introduces the PyParsing module. The initial examples are the same as those for which handcrafted parsers are created in the second section—this is to help learn the PyParsing approach, and also to provide the opportunity to compare and contrast. The section’s last example has a more ambitious grammar and is new in this section. The last section introduces the PLY module, and shows thesameexamplesweused in thePyParsing section,again for easeof learning and to provide a basis for comparison.\n\nNote that with one exception, the handcrafted parsers section is where each data format and DSL is described, its BNF given, and an example of the data or DSL shown, with the other sections providing backreferences to these where appropriate. The exception is the ﬁrst-order logic parser whose details are given in the PyParsing section, with corresponding backreferences in the PLY section.\n\nBNF Syntax and Parsing Terminology\n\nParsing is a means of transforming data that is in some structured format—whether the data representsactual data,or statementsin a program- ming language, or some mixture of both—into a representation that reﬂects the data’s structure and that can be used to infer the meaning that the data represents. The parsing process is most often done in two phases:lexing (also called lexicalanalysis,tokenizing,or scanning),and parsing proper (alsocalled syntactic analysis).\n\n|||",
      "content_length": 2745,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 522,
      "content": "BNF Syntax and Parsing Terminology\n\nFor example, given a sentence in the English language, such as “the dog barked”, we might transform the sentence into a sequence of (part-of-speech– word) 2-tuples, ((DEFINITE_ARTICLE, \"the\"), (NOUN, \"dog\"), (VERB, \"barked\")). We would then perform syntactic analysis to see if this is a valid English sen- tence. In this case it is, but our parser would have to reject, say, “the barked dog”.★\n\nThe lexing phase is used to convert the data into a stream of tokens. In typical cases,each token holds at least two pieces of information:the token’s type (the kind of data or language construct being represented), and the token’s value (which may be empty if the type stands for itself—for example, a keyword in a programming language).\n\nThe parsing phase is where a parser reads each token and performs some se- mantic action. The parser operates according to a predeﬁned set of grammar rules that deﬁne the syntax that the data is expected to follow. (If the data doesn’t follow the syntax rules the parser will correctly fail.) In multiphase parsers,the semantic action consistsof building up an internal representation of the input in memory (called an Abstract Syntax Tree—AST), which serves as input to the next phase. Once the AST has been constructed, it can be tra- versed, for example, to query the data, or to write the data out in a different format, or to perform computations that correspond to the meanings encoded in the data.\n\nData formats and DSLs (and programming languages generally) can be de- scribedusing agrammar—asetof syntaxrulesthatdeﬁnewhatisvalidsyntax for the data or language. Of course, just because a statement is syntactically valid doesn’t mean that it makes sense—for example, “the cat ate democracy” is syntactically valid English, but meaningless. Nonetheless,being able to de- ﬁne the grammar is very useful,so much so that there is a commonly used syn- tax for describing grammars—BNF (Backus–Naur Form). Creating a BNF is the ﬁrst step to creating a parser, and although not formally necessary, for all but the most trivial grammars it should be considered essential.\n\nHere we will describe a very simple subset of BNF syntax that is sufﬁcient for our needs.\n\nIn a BNF there are two kindsof item:terminalsand nonterminals. A terminal is an item which is in its ﬁnal form, for example, a literal number or string. A nonterminal is an item that is deﬁned in terms of zero or more other items (which themselves may be terminals or nonterminals). Every nonterminal must ultimately be deﬁned in terms of zero or more terminals. Figure 14.1 shows an example BNF that deﬁnes the syntax of a ﬁle of “attributes”, to put things into perspective.\n\n★In practice, parsing English and other natural languages is a very difﬁcult problem; see, for example, the Natural Language Toolkit (www.nltk.org) for more information.\n\n515",
      "content_length": 2887,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 523,
      "content": "516\n\nChapter 14. Introduction to Parsing\n\nATTRIBUTE_FILE ::= (ATTRIBUTE '\\n')+ ATTRIBUTE ::= NAME '=' VALUE NAME ::= [a-zA-Z]\\w* VALUE ::= 'true' | 'false' | \\d+ | [a-zA-Z]\\w*\n\nFigure 14.1 A BNF for a ﬁle of attributes\n\nThe symbol ::= means is deﬁned as. Nonterminals are written in uppercase italics (e.g., VALUE).Terminals are either literal strings enclosed in quotes (such as '=' and 'true') or regular expressions (such as \\d+). The deﬁnitions (on the right of the ::=) are made up of one or more terminals or nonterminals—these must be encountered in the sequence given to meet the deﬁnition. However, the vertical bar (|) is used to indicate alternatives, so instead of matching in sequence, matching any one of the alternatives is sufﬁcient to meet the deﬁ- nition. Terminals and nonterminals can be quantiﬁed with ? (zero or one, i.e., optional),+ (oneor more),or * (zeroor more);withoutanexplicitquantiﬁerthey arequantiﬁedtomatchexactly once. Parenthesescanbeusedfor grouping two or more terminalsor nonterminalsthat we want to treat asa unit,for example, to group alternatives or for quantiﬁcation.\n\nA BNF always has a “start symbol”—this is the nonterminal that must be matched by the entire input. We have adopted the convention that the ﬁrst nonterminal is always the start symbol.\n\nIn this example there are four nonterminals,ATTRIBUTE_FILE (the start symbol), ATTRIBUTE, NAME, and VALUE. An ATTRIBUTE_FILE is deﬁned as one or more of an ATTRIBUTE followed by a newline. An ATTRIBUTE is deﬁned as a NAME followed by a literal = (i.e., a terminal), followed by a VALUE. Since both the NAME and VALUE parts are nonterminals, they must themselves be deﬁned. The NAME is deﬁned by a regular expression (i.e., a terminal). The VALUE is deﬁned by any of four alternatives, two literals and two regular expressions (all of which are terminals).Since all the nonterminals are deﬁned in terms of terminals (or in terms of nonterminals which themselves are ultimately deﬁned in terms of terminals), the BNF is complete.\n\nThere is generally more than one way to write a BNF. Figure 14.2 shows an alternative version of the ATTRIBUTE_FILE BNF.\n\nATTRIBUTE_FILE ::= ATTRIBUTE+ ATTRIBUTE ::= NAME '=' VALUE '\\n' NAME ::= [a-zA-Z]\\w* VALUE ::= 'true' | 'false' | \\d+ | NAME\n\nFigure 14.2 An alternativeBNF for a ﬁle of attributes",
      "content_length": 2327,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 524,
      "content": "BNF Syntax and Parsing Terminology\n\nHere we have moved the newline to the end of the ATTRIBUTE nonterminal, thus simplifying the deﬁnition of ATTRIBUTE_FILE.We have also reused the NAME nonterminal in the VALUE—although this is a dubious change since it is mere coincidence that they can both match the same regex. Thisversion of the BNF should match exactly the same text as the ﬁrst one.\n\nOnce we have a BNF we can “test” it mentally or on paper. For example,given thetext“depth = 37\\n”,wecanwork throughtheBNFtoseeif thetextmatch- es,starting withtheﬁrstnonterminal,ATTRIBUTE_FILE.Thisnonterminalbegins by matching another nonterminal, ATTRIBUTE. And the ATTRIBUTE nonterminal begins by matching yet another nonterminal, NAME, which in turn must match the terminal regex, [a-zA-Z]\\w*. The regex does indeed match the beginning of the text, matching “depth”. The next thing that ATTRIBUTE must match is a terminal,theliteral =.And herethematch failsbecause“depth”isfollowedby a space. At thispoint theparser should reportthat thegiven text doesnot match thegrammar. Inthisparticularcasewemusteither ﬁx thedataby eliminating the space before and after the =, or opt to change the grammar—for example, changing the (ﬁrst) deﬁnition of ATTRIBUTE to NAME \\s* = \\s* VALUE. After doing a few paper tests and reﬁning the grammar like this we should have a much clearer idea of what our BNF will and won’t match.\n\nA BNF must be complete to be valid, but a valid BNF is not necessarily a correct one. One problem is with ambiguity—in the example shown here the literal value true matches the VALUE nonterminal’s ﬁrst alternative ('true'), and also itslast alternative([a-zA-Z]\\w*).Thisdoesn’t stopthe BNF frombeing valid, but it is something that a parser implementing the BNF must account for. And aswewill seelater in thischapter,BNFscan becomequitetricky since sometimeswedeﬁnethingsin termsof themselves. Thiscanbeanother source of ambiguity—and can result in unparseable grammars.\n\nPrecedence and associativity are used to decide the order in which operators should be applied in expressions that don’t have parentheses. Precedence is used when there are different operators, and associativity is used when the operators are the same.\n\nFor an example of precedence, the Python expression 3 + 4 * 5 evaluates to 23. This means that * has higher precedence in Python than + because the expression behaved as if it were written 3 + (4 * 5).Another way of saying this is “in Python, * binds more tightly than +”.\n\nFor an example of associativity, the expression 12 / 3 / 2 evaluates to 2. This means that / is left-associative, that is, when an expression contains two or more /s they will be evaluated from left to right. Here, 12 / 3 was evaluated ﬁrst to produce 4 and then 4 / 2 to produce 2. By contrast, the = operator is right-associative, which is why we can write x = y = 5. When there are two or more =s they are evaluated from right to left, so y = 5 is evaluated ﬁrst, giving y a value, and then x = y giving x a value. If = was not right-associative the\n\n517",
      "content_length": 3065,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 525,
      "content": "518\n\nChapter 14. Introduction to Parsing\n\nexpression would fail (assuming that y didn’t exist before) since it would start by trying to assign the value of nonexistent variable y to x.\n\nPrecedence and associativity can sometimes work together. For example, if two different operators have the same precedence (this is commonly the case with + and -), without the use of parentheses, their associativities are all that can be used to determine the evaluation order.\n\nExpressing precedence and associativity in a BNF can be done by composing factors into terms and terms into expressions. For example, the BNF in Figure 14.3 deﬁnes the four basic arithmetic operations over integers, as well asparenthesizedsubexpressions,and all with thecorrect precedencesand (left to right) associativities.\n\nINTEGER ::= \\d+ ADD_OPERATOR ::= '+' | '-' SCALE_OPERATOR ::= '*' | '/' EXPRESSION ::= TERM (ADD_OPERATOR TERM)* TERM ::= FACTOR (SCALE_OPERATOR FACTOR)* FACTOR ::= '-'? (INTEGER | '(' EXPRESSION ')')\n\nFigure 14.3 A BNF for arithmetic operations\n\nThe precedence relationships are set up by the way we combine expressions, terms, and factors,while the associativities are set up by the structure of each of the expression, term, and factor’s nonterminals’ deﬁnitions.\n\nIf we need right to left associativity, we can use the following structure:\n\nPOWER_EXPRESSION ::= FACTOR ('**' POWER_EXPRESSION)*\n\nThe recursive use of POWER_EXPRESSION forces the parser to work right to left.\n\nDealing with precedence and associativity can be avoided altogether: We can simply insist that the data or DSL uses parentheses to make all the relation- shipsexplicit. Although thisis easy to do,it isn’t doing any favorsfor the users of our data format or of our DSL, so we prefer to incorporate precedence and associativity where they are appropriate.★\n\nThere is a lot more to parsing than we have mentioned here—see,for example, the book Parsing Techniques:APracticalGuide,mentioned in thebibliography. Nonetheless,thischaptershouldbesufﬁcienttogetstarted,althoughaddition- al reading is recommended for those planning to create complex and sophisti- cated parsers.\n\n★Another way to avoid precedence and associativity—and which doesn’t require parentheses—is to use a Polish or Reverse Polish notation; see wikipedia.org/wiki/Polish_notation.\n\nBNF",
      "content_length": 2322,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 526,
      "content": "BNF Syntax and Parsing Terminology\n\nNow that we have a passing familiarity with BNF syntax and with some of the terminology used in parsing,we will writesome parsers,starting with ones written by hand.\n\nWriting Handcrafted Parsers\n\nIn this section we will develop three handcrafted parsers. The ﬁrst is little more than an extension of the key–value regex seen in the previous chapter, but shows the infrastructure needed to use such a regex. The second is also regex-based, but is actually a ﬁnite state automata since it has two states. Both the ﬁrst and second examples are data parsers. The third example is a parser for a DSL and uses recursive descent since the DSL allows expressions to be nested. In later sections we will develop new versions of these parsers using PyParsing and PLY, and for the DSL in particular we will see how much easier it is to use a generic parser generator than to handcraft a parser.\n\nSimple Key–Value Data Parsing\n\nprogram can The book’s examples include a program called playlists.py. This read a playlist in .m3u (extended Moving Picture Experts Group Audio Layer 3 Uniform Resource Locator) format,and output an equivalent playlist in .pls (Play List 2) format—or vice versa. In this subsection we will write a parser for .pls format, and in the following subsection we will write a parser for .m3u format. Both parsers are handcrafted and both use regexes.\n\nThe .pls format is essentially the same as Windows .ini format, so we ought to use thestandardlibrary’sconfigparser moduleto parseit. However,the .pls format is ideal for creating a ﬁrst data parser,since itssimplicity leavesusfree to focus on the parsing aspects, so for the sake of example we won’t use the configparser module in this case.\n\nWe will begin by looking at a tiny extract from a .pls ﬁle to get a feel for the data, then we will create a BNF, and then we will create a parser to read the data. The extract is shown in Figure 14.4.\n\nWe have omitted most of the data as indicated by the ellipsis (…). There is only one .ini-style header line, [playlist], with all the other entries in simple key=value format. One unusual aspect is that key names are repeated—but with numbers appended to keep them all unique. Three pieces of data are maintained for each song: the ﬁlename (in this example using Windows path separators), the title, and the duration (called “length”) in seconds. In this particular example, the ﬁrst song has a known duration, but the last entry’s duration is unknown, which is signiﬁed by a negative number.\n\n519\n\n|||\n\n||\n\nPyPars- ing key– value parser ➤ 539\n\nPLY key– value parser ➤ 555",
      "content_length": 2618,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 527,
      "content": "At- tributes BNF 516➤\n\n520\n\nChapter 14. Introduction to Parsing\n\n[playlist] File1=Blondie\\Atomic\\01-Atomic.ogg Title1=Blondie - Atomic Length1=230 ... File18=Blondie\\Atomic\\18-I'm Gonna Love You Too.ogg Title18=Blondie - I'm Gonna Love You Too Length18=-1 NumberOfEntries=18 Version=2\n\nFigure 14.4 An extract from a .pls ﬁle\n\nThe BNF we have created can handle .pls ﬁles,and is actually generic enough to handle similar key–value formats too. The BNF is shown in Figure 14.5.\n\nPLS ::= (LINE '\\n')+ LINE ::= INI_HEADER | KEY_VALUE | COMMENT | BLANK INI_HEADER ::= '[' [^]]+ ']' KEY_VALUE ::= KEY \\s* '=' \\s* VALUE? KEY ::= \\w+ VALUE ::= .+ COMMENT ::= #.* BLANK ::= ^$\n\nFigure 14.5 A BNF for the .pls ﬁle format\n\nThe BNF deﬁnes a PLS as one or more of a LINE followed by newline. Each LINE canbean INI_HEADER,a KEY_VALUE,a COMMENT,or BLANK.The INI_HEADER isdeﬁnedto beanopenbracket,followedby oneor morecharacters(excluding a closebrack- et),followed by a close bracket—we will skip these. The KEY_VALUE is subtly dif- ferent from the ATTRIBUTE in the ATTRIBUTE_FILE example shown in the previous section in that the VALUE is optional; also, here we allow whitespace before and after the =. This means that a line such as “title5=\\n” is valid in this BNF, as well as the ones that we would expect to be valid such as “length=126\\n”.The KEY is a sequence of one or more alphanumeric characters,and the VALUE is any sequence of characters. Comments are Python-style and we will skip them; similarly, blank lines (BLANK) are allowed but will be skipped.\n\nThe purpose of our parser is to populate a dictionary with key–value items matching those in the ﬁle, but with lowercase keys. The playlists.py program uses the parser to obtain a dictionary of playlist data which it then outputs in the requested format. We won’t cover the playlists.py program itself since it",
      "content_length": 1861,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 528,
      "content": "Key– value regex 495➤\n\nenu- merate() function 139➤\n\nWriting Handcrafted Parsers\n\nisn’t relevant to parsing assuch,and in any case it can be downloaded from the book’s web site.\n\nThe parsing is done in a single function that accepts an open ﬁle object (file), and a Boolean (lowercase_keys) that has a default value of False. The function uses two regexes and populates a dictionary (key_values) that it returns. We will look at the regexes and then the code that parses the ﬁle’s lines and that populates the dictionary.\n\nINI_HEADER = re.compile(r\"^\\[[^]]+\\]$\")\n\nAlthough we want to ignore .ini headers we still need to identify them. The regex makes no allowance for leading or trailing whitespace—this is because we will be stripping whitespace from each line that is read so there will never be any. The regex itself matches the start of the line, then an open bracket, then one or more characters (but not close brackets), then a close bracket, and ﬁnally, the end of the line.\n\nKEY_VALUE_RE = re.compile(r\"^(?P<key>\\w+)\\s*=\\s*(?P<value>.*)$\")\n\nbut we only The KEY_VALUE_RE regex allows for whitespace around the = sign, capture the actual key and value. The value is quantiﬁed by * so can be empty. Also, we use named captures since these are clearer to read and easier to maintain because they are not affected by new capture groups being added or removed—something that would affect us if we used numbers to identify the capture groups.\n\nkey_values = {} for lino, line in enumerate(file, start=1):\n\nline = line.strip() if not line or line.startswith(\"#\"):\n\ncontinue\n\nkey_value = KEY_VALUE_RE.match(line) if key_value:\n\nkey = key_value.group(\"key\") if lowercase_keys:\n\nkey = key.lower()\n\nkey_values[key] = key_value.group(\"value\")\n\nelse:\n\nini_header = INI_HEADER.match(line) if not ini_header:\n\nprint(\"Failed to parse line {0}: {1}\".format(lino,\n\nline))\n\nWe process the ﬁle’s contents line by line, using the built-in enumerate() function to return 2-tuplesof the line number (starting from 1as is traditional whendealing with textﬁles),andthelineitself. Westripoff whitespacesothat\n\n521",
      "content_length": 2093,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 529,
      "content": "522\n\nChapter 14. Introduction to Parsing\n\nwecan immediately skipblank lines(and useslightly simpler regexes);wealso skip comment lines.\n\nSince we expect most lines to be key=value lines, we always try to match the KEY_VALUE_RE regex ﬁrst. If this succeedswe extract the key,and lowercase it if necessary. Then we add the key and the value to the dictionary.\n\nIf the line is not a key=value line, we try to match a .ini header—and if we get a match we simply ignore it and continue to the next line; otherwise we report an error. (It would be quite straightforward to create a dictionary whose keys are .ini headers and whose values are dictionaries of the headers’ key–values—but if we want to go that far, we really ought to use the config- parser module.)\n\nThe regexes and the code are quite straightforward—but they are dependent on each other. For example, if we didn’t strip whitespace from each line we would have to change the regexes to allow for leading and trailing whitespace. Here we found it more convenient to strip the whitespace, but there may be occasions where we do things the other way round—there is no one single correct approach.\n\nAt the end (not shown), we simply return the key_values dictionary. One dis- advantage of using a dictionary in this particular case is that every key–value pair is distinct, whereas in fact, items with keys that end in the same number (e.g., “title12”, “ﬁle12”, and “length12”) are logically related. The playlists.py program has a function (songs_from_dictionary(), not shown, but in the book’s source code) that reads in a key–value dictionary of the kind returned by the codeshown hereand returnsa list of song tuples—something wewill dodirect- ly in the next subsection.\n\nPlaylist Data Parsing\n\nread The playlists.py program mentioned in the previous subsection can and write .pls format ﬁles. In this subsection we will write a parser that can read ﬁles in .m3u format and that returns its results in the form of a list of collections.namedtuple() objects, each of which holds a title, a duration in seconds, and a ﬁlename.\n\nAs usual, we will begin by looking at an extract of the data we want to parse, then we will create a suitable BNF, and ﬁnally we will create a parser to parse the data. The data extract is shown in Figure 14.6.\n\nWe have omitted most of the data asindicated by the ellipsis(…).The ﬁle must begin with the line #EXTM3U. Each entry occupies two lines. The ﬁrst line of an entry starts with #EXTINF: and provides the duration in seconds and the title. The second line of an entry has the ﬁlename. Just like with .pls format, a negative duration signiﬁes that the duration is unknown.\n\n||\n\nPyPars- ing .m3u parser ➤ 541\n\nPLY .m3u parser ➤ 557",
      "content_length": 2722,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 530,
      "content": "Named tuples 111➤\n\nWriting Handcrafted Parsers\n\n523\n\n#EXTM3U #EXTINF:230,Blondie - Atomic Blondie\\Atomic\\01-Atomic.ogg ... #EXTINF:-1,Blondie - I'm Gonna Love You Too Blondie\\Atomic\\18-I'm Gonna Love You Too.ogg\n\nFigure 14.6 An extract from a .m3u ﬁle\n\nThe BNF is shown in Figure 14.7. It deﬁnes a M3U as the literal text #EXTM3U followed by a newline and then one or more ENTRYs. Each ENTRY consists of an INFO followedby a newlinethena FILENAME followedby a newline. An INFO starts with theliteraltext #EXTINF: followed by thedurationspeciﬁedby SECONDS,then a comma, and then the TITLE. The SECONDS is deﬁned as an optional minus sign followed by one or more digits. Both the TITLE and FILENAME are loosely deﬁned as sequences of any characters except newlines.\n\nM3U ::= '#EXTM3U\\n' ENTRY+ ENTRY ::= INFO '\\n' FILENAME '\\n' INFO ::= '#EXTINF:' SECONDS ',' TITLE SECONDS ::= '-'? \\d+ TITLE ::= [^\\n]+ FILENAME ::= [^\\n]+\n\nFigure 14.7 A BNF for the .m3u format\n\nBefore reviewing the parser itself,we will ﬁrst look at the named will use to store each result:\n\ntuple that we\n\nSong = collections.namedtuple(\"Song\", \"title seconds filename\")\n\nThis is much more convenient than using a dictionary with keys like “ﬁle5”, “title17”,and so on,and where we have to write code to match up all those keys that end in the same number.\n\nWe will review the parser’s code in four very short parts for ease of expla- nation.\n\nif fh.readline() != \"#EXTM3U\\n\":\n\nprint(\"This is not a .m3u file\") return []\n\nsongs = [] INFO_RE = re.compile(r\"#EXTINF:(?P<seconds>-?\\d+),(?P<title>.+)\")",
      "content_length": 1565,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 531,
      "content": "524\n\nChapter 14. Introduction to Parsing\n\nWANT_INFO, WANT_FILENAME = range(2) state = WANT_INFO\n\nThe open ﬁle object is in variable fh. If the ﬁle doesn’t start with the correct text for a .m3u ﬁle we output an error message and return an empty list.\n\nThe Song namedtupleswillbestoredinthe songs list. Theregex isfor matching the BNF’s INFO nonterminal. The parser itself is always in one of two states, either WANT_INFO (the start state) or WANT_FILENAME. In the WANT_INFO state the parser tries to get the title and seconds, and in the WANT_FILENAME state the parser creates a new Song and adds it to the songs list.\n\nfor lino, line in enumerate(fh, start=2):\n\nline = line.strip() if not line: continue\n\nWe iterate over each line in the given open ﬁle object in a similar way to what we did for the .pls parser in the previous subsection, only this time we start the line numbers from 2 since we handle line 1 before entering the loop. We strip whitespace and skip blank lines, and do further processing depending on which state we are in.\n\nif state == WANT_INFO:\n\ninfo = INFO_RE.match(line) if info:\n\ntitle = info.group(\"title\") seconds = int(info.group(\"seconds\")) state = WANT_FILENAME\n\nelse:\n\nprint(\"Failed to parse line {0}: {1}\".format(\n\nlino, line))\n\nIf we are expecting an INFO line we attempt to match the INFO_RE regex to extract the title and the number of seconds. Then we change the parser’sstate so that it expectsthe next line to be the corresponding ﬁlename. We don’t have to check that the int() conversion works (e.g., by using a try … except), since the text used in the conversion always matches a valid integer because of the regex pattern (-?\\d+).\n\nelif state == WANT_FILENAME:\n\nsongs.append(Song(title, seconds, line)) title = seconds = None state = WANT_INFO\n\nIf we are expecting a FILENAME line we simply append a new Song with the previously set title and seconds, and with the current line as the ﬁlename.",
      "content_length": 1934,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 532,
      "content": "Writing Handcrafted Parsers\n\nWe then restore the parser’s state to its start state ready to parse another song’s details.\n\nAt the end (not shown),we return the songs list to the caller. And thanksto the use of named tuples, each song’s attributes can be conveniently accessed by name, for example, songs[12].title.\n\nKeeping track of state using a variable as we have done here works well in many simple cases. But in general this approach is insufﬁcient for dealing with data or DSLs that can contain nested expressions. In the next subsection we will see how to maintain state in the face of nesting.\n\nParsing the Blocks Domain-Speciﬁc Language\n\nThe blocks.py program is provided as one of the book’s examples. It reads one format—blocks format, a made-up or more .blk ﬁles that use a custom text language—that are speciﬁed on the command line, and for each one creates an SVG (Scalable Vector Graphics) ﬁle with the same name, but with its sufﬁx changed to .svg. While the rendered SVG ﬁles could not be accused of being pretty, they provide a good visual representation that makes it easy to see mistakesin the .blk ﬁles,aswellasshowing thepotentiality thateven a simple DSL can make possible.\n\n[] [lightblue: Director] // [] [lightgreen: Secretary] // [Minion #1] [] [Minion #2]\n\nFigure 14.8 The hierarchy.blkﬁle\n\nFigure 14.8 shows the complete hierarchy.blk ﬁle, and Figure 14.9 shows how the hierarchy.svg ﬁle that the blocks.py program produces is rendered.\n\nThe blocks format has essentially two elements: blocks and new row markers. Blocks are enclosed in brackets. Blocks may be empty, in which case they are used as spacers occupying one cell of a notional grid. Blocks may also contain text and optionally a color. New row markers are forward slashes and they indicate where a new row should begin. In Figure 14.8 two new row markers are used each time and this is what creates the two blank rows that are visible in Figure 14.9.\n\nThe blocks format also allows blocks to be nested inside one another, simply by including blocks and new row markers inside a block’s brackets, after the block’s text.\n\n525\n\n||\n\nPy- Parsing blocks parser ➤ 543\n\nPLY blocks parser ➤ 559",
      "content_length": 2177,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 533,
      "content": "526\n\nChapter 14. Introduction to Parsing\n\nFigure 14.9 The hierarchy.svg ﬁle\n\nFigure 14.10showsthe complete messagebox.blk ﬁle in which blocksare nested, and Figure 14.11 shows how the messagebox.svg ﬁle is rendered.\n\n[#00CCDE: MessageBox Window [lightgray: Frame [] [white: Message text] // [goldenrod: OK Button] [] [#ff0505: Cancel Button] / [] ] ]\n\nFigure 14.10 The messagebox.blk ﬁle\n\nColors can be speciﬁed using the names supported by the SVG format, or as hexadecimal values (indicated by a leading #). The blocks ﬁle shown in Figure 14.10 has one outer block (“MessageBox Window”), an inner block (“Frame”),and severalblocksand newrowmarkersinsidetheinner block. The whitespace is used purely to make the structureclearer to human readers;it is ignored by the blocks format.\n\nFigure 14.11 The messagebox.svg ﬁle",
      "content_length": 819,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 534,
      "content": "Writing Handcrafted Parsers\n\nNow that we have seen a couple of blocks ﬁles, we will look at the blocks BNF to more formally understand what constitutes a valid blocks ﬁle and as prepa- ration for parsing this recursive format. The BNF is shown in Figure 14.12.\n\nBLOCKS ::= NODES+ NODES ::= NEW_ROW* \\s* NODE+ NODE ::= '[' \\s* (COLOR ':')? \\s* NAME? \\s* NODES* \\s* ']' COLOR ::= '#' [\\dA-Fa-f]{6} | [a-zA-Z]\\w* NAME ::= [^][/]+ NEW_ROW ::= '/'\n\nFigure 14.12 A BNF for the .blk format\n\nThe BNF deﬁnes a BLOCKS ﬁle as having one or more NODES. A NODES consists of zero or more NEW_ROWs followed by one or more NODEs. A NODE is a left bracket followed by an optional COLOR followed by an optional NAME followed by zero or more NODES followed by a right square bracket. The COLOR is simply a hash (pound)symbolfollowed by six hexadecimaldigitsand a colon,or a sequenceof oneor morealphanumericcharactersthat beginswith an alphabeticcharacter, and followedby a colon. The NAME isa sequenceof any charactersbut excluding brackets or forward slashes. A NEW_ROW is a literal forward slash. As the many occurrencesof \\s* suggest,whitespaceisallowed anywherebetween terminals and nonterminals and is of no signiﬁcance.\n\nThe deﬁnition of the NODE nonterminal is recursive because it contains the NODES nonterminal which itself is deﬁned in terms of the NODE nonterminal. Recursive deﬁnitions like this are easy to get wrong and can lead to parsers that loop endlessly, so it might be worthwhile doing some paper-based testing to make sure the grammar does terminate, that is, that given a valid input the grammar will reach all terminals rather than endlessly looping from one nonterminal to another.\n\nPreviously, once we had a BNF, we have dived straight into creating a parser and doing the processing as we parse. This isn’t practical for recursive gram- mars because of the potential for elements to be nested. What we will need to do is to create a class to represent each block (or new row) and that can hold a list of nested child blocks,which themselvesmight contain children,and so on. We can then retrieve the parser’sresultsas a list (which will contain listswith- in lists as necessary to represent nested blocks), and we can convert this list into a tree with an “empty” root block and all the other blocks as its children.\n\nIn the case of the hierarchy.blk example, the root block has a list of new rows and of child blocks (including empty blocks),none of which have any children. This is illustrated in Figure 14.13—the hierarchy.blk ﬁle was shown earlier (525 ➤). The messagebox.blk example has a root block that has one child block (the “MessageBox Window”), which itself has one child block (the “Frame”),\n\n527",
      "content_length": 2717,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 536,
      "content": "Lambda func- tions 182➤\n\nWriting Handcrafted Parsers\n\nblock has no name and the color white. The children list contains Blocks and Nones—the latter representing new row markers. Rather than rely on users of the Block class remembering all of these conventions, we have provided some module methods to abstract them away.\n\nclass Block:\n\ndef __init__(self, name, color=\"white\"):\n\nself.name = name self.color = color self.children = []\n\ndef has_children(self):\n\nreturn bool(self.children)\n\nThe Block class is very simple. The has_children() method is provided as a convenience for the BlockOutput.py module. We haven’t provided any explicit API for adding children, since clients are expected to work directly with the children list attribute.\n\nget_root_block = lambda: Block(None, None) get_empty_block = lambda: Block(\"\") get_new_row = lambda: None is_new_row = lambda x: x is None\n\nThese four tiny helper functions provide abstractions for the Block class’s conventions. They mean that programmersusing the Block module don’t have to remember the conventions, just the functions,and also give us a little bit of wiggle room should we decide to change the conventions later on.\n\nNow that we have the Block class and supporting functions (all deﬁned in the Block.py module ﬁle imported by the blocks.py program that containsthe pars- er),we are ready to write a .blk parser. The parser will create a root block and populate it with children (and children’schildren,etc.),to represent the parsed .blk ﬁle,and which can then be passed to the BlockOutput.save_blocks_as_svg() function.\n\nThe parser is a recursive descent parser—this is necessary because the blocks format can contain nested blocks. The parser consists of a Data class that is initialized with the text of the ﬁle to be parsed and that keeps track of the current parse position and provides methods for advancing through the text. In addition, the parser has a group of parse functions that operate on an instance of the Data class, advancing through the data and populating a stack of Blocks. Some of these functions call each other recursively, reﬂecting the recursive nature of the data which is also reﬂected in the BNF.\n\n529",
      "content_length": 2190,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 537,
      "content": "530\n\nChapter 14. Introduction to Parsing\n\nWe will begin by looking at the Data class,then we will see how the classisused and the parsing started, and then we will review each parsing function as we encounter it.\n\nclass Data:\n\ndef __init__(self, text): self.text = text self.pos = 0 self.line = 1 self.column = 1 self.brackets = 0 self.stack = [Block.get_root_block()]\n\nThe Data class holds the text of the ﬁle we are parsing, the position we are up to (self.pos),and the(1-based)line and column thisposition represents. It also keepstrack of the brackets(adding one to the count for every open bracket and subtracting one for every close bracket).The stack is a list of Blocks,initialized with an empty root block. At theendwewillreturntheroot block—if theparse was successful this block will have child blocks (which may have their own child blocks, etc.), representing the blocks data.\n\ndef location(self):\n\nreturn \"line {0}, column {1}\".format(self.line,\n\nself.column)\n\nThis is a tiny convenience method to return the current location as a string containing the line and column numbers.\n\ndef advance_by(self, amount):\n\nfor x in range(amount):\n\nself._advance_by_one()\n\nThe parser needs to advance through the text as it parses. For convenience, several advancing methods are provided; this one advances by the given number of characters.\n\ndef _advance_by_one(self):\n\nself.pos += 1 if (self.pos < len(self.text) and self.text[self.pos] == \"\\n\"): self.line += 1 self.column = 1\n\nelse:\n\nself.column += 1",
      "content_length": 1503,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 538,
      "content": "Writing Handcrafted Parsers\n\nAll the advancing methods use this private method to actually advance the parser’s position. This means that the code to keep the line and column numbers up-to-date is kept in one place.\n\ndef advance_to_position(self, position):\n\nwhile self.pos < position: self._advance_by_one()\n\nThis method advances to a given index position in the text, again using the private _advance_by_one() method.\n\ndef advance_up_to(self, characters):\n\nwhile (self.pos < len(self.text) and\n\nself.text[self.pos] not in characters and self.text[self.pos].isspace()):\n\nself._advance_by_one()\n\nif not self.pos < len(self.text):\n\nreturn False\n\nif self.text[self.pos] in characters:\n\nreturn True\n\nraise LexError(\"expected '{0}' but got '{1}'\"\n\n.format(characters, self.text[self.pos]))\n\nThis method advances over whitespace until the character at the current position is one of those in the given string of characters. It differs from the other advancemethodsin that it can fail (sinceit might reach a nonwhitespace character that is not one of the expected characters); it returns a Boolean to indicate whether it succeeded.\n\nclass LexError(Exception): pass\n\nThisexception classisused internally by the parser. We prefer to use a custom exception rather than,say,ValueError,because it makesit easier to distinguish our own exceptions from Python’s when debugging.\n\ndata = Data(text) try:\n\nparse(data)\n\nexcept LexError as err:\n\nraise ValueError(\"Error {{0}}:{0}: {1}\".format(\n\ndata.location(), err))\n\nreturn data.stack[0]\n\nThe top-level parsing is quite simple. We create an instance of the Data class based on the text we want to parseand then we call the parse() function (which we will see in a moment) to perform the parsing. If an error occurs a custom LexError is raised; we simply convert this to a ValueError to insulate any caller\n\n531",
      "content_length": 1844,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 539,
      "content": "532\n\nChapter 14. Introduction to Parsing\n\nfrom the internal exceptionswe use. Unusually,the error message containsan escaped str.format() ﬁeld name—the caller is expected to use thisto insert the ﬁlename,something we cannot do herebecauseweareonly given theﬁle’stext, not the ﬁlename or ﬁle object.\n\nAt the end we return the root block, which should have children (and their children) representing the parsed blocks.\n\ndef parse(data):\n\nwhile data.pos < len(data.text):\n\nif not data.advance_up_to(\"[]/\"):\n\nbreak\n\nif data.text[data.pos] == \"[\":\n\ndata.brackets += 1 parse_block(data)\n\nelif data.text[data.pos] == \"/\":\n\nparse_new_row(data)\n\nelif data.text[data.pos] == \"]\":\n\ndata.brackets -= 1 data.advance_by(1)\n\nelse:\n\nraise LexError(\"expecting '[', ']', or '/'; \"\n\n\"but got '{0}'\".format(data.text[data.pos]))\n\nif data.brackets:\n\nraise LexError(\"ran out of text when expecting '{0}'\"\n\n.format(']' if data.brackets > 0 else '['))\n\nThis function is the heart of the recursive descent parser. It iterates over the text looking for the start or end of a block or a new row marker. If it reaches the start of a block it increments the brackets count and calls parse_block(); if it reaches a new row marker it calls parse_new_row(); and if it reaches the end of a block it decrementsthe bracketscount and advancesto the next character. If any other character is encountered it is an error and is reported accordingly. Similarly, when all the data has been parsed, if the brackets count is not zero the function reports the error.\n\ndef parse_block(data): data.advance_by(1) nextBlock = data.text.find(\"[\", data.pos) endOfBlock = data.text.find(\"]\", data.pos) if nextBlock == -1 or endOfBlock < nextBlock:\n\nparse_block_data(data, endOfBlock)\n\nelse:\n\nblock = parse_block_data(data, nextBlock)",
      "content_length": 1782,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 540,
      "content": "Writing Handcrafted Parsers\n\ndata.stack.append(block) parse(data) data.stack.pop()\n\nThis function begins by advancing by one character (to skip the start-of-block open bracket).It then looksfor thenext startof block and thenext end of block. If there is no following block or if the next end of block is before the start of another block then thisblock doesnot haveany nested blocks,sowecan simply call parse_block_data() and give it an end position of the end of this block.\n\nIf this block does have one or more nested blocks inside it we parse this block’s data up to where its ﬁrst nested block begins. We then push this block onto the stack of blocksand recursively call the parse() function to parse the nested block (or blocks—andtheir nestedblocks,etc.).Andat theendwepopthisblock off the stack since all the nesting has been handled by the recursive calls.\n\ndef parse_block_data(data, end):\n\ncolor = None colon = data.text.find(\":\", data.pos) if -1 < colon < end:\n\ncolor = data.text[data.pos:colon] data.advance_to_position(colon + 1)\n\nname = data.text[data.pos:end].strip() data.advance_to_position(end) if not name and color is None:\n\nblock = Block.get_empty_block()\n\nelse:\n\nblock = Block.Block(name, color)\n\ndata.stack[-1].children.append(block) return block\n\nThisfunction isused to parse one block’sdata—upto the given end point in the text—and to add a corresponding Block object to the stack of blocks.\n\nWe start by trying to ﬁnd a color, and if we ﬁnd one, we advance over it. Next we try to ﬁnd the block’s text (its name), although this can legitimately be empty. If we have a block with no name or color we create an empty Block; otherwise we create a Block with the given name and color.\n\nOncethe Block hasbeen createdweaddit asthelastchildof thestack of block’s top block. (Initially the top block is the root block,but if we have nested blocks it could besomeother block that hasbeen pushedon top.) At theend wereturn the block so that it can be pushed onto the stack of blocks—something we do only if the block has other blocks nested inside it.\n\ndef parse_new_row(data):\n\ndata.stack[-1].children.append(Block.get_new_row()) data.advance_by(1)\n\n533",
      "content_length": 2170,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 541,
      "content": "534\n\nChapter 14. Introduction to Parsing\n\nThis is the easiest of the parsing functions. It simply adds a new row as the last child of the stack of block’stop block,and advancesover the new row char- acter.\n\nThis completes the review of the blocks recursive descent parser. The parser does not require a huge amount of code, fewer than 100 lines, but that’s still more than 50 percent more lines than the PyParsing version needs, and about 33 percent more lines than the PLY version needs. And as we will see, using PyParsing or PLY is much easier than handcrafting a recursive descent parser—and they also lead to parsers that are much easier to maintain.\n\nThe conversion into an SVG ﬁle using the BlockOutput.save_blocks_as_svg() function is the same for all the blocks parsers, since they all produce the same root block and children structures. We won’t review the function’s code since it isn’t relevant to parsing as such—it is in the BlockOutput.py module ﬁle that comes with the book’s examples.\n\nWe have now ﬁnished reviewing the handcrafted parsers. In the following two sections we will show PyParsing and PLY versions of these parsers. In addi- tion, we will show a parser for a DSL that would need a quite sophisticated recursive descent parser if we did it by hand,and that really showsthat as our needs grow, using a generic parser scales much better than a handcrafted so- lution.\n\nPythonic Parsing with PyParsing\n\nWriting recursive descent parsers by hand can be quite tricky to get right,and if we need to create many parsers it can soon become tedious both to write them and especially to maintain them. One obvioussolution isto use a generic parsing module, and those experienced with BNFs or with the Unix lex and yacc tools will naturally gravitate to similar tools. In the section following this one we cover PLY (Python Lex Yacc), a tool that exempliﬁes this classic approach. But in this section we will look at a very different kind of parsing tool: PyParsing.\n\nPyParsingisdescribedby itsauthor,PaulMcGuire,as“analternativeapproach to creating and executing simple grammars, vs. the traditional lex/yacc ap- proach, or the use of regular expressions”. (Although in fact, regexes can be used with PyParsing.) For those used to the traditional approach, PyParsing requires some reorientation in thinking. The payback is the ability to develop parsersthat do not require a lot of code—thanksto PyParsing providing many high-level elementsthatcan matchcommonconstructs—andwhich areeasy to understand and maintain.\n\nPyParsing is available under an open source license and can be used in both noncommercial and commercial contexts. However, PyParsing is not\n\n|||",
      "content_length": 2681,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 542,
      "content": "Pythonic Parsing with PyParsing\n\nincluded in Python’s standard library, so it must be downloaded and in- stalled separately—although for Linux users it is almost certainly available through the package management system. It can be obtained from pypars- ing.wikispaces.com—click the page’s Download link. It comes in the form of an executable installation program for Windows and in source form for Unix-like systems such as Linux and Mac OS X. The download page explains how to in- stall it. PyParsing is contained in a single module ﬁle, pyparsing_py3.py, so it can easily be distributed with any program that uses it.\n\nA Quick Introduction to PyParsing\n\nPyParsing makes no real distinction between lexing and parsing. Instead, it providesfunctionsand classestocreateparser elements—oneelement for each thing tobematched. Someparserelementsareprovidedpredeﬁnedby PyPars- ing,otherscanbecreatedby calling PyParsingfunctionsorby instantiatingPy- Parsing classes. Parserelementscanalsobecreatedby combiningotherparser elementstogether—forexample,concatenating themwith + toforma sequence of parser elements, or OR-ing them with | to form a set of parser element al- ternatives. Ultimately,a PyParsing parser is simply a collection of parser ele- ments (which themselves may be made up of parser elements, etc.), composed together.\n\nIf we want to processwhat we parse,we can processthe resultsthat PyParsing returns, or we can add parse actions (code snippets) to particular parser elements, or some combination of both.\n\nPyParsing provides a wide range of parser elements, of which we will brieﬂy describe some of the most commonly used. The Literal() parser element matches the literal text it is given, and CaselessLiteral() does the same thing but ignores case. If we are not interested in some part of the grammar we can use Suppress(); this matches the literal text (or parser element) it is given, but does not add it to the results.\n\nThe Keyword() element is almost the same as Literal() except that it must be followed by a nonkeyword character—this prevents a match where a keyword is a preﬁx of something else. For example, given the data text, “ﬁlename”, Literal(\"file\") will match filename, with the name part left for the next parser element to match, but Keyword(\"file\") won’t match at all.\n\nAnother important parser element is Word(). This element is given a string that it treats as a set of characters,and will match any sequence of any of the given characters. For example, given the data text, “abacus”, Word(\"abc\") will match abacus. If the Word() element is given two strings, the ﬁrst is taken to contain those charactersthat are valid for the ﬁrst character of the match and the second to contain those characters that are valid for the remaining char- acters. This is typically used to match identiﬁers—for example, Word(alphas,\n\n535\n\n||",
      "content_length": 2859,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 543,
      "content": "536\n\nChapter 14. Introduction to Parsing\n\nalphanums) matches text that starts with an alphabetic character and that is followed by zero or more alphanumeric characters. (Both alphas and alphanums are predeﬁned strings of characters provided by the PyParsing module.)\n\nA lessfrequently used alternativeto Word() is CharsNotIn().Thiselement isgiv- en a string that it treats as a set of characters, and will match all the charac- ters from the current parse position onward until it reaches a character from the given set of characters. It does not skip whitespace and it will fail if the current parse character is in the given set, that is, if there are no characters to accumulate. Two other alternatives to Word() are also used. One is Skip- To(); this is similar to CharsNotIn() except that it skips whitespace and it al- ways succeeds—even if it accumulates nothing (an empty string).The other is Regex() which is used to specify a regex to match.\n\nPyParsing also has various predeﬁned parser elements, including restOfLine that matches any characters from the point the parser has reached until the end of the line, pythonStyleComment which matches a Python-style comment, quotedString that matches a string that’s enclosed in single or double quotes (with the start and end quotes matching), and many others.\n\nThere are also many helper functions provided to cater for common cases. For example,the delimitedList() function returnsa parser element that matchesa list of itemswith a given delimiter,and makeHTMLTags() returnsa pair of parser elements to match a given HTML tag’s start and end, and for the start also matches any attributes the tag may have.\n\nParsing elements can be quantiﬁed in a similar way to regexes, using Option- al(), ZeroOrMore(), OneOrMore(), and some others. If no quantiﬁer is speciﬁed, the quantity defaults to 1. Elements can be grouped using Group() and com- bined using Combine()—we’ll see what these do further on.\n\nOnce we have speciﬁed all of our individual parser elements and their quan- tities, we can start to combine them to make a parser. We can specify parser elements that must follow each other in sequence by creating a new parser el- ement that concatenates two or more existing parser elements together—for example, if we have parser elements key and value we can create a key_value parser element by writing key_value = key + Suppress(\"=\") + value.We can spec- ify parser elements that can match any one of two or more alternatives by creating a new parser element that ORs two or more existing parser elements together—forexample,if wehaveparserelementstrue and false wecancreate a boolean parser element by writing boolean = true | false.\n\nNotice that for the key_value parser element we did not need to say anything about whitespace around the =. By default, PyParsing will accept any amount of whitespace (including none) between parser elements, so for example, PyParsing treats the BNF deﬁnition KEY '=' VALUE as if it were written \\s* KEY \\s* '=' \\s* VALUE \\s*. (This default behavior can be switched off, of course.)",
      "content_length": 3077,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 544,
      "content": "Pythonic Parsing with PyParsing\n\nNote that here and in the subsections that follow, we import each PyParsing name that we need individually. For example:\n\nfrom pyparsing_py3 import (alphanums, alphas, CharsNotIn, Forward,\n\nGroup, hexnums, OneOrMore, Optional, ParseException, ParseSyntaxException, Suppress, Word, ZeroOrMore)\n\nThis avoids using the import * syntax which can pollute our namespace with unwanted names, but at the same time affords us the convenience to write alphanums and Word() rather than pyparsing_py3.alphanums and pypars- ing_py3.Word(), and so on.\n\nBefore we ﬁnish this quick introduction to PyParsing and look at the examples in the following subsections, it is worth noting a couple of important ideas relating to how we translate a BNF into a PyParsing parser.\n\nPyParsing has many predeﬁned elements that can match common constructs. We should always use these elements wherever possible to ensure the best possible performance. Also, translating BNFs directly into PyParsing syntax is not always the right approach. PyParsing has certain idiomatic ways of handling particular BNF constructs, and we should always follow these to ensure that our parser runs efﬁciently. Here we’ll very brieﬂy review a few of the predeﬁned elements and idioms.\n\nOne common BNF deﬁnition is where we have an optional item. For example:\n\nOPTIONAL_ITEM ::= ITEM | EMPTY\n\nIf we translated this directly into PyParsing we would write:\n\noptional_item = item | Empty() # WRONG!\n\nThis assumes that item is some parser element deﬁned earlier. The Empty() class provides a parser element that can match nothing. Although syntacti- cally correct, this goes against the grain of how PyParsing works. The correct PyParsing idiom is much simpler and involves using a predeﬁned element:\n\noptional_item = Optional(item)\n\nSome BNF statementsinvolvedeﬁning an item in termsof itself. For example, to represent a list of variables(perhapsthe argumentsto a function),we might have the BNF:\n\nVAR_LIST ::= VARIABLE | VARIABLE ',' VAR_LIST VARIABLE ::= [a-zA-Z]\\w*\n\nAt ﬁrst sight we might be tempted to translate this directly into PyParsing syntax:\n\n537\n\nBNF\n\nBNF",
      "content_length": 2150,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 545,
      "content": "538\n\nChapter 14. Introduction to Parsing\n\nvariable = Word(alphas, alphanums) var_list = variable | variable + Suppress(\",\") + var_list # WRONG!\n\nThe problem seems to be simply a matter of Python syntax—we can’t refer to var_list before we have deﬁned it. PyParsing offers a solution to this: We can create an “empty” parser element using Forward(), and then later on we can append parse elements—including itself—to it. So now we can try again.\n\nvar_list = Forward() var_list << (variable | variable + Suppress(\",\") + var_list) # WRONG!\n\nThis second version is syntactically valid, but again, it goes against the grain of how PyParsing works—and as part of a larger parser its use could lead to a parser that is very slow, or that simply doesn’t work. (Note that we must use parentheses to ensure that the whole right-hand expression is appended and not just the ﬁrst part because << has a higher precedence level than |,that is, it binds more tightly than |.) Although its use is not appropriate here, the Forward() class is very useful in other contexts,and we will use it in a couple of the examples in the following subsections.\n\nInstead of using Forward() in situations like this, there are alternative coding patterns that go with the PyParsing grain. Here is the simplest and most literal version:\n\nvar_list = variable + ZeroOrMore(Suppress(\",\") + variable)\n\nThis pattern is ideal for handling binary operators, for example:\n\nplus_expression = operand + ZeroOrMore(Suppress(\"+\") + operand)\n\nBoth of these kindsof usage are so common that PyParsing offersconvenience functions that provide suitable parser elements. We will look at the operator- Precedence() function that is used to create parser elements for unary, binary, and ternary operators in the example in the last of the following subsections. For delimited lists, the convenience function to use is delimitedList(), which we will show now, and which we will use in an example in the following sub- sections:\n\nvar_list = delimitedList(variable)\n\nThe delimitedList() function takes a parser element and an optional delimiter—we didn’t need to specify the delimiter in this case because the de- fault is comma, the delimiter we happen to be using.\n\nSo far thediscussionhasbeen fairly abstract. In thefollowing four subsections wewillcreatefour parsers,each of increasing sophistication,thatdemonstrate how to make the best use of the PyParsing module. The ﬁrst three parsers are PyParsing versions of the handcrafted parsers we created in the previous",
      "content_length": 2516,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 546,
      "content": "Hand- crafted key– value parser 519➤\n\nFunc- tional- style pro- gramm- ing 395➤\n\nPythonic Parsing with PyParsing\n\nsection;the fourth parser is new and much more complex,and is shown in this section, and in lex/yacc form in the following section.\n\nSimple Key–Value Data Parsing\n\nregex-based In the previous section’sﬁrst subsection we created a handcrafted key–value parser that was used by the playlists.py program to read .pls ﬁles. In thissubsectionwe will createa parser to do the samejob,but thistimeusing the PyParsing module.\n\nAs before,the purpose of our parser is to populate a dictionary with key–value items matching those in the ﬁle, but with lowercase keys. An extract from a .pls ﬁle is shown in Figure 14.4 (520 ➤), and the BNF is shown in Figure 14.5 (520➤).Since PyParsing skips whitespace by default,we can ignore the BNF’s BLANK nonterminal and optional whitespace (\\s*).\n\nWe will look at the code in three parts: ﬁrst, the creation of the parser itself; second, a helper function used by the parser; and third, the call to the parser to parse a .pls ﬁle. All the code is quoted from the ReadKeyValue.py module ﬁle that is imported by the playlists.py program.\n\nkey_values = {} left_bracket, right_bracket, equals = map(Suppress, \"[]=\") ini_header = left_bracket + CharsNotIn(\"]\") + right_bracket key_value = Word(alphanums) + equals + restOfLine key_value.setParseAction(accumulate) comment = \"#\" + restOfLine parser = OneOrMore(ini_header | key_value) parser.ignore(comment)\n\nFor this particular parser, instead of reading the results at the end we will accumulate results as we go, populating the key_values dictionary with each key=value we encounter.\n\nThe left and right bracketsand the equals signs are important elements of the grammar, but are of no interest in themselves. So for each of them we create a Suppress() parser element—this will match the appropriate character, but won’t include the character in the results. (We could have written each of them individually, for example, as left_bracket = Suppress(\"[\"), and so on, but using the built-in map() function is more convenient.)\n\nThe deﬁnition of the ini_header parser element follows quite naturally from the BNF: a left bracket, then any characters except a right bracket, and then a right bracket. We haven’t deﬁned a parse action for this parser element, so although the parser will match any occurrences that it encounters, nothing will be done with them, which is what we want.\n\n539\n\n||\n\nPLY key– value parser ➤ 555",
      "content_length": 2506,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 547,
      "content": "540\n\nChapter 14. Introduction to Parsing\n\nThekey_valueparserelementistheonewearereallyinterestedin. Thismatch- es a “word”—a sequence of alphanumeric characters, followed by an equals sign, followed by the rest of the line (which may be empty). The restOfLine is a predeﬁned parser element supplied by PyParsing. Since we want to ac- cumulate results as we go we add a parse action (a function reference) to the key_value parser element—this function will be called for every key=value that is matched.\n\nAlthough PyParsing provides a predeﬁned pythonStyleComment parser element, here we prefer the simpler Literal(\"#\") followed by the rest of the line. (And thanks to PyParsing’s smart operator overloading we were able to write the literal # as a string because when we concatenated it with another parser element to producethe comment parser element,PyParsing promoted the # to be a Literal().)\n\nThe parser itself is a parser element that matches one or more ini_header or key_value parser elements, and that ignores comment parser elements.\n\ndef accumulate(tokens): key, value = tokens key = key.lower() if lowercase_keys else key key_values[key] = value\n\nThis function is called once for each key=value match. The tokens parameter is a tuple of the matched parser elements. In this case we would have expected the tuple to have the key,the equals sign,and the value,but since we used Sup- press() on the equals sign we get only the key and the value, which is exactly what we want. The lowercase_keys variable is a Boolean created in an outer scope and that for .pls ﬁles is set to True.(Note that for ease of explanation we have shown this function after the creation of the parser, although in fact it must be deﬁned before we create the parser since the parser refers to it.)\n\ntry:\n\nparser.parseFile(file) except ParseException as err:\n\nprint(\"parse error: {0}\".format(err)) return {} return key_values\n\nWith the parser set up we are ready to call the parseFile() method, which in thisexampletakesthe name of a .pls ﬁle and attemptsto parseit. If theparse fails we output a simple error message based on what PyParsing tells us. At the end we return the key_values dictionary—or an empty dictionary if the parsing failed—and we ignore the parseFile() method’s return value since we did all our processing in the parse action.",
      "content_length": 2332,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 548,
      "content": "Hand- crafted .m3u parser 522➤\n\nSong named tuple 523➤\n\nPythonic Parsing with PyParsing\n\nPlaylist Data Parsing\n\nIn the previous section’s second subsection we created a handcrafted regex- based parser for .m3u ﬁles. In this subsection we will create a parser to do the same thing, but this time using the PyParsing module. An extract from a .m3u ﬁle is shown in Figure 14.6 (523 ➤), and the BNF is shown in Figure 14.7 (523➤).\n\nAs we did when reviewing the previoussubsection’s .pls parser,we will review the .m3u parser in three parts: ﬁrst the creation of the parser, then the helper function,and ﬁnally the call to the parser. Just as with the .pls parser,we are ignoring the parser’s return value and instead populating our data structure as the parsing progresses. (In the following two subsections we will create parsers whose return values are used.)\n\nsongs = [] title = restOfLine(\"title\") filename = restOfLine(\"filename\") seconds = Combine(Optional(\"-\") + Word(nums)).setParseAction(\n\nlambda tokens: int(tokens[0]))(\"seconds\")\n\ninfo = Suppress(\"#EXTINF:\") + seconds + Suppress(\",\") + title entry = info + LineEnd() + filename + LineEnd() entry.setParseAction(add_song) parser = Suppress(\"#EXTM3U\") + OneOrMore(entry)\n\nWe begin by creating an empty list that will hold the Song named\n\ntuples.\n\nAlthough the BNF is quite simple, some of the parser elements are more com- plex than those we have seen so far. Notice also that we create the parser ele- ments in reverse order to the order used in the BNF.This is because in Python we can only refer to things that already exist,so for example,we cannot create a parser element for an ENTRY before we have created one for an INFO since the former refers to the latter.\n\nThe title and filename parser elements are ones that match every character from the parse position where they are tried until the end of the line. This means that they can match any characters, including whitespace—but not including newline which is where they stop. We also give these parser el- ements names, for example, “title”—this allows us to conveniently access them by name as an attribute of the tokens object that is given to parse action functions.\n\nThe seconds parser element matches an optional minus sign followed by digits; (nums is a predeﬁned PyParsing string that contains the digits). We use Combine() to ensure that the sign (if present)and digitsare returned asa single string. (It is possible to specify a separator for Combine(), but there is no need in thiscase,since the default of an empty string isexactly what we want.) The\n\n541\n\n||\n\nPLY .m3u parser ➤ 557",
      "content_length": 2608,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 549,
      "content": "Map- ping unpack- ing 179➤\n\n542\n\nChapter 14. Introduction to Parsing\n\nparse action is so simple that we have used a lambda. The Combine() ensures that there is alwaysprecisely one token in the tokens tuple,and we use int() to convert thisto an integer. If a parseaction returnsa value,that value becomes the value associatedwith the token rather than the text that wasmatched. We have also given a name to the token for convenience of access later on.\n\nThe info parse action consists of the literal string that indicates an entry, followed by the seconds, followed by a comma, followed by the title—and all this is deﬁned very simply and naturally in a way that matches the BNF. Noticealsothat weuse Suppress() for theliteral string and for thecomma since although both are essential for the grammar, they are of no interest to us in terms of the data itself.\n\nThe entry parser element is very easy to deﬁne: simply an info followed by a newline, then a filename followed by a newline—the LineEnd() is a predeﬁned PyParsing parser element to match a newline. And since we are populating our list of songs as we parse rather than at the end, we give the entry parser element a parse action that will be called whenever an ENTRY is matched.\n\nThe parser itself is a parser element that matches the literal string that indicates a .m3u ﬁle, followed by one or more ENTRYs.\n\ndef add_song(tokens):\n\nsongs.append(Song(tokens.title, tokens.seconds,\n\ntokens.filename))\n\nThe add_song() function is simple, especially since we named the parser ele- ments we are interested in and are therefore able to access them as attributes of the tokens object. And of course, we could have written the function even more compactly by converting the tokens to a dictionary and using mapping unpacking—for example, songs.append(Song(**tokens.asDict())).\n\ntry:\n\nparser.parseFile(fh) except ParseException as err:\n\nprint(\"parse error: {0}\".format(err)) return []\n\nreturn songs\n\nThe code for calling ParserElement.parseFile() is almost identical to the code we used for the .pls parser,although in this case instead of passing a ﬁlename we opened a ﬁle in text mode and passed in the io.TextIOWrapper returned by the built-in open() function as the fh (“ﬁle handle”) variable.\n\nWe have now ﬁnished reviewing two simplePyParsing parsers,and seen many of the most commonly used parts of the PyParsing API. In the following two subsections we will look at more complex parsers,both of which are recursive, that is, they have nonterminals whose deﬁnition includes themselves, and in",
      "content_length": 2551,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 550,
      "content": "Hand- crafted blocks parser 525➤\n\nPythonic Parsing with PyParsing\n\nthe ﬁnal example we will also see how to handle operators and their prece- dences and associativities.\n\nParsing the Blocks Domain-Speciﬁc Language\n\nparser In theprevioussection’sthirdsubsectionwecreateda recursivedescent for .blk ﬁles. Inthissubsectionwewillcreatea PyParsing implementationof a blocks parser that should be easier to understand and be more maintainable.\n\nTwo example .blk ﬁles are shown in Figures 14.8 (525 ➤) and 14.10 (526 ➤). The BNF for the blocks format is shown in Figure 14.12 (527 ➤).\n\nWe will look at the creation of the parser elements in two parts, then we will look at the helper function, and then we will see how the parser is called. And at the end we will see how theparser’sresultsare transformedinto a root block with child blocks (which themselves may contain child blocks, etc.), that is our required output.\n\nleft_bracket, right_bracket = map(Suppress, \"[]\") new_rows = Word(\"/\")(\"new_rows\").setParseAction(\n\nlambda tokens: len(tokens.new_rows))\n\nname = CharsNotIn(\"[]/\\n\")(\"name\").setParseAction( lambda tokens: tokens.name.strip())\n\ncolor = (Word(\"#\", hexnums, exact=7) |\n\nWord(alphas, alphanums))(\"color\")\n\nempty_node = (left_bracket + right_bracket).setParseAction(\n\nlambda: EmptyBlock)\n\nAsalwayswithPyParsingparsers,wecreateparserelementstomatchtheBNF fromlast toﬁrst sothat for every parser element wecreatethat dependson one or more other parser elements, the elements it depends on already exist.\n\nThe brackets are an important part of the BNF, but are of no interest to us for the results, so we create suitable Suppress() parser elements for them.\n\nFor the new_rows parser element it might be tempting to use Literal(\"/\")—but that must match the given text exactly whereas we want to match as many /s as are present. Having created the new_rows parser element,we give a name to its results and add a parsing action that replaces the string of one or more /s with an integer count of how many /s there were. Notice also that because we gave a name to the result, we can access the result (i.e., the matched text), by using the name as an attribute of the tokens object in the lambda.\n\nThe name parser element is slightly different from that speciﬁed in the BNF in that we have chosen to disallow not only bracketsand forward slashes,but also newlines. Again, we give the result a name. We also set a parse action, this\n\n543\n\n||\n\nPLY blocks parser ➤ 559",
      "content_length": 2467,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 551,
      "content": "544\n\nChapter 14. Introduction to Parsing\n\ntime to strip whitespace since whitespace (apart from newlines) is allowed as part of a name, yet we don’t want any leading or trailing whitespace.\n\nFor the color parser element we have speciﬁed that the ﬁrst character must be a # followed by exactly six hexadecimal digits (seven characters in all), or a sequence of alphanumeric characters with the ﬁrst character alphabetic.\n\nWe have chosen to handle empty nodes specially. We deﬁne an empty node as a left bracket followed by a right bracket, and replace the brackets with the value EmptyBlock which earlier in the ﬁle is deﬁned as EmptyBlock = 0. This means that in the parser’s results list we represent empty blocks with 0, and as noted earlier, we represent new rows by an integer row count (which will always be > 0).\n\nnodes = Forward() node_data = Optional(color + Suppress(\":\")) + Optional(name) node_data.setParseAction(add_block) node = left_bracket - node_data + nodes + right_bracket nodes << Group(ZeroOrMore(Optional(new_rows) +\n\nOneOrMore(node | empty_node)))\n\nWe deﬁne nodes to be a Forward() parser element,since we need to use it before we specify what it matches. We have also introduced a new parser element that isn’t in the BNF, node_data, which matches the optional color and optional name. We give this parser element a parse action that will create a new Block, so each time a node_data is encountered a Block will be added to the parser’s results list.\n\nThe node parser element is deﬁned very naturally as a direct translation of the BNF.Notice that both the node_data and nodes parser elementsare optional (the former consisting of two optional elements, the latter quantiﬁed by zero or more), so empty nodes are correctly allowed.\n\nFinally,we can deﬁne the nodes parser element. Since it wasoriginally created as a Forward() we must append parser elementsto it using <<.Here we have set nodes to be zero or more of an optional new row and one or more nodes. Notice that we put node before empty_node—since PyParsing matches left to right we normally order parser elements that have common preﬁxes from longest to shortest matching.\n\nWe have also grouped the nodes parser element’s results using Group()—this ensures that each nodes is created as a list in its own right. This means that a node that contains nodes will be represented by a Block for the node,and by a list for the contained nodes—and which in turn may contain Blocks, or integers for empty nodes or new rows, and so on. It is because of this recursive structure that we had to create nodes as a Forward(), and also why we must use the << operator (which in PyParsing is used to append), to add the Group() parser element and the elements it contains to the nodes element.",
      "content_length": 2760,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 552,
      "content": "Pythonic Parsing with PyParsing\n\nOne important but subtle point to note is that we used the - operator rather than the + operator in the deﬁnition of the node parser element. We could just as easily have used +, since both + (ParserElement.__add__()) and - (Parser- Element.__sub__()) do the same job—they return a parser element that represents the concatenation of the two parser elements that are the opera- tor’s operands.\n\nThe reason we chose to use - rather than + is due to a subtle but important difference between them. The - operator will stop parsing and raise a Parse- SyntaxException as soon as an error is encountered,something that the + opera- tor doesn’t do. If we had used + all errors would have a line number of 1 and a column of 1; but by using -, any errors have the correct line and column num- bers. In general,using + istheright approach,but if our testsshow that we are getting incorrect error locations, then we can start to change +s into -s as we have done here—and in this case only a single change was necessary.\n\ndef add_block(tokens):\n\nreturn Block.Block(tokens.name, tokens.color if tokens.color\n\nelse \"white\")\n\nWhenever a node_data is parsed instead of the text being returned and added to the parser’s results list, we create and return a Block.We also always set the color to white unless a color is explicitly speciﬁed.\n\nIn the previous examples we parsed a ﬁle and an open ﬁle handle (an opened io.TextIOWrapper); here we will parse a string. It makes no difference to Py- Parsing whether we give it a string or a ﬁle, so long as we use ParserElement. parseFile() or ParserElement.parseString() as appropriate. In fact, PyParsing offers other parsing methods, including ParserElement.scanString() which searches a string for matches, and ParserElement.transformString() which re- turns a copy of the string it is given, but with matched texts transformed into new texts by returning new text from parse actions.\n\nstack = [Block.get_root_block()] try:\n\nresults = nodes.parseString(text, parseAll=True) assert len(results) == 1 items = results.asList()[0] populate_children(items, stack)\n\nexcept (ParseException, ParseSyntaxException) as err:\n\nraise ValueError(\"Error {{0}}: syntax error, line \"\n\n\"{0}\".format(err.lineno))\n\nreturn stack[0]\n\nThis is the ﬁrst PyParsing parser where we have used the parser’s results rather than created the data structures ourselves during the parsing process. We expect the results to be returned as a list containing a single ParseResults\n\n545",
      "content_length": 2514,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 553,
      "content": "The hierar- chy.blk ﬁle 525➤\n\nThe message- box.blk ﬁle 526➤\n\n546\n\nChapter 14. Introduction to Parsing\n\nobject. Weconvertthisobjectintoa standardPythonlist,sonowwehavea list containing a single item—a list of our results—which we assign to the items variable, and that we then further process via the populate_children() call.\n\nBefore discussing the handling of the results, we will brieﬂy mention the error handling. If the parser fails it will raise an exception. We don’t want PyParsing’sexceptionsto leak out to clients since we may choose to change the parser generator later on. So,if an exception occurs,we catch it and then raise our own exception (a ValueError) with the relevant details.\n\nIn the case of a successful parse of the hierarchy.blk example, the items list looks like this (with occurrences of <Block.Block object at 0x8f52acd> and similar, replaced with Block for clarity):\n\n[0, Block, [], 2, 0, Block, [], 2, Block, [], 0, Block, []]\n\nWhenever we parsed an empty block we returned 0 to the parser’s results list; whenever we parsed new rowswe returned the number of rows;and whenever we encountered a node_data, we created a Block to represent it. In the case of Blocks they always have an empty child list (i.e.,the children attribute is set to []), since at this point we don’t know if the block will have children or not.\n\nSo here the outer list represents the root block, the 0s represent empty blocks, theother integers(all 2sinthiscase)representnewrows,andthe []sareempty child lists since none of the hierarchy.blk ﬁle’s blocks contain other blocks.\n\nThe messagebox.blk example’s items list (pretty printed to and again using Block for clarity) is:\n\nreveal its structure,\n\n[Block,\n\n[Block,\n\n[0, Block, [], 2, Block, [], 0, Block, [], 1, 0]\n\n]\n\n]\n\nHere we can see that the outer list (representing the root block) contains a block that has a child list of one block that contains its own child list, and where these children are blocks (with their own empty child lists),new rows (2 and 1), and empty blocks (0s).\n\nOne problem with the list results representation is that every Block’s children list is empty—each block’s children are in a list that follows the block in the parser’s results list. We need to convert this structure into a single root block with child blocks. To this end we have created a stack—a list containing a single root Block. We then call the populate_children() function that takes the list of items returned by the parser and a list with a root block, and populates the root block’s children (and their children, and so on, as appropriate) with the items.",
      "content_length": 2610,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 554,
      "content": "Pythonic Parsing with PyParsing\n\nThe populate_children() function is quite short, but also rather subtle.\n\ndef populate_children(items, stack):\n\nfor item in items:\n\nif isinstance(item, Block.Block):\n\nstack[-1].children.append(item)\n\nelif isinstance(item, list) and item:\n\nstack.append(stack[-1].children[-1]) populate_children(item, stack) stack.pop()\n\nelif isinstance(item, int):\n\nif item == EmptyBlock:\n\nstack[-1].children.append(Block.get_empty_block())\n\nelse:\n\nfor x in range(item):\n\nstack[-1].children.append(Block.get_new_row())\n\nWe iterate over every item in the results list. If the item is a Block we append it to the stack’s last (top) Block’s child list. (Recall that the stack is initialized with a single root Block item.) If the item is a nonempty list, then it is a child list that belongs to the previous block. So we append the previous block (i.e., the top Block’s last child) to the stack to make it the top of the stack, and then recursively call populate_children() on the list item and the stack. This ensures that the list item (i.e., its child items) is appended to the correct item’s child list. Once the recursive call is ﬁnished,we pop the top of the stack,ready for the next item.\n\nIf the item is an integer then it is either an empty block (0, i.e., EmptyBlock) or a count of new rows. If it is an empty block we append an empty block to the stack’s top Block’s list of children. If the item is a new row count, we append that number of new rows to the stack’s top Block’s list of children.\n\nIf the item is an empty list this signiﬁes an empty child list and we do nothing, since by default all Blocks are initialized to have an empty child list.\n\nAt the end the stack’s top item is still the root Block, but now it has children (which may have their own children, and so on). For the hierarchy.blk exam- ple, the populate_children() function produces the structure illustrated in Fig- ure 14.13 (528 ➤). And for the messagebox.blk example, the function produces the structure illustrated in Figure 14.14 (528 ➤).\n\nThe conversion into an SVG ﬁle using the BlockOutput.save_blocks_as_svg() function is the same for all the blocks parsers, since they all produce the same root block and children structures.\n\n547",
      "content_length": 2239,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 555,
      "content": "548\n\nChapter 14. Introduction to Parsing\n\nParsing First-Order Logic\n\nIn this last PyParsing subsection we will create a parser for a DSL for express- ing formulas in ﬁrst-order logic. This has the most complex BNF of all the examples in the chapter, and the implementation requires us to handle oper- ators, including their precedences and associativities, something we have not needed to do so far. There is no handcrafted version of this parser—once we have reached thislevel of complexity it is better to use a parser generator. But in addition to the PyParsing version shown here, in the following section’s last subsection there is an equivalent PLY parser for comparison.\n\nHere are a few examples of the kind of ﬁrst-order logical formulas that we want to be able to parse:\n\na = b forall x: a = b exists y: a -> b ~ true | true & true -> forall x: exists y: true (forall x: exists y: true) -> true & ~ true -> true true & forall x: x = x true & (forall x: x = x) forall x: x = x & true (forall x: x = x) & true\n\nWe have opted to use ASCII charactersrather than the proper logical operator symbols, to avoid any distraction from the parser itself. So, we have used forall for ∀, exists for ∃, -> for ⇒ (implies), | for ∨ (logical OR), & for ∧ (logical AND),and ~ for ¬(logical NOT).SincePythonstringsareUnicodeit would beeasy to use the real symbols—or we could adapt the parser to accept both the ASCII forms shown here and the real symbols.\n\nIn the formulas shown here, the parentheses make a difference in the last two formulas—so those formulas are different—but not for the two above them (those starting with true), which are the same despite the parentheses. Naturally, the parser must get these details right.\n\nOne surprising aspect of ﬁrst-order logic is that not (~) has a lower precedence than equals (=), so ~ a = b is actually ~ (a = b). This is why logicians usually put a space after ~.\n\nA BNF for our ﬁrst-order logic DSL is given in Figure 14.15. For the sake of clarity the BNF does not include any explicit mention of whitespace (no \\n or \\s* elements), but we will assume that whitespace is allowed between all terminals and nonterminals.\n\nAlthough our subset of BNF syntax hasnoprovisionfor expressing precedence or associativity, we have added comments to indicate associativities for the\n\n||\n\nPLY ﬁrst-or- der logic parser ➤ 562\n\nFor- mulas",
      "content_length": 2368,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 556,
      "content": "Memoiz- ing 351➤\n\nPythonic Parsing with PyParsing\n\nFORMULA ::= ('forall' | 'exists') SYMBOL ':' FORMULA | FORMULA '->' FORMULA # right associative | FORMULA '|' FORMULA # left associative | FORMULA '&' FORMULA # left associative | '~' FORMULA | '(' FORMULA ')' | TERM '=' TERM | 'true' | 'false' TERM ::= SYMBOL | SYMBOL '(' TERM_LIST ')' TERM_LIST ::= TERM | TERM ',' TERM_LIST SYMBOL ::= [a-zA-Z]\\w*\n\nFigure 14.15 A BNF for ﬁrst-order logic\n\nbinary operators. As for precedence, the order is from lowest to highest in the order shown in the BNF for the ﬁrst few alternatives; that is, forall and exists have the lowest precedence, then ->, then |, then &. And the remaining alternatives all have higher precedence than those mentioned here.\n\nBefore looking at the parser itself, we will look at the import and the line that follows it since they are different than before.\n\nfrom pyparsing_py3 import (alphanums, alphas, delimitedList, Forward, Group, Keyword, Literal, opAssoc, operatorPrecedence, ParserElement, ParseException, ParseSyntaxException, Suppress, Word)\n\nParserElement.enablePackrat()\n\nThe import brings in some things we haven’t seen before and that we will cov- er when we encounter them in the parser. The enablePackrat() call is used to switch on an optimization (based on memoizing) that can produce a consider- able speedup when parsing deep operator hierarchies.★ If we do this at all it is best to do it immediately after importing the pyparsing_py3 module—and be- fore creating any parser elements.\n\nAlthough the parser is short, we will review it in three parts for ease of expla- nation, and then we will see how it is called. We don’t have any parser actions since all we want to do is to get an AST (Abstract Syntax Tree)—a list repre- senting what we have parsed—that we can post-process later on if we wish.\n\nleft_parenthesis, right_parenthesis, colon = map(Suppress, \"():\") forall = Keyword(\"forall\")\n\n★For more on packrat parsing, see Bryan Ford’s master’s thesis at pdos.csail.mit.edu/~baford/ packrat/.\n\n549",
      "content_length": 2041,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 557,
      "content": "550\n\nChapter 14. Introduction to Parsing\n\nexists = Keyword(\"exists\") implies = Literal(\"->\") or_ = Literal(\"|\") and_ = Literal(\"&\") not_ = Literal(\"~\") equals = Literal(\"=\") boolean = Keyword(\"false\") | Keyword(\"true\") symbol = Word(alphas, alphanums)\n\nAll the parser elements created here are straightforward, although we had to add underscores to the end of a few names to avoid conﬂicts with Python keywords. If we wanted to give users the choice of using ASCII or the proper Unicode symbols, we could change some of the deﬁnitions. For example:\n\nforall = Keyword(\"forall\") | Literal(\"∀\")\n\nIf we are using a non-Unicode editor we could use the appropriate escaped Unicode code point, such as Literal(\"\\u2200\"), instead of the symbol.\n\nterm = Forward() term << (Group(symbol + Group(left_parenthesis +\n\ndelimitedList(term) + right_parenthesis)) | symbol)\n\nA term is deﬁned in terms of itself, which is why we begin by creating it as a Forward(). And rather than using a straight translation of the BNF we use one of PyParsing’s coding patterns. Recall that the delimitedList() function returns a parser element that can match a list of one or more occurrences of the given parser element, separated by commas (or by something else if we explicitly specify the separator). So here we have deﬁned the term parser element asbeing either a symbol followed by a comma-separatedlist of termsor a symbol—and since both start with the same parser element we must put the one with the longest potential match ﬁrst.\n\nformula = Forward() forall_expression = Group(forall + symbol + colon + formula) exists_expression = Group(exists + symbol + colon + formula) operand = forall_expression | exists_expression | boolean | term formula << operatorPrecedence(operand, [\n\n(equals, 2, opAssoc.LEFT), (not_, 1, opAssoc.RIGHT), (and_, 2, opAssoc.LEFT), (or_, 2, opAssoc.LEFT), (implies, 2, opAssoc.RIGHT)])\n\nAlthough the formula looks quite complicated in the BNF, it isn’t so bad in PyParsing syntax. First we deﬁne formula as a Forward() since it is deﬁned in terms of itself. The forall_expression and exists_expression parser elements",
      "content_length": 2121,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 558,
      "content": "Pythonic Parsing with PyParsing\n\nare straightforward to deﬁne; we’ve just used Group() to make them sublists within the results list to keep their components together and at the same time distinct as a unit.\n\nThe operatorPrecedence() function (which really ought to have been called something like createOperators()) creates a parser element that matches one or more unary, binary, and ternary operators. Before calling it, we ﬁrst specify what our operands are—in this case a forall_expression or an ex- ists_expression or a boolean or a term. The operatorPrecedence() function takes a parser element that matches valid operands, and then a list of parser ele- ments that must be treated as operators, along with their arities (how many operandstheytake),andtheirassociativities. Theresultantparserelement(in this case, formula) will match the speciﬁed operators and their operands.\n\nEach operator is speciﬁed as a three- or four-item tuple. The ﬁrst item is the operator’sparser element,the second is the operator’sarity as an integer (1for a unary operator,2for a binary operator,and3for a ternary operator),thethird is the associativity, and the fourth is an optional parse action.\n\nPyParsing infers the operators’ order of precedence from their relative posi- tions in the list given to the operatorPrecedence() function, with the ﬁrst oper- ator having the highest precedence and the last the lowest, so the order of the itemsin the list we passis important. In thisexample,= hasthe highest prece- dence (and has no associativity,so we have made it left-associative),and -> has the lowest precedence and is right-associative.\n\nThis completes the parser, so we can now look at how it is called.\n\ntry:\n\nresult = formula.parseString(text, parseAll=True) assert len(result) == 1 return result[0].asList()\n\nexcept (ParseException, ParseSyntaxException) as err: print(\"Syntax error:\\n{0.line}\\n{1}^\".format(err,\n\n\" \" * (err.column - 1)))\n\nThis code is similar to what we used for the blocks example in the previous subsection, only here we have tried to give more sophisticated error handling. In particular,if an error occurs we print the line that had the error and on the line below it we print spaces followed by a caret (^) to indicate where the error wasdetected. For example,if we parsethe invalid formula,forall x: = x & true, we will get:\n\nSyntax error: forall x: = x & true\n\n^\n\n551",
      "content_length": 2391,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 559,
      "content": "552\n\nChapter 14. Introduction to Parsing\n\nIn this case the error location is slightly off—the error is that = x should have the form y = x, but it is still pretty good.\n\nIn the case of a successfulparse we get a list of ParseResults which hasa single result—as before we convert this to a Python list.\n\nEarlier we saw some example formulas; now we will look at some of them again, this time with the result lists produced by the parser, pretty printed to help reveal their structure.\n\nWe mentioned before that the ~ operator has a lower precedence than the = operator—so let’s see if this is handled correctly by the parser.\n\n# ~true -> ~b = c [ ['~', 'true'], '->', ['~', ['b', '=', 'c'] ] ]\n\n# ~true -> ~(b = c) [ ['~', 'true'], '->', ['~', ['b', '=', 'c'] ] ]\n\nHere we get exactly the same results for both formulas, which demonstrates that = has higher precedence than ~.Of course,we would need to write several more test formulas to check all the cases, but this at least looks promising.\n\nTwo of the formulasthat we saw earlier were forall x: x = x & true and (forall x: x = x) & true, and we pointed out that although the only difference between them is the parentheses, this is sufﬁcient to make them different formulas. Here are the lists the parser produces for them:\n\n# forall x: x = x & true [ 'forall', 'x', [ ['x', '=', 'x'], '&', 'true' ] ]\n\n# (forall x: x = x) & true [ [ 'forall', 'x', ['x', '=', 'x'] ], '&', 'true' ]\n\nThe parser is clearly able to distinguish between these two formulas, and creates quite different parse trees (nested lists). Without the parentheses, forall’s formula is everything right of the colon, but with the parentheses, forall’s scope is limited to within the parentheses.\n\nBut what about the two formulas that again are different only in that one has parentheses, but where the parentheses don’t matter, so that the formulas are",
      "content_length": 1874,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 560,
      "content": "Pythonic Parsing with PyParsing\n\nactually the same? These two formulas are true & forall x: x = x and true & (forall x: x = x), and fortunately, when parsed they both produce exactly the same list:\n\n[ 'true', '&', [ 'forall', 'x', ['x', '=', 'x'] ] ]\n\nThe parentheses don’t matter here because only one valid parse is possible.\n\nWe have now completed the PyParsing ﬁrst-order logic parser, and in fact, all of the book’s PyParsing examples. If PyParsing is of interest, the PyParsing web site (pyparsing.wikispaces.com) has many other examples and extensive documentation, and there is also an active Wiki and mailing list.\n\nIn the next section we will look at the same examples as we covered in this section,but thistimeusing thePLY parser which worksin a very differentway from PyParsing.\n\nLex/Yacc-Style Parsing with PLY\n\nPLY (Python Lex Yacc) is a pure Python implementation of the classic Unix tools, lex and yacc. Lex is a tool that creates lexers, and yacc is a tool that cre- atesparsers—oftenusing a lexer createdby lex. PLY isdescribedby itsauthor, David Beazley, as “reasonably efﬁcient and well suited for larger grammars. [It]provides most of the standard lex/yacc features including support for emp- ty productions, precedence rules, error recovery, and support for ambiguous grammars. PLY is straightforward to use and provides very extensive error checking.”\n\nPLY is available under the LGPL open source license and so can be used in most contexts. Like PyParsing, PLY is not included in Python’s standard li- brary, so it must be downloaded and installed separately—although for Linux usersitisalmostcertainlyavailablethroughthepackagemanagementsystem. And fromPLY version 3.0,thesamePLY moduleswork with both Python2and Python 3.\n\nIf it is necessary to obtain and install PLY manually,it is available as a tarball from www.dabeaz.com/ply. On Unix-like systems such as Linux and Mac OS X, the tarball can be unpacked by executing tar xvfz ply-3.2.tar.gz in a console. (Of course, the exact PLY version may be different.) Windows users can use\n\n553\n\n|||",
      "content_length": 2069,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 561,
      "content": "554\n\nChapter 14. Introduction to Parsing\n\nthe untar.py example program that comes with this book’s examples. For in- stance, assuming the book’s examples are located in C:\\py3eg, the command to execute in the console is C:\\Python31\\python.exe C:\\py3eg\\untar.py ply- 3.2.tar.gz.\n\nOnce the tarball is unpacked, change directory to PLY’s directory—this direc- tory should contain a ﬁle called setup.py and a subdirectory called ply.PLY can be installed automatically or manually. To do it automatically, in the console execute python setup.py install,or on Windows execute C:\\Python31\\python.exe setup.py install.Alternatively, just copy or move the ply directory and its con- tentsto Python’s site-packages directory (or to your local site-packages directo- ry). Once installed, PLY’s modules are available as ply.lex and ply.yacc.\n\nPLY makesa clear distinctionbetweenlexing (tokenizing)and parsing. Andin fact, PLY’s lexer is so powerful that it is sufﬁcient on its own to handle all the examplesshown in thischapter except for the ﬁrst-order logic parser for which we use both the ply.lex and ply.yacc modules.\n\nWhen we discussed the PyParsing module we began by ﬁrst reviewing various PyParsing-speciﬁc concepts, and in particular how to convert certain BNF constructs into PyParsing syntax. This isn’t necessary with PLY since it is designed to work directly with regexes and BNFs, so rather than give any conceptual overview, we will summarize a few key PLY conventions and then dive straight into the examples and explain the details as we go along.\n\nPLY makes extensive use of naming conventions and introspection, so it is important to be aware of these when we create lexers and parsers using PLY.\n\nEvery PLY lexer and parser depends on a variable called tokens. This variable must hold a tuple or list of token names—they are usually uppercase strings corresponding to nonterminals in the BNF. Every token must have a corre- sponding variableor function whosenameisof theform t_TOKEN_NAME.If a vari- able is deﬁned it must be set to a string containing a regex—so normally a raw string is used for convenience;if a function is deﬁned it must have a docstring thatcontainsa regex,againusually using a rawstring. Ineithercasetheregex speciﬁes a pattern that matches the corresponding token.\n\nOne name that is special to PLY is t_error(); if a lexing error occurs and a function with this name is deﬁned, it will be called.\n\nIf we want the lexer to match a token but discard it from the results (e.g., a comment in a programming language), we can do this in one of two ways. If we are using a variable then we make its name t_ignore_TOKEN_NAME; if we are using a function then we use the normal name t_TOKEN_NAME, but ensure that it returns None.\n\nThe PLY parser follows a similar convention to the lexer in that for each BNF rule we create a function with the preﬁx p_, and whose docstring contains the BNF rule we’re matching (only with ::= replaced with :). Whenever a",
      "content_length": 2976,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 562,
      "content": "Hand- crafted key– value parser 519➤\n\nPyPars- ing key– value parser 539➤\n\n.pls BNF 520➤\n\nLex/Yacc-Style Parsing with PLY\n\nrule matches its corresponding function is called with a parameter (called p, following the PLY documentation’s examples); this parameter can be indexed with p[0] corresponding to the nonterminal that the rule deﬁnes,and p[1] and so on, corresponding to the parts on the right-hand side of the BNF.\n\nPrecedenceand associativity canbeset by creating a variablecalled precedence and giving it a tuple of tuples—in precedence order—that indicate the tokens’ associativities.\n\nSimilarly to the lexer,if there isa parsing error and we have created a function called p_error(), it will be called.\n\nWe will make use of all the conventions described here, and more, when we review the examples.\n\nTo avoid duplicating information from earlier in the chapter,the examplesand explanations given here focus purely on parsing with PLY. It is assumed that you are familiar with the formats to be parsed and their contexts of use. This means that either you have read at least this chapter’s second section and the ﬁrst-order logic parser from the third section’slast subsection,or that you skip back using the backreferences provided when necessary.\n\nSimple Key–Value Data Parsing\n\nﬁles. Every PLY’s lexer is sufﬁcient to handle the key–value data held in .pls PLY lexer (and parser) has a list of tokens which must be stored in the tokens variable. PLY makes extensive use of introspection,so the names of variables and functions, and even the contents of docstrings, must follow PLY’s conven- tions. Here are the tokens and their regexes and functions for the PLY .pls parser:\n\ntokens = (\"INI_HEADER\", \"COMMENT\", \"KEY\", \"VALUE\")\n\nt_ignore_INI_HEADER = r\"\\[[^]]+\\]\" t_ignore_COMMENT = r\"\\#.*\"\n\ndef t_KEY(t): r\"\\w+\" if lowercase_keys:\n\nt.value = t.value.lower()\n\nreturn t\n\ndef t_VALUE(t): r\"=.*\" t.value = t.value[1:].strip() return t\n\n555\n\n||",
      "content_length": 1951,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 563,
      "content": "556\n\nChapter 14. Introduction to Parsing\n\nBoth the INI_HEADER and COMMENT tokens’ matchers are simple regexes, and since both use the t_ignore_ preﬁx, both will be correctly matched—and then discarded. An alternative approach to ignoring matches is to deﬁne a function that just uses the t_ preﬁx (e.g., t_COMMENT()), and that has a suite of pass (or return None), since if the return value is None the token is discarded.\n\nFor the KEY and VALUE tokens we have used functions rather than regexes. In such cases the regex to match must be speciﬁed in the function’s docstring— and here the docstrings are raw strings since that is our practice for regexes, and it meanswe don’t have to escape backslashes. When a function is used the token is passed as token object t (following the PLY examples’ naming conven- tions) of type ply.lex.LexToken. The matched text is held in the ply.lex.Lex- Token.value attribute, and we are permitted to change this if we wish. We must always return t from the function if we want the token included in the results.\n\nIn the case of the t_KEY() function, we lowercase the matching key if the lowercase_keys variable (from an outer scope) is True. And for the t_VALUE() function, we strip off the = and any leading or trailing whitespace.\n\nIn addition to our own custom tokens, it is conventional to deﬁne a couple of PLY-speciﬁc functions to provide error reporting.\n\ndef t_newline(t):\n\nr\"\\n+\" t.lexer.lineno += len(t.value)\n\ndef t_error(t):\n\nline = t.value.lstrip() i = line.find(\"\\n\") line = line if i == -1 else line[:i] print(\"Failed to parse line {0}: {1}\".format(t.lineno + 1,\n\nline))\n\nThe token’s lexer attribute (of type ply.lex.Lexer) provides access to the lexer itself. Here we have updated the lexer’s lineno attribute by the number of newlines that have been matched.\n\nNotice that we don’t have to speciﬁcally account for blank lines since the t_newline() matching function effectively does that for us.\n\nIf an error occurs the t_error() function is called. We print an error message and at most one line of the input. We add 1 to the line number since PLY’s lexer.lineno attribute starts counting from 0.\n\nWith all the token deﬁnitionsin place we are ready to lex some data and create a corresponding key–value dictionary.",
      "content_length": 2267,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 564,
      "content": "Hand- crafted .m3u parser 522➤\n\nPyPars- ing .m3u parser 541➤\n\n.m3u BNF 523➤\n\nLex/Yacc-Style Parsing with PLY\n\nkey_values = {} lexer = ply.lex.lex() lexer.input(file.read()) key = None for token in lexer:\n\nif token.type == \"KEY\":\n\nkey = token.value\n\nelif token.type == \"VALUE\":\n\nif key is None:\n\nprint(\"Failed to parse: value '{0}' without key\"\n\n.format(token.value))\n\nelse:\n\nkey_values[key] = token.value key = None\n\nThe lexer reads the entire input text and can be used as an iterator that produces one token at each iteration. The token.type attribute holds the name of the current token—this is one of the names from the tokens list—and the token.value holds the matched text—or whatever we replaced it with.\n\nFor each token, if the token is a KEY we hold it and wait for its value, and if it is a VALUE we add it using the current key to the key_values dictionary. At the end (not shown), we return the dictionary to the caller just as we did with the playlists.py .pls regex and PyParsing parsers.\n\nPlaylist Data Parsing\n\nformat. And just In this subsection we will develop a PLY parser for the .m3u as we did in the previous implementations,the parser will return its results in the form of a list of Song (collections.namedtuple()) objects,each of which holds a title, a duration in seconds, and a ﬁlename.\n\nSince the format is so simple, PLY’s lexer is sufﬁcient to do all the parsing. As before we will create a list of tokens, each one corresponding to a nonterminal in the BNF:\n\ntokens = (\"M3U\", \"INFO\", \"SECONDS\", \"TITLE\", \"FILENAME\")\n\nWe haven’t got an ENTRY token—thisnonterminal is made up of a SECONDS and a TITLE.Instead we deﬁne two states,called entry and filename.When the lexer is in the entry state we will try to read the SECONDS and the TITLE,that is,an ENTRY, and when the lexer is in the filename state we will try to read the FILENAME. To make PLY understand states we must create a states variable that is set to a list of one or more 2-tuples. The ﬁrst item in each of the tuples is a state name and the second item is the state’s type, either inclusive (i.e., this state is in addition to the current state) or exclusive (i.e., this state is the only active\n\n557\n\n||",
      "content_length": 2196,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 565,
      "content": "558\n\nChapter 14. Introduction to Parsing\n\nstate). PLY predeﬁnes the INITIAL state which all lexers start in. Here is the deﬁnition of the states variable for the PLY .m3u parser:\n\nstates = ((\"entry\", \"exclusive\"), (\"filename\", \"exclusive\"))\n\nNow that we have deﬁned our tokens and our states we can deﬁne the regexes and functions to match the BNF.\n\nt_M3U = r\"\\#EXTM3U\"\n\ndef t_INFO(t):\n\nr\"\\#EXTINF:\" t.lexer.begin(\"entry\") return None\n\ndef t_entry_SECONDS(t):\n\nr\"-?\\d+,\" t.value = int(t.value[:-1]) return t\n\ndef t_entry_TITLE(t):\n\nr\"[^\\n]+\" t.lexer.begin(\"filename\") return t\n\ndef t_filename_FILENAME(t):\n\nr\"[^\\n]+\" t.lexer.begin(\"INITIAL\") return t\n\nBy default, the tokens, regexes, and functions operate in the INITIAL state. However,we can specify that they areactivein only oneparticular stateby em- bedding the state’sname after the t_ preﬁx. So in thiscase the t_M3U regex and the t_INFO() functionwillmatchonly in the INITIAL state,the t_entry_SECONDS() and t_entry_TITLE() functions will match only in the entry state, and the t_filename_FILENAME() function will match only in the filename state.\n\nThe lexer’s state is changed by calling the lexer object’s begin() method with the new state’s name as its argument. So in this example, when we match the INFO token we switch to the entry state; now only the SECONDS and TITLE tokens can match. Once we have matched a TITLE we switch to the filename state,and once we have matched a FILENAME we switch back to the INITIAL state ready to match the next INFO token.\n\nNotice that in the case of the t_INFO() function we return None;this means that the token will be discarded, which is correct since although we must match #EXTINF: for each entry, we don’t need that text. For the t_entry_SECONDS() function,we stripoff the trailing comma and replacethe token’svalue with the integer number of seconds.",
      "content_length": 1856,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 566,
      "content": "Hand- crafted blocks parser 525➤\n\nLex/Yacc-Style Parsing with PLY\n\nIn this parser we want to ignore spurious whitespace that may occur between tokens,and we want to do so regardlessof the state the lexer is in. This can be achieved by creating a t_ignore variable, and by giving it a state of ANY which means it is active in any state:\n\nt_ANY_ignore = \" \\t\\n\"\n\nThiswillensurethatany whitespacebetweentokensissafely andconveniently ignored.\n\nWe have also deﬁned two functions, t_ANY_newline() and t_ANY_error(); these have exactly the same bodies as the t_newline() and t_error() functions deﬁned in the previous subsection (556 ➤)—so neither are shown here—but include the state of ANY in their names so that they are active no matter what state the lexer is in.\n\nsongs = [] title = seconds = None lexer = ply.lex.lex() lexer.input(fh.read()) for token in lexer:\n\nif token.type == \"SECONDS\":\n\nseconds = token.value\n\nelif token.type == \"TITLE\": title = token.value\n\nelif token.type == \"FILENAME\":\n\nif title is not None and seconds is not None:\n\nsongs.append(Song(title, seconds, token.value)) title = seconds = None\n\nelse:\n\nprint(\"Failed, filename '{0}' without title/duration\"\n\n.format(token.value))\n\nWe use the lexer in the same way as we did for the .pls lexer, iterating over the tokens, accumulating values (for the seconds and title), and whenever we get a ﬁlename to go with the seconds and title, adding a new song to the song list. As before, at the end (not shown), we return the key_values dictionary to the caller.\n\nParsing the Blocks Domain-Speciﬁc Language\n\nThe blocks format is more sophisticated than the key–value-based .pls format or the .m3u format since it allows blocks to be nested inside each other. This presents no problems to PLY, and in fact the deﬁnitions of the tokens can be done wholly using regexes without requiring any functions or states at all.\n\n559\n\n||",
      "content_length": 1888,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 567,
      "content": "Py- Parsing blocks parser 543➤\n\n.blk BNF 527➤\n\n560\n\nChapter 14. Introduction to Parsing\n\ntokens = (\"NODE_START\", \"NODE_END\", \"COLOR\", \"NAME\", \"NEW_ROWS\",\n\n\"EMPTY_NODE\")\n\nt_NODE_START = r\"\\[\" t_NODE_END = r\"\\]\" t_COLOR = r\"(?:\\#[\\dA-Fa-f]{6}|[a-zA-Z]\\w*):\" t_NAME = r\"[^][/\\n]+\" t_NEW_ROWS = r\"/+\" t_EMPTY_NODE = r\"\\[\\]\"\n\nThe regexes are taken directly from the BNF, except that we have chosen to disallow newlines in names. In addition, we have deﬁned a t_ignore regex to skip spaces and tabs, and t_newline() and t_error() functions that are the same as before except that t_error() raises a custom LexError with its error message rather than printing the error message.\n\nWith the tokens set up, we are ready to prepare for lexing and then to do the lexing.\n\nstack = [Block.get_root_block()] block = None brackets = 0 lexer = ply.lex.lex() try:\n\nlexer.input(text) for token in lexer:\n\nAs with the previous blocks parsers we begin by creating a stack (a list) with an empty root Block. This will be populated with child blocks (and the child blocks with child blocks, etc.) to reﬂect the blocks that are parsed; at the end we will return the root block with all its children. The block variable is used to hold a reference to the block that is currently being parsed so that it can be updated as we go. We also keep a count of the brackets purely to improve the error reporting.\n\nOne difference from before is that we do the lexing and the parsing of the tokens inside a try … except suite—this is so that we can catch any LexError exceptions and convert them to ValueErrors.\n\nif token.type == \"NODE_START\":\n\nbrackets += 1 block = Block.get_empty_block() stack[-1].children.append(block) stack.append(block)\n\nelif token.type == \"NODE_END\":\n\nbrackets -= 1 if brackets < 0:\n\nraise LexError(\"too many ']'s\")",
      "content_length": 1804,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 568,
      "content": "Lex/Yacc-Style Parsing with PLY\n\nblock = None stack.pop()\n\nWhenever we start a new node we increment the brackets count and create a new empty block. This block is added as the last child of the stack’stop block’s list of children and is itself pushed onto the stack. If the block has a color or name we will be able to set it because we keep a reference to the block in the block variable.\n\nThe logic used here is slightly different from the logic used in the recursive de- scent parser—there we pushed new blocks onto the stack only if we knew that they had nested blocks. Here we always push new blocks onto the stack, safe in the knowledge that they’ll be popped straight off again if they don’t contain any nested blocks. This also makes the code simpler and more regular.\n\nWhen we reach the end of a block we decrement the brackets count—and if it is negative we know that we have had too many close brackets and can report the error immediately. Otherwise, we set block to None since we now have no current block and pop the top of the stack (which should never be empty).\n\nelif token.type == \"COLOR\":\n\nif block is None or Block.is_new_row(block):\n\nraise LexError(\"syntax error\")\n\nblock.color = token.value[:-1]\n\nelif token.type == \"NAME\":\n\nif block is None or Block.is_new_row(block):\n\nraise LexError(\"syntax error\")\n\nblock.name = token.value\n\nIf we get a color or a name, we set the corresponding attribute of the current block which should refer to a Block rather than being None or denoting a new row.\n\nelif token.type == \"EMPTY_NODE\":\n\nstack[-1].children.append(Block.get_empty_block())\n\nelif token.type == \"NEW_ROWS\":\n\nfor x in range(len(token.value)):\n\nstack[-1].children.append(Block.get_new_row())\n\nIf we get an empty node or one or more new rows,we add them as the last child of the stack’s top block’s list of children.\n\nif brackets:\n\nraise LexError(\"unbalanced brackets []\")\n\nexcept LexError as err:\n\nraise ValueError(\"Error {{0}}:line {0}: {1}\".format(\n\ntoken.lineno + 1, err))\n\n561",
      "content_length": 2002,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 569,
      "content": "PyPars- ing ﬁrst- order logic parser 548➤\n\nFirst-or- der logic BNF 549➤\n\n562\n\nChapter 14. Introduction to Parsing\n\nOnce lexing has ﬁnished we check that the brackets have balanced, and if not we raise a LexError. If a LexError occurred during lexing, parsing, or when we checked the brackets, we raise a ValueError that contains an escaped str.format() ﬁeld name—the caller is expected to use this to insert the ﬁle- name, something we cannot do here because we are given only the ﬁle’s text, not the ﬁlename or ﬁle object.\n\nAt the end (not shown), we return stack[0]; this is the root Block that should now have children (and which in turn might have children), representing the .blk ﬁle we have parsed. This block is suitable for passing to the BlockOut- put.save_blocks_as_svg() function, just as we did with the recursive descent and PyParsing blocks parsers.\n\nParsing First-Order Logic\n\nIn the last PyParsing subsection we created a parser for ﬁrst-order logic. In this subsection we will create a PLY version that is designed to produce identical output to the PyParsing version.\n\nSetting up the lexer is very similar to what we did earlier. The only novel aspect is that we keep a dictionary of “keywords” which we check whenever we have matched a SYMBOL (the equivalent to an identiﬁer in a programming language). Here is the lexer code, complete except for the t_ignore regex and the t_newline() and t_error() functions which are not shown because they are the same as ones we have seen before.\n\nkeywords = {\"exists\": \"EXISTS\", \"forall\": \"FORALL\",\n\n\"true\": \"TRUE\", \"false\": \"FALSE\"} tokens = ([\"SYMBOL\", \"COLON\", \"COMMA\", \"LPAREN\", \"RPAREN\",\n\n\"EQUALS\", \"NOT\", \"AND\", \"OR\", \"IMPLIES\"] +\n\nlist(keywords.values()))\n\ndef t_SYMBOL(t):\n\nr\"[a-zA-Z]\\w*\" t.type = keywords.get(t.value, \"SYMBOL\") return t\n\nt_EQUALS = r\"=\" t_NOT = r\"~\" t_AND = r\"&\" t_OR = r\"\\|\" t_IMPLIES = r\"->\" t_COLON = r\":\" t_COMMA = r\",\" t_LPAREN = r\"\\(\" t_RPAREN = r\"\\)\"\n\n||",
      "content_length": 1946,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 570,
      "content": "dict type 126➤\n\nSe- quence types 107➤\n\nLex/Yacc-Style Parsing with PLY\n\nThe t_SYMBOL() function is used to match both symbols (identiﬁers) and key- words. If the key given to dict.get() isn’t in the dictionary the default value (in this case \"SYMBOL\") is returned; otherwise the key’s corresponding token name is returned. Notice also that unlike in previous lexers, we don’t change the ply.lex.LexToken’s value attribute,but we do change its type attribute to be either \"SYMBOL\" or the appropriate keyword token name. All the other tokens arematchedby simpleregexes—allof whichhappentomatchoneor twoliteral characters.\n\nIn all the previous PLY examples the lexer alone has been sufﬁcient for our parsing needs. But for the ﬁrst-order logic BNF we need to use PLY’s pars- er as well as its lexer to do the parsing. Setting up a PLY parser is quite straightforward—andunlike PyParsing we don’t have to reformulateour BNF to match certain patterns but can use the BNF directly.\n\nFor each BNF deﬁnition, we create a function with a name preﬁxed by p_ and whose docstring contains the BNF statement the function is designed to pro- cess. As the parser parses, it calls the function with the matching BNF state- ment and passes it a single argument of type ply.yacc.YaccProduction. The argument is given the name p (following the PLY examples’ naming conven- tions).When a BNF statementincludesalternatives,it ispossibleto createjust one function to handle them all, although in most cases it is clearer to create one function per alternativeor set of structurally similar alternatives. We will look at each of the parser functions, starting with the one for handling quan- tiﬁers.\n\ndef p_formula_quantifier(p):\n\n\"\"\"FORMULA : FORALL SYMBOL COLON FORMULA\n\n| EXISTS SYMBOL COLON FORMULA\"\"\"\n\np[0] = [p[1], p[2], p[4]]\n\nThe docstring contains the BNF statement that the function corresponds to, but using : rather than ::= to mean is deﬁned by. Note that the words in the BNF are either tokens that the lexer matches or nonterminals (e.g., FORMULA) that the BNF matches. One PLY quirk to be aware of is that if we have alter- natives as we have here, each one must be on a separate line in the docstring.\n\nThe BNF’s deﬁnition of the FORMULA nonterminal involves many alternatives, but here we have used just the parts that are concerned with quantiﬁers—we will handle the other alternatives in other functions. The argument p of type supports Python’s sequence API, with each item cor- ply.yacc.YaccProduction responding to an item in the BNF. So in all cases, p[0] corresponds to the nonterminal that is being deﬁned (in this case FORMULA), with the other items matching the partson the right-hand side. Here, p[1] matches one of the sym- bols \"exists\" or \"forall\", p[2] matches the quantiﬁed identiﬁer (typically, x or y), p[3] matchesthe COLON token (a literal : which we ignore),and p[4] matches the formula that is quantiﬁed. This is a recursive deﬁnition, so the p[4] item\n\n563",
      "content_length": 2974,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 571,
      "content": "564\n\nChapter 14. Introduction to Parsing\n\nis itself a formula which may contain formulas and so on. We don’t have to concern ourselves with whitespace between tokens since we created a t_ignore regex which told the lexer to ignore (i.e., skip) whitespace.\n\nIn this example, we could just as easily have created two separate functions, say, p_formula_forall() and p_formula_exists(), giving them one alternative of the BNF each and the samesuite. We choseto combinethem—andsome of the others—simply because they have the same suites.\n\nFormulas in the BNF have three binary operators involving formulas. Since these can be handled by the same suite, we have chosen to parse them using a single function and a BNF with alternatives.\n\ndef p_formula_binary(p):\n\n\"\"\"FORMULA : FORMULA IMPLIES FORMULA\n\n| FORMULA OR FORMULA | FORMULA AND FORMULA\"\"\"\n\np[0] = [p[1], p[2], p[3]]\n\nThe result, that is, the FORMULA stored in p[0], is simply a list containing the left operand,the operator,and the right operand. Thiscode saysnothing about precedence and associativity—and yet we know that IMPLIES is right-associa- tive and that the other two are left-associative, and that IMPLIES has lower precedence than the others. We will see how to handle these aspects once we have ﬁnished reviewing the parser’s functions.\n\ndef p_formula_not(p):\n\n\"FORMULA : NOT FORMULA\" p[0] = [p[1], p[2]]\n\ndef p_formula_boolean(p): \"\"\"FORMULA : FALSE\n\n| TRUE\"\"\"\n\np[0] = p[1]\n\ndef p_formula_group(p):\n\n\"FORMULA : LPAREN FORMULA RPAREN\" p[0] = p[2]\n\ndef p_formula_symbol(p):\n\n\"FORMULA : SYMBOL\" p[0] = p[1]\n\nAll these FORMULA alternatives are unary, but even though the suites for p_formula_boolean() and p_formula_symbol() are the same, we have given each one its own function since they are all logically different from each other. One slightly surprising aspect of the p_formula_group() function is that we set its value to be p[1] rather than [p[1]]. This works because we already use lists to",
      "content_length": 1960,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 572,
      "content": "Lex/Yacc-Style Parsing with PLY\n\nembody all the operators,so while it would be harmless to use a list here—and might be essential for other parsers—in this example it isn’t necessary.\n\ndef p_formula_equals(p):\n\n\"FORMULA : TERM EQUALS TERM\" p[0] = [p[1], p[2], p[3]]\n\nThis is the part of the BNF that relates formulas and terms. The implementa- tion is straightforward,and we could have included this with the other binary operators since the function’s suite is the same. We chose to handle this sepa- rately purely because it is logically different from the other binary operators.\n\ndef p_term(p):\n\n\"\"\"TERM : SYMBOL LPAREN TERMLIST RPAREN\n\n| SYMBOL\"\"\"\n\np[0] = p[1] if len(p) == 2 else [p[1], p[3]]\n\ndef p_termlist(p):\n\n\"\"\"TERMLIST : TERM COMMA TERMLIST | TERM\"\"\"\n\np[0] = p[1] if len(p) == 2 else [p[1], p[3]]\n\nTerms can either be a single symbol or a symbol followed by a parenthesized term list (a comma-separated list of terms), and these two functions between them handle both cases.\n\ndef p_error(p):\n\nif p is None:\n\nraise ValueError(\"Unknown error\")\n\nraise ValueError(\"Syntax error, line {0}: {1}\".format(\n\np.lineno + 1, p.type))\n\nIf a parser error occurs the p_error() function is called. Although we have treated the ply.yacc.YaccProduction argument as a sequence up to now, it also has attributes, and here we have used the lineno attribute to indicate where the problem occurred.\n\nprecedence = ((\"nonassoc\", \"FORALL\", \"EXISTS\"),\n\n(\"right\", \"IMPLIES\"), (\"left\", \"OR\"), (\"left\", \"AND\"), (\"right\", \"NOT\"), (\"nonassoc\", \"EQUALS\"))\n\nTo set the precedences and associativities of operators in a PLY parser, we must create a precedence variable and give it a list of tuples where each tu- ple’s ﬁrst item is the required associativity and where each tuple’s second and subsequent items are the tokens concerned. PLY will honor the speciﬁed as-\n\n565",
      "content_length": 1850,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 573,
      "content": "566\n\nChapter 14. Introduction to Parsing\n\nsociativities and will set the precedences from lowest (ﬁrst tuple in the list) to highest(lasttupleinthelist).★For unary operators,associativityisn’treally an issue for PLY (although it can be for PyParsing), so for NOT we could have used \"nonassoc\" and the parsing results would not be affected.\n\nAt this point we have the tokens, the lexer’s functions, the parser’s functions, and the precedence variable all set up. Now we can create a PLY lexer and parser and parse some text.\n\nlexer = ply.lex.lex() parser = ply.yacc.yacc() try:\n\nreturn parser.parse(text, lexer=lexer)\n\nexcept ValueError as err:\n\nprint(err) return []\n\nThis code parses the formula it is given and returns a list that has exactly the sameformatasthe listsreturnedby thePyParsing version. (See theend of the subsectionon thePyParsing ﬁrst-orderlogic parser toseeexamplesof thekind of lists that the parser returns; 552➤.)\n\nPLY triesvery hardtogiveusefulandcomprehensiveerrormessages,although in some cases it can be overzealous—for example, when PLY creates the ﬁrst- order logic parser for the ﬁrst time, it warns that there are “6 shift/reduce conﬂicts”.Inpractice,PLY defaultstoshifting insuchcases,sincethat’susually the right thing to do, and is certainly the right action for the ﬁrst-order logic parser. The PLY documentation explains this and many other issues that can arise, and the parser’s parser.out ﬁle which is produced whenever a parser is created contains all the information necessary to analyze what is going on. As a rule of thumb, shift/reduce warnings may be benign, but any other kind of warning should be eliminated by correcting the parser.\n\nWe havenow completedour coverageof thePLY examples. ThePLY documen- tation (www.dabeaz.com/ply) provides much more information than we have had space to convey here, including complete coverage of all of PLY’s features in- cluding many that were not needed for this chapter’s examples.\n\nSummary\n\nFor the simplest situations and for nonrecursive grammars, using regexes is a good choice—at least for those who are comfortable with regex syntax. Another approach isto create a ﬁnite state automata—for example,by reading the text character by character,and maintaining one or more state variables—\n\n★In PyParsing,precedences are set the other way up, from highest to lowest.\n\n|||",
      "content_length": 2357,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 574,
      "content": "Summary\n\nalthough thiscan lead to if statementswith lotsof elifsand nested if …elifs that can be difﬁcult to maintain. For more complex grammars,and those that are recursive,PyParsing,PLY,and other generic parser generatorsare a better choice than using regexes or ﬁnite state automata, or doing a handcrafted recursive descent parser.\n\nOf all the approaches, PyParsing seems to require the least amount of code, although it can be tricky to get recursive grammars right, at least at ﬁrst. PyParsing works at its best when we take full advantage of its predeﬁned functionality—of which there is quite a lot more than we covered in this chapter—and use the programming patterns that suit it. This means that in more complex cases we cannot simply translate a BNF directly into PyParsing syntax, but must adapt the implementation of the BNF to ﬁt in with the Py- Parsing philosophy. PyParsing is an excellent module, and it is used in many programming projects.\n\nPLY not only supports the direct translation of BNFs, it requires that we do this, at least for the ply.yacc module. It also has a powerful and ﬂexible lex- er which is sufﬁcient in its own right for handling many simple grammars. PLY also has excellent error reporting. PLY uses a table-driven algorithm that makes its speed independent of the size or complexity of the grammar, so it tends to run faster than parsers that use recursive descent such as Py- Parsing. One aspect of PLY that may take some getting used to is its heavy reliance on introspection,where both docstrings and function names have sig- niﬁcance. Nonetheless, PLY is an excellent module, and has been used to cre- ate some complex parsers,including ones for the C and ZXBasic programming languages.\n\nAlthough it is generally straightforward to create a parser that accepts valid input, creating one that accepts all valid input and rejects all invalid input can be quite a challenge. For example, do the ﬁrst-order logic parsers in this chapter’slast section accept all valid formulasand reject all invalid ones? And even if we do manage to reject invalid input,do we provideerror messagesthat correctlyidentify whattheproblemisandwhereit occurred? Parsing isa large and fascinating topic,and this chapter is designed to introduce the very basics, so further reading and practical experience are essential for those wanting to go further.\n\nOne other point that this chapter hints at is that as large and wide-rang- ing as Python’s standard library is, many high-quality, third-party pack- ages and modules that provide very useful additional functionality are also available. Most of these are available through the Python Package Index, pypi.python.org/pypi, but some can only be discovered using a search engine. In general, when you have some specialized need that is not met by Python’s standard library, it is always worth looking for a third-party solution before writing your own.\n\n567",
      "content_length": 2926,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 575,
      "content": "568\n\nChapter 14. Introduction to Parsing\n\nExercise\n\nCreate a suitable BNF and then write a simple program for parsing basic BIBTEX book references, and that produces output in the form of a dictionary of dictionaries. For example, given input like this:\n\n@Book{blanchette+summerfield08, author = \"Jasmin Blanchette and Mark Summerfield\", title = \"C++ GUI Programming with Qt 4, Second Edition\", year = 2008, publisher = \"Prentice Hall\" }\n\nthe expected output would be a dictionary like this (here, pretty printed):\n\n{'blanchette+summerfield08': { 'author': 'Jasmin Blanchette and Mark Summerfield', 'publisher': 'Prentice Hall', 'title': 'C++ GUI Programming with Qt 4, Second Edition', 'year': 2008 } }\n\nEach book has an identiﬁer and this should be used as the key for the outer dictionary. The value should itself be a dictionary of key–value items.\n\nEach book’s identiﬁer can contain any characters except whitespace, and each key=value ﬁeld’svalue caneither beanintegeror a double-quotedstring. String values can include arbitrary whitespace including newlines, so replace every internal sequence of whitespace (including newlines) with a single space, and of course strip whitespace from the ends. Note that the last key=value for a given book is not followed by a comma.\n\nCreate the parser using either PyParsing or PLY. If using PyParsing, the Regex() classwill beusefulfor theidentiﬁer and the QuotedString() classwill be useful when deﬁning the value. Use the delimitedList() function for handling the list of key=values. If using PLY, the lexer is sufﬁcient, providing you use separate tokens for integer and string values.\n\nA solution using PyParsing should take around 30 lines, while one using PLY might take about 60 lines. A solution that includes both PyParsing and PLY functions is provided in BibTeX.py.\n\n|||",
      "content_length": 1827,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 576,
      "content": "15 ● Dialog-Style Programs\n\nMain-Window-Style Programs\n\nIntroduction to GUI Programming\n\nPython has no native support for GUI (Graphical User Interface) program- ming, but this isn’t a problem since many GUI libraries written in other lan- guages can be used by Python programmers. This is possible because many GUIlibrarieshavePythonwrappersor bindings—thesearepackagesandmod- ules that are imported and used like any other Python packages and modules but which access functionality that is in non-Python libraries under the hood.\n\nPython’sstandard library includesTcl/Tk—Tcl is an almost syntax-free script- ing language and Tk is a GUI library written in Tcl and C. Python’s tkinter module provides Python bindings for the Tk GUI library. Tk has three advan- tages compared with the other GUI libraries that are available for Python. First, it is installed as standard with Python, so it is always available; second, it is small (even including Tcl); and third, it comes with IDLE which is very useful for experimenting with Python and for editing and debugging Python programs.\n\nUnfortunately,prior to Tk 8.5, Tk had a very dated look and a very limited set of widgets (“controls” or “containers” in Windows-speak). Although it is fairly easy to create custom widgets in Tk by composing other widgets together in a layout, Tk does not provide any direct way of creating custom widgets from scratchwith theprogrammerabletodrawwhateverthey want. AdditionalTk- compatible widgets are available using the Ttk library (only with Python 3.1 and Tk 8.5and later)and the Tix library—these are also part of Python’sstan- dard library. Note that Tix is not always provided on non-Windows platforms, most notably Ubuntu, which at the time of this writing offers it only as an unsupported add-on, so for maximum portability it is best to avoid using Tix altogether. The Python-oriented documentation for Tk, Ttk, and Tix is rather sparse—mostof thedocumentationfor theselibrariesiswrittenfor Tcl/Tk pro- grammers and may not be easy for non-Tcl programmers to decipher.\n\n569\n\n||||\n\n3.x",
      "content_length": 2077,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 577,
      "content": "570\n\nChapter 15. Introduction to GUI Programming\n\nFor developing GUI programs that must run on any or all Python desktop platforms(e.g.,Windows,Mac OS X,and Linux),using only a standard Python installation with no additional libraries, there is just one choice: Tk.\n\nIf it is possible to use third-party libraries the number of options opens up considerably. One route is to get the WCK (Widget Construction Kit, www.effbot.org/zone/wck.htm) which provides additional Tk-compatible func- tionality including the ability to create custom widgets whose contents are drawn in code.\n\nThe other choices don’t use Tk and fall into two categories, those that are spe- ciﬁc to a particular platform and those that are cross-platform. Platform-spe- ciﬁc GUI libraries can give us access to platform-speciﬁc features, but at the price of locking us in to the platform. The three most well-established cross- platform GUI libraries with Python bindings are PyGtk (www.pygtk.org), PyQt (www.riverbankcomputing.com/software/pyqt), and wxPython (www.wxpython.org). All three of these offer far more widgets than Tk, produce better-looking GUIs (although the gap has narrowed with Tk 8.5 and even more with Ttk), and makeit possibleto createcustomwidgetsdrawn in code. All of them areeasier to learn and use than Tk and all have more and much better Python-oriented documentation than Tk. And in general, programs that use PyGtk, PyQt, or wxPython need lesscode and produce better resultsthan programswritten us- ing Tk. (At the time of thiswriting,PyQt had already been ported to Python 3, but the ports of both wxPython and PyGtk were still being done.)\n\nYet despite its limitations and frustrations,Tk can be used to build useful GUI programs—IDLE being the most well known in the Python world. Further- more, Tk development seems to have picked up lately, with Tk 8.5 offering theming which makes Tk programs look much more native,as well as the wel- come addition of many new widgets.\n\nThe purpose of this chapter is to give just a ﬂavor of Tk programming—for serious GUI development it is best to skip this chapter (since it shows the vintage Tk approach to GUI programming), and to use one of the alternative libraries. But if Tk is your only option—for example,if your users have only a standard Python installation and cannot or will not install a third-party GUI library—then realistically you will need to learn enough of the Tcl language to be able to read Tk’s documentation.★\n\nIn the following sections we will use Tk to create two GUI programs. The ﬁrst is a very small dialog-style program that does compound interest calculations. The second is a more elaborate main-window-style program that manages a list of bookmarks (names and URLs). By using such simple data we can\n\n★The only Python/Tk book known to the author is Python and Tkinter Programming by John Grayson,ISBN 1884777813,published in 2000;it is out of date in some areas. A good Tcl/Tk book is Practical Programming in Tcl and Tkby Brent Welch and Ken Jones,ISBN 0130385603.All the Tcl/Tk documentation is online at www.tcl.tk, and tutorials can be found at www.tkdocs.com.",
      "content_length": 3138,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 578,
      "content": "Chapter 15. Introduction to GUI Programming\n\nInvoke\n\nInvoke\n\nRead Input\n\nCreate GUI\n\nProcess\n\nStart Event Loop\n\nWrite Output\n\nNo\n\nEvent to\n\nProcess?\n\nTerminate\n\nYes\n\nClassic console program\n\nRequest to\n\nTerminate?\n\nNo\n\nProcess\n\nYes\n\nTerminate\n\nClassic GUI program\n\nFigure 15.1 Console programs versus GUI programs\n\nconcentrate on the GUI programming aspects without distraction. In the coverage of the bookmarks program we will see how to create a custom dialog, and how to create a main window with menus and toolbars, as well as how to combine them all together to create a complete working program.\n\nBoth of the example programs use pure Tk, making no use of the Ttk and Tix libraries, so as to ensure compatibility with Python 3.0. It isn’t difﬁcult to convertthemtouseTtk,but at thetimeof thiswriting,someof theTtk widgets provide less support for keyboard users than their Tk cousins, so while Ttk programs might look better, they may also be less convenient to use.\n\nBut before diving into the code, we must review some of the basics of GUI programming since it is a bit different from writing console programs.\n\nPython console programs and module ﬁles always have a .py extension, but for Python GUI programswe use a .pyw extension (module ﬁles always use .py, though). Both .py and .pyw work ﬁne on Linux, but on Windows, .pyw ensures that Windows uses the pythonw.exe interpreter instead of python.exe, and this in turn ensures that when we execute a Python GUI program,no unnecessary console window will appear. Mac OS X works similarly to Windows, using the .pyw extension for GUI programs.\n\n571",
      "content_length": 1607,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 579,
      "content": "572\n\nChapter 15. Introduction to GUI Programming\n\nWhen a GUI program is run it normally begins by creating its main window and all of the main window’s widgets, such as the menu bar, toolbars, the cen- tral area, and the status bar. Once the window has been created, like a server program,theGUIprogramsimply waits. Whereasa server waitsfor clientpro- grams to connect to it,a GUI program waitsfor user interaction such as mouse clicks and key presses. This is illustrated in contrast to console programs in Figure 15.1. The GUI program does not wait passively; it runs an event loop, which in pseudocode looks like this:\n\nwhile True:\n\nevent = getNextEvent() if event:\n\nif event == Terminate:\n\nbreak\n\nprocessEvent(event)\n\nWhen the user interacts with the program,or when certain other things occur, such as a timer timing out or the program’s window being activated (maybe because another program was closed), an event is generated inside the GUI library and added to the event queue. The program’s event loop continuously checks to see whether there is an event to process, and if there is, it processes it (or passes it on to the event’s associated function or method for processing).\n\nAs GUI programmers we can rely on the GUI library to provide the event loop. Our responsibility is to create classes that represent the windows and widgets our program needs and to provide them with methods that respond appropriately to user interactions.\n\nDialog-Style Programs\n\nThe ﬁrst program we will look at is the Interest program. Thisis a dialog-style program (i.e., it has no menus), which the user can use to perform compound interest calculations. The program is shown in Figure 15.2.\n\nIn most object-oriented GUI programs, a custom class is used to represent a single main window or dialog, with most of the widgets it contains being instances of standard widgets, such as buttons or checkboxes, supplied by the library. Like most cross-platform GUI libraries, Tk doesn’t really make a distinction between a window and a widget—a window is simply a widget that has no widget parent (i.e., it is not contained inside another widget). Widgets that don’t have a widget parent (windows) are automatically supplied with a frame and window decorations (such as a title bar and close button), and they usually contains other widgets.\n\nMost widgets are created as children of another widget (and are contained insidetheir parent),whereaswindowsarecreatedaschildren of the tkinter.Tk\n\n|||",
      "content_length": 2479,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 580,
      "content": "Dialog-Style Programs\n\nFigure 15.2 The Interest program\n\nobject—an object that conceptually represents the application,and something we will return to later on. In addition to distinguishing between widgets and windows (also called top-level widgets), the parent–child relationships help ensure that widgets are deleted in the right order and that child widgets are automatically deleted when their parent is deleted.\n\nThe initializer is where the user interface is created (the widgets added and laid out, the mouse and keyboard bindings made), and the other methods are used to respond to user interactions. Tk allows us to create custom widgets either by subclassing a predeﬁned widget such as tkinter.Frame,or by creating an ordinary class and adding widgets to it as attributes. Here we have used subclassing—in the next example we will show both approaches.\n\nSince the Interest program has just one main window it is implemented in a single class. We will start by looking at the class’s initializer, broken into ﬁve parts since it is rather long.\n\nclass MainWindow(tkinter.Frame):\n\ndef __init__(self, parent):\n\nsuper().__init__(parent) self.parent = parent self.grid(row=0, column=0)\n\nWe begin by initializing the base class, and we keep a copy of the parent for later use. Rather than using absolute positions and sizes, widgets are laid out inside other widgets using layout managers. The call to grid() lays out the frame using the grid layout manager. Every widget that is shown must be laid out, even top-level ones. Tk has several layout managers, but the grid is the easiest to understand and use, although for top-level layouts where there is only one widget to lay out we could use the packer layout manager by calling pack() instead of grid(row=0, column=0) to achieve the same effect.\n\nself.principal = tkinter.DoubleVar() self.principal.set(1000.0)\n\n573",
      "content_length": 1872,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 581,
      "content": "574\n\nChapter 15. Introduction to GUI Programming\n\nself.rate = tkinter.DoubleVar() self.rate.set(5.0) self.years = tkinter.IntVar() self.amount = tkinter.StringVar()\n\nTk allowsustocreatevariablesthatareassociatedwithwidgets. If avariable’s value is changed programmatically, the change is reﬂected in its associated widget,andsimilarly,if theuser changesthevaluein thewidgettheassociated variable’svalueischanged. Herewehavecreatedtwo“double”variables(these hold float values), an integer variable, and a string variable, and have set ini- tial values for two of them.\n\nprincipalLabel = tkinter.Label(self, text=\"Principal $:\",\n\nanchor=tkinter.W, underline=0) principalScale = tkinter.Scale(self, variable=self.principal, command=self.updateUi, from_=100, to=10000000, resolution=100, orient=tkinter.HORIZONTAL)\n\nrateLabel = tkinter.Label(self, text=\"Rate %:\", underline=0,\n\nanchor=tkinter.W)\n\nrateScale = tkinter.Scale(self, variable=self.rate,\n\ncommand=self.updateUi, from_=1, to=100, resolution=0.25, digits=5, orient=tkinter.HORIZONTAL)\n\nyearsLabel = tkinter.Label(self, text=\"Years:\", underline=0,\n\nanchor=tkinter.W)\n\nyearsScale = tkinter.Scale(self, variable=self.years, command=self.updateUi, from_=1, to=50, orient=tkinter.HORIZONTAL)\n\namountLabel = tkinter.Label(self, text=\"Amount $\",\n\nanchor=tkinter.W)\n\nactualAmountLabel = tkinter.Label(self,\n\ntextvariable=self.amount, relief=tkinter.SUNKEN, anchor=tkinter.E)\n\nThis part of the initializer is where we create the widgets. The tkinter.Label widget is used to display read-only text to the user. Like all widgets it is cre- ated with a parent (in this case—and as usual—the parent is the containing widget), and then keyword arguments are used to set various other aspects of thewidget’sbehaviorandappearance. WehavesettheprincipalLabel’stextap- propriately,and set its anchor to tkinter.W, which means that the label’s text is aligned west (left).The underline parameter is used to specify which character in the label should be underlined to indicate a keyboard accelerator (e.g.,Alt+P); further on we will see how to make the accelerator work. (A keyboard acceler- ator is a key sequence of the form Alt+letter where letter is an underlined letter andwhichresultsinthekeyboardfocusbeing switchedtothewidgetassociated with the accelerator, most commonly the widget to the right or below the label that has the accelerator.)",
      "content_length": 2385,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 582,
      "content": "Dialog-Style Programs\n\nFor the tkinter.Scale widgets we give them a parent of self as usual, and as- sociate a variable with each one. In addition,we give a function (or in thiscase a method) object reference as their command—this method will be called au- tomatically whenever the scale’s value is changed,and set its minimum (from_, with a trailing underscore since plain from is a keyword) and maximum (to) values, and a horizontal orientation. For some of the scales we set a resolu- tion (step size) and for the rateScale the number of digits it must be able to display.\n\nThe actualAmountLabel is also associated with a variable so that we can easily change the text the label displays later on. We have also given this label a sunken relief so that it ﬁts in better visually with the scales.\n\nprincipalLabel.grid(row=0, column=0, padx=2, pady=2,\n\nsticky=tkinter.W)\n\nprincipalScale.grid(row=0, column=1, padx=2, pady=2,\n\nsticky=tkinter.EW)\n\nrateLabel.grid(row=1, column=0, padx=2, pady=2, sticky=tkinter.W) rateScale.grid(row=1, column=1, padx=2, pady=2, sticky=tkinter.EW) yearsLabel.grid(row=2, column=0, padx=2, pady=2, sticky=tkinter.W) yearsScale.grid(row=2, column=1, padx=2, pady=2,\n\nsticky=tkinter.EW) amountLabel.grid(row=3, column=0, padx=2, pady=2,\n\nsticky=tkinter.W)\n\nactualAmountLabel.grid(row=3, column=1, padx=2, pady=2,\n\nsticky=tkinter.EW)\n\nHaving created the widgets, we must now lay them out. The grid layout we have used is illustrated in Figure 15.3.\n\nprincipalLabel\n\nprincipalScale\n\nrateLabel\n\nrateScale\n\nyearsLabel\n\nyearsScale\n\namountLabel\n\nactualAmountLabel\n\nFigure 15.3 The Interest program’s layout\n\nEvery widget supports the grid() method (and some other layout methods such as pack()). Calling grid() lays out the widget within its parent, making it occupy the speciﬁed row and column. We can set widgets to span multiple columns and multiple rows using additional keyword arguments (rowspan and columnspan), and we can add some margin around them using the padx (left and\n\n575",
      "content_length": 2009,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 583,
      "content": "576\n\nChapter 15. Introduction to GUI Programming\n\nright margin) and pady (top and bottom margin) keyword arguments giving integer pixel amounts as arguments. If a widget is allocated more space than it needs, the sticky option is used to determine what should be done with the space; if not speciﬁed the widget will occupy the middle of its allocated space. We have set all of the ﬁrst column’s labels to be sticky tkinter.W (west) and all of the second column’s widgets to be sticky tkinter.EW (east and west), which makes them stretch to ﬁll the entire width available to them.\n\nAll of the widgets are held in local variables, but they don’t get scheduled for garbage collection because the parent–child relationships ensure that they are not deleted when they go out of scope at the end of the initializer, since all of them have the main window as their parent. Sometimes widgets are created as instance variables, for example, if we need to refer to them outside the initializer, but in this case we used instance variables for the variables associated with the widgets (self.principal, self.rate, and self.years), so it is these we will use outside the initializer.\n\nprincipalScale.focus_set() self.updateUi() parent.bind(\"<Alt-p>\", lambda *ignore: principalScale.focus_set()) parent.bind(\"<Alt-r>\", lambda *ignore: rateScale.focus_set()) parent.bind(\"<Alt-y>\", lambda *ignore: yearsScale.focus_set()) parent.bind(\"<Control-q>\", self.quit) parent.bind(\"<Escape>\", self.quit)\n\nAt the end of the initializer we give the keyboard focus to the principalScale widget so that as soon as the program starts the user is able to set the initial amount of money. We then call the self.updateUi() method to calculate the initial amount.\n\nNext,weset upa fewkey bindings. (Unfortunately,binding hasthreedifferent meanings—variable binding is where a name, that is, an object reference, is boundtoanobject;a key binding iswherea keyboardactionsuch asa key press or releaseisassociatedwitha functionor methodtocallwhentheactionoccurs; and bindings for a library is the glue code that makes a library written in a languageother than Python availableto Python programmersthrough Python modules.) Key bindings are essential for some disabled users who have difﬁ- culty with or are unable to use the mouse,and they are a great convenience for fast typists who want to avoid using the mouse because it slows them down.\n\nThe ﬁrst three key bindings are used to move the keyboard focus to a scale widget. For example, the principalLabel’s text is set to Principal $: and its underline to 0, so the label appears as Principal $:, and with the ﬁrst keyboard binding in place when the user types Alt+Pthe keyboard focuswill switch to the principleScale widget. The same applies to the other two bindings. Note that we do not bind the focus_set() method directly. Thisisbecausewhen functions or methodsarecalled astheresult of an event binding they aregiven theevent",
      "content_length": 2946,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 584,
      "content": "Dialog-Style Programs\n\nthatinvokedthemastheir ﬁrstargument,andwedon’twantthisevent. So,we use a lambda function that accepts but ignores the event and calls the method without the unwanted argument.\n\nWe have also created two keyboard shortcuts—these are key combinationsthat invoke a particular action. Here we have set Ctrl+Q and Esc and bound them both to the self.quit() method that cleanly terminates the program.\n\nIt is possible to create keyboard bindings for individual widgets, but here we have set them all on the parent (the application), so they all work no matter where the keyboard focus is.\n\nTk’s bind() method can be used to bind both mouse clicks and key presses,and also programmer-deﬁnedevents. Special keyslike Ctrland Esc haveTk-speciﬁc names (Control and Escape), and ordinary letters stand for themselves. Key sequences are created by putting the parts in angle brackets and separating them with hyphens.\n\nHaving created and laid out the widgets, and set up the key bindings, the ap- pearance and basic behavior of the program are in place. Now we will review themethodsthatrespondtouseractionstocompletetheimplementationof the program’s behavior.\n\ndef updateUi(self, *ignore):\n\namount = self.principal.get() * (\n\n(1 + (self.rate.get() / 100.0)) ** self.years.get())\n\nself.amount.set(\"{0:.2f}\".format(amount))\n\nThis method is called whenever the user changes the principal,the rate,or the years since it is the command associated with each of the scales. All it does is retrieve the value from each scale’sassociated variable,perform the compound interest calculation,and store the result (asa string)in the variable associated with the actual amount label. As a result, the actual amount label always shows an up-to-date amount.\n\ndef quit(self, event=None):\n\nself.parent.destroy()\n\nIf theuser choosesto quit (by pressing Ctrl+Qor Esc,or by clicking thewindow’s close button) this method is called. Since there is no data to save we just tell the parent (which is the application object) to destroy itself. The parent will destroy all of its children—all of the windows,which in turn will destroy all of their widgets—so a clean termination takes place.\n\napplication = tkinter.Tk() path = os.path.join(os.path.dirname(__file__), \"images/\") if sys.platform.startswith(\"win\"):\n\nicon = path + \"interest.ico\"\n\n577",
      "content_length": 2331,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 585,
      "content": "578\n\nChapter 15. Introduction to GUI Programming\n\nelse:\n\nicon = \"@\" + path + \"interest.xbm\"\n\napplication.iconbitmap(icon) application.title(\"Interest\") window = MainWindow(application) application.protocol(\"WM_DELETE_WINDOW\", window.quit) application.mainloop()\n\nAfter deﬁning theclassfor themain (and in thiscaseonly)window,wehavethe code that startsthe program running. We begin by creating an object to repre- senttheapplicationasawhole. TogivetheprogramanicononWindowsweuse an .ico ﬁle and pass the name of the ﬁle (with its full path) to the iconbitmap() method. But for Unix platformswe must provide a bitmap (i.e.,a monochrome image). Tk has several built-in bitmaps, so to distinguish one that comes from the ﬁle system we must precede its name with an @ symbol. Next we give the application a title (which will appear in the title bar),and then we create an in- stanceof our MainWindow classgiving the applicationobject asitsparent. At the end we call the protocol() method to say what should happen if the user clicks the close button—we have said that the MainWindow.quit() method should be called, and ﬁnally we start the event loop—it is only when we reach this point that the window is displayed and is able to respond to user interactions.\n\nMain-Window-Style Programs\n\nAlthough dialog-style programs are often sufﬁcient for simple tasks, as the range of functionality a program offers grows it often makes sense to create a complete main-window-style application with menus and toolbars. Such applications are usually easier to extend than dialog-style programs since we canaddextra menusor menuoptionsandtoolbarbuttonswithoutaffecting the main window’s layout.\n\nIn this section we will review the bookmarks-tk.pyw program shown in Fig- ure 15.4. The program maintains a set of bookmarks as pairs of (name, URL) strings and has facilities for the user to add, edit, and remove bookmarks, and to open their web browser at a particular bookmarked web page.\n\nThe program has two windows: the main window with the menu bar, toolbar, list of bookmarks, and status bar; and a dialog window for adding or editing bookmarks.\n\nCreating a Main Window\n\nThe main window is similar to a dialog in that it has widgets that must be cre- ated and laid out. And in addition we must add the menu bar, menus, toolbar, and status bar, as well as methods to perform the actions the user requests.\n\n|||\n\n||",
      "content_length": 2399,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 586,
      "content": "Main-Window-StylePrograms\n\nFigure 15.4 The Bookmarks program\n\nThe user interface is all set up in the main window’s initializer, which we will review in ﬁve parts because it is fairly long.\n\nclass MainWindow:\n\ndef __init__(self, parent): self.parent = parent\n\nself.filename = None self.dirty = False self.data = {}\n\nmenubar = tkinter.Menu(self.parent) self.parent[\"menu\"] = menubar\n\nFor this window, instead of inheriting a widget as we did in the preceding ex- ample, we have just created a normal Python class. If we inherit we can reim- plement the methods of the class we have inherited, but if we don’t need to do that we can simply use composition as we have done here. The appearance is provided by creating widget instance variables, all contained within a tkin- ter.Frame as we will see in a moment.\n\nWe need to keep track of four pieces of information: the parent (application) object, the name of the current bookmarks ﬁle, a dirty ﬂag (if True this means that changeshave been madeto the data that have not been saved to disk),and the data itself,a dictionary whose keys are bookmark namesand whose values are URLs.\n\nTo create a menu bar we must create a tkinter.Menu object whose parent is the window’sparent,and we must tell the parent that it hasa menu. (It may seem strange that a menu bar isa menu,but Tk hashad a very long evolution which\n\n579",
      "content_length": 1361,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 587,
      "content": "580\n\nChapter 15. Introduction to GUI Programming\n\nhas left it with some odd corners.) Menu bars created like this do not need to be laid out; Tk will do that for us.\n\nfileMenu = tkinter.Menu(menubar) for label, command, shortcut_text, shortcut in (\n\n(\"New...\", self.fileNew, \"Ctrl+N\", \"<Control-n>\"), (\"Open...\", self.fileOpen, \"Ctrl+O\", \"<Control-o>\"), (\"Save\", self.fileSave, \"Ctrl+S\", \"<Control-s>\"), (None, None, None, None), (\"Quit\", self.fileQuit, \"Ctrl+Q\", \"<Control-q>\")):\n\nif label is None:\n\nfileMenu.add_separator()\n\nelse:\n\nfileMenu.add_command(label=label, underline=0,\n\ncommand=command, accelerator=shortcut_text)\n\nself.parent.bind(shortcut, command)\n\nmenubar.add_cascade(label=\"File\", menu=fileMenu, underline=0)\n\nEach menubar menuiscreatedin thesameway. Firstwecreatea tkinter.Menu object that isa child of the menu bar,and then we add separatorsor commands tothemenu. (NotethatanacceleratorinTk terminologyisactuallyakeyboard shortcut, and that all the accelerator option sets is the text of the shortcut; it does not actually set up a key binding.) The underline indicateswhich charac- ter is underlined,in this case the ﬁrst one of every menu option,and thisletter becomes the menu option’s keyboard accelerator.\n\nIn addition to adding a menu option (called a command), we also provide a keyboard shortcut by binding a key sequence to the same command as that invoked when the corresponding menu option is chosen. At the end the menu is added to the menu bar using the add_cascade() method.\n\nWe have omitted the edit menu since it is structurally identical to the ﬁle menu’s code.\n\nframe = tkinter.Frame(self.parent) self.toolbar_images = [] toolbar = tkinter.Frame(frame) for image, command in (\n\n(\"images/filenew.gif\", self.fileNew), (\"images/fileopen.gif\", self.fileOpen), (\"images/filesave.gif\", self.fileSave), (\"images/editadd.gif\", self.editAdd), (\"images/editedit.gif\", self.editEdit), (\"images/editdelete.gif\", self.editDelete), (\"images/editshowwebpage.gif\", self.editShowWebPage)):\n\nimage = os.path.join(os.path.dirname(__file__), image) try:",
      "content_length": 2070,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 588,
      "content": "Main-Window-StylePrograms\n\nimage = tkinter.PhotoImage(file=image) self.toolbar_images.append(image) button = tkinter.Button(toolbar, image=image,\n\ncommand=command)\n\nbutton.grid(row=0, column=len(self.toolbar_images) -1)\n\nexcept tkinter.TclError as err:\n\nprint(err)\n\ntoolbar.grid(row=0, column=0, columnspan=2, sticky=tkinter.NW)\n\nWe begin by creating a frame in which all of the window’s widgets will be contained. Then we create another frame, toolbar, to contain a horizontal row of buttons that have images instead of texts, to serve as toolbar buttons. We lay out each toolbar button one after the other in a grid that has one row and as many columnsas there are buttons. At the end we lay out the toolbar frame itself as the main window frame’sﬁrst row,making it north west sticky so that it will always cling to the top left of the window. (Tk automatically puts the menu bar above all the widgets laid out in the window.)\n\nThe layout is illustrated in Figure 15.5, with the menu bar laid out by Tk shown with a white background, and our layouts shown with gray back- grounds.\n\nmenubar\n\ntoolbar\n\nself.listBox\n\nscrollbar\n\nself.statusbar\n\nFigure 15.5 The Bookmarks program’s main window layouts\n\nWhen an image is added to a button it is added as a weak reference,so once the image goes out of scope it is scheduled for garbage collection. We must avoid this because we want the buttons to show their images after the initializer has ﬁnished, so we create an instance variable, self.toolbar_images, simply to hold references to the images to keep them alive for the program’s lifetime.\n\nOut of the box, Tk can read only a few image ﬁle formats, so we have had to use .gif images.★ If any image is not found a tkinter.TclError exception is raised, so we must be careful to catch this to avoid the program terminating just because of a missing image.\n\nNotice that we have not made all of the actions available from the menus available as toolbar buttons—this is common practice.\n\n★ If the Python Imaging Library’s Tk extension is installed, all of the modern image formats become supported. See www.pythonware.com/products/pil/for details.\n\n581",
      "content_length": 2145,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 589,
      "content": "582\n\nChapter 15. Introduction to GUI Programming\n\nscrollbar = tkinter.Scrollbar(frame, orient=tkinter.VERTICAL) self.listBox = tkinter.Listbox(frame,\n\nyscrollcommand=scrollbar.set)\n\nself.listBox.grid(row=1, column=0, sticky=tkinter.NSEW) self.listBox.focus_set() scrollbar[\"command\"] = self.listBox.yview scrollbar.grid(row=1, column=1, sticky=tkinter.NS)\n\nself.statusbar = tkinter.Label(frame, text=\"Ready...\",\n\nanchor=tkinter.W)\n\nself.statusbar.after(5000, self.clearStatusBar) self.statusbar.grid(row=2, column=0, columnspan=2,\n\nsticky=tkinter.EW)\n\nframe.grid(row=0, column=0, sticky=tkinter.NSEW)\n\nThe main window’s central area (the area between the toolbar and the status bar)isoccupiedby a list box and an associatedscrollbar. The list box islaid out to be sticky in all directions, and the scrollbar is sticky only north and south (vertically).Both widgets are added to the window frame’s grid, side by side.\n\nWe must ensure that if the user scrollsthe list box by tabbing into it and using the up and down arrow keys, or if they scroll the scrollbar, both widgets are kept in sync. This is achieved by setting the list box’s yscrollcommand to the scrollbar’s set() method (so that user navigation in the list box results in the scrollbar being moved if necessary), and by setting the scrollbar’s command to the listbox’s yview() method (so that scrollbar movements result in the list box being moved correspondingly).\n\nThestatusbar isjust a label. The after() methodisa singleshottimer (a timer that times out once after the given interval) whose ﬁrst argument is a timeout in milliseconds and whose second argument is a function or method to call when the timeout is reached. This means that when the program startsup the status bar will show the text “Ready…” for ﬁve seconds, and then the status bar will be cleared. The statusbar islaid out asthe last row and ismade sticky west and east (horizontally).\n\nAt the end we lay out the window’s frame itself. We have now completed the creation and layout of the main window’s widgets, but as things stand the widgets will assume a ﬁxed default size, and if the window is resized the widgets will not change size to shrink or grow to ﬁt. The next piece of code solves this problem and completes the initializer.\n\nframe.columnconfigure(0, weight=999) frame.columnconfigure(1, weight=1) frame.rowconfigure(0, weight=1) frame.rowconfigure(1, weight=999) frame.rowconfigure(2, weight=1)",
      "content_length": 2439,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 590,
      "content": "Main-Window-StylePrograms\n\nwindow = self.parent.winfo_toplevel() window.columnconfigure(0, weight=1) window.rowconfigure(0, weight=1)\n\nself.parent.geometry(\"{0}x{1}+{2}+{3}\".format(400, 500,\n\n0, 50))\n\nself.parent.title(\"Bookmarks - Unnamed\")\n\nThe columnconfigure() and rowconfigure() methods allow us to give weightings to a grid. We begin with the window frame, giving all the weight to the ﬁrst column and the second row (which is occupied by the list box),so if the frame is resizedany excessspaceisgiventothelist box. On itsownthisisnotsufﬁcient; we must also make the top-level window that containsthe frameresizable,and we do this by getting a reference to the window using the wininfo_toplevel() method, and then making the window resizable by setting its row and column weights to 1.\n\nAt the end of the initializer we set an initial window size and position using a string of the form widthxheight+x+y. (If we wanted to set only the size we could use the form widthxheight instead.) Finally, we set the window’s title, thereby completing the window’s user interface.\n\nIf the user clicks a toolbar button or chooses a menu option a method is called to carry out the required action. And some of these methods rely on helper methods. We will now review all the methods in turn,starting with one that is called ﬁve seconds after the program starts.\n\ndef clearStatusBar(self):\n\nself.statusbar[\"text\"] = \"\"\n\nThe status bar is a simple tkinter.Label. We could have used a lambda expres- sion in the after() method call to clear it, but since we need to clear the status bar from more than one place we have created a method to do it.\n\ndef fileNew(self, *ignore):\n\nif not self.okayToContinue():\n\nreturn\n\nself.listBox.delete(0, tkinter.END) self.dirty = False self.filename = None self.data = {} self.parent.title(\"Bookmarks - Unnamed\")\n\nIf the user wants to create a new bookmarks ﬁle we must ﬁrst give them the chance to save any unsaved changes in the existing ﬁle if there is one. This is factored out into the MainWindow.okayToContinue() method since it is used in a few different places. The method returns True if it is okay to continue, and False otherwise. If continuing, we clear the list box by deleting all its entries\n\n583",
      "content_length": 2235,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 591,
      "content": "584\n\nChapter 15. Introduction to GUI Programming\n\nfrom the ﬁrst to the last—tkinter.END isa constant used to signify the last item in contextswhere a widget can contain multipleitems. Then we clear the dirty ﬂag, ﬁlename, and data, since the ﬁle is new and unchanged, and we set the window title to reﬂect the fact that we have a new but unsaved ﬁle.\n\nThe ignore variable holds a sequence of zero or more positional arguments that we don’t care about. In the case of methods invoked as a result of menu options choices or toolbar button presses there are no ignored arguments, but if a keyboard shortcut is used (e.g., Ctrl+N), then the invoking event is passed, and since we don’t care how the user invoked the action, we ignore the event that requested it.\n\ndef okayToContinue(self): if not self.dirty: return True\n\nreply = tkinter.messagebox.askyesnocancel(\n\n\"Bookmarks - Unsaved Changes\", \"Save unsaved changes?\", parent=self.parent)\n\nif reply is None:\n\nreturn False\n\nif reply:\n\nreturn self.fileSave()\n\nreturn True\n\nIf the user wants to perform an action that will clear the list box (creating or opening a new ﬁle, for example), we must give them a chance to save any unsaved changes. If the ﬁle isn’t dirty there are no changes to save, so we return True right away. Otherwise, we pop up a standard message box with Yes, No, and Cancelbuttons. If the user cancels the reply is None; we take this to mean that they don’t want to continue the action they started and don’t want to save, so we just return False. If the user says yes, reply is True, so we give them the chance to save and return True if they saved and False otherwise. And if the user says no, reply is False, telling us not to save, but we still return True because they want to continue the action they started, abandoning their unsaved changes.\n\nTk’s standard dialogs are not imported by import tkinter, so in addition to that import we must do import tkinter.messagebox, and for the following method, import tkinter.filedialog. On Windows and Mac OS X the standard native dialogs are used, whereas on other platforms Tk-speciﬁc dialogs are used. We always give the parent to standard dialogs since this ensures that they are automatically centered over the parent window when they pop up.\n\nAll thestandarddialogsaremodal,which meansthat onceonepopsup,it isthe only window in the program that the user can interact with,so they must close it (by clicking OK, Open, Cancel, or a similar button) before they can interact with the rest of the program. Modal dialogs are easiest for programmers to",
      "content_length": 2566,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 592,
      "content": "Main-Window-StylePrograms\n\nwork with since the user cannot change the program’sstate behind the dialog’s back, and because they block until they are closed. The blocking means that when we create or invoke a modal dialog the statement that follows will be executed only when the dialog is closed.\n\ndef fileSave(self, *ignore):\n\nif self.filename is None:\n\nfilename = tkinter.filedialog.asksaveasfilename(\n\ntitle=\"Bookmarks - Save File\", initialdir=\".\", filetypes=[(\"Bookmarks files\", \"*.bmf\")], defaultextension=\".bmf\", parent=self.parent)\n\nif not filename: return False\n\nself.filename = filename if not self.filename.endswith(\".bmf\"):\n\nself.filename += \".bmf\"\n\ntry:\n\nwith open(self.filename, \"wb\") as fh:\n\npickle.dump(self.data, fh, pickle.HIGHEST_PROTOCOL)\n\nself.dirty = False self.setStatusBar(\"Saved {0} items to {1}\".format(\n\nlen(self.data), self.filename))\n\nself.parent.title(\"Bookmarks - {0}\".format(\n\nos.path.basename(self.filename)))\n\nexcept (EnvironmentError, pickle.PickleError) as err:\n\ntkinter.messagebox.showwarning(\"Bookmarks - Error\", \"Failed to save {0}:\\n{1}\".format( self.filename, err), parent=self.parent)\n\nreturn True\n\nIf there is no current ﬁle we must ask the user to choose a ﬁlename. If they cancelwereturn False toindicatethattheentireoperationshouldbecancelled. Otherwise, we make sure that the given ﬁlename has the right extension. Using the existing or new ﬁlename we save the pickled self.data dictionary into the ﬁle. After saving the bookmarks we clear the dirty ﬂag since there are now no unsaved changes, and put a message on the status bar (which will time out as we will see in a moment), and we update the window’s title bar to include the ﬁlename (without the path).If we could not save the ﬁle,we pop up a warning messagebox (which will automatically have an OK button)to inform the user.\n\ndef setStatusBar(self, text, timeout=5000):\n\nself.statusbar[\"text\"] = text if timeout:\n\n585",
      "content_length": 1921,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 593,
      "content": "586\n\nChapter 15. Introduction to GUI Programming\n\nself.statusbar.after(timeout, self.clearStatusBar)\n\nThis method sets the status bar label’s text, and if there is a timeout (a ﬁve- second timeout is the default), the method sets up a single shot timer to clear the status bar after the timeout period.\n\ndef fileOpen(self, *ignore):\n\nif not self.okayToContinue():\n\nreturn\n\ndir = (os.path.dirname(self.filename)\n\nif self.filename is not None else \".\")\n\nfilename = tkinter.filedialog.askopenfilename( title=\"Bookmarks - Open File\", initialdir=dir, filetypes=[(\"Bookmarks files\", \"*.bmf\")], defaultextension=\".bmf\", parent=self.parent)\n\nif filename:\n\nself.loadFile(filename)\n\nThis method starts off the same as MainWindow.fileNew() to give the user the chance to save any unsaved changes or to cancel the ﬁle open action. If the user chooses to continue we want to give them a sensible starting directory,so we use the directory of the current ﬁle if there is one, and the current working directory otherwise. The filetypes argument isa list of (description,wildcard) 2-tuples that the ﬁle dialog should show. If the user chose a ﬁlename, we set the current ﬁlename to the one they chose and call the loadFile() method to do the actual ﬁle reading.\n\nSeparating out the loadFile() method is common practice to make it easier to loada ﬁlewithouthaving toprompttheuser. For example,someprogramsload the last used ﬁle at start-up,and some programshave recently used ﬁles listed in a menu so that when the user chooses one the loadFile() method is called directly with the menu option’s associated ﬁlename.\n\ndef loadFile(self, filename):\n\nself.filename = filename self.listBox.delete(0, tkinter.END) self.dirty = False try:\n\nwith open(self.filename, \"rb\") as fh:\n\nself.data = pickle.load(fh)\n\nfor name in sorted(self.data, key=str.lower): self.listBox.insert(tkinter.END, name)\n\nself.setStatusBar(\"Loaded {0} bookmarks from {1}\".format(\n\nself.listBox.size(), self.filename))\n\nself.parent.title(\"Bookmarks - {0}\".format(\n\nos.path.basename(self.filename)))",
      "content_length": 2046,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 594,
      "content": "Main-Window-StylePrograms\n\nexcept (EnvironmentError, pickle.PickleError) as err:\n\ntkinter.messagebox.showwarning(\"Bookmarks - Error\", \"Failed to load {0}:\\n{1}\".format( self.filename, err), parent=self.parent)\n\nWhen this method is called we know that any unsaved changes have been saved or abandoned, so we are free to clear the list box. We set the current ﬁlename to the one passed in, clear the list box and the dirty ﬂag, and then attempt to open the ﬁle and unpickle it into the self.data dictionary. Once we have the data we iterate over all the bookmark names and append each one to the list box. Finally, we give an informative message in the status bar and update the window’s title bar. If we could not read the ﬁle or if we couldn’t unpickle it, we pop up a warning message box to inform the user.\n\ndef fileQuit(self, event=None):\n\nif self.okayToContinue(): self.parent.destroy()\n\nThis is the last ﬁle menu option method. We give the user the chance to save any unsaved changes;if they cancel we do nothing and the program continues; otherwise,we tell the parent to destroy itself and this leads to a clean program termination. If we wanted to save user preferences we would do so here, just before the destroy() call.\n\ndef editAdd(self, *ignore):\n\nform = AddEditForm(self.parent) if form.accepted and form.name:\n\nself.data[form.name] = form.url self.listBox.delete(0, tkinter.END) for name in sorted(self.data, key=str.lower): self.listBox.insert(tkinter.END, name)\n\nself.dirty = True\n\nIf the user asks to add a new bookmark (by clicking Edit→Add, or by clicking toolbar button,or by pressing the Ctrl+A keyboard shortcut),thismethod the is called. The AddEditForm is a custom dialog covered in the next subsection; all that we need to know to use it is that it has an accepted ﬂag which is set to True if the user clicked OK, and to False if they clicked Cancel, and two data attributes,name and url,that hold the name and URL of the bookmark the user has added or edited.\n\nWe create a new AddEditForm which immediately pops up as a modal dialog—and therefore blocks, so the if form.accepted … statement is not exe- cuted until the dialog has closed.\n\nIf the user clicked OK in the AddEditForm dialog and they gave the bookmark a name, we add the new bookmark’s name and URL to the self.data dictionary.\n\n587",
      "content_length": 2321,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 595,
      "content": "588\n\nChapter 15. Introduction to GUI Programming\n\nThen we clear the list box and reinsert all the data in sorted order. It would be more efﬁcient to simply insert the new bookmark in the right place, but even with hundreds of bookmarks the difference would hardly be noticeable on a modern machine. At the end we set the dirty ﬂag since we now have an unsaved change.\n\ndef editEdit(self, *ignore):\n\nindexes = self.listBox.curselection() if not indexes or len(indexes) > 1:\n\nreturn\n\nindex = indexes[0] name = self.listBox.get(index) form = AddEditForm(self.parent, name, self.data[name]) if form.accepted and form.name:\n\nself.data[form.name] = form.url if form.name != name:\n\ndel self.data[name] self.listBox.delete(0, tkinter.END) for name in sorted(self.data, key=str.lower): self.listBox.insert(tkinter.END, name)\n\nself.dirty = True\n\nEditing is slightly more involved than adding because ﬁrst we must ﬁnd the bookmark the user wants to edit. The curselection() method returns a (possibly empty) list of index positions for all its selected items. If exactly one item is selected we retrieve its text since that is the name of the bookmark the user wantsto edit (and also the key to the self.data dictionary).We then create a new AddEditForm passing the name and URL of the bookmark the user wants to edit.\n\nAfter the form has been closed, if the user clicked OK and set a nonempty bookmark name we update the self.data dictionary. If the new name and the old name are the same we can just set the dirty ﬂag and we are ﬁnished (in thiscasepresumably theuser editedtheURL),but if thebookmark’snamehas changed we delete the dictionary item whose key is the old name, clear the list box, and then repopulate the list box with the bookmarks just as we did after adding a bookmark.\n\ndef editDelete(self, *ignore):\n\nindexes = self.listBox.curselection() if not indexes or len(indexes) > 1:\n\nreturn\n\nindex = indexes[0] name = self.listBox.get(index) if tkinter.messagebox.askyesno(\"Bookmarks - Delete\",\n\n\"Delete '{0}'?\".format(name)):",
      "content_length": 2028,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 596,
      "content": "Main-Window-StylePrograms\n\nself.listBox.delete(index) self.listBox.focus_set() del self.data[name] self.dirty = True\n\nTo delete a bookmark we must ﬁrst ﬁnd out which bookmark the user has cho- sen, so this method begins with the same lines that the MainWindow.editEdit() method starts with. If exactly one bookmark is selected we pop up a message box asking the user whether they really want to delete it. If they say yes the message box function returns True and we delete the bookmark from the list box and from the self.data dictionary, and set the dirty ﬂag. We also set the keyboard focus back to the list box.\n\ndef editShowWebPage(self, *ignore):\n\nindexes = self.listBox.curselection() if not indexes or len(indexes) > 1:\n\nreturn\n\nindex = indexes[0] url = self.data[self.listBox.get(index)] webbrowser.open_new_tab(url)\n\nIf the user invokes this method we ﬁnd the bookmark they have selected and retrievethecorrespondingURLfromthe self.data dictionary. Thenweusethe webbrowser module’s webbrowser.open_new_tab() function to open the user’s web browser with the given URL.If the web browser is not already running, it will be launched.\n\napplication = tkinter.Tk() path = os.path.join(os.path.dirname(__file__), \"images/\") if sys.platform.startswith(\"win\"):\n\nicon = path + \"bookmark.ico\" application.iconbitmap(icon, default=icon)\n\nelse:\n\napplication.iconbitmap(\"@\" + path + \"bookmark.xbm\")\n\nwindow = MainWindow(application) application.protocol(\"WM_DELETE_WINDOW\", window.fileQuit) application.mainloop()\n\nThe last lines of the program are similar to those used for the interest-tk.pyw program we saw earlier, but with three differences. One difference is that if the user clicks the program window’s close box a different method is called for the Bookmarks program than the one used for the Interest program. An- other difference is that on Windows the iconbitmap() method has an addi- tional argument which allows us to specify a default icon for all the program’s windows—this is not needed on Unix platforms since this happens automati- cally. And the last difference is that we set the application’s title (in the title\n\n589",
      "content_length": 2134,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 597,
      "content": "590\n\nChapter 15. Introduction to GUI Programming\n\nbar) in the MainWindow class’s methods rather than here. For the Interest pro- gram the title never changed,so it needed to be set only once,but for the Book- marks program we change the title text to include the name of the bookmarks ﬁle being worked on.\n\nNow that we have seen the implementationof the main window’sclassand the code that initializes the program and starts off the event loop, we can turn our attention to the AddEditForm dialog.\n\nCreating a Custom Dialog\n\nThe AddEditForm dialog provides a means by which users can add and edit bookmark names and URLs. It is shown in Figure 15.6 where it is being used to edit an existing bookmark (hence the “Edit” in the title). The same dialog can also be used for adding bookmarks. We will begin by reviewing thedialog’s initializer, broken into four parts.\n\nFigure 15.6 The Bookmarks program’s Add/Edit dialog\n\nclass AddEditForm(tkinter.Toplevel):\n\ndef __init__(self, parent, name=None, url=None):\n\nsuper().__init__(parent) self.parent = parent self.accepted = False self.transient(self.parent) self.title(\"Bookmarks - \" + (\n\n\"Edit\" if name is not None else \"Add\"))\n\nself.nameVar = tkinter.StringVar() if name is not None:\n\nself.nameVar.set(name)\n\nself.urlVar = tkinter.StringVar() self.urlVar.set(url if url is not None else \"http://\")\n\nWe have chosen to inherit tkinter.TopLevel, a bare widget designed to serve as a base class for widgets used as top-level windows. We keep a reference to the parent and create a self.accepted attribute and set it to False. The call to the transient() method is done to inform the parent window that this window must always appear on top of the parent. The title is set to indicate adding or editing depending on whether a name and URL have been passed in. Two\n\n||",
      "content_length": 1809,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 598,
      "content": "Main-Window-StylePrograms\n\ntkinter.StringVars are created to keep track of the bookmark’sname and URL, and both are initialized with the passed-in values if the dialog is being used for editing.\n\nnameLabel\n\nnameEntry\n\nurlLabel\n\nurlEntry\n\nokButton\n\ncancelButton\n\nFigure 15.7 The Bookmarks program’s Add/Edit dialog’s layout\n\nframe = tkinter.Frame(self) nameLabel = tkinter.Label(frame, text=\"Name:\", underline=0) nameEntry = tkinter.Entry(frame, textvariable=self.nameVar) nameEntry.focus_set() urlLabel = tkinter.Label(frame, text=\"URL:\", underline=0) urlEntry = tkinter.Entry(frame, textvariable=self.urlVar) okButton = tkinter.Button(frame, text=\"OK\", command=self.ok) cancelButton = tkinter.Button(frame, text=\"Cancel\",\n\ncommand=self.close)\n\nnameLabel.grid(row=0, column=0, sticky=tkinter.W, pady=3,\n\npadx=3)\n\nnameEntry.grid(row=0, column=1, columnspan=3,\n\nsticky=tkinter.EW, pady=3, padx=3)\n\nurlLabel.grid(row=1, column=0, sticky=tkinter.W, pady=3,\n\npadx=3)\n\nurlEntry.grid(row=1, column=1, columnspan=3,\n\nsticky=tkinter.EW, pady=3, padx=3)\n\nokButton.grid(row=2, column=2, sticky=tkinter.EW, pady=3,\n\npadx=3)\n\ncancelButton.grid(row=2, column=3, sticky=tkinter.EW, pady=3,\n\npadx=3)\n\nThe widgets are created and laid out in a grid, as illustrated in Figure 15.7. The name and URL text entry widgets are associated with the correspond- ing tkinter.StringVars and the two buttons are set to call the self.ok() and self.close() methods shown further on.\n\nframe.grid(row=0, column=0, sticky=tkinter.NSEW) frame.columnconfigure(1, weight=1) window = self.winfo_toplevel() window.columnconfigure(0, weight=1)\n\nIt only makes sense for the dialog to be resized horizontally, so we make the window frame’s second column horizontally resizable by setting its column weight to 1—this means that if the frame is horizontally stretched the widgets\n\n591",
      "content_length": 1840,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 599,
      "content": "592\n\nChapter 15. Introduction to GUI Programming\n\nin column 1 (the name and URL text entry widgets) will grow to take advan- tage of the extra space. Similarly, we make the window’s column horizontally resizable by setting its weight to 1. If the user changes the dialog’s height, the widgetswill keep their relative positionsand all of them will be centered with- in the window; but if the user changes the dialog’s width, the name and URL text entry widgets will shrink or grow to ﬁt the available horizontal space.\n\nself.bind(\"<Alt-n>\", lambda *ignore: nameEntry.focus_set()) self.bind(\"<Alt-u>\", lambda *ignore: urlEntry.focus_set()) self.bind(\"<Return>\", self.ok) self.bind(\"<Escape>\", self.close)\n\nself.protocol(\"WM_DELETE_WINDOW\", self.close) self.grab_set() self.wait_window(self)\n\nWe created two labels, Name: and URL:,which indicate that they have keyboard accelerators Alt+Nand Alt+U,which when clicked will give the keyboard focus to their corresponding text entry widgets. To make this work we have provided the necessary keyboard bindings. We use lambda functions rather than pass the focus_set() methodsdirectly sothatwecanignoretheevent argument. We have also provided the standard keyboard bindings (Enter and Esc) for the OK and Cancel buttons.\n\nWe usethe protocol() methodtospecify themethodto callif theuser closesthe dialog by clicking the close button. The calls to grab_set() and wait_window() are both needed to turn the window into a modal dialog.\n\ndef ok(self, event=None):\n\nself.name = self.nameVar.get() self.url = self.urlVar.get() self.accepted = True self.close()\n\nIf the user clicks OK (or presses Enter), this method is called. The texts from the tkinter.StringVars are copied to correponding instance variables (which are only now created), the self.accepted variable is set to True, and we call self.close() to close the dialog.\n\ndef close(self, event=None):\n\nself.parent.focus_set() self.destroy()\n\nThis method is called from the self.ok() method, or if the user clicks the win- dow’sclose box or if the user clicks Cancel(or presses Esc).It givesthe keyboard focusback to the parent and makesthe dialog destroy itself. In thiscontext de- stroy justmeansthatthewindowanditswidgetsaredestroyed;theAddEditForm instance continues to exist because the caller has a reference to it.",
      "content_length": 2313,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 600,
      "content": "Main-Window-StylePrograms\n\nAfter the dialog has been closed the caller checks the accepted variable, and if True, retrieves the name and URL that were added or edited. Then, once the MainWindow.editAdd() or MainWindow.editEdit() method has ﬁnished, the AddEditForm object goes out of scope and is scheduled for garbage collection.\n\nSummary\n\nThis chapter gave you a ﬂavor of GUI programming using the Tk GUI library. Tk’s big advantage is that it comes as standard with Python. But it has many drawbacks, not the least of which is that it is a vintage library that works somewhat differently than most of the more modern alternatives.\n\nIf you are new to GUI programming, keep in mind that the major cross-plat- form competitors to Tk—PyGtk, PyQt, and wxPython—are all much easier to learn and use than Tk, and all can achieve better results using less code. Furthermore, these Tk competitors all have more and better Python-speciﬁc documentation, far more widgets, and a better look and feel, and allow us to create widgets from scratch with complete control over their appearance and behavior.\n\nAlthough Tk is useful for creating very small programsor for situationswhere only Python’s standard library is available, in all other circumstances any one of the other cross-platform libraries is a much better choice.\n\nExercises\n\nThe ﬁrst exercise involves copying and modifying the Bookmarks program shown in this chapter; the second exercise involves creating a GUI program from scratch.\n\n1. Copy the bookmarks-tk.pyw program and modify it so that it can import and export the DBM ﬁles that the bookmarks.py console program (created as an exercise in Chapter 12) uses. Provide two new menu options in the File menu, Import and Export.Make sure you provide keyboard shortutsfor both (keep in mind that Ctrl+E is already in use for Edit→Edit). Similarly, create two corresponding toolbar buttons. This involves adding about ﬁve lines of code to the main window’s initializer. Two methods to provide the functionality will be required, fileImport() and fileExport(), between them fewer than 60 lines of code including error handling. For importing you can decide whether to merge imported bookmarks,or toreplacetheexisting bookmarkswiththoseimported. The code is not difﬁcult, but does require quite a bit of care. A solution (that merges imported bookmarks) is provided in bookmarks-tk_ans.py.\n\n593\n\n|||\n\n|||",
      "content_length": 2405,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 601,
      "content": "594\n\nChapter 15. Introduction to GUI Programming\n\nNote that while on Unix-like systems a ﬁle sufﬁx of .dbm is ﬁne, on Win- dows each DBM “ﬁle” is actually three ﬁles. So for Windows ﬁle dialogs the pattern should be *.dbm.dat and the default extension *.dbm.dat—but the actual ﬁlename should have a sufﬁx of .dbm,so the last four characters must be chopped off the ﬁlename.\n\n2. In Chapter 13 we saw how to create and use regular expressions to match text. Create a dialog-style GUI program that can be used to enter and test regexes, as shown in Figure 15.8.\n\nFigure 15.8 The Regex program\n\nYou will need to read the re module’s documentation since the program must behave correctly in the face of invalid regexesor when iterating over the match groups,since in most casesthe regex won’t have as many match groups as there are labels to show them. Make sure the program has full support for keyboard users—with navigation to the text entry widgets us- ing Alt+R and Alt+T, control of the checkboxes with Alt+I and Alt+D, program termination on Ctrl+Qand Esc,and recalculationif the user pressesand re- leases a key in either of the text entry widgets, and whenever a checkbox is checked or unchecked.\n\nThe program is not too difﬁcult to write, although the code for displaying the matches and the group numbers (and names where speciﬁed) is a tiny bit tricky—a solution is provided in regex-tk.pyw, which is about one hundred forty lines.",
      "content_length": 1438,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 602,
      "content": "Epilogue\n\nIf you’ve read at least the ﬁrst six chapters and either done the exercises or written your own Python 3 programs independently, you should be in a good position to build up your experienceand programming skillsasfar asyou want to go—Python won’t hold you back!\n\nTo improve and deepen your Python language skills, if you read only the ﬁrst six chapters, make sure you are familiar with the material in Chapter 7, and that you read and experiment with at least some of the material in Chapter 8, and in particular the with statement and context managers. It is also worth reading at least Chapter 9’s section on testing.\n\nKeep in mind, though, that apart from the pleasure and learning aspects of developing everything from scratch, doing so is rarely necessary in Python. We have already mentioned the standard library and the Python Package Index, pypi.python.org/pypi, both of which provide a huge amount of func- tionality. In addition, the online Python Cookbook at code.activestate.com/ recipes/langs/python/ offers a large number of tricks,tips,and ideas,although it is Python 2-oriented at the time of this writing.\n\nIt is also possible to create modules for Python in other languages (any lan- guage that can export C functions, as most can). These can be developed to work cooperatively with Python using Python’s C API.Shared libraries (DLLs on Windows), whether created by us or obtained from a third party, can be ac- cessed from Python using the ctypes module, giving us virtually unlimited ac- cess to the vast amount of functionality available over the Internet thanks to the skill and generosity of open source programmers worldwide.\n\nAnd if you want to participate in the Python community, a good place to start is www.python.org/community where you will ﬁnd Wikis and many general and special-interest mailing lists.\n\n595\n\n||||",
      "content_length": 1855,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 603,
      "content": "Selected Bibliography\n\nThisisa small selected annotatedbibliography of programming-relatedbooks. Most of thebookslisted arenot Python-speciﬁc,but all of them areinteresting, useful—and accessible.\n\nClean Code\n\nRobert C. Martin (Prentice Hall, 2009, ISBN 0132350882) This book addressesmany “tactical” issuesin programming:good naming, function design, refactoring, and similar. The book has many interesting and useful ideas that should help any programmer improve their coding style and make their programs more maintainable. (The book’s examples are in Java.)\n\nCode Complete: A Practical Handbook of Software Construction,Second Edition\n\nSteve McConnell (Microsoft Press, 2004, ISBN 0735619670) This book shows how to build solid software, going beyond the language speciﬁcs into the realms of ideas, principles, and practices. The book is packed with ideas that will make any programmer think more deeply about their programming. (The book’s examples are mostly in C++, Java, and Visual Basic.)\n\nDomain-Driven Design\n\nEric Evans (Addison-Wesley, 2004, ISBN 0321125215) A very interesting book on software design, particularly useful for large, multiperson projects. At itsheart it is about creating and reﬁning domain models that represent what the system is designed to do, and about creating a ubiquitous language through which all those involved with the system—not just software engineers—can communicate their ideas. (The book’s examples are in Java.)\n\nDesign Patterns\n\nErich Gamma, Richard Helm, Ralph Johnson, John Vlissides (Addison- Wesley, 1998, ISBN 0201633612) Deservedly one of the most inﬂuential programming books of modern times. The design patterns are fascinating and of great practical use in everyday programming. (The book’s examples are in C++.)\n\nMastering Regular Expressions,Third Edition\n\nJeffrey E. F. Friedl (O’Reilly, 2006, ISBN 0596528124) This is the standard text on regular expressions—a very interesting and useful book. Most of the coverage is understandably devoted to\n\n597\n\n||||",
      "content_length": 2017,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 604,
      "content": "598\n\nSelected Bibliography\n\nPerl—which probably has more regular expression features than any oth- er tool. However, since Python supports a large subset of what Perl pro- vides (plus Python’s own ?P extensions), the book is still useful to Python programmers.\n\nParsing Techniques: A Practical Guide,Second Edition\n\nDick Grune, Ceriel J. H. Jacobs (Springer, 2007, ISBN 038720248X) This book provides comprehensive and in-depth coverage of parsing. The ﬁrst edition can be downloaded in PDF format from www.cs.vu.nl/~dick/ PTAPG.html.\n\nPython Cookbook,Second Edition\n\nAlex Martelli, Anna Ravenscroft, David Ascher ISBN 0596007973) This book is full of interesting—and practical—ideas covering all aspects of Python programming. The second edition is based on Python 2.4, so it might be worthwhile waiting and hoping for a Python 3-speciﬁc edition to appear.\n\n(O’Reilly, 2005,\n\nPython Essential Reference,Fourth Edition\n\nDavid M. Beazley (Addison-Wesley, 2009, ISBN 0672329786) The book’s title is an accurate description. The fourth edition has been updated to cover both Python 2.6 and Python 3.0. There is a little overlap with this book, but most of the Essential Reference is devoted to Python’s standard library as well as covering more advanced features such as extending Python with C libraries and embedding the Python interpreter into other programs.\n\nRapid GUI Programming with Python and Qt\n\nMark Summerﬁeld (Prentice Hall, 2007, ISBN 0132354187) This book (by this book’s author) teaches PyQt4 programing. PyQt4 (built on top of Nokia’s C++/Qt GUI toolkit) is probably the easiest-to-use cross- platform GUI library, and the one that arguably produces the best user interfaces—especially compared with tkinter. The book uses Python 2.5, although Python 3 versions of the examples are available from the book’s web site.",
      "content_length": 1831,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 605,
      "content": "Index\n\nAll functions and methods are listed under their class or module, and in most casesalsoastop-leveltermsin their own right.For modulesthat containclasses, look under the class for its methods. Where a method or function name is close enough to a concept, the concept is not usually listed. For example, there is no entry for “splitting strings”,but there are entries for the str.split() method.\n\nSymbols\n\n!= (not equal operator), 23, 241, 242,\n\n259, 379\n\n# comment character, 10 % (modulus/remainder operator), 55,\n\n253\n\n%= (modulusaugmented assignment\n\noperator), 253\n\n& (bitwise AND operator),57,122,123,\n\n130, 253\n\n+ (addition operator, concatenation operator), 55, 108, 114, 140, 253 += (addition augmented assignment operator, append/extend opera- tor), 108, 114, 115, 144, 253\n\n(subtraction operator, negation operator), 55, 122, 123, 253 -= (subtraction augmented assign- ment operator), 123, 253 / (division operator), 31, 55, 253 /= (division augmented assignment\n\n&= (bitwise AND augmented assign- ment operator), 123, 253 () (tuple creation operator, func-\n\noperator), 253\n\n// (truncating division operator),55,\n\n253, 330\n\ntion and method call operator, expression operator), 341, 377, 383\n\n//= (truncating division augmented assignment operator), 253 < (less than operator), 123, 145, 242,\n\n(multiplication operator, replica- tion operator,sequence unpack- er, from … import operator), 55, 72, 90, 108, 110, 114, 140, 197, 200–201, 253, 336, 379, 460\n\n(multiplication operator, replica- tion operator,sequence unpack- er, from … import operator), 55, 72, 90, 108, 110, 114, 140, 197, 200–201, 253, 336, 379, 460\n\n<< (int shift left operator), 57, 253 <<= (int shift left augmented assign-\n\nment operator), 253\n\n<= (less than or equal to operator),\n\n= (multiplication augmented as- signment operator, replication augmented assignment opera- tor), 72, 108, 114, 253\n\n= (multiplication augmented as- signment operator, replication augmented assignment opera- tor), 72, 108, 114, 253\n\n= (name binding operator,object ref- erencecreationandassignment operator), 16, 146\n\n** (power/exponentiation operator,\n\n== (equal to operator), 23, 241, 242,\n\nmapping unpacker), 55, 179, 253, 304, 379\n\n254, 259, 379\n\n> (greater than operator), 123, 242,\n\n**= (power/exponentiation aug-\n\n259, 379\n\nmented assignment operator), 253\n\n>= (greater than or equal to opera-\n\ntor), 123, 242, 259, 379\n\n>> (int shift right operator), 57, 253\n\n599",
      "content_length": 2437,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 606,
      "content": "600\n\n>>= (int shift right augmented as- signment operator), 253 @ (decorator operator), 246–248 [] (indexing operator, item access operator, slicing operator), 69, 108,110,113,114,116,117,262, 264, 273, 274, 278, 279, 293\n\n\\n (newline character, statement\n\nterminator), 66\n\n^ (bitwise XOR operator),57,122,123,\n\n253\n\n^= (bitwise XOR augmented assign- ment operator), 123, 253\n\n_ (underscore), 53 | (bitwise OR operator), 57, 122, 123,\n\n253\n\n|= (bitwise OR augmented assign- ment operator), 123, 253 ~ (bitwise NOT operator), 57, 253\n\nA\n\nabc module\n\nABCMeta type, 381, 384, 387 @abstractmethod(), 384, 387 abstractproperty(), 384, 387\n\n__abs__(), 253 abs() (built-in), 55, 56, 96, 145, 253 abspath() (os.path module), 223, 406 abstract base class (ABC), 269,\n\n380–388\n\nsee also collections and numbers\n\nmodules\n\nAbstract.py (example), 386 Abstract Syntax Tree (AST), 515 @abstractmethod() (abc module), 384,\n\n387\n\nabstractproperty() (abc module),\n\n384, 387\n\naccelerator, keyboard, 574, 580, 592 access control, 238, 249, 270, 271 acos() (math module), 60 acosh() (math module), 60 __add__() (+), 55, 253\n\nIndex\n\nadd() (set type), 123 aggregating data, 111 aggregation, 269 aifc module, 219 algorithm, for searching, 217, 272 algorithm, for sorting, 145, 282 algorithm, MD5, 449, 452 __all__ (attribute), 197, 200, 201 all() (built-in), 140, 184, 396, 397 alternation, regex, 494–495 __and__() (&), 57, 251, 253, 257 and (logical operator), 58 annotations, 360–363 __annotations__ (attribute), 360 anonymous functions; see lambda\n\nstatement\n\nany() (built-in), 140, 205, 396, 397 append()\n\nbytearray type, 299 list type, 115, 117, 118, 271\n\narchive ﬁles, 219 arguments, command-line, 215 arguments, function, 379 default, 173, 174, 175 immutable, 175 keyword, 174–175, 178, 179, 188,\n\n189, 362 mutable, 175 positional, 173–175, 178, 179,\n\n189, 362\n\nunpacking, 177–180\n\narguments, interpreter, 185, 198,\n\n199\n\nargv list (sys module), 41, 343 array module, 218 arraysize attribute (cursor object),\n\n482\n\nas_integer_ratio() (float type), 61 as (binding operator), 163, 196, 369 ascii() (built-in), 68, 83 ASCII encoding, 9, 68, 91–94, 220,\n\n293, 504\n\nsee also character encodings\n\nasin() (math module), 60 asinh() (math module), 60",
      "content_length": 2225,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 607,
      "content": "Index\n\naskopenfilename() (tkin-\n\nter.filedialog module), 586\n\nasksaveasfilename() (tkin-\n\nter.filedialog module), 585 askyesno() (tkinter.messagebox mod-\n\nule), 589\n\naskyesnocancel() (tkin-\n\nter.messagebox module), 584 assert (statement), 184–185, 205,\n\n208, 247\n\nAssertionError (exception), 184 assertions, regex, 496–499 associativity, 517–518, 551, 565 AST (Abstract Syntax Tree), 515 asynchat module, 225 asyncore module, 225 atan() (math module), 60 atan2() (math module), 60 atanh() (math module), 60 attrgetter() (operator module), 369,\n\n397 attribute\n\n__all__, 197, 200, 201 __annotations__, 360 __call__, 271, 350, 392 __class__, 252, 364, 366 __dict__, 348, 363, 364 __doc__, 357 __file__, 441 __module__, 243 __name__, 206, 252, 357, 362, 377 private, 238, 249, 270, 271, 366 __slots__, 363, 373, 375, 394 attribute access methods, table of,\n\n365\n\nAttributeError (exception), 240, 241,\n\n275, 350, 364, 366 attributes, 197, 200, 201,\n\n206, 246–248, 252, 271, 351, 363–367\n\nattributes, mutable and immutable,\n\n264\n\naudio-related modules, 219 audioop module, 219\n\naugmented assignment, 31–33, 56,\n\n108, 114\n\nB\n\nB option, interpreter, 199 backreferences,regex, 495 backtrace; see traceback backups, 414 base64 module, 219, 220–221 basename() (os.path module), 223 Berkeley DB, 475 bigdigits.py (example), 39–42 BikeStock.py (example), 332–336 bin() (built-in), 55, 253 binary data, 220 binary ﬁles, 295–304, 324–336 binary numbers, 56 binary search, 272 bindings, event, 576 bindings, keyboard, 576 bisect module, 217, 272 bit_length() (int type), 57 bitwise operators, table of, 57 block structure, using indentation,\n\n27\n\nblocks.py (example), 525–534,\n\n543–547, 559–562 BNF (Backus–Naur Form),\n\n515–518\n\nbookmarks-tk.pyw (example),\n\n578–593\n\n__bool__(), 250, 252, 258 bool() (built-in), 250 bool type, 58\n\nbool() (built-in), 58, 250, 309 conversion, 58\n\nBoolean expressions, 26, 54 branching; see if statement branching, with dictionaries,\n\n340–341\n\nbreak (statement), 161, 162\n\n601",
      "content_length": 1991,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 608,
      "content": "602\n\nbuilt-in\n\nabs(), 55, 56, 96, 145, 253 all(), 140, 184, 396, 397 any(), 140, 205, 396, 397 ascii(), 68, 83 bin(), 55, 253 bool(), 58, 250, 309 chr(), 67, 90, 504 @classmethod(), 257, 278 compile(), 349 complex(), 63, 253 delattr(), 349 dict(), 127, 147 dir(), 52, 172, 349, 365 divmod(), 55, 253 enumerate(), 139–141, 398, 524 eval(), 242, 243, 258, 266, 275,\n\n344, 349, 379\n\nexec(), 260, 345–346, 348, 349,\n\n351\n\nfilter(), 395, 397 float(), 61, 154, 253 format(), 250, 254 frozenset(), 125 getattr(),349,350,364,368,374,\n\n391, 409\n\nglobals(), 345, 349 hasattr(), 270, 349, 350, 391 hash(), 241, 250, 254 help(), 61, 172 hex(), 55, 253 id(), 254 __import__(), 349, 350 input(), 34, 96 int(), 55, 61, 136, 253, 309 isinstance(), 170, 216, 242, 270,\n\n382, 390, 391 issubclass(), 390 iter(), 138, 274, 281 len(), 71, 114, 122, 140, 265, 275 list(), 113, 147 locals(), 81, 82, 97, 154, 188, 189,\n\n190, 345, 349, 422, 423, 484\n\nmap(), 395, 397, 539 max(), 140, 154, 396, 397\n\nIndex\n\nbuilt-in (cont.)\n\nmin(), 140, 396, 397 next(), 138, 343, 401 oct(), 55, 253 ord(), 67, 90, 364 pow(), 55 print(), 11, 180, 181, 214, 422 @property(), 246–248, 376, 385,\n\n394\n\nrange(), 115, 118, 119, 140,\n\n141–142, 365 repr(), 242, 250 reversed(), 72, 140, 144, 265, 274 round(), 55, 56, 61, 252, 253, 258 set(), 122, 147 setattr(), 349, 379, 409 sorted(), 118, 133, 140, 144–146,\n\n270\n\n@staticmethod(), 255 str(), 65, 136, 243, 250 sum(), 140, 396, 397 super(), 241, 244, 256, 276, 282,\n\n381, 385 tuple(), 108 type(), 18, 348, 349 vars(), 349 zip(), 127, 140, 143–144, 205,\n\n389\n\nbuiltins module, 364 Button type (tkinter module), 581,\n\n591 byte-code, 198 byte order, 297 bytearray type, 293, 301, 383,\n\n418–419, 462\n\nappend(), 299 capitalize(), 299 center(), 299 count(), 299 decode(), 93, 94, 299, 326, 336,\n\n443\n\nendswith(), 299 expandtabs(), 299 extend(), 299, 301, 462 find(), 299",
      "content_length": 1867,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 609,
      "content": "Index\n\nbytearray type (cont.) fromhex(), 293, 299 index(), 299 insert(), 293, 299 isalnum(), 299 isalpha(), 299 isdigit(), 299 islower(), 299 isspace(), 299 istitle(), 300 isupper(), 300 join(), 300 ljust(), 300 lower(), 300 lstrip(), 300 methods, table of, 299, 300, 301 partition(), 300 pop(), 293, 300 remove(), 300 replace(), 293, 300 reverse(), 300 rfind(), 299 rindex(), 299 rjust(), 300 rpartition(), 300 rsplit(), 300 rstrip(), 300 split(), 300 splitlines(), 300 startswith(), 300 strip(), 300 swapcase(), 300 title(), 300 translate(), 300 upper(), 293, 301 zfill(), 301\n\nbytes type, 93, 293, 297, 383,\n\n418–419\n\ncapitalize(), 299 center(), 299 count(), 299 decode(), 93, 94, 226, 228, 299,\n\n302, 326, 336, 418, 443\n\nendswith(), 299 expandtabs(), 299\n\nbytes type (cont.) find(), 299 fromhex(), 293, 299 index(), 299 isalnum(), 299 isalpha(), 299 isdigit(), 299 islower(), 299 isspace(), 299 istitle(), 300 isupper(), 300 join(), 300 literal, 93, 220 ljust(), 300 lower(), 300 lstrip(), 300 methods, table of, 299, 300, 301 partition(), 300 replace(), 293, 300 rfind(), 299 rindex(), 299 rjust(), 300 rpartition(), 300 rsplit(), 300 rstrip(), 300 split(), 300 splitlines(), 300 startswith(), 300 strip(), 300 swapcase(), 300 title(), 300 translate(), 300 upper(), 293, 301 zfill(), 301\n\n.bz2 (extension), 219 bz2 module, 219\n\nC\n\nc option, interpreter, 198 calcsize() (struct module), 297 calendar module, 216 __call__ (attribute), 271, 350, 392 __call__(), 367, 368\n\n603",
      "content_length": 1477,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 610,
      "content": "604\n\ncall() (subprocess module), 209 callable; see functions and methods Callable ABC (collections module),\n\n383, 391\n\ncallable objects, 271, 367 capitalize()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\ncaptures, regex, 494–495, 506 car_registration_server.py (exam-\n\nple), 464–471\n\ncar_registration.py (example),\n\n458–464\n\ncase statement; see dictionary\n\nbranching\n\ncategory() (unicodedata module),\n\n361\n\nceil() (math module), 60 center()\n\nbytearray type, 299 bytes type, 299 str type, 73 cgi module, 225 cgitb module, 225 chaining exceptions, 419–420 changing dictionaries, 128 changing lists, 115 character class, regex, 491 character encodings, 9, 91–94, 314\n\nsee also ASCII encoding, Latin 1\n\nencoding, Unicode\n\nCharGrid.py (example), 207–212 chdir() (os module), 223 checktags.py (example), 169 choice() (random module), 142 chr() (built-in), 67, 90, 504 class (statement), 238, 244, 378,\n\n407\n\n__class__ (attribute), 252, 364, 366 class, mixin, 466 class decorators, 378–380, 407–409 class methods, 257 class variables, 255, 465 classes, immutable, 256, 261\n\nIndex\n\n@classmethod(), 257, 278 clear()\n\ndict type, 129 set type, 123\n\nclose()\n\nconnection object, 481 coroutines, 399, 401, 402 cursor object, 482 ﬁle object, 131, 167, 325\n\nclosed attribute (ﬁle object), 325 closures, 367, 369 cmath module, 63 code comments, 10 collation order (Unicode), 68–69 collections; see dict, list, set, and\n\ntuple types\n\ncollections, copying, 146–148 collections module, 217–219, 382\n\nCallable ABC, 383, 391 classes, table of, 383 Container ABC, 383 defaultdict type, 135–136, 153,\n\n183, 450\n\ndeque type, 218, 383 Hashable ABC, 383 Iterable ABC, 383 Iterator ABC, 383 Mapping ABC, 383 MutableMapping ABC, 269, 383 MutableSequence ABC, 269, 383 MutableSet ABC, 383 namedtuple type, 111–113, 234,\n\n365, 523\n\nOrderedDict type, 136–138, 218 Sequence ABC, 383 Set ABC, 383 Sized ABC, 383\n\ncombining functions, 395–397,\n\n403–407\n\ncommand-line arguments; see\n\nsys.argv list\n\ncomment character (#), 10 commit() (connection object), 481,\n\n483\n\ncomparing ﬁles and directories, 223",
      "content_length": 2071,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 611,
      "content": "Index\n\ncomparing objects, 23, 242 comparing strings, 68–69 comparisons; see <, <=, ==, !=, >, and\n\n>= operators\n\ncompile()\n\nbuilt-in, 349 re module, 310, 400, 500, 501,\n\n502, 521, 524 __complex__(), 253 complex() (built-in), 253 Complex ABC (numbers module), 381 complex type, 62–63, 381\n\ncomplex() (built-in), 63, 253 conjugate(), 62 imag attribute, 62 real attribute, 62\n\ncomposing functions, 395–397,\n\n403–407 composition, 269 comprehensions; see under dict,\n\nlist, and set types compressing ﬁles, 219 concatenation of lists, 114 of strings, 71 of tuples, 108\n\nconcepts, object-oriented, 235 conditional branching; see if state-\n\nment\n\nconditional expression, 160, 176,\n\n189\n\nconfigparser module, 220, 519 conﬁguration ﬁles, 220 conjugate() (complex type), 62 connect() (sqlite3 module), 481 connection object close(), 481 commit(), 481, 483 cursor(), 481, 483 methods, table of, 481 rollback(), 481 see also cursor object\n\nconstant set; see frozenset type constants, 149, 180, 364–365\n\n605\n\nContainer ABC(collections module),\n\n383\n\n__contains__(), 265, 274 context managers, 369–372, 452,\n\n464, 466\n\ncontextlib module, 370, 466 continue (statement), 161, 162 conversions, 57\n\ndate and time, 217 float to int, 61 int to character, 67 int to float, 61 to bool, 58 to complex, 63 to dict, 127 to float, 59, 154 to int, 15, 55 to list, 113, 139 to set, 122 to str, 15, 65 to tuple, 108, 139\n\nconvert-incidents.py (example),\n\n289–323\n\nCoordinated Universal Time (UTC),\n\n216\n\n__copy__(), 275 copy()\n\ncopy module, 147, 275, 282, 469 dict type, 129, 147 frozenset type, 123 set type, 123, 147\n\ncopy module, 245\n\ncopy(), 147, 275, 282, 469 deepcopy(), 148\n\ncopying collections, 146–148 copying objects, 245 copysign() (math module), 60 coroutines, 399–407\n\nclose(), 399, 401, 402 decorator, 401 send(), 401, 402, 405, 406\n\ncos() (math module), 60 cosh() (math module), 60 count()\n\nbytearray type, 299",
      "content_length": 1895,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 612,
      "content": "606\n\ncount() (cont.)\n\nbytes type, 299 list type, 115 str type, 73, 75 tuple type, 108\n\ncProfile module, 360, 432, 434–437 CREATE TABLE (SQL statement), 481 creation, of objects, 240 .csv (extension), 220 csv module, 220 csv2html.py (example), 97–102 csv2html2_opt.py (example), 215 ctypes module, 229 currying; see partial function appli-\n\ncation\n\ncursor() (connection object), 481,\n\n483 cursor object\n\narraysize attribute, 482 close(), 482 description attribute, 482 execute(), 481, 482, 483, 484, 485,\n\n486, 487\n\nexecutemany(), 482 fetchall(), 482, 485 fetchmany(), 482 fetchone(), 482, 484, 486 methods, table of, 482 rowcount attribute, 482 see also connection object custom exceptions, 168–171, 208 custom functions; see functions custom modules and packages,\n\n195–202\n\nD\n\ndaemon threads, 447, 448, 451 data persistence, 220 data structures;see dict, list, set,\n\nand tuple types\n\ndata type conversion; see conver-\n\nsions\n\nIndex\n\ndatabase connection; see connection\n\nobject\n\ndatabase cursor; see cursor object datetime.date type (datetime mod-\n\nule), 306\n\nfromordinal(), 301, 304 today(), 187, 477 toordinal(), 301\n\ndatetime.datetime type (datetime\n\nmodule) now(), 217 strptime(), 309 utcnow(), 217\n\ndatetime module, 186, 216 date type, 301, 309 datetime type, 309\n\nDB-API; see connection object and\n\ncursor object\n\ndeadlock, 445 __debug__ constant, 360 debug (normal) mode; see PYTHONOP-\n\nTIMIZE\n\ndebuggers; see IDLE and pdb mod-\n\nule\n\ndecimal module, 63–65\n\nDecimal(), 64 Decimal type, 63–65, 381\n\ndecode()\n\nbytearray type, 93, 94, 299, 326,\n\n336, 443\n\nbytes type, 93, 94, 226, 228, 299,\n\n302, 326, 336, 418, 443\n\nDecorate, Sort, Undecorate (DSU),\n\n140, 145\n\ndecorating methods and functions,\n\n356–360\n\ndecorator\n\nclass, 378–380, 407–409 @classmethod(), 257, 278 @functools.wraps(), 357 @property(), 246–248, 376, 385,\n\n394\n\n@staticmethod(), 255\n\ndedent() (textwrap module), 307",
      "content_length": 1884,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 613,
      "content": "Index\n\ndeep copying; see copying collec-\n\ntions\n\ndeepcopy() (copy module), 148 def (statement), 37, 173–176, 209,\n\n238\n\ndefault arguments, 173, 174, 175 defaultdict type (collections mod- ule), 135–136, 153, 183, 450\n\ndegrees() (math module), 60 del (statement), 116, 117, 127, 250,\n\n265, 273, 365\n\n__del__(), 250 __delattr__(), 364, 365 delattr() (built-in), 349 delegation, 378 DELETE (SQL statement), 487 __delitem__() ([]),265,266,273,279,\n\n329, 334\n\ndeque type (collections module),\n\n218, 383\n\ndescription attribute(cursor object),\n\n482\n\ndescriptors, 372–377, 407–409 detach() (stdin ﬁle object), 443 development environment (IDLE),\n\n13–14, 364, 424–425 dialogs, modal, 584, 587, 592 __dict__ (attribute), 348, 363, 364 dict type, 126–135, 383\n\nchanging, 128 clear(), 129 comparing, 126 comprehensions, 134–135 copy(), 129, 147 dict() (built-in), 127, 147 fromkeys(), 129 get(), 129, 130, 264, 351, 374,\n\n469\n\ninverting, 134 items(), 128, 129 keys(), 128, 129, 277 methods, table of, 129 pop(), 127, 129, 265 popitem(), 129 setdefault(), 129, 133, 374\n\ndict type (cont.)\n\nupdate(), 129, 188, 276, 295 updating, 128 values(), 128, 129 view, 129 see also collections.defaultdict, collections.OrderedDict, and SortedDict.py\n\ndictionary, inverting, 134 dictionary branching, 340–341 dictionary comprehensions,\n\n134–135, 278 dictionary keys, 135 difference_update() (set type), 123 difference()\n\nfrozenset type, 123 set type, 122, 123 difflib module, 213 digit_names.py (example), 180 __dir__(), 365 dir() (built-in), 52, 172, 349, 365 directories, comparing, 223 directories, temporary, 222 directory handling, 222–225 dirname() (os.path module), 223, 348 discard() (set type), 123, 124 __divmod__(), 253 divmod() (built-in), 55, 253 __doc__ (attribute), 357 docstrings, 176–177, 202, 204, 210,\n\n211, 247\n\nsee also doctest module\n\ndoctest module, 206–207, 211, 228,\n\n426–428\n\ndocumentation, 172 DOM (Document Object Model); see\n\nxml.dom module\n\nDomain-Speciﬁc Language (DSL),\n\n513\n\nDoubleVar type (tkinter module),\n\n574\n\nDSL (Domain-Speciﬁc Language),\n\n513\n\nDSU (Decorate, Sort, Undecorate),\n\n140, 145\n\n607",
      "content_length": 2107,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 614,
      "content": "608\n\nduck typing; see dynamic typing dump() (pickle module), 267, 294 dumps() (pickle module), 462 duplicates, eliminating, 122 dvds-dbm.py (example), 476–479 dvds-sql.py (example), 480–487 dynamic code execution, 260,\n\n344–346\n\ndynamic functions, 209 dynamic imports, 346–351 dynamic typing, 17, 237, 382\n\nE\n\ne (constant) (math module), 60 editor (IDLE), 13–14, 364, 424–425 element trees; see xml.etree pack-\n\nage\n\nelif (statement);see if statement else (statement);see for loop, if\n\nstatement, and while loop\n\nemail module, 226 encode() (str type), 73, 92, 93, 296,\n\n336, 419, 441\n\nencoding attribute (ﬁle object), 325 encoding errors, 167 encodings, 91–94 encodings, XML, 314 end() (match object), 507 END constant (tkinter module), 583,\n\n587, 588 endianness, 297 endpos attribute (match object), 507 endswith()\n\nbytearray type, 299 bytes type, 299 str type, 73, 75, 76 __enter__(), 369, 371, 372 entities, HTML, 504 Entry type (tkinter module), 591 enumerate() (built-in), 139–141, 398,\n\n524\n\nenums; see namedtuple type environ mapping (os module), 223\n\nIndex\n\nenvironment variable\n\nLANG, 87 PATH, 12, 13 PYTHONDONTWRITEBYTECODE, 199 PYTHONOPTIMIZE, 185, 199, 359,\n\n362\n\nPYTHONPATH, 197, 205\n\nEnvironmentError (exception), 167 EOFError (exception), 100 epsilon; see sys.float_info.epsilon\n\nattribute\n\n__eq__() (==), 241, 242, 244, 252, 254,\n\n259, 379\n\nerror handling; see exception han-\n\ndling\n\nerror-handling policy, 208 escape()\n\nre module, 502 xml.sax.saxutils module, 186,\n\n226, 320\n\nescapes, HTML and XML, 186, 316 escapes, string, 66, 67 escaping, newlines, 67 eval() (built-in), 242, 243, 258, 266,\n\n275, 344, 349, 379\n\nevent bindings, 576 event loop, 572, 578, 590 example\n\nAbstract.py, 386 bigdigits.py, 39–42 BikeStock.py, 332–336 BinaryRecordFile.py, 324–332 blocks.py, 525–534, 543–547,\n\n559–562\n\nbookmarks-tk.pyw, 578–593 car_registration_server.py,\n\n464–471\n\ncar_registration.py, 458–464 CharGrid.py, 207–212 checktags.py, 169 convert-incidents.py, 289–323 csv2html.py, 97–102 csv2html2_opt.py, 215 digit_names.py, 180 dvds-dbm.py, 476–479",
      "content_length": 2058,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 615,
      "content": "Index\n\nexample (cont.)\n\ndvds-sql.py, 480–487 external_sites.py, 132 ExternalStorage.py, 375 finddup.py, 224 findduplicates-t.py, 449–453 first-order-logic.py, 548–553,\n\n562–566\n\nFuzzyBool.py, 249–255 FuzzyBoolAlt.py, 256–261 generate_grid.py, 42–44 generate_test_names1.py, 142 generate_test_names2.py, 143 generate_usernames.py, 149–152 grepword-m.py, 448 grepword-p.py, 440–442 grepword.py, 139 grepword-t.py, 446–448 html2text.py, 503 Image.py, 261–269 IndentedList.py, 352–356 interest-tk.pyw, 572–578 magic-numbers.py, 346–351 make_html_skeleton.py, 185–191 noblanks.py, 166 playlists.py, 519–525, 539–543,\n\n555–559\n\nprint_unicode.py, 88–91 Property.py, 376 quadratic.py, 94–96 Shape.py, 238–245 ShapeAlt.py, 246–248 SortedDict.py, 276–283 SortedList.py, 270–275 SortKey.py, 368 statistics.py, 152–156 TextFilter.py, 385 TextUtil.py, 202–207 uniquewords1.py, 130 uniquewords2.py, 136 untar.py, 221 Valid.py, 407–409 XmlShadow.py, 373\n\nexcept (statement);see try state-\n\nment\n\n609\n\nexception\n\nAssertionError, 184 AttributeError, 240, 241, 275,\n\n350, 364, 366\n\ncustom, 168–171, 208 EnvironmentError, 167 EOFError, 100 Exception, 164, 165, 360, 418 ImportError, 198, 221, 350 IndexError, 69, 211, 273 IOError, 167 KeyboardInterrupt, 190, 418, 442 KeyError, 135, 164, 279 LookupError, 164 NameError, 116 NotImplementedError, 258, 381,\n\n385\n\nOSError, 167 StopIteration, 138, 279 SyntaxError, 54, 348, 414–415 TypeError, 57, 135, 138, 146, 167, 173,179,197,242,258,259,274, 364, 380\n\nUnicodeDecodeError, 167 UnicodeEncodeError, 93 ValueError, 57, 272, 279 ZeroDivisionError, 165, 416 Exception (exception), 164, 165, 360 exception handling, 163–171, 312\n\nsee also try statement exceptions, chaining, 419–420 exceptions, custom, 168–171, 208 exceptions, propagating, 370 exec() (built-in), 260, 345–346, 348,\n\n349, 351\n\nexecutable attribute (sys module),\n\n441\n\nexecute() (cursor object), 481, 482,\n\n483, 484, 485, 486, 487 executemany() (cursor object), 482 exists() (os.path module), 224, 327,\n\n481\n\n__exit__(), 369, 371, 372 exit() (sys module), 141, 215 exp() (math module), 60",
      "content_length": 2078,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 616,
      "content": "610\n\nexpand() (match object), 507 expandtabs()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nexpat XML parser, 315, 317, 318 expression, conditional, 160, 176,\n\n189\n\nexpressions, Boolean, 54 extend()\n\nbytearray type, 299, 301, 462 list type, 115, 116\n\nextending lists, 114 extension\n\n.bz2, 219 .csv, 220 .gz, 219, 228 .ini, 220, 519 .m3u, 522, 541, 557 .pls, 519, 539, 555 .py, 9, 195, 571 .pyc and .pyo, 199 .pyw, 9, 571 .svg, 525 .tar, .tar.gz, .tar.bz2, 219, 221 .tgz, 219, 221 .wav, 219 .xpm, 268 .zip, 219\n\nexternal_sites.py (example), 132 ExternalStorage.py (example), 375\n\nF\n\nfabs() (math module), 60 factorial() (math module), 60 factory functions, 136 False (built-in constant); see bool\n\ntype\n\nfetchall() (cursor object), 482, 485 fetchmany() (cursor object), 482 fetchone() (cursor object), 482, 484,\n\n486\n\n__file__ (attribute), 441\n\nFile associations, Windows, 11 ﬁle extension; see extension ﬁle globbing, 343 ﬁle handling, 222–225 ﬁle object, 370\n\nclose(), 131, 167, 325 closed attribute, 325 encoding attribute, 325 fileno(), 325 flush(), 325, 327 isatty(), 325 methods, table of, 325, 326 mode attribute, 325 name attribute, 325 newlines attribute, 325 __next__(), 325 open(), 131, 141, 167, 174, 267, 268, 327, 347, 369, 398, 443\n\npeek(), 325 read(), 131, 295, 302, 325, 347,\n\n443\n\nreadable(), 325 readinto(), 325 readline(), 325 readlines(), 131, 325 seek(), 295, 325, 327, 329 seekable(), 326 stderr (sys module), 184, 214 stdin (sys module), 214 stdin.detach(), 443 stdout (sys module), 181, 214 tell(), 326, 329 truncate(), 326, 331 writable(), 326 write(), 131, 214, 301, 326, 327 writelines(), 326 ﬁle sufﬁx; see extension ﬁle system interaction, 222–225 File Transfer Protocol (FTP), 226 filecmp module, 223 fileinput module, 214 fileno() (ﬁle object), 325 ﬁles; see ﬁle object and open() ﬁles, archive, 219 ﬁles, binary, 295–304, 324–336\n\nIndex",
      "content_length": 1874,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 617,
      "content": "Index\n\nﬁles, comparing, 223 ﬁles, compressing and uncompress-\n\ning, 219\n\nﬁles, format comparison, 288–289 ﬁles, random access; see binary ﬁles ﬁles, temporary, 222 ﬁles, text, 305–312 ﬁles, XML, 312–323 filter() (built-in), 395, 397 ﬁltering, 395, 403–407 finally (statement);see try state-\n\nment\n\nfind()\n\nbytearray type, 299 bytes type, 299 str type, 72–75, 133, 532\n\nfindall()\n\nre module, 502 regex object, 503\n\nfinddup.py (example), 224 findduplicates-t.py (example),\n\n449–453\n\nfinditer()\n\nre module, 311, 502 regex object, 401, 500, 501, 503\n\nfirst-order-logic.py (example),\n\n548–553, 562–566\n\nflags attribute (regex object), 503 __float__(), 252, 253 float_info.epsilon attribute (sys\n\nmodule), 61, 96, 343\n\nfloat() (built-in), 253 float type, 59–62, 381\n\nas_integer_ratio(), 61 float() (built-in), 61, 154, 253 fromhex(), 61 hex(), 61 is_integer(), 61\n\nfloor() (math module), 60 __floordiv__() (//), 55, 253 flush() (ﬁle object), 325, 327 fmod() (math module), 60 focus, keyboard, 574, 576, 577, 589,\n\n592\n\nfor loop, 120, 138, 141, 143, 162–163\n\n611\n\nforeign functions, 229 __format__(), 250, 254 format()\n\nbuilt-in, 250, 254 str type, 73, 78–88, 152, 156, 186,\n\n189, 249, 306, 531\n\nformat speciﬁcations, for strings,\n\n83–88\n\nformatting strings; see str.format() Fraction type (fractions module),\n\n381\n\nFrame type (tkinter module), 573,\n\n581, 591\n\nfrexp() (math module), 60 from (statement);seechaining excep- tions and import statement\n\nfromhex()\n\nbytearray type, 293, 299 bytes type, 293, 299 float type, 61\n\nfromkeys() (dict type), 129 fromordinal() (datetime.date type),\n\n301, 304\n\nfrozenset type, 125–126, 383\n\ncopy(), 123 difference(), 123 frozenset() (built-in), 125 intersection(), 123 isdisjoint(), 123 issubset(), 123 issuperset(), 123 methods, table of, 123 symmetric_difference(), 123\n\nfsum() (math module), 60 FTP (File Transfer Protocol), 226 ftplib module, 226 functions, 171–185\n\nannotations, 360–363 anonymous; see lambda state-\n\nment\n\ncomposing, 395–397, 403–407 decorating, 246–248, 356–360 dynamic, 209 factory, 136 foreign, 229",
      "content_length": 2054,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 618,
      "content": "612\n\nfunctions (cont.)\n\nlambda; see lambda statement local, 296, 319, 351–356 module, 256 object reference to, 136, 270, 341 parameters;seearguments,func-\n\ntion\n\nrecursive, 351–356 see also functors\n\nfunctions, introspection-related, ta-\n\nble of, 349\n\nfunctions, iterator, table of, 140 functions, nested; see local func-\n\ntions\n\nfunctions, table of (math module),\n\n60, 61\n\nfunctions, table of (re module), 502 functools module partial(), 398 reduce(), 396, 397 @wraps(), 357\n\nfunctors, 367–369, 385 FuzzyBool.py (example), 249–255 FuzzyBoolAlt.py (example), 256–261\n\nG\n\ngarbage collection, 17, 116, 218, 576,\n\n581, 593\n\n__ge__() (>=), 242, 259, 379 generate_grid.py (example), 42–44 generate_test_names1.py (example),\n\n142\n\ngenerate_test_names2.py (example),\n\n143\n\ngenerate_usernames.py (example),\n\n149–152 generator object send(), 343\n\ngenerators, 279, 342–344, 395, 396,\n\n401\n\n__get__(), 374, 375, 376, 377 get() (dict type), 129, 130, 264, 351,\n\n374, 469\n\nIndex\n\n__getattr__(), 365, 366 getattr() (built-in), 349, 350, 364,\n\n368, 374, 391, 409 __getattribute__(), 365, 366 getcwd() (os module), 223 __getitem__() ([]),264,265,273,328,\n\n334\n\ngetmtime() (os.path module), 224 getopt module; see optparse module getrecursionlimit() (sys module),\n\n352\n\ngetsize() (os.path module),134,224,\n\n407\n\ngettempdir() (tempfile module), 360 GIL (Global Interpreter Lock), 449 glob module, 344 global (statement), 210 global functions; see functions Global Interpreter Lock (GIL), 449 global variables, 180 globals() (built-in), 345, 349 globbing, 343 GMT; see Coordinated Universal\n\nTime grammar, 515 greedy regexes, 493 grepword-m.py (example), 448 grepword-p.py (example), 440–442 grepword.py (example), 139 grepword-t.py (example), 446–448 grid layout, 573, 575, 591 group() (match object),311,500,501,\n\n504, 507, 508, 521, 524\n\ngroupdict() (match object), 402, 507 groupindex attribute (regex object),\n\n503\n\ngroups() (match object), 507 groups, regex, 494–495, 506 __gt__() (>), 242, 259, 379 .gz (extension), 219, 228 gzip module, 219\n\nopen(), 228, 294 write(), 301",
      "content_length": 2060,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 619,
      "content": "Index\n\nH\n\nhasattr() (built-in), 270, 349, 350,\n\n391\n\n__hash__(), 250, 254 hash() (built-in), 241, 250, 254 Hashable ABC (collections module),\n\n383\n\nhashable objects, 121, 126, 130, 135,\n\n241, 254\n\nheapq module, 217, 218–219 help() (built-in), 61, 172 hex()\n\nbuilt-in, 55, 253 float type, 61\n\nhexadecimal numbers, 56 html.entities module, 504, 505 HTML escapes, 186 html.parser module, 226 html2text.py (example), 503 http package, 225 hypot() (math module), 60\n\nI\n\n__iadd__() (+=), 253 __iand__() (&=), 251, 253, 257 id() (built-in), 254 identiﬁers, 51–54, 127 identity testing;see is identity oper-\n\nator\n\nIDLE (programming environment),\n\n13–14, 364, 424–425 if (statement), 159–161 __ifloordiv__() (//=), 253 __ilshift__() (<<=), 253 Image.py (example), 261–269 IMAP4 (Internet Message Access\n\nProtocol), 226\n\nimaplib module, 226 immutable arguments, 175 immutable attributes, 264 immutable classes, 256, 261 immutable objects, 15, 16, 108, 113,\n\n126\n\n__imod__() (%=), 253 import (statement), 196–202, 348 __import__() (built-in), 349, 350 import order policy, 196 ImportError (exception), 198, 221,\n\n350\n\nimports, dynamic, 346–351 imports, relative, 202 __imul__() (*=), 253 in (membership operator), 114, 118,\n\n122, 140, 265, 274\n\nindentation, for block structure, 27 IndentedList.py (example), 352–356 __index__(), 253 index()\n\nbytearray type, 299 bytes type, 299 list type, 115, 118 str type, 72–75 tuple type, 108\n\nIndexError (exception), 69, 211, 273 indexing operator ([]), 273, 274 inﬁnite loop, 399, 406 inheritance, 243–245 inheritance, multiple, 388–390, 466 .ini (extension), 220, 519 __init__(), 241, 244, 249, 250, 270,\n\n276\n\ntype type, 391, 392\n\n__init__.py package ﬁle, 199, 200 initialization, of objects, 240 input() (built-in), 34, 96 INSERT (SQL statement), 483 insert()\n\nbytearray type, 293, 299 list type, 115, 117, 271\n\ninspect module, 362 installing Python, 4–6 instance variables, 241 __int__(), 252, 253, 258 int() (built-in), 253 int type, 54–57, 381 bit_length(), 57 bitwise operators, table of, 57 conversions, table of, 55\n\n613",
      "content_length": 2059,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 620,
      "content": "614\n\nint type (cont.)\n\nint() (built-in), 55, 61, 136, 253,\n\n309\n\nIntegral ABC (numbers module), 381 interest-tk.pyw (example), 572–578 internationalization, 86 Internet Message Access Protocol\n\n(IMAP4), 226\n\ninterpreter options, 185, 198, 199 intersection_update() (set type),\n\n123 intersection()\n\nfrozenset type, 123 set type, 122, 123\n\nintrospection, 350, 357, 360, 362 IntVar type (tkinter module), 574 __invert__() (~), 57, 250, 253, 257 inverting, a dictionary, 134 io module\n\nStringIO type, 213–214, 228 see also ﬁle object and open()\n\nIOError (exception), 167 __ior__() (|=), 253 IP address, 457, 458, 464 __ipow__() (**=), 253 __irshift__() (>>=), 253 is_integer() (float type), 61 is (identity operator), 22, 254 isalnum()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nisalpha()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nisatty() (ﬁle object), 325 isdecimal() (str type), 73 isdigit()\n\nbytearray type, 299 bytes type, 299 str type, 73, 76\n\nisdir() (os.path module), 224 isdisjoint()\n\nfrozenset type, 123\n\nIndex\n\nisdisjoint() (cont.) set type, 123\n\nisfile() (os.path module), 134, 224,\n\n344, 406\n\nisidentifier() (str type), 73, 348 isinf() (math module), 60 isinstance() (built-in),170,216,242,\n\n270, 382, 390, 391\n\nislower()\n\nbytearray type, 299 bytes type, 299 str type, 73\n\nisnan() (math module), 60 isnumeric() (str type), 74 isprintable() (str type), 74 isspace()\n\nbytearray type, 299 bytes type, 299 str type, 74, 531\n\nissubclass() (built-in), 390 issubset()\n\nfrozenset type, 123 set type, 123\n\nissuperset()\n\nfrozenset type, 123 set type, 123\n\nistitle()\n\nbytearray type, 300 bytes type, 300 str type, 74 __isub__() (-=), 253 isupper()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nitem access operator ([]), 262, 264,\n\n273, 274, 278, 279, 293\n\nitemgetter() (operator module), 397 items() (dict type), 128, 129 __iter__(), 265, 274, 281, 335 iter() (built-in), 138, 274, 281 iterable; see iterators Iterable ABC (collections module),\n\n383",
      "content_length": 1970,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 621,
      "content": "Index\n\nIterator ABC (collections module),\n\n383\n\niterators, 138–146\n\nfunctions and operators, table\n\nof, 140\n\nitertools module, 397 __ixor__() (^=), 253\n\nJ\n\njoin()\n\nbytearray type, 300 bytes type, 300 os.path module, 223, 224 str type, 71, 72, 189\n\njson module, 226\n\nK\n\nkey bindings, 576 keyboard accelerators, 574, 580,\n\n592\n\nkeyboard focus, 574, 576, 577, 589,\n\n592\n\nkeyboard shortcuts, 577, 580 KeyboardInterrupt (exception), 190,\n\n418, 442\n\nKeyError (exception), 135, 164, 279 keys() (dict type), 128, 129, 277 keyword arguments, 174–175, 178,\n\n179, 188, 189, 362 keywords, table of, 52\n\nL\n\nLabel type (tkinter module), 574,\n\n582, 583, 591\n\nlambda (statement), 182–183, 379, 380, 388, 396, 467, 504 LANG (environment variable), 87 lastgroup attribute (match object),\n\n507\n\nlastindex attribute (match object),\n\n507, 508\n\n615\n\nLatin 1 encoding, 91, 93 layouts, 573, 575, 591 lazy evaluation, 342 ldexp() (math module), 60 __le__() (<=), 242, 259, 379 __len__(), 265, 330 len() (built-in), 71, 114, 122, 140,\n\n265, 275\n\nlexical analysis, 514 library, standard, 212–229 LifoQueue type (queue module), 446 linear search, 272 list comprehensions, 118–120, 189,\n\n210, 396\n\nlist type, 113–120, 383\n\nappend(), 115, 117, 118, 271 changing, 115 comparing, 113, 114 comprehensions, 118–120, 396 count(), 115 extend(), 115, 116 index(), 115, 118 insert(), 115, 117, 271 list() (built-in), 113, 147 methods, table of, 115 pop(), 115, 117, 118 remove(), 115, 117, 118 replication (*, *=), 114, 118 reverse(), 115, 118 slicing, 113, 114, 116–118 sort(), 115, 118, 182, 368, 397 updating, 115 see also SortedList.py\n\nListbox type (tkinter module), 582,\n\n583, 587, 588, 589\n\nlistdir() (os module), 134, 223, 224,\n\n348 ljust()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nload() (pickle module), 268, 295 loads() (pickle module), 462 local functions, 296, 319, 351–356 local variables, 163",
      "content_length": 1879,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 622,
      "content": "616\n\nlocale module, 86\n\nsetlocale(), 86, 87\n\nlocalization, 86 locals() (built-in), 81, 82, 97, 154,\n\n188,189,190,345,349,422,423, 484\n\nlocaltime() (time module), 217 Lock type (threading module), 452,\n\n467\n\nlog() (math module), 60 log10() (math module), 60 log1p() (math module), 60 logging module, 229, 360 logic, short-circuit, 25, 58 logical operators; see and, or, and\n\nnot\n\nLookupError (exception), 164 looping, see for loop and while loop,\n\n161 lower()\n\nbytearray type, 300 bytes type, 300 str type, 74, 76\n\n__lshift__() (<<), 57, 253 lstrip()\n\nbytearray type, 300 bytes type, 300 str type, 75, 76\n\n__lt__() (<), 242, 252, 259, 379\n\nM\n\n.m3u (extension), 522, 541, 557 magic number, 294 magic-numbers.py (example),\n\n346–351\n\nmailbox module, 226 make_html_skeleton.py (example),\n\n185–191\n\nmakedirs() (os module), 223 maketrans() (str type), 74, 77–78 mandatory parameters, 174 map() (built-in), 395, 397, 539 mapping, 395\n\nIndex\n\nMapping ABC (collections module),\n\n383\n\nmapping types; see dict and collec-\n\ntions.defaultdict\n\nmapping unpacking (**), 179, 187,\n\n304 match()\n\nre module, 502, 521, 524 regex object, 503\n\nmatch object end(), 507 endpos attribute, 507 expand(), 507 group(), 311, 500, 501, 504, 507,\n\n508, 521, 524\n\ngroupdict(), 402, 507 groups(), 507 lastgroup attribute, 507 lastindex attribute, 507, 508 methods, table of, 507 pos attribute, 507 re attribute, 507 span(), 507 start(), 507 string attribute, 507 see also re module and regex ob-\n\nject\n\nmath module, 62 acos(), 60 acosh(), 60 asin(), 60 asinh(), 60 atan(), 60 atan2(), 60 atanh(), 60 ceil(), 60 copysign(), 60 cos(), 60 cosh(), 60 degrees(), 60 e (constant), 60 exp(), 60 fabs(), 60 factorial(), 60 floor(), 60",
      "content_length": 1693,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 623,
      "content": "Index\n\nmath module (cont.)\n\nfmod(), 60 frexp(), 60 fsum(), 60 functions, table of, 60, 61 hypot(), 60 isinf(), 60 isnan(), 60 ldexp(), 60 log(), 60 log10(), 60 log1p(), 60 modf(), 60 pi (constant), 61 pow(), 61 radians(), 61 sin(), 61 sinh(), 61 sqrt(), 61, 96 tan(), 61 tanh(), 61 trunc(), 61\n\nmax() (built-in), 140, 154, 396, 397 maxunicode attribute (sys module),\n\n90, 92\n\nMD5 (Message Digest algorithm),\n\n449, 452\n\nmembership testing; see in opera-\n\ntor\n\nmemoizing, 351 memory management; see garbage\n\ncollection\n\nMenu type (tkinter module), 579, 580 Message Digest algorithm (MD5),\n\n449, 452\n\nmetaclasses, 381, 384, 390–395 methods\n\nattribute access, table of, 365 bytearray type, table of, 299, 300,\n\n301\n\nbytes type, table of, 299, 300,\n\n301\n\nclass, 257\n\nmethods (cont.)\n\nconnection object, table of, 481 cursor object, table of, 482 decorating, 246–248, 356–360 dict type, table of, 129 ﬁle object, table of, 325, 326 frozenset type, table of, 123 list type, table of, 115 match object, table of, 507 object reference to, 377 regex object, table of, 503 set type, table of, 123 static, 257 str type, table of, 73, 74, 75 unimplementing, 258–261 see also special method\n\nmimetypes module, 224 min() (built-in), 140, 396, 397 minimal regexes, 493, 504 missing dictionary keys, 135 mixin class, 466 mkdir() (os module), 223 __mod__() (%), 55, 253 modal dialogs, 584, 587, 592 mode attribute (ﬁle object), 325 modf() (math module), 60 __module__ (attribute), 243 module functions, 256 modules, 195–202, 348 modules attribute (sys module), 348 __mul__() (*), 55, 253 multiple inheritance, 388–390, 466 multiprocessing module, 448, 453 mutable arguments, 175 mutable attributes, policy, 264 mutable objects; see immutable ob-\n\njects\n\nMutableMapping ABC (collections\n\nmodule), 269, 383\n\nMutableSequence ABC (collections\n\nmodule), 269, 383\n\nMutableSet ABC (collections mod-\n\nule), 383\n\n617",
      "content_length": 1889,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 624,
      "content": "618\n\nN\n\n__name__ (attribute), 206, 252, 357,\n\n362, 377\n\nname() (unicodedata module), 90 name attribute (ﬁle object), 325 name conﬂicts, avoiding, 198, 200 name mangling, 366, 379 namedtuple type (collections mod-\n\nule), 111–113, 234, 365, 523\n\nNameError (exception), 116 names, qualiﬁed, 196 namespace, 236 naming policy, 176–177 __ne__() (!=), 241, 242, 259, 379 __neg__() (-), 55, 253 nested collections;see dict, list, set,\n\nand tuple types\n\nnested functions; see local functions Network News Transfer Protocol\n\n(NNTP), 226\n\n__new__(), 250\n\nobject type, 256 type type, 392, 394 newline escaping, 67 newlines attribute (ﬁle object), 325 __next__(), 325, 343 next() (built-in), 138, 343, 401 NNTP (Network News Transfer\n\nProtocol), 226\n\nnntplib module, 226 noblanks.py (example), 166 None object, 22, 23, 26, 173 nongreedy regexes, 493, 504 nonlocal (statement), 355, 379 nonterminal, 515 normal (debug) mode; see PYTHONOP-\n\nTIMIZE\n\nnormalize() (unicodedata module),\n\n68\n\nnot (logical operator), 58 NotImplemented object, 242, 258, 259 NotImplementedError (exception),\n\n258, 381, 385\n\nnow() (datetime.datetime type), 217\n\nIndex\n\nNumber ABC (numbers module), 381 numbers module, 216, 382 classes, table of, 381 Complex ABC, 381 Integral ABC, 381 Number ABC, 381 Rational ABC, 381 Real ABC, 381\n\nnumeric operators and functions,\n\ntable of, 55\n\nO\n\nO option, interpreter, 185, 199, 359, 362\n\nobject creation and initialization,\n\n240\n\nobject-oriented concepts and termi-\n\nnology, 235\n\nobject references, 16–18, 19, 110,\n\n116,126,136,142,146,250,254, 281, 340, 345, 356, 367, 377, 576\n\nobject type, 380\n\n__new__(), 256 __repr__(), 266\n\nobjects, comparing, 23, 242 obtaining Python, 4–6 oct() (built-in), 55, 253 octal numbers, 56 open()\n\nﬁle object,131,141,167,174,267,\n\n268, 327, 347, 369, 398, 443\n\ngzip module, 228, 294 shelve module, 476 operator module, 396\n\nattrgetter(), 369, 397 itemgetter(), 397\n\noperators, iterator, table of, 140 optimized mode; see PYTHONOPTIMIZE optional parameters, 174 options, for interpreter, 185, 198,\n\n199, 359, 362 optparse module, 215 __or__() (|), 57, 253",
      "content_length": 2089,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 625,
      "content": "Index\n\nor (logical operator), 58 ord() (built-in), 67, 90, 364 ordered collections; see list and tu-\n\nple types\n\nOrderedDict type (collections mod-\n\nule), 136–138, 218\n\nos module, 223, 224–225\n\nchdir(), 223 environ mapping, 223 getcwd(), 223 listdir(), 134, 223, 224, 348 makedirs(), 223 mkdir(), 223 remove(), 223, 332 removedirs(), 223 rename(), 223, 332 rmdir(), 223 sep attribute, 142 stat(), 223, 407 system(), 444 walk(), 223, 224, 406\n\nos.path module, 197, 223, 224–225\n\nabspath(), 223, 406 basename(), 223 dirname(), 223, 348 exists(), 224, 327, 481 getmtime(), 224 getsize(), 134, 224, 407 isdir(), 224 isfile(), 134, 224, 344, 406 join(), 223, 224 split(), 223 splitext(), 223, 268, 348\n\nOSError (exception), 167\n\nP\n\npack() (struct module), 296, 297,\n\n301, 336\n\npackage directories, 205 packages, 195–202 packrat parsing, 549 parameters; see arguments, func-\n\ntion\n\nparameters, unpacking, 177–180 parent–child relationships, 572,\n\n576 parsing\n\ncommand-line arguments, 215 dates and times, 216 text ﬁles, 307–310 with PLY, 553–566 with PyParsing, 534–553 with regexes, 310–312, 519–525 XML (with DOM), 317–319 XML (with SAX), 321–323 XML (with xml.etree), 315–316 partial() (functools module), 398 partial function application,\n\n398–399\n\npartition()\n\nbytearray type, 300 bytes type, 300 str type, 74, 76\n\npass (statement), 26, 160, 381, 385 PATH (environment variable), 12, 13 path attribute (sys module), 197 paths, Unix-style, 142 pattern attribute (regex object), 503 pdb module, 423–424 peek() (ﬁle object), 325 PEP 249 (Python Database API Speciﬁcation v2.0), 480\n\nPEP 3107 (Function Annotations),\n\n363\n\nPEP 3119 (Introducing Abstract\n\nBase Classes), 380\n\nPEP 3131 (Supporting Non-ASCII\n\nIdentiﬁers), 52\n\nPEP 3134 (Exception Chaining and Embedded Tracebacks), 420\n\npersistence, of data, 220 PhotoImage type (tkinter module),\n\n581\n\npi (constant) (math module), 61 pickle module, 292–295 dump(), 267, 294 dumps(), 462 load(), 268, 295\n\n619",
      "content_length": 1951,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 626,
      "content": "620\n\npickle module (cont.)\n\nloads(), 462\n\npickles, 266, 292–295, 476 pipelines, 403–407 pipes; see subprocess module placeholders, SQL, 483, 484 platform attribute (sys module), 160,\n\n209, 344\n\nplaylists.py (example), 519–525,\n\n539–543, 555–559\n\n.pls (extension), 519, 539, 555 PLY\n\np_error(), 555 precedence variable, 555, 565 states variable, 557–558 t_error(), 554, 556 t_ignore variable, 559 t_newline(), 556 tokens variable, 554, 555, 557\n\npointers; see object references policy, error handling, 208 policy, import order, 196 policy, mutable attributes, 264 policy, naming, 176–177 polymorphism, 243–245 pop()\n\nbytearray type, 293, 300 dict type, 127, 129, 265 list type, 115, 117, 118 set type, 123\n\nPOP3 (Post Ofﬁce Protocol), 226 Popen() (subprocess module), 441 popitem() (dict type), 129 poplib module, 226 __pos__() (+), 55, 253 pos attribute (match object), 507 positional arguments, 173–175, 178,\n\n179, 189, 362\n\nPost Ofﬁce Protocol (POP3), 226 __pow__() (**), 55, 253 pow()\n\nbuilt-in, 55 math module, 61 pprint module, 229, 355 precedence, 517–518, 551, 565\n\nIndex\n\nprint_unicode.py (example), 88–91 print() (built-in), 11, 180, 181, 214,\n\n422\n\nPriorityQueue type (queue module),\n\n446, 450\n\nprivate attributes, 238, 249, 270,\n\n271, 366\n\nprocessing pipelines, 403–407 processor endianness, 297 profile module, 432, 434–437 propagating exceptions, 370 properties, 246–248 @property(), 246–248, 376, 385, 394 Property.py (example), 376 .py (extension), 9, 195, 571 .pyc and .pyo (extension), 199 PyGtk, 570, 593 PyParsing\n\n+ (concatenation operator), 536, 539, 541, 543, 544, 545, 550 - (concatenation operator), 544,\n\n545\n\n<< (append operator), 538, 544,\n\n550\n\n| (OR operator),536,539,541,543,\n\n544, 550\n\nalphanums, 535 alphas, 535 CaselessLiteral(), 535 CharsNotIn(), 536, 539, 543 Combine(), 541 delimitedList(), 536, 538, 550 Empty(), 537 Forward(), 538, 544, 550 Group(), 544, 550, 551 Keyword(), 535, 550 LineEnd(), 541, 542 Literal(), 535, 540, 550 makeHTMLTags(), 536 nums, 541 OneOrMore(), 536, 539, 541, 544 operatorPrecedence(), 550–551 Optional(), 536, 537, 541, 544 pythonStyleComment, 536 quotedString, 536",
      "content_length": 2131,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 627,
      "content": "Index\n\nPyParsing (cont.) Regex(), 536 restOfLine, 536, 539, 541 SkipTo(), 536 Suppress(), 535, 536, 539, 541 Word(), 535, 539, 541, 543 ZeroOrMore(), 536, 538, 544\n\nPyQt, 570, 593 PYTHONDONTWRITEBYTECODE (environ-\n\nment variable), 199\n\nPython enhancement proposals; see\n\nPEPs\n\nPython Shell (IDLE or interpreter),\n\n13\n\nPYTHONOPTIMIZE (environment vari- able), 185, 199, 359, 362\n\nPYTHONPATH (environment variable),\n\n197, 205\n\n.pyw (extension), 9, 571\n\nQ\n\nquadratic.py (example), 94–96 qualiﬁed names, 196 quantiﬁers, regex, 491–494 queue module\n\nLifoQueue type, 446 PriorityQueue type, 446, 450 Queue type, 446, 447, 450\n\nQueue type (queue module), 446, 447,\n\n450\n\nquopri module, 219 quoteattr() (xml.sax.saxutils mod-\n\nule), 226, 320\n\nR\n\n__radd__() (+), 253 radians() (math module), 61 raise (statement), 167, 211, 350,\n\n360\n\nsee also try statement\n\n__rand__() (&), 253 random access ﬁles; see binary ﬁles\n\n621\n\nrandom module\n\nchoice(), 142 sample(), 143\n\nrange() (built-in), 115, 118, 119, 140,\n\n141–142, 365\n\nRational ABC (numbers module), 381 raw binary data; see binary ﬁles raw strings, 67, 204, 310, 500, 556 __rdivmod__(), 253 re attribute (match object), 507 re module, 499–509\n\ncompile(), 310, 400, 500, 501, 502,\n\n521, 524 escape(), 502 findall(), 502 finditer(), 311, 502 functions, table of, 502 match(), 502, 521, 524 search(), 500, 502, 508 split(), 502, 509 sub(), 502, 504, 505 subn(), 502 see also match object and regex\n\nobject\n\nread() (ﬁleobject),131,295,302,325,\n\n347, 443\n\nreadable() (ﬁle object), 325 readinto() (ﬁle object), 325 readline() (ﬁle object), 325 readlines() (ﬁle object), 131, 325 Real ABC (numbers module), 381 records; see struct module recursive descent parser, 529 recursive functions, 351–356 recv() (socket module), 462, 463 reduce() (functools module), 396,\n\n397 reducing, 395 references; see object references regex\n\nalternation, 494–495 assertions, 496–499 backreferences, 495 captures, 494–495, 506 character classes, 491",
      "content_length": 1966,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 628,
      "content": "622\n\nregex (cont.)\n\nﬂags, 400, 499, 500 greedy, 493, 504 groups, 494–495, 506 match; see match object nongreedy, 493, 504 quantiﬁers, 491–494 special characters, 491\n\nregex object\n\nfindall(), 503 finditer(), 401, 500, 501, 503 flags attribute, 503 groupindex attribute, 503 match(), 503 methods, table of, 503 pattern attribute, 503 search(), 500, 503 split(), 503, 509 sub(), 503 subn(), 503 see also re module and match ob-\n\nject\n\nrelational integrity, 481 relative imports, 202 remove()\n\nbytearray type, 300 list type, 115, 117, 118 os module, 223, 332 set type, 123\n\nremovedirs() (os module), 223 rename() (os module), 223, 332 replace()\n\nbytearray type, 293, 300 bytes type, 293, 300 str type, 74, 77, 101\n\nreplication (*, *=)\n\nof lists, 114, 118 of strings, 72, 90 of tuples, 108\n\n__repr__(), 242, 244, 250, 252, 258,\n\n281\n\nobject type, 266\n\nrepr() (built-in), 242, 250 representational form, 82–83 resizable windows, 582–583, 591\n\nIndex\n\nreturn (statement), 161, 162, 173 reverse()\n\nbytearray type, 300 list type, 115, 118 __reversed__(), 265, 274 reversed() (built-in), 72, 140, 144,\n\n265\n\nreversing strings, 71, 72 rfind()\n\nbytearray type, 299 bytes type, 299 str type, 73, 75, 76 __rfloordiv__() (//), 253 rindex()\n\nbytearray type, 299 bytes type, 299 str type, 73, 75\n\nrjust()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\n__rlshift__() (<<), 253 rmdir() (os module), 223 __rmod__() (%), 253 __rmul__() (*), 253 rollback() (connection object), 481 __ror__() (|), 253 __round__(), 253 round() (built-in),55,56,61,252,253,\n\n258\n\nrowcount attribute (cursor object),\n\n482 rpartition()\n\nbytearray type, 300 bytes type, 300 str type, 74, 76 __rpow__() (**), 253 __rrshift__() (>>), 253 __rshift__() (>>), 57, 253 rsplit()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nrstrip()\n\nbytearray type, 300",
      "content_length": 1812,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 629,
      "content": "Index\n\nrstrip() (cont.)\n\nbytes type, 300 str type, 75, 76 __rsub__() (-), 253 __rtruediv__() (/), 253 run() (Thread type), 445, 448 __rxor__() (^), 253\n\nS\n\nsample() (random module), 143 SAX (Simple API for XML); see\n\nxml.sax module\n\nScalable Vector Graphics (SVG),\n\n525\n\nScale type (tkinter module), 574,\n\n575 scanning, 514 Scrollbar type (tkinter module),\n\n582 search()\n\nre module, 500, 502, 508 regex object, 500, 503\n\nsearching, 272 seek() (ﬁle object), 295, 325, 327,\n\n329\n\nseekable() (ﬁle object), 326 SELECT (SQL statement), 484, 485,\n\n486\n\nself object, 239, 257, 469 send()\n\ncoroutines, 401, 402, 405, 406 generator object, 343 socket module, 463\n\nsendall() (socket module), 462, 463 sep attribute (os module), 142 Sequence ABC (collections module),\n\n383\n\nsequence types; see bytearray, bytes, list, str, and tuple types sequence unpacking (*), 110,\n\n114–115, 141, 162, 178, 336, 460\n\nserialized data access, for threads,\n\n446\n\n623\n\nserializing; see pickles __set__(), 375, 377 Set ABC (collections module), 383 set comprehensions, 125 set type, 121–125, 130, 383\n\nadd(), 123 clear(), 123 comprehensions, 125 copy(), 123, 147 difference_update(), 123 difference(), 122, 123 discard(), 123, 124 intersection_update(), 123 intersection(), 122, 123 isdisjoint(), 123 issubset(), 123 issuperset(), 123 methods, table of, 123 pop(), 123 remove(), 123 set() (built-in), 122, 147 symmetric_difference_update(),\n\n123\n\nsymmetric_difference(), 122, 123 union(), 122, 123 update(), 123\n\nset types; see frozenset and set\n\ntypes\n\n__setattr__(), 364, 365 setattr() (built-in), 349, 379, 409 setdefault() (dict type), 129, 133,\n\n374\n\n__setitem__() ([]), 265, 274, 278,\n\n327\n\nsetlocale() (locale module), 86, 87 setrecursionlimit() (sys module),\n\n352\n\nshallow copying; see copying collec-\n\ntions\n\nShape.py (example), 238–245 ShapeAlt.py (example), 246–248 shebang (shell execute), 12 Shell, Python (IDLE or interpreter),\n\n13\n\nshell execute (#!), 12",
      "content_length": 1939,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 630,
      "content": "624\n\nshelve module, 220, 476\n\nopen(), 476 sync(), 477\n\nshort-circuit logic, 25, 58 shortcut, keyboard, 577, 580 showwarning() (tkinter.messagebox\n\nmodule), 585, 587\n\nshutil module, 222 Simple API for XML (SAX); see\n\nxml.sax module\n\nSimple Mail Transfer Protocol\n\n(SMTP), 226 sin() (math module), 61 single shot timer, 582, 586 sinh() (math module), 61 site-packages directory, 205 Sized ABC (collections module),\n\n383 slicing ([])\n\nbytes, 293 lists, 113, 114, 116–118 operator, 69, 110, 116, 273, 274,\n\n397\n\nstrings, 69–71, 151 tuples, 108\n\n__slots__ (attribute), 363, 373, 375,\n\n394\n\nSMTP (Simple Mail Transfer Proto-\n\ncol), 226 smtpd module, 226 smtplib module, 226 sndhdr module, 219 socket module, 225, 457 recv(), 462, 463 send(), 463 sendall(), 462, 463 socket(), 464\n\nsocketserver module, 225, 464, 466 sort() (list type),115, 118,182,368,\n\n397\n\nsort algorithm, 145, 282 sorted() (built-in), 118, 133, 140,\n\n144–146, 270\n\nSortedDict.py (example), 276–283 SortedList.py (example), 270–275\n\nIndex\n\nSortKey.py (example), 368 sound-related modules, 219 span() (match object), 507 special characters, regex, 491 special method, 235, 239\n\n__abs__(), 253 __add__() (+), 55, 253 __and__() (&), 57, 251, 253, 257 bitwise and numeric methods,\n\ntable of, 253\n\n__bool__(), 250, 252, 258 __call__(), 367, 368 collection methods, table of, 265 comparison methods, table of,\n\n242\n\n__complex__(), 253 __contains__(), 265, 274 __copy__(), 275 __del__(), 250 __delattr__(), 364, 365 __delitem__() ([]), 265, 266, 273,\n\n279, 329, 334 __dir__(), 365 __divmod__(), 253 __enter__(), 369, 371, 372 __eq__() (==), 241, 242, 244, 252,\n\n254, 259, 379\n\n__exit__(), 369, 371, 372 __float__(), 252, 253 __floordiv__() (//), 55, 253 __format__(), 250, 254 fundamental methods, table of,\n\n250\n\n__ge__() (>=), 242, 259, 379 __get__(), 374, 375, 376, 377 __getattr__(), 365, 366 __getattribute__(), 365, 366 __getitem__() ([]), 264, 265, 273,\n\n328, 334\n\n__gt__() (>), 242, 259, 379 __hash__(), 250, 254 __iadd__() (+=), 253 __iand__() (&=), 251, 253, 257 __ifloordiv__() (//=), 253 __ilshift__() (<<=), 253",
      "content_length": 2080,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 631,
      "content": "Index\n\nspecial method (cont.) __imod__() (%=), 253 __imul__() (*=), 253 __index__(), 253 __init__(), 241, 244, 249, 250,\n\n270, 276, 391, 392\n\n__int__(), 252, 253, 258 __invert__() (~), 57, 250, 253, 257 __ior__() (|=), 253 __ipow__() (**=), 253 __irshift__() (>>=), 253 __isub__() (-=), 253 __iter__(), 265, 274, 281, 335 __ixor__() (^=), 253 __le__() (<=), 242, 259, 379 __len__(), 265, 330 __lshift__() (<<), 57, 253 __lt__() (<), 242, 252, 259, 379 __mod__() (%), 55, 253 __mul__() (*), 55, 253 __ne__() (!=), 241, 242, 259, 379 __neg__() (-), 55, 253 __new__(), 250, 256, 392 __next__(), 325, 343 __or__() (|), 57, 253 __pos__() (+), 55, 253 __pow__() (**), 55, 253 __radd__() (+), 253 __rand__() (&), 253 __rdivmod__(), 253 __repr__(), 242, 244, 250, 252,\n\n258, 281\n\n__reversed__(), 265, 274 __rfloordiv__() (//), 253 __rlshift__() (<<), 253 __rmod__() (%), 253 __rmul__() (*), 253 __ror__() (|), 253 __round__(), 253 __rpow__() (**), 253 __rrshift__() (>>), 253 __rshift__() (>>), 57, 253 __rsub__() (-), 253 __rtruediv__() (/), 253 __rxor__() (^), 253\n\nspecial method (cont.) __set__(), 375, 377 __setattr__(), 364, 365 __setitem__() ([]), 265, 274, 278,\n\n327\n\n__str__(), 243, 244, 250, 252 __sub__() (-), 55, 253 __truediv__() (/), 31, 55, 253 __xor__() (^), 57, 253\n\nsplit()\n\nbytearray type, 300 bytes type, 300 os.path module, 223 re module, 502, 509 regex object, 503, 509 str type, 74, 77, 509\n\nsplitext() (os.path module), 223,\n\n268, 348 splitlines()\n\nbytearray type, 300 bytes type, 300 str type, 74\n\nSQL databases, 475, 480 SQL placeholders, 483, 484 SQL statement\n\nCREATE TABLE, 481 DELETE, 487 INSERT, 483 SELECT, 484, 485, 486 UPDATE, 484\n\nsqlite3 module, 480, 481\n\nconnect(), 481\n\nsqrt() (math module), 61, 96 ssl module, 225 standard library, 212–229 starred arguments, 114, 460 starred expressions; see sequence\n\nunpacking\n\nstart()\n\nmatch object, 507 Thread type, 445\n\nstart symbol, 516 startswith()\n\nbytearray type, 300 bytes type, 300\n\n625",
      "content_length": 1962,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 632,
      "content": "626\n\nstartswith() (cont.)\n\nstr type, 74, 75, 76\n\nstat() (os module), 223, 407 statement\n\nassert, 184–185, 205, 208, 247 break, 161, 162 class, 238, 244, 378, 407 continue, 161, 162 def, 37, 173–176, 209, 238 del, 116, 117, 127, 250, 265, 273,\n\n365\n\nglobal, 210 if, 159–161 import, 196–202, 348 lambda, 182–183, 379, 380, 388,\n\n396, 467, 504 nonlocal, 355, 379 pass, 26, 160, 381, 385 raise, 167, 211, 350, 360 return, 161, 162, 173 try, 163–171, 360 with, 369–372, 389 yield, 279, 281, 342–344,\n\n399–407\n\nsee also for loop and while loop\n\nstatement terminator (\\n), 66 static methods, 257 static variables, 255 @staticmethod(), 255 statistics.py (example), 152–156 stderr ﬁle object (sys module), 184,\n\n214\n\nstdin ﬁle object (sys module), 214 __stdout__ ﬁle object (sys module),\n\n214\n\nstdout ﬁle object (sys module), 181,\n\n214\n\nStopIteration (exception), 138, 279 __str__(), 243, 244, 250, 252 str type, 65–94, 383, 418–419\n\ncapitalize(), 73 center(), 73 comparing, 68–69 count(), 73, 75\n\nIndex\n\nstr type (cont.)\n\nencode(), 73, 92, 93, 296, 336, 419,\n\n441\n\nendswith(), 73, 75, 76 escapes, 66, 67 expandtabs(), 73 find(), 72–75, 133, 532 format(),73, 78–88,152, 156,186,\n\n189, 249, 306, 531\n\nformat speciﬁcations, 83–88 index(), 72–75 isalnum(), 73 isalpha(), 73 isdecimal(), 73 isdigit(), 73, 76 isidentifier(), 73, 348 islower(), 73 isnumeric(), 74 isprintable(), 74 isspace(), 74, 531 istitle(), 74 isupper(), 74 join(), 71, 72, 74, 189 literal concatenation, 78 ljust(), 74 lower(), 74, 76 lstrip(), 75, 76 maketrans(), 74, 77–78 methods, table of, 73, 74, 75 partition(), 74, 76 raw strings, 67, 204, 310, 500,\n\n556\n\nreplace(), 74, 77, 101 replication (*, *=), 72, 90 reversing, 71, 72 rfind(), 73, 75, 76 rindex(), 73, 75 rjust(), 74 rpartition(), 74, 76 rsplit(), 74 rstrip(), 75, 76 slicing, 69–71 slicing operator ([]), 69 split(), 74, 77, 509 splitlines(), 74",
      "content_length": 1868,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 633,
      "content": "Index\n\nstr type (cont.)\n\nstartswith(), 74, 75, 76 strip(), 75, 76 str() (built-in), 65, 136, 243, 250 swapcase(), 75 title(), 75, 90 translate(), 75, 77–78 triple quoted, 65, 156, 204 upper(), 75 zfill(), 75 striding; see slicing string attribute (match object), 507 string form, 82–83 string handling, 213–214 string literal concatenation, 78 string module, 130, 213 StringIO type (io module), 213–214,\n\n228\n\nstrings; see str type StringVar type (tkinter module),\n\n574, 590, 592\n\nstrip()\n\nbytearray type, 300 bytes type, 300 str type, 75, 76 strong typing, 17 strptime() (datetime.datetime type),\n\n309\n\nstruct module, 213, 296–298\n\ncalcsize(), 297 pack(), 296, 297, 301, 336 Struct type, 297, 302, 324, 336,\n\n462\n\nunpack(), 297, 302, 336\n\n__sub__() (-), 55, 253 sub()\n\nre module, 502, 504, 505 regex object, 503\n\nsubn()\n\nre module, 502 regex object, 503\n\n627\n\nsubprocess module, 440–442\n\ncall(), 209 Popen(), 441 sufﬁx; see extension sum() (built-in), 140, 396, 397 super() (built-in), 241, 244, 256, 276,\n\n282, 381, 385 .svg (extension), 525 SVG (Scalable Vector Graphics),\n\n525 swapcase()\n\nbytearray type, 300 bytes type, 300 str type, 75\n\nswitch statement; see dictionary\n\nbranching\n\nsymmetric_difference_update() (set\n\ntype), 123\n\nsymmetric_difference() frozenset type, 123 set type, 122, 123\n\nsync() (shelve module), 477 syntactic analysis, 514 syntax rules, 515 SyntaxError (exception), 54, 348,\n\n414–415\n\nsys module\n\nargv list, 41, 343 executable attribute, 441 exit(), 141, 215 float_info.epsilon attribute, 61,\n\n96, 343\n\ngetrecursionlimit(), 352 maxunicode attribute, 90, 92 modules attribute, 348 path attribute, 197 platform attribute, 160, 209, 344 setrecursionlimit(), 352 stderr ﬁle object, 184, 214 stdin ﬁle object, 214 __stdout__ ﬁle object, 214 stdout ﬁle object, 181, 214\n\nsystem() (os module), 444",
      "content_length": 1818,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 634,
      "content": "628\n\nT\n\ntan() (math module), 61 tanh() (math module), 61 tarfile module, 219, 221–222 .tar, .tar.gz, .tar.bz2 (extension),\n\n219, 221\n\nTcl/Tk, 569 TCP (Transmission Control Proto-\n\ncol), 225, 457\n\nTDD (Test Driven Development),\n\n426\n\ntell() (ﬁle object), 326, 329 telnetlib module, 226 tempfile module, 222 gettempdir(), 360\n\ntemporary ﬁles and directories, 222 terminal, 515 terminology, object-oriented, 235 Test Driven Development (TDD),\n\n426\n\ntestmod() (doctest module), 206 text ﬁles, 131, 305–312 TextFilter.py (example), 385 TextUtil.py (example), 202–207 textwrap module, 213 dedent(), 307 TextWrapper type, 306 wrap(), 306, 320\n\n.tgz (extension), 219, 221 this; see self object Thread type (threading module), 445,\n\n448, 450, 451, 452\n\nrun(), 445, 448 start(), 445\n\nthreading module, 445–453\n\nLock type, 452, 467 Thread type, 445, 448, 450, 451,\n\n452\n\ntime module, 216\n\nlocaltime(), 217 time(), 217\n\ntimeit module, 432–434 timer, single shot, 582, 586\n\nIndex\n\ntitle()\n\nbytearray type, 300 bytes type, 300 str type, 75, 90\n\nTk type (tkinter module), 572, 578,\n\n589\n\ntkinter.filedialog module askopenfilename(), 586 asksaveasfilename(), 585 tkinter.messagebox module\n\naskyesno(), 589 askyesnocancel(), 584 showwarning(), 585, 587\n\ntkinter module, 569\n\nButton type, 581, 591 DoubleVar type, 574 END constant, 583, 587, 588 Entry type, 591 Frame type, 573, 581, 591 IntVar type, 574 Label type, 574, 582, 583, 591 Listbox type, 582, 583, 587, 588,\n\n589\n\nMenu type, 579, 580 PhotoImage type, 581 Scale type, 574, 575 Scrollbar type, 582 StringVar type, 574, 590, 592 Tk type, 572, 578, 589 TopLevel type, 590\n\ntoday() (datetime.date type), 187,\n\n477\n\ntokenizing, 514 toordinal() (datetime.date type),\n\n301\n\nTopLevel type (tkinter module), 590 trace module, 360 traceback, 415–420 translate()\n\nbytearray type, 300 bytes type, 300 str type, 75, 77–78\n\nTransmission Control Protocol\n\n(TCP), 225, 457\n\ntriple quoted strings, 65, 156, 204",
      "content_length": 1936,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 635,
      "content": "Index\n\nTrue (built-in constant); see bool\n\ntype\n\n__truediv__() (/), 31, 55, 253 trunc() (math module), 61 truncate() (ﬁle object), 326, 331 truth values; see bool type try (statement), 163–171, 360\n\nsee also exceptions and exception\n\nhandling\n\ntuple type, 108–111, 383\n\ncomparing, 108 count(), 108 index(), 108 parentheses policy, 109 replication (*, *=), 108 slicing, 108 tuple() (built-in), 108\n\ntype() (built-in), 18 type checking, 361 type conversion; see conversions type type, 391\n\n__init__(), 391, 392 __new__(), 392, 394 type() (built-in), 348, 349\n\nTypeError (exception), 57, 135, 138,\n\n146,167,173,179,197,242,258, 259, 274, 364, 380 typing; see dynamic typing\n\nU\n\nUCS-2/4 encoding (Unicode), 92 UDP (UserDatagramProtocol),225,\n\n457\n\nuncompressing ﬁles, 219 underscore (_), 53 unescape() (xml.sax.saxutils mod-\n\nule), 226\n\nunhandled exception; see traceback Unicode, 9, 91–94, 505\n\ncollation order, 68–69 identiﬁers, 53 strings; see str type, 65–94 UCS-2/4 encoding, 92\n\n629\n\nUnicode (cont.)\n\nUTF-8/16/32 encoding, 92, 94,\n\n228\n\nsee also character encodings\n\nunicodedata module, 68 category(), 361 name(), 90 normalize(), 68\n\nUnicodeDecodeError (exception), 167 UnicodeEncodeError (exception), 93 unimplementing methods, 258–261 union() (set type), 122, 123 uniquewords1.py (example), 130 uniquewords2.py (example), 136 unittest module, 228, 426–432 Unix-style paths, 142 unordered collections; see dict, frozenset, and set types unpack() (struct module), 297, 302,\n\n336\n\nunpacking (* and **), 110, 114–115, 162, 177–180, 187, 268, 304, 336\n\nuntar.py (example), 221 UPDATE (SQL statement), 484 update()\n\ndict type, 129, 188, 276, 295 set type, 123\n\nupdating dictionaries, 128 updating lists, 115 upper()\n\nbytearray type, 293, 301 bytes type, 293, 301 str type, 75 urllib package, 226 User DatagramProtocol(UDP),225,\n\n457\n\nUTC (Coordinated Universal Time),\n\n216\n\nutcnow() (datetime.datetime type),\n\n217\n\nUTF-8/16/32encoding (Unicode),92,\n\n94, 228 uu module, 219",
      "content_length": 1970,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 636,
      "content": "630\n\nV\n\nValid.py (example), 407–409 ValueError (exception), 57, 272, 279 values() (dict type), 128, 129 variables; see object references variables,callable;seefunctionsand\n\nmethods\n\nvariables, class, 255, 465 variables, global, 180 variables, instance, 241 variables, local, 163 variables, names; see identiﬁers variables, static, 255 vars() (built-in), 349 version control, 414 view (dict type), 129 virtual subclasses, 391\n\nW\n\nwalk() (os module), 223, 224, 406 .wav (extension), 219 wave module, 219 weak reference, 581 weakref module, 218 Web Server Gateway Interface\n\n(WSGI), 225 webbrowser module, 589 while loop, 141, 161–162 wildcard expansion, 343 Windows, ﬁle association, 11 windows, resizable, 582–583, 591 with (statement), 369–372, 389 wrap() (textwrap module), 306, 320 @wraps() (functools module), 357 writable() (ﬁle object), 326 write()\n\nﬁle object, 131, 214, 301, 326, 327 gzip module, 301\n\nwritelines() (ﬁle object), 326 WSGI (Web Server Gateway Inter-\n\nface), 225\n\nwsgiref package, 225 wxPython, 570, 593\n\nIndex\n\nX\n\nxdrlib module, 219 xml.dom.minidom module, 226 xml.dom module, 226, 316–319 XML encoding, 314 XML escapes, 186, 316 xml.etree.ElementTree module, 227,\n\n227–228\n\nxml.etree package, 313–316 XML ﬁle format, 94 XML ﬁles, 312–323 XML parsers, expat, 315, 317, 318 xml.parsers.expat module, 227 xml.sax module, 226, 321–323 xml.sax.saxutils module, 186, 226\n\nescape(), 186, 226, 320 quoteattr(), 226, 320 unescape(), 226 xmlrpc package, 226 XmlShadow.py (example), 373 __xor__() (^), 57, 253 .xpm (extension), 268\n\nY\n\nyield (statement), 279, 281, 342–344, 399–407\n\nZ\n\nZeroDivisionError (exception), 165,\n\n416 zfill()\n\nbytearray type, 301 bytes type, 301 str type, 75\n\n.zip (extension), 219 zip() (built-in), 127, 140, 143–144,\n\n205, 389\n\nzipfile module, 219",
      "content_length": 1787,
      "extraction_method": "Unstructured"
    }
  ]
}